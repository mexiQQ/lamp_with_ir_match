


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.08 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 60.14it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9992716374753432
highest_index [0]
highest [0.9992716374753432]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.0017677545547485 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9434316158294678 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9404582977294922 for ['[CLS] ronnie huff [SEP]']
[Init] best rec loss: 0.9324178695678711 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9268800020217896 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8593006730079651 for ['[CLS] panel officer [SEP]']
[Init] best perm rec loss: 0.8530735373497009 for ['[CLS] officer panel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.449 (perp=11.151, rec=0.204, cos=0.014), tot_loss_proj:2.630 [t=0.25s]
prediction: ['[CLS] disappointed really [SEP]']
[ 100/2000] tot_loss=2.329 (perp=11.087, rec=0.109, cos=0.003), tot_loss_proj:2.527 [t=0.24s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 150/2000] tot_loss=2.286 (perp=11.087, rec=0.067, cos=0.002), tot_loss_proj:2.538 [t=0.24s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 200/2000] tot_loss=2.277 (perp=11.087, rec=0.058, cos=0.001), tot_loss_proj:2.545 [t=0.24s]
prediction: ['[CLS] disappointed slightly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.098 (perp=10.252, rec=0.046, cos=0.002), tot_loss_proj:2.117 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.107 (perp=10.252, rec=0.055, cos=0.001), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.114 (perp=10.252, rec=0.062, cos=0.001), tot_loss_proj:2.116 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.112 (perp=10.252, rec=0.061, cos=0.001), tot_loss_proj:2.127 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.110 (perp=10.252, rec=0.059, cos=0.001), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.103 (perp=10.252, rec=0.051, cos=0.001), tot_loss_proj:2.116 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.117 (perp=10.252, rec=0.065, cos=0.001), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.116 (perp=10.252, rec=0.064, cos=0.001), tot_loss_proj:2.126 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.114 (perp=10.252, rec=0.062, cos=0.001), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.123 (perp=10.252, rec=0.071, cos=0.001), tot_loss_proj:2.131 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.105 (perp=10.252, rec=0.053, cos=0.001), tot_loss_proj:2.124 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.113 (perp=10.252, rec=0.061, cos=0.001), tot_loss_proj:2.123 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.106 (perp=10.252, rec=0.055, cos=0.001), tot_loss_proj:2.117 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.110 (perp=10.252, rec=0.058, cos=0.001), tot_loss_proj:2.113 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.117 (perp=10.252, rec=0.066, cos=0.001), tot_loss_proj:2.115 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.117 (perp=10.252, rec=0.065, cos=0.001), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.107 (perp=10.252, rec=0.056, cos=0.001), tot_loss_proj:2.108 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.118 (perp=10.252, rec=0.066, cos=0.001), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.102 (perp=10.252, rec=0.050, cos=0.001), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.116 (perp=10.252, rec=0.064, cos=0.001), tot_loss_proj:2.129 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.110 (perp=10.252, rec=0.058, cos=0.001), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.112 (perp=10.252, rec=0.060, cos=0.001), tot_loss_proj:2.116 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.110 (perp=10.252, rec=0.058, cos=0.001), tot_loss_proj:2.120 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.107 (perp=10.252, rec=0.055, cos=0.001), tot_loss_proj:2.105 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.103 (perp=10.252, rec=0.051, cos=0.001), tot_loss_proj:2.122 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.100 (perp=10.252, rec=0.049, cos=0.001), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.099 (perp=10.252, rec=0.047, cos=0.001), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.104 (perp=10.252, rec=0.052, cos=0.001), tot_loss_proj:2.121 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.101 (perp=10.252, rec=0.049, cos=0.001), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.128 (perp=10.252, rec=0.076, cos=0.001), tot_loss_proj:2.121 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.098 (perp=10.252, rec=0.046, cos=0.001), tot_loss_proj:2.128 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.119 (perp=10.252, rec=0.068, cos=0.001), tot_loss_proj:2.120 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.113 (perp=10.252, rec=0.061, cos=0.001), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.110 (perp=10.252, rec=0.059, cos=0.001), tot_loss_proj:2.117 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.106 (perp=10.252, rec=0.054, cos=0.001), tot_loss_proj:2.120 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.130 (perp=10.252, rec=0.078, cos=0.001), tot_loss_proj:2.124 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:09:39 | total time: 0:09:39


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9993549160877631
highest_index [0]
highest [0.9993549160877631]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.019070029258728 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9784805774688721 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.8989198803901672 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 0.8676603436470032 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8272038102149963 for ['[CLS] passage erupted [SEP]']
[Init] best rec loss: 0.8209529519081116 for ['[CLS] siam presidents [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.402 (perp=10.892, rec=0.220, cos=0.003), tot_loss_proj:2.535 [t=0.24s]
prediction: ['[CLS] wonderful splendid [SEP]']
[ 100/2000] tot_loss=2.215 (perp=10.288, rec=0.156, cos=0.001), tot_loss_proj:2.355 [t=0.24s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.128 (perp=10.288, rec=0.069, cos=0.001), tot_loss_proj:2.348 [t=0.24s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.128 (perp=10.288, rec=0.069, cos=0.001), tot_loss_proj:2.348 [t=0.24s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.899 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.896 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.902 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.895 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.881 (perp=9.171, rec=0.046, cos=0.001), tot_loss_proj:1.897 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.901 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.890 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.910 (perp=9.171, rec=0.075, cos=0.001), tot_loss_proj:1.889 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.901 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.893 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.888 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.889 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.901 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.905 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.896 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.892 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.901 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.897 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.906 (perp=9.171, rec=0.071, cos=0.001), tot_loss_proj:1.899 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.909 (perp=9.171, rec=0.074, cos=0.001), tot_loss_proj:1.904 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.902 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.899 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.889 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.892 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.910 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.899 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.891 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.902 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.905 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.893 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.906 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.894 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.897 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.886 (perp=9.171, rec=0.050, cos=0.001), tot_loss_proj:1.894 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.892 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.897 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.884 (perp=9.171, rec=0.049, cos=0.001), tot_loss_proj:1.910 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.894 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.894 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.906 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.899 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.910 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.904 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.904 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.905 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.903 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.901 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.893 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.902 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.917 (perp=9.171, rec=0.081, cos=0.001), tot_loss_proj:1.890 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.892 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.895 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.901 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:09:38 | total time: 0:19:17


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9994334295644651
highest_index [0]
highest [0.9994334295644651]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.8400301933288574 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.8265790939331055 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best rec loss: 0.8116205930709839 for ['[CLS] dailypol food [SEP]']
[Init] best rec loss: 0.8050260543823242 for ['[CLS] just percussion universal [SEP]']
[Init] best rec loss: 0.7912572026252747 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 0.7776637077331543 for ['[CLS] we would working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.324 (perp=10.095, rec=0.290, cos=0.015), tot_loss_proj:2.629 [t=0.24s]
prediction: ['[CLS] gaining very momentum [SEP]']
[ 100/2000] tot_loss=1.811 (perp=8.515, rec=0.107, cos=0.002), tot_loss_proj:1.811 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=1.774 (perp=8.515, rec=0.070, cos=0.001), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=1.780 (perp=8.515, rec=0.076, cos=0.001), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.805 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.794 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.794 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.790 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.787 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.777 (perp=8.515, rec=0.073, cos=0.001), tot_loss_proj:1.792 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.757 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.795 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.803 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.785 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.756 (perp=8.515, rec=0.052, cos=0.001), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.788 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.789 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.798 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.774 (perp=8.515, rec=0.070, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.756 (perp=8.515, rec=0.052, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.771 (perp=8.515, rec=0.067, cos=0.001), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.790 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.794 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.802 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.770 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.782 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.762 (perp=8.515, rec=0.058, cos=0.001), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.804 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.757 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.789 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.771 (perp=8.515, rec=0.067, cos=0.001), tot_loss_proj:1.790 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:09:36 | total time: 0:28:54


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.999300207712396
highest_index [0]
highest [0.999300207712396]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.0158096551895142 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9032942652702332 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8778855204582214 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8744809627532959 for ['[CLS] role bart [SEP]']
[Init] best rec loss: 0.8518046140670776 for ['[CLS] gallons professor [SEP]']
[Init] best rec loss: 0.8455400466918945 for ['[CLS] canterbury havoc [SEP]']
[Init] best rec loss: 0.8341601490974426 for ['[CLS] anthony robin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.341 (perp=10.476, rec=0.241, cos=0.005), tot_loss_proj:2.443 [t=0.24s]
prediction: ['[CLS] flawless flawless [SEP]']
[ 100/2000] tot_loss=2.128 (perp=10.224, rec=0.081, cos=0.002), tot_loss_proj:2.365 [t=0.25s]
prediction: ['[CLS] film flawless [SEP]']
[ 150/2000] tot_loss=2.110 (perp=10.224, rec=0.063, cos=0.001), tot_loss_proj:2.369 [t=0.25s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.112 (perp=10.224, rec=0.066, cos=0.001), tot_loss_proj:2.367 [t=0.24s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.770 (perp=8.385, rec=0.091, cos=0.002), tot_loss_proj:1.756 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.750 (perp=8.385, rec=0.072, cos=0.001), tot_loss_proj:1.752 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.734 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.753 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.756 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.734 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.751 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.753 (perp=8.385, rec=0.075, cos=0.001), tot_loss_proj:1.755 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.733 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.740 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.738 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.741 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.757 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.756 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.760 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.739 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.740 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.753 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.733 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.750 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.731 (perp=8.385, rec=0.053, cos=0.001), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.749 (perp=8.385, rec=0.070, cos=0.001), tot_loss_proj:1.759 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.736 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.751 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.740 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.763 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.752 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.733 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.751 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.747 (perp=8.385, rec=0.069, cos=0.001), tot_loss_proj:1.762 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.747 (perp=8.385, rec=0.069, cos=0.001), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.750 (perp=8.385, rec=0.071, cos=0.001), tot_loss_proj:1.747 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.725 (perp=8.385, rec=0.047, cos=0.001), tot_loss_proj:1.760 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.746 (perp=8.385, rec=0.068, cos=0.001), tot_loss_proj:1.750 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.754 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.745 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.755 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.728 (perp=8.385, rec=0.049, cos=0.001), tot_loss_proj:1.754 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.744 (perp=8.385, rec=0.066, cos=0.001), tot_loss_proj:1.756 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.730 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.754 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:09:36 | total time: 0:38:30


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.999229949404915
highest_index [0]
highest [0.999229949404915]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.0350229740142822 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9845936894416809 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9643853306770325 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9641659259796143 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9627823233604431 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 0.9362619519233704 for ['[CLS] who table christ [SEP]']
[Init] best rec loss: 0.9233399629592896 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.8893289566040039 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.124 (perp=9.705, rec=0.176, cos=0.007), tot_loss_proj:2.154 [t=0.28s]
prediction: ['[CLS] tiresomently [SEP]']
[ 100/2000] tot_loss=1.591 (perp=7.515, rec=0.086, cos=0.002), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.582 (perp=7.515, rec=0.078, cos=0.002), tot_loss_proj:1.574 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.565 (perp=7.515, rec=0.060, cos=0.002), tot_loss_proj:1.580 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.573 (perp=7.515, rec=0.068, cos=0.001), tot_loss_proj:1.569 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.570 (perp=7.515, rec=0.065, cos=0.001), tot_loss_proj:1.568 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.567 (perp=7.515, rec=0.063, cos=0.001), tot_loss_proj:1.583 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.564 (perp=7.515, rec=0.059, cos=0.001), tot_loss_proj:1.563 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.559 (perp=7.515, rec=0.055, cos=0.001), tot_loss_proj:1.576 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.565 (perp=7.515, rec=0.061, cos=0.001), tot_loss_proj:1.559 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.574 (perp=7.515, rec=0.069, cos=0.002), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.565 (perp=7.515, rec=0.060, cos=0.002), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.564 (perp=7.515, rec=0.059, cos=0.002), tot_loss_proj:1.566 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.563 (perp=7.515, rec=0.058, cos=0.002), tot_loss_proj:1.571 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.557 (perp=7.515, rec=0.052, cos=0.001), tot_loss_proj:1.566 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.569 (perp=7.515, rec=0.064, cos=0.002), tot_loss_proj:1.562 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.562 (perp=7.515, rec=0.057, cos=0.002), tot_loss_proj:1.553 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.563 (perp=7.515, rec=0.058, cos=0.002), tot_loss_proj:1.569 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.558 (perp=7.515, rec=0.054, cos=0.002), tot_loss_proj:1.564 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.565 (perp=7.515, rec=0.061, cos=0.002), tot_loss_proj:1.565 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.563 (perp=7.515, rec=0.058, cos=0.002), tot_loss_proj:1.568 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.570 (perp=7.515, rec=0.065, cos=0.002), tot_loss_proj:1.562 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.560 (perp=7.515, rec=0.055, cos=0.002), tot_loss_proj:1.561 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.567 (perp=7.515, rec=0.062, cos=0.002), tot_loss_proj:1.575 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.563 (perp=7.515, rec=0.058, cos=0.002), tot_loss_proj:1.572 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.566 (perp=7.515, rec=0.061, cos=0.002), tot_loss_proj:1.562 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.562 (perp=7.515, rec=0.058, cos=0.002), tot_loss_proj:1.558 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.568 (perp=7.515, rec=0.063, cos=0.002), tot_loss_proj:1.560 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.562 (perp=7.515, rec=0.057, cos=0.002), tot_loss_proj:1.558 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.563 (perp=7.515, rec=0.059, cos=0.002), tot_loss_proj:1.561 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.560 (perp=7.515, rec=0.056, cos=0.002), tot_loss_proj:1.567 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.566 (perp=7.515, rec=0.061, cos=0.002), tot_loss_proj:1.559 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.559 (perp=7.515, rec=0.054, cos=0.002), tot_loss_proj:1.564 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.561 (perp=7.515, rec=0.056, cos=0.002), tot_loss_proj:1.554 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.564 (perp=7.515, rec=0.060, cos=0.002), tot_loss_proj:1.565 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.561 (perp=7.515, rec=0.057, cos=0.002), tot_loss_proj:1.563 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.563 (perp=7.515, rec=0.059, cos=0.002), tot_loss_proj:1.574 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.565 (perp=7.515, rec=0.061, cos=0.002), tot_loss_proj:1.568 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.565 (perp=7.515, rec=0.060, cos=0.002), tot_loss_proj:1.573 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.575 (perp=7.515, rec=0.071, cos=0.002), tot_loss_proj:1.585 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:09:23 | total time: 0:47:54


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9993648656803427
highest_index [0]
highest [0.9993648656803427]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9518389701843262 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9517901539802551 for ['[CLS] stay orgasm [SEP]']
[Init] best rec loss: 0.9451121091842651 for ['[CLS] territorial half [SEP]']
[Init] best rec loss: 0.9313843846321106 for ['[CLS] pleasant favorable [SEP]']
[Init] best rec loss: 0.9138829708099365 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 0.8891943693161011 for ['[CLS] quiet. [SEP]']
[Init] best perm rec loss: 0.8871971964836121 for ['[CLS]. quiet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.455 (perp=11.369, rec=0.177, cos=0.004), tot_loss_proj:3.589 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
[ 100/2000] tot_loss=2.401 (perp=11.369, rec=0.124, cos=0.004), tot_loss_proj:3.580 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
[ 150/2000] tot_loss=2.381 (perp=11.369, rec=0.104, cos=0.003), tot_loss_proj:3.580 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
[ 200/2000] tot_loss=2.589 (perp=12.316, rec=0.122, cos=0.003), tot_loss_proj:2.526 [t=0.24s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.504 (perp=11.854, rec=0.130, cos=0.003), tot_loss_proj:2.571 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 300/2000] tot_loss=2.494 (perp=11.854, rec=0.119, cos=0.003), tot_loss_proj:2.568 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.490 (perp=11.854, rec=0.116, cos=0.003), tot_loss_proj:2.562 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.503 (perp=11.854, rec=0.129, cos=0.004), tot_loss_proj:2.577 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/2000] tot_loss=2.499 (perp=11.854, rec=0.125, cos=0.003), tot_loss_proj:2.560 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.484 (perp=11.854, rec=0.110, cos=0.003), tot_loss_proj:2.585 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.487 (perp=11.854, rec=0.112, cos=0.003), tot_loss_proj:2.584 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 600/2000] tot_loss=2.476 (perp=11.854, rec=0.102, cos=0.003), tot_loss_proj:2.582 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.482 (perp=11.854, rec=0.108, cos=0.003), tot_loss_proj:2.579 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.473 (perp=11.854, rec=0.099, cos=0.003), tot_loss_proj:2.574 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 750/2000] tot_loss=2.478 (perp=11.854, rec=0.104, cos=0.003), tot_loss_proj:2.580 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.480 (perp=11.854, rec=0.106, cos=0.003), tot_loss_proj:2.576 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.468 (perp=11.854, rec=0.094, cos=0.003), tot_loss_proj:2.574 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 900/2000] tot_loss=2.465 (perp=11.854, rec=0.091, cos=0.003), tot_loss_proj:2.577 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.449 (perp=11.854, rec=0.076, cos=0.002), tot_loss_proj:2.577 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1000/2000] tot_loss=2.438 (perp=11.854, rec=0.065, cos=0.001), tot_loss_proj:2.577 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1050/2000] tot_loss=2.429 (perp=11.854, rec=0.057, cos=0.001), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1100/2000] tot_loss=2.432 (perp=11.854, rec=0.060, cos=0.001), tot_loss_proj:2.580 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1150/2000] tot_loss=2.423 (perp=11.854, rec=0.051, cos=0.001), tot_loss_proj:2.575 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1200/2000] tot_loss=2.429 (perp=11.854, rec=0.057, cos=0.001), tot_loss_proj:2.574 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1250/2000] tot_loss=2.441 (perp=11.854, rec=0.068, cos=0.001), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1300/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.572 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1350/2000] tot_loss=2.429 (perp=11.854, rec=0.057, cos=0.001), tot_loss_proj:2.572 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1400/2000] tot_loss=2.442 (perp=11.854, rec=0.069, cos=0.001), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1450/2000] tot_loss=2.445 (perp=11.854, rec=0.073, cos=0.001), tot_loss_proj:2.577 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1500/2000] tot_loss=2.439 (perp=11.854, rec=0.067, cos=0.001), tot_loss_proj:2.579 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1550/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.577 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1600/2000] tot_loss=2.443 (perp=11.854, rec=0.071, cos=0.001), tot_loss_proj:2.580 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1650/2000] tot_loss=2.430 (perp=11.854, rec=0.058, cos=0.001), tot_loss_proj:2.580 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1700/2000] tot_loss=2.421 (perp=11.854, rec=0.049, cos=0.001), tot_loss_proj:2.574 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1750/2000] tot_loss=2.437 (perp=11.854, rec=0.064, cos=0.001), tot_loss_proj:2.579 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1800/2000] tot_loss=2.436 (perp=11.854, rec=0.064, cos=0.001), tot_loss_proj:2.579 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1850/2000] tot_loss=2.424 (perp=11.854, rec=0.052, cos=0.001), tot_loss_proj:2.580 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1900/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.572 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1950/2000] tot_loss=2.430 (perp=11.854, rec=0.058, cos=0.001), tot_loss_proj:2.577 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[2000/2000] tot_loss=2.424 (perp=11.854, rec=0.052, cos=0.001), tot_loss_proj:2.570 [t=0.25s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 183.333

input #5 time: 0:09:39 | total time: 0:57:33


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.9992509755027666
highest_index [0]
highest [0.9992509755027666]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9576692581176758 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9543807506561279 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9314477443695068 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.8687410354614258 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.8670455813407898 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.8099329471588135 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7884305119514465 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.7730320692062378 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.7621805667877197 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 0.7525128126144409 for ['[CLS] too u2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.605 (perp=6.812, rec=0.229, cos=0.014), tot_loss_proj:2.711 [t=0.24s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.712 (perp=8.088, rec=0.092, cos=0.003), tot_loss_proj:1.700 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.695 (perp=8.088, rec=0.075, cos=0.002), tot_loss_proj:1.717 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.683 (perp=8.088, rec=0.064, cos=0.002), tot_loss_proj:1.705 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.690 (perp=8.088, rec=0.071, cos=0.002), tot_loss_proj:1.689 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.675 (perp=8.088, rec=0.056, cos=0.002), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.695 (perp=8.088, rec=0.076, cos=0.001), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.690 (perp=8.088, rec=0.071, cos=0.001), tot_loss_proj:1.706 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.673 (perp=8.088, rec=0.054, cos=0.001), tot_loss_proj:1.690 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.675 (perp=8.088, rec=0.056, cos=0.001), tot_loss_proj:1.689 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.683 (perp=8.088, rec=0.064, cos=0.001), tot_loss_proj:1.705 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.676 (perp=8.088, rec=0.057, cos=0.001), tot_loss_proj:1.707 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.686 (perp=8.088, rec=0.067, cos=0.001), tot_loss_proj:1.695 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.662 (perp=8.088, rec=0.043, cos=0.001), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.688 (perp=8.088, rec=0.069, cos=0.001), tot_loss_proj:1.698 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.673 (perp=8.088, rec=0.054, cos=0.001), tot_loss_proj:1.695 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.687 (perp=8.088, rec=0.068, cos=0.001), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.691 (perp=8.088, rec=0.072, cos=0.001), tot_loss_proj:1.701 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.685 (perp=8.088, rec=0.066, cos=0.001), tot_loss_proj:1.703 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.685 (perp=8.088, rec=0.066, cos=0.001), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.677 (perp=8.088, rec=0.058, cos=0.001), tot_loss_proj:1.681 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.688 (perp=8.088, rec=0.068, cos=0.001), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.680 (perp=8.088, rec=0.061, cos=0.001), tot_loss_proj:1.688 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.688 (perp=8.088, rec=0.069, cos=0.001), tot_loss_proj:1.679 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.676 (perp=8.088, rec=0.057, cos=0.002), tot_loss_proj:1.707 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.678 (perp=8.088, rec=0.059, cos=0.001), tot_loss_proj:1.687 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.669 (perp=8.088, rec=0.050, cos=0.001), tot_loss_proj:1.687 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.697 (perp=8.088, rec=0.078, cos=0.001), tot_loss_proj:1.715 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.675 (perp=8.088, rec=0.056, cos=0.001), tot_loss_proj:1.686 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.682 (perp=8.088, rec=0.063, cos=0.001), tot_loss_proj:1.691 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.675 (perp=8.088, rec=0.056, cos=0.001), tot_loss_proj:1.690 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.667 (perp=8.088, rec=0.048, cos=0.001), tot_loss_proj:1.681 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.684 (perp=8.088, rec=0.065, cos=0.001), tot_loss_proj:1.693 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.668 (perp=8.088, rec=0.049, cos=0.001), tot_loss_proj:1.680 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.671 (perp=8.088, rec=0.052, cos=0.001), tot_loss_proj:1.685 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.700 (perp=8.088, rec=0.081, cos=0.001), tot_loss_proj:1.685 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.665 (perp=8.088, rec=0.046, cos=0.001), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.687 (perp=8.088, rec=0.068, cos=0.001), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.687 (perp=8.088, rec=0.067, cos=0.001), tot_loss_proj:1.695 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.684 (perp=8.088, rec=0.064, cos=0.001), tot_loss_proj:1.693 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 185.714

input #6 time: 0:09:14 | total time: 1:06:48


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.99917817891147
highest_index [0]
highest [0.99917817891147]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9091315269470215 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8410571217536926 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8275896310806274 for ['[CLS] minor bonnetmme near routine cluster confirmed pray mail guy smooth us empty bleeding interior [CLS] relegated seen tapes in beast risk contributingds addedores [SEP]']
[Init] best rec loss: 0.7972196936607361 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best perm rec loss: 0.7952162623405457 for ['[CLS] dependingzed alec disease battalion tourism none consisting sony pacific main moffat animal on manual career classicside mukherjee madagascar 17th blow rannies gold life [SEP]']
[Init] best perm rec loss: 0.7940846085548401 for ['[CLS] classics tourism alec depending gold ran manual pacific nonezed battalion career sony main 17th moffat disease mukherjee madagascar animalide consisting on life blownies [SEP]']
[Init] best perm rec loss: 0.7933159470558167 for ['[CLS] diseasenies life sony manual career moffat depending classics consisting main blow gold 17thide animal mukherjee ran battalion nonezed on alec pacific tourism madagascar [SEP]']
[Init] best perm rec loss: 0.7899006605148315 for ['[CLS] blow mukherjee none battalion moffat dependingzed gold 17th ran consistingnies career manual sony madagascaride disease tourism alec pacific classics animal life main on [SEP]']
[Init] best perm rec loss: 0.7890241742134094 for ['[CLS] madagascar disease main depending mukherjee tourism blownies consisting sony animal gold pacific onzed alec moffat battalion none manual life career classics ranide 17th [SEP]']
[Init] best perm rec loss: 0.7871341705322266 for ['[CLS] on sony diseasenies 17th manualide ran madagascarzed gold animal life mukherjee main battalion none classics moffat tourism career blow alec depending pacific consisting [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.519 (perp=10.825, rec=0.339, cos=0.015), tot_loss_proj:3.090 [t=0.25s]
prediction: ['[CLS] facade nobody problem ugly least elizabeth accident least hairs ugly ugly nasty of itunes prostitution issue no no character or. office phone problem government fraud [SEP]']
[ 100/2000] tot_loss=2.370 (perp=10.379, rec=0.282, cos=0.012), tot_loss_proj:2.879 [t=0.25s]
prediction: ['[CLS] neighborhood no problem is tackles he truth leastness ugly ugly ugly - is sort has no no character or. lifestyle phone problem mind fraud [SEP]']
[ 150/2000] tot_loss=2.048 (perp=9.142, rec=0.214, cos=0.006), tot_loss_proj:2.622 [t=0.25s]
prediction: ['[CLS] problem no problem is really he movement least is ugly ugly ugly. is relationship has no no character or character attorney problem problem mind trying [SEP]']
[ 200/2000] tot_loss=2.011 (perp=9.089, rec=0.189, cos=0.004), tot_loss_proj:2.909 [t=0.26s]
prediction: ['[CLS] cute no problem is really he movement least is ugly ugly ugly. is relationship has no no character no character i problem or mind tested [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.848 (perp=8.322, rec=0.180, cos=0.003), tot_loss_proj:3.355 [t=0.25s]
prediction: ['[CLS] cute has no problem is really he introduced only is ugly ugly ugly or relationship has no no character ; character i character or mind love [SEP]']
[ 300/2000] tot_loss=1.973 (perp=9.026, rec=0.164, cos=0.004), tot_loss_proj:3.644 [t=0.25s]
prediction: ['[CLS] cute has no problem is here he introducedr is no ugly ugly, loved factor no no character. character eable or mind love [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.970 (perp=9.038, rec=0.159, cos=0.004), tot_loss_proj:3.106 [t=0.25s]
prediction: ['[CLS] no has no problem which here he introduced only is i ugly ugly here love factor no cute factor ; character moneyable or mind ( [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.762 (perp=8.033, rec=0.153, cos=0.003), tot_loss_proj:3.421 [t=0.25s]
prediction: ['[CLS] no has no problem. here he introduced love is i ugly ugly here love factor no cute factor ; character. orable mind. [SEP]']
[ 450/2000] tot_loss=1.747 (perp=8.033, rec=0.138, cos=0.002), tot_loss_proj:3.421 [t=0.25s]
prediction: ['[CLS] no has no problem. here he introduced love is i ugly ugly here love factor no cute factor ; character. orable mind. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.735 (perp=8.015, rec=0.130, cos=0.002), tot_loss_proj:3.012 [t=0.25s]
prediction: ['[CLS] no has no problem, really he introduced ugly is i only ugly here love factor no cute factor ; character. orable mind. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.663 (perp=7.695, rec=0.121, cos=0.002), tot_loss_proj:2.525 [t=0.25s]
prediction: ['[CLS] no has introduced no problem ; really he ugly is i only ugly here love factor no cute factor ; character. orable mind. [SEP]']
[ 600/2000] tot_loss=1.717 (perp=7.953, rec=0.125, cos=0.002), tot_loss_proj:2.713 [t=0.25s]
prediction: ['[CLS] no has introduced no problem ; here he ugly is i only ugly here love factor no cute factor ; character. orable mind, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.640 (perp=7.622, rec=0.114, cos=0.002), tot_loss_proj:2.814 [t=0.25s]
prediction: ['[CLS] no has introduced no problem ; here he ugly is i only ugly ; here love factor no cute factor character. orable mind, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.639 (perp=7.622, rec=0.113, cos=0.002), tot_loss_proj:2.822 [t=0.25s]
prediction: ['[CLS] no has introduced no problem ; here he ugly is i only ugly ; here love factor no cute factor character. orable mind, [SEP]']
[ 750/2000] tot_loss=1.660 (perp=7.745, rec=0.109, cos=0.002), tot_loss_proj:2.823 [t=0.25s]
prediction: ['[CLS] no has introduced no problem ;. he ugly is i only ugly ; here love factor no cute factor character. orable mind, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.604 (perp=7.499, rec=0.103, cos=0.002), tot_loss_proj:2.930 [t=0.25s]
prediction: ['[CLS] no has ugly no problem ;. he introduced is i only ugly ; here love factor no cute factor character. orable mind, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.613 (perp=7.499, rec=0.112, cos=0.002), tot_loss_proj:2.927 [t=0.25s]
prediction: ['[CLS] no has ugly no problem ;. he introduced is i only ugly ; here love factor no cute factor character. orable mind, [SEP]']
[ 900/2000] tot_loss=1.576 (perp=7.372, rec=0.100, cos=0.002), tot_loss_proj:2.719 [t=0.26s]
prediction: ['[CLS] no has ugly no problem ;. he. is i only ugly ; here love factor no cute factor character. orable mind, [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.522 (perp=7.100, rec=0.100, cos=0.002), tot_loss_proj:2.637 [t=0.25s]
prediction: ['[CLS] no has ugly no problem ; he.. is i only ugly ; here love factor no cute factor character. orable mind, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.512 (perp=7.008, rec=0.109, cos=0.002), tot_loss_proj:2.690 [t=0.25s]
prediction: ['[CLS] no has ugly no problem ; he.. is i only ugly ; here loveable no cute factor character. orable mind, [SEP]']
[1050/2000] tot_loss=1.501 (perp=7.008, rec=0.098, cos=0.002), tot_loss_proj:2.693 [t=0.25s]
prediction: ['[CLS] no has ugly no problem ; he.. is i only ugly ; here loveable no cute factor character. orable mind, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.473 (perp=6.860, rec=0.099, cos=0.002), tot_loss_proj:2.636 [t=0.25s]
prediction: ['[CLS] no has ugly no problem ; he.. is i only ugly ; here loveable no cute factor character. orable mind. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.466 (perp=6.860, rec=0.092, cos=0.002), tot_loss_proj:2.637 [t=0.25s]
prediction: ['[CLS] no has ugly no problem ; he.. is i only ugly ; here loveable no cute factor character. orable mind. [SEP]']
[1200/2000] tot_loss=1.469 (perp=6.860, rec=0.095, cos=0.002), tot_loss_proj:2.633 [t=0.25s]
prediction: ['[CLS] no has ugly no problem ; he.. is i only ugly ; here loveable no cute factor character. orable mind. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.502 (perp=6.996, rec=0.101, cos=0.002), tot_loss_proj:2.473 [t=0.25s]
prediction: ['[CLS] no has ugly. problem ;.. he is i only ugly ; here loveable no cute factor character. orable mind. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.492 (perp=6.996, rec=0.092, cos=0.002), tot_loss_proj:2.471 [t=0.25s]
prediction: ['[CLS] no has ugly. problem ;.. he is i only ugly ; here loveable no cute factor character. orable mind. [SEP]']
[1350/2000] tot_loss=1.497 (perp=6.996, rec=0.096, cos=0.002), tot_loss_proj:2.470 [t=0.25s]
prediction: ['[CLS] no has ugly. problem ;.. he is i only ugly ; here loveable no cute factor character. orable mind. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.453 (perp=6.776, rec=0.096, cos=0.002), tot_loss_proj:2.546 [t=0.25s]
prediction: ['[CLS] no has ugly problem ;... he is i only ugly ; here loveable no cute factor character. orable mind, [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.400 (perp=6.506, rec=0.097, cos=0.002), tot_loss_proj:2.982 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only ugly ; here loveable no cute factor character. orable mind, [SEP]']
[1500/2000] tot_loss=1.399 (perp=6.506, rec=0.096, cos=0.002), tot_loss_proj:2.986 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only ugly ; here loveable no cute factor character. orable mind, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.398 (perp=6.506, rec=0.095, cos=0.002), tot_loss_proj:2.984 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only ugly ; here loveable no cute factor character. orable mind, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.396 (perp=6.506, rec=0.093, cos=0.002), tot_loss_proj:2.983 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only ugly ; here loveable no cute factor character. orable mind, [SEP]']
[1650/2000] tot_loss=1.391 (perp=6.506, rec=0.089, cos=0.002), tot_loss_proj:2.980 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only ugly ; here loveable no cute factor character. orable mind, [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.391 (perp=6.506, rec=0.088, cos=0.002), tot_loss_proj:2.977 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only ugly ; here loveable no cute factor character. orable mind, [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.381 (perp=6.417, rec=0.096, cos=0.002), tot_loss_proj:2.981 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only ugly here loveable ; no cute factor character. orable mind, [SEP]']
[1800/2000] tot_loss=1.371 (perp=6.417, rec=0.086, cos=0.002), tot_loss_proj:2.987 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only ugly here loveable ; no cute factor character. orable mind, [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.355 (perp=6.309, rec=0.091, cos=0.002), tot_loss_proj:2.790 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only here ugly loveable ; no cute factor character. orable mind, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.349 (perp=6.309, rec=0.086, cos=0.002), tot_loss_proj:2.793 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only here ugly loveable ; no cute factor character. orable mind, [SEP]']
[1950/2000] tot_loss=1.351 (perp=6.309, rec=0.088, cos=0.002), tot_loss_proj:2.792 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only here ugly loveable ; no cute factor character. orable mind, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.354 (perp=6.309, rec=0.091, cos=0.002), tot_loss_proj:2.791 [t=0.25s]
prediction: ['[CLS] has no ugly problem ;... he is i only here ugly loveable ; no cute factor character. orable mind, [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] has no ugly problem ;... he is i only ugly ; here loveable no cute factor character. orable mind, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 84.211 | r: 76.190
rouge2     | fm: 15.789 | p: 16.667 | r: 15.000
rougeL     | fm: 40.000 | p: 42.105 | r: 38.095
rougeLsum  | fm: 40.000 | p: 42.105 | r: 38.095
r1fm+r2fm = 95.789

[Aggregate metrics]:
rouge1     | fm: 97.500 | p: 98.026 | r: 97.024
rouge2     | fm: 76.974 | p: 77.083 | r: 76.875
rougeL     | fm: 89.375 | p: 89.638 | r: 89.137
rougeLsum  | fm: 89.375 | p: 89.638 | r: 89.137
r1fm+r2fm = 174.474

input #7 time: 0:09:54 | total time: 1:16:43


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.999402751418655
highest_index [0]
highest [0.999402751418655]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.752513587474823 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7108113169670105 for ['[CLS] assassins able a bowled palace times drive camequal happens silver only foreign shelley pumping nbc camp easy payyo bigutounded meaning [SEP]']
[Init] best rec loss: 0.6920523047447205 for ['[CLS]dry pace hash mike parker guard defence disease relief studentquest steiner downdin dance domain briefly crystal beech reason newcastle kai prenostic [SEP]']
[Init] best rec loss: 0.6836101412773132 for ['[CLS] air namely fourjun nkend neitherdf rich ; bit healthcare formula noon abdul drill parks pr daylight longitude tent milo usaas [SEP]']
[Init] best rec loss: 0.674540102481842 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.671164333820343 for ['[CLS] eisenhower plaque arkansas screens sweat adventuremei wanda productey dna prison canontta tail franchise facts res si february season sociallydent badminton [SEP]']
[Init] best perm rec loss: 0.6662924885749817 for ['[CLS]dentey simei sweat franchise arkansas plaque facts canon february product res badminton screens adventuretta socially wanda prison eisenhower season tail dna [SEP]']
[Init] best perm rec loss: 0.6620703935623169 for ['[CLS] tail adventure plaquedent facts badminton arkansas dna season canon product screenseytta wanda franchise sweat february socially si eisenhowermei res prison [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.253 (perp=13.932, rec=0.413, cos=0.054), tot_loss_proj:4.623 [t=0.25s]
prediction: ['[CLS] corn o agent department pickeringdition vanity per expectedes against fake prep injury reached usual least allegeddy supposed supply threat rhode tax [SEP]']
[ 100/2000] tot_loss=3.151 (perp=14.121, rec=0.311, cos=0.016), tot_loss_proj:4.755 [t=0.25s]
prediction: ['[CLS] vanity a piracy department norrisists vanity pays whateveres probable government demand debt reached cases what victimene bug cartridge pull debt tax [SEP]']
[ 150/2000] tot_loss=2.967 (perp=13.510, rec=0.254, cos=0.011), tot_loss_proj:4.264 [t=0.25s]
prediction: ['[CLS] vanity a med films cesarevating vanity pays debt off nina government pay debt station cases what filme hearings estimate pulled debt debt [SEP]']
[ 200/2000] tot_loss=2.817 (perp=13.014, rec=0.207, cos=0.007), tot_loss_proj:3.945 [t=0.25s]
prediction: ['[CLS] vanity a med films tessa debt vanity pays doubt off no de pay debt station debt what film sgnant suspects pulled debt debt [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.582 (perp=11.805, rec=0.206, cos=0.014), tot_loss_proj:3.872 [t=0.25s]
prediction: ['[CLS] majority a imprisonment film tessa debt vanity pays doubt off no de pay debt station cases what film that benign vanity case debt owed [SEP]']
[ 300/2000] tot_loss=2.614 (perp=12.182, rec=0.158, cos=0.020), tot_loss_proj:3.837 [t=0.25s]
prediction: ['[CLS] feel sful filmmax debt vanity pays doubt off no la pay debt forgive felt what film that benign vanity crimes debt owed [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.228 (perp=10.396, rec=0.145, cos=0.005), tot_loss_proj:3.625 [t=0.25s]
prediction: ["[CLS]'sful filmmax debt la pays doubt off no vanity pay debt call felt what film that benign vanityiance debt owed [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.272 (perp=10.520, rec=0.157, cos=0.011), tot_loss_proj:3.358 [t=0.25s]
prediction: ['[CLS] feel sful filmmax debt la pays doubt off no vanity off debt? felt what that benign vanityi film debt owed [SEP]']
[ 450/2000] tot_loss=2.258 (perp=10.619, rec=0.132, cos=0.003), tot_loss_proj:3.412 [t=0.25s]
prediction: ['[CLS] feel sful filmmax debt la pays doubt off no vanity off pays? felt what that benign horrori film debt owed [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.171 (perp=10.225, rec=0.124, cos=0.002), tot_loss_proj:3.257 [t=0.25s]
prediction: ['[CLS] feel sful filmmax debt la pays doubt off no vanity off pays, felt what that benigni film debt owed fright [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.091 (perp=9.839, rec=0.121, cos=0.002), tot_loss_proj:3.084 [t=0.25s]
prediction: ['[CLS] feel sful filmmax debt la pays off doubt no vanity off off, felt what that benigni film debt owed fright [SEP]']
[ 600/2000] tot_loss=1.903 (perp=8.960, rec=0.109, cos=0.002), tot_loss_proj:2.975 [t=0.25s]
prediction: ["[CLS]'sful filmmax debt - pays off doubt no vanity off off, felt what that benigni film debt owed fright [SEP]"]
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.795 (perp=8.384, rec=0.117, cos=0.002), tot_loss_proj:2.803 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt - pays off no vanity off off, felt what that benigni film debt owed fright [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.780 (perp=8.384, rec=0.102, cos=0.002), tot_loss_proj:2.807 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt - pays off no vanity off off, felt what that benigni film debt owed fright [SEP]"]
[ 750/2000] tot_loss=1.804 (perp=8.564, rec=0.090, cos=0.002), tot_loss_proj:2.853 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt - pays off no vanity off negative, felt what that benigni film debt owed fright [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.766 (perp=8.343, rec=0.096, cos=0.001), tot_loss_proj:2.924 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt, pays off no vanity off that, felt what negative benigni film debt owed fright [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.737 (perp=8.189, rec=0.098, cos=0.002), tot_loss_proj:2.703 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt, pays off no vanity off that, what negative benigni film debt owed fright felt [SEP]"]
[ 900/2000] tot_loss=1.737 (perp=8.189, rec=0.098, cos=0.001), tot_loss_proj:2.703 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt, pays off no vanity off that, what negative benigni film debt owed fright felt [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.790 (perp=8.480, rec=0.093, cos=0.001), tot_loss_proj:2.785 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt, pays off no vanity off that, what feels benigni film debt owed fright felt [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.796 (perp=8.479, rec=0.097, cos=0.003), tot_loss_proj:3.046 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt, pays a no vanity off debt, what feels benigni film that owed fright felt [SEP]"]
[1050/2000] tot_loss=1.794 (perp=8.479, rec=0.097, cos=0.001), tot_loss_proj:3.052 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt, pays a no vanity off debt, what feels benigni film that owed fright felt [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.727 (perp=8.161, rec=0.093, cos=0.001), tot_loss_proj:2.907 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt, pays a debt no vanity off, what feels benigni film that owed fright felt [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.699 (perp=8.069, rec=0.084, cos=0.001), tot_loss_proj:2.898 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt, pays a debt no vanity off, what feels benigni film owed that fright felt [SEP]"]
[1200/2000] tot_loss=1.702 (perp=8.069, rec=0.087, cos=0.001), tot_loss_proj:2.897 [t=0.25s]
prediction: ["[CLS]'s doubtful filmmax debt, pays a debt no vanity off, what feels benigni film owed that fright felt [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.661 (perp=7.877, rec=0.084, cos=0.001), tot_loss_proj:2.734 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels debt, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.667 (perp=7.877, rec=0.091, cos=0.001), tot_loss_proj:2.734 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels debt, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
[1350/2000] tot_loss=1.657 (perp=7.877, rec=0.080, cos=0.001), tot_loss_proj:2.735 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels debt, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.665 (perp=7.877, rec=0.089, cos=0.001), tot_loss_proj:2.734 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels debt, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.664 (perp=7.877, rec=0.088, cos=0.001), tot_loss_proj:2.735 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels debt, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
[1500/2000] tot_loss=1.744 (perp=8.307, rec=0.082, cos=0.001), tot_loss_proj:2.739 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.753 (perp=8.307, rec=0.090, cos=0.001), tot_loss_proj:2.735 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.743 (perp=8.307, rec=0.081, cos=0.001), tot_loss_proj:2.737 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
[1650/2000] tot_loss=1.755 (perp=8.307, rec=0.092, cos=0.001), tot_loss_proj:2.742 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.752 (perp=8.307, rec=0.089, cos=0.001), tot_loss_proj:2.739 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.749 (perp=8.307, rec=0.086, cos=0.001), tot_loss_proj:2.740 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
[1800/2000] tot_loss=1.749 (perp=8.307, rec=0.087, cos=0.001), tot_loss_proj:2.738 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.742 (perp=8.307, rec=0.080, cos=0.001), tot_loss_proj:2.740 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.751 (perp=8.307, rec=0.089, cos=0.001), tot_loss_proj:2.733 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
[1950/2000] tot_loss=1.745 (perp=8.307, rec=0.083, cos=0.001), tot_loss_proj:2.741 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.720 (perp=8.191, rec=0.080, cos=0.002), tot_loss_proj:2.702 [t=0.25s]
prediction: ["[CLS]'s doubtful film feels mira pays a debt, no vanity off, whatmax benigni film owed that fright felt [SEP]"]
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS]'s doubtful film feels mira, pays a debt no vanity off, whatmax benigni film owed that fright felt [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.000 | p: 70.000 | r: 70.000
rouge2     | fm: 5.263 | p: 5.263 | r: 5.263
rougeL     | fm: 40.000 | p: 40.000 | r: 40.000
rougeLsum  | fm: 40.000 | p: 40.000 | r: 40.000
r1fm+r2fm = 75.263

[Aggregate metrics]:
rouge1     | fm: 94.444 | p: 94.912 | r: 94.021
rouge2     | fm: 69.006 | p: 69.103 | r: 68.918
rougeL     | fm: 83.889 | p: 84.123 | r: 83.677
rougeLsum  | fm: 83.889 | p: 84.240 | r: 83.677
r1fm+r2fm = 163.450

input #8 time: 0:09:48 | total time: 1:26:31


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9993987163307133
highest_index [0]
highest [0.9993987163307133]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.8139041066169739 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.7717182636260986 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7365254759788513 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.7207859754562378 for ['[CLS] owners pad there arena da rico weekly family [SEP]']
[Init] best rec loss: 0.6855643391609192 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6805217862129211 for ['[CLS] red sh dipped in outstretched hour go imagine [SEP]']
[Init] best rec loss: 0.6490535736083984 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6489459872245789 for ['[CLS] edward arsenal luck deaths decca outlaw codydden [SEP]']
[Init] best perm rec loss: 0.6477984189987183 for ['[CLS] luck edward deaths decca arsenal outlaw codydden [SEP]']
[Init] best perm rec loss: 0.6473267078399658 for ['[CLS] edward deathsdden luck cody outlaw decca arsenal [SEP]']
[Init] best perm rec loss: 0.6464244723320007 for ['[CLS] cody luck deaths deccadden edward arsenal outlaw [SEP]']
[Init] best perm rec loss: 0.6462475657463074 for ['[CLS] arsenal deccadden deaths luck edward cody outlaw [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.984 (perp=13.599, rec=0.250, cos=0.014), tot_loss_proj:3.854 [t=0.24s]
prediction: ['[CLS] softed of clap snap shortage vimesumen [SEP]']
[ 100/2000] tot_loss=2.493 (perp=11.304, rec=0.211, cos=0.021), tot_loss_proj:3.093 [t=0.24s]
prediction: ['[CLS] softhead of clap clap shortage claptra [SEP]']
[ 150/2000] tot_loss=2.286 (perp=10.605, rec=0.158, cos=0.007), tot_loss_proj:3.018 [t=0.24s]
prediction: ['[CLS] softhead of clap claphead claptra [SEP]']
[ 200/2000] tot_loss=2.236 (perp=10.567, rec=0.118, cos=0.004), tot_loss_proj:2.901 [t=0.24s]
prediction: ['[CLS] softhead of clap clap metaphysical claptra [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.137 (perp=10.086, rec=0.114, cos=0.006), tot_loss_proj:2.710 [t=0.24s]
prediction: ['[CLS] softhead of claptrap clap metaphysical [SEP]']
[ 300/2000] tot_loss=2.117 (perp=10.086, rec=0.098, cos=0.002), tot_loss_proj:2.706 [t=0.24s]
prediction: ['[CLS] softhead of claptrap clap metaphysical [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.881 (perp=8.943, rec=0.091, cos=0.002), tot_loss_proj:2.564 [t=0.24s]
prediction: ['[CLS] softhead of metaphysical claptrap clap [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.762 (perp=8.391, rec=0.082, cos=0.002), tot_loss_proj:2.325 [t=0.24s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
[ 450/2000] tot_loss=1.763 (perp=8.391, rec=0.084, cos=0.001), tot_loss_proj:2.324 [t=0.24s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.679 (perp=7.973, rec=0.082, cos=0.002), tot_loss_proj:2.469 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.673 (perp=7.973, rec=0.078, cos=0.001), tot_loss_proj:2.474 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[ 600/2000] tot_loss=1.681 (perp=7.973, rec=0.085, cos=0.001), tot_loss_proj:2.469 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.676 (perp=7.973, rec=0.081, cos=0.001), tot_loss_proj:2.462 [t=0.25s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.669 (perp=7.973, rec=0.073, cos=0.002), tot_loss_proj:2.466 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[ 750/2000] tot_loss=1.676 (perp=7.973, rec=0.080, cos=0.001), tot_loss_proj:2.466 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.667 (perp=7.973, rec=0.071, cos=0.001), tot_loss_proj:2.465 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.675 (perp=7.973, rec=0.079, cos=0.001), tot_loss_proj:2.463 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[ 900/2000] tot_loss=1.678 (perp=7.973, rec=0.082, cos=0.001), tot_loss_proj:2.461 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.672 (perp=7.973, rec=0.076, cos=0.001), tot_loss_proj:2.461 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.672 (perp=7.973, rec=0.076, cos=0.001), tot_loss_proj:2.460 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1050/2000] tot_loss=1.675 (perp=7.973, rec=0.079, cos=0.001), tot_loss_proj:2.465 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.668 (perp=7.973, rec=0.072, cos=0.001), tot_loss_proj:2.458 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.666 (perp=7.973, rec=0.070, cos=0.001), tot_loss_proj:2.455 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1200/2000] tot_loss=1.659 (perp=7.973, rec=0.064, cos=0.001), tot_loss_proj:2.458 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.658 (perp=7.973, rec=0.062, cos=0.001), tot_loss_proj:2.460 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.673 (perp=7.973, rec=0.077, cos=0.001), tot_loss_proj:2.458 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1350/2000] tot_loss=1.662 (perp=7.973, rec=0.066, cos=0.001), tot_loss_proj:2.459 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.664 (perp=7.973, rec=0.068, cos=0.001), tot_loss_proj:2.453 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.666 (perp=7.973, rec=0.071, cos=0.001), tot_loss_proj:2.455 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1500/2000] tot_loss=1.664 (perp=7.973, rec=0.068, cos=0.001), tot_loss_proj:2.461 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.659 (perp=7.973, rec=0.064, cos=0.001), tot_loss_proj:2.463 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.668 (perp=7.973, rec=0.072, cos=0.001), tot_loss_proj:2.457 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1650/2000] tot_loss=2.445 (perp=11.864, rec=0.071, cos=0.001), tot_loss_proj:3.179 [t=0.24s]
prediction: ['[CLS] claphead of metaphysical softedtrap [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.741 (perp=8.329, rec=0.073, cos=0.001), tot_loss_proj:2.486 [t=0.24s]
prediction: ['[CLS]edhead of metaphysical soft claptrap [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.704 (perp=8.142, rec=0.074, cos=0.001), tot_loss_proj:2.430 [t=0.24s]
prediction: ['[CLS]edhead of soft metaphysical claptrap [SEP]']
[1800/2000] tot_loss=1.691 (perp=8.142, rec=0.062, cos=0.001), tot_loss_proj:2.432 [t=0.24s]
prediction: ['[CLS]edhead of soft metaphysical claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.693 (perp=8.142, rec=0.063, cos=0.001), tot_loss_proj:2.436 [t=0.24s]
prediction: ['[CLS]edhead of soft metaphysical claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.700 (perp=8.142, rec=0.071, cos=0.001), tot_loss_proj:2.430 [t=0.24s]
prediction: ['[CLS]edhead of soft metaphysical claptrap [SEP]']
[1950/2000] tot_loss=1.703 (perp=8.142, rec=0.073, cos=0.001), tot_loss_proj:2.424 [t=0.24s]
prediction: ['[CLS]edhead of soft metaphysical claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.701 (perp=8.142, rec=0.072, cos=0.001), tot_loss_proj:2.431 [t=0.24s]
prediction: ['[CLS]edhead of soft metaphysical claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] claphead of metaphysical soft claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 18.182 | p: 16.667 | r: 20.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 95.105

[Aggregate metrics]:
rouge1     | fm: 92.692 | p: 92.564 | r: 92.952
rouge2     | fm: 64.211 | p: 64.386 | r: 64.500
rougeL     | fm: 83.192 | p: 83.000 | r: 83.833
rougeLsum  | fm: 83.192 | p: 82.929 | r: 84.000
r1fm+r2fm = 156.903

input #9 time: 0:09:34 | total time: 1:36:06


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9991463287867453
highest_index [0]
highest [0.9991463287867453]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8793880939483643 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8667941689491272 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8236117959022522 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 0.8160073757171631 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.8075990080833435 for ['[CLS] hidelin swing reacher immediately championship nervous accompaniedcar eva pounded besides help [SEP]']
[Init] best perm rec loss: 0.8071138858795166 for ['[CLS] nervous immediately hid besides pounded swing accompaniedcar help reacherelin eva championship [SEP]']
[Init] best perm rec loss: 0.806658923625946 for ['[CLS] immediately swing nervous reacher hidcar help eva accompaniedelin championship pounded besides [SEP]']
[Init] best perm rec loss: 0.8043859004974365 for ['[CLS]elin accompanied swing pounded championship nervous reacher hid eva immediately helpcar besides [SEP]']
[Init] best perm rec loss: 0.8037967681884766 for ['[CLS] eva immediately swing accompanied nervous championshipelin reachercar hid besides help pounded [SEP]']
[Init] best perm rec loss: 0.8032265901565552 for ['[CLS] accompanied swing nervous championship eva immediatelyelincar pounded hid reacher besides help [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.055 (perp=13.438, rec=0.343, cos=0.024), tot_loss_proj:4.508 [t=0.24s]
prediction: ['[CLS]ramamaticling himself flight confinesingfree feeling carefulthic unit sat [SEP]']
[ 100/2000] tot_loss=2.693 (perp=12.268, rec=0.233, cos=0.006), tot_loss_proj:4.248 [t=0.24s]
prediction: ['[CLS]rama ab balance balance rhythms balancely ab moments consider voluntary.ly [SEP]']
[ 150/2000] tot_loss=2.559 (perp=11.724, rec=0.206, cos=0.008), tot_loss_proj:3.614 [t=0.24s]
prediction: ['[CLS]ulsive ab balance balance rhythms rhythms releasing global situations dependingulsive.ly [SEP]']
[ 200/2000] tot_loss=2.107 (perp=9.750, rec=0.153, cos=0.004), tot_loss_proj:3.374 [t=0.24s]
prediction: ['[CLS]ulsive ab balance balance rhythms rhythms with abulsive.ulsive.ly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.533 (perp=11.676, rec=0.191, cos=0.007), tot_loss_proj:3.456 [t=0.24s]
prediction: ['[CLS]riam ab balance balance rhythms rhythms with incidentlyulsive. ably [SEP]']
[ 300/2000] tot_loss=2.044 (perp=9.418, rec=0.156, cos=0.005), tot_loss_proj:2.918 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balance rhythms rhythms with incidentlyulsive. ably [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.605 (perp=10.957, rec=0.371, cos=0.042), tot_loss_proj:3.757 [t=0.24s]
prediction: ['[CLS] rhythms ab balance total balance rhythms. incident - rhythms.ethly [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.196 (perp=9.772, rec=0.234, cos=0.008), tot_loss_proj:3.232 [t=0.24s]
prediction: ['[CLS] rhythm ab balance titles balance rhythm with actor - 3rd. robertly [SEP]']
[ 450/2000] tot_loss=1.983 (perp=8.898, rec=0.198, cos=0.005), tot_loss_proj:2.868 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsive rhythms with actor - score..ly [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.066 (perp=9.402, rec=0.181, cos=0.004), tot_loss_proj:3.153 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsive rhythms with actor score -. :ly [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.950 (perp=8.862, rec=0.174, cos=0.004), tot_loss_proj:3.080 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsive rhythms with actor score -.ly : [SEP]']
[ 600/2000] tot_loss=1.932 (perp=8.862, rec=0.156, cos=0.004), tot_loss_proj:3.068 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsive rhythms with actor score -.ly : [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.857 (perp=8.461, rec=0.161, cos=0.004), tot_loss_proj:3.020 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsive rhythms with actor score. -ly : [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.844 (perp=8.461, rec=0.148, cos=0.003), tot_loss_proj:3.016 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsive rhythms with actor score. -ly : [SEP]']
[ 750/2000] tot_loss=1.987 (perp=9.221, rec=0.139, cos=0.003), tot_loss_proj:3.201 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsive rhythms with actor 3rd. -ly : [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.979 (perp=9.140, rec=0.147, cos=0.003), tot_loss_proj:3.271 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsive rhythms with - 3rd. actorly : [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.911 (perp=8.886, rec=0.131, cos=0.003), tot_loss_proj:3.113 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsive rhythms with - 3rdly. actor : [SEP]']
[ 900/2000] tot_loss=1.915 (perp=8.886, rec=0.135, cos=0.003), tot_loss_proj:3.115 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsive rhythms with - 3rdly. actor : [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.844 (perp=8.454, rec=0.149, cos=0.004), tot_loss_proj:3.171 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsively with - 3rd rhythms. actor : [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.784 (perp=8.193, rec=0.142, cos=0.003), tot_loss_proj:2.867 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsively with rhythms. actor - 3rd : [SEP]']
[1050/2000] tot_loss=1.773 (perp=8.193, rec=0.131, cos=0.003), tot_loss_proj:2.857 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsively with rhythms. actor - 3rd : [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.700 (perp=7.878, rec=0.121, cos=0.003), tot_loss_proj:2.838 [t=0.24s]
prediction: ['[CLS] rhythms ab balance balanceulsively with rhythms. - 3rd : actor [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.766 (perp=8.189, rec=0.125, cos=0.003), tot_loss_proj:2.474 [t=0.24s]
prediction: ['[CLS] real ab balance balanceulsively with rhythms. - 3rd actor : [SEP]']
[1200/2000] tot_loss=1.755 (perp=8.152, rec=0.122, cos=0.003), tot_loss_proj:2.525 [t=0.24s]
prediction: ['[CLS] real ab balance balanceulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.762 (perp=8.152, rec=0.128, cos=0.003), tot_loss_proj:2.534 [t=0.24s]
prediction: ['[CLS] real ab balance balanceulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.759 (perp=8.152, rec=0.126, cos=0.003), tot_loss_proj:2.525 [t=0.24s]
prediction: ['[CLS] real ab balance balanceulsively with rhythms. - 3rd actor. [SEP]']
[1350/2000] tot_loss=1.670 (perp=7.768, rec=0.114, cos=0.003), tot_loss_proj:2.583 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.675 (perp=7.768, rec=0.119, cos=0.003), tot_loss_proj:2.583 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.669 (perp=7.768, rec=0.113, cos=0.003), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
[1500/2000] tot_loss=1.672 (perp=7.768, rec=0.116, cos=0.003), tot_loss_proj:2.582 [t=0.25s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.675 (perp=7.768, rec=0.119, cos=0.003), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.674 (perp=7.768, rec=0.118, cos=0.002), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
[1650/2000] tot_loss=1.669 (perp=7.768, rec=0.113, cos=0.002), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.664 (perp=7.768, rec=0.108, cos=0.002), tot_loss_proj:2.580 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.664 (perp=7.768, rec=0.108, cos=0.002), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
[1800/2000] tot_loss=1.661 (perp=7.768, rec=0.105, cos=0.002), tot_loss_proj:2.585 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.661 (perp=7.768, rec=0.105, cos=0.002), tot_loss_proj:2.591 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.664 (perp=7.768, rec=0.108, cos=0.002), tot_loss_proj:2.593 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
[1950/2000] tot_loss=1.671 (perp=7.768, rec=0.115, cos=0.002), tot_loss_proj:2.585 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.669 (perp=7.768, rec=0.113, cos=0.002), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] real ab balancesulsively with rhythms. - 3rd actor. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 52.632 | p: 55.556 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.105 | p: 44.444 | r: 40.000
rougeLsum  | fm: 42.105 | p: 44.444 | r: 40.000
r1fm+r2fm = 52.632

[Aggregate metrics]:
rouge1     | fm: 89.050 | p: 89.200 | r: 89.048
rouge2     | fm: 57.895 | p: 58.054 | r: 58.182
rougeL     | fm: 79.457 | p: 79.362 | r: 79.675
rougeLsum  | fm: 79.649 | p: 79.598 | r: 80.433
r1fm+r2fm = 146.945

input #10 time: 0:09:38 | total time: 1:45:45


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9992854056069841
highest_index [0]
highest [0.9992854056069841]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.91344153881073 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8994779586791992 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.8188697099685669 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.817574679851532 for ['[CLS] familiar mile drawn tal platformgu mevdture inland [SEP]']
[Init] best perm rec loss: 0.8121586441993713 for ['[CLS]ture me mile inland platformguvd drawn tal familiar [SEP]']
[Init] best perm rec loss: 0.8105562329292297 for ['[CLS] mile me inlandvd platformturegu familiar drawn tal [SEP]']
[Init] best perm rec loss: 0.8066157102584839 for ['[CLS] inland mileture me drawn tal platformguvd familiar [SEP]']
[Init] best perm rec loss: 0.802373468875885 for ['[CLS] inlandture drawnvd platform tal mile megu familiar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.588 (perp=11.327, rec=0.306, cos=0.016), tot_loss_proj:3.318 [t=0.24s]
prediction: ['[CLS] however persistent narrowted door faerie gel to gel refused [SEP]']
[ 100/2000] tot_loss=2.285 (perp=10.285, rec=0.220, cos=0.008), tot_loss_proj:3.263 [t=0.24s]
prediction: ['[CLS] however attempted stubborn that might here refused to gel refused [SEP]']
[ 150/2000] tot_loss=2.382 (perp=11.158, rec=0.146, cos=0.004), tot_loss_proj:3.314 [t=0.24s]
prediction: ['[CLS] was attempted stubborn that might was refusedly gel refused [SEP]']
[ 200/2000] tot_loss=2.567 (perp=12.200, rec=0.124, cos=0.003), tot_loss_proj:3.541 [t=0.24s]
prediction: ['[CLS] was attempted stubborn that here here refusedly gel refused [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.322 (perp=11.080, rec=0.104, cos=0.002), tot_loss_proj:3.665 [t=0.24s]
prediction: ['[CLS] was attempted stubborn that here here refused gelly refused [SEP]']
[ 300/2000] tot_loss=2.310 (perp=11.080, rec=0.092, cos=0.001), tot_loss_proj:3.665 [t=0.24s]
prediction: ['[CLS] was attempted stubborn that here here refused gelly refused [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.164 (perp=10.383, rec=0.086, cos=0.001), tot_loss_proj:3.471 [t=0.24s]
prediction: ['[CLS] was attempted stubborn here that here refused gelly refused [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.015 (perp=8.999, rec=0.204, cos=0.010), tot_loss_proj:3.095 [t=0.24s]
prediction: ['[CLS] < that here to gel was attempted stubbornly refused [SEP]']
[ 450/2000] tot_loss=1.952 (perp=8.999, rec=0.148, cos=0.004), tot_loss_proj:3.087 [t=0.24s]
prediction: ['[CLS] < that here to gel was attempted stubbornly refused [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.653 (perp=7.540, rec=0.142, cos=0.004), tot_loss_proj:2.202 [t=0.24s]
prediction: ['[CLS] attempt that attempted here to gel was stubbornly refused [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.614 (perp=7.469, rec=0.117, cos=0.004), tot_loss_proj:2.263 [t=0.24s]
prediction: ['[CLS] that use attempted here to gel was stubbornly refused [SEP]']
[ 600/2000] tot_loss=1.597 (perp=7.469, rec=0.100, cos=0.002), tot_loss_proj:2.271 [t=0.24s]
prediction: ['[CLS] that use attempted here to gel was stubbornly refused [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.679 (perp=7.924, rec=0.092, cos=0.002), tot_loss_proj:2.364 [t=0.24s]
prediction: ['[CLS] was attempted here to use gel that stubbornly refused [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.701 (perp=8.042, rec=0.091, cos=0.002), tot_loss_proj:2.797 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
[ 750/2000] tot_loss=1.690 (perp=8.042, rec=0.080, cos=0.001), tot_loss_proj:2.793 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.696 (perp=8.042, rec=0.087, cos=0.001), tot_loss_proj:2.792 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.690 (perp=8.042, rec=0.080, cos=0.001), tot_loss_proj:2.790 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
[ 900/2000] tot_loss=1.696 (perp=8.042, rec=0.086, cos=0.001), tot_loss_proj:2.786 [t=0.25s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.694 (perp=8.042, rec=0.084, cos=0.001), tot_loss_proj:2.790 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1000/2000] tot_loss=1.686 (perp=8.042, rec=0.076, cos=0.001), tot_loss_proj:2.789 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
[1050/2000] tot_loss=1.694 (perp=8.042, rec=0.084, cos=0.001), tot_loss_proj:2.786 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1100/2000] tot_loss=1.687 (perp=8.042, rec=0.077, cos=0.001), tot_loss_proj:2.786 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1150/2000] tot_loss=1.687 (perp=8.042, rec=0.077, cos=0.001), tot_loss_proj:2.783 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
[1200/2000] tot_loss=1.686 (perp=8.042, rec=0.076, cos=0.001), tot_loss_proj:2.787 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1250/2000] tot_loss=1.693 (perp=8.042, rec=0.083, cos=0.001), tot_loss_proj:2.787 [t=0.25s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1300/2000] tot_loss=1.688 (perp=8.042, rec=0.078, cos=0.001), tot_loss_proj:2.782 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
[1350/2000] tot_loss=1.694 (perp=8.042, rec=0.084, cos=0.001), tot_loss_proj:2.783 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1400/2000] tot_loss=1.688 (perp=8.042, rec=0.078, cos=0.001), tot_loss_proj:2.783 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1450/2000] tot_loss=1.687 (perp=8.042, rec=0.077, cos=0.001), tot_loss_proj:2.784 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
[1500/2000] tot_loss=1.685 (perp=8.042, rec=0.075, cos=0.001), tot_loss_proj:2.780 [t=0.25s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1550/2000] tot_loss=1.686 (perp=8.042, rec=0.076, cos=0.001), tot_loss_proj:2.783 [t=0.25s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1600/2000] tot_loss=1.688 (perp=8.042, rec=0.078, cos=0.001), tot_loss_proj:2.779 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
[1650/2000] tot_loss=1.689 (perp=8.042, rec=0.079, cos=0.001), tot_loss_proj:2.776 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1700/2000] tot_loss=1.698 (perp=8.042, rec=0.088, cos=0.001), tot_loss_proj:2.781 [t=0.25s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1750/2000] tot_loss=1.685 (perp=8.042, rec=0.075, cos=0.001), tot_loss_proj:2.779 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
[1800/2000] tot_loss=1.697 (perp=8.042, rec=0.087, cos=0.001), tot_loss_proj:2.776 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1850/2000] tot_loss=1.689 (perp=8.042, rec=0.079, cos=0.001), tot_loss_proj:2.777 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[1900/2000] tot_loss=1.695 (perp=8.042, rec=0.086, cos=0.001), tot_loss_proj:2.776 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
[1950/2000] tot_loss=1.688 (perp=8.042, rec=0.078, cos=0.001), tot_loss_proj:2.777 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Attempt swap
[2000/2000] tot_loss=1.675 (perp=8.042, rec=0.065, cos=0.001), tot_loss_proj:2.780 [t=0.24s]
prediction: ['[CLS] might was attempted here to gel that stubbornly refused [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] might was attempted here to gel that stubbornly refused [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 130.909

[Aggregate metrics]:
rouge1     | fm: 89.318 | p: 89.345 | r: 89.302
rouge2     | fm: 57.041 | p: 56.988 | r: 57.127
rougeL     | fm: 78.896 | p: 78.809 | r: 79.127
rougeLsum  | fm: 79.057 | p: 78.979 | r: 79.255
r1fm+r2fm = 146.360

input #11 time: 0:09:37 | total time: 1:55:23


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9993446475795855
highest_index [0]
highest [0.9993446475795855]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8687862157821655 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.862207293510437 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 0.799700915813446 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.77464359998703 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7713767886161804 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7438812255859375 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best perm rec loss: 0.7414798736572266 for ['[CLS] translate lay few ha series officeitas margin shades guess bethnction victoryn [SEP]']
[Init] best perm rec loss: 0.7407479882240295 for ['[CLS] ha margin series victornction beth translateitas lay shadesyn office guess few [SEP]']
[Init] best perm rec loss: 0.7403061985969543 for ['[CLS]ynnction layitas guess margin beth victor few series translate office ha shades [SEP]']
[Init] best perm rec loss: 0.7398918867111206 for ['[CLS] translate layitas margin series office bethnction shadesyn few ha guess victor [SEP]']
[Init] best perm rec loss: 0.7394150495529175 for ['[CLS] beth victoritasnction translate office shades lay fewyn margin guess ha series [SEP]']
[Init] best perm rec loss: 0.7388815879821777 for ['[CLS] victornction office series lay margin translate bethyn shades fewitas guess ha [SEP]']
[Init] best perm rec loss: 0.738705039024353 for ['[CLS] victor guessyn translate ha few shades beth series lay office marginnctionitas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.342 (perp=10.005, rec=0.302, cos=0.040), tot_loss_proj:3.031 [t=0.24s]
prediction: ['[CLS] better those toppled look better barely advantage at himself because apparent advantage on cable [SEP]']
[ 100/2000] tot_loss=2.218 (perp=10.060, rec=0.198, cos=0.008), tot_loss_proj:3.000 [t=0.24s]
prediction: ['[CLS] better that seen will better barely advantage on ) despite advantage advantage on cable [SEP]']
[ 150/2000] tot_loss=2.118 (perp=9.808, rec=0.151, cos=0.005), tot_loss_proj:2.892 [t=0.24s]
prediction: ['[CLS] better that seen to better barely advantage on ) will potential considering on cable [SEP]']
[ 200/2000] tot_loss=1.834 (perp=8.654, rec=0.100, cos=0.003), tot_loss_proj:2.511 [t=0.24s]
prediction: ['[CLS] be that seen to better barely advantage on its will be considering on cable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.762 (perp=8.333, rec=0.092, cos=0.003), tot_loss_proj:2.507 [t=0.24s]
prediction: ['[CLS] be that seen to better advantage barely on its will especially considering its cable [SEP]']
[ 300/2000] tot_loss=1.893 (perp=9.074, rec=0.076, cos=0.002), tot_loss_proj:2.599 [t=0.24s]
prediction: ['[CLS] be that seen to better advantage barely on especially will especially considering its cable [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.816 (perp=8.712, rec=0.072, cos=0.002), tot_loss_proj:2.490 [t=0.24s]
prediction: ['[CLS] that be seen to better advantage barely on especially will especially considering its cable [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.758 (perp=8.368, rec=0.082, cos=0.003), tot_loss_proj:2.218 [t=0.24s]
prediction: ['[CLS] will be seen to better advantage barely on especially that especially considering its cable [SEP]']
[ 450/2000] tot_loss=1.745 (perp=8.368, rec=0.070, cos=0.001), tot_loss_proj:2.215 [t=0.24s]
prediction: ['[CLS] will be seen to better advantage barely on especially that especially considering its cable [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.584 (perp=7.589, rec=0.065, cos=0.001), tot_loss_proj:2.211 [t=0.24s]
prediction: ['[CLS] will barely be seen to better advantage on especially that especially considering its cable [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.594 (perp=7.589, rec=0.075, cos=0.001), tot_loss_proj:2.205 [t=0.25s]
prediction: ['[CLS] will barely be seen to better advantage on especially that especially considering its cable [SEP]']
[ 600/2000] tot_loss=1.584 (perp=7.589, rec=0.064, cos=0.001), tot_loss_proj:2.205 [t=0.24s]
prediction: ['[CLS] will barely be seen to better advantage on especially that especially considering its cable [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.555 (perp=7.383, rec=0.077, cos=0.001), tot_loss_proj:2.201 [t=0.24s]
prediction: ['[CLS] will barely be seen to better advantage on especially considering that especially its cable [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.485 (perp=7.083, rec=0.067, cos=0.001), tot_loss_proj:2.155 [t=0.24s]
prediction: ['[CLS] will barely be seen to better advantage on. considering that especially its cable [SEP]']
[ 750/2000] tot_loss=1.443 (perp=6.867, rec=0.068, cos=0.001), tot_loss_proj:2.129 [t=0.24s]
prediction: ['[CLS] will barely be seen to better advantage on, considering that especially its cable [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.442 (perp=6.867, rec=0.067, cos=0.001), tot_loss_proj:2.132 [t=0.24s]
prediction: ['[CLS] will barely be seen to better advantage on, considering that especially its cable [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.577 (perp=7.563, rec=0.063, cos=0.001), tot_loss_proj:2.239 [t=0.24s]
prediction: ['[CLS] will barely be seen to better advantage on especially especially considering that its cable [SEP]']
[ 900/2000] tot_loss=1.401 (perp=6.674, rec=0.065, cos=0.001), tot_loss_proj:2.116 [t=0.24s]
prediction: ['[CLS] will barely be seen to better advantage on ( especially considering that its cable [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.396 (perp=6.674, rec=0.060, cos=0.001), tot_loss_proj:2.110 [t=0.24s]
prediction: ['[CLS] will barely be seen to better advantage on ( especially considering that its cable [SEP]']
Attempt swap
[1000/2000] tot_loss=1.362 (perp=6.455, rec=0.070, cos=0.001), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
[1050/2000] tot_loss=1.361 (perp=6.455, rec=0.069, cos=0.001), tot_loss_proj:1.999 [t=0.23s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1100/2000] tot_loss=1.360 (perp=6.455, rec=0.068, cos=0.001), tot_loss_proj:1.995 [t=0.23s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1150/2000] tot_loss=1.361 (perp=6.455, rec=0.069, cos=0.001), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
[1200/2000] tot_loss=1.349 (perp=6.455, rec=0.057, cos=0.001), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1250/2000] tot_loss=1.357 (perp=6.455, rec=0.065, cos=0.001), tot_loss_proj:1.994 [t=0.23s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1300/2000] tot_loss=1.354 (perp=6.455, rec=0.062, cos=0.001), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
[1350/2000] tot_loss=1.356 (perp=6.455, rec=0.063, cos=0.001), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1400/2000] tot_loss=1.358 (perp=6.455, rec=0.065, cos=0.001), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1450/2000] tot_loss=1.358 (perp=6.455, rec=0.066, cos=0.001), tot_loss_proj:1.997 [t=0.23s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
[1500/2000] tot_loss=1.355 (perp=6.455, rec=0.062, cos=0.001), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1550/2000] tot_loss=1.359 (perp=6.455, rec=0.067, cos=0.001), tot_loss_proj:1.999 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1600/2000] tot_loss=1.361 (perp=6.455, rec=0.068, cos=0.001), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
[1650/2000] tot_loss=1.350 (perp=6.455, rec=0.058, cos=0.001), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1700/2000] tot_loss=1.350 (perp=6.455, rec=0.058, cos=0.001), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1750/2000] tot_loss=1.358 (perp=6.455, rec=0.066, cos=0.001), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
[1800/2000] tot_loss=1.355 (perp=6.455, rec=0.063, cos=0.001), tot_loss_proj:1.994 [t=0.23s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1850/2000] tot_loss=1.354 (perp=6.455, rec=0.062, cos=0.001), tot_loss_proj:1.999 [t=0.23s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[1900/2000] tot_loss=1.351 (perp=6.455, rec=0.058, cos=0.001), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
[1950/2000] tot_loss=1.349 (perp=6.455, rec=0.057, cos=0.001), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Attempt swap
[2000/2000] tot_loss=1.356 (perp=6.455, rec=0.064, cos=0.001), tot_loss_proj:1.994 [t=0.23s]
prediction: ['[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] will barely be seen to better advantage on, especially considering that its cable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 142.857

[Aggregate metrics]:
rouge1     | fm: 90.202 | p: 90.221 | r: 90.326
rouge2     | fm: 55.360 | p: 55.331 | r: 55.440
rougeL     | fm: 78.820 | p: 78.714 | r: 79.138
rougeLsum  | fm: 79.142 | p: 78.867 | r: 79.221
r1fm+r2fm = 145.563

input #12 time: 0:09:25 | total time: 2:04:48


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9992539461450387
highest_index [0]
highest [0.9992539461450387]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8865664601325989 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8836308717727661 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.8601260781288147 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7841423749923706 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7840108871459961 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 0.7708356380462646 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 0.7580289244651794 for ['[CLS]typic malice avenue andy rightart brought [SEP]']
[Init] best rec loss: 0.7500137090682983 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best perm rec loss: 0.7499359250068665 for ['[CLS] furnace without card double experiment working corruption [SEP]']
[Init] best perm rec loss: 0.748815655708313 for ['[CLS] without corruption double working card furnace experiment [SEP]']
[Init] best perm rec loss: 0.7485044002532959 for ['[CLS] without card working furnace corruption experiment double [SEP]']
[Init] best perm rec loss: 0.7479153871536255 for ['[CLS] without working corruption double furnace card experiment [SEP]']
[Init] best perm rec loss: 0.7478422522544861 for ['[CLS] card double working furnace without experiment corruption [SEP]']
[Init] best perm rec loss: 0.7478395700454712 for ['[CLS] corruption without experiment working card double furnace [SEP]']
[Init] best perm rec loss: 0.7461642026901245 for ['[CLS] corruption card double furnace experiment without working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.554 (perp=11.112, rec=0.296, cos=0.035), tot_loss_proj:3.262 [t=0.22s]
prediction: ['[CLS] point the spectacular stupid eyed flame flame [SEP]']
[ 100/2000] tot_loss=2.305 (perp=10.512, rec=0.189, cos=0.013), tot_loss_proj:2.976 [t=0.22s]
prediction: ['[CLS] point at things crazy explode flame flame [SEP]']
[ 150/2000] tot_loss=2.271 (perp=10.676, rec=0.130, cos=0.005), tot_loss_proj:3.083 [t=0.23s]
prediction: ['[CLS] point at things into into flame flame [SEP]']
[ 200/2000] tot_loss=2.324 (perp=11.093, rec=0.102, cos=0.003), tot_loss_proj:2.891 [t=0.23s]
prediction: ['[CLS] point at things into into explode flame [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.734 (perp=8.254, rec=0.081, cos=0.003), tot_loss_proj:2.020 [t=0.23s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 300/2000] tot_loss=1.718 (perp=8.254, rec=0.065, cos=0.001), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.717 (perp=8.254, rec=0.065, cos=0.001), tot_loss_proj:2.001 [t=0.23s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.718 (perp=8.254, rec=0.066, cos=0.001), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 450/2000] tot_loss=1.708 (perp=8.254, rec=0.056, cos=0.001), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.718 (perp=8.254, rec=0.066, cos=0.001), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.710 (perp=8.254, rec=0.057, cos=0.001), tot_loss_proj:1.987 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 600/2000] tot_loss=1.716 (perp=8.254, rec=0.064, cos=0.001), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.720 (perp=8.254, rec=0.067, cos=0.001), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.711 (perp=8.254, rec=0.058, cos=0.001), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 750/2000] tot_loss=1.720 (perp=8.254, rec=0.067, cos=0.001), tot_loss_proj:2.004 [t=0.23s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.712 (perp=8.254, rec=0.059, cos=0.001), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.711 (perp=8.254, rec=0.059, cos=0.001), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 900/2000] tot_loss=1.707 (perp=8.254, rec=0.054, cos=0.001), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.708 (perp=8.254, rec=0.055, cos=0.001), tot_loss_proj:1.989 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.712 (perp=8.254, rec=0.060, cos=0.001), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1050/2000] tot_loss=1.720 (perp=8.254, rec=0.068, cos=0.001), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.714 (perp=8.254, rec=0.062, cos=0.001), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.717 (perp=8.254, rec=0.065, cos=0.001), tot_loss_proj:2.000 [t=0.23s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1200/2000] tot_loss=1.714 (perp=8.254, rec=0.062, cos=0.001), tot_loss_proj:1.984 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.719 (perp=8.254, rec=0.067, cos=0.001), tot_loss_proj:1.989 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.711 (perp=8.254, rec=0.059, cos=0.001), tot_loss_proj:1.996 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1350/2000] tot_loss=1.715 (perp=8.254, rec=0.063, cos=0.001), tot_loss_proj:1.991 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.712 (perp=8.254, rec=0.060, cos=0.001), tot_loss_proj:1.996 [t=0.23s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.715 (perp=8.254, rec=0.063, cos=0.001), tot_loss_proj:1.996 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1500/2000] tot_loss=1.718 (perp=8.254, rec=0.065, cos=0.001), tot_loss_proj:1.993 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.717 (perp=8.254, rec=0.065, cos=0.001), tot_loss_proj:1.991 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.713 (perp=8.254, rec=0.060, cos=0.001), tot_loss_proj:1.986 [t=0.23s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1650/2000] tot_loss=1.723 (perp=8.254, rec=0.071, cos=0.001), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.711 (perp=8.254, rec=0.059, cos=0.001), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.708 (perp=8.254, rec=0.055, cos=0.001), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1800/2000] tot_loss=1.710 (perp=8.254, rec=0.058, cos=0.001), tot_loss_proj:1.996 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.714 (perp=8.254, rec=0.062, cos=0.001), tot_loss_proj:1.991 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.714 (perp=8.254, rec=0.062, cos=0.001), tot_loss_proj:1.989 [t=0.23s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1950/2000] tot_loss=1.704 (perp=8.254, rec=0.052, cos=0.001), tot_loss_proj:1.993 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.707 (perp=8.254, rec=0.055, cos=0.001), tot_loss_proj:1.994 [t=0.22s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] point at things that explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.967 | p: 90.967 | r: 91.017
rouge2     | fm: 58.550 | p: 58.521 | r: 58.590
rougeL     | fm: 80.413 | p: 80.323 | r: 80.649
rougeLsum  | fm: 80.764 | p: 80.783 | r: 80.914
r1fm+r2fm = 149.517

input #13 time: 0:09:03 | total time: 2:13:51


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9993215770683852
highest_index [0]
highest [0.9993215770683852]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9575048089027405 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.939458429813385 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.923689067363739 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9127009510993958 for ['[CLS] bar these catch arms state [SEP]']
[Init] best rec loss: 0.8922421336174011 for ['[CLS] return him always kolkata frame [SEP]']
[Init] best rec loss: 0.8753606081008911 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8746199011802673 for ['[CLS] sprayed myers harold [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8732940554618835 for ['[CLS] sprayed harold myers [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8731610178947449 for ['[CLS] harold [MASK] tom myers sprayed [SEP]']
[Init] best perm rec loss: 0.8726160526275635 for ['[CLS] harold tom sprayed [MASK] myers [SEP]']
[Init] best perm rec loss: 0.872270405292511 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
[Init] best perm rec loss: 0.8718624114990234 for ['[CLS] [MASK] harold sprayed tom myers [SEP]']
[Init] best perm rec loss: 0.8703657984733582 for ['[CLS] tom [MASK] sprayed myers harold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.636 (perp=11.834, rec=0.263, cos=0.006), tot_loss_proj:3.781 [t=0.22s]
prediction: ['[CLS] middle film gotta genuinely intriguing [SEP]']
[ 100/2000] tot_loss=2.599 (perp=12.090, rec=0.178, cos=0.003), tot_loss_proj:3.043 [t=0.22s]
prediction: ['[CLS] middle filmbly intriguing intriguing [SEP]']
[ 150/2000] tot_loss=2.930 (perp=13.947, rec=0.138, cos=0.002), tot_loss_proj:3.336 [t=0.22s]
prediction: ['[CLS] amazing filmblybly intriguing [SEP]']
[ 200/2000] tot_loss=3.148 (perp=15.075, rec=0.131, cos=0.002), tot_loss_proj:3.593 [t=0.22s]
prediction: ['[CLS] amazing filmblyenia intriguing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.285 (perp=10.828, rec=0.117, cos=0.002), tot_loss_proj:2.474 [t=0.22s]
prediction: ['[CLS] amazingeniably film intriguing [SEP]']
[ 300/2000] tot_loss=2.283 (perp=10.918, rec=0.097, cos=0.002), tot_loss_proj:2.599 [t=0.22s]
prediction: ['[CLS] enigmaeniably film intriguing [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.225 (perp=10.664, rec=0.090, cos=0.002), tot_loss_proj:3.863 [t=0.22s]
prediction: ['[CLS]eniably und film intriguing [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.632 (perp=7.738, rec=0.083, cos=0.002), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] undeniably film intriguing [SEP]']
[ 450/2000] tot_loss=1.624 (perp=7.738, rec=0.075, cos=0.002), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] undeniably film intriguing [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.433 (perp=6.728, rec=0.085, cos=0.002), tot_loss_proj:1.412 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.430 (perp=6.728, rec=0.083, cos=0.002), tot_loss_proj:1.420 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.442 (perp=6.728, rec=0.095, cos=0.002), tot_loss_proj:1.402 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.428 (perp=6.728, rec=0.081, cos=0.002), tot_loss_proj:1.403 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.426 (perp=6.728, rec=0.079, cos=0.002), tot_loss_proj:1.403 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.437 (perp=6.728, rec=0.090, cos=0.002), tot_loss_proj:1.400 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.428 (perp=6.728, rec=0.081, cos=0.002), tot_loss_proj:1.398 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.420 (perp=6.728, rec=0.073, cos=0.002), tot_loss_proj:1.410 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.400 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.407 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.401 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.400 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.416 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.410 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.425 (perp=6.728, rec=0.078, cos=0.001), tot_loss_proj:1.401 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.404 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.410 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.405 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.400 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.404 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.404 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.406 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.411 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.399 (perp=6.728, rec=0.052, cos=0.001), tot_loss_proj:1.406 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.402 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.405 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.414 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.421 (perp=6.728, rec=0.074, cos=0.001), tot_loss_proj:1.406 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.414 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.397 (perp=6.728, rec=0.050, cos=0.001), tot_loss_proj:1.416 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.423 (perp=6.728, rec=0.076, cos=0.001), tot_loss_proj:1.417 [t=0.22s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.568 | p: 91.584 | r: 91.616
rouge2     | fm: 61.393 | p: 61.430 | r: 61.541
rougeL     | fm: 81.953 | p: 81.723 | r: 82.166
rougeLsum  | fm: 81.935 | p: 81.715 | r: 82.055
r1fm+r2fm = 152.960

input #14 time: 0:09:02 | total time: 2:22:54


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9992721399802154
highest_index [0]
highest [0.9992721399802154]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9675636291503906 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.9328241348266602 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 0.9158609509468079 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.9073993563652039 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.9044149518013 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8923435807228088 for ['[CLS]che carolezard multi zone rhythmic watervating [SEP]']
[Init] best rec loss: 0.8854512572288513 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8833559155464172 for ['[CLS] 0 humanities metaphor olivia easily fetch first sweden [SEP]']
[Init] best perm rec loss: 0.8797237277030945 for ['[CLS] humanities easily metaphor 0 first fetch sweden olivia [SEP]']
[Init] best perm rec loss: 0.87762451171875 for ['[CLS] first sweden 0 metaphor fetch humanities easily olivia [SEP]']
[Init] best perm rec loss: 0.8739213347434998 for ['[CLS] first sweden 0 humanities fetch metaphor easily olivia [SEP]']
[Init] best perm rec loss: 0.873146653175354 for ['[CLS] humanities first fetch metaphor 0 olivia easily sweden [SEP]']
[Init] best perm rec loss: 0.8725970387458801 for ['[CLS] metaphor humanities 0 sweden fetch easily first olivia [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.943 (perp=13.511, rec=0.235, cos=0.006), tot_loss_proj:3.487 [t=0.24s]
prediction: ['[CLS] efficient featuringablyably miller careful efficient efficient [SEP]']
[ 100/2000] tot_loss=2.509 (perp=11.642, rec=0.177, cos=0.003), tot_loss_proj:2.740 [t=0.24s]
prediction: ['[CLS] suitably suit chill chill ; efficient efficient [SEP]']
[ 150/2000] tot_loss=2.327 (perp=10.970, rec=0.131, cos=0.002), tot_loss_proj:2.802 [t=0.24s]
prediction: ['[CLS],ably suit chiller ; anonymous efficient [SEP]']
[ 200/2000] tot_loss=2.217 (perp=10.561, rec=0.103, cos=0.002), tot_loss_proj:3.417 [t=0.24s]
prediction: ['[CLS], anonymous suit chillerably anonymous efficient [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.873 (perp=8.881, rec=0.095, cos=0.002), tot_loss_proj:2.634 [t=0.24s]
prediction: ['[CLS], anonymous suitably anonymous chiller efficient [SEP]']
[ 300/2000] tot_loss=1.849 (perp=8.881, rec=0.072, cos=0.002), tot_loss_proj:2.622 [t=0.24s]
prediction: ['[CLS], anonymous suitably anonymous chiller efficient [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.759 (perp=8.390, rec=0.079, cos=0.002), tot_loss_proj:2.212 [t=0.24s]
prediction: ['[CLS], anonymous suitably efficient anonymous chiller [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.668 (perp=7.816, rec=0.103, cos=0.002), tot_loss_proj:1.959 [t=0.24s]
prediction: ['[CLS] anonymous suitably efficient, anonymous chiller [SEP]']
[ 450/2000] tot_loss=1.640 (perp=7.816, rec=0.075, cos=0.002), tot_loss_proj:1.966 [t=0.24s]
prediction: ['[CLS] anonymous suitably efficient, anonymous chiller [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.872 (perp=8.994, rec=0.072, cos=0.002), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS]¤ suitably efficient, anonymous chiller [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=1.484 (perp=6.697, rec=0.142, cos=0.003), tot_loss_proj:1.528 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.409 (perp=6.697, rec=0.068, cos=0.002), tot_loss_proj:1.540 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.423 (perp=6.697, rec=0.082, cos=0.002), tot_loss_proj:1.535 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.408 (perp=6.697, rec=0.067, cos=0.001), tot_loss_proj:1.521 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.411 (perp=6.697, rec=0.070, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.417 (perp=6.697, rec=0.076, cos=0.001), tot_loss_proj:1.527 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.404 (perp=6.697, rec=0.063, cos=0.001), tot_loss_proj:1.531 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.409 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.522 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.403 (perp=6.697, rec=0.062, cos=0.001), tot_loss_proj:1.533 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.407 (perp=6.697, rec=0.066, cos=0.001), tot_loss_proj:1.522 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.408 (perp=6.697, rec=0.067, cos=0.001), tot_loss_proj:1.534 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.402 (perp=6.697, rec=0.061, cos=0.001), tot_loss_proj:1.519 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.407 (perp=6.697, rec=0.066, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.412 (perp=6.697, rec=0.071, cos=0.001), tot_loss_proj:1.524 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.402 (perp=6.697, rec=0.061, cos=0.001), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.402 (perp=6.697, rec=0.061, cos=0.001), tot_loss_proj:1.517 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.402 (perp=6.697, rec=0.061, cos=0.001), tot_loss_proj:1.522 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.406 (perp=6.697, rec=0.065, cos=0.001), tot_loss_proj:1.522 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.409 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.525 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.408 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.528 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.404 (perp=6.697, rec=0.064, cos=0.001), tot_loss_proj:1.519 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.403 (perp=6.697, rec=0.062, cos=0.001), tot_loss_proj:1.531 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.410 (perp=6.697, rec=0.069, cos=0.001), tot_loss_proj:1.522 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.408 (perp=6.697, rec=0.067, cos=0.001), tot_loss_proj:1.523 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.392 (perp=6.697, rec=0.052, cos=0.001), tot_loss_proj:1.525 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.404 (perp=6.697, rec=0.063, cos=0.001), tot_loss_proj:1.513 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.416 (perp=6.697, rec=0.075, cos=0.001), tot_loss_proj:1.525 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.409 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.519 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.401 (perp=6.697, rec=0.061, cos=0.001), tot_loss_proj:1.523 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.406 (perp=6.697, rec=0.065, cos=0.001), tot_loss_proj:1.519 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 92.153 | p: 92.176 | r: 92.254
rouge2     | fm: 60.065 | p: 60.003 | r: 60.179
rougeL     | fm: 82.032 | p: 81.939 | r: 82.224
rougeLsum  | fm: 82.194 | p: 82.173 | r: 82.258
r1fm+r2fm = 152.218

input #15 time: 0:09:41 | total time: 2:32:35


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9993407915045383
highest_index [0]
highest [0.9993407915045383]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.020234227180481 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.9004251956939697 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7400387525558472 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.7389788627624512 for ['[CLS] alta film various slowly lordathi [SEP]']
[Init] best perm rec loss: 0.7379375100135803 for ['[CLS] alta various film lord slowlyathi [SEP]']
[Init] best perm rec loss: 0.7354840040206909 for ['[CLS]athi film lord slowly various alta [SEP]']
[Init] best perm rec loss: 0.7348273396492004 for ['[CLS] film slowly lord various altaathi [SEP]']
[Init] best perm rec loss: 0.7346431612968445 for ['[CLS] lord various film slowlyathi alta [SEP]']
[Init] best perm rec loss: 0.7346169948577881 for ['[CLS] film various lord slowly altaathi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.814 (perp=11.027, rec=0.493, cos=0.115), tot_loss_proj:3.854 [t=0.22s]
prediction: ['[CLS] appeal oriented generation on rather package [SEP]']
[ 100/2000] tot_loss=2.255 (perp=9.284, rec=0.360, cos=0.038), tot_loss_proj:2.920 [t=0.22s]
prediction: ['[CLS] - - generation this more that [SEP]']
[ 150/2000] tot_loss=1.949 (perp=8.346, rec=0.264, cos=0.017), tot_loss_proj:2.536 [t=0.22s]
prediction: ['[CLS] - of the all more this [SEP]']
[ 200/2000] tot_loss=1.692 (perp=7.397, rec=0.199, cos=0.014), tot_loss_proj:2.385 [t=0.22s]
prediction: ['[CLS] as of the all more this [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.347 (perp=5.665, rec=0.192, cos=0.022), tot_loss_proj:1.765 [t=0.22s]
prediction: ['[CLS] and all of the more this [SEP]']
[ 300/2000] tot_loss=1.794 (perp=8.313, rec=0.123, cos=0.008), tot_loss_proj:2.275 [t=0.22s]
prediction: ['[CLS] and all of of more this [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.310 (perp=5.986, rec=0.107, cos=0.006), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] and all of more of this [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.189 (perp=5.400, rec=0.102, cos=0.007), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
[ 450/2000] tot_loss=1.179 (perp=5.400, rec=0.094, cos=0.006), tot_loss_proj:1.675 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.174 (perp=5.400, rec=0.089, cos=0.005), tot_loss_proj:1.681 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.174 (perp=5.400, rec=0.089, cos=0.005), tot_loss_proj:1.682 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[ 600/2000] tot_loss=1.172 (perp=5.400, rec=0.087, cos=0.005), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.170 (perp=5.400, rec=0.085, cos=0.005), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.172 (perp=5.400, rec=0.087, cos=0.005), tot_loss_proj:1.676 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
[ 750/2000] tot_loss=1.180 (perp=5.400, rec=0.095, cos=0.005), tot_loss_proj:1.679 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.172 (perp=5.400, rec=0.087, cos=0.005), tot_loss_proj:1.681 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.168 (perp=5.400, rec=0.084, cos=0.004), tot_loss_proj:1.680 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
[ 900/2000] tot_loss=1.164 (perp=5.400, rec=0.080, cos=0.004), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.170 (perp=5.400, rec=0.086, cos=0.004), tot_loss_proj:1.679 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1000/2000] tot_loss=1.160 (perp=5.400, rec=0.076, cos=0.004), tot_loss_proj:1.672 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[1050/2000] tot_loss=1.166 (perp=5.400, rec=0.082, cos=0.004), tot_loss_proj:1.680 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1100/2000] tot_loss=1.168 (perp=5.400, rec=0.083, cos=0.004), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1150/2000] tot_loss=1.171 (perp=5.400, rec=0.087, cos=0.004), tot_loss_proj:1.675 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
[1200/2000] tot_loss=1.173 (perp=5.400, rec=0.089, cos=0.004), tot_loss_proj:1.679 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1250/2000] tot_loss=1.173 (perp=5.400, rec=0.088, cos=0.004), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1300/2000] tot_loss=1.162 (perp=5.400, rec=0.078, cos=0.004), tot_loss_proj:1.673 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
[1350/2000] tot_loss=1.170 (perp=5.400, rec=0.086, cos=0.004), tot_loss_proj:1.670 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1400/2000] tot_loss=1.168 (perp=5.400, rec=0.084, cos=0.004), tot_loss_proj:1.683 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1450/2000] tot_loss=1.173 (perp=5.400, rec=0.089, cos=0.004), tot_loss_proj:1.677 [t=0.23s]
prediction: ['[CLS] and more of all of this [SEP]']
[1500/2000] tot_loss=1.169 (perp=5.400, rec=0.085, cos=0.004), tot_loss_proj:1.687 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1550/2000] tot_loss=1.166 (perp=5.400, rec=0.082, cos=0.004), tot_loss_proj:1.679 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1600/2000] tot_loss=1.160 (perp=5.400, rec=0.076, cos=0.004), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
[1650/2000] tot_loss=1.165 (perp=5.400, rec=0.081, cos=0.004), tot_loss_proj:1.676 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1700/2000] tot_loss=1.158 (perp=5.400, rec=0.074, cos=0.004), tot_loss_proj:1.680 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1750/2000] tot_loss=1.163 (perp=5.400, rec=0.079, cos=0.004), tot_loss_proj:1.669 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
[1800/2000] tot_loss=1.173 (perp=5.400, rec=0.089, cos=0.004), tot_loss_proj:1.681 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1850/2000] tot_loss=1.166 (perp=5.400, rec=0.082, cos=0.004), tot_loss_proj:1.676 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[1900/2000] tot_loss=1.159 (perp=5.400, rec=0.075, cos=0.004), tot_loss_proj:1.676 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
[1950/2000] tot_loss=1.163 (perp=5.400, rec=0.079, cos=0.004), tot_loss_proj:1.679 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Attempt swap
[2000/2000] tot_loss=1.163 (perp=5.400, rec=0.079, cos=0.004), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] and more of all of this [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] and more of all of this [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 46.154 | p: 42.857 | r: 50.000
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 139.487

[Aggregate metrics]:
rouge1     | fm: 92.224 | p: 91.944 | r: 92.602
rouge2     | fm: 60.137 | p: 59.919 | r: 60.341
rougeL     | fm: 81.590 | p: 81.221 | r: 82.083
rougeLsum  | fm: 80.896 | p: 80.635 | r: 81.414
r1fm+r2fm = 152.361

input #16 time: 0:09:02 | total time: 2:41:37


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9992298074118964
highest_index [0]
highest [0.9992298074118964]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8472551703453064 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8236850500106812 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.8234798908233643 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.8217296600341797 for ['[CLS] bit crookedus felicity york electedyre = cheese ourselves consulting [SEP]']
[Init] best rec loss: 0.8205518126487732 for ['[CLS] santa bourneity church jacence move nativeburnub early [SEP]']
[Init] best rec loss: 0.8091399073600769 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7916844487190247 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 0.7702016830444336 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 0.7585719227790833 for ['[CLS] lieutenant magazineuin miss grey marius honestly pressure saved meeting i [SEP]']
[Init] best perm rec loss: 0.753882884979248 for ['[CLS] grey lieutenant marius honestlyuin magazine i meeting pressure saved miss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.910 (perp=12.250, rec=0.403, cos=0.057), tot_loss_proj:3.685 [t=0.24s]
prediction: ['[CLS] stress anatomy want want controlas too thinks pressure immediately rash [SEP]']
[ 100/2000] tot_loss=2.435 (perp=11.130, rec=0.190, cos=0.019), tot_loss_proj:3.343 [t=0.24s]
prediction: ['[CLS] doubt what want want thinksch too much much much rash [SEP]']
[ 150/2000] tot_loss=1.407 (perp=6.418, rec=0.117, cos=0.006), tot_loss_proj:2.482 [t=0.24s]
prediction: ['[CLS] think what want to think about too much about much about [SEP]']
[ 200/2000] tot_loss=1.420 (perp=6.598, rec=0.097, cos=0.003), tot_loss_proj:2.484 [t=0.24s]
prediction: ['[CLS] think what want to think about too much about much on [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.414 (perp=6.548, rec=0.100, cos=0.004), tot_loss_proj:1.911 [t=0.24s]
prediction: ['[CLS] think on want to think about too much what much frame [SEP]']
[ 300/2000] tot_loss=1.558 (perp=7.381, rec=0.079, cos=0.003), tot_loss_proj:2.152 [t=0.24s]
prediction: ['[CLS] think going want to think about too much what much frame [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.331 (perp=6.281, rec=0.073, cos=0.002), tot_loss_proj:1.847 [t=0.24s]
prediction: ['[CLS] think want to think about too much on what much frame [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.621 (perp=7.715, rec=0.076, cos=0.002), tot_loss_proj:2.341 [t=0.24s]
prediction: ['[CLS] what want to think about too much going what going frame [SEP]']
[ 450/2000] tot_loss=1.478 (perp=6.966, rec=0.083, cos=0.002), tot_loss_proj:2.091 [t=0.24s]
prediction: ['[CLS] what want to think about too much on what going frame [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.331 (perp=6.303, rec=0.068, cos=0.002), tot_loss_proj:1.834 [t=0.25s]
prediction: ['[CLS] want to think about what too much on what going frame [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.277 (perp=6.019, rec=0.072, cos=0.002), tot_loss_proj:1.779 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
[ 600/2000] tot_loss=1.283 (perp=6.019, rec=0.077, cos=0.002), tot_loss_proj:1.781 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.278 (perp=6.019, rec=0.073, cos=0.002), tot_loss_proj:1.774 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.272 (perp=6.019, rec=0.066, cos=0.002), tot_loss_proj:1.783 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
[ 750/2000] tot_loss=1.267 (perp=6.019, rec=0.062, cos=0.002), tot_loss_proj:1.778 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.270 (perp=6.019, rec=0.065, cos=0.002), tot_loss_proj:1.780 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.278 (perp=6.019, rec=0.072, cos=0.002), tot_loss_proj:1.775 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
[ 900/2000] tot_loss=1.266 (perp=6.019, rec=0.060, cos=0.002), tot_loss_proj:1.778 [t=0.25s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.275 (perp=6.019, rec=0.070, cos=0.002), tot_loss_proj:1.771 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
Attempt swap
[1000/2000] tot_loss=1.276 (perp=6.019, rec=0.070, cos=0.002), tot_loss_proj:1.775 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
[1050/2000] tot_loss=1.272 (perp=6.019, rec=0.066, cos=0.002), tot_loss_proj:1.775 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
Attempt swap
[1100/2000] tot_loss=1.279 (perp=6.019, rec=0.073, cos=0.002), tot_loss_proj:1.779 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.271 (perp=6.019, rec=0.066, cos=0.002), tot_loss_proj:1.771 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
[1200/2000] tot_loss=1.277 (perp=6.019, rec=0.072, cos=0.002), tot_loss_proj:1.771 [t=0.24s]
prediction: ['[CLS] want to think about what too much frame what going on [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.166 (perp=5.486, rec=0.068, cos=0.002), tot_loss_proj:1.735 [t=0.24s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
Attempt swap
[1300/2000] tot_loss=1.336 (perp=6.270, rec=0.080, cos=0.002), tot_loss_proj:1.864 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on frame [SEP]']
[1350/2000] tot_loss=1.322 (perp=6.270, rec=0.066, cos=0.002), tot_loss_proj:1.856 [t=0.23s]
prediction: ['[CLS] want to think about what too much what going on frame [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.261 (perp=5.961, rec=0.067, cos=0.002), tot_loss_proj:1.828 [t=0.22s]
prediction: ['[CLS] want to think about what too much [ what going on [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.174 (perp=5.486, rec=0.075, cos=0.002), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
[1500/2000] tot_loss=1.165 (perp=5.486, rec=0.066, cos=0.002), tot_loss_proj:1.722 [t=0.23s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
Attempt swap
[1550/2000] tot_loss=1.158 (perp=5.486, rec=0.059, cos=0.002), tot_loss_proj:1.723 [t=0.23s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
Attempt swap
[1600/2000] tot_loss=1.180 (perp=5.486, rec=0.082, cos=0.002), tot_loss_proj:1.721 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
[1650/2000] tot_loss=1.169 (perp=5.486, rec=0.071, cos=0.002), tot_loss_proj:1.733 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
Attempt swap
[1700/2000] tot_loss=1.163 (perp=5.486, rec=0.064, cos=0.002), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
Attempt swap
[1750/2000] tot_loss=1.163 (perp=5.486, rec=0.064, cos=0.002), tot_loss_proj:1.728 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
[1800/2000] tot_loss=1.174 (perp=5.486, rec=0.075, cos=0.002), tot_loss_proj:1.725 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
Attempt swap
[1850/2000] tot_loss=1.165 (perp=5.486, rec=0.066, cos=0.002), tot_loss_proj:1.730 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
Attempt swap
[1900/2000] tot_loss=1.169 (perp=5.486, rec=0.070, cos=0.002), tot_loss_proj:1.720 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
[1950/2000] tot_loss=1.169 (perp=5.486, rec=0.071, cos=0.002), tot_loss_proj:1.727 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
Attempt swap
[2000/2000] tot_loss=1.170 (perp=5.486, rec=0.071, cos=0.002), tot_loss_proj:1.725 [t=0.22s]
prediction: ['[CLS] want to think about what too much what going on [ [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want to think about what too much frame what going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 60.870 | p: 58.333 | r: 63.636
rougeL     | fm: 80.000 | p: 76.923 | r: 83.333
rougeLsum  | fm: 80.000 | p: 76.923 | r: 83.333
r1fm+r2fm = 148.870

[Aggregate metrics]:
rouge1     | fm: 91.851 | p: 91.503 | r: 92.384
rouge2     | fm: 59.580 | p: 59.277 | r: 59.914
rougeL     | fm: 81.372 | p: 80.930 | r: 81.926
rougeLsum  | fm: 81.005 | p: 80.564 | r: 81.511
r1fm+r2fm = 151.432

input #17 time: 0:09:28 | total time: 2:51:06


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9993190368282765
highest_index [0]
highest [0.9993190368282765]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9812633991241455 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9802066087722778 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.9420520067214966 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9321717023849487 for ['[CLS] deportivo suspect usual aston [SEP]']
[Init] best rec loss: 0.9248862266540527 for ['[CLS] water global accreditation originally [SEP]']
[Init] best rec loss: 0.8890918493270874 for ['[CLS] press lose hunger tracks [SEP]']
[Init] best rec loss: 0.8745237588882446 for ['[CLS] affectionately character hundreds team [SEP]']
[Init] best rec loss: 0.8682559132575989 for ['[CLS] oniest α department [SEP]']
[Init] best rec loss: 0.8211305737495422 for ['[CLS] dual circle duodle [SEP]']
[Init] best perm rec loss: 0.8210713267326355 for ['[CLS] du dual circleodle [SEP]']
[Init] best perm rec loss: 0.8178795576095581 for ['[CLS]odle dual circle du [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.374 (perp=15.457, rec=0.276, cos=0.006), tot_loss_proj:4.698 [t=0.24s]
prediction: ['[CLS]gor finite spiritgor [SEP]']
[ 100/2000] tot_loss=2.872 (perp=13.296, rec=0.209, cos=0.004), tot_loss_proj:4.607 [t=0.24s]
prediction: ['[CLS]gorvivigor [SEP]']
[ 150/2000] tot_loss=3.161 (perp=14.810, rec=0.196, cos=0.004), tot_loss_proj:4.736 [t=0.24s]
prediction: ['[CLS]atingvigorgor [SEP]']
[ 200/2000] tot_loss=3.111 (perp=14.810, rec=0.147, cos=0.003), tot_loss_proj:4.746 [t=0.24s]
prediction: ['[CLS]atingvigorgor [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.298 (perp=10.732, rec=0.148, cos=0.003), tot_loss_proj:2.965 [t=0.24s]
prediction: ['[CLS]vigoratinggor [SEP]']
[ 300/2000] tot_loss=2.263 (perp=10.732, rec=0.114, cos=0.002), tot_loss_proj:2.996 [t=0.24s]
prediction: ['[CLS]vigoratinggor [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.934 (perp=14.198, rec=0.093, cos=0.002), tot_loss_proj:4.640 [t=0.24s]
prediction: ['[CLS]viviatinggor [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.560 (perp=7.299, rec=0.099, cos=0.002), tot_loss_proj:1.824 [t=0.24s]
prediction: ['[CLS]vigorating in [SEP]']
[ 450/2000] tot_loss=1.544 (perp=7.299, rec=0.083, cos=0.001), tot_loss_proj:1.836 [t=0.24s]
prediction: ['[CLS]vigorating in [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.174 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.191 (perp=5.588, rec=0.072, cos=0.001), tot_loss_proj:1.190 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.194 (perp=5.588, rec=0.075, cos=0.001), tot_loss_proj:1.188 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.175 (perp=5.588, rec=0.056, cos=0.001), tot_loss_proj:1.183 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.185 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.189 (perp=5.588, rec=0.070, cos=0.001), tot_loss_proj:1.177 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.174 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.191 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.197 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.184 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.187 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.176 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.176 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.190 (perp=5.588, rec=0.071, cos=0.001), tot_loss_proj:1.183 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.176 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.181 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.188 (perp=5.588, rec=0.069, cos=0.001), tot_loss_proj:1.191 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.181 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.186 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.184 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.183 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.185 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.190 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.194 (perp=5.588, rec=0.075, cos=0.001), tot_loss_proj:1.178 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.185 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.187 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.189 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.188 (perp=5.588, rec=0.069, cos=0.001), tot_loss_proj:1.173 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.187 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.182 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.176 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.192 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.185 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.184 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.318 | p: 91.893 | r: 92.890
rouge2     | fm: 61.811 | p: 61.557 | r: 62.191
rougeL     | fm: 82.318 | p: 81.891 | r: 82.841
rougeLsum  | fm: 81.978 | p: 81.626 | r: 82.613
r1fm+r2fm = 154.130

input #18 time: 0:09:27 | total time: 3:00:33


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.999363157298685
highest_index [0]
highest [0.999363157298685]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.772068977355957 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7611664533615112 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.7419012188911438 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7293687462806702 for ['[CLS] target jessica episode ling [SEP]']
[Init] best rec loss: 0.7094267010688782 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.6969524025917053 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6877771019935608 for ['[CLS] centers recordtion difficult [SEP]']
[Init] best rec loss: 0.6869916915893555 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.674118161201477 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 0.6444098353385925 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6434956789016724 for ['[CLS] orderyna reaching pin [SEP]']
[Init] best perm rec loss: 0.6406313180923462 for ['[CLS] pin reachingyna order [SEP]']
[Init] best perm rec loss: 0.6404289603233337 for ['[CLS] pinyna order reaching [SEP]']
[Init] best perm rec loss: 0.6399739980697632 for ['[CLS]yna order pin reaching [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.196 (perp=13.947, rec=0.355, cos=0.052), tot_loss_proj:4.153 [t=0.22s]
prediction: ['[CLS], sickfa [SEP] [SEP]']
[ 100/2000] tot_loss=2.596 (perp=11.691, rec=0.237, cos=0.021), tot_loss_proj:4.185 [t=0.22s]
prediction: ['[CLS] tofafa in [SEP]']
[ 150/2000] tot_loss=2.375 (perp=10.916, rec=0.178, cos=0.014), tot_loss_proj:3.947 [t=0.22s]
prediction: ['[CLS] tomyfa in [SEP]']
[ 200/2000] tot_loss=2.307 (perp=10.916, rec=0.115, cos=0.009), tot_loss_proj:3.952 [t=0.22s]
prediction: ['[CLS] tomyfa in [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.341 (perp=6.109, rec=0.112, cos=0.007), tot_loss_proj:1.310 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.323 (perp=6.109, rec=0.097, cos=0.004), tot_loss_proj:1.310 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.330 (perp=6.109, rec=0.104, cos=0.004), tot_loss_proj:1.309 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.315 (perp=6.109, rec=0.090, cos=0.004), tot_loss_proj:1.295 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.323 (perp=6.109, rec=0.097, cos=0.004), tot_loss_proj:1.303 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.312 (perp=6.109, rec=0.086, cos=0.004), tot_loss_proj:1.317 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.311 (perp=6.109, rec=0.085, cos=0.004), tot_loss_proj:1.296 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.312 (perp=6.109, rec=0.086, cos=0.004), tot_loss_proj:1.307 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.303 (perp=6.109, rec=0.077, cos=0.004), tot_loss_proj:1.302 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.313 (perp=6.109, rec=0.087, cos=0.004), tot_loss_proj:1.307 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.304 (perp=6.109, rec=0.078, cos=0.004), tot_loss_proj:1.315 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.302 (perp=6.109, rec=0.076, cos=0.004), tot_loss_proj:1.311 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.311 (perp=6.109, rec=0.085, cos=0.004), tot_loss_proj:1.311 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.315 (perp=6.109, rec=0.090, cos=0.004), tot_loss_proj:1.306 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.314 (perp=6.109, rec=0.088, cos=0.004), tot_loss_proj:1.302 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.300 (perp=6.109, rec=0.074, cos=0.004), tot_loss_proj:1.300 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.301 (perp=6.109, rec=0.075, cos=0.004), tot_loss_proj:1.300 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.314 (perp=6.109, rec=0.088, cos=0.004), tot_loss_proj:1.299 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.306 (perp=6.109, rec=0.080, cos=0.004), tot_loss_proj:1.292 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.309 (perp=6.109, rec=0.083, cos=0.004), tot_loss_proj:1.304 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.312 (perp=6.109, rec=0.086, cos=0.004), tot_loss_proj:1.298 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.304 (perp=6.109, rec=0.078, cos=0.004), tot_loss_proj:1.302 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.305 (perp=6.109, rec=0.079, cos=0.004), tot_loss_proj:1.288 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.311 (perp=6.109, rec=0.086, cos=0.004), tot_loss_proj:1.300 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.300 (perp=6.109, rec=0.074, cos=0.004), tot_loss_proj:1.300 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.311 (perp=6.109, rec=0.085, cos=0.004), tot_loss_proj:1.307 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.308 (perp=6.109, rec=0.082, cos=0.004), tot_loss_proj:1.319 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.317 (perp=6.109, rec=0.091, cos=0.004), tot_loss_proj:1.296 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.309 (perp=6.109, rec=0.084, cos=0.004), tot_loss_proj:1.306 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.310 (perp=6.109, rec=0.085, cos=0.004), tot_loss_proj:1.304 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.316 (perp=6.109, rec=0.090, cos=0.004), tot_loss_proj:1.300 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.298 (perp=6.109, rec=0.073, cos=0.004), tot_loss_proj:1.300 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.303 (perp=6.109, rec=0.078, cos=0.004), tot_loss_proj:1.307 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.302 (perp=6.109, rec=0.076, cos=0.004), tot_loss_proj:1.297 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.301 (perp=6.109, rec=0.075, cos=0.004), tot_loss_proj:1.301 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.314 (perp=6.109, rec=0.089, cos=0.004), tot_loss_proj:1.309 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.811 | p: 92.338 | r: 93.310
rouge2     | fm: 63.802 | p: 63.470 | r: 64.188
rougeL     | fm: 83.341 | p: 82.948 | r: 83.794
rougeLsum  | fm: 82.982 | p: 82.570 | r: 83.529
r1fm+r2fm = 156.613

input #19 time: 0:09:01 | total time: 3:09:34


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9992466282325256
highest_index [0]
highest [0.9992466282325256]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8128877878189087 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.7983160018920898 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7954925298690796 for ['[CLS] york match causearu [SEP]']
[Init] best rec loss: 0.7945184111595154 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.765099823474884 for ['[CLS] poorpid african forming [SEP]']
[Init] best perm rec loss: 0.7603084444999695 for ['[CLS]pid poor forming african [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.602 (perp=10.780, rec=0.380, cos=0.066), tot_loss_proj:3.166 [t=0.23s]
prediction: ['[CLS]verse cavalry pleasure pleasure [SEP]']
[ 100/2000] tot_loss=2.456 (perp=10.953, rec=0.242, cos=0.023), tot_loss_proj:2.963 [t=0.24s]
prediction: ['[CLS]verseverseverse pleasure [SEP]']
[ 150/2000] tot_loss=2.194 (perp=10.297, rec=0.128, cos=0.007), tot_loss_proj:3.145 [t=0.24s]
prediction: ['[CLS]verseverse the pleasure [SEP]']
[ 200/2000] tot_loss=1.993 (perp=9.465, rec=0.092, cos=0.008), tot_loss_proj:2.867 [t=0.24s]
prediction: ['[CLS]verse per the pleasure [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.692 (perp=7.610, rec=0.153, cos=0.016), tot_loss_proj:1.987 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 300/2000] tot_loss=1.603 (perp=7.610, rec=0.079, cos=0.002), tot_loss_proj:1.818 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.602 (perp=7.610, rec=0.078, cos=0.002), tot_loss_proj:1.811 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.598 (perp=7.610, rec=0.074, cos=0.002), tot_loss_proj:1.810 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.582 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.806 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.582 (perp=7.610, rec=0.058, cos=0.002), tot_loss_proj:1.812 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.604 (perp=7.610, rec=0.081, cos=0.002), tot_loss_proj:1.805 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.589 (perp=7.610, rec=0.066, cos=0.001), tot_loss_proj:1.802 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.593 (perp=7.610, rec=0.070, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.592 (perp=7.610, rec=0.069, cos=0.001), tot_loss_proj:1.815 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.001), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.579 (perp=7.610, rec=0.056, cos=0.001), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.594 (perp=7.610, rec=0.071, cos=0.001), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.576 (perp=7.610, rec=0.053, cos=0.001), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.575 (perp=7.610, rec=0.052, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.575 (perp=7.610, rec=0.052, cos=0.002), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.586 (perp=7.610, rec=0.062, cos=0.001), tot_loss_proj:1.790 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.580 (perp=7.610, rec=0.056, cos=0.002), tot_loss_proj:1.798 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.566 (perp=7.610, rec=0.042, cos=0.001), tot_loss_proj:1.796 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.589 (perp=7.610, rec=0.065, cos=0.001), tot_loss_proj:1.790 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.573 (perp=7.610, rec=0.049, cos=0.001), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.570 (perp=7.610, rec=0.046, cos=0.001), tot_loss_proj:1.787 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.585 (perp=7.610, rec=0.061, cos=0.002), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.587 (perp=7.610, rec=0.063, cos=0.001), tot_loss_proj:1.780 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.596 (perp=7.610, rec=0.073, cos=0.001), tot_loss_proj:1.790 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.001), tot_loss_proj:1.786 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.581 (perp=7.610, rec=0.057, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.584 (perp=7.610, rec=0.060, cos=0.001), tot_loss_proj:1.794 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.582 (perp=7.610, rec=0.059, cos=0.001), tot_loss_proj:1.792 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.578 (perp=7.610, rec=0.054, cos=0.001), tot_loss_proj:1.796 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.600 (perp=7.610, rec=0.077, cos=0.001), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.584 (perp=7.610, rec=0.060, cos=0.001), tot_loss_proj:1.788 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.576 (perp=7.610, rec=0.052, cos=0.002), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.592 (perp=7.610, rec=0.069, cos=0.002), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.581 (perp=7.610, rec=0.058, cos=0.001), tot_loss_proj:1.794 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.590 (perp=7.610, rec=0.067, cos=0.002), tot_loss_proj:1.795 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.184 | p: 92.817 | r: 93.689
rouge2     | fm: 64.873 | p: 64.650 | r: 65.302
rougeL     | fm: 84.177 | p: 83.746 | r: 84.705
rougeLsum  | fm: 83.753 | p: 83.325 | r: 84.310
r1fm+r2fm = 158.057

input #20 time: 0:09:29 | total time: 3:19:03


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.9993230237614525
highest_index [0]
highest [0.9993230237614525]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9383777379989624 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8842588663101196 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.871904194355011 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 0.8708706498146057 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.850473165512085 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.8207973837852478 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best rec loss: 0.8122449517250061 for ['[CLS] chamber firm returnfying evidence commission clear sq extra above episodeoom [SEP] brows ashland odd viva range surgical waters village right daddy speed jin [SEP]']
[Init] best perm rec loss: 0.8117348551750183 for ['[CLS] extra right viva clear waters chamber above firm episode sq village returnoom brows odd commission ashland surgical daddy evidencefying [SEP] jin speed range [SEP]']
[Init] best perm rec loss: 0.8112597465515137 for ['[CLS] chamber viva episode clear commission range right [SEP] speed return extra above evidence brows village jin waters surgical firm sq ashland daddyoomfying odd [SEP]']
[Init] best perm rec loss: 0.81005859375 for ['[CLS] sq speed odd return above commission extra surgical episode range clear jin village viva brows firm watersoom daddy ashland [SEP] evidence chamber rightfying [SEP]']
[Init] best perm rec loss: 0.8099977970123291 for ['[CLS] viva chamber brows odd surgical commission clear village daddy jin range right extra speed evidence ashland above waters sq returnfying [SEP]oom episode firm [SEP]']
[Init] best perm rec loss: 0.8085297346115112 for ['[CLS] ashland chamber [SEP] return range above firm episode daddy brows surgical vivafying clear waters extraoom evidence village commission speed jin sq right odd [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.890 (perp=12.495, rec=0.370, cos=0.021), tot_loss_proj:3.739 [t=0.24s]
prediction: ['[CLS] stress drivers orphan abandonedting betweens system drugs through women scheme opposed many.bi blown portrayed wielding ignorant initially concern always woman forces [SEP]']
[ 100/2000] tot_loss=2.424 (perp=10.265, rec=0.342, cos=0.029), tot_loss_proj:3.008 [t=0.24s]
prediction: ['[CLS] obvious mothers caretaker complicated this findss stunt. any more treatment opposed many. needs athletes betrayed reputation teacher is teams before women athletes [SEP]']
[ 150/2000] tot_loss=2.323 (perp=10.405, rec=0.233, cos=0.009), tot_loss_proj:3.457 [t=0.25s]
prediction: ['[CLS] way mothers caretaker way works worksde way. any more athletes opposed many. teachers athletes like serious curriculum is teams instead women athletes [SEP]']
[ 200/2000] tot_loss=2.165 (perp=9.780, rec=0.205, cos=0.004), tot_loss_proj:2.885 [t=0.25s]
prediction: ['[CLS] way women caretaker way works out off out. look more athletes turn seem more teachers athletes like serious theological makes athletes instead women athletes [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.135 (perp=9.789, rec=0.173, cos=0.004), tot_loss_proj:2.848 [t=0.25s]
prediction: ['[CLS] way women caretaker this works outex out. look more athletes makes look more teachers makes like serious theological athletess instead women athletes [SEP]']
[ 300/2000] tot_loss=2.310 (perp=10.845, rec=0.138, cos=0.003), tot_loss_proj:2.975 [t=0.24s]
prediction: ['[CLS] way women caretaker this works outrz all.typical more athletes makes look more caretaker makes like serious stereo athletess instead women athletes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.167 (perp=10.079, rec=0.147, cos=0.005), tot_loss_proj:3.016 [t=0.25s]
prediction: ['[CLS] way women tournament this works out with all.typical more caretaker makes look more caretaker makes seemedtypical stereo athletes, instead women athletes [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.018 (perp=9.319, rec=0.150, cos=0.004), tot_loss_proj:3.055 [t=0.24s]
prediction: ['[CLS] way the tournament this works out with all. athletes more caretaker like look more caretaker makes seemed like moraltypical, instead women athletes [SEP]']
[ 450/2000] tot_loss=2.105 (perp=9.873, rec=0.127, cos=0.003), tot_loss_proj:3.281 [t=0.25s]
prediction: ['[CLS] way the tournament this works outs all. athletes more caretaker like look more caretaker makes charley like moraltypical, instead women athletes [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.925 (perp=9.018, rec=0.118, cos=0.003), tot_loss_proj:2.627 [t=0.25s]
prediction: ['[CLS] way the athletes this works outs all makes athletes more caretaker like look more caretaker. charley like stereotypical, instead women athletes [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.825 (perp=8.517, rec=0.117, cos=0.004), tot_loss_proj:2.513 [t=0.24s]
prediction: ['[CLS] way the caretaker this works outs all makes athletes more athletes like look more caretaker. devoted like stereotypical, instead women athletes [SEP]']
[ 600/2000] tot_loss=1.812 (perp=8.517, rec=0.105, cos=0.003), tot_loss_proj:2.517 [t=0.25s]
prediction: ['[CLS] way the caretaker this works outs all makes athletes more athletes like look more caretaker. devoted like stereotypical, instead women athletes [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.734 (perp=8.104, rec=0.110, cos=0.003), tot_loss_proj:2.320 [t=0.24s]
prediction: ['[CLS] way the caretaker this works outs all makes athletes more athletes like look more caretaker. instead like stereotypical, devoted women athletes [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.690 (perp=7.892, rec=0.109, cos=0.003), tot_loss_proj:2.255 [t=0.25s]
prediction: ['[CLS] way the caretaker this works outs all makes athletes more athletes more look like caretaker. instead like stereotypical, devoted women athletes [SEP]']
[ 750/2000] tot_loss=1.685 (perp=7.892, rec=0.104, cos=0.003), tot_loss_proj:2.258 [t=0.25s]
prediction: ['[CLS] way the caretaker this works outs all makes athletes more athletes more look like caretaker. instead like stereotypical, devoted women athletes [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.600 (perp=7.531, rec=0.091, cos=0.003), tot_loss_proj:2.241 [t=0.24s]
prediction: ['[CLS] caretaker the way this works outs all makes athletes more athletes more look like caretaker. instead like stereotypical, devoted women athletes [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.637 (perp=7.528, rec=0.127, cos=0.004), tot_loss_proj:2.128 [t=0.24s]
prediction: ['[CLS] caretaker the way this works outs all makes athletes the athletes more look like caretaker athletes instead like stereotypical, devoted women. [SEP]']
[ 900/2000] tot_loss=1.606 (perp=7.528, rec=0.097, cos=0.003), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] caretaker the way this works outs all makes athletes the athletes more look like caretaker athletes instead like stereotypical, devoted women. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.521 (perp=7.045, rec=0.109, cos=0.003), tot_loss_proj:1.991 [t=0.25s]
prediction: ['[CLS] caretaker the way this works outs all makes the athletes athletes more look like caretaker athletes instead like stereotypical, devoted women. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.446 (perp=6.686, rec=0.105, cos=0.003), tot_loss_proj:1.853 [t=0.25s]
prediction: ['[CLS] the way this works outs all makes the teachers caretaker athletes more look like caretaker athletes instead like stereotypical, devoted women. [SEP]']
[1050/2000] tot_loss=1.475 (perp=6.870, rec=0.099, cos=0.003), tot_loss_proj:1.880 [t=0.25s]
prediction: ['[CLS] the way this works outs all makes the teachers caretaker athletes more look like caretaker athletes instead like stereotypical,stituting women. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.473 (perp=6.870, rec=0.097, cos=0.003), tot_loss_proj:1.876 [t=0.25s]
prediction: ['[CLS] the way this works outs all makes the teachers caretaker athletes more look like caretaker athletes instead like stereotypical,stituting women. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.588 (perp=7.361, rec=0.113, cos=0.003), tot_loss_proj:1.963 [t=0.25s]
prediction: ['[CLS] the way this works outs all makes the teachers caretaker athletes more look liketypical, caretaker athletes instead like stereostituting women. [SEP]']
[1200/2000] tot_loss=1.569 (perp=7.361, rec=0.094, cos=0.003), tot_loss_proj:1.965 [t=0.24s]
prediction: ['[CLS] the way this works outs all makes the teachers caretaker athletes more look liketypical, caretaker athletes instead like stereostituting women. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.527 (perp=7.178, rec=0.089, cos=0.003), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] the way this works outs makes all the teachers caretaker athletes more look stereotypical, caretaker athletes instead like stereostituting women. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.494 (perp=6.928, rec=0.105, cos=0.003), tot_loss_proj:1.923 [t=0.25s]
prediction: ['[CLS] the way this works outs makes all the teachers caretaker athletes look more stereotypical, caretaker athletes instead like stereostituting women. [SEP]']
[1350/2000] tot_loss=1.480 (perp=6.928, rec=0.091, cos=0.003), tot_loss_proj:1.920 [t=0.25s]
prediction: ['[CLS] the way this works outs makes all the teachers caretaker athletes look more stereotypical, caretaker athletes instead like stereostituting women. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.435 (perp=6.645, rec=0.103, cos=0.003), tot_loss_proj:2.285 [t=0.25s]
prediction: ['[CLS] the way this works out athletes makes all the teachers caretaker athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.428 (perp=6.648, rec=0.096, cos=0.003), tot_loss_proj:2.257 [t=0.24s]
prediction: ['[CLS] the way this works athletes out makes all the teachers caretaker athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
[1500/2000] tot_loss=1.437 (perp=6.693, rec=0.096, cos=0.003), tot_loss_proj:2.237 [t=0.25s]
prediction: ['[CLS] the way this works athletes out makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.423 (perp=6.649, rec=0.090, cos=0.003), tot_loss_proj:2.354 [t=0.25s]
prediction: ['[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.433 (perp=6.649, rec=0.101, cos=0.003), tot_loss_proj:2.354 [t=0.25s]
prediction: ['[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
[1650/2000] tot_loss=1.428 (perp=6.649, rec=0.095, cos=0.003), tot_loss_proj:2.348 [t=0.24s]
prediction: ['[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.436 (perp=6.649, rec=0.103, cos=0.003), tot_loss_proj:2.350 [t=0.25s]
prediction: ['[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.425 (perp=6.649, rec=0.092, cos=0.003), tot_loss_proj:2.346 [t=0.24s]
prediction: ['[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
[1800/2000] tot_loss=1.435 (perp=6.649, rec=0.102, cos=0.003), tot_loss_proj:2.356 [t=0.25s]
prediction: ['[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.421 (perp=6.649, rec=0.088, cos=0.003), tot_loss_proj:2.349 [t=0.25s]
prediction: ['[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.426 (perp=6.649, rec=0.094, cos=0.003), tot_loss_proj:2.349 [t=0.24s]
prediction: ['[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
[1950/2000] tot_loss=1.437 (perp=6.649, rec=0.104, cos=0.003), tot_loss_proj:2.353 [t=0.25s]
prediction: ['[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.430 (perp=6.649, rec=0.098, cos=0.003), tot_loss_proj:2.348 [t=0.25s]
prediction: ['[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] the way this works out athletes makes all the teachers moral athletes look more stereotypical, caretakers instead like stereostituting women. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 90.909 | r: 86.957
rouge2     | fm: 27.907 | p: 28.571 | r: 27.273
rougeL     | fm: 62.222 | p: 63.636 | r: 60.870
rougeLsum  | fm: 62.222 | p: 63.636 | r: 60.870
r1fm+r2fm = 116.796

[Aggregate metrics]:
rouge1     | fm: 92.888 | p: 92.667 | r: 93.220
rouge2     | fm: 63.865 | p: 63.626 | r: 64.162
rougeL     | fm: 82.944 | p: 82.738 | r: 83.432
rougeLsum  | fm: 82.890 | p: 82.495 | r: 83.296
r1fm+r2fm = 156.753

input #21 time: 0:09:43 | total time: 3:28:47


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9993371438838807
highest_index [0]
highest [0.9993371438838807]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9595676064491272 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9528931379318237 for ['[CLS] so saddle bronze dimension was hal code throughout semester static paced [SEP]']
[Init] best rec loss: 0.9366499781608582 for ['[CLS] along amount clear garden isn crime jockey gillespiecies dorian same [SEP]']
[Init] best rec loss: 0.9234999418258667 for ['[CLS] immunity manufacture poor vested access another dir $ resemblance i wrote [SEP]']
[Init] best perm rec loss: 0.9191067814826965 for ['[CLS] resemblance manufacture another immunity poor wrote access $ vested dir i [SEP]']
[Init] best perm rec loss: 0.9184873104095459 for ['[CLS] another immunity access $ vested wrote manufacture i poor resemblance dir [SEP]']
[Init] best perm rec loss: 0.9146518707275391 for ['[CLS] wrote manufacture resemblance immunity vested i poor access $ dir another [SEP]']
[Init] best perm rec loss: 0.9144909381866455 for ['[CLS] access immunity dir vested wrote another $ manufacture resemblance poor i [SEP]']
[Init] best perm rec loss: 0.9138860106468201 for ['[CLS] vested manufacture access immunity resemblance wrote i $ poor another dir [SEP]']
[Init] best perm rec loss: 0.9131993651390076 for ['[CLS] manufacture vested $ resemblance wrote dir immunity i another access poor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.696 (perp=12.143, rec=0.262, cos=0.005), tot_loss_proj:3.014 [t=0.24s]
prediction: ['[CLS] successful successful build wonderful successful production innovative adaptation leroy relations successful [SEP]']
[ 100/2000] tot_loss=2.158 (perp=9.947, rec=0.167, cos=0.002), tot_loss_proj:2.481 [t=0.24s]
prediction: ['[CLS] a successful development enjoyable an enjoyable enjoyable adaptation its affairs successful [SEP]']
[ 150/2000] tot_loss=2.278 (perp=10.724, rec=0.131, cos=0.002), tot_loss_proj:2.574 [t=0.24s]
prediction: ['[CLS] a successful and film a own enjoyable adaptation an right successful [SEP]']
[ 200/2000] tot_loss=1.969 (perp=9.389, rec=0.090, cos=0.001), tot_loss_proj:2.329 [t=0.25s]
prediction: ['[CLS] a successful and film an own enjoyable adaptation its right right [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.727 (perp=8.238, rec=0.078, cos=0.001), tot_loss_proj:2.066 [t=0.25s]
prediction: ['[CLS] a successful film and an own enjoyable adaptation its right right [SEP]']
[ 300/2000] tot_loss=1.713 (perp=8.168, rec=0.078, cos=0.001), tot_loss_proj:1.961 [t=0.24s]
prediction: ['[CLS] a successful film and an own enjoyable adaptation in right right [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.472 (perp=6.998, rec=0.071, cos=0.001), tot_loss_proj:1.622 [t=0.24s]
prediction: ['[CLS] a successful film and enjoyable adaptation in an own right right [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.428 (perp=6.765, rec=0.074, cos=0.001), tot_loss_proj:1.705 [t=0.25s]
prediction: ['[CLS] a successful right and enjoyable adaptation in an own right film [SEP]']
[ 450/2000] tot_loss=1.419 (perp=6.765, rec=0.064, cos=0.001), tot_loss_proj:1.705 [t=0.24s]
prediction: ['[CLS] a successful right and enjoyable adaptation in an own right film [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.341 (perp=6.346, rec=0.071, cos=0.001), tot_loss_proj:1.605 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable adaptation right in an own right film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.348 (perp=6.346, rec=0.078, cos=0.001), tot_loss_proj:1.596 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable adaptation right in an own right film [SEP]']
[ 600/2000] tot_loss=1.344 (perp=6.346, rec=0.074, cos=0.001), tot_loss_proj:1.600 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable adaptation right in an own right film [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.295 (perp=6.106, rec=0.073, cos=0.001), tot_loss_proj:1.536 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.291 (perp=6.106, rec=0.069, cos=0.001), tot_loss_proj:1.542 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
[ 750/2000] tot_loss=1.300 (perp=6.106, rec=0.078, cos=0.001), tot_loss_proj:1.535 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.301 (perp=6.106, rec=0.079, cos=0.001), tot_loss_proj:1.530 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.296 (perp=6.106, rec=0.073, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
[ 900/2000] tot_loss=1.283 (perp=6.106, rec=0.061, cos=0.001), tot_loss_proj:1.533 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.300 (perp=6.106, rec=0.078, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1000/2000] tot_loss=1.290 (perp=6.106, rec=0.067, cos=0.001), tot_loss_proj:1.540 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
[1050/2000] tot_loss=1.305 (perp=6.106, rec=0.082, cos=0.001), tot_loss_proj:1.532 [t=0.25s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1100/2000] tot_loss=1.299 (perp=6.106, rec=0.076, cos=0.001), tot_loss_proj:1.527 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1150/2000] tot_loss=1.288 (perp=6.106, rec=0.065, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
[1200/2000] tot_loss=1.289 (perp=6.106, rec=0.066, cos=0.001), tot_loss_proj:1.530 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1250/2000] tot_loss=1.301 (perp=6.106, rec=0.078, cos=0.001), tot_loss_proj:1.531 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1300/2000] tot_loss=1.295 (perp=6.106, rec=0.073, cos=0.001), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
[1350/2000] tot_loss=1.296 (perp=6.106, rec=0.074, cos=0.001), tot_loss_proj:1.533 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1400/2000] tot_loss=1.285 (perp=6.106, rec=0.063, cos=0.001), tot_loss_proj:1.534 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1450/2000] tot_loss=1.296 (perp=6.106, rec=0.074, cos=0.001), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
[1500/2000] tot_loss=1.290 (perp=6.106, rec=0.067, cos=0.001), tot_loss_proj:1.524 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1550/2000] tot_loss=1.299 (perp=6.106, rec=0.077, cos=0.001), tot_loss_proj:1.534 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1600/2000] tot_loss=1.291 (perp=6.106, rec=0.068, cos=0.001), tot_loss_proj:1.533 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
[1650/2000] tot_loss=1.296 (perp=6.106, rec=0.074, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1700/2000] tot_loss=1.302 (perp=6.106, rec=0.079, cos=0.001), tot_loss_proj:1.533 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1750/2000] tot_loss=1.292 (perp=6.106, rec=0.069, cos=0.001), tot_loss_proj:1.532 [t=0.25s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
[1800/2000] tot_loss=1.284 (perp=6.106, rec=0.062, cos=0.001), tot_loss_proj:1.531 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1850/2000] tot_loss=1.297 (perp=6.106, rec=0.074, cos=0.001), tot_loss_proj:1.535 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[1900/2000] tot_loss=1.286 (perp=6.106, rec=0.064, cos=0.001), tot_loss_proj:1.534 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
[1950/2000] tot_loss=1.303 (perp=6.106, rec=0.080, cos=0.001), tot_loss_proj:1.538 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Attempt swap
[2000/2000] tot_loss=1.294 (perp=6.106, rec=0.071, cos=0.001), tot_loss_proj:1.525 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in an own right [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a successful and enjoyable film adaptation right in an own right [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 41.667 | p: 41.667 | r: 41.667
rougeL     | fm: 76.923 | p: 76.923 | r: 76.923
rougeLsum  | fm: 76.923 | p: 76.923 | r: 76.923
r1fm+r2fm = 133.974

[Aggregate metrics]:
rouge1     | fm: 92.879 | p: 92.678 | r: 93.191
rouge2     | fm: 62.735 | p: 62.429 | r: 63.003
rougeL     | fm: 82.883 | p: 82.500 | r: 83.284
rougeLsum  | fm: 82.536 | p: 82.225 | r: 82.938
r1fm+r2fm = 155.614

input #22 time: 0:09:37 | total time: 3:38:24


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.9992355413950258
highest_index [0]
highest [0.9992355413950258]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.8026672005653381 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7627371549606323 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.7624605298042297 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 0.7589111328125 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell re書amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7574781775474548 for ['[CLS] catching directita antibiotics portrait omeza billy together nile skirtly rovers \\ aw remarks [CLS] soothing nonprofit attitude maybetag amar article tattooll camp [SEP] iii toe been ouaine var outrina " wild addition barry faced travelled rocket leigh engine ribbon abbreviation orders [SEP]']
[Init] best rec loss: 0.7385736107826233 for ['[CLS] ricky chief judas hai north hasiating machinery fathers next shown twitter industry guilty eye media possession grandª variety room cover administrativevere earlier del min fee becomeszzlingap matter trial fact boone pitch arranged saying gutime independence viola battle mentioning motorway song2 belgian [SEP]']
[Init] best rec loss: 0.737342894077301 for ['[CLS] 2018 screenwriter stone arlington lightquist circle only tight wire hospital weaponerateau would homestead grid inquiries das all locomotives makeup amazingpireau opponent velocitypressedise modifiedrish like footballer berlinnesian counter, nomination aden plantented bye brass mine gave a transport mira [SEP]']
[Init] best rec loss: 0.7356162071228027 for ['[CLS] florence heck vineyard breachpping spider hoptive mp ware property exploitation drew genre producer vic 5 alien straw becoming todder cut lackdity takgles queen warner una cloak orientation relations mouth copmed integer dd pearson jessie exterioristic abbreviated extra home round responded facts [SEP]']
[Init] best rec loss: 0.7274777293205261 for ['[CLS]tat erica asleep mayo test bullshit fine air sensation host rockeront into tracks. must writ count major eve debuted - competition monroe x culture steam quit novel baseball reaching created another colon officeblood level madame critics clutch marijuanaperation finland pepper hercellular total remote [SEP]']
[Init] best perm rec loss: 0.7271437048912048 for ['[CLS] monroe writ tracks - mayo steam erica must office baseball bullshit. marijuana into heront criticscellular asleep eve novel remote total rocker level clutch test air count madameperationtat host created pepper another debuted fine quit finland culture major reaching colonblood competition sensation x [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.748 (perp=11.454, rec=0.423, cos=0.034), tot_loss_proj:3.495 [t=0.24s]
prediction: ['[CLS] base colors negativem as design then plus restoration hopefully force national landscape in photo risk directly academy di wildlife ; power iien cultural lucius remainsger : goal nba serve /ur subtropical landscape - design design the varied armenian returns services historicalppet : aging [SEP]']
[ 100/2000] tot_loss=2.517 (perp=11.088, rec=0.288, cos=0.011), tot_loss_proj:3.402 [t=0.25s]
prediction: ['[CLS] battle arts significant a - idea the realm thus hopefullying national views of [SEP] interact [SEP] academy confederate environmental ; pool,us televised otherwise pac war : objective corps its / :ー studies - based pursuit the to armenian patriotic objective economic : : aging [SEP]']
[ 150/2000] tot_loss=2.533 (perp=11.375, rec=0.248, cos=0.010), tot_loss_proj:3.388 [t=0.25s]
prediction: ['[CLS] base achieve main a - objective by create technology hopefullyter political reservoir of [SEP] interact [SEP] besidesley patriotic ; string, electro ultimately otherwise ultimately troops : objective soldiers its / : factory memory -r institute the to ii patriotic ultimately strategic : : aging [SEP]']
[ 200/2000] tot_loss=2.256 (perp=10.313, rec=0.189, cos=0.005), tot_loss_proj:3.050 [t=0.24s]
prediction: ['[CLS] achieve achieve main a as objective ( thet hopefully raum situation, [SEP]. [SEP] while could patriotic,h, electro ultimately sometimes ultimately soldiers : objective soldiers its / : factory memory -r analysis the tellingur patriotic ultimately strategic :, development [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.144 (perp=9.862, rec=0.168, cos=0.004), tot_loss_proj:3.142 [t=0.25s]
prediction: ['[CLS] experience achieve main strategic as idea by foreign style hopefully student on your tech [SEP]aniesising while rejection patriotic, ra, political dramatic commander ultimately soldiers : objective soldiers its less patrioticminated memory - style : the the settlement - ultimately strategic romantic, development [SEP]']
[ 300/2000] tot_loss=2.156 (perp=10.069, rec=0.140, cos=0.003), tot_loss_proj:3.273 [t=0.25s]
prediction: ['[CLS] experience achieve main a as idea such u style hopefully character on your to storiesaniesising while rejection vietnam, ra, ra drama ultimately ultimately soldiers : objective soldiers its less patrioticctric memory - style : the drama settlement - ultimately strategic romantic, development [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.139 (perp=10.047, rec=0.127, cos=0.002), tot_loss_proj:3.384 [t=0.25s]
prediction: ['[CLS] achieve achieve main a as idea such of style hopefully character for your soldiers storiesanieszing while cannot vietnam, ra, political drama tone ultimately soldiers : objective to its would patrioticctric beauty - style : the drama conflict co ultimately strategic what, development [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.131 (perp=10.043, rec=0.120, cos=0.002), tot_loss_proj:3.337 [t=0.25s]
prediction: ['[CLS] achieve achieve main a as idea such of style hopefully character on your soldiers storiesanieszing while disapproval vietnam, ra, political drama tone ultimately soldiers : objective to its patriotic wouldzing beauty - style : the drama conflict co ultimately strategic what, development [SEP]']
[ 450/2000] tot_loss=2.269 (perp=10.710, rec=0.124, cos=0.003), tot_loss_proj:3.113 [t=0.24s]
prediction: ['[CLS] achieve achieve main contest as idea such caused creatureing character for your soldiers storiesanieszing while [SEP] vietnam, ra,, drama tone ultimately soldiers : objective to its patriotic would ⺩ memory - contemporary : the drama that co ultimately strategic what generation development [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.207 (perp=10.445, rec=0.117, cos=0.002), tot_loss_proj:3.145 [t=0.25s]
prediction: ['[CLS] had achieve main as idea such the style a ending character for the soldiersrogatedanieszing while cannot vietnam, ra,, drama tone ultimately soldiers : objective to its patriotic would ⺩ memory - contemporary : the drama that co ultimately strategicntes generation development [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.031 (perp=9.591, rec=0.111, cos=0.002), tot_loss_proj:2.994 [t=0.25s]
prediction: ['[CLS]s achieve main idea as such the style objecting character of the soldiersrogatedanieszing while cannot vietnam, ra,, drama tone ultimately soldiers : objective to its patriotic would ⺩ memory - style : the drama that cos strategicntes generation development [SEP]']
[ 600/2000] tot_loss=2.065 (perp=9.746, rec=0.113, cos=0.003), tot_loss_proj:3.000 [t=0.25s]
prediction: ['[CLS]s achieve main idea of such the style objecting character of the soldiersrogatedanieszing while cannot vietnam, ra,, drama tone ultimately soldiers : objective to its patriotic would ⺩ losses - style : the drama that tours strategic define generation syndrome [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.037 (perp=9.639, rec=0.107, cos=0.002), tot_loss_proj:2.891 [t=0.25s]
prediction: ['[CLS]s achieve main idea of such the soldiers style objecting character of the documentaryanieszing while cannot vietnam, ra,, drama tone ultimately soldiers : objective to its patriotic would ⺩ losses - derived : the drama that tours strategic define generation syndrome [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.987 (perp=9.432, rec=0.098, cos=0.002), tot_loss_proj:2.866 [t=0.25s]
prediction: ['[CLS]s achieve main idea of such wife soldiers style objecting character of the additionalanieszing while object vietnam, ra,, drama tone ultimately soldiers : objective to its patriotic tour ⺩ losses - - : the drama that woulds strategic define generation syndrome [SEP]']
[ 750/2000] tot_loss=1.978 (perp=9.404, rec=0.095, cos=0.002), tot_loss_proj:2.826 [t=0.25s]
prediction: ['[CLS] would achieve main idea of such wife soldiers style objecting character of the additionalanieszing while object vietnam, ra,, drama tone ultimately soldiers : objective to its patriotic tour ⺩ losses - - : the drama that woulds strategic define generation syndrome [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.937 (perp=9.170, rec=0.101, cos=0.002), tot_loss_proj:2.821 [t=0.25s]
prediction: ['[CLS] would achieve main idea of such wife soldiers style objecting character of the additionalanieszing while object vietnam, ra,, drama, ultimately soldiers tone objective to its patriotic such ⺩ losses - - : the drama that woulds strategic define generation syndrome [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.865 (perp=8.842, rec=0.095, cos=0.002), tot_loss_proj:2.685 [t=0.24s]
prediction: ['[CLS] will achieve main idea of such the soldiers style objecting character of the additionalanieszing while object vietnam, ra,, drama, ultimately soldiers patriotic objective to its tone such ⺩ role - - : the drama that woulds strategic define generation cost [SEP]']
[ 900/2000] tot_loss=1.847 (perp=8.758, rec=0.093, cos=0.002), tot_loss_proj:2.666 [t=0.24s]
prediction: ['[CLS] will achieve main idea of such the soldiers style objecting picture of the additional thezing while object vietnam, ra,, drama, ultimately soldiers patriotic objective to its tone such ⺩ role - - : the drama that woulds strategic define generation cost [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.832 (perp=8.669, rec=0.096, cos=0.002), tot_loss_proj:2.638 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such - soldiers style objecting picture of theam thezing while object vietnam, ra,, drama, ultimately soldiers patriotic objective to its such tone ⺩ role - - : the drama that woulds strategic define generation cost [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.862 (perp=8.826, rec=0.095, cos=0.002), tot_loss_proj:2.649 [t=0.24s]
prediction: ['[CLS] will achieve main idea of such - soldiers a objecting picture while theelia thezing of object vietnam, ra,, drama, ultimately soldiers patriotic objective to its such tone ⺩ role - - : the drama that woulds strategic define generation cost [SEP]']
[1050/2000] tot_loss=1.870 (perp=8.873, rec=0.094, cos=0.002), tot_loss_proj:2.664 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such - soldiers a objecting picture while theelia thezing of object vietnam, ra,, drama, ultimately soldiers patriotic objective to its such tone ⺩ conflict - - : the drama that woulds strategic define generation cost [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.842 (perp=8.732, rec=0.094, cos=0.002), tot_loss_proj:2.655 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such - soldiers a objecting picture while theelia thezing object of vietnam, ra,, drama, ultimately soldiers patriotic objective to its such tone ⺩ conflict - - : the drama that withs strategic define generation cost [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.812 (perp=8.572, rec=0.096, cos=0.002), tot_loss_proj:2.660 [t=0.24s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture while theelia thezing object of vietnam, ra,, drama, ultimately soldiers patriotic objective to its such tone ⺩ conflict - - : the drama that with soldiers strategic define generation cost [SEP]']
[1200/2000] tot_loss=1.830 (perp=8.694, rec=0.090, cos=0.002), tot_loss_proj:2.709 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture while theelia thezing object of vietnam, ra,, drama of ultimately soldiers patriotic objective to its such tone ⺩ conflict - - : the drama that with soldiers strategic define generation cost [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.809 (perp=8.560, rec=0.095, cos=0.002), tot_loss_proj:2.658 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture while theelia thezing object of vietnam, ra,, drama ि ultimately soldiers patriotic objective to its such tone of conflict - - : the drama that would soldiers strategic define generation cost [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.791 (perp=8.461, rec=0.097, cos=0.002), tot_loss_proj:2.664 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture while theelia thezing object of vietnam, ra,, conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would soldiers strategic define generation cost [SEP]']
[1350/2000] tot_loss=1.772 (perp=8.378, rec=0.094, cos=0.002), tot_loss_proj:2.623 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture while theelia thezing object of vietnam, ra,, conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that with soldiers strategic define generation cost [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.759 (perp=8.354, rec=0.086, cos=0.002), tot_loss_proj:2.651 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture, theelia thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would soldiers strategic define generation cost [SEP]']
Attempt swap
[1450/2000] tot_loss=1.782 (perp=8.446, rec=0.092, cos=0.001), tot_loss_proj:2.656 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture, thee thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would soldiers strategic define generation cost [SEP]']
[1500/2000] tot_loss=1.783 (perp=8.446, rec=0.092, cos=0.001), tot_loss_proj:2.652 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture, thee thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would soldiers strategic define generation cost [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.762 (perp=8.352, rec=0.090, cos=0.002), tot_loss_proj:2.658 [t=0.24s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture, thee thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would strategic soldiers define generation cost [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.737 (perp=8.243, rec=0.087, cos=0.002), tot_loss_proj:2.543 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture, thee thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would strategic define soldiers generation cost [SEP]']
[1650/2000] tot_loss=1.742 (perp=8.243, rec=0.092, cos=0.002), tot_loss_proj:2.543 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such -s a objecting picture, thee thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would strategic define soldiers generation cost [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.712 (perp=8.093, rec=0.092, cos=0.002), tot_loss_proj:2.477 [t=0.25s]
prediction: ['[CLS] will achieve main idea of such -s objecting a picture, thee thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would strategic define soldiers generation cost [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.697 (perp=8.011, rec=0.093, cos=0.001), tot_loss_proj:2.508 [t=0.25s]
prediction: ['[CLS] will achieve main idea - such ofs objecting a picture, thee thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would strategic define soldiers generation cost [SEP]']
[1800/2000] tot_loss=1.694 (perp=8.011, rec=0.090, cos=0.002), tot_loss_proj:2.505 [t=0.25s]
prediction: ['[CLS] will achieve main idea - such ofs objecting a picture, thee thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would strategic define soldiers generation cost [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.714 (perp=8.104, rec=0.092, cos=0.002), tot_loss_proj:2.609 [t=0.24s]
prediction: ['[CLS] will achieve idea - such ofs objecting a picture, the maine thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that with strategic define soldiers generation cost [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.701 (perp=8.042, rec=0.091, cos=0.002), tot_loss_proj:2.559 [t=0.25s]
prediction: ['[CLS] will achieve idea - such ofs objecting a picture, the maine thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its strategic tone of drama - - : the drama that withti define soldiers generation cost [SEP]']
[1950/2000] tot_loss=1.701 (perp=8.042, rec=0.092, cos=0.002), tot_loss_proj:2.552 [t=0.25s]
prediction: ['[CLS] will achieve idea - such ofs objecting a picture, the maine thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its strategic tone of drama - - : the drama that withti define soldiers generation cost [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.686 (perp=7.941, rec=0.096, cos=0.002), tot_loss_proj:2.509 [t=0.25s]
prediction: ['[CLS] will achieve idea - such ofs objecting a picture, the mainezing the object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its strategic tone of drama - - : the drama that withti define soldiers generation cost [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] will achieve main idea of such -s a objecting picture, thee thezing object of vietnam, ra, while conflict ि ultimately soldiers patriotic objective to its such tone of drama - - : the drama that would soldiers strategic define generation cost [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.354 | p: 69.231 | r: 67.500
rouge2     | fm: 2.597 | p: 2.632 | r: 2.564
rougeL     | fm: 35.443 | p: 35.897 | r: 35.000
rougeLsum  | fm: 35.443 | p: 35.897 | r: 35.000
r1fm+r2fm = 70.952

[Aggregate metrics]:
rouge1     | fm: 91.763 | p: 91.601 | r: 92.044
rouge2     | fm: 59.978 | p: 59.788 | r: 60.262
rougeL     | fm: 80.797 | p: 80.511 | r: 81.112
rougeLsum  | fm: 80.764 | p: 80.437 | r: 81.096
r1fm+r2fm = 151.741

input #23 time: 0:09:50 | total time: 3:48:15


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9993536462675896
highest_index [0]
highest [0.9993536462675896]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.897294282913208 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8667358160018921 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8546316623687744 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.8263182044029236 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.8232395052909851 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.8148535490036011 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 0.7650976181030273 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7616472244262695 for ['[CLS] port happy nowyl arms em ryu damnedaneous mid village bush bond suffer younger attack unless snow play county [SEP]']
[Init] best perm rec loss: 0.7595656514167786 for ['[CLS] attack port unless bond em village no happy sufferwyl mid youngeraneous damned bush snow arms ryu county play [SEP]']
[Init] best perm rec loss: 0.7575969696044922 for ['[CLS] ryu arms damned port happywyl em bush no county sufferaneous play snow attack village mid unless bond younger [SEP]']
[Init] best perm rec loss: 0.757588803768158 for ['[CLS] bush damned play suffer attack ryu village happy arms midwyl countyaneous bond snow younger port unless em no [SEP]']
[Init] best perm rec loss: 0.7541797757148743 for ['[CLS] arms village suffer bush attackwyl play happy mid em county unless port damned ryu no youngeraneous snow bond [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.532 (perp=10.838, rec=0.342, cos=0.023), tot_loss_proj:3.118 [t=0.24s]
prediction: ['[CLS] caught using are check terrorist illegitimate fae institute using current context unless terrorists.! was terrorists a removed evil [SEP]']
[ 100/2000] tot_loss=2.157 (perp=9.586, rec=0.231, cos=0.008), tot_loss_proj:2.668 [t=0.25s]
prediction: ['[CLS] taken the evil than terrorists techniques! out outside political context terrorists terrorists (! are terrorists a taken evil [SEP]']
[ 150/2000] tot_loss=2.102 (perp=9.504, rec=0.187, cos=0.014), tot_loss_proj:2.639 [t=0.25s]
prediction: ['[CLS] taken the evil than terroristsc! climate outside current context terrorists terrorists (! are terrorists : taken evil [SEP]']
[ 200/2000] tot_loss=2.290 (perp=10.664, rec=0.155, cos=0.003), tot_loss_proj:2.796 [t=0.25s]
prediction: ['[CLS] taken the of than terroristsc! climate outside current context political terrorists (! are terrorists : taken evil [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.028 (perp=9.351, rec=0.154, cos=0.004), tot_loss_proj:2.549 [t=0.25s]
prediction: ['[CLS] taken ofc are terrorists of! climate outside current context political terrorists (! are terrorists : taken evil [SEP]']
[ 300/2000] tot_loss=2.155 (perp=10.092, rec=0.133, cos=0.003), tot_loss_proj:2.777 [t=0.25s]
prediction: ['[CLS] taken of see than terrorists of ever climate outside current context political terrorists (! are terrorists : taken evil [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.050 (perp=9.579, rec=0.131, cos=0.003), tot_loss_proj:2.682 [t=0.24s]
prediction: ['[CLS] taken of see the terrorists than ever climate outside current context political political (! are terrorists : taken evil [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.466 (perp=9.746, rec=0.425, cos=0.092), tot_loss_proj:2.765 [t=0.24s]
prediction: ['[CLS] taken of see the situ than ever outside current context political political climate (! are terrorists : taken evil [SEP]']
[ 450/2000] tot_loss=2.411 (perp=10.572, rec=0.273, cos=0.024), tot_loss_proj:2.954 [t=0.24s]
prediction: ['[CLS] taken of see its situ rhodes ever outside current context beverage political climate (! are terrorists saying taken evil [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.239 (perp=9.994, rec=0.228, cos=0.012), tot_loss_proj:2.831 [t=0.25s]
prediction: ['[CLS] taken of see evil situ rhodes ever outside current context beverage political climate (! are terrorists saying taken the [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.202 (perp=9.965, rec=0.200, cos=0.009), tot_loss_proj:2.901 [t=0.25s]
prediction: ['[CLS] taken of see evil situ context ever outside current rhodes beverage political climate (! are terrorists saying taken those [SEP]']
[ 600/2000] tot_loss=2.178 (perp=9.914, rec=0.188, cos=0.007), tot_loss_proj:2.845 [t=0.25s]
prediction: ['[CLS] taken of see evil situ context ever outside current rhodes beverage political climate (! are terrorists : taken those [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.104 (perp=9.531, rec=0.192, cos=0.006), tot_loss_proj:2.777 [t=0.24s]
prediction: ['[CLS] taken of see evil situ context ever outside current rhodes beverage political climate (! are terrorists taken : those [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.981 (perp=8.944, rec=0.186, cos=0.006), tot_loss_proj:2.556 [t=0.25s]
prediction: ['[CLS] taken of see situ evil context ever outside current rhodes political political climate (! are terrorists taken : those [SEP]']
[ 750/2000] tot_loss=1.964 (perp=8.944, rec=0.170, cos=0.005), tot_loss_proj:2.552 [t=0.25s]
prediction: ['[CLS] taken of see situ evil context ever outside current rhodes political political climate (! are terrorists taken : those [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.904 (perp=8.666, rec=0.167, cos=0.004), tot_loss_proj:2.500 [t=0.25s]
prediction: ['[CLS] taken of see situ evil context ever outside current political rhodes political climate (! are terrorists taken : those [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.888 (perp=8.587, rec=0.167, cos=0.004), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS] taken of see situ evil context ever outside current political political climate rhodes (! are terrorists taken : those [SEP]']
[ 900/2000] tot_loss=1.876 (perp=8.587, rec=0.155, cos=0.004), tot_loss_proj:2.526 [t=0.25s]
prediction: ['[CLS] taken of see situ evil context ever outside current political political climate rhodes (! are terrorists taken : those [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.755 (perp=7.955, rec=0.160, cos=0.004), tot_loss_proj:2.261 [t=0.25s]
prediction: ['[CLS] taken of see situ evil context ever outside current political political climate ) (! those are terrorists taken : [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.737 (perp=7.868, rec=0.159, cos=0.004), tot_loss_proj:2.344 [t=0.25s]
prediction: ['[CLS] taken of see situ evil context ever outside current political political climate ) (! are those terrorists taken : [SEP]']
[1050/2000] tot_loss=1.723 (perp=7.822, rec=0.155, cos=0.004), tot_loss_proj:2.363 [t=0.25s]
prediction: ['[CLS] taken of see situ evil context ever outside current political political climate ) (! are the terrorists taken : [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.668 (perp=7.547, rec=0.155, cos=0.004), tot_loss_proj:2.334 [t=0.24s]
prediction: ['[CLS] taken of see situ evil context ever outside current political political climate (! are the terrorists taken : ) [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.642 (perp=7.448, rec=0.149, cos=0.003), tot_loss_proj:2.291 [t=0.25s]
prediction: ['[CLS] taken of see situ evil context ever outside current political political climate! ( are the terrorists taken : ) [SEP]']
[1200/2000] tot_loss=1.647 (perp=7.448, rec=0.154, cos=0.003), tot_loss_proj:2.299 [t=0.25s]
prediction: ['[CLS] taken of see situ evil context ever outside current political political climate! ( are the terrorists taken : ) [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.690 (perp=7.706, rec=0.146, cos=0.003), tot_loss_proj:2.362 [t=0.25s]
prediction: ['[CLS] taken see of situ evil context than outside current political political climate! ( are the terrorists taken : ) [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.662 (perp=7.523, rec=0.155, cos=0.003), tot_loss_proj:2.476 [t=0.24s]
prediction: ['[CLS] taken see of evil situ context than outside current political political climate! ( are the terrorists taken : ) [SEP]']
[1350/2000] tot_loss=1.647 (perp=7.523, rec=0.140, cos=0.003), tot_loss_proj:2.471 [t=0.25s]
prediction: ['[CLS] taken see of evil situ context than outside current political political climate! ( are the terrorists taken : ) [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.648 (perp=7.456, rec=0.153, cos=0.003), tot_loss_proj:2.458 [t=0.24s]
prediction: ['[CLS] taken see of evil situ context than outside current political climate! ( are the political terrorists taken : ) [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.577 (perp=7.077, rec=0.157, cos=0.004), tot_loss_proj:2.234 [t=0.25s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate! ( are political terrorists taken : ) [SEP]']
[1500/2000] tot_loss=1.564 (perp=7.077, rec=0.146, cos=0.003), tot_loss_proj:2.230 [t=0.25s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate! ( are political terrorists taken : ) [SEP]']
Attempt swap
[1550/2000] tot_loss=1.571 (perp=7.077, rec=0.152, cos=0.003), tot_loss_proj:2.234 [t=0.25s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate! ( are political terrorists taken : ) [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.554 (perp=6.994, rec=0.152, cos=0.003), tot_loss_proj:2.287 [t=0.25s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate! ( political terrorists are taken : ) [SEP]']
[1650/2000] tot_loss=1.558 (perp=6.994, rec=0.156, cos=0.003), tot_loss_proj:2.284 [t=0.25s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate! ( political terrorists are taken : ) [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.509 (perp=6.804, rec=0.144, cos=0.003), tot_loss_proj:2.203 [t=0.25s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate : ( political terrorists are taken! ) [SEP]']
Attempt swap
[1750/2000] tot_loss=1.513 (perp=6.804, rec=0.149, cos=0.003), tot_loss_proj:2.203 [t=0.25s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate : ( political terrorists are taken! ) [SEP]']
[1800/2000] tot_loss=1.517 (perp=6.804, rec=0.153, cos=0.003), tot_loss_proj:2.203 [t=0.25s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate : ( political terrorists are taken! ) [SEP]']
Attempt swap
[1850/2000] tot_loss=1.508 (perp=6.804, rec=0.145, cos=0.003), tot_loss_proj:2.203 [t=0.24s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate : ( political terrorists are taken! ) [SEP]']
Attempt swap
[1900/2000] tot_loss=1.505 (perp=6.804, rec=0.141, cos=0.003), tot_loss_proj:2.207 [t=0.25s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate : ( political terrorists are taken! ) [SEP]']
[1950/2000] tot_loss=1.501 (perp=6.804, rec=0.138, cos=0.003), tot_loss_proj:2.207 [t=0.24s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate : ( political terrorists are taken! ) [SEP]']
Attempt swap
[2000/2000] tot_loss=1.513 (perp=6.804, rec=0.149, cos=0.003), tot_loss_proj:2.200 [t=0.24s]
prediction: ['[CLS] taken see of evil situ context than outside the current political climate : ( political terrorists are taken! ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] taken of see the terrorists than ever climate outside current context political political (! are terrorists : taken evil [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.486 | p: 84.211 | r: 88.889
rouge2     | fm: 11.429 | p: 11.111 | r: 11.765
rougeL     | fm: 48.649 | p: 47.368 | r: 50.000
rougeLsum  | fm: 48.649 | p: 47.368 | r: 50.000
r1fm+r2fm = 97.915

[Aggregate metrics]:
rouge1     | fm: 91.528 | p: 91.390 | r: 91.926
rouge2     | fm: 58.243 | p: 57.979 | r: 58.558
rougeL     | fm: 79.530 | p: 79.246 | r: 79.900
rougeLsum  | fm: 79.170 | p: 78.866 | r: 79.539
r1fm+r2fm = 149.772

input #24 time: 0:09:50 | total time: 3:58:05


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9993175914078982
highest_index [0]
highest [0.9993175914078982]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.0069104433059692 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9421877264976501 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 0.9308463931083679 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.9195635914802551 for ['[CLS] cigarettes happy before makers [SEP]']
[Init] best rec loss: 0.9119874835014343 for ['[CLS] each envoy socialist achieving [SEP]']
[Init] best rec loss: 0.9097086787223816 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best rec loss: 0.880748987197876 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best perm rec loss: 0.8788651823997498 for ['[CLS] oblast mouth jury cycle [SEP]']
[Init] best perm rec loss: 0.8779757618904114 for ['[CLS] oblast cycle mouth jury [SEP]']
[Init] best perm rec loss: 0.8775536417961121 for ['[CLS] jury oblast cycle mouth [SEP]']
[Init] best perm rec loss: 0.8773100972175598 for ['[CLS] jury cycle mouth oblast [SEP]']
[Init] best perm rec loss: 0.8765084147453308 for ['[CLS] cycle jury mouth oblast [SEP]']
[Init] best perm rec loss: 0.8761308193206787 for ['[CLS] mouth oblast jury cycle [SEP]']
[Init] best perm rec loss: 0.8731858730316162 for ['[CLS] oblast mouth cycle jury [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.047 (perp=9.202, rec=0.201, cos=0.006), tot_loss_proj:2.210 [t=0.24s]
prediction: ['[CLS] beautiful sometimes beautiful film [SEP]']
[ 100/2000] tot_loss=1.786 (perp=8.327, rec=0.118, cos=0.002), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] beautiful strange beautiful film [SEP]']
[ 150/2000] tot_loss=1.782 (perp=8.327, rec=0.115, cos=0.002), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] beautiful strange beautiful film [SEP]']
[ 200/2000] tot_loss=1.761 (perp=8.327, rec=0.093, cos=0.002), tot_loss_proj:1.963 [t=0.24s]
prediction: ['[CLS] beautiful strange beautiful film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.552 (perp=7.298, rec=0.091, cos=0.001), tot_loss_proj:1.750 [t=0.24s]
prediction: ['[CLS] beautiful beautiful strange film [SEP]']
[ 300/2000] tot_loss=1.492 (perp=7.105, rec=0.070, cos=0.001), tot_loss_proj:1.621 [t=0.24s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.434 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.395 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.424 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.390 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.443 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.435 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.432 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.383 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.434 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.434 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.399 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.434 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.396 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.441 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.395 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.434 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.435 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.446 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.402 (perp=6.646, rec=0.072, cos=0.001), tot_loss_proj:1.428 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.437 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.393 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.437 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.386 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.428 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.399 (perp=6.646, rec=0.069, cos=0.001), tot_loss_proj:1.431 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.432 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.435 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.440 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.435 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.394 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.437 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.437 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.434 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.390 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.427 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.402 (perp=6.646, rec=0.071, cos=0.001), tot_loss_proj:1.423 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.386 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.440 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.384 (perp=6.646, rec=0.054, cos=0.001), tot_loss_proj:1.430 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.437 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.436 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.399 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.433 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.387 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.440 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.441 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.426 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.918 | p: 91.657 | r: 92.235
rouge2     | fm: 59.478 | p: 59.271 | r: 59.763
rougeL     | fm: 80.392 | p: 80.118 | r: 80.807
rougeLsum  | fm: 80.029 | p: 79.618 | r: 80.405
r1fm+r2fm = 151.396

input #25 time: 0:09:36 | total time: 4:07:42


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9992055446704899
highest_index [0]
highest [0.9992055446704899]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.9754382967948914 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.9662841558456421 for ['[CLS] arthur senior green europa out reach o approaching beck saga phone kimball range tel alain pointing spoil during people na tanggram bucket [SEP]']
[Init] best rec loss: 0.9602839946746826 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 0.9527743458747864 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 0.9404274821281433 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.9382520318031311 for ['[CLS] own aren solelyval hull shoot [CLS] letter four t gore plan when how marsh recently assessment throughout hiv bequeathed administrative liberty branch [SEP]']
[Init] best rec loss: 0.934402585029602 for ['[CLS] frozen peru embarrassed not one farimus sole australian clearance ladder | heir stevie covert dollars hunter allmusic post remain depending⁺ isolation [SEP]']
[Init] best rec loss: 0.8873080015182495 for ['[CLS] also space add ao intent bat intentם should huge charity family timeline rectangular whom failed list supposed boat deputyness teaches hair [SEP]']
[Init] best perm rec loss: 0.8835697174072266 for ['[CLS] ao also supposed failed bat rectangular space huge teaches deputy familyם add intentness hair boat whom intent should list timeline charity [SEP]']
[Init] best perm rec loss: 0.8818390369415283 for ['[CLS] addם list whomness charity deputy boat failed hair bat rectangular family intent ao intent timeline also huge should supposed teaches space [SEP]']
[Init] best perm rec loss: 0.8793982267379761 for ['[CLS] timeline also boat whomם aoness teaches rectangular failed intent add hair charity bat huge supposed list should space intent family deputy [SEP]']
[Init] best perm rec loss: 0.878783106803894 for ['[CLS] charity failedness deputy bat supposed space family intent should teaches intent boat huge hair add timeline whom ao rectangular list alsoם [SEP]']
[Init] best perm rec loss: 0.8784042000770569 for ['[CLS] supposed ao list intent batness also intent space teaches should deputy family failed add huge whom hair charityם boat rectangular timeline [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.629 (perp=11.815, rec=0.257, cos=0.009), tot_loss_proj:3.093 [t=0.24s]
prediction: ['[CLS] pointless decide directed owned sorting import foreigneo francois viewers french ) import accident pointless french polish twisting * european - as [SEP]']
[ 100/2000] tot_loss=2.424 (perp=11.060, rec=0.208, cos=0.005), tot_loss_proj:2.869 [t=0.24s]
prediction: ['[CLS] pointless heather direct import meaning import writer replacing anne generation english ) import - pointless french french mean import french - - [SEP]']
[ 150/2000] tot_loss=2.280 (perp=10.546, rec=0.167, cos=0.004), tot_loss_proj:2.705 [t=0.25s]
prediction: ['[CLS] pointless searching direct import meander french writer replacing anne coming age ) import - pointless writer french mean import french - - [SEP]']
[ 200/2000] tot_loss=2.028 (perp=9.461, rec=0.134, cos=0.002), tot_loss_proj:2.487 [t=0.25s]
prediction: ['[CLS] pointless thus : from meander french directormax anne coming age ) import - pointless writer french and import french - - [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.928 (perp=9.088, rec=0.109, cos=0.002), tot_loss_proj:2.433 [t=0.25s]
prediction: ['[CLS] pointless this here from meander french director - anne coming age ) import - pointless writer french and french import age - [SEP]']
[ 300/2000] tot_loss=1.990 (perp=9.485, rec=0.091, cos=0.002), tot_loss_proj:2.509 [t=0.24s]
prediction: ['[CLS] pointless this here from meander french directorrot anne coming age ) import - pointless writer - and french import age - [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.929 (perp=9.214, rec=0.085, cos=0.002), tot_loss_proj:2.466 [t=0.25s]
prediction: ['[CLS] pointless this here from meander french directorrot anne coming age ) - pointless writer - and of import import age - [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.823 (perp=8.672, rec=0.087, cos=0.002), tot_loss_proj:2.325 [t=0.24s]
prediction: ['[CLS] pointless this age from meander french directorrot anne coming age ) - pointless writer - and of import import - - [SEP]']
[ 450/2000] tot_loss=1.763 (perp=8.441, rec=0.073, cos=0.002), tot_loss_proj:2.297 [t=0.25s]
prediction: ['[CLS] pointless this age from meander french directorrot anne coming age ) - pointless writer - and of importing - - [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.677 (perp=7.944, rec=0.087, cos=0.002), tot_loss_proj:2.187 [t=0.25s]
prediction: ['[CLS] of this age from meander french directorrot anne coming age ) - pointless writer - and pointless importing - - [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.662 (perp=7.913, rec=0.077, cos=0.002), tot_loss_proj:2.141 [t=0.25s]
prediction: ['[CLS] of this age from meander french director - anne coming age ) - pointless writer - and pointless importingrot - [SEP]']
[ 600/2000] tot_loss=1.650 (perp=7.913, rec=0.066, cos=0.002), tot_loss_proj:2.142 [t=0.25s]
prediction: ['[CLS] of this age from meander french director - anne coming age ) - pointless writer - and pointless importingrot - [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.630 (perp=7.768, rec=0.075, cos=0.002), tot_loss_proj:2.111 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne coming french age ) - pointless writer - and pointless importingrot - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.625 (perp=7.768, rec=0.070, cos=0.002), tot_loss_proj:2.106 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne coming french age ) - pointless writer - and pointless importingrot - [SEP]']
[ 750/2000] tot_loss=1.618 (perp=7.768, rec=0.063, cos=0.002), tot_loss_proj:2.113 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne coming french age ) - pointless writer - and pointless importingrot - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.629 (perp=7.768, rec=0.073, cos=0.002), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne coming french age ) - pointless writer - and pointless importingrot - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.630 (perp=7.768, rec=0.075, cos=0.002), tot_loss_proj:2.109 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne coming french age ) - pointless writer - and pointless importingrot - [SEP]']
[ 900/2000] tot_loss=1.627 (perp=7.768, rec=0.072, cos=0.002), tot_loss_proj:2.109 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne coming french age ) - pointless writer - and pointless importingrot - [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.617 (perp=7.732, rec=0.069, cos=0.002), tot_loss_proj:2.105 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming age ) - pointless writer - and pointless importingrot - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.620 (perp=7.732, rec=0.072, cos=0.002), tot_loss_proj:2.107 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming age ) - pointless writer - and pointless importingrot - [SEP]']
[1050/2000] tot_loss=1.615 (perp=7.732, rec=0.067, cos=0.002), tot_loss_proj:2.109 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming age ) - pointless writer - and pointless importingrot - [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.588 (perp=7.605, rec=0.065, cos=0.002), tot_loss_proj:2.093 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
Attempt swap
[1150/2000] tot_loss=1.594 (perp=7.605, rec=0.071, cos=0.002), tot_loss_proj:2.093 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
[1200/2000] tot_loss=1.585 (perp=7.605, rec=0.062, cos=0.002), tot_loss_proj:2.092 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
Attempt swap
[1250/2000] tot_loss=1.592 (perp=7.605, rec=0.070, cos=0.002), tot_loss_proj:2.094 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
Attempt swap
[1300/2000] tot_loss=1.596 (perp=7.605, rec=0.073, cos=0.002), tot_loss_proj:2.097 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
[1350/2000] tot_loss=1.771 (perp=8.487, rec=0.072, cos=0.002), tot_loss_proj:2.268 [t=0.25s]
prediction: ['[CLS] of this age from meander director bi anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
Attempt swap
[1400/2000] tot_loss=1.769 (perp=8.487, rec=0.070, cos=0.002), tot_loss_proj:2.272 [t=0.25s]
prediction: ['[CLS] of this age from meander director bi anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
Attempt swap
[1450/2000] tot_loss=1.779 (perp=8.487, rec=0.080, cos=0.002), tot_loss_proj:2.272 [t=0.25s]
prediction: ['[CLS] of this age from meander director bi anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
[1500/2000] tot_loss=1.774 (perp=8.487, rec=0.076, cos=0.002), tot_loss_proj:2.269 [t=0.25s]
prediction: ['[CLS] of this age from meander director bi anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
Attempt swap
[1550/2000] tot_loss=1.767 (perp=8.487, rec=0.068, cos=0.002), tot_loss_proj:2.274 [t=0.25s]
prediction: ['[CLS] of this age from meander director bi anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
Attempt swap
[1600/2000] tot_loss=1.770 (perp=8.487, rec=0.071, cos=0.002), tot_loss_proj:2.270 [t=0.25s]
prediction: ['[CLS] of this age from meander director bi anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
[1650/2000] tot_loss=1.772 (perp=8.487, rec=0.073, cos=0.002), tot_loss_proj:2.272 [t=0.25s]
prediction: ['[CLS] of this age from meander director bi anne french coming age ) - pointless writer - and pointless importing -rot [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.718 (perp=8.245, rec=0.068, cos=0.002), tot_loss_proj:2.206 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming age ) bi pointless writer - and pointless importing -rot [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.699 (perp=8.175, rec=0.063, cos=0.002), tot_loss_proj:2.216 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming pointless ) bi pointless writer - and age importing -rot [SEP]']
[1800/2000] tot_loss=1.716 (perp=8.175, rec=0.079, cos=0.002), tot_loss_proj:2.222 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming pointless ) bi pointless writer - and age importing -rot [SEP]']
Attempt swap
[1850/2000] tot_loss=1.707 (perp=8.175, rec=0.070, cos=0.002), tot_loss_proj:2.211 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming pointless ) bi pointless writer - and age importing -rot [SEP]']
Attempt swap
[1900/2000] tot_loss=1.706 (perp=8.175, rec=0.069, cos=0.002), tot_loss_proj:2.219 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming pointless ) bi pointless writer - and age importing -rot [SEP]']
[1950/2000] tot_loss=1.705 (perp=8.175, rec=0.068, cos=0.002), tot_loss_proj:2.221 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming pointless ) bi pointless writer - and age importing -rot [SEP]']
Attempt swap
[2000/2000] tot_loss=1.702 (perp=8.175, rec=0.066, cos=0.002), tot_loss_proj:2.222 [t=0.25s]
prediction: ['[CLS] of this age from meander director - anne french coming pointless ) bi pointless writer - and age importing -rot [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] of this age from meander director - anne french coming pointless ) bi pointless writer - and age importing -rot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.222 | p: 68.421 | r: 76.471
rouge2     | fm: 11.765 | p: 11.111 | r: 12.500
rougeL     | fm: 38.889 | p: 36.842 | r: 41.176
rougeLsum  | fm: 38.889 | p: 36.842 | r: 41.176
r1fm+r2fm = 83.987

[Aggregate metrics]:
rouge1     | fm: 91.278 | p: 90.858 | r: 91.754
rouge2     | fm: 57.693 | p: 57.437 | r: 57.961
rougeL     | fm: 78.803 | p: 78.472 | r: 79.279
rougeLsum  | fm: 78.378 | p: 78.095 | r: 78.818
r1fm+r2fm = 148.972

input #26 time: 0:09:48 | total time: 4:17:30


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.9993448911552003
highest_index [0]
highest [0.9993448911552003]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9619437456130981 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.935196042060852 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9044073820114136 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.85403972864151 for ['[CLS] landing imposed distant [SEP]']
[Init] best rec loss: 0.8062134385108948 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.8017191290855408 for ['[CLS] transitwine given [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.448 (perp=11.470, rec=0.730, cos=0.424), tot_loss_proj:3.833 [t=0.23s]
prediction: ['[CLS] carmen her included [SEP]']
[ 100/2000] tot_loss=3.217 (perp=11.241, rec=0.650, cos=0.319), tot_loss_proj:2.835 [t=0.24s]
prediction: ['[CLS] generic ancient generic [SEP]']
[ 150/2000] tot_loss=2.945 (perp=9.693, rec=0.721, cos=0.286), tot_loss_proj:2.521 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 200/2000] tot_loss=2.820 (perp=9.693, rec=0.624, cos=0.257), tot_loss_proj:2.522 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.899 (perp=9.693, rec=0.608, cos=0.352), tot_loss_proj:2.524 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 300/2000] tot_loss=2.660 (perp=9.693, rec=0.527, cos=0.194), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.927 (perp=9.508, rec=0.762, cos=0.263), tot_loss_proj:2.326 [t=0.24s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.640 (perp=9.693, rec=0.557, cos=0.144), tot_loss_proj:2.519 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 450/2000] tot_loss=2.600 (perp=9.693, rec=0.533, cos=0.128), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.469 (perp=9.508, rec=0.494, cos=0.073), tot_loss_proj:2.327 [t=0.24s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.436 (perp=9.508, rec=0.480, cos=0.055), tot_loss_proj:2.318 [t=0.22s]
prediction: ['[CLS] are generic generic [SEP]']
[ 600/2000] tot_loss=2.480 (perp=9.508, rec=0.484, cos=0.094), tot_loss_proj:2.333 [t=0.22s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.657 (perp=9.508, rec=0.477, cos=0.278), tot_loss_proj:2.327 [t=0.22s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.468 (perp=9.508, rec=0.467, cos=0.099), tot_loss_proj:2.322 [t=0.22s]
prediction: ['[CLS] are generic generic [SEP]']
[ 750/2000] tot_loss=2.823 (perp=11.080, rec=0.479, cos=0.128), tot_loss_proj:2.801 [t=0.23s]
prediction: ['[CLS] unnecessary generic generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.494 (perp=10.087, rec=0.454, cos=0.022), tot_loss_proj:2.390 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.740 (perp=11.080, rec=0.475, cos=0.049), tot_loss_proj:2.814 [t=0.22s]
prediction: ['[CLS] unnecessary generic generic [SEP]']
[ 900/2000] tot_loss=2.484 (perp=10.087, rec=0.450, cos=0.016), tot_loss_proj:2.391 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.467 (perp=10.087, rec=0.440, cos=0.010), tot_loss_proj:2.386 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1000/2000] tot_loss=2.642 (perp=10.087, rec=0.478, cos=0.147), tot_loss_proj:2.397 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
[1050/2000] tot_loss=2.485 (perp=10.087, rec=0.454, cos=0.013), tot_loss_proj:2.394 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1100/2000] tot_loss=2.469 (perp=10.087, rec=0.444, cos=0.008), tot_loss_proj:2.397 [t=0.23s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1150/2000] tot_loss=2.484 (perp=10.087, rec=0.443, cos=0.023), tot_loss_proj:2.400 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
[1200/2000] tot_loss=2.467 (perp=10.087, rec=0.439, cos=0.010), tot_loss_proj:2.395 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1250/2000] tot_loss=2.457 (perp=10.087, rec=0.436, cos=0.004), tot_loss_proj:2.392 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1300/2000] tot_loss=2.711 (perp=10.087, rec=0.467, cos=0.226), tot_loss_proj:2.391 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
[1350/2000] tot_loss=2.469 (perp=10.087, rec=0.442, cos=0.009), tot_loss_proj:2.399 [t=0.23s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1400/2000] tot_loss=2.456 (perp=10.087, rec=0.436, cos=0.002), tot_loss_proj:2.395 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1450/2000] tot_loss=2.480 (perp=10.087, rec=0.433, cos=0.030), tot_loss_proj:2.386 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
[1500/2000] tot_loss=2.455 (perp=10.087, rec=0.433, cos=0.005), tot_loss_proj:2.401 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1550/2000] tot_loss=2.458 (perp=10.087, rec=0.438, cos=0.002), tot_loss_proj:2.399 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1600/2000] tot_loss=2.571 (perp=10.087, rec=0.431, cos=0.122), tot_loss_proj:2.392 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
[1650/2000] tot_loss=2.445 (perp=10.087, rec=0.425, cos=0.002), tot_loss_proj:2.396 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1700/2000] tot_loss=2.452 (perp=10.087, rec=0.427, cos=0.007), tot_loss_proj:2.394 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.459 (perp=10.087, rec=0.429, cos=0.012), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
[1800/2000] tot_loss=2.444 (perp=10.087, rec=0.424, cos=0.002), tot_loss_proj:2.393 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1850/2000] tot_loss=2.479 (perp=10.087, rec=0.436, cos=0.026), tot_loss_proj:2.387 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1900/2000] tot_loss=2.442 (perp=10.087, rec=0.422, cos=0.003), tot_loss_proj:2.390 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
[1950/2000] tot_loss=2.450 (perp=10.087, rec=0.430, cos=0.003), tot_loss_proj:2.397 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.451 (perp=10.087, rec=0.421, cos=0.013), tot_loss_proj:2.400 [t=0.22s]
prediction: ['[CLS] so generic generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] so generic generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 90.797 | p: 90.394 | r: 91.292
rouge2     | fm: 57.193 | p: 56.988 | r: 57.480
rougeL     | fm: 78.838 | p: 78.523 | r: 79.320
rougeLsum  | fm: 78.397 | p: 78.068 | r: 78.851
r1fm+r2fm = 147.990

input #27 time: 0:09:05 | total time: 4:26:36


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.9993341797945816
highest_index [0]
highest [0.9993341797945816]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8130366802215576 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.7981401681900024 for ['[CLS] guests mackenzie voyager reader [SEP]']
[Init] best rec loss: 0.7943398356437683 for ['[CLS] stations finchyte planned [SEP]']
[Init] best rec loss: 0.7936493754386902 for ['[CLS]ness aluminium cleveland tv [SEP]']
[Init] best rec loss: 0.782181978225708 for ['[CLS] james facilitieslty ¨ [SEP]']
[Init] best rec loss: 0.7480621337890625 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best perm rec loss: 0.7475418448448181 for ['[CLS] mixed battlefield fullyuro [SEP]']
[Init] best perm rec loss: 0.7444020509719849 for ['[CLS] fullyuro battlefield mixed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.195 (perp=9.617, rec=0.249, cos=0.022), tot_loss_proj:2.757 [t=0.22s]
prediction: ['[CLS] for i days minutes [SEP]']
[ 100/2000] tot_loss=1.903 (perp=8.884, rec=0.118, cos=0.008), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS] for 71 minutes minutes [SEP]']
[ 150/2000] tot_loss=1.565 (perp=7.445, rec=0.074, cos=0.002), tot_loss_proj:1.833 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 200/2000] tot_loss=1.555 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.847 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.560 (perp=7.445, rec=0.070, cos=0.001), tot_loss_proj:1.835 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 300/2000] tot_loss=1.558 (perp=7.445, rec=0.067, cos=0.002), tot_loss_proj:1.844 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.553 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.850 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.562 (perp=7.445, rec=0.072, cos=0.001), tot_loss_proj:1.844 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=1.558 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.840 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.550 (perp=7.445, rec=0.060, cos=0.001), tot_loss_proj:1.835 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.843 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=1.546 (perp=7.445, rec=0.056, cos=0.001), tot_loss_proj:1.838 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.564 (perp=7.445, rec=0.074, cos=0.001), tot_loss_proj:1.840 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.846 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=1.559 (perp=7.445, rec=0.069, cos=0.001), tot_loss_proj:1.847 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.553 (perp=7.445, rec=0.062, cos=0.001), tot_loss_proj:1.837 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.554 (perp=7.445, rec=0.064, cos=0.001), tot_loss_proj:1.848 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=1.546 (perp=7.445, rec=0.056, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.557 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.837 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=1.551 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.840 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=1.555 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.841 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=1.543 (perp=7.445, rec=0.053, cos=0.001), tot_loss_proj:1.836 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=1.548 (perp=7.445, rec=0.058, cos=0.001), tot_loss_proj:1.842 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=1.547 (perp=7.445, rec=0.057, cos=0.001), tot_loss_proj:1.842 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=1.557 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.843 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=1.555 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.848 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.841 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=1.552 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.829 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=1.548 (perp=7.445, rec=0.057, cos=0.001), tot_loss_proj:1.835 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.834 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=1.560 (perp=7.445, rec=0.070, cos=0.001), tot_loss_proj:1.833 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=1.553 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.844 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=1.545 (perp=7.445, rec=0.055, cos=0.001), tot_loss_proj:1.833 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=1.553 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.845 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=1.545 (perp=7.445, rec=0.054, cos=0.001), tot_loss_proj:1.831 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=1.543 (perp=7.445, rec=0.053, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=1.552 (perp=7.445, rec=0.062, cos=0.001), tot_loss_proj:1.843 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=1.561 (perp=7.445, rec=0.070, cos=0.001), tot_loss_proj:1.836 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=1.543 (perp=7.445, rec=0.053, cos=0.001), tot_loss_proj:1.836 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 91.153 | p: 90.726 | r: 91.655
rouge2     | fm: 56.599 | p: 56.389 | r: 56.943
rougeL     | fm: 78.998 | p: 78.660 | r: 79.422
rougeLsum  | fm: 78.690 | p: 78.352 | r: 79.129
r1fm+r2fm = 147.752

input #28 time: 0:09:32 | total time: 4:36:08


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9992957407854928
highest_index [0]
highest [0.9992957407854928]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.947530210018158 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.9259920120239258 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.9125291109085083 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.8549603223800659 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8497192859649658 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 0.8459416627883911 for ['[CLS] lordship buckingham rather postsbor we home wildlife valleygan [SEP]']
[Init] best rec loss: 0.845466136932373 for ['[CLS] crystal shock completion carrydable stay recordingdrive ella off [SEP]']
[Init] best rec loss: 0.8421328067779541 for ['[CLS] downke his heir wantedø degree opposition march head [SEP]']
[Init] best rec loss: 0.8202964663505554 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 0.8111938834190369 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best perm rec loss: 0.8096943497657776 for ['[CLS] transmit f veto u cells axlefounded meters mostly bu [SEP]']
[Init] best perm rec loss: 0.8091574907302856 for ['[CLS] cells meters axle bu mostly u transmit f vetofounded [SEP]']
[Init] best perm rec loss: 0.8048059940338135 for ['[CLS] veto transmit f cells axle mostlyfounded meters u bu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.069 (perp=13.319, rec=0.371, cos=0.034), tot_loss_proj:3.932 [t=0.23s]
prediction: ['[CLS]unce video shoved fiona ignorance leader thin introduced destroy scuba [SEP]']
[ 100/2000] tot_loss=2.458 (perp=10.797, rec=0.284, cos=0.015), tot_loss_proj:3.312 [t=0.24s]
prediction: ['[CLS] they its believe fiona disbelief believe. believe not. [SEP]']
[ 150/2000] tot_loss=2.560 (perp=11.538, rec=0.233, cos=0.019), tot_loss_proj:3.672 [t=0.24s]
prediction: ['[CLS] idown believe fiona disbelief believe. believe not resident [SEP]']
[ 200/2000] tot_loss=2.036 (perp=9.184, rec=0.188, cos=0.011), tot_loss_proj:2.817 [t=0.24s]
prediction: ['[CLS] idown i fiona also believe. is not resident [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.881 (perp=8.342, rec=0.197, cos=0.016), tot_loss_proj:3.209 [t=0.24s]
prediction: ['[CLS] i believe i fiona also edition. it not resident [SEP]']
[ 300/2000] tot_loss=1.861 (perp=8.503, rec=0.153, cos=0.007), tot_loss_proj:3.474 [t=0.24s]
prediction: ['[CLS] i believe i fiona also peace is it not resident [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.859 (perp=8.564, rec=0.141, cos=0.005), tot_loss_proj:3.530 [t=0.24s]
prediction: ['[CLS] i believe i also we peace is it not resident [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.630 (perp=7.478, rec=0.130, cos=0.005), tot_loss_proj:3.062 [t=0.24s]
prediction: ['[CLS] i believe that i also flap is it not resident [SEP]']
[ 450/2000] tot_loss=1.608 (perp=7.478, rec=0.108, cos=0.004), tot_loss_proj:3.071 [t=0.24s]
prediction: ['[CLS] i believe that i also flap is it not resident [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.614 (perp=7.478, rec=0.114, cos=0.004), tot_loss_proj:3.073 [t=0.24s]
prediction: ['[CLS] i believe that i also flap is it not resident [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.604 (perp=7.478, rec=0.106, cos=0.003), tot_loss_proj:3.074 [t=0.24s]
prediction: ['[CLS] i believe that i also flap is it not resident [SEP]']
[ 600/2000] tot_loss=1.417 (perp=6.584, rec=0.098, cos=0.003), tot_loss_proj:2.565 [t=0.24s]
prediction: ['[CLS] i believe that evil also evil is it not resident [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.382 (perp=6.431, rec=0.093, cos=0.003), tot_loss_proj:2.187 [t=0.24s]
prediction: ['[CLS] i believe that evil also evil is not it resident [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.272 (perp=5.804, rec=0.108, cos=0.003), tot_loss_proj:1.625 [t=0.24s]
prediction: ['[CLS] i believe that resident evil also evil is not it [SEP]']
[ 750/2000] tot_loss=1.260 (perp=5.804, rec=0.096, cos=0.003), tot_loss_proj:1.625 [t=0.24s]
prediction: ['[CLS] i believe that resident evil also evil is not it [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.363 (perp=6.293, rec=0.101, cos=0.003), tot_loss_proj:2.382 [t=0.24s]
prediction: ['[CLS] i believe that resident evil also is not it secretly [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.191 (perp=5.467, rec=0.094, cos=0.003), tot_loss_proj:2.393 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[ 900/2000] tot_loss=1.181 (perp=5.467, rec=0.085, cos=0.003), tot_loss_proj:2.392 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.174 (perp=5.467, rec=0.077, cos=0.003), tot_loss_proj:2.391 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1000/2000] tot_loss=1.175 (perp=5.467, rec=0.079, cos=0.003), tot_loss_proj:2.395 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[1050/2000] tot_loss=1.181 (perp=5.467, rec=0.085, cos=0.003), tot_loss_proj:2.388 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1100/2000] tot_loss=1.174 (perp=5.467, rec=0.078, cos=0.003), tot_loss_proj:2.389 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
Attempt swap
[1150/2000] tot_loss=1.177 (perp=5.467, rec=0.081, cos=0.003), tot_loss_proj:2.390 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it not [SEP]']
[1200/2000] tot_loss=1.061 (perp=4.901, rec=0.078, cos=0.003), tot_loss_proj:1.397 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it! [SEP]']
Attempt swap
[1250/2000] tot_loss=1.068 (perp=4.901, rec=0.085, cos=0.003), tot_loss_proj:1.394 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it! [SEP]']
Attempt swap
[1300/2000] tot_loss=1.057 (perp=4.901, rec=0.074, cos=0.003), tot_loss_proj:1.392 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it! [SEP]']
[1350/2000] tot_loss=0.987 (perp=4.571, rec=0.070, cos=0.003), tot_loss_proj:1.070 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.995 (perp=4.571, rec=0.078, cos=0.003), tot_loss_proj:1.067 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.995 (perp=4.571, rec=0.078, cos=0.003), tot_loss_proj:1.073 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1500/2000] tot_loss=0.986 (perp=4.571, rec=0.069, cos=0.003), tot_loss_proj:1.069 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.999 (perp=4.571, rec=0.082, cos=0.003), tot_loss_proj:1.066 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.988 (perp=4.571, rec=0.071, cos=0.003), tot_loss_proj:1.071 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1650/2000] tot_loss=0.988 (perp=4.571, rec=0.072, cos=0.003), tot_loss_proj:1.072 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.000 (perp=4.571, rec=0.083, cos=0.003), tot_loss_proj:1.062 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.994 (perp=4.571, rec=0.078, cos=0.003), tot_loss_proj:1.063 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1800/2000] tot_loss=0.987 (perp=4.571, rec=0.070, cos=0.002), tot_loss_proj:1.058 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.995 (perp=4.571, rec=0.079, cos=0.002), tot_loss_proj:1.064 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.992 (perp=4.571, rec=0.076, cos=0.002), tot_loss_proj:1.061 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1950/2000] tot_loss=1.001 (perp=4.571, rec=0.084, cos=0.002), tot_loss_proj:1.064 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.998 (perp=4.571, rec=0.082, cos=0.002), tot_loss_proj:1.063 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.295 | p: 91.034 | r: 91.783
rouge2     | fm: 58.174 | p: 57.962 | r: 58.399
rougeL     | fm: 79.653 | p: 79.285 | r: 80.067
rougeLsum  | fm: 79.323 | p: 78.923 | r: 79.781
r1fm+r2fm = 149.469

input #29 time: 0:09:26 | total time: 4:45:35


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.9992726237091217
highest_index [0]
highest [0.9992726237091217]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.915320873260498 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8711962103843689 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.8100265264511108 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7817462682723999 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7791784405708313 for ['[CLS] footading night [SEP]']
[Init] best rec loss: 0.7326138615608215 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.7145380973815918 for ['[CLS] acceleration council lizard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.872 (perp=12.949, rec=0.270, cos=0.012), tot_loss_proj:3.692 [t=0.23s]
prediction: ['[CLS]zzability fi [SEP]']
[ 100/2000] tot_loss=2.751 (perp=12.949, rec=0.156, cos=0.005), tot_loss_proj:3.703 [t=0.23s]
prediction: ['[CLS]zzability fi [SEP]']
[ 150/2000] tot_loss=2.677 (perp=12.949, rec=0.084, cos=0.003), tot_loss_proj:3.704 [t=0.24s]
prediction: ['[CLS]zzability fi [SEP]']
[ 200/2000] tot_loss=2.692 (perp=12.949, rec=0.098, cos=0.004), tot_loss_proj:3.704 [t=0.24s]
prediction: ['[CLS]zzability fi [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.999 (perp=9.539, rec=0.087, cos=0.005), tot_loss_proj:1.966 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.972 (perp=9.539, rec=0.062, cos=0.002), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.982 (perp=9.539, rec=0.071, cos=0.003), tot_loss_proj:1.958 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.971 (perp=9.539, rec=0.062, cos=0.002), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.960 (perp=9.539, rec=0.051, cos=0.002), tot_loss_proj:1.975 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.968 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.979 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.957 (perp=9.539, rec=0.047, cos=0.001), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.974 (perp=9.539, rec=0.065, cos=0.001), tot_loss_proj:1.955 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.977 (perp=9.539, rec=0.068, cos=0.001), tot_loss_proj:1.970 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.955 (perp=9.539, rec=0.046, cos=0.001), tot_loss_proj:1.977 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.975 (perp=9.539, rec=0.066, cos=0.001), tot_loss_proj:1.976 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.966 (perp=9.539, rec=0.057, cos=0.001), tot_loss_proj:1.966 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.963 (perp=9.539, rec=0.054, cos=0.001), tot_loss_proj:1.975 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.970 (perp=9.539, rec=0.060, cos=0.001), tot_loss_proj:1.976 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.967 (perp=9.539, rec=0.058, cos=0.001), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.972 (perp=9.539, rec=0.063, cos=0.001), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.961 (perp=9.539, rec=0.052, cos=0.001), tot_loss_proj:1.964 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.970 (perp=9.539, rec=0.060, cos=0.001), tot_loss_proj:1.977 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.970 (perp=9.539, rec=0.060, cos=0.001), tot_loss_proj:1.966 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.974 (perp=9.539, rec=0.065, cos=0.001), tot_loss_proj:1.981 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.970 (perp=9.539, rec=0.060, cos=0.001), tot_loss_proj:1.976 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.960 (perp=9.539, rec=0.051, cos=0.001), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.986 (perp=9.539, rec=0.076, cos=0.001), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.963 (perp=9.539, rec=0.054, cos=0.001), tot_loss_proj:1.979 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.967 (perp=9.539, rec=0.057, cos=0.001), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.965 (perp=9.539, rec=0.056, cos=0.001), tot_loss_proj:1.976 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.971 (perp=9.539, rec=0.062, cos=0.001), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.978 (perp=9.539, rec=0.069, cos=0.001), tot_loss_proj:1.981 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.977 (perp=9.539, rec=0.068, cos=0.001), tot_loss_proj:1.965 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.964 (perp=9.539, rec=0.055, cos=0.001), tot_loss_proj:1.981 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.968 (perp=9.539, rec=0.058, cos=0.001), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.968 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.977 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.975 (perp=9.539, rec=0.066, cos=0.001), tot_loss_proj:1.978 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.961 (perp=9.539, rec=0.051, cos=0.001), tot_loss_proj:1.987 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.973 (perp=9.539, rec=0.064, cos=0.001), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.958 (perp=9.539, rec=0.049, cos=0.001), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.722 | p: 91.394 | r: 92.131
rouge2     | fm: 59.624 | p: 59.481 | r: 59.929
rougeL     | fm: 80.185 | p: 79.941 | r: 80.585
rougeLsum  | fm: 79.944 | p: 79.595 | r: 80.395
r1fm+r2fm = 151.346

input #30 time: 0:09:32 | total time: 4:55:07


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9993397445870693
highest_index [0]
highest [0.9993397445870693]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9391812086105347 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.9200879335403442 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8856512308120728 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.8632071614265442 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.8012497425079346 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 0.8010070323944092 for ['[CLS] robin artwork running [SEP]']
[Init] best perm rec loss: 0.7970992922782898 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.233 (perp=9.604, rec=0.282, cos=0.030), tot_loss_proj:2.402 [t=0.24s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 100/2000] tot_loss=2.100 (perp=9.604, rec=0.164, cos=0.016), tot_loss_proj:2.378 [t=0.24s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 150/2000] tot_loss=2.075 (perp=9.604, rec=0.139, cos=0.015), tot_loss_proj:2.377 [t=0.24s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 200/2000] tot_loss=1.845 (perp=8.742, rec=0.094, cos=0.003), tot_loss_proj:3.265 [t=0.24s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.002), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.595 (perp=7.603, rec=0.073, cos=0.002), tot_loss_proj:1.693 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.594 (perp=7.603, rec=0.072, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.586 (perp=7.603, rec=0.063, cos=0.002), tot_loss_proj:1.664 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.579 (perp=7.603, rec=0.058, cos=0.001), tot_loss_proj:1.686 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.590 (perp=7.603, rec=0.068, cos=0.001), tot_loss_proj:1.665 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.672 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.584 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.576 (perp=7.603, rec=0.054, cos=0.001), tot_loss_proj:1.682 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.591 (perp=7.603, rec=0.070, cos=0.001), tot_loss_proj:1.675 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.672 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.670 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.576 (perp=7.603, rec=0.054, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.686 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.595 (perp=7.603, rec=0.073, cos=0.001), tot_loss_proj:1.677 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.682 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.581 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.666 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.678 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.671 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.574 (perp=7.603, rec=0.052, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.574 (perp=7.603, rec=0.052, cos=0.001), tot_loss_proj:1.674 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.677 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.578 (perp=7.603, rec=0.056, cos=0.001), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.669 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.582 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.674 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.670 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.678 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.581 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.682 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.590 (perp=7.603, rec=0.068, cos=0.001), tot_loss_proj:1.673 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.571 (perp=7.603, rec=0.050, cos=0.001), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.678 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.985 | p: 91.615 | r: 92.404
rouge2     | fm: 61.131 | p: 60.936 | r: 61.374
rougeL     | fm: 80.921 | p: 80.633 | r: 81.322
rougeLsum  | fm: 80.621 | p: 80.376 | r: 80.995
r1fm+r2fm = 153.116

input #31 time: 0:09:36 | total time: 5:04:43


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9992524215190559
highest_index [0]
highest [0.9992524215190559]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.0390509366989136 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9474079608917236 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 0.8893988728523254 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.8806267380714417 for ['[CLS] shot scale nest benefit jenny aspen introduced everything zoe arrival capital theory [SEP]']
[Init] best rec loss: 0.8802824020385742 for ['[CLS] spiders armenian dreams¨ me riff clearly space cyprus center ᵍ glory [SEP]']
[Init] best rec loss: 0.8597884774208069 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.8490630984306335 for ['[CLS]ono harlem auckland hanna organization rex force riot back decker mud tune [SEP]']
[Init] best rec loss: 0.8473441004753113 for ['[CLS]erated doc tax 2009 citizens completely fa outreach {zic spot 2 [SEP]']
[Init] best perm rec loss: 0.8473353981971741 for ['[CLS] taxerated 2009zic doc fa spot outreach completely citizens { 2 [SEP]']
[Init] best perm rec loss: 0.8460664749145508 for ['[CLS] { citizens tax doc 2009erated fa outreachzic spot 2 completely [SEP]']
[Init] best perm rec loss: 0.8459265828132629 for ['[CLS] 2009 citizens fa doc { 2 completelyzicerated tax spot outreach [SEP]']
[Init] best perm rec loss: 0.8454993963241577 for ['[CLS]erated doc spot citizens completely outreach fazic tax 2 2009 { [SEP]']
[Init] best perm rec loss: 0.8453917503356934 for ['[CLS] completely citizenserated { fa 2009 spot 2 doc tax outreachzic [SEP]']
[Init] best perm rec loss: 0.8444403409957886 for ['[CLS]zic completely { tax 2009erated doc outreach fa spot 2 citizens [SEP]']
[Init] best perm rec loss: 0.8436647057533264 for ['[CLS] 2009 tax 2 outreach doc completely spotzic { faerated citizens [SEP]']
[Init] best perm rec loss: 0.8428959250450134 for ['[CLS] fa { 2009zic 2 outreach spot doc completely tax citizenserated [SEP]']
[Init] best perm rec loss: 0.842507541179657 for ['[CLS] {zic spot 2009 citizens outreach completely 2 fa doc taxerated [SEP]']
[Init] best perm rec loss: 0.8423187732696533 for ['[CLS] 2009 outreach citizens tax { completely 2 doc spot faeratedzic [SEP]']
[Init] best perm rec loss: 0.8402031660079956 for ['[CLS] citizens doc 2009 spot completely { outreach 2erated fazic tax [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.900 (perp=13.103, rec=0.274, cos=0.006), tot_loss_proj:3.779 [t=0.24s]
prediction: ['[CLS] dedicated effective experienced placesonate easily about offer ; artisticologicalible [SEP]']
[ 100/2000] tot_loss=2.715 (perp=12.601, rec=0.193, cos=0.002), tot_loss_proj:3.789 [t=0.24s]
prediction: ['[CLS] accessible accessible experienced storiesonate resress pull res withonate accessible [SEP]']
[ 150/2000] tot_loss=2.713 (perp=12.748, rec=0.161, cos=0.002), tot_loss_proj:3.877 [t=0.24s]
prediction: ['[CLS] easily easily around storiesonate resity pull res withuded accessible [SEP]']
[ 200/2000] tot_loss=2.764 (perp=13.182, rec=0.126, cos=0.002), tot_loss_proj:4.101 [t=0.24s]
prediction: ['[CLS] easily together around storiesonate resity pull res thatund accessible [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.437 (perp=11.674, rec=0.100, cos=0.002), tot_loss_proj:3.218 [t=0.24s]
prediction: ['[CLS] easily together around resonate resity pull stories thatund accessible [SEP]']
[ 300/2000] tot_loss=2.417 (perp=11.560, rec=0.103, cos=0.002), tot_loss_proj:3.252 [t=0.24s]
prediction: ['[CLS] easily together mostly resonate resity pull stories thatund accessible [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.221 (perp=10.624, rec=0.094, cos=0.002), tot_loss_proj:3.499 [t=0.24s]
prediction: ['[CLS] easily together mostly resonate resity stories that pullund accessible [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.110 (perp=10.014, rec=0.106, cos=0.002), tot_loss_proj:3.069 [t=0.24s]
prediction: ['[CLS] pull together mostly resonate resity stories that easilyund accessible [SEP]']
[ 450/2000] tot_loss=2.091 (perp=10.014, rec=0.087, cos=0.002), tot_loss_proj:3.066 [t=0.24s]
prediction: ['[CLS] pull together mostly resonate resity stories that easilyund accessible [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.030 (perp=9.738, rec=0.081, cos=0.002), tot_loss_proj:2.791 [t=0.24s]
prediction: ['[CLS] pull together animals resonate resityund stories that easily accessible [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.796 (perp=8.437, rec=0.106, cos=0.002), tot_loss_proj:2.638 [t=0.24s]
prediction: ['[CLS] pull together mostly resonate resundity stories that easily accessible [SEP]']
[ 600/2000] tot_loss=1.776 (perp=8.437, rec=0.087, cos=0.002), tot_loss_proj:2.630 [t=0.24s]
prediction: ['[CLS] pull together mostly resonate resundity stories that easily accessible [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.900 (perp=9.080, rec=0.083, cos=0.002), tot_loss_proj:2.457 [t=0.24s]
prediction: ['[CLS] pull together sensation resonate resundity stories that easily accessible [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.979 (perp=9.431, rec=0.091, cos=0.002), tot_loss_proj:2.753 [t=0.24s]
prediction: ['[CLS] pull together sensation prof resonateundity stories that easily accessible [SEP]']
[ 750/2000] tot_loss=1.963 (perp=9.431, rec=0.075, cos=0.002), tot_loss_proj:2.756 [t=0.24s]
prediction: ['[CLS] pull together sensation prof resonateundity stories that easily accessible [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.823 (perp=8.693, rec=0.083, cos=0.002), tot_loss_proj:2.429 [t=0.24s]
prediction: ['[CLS] pull together resonate animals profundity stories that easily accessible [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.596 (perp=7.586, rec=0.077, cos=0.002), tot_loss_proj:2.124 [t=0.24s]
prediction: ['[CLS] pull together animals resonate profundity stories that easily accessible [SEP]']
[ 900/2000] tot_loss=1.680 (perp=7.960, rec=0.086, cos=0.002), tot_loss_proj:2.188 [t=0.24s]
prediction: ['[CLS] pull together sensation resonate profundity stories that easily accessible [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.668 (perp=7.960, rec=0.075, cos=0.002), tot_loss_proj:2.175 [t=0.24s]
prediction: ['[CLS] pull together sensation resonate profundity stories that easily accessible [SEP]']
Attempt swap
[1000/2000] tot_loss=1.673 (perp=7.960, rec=0.080, cos=0.002), tot_loss_proj:2.183 [t=0.24s]
prediction: ['[CLS] pull together sensation resonate profundity stories that easily accessible [SEP]']
[1050/2000] tot_loss=1.679 (perp=7.960, rec=0.085, cos=0.002), tot_loss_proj:2.172 [t=0.24s]
prediction: ['[CLS] pull together sensation resonate profundity stories that easily accessible [SEP]']
Attempt swap
[1100/2000] tot_loss=1.668 (perp=7.960, rec=0.075, cos=0.002), tot_loss_proj:2.186 [t=0.24s]
prediction: ['[CLS] pull together sensation resonate profundity stories that easily accessible [SEP]']
Attempt swap
[1150/2000] tot_loss=1.662 (perp=7.960, rec=0.068, cos=0.002), tot_loss_proj:2.178 [t=0.24s]
prediction: ['[CLS] pull together sensation resonate profundity stories that easily accessible [SEP]']
[1200/2000] tot_loss=1.670 (perp=7.960, rec=0.077, cos=0.002), tot_loss_proj:2.176 [t=0.24s]
prediction: ['[CLS] pull together sensation resonate profundity stories that easily accessible [SEP]']
Attempt swap
[1250/2000] tot_loss=1.671 (perp=7.960, rec=0.077, cos=0.002), tot_loss_proj:2.169 [t=0.24s]
prediction: ['[CLS] pull together sensation resonate profundity stories that easily accessible [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.672 (perp=7.979, rec=0.074, cos=0.002), tot_loss_proj:2.269 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
[1350/2000] tot_loss=1.679 (perp=7.979, rec=0.082, cos=0.002), tot_loss_proj:2.278 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
Attempt swap
[1400/2000] tot_loss=1.672 (perp=7.979, rec=0.075, cos=0.002), tot_loss_proj:2.270 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
Attempt swap
[1450/2000] tot_loss=1.667 (perp=7.979, rec=0.069, cos=0.002), tot_loss_proj:2.276 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
[1500/2000] tot_loss=1.676 (perp=7.979, rec=0.079, cos=0.002), tot_loss_proj:2.279 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
Attempt swap
[1550/2000] tot_loss=1.671 (perp=7.979, rec=0.074, cos=0.002), tot_loss_proj:2.280 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
Attempt swap
[1600/2000] tot_loss=1.671 (perp=7.979, rec=0.073, cos=0.002), tot_loss_proj:2.273 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
[1650/2000] tot_loss=1.677 (perp=7.979, rec=0.080, cos=0.002), tot_loss_proj:2.278 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
Attempt swap
[1700/2000] tot_loss=1.673 (perp=7.979, rec=0.075, cos=0.002), tot_loss_proj:2.281 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
Attempt swap
[1750/2000] tot_loss=1.671 (perp=7.979, rec=0.074, cos=0.002), tot_loss_proj:2.270 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
[1800/2000] tot_loss=1.670 (perp=7.979, rec=0.073, cos=0.002), tot_loss_proj:2.274 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
Attempt swap
[1850/2000] tot_loss=1.665 (perp=7.979, rec=0.068, cos=0.002), tot_loss_proj:2.273 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
Attempt swap
[1900/2000] tot_loss=1.679 (perp=7.979, rec=0.081, cos=0.002), tot_loss_proj:2.282 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
[1950/2000] tot_loss=1.672 (perp=7.979, rec=0.075, cos=0.002), tot_loss_proj:2.273 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
Attempt swap
[2000/2000] tot_loss=1.670 (perp=7.979, rec=0.072, cos=0.002), tot_loss_proj:2.278 [t=0.24s]
prediction: ['[CLS] pull together resonate profundityation stories that easily accessible [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] pull together resonate profundityation stories that easily accessible [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 90.000 | r: 81.818
rouge2     | fm: 42.105 | p: 44.444 | r: 40.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 127.820

[Aggregate metrics]:
rouge1     | fm: 91.784 | p: 91.572 | r: 92.082
rouge2     | fm: 60.659 | p: 60.483 | r: 60.826
rougeL     | fm: 80.143 | p: 79.915 | r: 80.491
rougeLsum  | fm: 79.895 | p: 79.630 | r: 80.212
r1fm+r2fm = 152.442

input #32 time: 0:09:38 | total time: 5:14:22


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9992770423515678
highest_index [0]
highest [0.9992770423515678]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 1.0013114213943481 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9758126139640808 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.954909086227417 for ['[CLS] parent [SEP]']
[Init] best rec loss: 0.9039609432220459 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8219714164733887 for ['[CLS] attributed [SEP]']
[Init] best rec loss: 0.7999625205993652 for ['[CLS] showing [SEP]']
[Init] best rec loss: 0.7876425981521606 for ['[CLS] manifold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.416 (perp=11.231, rec=0.160, cos=0.010), tot_loss_proj:3.015 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.322 (perp=11.231, rec=0.074, cos=0.002), tot_loss_proj:2.406 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.303 (perp=11.231, rec=0.055, cos=0.002), tot_loss_proj:2.396 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.306 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.406 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.307 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.395 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.322 (perp=11.231, rec=0.074, cos=0.002), tot_loss_proj:2.407 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.403 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.319 (perp=11.231, rec=0.072, cos=0.001), tot_loss_proj:2.407 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.296 (perp=11.231, rec=0.048, cos=0.001), tot_loss_proj:2.399 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.295 (perp=11.231, rec=0.047, cos=0.001), tot_loss_proj:2.406 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.314 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.402 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.312 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.394 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.395 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.384 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.389 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.285 (perp=11.231, rec=0.037, cos=0.001), tot_loss_proj:2.405 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.399 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.408 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.306 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.405 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.292 (perp=11.231, rec=0.044, cos=0.001), tot_loss_proj:2.393 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.311 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.403 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.325 (perp=11.231, rec=0.077, cos=0.001), tot_loss_proj:2.400 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.312 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.397 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.319 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.400 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.314 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.395 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.001), tot_loss_proj:2.395 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.319 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.403 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.313 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.381 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.322 (perp=11.231, rec=0.074, cos=0.001), tot_loss_proj:2.402 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.390 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.309 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.404 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.399 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.301 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.391 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.319 (perp=11.231, rec=0.072, cos=0.001), tot_loss_proj:2.399 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.391 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.306 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.391 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.314 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.400 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.319 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.401 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.292 (perp=11.231, rec=0.045, cos=0.001), tot_loss_proj:2.397 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.989 | p: 91.721 | r: 92.255
rouge2     | fm: 61.812 | p: 61.660 | r: 61.960
rougeL     | fm: 80.831 | p: 80.638 | r: 81.081
rougeLsum  | fm: 80.432 | p: 80.252 | r: 80.723
r1fm+r2fm = 153.801

input #33 time: 0:09:30 | total time: 5:23:52


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9992090053245604
highest_index [0]
highest [0.9992090053245604]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8960171341896057 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8869714736938477 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8454265594482422 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8433679938316345 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.8128030300140381 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.812659740447998 for ['[CLS] ship founder drivers worth slight okay lissa field alongaskibe who statue [SEP]']
[Init] best perm rec loss: 0.8106471300125122 for ['[CLS] slight founder ship drivers statue along okayask lissa whoibe field worth [SEP]']
[Init] best perm rec loss: 0.8101394176483154 for ['[CLS]ibe drivers lissa okay along worth statue shipask who field slight founder [SEP]']
[Init] best perm rec loss: 0.8095391392707825 for ['[CLS] slightask statueibe who field founder worth okay along drivers lissa ship [SEP]']
[Init] best perm rec loss: 0.808542013168335 for ['[CLS] worth who drivers along ship slight founder okay lissa fieldaskibe statue [SEP]']
[Init] best perm rec loss: 0.8066660165786743 for ['[CLS] slight founder lissa whoask ship statue along drivers fieldibe okay worth [SEP]']
[Init] best perm rec loss: 0.8065962791442871 for ['[CLS] along ship drivers statueask who worth lissa field founder slightibe okay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.649 (perp=11.557, rec=0.317, cos=0.020), tot_loss_proj:3.799 [t=0.24s]
prediction: ['[CLS] the envelope viewer pope julia. steve increased urgency urgency urgency bart urgency [SEP]']
[ 100/2000] tot_loss=2.414 (perp=10.992, rec=0.209, cos=0.007), tot_loss_proj:3.611 [t=0.24s]
prediction: ['[CLS] the onto viewer john viewers. viewer take urgency urgency urgency extreme urgency [SEP]']
[ 150/2000] tot_loss=2.181 (perp=10.109, rec=0.155, cos=0.004), tot_loss_proj:3.510 [t=0.24s]
prediction: ['[CLS] build build viewer. viewer. the take urgency urgency urgency extreme urgency [SEP]']
[ 200/2000] tot_loss=2.137 (perp=10.078, rec=0.119, cos=0.003), tot_loss_proj:3.258 [t=0.25s]
prediction: ['[CLS] build build viewer. viewer and the take urgency urgency mind extreme urgency [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.999 (perp=9.438, rec=0.109, cos=0.003), tot_loss_proj:2.902 [t=0.25s]
prediction: ['[CLS] build build viewer of viewer mind and the take urgency urgency extreme urgency [SEP]']
[ 300/2000] tot_loss=1.991 (perp=9.438, rec=0.101, cos=0.003), tot_loss_proj:2.910 [t=0.24s]
prediction: ['[CLS] build build viewer of viewer mind and the take urgency urgency extreme urgency [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.833 (perp=8.658, rec=0.100, cos=0.002), tot_loss_proj:2.433 [t=0.24s]
prediction: ['[CLS] build build viewer in viewer mind and take the urgency. extreme urgency [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.698 (perp=7.891, rec=0.115, cos=0.004), tot_loss_proj:2.176 [t=0.24s]
prediction: ['[CLS] build build viewer in viewer mind and take the urgency extreme urgency. [SEP]']
[ 450/2000] tot_loss=1.661 (perp=7.891, rec=0.082, cos=0.002), tot_loss_proj:2.185 [t=0.24s]
prediction: ['[CLS] build build viewer in viewer mind and take the urgency extreme urgency. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.577 (perp=7.476, rec=0.080, cos=0.002), tot_loss_proj:2.209 [t=0.24s]
prediction: ['[CLS] build viewer build viewer in mind and take the urgency extreme urgency. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.535 (perp=7.286, rec=0.076, cos=0.002), tot_loss_proj:2.091 [t=0.25s]
prediction: ['[CLS] build build viewer in mind and take the viewer urgency extreme urgency. [SEP]']
[ 600/2000] tot_loss=1.559 (perp=7.440, rec=0.070, cos=0.002), tot_loss_proj:2.098 [t=0.24s]
prediction: ['[CLS] build build viewer in mind and take the viewer urgency extreme on. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.526 (perp=7.217, rec=0.081, cos=0.002), tot_loss_proj:2.156 [t=0.24s]
prediction: ['[CLS] build on on in mind and take the viewer urgency extreme viewer. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.480 (perp=6.999, rec=0.079, cos=0.002), tot_loss_proj:2.057 [t=0.24s]
prediction: ['[CLS] build on in mind and take the viewer on urgency extreme viewer. [SEP]']
[ 750/2000] tot_loss=1.483 (perp=6.999, rec=0.081, cos=0.002), tot_loss_proj:2.059 [t=0.24s]
prediction: ['[CLS] build on in mind and take the viewer on urgency extreme viewer. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.310 (perp=6.204, rec=0.068, cos=0.002), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] build on in mind and take the viewer on extreme viewer urgency. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.306 (perp=6.204, rec=0.064, cos=0.002), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] build on in mind and take the viewer on extreme viewer urgency. [SEP]']
[ 900/2000] tot_loss=1.310 (perp=6.204, rec=0.067, cos=0.002), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] build on in mind and take the viewer on extreme viewer urgency. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.315 (perp=6.204, rec=0.073, cos=0.002), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] build on in mind and take the viewer on extreme viewer urgency. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.317 (perp=6.204, rec=0.074, cos=0.002), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] build on in mind and take the viewer on extreme viewer urgency. [SEP]']
[1050/2000] tot_loss=1.307 (perp=6.204, rec=0.065, cos=0.002), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] build on in mind and take the viewer on extreme viewer urgency. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.271 (perp=6.044, rec=0.061, cos=0.002), tot_loss_proj:1.591 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.287 (perp=6.044, rec=0.077, cos=0.002), tot_loss_proj:1.586 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
[1200/2000] tot_loss=1.278 (perp=6.044, rec=0.067, cos=0.002), tot_loss_proj:1.588 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.273 (perp=6.044, rec=0.063, cos=0.002), tot_loss_proj:1.587 [t=0.25s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.283 (perp=6.044, rec=0.072, cos=0.002), tot_loss_proj:1.589 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
[1350/2000] tot_loss=1.280 (perp=6.044, rec=0.069, cos=0.002), tot_loss_proj:1.588 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.280 (perp=6.044, rec=0.070, cos=0.002), tot_loss_proj:1.586 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.276 (perp=6.044, rec=0.066, cos=0.002), tot_loss_proj:1.589 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
[1500/2000] tot_loss=1.274 (perp=6.044, rec=0.064, cos=0.002), tot_loss_proj:1.584 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.275 (perp=6.044, rec=0.064, cos=0.002), tot_loss_proj:1.588 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.284 (perp=6.044, rec=0.074, cos=0.002), tot_loss_proj:1.585 [t=0.25s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
[1650/2000] tot_loss=1.283 (perp=6.044, rec=0.073, cos=0.002), tot_loss_proj:1.586 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.277 (perp=6.044, rec=0.067, cos=0.002), tot_loss_proj:1.584 [t=0.25s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.275 (perp=6.044, rec=0.065, cos=0.002), tot_loss_proj:1.587 [t=0.25s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
[1800/2000] tot_loss=1.274 (perp=6.044, rec=0.063, cos=0.002), tot_loss_proj:1.584 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.271 (perp=6.044, rec=0.061, cos=0.002), tot_loss_proj:1.586 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.269 (perp=6.044, rec=0.059, cos=0.002), tot_loss_proj:1.587 [t=0.24s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
[1950/2000] tot_loss=1.270 (perp=6.044, rec=0.060, cos=0.002), tot_loss_proj:1.585 [t=0.25s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.277 (perp=6.044, rec=0.067, cos=0.002), tot_loss_proj:1.588 [t=0.23s]
prediction: ['[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] build on viewer in mind and take the viewer on extreme urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 46.154 | p: 46.154 | r: 46.154
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 131.868

[Aggregate metrics]:
rouge1     | fm: 91.862 | p: 91.625 | r: 92.246
rouge2     | fm: 61.005 | p: 60.897 | r: 61.211
rougeL     | fm: 80.611 | p: 80.387 | r: 80.909
rougeLsum  | fm: 80.314 | p: 80.100 | r: 80.514
r1fm+r2fm = 152.867

input #34 time: 0:09:39 | total time: 5:33:32


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9993270316838965
highest_index [0]
highest [0.9993270316838965]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9252316951751709 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.9247497320175171 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 0.9241513609886169 for ['[CLS] nightstand locality shall shifted pdfish migrated reason features happy statisticsbant medium singled anti but least [SEP] contemptness second mia architecture nonsense departments order deserved ا guardian [MASK] hospitaluts itsried direction soc christmas merely sodiummeral score because [SEP]']
[Init] best rec loss: 0.9187696576118469 for ['[CLS] thousand lack alternative energy fae deservevil denied field outside pages province beauty fade actsar dynamic sole one organized folk ms primary appointment devicedran part zion nightmaresdrive isabellaght intervals singer published sleeper signs lynch, somehow position flow [SEP]']
[Init] best perm rec loss: 0.9162565469741821 for ['[CLS], part isabella published lynch one denied folk sleeper beautyght ms nightmares energy province actdrive zionvil appointment fade thousand singer deservesar pages signs somehow intervals dynamic alternative primary sole device flow fae lack field position organizeddran outside [SEP]']
[Init] best perm rec loss: 0.9161269068717957 for ['[CLS] sleeper, flow intervals isabella appointmentdran singer publishedvil deserve province zionsar outside position act dynamic organized part sole beauty folk fae device primary nightmares alternative lack lynch signs field somehowght ms denied thousand fade energy pages onedrive [SEP]']
[Init] best perm rec loss: 0.9152407050132751 for ['[CLS] device zion denied ms pages primary, sleeper dynamic lynchght one intervals singerdran field alternative somehow part fae fade province isabella signsdrive lack thousandvil sole positionsar published nightmares appointment beauty flow deserve organized act folk energy outside [SEP]']
[Init] best perm rec loss: 0.9150510430335999 for ['[CLS] flow, folk act lynch signs positiondrive zion intervals outside thousand lacksar ms pages sole sleeperght appointment published organized device alternative deserve somehow beauty province singer dynamic faevil fade primary one denieddran nightmares part isabella field energy [SEP]']
[Init] best perm rec loss: 0.9148762822151184 for ['[CLS] field, provincedran sole act outside one flow primary zion dynamicght organized isabella fae fade alternative published part energy lack folk thousand mssar intervals signs singer pages denied beauty nightmares sleeper somehowvil position lynch deserve appointment devicedrive [SEP]']
[Init] best perm rec loss: 0.9113529920578003 for ['[CLS] dynamic zion deserve sole sleeper primary act singer isabellasar flow energy appointment pages onedran outside nightmares lack somehow alternative, field position fade province denied signs organizeddrivevil ms intervalsght part lynch fae published thousand device folk beauty [SEP]']
[Init] best perm rec loss: 0.9103208780288696 for ['[CLS] ziondrive pages published, deserve denied outside partdran fade lynch folk alternativevil somehow field signs isabella appointment province position intervals sleeper lack thousand sole beauty ms dynamic one nightmares act flow singer energysar organized faeght device primary [SEP]']
[Init] best perm rec loss: 0.9080803394317627 for ['[CLS]ght one part signsdrivevil provincesar published alternative, primary folk fae flow zion fade deserve device ms organized appointment nightmares sleeper energy field lack position dynamic act pages beauty sole intervals lynch outside isabella somehow thousand denied singerdran [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.562 (perp=10.944, rec=0.364, cos=0.009), tot_loss_proj:3.118 [t=0.24s]
prediction: ['[CLS] [SEP]ª roleicsnation particular the elaine their (, further part festival new martin few network institute of special nicholas amazing with care continuedresh command. the aggressive / life 1980s to wave history unique and super to mccartney [SEP]']
[ 100/2000] tot_loss=2.634 (perp=11.437, rec=0.338, cos=0.008), tot_loss_proj:4.169 [t=0.24s]
prediction: ["[CLS]'didn who testamentnation but the mother the ', younger part past through hardly friend network musicpe great le has makes care continues great assistant... the of of western 1980s lightning onto amateur pharmaceutical we special to evil [SEP]"]
[ 150/2000] tot_loss=2.395 (perp=10.445, rec=0.301, cos=0.006), tot_loss_proj:3.371 [t=0.26s]
prediction: ['[CLS] qualifying pastor of testamentnation but has spirit the \', began - before " galen millions the!ed great stephen adventure makes care makes great help here the outstanding the introduced 1970s to from local [SEP]g russian of guide [SEP]']
[ 200/2000] tot_loss=2.489 (perp=11.214, rec=0.243, cos=0.003), tot_loss_proj:3.845 [t=0.25s]
prediction: ['[CLS]\'nodded of varietynation but ve theme the \', began of before " director father zone temple\'great\'latest makes care makes great help latestened what the through younger reinnation individual [SEP] they rayon to we [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=4.478 (perp=13.001, rec=0.879, cos=0.998), tot_loss_proj:4.244 [t=0.25s]
prediction: ["[CLS],ya a [SEP] [SEP] but ve warmth boundary [SEP]. kincaid quite before'gabe kade [SEP] [SEP] legal good 3 maybe icao care made the [SEP] this immigration gmina koppen ferrari [SEP] [SEP]iente [SEP] [SEP] [SEP] [SEP] [SEP] 1 [SEP]"]
[ 300/2000] tot_loss=4.269 (perp=12.646, rec=0.755, cos=0.985), tot_loss_proj:4.464 [t=0.25s]
prediction: ['[CLS],ya. [SEP] [SEP] [SEP] we warmth overheard [SEP].cat quite before before less kade [SEP] [SEP] [SEP] things 3 probably this care. the rank thishal lord koppen horses [SEP] [SEP]tung [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.548 (perp=12.109, rec=0.829, cos=0.297), tot_loss_proj:4.207 [t=0.25s]
prediction: ['[CLS],ys. [SEP] [SEP] [SEP] we awesometled [SEP]. ¨ quite before before less kade legal [SEP] [SEP]lais [CLS] 3 sure a care.wl position this got this awesome [SEP] [SEP] thor [SEP] [SEP] [SEP] [SEP] [SEP] 1 [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.919 (perp=11.539, rec=0.572, cos=0.040), tot_loss_proj:4.210 [t=0.25s]
prediction: ['[CLS],icate. [SEP] formed [SEP] looked awetled [SEP] : leaf has [SEP] " less aidan dutch [SEP] [SEP] converting eyes the vampires better and [SEP] mountain good this got was yeah are [SEP] super [SEP] [SEP] before [SEP] [SEP] step [SEP]']
[ 450/2000] tot_loss=2.832 (perp=11.604, rec=0.485, cos=0.026), tot_loss_proj:4.128 [t=0.25s]
prediction: ['[CLS],tative. [SEP] → [SEP] looked awetled [SEP] : leaf has [SEP] " less aidan dutch [SEP] [SEP] sent eyes dam vampires got and [SEP] mountain beautiful this got when great are [SEP] madagascar [SEP] [SEP] before [SEP] [SEP] step [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.761 (perp=11.477, rec=0.447, cos=0.018), tot_loss_proj:4.236 [t=0.25s]
prediction: ['[CLS] andtative. [SEP] → [SEP] we awe lips [SEP] : leaf has [SEP] " less gracie dutch [SEP] [SEP] sent eyes convicts vampires got, [SEP] mountainquel this got when great are [SEP] pod [SEP] [SEP] before [SEP] [SEP]fulness [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.568 (perp=10.679, rec=0.420, cos=0.012), tot_loss_proj:4.070 [t=0.25s]
prediction: ['[CLS] andtative. [SEP] → [SEP] we awe lips [SEP] : leaf has~ " less gracie dutch [CLS] [SEP] sent [SEP] [CLS] vampires gets, [SEP] mountain important this got when great are [SEP] pod medical [SEP] before eyes [SEP] advocacy [SEP]']
[ 600/2000] tot_loss=3.687 (perp=10.686, rec=0.954, cos=0.596), tot_loss_proj:3.863 [t=0.25s]
prediction: ['[CLS] words ॥. [SEP] allowing that we awesome shape [SEP] equal leaf has [SEP] pole nine sorority are [CLS] [SEP] summoned on inner vampire nice, that as when thistery was yeah church [SEP] wonders if [SEP] before him [SEP] lizzie [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.217 (perp=12.100, rec=0.704, cos=0.094), tot_loss_proj:4.424 [t=0.25s]
prediction: ["[CLS] words ॥ already [MASK] allowing that goddamn colorsta [SEP] are etc has [SEP] [SEP] pole besides trees. [SEP] hammond plan competition vampire royale, that as seeing this new had ari'[SEP] display if [SEP] before peoplewater lizzie [SEP]"]
Attempt swap
Put prefix at the end
[ 700/2000] tot_loss=2.808 (perp=10.324, rec=0.666, cos=0.077), tot_loss_proj:3.789 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the etc has pathways [CLS] " less species. [SEP] converts ancient competition vampire devised, that are seeing this true was great\'[SEP] wonderful if [SEP] before people [SEP] lizzie words ॥ already blood offering that goddamn colors [SEP]']
[ 750/2000] tot_loss=2.775 (perp=10.459, rec=0.616, cos=0.068), tot_loss_proj:3.879 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the etc has pathways [CLS] " less trees. [SEP] converts ancient competition vampire royale, that are seeing much true was great\'[SEP] wonderful if [SEP] before people [SEP] lizzie words ॥ already blood offering that goddamn colors [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.788 (perp=10.605, rec=0.604, cos=0.064), tot_loss_proj:4.052 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the etc has pathways year " less trees. [SEP] converts infinite\'[SEP] wonderful if [SEP] before people [SEP] lizzie words ॥ ancient competition vampire royale, that are seeing much true was already blood offering that goddamn colors [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.718 (perp=10.358, rec=0.587, cos=0.060), tot_loss_proj:3.964 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the etc has pathways year " less trees [SEP] converts infinite \'. [SEP] wonderful if [SEP] before here [SEP] lizzie words ॥ ancient competition vampire royale, that are seeing much true was already telling offering that goddamn colors [SEP]']
[ 900/2000] tot_loss=2.677 (perp=10.215, rec=0.576, cos=0.057), tot_loss_proj:3.623 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the etc has [SEP] year " besides trees [SEP] converts infinite \'. [SEP] wonderful if [SEP] before here [SEP] lizzie words ॥ ancient competition vampire royale, that are seeing much true was already telling offering that goddamn colors [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.675 (perp=10.276, rec=0.565, cos=0.054), tot_loss_proj:3.611 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the etc has [SEP] year " besides trees [SEP] converts infinitecle. [SEP] wonderful if [SEP] before here [SEP] lizzie words ॥ ancient competition vampire royale, that are seeing much true colors already telling offering that goddamn was [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.682 (perp=10.284, rec=0.570, cos=0.054), tot_loss_proj:3.660 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the etc has [SEP] goddamn " besides trees [SEP] converts infinitecle. [SEP] wonderful if [SEP] before here [SEP] lizzie words ॥ ancient competition vampire royale, that are seeing much true colors already telling offering about year was [SEP]']
[1050/2000] tot_loss=2.711 (perp=10.514, rec=0.557, cos=0.051), tot_loss_proj:3.981 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the etc has [SEP] goddamn " besides trees [SEP] converts infinitecle. [SEP] monk if [SEP] before here [SEP] lizzie words ॥ ancient competition vampire royale, that are seeing much true colors already telling offering about year was [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.619 (perp=9.978, rec=0.570, cos=0.053), tot_loss_proj:3.847 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts greatcle. [SEP] [SEP] nice words ॥ ancient competition vampire royale, that are seeing very true colors already telling offering about year was [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.573 (perp=9.827, rec=0.556, cos=0.051), tot_loss_proj:3.827 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts greatcle. [SEP] nice words ॥ ancient competition vampire royale, that are seeing very true colors already telling offering about year was [SEP]']
[1200/2000] tot_loss=2.560 (perp=9.827, rec=0.545, cos=0.049), tot_loss_proj:3.829 [t=0.24s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts greatcle. [SEP] nice words ॥ ancient competition vampire royale, that are seeing very true colors already telling offering about year was [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.566 (perp=9.850, rec=0.548, cos=0.048), tot_loss_proj:3.793 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] nice words ॥ ancient competition vampire royale, that are seeing thus true colors already great offering about year was [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.540 (perp=9.753, rec=0.544, cos=0.046), tot_loss_proj:3.747 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] nice words about ancient competition vampire royale, that are seeing thus true colors already great offering ॥ year was [SEP]']
[1350/2000] tot_loss=2.536 (perp=9.753, rec=0.540, cos=0.045), tot_loss_proj:3.740 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] nice words about ancient competition vampire royale, that are seeing thus true colors already great offering ॥ year was [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.527 (perp=9.753, rec=0.532, cos=0.045), tot_loss_proj:3.748 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] nice words about ancient competition vampire royale, that are seeing thus true colors already great offering ॥ year was [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.498 (perp=9.638, rec=0.526, cos=0.044), tot_loss_proj:3.698 [t=0.24s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] nice words about ancient competition vampire royale, that are seeing thus true colors already ॥ offering great year was [SEP]']
[1500/2000] tot_loss=2.496 (perp=9.638, rec=0.525, cos=0.044), tot_loss_proj:3.700 [t=0.24s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] nice words about ancient competition vampire royale, that are seeing thus true colors already ॥ offering great year was [SEP]']
Attempt swap
[1550/2000] tot_loss=2.544 (perp=9.877, rec=0.526, cos=0.043), tot_loss_proj:3.781 [t=0.24s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn which besides trees [SEP] converts tellingcle. [SEP] " words about ancient competition vampire royale, that are seeing thus true colors already ॥ offering great year was [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.512 (perp=9.694, rec=0.529, cos=0.044), tot_loss_proj:3.733 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn which besides trees [SEP] converts tellingcle. [SEP] " words about ancient vampire royale, that are seeing thus true colors already ॥ offering great competition year was [SEP]']
[1650/2000] tot_loss=2.505 (perp=9.694, rec=0.523, cos=0.043), tot_loss_proj:3.733 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn which besides trees [SEP] converts tellingcle. [SEP] " words about ancient vampire royale, that are seeing thus true colors already ॥ offering great competition year was [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.482 (perp=9.565, rec=0.527, cos=0.042), tot_loss_proj:3.698 [t=0.24s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn which besides trees [SEP] converts tellingcle. [SEP] " words about ancient vampire royale, seeing that are thus true colors already ॥ offering great competition year was [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.453 (perp=9.415, rec=0.528, cos=0.043), tot_loss_proj:3.779 [t=0.24s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] which words about ancient vampire royale, seeing that are thus true colors already ॥ offering great competition year was [SEP]']
[1800/2000] tot_loss=2.448 (perp=9.415, rec=0.523, cos=0.042), tot_loss_proj:3.780 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] which words about ancient vampire royale, seeing that are thus true colors already ॥ offering great competition year was [SEP]']
Attempt swap
[1850/2000] tot_loss=2.441 (perp=9.415, rec=0.517, cos=0.041), tot_loss_proj:3.780 [t=0.24s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] which words about ancient vampire royale, seeing that are thus true colors already ॥ offering great competition year was [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.432 (perp=9.339, rec=0.522, cos=0.042), tot_loss_proj:3.769 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] which words about ancient vampire year royale, seeing that are thus true colors already ॥ offering great competition was [SEP]']
[1950/2000] tot_loss=2.428 (perp=9.339, rec=0.519, cos=0.042), tot_loss_proj:3.768 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] which words about ancient vampire year royale, seeing that are thus true colors already ॥ offering great competition was [SEP]']
Attempt swap
[2000/2000] tot_loss=2.428 (perp=9.339, rec=0.519, cos=0.041), tot_loss_proj:3.766 [t=0.25s]
prediction: ['[CLS] slovenia [SEP] the monk [SEP] if [SEP] before here etc has [SEP] goddamn " besides trees [SEP] converts tellingcle. [SEP] which words about ancient vampire year royale, seeing that are thus true colors already ॥ offering great competition was [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS]'nodded of seennation but ve theme the ', began seen before " director bastard zone temple'great'glanced makes care makes great help latestened greatest of from younger reinnation local [SEP] they greatest to we [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 45.714 | p: 45.714 | r: 45.714
rouge2     | fm: 2.941 | p: 2.941 | r: 2.941
rougeL     | fm: 31.429 | p: 31.429 | r: 31.429
rougeLsum  | fm: 31.429 | p: 31.429 | r: 31.429
r1fm+r2fm = 48.655

[Aggregate metrics]:
rouge1     | fm: 90.510 | p: 90.336 | r: 90.796
rouge2     | fm: 59.361 | p: 59.304 | r: 59.587
rougeL     | fm: 79.084 | p: 78.860 | r: 79.309
rougeLsum  | fm: 78.995 | p: 78.905 | r: 79.208
r1fm+r2fm = 149.871

input #35 time: 0:09:45 | total time: 5:43:17


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.999284814212414
highest_index [0]
highest [0.999284814212414]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9979257583618164 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.99554443359375 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9552820920944214 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9281548857688904 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9227340221405029 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.9187840819358826 for ['[CLS] papa sinclairevsky perhaps [SEP]']
[Init] best rec loss: 0.8236973285675049 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8220551609992981 for ['[CLS] cornelius bates ramsey harassment [SEP]']
[Init] best perm rec loss: 0.8182108998298645 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.956 (perp=9.086, rec=0.132, cos=0.006), tot_loss_proj:2.105 [t=0.22s]
prediction: ['[CLS] is horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=1.901 (perp=9.147, rec=0.070, cos=0.002), tot_loss_proj:2.104 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=1.900 (perp=9.147, rec=0.069, cos=0.002), tot_loss_proj:2.111 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=1.898 (perp=9.147, rec=0.067, cos=0.002), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.899 (perp=9.147, rec=0.068, cos=0.002), tot_loss_proj:2.118 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 300/2000] tot_loss=1.901 (perp=9.147, rec=0.070, cos=0.002), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.896 (perp=9.147, rec=0.065, cos=0.002), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.904 (perp=9.147, rec=0.073, cos=0.002), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 450/2000] tot_loss=1.790 (perp=8.607, rec=0.067, cos=0.002), tot_loss_proj:1.930 [t=0.23s]
prediction: ["[CLS] s horribly wrong'[SEP]"]
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.520 (perp=7.158, rec=0.087, cos=0.002), tot_loss_proj:1.830 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.501 (perp=7.158, rec=0.068, cos=0.001), tot_loss_proj:1.827 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 600/2000] tot_loss=1.505 (perp=7.158, rec=0.072, cos=0.001), tot_loss_proj:1.825 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.509 (perp=7.158, rec=0.076, cos=0.001), tot_loss_proj:1.817 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.502 (perp=7.158, rec=0.069, cos=0.001), tot_loss_proj:1.822 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 750/2000] tot_loss=1.484 (perp=7.158, rec=0.051, cos=0.001), tot_loss_proj:1.822 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.490 (perp=7.158, rec=0.056, cos=0.001), tot_loss_proj:1.825 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.515 (perp=7.158, rec=0.082, cos=0.001), tot_loss_proj:1.821 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 900/2000] tot_loss=1.501 (perp=7.158, rec=0.067, cos=0.001), tot_loss_proj:1.823 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.488 (perp=7.158, rec=0.055, cos=0.001), tot_loss_proj:1.827 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.493 (perp=7.158, rec=0.060, cos=0.001), tot_loss_proj:1.824 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1050/2000] tot_loss=1.505 (perp=7.158, rec=0.072, cos=0.001), tot_loss_proj:1.824 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.500 (perp=7.158, rec=0.067, cos=0.001), tot_loss_proj:1.810 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.508 (perp=7.158, rec=0.075, cos=0.001), tot_loss_proj:1.826 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1200/2000] tot_loss=1.502 (perp=7.158, rec=0.069, cos=0.001), tot_loss_proj:1.823 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.502 (perp=7.158, rec=0.068, cos=0.001), tot_loss_proj:1.821 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.500 (perp=7.158, rec=0.066, cos=0.001), tot_loss_proj:1.826 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1350/2000] tot_loss=1.497 (perp=7.158, rec=0.064, cos=0.001), tot_loss_proj:1.826 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.488 (perp=7.158, rec=0.055, cos=0.001), tot_loss_proj:1.820 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.501 (perp=7.158, rec=0.068, cos=0.001), tot_loss_proj:1.825 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1500/2000] tot_loss=1.500 (perp=7.158, rec=0.067, cos=0.001), tot_loss_proj:1.828 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.504 (perp=7.158, rec=0.071, cos=0.001), tot_loss_proj:1.825 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.499 (perp=7.158, rec=0.066, cos=0.001), tot_loss_proj:1.821 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1650/2000] tot_loss=1.494 (perp=7.158, rec=0.061, cos=0.001), tot_loss_proj:1.815 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.501 (perp=7.158, rec=0.067, cos=0.001), tot_loss_proj:1.822 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.496 (perp=7.158, rec=0.063, cos=0.001), tot_loss_proj:1.824 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1800/2000] tot_loss=1.497 (perp=7.158, rec=0.064, cos=0.001), tot_loss_proj:1.821 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.495 (perp=7.158, rec=0.062, cos=0.001), tot_loss_proj:1.826 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.497 (perp=7.158, rec=0.064, cos=0.001), tot_loss_proj:1.823 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1950/2000] tot_loss=1.499 (perp=7.158, rec=0.066, cos=0.001), tot_loss_proj:1.816 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.507 (perp=7.158, rec=0.074, cos=0.001), tot_loss_proj:1.825 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] horribly wrong's [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 90.795 | p: 90.616 | r: 91.080
rouge2     | fm: 58.450 | p: 58.353 | r: 58.574
rougeL     | fm: 79.107 | p: 78.949 | r: 79.369
rougeLsum  | fm: 78.954 | p: 78.827 | r: 79.180
r1fm+r2fm = 149.245

input #36 time: 0:09:23 | total time: 5:52:40


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9993689804820187
highest_index [0]
highest [0.9993689804820187]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.9596894383430481 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.9509360194206238 for ['[CLS]quest medical [SEP]']
[Init] best rec loss: 0.8898118138313293 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.8017318248748779 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.7998512983322144 for ['[CLS] living metacritic [SEP]']
[Init] best rec loss: 0.7796184420585632 for ['[CLS] housemple [SEP]']
[Init] best rec loss: 0.777220606803894 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.7522561550140381 for ['[CLS] year clarissa [SEP]']
[Init] best rec loss: 0.7436131834983826 for ['[CLS]atal purpose [SEP]']
[Init] best rec loss: 0.7150478363037109 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.7001022100448608 for ['[CLS] cousin many [SEP]']
[Init] best rec loss: 0.6871371269226074 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6777796745300293 for ['[CLS] cassidystream [SEP]']
[Init] best rec loss: 0.6420923471450806 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6359727382659912 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.927 (perp=12.496, rec=0.329, cos=0.099), tot_loss_proj:3.314 [t=0.24s]
prediction: ['[CLS] eccentric newly [SEP]']
[ 100/2000] tot_loss=2.187 (perp=9.583, rec=0.176, cos=0.095), tot_loss_proj:2.024 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[ 150/2000] tot_loss=1.992 (perp=9.583, rec=0.073, cos=0.002), tot_loss_proj:2.023 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.981 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.021 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.007 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[ 300/2000] tot_loss=1.986 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.017 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.983 (perp=9.583, rec=0.064, cos=0.003), tot_loss_proj:2.021 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.015 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[ 450/2000] tot_loss=1.984 (perp=9.583, rec=0.066, cos=0.001), tot_loss_proj:2.009 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.985 (perp=9.583, rec=0.067, cos=0.001), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[ 600/2000] tot_loss=1.974 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.007 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.967 (perp=9.583, rec=0.049, cos=0.001), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.981 (perp=9.583, rec=0.063, cos=0.001), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[ 750/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.015 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.990 (perp=9.583, rec=0.073, cos=0.001), tot_loss_proj:2.013 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.985 (perp=9.583, rec=0.067, cos=0.001), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.968 (perp=9.583, rec=0.050, cos=0.001), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.989 (perp=9.583, rec=0.071, cos=0.001), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.968 (perp=9.583, rec=0.050, cos=0.001), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.966 (perp=9.583, rec=0.048, cos=0.001), tot_loss_proj:2.020 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.007 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.987 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.987 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.005 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.981 (perp=9.583, rec=0.063, cos=0.001), tot_loss_proj:2.007 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.021 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.986 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.004 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.978 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.015 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.976 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.019 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.019 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.982 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.973 (perp=9.583, rec=0.055, cos=0.001), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.023 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.984 (perp=9.583, rec=0.066, cos=0.001), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.089 | p: 90.924 | r: 91.404
rouge2     | fm: 59.263 | p: 59.121 | r: 59.477
rougeL     | fm: 79.545 | p: 79.312 | r: 79.841
rougeLsum  | fm: 79.455 | p: 79.325 | r: 79.775
r1fm+r2fm = 150.351

input #37 time: 0:09:34 | total time: 6:02:15


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9992647518341967
highest_index [0]
highest [0.9992647518341967]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8108127117156982 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.80867999792099 for ['[CLS] federation [SEP]']
[Init] best rec loss: 0.774891197681427 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7043036222457886 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6709908246994019 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6299773454666138 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.910 (perp=14.069, rec=0.089, cos=0.007), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.882 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.876 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.878 (perp=14.069, rec=0.063, cos=0.002), tot_loss_proj:2.880 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.878 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.869 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.872 (perp=14.069, rec=0.056, cos=0.002), tot_loss_proj:2.868 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.884 (perp=14.069, rec=0.068, cos=0.002), tot_loss_proj:2.880 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.873 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.868 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.878 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.873 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.881 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.869 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.869 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.876 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.882 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.880 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.877 (perp=14.069, rec=0.062, cos=0.001), tot_loss_proj:2.870 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.888 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.874 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.875 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.875 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.882 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.871 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.875 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.877 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.870 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.886 (perp=14.069, rec=0.071, cos=0.001), tot_loss_proj:2.876 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.874 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.883 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.869 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.877 (perp=14.069, rec=0.062, cos=0.001), tot_loss_proj:2.871 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.886 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.871 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.870 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.877 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.859 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.892 (perp=14.069, rec=0.077, cos=0.001), tot_loss_proj:2.878 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.875 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.871 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.892 (perp=14.069, rec=0.077, cos=0.001), tot_loss_proj:2.864 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.864 (perp=14.069, rec=0.049, cos=0.001), tot_loss_proj:2.871 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.874 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.869 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.890 (perp=14.069, rec=0.075, cos=0.001), tot_loss_proj:2.871 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.882 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.878 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.877 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.869 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.872 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.269 | p: 91.073 | r: 91.528
rouge2     | fm: 60.899 | p: 60.716 | r: 61.072
rougeL     | fm: 80.349 | p: 80.120 | r: 80.615
rougeLsum  | fm: 80.076 | p: 79.867 | r: 80.314
r1fm+r2fm = 152.169

input #38 time: 0:09:30 | total time: 6:11:46


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9992526080235489
highest_index [0]
highest [0.9992526080235489]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.0121337175369263 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.0089290142059326 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9913747310638428 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.9341997504234314 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.9286713004112244 for ['[CLS] ira estimate rabbi relegationbiotic request veronica his baby firedusia property management spring gone dub related location cd age eastern drove than kelly parking [SEP]']
[Init] best rec loss: 0.9269349575042725 for ['[CLS] pressed score limiting value blinking walkerson hitch micro mouths inside pockets... : international darby mclaren trace lightec madman formation inquiry end soul [SEP]']
[Init] best rec loss: 0.9190372824668884 for ['[CLS] mutual peopleュ stone intimate reeve templeming freak shores over they sprinterous pro dedication harbour along ll minority [CLS] class raise issue need [SEP]']
[Init] best rec loss: 0.9160887002944946 for ['[CLS] will press caseztty never crimson bohemia journal search band relations behind formula cells main commissioner quick palmer present bible backs duty sogh [SEP]']
[Init] best rec loss: 0.908961832523346 for ['[CLS] townwind hurt main thenney cassidyowa position jury southpher wash sailhy gordon lab happened bepettive in etc sometimes event [SEP]']
[Init] best perm rec loss: 0.9082816243171692 for ['[CLS] south be main sailwindtive gordon positionowapet etc lab thenneyhy wash cassidy jury hurt in event townpher sometimes happened [SEP]']
[Init] best perm rec loss: 0.9072545170783997 for ['[CLS] main wash position eventtivewind beney hurt then town south jury etc inowa cassidy sailhy sometimespet gordon lab happenedpher [SEP]']
[Init] best perm rec loss: 0.9072453379631042 for ['[CLS] event gordonowa jury etc townpher then hurt cassidy be position main sail in washpet lab sometimeswindhy south happenedtiveney [SEP]']
[Init] best perm rec loss: 0.9061841368675232 for ['[CLS] hurtphertive happened sail washwind then lab inney etc sometimes cassidy positionowa behy gordon south jury event town mainpet [SEP]']
[Init] best perm rec loss: 0.9043102264404297 for ['[CLS] south in hurt lab happenedpher wash main sail cassidy sometimeshyowa then gordonwindneypettive event be jury etc position town [SEP]']
[Init] best perm rec loss: 0.902638852596283 for ['[CLS] labpher etc happened hurt be townwind wash in gordonowative south sometimes position then main sail cassidyhy eventpet juryney [SEP]']
[Init] best perm rec loss: 0.902492344379425 for ['[CLS]pher lab in be cassidy gordon hurt town washney sometimesowa event happened position sailtive etcpet jury then south mainwindhy [SEP]']
[Init] best perm rec loss: 0.9024226665496826 for ['[CLS] etcowa lab gordon cassidy positionpher then wash sometimespet town south sailtive mainhy in eventwind hurt be juryney happened [SEP]']
[Init] best perm rec loss: 0.902267336845398 for ['[CLS] gordontivepher event sailney hurt thenhy sometimes happened townowa mainpet jury etc be washwind lab position in south cassidy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.494 (perp=10.779, rec=0.324, cos=0.014), tot_loss_proj:3.209 [t=0.24s]
prediction: ['[CLS] acceleration new lightweight resulting find charles theme new conservative imprint giving. new um critic [SEP] i : element. story myth in broke heart [SEP]']
[ 100/2000] tot_loss=2.326 (perp=10.423, rec=0.236, cos=0.005), tot_loss_proj:3.634 [t=0.25s]
prediction: ['[CLS] acceleration new lightweight, finds conservative tradition new conservative imprint giving and new um warden. both it describes. story hide, new that [SEP]']
[ 150/2000] tot_loss=2.347 (perp=10.710, rec=0.199, cos=0.006), tot_loss_proj:3.809 [t=0.25s]
prediction: ['[CLS]bound gave lightweight, finds conservative texture new conservativebound giving and new city warden technique from it praised conservative texture hide its new texture [SEP]']
[ 200/2000] tot_loss=2.431 (perp=11.189, rec=0.182, cos=0.011), tot_loss_proj:4.213 [t=0.25s]
prediction: ['[CLS]bound gives conservative, finds conservative texture new conservativebound ( and new ship warden technique from it mi versus site hide our new texture [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.415 (perp=11.337, rec=0.143, cos=0.004), tot_loss_proj:4.192 [t=0.26s]
prediction: ['[CLS]bound gives conservative, finds conservative texture new conservativebound or and new. warden tradition it reality versus movie from hide our most texture [SEP]']
[ 300/2000] tot_loss=2.429 (perp=11.477, rec=0.131, cos=0.004), tot_loss_proj:4.219 [t=0.25s]
prediction: ['[CLS]bound gives conservative, finds conservative texture new conservativebound or and reality. warden traditions it reality versus movie from hide our most texture [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.231 (perp=10.517, rec=0.124, cos=0.004), tot_loss_proj:4.071 [t=0.25s]
prediction: ['[CLS]bound gives texture, finds conservative texture new conservativebound or and reality. warden traditions it reality versus movie movie hide our most conservative [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.153 (perp=10.175, rec=0.115, cos=0.003), tot_loss_proj:3.893 [t=0.25s]
prediction: ['[CLS]bound gives texture, finds conservative texture new conservativebound or and reality. bird traditions it hidebound movie movie reality our most conservative [SEP]']
[ 450/2000] tot_loss=2.128 (perp=10.049, rec=0.115, cos=0.004), tot_loss_proj:4.004 [t=0.25s]
prediction: ['[CLS]bound gives texture, finds conservative texture new conservativebound - and reality. movie traditions it hidebound movie movie reality our most conservative [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.118 (perp=10.065, rec=0.102, cos=0.002), tot_loss_proj:3.744 [t=0.25s]
prediction: ['[CLS]bound gives texture, finds one texture new conservativebound three traditions movie and new nova it hide movie movie of reality our most conservative [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.999 (perp=9.503, rec=0.097, cos=0.002), tot_loss_proj:3.823 [t=0.25s]
prediction: ['[CLS]bound gives., finds one texture new conservativebound traditions - reality and new nova it hide movie movie movie reality our most conservative [SEP]']
[ 600/2000] tot_loss=1.977 (perp=9.392, rec=0.097, cos=0.002), tot_loss_proj:3.725 [t=0.25s]
prediction: ['[CLS]bound gives., finds one texture new conservativebound traditions - reality and new nova it hide. movie movie reality our most conservative [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.921 (perp=9.133, rec=0.093, cos=0.002), tot_loss_proj:3.647 [t=0.24s]
prediction: ['[CLS]bound gives., finds one conservative texture newbound traditions - reality and new nova it hide. movie and reality our most conservative [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.871 (perp=8.905, rec=0.088, cos=0.002), tot_loss_proj:3.622 [t=0.25s]
prediction: ['[CLS] and gives., finds one conservative texture newbound traditions - reality and new nova it hide and moviebound reality our most conservative [SEP]']
[ 750/2000] tot_loss=1.875 (perp=8.905, rec=0.092, cos=0.002), tot_loss_proj:3.625 [t=0.25s]
prediction: ['[CLS] and gives., finds one conservative texture newbound traditions - reality and new nova it hide and moviebound reality our most conservative [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.839 (perp=8.771, rec=0.083, cos=0.002), tot_loss_proj:3.698 [t=0.25s]
prediction: ['[CLS] and gives texture, finds one conservative texture newbound traditions - reality and new nova it hide our moviebound reality and most conservative [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.841 (perp=8.771, rec=0.086, cos=0.002), tot_loss_proj:3.705 [t=0.25s]
prediction: ['[CLS] and gives texture, finds one conservative texture newbound traditions - reality and new nova it hide our moviebound reality and most conservative [SEP]']
[ 900/2000] tot_loss=1.847 (perp=8.771, rec=0.091, cos=0.002), tot_loss_proj:3.704 [t=0.25s]
prediction: ['[CLS] and gives texture, finds one conservative texture newbound traditions - reality and new nova it hide our moviebound reality and most conservative [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.822 (perp=8.669, rec=0.087, cos=0.002), tot_loss_proj:3.607 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative texture newbound traditions - reality and new nova it hide our moviebound reality and most conservative [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.806 (perp=8.592, rec=0.086, cos=0.002), tot_loss_proj:3.608 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texturebound traditions - reality and new nova it hide our moviebound reality and most conservative [SEP]']
[1050/2000] tot_loss=1.797 (perp=8.592, rec=0.077, cos=0.001), tot_loss_proj:3.608 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texturebound traditions - reality and new nova it hide our moviebound reality and most conservative [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.793 (perp=8.532, rec=0.086, cos=0.002), tot_loss_proj:3.494 [t=0.25s]
prediction: ['[CLS] and gives relevance, finds one conservative new texturebound traditions and reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
[1150/2000] tot_loss=1.786 (perp=8.532, rec=0.078, cos=0.001), tot_loss_proj:3.495 [t=0.25s]
prediction: ['[CLS] and gives relevance, finds one conservative new texturebound traditions and reality and new nova it hide our moviebound reality - most conservative [SEP]']
[1200/2000] tot_loss=1.787 (perp=8.532, rec=0.079, cos=0.001), tot_loss_proj:3.494 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texturebound traditions and reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.723 (perp=8.185, rec=0.084, cos=0.002), tot_loss_proj:3.462 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
[1300/2000] tot_loss=1.720 (perp=8.185, rec=0.081, cos=0.001), tot_loss_proj:3.466 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
[1350/2000] tot_loss=1.722 (perp=8.185, rec=0.083, cos=0.002), tot_loss_proj:3.468 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
[1400/2000] tot_loss=1.716 (perp=8.185, rec=0.077, cos=0.001), tot_loss_proj:3.462 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
[1450/2000] tot_loss=1.714 (perp=8.185, rec=0.075, cos=0.002), tot_loss_proj:3.461 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
[1500/2000] tot_loss=1.713 (perp=8.185, rec=0.074, cos=0.002), tot_loss_proj:3.464 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
[1550/2000] tot_loss=1.716 (perp=8.185, rec=0.078, cos=0.001), tot_loss_proj:3.467 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
[1600/2000] tot_loss=1.719 (perp=8.185, rec=0.081, cos=0.001), tot_loss_proj:3.466 [t=0.25s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
[1650/2000] tot_loss=1.723 (perp=8.185, rec=0.084, cos=0.001), tot_loss_proj:3.467 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
[1700/2000] tot_loss=1.721 (perp=8.185, rec=0.083, cos=0.002), tot_loss_proj:3.467 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.715 (perp=8.160, rec=0.082, cos=0.002), tot_loss_proj:3.477 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one new conservative texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
[1800/2000] tot_loss=1.713 (perp=8.160, rec=0.079, cos=0.001), tot_loss_proj:3.473 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one new conservative texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.718 (perp=8.185, rec=0.079, cos=0.002), tot_loss_proj:3.466 [t=0.25s]
prediction: ['[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.714 (perp=8.160, rec=0.081, cos=0.002), tot_loss_proj:3.477 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one new conservative texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
[1950/2000] tot_loss=1.720 (perp=8.160, rec=0.087, cos=0.002), tot_loss_proj:3.473 [t=0.25s]
prediction: ['[CLS] and gives relevance, finds one new conservative texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Attempt swap
[2000/2000] tot_loss=1.711 (perp=8.160, rec=0.078, cos=0.001), tot_loss_proj:3.477 [t=0.24s]
prediction: ['[CLS] and gives relevance, finds one new conservative texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] and gives relevance, finds one conservative new texture and traditionsbound reality and new nova it hide our moviebound reality - most conservative [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.111 | p: 69.565 | r: 72.727
rouge2     | fm: 18.605 | p: 18.182 | r: 19.048
rougeL     | fm: 40.000 | p: 39.130 | r: 40.909
rougeLsum  | fm: 40.000 | p: 39.130 | r: 40.909
r1fm+r2fm = 89.716

[Aggregate metrics]:
rouge1     | fm: 90.854 | p: 90.602 | r: 91.153
rouge2     | fm: 59.292 | p: 59.196 | r: 59.494
rougeL     | fm: 79.269 | p: 79.047 | r: 79.670
rougeLsum  | fm: 78.856 | p: 78.697 | r: 79.116
r1fm+r2fm = 150.146

input #39 time: 0:09:46 | total time: 6:21:32


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9993180163624655
highest_index [0]
highest [0.9993180163624655]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9940409064292908 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9588767290115356 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9404011964797974 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 0.9336565732955933 for ['[CLS] alive represents adelaide cinder majestymersfordthes s [SEP]']
[Init] best rec loss: 0.9329563975334167 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 0.9272531867027283 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 0.9182189702987671 for ['[CLS] formula expression groundsoft written used ⇒ution murray [SEP]']
[Init] best rec loss: 0.9071977734565735 for ['[CLS] alloid courtesy [MASK]blood mean gownrarm [SEP]']
[Init] best rec loss: 0.847230076789856 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8415253162384033 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8396544456481934 for ['[CLS]° georgian but kent lady abd many already deciding [SEP]']
[Init] best perm rec loss: 0.8368232250213623 for ['[CLS] deciding° lady abd but kent georgian already many [SEP]']
[Init] best perm rec loss: 0.834687352180481 for ['[CLS] kent already deciding lady but abd georgian° many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.758 (perp=12.157, rec=0.316, cos=0.010), tot_loss_proj:3.437 [t=0.24s]
prediction: ['[CLS] electronicmmel us pu anger orony language corruption [SEP]']
[ 100/2000] tot_loss=2.918 (perp=13.705, rec=0.171, cos=0.006), tot_loss_proj:3.761 [t=0.24s]
prediction: ['[CLS] electronicmmel us pu kanye withony imageryony [SEP]']
[ 150/2000] tot_loss=2.834 (perp=13.601, rec=0.110, cos=0.004), tot_loss_proj:3.367 [t=0.24s]
prediction: ['[CLS] electronicmmel us pu ph withony imageryony [SEP]']
[ 200/2000] tot_loss=2.584 (perp=12.407, rec=0.100, cos=0.003), tot_loss_proj:2.941 [t=0.24s]
prediction: ['[CLS] artworkmmel us pu ph withony imagery or [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.296 (perp=10.838, rec=0.125, cos=0.003), tot_loss_proj:3.018 [t=0.24s]
prediction: ['[CLS] musicmmel us pu phony with imagery or [SEP]']
[ 300/2000] tot_loss=2.254 (perp=10.838, rec=0.085, cos=0.002), tot_loss_proj:3.036 [t=0.24s]
prediction: ['[CLS] musicmmel us pu phony with imagery or [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.094 (perp=10.078, rec=0.077, cos=0.001), tot_loss_proj:2.759 [t=0.24s]
prediction: ['[CLS] pu musicmmel us phony with imagery or [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.708 (perp=8.184, rec=0.070, cos=0.001), tot_loss_proj:2.365 [t=0.24s]
prediction: ['[CLS] music pummel us phony with imagery or [SEP]']
[ 450/2000] tot_loss=1.707 (perp=8.184, rec=0.069, cos=0.001), tot_loss_proj:2.369 [t=0.24s]
prediction: ['[CLS] music pummel us phony with imagery or [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.707 (perp=8.184, rec=0.069, cos=0.001), tot_loss_proj:2.379 [t=0.24s]
prediction: ['[CLS] music pummel us phony with imagery or [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.588 (perp=7.355, rec=0.114, cos=0.003), tot_loss_proj:2.057 [t=0.24s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
[ 600/2000] tot_loss=1.550 (perp=7.355, rec=0.078, cos=0.001), tot_loss_proj:2.104 [t=0.24s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.494 (perp=7.096, rec=0.073, cos=0.001), tot_loss_proj:2.054 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.486 (perp=7.096, rec=0.066, cos=0.001), tot_loss_proj:2.045 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[ 750/2000] tot_loss=1.494 (perp=7.096, rec=0.073, cos=0.001), tot_loss_proj:2.053 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.483 (perp=7.096, rec=0.062, cos=0.001), tot_loss_proj:2.050 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.488 (perp=7.096, rec=0.067, cos=0.001), tot_loss_proj:2.052 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[ 900/2000] tot_loss=1.489 (perp=7.096, rec=0.068, cos=0.001), tot_loss_proj:2.052 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.486 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.048 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1000/2000] tot_loss=1.491 (perp=7.096, rec=0.070, cos=0.001), tot_loss_proj:2.052 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1050/2000] tot_loss=1.493 (perp=7.096, rec=0.072, cos=0.001), tot_loss_proj:2.049 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1100/2000] tot_loss=1.490 (perp=7.096, rec=0.070, cos=0.001), tot_loss_proj:2.038 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1150/2000] tot_loss=1.490 (perp=7.096, rec=0.069, cos=0.001), tot_loss_proj:2.045 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1200/2000] tot_loss=1.484 (perp=7.096, rec=0.064, cos=0.001), tot_loss_proj:2.044 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1250/2000] tot_loss=1.485 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.038 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1300/2000] tot_loss=1.490 (perp=7.096, rec=0.070, cos=0.001), tot_loss_proj:2.043 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1350/2000] tot_loss=1.494 (perp=7.096, rec=0.074, cos=0.001), tot_loss_proj:2.053 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1400/2000] tot_loss=1.485 (perp=7.096, rec=0.064, cos=0.001), tot_loss_proj:2.050 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1450/2000] tot_loss=1.487 (perp=7.096, rec=0.067, cos=0.001), tot_loss_proj:2.047 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1500/2000] tot_loss=1.486 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.047 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1550/2000] tot_loss=1.498 (perp=7.096, rec=0.078, cos=0.001), tot_loss_proj:2.046 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1600/2000] tot_loss=1.482 (perp=7.096, rec=0.062, cos=0.001), tot_loss_proj:2.038 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1650/2000] tot_loss=1.492 (perp=7.096, rec=0.071, cos=0.001), tot_loss_proj:2.038 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1700/2000] tot_loss=1.490 (perp=7.096, rec=0.069, cos=0.001), tot_loss_proj:2.051 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1750/2000] tot_loss=1.478 (perp=7.096, rec=0.058, cos=0.001), tot_loss_proj:2.040 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1800/2000] tot_loss=1.487 (perp=7.096, rec=0.066, cos=0.001), tot_loss_proj:2.053 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1850/2000] tot_loss=1.483 (perp=7.096, rec=0.062, cos=0.001), tot_loss_proj:2.044 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1900/2000] tot_loss=1.481 (perp=7.096, rec=0.060, cos=0.001), tot_loss_proj:2.046 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1950/2000] tot_loss=1.486 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.047 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[2000/2000] tot_loss=1.480 (perp=7.096, rec=0.059, cos=0.001), tot_loss_proj:2.051 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] imagery pummel us or phony with music [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.065 | p: 90.842 | r: 91.377
rouge2     | fm: 58.638 | p: 58.560 | r: 58.839
rougeL     | fm: 78.868 | p: 78.676 | r: 79.118
rougeLsum  | fm: 78.714 | p: 78.536 | r: 79.001
r1fm+r2fm = 149.703

input #40 time: 0:09:41 | total time: 6:31:13


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.9993041155296631
highest_index [0]
highest [0.9993041155296631]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9744104743003845 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9511962532997131 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 0.9439316987991333 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 0.933946430683136 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.9258303642272949 for ['[CLS]grapher pr [SEP]']
[Init] best rec loss: 0.9252661466598511 for ['[CLS]mler previously [SEP]']
[Init] best rec loss: 0.9075953364372253 for ['[CLS] electors mediterranean [SEP]']
[Init] best rec loss: 0.8915941715240479 for ['[CLS] meetswr [SEP]']
[Init] best rec loss: 0.852973222732544 for ['[CLS] bolivar satisfied [SEP]']
[Init] best rec loss: 0.8348253965377808 for ['[CLS] ways whether [SEP]']
[Init] best perm rec loss: 0.8253730535507202 for ['[CLS] whether ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.159 (perp=10.212, rec=0.114, cos=0.002), tot_loss_proj:2.107 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.124 (perp=10.212, rec=0.080, cos=0.001), tot_loss_proj:2.116 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.101 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.094 (perp=10.212, rec=0.051, cos=0.001), tot_loss_proj:2.110 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.002), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.095 (perp=10.212, rec=0.051, cos=0.002), tot_loss_proj:2.105 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.102 (perp=10.212, rec=0.058, cos=0.001), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.096 (perp=10.212, rec=0.052, cos=0.002), tot_loss_proj:2.106 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.113 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.114 (perp=10.212, rec=0.070, cos=0.001), tot_loss_proj:2.108 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.125 (perp=10.212, rec=0.081, cos=0.001), tot_loss_proj:2.107 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.118 (perp=10.212, rec=0.074, cos=0.001), tot_loss_proj:2.107 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.116 (perp=10.212, rec=0.072, cos=0.001), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.107 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.100 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.113 (perp=10.212, rec=0.069, cos=0.001), tot_loss_proj:2.105 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.093 (perp=10.212, rec=0.050, cos=0.001), tot_loss_proj:2.110 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.111 (perp=10.212, rec=0.068, cos=0.001), tot_loss_proj:2.117 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.108 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.102 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.113 (perp=10.212, rec=0.069, cos=0.001), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.113 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.104 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.117 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.115 (perp=10.212, rec=0.071, cos=0.001), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.114 (perp=10.212, rec=0.071, cos=0.001), tot_loss_proj:2.104 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.102 (perp=10.212, rec=0.058, cos=0.001), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.101 (perp=10.212, rec=0.058, cos=0.001), tot_loss_proj:2.106 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.114 (perp=10.212, rec=0.070, cos=0.001), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.115 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.111 (perp=10.212, rec=0.068, cos=0.001), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.107 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.118 (perp=10.212, rec=0.074, cos=0.001), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.107 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.240 | p: 91.054 | r: 91.506
rouge2     | fm: 59.566 | p: 59.440 | r: 59.741
rougeL     | fm: 79.479 | p: 79.262 | r: 79.701
rougeLsum  | fm: 79.296 | p: 79.153 | r: 79.526
r1fm+r2fm = 150.807

input #41 time: 0:09:35 | total time: 6:40:49


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9993266219365816
highest_index [0]
highest [0.9993266219365816]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9052959084510803 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8539038896560669 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8489475846290588 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8198183178901672 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.797766923904419 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7967566251754761 for ['[CLS] wish stages ran offendedrs bandagible attracted ever scale kitchenctric international liftedtaking superseded cut assignmentures enough treatyplingbe larger dare maple [SEP]']
[Init] best perm rec loss: 0.7962284684181213 for ['[CLS]ures dare scale offended international evertaking wish enough largerpling assignmentgiblectric ran kitchen stagesrs attracted banda treaty lifted maple supersededbe cut [SEP]']
[Init] best perm rec loss: 0.7946922779083252 for ['[CLS]taking superseded international banda maple dare cut wish attracted ran kitchen treaty scale larger ever enoughbegible stagesuresrs liftedctric assignmentpling offended [SEP]']
[Init] best perm rec loss: 0.7929145693778992 for ['[CLS] bandataking dare rangible attracted maplers international stagespling assignment cut treaty scale enough everctric lifteduresbe superseded wish larger offended kitchen [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.681 (perp=11.929, rec=0.285, cos=0.011), tot_loss_proj:3.196 [t=0.24s]
prediction: ['[CLS] sufficiently government forgot legislative phone terminal phone script site. interceptions itself meant hardware poor poorly earlier burstinator apparently. vault poorly business forgot information [SEP]']
[ 100/2000] tot_loss=2.380 (perp=10.859, rec=0.204, cos=0.004), tot_loss_proj:2.764 [t=0.25s]
prediction: ['[CLS] they they forgot any scary theater a forgot projects includes forgot itself as they poorly poorly actuallyggergated poorly.ggerential school forgot information [SEP]']
[ 150/2000] tot_loss=2.529 (perp=11.790, rec=0.165, cos=0.005), tot_loss_proj:3.051 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything scary scary to forgot filmmakers includes forgot republicans as they poorly poorly actuallyggergated poorlyjiggerential school forgot into [SEP]']
[ 200/2000] tot_loss=2.290 (perp=10.744, rec=0.139, cos=0.002), tot_loss_proj:2.907 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything scary scary to forgot filmmakers include even filmmakers as they poorly poorly actuallyggergated poorlyjigger high school forgot into [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.229 (perp=10.465, rec=0.133, cos=0.003), tot_loss_proj:2.691 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even scary to charlemagne filmmakers include scary colby as they poorly poorly actually attractionized poorlyjigger high school forgot into [SEP]']
[ 300/2000] tot_loss=2.150 (perp=10.156, rec=0.116, cos=0.003), tot_loss_proj:2.642 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even scary to include include include scary colby as they poorly poorly include attraction posted poorlyjigger high school forgot into [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.151 (perp=9.953, rec=0.156, cos=0.005), tot_loss_proj:2.549 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even scary to poorly specifically include they scary, as. poorly include attraction attraction poorlyjigger high school forgot into [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.982 (perp=9.252, rec=0.128, cos=0.004), tot_loss_proj:2.419 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to poorly specifically include they scary, as into poorly include attraction attraction poorlyjigger high school forgot. [SEP]']
[ 450/2000] tot_loss=1.970 (perp=9.252, rec=0.116, cos=0.003), tot_loss_proj:2.417 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to poorly specifically include they scary, as into poorly include attraction attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.006 (perp=9.424, rec=0.119, cos=0.003), tot_loss_proj:2.576 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to poorly scary include they scary, as into attraction poorly include attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.902 (perp=8.964, rec=0.107, cos=0.002), tot_loss_proj:2.535 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to poorly scary include scary, as they into attraction poorly include attraction poorlyjigger high school forgot. [SEP]']
[ 600/2000] tot_loss=1.959 (perp=9.271, rec=0.103, cos=0.002), tot_loss_proj:2.725 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to poorly scary include scary. as they into attraction poorly to attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.886 (perp=8.891, rec=0.106, cos=0.002), tot_loss_proj:2.631 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to poorly include scary. as scary they into attraction poorly to attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.908 (perp=9.037, rec=0.099, cos=0.002), tot_loss_proj:2.586 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to poorly include scary. as scary they fatal into poorly to attraction poorlyjigger high school forgot. [SEP]']
[ 750/2000] tot_loss=1.976 (perp=9.384, rec=0.097, cos=0.002), tot_loss_proj:2.726 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to halfway include scary. as scary they fatal into poorly to attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.934 (perp=9.195, rec=0.093, cos=0.002), tot_loss_proj:2.755 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting halfway to include scary. as scary they fatal into poorly to attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.934 (perp=9.170, rec=0.099, cos=0.002), tot_loss_proj:2.696 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting halfway to include scary. as scary they to into poorly fatal attraction poorlyjigger high school forgot. [SEP]']
[ 900/2000] tot_loss=1.932 (perp=9.170, rec=0.096, cos=0.002), tot_loss_proj:2.696 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting halfway to include scary. as scary they to into poorly fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.872 (perp=8.886, rec=0.094, cos=0.002), tot_loss_proj:2.705 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to to include scary. as scary they halfway into poorly fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.847 (perp=8.792, rec=0.088, cos=0.001), tot_loss_proj:2.643 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting. to include scary to as scary they halfway into poorly fatal attraction poorlyjigger high school forgot. [SEP]']
[1050/2000] tot_loss=1.853 (perp=8.792, rec=0.093, cos=0.001), tot_loss_proj:2.642 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting. to include scary to as scary they halfway into poorly fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.826 (perp=8.664, rec=0.091, cos=0.001), tot_loss_proj:2.547 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to. to include scary as scary they halfway into poorly fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.785 (perp=8.445, rec=0.094, cos=0.002), tot_loss_proj:2.426 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
[1200/2000] tot_loss=1.787 (perp=8.445, rec=0.096, cos=0.002), tot_loss_proj:2.418 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.779 (perp=8.445, rec=0.089, cos=0.002), tot_loss_proj:2.418 [t=0.25s]
prediction: ['[CLS] filmmakers they forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.773 (perp=8.425, rec=0.087, cos=0.002), tot_loss_proj:2.309 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
[1350/2000] tot_loss=1.777 (perp=8.425, rec=0.091, cos=0.001), tot_loss_proj:2.315 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.781 (perp=8.425, rec=0.095, cos=0.001), tot_loss_proj:2.307 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.772 (perp=8.425, rec=0.086, cos=0.001), tot_loss_proj:2.311 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
[1500/2000] tot_loss=1.780 (perp=8.425, rec=0.093, cos=0.001), tot_loss_proj:2.313 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.775 (perp=8.425, rec=0.089, cos=0.002), tot_loss_proj:2.313 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.775 (perp=8.425, rec=0.088, cos=0.001), tot_loss_proj:2.314 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
[1650/2000] tot_loss=1.771 (perp=8.425, rec=0.085, cos=0.001), tot_loss_proj:2.309 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.777 (perp=8.425, rec=0.090, cos=0.001), tot_loss_proj:2.319 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.774 (perp=8.425, rec=0.087, cos=0.001), tot_loss_proj:2.317 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
[1800/2000] tot_loss=1.783 (perp=8.425, rec=0.096, cos=0.001), tot_loss_proj:2.309 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.777 (perp=8.425, rec=0.091, cos=0.001), tot_loss_proj:2.310 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.771 (perp=8.425, rec=0.084, cos=0.001), tot_loss_proj:2.308 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
[1950/2000] tot_loss=1.770 (perp=8.425, rec=0.084, cos=0.001), tot_loss_proj:2.309 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.783 (perp=8.434, rec=0.094, cos=0.001), tot_loss_proj:2.260 [t=0.25s]
prediction: ['[CLS] they filmmakers forgot anything even setting to. to include poorly as scary scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] they filmmakers forgot anything even setting to. to include poorly scary as scary they halfway into fatal attraction poorlyjigger high school forgot. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 79.167 | p: 79.167 | r: 79.167
rouge2     | fm: 26.087 | p: 26.087 | r: 26.087
rougeL     | fm: 54.167 | p: 54.167 | r: 54.167
rougeLsum  | fm: 54.167 | p: 54.167 | r: 54.167
r1fm+r2fm = 105.254

[Aggregate metrics]:
rouge1     | fm: 90.984 | p: 90.837 | r: 91.217
rouge2     | fm: 59.087 | p: 58.930 | r: 59.232
rougeL     | fm: 78.788 | p: 78.627 | r: 79.090
rougeLsum  | fm: 78.577 | p: 78.387 | r: 78.865
r1fm+r2fm = 150.071

input #42 time: 0:09:51 | total time: 6:50:41


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9992735963516287
highest_index [0]
highest [0.9992735963516287]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9571977853775024 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9207459688186646 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8901294469833374 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8651462197303772 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.85670405626297 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.8478173613548279 for ['[CLS] carested royals erica [SEP]']
[Init] best rec loss: 0.8367412090301514 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 0.8362466096878052 for ['[CLS]sh nadu shall taylor [SEP]']
[Init] best rec loss: 0.7853533625602722 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7812954783439636 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.7793064117431641 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 0.7782993912696838 for ['[CLS] secondckbus climb [SEP]']
[Init] best perm rec loss: 0.7752212882041931 for ['[CLS] climb secondbusck [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.542 (perp=11.440, rec=0.247, cos=0.007), tot_loss_proj:2.795 [t=0.24s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 100/2000] tot_loss=2.445 (perp=11.440, rec=0.153, cos=0.004), tot_loss_proj:2.801 [t=0.24s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 150/2000] tot_loss=2.299 (perp=10.986, rec=0.099, cos=0.003), tot_loss_proj:2.786 [t=0.24s]
prediction: ['[CLS] naissisticrc [SEP]']
[ 200/2000] tot_loss=2.270 (perp=10.986, rec=0.071, cos=0.002), tot_loss_proj:2.804 [t=0.24s]
prediction: ['[CLS] naissisticrc [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.137 (perp=5.048, rec=0.123, cos=0.005), tot_loss_proj:1.072 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.074 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.072 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.066 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.080 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.092 (perp=5.048, rec=0.081, cos=0.001), tot_loss_proj:1.082 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.002), tot_loss_proj:1.091 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.077 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.087 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.083 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.083 (perp=5.048, rec=0.072, cos=0.001), tot_loss_proj:1.080 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.052 (perp=5.048, rec=0.041, cos=0.001), tot_loss_proj:1.081 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.086 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.062 (perp=5.048, rec=0.051, cos=0.001), tot_loss_proj:1.077 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.063 (perp=5.048, rec=0.052, cos=0.001), tot_loss_proj:1.078 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.060 (perp=5.048, rec=0.049, cos=0.001), tot_loss_proj:1.082 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.087 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.073 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.090 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.069 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.080 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.078 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.063 (perp=5.048, rec=0.052, cos=0.001), tot_loss_proj:1.080 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.083 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.086 (perp=5.048, rec=0.075, cos=0.001), tot_loss_proj:1.084 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.059 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.084 (perp=5.048, rec=0.073, cos=0.001), tot_loss_proj:1.078 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.094 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.085 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.060 (perp=5.048, rec=0.049, cos=0.001), tot_loss_proj:1.072 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.077 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.091 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.079 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.065 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.074 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.078 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.079 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.083 (perp=5.048, rec=0.072, cos=0.001), tot_loss_proj:1.079 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.062 (perp=5.048, rec=0.051, cos=0.001), tot_loss_proj:1.067 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.064 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.163 | p: 91.013 | r: 91.484
rouge2     | fm: 59.884 | p: 59.768 | r: 60.010
rougeL     | fm: 79.251 | p: 79.002 | r: 79.573
rougeLsum  | fm: 79.138 | p: 78.960 | r: 79.357
r1fm+r2fm = 151.046

input #43 time: 0:09:35 | total time: 7:00:16


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9992421634507239
highest_index [0]
highest [0.9992421634507239]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9847252368927002 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9550042748451233 for ['[CLS] photo led breath sound coin day opponents allies joycevel move throne doin head huge guest perhaps ; his gaze saddle decide willise new great ¡wark grand [SEP]']
[Init] best rec loss: 0.9321396350860596 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.9320439100265503 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best rec loss: 0.9308730363845825 for ['[CLS] balls greenhouse with punch por new oscar shut puzzle crunch interactive role substanceport those beg than units aged host roller alphabet defeat writing meet guinea one then percentage [SEP]']
[Init] best rec loss: 0.9090942740440369 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best perm rec loss: 0.907383382320404 for ['[CLS] ; raceway contact harbor slave settled haley brow graphic nation hee fatty co contains rock hello formerly data blue landonosihair capacity s illustrated ltd contestants intent comedy [SEP]']
[Init] best perm rec loss: 0.9066078662872314 for ['[CLS] haleyhair fatty intentosi settled illustrated harbor ltd rock nation comedy blue landon brow raceway data contestants graphic hello s ; hee contact formerly co slave capacity contains [SEP]']
[Init] best perm rec loss: 0.9063311815261841 for ['[CLS]osi raceway ltd capacity blue haley contains hee slave hello ; contact rock nation settled comedy formerly data brow intent graphichair harbor contestants illustrated co s fatty landon [SEP]']
[Init] best perm rec loss: 0.9054985046386719 for ['[CLS] rock ltd blue ; contains contact raceway co illustrated haley slave comedy helloosi s intent hee graphic contestants fattyhair harbor settled data brow nation formerly landon capacity [SEP]']
[Init] best perm rec loss: 0.9040576815605164 for ['[CLS] co contains fatty contacthair haley settled contestants graphic data nation blue capacity comedy landon ltd hello brow ; rock raceway hee formerly illustrated harbor s slave intentosi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.367 (perp=10.555, rec=0.249, cos=0.007), tot_loss_proj:2.721 [t=0.24s]
prediction: ['[CLS]m. empty lost than miller routine translation portion execution translation that lost smackdown mis wasted this hosted. stupid executionization lost the psychology of de lost lost [SEP]']
[ 100/2000] tot_loss=2.269 (perp=10.514, rec=0.162, cos=0.004), tot_loss_proj:2.746 [t=0.24s]
prediction: ['[CLS]. been lost lost as few routine translationwest execution translation the া fright is wasted slack beliefs. slack executionizes slack the hollywood the hollywood fright lost [SEP]']
[ 150/2000] tot_loss=2.344 (perp=11.042, rec=0.133, cos=0.002), tot_loss_proj:2.809 [t=0.25s]
prediction: ['[CLS]. been empty lose as in routine translation tired executionfest the fright fright isfest slackizes.alic executionizes slack the premise. hollywood fright lost [SEP]']
[ 200/2000] tot_loss=2.154 (perp=10.238, rec=0.105, cos=0.002), tot_loss_proj:2.611 [t=0.24s]
prediction: ['[CLS]. has empty several as in routine translation. executionfest the frightfest isfest slackfest.alic executionizes slack the premise. hollywood fright lost [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.109 (perp=10.028, rec=0.102, cos=0.002), tot_loss_proj:2.609 [t=0.24s]
prediction: ['[CLS] another has absurd several as in routine translation. executionfest the frightfest isfest slackfest.alic whichizes the premise. hollywood slack fright lost [SEP]']
[ 300/2000] tot_loss=2.070 (perp=9.886, rec=0.091, cos=0.002), tot_loss_proj:2.613 [t=0.24s]
prediction: ['[CLS]. has absurd several as in routine translation. executionfest the anotherfest isfest slackfest.alic whichizes the premise. hollywood slack fright lost [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.090 (perp=9.956, rec=0.097, cos=0.002), tot_loss_proj:2.537 [t=0.25s]
prediction: ['[CLS]. has absurd severalised in routine translationwest executionfest the anotherfest infest slackfest. whichalicizes the premise. hollywood slack fright lost [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.082 (perp=9.946, rec=0.091, cos=0.002), tot_loss_proj:2.749 [t=0.24s]
prediction: ['[CLS]. has premise severalde in routine translationwest executionfest the another fright infest slackfest. whichalicizes the absurd. hollywood slack fright lost [SEP]']
[ 450/2000] tot_loss=2.075 (perp=9.934, rec=0.087, cos=0.002), tot_loss_proj:2.689 [t=0.24s]
prediction: ['[CLS]. has premise severalde in routine translationwest executionfest the another fright infest slack execution. whichalicizes the absurd. hollywood slack fright lost [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.926 (perp=9.233, rec=0.078, cos=0.002), tot_loss_proj:2.468 [t=0.24s]
prediction: ['[CLS]. has premise thede in routine translationwest executionfest the another fright in fright slack execution. whichalicizes the absurd. hollywood slackfest lost [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.934 (perp=9.217, rec=0.089, cos=0.002), tot_loss_proj:2.420 [t=0.24s]
prediction: ['[CLS]. has premise thede in routine translationutive executionfest. the another fright in fright slack execution whichalicizes the absurd. hollywood slackfest lost [SEP]']
[ 600/2000] tot_loss=2.027 (perp=9.719, rec=0.081, cos=0.002), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS]. has premise thede in routine translationutive executionfest. the another fright as fright slack execution whichalicizes the absurd. hollywood slackfest lost [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.897 (perp=9.052, rec=0.085, cos=0.002), tot_loss_proj:2.413 [t=0.24s]
prediction: ['[CLS]. has premise thede in routine translation net execution.fest the another fright in fright slack execution whichalicizes the absurd. hollywood slackfest lost [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.847 (perp=8.883, rec=0.069, cos=0.001), tot_loss_proj:2.368 [t=0.25s]
prediction: ['[CLS]. has the premise of in routine translation it execution.fest the another fright in fright slack execution whichalicizes the absurd. hollywood slack acknowledge lost [SEP]']
[ 750/2000] tot_loss=1.815 (perp=8.629, rec=0.088, cos=0.001), tot_loss_proj:2.336 [t=0.24s]
prediction: ['[CLS]. has the premise of in routine translation it execution.fest the another fright in fright slack execution whichalicizes the absurd. hollywood slack with lost [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.753 (perp=8.409, rec=0.070, cos=0.001), tot_loss_proj:2.359 [t=0.24s]
prediction: ['[CLS]. has the premise of translation routine in it execution.fest the another fright in fright slack execution whichalicizes the absurd. hollywood slack of lost [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.724 (perp=8.225, rec=0.078, cos=0.001), tot_loss_proj:2.299 [t=0.24s]
prediction: ['[CLS] execution has the premise of translation routine in it..fest the another fright in fright slack execution whichalicizes the absurd. hollywood slack of lost [SEP]']
[ 900/2000] tot_loss=1.746 (perp=8.400, rec=0.065, cos=0.002), tot_loss_proj:2.343 [t=0.25s]
prediction: ['[CLS] execution has the premise of translation routine in it..fest the another fright in fright slackity whichalicizes the absurd. hollywood slack of lost [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.714 (perp=8.179, rec=0.077, cos=0.002), tot_loss_proj:2.439 [t=0.24s]
prediction: ['[CLS] execution has the premise of translation routine in it..fest the another fright in fright slackity whichalicizes the absurd. lost slack of hollywood [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.621 (perp=7.774, rec=0.064, cos=0.002), tot_loss_proj:2.121 [t=0.25s]
prediction: ['[CLS] execution has the premise of translation slack in it..fest the another fright in fright slackity whichalicizes the absurd. lost routine of hollywood [SEP]']
[1050/2000] tot_loss=1.627 (perp=7.774, rec=0.070, cos=0.001), tot_loss_proj:2.118 [t=0.25s]
prediction: ['[CLS] execution has the premise of translation slack in it..fest the another fright in fright slackity whichalicizes the absurd. lost routine of hollywood [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.616 (perp=7.678, rec=0.079, cos=0.001), tot_loss_proj:2.093 [t=0.24s]
prediction: ['[CLS]ity has the premise of translation slack in it..fest the another fright in fright slack execution whichalicizes the absurd. lost routine of hollywood [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.580 (perp=7.538, rec=0.071, cos=0.002), tot_loss_proj:2.071 [t=0.24s]
prediction: ['[CLS]. has the premise of translation slack in it..fest the another fright in fright slack execution whichalicizes the absurdity lost routine of hollywood [SEP]']
[1200/2000] tot_loss=1.579 (perp=7.538, rec=0.070, cos=0.001), tot_loss_proj:2.068 [t=0.25s]
prediction: ['[CLS]. has the premise of translation slack in it..fest the another fright in fright slack execution whichalicizes the absurdity lost routine of hollywood [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.575 (perp=7.511, rec=0.071, cos=0.001), tot_loss_proj:2.048 [t=0.24s]
prediction: ['[CLS]. has the premise of translation slack in it..fest the another fright in fright slack execution whichalicizes the absurdity lost of hollywood routine [SEP]']
Attempt swap
[1300/2000] tot_loss=1.582 (perp=7.511, rec=0.078, cos=0.002), tot_loss_proj:2.045 [t=0.24s]
prediction: ['[CLS]. has the premise of translation slack in it..fest the another fright in fright slack execution whichalicizes the absurdity lost of hollywood routine [SEP]']
[1350/2000] tot_loss=1.577 (perp=7.511, rec=0.074, cos=0.002), tot_loss_proj:2.050 [t=0.24s]
prediction: ['[CLS]. has the premise of translation slack in it..fest the another fright in fright slack execution whichalicizes the absurdity lost of hollywood routine [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.544 (perp=7.369, rec=0.069, cos=0.002), tot_loss_proj:1.997 [t=0.24s]
prediction: ['[CLS]. has the premise of translation slack in it..fest the another fright in fright slack execution whichalicizes the absurdity of lost hollywood routine [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.518 (perp=7.200, rec=0.077, cos=0.002), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS]. has lost premise of translation slack in it..fest the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
[1500/2000] tot_loss=1.517 (perp=7.247, rec=0.066, cos=0.002), tot_loss_proj:1.916 [t=0.24s]
prediction: ['[CLS]. has lost premise in translation slack in it..fest the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.471 (perp=7.010, rec=0.067, cos=0.002), tot_loss_proj:1.844 [t=0.25s]
prediction: ['[CLS]. has lost premise in slack translation in it..fest the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
Attempt swap
[1600/2000] tot_loss=1.478 (perp=7.010, rec=0.075, cos=0.002), tot_loss_proj:1.839 [t=0.25s]
prediction: ['[CLS]. has lost premise in slack translation in it..fest the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
[1650/2000] tot_loss=1.468 (perp=7.010, rec=0.064, cos=0.002), tot_loss_proj:1.831 [t=0.24s]
prediction: ['[CLS]. has lost premise in slack translation in it..fest the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
Attempt swap
[1700/2000] tot_loss=1.471 (perp=7.010, rec=0.067, cos=0.002), tot_loss_proj:1.846 [t=0.25s]
prediction: ['[CLS]. has lost premise in slack translation in it..fest the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
Attempt swap
[1750/2000] tot_loss=1.475 (perp=7.010, rec=0.071, cos=0.002), tot_loss_proj:1.851 [t=0.24s]
prediction: ['[CLS]. has lost premise in slack translation in it..fest the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
[1800/2000] tot_loss=1.462 (perp=7.010, rec=0.058, cos=0.002), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS]. has lost premise in slack translation in it..fest the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
Attempt swap
[1850/2000] tot_loss=1.472 (perp=7.010, rec=0.068, cos=0.002), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS]. has lost premise in slack translation in it..fest the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.413 (perp=6.651, rec=0.081, cos=0.002), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS]fest has lost premise in slack translation in it... the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
[1950/2000] tot_loss=1.396 (perp=6.651, rec=0.064, cos=0.002), tot_loss_proj:1.783 [t=0.24s]
prediction: ['[CLS]fest has lost premise in slack translation in it... the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
Attempt swap
[2000/2000] tot_loss=1.397 (perp=6.651, rec=0.065, cos=0.002), tot_loss_proj:1.789 [t=0.24s]
prediction: ['[CLS]fest has lost premise in slack translation in it... the another fright in fright slack execution whichalicizes the absurdity of the hollywood routine [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS]. has the premise of translation slack in it..fest the another fright in fright slack execution whichalicizes the absurdity lost of hollywood routine [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 72.000 | r: 78.261
rouge2     | fm: 17.391 | p: 16.667 | r: 18.182
rougeL     | fm: 50.000 | p: 48.000 | r: 52.174
rougeLsum  | fm: 50.000 | p: 48.000 | r: 52.174
r1fm+r2fm = 92.391

[Aggregate metrics]:
rouge1     | fm: 90.805 | p: 90.565 | r: 91.186
rouge2     | fm: 58.692 | p: 58.628 | r: 58.889
rougeL     | fm: 78.659 | p: 78.408 | r: 78.961
rougeLsum  | fm: 78.485 | p: 78.249 | r: 78.723
r1fm+r2fm = 149.497

input #44 time: 0:09:44 | total time: 7:10:01


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9993981045144514
highest_index [0]
highest [0.9993981045144514]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.9814025163650513 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.93677818775177 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.9145281910896301 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.9122018218040466 for ['[CLS] look greater applications dating decay line learning reagan ata alley fact isn starboard thorne portion stepped women5 bee defense producing ł wingtlestation hold net festival [SEP]']
[Init] best rec loss: 0.9019213914871216 for ['[CLS] need invitation small cross hot no sk cello deep leader motions harry slide guest pity ash nepal rather ashleyinsman previous walt mclean prix van zoneition [SEP]']
[Init] best rec loss: 0.8711106777191162 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.8676222562789917 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.8668943643569946 for ['[CLS] letter fivetiv via v around skin tree murmured taste special single enclosed entrance military curtis joan borelanda football gentry status2 ku ( operated few whoa [SEP]']
[Init] best perm rec loss: 0.8638823628425598 for ['[CLS]tiv single special whoa tree operated gentry football enclosed ( fewlanda five curtis military v taste letter murmured bore around joan ku status2 entrance via skin [SEP]']
[Init] best perm rec loss: 0.8630584478378296 for ['[CLS] enclosed ( taste special murmured whoa letter v bore single via2tivlanda five military curtis gentry operated football entrance joan skin few tree status around ku [SEP]']
[Init] best perm rec loss: 0.8626331686973572 for ['[CLS] taste special murmured skin ( via aroundlanda military letter v enclosed football2 curtis five single entrance few operated whoa bore gentrytiv joan tree status ku [SEP]']
[Init] best perm rec loss: 0.8599068522453308 for ['[CLS] few special fivetiv ku joan around letter bore tree murmured enclosedlanda whoa football military entrance taste skin status gentry curtis via single v ( operated2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.594 (perp=11.244, rec=0.333, cos=0.013), tot_loss_proj:3.757 [t=0.24s]
prediction: ['[CLS] vamp - almost wanted arrested - start australian floors the, surface dirty institute shot - shoot yu hawk - kowalski back hotot beernainey action [SEP]']
[ 100/2000] tot_loss=2.085 (perp=9.225, rec=0.236, cos=0.005), tot_loss_proj:2.634 [t=0.24s]
prediction: ['[CLS] - - exercisel any than start - movements -, this wrong - shot - shooting bow stretch - poetry back bowel shoot quotesie exercise [SEP]']
[ 150/2000] tot_loss=2.154 (perp=9.836, rec=0.182, cos=0.004), tot_loss_proj:3.057 [t=0.24s]
prediction: ['[CLS] - - shelfl shoot than shelf - movements this, this bob - around - shooting bow than - poetry back bowel shootick - movements [SEP]']
[ 200/2000] tot_loss=2.237 (perp=10.386, rec=0.155, cos=0.004), tot_loss_proj:2.827 [t=0.25s]
prediction: ['[CLS] - - shelfl shoot than shelf - movements this, this long -el crime shoot bowshaft - shelf this gielmmickick movements [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.179 (perp=10.167, rec=0.143, cos=0.003), tot_loss_proj:2.782 [t=0.24s]
prediction: ['[CLS] - - -l shoot than shelf - movements this, this longelel crime drama bowshaft exercise shelf shelf gielmmicky movements [SEP]']
[ 300/2000] tot_loss=2.077 (perp=9.735, rec=0.128, cos=0.002), tot_loss_proj:2.729 [t=0.24s]
prediction: ['[CLS] - - -l shoot than shelf - movements this, this long -el crime drama bow long exercise shelf shelf gielmmicky movements [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.007 (perp=9.414, rec=0.122, cos=0.002), tot_loss_proj:2.792 [t=0.25s]
prediction: ['[CLS] - - -el shoot than shelf on movements this, this long shelf - crime drama bow long exercise - shelf gielmmicky movements [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.001 (perp=8.816, rec=0.231, cos=0.006), tot_loss_proj:2.496 [t=0.24s]
prediction: ['[CLS] - - - long shoot than shelf on movements this, this long shelf and crime drama bowel exercise - shelf gielmmicky movements [SEP]']
[ 450/2000] tot_loss=1.882 (perp=8.630, rec=0.154, cos=0.002), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] - - - long shoot than shelf on movements this, - long shelf and crime drama bowel exercise - shelf gielmmicky movements [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.822 (perp=8.450, rec=0.130, cos=0.002), tot_loss_proj:2.497 [t=0.25s]
prediction: ['[CLS] - - - long shoot than shelf, movements this on - long shelf and crime drama bowel exercise - shelf gielmmicky movements [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.858 (perp=8.581, rec=0.139, cos=0.002), tot_loss_proj:2.450 [t=0.25s]
prediction: ['[CLS] - - - long shoot than -, movements - on this long shelf and crime drama bow - exercise - shelf gielmmickick movements [SEP]']
[ 600/2000] tot_loss=1.877 (perp=8.736, rec=0.128, cos=0.001), tot_loss_proj:2.466 [t=0.24s]
prediction: ['[CLS] - - - point shoot than -, movements - on this long shelf and crime drama bow - exercise - shelf gielmmickick movements [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.788 (perp=8.361, rec=0.114, cos=0.001), tot_loss_proj:2.429 [t=0.25s]
prediction: ['[CLS] - - - point shoot than -, movements - on this long shelf and crime drama bow - exercise - shelf gielickmmick movements [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.751 (perp=8.172, rec=0.115, cos=0.002), tot_loss_proj:2.428 [t=0.25s]
prediction: ['[CLS] - - - point shoot than - - movements - on this long shelf and crime drama bow - exercise, shelf gielickmmick movements [SEP]']
[ 750/2000] tot_loss=1.737 (perp=8.172, rec=0.101, cos=0.001), tot_loss_proj:2.422 [t=0.24s]
prediction: ['[CLS] - - - point shoot than - - movements - on this long shelf and crime drama bow - exercise, shelf gielickmmick movements [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.696 (perp=7.912, rec=0.113, cos=0.001), tot_loss_proj:2.403 [t=0.24s]
prediction: ['[CLS] - - - point shoot than - - movements - on this long shelf shelf crime drama bow - exercise, and gielickmmick movements [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.656 (perp=7.699, rec=0.115, cos=0.001), tot_loss_proj:2.279 [t=0.25s]
prediction: ['[CLS] - - - point shoot than - - movements - on this long shelf any crime drama bow - exercise, and gimmickelick movements [SEP]']
[ 900/2000] tot_loss=1.637 (perp=7.699, rec=0.096, cos=0.001), tot_loss_proj:2.284 [t=0.25s]
prediction: ['[CLS] - - - point shoot than - - movements - on this long shelf any crime drama bow - exercise, and gimmickelick movements [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.681 (perp=7.898, rec=0.100, cos=0.002), tot_loss_proj:2.374 [t=0.24s]
prediction: ['[CLS] - - - shelf shoot than - - movements - on this long shelf point crime drama bow - exercise, and gimmickelick movements [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.586 (perp=7.502, rec=0.084, cos=0.001), tot_loss_proj:2.167 [t=0.25s]
prediction: ['[CLS] - - - point shoot than - - movements - on this long shelf shelf crime drama bow - exercise, and gimmickelick movements [SEP]']
[1050/2000] tot_loss=1.540 (perp=7.262, rec=0.086, cos=0.001), tot_loss_proj:2.084 [t=0.24s]
prediction: ['[CLS] - - - point shoot than - - movements - on this long shelf shelf crime drama bow - exercise, and gimmickely movements [SEP]']
Attempt swap
[1100/2000] tot_loss=1.542 (perp=7.262, rec=0.089, cos=0.001), tot_loss_proj:2.087 [t=0.25s]
prediction: ['[CLS] - - - point shoot than - - movements - on this long shelf shelf crime drama bow - exercise, and gimmickely movements [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.537 (perp=7.231, rec=0.089, cos=0.001), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] - - - point shoot than shelf - movements - on this long shelf - crime drama bow - exercise, and gimmickely movements [SEP]']
[1200/2000] tot_loss=1.505 (perp=7.094, rec=0.085, cos=0.001), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] - - - point shoot than gun - movements - on this long shelf - crime drama bow - exercise, and gimmickely movements [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.485 (perp=6.983, rec=0.088, cos=0.001), tot_loss_proj:2.007 [t=0.25s]
prediction: ['[CLS] - - - point gun than shoot - movements - on this long shelf - crime drama bow - exercise, and gimmickely movements [SEP]']
Attempt swap
[1300/2000] tot_loss=1.478 (perp=6.983, rec=0.080, cos=0.001), tot_loss_proj:2.016 [t=0.24s]
prediction: ['[CLS] - - - point gun than shoot - movements - on this long shelf - crime drama bow - exercise, and gimmickely movements [SEP]']
[1350/2000] tot_loss=1.482 (perp=6.983, rec=0.085, cos=0.001), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] - - - point gun than shoot - movements - on this long shelf - crime drama bow - exercise, and gimmickely movements [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.416 (perp=6.605, rec=0.094, cos=0.001), tot_loss_proj:1.953 [t=0.24s]
prediction: ['[CLS] - - - point gun than shoot - movements - on this long shelf - crime drama bowel - exercise, and gimmicky movements [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.383 (perp=6.436, rec=0.094, cos=0.001), tot_loss_proj:1.889 [t=0.24s]
prediction: ['[CLS] - - - point gun than shoot - exercise - on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
[1500/2000] tot_loss=1.380 (perp=6.436, rec=0.091, cos=0.001), tot_loss_proj:1.891 [t=0.24s]
prediction: ['[CLS] - - - point gun than shoot - exercise - on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
Attempt swap
[1550/2000] tot_loss=1.365 (perp=6.436, rec=0.077, cos=0.001), tot_loss_proj:1.894 [t=0.24s]
prediction: ['[CLS] - - - point gun than shoot - exercise - on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
Attempt swap
[1600/2000] tot_loss=1.378 (perp=6.436, rec=0.089, cos=0.001), tot_loss_proj:1.888 [t=0.24s]
prediction: ['[CLS] - - - point gun than shoot - exercise - on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
[1650/2000] tot_loss=1.374 (perp=6.436, rec=0.086, cos=0.001), tot_loss_proj:1.892 [t=0.24s]
prediction: ['[CLS] - - - point gun than shoot - exercise - on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.351 (perp=6.307, rec=0.088, cos=0.001), tot_loss_proj:1.884 [t=0.25s]
prediction: ['[CLS] - - - point gun than shoot - - exercise on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
Attempt swap
[1750/2000] tot_loss=1.343 (perp=6.307, rec=0.081, cos=0.001), tot_loss_proj:1.879 [t=0.24s]
prediction: ['[CLS] - - - point gun than shoot - - exercise on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
[1800/2000] tot_loss=1.350 (perp=6.307, rec=0.088, cos=0.001), tot_loss_proj:1.874 [t=0.24s]
prediction: ['[CLS] - - - point gun than shoot - - exercise on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
Attempt swap
[1850/2000] tot_loss=1.325 (perp=6.164, rec=0.091, cos=0.001), tot_loss_proj:1.823 [t=0.24s]
prediction: ['[CLS] - - - point back than shoot - - exercise on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
Attempt swap
[1900/2000] tot_loss=1.322 (perp=6.164, rec=0.088, cos=0.001), tot_loss_proj:1.823 [t=0.24s]
prediction: ['[CLS] - - - point back than shoot - - exercise on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
[1950/2000] tot_loss=1.321 (perp=6.164, rec=0.087, cos=0.001), tot_loss_proj:1.823 [t=0.24s]
prediction: ['[CLS] - - - point back than shoot - - exercise on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.323 (perp=6.164, rec=0.089, cos=0.001), tot_loss_proj:1.811 [t=0.24s]
prediction: ['[CLS] - - - point back than shoot - - exercise on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] - - - point gun than shoot - exercise - on this long shelf - crime drama bowel - movements, and gimmicky movements [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 23.529 | p: 23.529 | r: 23.529
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 112.418

[Aggregate metrics]:
rouge1     | fm: 90.679 | p: 90.501 | r: 91.027
rouge2     | fm: 58.280 | p: 58.107 | r: 58.457
rougeL     | fm: 77.928 | p: 77.746 | r: 78.215
rougeLsum  | fm: 77.753 | p: 77.537 | r: 77.979
r1fm+r2fm = 148.960

input #45 time: 0:09:45 | total time: 7:19:46


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9992705828001183
highest_index [0]
highest [0.9992705828001183]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9912108182907104 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9792644381523132 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 0.9478821158409119 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9439657926559448 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9418700933456421 for ['[CLS] figures w direction pedrich newspaper [SEP]']
[Init] best rec loss: 0.9365411996841431 for ['[CLS] sacked age s between pack lowell [SEP]']
[Init] best rec loss: 0.933304488658905 for ['[CLS] once definition delgnoeousosed [SEP]']
[Init] best rec loss: 0.9163591265678406 for ['[CLS] four no and canada reed donald [SEP]']
[Init] best rec loss: 0.9133361577987671 for ['[CLS] serie templebie half succeeding coast [SEP]']
[Init] best perm rec loss: 0.9114199876785278 for ['[CLS] coast succeedingbie temple half serie [SEP]']
[Init] best perm rec loss: 0.910995364189148 for ['[CLS] serie coast succeedingbie half temple [SEP]']
[Init] best perm rec loss: 0.9107672572135925 for ['[CLS] serie succeeding coastbie half temple [SEP]']
[Init] best perm rec loss: 0.9105656743049622 for ['[CLS] succeedingbie serie half coast temple [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.912 (perp=13.417, rec=0.225, cos=0.004), tot_loss_proj:3.804 [t=0.24s]
prediction: ['[CLS] visually « ᅩ striking knows striking [SEP]']
[ 100/2000] tot_loss=2.037 (perp=9.370, rec=0.160, cos=0.003), tot_loss_proj:2.264 [t=0.24s]
prediction: ['[CLS] visually striking slick slickly visually [SEP]']
[ 150/2000] tot_loss=2.183 (perp=10.263, rec=0.128, cos=0.003), tot_loss_proj:2.533 [t=0.24s]
prediction: ['[CLS] visually striking slick stagedly slick [SEP]']
[ 200/2000] tot_loss=1.706 (perp=8.043, rec=0.095, cos=0.002), tot_loss_proj:1.876 [t=0.24s]
prediction: ['[CLS] visually strikingly stagedly slick [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.376 (perp=6.442, rec=0.086, cos=0.002), tot_loss_proj:1.474 [t=0.24s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[ 300/2000] tot_loss=1.267 (perp=5.916, rec=0.082, cos=0.002), tot_loss_proj:1.251 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.254 (perp=5.916, rec=0.069, cos=0.002), tot_loss_proj:1.242 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.254 (perp=5.916, rec=0.069, cos=0.002), tot_loss_proj:1.248 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 450/2000] tot_loss=1.254 (perp=5.916, rec=0.068, cos=0.002), tot_loss_proj:1.252 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.248 (perp=5.916, rec=0.063, cos=0.002), tot_loss_proj:1.259 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.256 (perp=5.916, rec=0.071, cos=0.002), tot_loss_proj:1.244 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 600/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.002), tot_loss_proj:1.248 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.245 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.255 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.241 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.250 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 750/2000] tot_loss=1.251 (perp=5.916, rec=0.066, cos=0.001), tot_loss_proj:1.257 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.236 (perp=5.916, rec=0.052, cos=0.001), tot_loss_proj:1.243 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.246 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.250 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.238 (perp=5.916, rec=0.053, cos=0.001), tot_loss_proj:1.247 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.248 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.244 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.262 (perp=5.916, rec=0.078, cos=0.001), tot_loss_proj:1.256 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.242 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.251 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.001), tot_loss_proj:1.251 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.241 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.248 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.250 (perp=5.916, rec=0.066, cos=0.001), tot_loss_proj:1.246 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.249 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.246 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.239 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.242 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.253 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.248 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.237 (perp=5.916, rec=0.052, cos=0.001), tot_loss_proj:1.238 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.245 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.257 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.251 (perp=5.916, rec=0.067, cos=0.001), tot_loss_proj:1.258 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.256 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.249 (perp=5.916, rec=0.065, cos=0.001), tot_loss_proj:1.246 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.250 (perp=5.916, rec=0.066, cos=0.001), tot_loss_proj:1.253 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.242 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.261 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.248 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.246 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.248 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.247 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.253 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.251 (perp=5.916, rec=0.066, cos=0.001), tot_loss_proj:1.243 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.973 | p: 90.744 | r: 91.291
rouge2     | fm: 59.216 | p: 59.148 | r: 59.332
rougeL     | fm: 78.240 | p: 78.011 | r: 78.539
rougeLsum  | fm: 78.157 | p: 77.899 | r: 78.423
r1fm+r2fm = 150.189

input #46 time: 0:09:32 | total time: 7:29:18


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9992061235456344
highest_index [0]
highest [0.9992061235456344]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6903454661369324 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6838828325271606 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6738404035568237 for ['[CLS] network biceps truth [SEP]']
[Init] best perm rec loss: 0.672116756439209 for ['[CLS] truth network biceps [SEP]']
[Init] best perm rec loss: 0.6701898574829102 for ['[CLS] truth biceps network [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.737 (perp=12.488, rec=0.217, cos=0.022), tot_loss_proj:3.348 [t=0.24s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 100/2000] tot_loss=2.634 (perp=12.488, rec=0.127, cos=0.009), tot_loss_proj:3.387 [t=0.24s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=2.623 (perp=12.488, rec=0.105, cos=0.020), tot_loss_proj:3.415 [t=0.24s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 200/2000] tot_loss=2.537 (perp=12.148, rec=0.100, cos=0.008), tot_loss_proj:3.026 [t=0.24s]
prediction: ['[CLS]right down transparent [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.848 (perp=8.803, rec=0.084, cos=0.004), tot_loss_proj:1.889 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 300/2000] tot_loss=1.836 (perp=8.803, rec=0.067, cos=0.009), tot_loss_proj:1.891 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.867 (perp=8.803, rec=0.069, cos=0.038), tot_loss_proj:1.879 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.826 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.878 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=1.820 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.871 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.841 (perp=8.803, rec=0.067, cos=0.014), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.820 (perp=8.803, rec=0.057, cos=0.003), tot_loss_proj:1.886 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.832 (perp=8.803, rec=0.067, cos=0.004), tot_loss_proj:1.885 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.811 (perp=8.803, rec=0.049, cos=0.001), tot_loss_proj:1.892 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.824 (perp=8.803, rec=0.057, cos=0.006), tot_loss_proj:1.889 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.831 (perp=8.803, rec=0.068, cos=0.003), tot_loss_proj:1.880 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.819 (perp=8.803, rec=0.055, cos=0.003), tot_loss_proj:1.881 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.830 (perp=8.803, rec=0.068, cos=0.002), tot_loss_proj:1.884 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.829 (perp=8.803, rec=0.067, cos=0.002), tot_loss_proj:1.878 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.830 (perp=8.803, rec=0.068, cos=0.001), tot_loss_proj:1.896 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.001), tot_loss_proj:1.876 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.882 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.804 (perp=8.803, rec=0.042, cos=0.002), tot_loss_proj:1.876 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.817 (perp=8.803, rec=0.055, cos=0.002), tot_loss_proj:1.896 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.808 (perp=8.803, rec=0.046, cos=0.002), tot_loss_proj:1.877 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.815 (perp=8.803, rec=0.053, cos=0.002), tot_loss_proj:1.888 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.825 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.877 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.881 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.835 (perp=8.803, rec=0.073, cos=0.002), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.885 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.816 (perp=8.803, rec=0.054, cos=0.002), tot_loss_proj:1.891 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.825 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.877 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.880 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.874 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.828 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.879 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.828 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.873 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.820 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.885 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.828 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.825 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.872 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.823 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.865 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.825 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.883 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.090 | p: 90.856 | r: 91.407
rouge2     | fm: 60.045 | p: 59.942 | r: 60.211
rougeL     | fm: 78.874 | p: 78.619 | r: 79.170
rougeLsum  | fm: 78.634 | p: 78.477 | r: 78.859
r1fm+r2fm = 151.136

input #47 time: 0:09:31 | total time: 7:38:50


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9993043978769418
highest_index [0]
highest [0.9993043978769418]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.9514000415802002 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.9303548336029053 for ['[CLS] general deathstle air [SEP]']
[Init] best rec loss: 0.9121167063713074 for ['[CLS] indians * progress elevator [SEP]']
[Init] best rec loss: 0.895457923412323 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 0.8773390650749207 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.8653813004493713 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8400688171386719 for ['[CLS]lu natural horizontal work [SEP]']
[Init] best rec loss: 0.7992453575134277 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7948036193847656 for ['[CLS]tutedine graveyard runs [SEP]']
[Init] best perm rec loss: 0.7941678166389465 for ['[CLS]tute graveyarddine runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.674 (perp=12.473, rec=0.174, cos=0.005), tot_loss_proj:2.922 [t=0.23s]
prediction: ['[CLS] rotting rotting rottingbell [SEP]']
[ 100/2000] tot_loss=2.806 (perp=13.479, rec=0.107, cos=0.003), tot_loss_proj:3.029 [t=0.24s]
prediction: ['[CLS] rotting under rottingbell [SEP]']
[ 150/2000] tot_loss=2.785 (perp=13.479, rec=0.087, cos=0.002), tot_loss_proj:3.017 [t=0.24s]
prediction: ['[CLS] rotting under rottingbell [SEP]']
[ 200/2000] tot_loss=2.866 (perp=13.991, rec=0.067, cos=0.002), tot_loss_proj:3.083 [t=0.24s]
prediction: ['[CLS] rotting underybell [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.488 (perp=7.107, rec=0.066, cos=0.001), tot_loss_proj:1.488 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 300/2000] tot_loss=1.482 (perp=7.107, rec=0.059, cos=0.001), tot_loss_proj:1.490 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.478 (perp=7.107, rec=0.056, cos=0.001), tot_loss_proj:1.491 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.487 (perp=7.107, rec=0.065, cos=0.001), tot_loss_proj:1.483 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 450/2000] tot_loss=1.487 (perp=7.107, rec=0.064, cos=0.001), tot_loss_proj:1.492 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.476 (perp=7.107, rec=0.053, cos=0.001), tot_loss_proj:1.471 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.486 (perp=7.107, rec=0.063, cos=0.001), tot_loss_proj:1.474 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 600/2000] tot_loss=1.495 (perp=7.107, rec=0.072, cos=0.001), tot_loss_proj:1.484 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.478 (perp=7.107, rec=0.055, cos=0.001), tot_loss_proj:1.486 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.484 (perp=7.107, rec=0.061, cos=0.001), tot_loss_proj:1.480 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 750/2000] tot_loss=1.488 (perp=7.107, rec=0.065, cos=0.001), tot_loss_proj:1.478 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.486 (perp=7.107, rec=0.063, cos=0.001), tot_loss_proj:1.484 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.484 (perp=7.107, rec=0.061, cos=0.001), tot_loss_proj:1.475 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 900/2000] tot_loss=1.486 (perp=7.107, rec=0.064, cos=0.001), tot_loss_proj:1.483 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.483 (perp=7.107, rec=0.060, cos=0.001), tot_loss_proj:1.483 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.481 (perp=7.107, rec=0.058, cos=0.001), tot_loss_proj:1.485 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1050/2000] tot_loss=1.483 (perp=7.107, rec=0.060, cos=0.001), tot_loss_proj:1.474 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.489 (perp=7.107, rec=0.066, cos=0.001), tot_loss_proj:1.482 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.473 (perp=7.107, rec=0.050, cos=0.001), tot_loss_proj:1.486 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1200/2000] tot_loss=1.488 (perp=7.107, rec=0.066, cos=0.001), tot_loss_proj:1.494 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.485 (perp=7.107, rec=0.063, cos=0.001), tot_loss_proj:1.484 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.479 (perp=7.107, rec=0.056, cos=0.001), tot_loss_proj:1.493 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1350/2000] tot_loss=1.494 (perp=7.107, rec=0.071, cos=0.001), tot_loss_proj:1.496 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.489 (perp=7.107, rec=0.066, cos=0.001), tot_loss_proj:1.493 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.485 (perp=7.107, rec=0.062, cos=0.001), tot_loss_proj:1.482 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1500/2000] tot_loss=1.476 (perp=7.107, rec=0.053, cos=0.001), tot_loss_proj:1.500 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.496 (perp=7.107, rec=0.073, cos=0.001), tot_loss_proj:1.478 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.477 (perp=7.107, rec=0.055, cos=0.001), tot_loss_proj:1.481 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1650/2000] tot_loss=1.485 (perp=7.107, rec=0.062, cos=0.001), tot_loss_proj:1.485 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.475 (perp=7.107, rec=0.052, cos=0.001), tot_loss_proj:1.478 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.475 (perp=7.107, rec=0.053, cos=0.001), tot_loss_proj:1.487 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1800/2000] tot_loss=1.480 (perp=7.107, rec=0.057, cos=0.001), tot_loss_proj:1.482 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.484 (perp=7.107, rec=0.062, cos=0.001), tot_loss_proj:1.487 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.470 (perp=7.107, rec=0.047, cos=0.001), tot_loss_proj:1.486 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1950/2000] tot_loss=1.483 (perp=7.107, rec=0.061, cos=0.001), tot_loss_proj:1.473 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.482 (perp=7.107, rec=0.059, cos=0.001), tot_loss_proj:1.466 [t=0.24s]
prediction: ['[CLS] rotting underbelly [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbelly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.344 | p: 91.075 | r: 91.680
rouge2     | fm: 60.683 | p: 60.589 | r: 60.807
rougeL     | fm: 79.169 | p: 78.976 | r: 79.441
rougeLsum  | fm: 79.134 | p: 78.916 | r: 79.395
r1fm+r2fm = 152.027

input #48 time: 0:09:29 | total time: 7:48:20


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9992283885028335
highest_index [0]
highest [0.9992283885028335]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8313477635383606 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7865213751792908 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7855995297431946 for ['[CLS] painted exactly tips haunt unknown going wrong matches until tamillaw ambulance [SEP]']
[Init] best rec loss: 0.7833266854286194 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7775081992149353 for ['[CLS] auto indies pitch after walk lime *wled nike contested fit justin [SEP]']
[Init] best rec loss: 0.7649335861206055 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best rec loss: 0.7577332258224487 for ['[CLS] trick jose college legs jockey baby tongue processiza during gmina patrick [SEP]']
[Init] best perm rec loss: 0.7532427906990051 for ['[CLS] legs jose trick tongue gmina collegeiza during jockey patrick process baby [SEP]']
[Init] best perm rec loss: 0.7514466047286987 for ['[CLS] joseiza legs tongue trick jockey college gmina during process baby patrick [SEP]']
[Init] best perm rec loss: 0.7511851191520691 for ['[CLS] process gmina jockey legs during jose baby tongue patrickiza trick college [SEP]']
[Init] best perm rec loss: 0.7511382102966309 for ['[CLS] trick jose gmina legs collegeiza baby during tongue process patrick jockey [SEP]']
[Init] best perm rec loss: 0.7508964538574219 for ['[CLS] legs college process patrick trick jose babyiza gmina tongue during jockey [SEP]']
[Init] best perm rec loss: 0.7492689490318298 for ['[CLS] jose process legs during baby gmina jockey trick college tongue patrickiza [SEP]']
[Init] best perm rec loss: 0.7477436661720276 for ['[CLS]iza patrick tongue college trick process during legs gmina jose jockey baby [SEP]']
[Init] best perm rec loss: 0.7475663423538208 for ['[CLS]iza process patrick trick jockey tongue legs during college baby jose gmina [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.997 (perp=13.258, rec=0.315, cos=0.030), tot_loss_proj:4.095 [t=0.24s]
prediction: ['[CLS] edgar relax woman tonight female contempt humans. person grade stopped could [SEP]']
[ 100/2000] tot_loss=2.586 (perp=11.851, rec=0.206, cos=0.010), tot_loss_proj:3.664 [t=0.24s]
prediction: ['[CLS] edgar relax female contempt population contempt values. more grade stopped could [SEP]']
[ 150/2000] tot_loss=2.375 (perp=11.037, rec=0.162, cos=0.006), tot_loss_proj:3.554 [t=0.24s]
prediction: ['[CLS] can relax female contempt single contemptuous. more grade population possibly [SEP]']
[ 200/2000] tot_loss=2.344 (perp=10.992, rec=0.140, cos=0.006), tot_loss_proj:3.380 [t=0.24s]
prediction: ['[CLS] could relax female contempt single contemptuous. more grade population possibly [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.175 (perp=11.752, rec=0.535, cos=0.289), tot_loss_proj:3.376 [t=0.24s]
prediction: ['[CLS] [SEP] career female contempt single contemptuous [SEP] more possibly population learning [SEP]']
[ 300/2000] tot_loss=2.610 (perp=11.036, rec=0.341, cos=0.062), tot_loss_proj:3.139 [t=0.24s]
prediction: ['[CLS] [SEP] casual female excessive single contemptuous [SEP] more possibly population jewish [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.553 (perp=11.165, rec=0.289, cos=0.031), tot_loss_proj:3.175 [t=0.24s]
prediction: ['[CLS] [SEP] live female excessive single contemptuous [SEP] characters possibly more society [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.408 (perp=10.595, rec=0.265, cos=0.024), tot_loss_proj:3.204 [t=0.24s]
prediction: ['[CLS] [SEP] live female ms possibly more single contemptuous [SEP] female jewish [SEP]']
[ 450/2000] tot_loss=2.367 (perp=10.595, rec=0.232, cos=0.016), tot_loss_proj:3.205 [t=0.24s]
prediction: ['[CLS] [SEP] live female ms possibly more single contemptuous [SEP] female jewish [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.291 (perp=10.250, rec=0.227, cos=0.014), tot_loss_proj:3.160 [t=0.24s]
prediction: ['[CLS] [SEP] live female ms possibly more single contemptuous [SEP] development female [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.264 (perp=9.561, rec=0.309, cos=0.043), tot_loss_proj:2.754 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single thirty female usually contemptuous. meat female [SEP]']
[ 600/2000] tot_loss=2.183 (perp=9.561, rec=0.250, cos=0.022), tot_loss_proj:2.759 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single thirty female usually contemptuous. meat female [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.969 (perp=8.593, rec=0.232, cos=0.018), tot_loss_proj:2.702 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat female usually contemptuous. thirty female [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.916 (perp=8.327, rec=0.232, cos=0.019), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
[ 750/2000] tot_loss=1.903 (perp=8.327, rec=0.222, cos=0.015), tot_loss_proj:2.594 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.894 (perp=8.327, rec=0.215, cos=0.014), tot_loss_proj:2.591 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.894 (perp=8.327, rec=0.215, cos=0.014), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
[ 900/2000] tot_loss=1.888 (perp=8.327, rec=0.210, cos=0.013), tot_loss_proj:2.586 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.887 (perp=8.327, rec=0.209, cos=0.013), tot_loss_proj:2.592 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1000/2000] tot_loss=1.879 (perp=8.327, rec=0.201, cos=0.012), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
[1050/2000] tot_loss=1.875 (perp=8.327, rec=0.198, cos=0.012), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1100/2000] tot_loss=1.873 (perp=8.327, rec=0.196, cos=0.012), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1150/2000] tot_loss=1.871 (perp=8.327, rec=0.194, cos=0.011), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
[1200/2000] tot_loss=1.872 (perp=8.327, rec=0.195, cos=0.011), tot_loss_proj:2.593 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1250/2000] tot_loss=1.869 (perp=8.327, rec=0.193, cos=0.011), tot_loss_proj:2.583 [t=0.25s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1300/2000] tot_loss=1.867 (perp=8.327, rec=0.191, cos=0.011), tot_loss_proj:2.584 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
[1350/2000] tot_loss=1.858 (perp=8.327, rec=0.183, cos=0.011), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1400/2000] tot_loss=1.864 (perp=8.327, rec=0.189, cos=0.010), tot_loss_proj:2.591 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1450/2000] tot_loss=1.866 (perp=8.327, rec=0.190, cos=0.010), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
[1500/2000] tot_loss=1.861 (perp=8.327, rec=0.186, cos=0.010), tot_loss_proj:2.591 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1550/2000] tot_loss=1.865 (perp=8.327, rec=0.190, cos=0.010), tot_loss_proj:2.588 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1600/2000] tot_loss=1.861 (perp=8.327, rec=0.186, cos=0.010), tot_loss_proj:2.593 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
[1650/2000] tot_loss=1.864 (perp=8.327, rec=0.189, cos=0.010), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1700/2000] tot_loss=1.868 (perp=8.327, rec=0.192, cos=0.010), tot_loss_proj:2.596 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1750/2000] tot_loss=1.863 (perp=8.327, rec=0.188, cos=0.010), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
[1800/2000] tot_loss=1.860 (perp=8.327, rec=0.185, cos=0.010), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1850/2000] tot_loss=1.856 (perp=8.327, rec=0.181, cos=0.010), tot_loss_proj:2.592 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[1900/2000] tot_loss=1.854 (perp=8.327, rec=0.179, cos=0.010), tot_loss_proj:2.592 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
[1950/2000] tot_loss=1.864 (perp=8.327, rec=0.188, cos=0.010), tot_loss_proj:2.584 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Attempt swap
[2000/2000] tot_loss=1.853 (perp=8.327, rec=0.179, cos=0.010), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] [SEP] possibly more single meat contemptuous. thirty female particularly female [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] could relax female contempt single contemptuous. more grade population possibly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 9.091 | p: 9.091 | r: 9.091
rougeL     | fm: 41.667 | p: 41.667 | r: 41.667
rougeLsum  | fm: 41.667 | p: 41.667 | r: 41.667
r1fm+r2fm = 84.091

[Aggregate metrics]:
rouge1     | fm: 90.997 | p: 90.769 | r: 91.303
rouge2     | fm: 59.820 | p: 59.715 | r: 59.933
rougeL     | fm: 78.403 | p: 78.203 | r: 78.660
rougeLsum  | fm: 78.371 | p: 78.166 | r: 78.592
r1fm+r2fm = 150.817

input #49 time: 0:09:34 | total time: 7:57:55


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.999284077484796
highest_index [0]
highest [0.999284077484796]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.9135558009147644 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8380478620529175 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.8375792503356934 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7549297213554382 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7542427182197571 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best perm rec loss: 0.7526724338531494 for ['[CLS] bridgetievinghamlent red by crisis accordance night [SEP]']
[Init] best perm rec loss: 0.7519044876098633 for ['[CLS]ieving byham crisis red accordance night bridgetlent [SEP]']
[Init] best perm rec loss: 0.7473711967468262 for ['[CLS] redham crisislent accordanceieving night bridget by [SEP]']
[Init] best perm rec loss: 0.7473464608192444 for ['[CLS] redlent night crisis accordanceieving by bridgetham [SEP]']
[Init] best perm rec loss: 0.74727863073349 for ['[CLS]lentham nightieving red accordance by crisis bridget [SEP]']
[Init] best perm rec loss: 0.7469528913497925 for ['[CLS] nightlent crisisham accordance bridgetieving red by [SEP]']
[Init] best perm rec loss: 0.7462561130523682 for ['[CLS] night byieving accordancelent crisis red bridgetham [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.584 (perp=10.882, rec=0.371, cos=0.036), tot_loss_proj:3.927 [t=0.24s]
prediction: ['[CLS] momentishly clever class swedish judging clever less half [SEP]']
[ 100/2000] tot_loss=2.449 (perp=10.591, rec=0.310, cos=0.021), tot_loss_proj:3.219 [t=0.24s]
prediction: ['[CLS] unishly clever ` english seeing clever too half [SEP]']
[ 150/2000] tot_loss=2.481 (perp=10.941, rec=0.276, cos=0.016), tot_loss_proj:3.273 [t=0.24s]
prediction: ['[CLS] what surprise clever ` english by clever too half [SEP]']
[ 200/2000] tot_loss=2.486 (perp=11.037, rec=0.257, cos=0.021), tot_loss_proj:3.118 [t=0.24s]
prediction: ['[CLS] what call clever ` english by considers too half [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.321 (perp=10.615, rec=0.190, cos=0.008), tot_loss_proj:3.649 [t=0.25s]
prediction: ['[CLS] what clever call ` english by call too half [SEP]']
[ 300/2000] tot_loss=2.227 (perp=10.615, rec=0.101, cos=0.003), tot_loss_proj:3.653 [t=0.25s]
prediction: ['[CLS] what clever call ` english by call too half [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.075 (perp=9.941, rec=0.085, cos=0.002), tot_loss_proj:3.131 [t=0.24s]
prediction: ['[CLS] what clever call ` english too call by half [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.057 (perp=9.941, rec=0.067, cos=0.002), tot_loss_proj:3.121 [t=0.24s]
prediction: ['[CLS] what clever call ` english too call by half [SEP]']
[ 450/2000] tot_loss=2.068 (perp=9.941, rec=0.079, cos=0.002), tot_loss_proj:3.121 [t=0.24s]
prediction: ['[CLS] what clever call ` english too call by half [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.068 (perp=9.941, rec=0.077, cos=0.003), tot_loss_proj:3.121 [t=0.24s]
prediction: ['[CLS] what clever call ` english too call by half [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.169 (perp=10.435, rec=0.080, cos=0.003), tot_loss_proj:3.043 [t=0.24s]
prediction: ['[CLS] what ` call clever english too call by half [SEP]']
[ 600/2000] tot_loss=2.163 (perp=10.435, rec=0.075, cos=0.002), tot_loss_proj:3.037 [t=0.24s]
prediction: ['[CLS] what ` call clever english too call by half [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.065 (perp=9.906, rec=0.082, cos=0.002), tot_loss_proj:3.192 [t=0.24s]
prediction: ['[CLS] what ` english clever call too call by half [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.058 (perp=9.906, rec=0.075, cos=0.001), tot_loss_proj:3.188 [t=0.24s]
prediction: ['[CLS] what ` english clever call too call by half [SEP]']
[ 750/2000] tot_loss=2.052 (perp=9.906, rec=0.069, cos=0.001), tot_loss_proj:3.188 [t=0.24s]
prediction: ['[CLS] what ` english clever call too call by half [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.056 (perp=9.906, rec=0.073, cos=0.001), tot_loss_proj:3.190 [t=0.24s]
prediction: ['[CLS] what ` english clever call too call by half [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.009 (perp=9.676, rec=0.072, cos=0.002), tot_loss_proj:2.498 [t=0.24s]
prediction: ['[CLS] what ` english call its too clever by half [SEP]']
[ 900/2000] tot_loss=2.007 (perp=9.676, rec=0.070, cos=0.001), tot_loss_proj:2.493 [t=0.24s]
prediction: ['[CLS] what ` english call its too clever by half [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.954 (perp=9.431, rec=0.067, cos=0.001), tot_loss_proj:2.375 [t=0.24s]
prediction: ['[CLS] what ` english call too clever by the half [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.743 (perp=8.302, rec=0.080, cos=0.003), tot_loss_proj:2.072 [t=0.25s]
prediction: ['[CLS] what the english call too clever by ` half [SEP]']
[1050/2000] tot_loss=1.730 (perp=8.302, rec=0.068, cos=0.002), tot_loss_proj:2.064 [t=0.24s]
prediction: ['[CLS] what the english call too clever by ` half [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.710 (perp=8.182, rec=0.072, cos=0.001), tot_loss_proj:2.053 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1150/2000] tot_loss=1.718 (perp=8.182, rec=0.081, cos=0.001), tot_loss_proj:2.048 [t=0.22s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
[1200/2000] tot_loss=1.702 (perp=8.182, rec=0.064, cos=0.001), tot_loss_proj:2.052 [t=0.22s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1250/2000] tot_loss=1.705 (perp=8.182, rec=0.067, cos=0.001), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1300/2000] tot_loss=1.704 (perp=8.182, rec=0.066, cos=0.001), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
[1350/2000] tot_loss=1.707 (perp=8.182, rec=0.069, cos=0.001), tot_loss_proj:2.048 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1400/2000] tot_loss=1.715 (perp=8.182, rec=0.077, cos=0.001), tot_loss_proj:2.055 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1450/2000] tot_loss=1.707 (perp=8.182, rec=0.069, cos=0.001), tot_loss_proj:2.052 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
[1500/2000] tot_loss=1.703 (perp=8.182, rec=0.066, cos=0.001), tot_loss_proj:2.052 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1550/2000] tot_loss=1.704 (perp=8.182, rec=0.066, cos=0.001), tot_loss_proj:2.049 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1600/2000] tot_loss=1.704 (perp=8.182, rec=0.066, cos=0.001), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
[1650/2000] tot_loss=1.709 (perp=8.182, rec=0.071, cos=0.001), tot_loss_proj:2.057 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1700/2000] tot_loss=1.704 (perp=8.182, rec=0.066, cos=0.001), tot_loss_proj:2.056 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1750/2000] tot_loss=1.708 (perp=8.182, rec=0.070, cos=0.001), tot_loss_proj:2.047 [t=0.22s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
[1800/2000] tot_loss=1.705 (perp=8.182, rec=0.067, cos=0.001), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1850/2000] tot_loss=1.705 (perp=8.182, rec=0.067, cos=0.001), tot_loss_proj:2.051 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[1900/2000] tot_loss=1.714 (perp=8.182, rec=0.076, cos=0.001), tot_loss_proj:2.055 [t=0.22s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
[1950/2000] tot_loss=1.705 (perp=8.182, rec=0.067, cos=0.001), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Attempt swap
[2000/2000] tot_loss=1.705 (perp=8.182, rec=0.067, cos=0.001), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] what the english call too clever ` by half [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what the english call too clever ` by half [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.143 | p: 90.997 | r: 91.432
rouge2     | fm: 60.597 | p: 60.471 | r: 60.753
rougeL     | fm: 78.954 | p: 78.711 | r: 79.205
rougeLsum  | fm: 78.770 | p: 78.625 | r: 79.020
r1fm+r2fm = 151.740

input #50 time: 0:09:24 | total time: 8:07:19


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9992547713036274
highest_index [0]
highest [0.9992547713036274]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.8252744078636169 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7898684740066528 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.739183247089386 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7309952974319458 for ['[CLS] join paying nonsense thought secret mine sans fields sara stench [SEP]']
[Init] best rec loss: 0.7296013236045837 for ['[CLS] lying acceptance [MASK] longer fence hotel rocking view knocked iaaf [SEP]']
[Init] best rec loss: 0.719580888748169 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7093055844306946 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 0.7078049778938293 for ['[CLS] disappointed market in toured literary watching once renamedrak medium [SEP]']
[Init] best perm rec loss: 0.7040138840675354 for ['[CLS] in toured once renamed medium watching market disappointed literaryrak [SEP]']
[Init] best perm rec loss: 0.7027232050895691 for ['[CLS] market mediumrak in disappointed once watching literary toured renamed [SEP]']
[Init] best perm rec loss: 0.702092707157135 for ['[CLS]rak once toured market watching renamed disappointed medium literary in [SEP]']
[Init] best perm rec loss: 0.7017946243286133 for ['[CLS] watching disappointed literaryrak once in renamed toured market medium [SEP]']
[Init] best perm rec loss: 0.700471043586731 for ['[CLS] market toured watching in disappointed renamed medium once literaryrak [SEP]']
[Init] best perm rec loss: 0.7004427313804626 for ['[CLS] toured watching disappointed once market literaryrak renamed medium in [SEP]']
[Init] best perm rec loss: 0.6999508738517761 for ['[CLS] toured renamed disappointed market once literary watching inrak medium [SEP]']
[Init] best perm rec loss: 0.6995094418525696 for ['[CLS] watching inrak renamed medium disappointed toured once market literary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.108 (perp=13.636, rec=0.346, cos=0.034), tot_loss_proj:3.839 [t=0.22s]
prediction: ['[CLS] sucks sucks few sucks funny funny [SEP] funnyumb s [SEP]']
[ 100/2000] tot_loss=2.183 (perp=9.779, rec=0.213, cos=0.014), tot_loss_proj:2.846 [t=0.22s]
prediction: ['[CLS] sucks sucks.? funny funny meter moment but is [SEP]']
[ 150/2000] tot_loss=2.234 (perp=10.384, rec=0.150, cos=0.007), tot_loss_proj:3.022 [t=0.22s]
prediction: ['[CLS] has sucks or or funny funny meter moment but. [SEP]']
[ 200/2000] tot_loss=1.818 (perp=8.537, rec=0.107, cos=0.004), tot_loss_proj:2.769 [t=0.22s]
prediction: ['[CLS] has sucks, or funny funny two moment but. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.843 (perp=8.690, rec=0.101, cos=0.004), tot_loss_proj:2.787 [t=0.22s]
prediction: ['[CLS] has sucks a or funny two moment but two. [SEP]']
[ 300/2000] tot_loss=1.822 (perp=8.690, rec=0.082, cos=0.002), tot_loss_proj:2.780 [t=0.22s]
prediction: ['[CLS] has sucks a or funny two moment but two. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.518 (perp=7.193, rec=0.077, cos=0.002), tot_loss_proj:2.387 [t=0.23s]
prediction: ['[CLS] has sucks a but funny two moment or two. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.424 (perp=6.693, rec=0.084, cos=0.002), tot_loss_proj:1.990 [t=0.22s]
prediction: ['[CLS] has sucks but a funny two moment or two. [SEP]']
[ 450/2000] tot_loss=1.423 (perp=6.693, rec=0.083, cos=0.002), tot_loss_proj:1.991 [t=0.22s]
prediction: ['[CLS] has sucks but a funny two moment or two. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.362 (perp=6.272, rec=0.099, cos=0.008), tot_loss_proj:1.889 [t=0.23s]
prediction: ['[CLS] double has sucks but a funny moment or two. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.349 (perp=6.272, rec=0.090, cos=0.005), tot_loss_proj:1.890 [t=0.22s]
prediction: ['[CLS] double has sucks but a funny moment or two. [SEP]']
[ 600/2000] tot_loss=1.401 (perp=6.613, rec=0.076, cos=0.003), tot_loss_proj:1.956 [t=0.23s]
prediction: ['[CLS] double has sucks but a funny moment or two, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.396 (perp=6.613, rec=0.070, cos=0.003), tot_loss_proj:1.953 [t=0.23s]
prediction: ['[CLS] double has sucks but a funny moment or two, [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.323 (perp=6.191, rec=0.081, cos=0.003), tot_loss_proj:1.506 [t=0.23s]
prediction: ['[CLS] double sucks but has a funny moment or two, [SEP]']
[ 750/2000] tot_loss=1.295 (perp=6.036, rec=0.085, cos=0.003), tot_loss_proj:1.774 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.290 (perp=6.036, rec=0.081, cos=0.003), tot_loss_proj:1.772 [t=0.23s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.282 (perp=6.036, rec=0.073, cos=0.002), tot_loss_proj:1.772 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
[ 900/2000] tot_loss=1.284 (perp=6.036, rec=0.075, cos=0.002), tot_loss_proj:1.762 [t=0.23s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.289 (perp=6.036, rec=0.079, cos=0.002), tot_loss_proj:1.771 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.289 (perp=6.036, rec=0.080, cos=0.002), tot_loss_proj:1.765 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
[1050/2000] tot_loss=1.288 (perp=6.036, rec=0.079, cos=0.002), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.283 (perp=6.036, rec=0.074, cos=0.002), tot_loss_proj:1.766 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.290 (perp=6.036, rec=0.081, cos=0.002), tot_loss_proj:1.773 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
[1200/2000] tot_loss=1.276 (perp=6.036, rec=0.067, cos=0.002), tot_loss_proj:1.761 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.281 (perp=6.036, rec=0.072, cos=0.002), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.283 (perp=6.036, rec=0.074, cos=0.002), tot_loss_proj:1.766 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
[1350/2000] tot_loss=1.281 (perp=6.036, rec=0.072, cos=0.002), tot_loss_proj:1.768 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.286 (perp=6.036, rec=0.077, cos=0.002), tot_loss_proj:1.771 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.284 (perp=6.036, rec=0.075, cos=0.002), tot_loss_proj:1.773 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
[1500/2000] tot_loss=1.286 (perp=6.036, rec=0.077, cos=0.002), tot_loss_proj:1.768 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.283 (perp=6.036, rec=0.074, cos=0.002), tot_loss_proj:1.776 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.282 (perp=6.036, rec=0.073, cos=0.002), tot_loss_proj:1.773 [t=0.23s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
[1650/2000] tot_loss=1.280 (perp=6.036, rec=0.071, cos=0.002), tot_loss_proj:1.771 [t=0.23s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.286 (perp=6.036, rec=0.077, cos=0.002), tot_loss_proj:1.768 [t=0.23s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.280 (perp=6.036, rec=0.071, cos=0.002), tot_loss_proj:1.766 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
[1800/2000] tot_loss=1.280 (perp=6.036, rec=0.071, cos=0.002), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.285 (perp=6.036, rec=0.076, cos=0.002), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.283 (perp=6.036, rec=0.074, cos=0.002), tot_loss_proj:1.763 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
[1950/2000] tot_loss=1.282 (perp=6.036, rec=0.074, cos=0.002), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.283 (perp=6.036, rec=0.074, cos=0.002), tot_loss_proj:1.770 [t=0.22s]
prediction: ['[CLS] six sucks but has a funny moment or two, [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] six sucks but has a funny moment or two, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 84.211 | p: 80.000 | r: 88.889
rougeL     | fm: 95.238 | p: 90.909 | r: 100.000
rougeLsum  | fm: 95.238 | p: 90.909 | r: 100.000
r1fm+r2fm = 179.449

[Aggregate metrics]:
rouge1     | fm: 91.314 | p: 91.033 | r: 91.645
rouge2     | fm: 61.029 | p: 60.851 | r: 61.298
rougeL     | fm: 79.124 | p: 78.896 | r: 79.448
rougeLsum  | fm: 79.192 | p: 78.917 | r: 79.554
r1fm+r2fm = 152.343

input #51 time: 0:09:03 | total time: 8:16:23


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9992764367772101
highest_index [0]
highest [0.9992764367772101]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9593117237091064 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9314094185829163 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8956812024116516 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 0.869678795337677 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.796468198299408 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7784504294395447 for ['[CLS] confession commentator die [SEP]']
[Init] best rec loss: 0.7061877846717834 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.7012255787849426 for ['[CLS] expected football vocabulary [SEP]']
[Init] best perm rec loss: 0.6979407072067261 for ['[CLS] football vocabulary expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.257 (perp=10.655, rec=0.123, cos=0.003), tot_loss_proj:2.461 [t=0.22s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 100/2000] tot_loss=2.187 (perp=10.529, rec=0.080, cos=0.001), tot_loss_proj:2.202 [t=0.22s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 150/2000] tot_loss=2.167 (perp=10.529, rec=0.060, cos=0.001), tot_loss_proj:2.197 [t=0.22s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 200/2000] tot_loss=2.180 (perp=10.529, rec=0.072, cos=0.002), tot_loss_proj:2.198 [t=0.22s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.819 (perp=8.483, rec=0.119, cos=0.004), tot_loss_proj:2.137 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.771 (perp=8.483, rec=0.074, cos=0.001), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.762 (perp=8.483, rec=0.064, cos=0.001), tot_loss_proj:2.137 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.758 (perp=8.483, rec=0.060, cos=0.001), tot_loss_proj:2.136 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.764 (perp=8.483, rec=0.066, cos=0.001), tot_loss_proj:2.140 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.128 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.757 (perp=8.483, rec=0.059, cos=0.001), tot_loss_proj:2.130 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.766 (perp=8.483, rec=0.068, cos=0.001), tot_loss_proj:2.139 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.126 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.764 (perp=8.483, rec=0.066, cos=0.001), tot_loss_proj:2.139 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.769 (perp=8.483, rec=0.071, cos=0.001), tot_loss_proj:2.129 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.769 (perp=8.483, rec=0.071, cos=0.001), tot_loss_proj:2.131 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.777 (perp=8.483, rec=0.079, cos=0.001), tot_loss_proj:2.132 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.776 (perp=8.483, rec=0.078, cos=0.001), tot_loss_proj:2.130 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.128 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.752 (perp=8.483, rec=0.054, cos=0.001), tot_loss_proj:2.128 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.747 (perp=8.483, rec=0.049, cos=0.001), tot_loss_proj:2.130 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.767 (perp=8.483, rec=0.069, cos=0.001), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.766 (perp=8.483, rec=0.068, cos=0.001), tot_loss_proj:2.131 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.132 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.751 (perp=8.483, rec=0.053, cos=0.001), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.762 (perp=8.483, rec=0.064, cos=0.001), tot_loss_proj:2.131 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.765 (perp=8.483, rec=0.067, cos=0.001), tot_loss_proj:2.128 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.753 (perp=8.483, rec=0.055, cos=0.001), tot_loss_proj:2.137 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.750 (perp=8.483, rec=0.052, cos=0.001), tot_loss_proj:2.126 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.761 (perp=8.483, rec=0.063, cos=0.001), tot_loss_proj:2.135 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.750 (perp=8.483, rec=0.052, cos=0.001), tot_loss_proj:2.133 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.771 (perp=8.483, rec=0.073, cos=0.001), tot_loss_proj:2.127 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.124 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.132 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.128 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.764 (perp=8.483, rec=0.066, cos=0.001), tot_loss_proj:2.128 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.764 (perp=8.483, rec=0.066, cos=0.001), tot_loss_proj:2.132 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.767 (perp=8.483, rec=0.069, cos=0.001), tot_loss_proj:2.127 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 91.351 | p: 91.063 | r: 91.737
rouge2     | fm: 60.066 | p: 59.864 | r: 60.266
rougeL     | fm: 79.169 | p: 78.869 | r: 79.511
rougeLsum  | fm: 79.108 | p: 78.784 | r: 79.407
r1fm+r2fm = 151.417

input #52 time: 0:09:25 | total time: 8:25:49


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9993456844224258
highest_index [0]
highest [0.9993456844224258]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.9461240172386169 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.8590062260627747 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 0.8272409439086914 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 0.7982022166252136 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 0.7196051478385925 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.7162439823150635 for ['[CLS] oro edna [SEP]']
[Init] best rec loss: 0.70369952917099 for ['[CLS] lake highlands [SEP]']
[Init] best rec loss: 0.6949193477630615 for ['[CLS] towerbal [SEP]']
[Init] best rec loss: 0.6925686001777649 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6793366074562073 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6766685843467712 for ['[CLS] el peace [SEP]']
[Init] best perm rec loss: 0.6740282773971558 for ['[CLS] peace el [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.778 (perp=12.493, rec=0.236, cos=0.043), tot_loss_proj:3.329 [t=0.22s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=2.668 (perp=12.493, rec=0.151, cos=0.019), tot_loss_proj:3.339 [t=0.23s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=1.746 (perp=8.090, rec=0.120, cos=0.009), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 200/2000] tot_loss=1.692 (perp=8.090, rec=0.073, cos=0.002), tot_loss_proj:1.674 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.676 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.686 (perp=8.090, rec=0.067, cos=0.001), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.695 (perp=8.090, rec=0.076, cos=0.001), tot_loss_proj:1.695 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.694 (perp=8.090, rec=0.075, cos=0.001), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.686 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.685 (perp=8.090, rec=0.066, cos=0.001), tot_loss_proj:1.683 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.673 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.689 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.688 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.675 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.685 (perp=8.090, rec=0.066, cos=0.001), tot_loss_proj:1.685 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.668 (perp=8.090, rec=0.049, cos=0.001), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.686 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.666 (perp=8.090, rec=0.047, cos=0.001), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.686 (perp=8.090, rec=0.066, cos=0.001), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.685 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.681 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.678 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.672 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.689 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.674 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.667 (perp=8.090, rec=0.047, cos=0.001), tot_loss_proj:1.699 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.673 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.681 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.701 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.683 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.671 (perp=8.090, rec=0.052, cos=0.001), tot_loss_proj:1.703 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.686 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.691 (perp=8.090, rec=0.071, cos=0.001), tot_loss_proj:1.680 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.679 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.688 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.531 | p: 91.205 | r: 91.896
rouge2     | fm: 60.769 | p: 60.572 | r: 61.020
rougeL     | fm: 79.504 | p: 79.202 | r: 79.833
rougeLsum  | fm: 79.342 | p: 79.052 | r: 79.711
r1fm+r2fm = 152.300

input #53 time: 0:09:04 | total time: 8:34:53


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9991884370301731
highest_index [0]
highest [0.9991884370301731]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.9502385258674622 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.8056384325027466 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7584183812141418 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.7190370559692383 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.7029566168785095 for ['[CLS] deployment bro [SEP]']
[Init] best perm rec loss: 0.701512336730957 for ['[CLS] bro deployment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.713 (perp=11.486, rec=0.368, cos=0.048), tot_loss_proj:3.102 [t=0.24s]
prediction: ['[CLS] topics intense [SEP]']
[ 100/2000] tot_loss=2.619 (perp=11.553, rec=0.281, cos=0.027), tot_loss_proj:2.838 [t=0.24s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.423 (perp=11.553, rec=0.109, cos=0.003), tot_loss_proj:2.882 [t=0.24s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.394 (perp=11.553, rec=0.080, cos=0.003), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.722 (perp=8.197, rec=0.078, cos=0.004), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.732 (perp=8.197, rec=0.090, cos=0.003), tot_loss_proj:1.752 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.697 (perp=8.197, rec=0.056, cos=0.002), tot_loss_proj:1.741 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.711 (perp=8.197, rec=0.070, cos=0.002), tot_loss_proj:1.751 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.704 (perp=8.197, rec=0.063, cos=0.002), tot_loss_proj:1.750 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.710 (perp=8.197, rec=0.069, cos=0.002), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.709 (perp=8.197, rec=0.068, cos=0.002), tot_loss_proj:1.736 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.698 (perp=8.197, rec=0.057, cos=0.002), tot_loss_proj:1.753 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.703 (perp=8.197, rec=0.062, cos=0.002), tot_loss_proj:1.758 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.710 (perp=8.197, rec=0.069, cos=0.002), tot_loss_proj:1.751 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.715 (perp=8.197, rec=0.074, cos=0.002), tot_loss_proj:1.755 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.717 (perp=8.197, rec=0.076, cos=0.002), tot_loss_proj:1.729 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.712 (perp=8.197, rec=0.071, cos=0.002), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.712 (perp=8.197, rec=0.071, cos=0.002), tot_loss_proj:1.749 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.699 (perp=8.197, rec=0.058, cos=0.002), tot_loss_proj:1.743 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.714 (perp=8.197, rec=0.073, cos=0.002), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.695 (perp=8.197, rec=0.054, cos=0.002), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.702 (perp=8.197, rec=0.061, cos=0.002), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.700 (perp=8.197, rec=0.059, cos=0.002), tot_loss_proj:1.745 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.706 (perp=8.197, rec=0.065, cos=0.002), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.691 (perp=8.197, rec=0.050, cos=0.002), tot_loss_proj:1.751 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.698 (perp=8.197, rec=0.057, cos=0.002), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.707 (perp=8.197, rec=0.066, cos=0.002), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.692 (perp=8.197, rec=0.051, cos=0.002), tot_loss_proj:1.749 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.705 (perp=8.197, rec=0.064, cos=0.002), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.710 (perp=8.197, rec=0.069, cos=0.002), tot_loss_proj:1.740 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.692 (perp=8.197, rec=0.051, cos=0.002), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.711 (perp=8.197, rec=0.070, cos=0.002), tot_loss_proj:1.746 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.694 (perp=8.197, rec=0.053, cos=0.002), tot_loss_proj:1.743 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.707 (perp=8.197, rec=0.066, cos=0.002), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.691 (perp=8.197, rec=0.050, cos=0.002), tot_loss_proj:1.752 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.709 (perp=8.197, rec=0.068, cos=0.002), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.693 (perp=8.197, rec=0.052, cos=0.002), tot_loss_proj:1.753 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.690 (perp=8.197, rec=0.049, cos=0.002), tot_loss_proj:1.755 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.700 (perp=8.197, rec=0.059, cos=0.002), tot_loss_proj:1.735 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.695 (perp=8.197, rec=0.054, cos=0.002), tot_loss_proj:1.735 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.668 | p: 91.409 | r: 92.051
rouge2     | fm: 61.483 | p: 61.314 | r: 61.707
rougeL     | fm: 79.772 | p: 79.429 | r: 80.189
rougeLsum  | fm: 79.826 | p: 79.577 | r: 80.103
r1fm+r2fm = 153.151

input #54 time: 0:09:40 | total time: 8:44:34


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9991211459235085
highest_index [0]
highest [0.9991211459235085]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.913703441619873 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.8614296317100525 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7851947546005249 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 0.7724620699882507 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7565978169441223 for ['[CLS] kirk door regional [SEP]']
[Init] best rec loss: 0.7475483417510986 for ['[CLS] plantesthesia pr [SEP]']
[Init] best rec loss: 0.72279953956604 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7064613103866577 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7058060765266418 for ['[CLS] post holly stride [SEP]']
[Init] best perm rec loss: 0.7033426761627197 for ['[CLS] stride post holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.343 (perp=9.389, rec=0.384, cos=0.082), tot_loss_proj:3.693 [t=0.22s]
prediction: ['[CLS] easily settled easily [SEP]']
[ 100/2000] tot_loss=2.112 (perp=9.484, rec=0.197, cos=0.018), tot_loss_proj:3.809 [t=0.22s]
prediction: ['[CLS] easily settles easily [SEP]']
[ 150/2000] tot_loss=2.014 (perp=9.583, rec=0.095, cos=0.003), tot_loss_proj:2.327 [t=0.23s]
prediction: ['[CLS] too settles easily [SEP]']
[ 200/2000] tot_loss=1.991 (perp=9.583, rec=0.072, cos=0.002), tot_loss_proj:2.331 [t=0.23s]
prediction: ['[CLS] too settles easily [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.827 (perp=8.670, rec=0.085, cos=0.008), tot_loss_proj:1.811 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=1.798 (perp=8.670, rec=0.062, cos=0.002), tot_loss_proj:1.796 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.801 (perp=8.670, rec=0.065, cos=0.002), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.793 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.802 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.795 (perp=8.670, rec=0.059, cos=0.002), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.803 (perp=8.670, rec=0.067, cos=0.002), tot_loss_proj:1.796 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.793 (perp=8.670, rec=0.057, cos=0.002), tot_loss_proj:1.797 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.788 (perp=8.670, rec=0.052, cos=0.002), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.795 (perp=8.670, rec=0.059, cos=0.002), tot_loss_proj:1.821 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.807 (perp=8.670, rec=0.071, cos=0.002), tot_loss_proj:1.797 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.803 (perp=8.670, rec=0.067, cos=0.002), tot_loss_proj:1.804 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.795 (perp=8.670, rec=0.059, cos=0.002), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.799 (perp=8.670, rec=0.063, cos=0.002), tot_loss_proj:1.793 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.793 (perp=8.670, rec=0.057, cos=0.002), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.789 (perp=8.670, rec=0.053, cos=0.002), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.800 (perp=8.670, rec=0.064, cos=0.002), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.807 (perp=8.670, rec=0.071, cos=0.002), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.804 (perp=8.670, rec=0.068, cos=0.002), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.802 (perp=8.670, rec=0.066, cos=0.002), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.800 (perp=8.670, rec=0.064, cos=0.002), tot_loss_proj:1.804 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.805 (perp=8.670, rec=0.069, cos=0.002), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.790 (perp=8.670, rec=0.055, cos=0.002), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.788 (perp=8.670, rec=0.052, cos=0.002), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.791 (perp=8.670, rec=0.055, cos=0.002), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.793 (perp=8.670, rec=0.057, cos=0.002), tot_loss_proj:1.792 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.794 (perp=8.670, rec=0.059, cos=0.002), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.801 (perp=8.670, rec=0.065, cos=0.002), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.788 (perp=8.670, rec=0.053, cos=0.002), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.796 (perp=8.670, rec=0.061, cos=0.002), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.800 (perp=8.670, rec=0.064, cos=0.002), tot_loss_proj:1.803 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.803 (perp=8.670, rec=0.067, cos=0.002), tot_loss_proj:1.799 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.803 (perp=8.670, rec=0.067, cos=0.002), tot_loss_proj:1.806 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.791 (perp=8.670, rec=0.056, cos=0.002), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.792 (perp=8.670, rec=0.057, cos=0.002), tot_loss_proj:1.811 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.804 (perp=8.670, rec=0.068, cos=0.002), tot_loss_proj:1.797 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.809 (perp=8.670, rec=0.073, cos=0.002), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.930 | p: 91.626 | r: 92.279
rouge2     | fm: 62.204 | p: 62.009 | r: 62.449
rougeL     | fm: 80.187 | p: 79.892 | r: 80.545
rougeLsum  | fm: 80.193 | p: 79.943 | r: 80.484
r1fm+r2fm = 154.134

input #55 time: 0:09:25 | total time: 8:53:59


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.999275319141455
highest_index [0]
highest [0.999275319141455]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.930572509765625 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.9180293679237366 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.9034432768821716 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 0.8964918255805969 for ['[CLS] sergeant atlanticrted further enough face za sincedah had bringing experience claus stereo tour novelmler trails worn korean armed [SEP]']
[Init] best rec loss: 0.891231894493103 for ['[CLS] direction casual pl constitution orange storm beardction norris polo reaches accmity bladetlingus mayer hatch novels chinese ore [SEP]']
[Init] best rec loss: 0.8843615055084229 for ['[CLS] handed almost with leadership emotional obsidian wall households consolation potential spectroscopy defeated been existing organization variables up acquainted cas dive realm [SEP]']
[Init] best perm rec loss: 0.8818796873092651 for ['[CLS] leadership spectroscopy organization with potential acquainted almost households variables been defeated up wall cas consolation existing dive emotional obsidian handed realm [SEP]']
[Init] best perm rec loss: 0.8813957571983337 for ['[CLS] with handed defeated acquainted up existing cas organization leadership dive variables emotional households realm almost potential consolation wall spectroscopy been obsidian [SEP]']
[Init] best perm rec loss: 0.8785008788108826 for ['[CLS] potential with consolation up spectroscopy emotional almost been obsidian variables leadership organization existing wall handed defeated households cas dive acquainted realm [SEP]']
[Init] best perm rec loss: 0.8777846097946167 for ['[CLS] organization been almost defeated up handed dive households wall with cas spectroscopy existing emotional potential leadership variables consolation obsidian acquainted realm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.455 (perp=10.829, rec=0.281, cos=0.009), tot_loss_proj:3.331 [t=0.22s]
prediction: ['[CLS] films which after cause tons agency damage that seemed very concept damaged of costly analysis movie neutron without over films damage [SEP]']
[ 100/2000] tot_loss=2.234 (perp=10.261, rec=0.178, cos=0.004), tot_loss_proj:2.690 [t=0.23s]
prediction: ['[CLS] films which will cause loads route damage that might could fix costly of costly analysis movie neutron fix never films damage [SEP]']
[ 150/2000] tot_loss=2.480 (perp=11.765, rec=0.125, cos=0.002), tot_loss_proj:3.329 [t=0.23s]
prediction: ['[CLS] films which will cause loads would damage that years never fix costly years costly analysis usual fix fix never filmspara [SEP]']
[ 200/2000] tot_loss=2.303 (perp=10.947, rec=0.112, cos=0.002), tot_loss_proj:3.080 [t=0.23s]
prediction: ['[CLS] films which will cause loads would damage that years never fix costly years costly analysis of months fix never filmspara [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.157 (perp=10.265, rec=0.102, cos=0.002), tot_loss_proj:2.754 [t=0.23s]
prediction: ['[CLS] films which will cause loads would damage that years never fix costly years costly analysis of years films never fixpara [SEP]']
[ 300/2000] tot_loss=2.152 (perp=10.265, rec=0.097, cos=0.002), tot_loss_proj:2.758 [t=0.23s]
prediction: ['[CLS] films which will cause loads would damage that years never fix costly years costly analysis of years films never fixpara [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.034 (perp=9.732, rec=0.086, cos=0.002), tot_loss_proj:2.610 [t=0.23s]
prediction: ['[CLS] films which will cause loads of damage that years never fix costly years costly analysis of ir years never fixpara [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.946 (perp=9.205, rec=0.103, cos=0.002), tot_loss_proj:2.496 [t=0.23s]
prediction: ['[CLS] films which will cause loads of damage that years never fix costly years costly analysis of irpara years never fix [SEP]']
[ 450/2000] tot_loss=1.932 (perp=9.205, rec=0.089, cos=0.002), tot_loss_proj:2.488 [t=0.23s]
prediction: ['[CLS] films which will cause loads of damage that years never fix costly years costly analysis of irpara years never fix [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.890 (perp=9.029, rec=0.083, cos=0.001), tot_loss_proj:2.299 [t=0.23s]
prediction: ['[CLS] films which will cause loads of damage that years could fix of costly costly analysis of irpara years never fix [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.788 (perp=8.512, rec=0.084, cos=0.002), tot_loss_proj:2.119 [t=0.23s]
prediction: ['[CLS] films which will cause loads of damage that years could fix years of costly costly analysis of irpara never fix [SEP]']
[ 600/2000] tot_loss=1.782 (perp=8.512, rec=0.079, cos=0.001), tot_loss_proj:2.140 [t=0.23s]
prediction: ['[CLS] films which will cause loads of damage that years could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.784 (perp=8.512, rec=0.080, cos=0.001), tot_loss_proj:2.138 [t=0.23s]
prediction: ['[CLS] films which will cause loads of damage that years could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.761 (perp=8.385, rec=0.082, cos=0.001), tot_loss_proj:2.128 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
[ 750/2000] tot_loss=1.757 (perp=8.385, rec=0.079, cos=0.002), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.759 (perp=8.385, rec=0.081, cos=0.001), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.750 (perp=8.385, rec=0.072, cos=0.001), tot_loss_proj:2.139 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
[ 900/2000] tot_loss=1.751 (perp=8.385, rec=0.073, cos=0.001), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.754 (perp=8.385, rec=0.075, cos=0.001), tot_loss_proj:2.142 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1000/2000] tot_loss=1.747 (perp=8.385, rec=0.068, cos=0.001), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
[1050/2000] tot_loss=1.753 (perp=8.385, rec=0.074, cos=0.001), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1100/2000] tot_loss=1.748 (perp=8.385, rec=0.069, cos=0.001), tot_loss_proj:2.137 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1150/2000] tot_loss=1.747 (perp=8.385, rec=0.068, cos=0.001), tot_loss_proj:2.146 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
[1200/2000] tot_loss=1.759 (perp=8.385, rec=0.080, cos=0.001), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1250/2000] tot_loss=1.758 (perp=8.385, rec=0.079, cos=0.001), tot_loss_proj:2.142 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1300/2000] tot_loss=1.756 (perp=8.385, rec=0.078, cos=0.001), tot_loss_proj:2.150 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
[1350/2000] tot_loss=1.746 (perp=8.385, rec=0.068, cos=0.001), tot_loss_proj:2.146 [t=0.24s]
prediction: ['[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1400/2000] tot_loss=1.806 (perp=8.677, rec=0.070, cos=0.001), tot_loss_proj:2.160 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1450/2000] tot_loss=1.811 (perp=8.677, rec=0.075, cos=0.001), tot_loss_proj:2.150 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
[1500/2000] tot_loss=1.810 (perp=8.677, rec=0.074, cos=0.001), tot_loss_proj:2.147 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1550/2000] tot_loss=1.804 (perp=8.677, rec=0.067, cos=0.001), tot_loss_proj:2.147 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1600/2000] tot_loss=1.812 (perp=8.677, rec=0.075, cos=0.001), tot_loss_proj:2.155 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
[1650/2000] tot_loss=1.814 (perp=8.677, rec=0.078, cos=0.001), tot_loss_proj:2.153 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1700/2000] tot_loss=1.817 (perp=8.677, rec=0.080, cos=0.001), tot_loss_proj:2.155 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1750/2000] tot_loss=1.814 (perp=8.677, rec=0.078, cos=0.001), tot_loss_proj:2.146 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
[1800/2000] tot_loss=1.813 (perp=8.677, rec=0.077, cos=0.001), tot_loss_proj:2.150 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1850/2000] tot_loss=1.803 (perp=8.677, rec=0.066, cos=0.001), tot_loss_proj:2.141 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
[1900/2000] tot_loss=1.815 (perp=8.677, rec=0.078, cos=0.001), tot_loss_proj:2.153 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
[1950/2000] tot_loss=1.808 (perp=8.677, rec=0.071, cos=0.001), tot_loss_proj:2.154 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could· years of costly costly analysis of irpara never fix [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.778 (perp=8.486, rec=0.079, cos=0.001), tot_loss_proj:2.158 [t=0.23s]
prediction: ['[CLS] films which will cause loads of years damage that could years of costly costly analysis of irpara$ never fix [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] films which will cause loads of years damage that could fix years of costly costly analysis of irpara never fix [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 60.000 | p: 57.143 | r: 63.158
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 145.714

[Aggregate metrics]:
rouge1     | fm: 91.786 | p: 91.443 | r: 92.206
rouge2     | fm: 61.958 | p: 61.672 | r: 62.252
rougeL     | fm: 80.109 | p: 79.752 | r: 80.475
rougeLsum  | fm: 80.094 | p: 79.824 | r: 80.438
r1fm+r2fm = 153.745

input #56 time: 0:09:13 | total time: 9:03:13


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9993819320090143
highest_index [0]
highest [0.9993819320090143]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8591682314872742 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.805242121219635 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.7094612717628479 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6545407772064209 for ['[CLS] expressed [SEP]']
[Init] best rec loss: 0.6484116911888123 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.590 (perp=12.283, rec=0.121, cos=0.013), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.516 (perp=12.283, rec=0.057, cos=0.003), tot_loss_proj:2.523 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.525 (perp=12.283, rec=0.066, cos=0.002), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.524 (perp=12.283, rec=0.065, cos=0.002), tot_loss_proj:2.519 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.531 (perp=12.283, rec=0.071, cos=0.003), tot_loss_proj:2.525 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.532 (perp=12.283, rec=0.070, cos=0.005), tot_loss_proj:2.518 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.503 (perp=12.283, rec=0.045, cos=0.001), tot_loss_proj:2.521 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.520 (perp=12.283, rec=0.062, cos=0.001), tot_loss_proj:2.519 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.514 (perp=12.283, rec=0.056, cos=0.001), tot_loss_proj:2.514 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.520 (perp=12.283, rec=0.063, cos=0.001), tot_loss_proj:2.521 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.518 (perp=12.283, rec=0.061, cos=0.001), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.512 (perp=12.283, rec=0.055, cos=0.001), tot_loss_proj:2.518 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.534 (perp=12.283, rec=0.076, cos=0.001), tot_loss_proj:2.530 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.520 (perp=12.283, rec=0.062, cos=0.001), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.537 (perp=12.283, rec=0.080, cos=0.001), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.521 (perp=12.283, rec=0.063, cos=0.001), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.513 (perp=12.283, rec=0.055, cos=0.001), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.514 (perp=12.283, rec=0.056, cos=0.001), tot_loss_proj:2.521 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.520 (perp=12.283, rec=0.062, cos=0.001), tot_loss_proj:2.511 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.524 (perp=12.283, rec=0.067, cos=0.001), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.520 (perp=12.283, rec=0.062, cos=0.001), tot_loss_proj:2.523 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.519 (perp=12.283, rec=0.061, cos=0.001), tot_loss_proj:2.540 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.526 (perp=12.283, rec=0.068, cos=0.001), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.522 (perp=12.283, rec=0.064, cos=0.001), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.510 (perp=12.283, rec=0.052, cos=0.001), tot_loss_proj:2.519 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.505 (perp=12.283, rec=0.047, cos=0.001), tot_loss_proj:2.521 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.510 (perp=12.283, rec=0.053, cos=0.001), tot_loss_proj:2.522 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.494 (perp=12.283, rec=0.036, cos=0.001), tot_loss_proj:2.522 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.513 (perp=12.283, rec=0.055, cos=0.001), tot_loss_proj:2.517 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.525 (perp=12.283, rec=0.067, cos=0.001), tot_loss_proj:2.517 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.512 (perp=12.283, rec=0.054, cos=0.001), tot_loss_proj:2.513 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.524 (perp=12.283, rec=0.067, cos=0.001), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.533 (perp=12.283, rec=0.075, cos=0.001), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.512 (perp=12.283, rec=0.055, cos=0.001), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.518 (perp=12.283, rec=0.060, cos=0.001), tot_loss_proj:2.517 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.518 (perp=12.283, rec=0.060, cos=0.001), tot_loss_proj:2.509 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.510 (perp=12.283, rec=0.052, cos=0.001), tot_loss_proj:2.521 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.522 (perp=12.283, rec=0.065, cos=0.001), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.516 (perp=12.283, rec=0.059, cos=0.001), tot_loss_proj:2.519 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.524 (perp=12.283, rec=0.066, cos=0.001), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.927 | p: 91.621 | r: 92.372
rouge2     | fm: 62.863 | p: 62.610 | r: 63.117
rougeL     | fm: 80.363 | p: 80.096 | r: 80.797
rougeLsum  | fm: 80.340 | p: 80.015 | r: 80.719
r1fm+r2fm = 154.790

input #57 time: 0:08:38 | total time: 9:11:52


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9992687667984019
highest_index [0]
highest [0.9992687667984019]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.962661862373352 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9546318054199219 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9182192087173462 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9155486226081848 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army £100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.8889455795288086 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.875677764415741 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.8751990795135498 for ['[CLS] virtual marian go dreams seed company seat treaty beyond reigning hilt pile stay 2006 austin whereabouts [SEP]']
[Init] best rec loss: 0.8696123361587524 for ['[CLS] down trade zack serious verde thighsager finishedtyle chiefuration apart beautyitical est essay [SEP]']
[Init] best perm rec loss: 0.869049072265625 for ['[CLS]ager serious zack trade beauty finished thighs est essay chieftyleiticaluration apart verde down [SEP]']
[Init] best perm rec loss: 0.8682684898376465 for ['[CLS] finished chief beautyuration trade zack thighs aparttyle verdeitical essay downager serious est [SEP]']
[Init] best perm rec loss: 0.8666278719902039 for ['[CLS]uration finished serious beautytyle zack apart down thighsitical verde essay chief trade estager [SEP]']
[Init] best perm rec loss: 0.8663685321807861 for ['[CLS] beauty finished chief zack serious essay downtyle thighs verde esturation apartiticalager trade [SEP]']
[Init] best perm rec loss: 0.8658364415168762 for ['[CLS] esturationager thighs chief trade zacktyle apart verde down serious essay finished beautyitical [SEP]']
[Init] best perm rec loss: 0.8648908734321594 for ['[CLS] serious chiefager thighs finished est apart tradeitical zack downurationtyle beauty verde essay [SEP]']
[Init] best perm rec loss: 0.8633812665939331 for ['[CLS]uration zack chiefitical est thighs trade downager finished verde aparttyle essay beauty serious [SEP]']
[Init] best perm rec loss: 0.8627644777297974 for ['[CLS]ager down chiefitical finished thighs zacktyle serious beauty tradeuration est essay apart verde [SEP]']
[Init] best perm rec loss: 0.8620972037315369 for ['[CLS] finished verdeitical zackager aparttyleuration trade thighs down est chief serious beauty essay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.575 (perp=11.788, rec=0.214, cos=0.004), tot_loss_proj:3.824 [t=0.22s]
prediction: ['[CLS] was love encounteruin story courti love story love jockey sleeping inspirational story successfully nature [SEP]']
[ 100/2000] tot_loss=2.115 (perp=9.843, rec=0.144, cos=0.002), tot_loss_proj:2.656 [t=0.22s]
prediction: ['[CLS] is love story that encounter (i love captured love cathedral the inspirational innocence capturing nature [SEP]']
[ 150/2000] tot_loss=2.118 (perp=9.971, rec=0.122, cos=0.002), tot_loss_proj:2.657 [t=0.23s]
prediction: ['[CLS] is love story that encounter,i ideal innocence love records the inspirational innocence capturing thereby [SEP]']
[ 200/2000] tot_loss=2.038 (perp=9.727, rec=0.091, cos=0.002), tot_loss_proj:2.748 [t=0.22s]
prediction: ['[CLS] is love story that encounter,ions ideal innocence innocence cathedral the inspirational innocence capturing, [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.974 (perp=9.354, rec=0.102, cos=0.002), tot_loss_proj:2.951 [t=0.22s]
prediction: ['[CLS]i idealism is love story that encounter ( innocence latino the inspirational innocence capturing, [SEP]']
[ 300/2000] tot_loss=1.776 (perp=8.450, rec=0.085, cos=0.002), tot_loss_proj:2.424 [t=0.23s]
prediction: ['[CLS]i idealism is love story that encounter and innocence latino the inspirational innocence capturing, [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.759 (perp=8.381, rec=0.081, cos=0.002), tot_loss_proj:2.417 [t=0.23s]
prediction: ['[CLS]i idealism is love story first encounterquent innocence and the inspirational innocence capturing, [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.539 (perp=7.274, rec=0.083, cos=0.002), tot_loss_proj:2.062 [t=0.23s]
prediction: ['[CLS]i idealism is love story first encounterism capturing innocence and the inspirational innocence, [SEP]']
[ 450/2000] tot_loss=1.542 (perp=7.274, rec=0.086, cos=0.002), tot_loss_proj:2.061 [t=0.23s]
prediction: ['[CLS]i idealism is love story first encounterism capturing innocence and the inspirational innocence, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.611 (perp=7.659, rec=0.077, cos=0.002), tot_loss_proj:2.074 [t=0.23s]
prediction: ['[CLS]i idealism is love story first encounterism capturing and and the inspirational innocence, [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.542 (perp=7.302, rec=0.080, cos=0.002), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS]e idealism is love story first encounterism and capturing and the inspirational innocence, [SEP]']
[ 600/2000] tot_loss=1.548 (perp=7.302, rec=0.086, cos=0.002), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS]e idealism is love story first encounterism and capturing and the inspirational innocence, [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.479 (perp=6.983, rec=0.081, cos=0.002), tot_loss_proj:1.889 [t=0.23s]
prediction: ['[CLS]e idealism is love story and first encounterism and capturing the inspirational innocence, [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.413 (perp=6.652, rec=0.081, cos=0.002), tot_loss_proj:1.832 [t=0.23s]
prediction: ['[CLS] idealisme is love story and first encounterism and capturing the inspirational innocence, [SEP]']
[ 750/2000] tot_loss=1.421 (perp=6.652, rec=0.089, cos=0.002), tot_loss_proj:1.824 [t=0.23s]
prediction: ['[CLS] idealisme is love story and first encounterism and capturing the inspirational innocence, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.479 (perp=6.970, rec=0.083, cos=0.002), tot_loss_proj:2.082 [t=0.23s]
prediction: ['[CLS] idealisme is love story and first encounterism, capturing the inspirational innocence first [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.499 (perp=7.115, rec=0.074, cos=0.002), tot_loss_proj:2.042 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story and that encounterism, capturing the innocence first [SEP]']
[ 900/2000] tot_loss=1.501 (perp=7.115, rec=0.077, cos=0.002), tot_loss_proj:2.044 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story and that encounterism, capturing the innocence first [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.493 (perp=7.057, rec=0.080, cos=0.002), tot_loss_proj:2.029 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story that and encounterism, capturing the innocence first [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.419 (perp=6.684, rec=0.081, cos=0.002), tot_loss_proj:1.840 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story that first encounterism, capturing the innocence and [SEP]']
[1050/2000] tot_loss=1.420 (perp=6.684, rec=0.082, cos=0.002), tot_loss_proj:1.838 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story that first encounterism, capturing the innocence and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.415 (perp=6.684, rec=0.077, cos=0.002), tot_loss_proj:1.835 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story that first encounterism, capturing the innocence and [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.389 (perp=6.562, rec=0.075, cos=0.002), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story first encounterism, capturing the innocence and that [SEP]']
[1200/2000] tot_loss=1.395 (perp=6.562, rec=0.081, cos=0.002), tot_loss_proj:1.750 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story first encounterism, capturing the innocence and that [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.362 (perp=6.391, rec=0.082, cos=0.002), tot_loss_proj:1.710 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story first encounter, capturing the innocence and thatism [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.329 (perp=6.260, rec=0.075, cos=0.002), tot_loss_proj:1.625 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story first encounter, capturing the innocence andism that [SEP]']
[1350/2000] tot_loss=1.328 (perp=6.260, rec=0.074, cos=0.002), tot_loss_proj:1.626 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story first encounter, capturing the innocence andism that [SEP]']
Attempt swap
[1400/2000] tot_loss=1.329 (perp=6.260, rec=0.076, cos=0.002), tot_loss_proj:1.623 [t=0.23s]
prediction: ['[CLS] idealisme is inspirational love story first encounter, capturing the innocence andism that [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.224 (perp=5.756, rec=0.072, cos=0.002), tot_loss_proj:1.434 [t=0.23s]
prediction: ['[CLS] idealism is an inspirational love story first encounter, capturing the innocence andism that [SEP]']
[1500/2000] tot_loss=1.230 (perp=5.756, rec=0.077, cos=0.002), tot_loss_proj:1.436 [t=0.23s]
prediction: ['[CLS] idealism is an inspirational love story first encounter, capturing the innocence andism that [SEP]']
Attempt swap
[1550/2000] tot_loss=1.355 (perp=6.398, rec=0.074, cos=0.002), tot_loss_proj:1.792 [t=0.22s]
prediction: ['[CLS] idealism ise inspirational love story first encounter, capturing the innocence andism that [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.449 (perp=6.893, rec=0.069, cos=0.002), tot_loss_proj:1.769 [t=0.23s]
prediction: ['[CLS] idealism an is inspirational love story first encounter, capturing the innocence andism that [SEP]']
[1650/2000] tot_loss=1.449 (perp=6.893, rec=0.069, cos=0.002), tot_loss_proj:1.779 [t=0.23s]
prediction: ['[CLS] idealism an is inspirational love story first encounter, capturing the innocence andism that [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.231 (perp=5.756, rec=0.078, cos=0.002), tot_loss_proj:1.435 [t=0.23s]
prediction: ['[CLS] idealism is an inspirational love story first encounter, capturing the innocence andism that [SEP]']
Attempt swap
[1750/2000] tot_loss=1.229 (perp=5.756, rec=0.076, cos=0.002), tot_loss_proj:1.432 [t=0.23s]
prediction: ['[CLS] idealism is an inspirational love story first encounter, capturing the innocence andism that [SEP]']
[1800/2000] tot_loss=1.222 (perp=5.756, rec=0.070, cos=0.002), tot_loss_proj:1.435 [t=0.23s]
prediction: ['[CLS] idealism is an inspirational love story first encounter, capturing the innocence andism that [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.233 (perp=5.770, rec=0.077, cos=0.002), tot_loss_proj:1.444 [t=0.23s]
prediction: ['[CLS] idealism is an inspirational love story first encounter, capturing innocence and theism that [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.231 (perp=5.756, rec=0.078, cos=0.002), tot_loss_proj:1.437 [t=0.23s]
prediction: ['[CLS] idealism is an inspirational love story first encounter, capturing the innocence andism that [SEP]']
[1950/2000] tot_loss=1.350 (perp=6.398, rec=0.069, cos=0.002), tot_loss_proj:1.791 [t=0.22s]
prediction: ['[CLS] idealism ise inspirational love story first encounter, capturing the innocence andism that [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.331 (perp=6.247, rec=0.080, cos=0.002), tot_loss_proj:1.726 [t=0.23s]
prediction: ['[CLS]ism ise inspirational love story first encounter, capturing the innocence and idealism that [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] idealism is an inspirational love story first encounter, capturing the innocence andism that [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.323 | p: 93.333 | r: 87.500
rouge2     | fm: 48.276 | p: 50.000 | r: 46.667
rougeL     | fm: 70.968 | p: 73.333 | r: 68.750
rougeLsum  | fm: 70.968 | p: 73.333 | r: 68.750
r1fm+r2fm = 138.598

[Aggregate metrics]:
rouge1     | fm: 91.908 | p: 91.612 | r: 92.280
rouge2     | fm: 62.660 | p: 62.425 | r: 62.895
rougeL     | fm: 80.340 | p: 80.052 | r: 80.714
rougeLsum  | fm: 80.179 | p: 79.887 | r: 80.493
r1fm+r2fm = 154.568

input #58 time: 0:08:55 | total time: 9:20:47


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9992224840541208
highest_index [0]
highest [0.9992224840541208]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.9158618450164795 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.899953305721283 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 0.89546138048172 for ['[CLS] clutch sports meridian placed weekly dixonwords up⁄ faerie rugby been towards resist programming infantry [SEP]']
[Init] best rec loss: 0.8692657351493835 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.86898273229599 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best rec loss: 0.8669886589050293 for ['[CLS] het hill income rule helping icon minh were way lisa ufc these vampire skins notch good [SEP]']
[Init] best rec loss: 0.8595459461212158 for ['[CLS]ition wandering wearing right wore kent hemisphere purple strict we gas dark deserve tonnes did letterman [SEP]']
[Init] best rec loss: 0.8334484100341797 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best perm rec loss: 0.8307017087936401 for ['[CLS] fleetby tunnel information thus awhile noah wasak races temperament bologna stuff bobo pump 1993 [SEP]']
[Init] best perm rec loss: 0.8305091857910156 for ['[CLS] pumpak temperament thus tunnel noah was awhile bologna fleet information boboby 1993 races stuff [SEP]']
[Init] best perm rec loss: 0.8296042680740356 for ['[CLS] information fleetak 1993 awhile pump stuff noah thus boboby bologna temperament was races tunnel [SEP]']
[Init] best perm rec loss: 0.8292043805122375 for ['[CLS] bologna races stuff pump fleet tunnelakby 1993 noah awhile thus temperament bobo information was [SEP]']
[Init] best perm rec loss: 0.8289357423782349 for ['[CLS] stuff temperament awhile was 1993 races thus pump noah tunnel fleet bobo information bolognaakby [SEP]']
[Init] best perm rec loss: 0.8288805484771729 for ['[CLS] temperament racesby bologna thus awhile information bobo noah stuff pump 1993ak fleet was tunnel [SEP]']
[Init] best perm rec loss: 0.828627347946167 for ['[CLS] thus fleet stuff tunnelak was awhile races bobo 1993 informationby noah temperament pump bologna [SEP]']
[Init] best perm rec loss: 0.8283922672271729 for ['[CLS] bobo races stuff fleet tunnel temperament noah information awhileby thus was 1993ak bologna pump [SEP]']
[Init] best perm rec loss: 0.8274857401847839 for ['[CLS] fleet 1993by temperament bobo stuff thusak awhile noah tunnel information races bologna pump was [SEP]']
[Init] best perm rec loss: 0.8274096250534058 for ['[CLS] 1993 noah bologna tunnel fleet thus awhile stuff temperament pump was boboby informationak races [SEP]']
[Init] best perm rec loss: 0.8264302015304565 for ['[CLS] stuff noahak was awhile fleet races information temperamentby thus 1993 tunnel bobo bologna pump [SEP]']
[Init] best perm rec loss: 0.8250256180763245 for ['[CLS] thus tunnel was informationbyak stuff races 1993 pump temperament awhile bobo fleet bologna noah [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.459 (perp=10.655, rec=0.318, cos=0.010), tot_loss_proj:3.299 [t=0.22s]
prediction: ['[CLS] has young woman anniversary stories an woman with the is power 1997 screen actor presentation adult [SEP]']
[ 100/2000] tot_loss=2.201 (perp=10.049, rec=0.187, cos=0.004), tot_loss_proj:3.442 [t=0.22s]
prediction: ['[CLS] has theism of a a woman girl how woman streak young char screen screen adult [SEP]']
[ 150/2000] tot_loss=2.065 (perp=9.495, rec=0.163, cos=0.003), tot_loss_proj:3.281 [t=0.23s]
prediction: ['[CLS] has theism of a a woman girl knows how char hold char screen screen char [SEP]']
[ 200/2000] tot_loss=2.035 (perp=9.495, rec=0.134, cos=0.002), tot_loss_proj:3.279 [t=0.22s]
prediction: ['[CLS] has theism of a a woman girl knows how char hold char screen screen char [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.749 (perp=8.166, rec=0.114, cos=0.002), tot_loss_proj:2.962 [t=0.22s]
prediction: ['[CLS] has theism of young a woman who knows how char hold char screen char screen [SEP]']
[ 300/2000] tot_loss=1.691 (perp=7.969, rec=0.095, cos=0.002), tot_loss_proj:2.785 [t=0.23s]
prediction: ['[CLS] has theism of young a woman who knows howa hold char screen char screen [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.599 (perp=7.579, rec=0.082, cos=0.002), tot_loss_proj:2.965 [t=0.22s]
prediction: ['[CLS] has theism of a woman who knows how younga hold char screen char screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.592 (perp=7.579, rec=0.074, cos=0.002), tot_loss_proj:2.975 [t=0.22s]
prediction: ['[CLS] has theism of a woman who knows how younga hold char screen char screen [SEP]']
[ 450/2000] tot_loss=1.598 (perp=7.579, rec=0.081, cos=0.002), tot_loss_proj:2.973 [t=0.22s]
prediction: ['[CLS] has theism of a woman who knows how younga hold char screen char screen [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.565 (perp=7.456, rec=0.072, cos=0.002), tot_loss_proj:3.006 [t=0.22s]
prediction: ['[CLS] has theism of a woman who knows how young holda char screen char screen [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.515 (perp=7.211, rec=0.071, cos=0.001), tot_loss_proj:2.865 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char screen char screen [SEP]']
[ 600/2000] tot_loss=1.518 (perp=7.211, rec=0.074, cos=0.002), tot_loss_proj:2.857 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char screen char screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.511 (perp=7.211, rec=0.068, cos=0.002), tot_loss_proj:2.858 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char screen char screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.612 (perp=7.720, rec=0.067, cos=0.002), tot_loss_proj:2.645 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char screen char the [SEP]']
[ 750/2000] tot_loss=1.614 (perp=7.720, rec=0.068, cos=0.002), tot_loss_proj:2.647 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char screen char the [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.526 (perp=7.288, rec=0.066, cos=0.002), tot_loss_proj:2.620 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the char screen [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.509 (perp=7.177, rec=0.072, cos=0.001), tot_loss_proj:2.505 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
[ 900/2000] tot_loss=1.514 (perp=7.177, rec=0.078, cos=0.002), tot_loss_proj:2.512 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.500 (perp=7.177, rec=0.063, cos=0.002), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1000/2000] tot_loss=1.499 (perp=7.177, rec=0.063, cos=0.002), tot_loss_proj:2.505 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
[1050/2000] tot_loss=1.511 (perp=7.177, rec=0.074, cos=0.002), tot_loss_proj:2.508 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1100/2000] tot_loss=1.504 (perp=7.177, rec=0.067, cos=0.002), tot_loss_proj:2.513 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1150/2000] tot_loss=1.498 (perp=7.177, rec=0.061, cos=0.002), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
[1200/2000] tot_loss=1.496 (perp=7.177, rec=0.059, cos=0.002), tot_loss_proj:2.501 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1250/2000] tot_loss=1.501 (perp=7.177, rec=0.064, cos=0.002), tot_loss_proj:2.501 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1300/2000] tot_loss=1.497 (perp=7.177, rec=0.060, cos=0.002), tot_loss_proj:2.509 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
[1350/2000] tot_loss=1.492 (perp=7.177, rec=0.055, cos=0.002), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1400/2000] tot_loss=1.502 (perp=7.177, rec=0.065, cos=0.002), tot_loss_proj:2.503 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1450/2000] tot_loss=1.501 (perp=7.177, rec=0.064, cos=0.002), tot_loss_proj:2.493 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
[1500/2000] tot_loss=1.501 (perp=7.177, rec=0.064, cos=0.002), tot_loss_proj:2.497 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.502 (perp=7.177, rec=0.065, cos=0.002), tot_loss_proj:2.497 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1600/2000] tot_loss=1.504 (perp=7.177, rec=0.068, cos=0.002), tot_loss_proj:2.507 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
[1650/2000] tot_loss=1.508 (perp=7.177, rec=0.071, cos=0.002), tot_loss_proj:2.502 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1700/2000] tot_loss=1.510 (perp=7.177, rec=0.074, cos=0.002), tot_loss_proj:2.499 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1750/2000] tot_loss=1.505 (perp=7.177, rec=0.068, cos=0.002), tot_loss_proj:2.502 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
[1800/2000] tot_loss=1.508 (perp=7.177, rec=0.071, cos=0.002), tot_loss_proj:2.498 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1850/2000] tot_loss=1.500 (perp=7.177, rec=0.063, cos=0.002), tot_loss_proj:2.499 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[1900/2000] tot_loss=1.493 (perp=7.177, rec=0.056, cos=0.002), tot_loss_proj:2.497 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
[1950/2000] tot_loss=1.502 (perp=7.177, rec=0.065, cos=0.002), tot_loss_proj:2.503 [t=0.22s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Attempt swap
[2000/2000] tot_loss=1.504 (perp=7.177, rec=0.067, cos=0.002), tot_loss_proj:2.499 [t=0.23s]
prediction: ['[CLS] has theism of a young woman who knows how holda char the screen char [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] has theism of a young woman who knows how holda char the screen char [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 53.333 | p: 53.333 | r: 53.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 128.333

[Aggregate metrics]:
rouge1     | fm: 91.650 | p: 91.356 | r: 92.021
rouge2     | fm: 62.180 | p: 62.011 | r: 62.479
rougeL     | fm: 80.248 | p: 80.018 | r: 80.624
rougeLsum  | fm: 80.237 | p: 80.020 | r: 80.504
r1fm+r2fm = 153.830

input #59 time: 0:08:54 | total time: 9:29:42


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.9993723007306495
highest_index [0]
highest [0.9993723007306495]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9240039587020874 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9135375618934631 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8766923546791077 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8674620389938354 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8555521368980408 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 0.8470483422279358 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 0.8440579771995544 for ['[CLS] coverouringlby through strung plenty constitutionshaw majority /itude upset [SEP]']
[Init] best perm rec loss: 0.8426222205162048 for ['[CLS] plenty /lbyshawouring strung constitutionitude majority through cover upset [SEP]']
[Init] best perm rec loss: 0.8374884724617004 for ['[CLS] majority / strunglbyitude throughshaw plentyouring constitution upset cover [SEP]']
[Init] best perm rec loss: 0.8369754552841187 for ['[CLS]itude majority strung throughshaw plenty constitution coverlby upsetouring / [SEP]']
[Init] best perm rec loss: 0.8367394208908081 for ['[CLS] plentyitudelbyshaw / constitution through strung upset coverouring majority [SEP]']
[Init] best perm rec loss: 0.8362407684326172 for ['[CLS] plentylby strung upsetshaw constitution majority through coveritude /ouring [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.790 (perp=12.496, rec=0.282, cos=0.009), tot_loss_proj:3.106 [t=0.22s]
prediction: ['[CLS] awkwardly ª political clip awkwardly awkwardly house text its awkwardly awkwardly september [SEP]']
[ 100/2000] tot_loss=2.661 (perp=12.284, rec=0.199, cos=0.005), tot_loss_proj:3.061 [t=0.22s]
prediction: ['[CLS] awkwardly is paced paced awkwardly screen circuit soap is awkwardly awkwardly story [SEP]']
[ 150/2000] tot_loss=2.625 (perp=12.322, rec=0.158, cos=0.003), tot_loss_proj:3.035 [t=0.22s]
prediction: ['[CLS] awkwardly is paced paced awkwardly soap circuit soap is awkwardly awkwardly story [SEP]']
[ 200/2000] tot_loss=2.571 (perp=12.152, rec=0.137, cos=0.003), tot_loss_proj:2.989 [t=0.22s]
prediction: ['[CLS] awkwardly is paced paced awkwardly soap circuit soap the circuit awkwardly story [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.240 (perp=10.489, rec=0.139, cos=0.003), tot_loss_proj:2.669 [t=0.22s]
prediction: ['[CLS] awkwardly paced awkwardly soap circuit soap is paced the circuit awkwardly story [SEP]']
[ 300/2000] tot_loss=2.373 (perp=11.285, rec=0.113, cos=0.003), tot_loss_proj:2.807 [t=0.22s]
prediction: ['[CLS] awkwardly opera awkwardly soap circuit soap is paced the circuith story [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.290 (perp=10.901, rec=0.108, cos=0.002), tot_loss_proj:2.704 [t=0.22s]
prediction: ['[CLS] awkwardly circuit awkwardly opera opera soap is paced the circuith story [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.108 (perp=10.026, rec=0.100, cos=0.003), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] awkwardly circuit awkwardly opera soap opera is paced the circuith story [SEP]']
[ 450/2000] tot_loss=2.105 (perp=10.026, rec=0.097, cos=0.002), tot_loss_proj:2.513 [t=0.22s]
prediction: ['[CLS] awkwardly circuit awkwardly opera soap opera is paced the circuith story [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.965 (perp=9.309, rec=0.101, cos=0.002), tot_loss_proj:2.316 [t=0.22s]
prediction: ['[CLS] circuit awkwardly opera soap opera is awkwardly paced the circuith story [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.844 (perp=8.599, rec=0.121, cos=0.003), tot_loss_proj:2.256 [t=0.22s]
prediction: ['[CLS] circuit awkwardly opera soap opera circuit awkwardly paced the ish story [SEP]']
[ 600/2000] tot_loss=1.830 (perp=8.599, rec=0.108, cos=0.002), tot_loss_proj:2.251 [t=0.22s]
prediction: ['[CLS] circuit awkwardly opera soap opera circuit awkwardly paced the ish story [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.797 (perp=8.502, rec=0.095, cos=0.002), tot_loss_proj:2.190 [t=0.22s]
prediction: ['[CLS] circuit awkwardly soap opera circuit awkwardly paced opera the ish story [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.793 (perp=8.502, rec=0.090, cos=0.002), tot_loss_proj:2.201 [t=0.22s]
prediction: ['[CLS] circuit awkwardly soap opera circuit awkwardly paced opera the ish story [SEP]']
[ 750/2000] tot_loss=1.792 (perp=8.502, rec=0.090, cos=0.002), tot_loss_proj:2.195 [t=0.22s]
prediction: ['[CLS] circuit awkwardly soap opera circuit awkwardly paced opera the ish story [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.768 (perp=8.364, rec=0.093, cos=0.002), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] circuit awkwardly soap opera circuit opera awkwardly paced the ish story [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.768 (perp=8.404, rec=0.085, cos=0.002), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS] circuit awkwardly soap opera circuit is awkwardly paced the operah story [SEP]']
[ 900/2000] tot_loss=1.764 (perp=8.404, rec=0.081, cos=0.002), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] circuit awkwardly soap opera circuit is awkwardly paced the operah story [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.760 (perp=8.364, rec=0.085, cos=0.002), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] circuit awkwardly soap opera circuit opera awkwardly paced the ish story [SEP]']
Attempt swap
[1000/2000] tot_loss=1.772 (perp=8.364, rec=0.097, cos=0.002), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] circuit awkwardly soap opera circuit opera awkwardly paced the ish story [SEP]']
[1050/2000] tot_loss=1.768 (perp=8.364, rec=0.093, cos=0.002), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] circuit awkwardly soap opera circuit opera awkwardly paced the ish story [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.742 (perp=8.246, rec=0.091, cos=0.002), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera - opera paced the ish story [SEP]']
Attempt swap
[1150/2000] tot_loss=1.744 (perp=8.246, rec=0.093, cos=0.002), tot_loss_proj:2.125 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera - opera paced the ish story [SEP]']
[1200/2000] tot_loss=1.734 (perp=8.246, rec=0.083, cos=0.002), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera - opera paced the ish story [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.733 (perp=8.191, rec=0.093, cos=0.002), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Attempt swap
[1300/2000] tot_loss=1.721 (perp=8.191, rec=0.081, cos=0.002), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
[1350/2000] tot_loss=1.728 (perp=8.191, rec=0.088, cos=0.002), tot_loss_proj:2.067 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Attempt swap
[1400/2000] tot_loss=1.724 (perp=8.191, rec=0.084, cos=0.002), tot_loss_proj:2.067 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Attempt swap
[1450/2000] tot_loss=1.721 (perp=8.191, rec=0.081, cos=0.002), tot_loss_proj:2.065 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
[1500/2000] tot_loss=1.725 (perp=8.191, rec=0.085, cos=0.002), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Attempt swap
[1550/2000] tot_loss=1.720 (perp=8.191, rec=0.080, cos=0.002), tot_loss_proj:2.072 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Attempt swap
[1600/2000] tot_loss=1.718 (perp=8.191, rec=0.078, cos=0.002), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
[1650/2000] tot_loss=1.715 (perp=8.191, rec=0.075, cos=0.002), tot_loss_proj:2.064 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Attempt swap
[1700/2000] tot_loss=1.716 (perp=8.191, rec=0.076, cos=0.002), tot_loss_proj:2.071 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Attempt swap
[1750/2000] tot_loss=1.719 (perp=8.191, rec=0.079, cos=0.002), tot_loss_proj:2.069 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
[1800/2000] tot_loss=1.722 (perp=8.191, rec=0.082, cos=0.002), tot_loss_proj:2.065 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Attempt swap
[1850/2000] tot_loss=1.725 (perp=8.191, rec=0.085, cos=0.002), tot_loss_proj:2.068 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Attempt swap
[1900/2000] tot_loss=1.721 (perp=8.191, rec=0.081, cos=0.002), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
[1950/2000] tot_loss=1.722 (perp=8.191, rec=0.082, cos=0.002), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Attempt swap
[2000/2000] tot_loss=1.720 (perp=8.191, rec=0.080, cos=0.002), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] circuit awkwardly awkwardly soap opera paced opera - the ish story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 69.565 | p: 66.667 | r: 72.727
rougeLsum  | fm: 69.565 | p: 66.667 | r: 72.727
r1fm+r2fm = 125.052

[Aggregate metrics]:
rouge1     | fm: 91.555 | p: 91.206 | r: 91.996
rouge2     | fm: 62.084 | p: 61.852 | r: 62.323
rougeL     | fm: 80.026 | p: 79.754 | r: 80.406
rougeLsum  | fm: 80.085 | p: 79.797 | r: 80.423
r1fm+r2fm = 153.639

input #60 time: 0:08:46 | total time: 9:38:29


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.9992842374425217
highest_index [0]
highest [0.9992842374425217]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9796134233474731 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9755127429962158 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9502310752868652 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9452727437019348 for ['[CLS] paths whose bar [SEP]']
[Init] best rec loss: 0.9447370767593384 for ['[CLS]mbledssi commons [SEP]']
[Init] best rec loss: 0.936389148235321 for ['[CLS] crested tend prize [SEP]']
[Init] best rec loss: 0.9159070253372192 for ['[CLS] bologna nails steps [SEP]']
[Init] best rec loss: 0.9078887104988098 for ['[CLS] you wedding velvet [SEP]']
[Init] best rec loss: 0.8797362446784973 for ['[CLS] respect thrill butterfly [SEP]']
[Init] best rec loss: 0.8326549530029297 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 0.8251567482948303 for ['[CLS] lets request mini [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.756 (perp=7.753, rec=0.195, cos=0.010), tot_loss_proj:1.819 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 100/2000] tot_loss=1.699 (perp=7.753, rec=0.141, cos=0.007), tot_loss_proj:1.818 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 150/2000] tot_loss=1.675 (perp=7.753, rec=0.121, cos=0.003), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 200/2000] tot_loss=1.682 (perp=8.032, rec=0.074, cos=0.001), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.490 (perp=7.102, rec=0.068, cos=0.002), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 300/2000] tot_loss=1.489 (perp=7.102, rec=0.067, cos=0.001), tot_loss_proj:1.635 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.490 (perp=7.102, rec=0.068, cos=0.001), tot_loss_proj:1.619 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.478 (perp=7.102, rec=0.056, cos=0.001), tot_loss_proj:1.622 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.493 (perp=7.102, rec=0.071, cos=0.001), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.482 (perp=7.102, rec=0.061, cos=0.001), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.492 (perp=7.102, rec=0.070, cos=0.001), tot_loss_proj:1.616 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.479 (perp=7.102, rec=0.057, cos=0.001), tot_loss_proj:1.627 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.492 (perp=7.102, rec=0.070, cos=0.001), tot_loss_proj:1.623 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.493 (perp=7.102, rec=0.071, cos=0.001), tot_loss_proj:1.614 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.491 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.612 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.490 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.488 (perp=7.102, rec=0.066, cos=0.001), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.493 (perp=7.102, rec=0.071, cos=0.001), tot_loss_proj:1.622 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.490 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.487 (perp=7.102, rec=0.066, cos=0.001), tot_loss_proj:1.620 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.472 (perp=7.102, rec=0.050, cos=0.001), tot_loss_proj:1.620 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.484 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.619 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.491 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.621 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.494 (perp=7.102, rec=0.072, cos=0.001), tot_loss_proj:1.621 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.494 (perp=7.102, rec=0.072, cos=0.001), tot_loss_proj:1.616 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.480 (perp=7.102, rec=0.058, cos=0.001), tot_loss_proj:1.636 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.487 (perp=7.102, rec=0.065, cos=0.001), tot_loss_proj:1.612 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.490 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.622 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.496 (perp=7.102, rec=0.074, cos=0.001), tot_loss_proj:1.618 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.483 (perp=7.102, rec=0.061, cos=0.001), tot_loss_proj:1.614 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.495 (perp=7.102, rec=0.073, cos=0.001), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.481 (perp=7.102, rec=0.060, cos=0.001), tot_loss_proj:1.626 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.480 (perp=7.102, rec=0.059, cos=0.001), tot_loss_proj:1.623 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.487 (perp=7.102, rec=0.066, cos=0.001), tot_loss_proj:1.632 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.481 (perp=7.102, rec=0.059, cos=0.001), tot_loss_proj:1.619 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.469 (perp=7.102, rec=0.047, cos=0.001), tot_loss_proj:1.632 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.478 (perp=7.102, rec=0.056, cos=0.001), tot_loss_proj:1.624 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.493 (perp=7.102, rec=0.071, cos=0.001), tot_loss_proj:1.610 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.478 (perp=7.102, rec=0.056, cos=0.001), tot_loss_proj:1.631 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.496 (perp=7.102, rec=0.074, cos=0.001), tot_loss_proj:1.618 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.654 | p: 91.342 | r: 92.072
rouge2     | fm: 62.425 | p: 62.205 | r: 62.699
rougeL     | fm: 80.330 | p: 79.989 | r: 80.735
rougeLsum  | fm: 80.290 | p: 79.994 | r: 80.612
r1fm+r2fm = 154.079

input #61 time: 0:08:45 | total time: 9:47:14


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.9992552892713504
highest_index [0]
highest [0.9992552892713504]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9559537172317505 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9276927709579468 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.922580897808075 for ['[CLS] percentage trap danzinghur shapeee sacred persianlon record theater freestylegold cards dance sacks pits dreadmund existed [SEP]']
[Init] best rec loss: 0.9182294011116028 for ['[CLS] girl plain followedion recalls間 by spread fight sioux 2002 test origins humanitarian peck reed forumnce tooth closely mccarthy [SEP]']
[Init] best perm rec loss: 0.9180595874786377 for ['[CLS]間 origins closely mccarthy sioux tooth 2002 test reed by peck humanitarian girl recalls fight forumion followednce plain spread [SEP]']
[Init] best perm rec loss: 0.9156901240348816 for ['[CLS] fight mccarthy by closely tooth test recalls siouxnce spread humanitarian girl peckion 2002 followed間 reed forum origins plain [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.721 (perp=11.766, rec=0.357, cos=0.011), tot_loss_proj:3.689 [t=0.22s]
prediction: ['[CLS] strong rough fusion historic qualities best linear war quality grace prevention throughout best grade fault for for samurai recorded extreme hit [SEP]']
[ 100/2000] tot_loss=2.299 (perp=9.741, rec=0.338, cos=0.013), tot_loss_proj:3.406 [t=0.23s]
prediction: ['[CLS] making rough grace since recital best the prevention of grace prevention jensen best to grace for best war ever. best [SEP]']
[ 150/2000] tot_loss=2.024 (perp=9.012, rec=0.217, cos=0.004), tot_loss_proj:3.311 [t=0.23s]
prediction: ['[CLS] making trade grace of recital best the prevention of grace prevention grace best to grace for best war ever. movies [SEP]']
[ 200/2000] tot_loss=2.115 (perp=9.644, rec=0.183, cos=0.003), tot_loss_proj:2.986 [t=0.23s]
prediction: ['[CLS] to trade grace to recital best the prevention call grace prevention to best, making one best war ever war movies [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.849 (perp=8.481, rec=0.151, cos=0.002), tot_loss_proj:2.310 [t=0.23s]
prediction: ['[CLS] to call to grace rather best the prevention rather to prevention to best, making one best war ever war movies [SEP]']
[ 300/2000] tot_loss=1.801 (perp=8.454, rec=0.109, cos=0.002), tot_loss_proj:2.592 [t=0.23s]
prediction: ['[CLS] to call for grace call even the prevention rather to prevention to best, making one best war ever ever movies [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.684 (perp=7.885, rec=0.106, cos=0.002), tot_loss_proj:2.903 [t=0.23s]
prediction: ['[CLS] to call for grace ratherdable the best rather to blame to prevention, making one best war ever. movies [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.475 (perp=6.892, rec=0.095, cos=0.002), tot_loss_proj:2.311 [t=0.23s]
prediction: ['[CLS] to call for grace rather indeed the best rather to blame to prevention, making one best war movies ever. [SEP]']
[ 450/2000] tot_loss=1.463 (perp=6.820, rec=0.097, cos=0.002), tot_loss_proj:3.059 [t=0.23s]
prediction: ['[CLS] to call for grace rather indeed the best rather to blame to prevention, making one the war movies ever made [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.518 (perp=7.195, rec=0.078, cos=0.001), tot_loss_proj:3.275 [t=0.23s]
prediction: ['[CLS] to call for grace rather it the best rather to blame place prevention, making one the war movies ever made [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.450 (perp=6.795, rec=0.089, cos=0.002), tot_loss_proj:3.121 [t=0.23s]
prediction: ['[CLS] to call for grace rather it best rather to blame the than prevention, making one the war movies ever made [SEP]']
[ 600/2000] tot_loss=1.439 (perp=6.795, rec=0.079, cos=0.001), tot_loss_proj:3.126 [t=0.23s]
prediction: ['[CLS] to call for grace rather it best rather to blame the than prevention, making one the war movies ever made [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.377 (perp=6.501, rec=0.076, cos=0.002), tot_loss_proj:1.707 [t=0.23s]
prediction: ['[CLS] to call for grace rather it rather to blame the than prevention, making one the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.357 (perp=6.417, rec=0.072, cos=0.001), tot_loss_proj:1.691 [t=0.23s]
prediction: ['[CLS] to call for grace the it rather to blame rather than prevention, making one the best war movies ever made [SEP]']
[ 750/2000] tot_loss=1.360 (perp=6.417, rec=0.075, cos=0.001), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] to call for grace the it rather to blame rather than prevention, making one the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.255 (perp=5.872, rec=0.079, cos=0.001), tot_loss_proj:1.764 [t=0.23s]
prediction: ['[CLS] to call for grace making it rather to blame rather than prevention, the one the best war movies ever made [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.245 (perp=5.837, rec=0.076, cos=0.002), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] to call grace for making it rather to blame rather than prevention, the one the best war movies ever made [SEP]']
[ 900/2000] tot_loss=1.237 (perp=5.837, rec=0.068, cos=0.001), tot_loss_proj:1.699 [t=0.23s]
prediction: ['[CLS] to call grace for making it rather to blame rather than prevention, the one the best war movies ever made [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.242 (perp=5.837, rec=0.073, cos=0.001), tot_loss_proj:1.703 [t=0.23s]
prediction: ['[CLS] to call grace for making it rather to blame rather than prevention, the one the best war movies ever made [SEP]']
Attempt swap
[1000/2000] tot_loss=1.244 (perp=5.837, rec=0.076, cos=0.001), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] to call grace for making it rather to blame rather than prevention, the one the best war movies ever made [SEP]']
[1050/2000] tot_loss=1.379 (perp=6.543, rec=0.069, cos=0.001), tot_loss_proj:1.861 [t=0.23s]
prediction: ['[CLS] to call grace for making it rather to blame place than prevention, the one the best war movies ever made [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.311 (perp=6.147, rec=0.080, cos=0.001), tot_loss_proj:1.808 [t=0.23s]
prediction: ['[CLS] to call grace for making it to blame place rather than prevention, the one the best war movies ever made [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.287 (perp=6.065, rec=0.072, cos=0.001), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] to call grace for making it to place blame rather than prevention, the one the best war movies ever made [SEP]']
[1200/2000] tot_loss=1.285 (perp=6.065, rec=0.071, cos=0.001), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] to call grace for making it to place blame rather than prevention, the one the best war movies ever made [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.256 (perp=5.934, rec=0.068, cos=0.001), tot_loss_proj:1.729 [t=0.23s]
prediction: ['[CLS] to call grace for making it to place the blame rather than prevention, one the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.237 (perp=5.804, rec=0.075, cos=0.001), tot_loss_proj:1.661 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
[1350/2000] tot_loss=1.235 (perp=5.804, rec=0.073, cos=0.001), tot_loss_proj:1.662 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
Attempt swap
[1400/2000] tot_loss=1.236 (perp=5.804, rec=0.074, cos=0.001), tot_loss_proj:1.665 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
Attempt swap
[1450/2000] tot_loss=1.226 (perp=5.804, rec=0.063, cos=0.001), tot_loss_proj:1.667 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
[1500/2000] tot_loss=1.230 (perp=5.804, rec=0.067, cos=0.001), tot_loss_proj:1.666 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
Attempt swap
[1550/2000] tot_loss=1.227 (perp=5.804, rec=0.065, cos=0.001), tot_loss_proj:1.668 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
Attempt swap
[1600/2000] tot_loss=1.230 (perp=5.804, rec=0.068, cos=0.001), tot_loss_proj:1.666 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
[1650/2000] tot_loss=1.236 (perp=5.804, rec=0.073, cos=0.001), tot_loss_proj:1.667 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
Attempt swap
[1700/2000] tot_loss=1.233 (perp=5.804, rec=0.070, cos=0.001), tot_loss_proj:1.664 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
Attempt swap
[1750/2000] tot_loss=1.235 (perp=5.804, rec=0.073, cos=0.001), tot_loss_proj:1.665 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
[1800/2000] tot_loss=1.235 (perp=5.804, rec=0.073, cos=0.001), tot_loss_proj:1.667 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
Attempt swap
[1850/2000] tot_loss=1.229 (perp=5.804, rec=0.067, cos=0.001), tot_loss_proj:1.664 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
Attempt swap
[1900/2000] tot_loss=1.232 (perp=5.804, rec=0.070, cos=0.001), tot_loss_proj:1.660 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
[1950/2000] tot_loss=1.233 (perp=5.804, rec=0.070, cos=0.001), tot_loss_proj:1.666 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
Attempt swap
[2000/2000] tot_loss=1.232 (perp=5.804, rec=0.069, cos=0.001), tot_loss_proj:1.660 [t=0.23s]
prediction: ['[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] to call it for making grace to place the blame rather than prevention, one the best war movies ever made [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.455 | p: 95.455 | r: 95.455
rouge2     | fm: 47.619 | p: 47.619 | r: 47.619
rougeL     | fm: 68.182 | p: 68.182 | r: 68.182
rougeLsum  | fm: 68.182 | p: 68.182 | r: 68.182
r1fm+r2fm = 143.074

[Aggregate metrics]:
rouge1     | fm: 91.725 | p: 91.375 | r: 92.113
rouge2     | fm: 62.327 | p: 62.130 | r: 62.601
rougeL     | fm: 80.162 | p: 79.903 | r: 80.601
rougeLsum  | fm: 80.099 | p: 79.838 | r: 80.415
r1fm+r2fm = 154.051

input #62 time: 0:08:58 | total time: 9:56:13


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9992638993081941
highest_index [0]
highest [0.9992638993081941]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.9526534080505371 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.8990910053253174 for ['[CLS] touch alternative glacier bentry [SEP]']
[Init] best rec loss: 0.7447170615196228 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7446317672729492 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 0.7400466203689575 for ['[CLS] diploma catalogue honors knee skirt [SEP]']
[Init] best rec loss: 0.7324649691581726 for ['[CLS] forces solutions... offense civil [SEP]']
[Init] best perm rec loss: 0.727935254573822 for ['[CLS] forces offense civil... solutions [SEP]']
[Init] best perm rec loss: 0.7276415228843689 for ['[CLS] forces solutions offense... civil [SEP]']
[Init] best perm rec loss: 0.727533221244812 for ['[CLS]... solutions civil offense forces [SEP]']
[Init] best perm rec loss: 0.7274791598320007 for ['[CLS] solutions... offense civil forces [SEP]']
[Init] best perm rec loss: 0.7251647710800171 for ['[CLS] offense... solutions civil forces [SEP]']
[Init] best perm rec loss: 0.7243860960006714 for ['[CLS] forces offense... solutions civil [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.690 (perp=11.835, rec=0.292, cos=0.031), tot_loss_proj:3.598 [t=0.23s]
prediction: ['[CLS]gned face mistake return ticket [SEP]']
[ 100/2000] tot_loss=2.298 (perp=10.837, rec=0.125, cos=0.005), tot_loss_proj:2.828 [t=0.23s]
prediction: ['[CLS] for for looking return ticket [SEP]']
[ 150/2000] tot_loss=2.267 (perp=10.837, rec=0.097, cos=0.003), tot_loss_proj:2.835 [t=0.24s]
prediction: ['[CLS] for for looking return ticket [SEP]']
[ 200/2000] tot_loss=2.257 (perp=10.837, rec=0.086, cos=0.003), tot_loss_proj:2.831 [t=0.24s]
prediction: ['[CLS] for for looking return ticket [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.752 (perp=8.384, rec=0.072, cos=0.003), tot_loss_proj:2.229 [t=0.24s]
prediction: ['[CLS] for looking for return ticket [SEP]']
[ 300/2000] tot_loss=1.745 (perp=8.384, rec=0.066, cos=0.003), tot_loss_proj:2.240 [t=0.24s]
prediction: ['[CLS] for looking for return ticket [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.821 (perp=8.722, rec=0.074, cos=0.003), tot_loss_proj:2.268 [t=0.24s]
prediction: ['[CLS] for looking a return ticket [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.002), tot_loss_proj:1.319 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 450/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.001), tot_loss_proj:1.321 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.295 (perp=6.111, rec=0.071, cos=0.001), tot_loss_proj:1.312 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.292 (perp=6.111, rec=0.069, cos=0.001), tot_loss_proj:1.316 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 600/2000] tot_loss=1.286 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.322 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.286 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.311 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.285 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.322 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 750/2000] tot_loss=1.279 (perp=6.111, rec=0.055, cos=0.001), tot_loss_proj:1.317 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.276 (perp=6.111, rec=0.052, cos=0.001), tot_loss_proj:1.312 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.284 (perp=6.111, rec=0.060, cos=0.001), tot_loss_proj:1.316 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 900/2000] tot_loss=1.284 (perp=6.111, rec=0.060, cos=0.001), tot_loss_proj:1.313 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.281 (perp=6.111, rec=0.057, cos=0.001), tot_loss_proj:1.327 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.286 (perp=6.111, rec=0.062, cos=0.001), tot_loss_proj:1.315 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1050/2000] tot_loss=1.287 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.330 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.282 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.321 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.273 (perp=6.111, rec=0.049, cos=0.001), tot_loss_proj:1.317 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1200/2000] tot_loss=1.273 (perp=6.111, rec=0.050, cos=0.001), tot_loss_proj:1.319 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.287 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.276 (perp=6.111, rec=0.052, cos=0.001), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.289 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.326 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.282 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.332 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.286 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.312 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.274 (perp=6.111, rec=0.050, cos=0.001), tot_loss_proj:1.322 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.283 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.322 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.283 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.329 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.283 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.322 [t=0.30s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.287 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.283 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.327 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.274 (perp=6.111, rec=0.050, cos=0.001), tot_loss_proj:1.321 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.296 (perp=6.111, rec=0.073, cos=0.001), tot_loss_proj:1.334 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.283 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.312 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.819 | p: 91.522 | r: 92.248
rouge2     | fm: 62.817 | p: 62.626 | r: 63.070
rougeL     | fm: 80.429 | p: 80.127 | r: 80.774
rougeLsum  | fm: 80.370 | p: 80.105 | r: 80.678
r1fm+r2fm = 154.636

input #63 time: 0:09:16 | total time: 10:05:30


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.9991605989689818
highest_index [0]
highest [0.9991605989689818]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8780370354652405 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.865992546081543 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 0.7271021604537964 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6768224239349365 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.67481529712677 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 0.6732637882232666 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.973 (perp=8.653, rec=0.213, cos=0.030), tot_loss_proj:2.047 [t=0.22s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.898 (perp=8.653, rec=0.151, cos=0.016), tot_loss_proj:2.044 [t=0.22s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.870 (perp=8.653, rec=0.127, cos=0.012), tot_loss_proj:2.047 [t=0.22s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=1.868 (perp=8.653, rec=0.126, cos=0.012), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.045 (perp=9.634, rec=0.111, cos=0.006), tot_loss_proj:2.555 [t=0.22s]
prediction: ['[CLS] strange horror strange [SEP]']
[ 300/2000] tot_loss=1.923 (perp=9.286, rec=0.064, cos=0.002), tot_loss_proj:2.209 [t=0.22s]
prediction: ['[CLS] the horror strange [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.709 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.715 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.681 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.702 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.684 (perp=8.065, rec=0.069, cos=0.002), tot_loss_proj:1.702 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.673 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.706 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.670 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.712 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.668 (perp=8.065, rec=0.054, cos=0.002), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.673 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.711 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.684 (perp=8.065, rec=0.069, cos=0.002), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.672 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.706 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.706 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.683 (perp=8.065, rec=0.069, cos=0.002), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.679 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.713 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.666 (perp=8.065, rec=0.052, cos=0.002), tot_loss_proj:1.703 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.711 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.679 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.716 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.677 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.709 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.720 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.687 (perp=8.065, rec=0.072, cos=0.002), tot_loss_proj:1.703 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.702 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.712 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.711 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.665 (perp=8.065, rec=0.051, cos=0.002), tot_loss_proj:1.706 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.688 (perp=8.065, rec=0.074, cos=0.002), tot_loss_proj:1.701 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.674 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.713 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.681 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.702 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.028 | p: 91.691 | r: 92.417
rouge2     | fm: 63.767 | p: 63.519 | r: 64.065
rougeL     | fm: 80.796 | p: 80.546 | r: 81.144
rougeLsum  | fm: 80.847 | p: 80.573 | r: 81.195
r1fm+r2fm = 155.795

input #64 time: 0:08:45 | total time: 10:14:15


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9992253462692213
highest_index [0]
highest [0.9992253462692213]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.025086522102356 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9568408727645874 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9551860094070435 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.9448243975639343 for ['[CLS]blpf bce med stride plot skip honest what [SEP]']
[Init] best rec loss: 0.8855191469192505 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8788135051727295 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8770949840545654 for ['[CLS]mament even news general fun pu overshoff someday [SEP]']
[Init] best perm rec loss: 0.8740336894989014 for ['[CLS] even someday oversmament general pu funhoff news [SEP]']
[Init] best perm rec loss: 0.8733600378036499 for ['[CLS] news pu general evenmamenthoff someday fun overs [SEP]']
[Init] best perm rec loss: 0.8727949261665344 for ['[CLS] general newsmament someday overs fun puhoff even [SEP]']
[Init] best perm rec loss: 0.8721603155136108 for ['[CLS] general news someday pu even overshoff funmament [SEP]']
[Init] best perm rec loss: 0.8717846274375916 for ['[CLS] general pu even news someday overshoff funmament [SEP]']
[Init] best perm rec loss: 0.8717253804206848 for ['[CLS] general someday even news fun overs puhoffmament [SEP]']
[Init] best perm rec loss: 0.8714078068733215 for ['[CLS] someday generalhoff even oversmament pu news fun [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.336 (perp=10.131, rec=0.296, cos=0.014), tot_loss_proj:2.570 [t=0.22s]
prediction: ['[CLS]ous joy joy ofy joy film film joy [SEP]']
[ 100/2000] tot_loss=1.957 (perp=8.922, rec=0.169, cos=0.003), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS], joy joyousous romp film joy [SEP]']
[ 150/2000] tot_loss=2.137 (perp=10.084, rec=0.118, cos=0.002), tot_loss_proj:2.725 [t=0.22s]
prediction: ['[CLS], joy rom ofous romp film film [SEP]']
[ 200/2000] tot_loss=2.049 (perp=9.845, rec=0.078, cos=0.002), tot_loss_proj:2.600 [t=0.22s]
prediction: ['[CLS], joy rom ofous romp a film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.627 (perp=7.567, rec=0.111, cos=0.003), tot_loss_proj:2.391 [t=0.22s]
prediction: ['[CLS], of rom joyous romp a film [SEP]']
[ 300/2000] tot_loss=1.596 (perp=7.567, rec=0.082, cos=0.002), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS], of rom joyous romp a film [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.376 (perp=6.440, rec=0.086, cos=0.002), tot_loss_proj:1.529 [t=0.22s]
prediction: ['[CLS], joyous romp of film a film [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.302 (perp=6.098, rec=0.081, cos=0.001), tot_loss_proj:1.411 [t=0.22s]
prediction: ['[CLS], joyous film romp of a film [SEP]']
[ 450/2000] tot_loss=1.291 (perp=6.098, rec=0.070, cos=0.001), tot_loss_proj:1.413 [t=0.22s]
prediction: ['[CLS], joyous film romp of a film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.292 (perp=6.098, rec=0.071, cos=0.001), tot_loss_proj:1.411 [t=0.22s]
prediction: ['[CLS], joyous film romp of a film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.292 (perp=6.098, rec=0.071, cos=0.001), tot_loss_proj:1.395 [t=0.22s]
prediction: ['[CLS], joyous film romp of a film [SEP]']
[ 600/2000] tot_loss=1.299 (perp=6.098, rec=0.078, cos=0.001), tot_loss_proj:1.389 [t=0.22s]
prediction: ['[CLS], joyous film romp of a film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.296 (perp=6.098, rec=0.075, cos=0.002), tot_loss_proj:1.395 [t=0.22s]
prediction: ['[CLS], joyous film romp of a film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.461 (perp=6.915, rec=0.077, cos=0.002), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS], joyous. romp of a film [SEP]']
[ 750/2000] tot_loss=1.453 (perp=6.915, rec=0.068, cos=0.002), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS], joyous. romp of a film [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.151 (perp=5.396, rec=0.070, cos=0.002), tot_loss_proj:1.176 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.137 (perp=5.396, rec=0.056, cos=0.002), tot_loss_proj:1.178 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
[ 900/2000] tot_loss=1.133 (perp=5.396, rec=0.053, cos=0.002), tot_loss_proj:1.169 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.151 (perp=5.396, rec=0.070, cos=0.002), tot_loss_proj:1.177 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.137 (perp=5.396, rec=0.056, cos=0.002), tot_loss_proj:1.170 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
[1050/2000] tot_loss=1.148 (perp=5.396, rec=0.067, cos=0.002), tot_loss_proj:1.185 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.142 (perp=5.396, rec=0.062, cos=0.002), tot_loss_proj:1.179 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.144 (perp=5.396, rec=0.063, cos=0.002), tot_loss_proj:1.167 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
[1200/2000] tot_loss=1.144 (perp=5.396, rec=0.063, cos=0.002), tot_loss_proj:1.178 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.140 (perp=5.396, rec=0.059, cos=0.002), tot_loss_proj:1.179 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.138 (perp=5.396, rec=0.057, cos=0.002), tot_loss_proj:1.166 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
[1350/2000] tot_loss=1.145 (perp=5.396, rec=0.065, cos=0.002), tot_loss_proj:1.169 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.133 (perp=5.396, rec=0.052, cos=0.002), tot_loss_proj:1.171 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.135 (perp=5.396, rec=0.054, cos=0.002), tot_loss_proj:1.170 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
[1500/2000] tot_loss=1.141 (perp=5.396, rec=0.060, cos=0.002), tot_loss_proj:1.179 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.136 (perp=5.396, rec=0.056, cos=0.002), tot_loss_proj:1.168 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.146 (perp=5.396, rec=0.065, cos=0.002), tot_loss_proj:1.172 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
[1650/2000] tot_loss=1.144 (perp=5.396, rec=0.064, cos=0.002), tot_loss_proj:1.186 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.137 (perp=5.396, rec=0.056, cos=0.002), tot_loss_proj:1.176 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.139 (perp=5.396, rec=0.058, cos=0.002), tot_loss_proj:1.176 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
[1800/2000] tot_loss=1.143 (perp=5.396, rec=0.062, cos=0.002), tot_loss_proj:1.175 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.141 (perp=5.396, rec=0.060, cos=0.002), tot_loss_proj:1.176 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.136 (perp=5.396, rec=0.055, cos=0.002), tot_loss_proj:1.173 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
[1950/2000] tot_loss=1.134 (perp=5.396, rec=0.053, cos=0.002), tot_loss_proj:1.169 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.139 (perp=5.396, rec=0.058, cos=0.002), tot_loss_proj:1.169 [t=0.22s]
prediction: ['[CLS], joyous romp of a film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS], joyous romp of a film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.114 | p: 91.798 | r: 92.470
rouge2     | fm: 64.236 | p: 64.037 | r: 64.479
rougeL     | fm: 81.114 | p: 80.802 | r: 81.437
rougeLsum  | fm: 81.082 | p: 80.770 | r: 81.458
r1fm+r2fm = 156.350

input #65 time: 0:08:46 | total time: 10:23:02


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9992334111460102
highest_index [0]
highest [0.9992334111460102]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.9737173318862915 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.9308234453201294 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.9202260971069336 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8853452801704407 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.868087112903595 for ['[CLS]beersa bryce two [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.528 (perp=11.040, rec=0.302, cos=0.017), tot_loss_proj:3.509 [t=0.22s]
prediction: ['[CLS] fan attending fan fans [SEP]']
[ 100/2000] tot_loss=1.981 (perp=9.355, rec=0.108, cos=0.003), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] longtime a tolkien fan [SEP]']
[ 150/2000] tot_loss=1.948 (perp=9.355, rec=0.075, cos=0.002), tot_loss_proj:2.029 [t=0.22s]
prediction: ['[CLS] longtime a tolkien fan [SEP]']
[ 200/2000] tot_loss=1.941 (perp=9.355, rec=0.069, cos=0.002), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] longtime a tolkien fan [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.596 (perp=7.672, rec=0.060, cos=0.001), tot_loss_proj:1.608 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.605 (perp=7.672, rec=0.069, cos=0.002), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.587 (perp=7.672, rec=0.051, cos=0.002), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.588 (perp=7.672, rec=0.052, cos=0.002), tot_loss_proj:1.610 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.608 (perp=7.672, rec=0.072, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.596 (perp=7.672, rec=0.060, cos=0.002), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.587 (perp=7.672, rec=0.051, cos=0.002), tot_loss_proj:1.609 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.603 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.593 (perp=7.672, rec=0.057, cos=0.002), tot_loss_proj:1.607 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.607 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.593 (perp=7.672, rec=0.057, cos=0.002), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.603 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.604 (perp=7.672, rec=0.068, cos=0.002), tot_loss_proj:1.595 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.607 (perp=7.672, rec=0.071, cos=0.002), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.588 (perp=7.672, rec=0.052, cos=0.002), tot_loss_proj:1.604 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.599 (perp=7.672, rec=0.063, cos=0.002), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.617 (perp=7.672, rec=0.081, cos=0.002), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.603 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.604 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.608 (perp=7.672, rec=0.072, cos=0.002), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.610 (perp=7.672, rec=0.074, cos=0.002), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.601 (perp=7.672, rec=0.065, cos=0.002), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.603 (perp=7.672, rec=0.067, cos=0.002), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.589 (perp=7.672, rec=0.053, cos=0.002), tot_loss_proj:1.603 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.605 (perp=7.672, rec=0.069, cos=0.002), tot_loss_proj:1.608 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.608 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.592 (perp=7.672, rec=0.056, cos=0.002), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.604 (perp=7.672, rec=0.068, cos=0.002), tot_loss_proj:1.603 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.609 (perp=7.672, rec=0.073, cos=0.002), tot_loss_proj:1.605 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.604 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.586 (perp=7.672, rec=0.050, cos=0.002), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.261 | p: 91.927 | r: 92.641
rouge2     | fm: 64.692 | p: 64.518 | r: 64.939
rougeL     | fm: 81.393 | p: 81.169 | r: 81.692
rougeLsum  | fm: 81.335 | p: 80.981 | r: 81.714
r1fm+r2fm = 156.953

input #66 time: 0:08:45 | total time: 10:31:47


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.9992930121177666
highest_index [0]
highest [0.9992930121177666]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.005165934562683 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9613745808601379 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.9571365714073181 for ['[CLS] repeat well rv strikes combined leaned written itself welsh bunch [SEP]']
[Init] best rec loss: 0.9488541483879089 for ['[CLS] position citationliga carriage demands source administered leancode pope [SEP]']
[Init] best rec loss: 0.9410316348075867 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 0.9324914216995239 for ['[CLS] investment parker mostly radical national snow nearly baltimore contact are [SEP]']
[Init] best rec loss: 0.9314884543418884 for ['[CLS]ible ultimately season mainly swifthood abby source price need [SEP]']
[Init] best rec loss: 0.930374264717102 for ['[CLS] wild tribes upon cone home enough promotion mural courtney ） [SEP]']
[Init] best perm rec loss: 0.929959774017334 for ['[CLS] cone upon promotion ） courtney enough mural tribes wild home [SEP]']
[Init] best perm rec loss: 0.9298282265663147 for ['[CLS] mural tribes promotion wild cone ） courtney home enough upon [SEP]']
[Init] best perm rec loss: 0.927698016166687 for ['[CLS] home cone wild enough tribes ） courtney upon mural promotion [SEP]']
[Init] best perm rec loss: 0.9275584816932678 for ['[CLS] promotion ） wild courtney cone mural home tribes upon enough [SEP]']
[Init] best perm rec loss: 0.9234167337417603 for ['[CLS] ） cone home mural wild upon courtney promotion enough tribes [SEP]']
[Init] best perm rec loss: 0.923023521900177 for ['[CLS] upon tribes home cone promotion ） enough wild courtney mural [SEP]']
[Init] best perm rec loss: 0.921942949295044 for ['[CLS] upon promotion wild home cone tribes mural ） enough courtney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.905 (perp=12.955, rec=0.307, cos=0.008), tot_loss_proj:3.358 [t=0.24s]
prediction: ['[CLS] pastwar adult kind seeing enjoyeddberg kind kind kind [SEP]']
[ 100/2000] tot_loss=2.548 (perp=11.752, rec=0.195, cos=0.003), tot_loss_proj:3.397 [t=0.24s]
prediction: ['[CLS] heartwar eye kind,wargm kind kind kind [SEP]']
[ 150/2000] tot_loss=2.556 (perp=11.897, rec=0.172, cos=0.005), tot_loss_proj:4.046 [t=0.24s]
prediction: ['[CLS] heartwar eyewar nonwargmental kindental [SEP]']
[ 200/2000] tot_loss=2.843 (perp=13.585, rec=0.124, cos=0.002), tot_loss_proj:4.374 [t=0.24s]
prediction: ['[CLS] heartwarntwar nonwargmming kindental [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.316 (perp=10.809, rec=0.151, cos=0.003), tot_loss_proj:3.453 [t=0.24s]
prediction: ['[CLS] heartwar actedwar,warming kindgmental [SEP]']
[ 300/2000] tot_loss=2.356 (perp=11.202, rec=0.114, cos=0.002), tot_loss_proj:3.541 [t=0.24s]
prediction: ['[CLS] heartwar gameplaywar,warming kindgmental [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.246 (perp=10.617, rec=0.120, cos=0.002), tot_loss_proj:3.023 [t=0.24s]
prediction: ['[CLS] heartwarwarming blondwar, kind nonental [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.144 (perp=10.101, rec=0.121, cos=0.002), tot_loss_proj:2.770 [t=0.24s]
prediction: ['[CLS] heartwarwarming nonwar, kind quantitativeental [SEP]']
[ 450/2000] tot_loss=2.137 (perp=10.101, rec=0.115, cos=0.002), tot_loss_proj:2.780 [t=0.24s]
prediction: ['[CLS] heartwarwarming nonwar, kind quantitativeental [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.014 (perp=9.474, rec=0.117, cos=0.002), tot_loss_proj:2.528 [t=0.24s]
prediction: ['[CLS] heartwarwarming nonmingental kind quantitative, [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.822 (perp=8.516, rec=0.117, cos=0.002), tot_loss_proj:2.846 [t=0.24s]
prediction: ['[CLS] heartwarming nonwarmingental kind tasting, [SEP]']
[ 600/2000] tot_loss=1.693 (perp=7.993, rec=0.093, cos=0.002), tot_loss_proj:2.943 [t=0.24s]
prediction: ['[CLS] heartwarming nonwarmingental kindent, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.695 (perp=7.993, rec=0.095, cos=0.002), tot_loss_proj:2.943 [t=0.24s]
prediction: ['[CLS] heartwarming nonwarmingental kindent, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.683 (perp=7.993, rec=0.083, cos=0.002), tot_loss_proj:2.943 [t=0.24s]
prediction: ['[CLS] heartwarming nonwarmingental kindent, [SEP]']
[ 750/2000] tot_loss=1.938 (perp=9.247, rec=0.087, cos=0.002), tot_loss_proj:2.556 [t=0.24s]
prediction: ['[CLS] heartwarming nongmmingental kindent, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.609 (perp=7.580, rec=0.091, cos=0.002), tot_loss_proj:2.215 [t=0.24s]
prediction: ['[CLS] heartwarming nonminggmental kindent, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.603 (perp=7.580, rec=0.086, cos=0.002), tot_loss_proj:2.218 [t=0.24s]
prediction: ['[CLS] heartwarming nonminggmental kindent, [SEP]']
[ 900/2000] tot_loss=1.599 (perp=7.580, rec=0.081, cos=0.002), tot_loss_proj:2.220 [t=0.24s]
prediction: ['[CLS] heartwarming nonminggmental kindent, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.712 (perp=8.080, rec=0.094, cos=0.002), tot_loss_proj:2.178 [t=0.24s]
prediction: ['[CLS] heartwarming nonminggmental kind individuals, [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.542 (perp=7.164, rec=0.107, cos=0.002), tot_loss_proj:1.860 [t=0.24s]
prediction: ['[CLS] kind heartwarming nonminggmental individuals, [SEP]']
[1050/2000] tot_loss=1.592 (perp=7.496, rec=0.091, cos=0.002), tot_loss_proj:2.153 [t=0.24s]
prediction: ['[CLS] kind heartwarming nonminggmentald, [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.482 (perp=6.934, rec=0.094, cos=0.002), tot_loss_proj:1.763 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonminggmental creative [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.516 (perp=7.092, rec=0.096, cos=0.002), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nongmentaldming [SEP]']
[1200/2000] tot_loss=1.507 (perp=7.092, rec=0.087, cos=0.002), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nongmentaldming [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.443 (perp=6.837, rec=0.074, cos=0.002), tot_loss_proj:1.856 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nondgmentalming [SEP]']
Attempt swap
[1300/2000] tot_loss=1.452 (perp=6.837, rec=0.082, cos=0.002), tot_loss_proj:1.845 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nondgmentalming [SEP]']
[1350/2000] tot_loss=1.438 (perp=6.837, rec=0.069, cos=0.002), tot_loss_proj:1.841 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nondgmentalming [SEP]']
Attempt swap
[1400/2000] tot_loss=1.451 (perp=6.837, rec=0.082, cos=0.002), tot_loss_proj:1.849 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nondgmentalming [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.342 (perp=6.223, rec=0.095, cos=0.002), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
[1500/2000] tot_loss=1.328 (perp=6.223, rec=0.082, cos=0.002), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
Attempt swap
[1550/2000] tot_loss=1.330 (perp=6.223, rec=0.084, cos=0.002), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
Attempt swap
[1600/2000] tot_loss=1.323 (perp=6.223, rec=0.076, cos=0.002), tot_loss_proj:1.691 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
[1650/2000] tot_loss=1.337 (perp=6.223, rec=0.091, cos=0.002), tot_loss_proj:1.689 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
Attempt swap
[1700/2000] tot_loss=1.322 (perp=6.223, rec=0.076, cos=0.002), tot_loss_proj:1.691 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
Attempt swap
[1750/2000] tot_loss=1.317 (perp=6.223, rec=0.071, cos=0.002), tot_loss_proj:1.691 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
[1800/2000] tot_loss=1.328 (perp=6.223, rec=0.082, cos=0.002), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
Attempt swap
[1850/2000] tot_loss=1.333 (perp=6.223, rec=0.087, cos=0.002), tot_loss_proj:1.686 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
Attempt swap
[1900/2000] tot_loss=1.329 (perp=6.223, rec=0.083, cos=0.002), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
[1950/2000] tot_loss=1.329 (perp=6.223, rec=0.083, cos=0.002), tot_loss_proj:1.691 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
Attempt swap
[2000/2000] tot_loss=1.335 (perp=6.223, rec=0.089, cos=0.002), tot_loss_proj:1.686 [t=0.24s]
prediction: ['[CLS] kind heartwarming, nonmingdgmental [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind heartwarming, nonmingdgmental [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 80.000

[Aggregate metrics]:
rouge1     | fm: 92.018 | p: 91.737 | r: 92.428
rouge2     | fm: 63.778 | p: 63.584 | r: 64.040
rougeL     | fm: 81.053 | p: 80.815 | r: 81.341
rougeLsum  | fm: 80.997 | p: 80.737 | r: 81.343
r1fm+r2fm = 155.795

input #67 time: 0:09:28 | total time: 10:41:16


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9992788464941955
highest_index [0]
highest [0.9992788464941955]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9892685413360596 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9690264463424683 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.9392844438552856 for ['[CLS] raise describedwehrwork witch rom can bray fictional elton here sex pilots [SEP]']
[Init] best rec loss: 0.9260305762290955 for ['[CLS] neutron acrosswas 2005 security tip fa— identity david entitled readers letters [SEP]']
[Init] best rec loss: 0.8682870864868164 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8625865578651428 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8616510033607483 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8608852028846741 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8606603145599365 for ['[CLS]iferous form medal comfort councils possibly diedyn riding floor. view beth [SEP]']
[Init] best perm rec loss: 0.8585078120231628 for ['[CLS]yn view beth form. comfort riding medal died councils flooriferous possibly [SEP]']
[Init] best perm rec loss: 0.8575673699378967 for ['[CLS] riding possibly died bethyn medal. comfortiferous form view councils floor [SEP]']
[Init] best perm rec loss: 0.8523683547973633 for ['[CLS] medal comfort riding. councils beth died formyniferous floor view possibly [SEP]']
[Init] best perm rec loss: 0.8509644269943237 for ['[CLS]iferous died beth. ridingyn form councils medal possibly floor view comfort [SEP]']
[Init] best perm rec loss: 0.8499634861946106 for ['[CLS] died comfort beth riding councils possibly. medalyn floor form viewiferous [SEP]']
[Init] best perm rec loss: 0.8496124148368835 for ['[CLS] viewiferous comfort councils form beth possibly died medalyn floor riding. [SEP]']
[Init] best perm rec loss: 0.8491353988647461 for ['[CLS]yn councils possibly formiferous beth medal floor. riding comfort view died [SEP]']
[Init] best perm rec loss: 0.8445032835006714 for ['[CLS]yn. comfort diediferous possibly form councils beth floor medal view riding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.273 (perp=10.456, rec=0.178, cos=0.004), tot_loss_proj:2.736 [t=0.23s]
prediction: ['[CLS] un absurdct,,ulously libretto vicioussible vicious and absurd ( [SEP]']
[ 100/2000] tot_loss=2.352 (perp=10.639, rec=0.219, cos=0.006), tot_loss_proj:2.621 [t=0.24s]
prediction: ['[CLS] uncoct,, semi [CLS] / chapter vicious - absurd ellen [SEP]']
[ 150/2000] tot_loss=2.009 (perp=9.201, rec=0.165, cos=0.004), tot_loss_proj:2.220 [t=0.24s]
prediction: ['[CLS] uncouth,, semisible /omp vicious - absurd ellen [SEP]']
[ 200/2000] tot_loss=1.895 (perp=8.848, rec=0.123, cos=0.003), tot_loss_proj:2.219 [t=0.24s]
prediction: ['[CLS] uncouth, andidisible /sible vicious - absurd ellen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.095 (perp=9.853, rec=0.122, cos=0.002), tot_loss_proj:2.354 [t=0.24s]
prediction: ['[CLS] uncouth, andhen -siblesible vicious - absurdhurst [SEP]']
[ 300/2000] tot_loss=2.047 (perp=9.694, rec=0.106, cos=0.002), tot_loss_proj:2.561 [t=0.24s]
prediction: ['[CLS] uncouth, andhen -siblesible vicious - absurd inmates [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.697 (perp=7.987, rec=0.098, cos=0.002), tot_loss_proj:2.231 [t=0.24s]
prediction: ['[CLS] uncouth, andsible -hensible vicious - absurd inmates [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.501 (perp=6.950, rec=0.109, cos=0.002), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] uncouth andsible -hensible, vicious - absurd inmates [SEP]']
[ 450/2000] tot_loss=1.881 (perp=8.900, rec=0.099, cos=0.002), tot_loss_proj:2.306 [t=0.24s]
prediction: ['[CLS] uncouth andsibleihensible, vicious - absurd inmates [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.698 (perp=7.981, rec=0.100, cos=0.002), tot_loss_proj:2.139 [t=0.24s]
prediction: ['[CLS] uncouth andsible -hensible, viciousi absurd inmates [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.819 (perp=8.588, rec=0.100, cos=0.002), tot_loss_proj:2.222 [t=0.24s]
prediction: ['[CLS] uncouth andsible -hensible, vicious inmates absurd fi [SEP]']
[ 600/2000] tot_loss=1.850 (perp=8.804, rec=0.087, cos=0.002), tot_loss_proj:2.167 [t=0.24s]
prediction: ['[CLS] uncouth andsible -hensible, viciousion absurd af [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.813 (perp=8.612, rec=0.089, cos=0.002), tot_loss_proj:2.077 [t=0.24s]
prediction: ['[CLS] uncouth andsible -hensible, viciousre absurdion [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.628 (perp=7.681, rec=0.090, cos=0.002), tot_loss_proj:1.846 [t=0.24s]
prediction: ['[CLS] uncouth andsiblerehensible, vicious - absurdion [SEP]']
[ 750/2000] tot_loss=2.142 (perp=10.261, rec=0.088, cos=0.002), tot_loss_proj:2.495 [t=0.24s]
prediction: ['[CLS] uncouth andsibleihenomp, vicious - absurdion [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.722 (perp=8.219, rec=0.077, cos=0.002), tot_loss_proj:2.028 [t=0.24s]
prediction: ['[CLS] uncouth andsibleomprehen, vicious - absurdion [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.585 (perp=7.425, rec=0.097, cos=0.002), tot_loss_proj:1.827 [t=0.24s]
prediction: ['[CLS] uncouth -sibleomprehen, vicious and absurdion [SEP]']
[ 900/2000] tot_loss=1.567 (perp=7.425, rec=0.080, cos=0.002), tot_loss_proj:1.824 [t=0.24s]
prediction: ['[CLS] uncouth -sibleomprehen, vicious and absurdion [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.568 (perp=7.425, rec=0.081, cos=0.002), tot_loss_proj:1.829 [t=0.24s]
prediction: ['[CLS] uncouth -sibleomprehen, vicious and absurdion [SEP]']
Attempt swap
[1000/2000] tot_loss=1.583 (perp=7.425, rec=0.097, cos=0.002), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] uncouth -sibleomprehen, vicious and absurdion [SEP]']
[1050/2000] tot_loss=1.561 (perp=7.425, rec=0.074, cos=0.002), tot_loss_proj:1.829 [t=0.24s]
prediction: ['[CLS] uncouth -sibleomprehen, vicious and absurdion [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.335 (perp=6.247, rec=0.084, cos=0.002), tot_loss_proj:1.500 [t=0.24s]
prediction: ['[CLS] uncouth -omprehensible, vicious and absurdion [SEP]']
Attempt swap
[1150/2000] tot_loss=1.337 (perp=6.247, rec=0.086, cos=0.002), tot_loss_proj:1.501 [t=0.24s]
prediction: ['[CLS] uncouth -omprehensible, vicious and absurdion [SEP]']
[1200/2000] tot_loss=1.335 (perp=6.247, rec=0.084, cos=0.002), tot_loss_proj:1.501 [t=0.24s]
prediction: ['[CLS] uncouth -omprehensible, vicious and absurdion [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.287 (perp=6.061, rec=0.073, cos=0.002), tot_loss_proj:1.426 [t=0.24s]
prediction: ['[CLS] uncouthion -omprehensible, vicious and absurd [SEP]']
Attempt swap
[1300/2000] tot_loss=1.296 (perp=6.061, rec=0.082, cos=0.002), tot_loss_proj:1.420 [t=0.24s]
prediction: ['[CLS] uncouthion -omprehensible, vicious and absurd [SEP]']
[1350/2000] tot_loss=1.172 (perp=5.439, rec=0.082, cos=0.002), tot_loss_proj:1.339 [t=0.24s]
prediction: ['[CLS] uncouthion incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1400/2000] tot_loss=1.169 (perp=5.439, rec=0.079, cos=0.002), tot_loss_proj:1.331 [t=0.24s]
prediction: ['[CLS] uncouthion incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1450/2000] tot_loss=1.176 (perp=5.439, rec=0.087, cos=0.002), tot_loss_proj:1.321 [t=0.24s]
prediction: ['[CLS] uncouthion incomprehensible, vicious and absurd [SEP]']
[1500/2000] tot_loss=1.083 (perp=5.030, rec=0.076, cos=0.002), tot_loss_proj:1.199 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=1.079 (perp=5.030, rec=0.072, cos=0.002), tot_loss_proj:1.208 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1600/2000] tot_loss=1.083 (perp=5.030, rec=0.076, cos=0.001), tot_loss_proj:1.206 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
[1650/2000] tot_loss=1.080 (perp=5.030, rec=0.073, cos=0.001), tot_loss_proj:1.204 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=1.087 (perp=5.030, rec=0.079, cos=0.001), tot_loss_proj:1.205 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=1.078 (perp=5.030, rec=0.070, cos=0.001), tot_loss_proj:1.207 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
[1800/2000] tot_loss=1.076 (perp=5.030, rec=0.069, cos=0.001), tot_loss_proj:1.206 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=1.078 (perp=5.030, rec=0.070, cos=0.001), tot_loss_proj:1.195 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=1.081 (perp=5.030, rec=0.073, cos=0.001), tot_loss_proj:1.200 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
[1950/2000] tot_loss=1.084 (perp=5.030, rec=0.076, cos=0.001), tot_loss_proj:1.211 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=1.081 (perp=5.030, rec=0.073, cos=0.001), tot_loss_proj:1.201 [t=0.24s]
prediction: ['[CLS] uncouthious incomprehensible, vicious and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouthious incomprehensible, vicious and absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 152.381

[Aggregate metrics]:
rouge1     | fm: 91.929 | p: 91.653 | r: 92.292
rouge2     | fm: 63.677 | p: 63.487 | r: 63.890
rougeL     | fm: 81.135 | p: 80.888 | r: 81.418
rougeLsum  | fm: 81.010 | p: 80.727 | r: 81.353
r1fm+r2fm = 155.607

input #68 time: 0:09:18 | total time: 10:50:35


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9992906888884341
highest_index [0]
highest [0.9992906888884341]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.0882316827774048 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.945919394493103 for ['[CLS] cade atoms especially suddenly schneider commanded noble retirement causescap meant grin immortals fai act paternal [SEP]']
[Init] best rec loss: 0.930613100528717 for ['[CLS] meetings bells mountain bloody technical script⁄ sarah rebound fare they br hospital christmas value turkmenistan [SEP]']
[Init] best rec loss: 0.9267537593841553 for ['[CLS] et roughly christian cinema angela zoo commanded determinedpine treatcraft said being amountigo ; [SEP]']
[Init] best rec loss: 0.9248879551887512 for ['[CLS] transplant valley true bu golfer grabbed law ee wet especially comics energytics shorter packed hunting [SEP]']
[Init] best rec loss: 0.9164901375770569 for ['[CLS] operation tactics toes collective valley stitches drop criticism insteadivequitable francis surnamezer san zone [SEP]']
[Init] best rec loss: 0.9076429605484009 for ['[CLS] mans border mormon vocational be doubt recordseft outcomes same humor spring chi ears other ling [SEP]']
[Init] best rec loss: 0.8819190859794617 for ['[CLS] tract havinggated libraries himself odd magna courtney jonah tempted miller stunning spit opened french now [SEP]']
[Init] best rec loss: 0.8754848837852478 for ['[CLS]mission down unopposedacio tray adelaide african platform burnham ferrisest port case [MASK] gross main [SEP]']
[Init] best perm rec loss: 0.8741894364356995 for ['[CLS] [MASK]acio burnham platformest gross adelaide case unopposed ferris tray down africanmission main port [SEP]']
[Init] best perm rec loss: 0.8735032677650452 for ['[CLS]acio african tray burnham adelaide ferris gross port unopposed case [MASK] main platform downestmission [SEP]']
[Init] best perm rec loss: 0.8721978068351746 for ['[CLS] case platform portmission african adelaide tray mainacio ferrisest [MASK] burnham gross down unopposed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.179 (perp=9.616, rec=0.251, cos=0.004), tot_loss_proj:2.650 [t=0.24s]
prediction: ['[CLS] happy won smart really sweet. - brady real cu champion & :.,. [SEP]']
[ 100/2000] tot_loss=2.045 (perp=9.242, rec=0.194, cos=0.002), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] funnyona smart real smart, - winner real cu winner &,.,. [SEP]']
[ 150/2000] tot_loss=2.076 (perp=9.516, rec=0.170, cos=0.002), tot_loss_proj:2.556 [t=0.24s]
prediction: ['[CLS] funnyona smart real smart, - winner realvy winner &, -,. [SEP]']
[ 200/2000] tot_loss=2.106 (perp=9.794, rec=0.146, cos=0.002), tot_loss_proj:2.716 [t=0.24s]
prediction: ['[CLS] funnyona subtle real smart, - winner real wade winner &, -,. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.942 (perp=9.014, rec=0.137, cos=0.002), tot_loss_proj:2.500 [t=0.24s]
prediction: ['[CLS] funnyona subtle real smart, and winner real wade, &, - -. [SEP]']
[ 300/2000] tot_loss=2.045 (perp=9.623, rec=0.119, cos=0.002), tot_loss_proj:2.750 [t=0.24s]
prediction: ['[CLS] funnyona subtle real smart, and winner real obliquent and, - -. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.888 (perp=8.831, rec=0.120, cos=0.002), tot_loss_proj:2.439 [t=0.24s]
prediction: ['[CLS],ona subtle real smart, and winner real obliquent and funny - -. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.681 (perp=7.815, rec=0.116, cos=0.002), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS]ona subtle, real smart, and winner real petitent and funny - -. [SEP]']
[ 450/2000] tot_loss=1.860 (perp=8.775, rec=0.103, cos=0.002), tot_loss_proj:2.447 [t=0.24s]
prediction: ['[CLS]ona subtle, real smart, and winner real bethanynt and funny - res. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.752 (perp=8.132, rec=0.123, cos=0.002), tot_loss_proj:2.138 [t=0.24s]
prediction: ['[CLS]onant, real smart, and winner real assurance subtle and funny - res. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.458 (perp=6.543, rec=0.147, cos=0.002), tot_loss_proj:1.670 [t=0.24s]
prediction: ['[CLS], real smart, and winner real - subtle & funny - resonant. [SEP]']
[ 600/2000] tot_loss=1.626 (perp=7.503, rec=0.124, cos=0.002), tot_loss_proj:1.900 [t=0.24s]
prediction: ['[CLS], real smart, and winner real - subtle your funny - resonant. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.414 (perp=6.462, rec=0.120, cos=0.002), tot_loss_proj:1.617 [t=0.24s]
prediction: ['[CLS], real smart, and winner real - subtle and funny - resonant. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.310 (perp=6.027, rec=0.103, cos=0.002), tot_loss_proj:1.495 [t=0.24s]
prediction: ['[CLS], real smart, and real winner - subtle and funny - resonant. [SEP]']
[ 750/2000] tot_loss=1.303 (perp=6.027, rec=0.096, cos=0.002), tot_loss_proj:1.498 [t=0.24s]
prediction: ['[CLS], real smart, and real winner - subtle and funny - resonant. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.283 (perp=5.915, rec=0.099, cos=0.002), tot_loss_proj:1.472 [t=0.24s]
prediction: ['[CLS], real smart, and real winner - funny and subtle - resonant. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.280 (perp=5.915, rec=0.095, cos=0.002), tot_loss_proj:1.472 [t=0.24s]
prediction: ['[CLS], real smart, and real winner - funny and subtle - resonant. [SEP]']
[ 900/2000] tot_loss=1.286 (perp=5.915, rec=0.101, cos=0.002), tot_loss_proj:1.473 [t=0.24s]
prediction: ['[CLS], real smart, and real winner - funny and subtle - resonant. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.285 (perp=5.915, rec=0.100, cos=0.002), tot_loss_proj:1.480 [t=0.24s]
prediction: ['[CLS], real smart, and real winner - funny and subtle - resonant. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.253 (perp=5.798, rec=0.092, cos=0.002), tot_loss_proj:1.433 [t=0.24s]
prediction: ['[CLS], a smart, and real winner - funny and subtle - resonant. [SEP]']
[1050/2000] tot_loss=1.448 (perp=6.751, rec=0.096, cos=0.002), tot_loss_proj:2.088 [t=0.24s]
prediction: ['[CLS], a smart, when real winner - funny and subtle - resonant. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.341 (perp=6.204, rec=0.098, cos=0.002), tot_loss_proj:1.982 [t=0.24s]
prediction: ['[CLS], when smart, a real winner - funny and subtle - resonant. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.235 (perp=5.632, rec=0.106, cos=0.002), tot_loss_proj:1.969 [t=0.24s]
prediction: ['[CLS], when funny, a real winner - smart and subtle - resonant. [SEP]']
[1200/2000] tot_loss=1.369 (perp=6.356, rec=0.096, cos=0.002), tot_loss_proj:1.700 [t=0.24s]
prediction: ['[CLS], challenged funny, a real winner - smart and subtle - resonant. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.357 (perp=6.356, rec=0.084, cos=0.002), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS], challenged funny, a real winner - smart and subtle - resonant. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.371 (perp=6.356, rec=0.098, cos=0.002), tot_loss_proj:1.697 [t=0.24s]
prediction: ['[CLS], challenged funny, a real winner - smart and subtle - resonant. [SEP]']
[1350/2000] tot_loss=1.372 (perp=6.356, rec=0.099, cos=0.002), tot_loss_proj:1.700 [t=0.24s]
prediction: ['[CLS], challenged funny, a real winner - smart and subtle - resonant. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.328 (perp=6.170, rec=0.093, cos=0.002), tot_loss_proj:1.607 [t=0.24s]
prediction: ['[CLS], funny challenged, a real winner - smart and subtle - resonant. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.328 (perp=6.170, rec=0.093, cos=0.002), tot_loss_proj:1.603 [t=0.24s]
prediction: ['[CLS], funny challenged, a real winner - smart and subtle - resonant. [SEP]']
[1500/2000] tot_loss=1.433 (perp=6.673, rec=0.097, cos=0.002), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS], funny your, a real winner - smart and subtle - resonant. [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.370 (perp=6.376, rec=0.093, cos=0.002), tot_loss_proj:1.626 [t=0.24s]
prediction: ['[CLS], your, a real winner - funny smart and subtle - resonant. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.195 (perp=5.465, rec=0.100, cos=0.002), tot_loss_proj:1.395 [t=0.24s]
prediction: ['[CLS], your a real winner - funny, smart and subtle - resonant. [SEP]']
[1650/2000] tot_loss=1.187 (perp=5.465, rec=0.092, cos=0.002), tot_loss_proj:1.401 [t=0.24s]
prediction: ['[CLS], your a real winner - funny, smart and subtle - resonant. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.191 (perp=5.465, rec=0.097, cos=0.002), tot_loss_proj:1.399 [t=0.24s]
prediction: ['[CLS], your a real winner - funny, smart and subtle - resonant. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.185 (perp=5.465, rec=0.091, cos=0.002), tot_loss_proj:1.407 [t=0.24s]
prediction: ['[CLS], your a real winner - funny, smart and subtle - resonant. [SEP]']
[1800/2000] tot_loss=1.188 (perp=5.465, rec=0.093, cos=0.002), tot_loss_proj:1.399 [t=0.24s]
prediction: ['[CLS], your a real winner - funny, smart and subtle - resonant. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.165 (perp=5.354, rec=0.092, cos=0.002), tot_loss_proj:1.397 [t=0.24s]
prediction: ['[CLS], your real a winner - funny, smart and subtle - resonant. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.166 (perp=5.354, rec=0.093, cos=0.002), tot_loss_proj:1.399 [t=0.24s]
prediction: ['[CLS], your real a winner - funny, smart and subtle - resonant. [SEP]']
[1950/2000] tot_loss=1.164 (perp=5.354, rec=0.091, cos=0.002), tot_loss_proj:1.398 [t=0.24s]
prediction: ['[CLS], your real a winner - funny, smart and subtle - resonant. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.165 (perp=5.354, rec=0.093, cos=0.002), tot_loss_proj:1.398 [t=0.24s]
prediction: ['[CLS], your real a winner - funny, smart and subtle - resonant. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS], challenged funny, a real winner - smart and subtle - resonant. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 42.105 | p: 40.000 | r: 44.444
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 137.343

[Aggregate metrics]:
rouge1     | fm: 92.013 | p: 91.672 | r: 92.475
rouge2     | fm: 63.514 | p: 63.283 | r: 63.757
rougeL     | fm: 81.054 | p: 80.745 | r: 81.394
rougeLsum  | fm: 80.922 | p: 80.612 | r: 81.330
r1fm+r2fm = 155.527

input #69 time: 0:09:26 | total time: 11:00:01


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.999374729045543
highest_index [0]
highest [0.999374729045543]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8474195003509521 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.8209116458892822 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7967671751976013 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7394418716430664 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best perm rec loss: 0.7338972091674805 for ['[CLS] detention technological sharma herself blood mark effects [SEP]']
[Init] best perm rec loss: 0.7322249412536621 for ['[CLS] blood sharma herself effects mark detention technological [SEP]']
[Init] best perm rec loss: 0.7319478988647461 for ['[CLS] mark herself sharma effects technological detention blood [SEP]']
[Init] best perm rec loss: 0.731513500213623 for ['[CLS] effects sharma blood detention herself technological mark [SEP]']
[Init] best perm rec loss: 0.7302557826042175 for ['[CLS] sharma mark herself technological detention effects blood [SEP]']
[Init] best perm rec loss: 0.7295522689819336 for ['[CLS] mark sharma herself technological detention effects blood [SEP]']
[Init] best perm rec loss: 0.7283495664596558 for ['[CLS] herself sharma effects detention technological mark blood [SEP]']
[Init] best perm rec loss: 0.7259199619293213 for ['[CLS] detention sharma herself blood effects technological mark [SEP]']
[Init] best perm rec loss: 0.7253750562667847 for ['[CLS] detention sharma mark blood technological herself effects [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.182 (perp=14.075, rec=0.332, cos=0.035), tot_loss_proj:4.265 [t=0.23s]
prediction: ['[CLS] helpsunk stuckunkunk happeningunk [SEP]']
[ 100/2000] tot_loss=3.247 (perp=13.867, rec=0.329, cos=0.144), tot_loss_proj:3.904 [t=0.23s]
prediction: ['[CLS] gets screen getsunkunk around cl [SEP]']
[ 150/2000] tot_loss=2.719 (perp=12.764, rec=0.157, cos=0.009), tot_loss_proj:4.298 [t=0.24s]
prediction: ['[CLS] gets screen getsunkunk ony [SEP]']
[ 200/2000] tot_loss=2.677 (perp=12.764, rec=0.119, cos=0.006), tot_loss_proj:4.305 [t=0.24s]
prediction: ['[CLS] gets screen getsunkunk ony [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.128 (perp=10.045, rec=0.114, cos=0.005), tot_loss_proj:3.493 [t=0.24s]
prediction: ['[CLS] gets on screen getsunk cly [SEP]']
[ 300/2000] tot_loss=2.111 (perp=10.045, rec=0.099, cos=0.003), tot_loss_proj:3.486 [t=0.24s]
prediction: ['[CLS] gets on screen getsunk cly [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.382 (perp=6.438, rec=0.091, cos=0.003), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.375 (perp=6.438, rec=0.085, cos=0.003), tot_loss_proj:1.670 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[ 450/2000] tot_loss=1.369 (perp=6.438, rec=0.078, cos=0.002), tot_loss_proj:1.674 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.364 (perp=6.438, rec=0.074, cos=0.003), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.376 (perp=6.438, rec=0.086, cos=0.002), tot_loss_proj:1.673 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[ 600/2000] tot_loss=1.370 (perp=6.438, rec=0.081, cos=0.002), tot_loss_proj:1.672 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.368 (perp=6.438, rec=0.079, cos=0.002), tot_loss_proj:1.673 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.365 (perp=6.438, rec=0.076, cos=0.002), tot_loss_proj:1.676 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[ 750/2000] tot_loss=1.361 (perp=6.438, rec=0.072, cos=0.002), tot_loss_proj:1.668 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.847 (perp=8.827, rec=0.080, cos=0.002), tot_loss_proj:2.330 [t=0.24s]
prediction: ['[CLS] gets on screen cl clunky [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.395 (perp=6.438, rec=0.103, cos=0.005), tot_loss_proj:1.736 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[ 900/2000] tot_loss=1.370 (perp=6.438, rec=0.080, cos=0.003), tot_loss_proj:1.720 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.372 (perp=6.438, rec=0.082, cos=0.002), tot_loss_proj:1.716 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.364 (perp=6.438, rec=0.074, cos=0.002), tot_loss_proj:1.720 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[1050/2000] tot_loss=1.374 (perp=6.438, rec=0.084, cos=0.002), tot_loss_proj:1.724 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.376 (perp=6.438, rec=0.086, cos=0.002), tot_loss_proj:1.719 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.368 (perp=6.438, rec=0.078, cos=0.002), tot_loss_proj:1.725 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[1200/2000] tot_loss=1.369 (perp=6.438, rec=0.079, cos=0.002), tot_loss_proj:1.717 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.368 (perp=6.438, rec=0.078, cos=0.002), tot_loss_proj:1.716 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.366 (perp=6.438, rec=0.076, cos=0.002), tot_loss_proj:1.717 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[1350/2000] tot_loss=1.350 (perp=6.438, rec=0.060, cos=0.002), tot_loss_proj:1.714 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.367 (perp=6.438, rec=0.077, cos=0.002), tot_loss_proj:1.710 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.361 (perp=6.438, rec=0.071, cos=0.002), tot_loss_proj:1.710 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[1500/2000] tot_loss=1.354 (perp=6.438, rec=0.065, cos=0.002), tot_loss_proj:1.717 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.361 (perp=6.438, rec=0.071, cos=0.002), tot_loss_proj:1.705 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.363 (perp=6.438, rec=0.073, cos=0.002), tot_loss_proj:1.716 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[1650/2000] tot_loss=1.363 (perp=6.438, rec=0.073, cos=0.002), tot_loss_proj:1.711 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.358 (perp=6.438, rec=0.069, cos=0.002), tot_loss_proj:1.714 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.363 (perp=6.438, rec=0.073, cos=0.002), tot_loss_proj:1.715 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[1800/2000] tot_loss=1.362 (perp=6.438, rec=0.072, cos=0.002), tot_loss_proj:1.709 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.369 (perp=6.438, rec=0.079, cos=0.002), tot_loss_proj:1.711 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.364 (perp=6.438, rec=0.075, cos=0.002), tot_loss_proj:1.717 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
[1950/2000] tot_loss=1.368 (perp=6.438, rec=0.078, cos=0.002), tot_loss_proj:1.710 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.362 (perp=6.438, rec=0.072, cos=0.002), tot_loss_proj:1.709 [t=0.24s]
prediction: ['[CLS] gets on screen gets clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] gets on screen gets clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 119.048

[Aggregate metrics]:
rouge1     | fm: 91.892 | p: 91.548 | r: 92.355
rouge2     | fm: 62.916 | p: 62.715 | r: 63.142
rougeL     | fm: 80.958 | p: 80.663 | r: 81.361
rougeLsum  | fm: 80.877 | p: 80.577 | r: 81.274
r1fm+r2fm = 154.808

input #70 time: 0:09:18 | total time: 11:09:20


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9993408837696341
highest_index [0]
highest [0.9993408837696341]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8875375986099243 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.844735324382782 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8433874845504761 for ['[CLS] fed to radar county sun gunshot parchment waiting regional wallacewo dia [CLS] smiles fantasy [SEP]']
[Init] best rec loss: 0.8301323652267456 for ['[CLS] shoulders protocol powerfulfication sash jonas obligatory definition box thorough whole except visit flanked dated [SEP]']
[Init] best rec loss: 0.8257005214691162 for ['[CLS] cidloubridge living blues republicfl projections transition rally mere torpedo spellingcio espn [SEP]']
[Init] best rec loss: 0.8135210871696472 for ['[CLS] mutual internal travel grief with album careful item serious european either warp spoil waived every [SEP]']
[Init] best perm rec loss: 0.8111921548843384 for ['[CLS] serious album every either internal waived european grief warp travel mutual spoil item with careful [SEP]']
[Init] best perm rec loss: 0.809777557849884 for ['[CLS] either mutual travel warp album every grief with careful waived serious spoil european internal item [SEP]']
[Init] best perm rec loss: 0.8083569407463074 for ['[CLS] grief with careful serious warp every item internal mutual either waived album travel european spoil [SEP]']
[Init] best perm rec loss: 0.8064085245132446 for ['[CLS] serious mutual grief warp album european waived travel internal with spoil every item either careful [SEP]']
[Init] best perm rec loss: 0.8064031004905701 for ['[CLS] mutual every item with grief travel careful european serious warp waived spoil either album internal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.897 (perp=12.664, rec=0.331, cos=0.033), tot_loss_proj:3.906 [t=0.24s]
prediction: ['[CLS] station every argued moment notices afternoon given title single not when dynasty miners office not [SEP]']
[ 100/2000] tot_loss=2.199 (perp=9.898, rec=0.204, cos=0.015), tot_loss_proj:3.650 [t=0.24s]
prediction: ['[CLS] from every moment moment collective jump moment jump single not. - maps - on [SEP]']
[ 150/2000] tot_loss=2.144 (perp=9.850, rec=0.168, cos=0.006), tot_loss_proj:3.572 [t=0.24s]
prediction: ['[CLS]s - moment moment their jump seat seat single not and your - - and [SEP]']
[ 200/2000] tot_loss=2.131 (perp=9.952, rec=0.136, cos=0.004), tot_loss_proj:3.715 [t=0.24s]
prediction: ['[CLS]s exists moment moment your jump seat seat single not and your - - and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.925 (perp=8.900, rec=0.136, cos=0.008), tot_loss_proj:3.125 [t=0.24s]
prediction: ["[CLS]'s moment on second jump seat seat single not and your - - moment [SEP]"]
[ 300/2000] tot_loss=1.669 (perp=7.820, rec=0.103, cos=0.003), tot_loss_proj:2.939 [t=0.24s]
prediction: ["[CLS]'s there. second jump your seat single not and your - - moment [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=1.580 (perp=7.457, rec=0.087, cos=0.002), tot_loss_proj:2.772 [t=0.24s]
prediction: ["[CLS]'s there - second jump your seat single and not - - - moment [SEP]"]
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.365 (perp=6.286, rec=0.105, cos=0.003), tot_loss_proj:2.667 [t=0.24s]
prediction: ["[CLS]'s single there - - jump your seat and not in - - moment [SEP]"]
[ 450/2000] tot_loss=1.345 (perp=6.286, rec=0.086, cos=0.002), tot_loss_proj:2.674 [t=0.24s]
prediction: ["[CLS]'s single there - - jump your seat and not in - - moment [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.291 (perp=6.082, rec=0.073, cos=0.002), tot_loss_proj:2.549 [t=0.24s]
prediction: ["[CLS]'s single there - a jump in your seat and not - - moment [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.242 (perp=5.793, rec=0.082, cos=0.002), tot_loss_proj:2.240 [t=0.24s]
prediction: ["[CLS]'s single there not a jump in your seat and - - - moment [SEP]"]
[ 600/2000] tot_loss=1.234 (perp=5.793, rec=0.074, cos=0.002), tot_loss_proj:2.231 [t=0.24s]
prediction: ["[CLS]'s single there not a jump in your seat and - - - moment [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.175 (perp=5.475, rec=0.078, cos=0.001), tot_loss_proj:1.892 [t=0.24s]
prediction: ["[CLS] there's single not a jump in your seat and - - - moment [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.179 (perp=5.475, rec=0.082, cos=0.001), tot_loss_proj:1.897 [t=0.24s]
prediction: ["[CLS] there's single not a jump in your seat and - - - moment [SEP]"]
[ 750/2000] tot_loss=1.164 (perp=5.475, rec=0.068, cos=0.001), tot_loss_proj:1.883 [t=0.24s]
prediction: ["[CLS] there's single not a jump in your seat and - - - moment [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.161 (perp=5.475, rec=0.065, cos=0.001), tot_loss_proj:1.887 [t=0.24s]
prediction: ["[CLS] there's single not a jump in your seat and - - - moment [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.156 (perp=5.387, rec=0.077, cos=0.001), tot_loss_proj:2.014 [t=0.24s]
prediction: ["[CLS] there single's not a jump in your seat and - - - moment [SEP]"]
[ 900/2000] tot_loss=1.146 (perp=5.387, rec=0.068, cos=0.001), tot_loss_proj:2.016 [t=0.24s]
prediction: ["[CLS] there single's not a jump in your seat and - - - moment [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.159 (perp=5.387, rec=0.080, cos=0.001), tot_loss_proj:2.020 [t=0.24s]
prediction: ["[CLS] there single's not a jump in your seat and - - - moment [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.140 (perp=5.342, rec=0.070, cos=0.001), tot_loss_proj:2.173 [t=0.24s]
prediction: ["[CLS] single there's not a jump in your seat and - - - moment [SEP]"]
[1050/2000] tot_loss=1.139 (perp=5.342, rec=0.070, cos=0.001), tot_loss_proj:2.177 [t=0.24s]
prediction: ["[CLS] single there's not a jump in your seat and - - - moment [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.144 (perp=5.342, rec=0.074, cos=0.001), tot_loss_proj:2.179 [t=0.24s]
prediction: ["[CLS] single there's not a jump in your seat and - - - moment [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=0.982 (perp=4.597, rec=0.061, cos=0.001), tot_loss_proj:1.539 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
[1200/2000] tot_loss=0.994 (perp=4.597, rec=0.073, cos=0.001), tot_loss_proj:1.543 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
[1250/2000] tot_loss=0.995 (perp=4.597, rec=0.074, cos=0.001), tot_loss_proj:1.542 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
[1300/2000] tot_loss=0.983 (perp=4.597, rec=0.062, cos=0.001), tot_loss_proj:1.535 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
[1350/2000] tot_loss=0.990 (perp=4.597, rec=0.070, cos=0.001), tot_loss_proj:1.537 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
[1400/2000] tot_loss=0.993 (perp=4.597, rec=0.073, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
[1450/2000] tot_loss=0.986 (perp=4.597, rec=0.065, cos=0.001), tot_loss_proj:1.539 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
[1500/2000] tot_loss=0.991 (perp=4.597, rec=0.070, cos=0.001), tot_loss_proj:1.540 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=0.989 (perp=4.597, rec=0.068, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.004 (perp=4.597, rec=0.083, cos=0.001), tot_loss_proj:1.535 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
[1650/2000] tot_loss=0.996 (perp=4.597, rec=0.075, cos=0.001), tot_loss_proj:1.547 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
[1700/2000] tot_loss=0.984 (perp=4.597, rec=0.063, cos=0.001), tot_loss_proj:1.547 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
[1750/2000] tot_loss=0.980 (perp=4.597, rec=0.060, cos=0.001), tot_loss_proj:1.543 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
[1800/2000] tot_loss=0.972 (perp=4.597, rec=0.052, cos=0.001), tot_loss_proj:1.536 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
Moved sequence
[1850/2000] tot_loss=0.980 (perp=4.597, rec=0.059, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
Moved sequence
[1900/2000] tot_loss=0.992 (perp=4.597, rec=0.071, cos=0.001), tot_loss_proj:1.543 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
[1950/2000] tot_loss=0.982 (perp=4.597, rec=0.061, cos=0.001), tot_loss_proj:1.535 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Attempt swap
[2000/2000] tot_loss=0.988 (perp=4.597, rec=0.068, cos=0.001), tot_loss_proj:1.538 [t=0.24s]
prediction: ["[CLS] there's not a single jump in your seat and - - - moment [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] there's not a single jump in your seat and - - - moment [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 92.308 | p: 92.308 | r: 92.308
rougeLsum  | fm: 92.308 | p: 92.308 | r: 92.308
r1fm+r2fm = 175.000

[Aggregate metrics]:
rouge1     | fm: 92.037 | p: 91.664 | r: 92.507
rouge2     | fm: 63.186 | p: 62.980 | r: 63.442
rougeL     | fm: 81.192 | p: 80.867 | r: 81.498
rougeLsum  | fm: 81.008 | p: 80.645 | r: 81.434
r1fm+r2fm = 155.224

input #71 time: 0:09:26 | total time: 11:18:46


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9992332805099025
highest_index [0]
highest [0.9992332805099025]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7866917848587036 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7584322690963745 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7510275840759277 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7389710545539856 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.7389072179794312 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7173200249671936 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7166939377784729 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.7151522636413574 for ['[CLS] zone except orbital walking! ta support dna vanungen pork accidentally lifeboat nonetheless reserve [SEP]']
[Init] best perm rec loss: 0.7150953412055969 for ['[CLS] lifeboat support accidentallyungen zone nonetheless reserve ta orbital van dna! walking except pork [SEP]']
[Init] best perm rec loss: 0.7140606045722961 for ['[CLS] reserve ta nonetheless walking dna van orbital support except pork! zone lifeboatungen accidentally [SEP]']
[Init] best perm rec loss: 0.7136176228523254 for ['[CLS] pork reserve ta nonetheless walking! van lifeboat exceptungen orbital support dna zone accidentally [SEP]']
[Init] best perm rec loss: 0.7135342955589294 for ['[CLS] ta lifeboat accidentally van! walking zone except nonetheless dna orbital support reserveungen pork [SEP]']
[Init] best perm rec loss: 0.7135124802589417 for ['[CLS] reserve zone lifeboat walking pork support except dna van nonetheless ta! accidentally orbitalungen [SEP]']
[Init] best perm rec loss: 0.7132373452186584 for ['[CLS] zoneungen nonetheless walking van dna pork orbital lifeboat accidentally ta except reserve! support [SEP]']
[Init] best perm rec loss: 0.7126136422157288 for ['[CLS] lifeboat supportungen van! accidentally reserve ta dna pork except zone orbital walking nonetheless [SEP]']
[Init] best perm rec loss: 0.7125565409660339 for ['[CLS]! walking nonetheless pork van accidentally dna lifeboat reserveungen zone orbital ta except support [SEP]']
[Init] best perm rec loss: 0.7125199437141418 for ['[CLS] walking pork lifeboat nonetheless zone accidentally dna! reserve supportungen van ta orbital except [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.899 (perp=12.910, rec=0.297, cos=0.020), tot_loss_proj:3.968 [t=0.24s]
prediction: ['[CLS] heavily tough harder aination tough violent look reserved hendrix figured has mo price feminist [SEP]']
[ 100/2000] tot_loss=2.608 (perp=11.996, rec=0.201, cos=0.007), tot_loss_proj:3.858 [t=0.24s]
prediction: ['[CLS] heavily tough tough time its tough tough language munich hendrix figured has balancinger philosophy [SEP]']
[ 150/2000] tot_loss=2.299 (perp=10.772, rec=0.139, cos=0.005), tot_loss_proj:3.655 [t=0.24s]
prediction: ['[CLS] heavily tougher time its tough tough its violence hendrix assessment has balancing with philosophy [SEP]']
[ 200/2000] tot_loss=2.169 (perp=10.264, rec=0.111, cos=0.005), tot_loss_proj:3.492 [t=0.24s]
prediction: ['[CLS] heavily tougher time its tough violence its violencefk assessment has balancing with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.982 (perp=9.424, rec=0.095, cos=0.002), tot_loss_proj:3.110 [t=0.24s]
prediction: ['[CLS] a tougher time with tough violence its violencefk assessment has balancinger philosophy [SEP]']
[ 300/2000] tot_loss=2.246 (perp=10.780, rec=0.088, cos=0.002), tot_loss_proj:3.604 [t=0.24s]
prediction: ['[CLS] a aer time with tough violence its violencefk assessment has balancinger philosophy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.091 (perp=10.043, rec=0.080, cos=0.002), tot_loss_proj:3.467 [t=0.24s]
prediction: ['[CLS] - balancinger time with tough violence its violencefk added has aer philosophy [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.900 (perp=8.970, rec=0.103, cos=0.003), tot_loss_proj:3.240 [t=0.24s]
prediction: ['[CLS] - balancing time with tougher violence its violencefk added has aer philosophy [SEP]']
[ 450/2000] tot_loss=1.890 (perp=8.970, rec=0.094, cos=0.001), tot_loss_proj:3.244 [t=0.24s]
prediction: ['[CLS] - balancing time with tougher violence its violencefk added has aer philosophy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.893 (perp=9.002, rec=0.091, cos=0.002), tot_loss_proj:3.461 [t=0.24s]
prediction: ['[CLS] - balancing time with tougher violence its inspired added has afker philosophy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.730 (perp=8.224, rec=0.083, cos=0.002), tot_loss_proj:3.337 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence its inspired added has afka philosophy [SEP]']
[ 600/2000] tot_loss=1.721 (perp=8.224, rec=0.075, cos=0.001), tot_loss_proj:3.337 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence its inspired added has afka philosophy [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.659 (perp=7.895, rec=0.078, cos=0.001), tot_loss_proj:3.340 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence its added has afka inspired philosophy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.659 (perp=7.895, rec=0.078, cos=0.002), tot_loss_proj:3.331 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence its added has afka inspired philosophy [SEP]']
[ 750/2000] tot_loss=1.653 (perp=7.895, rec=0.072, cos=0.001), tot_loss_proj:3.335 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence its added has afka inspired philosophy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.652 (perp=7.895, rec=0.071, cos=0.002), tot_loss_proj:3.328 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence its added has afka inspired philosophy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.646 (perp=7.895, rec=0.065, cos=0.002), tot_loss_proj:3.332 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence its added has afka inspired philosophy [SEP]']
[ 900/2000] tot_loss=1.704 (perp=8.171, rec=0.068, cos=0.002), tot_loss_proj:3.420 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence its on has afka inspired philosophy [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.665 (perp=7.945, rec=0.074, cos=0.001), tot_loss_proj:3.390 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence its has afka inspired philosophy of [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.605 (perp=7.663, rec=0.071, cos=0.002), tot_loss_proj:3.203 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has its afka inspired philosophy of [SEP]']
[1050/2000] tot_loss=1.652 (perp=7.875, rec=0.075, cos=0.001), tot_loss_proj:3.281 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has its afka inspired philosophy on [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.597 (perp=7.659, rec=0.064, cos=0.001), tot_loss_proj:3.176 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1150/2000] tot_loss=1.607 (perp=7.659, rec=0.074, cos=0.001), tot_loss_proj:3.173 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
[1200/2000] tot_loss=1.607 (perp=7.659, rec=0.074, cos=0.001), tot_loss_proj:3.180 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1250/2000] tot_loss=1.603 (perp=7.659, rec=0.070, cos=0.001), tot_loss_proj:3.177 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1300/2000] tot_loss=1.608 (perp=7.659, rec=0.075, cos=0.002), tot_loss_proj:3.176 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
[1350/2000] tot_loss=1.610 (perp=7.659, rec=0.076, cos=0.002), tot_loss_proj:3.176 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1400/2000] tot_loss=1.594 (perp=7.659, rec=0.061, cos=0.002), tot_loss_proj:3.178 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1450/2000] tot_loss=1.611 (perp=7.659, rec=0.078, cos=0.001), tot_loss_proj:3.173 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
[1500/2000] tot_loss=1.607 (perp=7.659, rec=0.074, cos=0.001), tot_loss_proj:3.178 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1550/2000] tot_loss=1.611 (perp=7.659, rec=0.077, cos=0.002), tot_loss_proj:3.176 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1600/2000] tot_loss=1.608 (perp=7.659, rec=0.075, cos=0.002), tot_loss_proj:3.176 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
[1650/2000] tot_loss=1.601 (perp=7.659, rec=0.068, cos=0.002), tot_loss_proj:3.180 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1700/2000] tot_loss=1.598 (perp=7.659, rec=0.065, cos=0.002), tot_loss_proj:3.175 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1750/2000] tot_loss=1.603 (perp=7.659, rec=0.070, cos=0.002), tot_loss_proj:3.178 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
[1800/2000] tot_loss=1.602 (perp=7.659, rec=0.069, cos=0.002), tot_loss_proj:3.177 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1850/2000] tot_loss=1.607 (perp=7.659, rec=0.074, cos=0.002), tot_loss_proj:3.178 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[1900/2000] tot_loss=1.599 (perp=7.659, rec=0.066, cos=0.002), tot_loss_proj:3.176 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
[1950/2000] tot_loss=1.598 (perp=7.659, rec=0.065, cos=0.001), tot_loss_proj:3.181 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Attempt swap
[2000/2000] tot_loss=1.610 (perp=7.659, rec=0.077, cos=0.002), tot_loss_proj:3.179 [t=0.24s]
prediction: ['[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] time balancing - with tougher violence has itsfka inspired philosophy on a [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 84.615 | r: 84.615
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 53.846 | p: 53.846 | r: 53.846
rougeLsum  | fm: 53.846 | p: 53.846 | r: 53.846
r1fm+r2fm = 101.282

[Aggregate metrics]:
rouge1     | fm: 91.911 | p: 91.584 | r: 92.316
rouge2     | fm: 62.617 | p: 62.410 | r: 62.866
rougeL     | fm: 80.714 | p: 80.437 | r: 81.070
rougeLsum  | fm: 80.692 | p: 80.384 | r: 81.069
r1fm+r2fm = 154.527

input #72 time: 0:09:26 | total time: 11:28:13


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9991739905462714
highest_index [0]
highest [0.9991739905462714]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9930576682090759 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.970208466053009 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9534759521484375 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9143747687339783 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.911167323589325 for ['[CLS]dicated circles [SEP]']
[Init] best rec loss: 0.8457381725311279 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 0.8437196016311646 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.105 (perp=9.724, rec=0.155, cos=0.005), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.021 (perp=9.724, rec=0.075, cos=0.002), tot_loss_proj:2.010 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.008 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.012 (perp=9.724, rec=0.066, cos=0.002), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.002 (perp=9.724, rec=0.055, cos=0.002), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.003 (perp=9.724, rec=0.056, cos=0.002), tot_loss_proj:2.005 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.018 (perp=9.724, rec=0.072, cos=0.002), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.011 (perp=9.724, rec=0.065, cos=0.002), tot_loss_proj:2.005 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.006 (perp=9.724, rec=0.059, cos=0.002), tot_loss_proj:2.007 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.019 (perp=9.724, rec=0.072, cos=0.002), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.998 (perp=9.724, rec=0.051, cos=0.002), tot_loss_proj:1.999 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.012 (perp=9.724, rec=0.066, cos=0.002), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.008 (perp=9.724, rec=0.062, cos=0.002), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.004 (perp=9.724, rec=0.058, cos=0.002), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.002 (perp=9.724, rec=0.056, cos=0.002), tot_loss_proj:2.002 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.007 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.004 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.005 (perp=9.724, rec=0.058, cos=0.002), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.008 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.001 (perp=9.724, rec=0.055, cos=0.002), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.000 (perp=9.724, rec=0.054, cos=0.002), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.001 (perp=9.724, rec=0.055, cos=0.002), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.009 (perp=9.724, rec=0.062, cos=0.002), tot_loss_proj:2.019 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.014 (perp=9.724, rec=0.067, cos=0.002), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.012 (perp=9.724, rec=0.066, cos=0.002), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.009 (perp=9.724, rec=0.063, cos=0.002), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=1.996 (perp=9.724, rec=0.050, cos=0.002), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.013 (perp=9.724, rec=0.067, cos=0.002), tot_loss_proj:2.013 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=1.997 (perp=9.724, rec=0.051, cos=0.002), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.010 (perp=9.724, rec=0.063, cos=0.002), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.019 (perp=9.724, rec=0.072, cos=0.002), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.006 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.019 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.006 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.016 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.000 (perp=9.724, rec=0.053, cos=0.002), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.995 (perp=9.724, rec=0.049, cos=0.002), tot_loss_proj:2.024 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.013 (perp=9.724, rec=0.067, cos=0.002), tot_loss_proj:2.008 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.002 (perp=9.724, rec=0.055, cos=0.002), tot_loss_proj:2.003 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.008 (perp=9.724, rec=0.062, cos=0.002), tot_loss_proj:2.005 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.003 (perp=9.724, rec=0.056, cos=0.002), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.013 (perp=9.724, rec=0.067, cos=0.002), tot_loss_proj:2.013 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.006 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.058 | p: 91.722 | r: 92.449
rouge2     | fm: 63.010 | p: 62.835 | r: 63.315
rougeL     | fm: 81.146 | p: 80.848 | r: 81.459
rougeLsum  | fm: 80.887 | p: 80.625 | r: 81.300
r1fm+r2fm = 155.068

input #73 time: 0:09:17 | total time: 11:37:30


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9992586513675699
highest_index [0]
highest [0.9992586513675699]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.0039318799972534 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6881205439567566 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6577026844024658 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.997 (perp=8.178, rec=0.316, cos=0.045), tot_loss_proj:2.086 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.724 (perp=8.178, rec=0.086, cos=0.002), tot_loss_proj:1.831 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.002), tot_loss_proj:1.730 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.709 (perp=8.178, rec=0.071, cos=0.002), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.002), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.002), tot_loss_proj:1.743 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.001), tot_loss_proj:1.729 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.686 (perp=8.178, rec=0.048, cos=0.001), tot_loss_proj:1.742 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.688 (perp=8.178, rec=0.051, cos=0.001), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.692 (perp=8.178, rec=0.055, cos=0.001), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.689 (perp=8.178, rec=0.052, cos=0.001), tot_loss_proj:1.745 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.686 (perp=8.178, rec=0.049, cos=0.001), tot_loss_proj:1.728 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.687 (perp=8.178, rec=0.050, cos=0.001), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.683 (perp=8.178, rec=0.046, cos=0.001), tot_loss_proj:1.745 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.705 (perp=8.178, rec=0.068, cos=0.001), tot_loss_proj:1.743 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.705 (perp=8.178, rec=0.067, cos=0.001), tot_loss_proj:1.736 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.692 (perp=8.178, rec=0.055, cos=0.001), tot_loss_proj:1.734 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.689 (perp=8.178, rec=0.052, cos=0.001), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.001), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.687 (perp=8.178, rec=0.050, cos=0.001), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.687 (perp=8.178, rec=0.050, cos=0.001), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.729 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.695 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.724 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.739 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.711 (perp=8.178, rec=0.074, cos=0.001), tot_loss_proj:1.734 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.689 (perp=8.178, rec=0.052, cos=0.001), tot_loss_proj:1.726 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.701 (perp=8.178, rec=0.064, cos=0.001), tot_loss_proj:1.747 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.726 (perp=8.178, rec=0.088, cos=0.001), tot_loss_proj:1.717 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.203 | p: 91.878 | r: 92.598
rouge2     | fm: 63.622 | p: 63.447 | r: 63.881
rougeL     | fm: 81.236 | p: 80.958 | r: 81.580
rougeLsum  | fm: 81.193 | p: 80.909 | r: 81.536
r1fm+r2fm = 155.825

input #74 time: 0:09:10 | total time: 11:46:40


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9993457140726361
highest_index [0]
highest [0.9993457140726361]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9596470594406128 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.9503890872001648 for ['[CLS] changed door covert obviously tone sinclair final hard eventdrome apps nick tempo nations diveiii willem nodded rolled [SEP]']
[Init] best rec loss: 0.9403657913208008 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.9036276936531067 for ['[CLS] years public during cup months du sources community ind baseman viz together clinton est frog gum firing points prick [SEP]']
[Init] best rec loss: 0.8985481858253479 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 0.897793173789978 for ['[CLS] brother eco clockizes clint wagon identification % already spirit ceo vampires sighted international version glare contraction eds buck [SEP]']
[Init] best rec loss: 0.8942992091178894 for ['[CLS]orin rearview bore nicky yang dynasty confidence hockey preaching mangrove meanllet ventureix resistance constitution sun nicholas piece [SEP]']
[Init] best rec loss: 0.8870740532875061 for ['[CLS] stir will case bills blocked hand miniseries electricchen words tha batting shed az happen women known gen tourist [SEP]']
[Init] best rec loss: 0.8610764741897583 for ['[CLS]ception resultedrate left fact crown skill apollo auxiliary regardedcl magic to eachmmel viewed stood loop royalties [SEP]']
[Init] best perm rec loss: 0.8609409332275391 for ['[CLS]rate magic viewed apollo crown fact loop resulted auxiliarycl stood each regarded toceptionmmel skill left royalties [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.023 (perp=13.128, rec=0.376, cos=0.021), tot_loss_proj:4.335 [t=0.24s]
prediction: ['[CLS] folds talent passengers hungarian cricket. unknown literarydiofield where bwf trust thenna kingdom tourist non soon [SEP]']
[ 100/2000] tot_loss=2.526 (perp=11.156, rec=0.284, cos=0.011), tot_loss_proj:4.116 [t=0.24s]
prediction: ['[CLS] delta entered excursion easily taylor. instability entered not forgotten dismissed forgotten / the easily dismissed denied cannot. [SEP]']
[ 150/2000] tot_loss=2.451 (perp=11.130, rec=0.218, cos=0.007), tot_loss_proj:4.121 [t=0.24s]
prediction: ['[CLS] improvisationes excursion easily webster. instability entered not forgotten easily forgottendown the not. and not tonight [SEP]']
[ 200/2000] tot_loss=2.220 (perp=10.203, rec=0.175, cos=0.005), tot_loss_proj:3.571 [t=0.24s]
prediction: ['[CLS] this entered excursion easilyenter. instabilityenter not forgotten easily forgottenrued the easily. and not forgotten [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.035 (perp=9.291, rec=0.173, cos=0.004), tot_loss_proj:3.226 [t=0.24s]
prediction: ['[CLS] this is excursion easily or. instabilityenter not forgotten easily forgotten vested theenter. and not forgotten [SEP]']
[ 300/2000] tot_loss=2.157 (perp=9.996, rec=0.153, cos=0.005), tot_loss_proj:3.594 [t=0.24s]
prediction: ['[CLS] this is excursion easily or. instabilityenter not forgotten easily forgotten blair theenter. facto not forgotten [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.155 (perp=9.898, rec=0.162, cos=0.013), tot_loss_proj:3.859 [t=0.24s]
prediction: ['[CLS] this is excursion easily or instability.enter not forgotten easily forgotten blair theenter. facto dismissed forgotten [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.944 (perp=9.070, rec=0.127, cos=0.002), tot_loss_proj:3.686 [t=0.24s]
prediction: ['[CLS] this is excursion easily or instability blairenter not forgotten easily forgotten. theenter. facto dismissed forgotten [SEP]']
[ 450/2000] tot_loss=1.988 (perp=9.378, rec=0.110, cos=0.002), tot_loss_proj:3.737 [t=0.24s]
prediction: ['[CLS] this is excursion easily or instability blairenter not forgotten easily forgotten. theenter. into dismissed tonight [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.033 (perp=9.601, rec=0.111, cos=0.002), tot_loss_proj:3.780 [t=0.24s]
prediction: ['[CLS] this is excursion easily or instabilityrizeenter not forgotten easily forgotten. theenter. dismissed tonight facto [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.918 (perp=8.957, rec=0.123, cos=0.003), tot_loss_proj:3.616 [t=0.24s]
prediction: ['[CLS] this is excursion easily forgotten or instability blairenter not easily forgotten. theenter ; dismissed forgotten facto [SEP]']
[ 600/2000] tot_loss=1.774 (perp=8.312, rec=0.109, cos=0.002), tot_loss_proj:3.429 [t=0.24s]
prediction: ['[CLS] this is excursion easily forgotten or instabilityrizeenter not easily forgotten. theenter ; dismissed forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.686 (perp=7.864, rec=0.111, cos=0.002), tot_loss_proj:3.310 [t=0.24s]
prediction: ['[CLS] this is excursion easily forgotten or instabilityrizeenter not easily forgotten. the forgotten ; dismissed into. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.629 (perp=7.682, rec=0.090, cos=0.003), tot_loss_proj:3.288 [t=0.24s]
prediction: ['[CLS] this is excursion easily forgotten or forgotten teenagerenter not easily forgotten. the instability. dismissed into. [SEP]']
[ 750/2000] tot_loss=1.633 (perp=7.705, rec=0.090, cos=0.002), tot_loss_proj:3.273 [t=0.24s]
prediction: ['[CLS] this is excursion easily forgotten or forgottenrizeenter not easily forgotten. the instability. dismissed into. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.695 (perp=7.995, rec=0.094, cos=0.002), tot_loss_proj:3.351 [t=0.24s]
prediction: ['[CLS] this is excursion easily forgotten or forgottenrizeenter not easily forgotten. the instability ;. dismissed into [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.594 (perp=7.486, rec=0.094, cos=0.002), tot_loss_proj:3.232 [t=0.24s]
prediction: ['[CLS] this is excursion easily forgotten or forgottenrizeenter not easily forgotten. the instability.. dismissed into [SEP]']
[ 900/2000] tot_loss=1.598 (perp=7.486, rec=0.099, cos=0.002), tot_loss_proj:3.227 [t=0.24s]
prediction: ['[CLS] this is excursion easily forgotten or forgottenrizeenter not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.606 (perp=7.458, rec=0.113, cos=0.002), tot_loss_proj:3.408 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten or afterward teenagerenter is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.567 (perp=7.307, rec=0.103, cos=0.002), tot_loss_proj:3.294 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten afterward or teenagerenter is not easily forgotten. the instability.. dismissed into [SEP]']
[1050/2000] tot_loss=1.569 (perp=7.356, rec=0.095, cos=0.002), tot_loss_proj:3.361 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten afterward orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[1100/2000] tot_loss=1.569 (perp=7.356, rec=0.095, cos=0.002), tot_loss_proj:3.363 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten afterward orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[1150/2000] tot_loss=1.576 (perp=7.356, rec=0.103, cos=0.002), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten afterward orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
[1200/2000] tot_loss=1.571 (perp=7.356, rec=0.098, cos=0.002), tot_loss_proj:3.368 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten afterward orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[1250/2000] tot_loss=1.586 (perp=7.462, rec=0.092, cos=0.002), tot_loss_proj:3.396 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten into orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[1300/2000] tot_loss=1.588 (perp=7.462, rec=0.094, cos=0.002), tot_loss_proj:3.401 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten into orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.462, rec=0.092, cos=0.002), tot_loss_proj:3.397 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten into orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[1400/2000] tot_loss=1.586 (perp=7.462, rec=0.092, cos=0.002), tot_loss_proj:3.399 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten into orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.590 (perp=7.462, rec=0.095, cos=0.002), tot_loss_proj:3.399 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten into orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
[1500/2000] tot_loss=1.582 (perp=7.462, rec=0.088, cos=0.002), tot_loss_proj:3.404 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten into orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[1550/2000] tot_loss=1.587 (perp=7.462, rec=0.093, cos=0.001), tot_loss_proj:3.399 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten into orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[1600/2000] tot_loss=1.592 (perp=7.462, rec=0.098, cos=0.001), tot_loss_proj:3.399 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten into orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
[1650/2000] tot_loss=1.573 (perp=7.462, rec=0.079, cos=0.001), tot_loss_proj:3.398 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten into orcolaenter is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.553 (perp=7.325, rec=0.086, cos=0.001), tot_loss_proj:3.326 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten orcolaenter into is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[1750/2000] tot_loss=1.546 (perp=7.325, rec=0.080, cos=0.001), tot_loss_proj:3.330 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten orcolaenter into is not easily forgotten. the instability.. dismissed into [SEP]']
[1800/2000] tot_loss=1.562 (perp=7.325, rec=0.095, cos=0.001), tot_loss_proj:3.327 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten orcolaenter into is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[1850/2000] tot_loss=1.559 (perp=7.325, rec=0.093, cos=0.001), tot_loss_proj:3.323 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten orcolaenter into is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[1900/2000] tot_loss=1.557 (perp=7.325, rec=0.091, cos=0.001), tot_loss_proj:3.321 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten orcolaenter into is not easily forgotten. the instability.. dismissed into [SEP]']
[1950/2000] tot_loss=1.551 (perp=7.325, rec=0.085, cos=0.001), tot_loss_proj:3.323 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten orcolaenter into is not easily forgotten. the instability.. dismissed into [SEP]']
Attempt swap
[2000/2000] tot_loss=1.552 (perp=7.325, rec=0.086, cos=0.001), tot_loss_proj:3.326 [t=0.24s]
prediction: ['[CLS] this excursion easily forgotten orcolaenter into is not easily forgotten. the instability.. dismissed into [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this excursion easily forgotten orcolaenter into is not easily forgotten. the instability.. dismissed into [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 75.000 | r: 70.588
rouge2     | fm: 25.806 | p: 26.667 | r: 25.000
rougeL     | fm: 54.545 | p: 56.250 | r: 52.941
rougeLsum  | fm: 54.545 | p: 56.250 | r: 52.941
r1fm+r2fm = 98.534

[Aggregate metrics]:
rouge1     | fm: 91.923 | p: 91.649 | r: 92.300
rouge2     | fm: 62.980 | p: 62.785 | r: 63.231
rougeL     | fm: 80.928 | p: 80.675 | r: 81.241
rougeLsum  | fm: 80.779 | p: 80.578 | r: 81.153
r1fm+r2fm = 154.903

input #75 time: 0:09:25 | total time: 11:56:06


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9991390736873003
highest_index [0]
highest [0.9991390736873003]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.921407163143158 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.9002844095230103 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 0.8949021100997925 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 0.8901370167732239 for ['[CLS] carrie word 38 saying subject window rican disc anatomy awardscles cf past resisted [SEP]']
[Init] best rec loss: 0.8706420660018921 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 0.8616399168968201 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.8554098606109619 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 0.8517670035362244 for ['[CLS] pushed ( purse onwards lefthaw tautoning surreal hard ab backwardˣ mango [SEP]']
[Init] best perm rec loss: 0.8514449000358582 for ['[CLS] purse backward hard ab taut surreal onwards mango ( lefthaw pushedoningˣ [SEP]']
[Init] best perm rec loss: 0.8474489450454712 for ['[CLS] onwards aboning lefthaw taut ( pushed hardˣ surreal backward mango purse [SEP]']
[Init] best perm rec loss: 0.8473937511444092 for ['[CLS] mangoˣ abhaw purse onwards ( surrealoning hard taut pushed backward left [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.673 (perp=11.691, rec=0.306, cos=0.028), tot_loss_proj:3.617 [t=0.23s]
prediction: ['[CLS] feelsrting stopped career when. was challenging. stopped challengeuid stop attack [SEP]']
[ 100/2000] tot_loss=2.342 (perp=10.796, rec=0.177, cos=0.007), tot_loss_proj:3.269 [t=0.24s]
prediction: ['[CLS] like had stopped allen when, has himself. stopped challenging challenging stopped attack [SEP]']
[ 150/2000] tot_loss=1.964 (perp=9.091, rec=0.142, cos=0.004), tot_loss_proj:3.169 [t=0.24s]
prediction: ['[CLS] as sometimes stopped allen when, has himself, stopped challenging challenging if because [SEP]']
[ 200/2000] tot_loss=1.931 (perp=9.029, rec=0.122, cos=0.004), tot_loss_proj:2.864 [t=0.24s]
prediction: ['[CLS] as what stopped allen., has himself, stopped challenging challenging if because [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.794 (perp=8.337, rec=0.123, cos=0.004), tot_loss_proj:2.803 [t=0.24s]
prediction: ["[CLS] as'allen when, has stopped himself, stopped challenging'if mistake [SEP]"]
[ 300/2000] tot_loss=1.814 (perp=8.457, rec=0.117, cos=0.005), tot_loss_proj:2.625 [t=0.24s]
prediction: ["[CLS] as'allen., has stopped himself, stopped challenging s if allen [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.912 (perp=9.022, rec=0.105, cos=0.003), tot_loss_proj:2.717 [t=0.24s]
prediction: ["[CLS] as'allen thompson 66 has stopped himself, stopped challenging s if. [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.011 (perp=9.520, rec=0.103, cos=0.004), tot_loss_proj:2.871 [t=0.24s]
prediction: ["[CLS] as'allen 66 notice has stopped himself, stopped challenging s if. [SEP]"]
[ 450/2000] tot_loss=2.072 (perp=9.795, rec=0.110, cos=0.003), tot_loss_proj:2.954 [t=0.24s]
prediction: ["[CLS] as'allen 66 notice has stopped himself at stopped challenging s if. [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.985 (perp=9.343, rec=0.114, cos=0.003), tot_loss_proj:2.819 [t=0.24s]
prediction: ["[CLS] as'allen 66 notice has stopped himself at stopped challenging. if s [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.991 (perp=9.420, rec=0.104, cos=0.003), tot_loss_proj:2.738 [t=0.24s]
prediction: ["[CLS] as s allen 66 thompson has stopped himself at stopped challenging. if'[SEP]"]
[ 600/2000] tot_loss=2.076 (perp=9.858, rec=0.101, cos=0.003), tot_loss_proj:2.963 [t=0.24s]
prediction: ['[CLS] as s allen 66 effect has stopped himself at stopped challenging. if s [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.127 (perp=10.132, rec=0.098, cos=0.003), tot_loss_proj:3.415 [t=0.24s]
prediction: ['[CLS]awa as s allen 66 has, himself at stopped challenging. if s [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.958 (perp=9.300, rec=0.095, cos=0.003), tot_loss_proj:3.404 [t=0.24s]
prediction: ['[CLS]awa as s has allen 66, himself at stopped challenging. if s [SEP]']
[ 750/2000] tot_loss=2.014 (perp=9.587, rec=0.094, cos=0.003), tot_loss_proj:3.468 [t=0.24s]
prediction: ['[CLS]awa as. has allen 66, himself at stopped challenging. if s [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.943 (perp=9.267, rec=0.087, cos=0.003), tot_loss_proj:3.597 [t=0.24s]
prediction: ['[CLS]awa as. has allen 66, stopped at himself challenging. if s [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.881 (perp=8.911, rec=0.096, cos=0.003), tot_loss_proj:3.559 [t=0.24s]
prediction: ['[CLS] asawa. has allen 66, stopped at himself challenging. if s [SEP]']
[ 900/2000] tot_loss=1.828 (perp=8.686, rec=0.088, cos=0.003), tot_loss_proj:3.354 [t=0.24s]
prediction: ['[CLS] as immediately. has allen 66, stopped at himself challenging. if s [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.744 (perp=8.297, rec=0.082, cos=0.003), tot_loss_proj:3.160 [t=0.24s]
prediction: ['[CLS] as.. has allen 66, stopped at himself challenging immediately if s [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.712 (perp=8.083, rec=0.093, cos=0.003), tot_loss_proj:3.422 [t=0.24s]
prediction: ['[CLS] as.. has allen 66, stopped at himself immediately challenging if s [SEP]']
[1050/2000] tot_loss=1.704 (perp=8.083, rec=0.085, cos=0.003), tot_loss_proj:3.425 [t=0.24s]
prediction: ['[CLS] as.. has allen 66, stopped at himself immediately challenging if s [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.664 (perp=7.860, rec=0.089, cos=0.003), tot_loss_proj:3.033 [t=0.24s]
prediction: ['[CLS] as.. has allen 66, immediately stopped at himself challenging if s [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.661 (perp=7.860, rec=0.086, cos=0.003), tot_loss_proj:3.045 [t=0.24s]
prediction: ['[CLS] as.. has allen 66, immediately stopped at himself challenging if s [SEP]']
[1200/2000] tot_loss=1.667 (perp=7.860, rec=0.093, cos=0.003), tot_loss_proj:3.040 [t=0.24s]
prediction: ['[CLS] as.. has allen 66, immediately stopped at himself challenging if s [SEP]']
Attempt swap
[1250/2000] tot_loss=1.664 (perp=7.860, rec=0.089, cos=0.002), tot_loss_proj:3.036 [t=0.24s]
prediction: ['[CLS] as.. has allen 66, immediately stopped at himself challenging if s [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.603 (perp=7.557, rec=0.088, cos=0.003), tot_loss_proj:2.874 [t=0.24s]
prediction: ['[CLS] as s. has allen 66, immediately stopped at himself challenging if. [SEP]']
[1350/2000] tot_loss=1.594 (perp=7.557, rec=0.080, cos=0.003), tot_loss_proj:2.867 [t=0.24s]
prediction: ['[CLS] as s. has allen 66, immediately stopped at himself challenging if. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.501 (perp=7.044, rec=0.089, cos=0.003), tot_loss_proj:2.559 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at himself challenging if. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.493 (perp=7.044, rec=0.082, cos=0.002), tot_loss_proj:2.552 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at himself challenging if. [SEP]']
[1500/2000] tot_loss=1.502 (perp=7.044, rec=0.090, cos=0.002), tot_loss_proj:2.548 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at himself challenging if. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.497 (perp=7.044, rec=0.085, cos=0.002), tot_loss_proj:2.554 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at himself challenging if. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.473 (perp=6.922, rec=0.086, cos=0.002), tot_loss_proj:2.593 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at if challenging himself. [SEP]']
[1650/2000] tot_loss=1.465 (perp=6.922, rec=0.078, cos=0.002), tot_loss_proj:2.599 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at if challenging himself. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.468 (perp=6.922, rec=0.081, cos=0.002), tot_loss_proj:2.598 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at if challenging himself. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.468 (perp=6.922, rec=0.081, cos=0.002), tot_loss_proj:2.602 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at if challenging himself. [SEP]']
[1800/2000] tot_loss=1.465 (perp=6.922, rec=0.078, cos=0.002), tot_loss_proj:2.597 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at if challenging himself. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.480 (perp=6.922, rec=0.093, cos=0.002), tot_loss_proj:2.599 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at if challenging himself. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.466 (perp=6.922, rec=0.079, cos=0.002), tot_loss_proj:2.598 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at if challenging himself. [SEP]']
[1950/2000] tot_loss=1.476 (perp=6.922, rec=0.089, cos=0.002), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at if challenging himself. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.470 (perp=6.922, rec=0.083, cos=0.002), tot_loss_proj:2.599 [t=0.24s]
prediction: ['[CLS] as s. has 66, allen immediately stopped at if challenging himself. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] as s. has 66, allen immediately stopped at if challenging himself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 17.391 | p: 16.667 | r: 18.182
rougeL     | fm: 56.000 | p: 53.846 | r: 58.333
rougeLsum  | fm: 56.000 | p: 53.846 | r: 58.333
r1fm+r2fm = 113.391

[Aggregate metrics]:
rouge1     | fm: 91.947 | p: 91.612 | r: 92.368
rouge2     | fm: 62.339 | p: 62.202 | r: 62.532
rougeL     | fm: 80.581 | p: 80.312 | r: 80.908
rougeLsum  | fm: 80.503 | p: 80.197 | r: 80.850
r1fm+r2fm = 154.286

input #76 time: 0:09:18 | total time: 12:05:25


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9992001897790881
highest_index [0]
highest [0.9992001897790881]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.9115081429481506 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8812075853347778 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.872740626335144 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 0.8698508143424988 for ['[CLS] grayraphic sheep most purple winno lime sometime medium park ways outside where ole [SEP]']
[Init] best perm rec loss: 0.8668491840362549 for ['[CLS] purple most ole park sometime sheep outside limeno ways win gray medium whereraphic [SEP]']
[Init] best perm rec loss: 0.8652713298797607 for ['[CLS] sometime ole where lime ways park purpleno win medium sheepraphic most outside gray [SEP]']
[Init] best perm rec loss: 0.8633628487586975 for ['[CLS] outside most gray whereraphic mediumno ole sheep sometime ways lime purple park win [SEP]']
[Init] best perm rec loss: 0.8618069887161255 for ['[CLS] purple outsideno where lime park most ole sometime win ways medium sheepraphic gray [SEP]']
[Init] best perm rec loss: 0.8598276376724243 for ['[CLS] win gray park where sometime medium ole most limeno ways sheep purpleraphic outside [SEP]']
[Init] best perm rec loss: 0.8584883213043213 for ['[CLS] ways park where oleraphic sometime win limeno most purple medium outside gray sheep [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.919 (perp=12.704, rec=0.358, cos=0.020), tot_loss_proj:4.378 [t=0.24s]
prediction: ['[CLS] stars poem crystal display breath rockets grace monumentla. ignore sweether writing foundation [SEP]']
[ 100/2000] tot_loss=2.350 (perp=10.288, rec=0.281, cos=0.011), tot_loss_proj:2.746 [t=0.24s]
prediction: ['[CLS] stars feel believe that believe above promise its cover is its wonderful the thinkingology [SEP]']
[ 150/2000] tot_loss=2.016 (perp=9.069, rec=0.197, cos=0.004), tot_loss_proj:2.917 [t=0.24s]
prediction: ['[CLS] realm feel believe life that above promise its cover is its above the material above [SEP]']
[ 200/2000] tot_loss=1.954 (perp=8.925, rec=0.165, cos=0.004), tot_loss_proj:2.655 [t=0.24s]
prediction: ['[CLS] realm make believe life thatars promise its above is its above the material above [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.777 (perp=8.120, rec=0.149, cos=0.005), tot_loss_proj:2.676 [t=0.24s]
prediction: ['[CLS] realm make believe that lifears promise its above is its above a material realm [SEP]']
[ 300/2000] tot_loss=1.728 (perp=8.011, rec=0.123, cos=0.003), tot_loss_proj:2.466 [t=0.24s]
prediction: ['[CLS] promise make believe that lifears promise its above is its above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.838 (perp=8.602, rec=0.115, cos=0.002), tot_loss_proj:2.538 [t=0.24s]
prediction: ['[CLS] its make believe that promisears promisert above is promise above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.769 (perp=8.257, rec=0.116, cos=0.002), tot_loss_proj:2.608 [t=0.24s]
prediction: ['[CLS] its make believe that promisears promiseacious promise is above above the material realm [SEP]']
[ 450/2000] tot_loss=1.725 (perp=8.095, rec=0.104, cos=0.002), tot_loss_proj:2.539 [t=0.24s]
prediction: ['[CLS] its make believe that promisears life - promise is above above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.592 (perp=7.464, rec=0.097, cos=0.002), tot_loss_proj:2.332 [t=0.24s]
prediction: ['[CLS] its make believe that promise is life - promisears above above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.542 (perp=7.159, rec=0.108, cos=0.002), tot_loss_proj:2.152 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - promisears above above the material realm [SEP]']
[ 600/2000] tot_loss=1.526 (perp=7.159, rec=0.093, cos=0.002), tot_loss_proj:2.160 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - promisears above above the material realm [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.524 (perp=7.159, rec=0.090, cos=0.002), tot_loss_proj:2.164 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - promisears above above the material realm [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.523 (perp=7.159, rec=0.089, cos=0.002), tot_loss_proj:2.155 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - promisears above above the material realm [SEP]']
[ 750/2000] tot_loss=1.520 (perp=7.159, rec=0.087, cos=0.002), tot_loss_proj:2.167 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - promisears above above the material realm [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.522 (perp=7.159, rec=0.088, cos=0.002), tot_loss_proj:2.161 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - promisears above above the material realm [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.511 (perp=7.159, rec=0.077, cos=0.002), tot_loss_proj:2.154 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - promisears above above the material realm [SEP]']
[ 900/2000] tot_loss=1.515 (perp=7.159, rec=0.082, cos=0.002), tot_loss_proj:2.158 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - promisears above above the material realm [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.588 (perp=7.549, rec=0.076, cos=0.002), tot_loss_proj:2.328 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - promisears above so the material realm [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.454 (perp=6.830, rec=0.087, cos=0.002), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - so promisears above the material realm [SEP]']
[1050/2000] tot_loss=1.445 (perp=6.830, rec=0.078, cos=0.002), tot_loss_proj:2.013 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - so promisears above the material realm [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.406 (perp=6.625, rec=0.079, cos=0.002), tot_loss_proj:1.843 [t=0.24s]
prediction: ['[CLS] its make believe that life is promise - promise soars above the material realm [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.388 (perp=6.520, rec=0.082, cos=0.002), tot_loss_proj:1.752 [t=0.24s]
prediction: ['[CLS] its make believe that life promise is promise - soars above the material realm [SEP]']
[1200/2000] tot_loss=1.379 (perp=6.520, rec=0.074, cos=0.002), tot_loss_proj:1.756 [t=0.24s]
prediction: ['[CLS] its make believe that life promise is promise - soars above the material realm [SEP]']
Attempt swap
[1250/2000] tot_loss=1.380 (perp=6.520, rec=0.075, cos=0.002), tot_loss_proj:1.751 [t=0.24s]
prediction: ['[CLS] its make believe that life promise is promise - soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.303 (perp=6.126, rec=0.076, cos=0.002), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
[1350/2000] tot_loss=1.290 (perp=6.126, rec=0.063, cos=0.002), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
Attempt swap
[1400/2000] tot_loss=1.300 (perp=6.126, rec=0.073, cos=0.002), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
Attempt swap
[1450/2000] tot_loss=1.297 (perp=6.126, rec=0.070, cos=0.002), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
[1500/2000] tot_loss=1.299 (perp=6.126, rec=0.073, cos=0.002), tot_loss_proj:1.676 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
Attempt swap
[1550/2000] tot_loss=1.298 (perp=6.126, rec=0.071, cos=0.002), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
Attempt swap
[1600/2000] tot_loss=1.296 (perp=6.126, rec=0.069, cos=0.002), tot_loss_proj:1.678 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
[1650/2000] tot_loss=1.295 (perp=6.126, rec=0.068, cos=0.002), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
Attempt swap
[1700/2000] tot_loss=1.295 (perp=6.126, rec=0.068, cos=0.002), tot_loss_proj:1.681 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
Attempt swap
[1750/2000] tot_loss=1.293 (perp=6.126, rec=0.067, cos=0.002), tot_loss_proj:1.681 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
[1800/2000] tot_loss=1.288 (perp=6.126, rec=0.061, cos=0.002), tot_loss_proj:1.682 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise - soars above the material realm [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.252 (perp=5.864, rec=0.077, cos=0.002), tot_loss_proj:1.782 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise soars above the material realm - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.242 (perp=5.864, rec=0.067, cos=0.001), tot_loss_proj:1.781 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise soars above the material realm - [SEP]']
[1950/2000] tot_loss=1.240 (perp=5.864, rec=0.066, cos=0.001), tot_loss_proj:1.779 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise soars above the material realm - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.253 (perp=5.864, rec=0.078, cos=0.001), tot_loss_proj:1.785 [t=0.24s]
prediction: ['[CLS] life make believe that its promise is promise soars above the material realm - [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] life make believe that its promise is promise - soars above the material realm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 136.190

[Aggregate metrics]:
rouge1     | fm: 92.003 | p: 91.634 | r: 92.402
rouge2     | fm: 62.227 | p: 62.031 | r: 62.445
rougeL     | fm: 80.443 | p: 80.155 | r: 80.766
rougeLsum  | fm: 80.195 | p: 79.917 | r: 80.594
r1fm+r2fm = 154.229

input #77 time: 0:09:26 | total time: 12:14:52


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9992701713024241
highest_index [0]
highest [0.9992701713024241]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9870139360427856 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9769070744514465 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8536514043807983 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8296306133270264 for ['[CLS] le screens grant [SEP]']
[Init] best rec loss: 0.8287628889083862 for ['[CLS] lightatics help [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.285 (perp=10.266, rec=0.218, cos=0.014), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] exit rotten theater [SEP]']
[ 100/2000] tot_loss=1.676 (perp=7.958, rec=0.082, cos=0.002), tot_loss_proj:1.681 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 150/2000] tot_loss=1.664 (perp=7.958, rec=0.071, cos=0.002), tot_loss_proj:1.677 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 200/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.651 (perp=7.958, rec=0.058, cos=0.001), tot_loss_proj:1.673 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.682 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.640 (perp=7.958, rec=0.047, cos=0.001), tot_loss_proj:1.678 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.655 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.674 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.689 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.655 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.645 (perp=7.958, rec=0.052, cos=0.001), tot_loss_proj:1.685 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.681 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.651 (perp=7.958, rec=0.058, cos=0.001), tot_loss_proj:1.674 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.682 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.678 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.669 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.682 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.670 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.675 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.678 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.651 (perp=7.958, rec=0.058, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.651 (perp=7.958, rec=0.058, cos=0.001), tot_loss_proj:1.676 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.655 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.671 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.665 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.666 (perp=7.958, rec=0.073, cos=0.001), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.654 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.671 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.655 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.677 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.685 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.641 (perp=7.958, rec=0.048, cos=0.001), tot_loss_proj:1.689 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.655 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.668 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.066 | p: 91.712 | r: 92.447
rouge2     | fm: 62.793 | p: 62.593 | r: 63.052
rougeL     | fm: 80.661 | p: 80.347 | r: 81.022
rougeLsum  | fm: 80.577 | p: 80.326 | r: 80.926
r1fm+r2fm = 154.859

input #78 time: 0:09:16 | total time: 12:24:08


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.999333502749002
highest_index [0]
highest [0.999333502749002]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9713650941848755 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.8481886982917786 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.8465403318405151 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.8365461826324463 for ['[CLS] funslow [SEP]']
[Init] best rec loss: 0.8340138792991638 for ['[CLS] gray should [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.032 (perp=9.381, rec=0.152, cos=0.003), tot_loss_proj:1.962 [t=0.23s]
prediction: ['[CLS] is fascinating [SEP]']
[ 100/2000] tot_loss=1.951 (perp=9.381, rec=0.073, cos=0.001), tot_loss_proj:1.945 [t=0.23s]
prediction: ['[CLS] is fascinating [SEP]']
[ 150/2000] tot_loss=1.938 (perp=9.381, rec=0.060, cos=0.001), tot_loss_proj:1.944 [t=0.24s]
prediction: ['[CLS] is fascinating [SEP]']
[ 200/2000] tot_loss=1.933 (perp=9.381, rec=0.056, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.830 (perp=8.695, rec=0.089, cos=0.002), tot_loss_proj:1.963 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.809 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.963 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.959 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.961 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.808 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.955 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.962 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.811 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.954 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.808 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.956 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.795 (perp=8.695, rec=0.055, cos=0.001), tot_loss_proj:1.949 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.806 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.956 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.818 (perp=8.695, rec=0.078, cos=0.001), tot_loss_proj:1.953 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.794 (perp=8.695, rec=0.054, cos=0.001), tot_loss_proj:1.951 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.809 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.961 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.811 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.948 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.792 (perp=8.695, rec=0.052, cos=0.001), tot_loss_proj:1.954 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.807 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.955 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.812 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.959 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.963 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.961 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.964 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.966 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.954 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.799 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.954 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.798 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.950 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.953 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.959 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.958 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.792 (perp=8.695, rec=0.051, cos=0.001), tot_loss_proj:1.948 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.815 (perp=8.695, rec=0.075, cos=0.001), tot_loss_proj:1.963 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.808 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.948 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.950 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.820 (perp=8.695, rec=0.080, cos=0.001), tot_loss_proj:1.956 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.954 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.820 (perp=8.695, rec=0.080, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.800 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.955 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.194 | p: 91.853 | r: 92.600
rouge2     | fm: 61.942 | p: 61.759 | r: 62.188
rougeL     | fm: 80.563 | p: 80.319 | r: 80.941
rougeLsum  | fm: 80.502 | p: 80.223 | r: 80.806
r1fm+r2fm = 154.136

input #79 time: 0:09:16 | total time: 12:33:25


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9992804445056542
highest_index [0]
highest [0.9992804445056542]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9627042412757874 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9625917673110962 for ['[CLS]sol floor stand now district [SEP]']
[Init] best rec loss: 0.9617151618003845 for ['[CLS]yna snaps california mussolini kicked [SEP]']
[Init] best rec loss: 0.940487802028656 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.929239809513092 for ['[CLS]down frasercake court beta [SEP]']
[Init] best rec loss: 0.9261685013771057 for ['[CLS] western area whilepres took [SEP]']
[Init] best rec loss: 0.9155707359313965 for ["[CLS]'incense kraft it jubilee [SEP]"]
[Init] best perm rec loss: 0.9146585464477539 for ["[CLS] jubilee it'kraft incense [SEP]"]
[Init] best perm rec loss: 0.9138307571411133 for ["[CLS] jubilee it incense'kraft [SEP]"]
[Init] best perm rec loss: 0.9125903844833374 for ["[CLS] it'incense jubilee kraft [SEP]"]
[Init] best perm rec loss: 0.912357747554779 for ["[CLS] it kraft'jubilee incense [SEP]"]
[Init] best perm rec loss: 0.9113789796829224 for ["[CLS] it kraft incense jubilee'[SEP]"]
[Init] best perm rec loss: 0.9109885096549988 for ["[CLS] it jubilee kraft incense'[SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.732 (perp=12.370, rec=0.252, cos=0.006), tot_loss_proj:4.270 [t=0.23s]
prediction: ['[CLS] wiseou mileszen though [SEP]']
[ 100/2000] tot_loss=2.193 (perp=10.206, rec=0.149, cos=0.003), tot_loss_proj:3.688 [t=0.23s]
prediction: ['[CLS] wiseou :zenzen [SEP]']
[ 150/2000] tot_loss=2.876 (perp=13.721, rec=0.129, cos=0.003), tot_loss_proj:3.869 [t=0.24s]
prediction: ['[CLS] wise quadedzen wi [SEP]']
[ 200/2000] tot_loss=2.580 (perp=12.261, rec=0.125, cos=0.003), tot_loss_proj:3.519 [t=0.24s]
prediction: ['[CLS] wise hiedzen wi [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.962 (perp=9.023, rec=0.154, cos=0.003), tot_loss_proj:2.541 [t=0.24s]
prediction: ['[CLS] wiseow wizened [SEP]']
[ 300/2000] tot_loss=2.092 (perp=9.836, rec=0.123, cos=0.002), tot_loss_proj:2.291 [t=0.24s]
prediction: ['[CLS] wise wi wizened [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.833 (perp=8.574, rec=0.116, cos=0.002), tot_loss_proj:2.060 [t=0.24s]
prediction: ['[CLS] wise wizened wi [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.823 (perp=8.574, rec=0.106, cos=0.002), tot_loss_proj:2.071 [t=0.24s]
prediction: ['[CLS] wise wizened wi [SEP]']
[ 450/2000] tot_loss=1.819 (perp=8.574, rec=0.102, cos=0.002), tot_loss_proj:2.071 [t=0.24s]
prediction: ['[CLS] wise wizened wi [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.803 (perp=8.574, rec=0.086, cos=0.002), tot_loss_proj:2.073 [t=0.24s]
prediction: ['[CLS] wise wizened wi [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.806 (perp=8.574, rec=0.089, cos=0.002), tot_loss_proj:2.066 [t=0.24s]
prediction: ['[CLS] wise wizened wi [SEP]']
[ 600/2000] tot_loss=1.461 (perp=6.805, rec=0.097, cos=0.002), tot_loss_proj:1.646 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.447 (perp=6.805, rec=0.084, cos=0.002), tot_loss_proj:1.627 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.444 (perp=6.805, rec=0.081, cos=0.002), tot_loss_proj:1.634 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
[ 750/2000] tot_loss=1.441 (perp=6.805, rec=0.078, cos=0.002), tot_loss_proj:1.641 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.447 (perp=6.805, rec=0.084, cos=0.002), tot_loss_proj:1.638 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.453 (perp=6.805, rec=0.090, cos=0.002), tot_loss_proj:1.641 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
[ 900/2000] tot_loss=1.448 (perp=6.805, rec=0.085, cos=0.002), tot_loss_proj:1.644 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.443 (perp=6.805, rec=0.080, cos=0.002), tot_loss_proj:1.642 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.453 (perp=6.805, rec=0.090, cos=0.002), tot_loss_proj:1.636 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
[1050/2000] tot_loss=1.448 (perp=6.805, rec=0.084, cos=0.002), tot_loss_proj:1.647 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.439 (perp=6.805, rec=0.077, cos=0.002), tot_loss_proj:1.639 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.441 (perp=6.805, rec=0.078, cos=0.002), tot_loss_proj:1.642 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
[1200/2000] tot_loss=1.440 (perp=6.805, rec=0.077, cos=0.002), tot_loss_proj:1.637 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.442 (perp=6.805, rec=0.079, cos=0.002), tot_loss_proj:1.645 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.434 (perp=6.805, rec=0.071, cos=0.002), tot_loss_proj:1.646 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
[1350/2000] tot_loss=1.441 (perp=6.805, rec=0.078, cos=0.002), tot_loss_proj:1.640 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.435 (perp=6.805, rec=0.072, cos=0.002), tot_loss_proj:1.637 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.446 (perp=6.805, rec=0.083, cos=0.002), tot_loss_proj:1.648 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
[1500/2000] tot_loss=1.445 (perp=6.805, rec=0.082, cos=0.002), tot_loss_proj:1.637 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.434 (perp=6.805, rec=0.071, cos=0.002), tot_loss_proj:1.632 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.434 (perp=6.805, rec=0.071, cos=0.002), tot_loss_proj:1.637 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
[1650/2000] tot_loss=1.439 (perp=6.805, rec=0.077, cos=0.002), tot_loss_proj:1.632 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.444 (perp=6.805, rec=0.081, cos=0.002), tot_loss_proj:1.636 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.443 (perp=6.805, rec=0.080, cos=0.002), tot_loss_proj:1.642 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
[1800/2000] tot_loss=1.437 (perp=6.805, rec=0.075, cos=0.002), tot_loss_proj:1.629 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.435 (perp=6.805, rec=0.072, cos=0.002), tot_loss_proj:1.643 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.435 (perp=6.805, rec=0.072, cos=0.002), tot_loss_proj:1.630 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
[1950/2000] tot_loss=1.429 (perp=6.805, rec=0.067, cos=0.002), tot_loss_proj:1.642 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.433 (perp=6.805, rec=0.071, cos=0.002), tot_loss_proj:1.633 [t=0.24s]
prediction: ['[CLS] wise wizened, [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise wizened, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.292 | p: 91.974 | r: 92.678
rouge2     | fm: 62.357 | p: 62.158 | r: 62.591
rougeL     | fm: 80.833 | p: 80.540 | r: 81.153
rougeLsum  | fm: 80.711 | p: 80.465 | r: 81.045
r1fm+r2fm = 154.650

input #80 time: 0:09:16 | total time: 12:42:42


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9992872482218231
highest_index [0]
highest [0.9992872482218231]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9009989500045776 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.8568158745765686 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8462851047515869 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8266099095344543 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8195542097091675 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8106294274330139 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 0.7963440418243408 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 0.7945745587348938 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best rec loss: 0.7920742630958557 for ['[CLS] crawl taken grind choice azerbaijan potter [SEP]']
[Init] best perm rec loss: 0.7888742089271545 for ['[CLS] taken choice grind azerbaijan crawl potter [SEP]']
[Init] best perm rec loss: 0.7881178259849548 for ['[CLS] crawl choice potter azerbaijan taken grind [SEP]']
[Init] best perm rec loss: 0.7879045009613037 for ['[CLS] grind crawl taken choice azerbaijan potter [SEP]']
[Init] best perm rec loss: 0.7871419191360474 for ['[CLS] potter crawl taken choice azerbaijan grind [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.070 (perp=13.080, rec=0.406, cos=0.048), tot_loss_proj:3.580 [t=0.23s]
prediction: ['[CLS] actually debt failure actually gil fight [SEP]']
[ 100/2000] tot_loss=2.211 (perp=9.475, rec=0.301, cos=0.015), tot_loss_proj:2.703 [t=0.24s]
prediction: ['[CLS] is not not player impressive player [SEP]']
[ 150/2000] tot_loss=2.282 (perp=10.226, rec=0.227, cos=0.010), tot_loss_proj:3.053 [t=0.24s]
prediction: ['[CLS] is not is player impressive is [SEP]']
[ 200/2000] tot_loss=2.417 (perp=10.866, rec=0.220, cos=0.024), tot_loss_proj:3.591 [t=0.24s]
prediction: ['[CLS] most not is player impressive is [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.854 (perp=8.572, rec=0.135, cos=0.005), tot_loss_proj:2.508 [t=0.24s]
prediction: ['[CLS] most not impressive player is is [SEP]']
[ 300/2000] tot_loss=1.831 (perp=8.572, rec=0.113, cos=0.004), tot_loss_proj:2.509 [t=0.24s]
prediction: ['[CLS] most not impressive player is is [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.898 (perp=8.949, rec=0.104, cos=0.004), tot_loss_proj:3.602 [t=0.24s]
prediction: ['[CLS] most impressive not player is relatively [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.890 (perp=8.949, rec=0.096, cos=0.004), tot_loss_proj:3.602 [t=0.24s]
prediction: ['[CLS] most impressive not player is relatively [SEP]']
[ 450/2000] tot_loss=1.901 (perp=8.949, rec=0.107, cos=0.004), tot_loss_proj:3.604 [t=0.24s]
prediction: ['[CLS] most impressive not player is relatively [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.892 (perp=8.949, rec=0.098, cos=0.004), tot_loss_proj:3.604 [t=0.24s]
prediction: ['[CLS] most impressive not player is relatively [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.878 (perp=8.949, rec=0.085, cos=0.004), tot_loss_proj:3.600 [t=0.24s]
prediction: ['[CLS] most impressive not player is relatively [SEP]']
[ 600/2000] tot_loss=1.882 (perp=8.949, rec=0.088, cos=0.004), tot_loss_proj:3.605 [t=0.24s]
prediction: ['[CLS] most impressive not player is relatively [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.875 (perp=8.949, rec=0.082, cos=0.003), tot_loss_proj:3.603 [t=0.24s]
prediction: ['[CLS] most impressive not player is relatively [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.759 (perp=8.366, rec=0.083, cos=0.002), tot_loss_proj:3.499 [t=0.24s]
prediction: ['[CLS] most impressive not player is is [SEP]']
[ 750/2000] tot_loss=1.524 (perp=7.252, rec=0.072, cos=0.002), tot_loss_proj:3.249 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.522 (perp=7.252, rec=0.070, cos=0.002), tot_loss_proj:3.245 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.526 (perp=7.252, rec=0.074, cos=0.001), tot_loss_proj:3.252 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
[ 900/2000] tot_loss=1.519 (perp=7.252, rec=0.067, cos=0.001), tot_loss_proj:3.253 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.515 (perp=7.252, rec=0.063, cos=0.001), tot_loss_proj:3.250 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
Attempt swap
[1000/2000] tot_loss=1.520 (perp=7.252, rec=0.068, cos=0.001), tot_loss_proj:3.246 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
[1050/2000] tot_loss=1.521 (perp=7.252, rec=0.069, cos=0.001), tot_loss_proj:3.248 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
Attempt swap
[1100/2000] tot_loss=1.512 (perp=7.252, rec=0.060, cos=0.001), tot_loss_proj:3.245 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
Attempt swap
[1150/2000] tot_loss=1.514 (perp=7.252, rec=0.063, cos=0.001), tot_loss_proj:3.252 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
[1200/2000] tot_loss=1.520 (perp=7.252, rec=0.068, cos=0.001), tot_loss_proj:3.251 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
Attempt swap
[1250/2000] tot_loss=1.527 (perp=7.252, rec=0.075, cos=0.001), tot_loss_proj:3.246 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
Attempt swap
[1300/2000] tot_loss=1.513 (perp=7.252, rec=0.061, cos=0.001), tot_loss_proj:3.252 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
[1350/2000] tot_loss=1.513 (perp=7.252, rec=0.061, cos=0.001), tot_loss_proj:3.246 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
Attempt swap
[1400/2000] tot_loss=1.513 (perp=7.252, rec=0.061, cos=0.001), tot_loss_proj:3.248 [t=0.24s]
prediction: ['[CLS] most impressive not player is the [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.449 (perp=6.914, rec=0.065, cos=0.002), tot_loss_proj:3.126 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
[1500/2000] tot_loss=1.458 (perp=6.914, rec=0.074, cos=0.001), tot_loss_proj:3.130 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
Attempt swap
[1550/2000] tot_loss=1.456 (perp=6.914, rec=0.072, cos=0.001), tot_loss_proj:3.126 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
Attempt swap
[1600/2000] tot_loss=1.456 (perp=6.914, rec=0.072, cos=0.001), tot_loss_proj:3.131 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
[1650/2000] tot_loss=1.450 (perp=6.914, rec=0.066, cos=0.001), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
Attempt swap
[1700/2000] tot_loss=1.455 (perp=6.914, rec=0.071, cos=0.001), tot_loss_proj:3.134 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
Attempt swap
[1750/2000] tot_loss=1.448 (perp=6.914, rec=0.064, cos=0.001), tot_loss_proj:3.130 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
[1800/2000] tot_loss=1.442 (perp=6.914, rec=0.058, cos=0.001), tot_loss_proj:3.125 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
Attempt swap
[1850/2000] tot_loss=1.448 (perp=6.914, rec=0.064, cos=0.001), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
Attempt swap
[1900/2000] tot_loss=1.446 (perp=6.914, rec=0.062, cos=0.001), tot_loss_proj:3.129 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
[1950/2000] tot_loss=1.454 (perp=6.914, rec=0.070, cos=0.001), tot_loss_proj:3.130 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
Attempt swap
[2000/2000] tot_loss=1.448 (perp=6.914, rec=0.063, cos=0.001), tot_loss_proj:3.129 [t=0.24s]
prediction: ['[CLS] most impressive the player is not [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] most impressive not player is the [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 114.286

[Aggregate metrics]:
rouge1     | fm: 92.394 | p: 92.024 | r: 92.774
rouge2     | fm: 61.842 | p: 61.672 | r: 62.030
rougeL     | fm: 80.601 | p: 80.331 | r: 80.895
rougeLsum  | fm: 80.581 | p: 80.282 | r: 80.954
r1fm+r2fm = 154.236

input #81 time: 0:09:17 | total time: 12:52:00


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.999280197064362
highest_index [0]
highest [0.999280197064362]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9871094822883606 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9780022501945496 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9488106966018677 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9384766817092896 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9379804730415344 for ['[CLS] provided yards master cases risky wickets aboveflict [SEP]']
[Init] best rec loss: 0.9337881207466125 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 0.8673442602157593 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.826836884021759 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8214476704597473 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8205435276031494 for ['[CLS]furbasket respectiveach role record plumage whoever [SEP]']
[Init] best perm rec loss: 0.819252073764801 for ['[CLS]basket respective whoeverach record rolefur plumage [SEP]']
[Init] best perm rec loss: 0.8188300728797913 for ['[CLS]achbasket whoeverfur record respective plumage role [SEP]']
[Init] best perm rec loss: 0.8187480568885803 for ['[CLS] whoeverbasketfurach respective plumage role record [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.263 (perp=10.203, rec=0.215, cos=0.007), tot_loss_proj:2.795 [t=0.23s]
prediction: ['[CLS] a sloppy sloppy undone its sloppy script undone [SEP]']
[ 100/2000] tot_loss=2.049 (perp=9.686, rec=0.109, cos=0.003), tot_loss_proj:2.460 [t=0.24s]
prediction: ['[CLS] a sloppy sloppy undone by sloppy script undone [SEP]']
[ 150/2000] tot_loss=2.249 (perp=10.846, rec=0.078, cos=0.002), tot_loss_proj:2.622 [t=0.24s]
prediction: ['[CLS] a sloppy it s by sloppy script undone [SEP]']
[ 200/2000] tot_loss=2.243 (perp=10.846, rec=0.073, cos=0.002), tot_loss_proj:2.612 [t=0.24s]
prediction: ['[CLS] a sloppy it s by sloppy script undone [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.892 (perp=9.053, rec=0.080, cos=0.002), tot_loss_proj:2.345 [t=0.24s]
prediction: ['[CLS] a sloppy s by sloppy script undone it [SEP]']
[ 300/2000] tot_loss=1.887 (perp=9.053, rec=0.074, cos=0.001), tot_loss_proj:2.347 [t=0.24s]
prediction: ['[CLS] a sloppy s by sloppy script undone it [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.724 (perp=8.254, rec=0.072, cos=0.001), tot_loss_proj:1.986 [t=0.24s]
prediction: ['[CLS] a sloppy s sloppy script undone by it [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.683 (perp=8.110, rec=0.060, cos=0.001), tot_loss_proj:1.966 [t=0.24s]
prediction: ['[CLS] a s sloppy sloppy script undone by it [SEP]']
[ 450/2000] tot_loss=1.692 (perp=8.110, rec=0.068, cos=0.001), tot_loss_proj:1.961 [t=0.24s]
prediction: ['[CLS] a s sloppy sloppy script undone by it [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.670 (perp=8.062, rec=0.056, cos=0.001), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] s a sloppy sloppy script undone by it [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=1.625 (perp=7.778, rec=0.068, cos=0.002), tot_loss_proj:1.931 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 600/2000] tot_loss=1.631 (perp=7.778, rec=0.074, cos=0.001), tot_loss_proj:1.922 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.625 (perp=7.778, rec=0.068, cos=0.001), tot_loss_proj:1.934 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.619 (perp=7.778, rec=0.062, cos=0.001), tot_loss_proj:1.937 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 750/2000] tot_loss=1.622 (perp=7.778, rec=0.065, cos=0.001), tot_loss_proj:1.939 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.627 (perp=7.778, rec=0.070, cos=0.001), tot_loss_proj:1.930 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.618 (perp=7.778, rec=0.060, cos=0.001), tot_loss_proj:1.933 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 900/2000] tot_loss=1.614 (perp=7.778, rec=0.057, cos=0.001), tot_loss_proj:1.929 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.623 (perp=7.778, rec=0.066, cos=0.001), tot_loss_proj:1.933 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1000/2000] tot_loss=1.624 (perp=7.778, rec=0.067, cos=0.001), tot_loss_proj:1.931 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1050/2000] tot_loss=1.622 (perp=7.778, rec=0.065, cos=0.001), tot_loss_proj:1.928 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.622 (perp=7.778, rec=0.065, cos=0.001), tot_loss_proj:1.929 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1150/2000] tot_loss=1.633 (perp=7.778, rec=0.075, cos=0.001), tot_loss_proj:1.931 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1200/2000] tot_loss=1.626 (perp=7.778, rec=0.069, cos=0.001), tot_loss_proj:1.936 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.624 (perp=7.778, rec=0.067, cos=0.001), tot_loss_proj:1.934 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1300/2000] tot_loss=1.617 (perp=7.778, rec=0.060, cos=0.001), tot_loss_proj:1.932 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1350/2000] tot_loss=1.622 (perp=7.778, rec=0.065, cos=0.001), tot_loss_proj:1.934 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.613 (perp=7.778, rec=0.056, cos=0.001), tot_loss_proj:1.931 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.617 (perp=7.778, rec=0.060, cos=0.001), tot_loss_proj:1.932 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1500/2000] tot_loss=1.619 (perp=7.778, rec=0.061, cos=0.001), tot_loss_proj:1.931 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1550/2000] tot_loss=1.621 (perp=7.778, rec=0.064, cos=0.001), tot_loss_proj:1.937 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.620 (perp=7.778, rec=0.062, cos=0.001), tot_loss_proj:1.935 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1650/2000] tot_loss=1.620 (perp=7.778, rec=0.063, cos=0.001), tot_loss_proj:1.922 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.622 (perp=7.778, rec=0.065, cos=0.001), tot_loss_proj:1.937 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.628 (perp=7.778, rec=0.071, cos=0.001), tot_loss_proj:1.923 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1800/2000] tot_loss=1.621 (perp=7.778, rec=0.063, cos=0.001), tot_loss_proj:1.931 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1850/2000] tot_loss=1.621 (perp=7.778, rec=0.064, cos=0.001), tot_loss_proj:1.930 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.624 (perp=7.778, rec=0.067, cos=0.001), tot_loss_proj:1.932 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1950/2000] tot_loss=1.626 (perp=7.778, rec=0.069, cos=0.001), tot_loss_proj:1.934 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.629 (perp=7.778, rec=0.072, cos=0.001), tot_loss_proj:1.926 [t=0.24s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s a sloppy sloppy script undone by [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 92.368 | p: 92.013 | r: 92.835
rouge2     | fm: 61.870 | p: 61.652 | r: 62.147
rougeL     | fm: 80.563 | p: 80.238 | r: 80.958
rougeLsum  | fm: 80.441 | p: 80.099 | r: 80.820
r1fm+r2fm = 154.238

input #82 time: 0:09:18 | total time: 13:01:18


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9992437339704883
highest_index [0]
highest [0.9992437339704883]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.9575920701026917 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.9534390568733215 for ['[CLS] consisting hartley lives champions forgotten johnson account integeronal merge [SEP]']
[Init] best rec loss: 0.9510172605514526 for ['[CLS] ben tawork position naked map because sort been season [SEP]']
[Init] best rec loss: 0.9441697001457214 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.8845860362052917 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 0.8710569739341736 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8709710240364075 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.8656304478645325 for ['[CLS] original review giggled field floor arid read beckett cecil i [SEP]']
[Init] best rec loss: 0.8608826398849487 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.8563296794891357 for ['[CLS] ut sighed another tex predicted hooper alsoов toes personally [SEP]']
[Init] best rec loss: 0.8355855941772461 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best rec loss: 0.8123910427093506 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.8044590353965759 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
[Init] best perm rec loss: 0.8041741251945496 for ['[CLS] residence neck follows nearly stew pitch boys comprehensive vice envelope [SEP]']
[Init] best perm rec loss: 0.8038275837898254 for ['[CLS] nearly pitch vice boys neck residence envelope comprehensive follows stew [SEP]']
[Init] best perm rec loss: 0.8033164143562317 for ['[CLS] stew nearly boys follows neck pitch comprehensive vice residence envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.635 (perp=11.248, rec=0.355, cos=0.031), tot_loss_proj:4.061 [t=0.23s]
prediction: ['[CLS] pale growth. big concerning becoming respect. understand change [SEP]']
[ 100/2000] tot_loss=2.345 (perp=10.524, rec=0.232, cos=0.008), tot_loss_proj:3.614 [t=0.24s]
prediction: ['[CLS]dor grow when what when grows what. know when [SEP]']
[ 150/2000] tot_loss=2.169 (perp=9.967, rec=0.171, cos=0.005), tot_loss_proj:3.154 [t=0.24s]
prediction: ['[CLS]que grow when what it grows wants be know when [SEP]']
[ 200/2000] tot_loss=2.083 (perp=9.803, rec=0.119, cos=0.003), tot_loss_proj:3.203 [t=0.24s]
prediction: ['[CLS]dor grow it what it grows wants be know when [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.880 (perp=8.898, rec=0.098, cos=0.003), tot_loss_proj:2.857 [t=0.24s]
prediction: ['[CLS]dor grow what it grows wants to be know when [SEP]']
[ 300/2000] tot_loss=1.505 (perp=7.042, rec=0.094, cos=0.002), tot_loss_proj:2.482 [t=0.24s]
prediction: ['[CLS] up up what it grows wants to be know when [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.383 (perp=6.425, rec=0.095, cos=0.003), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] up grows up what it wants to be know when [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.257 (perp=5.822, rec=0.089, cos=0.003), tot_loss_proj:1.754 [t=0.24s]
prediction: ['[CLS] up grows up know what it wants to be when [SEP]']
[ 450/2000] tot_loss=1.249 (perp=5.822, rec=0.082, cos=0.003), tot_loss_proj:1.761 [t=0.24s]
prediction: ['[CLS] up grows up know what it wants to be when [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.255 (perp=5.822, rec=0.088, cos=0.003), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] up grows up know what it wants to be when [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.250 (perp=5.822, rec=0.083, cos=0.003), tot_loss_proj:1.749 [t=0.24s]
prediction: ['[CLS] up grows up know what it wants to be when [SEP]']
[ 600/2000] tot_loss=1.134 (perp=5.245, rec=0.083, cos=0.003), tot_loss_proj:1.523 [t=0.24s]
prediction: ['[CLS] it grows up know what it wants to be when [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.256 (perp=5.792, rec=0.095, cos=0.002), tot_loss_proj:1.579 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows [SEP] [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.156 (perp=5.368, rec=0.080, cos=0.003), tot_loss_proj:1.448 [t=0.24s]
prediction: ['[CLS] up know what it wants to be when it grows [SEP]']
[ 750/2000] tot_loss=1.159 (perp=5.368, rec=0.083, cos=0.002), tot_loss_proj:1.453 [t=0.24s]
prediction: ['[CLS] up know what it wants to be when it grows [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.028 (perp=4.691, rec=0.088, cos=0.002), tot_loss_proj:1.064 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.020 (perp=4.691, rec=0.079, cos=0.002), tot_loss_proj:1.072 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[ 900/2000] tot_loss=1.019 (perp=4.691, rec=0.078, cos=0.002), tot_loss_proj:1.067 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.012 (perp=4.691, rec=0.071, cos=0.002), tot_loss_proj:1.065 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.015 (perp=4.691, rec=0.074, cos=0.002), tot_loss_proj:1.071 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1050/2000] tot_loss=1.011 (perp=4.691, rec=0.070, cos=0.002), tot_loss_proj:1.058 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.018 (perp=4.691, rec=0.078, cos=0.002), tot_loss_proj:1.065 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.016 (perp=4.691, rec=0.076, cos=0.002), tot_loss_proj:1.064 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1200/2000] tot_loss=1.016 (perp=4.691, rec=0.076, cos=0.002), tot_loss_proj:1.071 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.015 (perp=4.691, rec=0.074, cos=0.002), tot_loss_proj:1.071 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.017 (perp=4.691, rec=0.077, cos=0.002), tot_loss_proj:1.061 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1350/2000] tot_loss=1.018 (perp=4.691, rec=0.078, cos=0.002), tot_loss_proj:1.061 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.011 (perp=4.691, rec=0.071, cos=0.002), tot_loss_proj:1.062 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.016 (perp=4.691, rec=0.075, cos=0.002), tot_loss_proj:1.062 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1500/2000] tot_loss=1.016 (perp=4.691, rec=0.075, cos=0.002), tot_loss_proj:1.072 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.013 (perp=4.691, rec=0.073, cos=0.002), tot_loss_proj:1.067 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.021 (perp=4.691, rec=0.080, cos=0.002), tot_loss_proj:1.058 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1650/2000] tot_loss=1.013 (perp=4.691, rec=0.073, cos=0.002), tot_loss_proj:1.063 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.019 (perp=4.691, rec=0.079, cos=0.002), tot_loss_proj:1.070 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.016 (perp=4.691, rec=0.075, cos=0.002), tot_loss_proj:1.070 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1800/2000] tot_loss=1.019 (perp=4.691, rec=0.078, cos=0.002), tot_loss_proj:1.063 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.022 (perp=4.691, rec=0.081, cos=0.002), tot_loss_proj:1.059 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.014 (perp=4.691, rec=0.073, cos=0.002), tot_loss_proj:1.061 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
[1950/2000] tot_loss=1.006 (perp=4.691, rec=0.066, cos=0.002), tot_loss_proj:1.061 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.005 (perp=4.691, rec=0.064, cos=0.002), tot_loss_proj:1.066 [t=0.24s]
prediction: ['[CLS] know what it wants to be when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.516 | p: 92.146 | r: 92.927
rouge2     | fm: 62.237 | p: 61.989 | r: 62.480
rougeL     | fm: 80.797 | p: 80.494 | r: 81.146
rougeLsum  | fm: 80.649 | p: 80.361 | r: 80.993
r1fm+r2fm = 154.754

input #83 time: 0:09:18 | total time: 13:10:37


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9991129649261612
highest_index [0]
highest [0.9991129649261612]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.927739679813385 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.9178661108016968 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 0.9015358686447144 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8932105898857117 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 0.8898106813430786 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.8857002258300781 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8841055631637573 for ['[CLS]oglaise catholicur prototype issues cheered [SEP]']
[Init] best rec loss: 0.8625176548957825 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8600064516067505 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best perm rec loss: 0.8589123487472534 for ['[CLS] caused infinite ca each goingiter its [SEP]']
[Init] best perm rec loss: 0.8584563136100769 for ['[CLS] going infiniteiter caused each its ca [SEP]']
[Init] best perm rec loss: 0.8573440313339233 for ['[CLS] going each caused its ca infiniteiter [SEP]']
[Init] best perm rec loss: 0.8568987250328064 for ['[CLS] its going infinite ca caused eachiter [SEP]']
[Init] best perm rec loss: 0.8566478490829468 for ['[CLS] caiter going its caused each infinite [SEP]']
[Init] best perm rec loss: 0.8562791347503662 for ['[CLS] ca going infinite its caused eachiter [SEP]']
[Init] best perm rec loss: 0.8562309145927429 for ['[CLS] eachiter going infinite caused ca its [SEP]']
[Init] best perm rec loss: 0.8557958602905273 for ['[CLS]iter infinite each its caused going ca [SEP]']
[Init] best perm rec loss: 0.8551145195960999 for ['[CLS]iter going ca its infinite caused each [SEP]']
[Init] best perm rec loss: 0.8549153208732605 for ['[CLS] going ca caused each itsiter infinite [SEP]']
[Init] best perm rec loss: 0.8547622561454773 for ['[CLS]iter infinite its ca each going caused [SEP]']
[Init] best perm rec loss: 0.8544797897338867 for ['[CLS] causediter infinite its ca going each [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.294 (perp=9.844, rec=0.298, cos=0.027), tot_loss_proj:2.723 [t=0.23s]
prediction: ['[CLS] kid lost thinking lost lost people ability [SEP]']
[ 100/2000] tot_loss=1.981 (perp=9.083, rec=0.159, cos=0.005), tot_loss_proj:2.298 [t=0.24s]
prediction: ['[CLS] people lost people to lost think ability [SEP]']
[ 150/2000] tot_loss=1.893 (perp=8.952, rec=0.100, cos=0.003), tot_loss_proj:2.594 [t=0.24s]
prediction: ['[CLS] people lost people to have think ability [SEP]']
[ 200/2000] tot_loss=1.990 (perp=9.495, rec=0.088, cos=0.003), tot_loss_proj:2.414 [t=0.24s]
prediction: ['[CLS] people lost the to have think ability [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.904 (perp=9.058, rec=0.090, cos=0.002), tot_loss_proj:2.645 [t=0.24s]
prediction: ['[CLS] people lost the ability off have think [SEP]']
[ 300/2000] tot_loss=1.813 (perp=8.678, rec=0.075, cos=0.002), tot_loss_proj:2.520 [t=0.24s]
prediction: ['[CLS] people lost the ability on have think [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.435 (perp=6.832, rec=0.066, cos=0.002), tot_loss_proj:1.627 [t=0.24s]
prediction: ['[CLS] people have lost the ability on think [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.441 (perp=6.832, rec=0.072, cos=0.002), tot_loss_proj:1.628 [t=0.24s]
prediction: ['[CLS] people have lost the ability on think [SEP]']
[ 450/2000] tot_loss=1.300 (perp=6.097, rec=0.078, cos=0.002), tot_loss_proj:1.408 [t=0.24s]
prediction: ['[CLS] people have lost the ability for think [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.010 (perp=4.681, rec=0.072, cos=0.002), tot_loss_proj:1.040 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.011 (perp=4.681, rec=0.073, cos=0.002), tot_loss_proj:1.040 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 600/2000] tot_loss=1.012 (perp=4.681, rec=0.074, cos=0.002), tot_loss_proj:1.041 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.013 (perp=4.681, rec=0.075, cos=0.002), tot_loss_proj:1.034 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.003 (perp=4.681, rec=0.065, cos=0.002), tot_loss_proj:1.037 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.043 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.032 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.006 (perp=4.681, rec=0.068, cos=0.002), tot_loss_proj:1.039 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=1.003 (perp=4.681, rec=0.065, cos=0.002), tot_loss_proj:1.026 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.039 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=0.999 (perp=4.681, rec=0.061, cos=0.002), tot_loss_proj:1.039 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=1.010 (perp=4.681, rec=0.072, cos=0.002), tot_loss_proj:1.029 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.039 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=0.999 (perp=4.681, rec=0.061, cos=0.002), tot_loss_proj:1.027 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.034 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.004 (perp=4.681, rec=0.066, cos=0.002), tot_loss_proj:1.039 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.043 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=0.993 (perp=4.681, rec=0.055, cos=0.002), tot_loss_proj:1.028 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=1.004 (perp=4.681, rec=0.066, cos=0.002), tot_loss_proj:1.040 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.037 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.038 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=0.999 (perp=4.681, rec=0.061, cos=0.002), tot_loss_proj:1.033 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.010 (perp=4.681, rec=0.072, cos=0.002), tot_loss_proj:1.043 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=0.989 (perp=4.681, rec=0.051, cos=0.002), tot_loss_proj:1.031 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.039 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=0.993 (perp=4.681, rec=0.055, cos=0.002), tot_loss_proj:1.038 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.036 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.004 (perp=4.681, rec=0.066, cos=0.002), tot_loss_proj:1.032 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=0.998 (perp=4.681, rec=0.060, cos=0.002), tot_loss_proj:1.035 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.028 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=0.999 (perp=4.681, rec=0.061, cos=0.002), tot_loss_proj:1.039 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.595 | p: 92.234 | r: 93.070
rouge2     | fm: 62.640 | p: 62.450 | r: 62.860
rougeL     | fm: 80.997 | p: 80.685 | r: 81.345
rougeLsum  | fm: 80.886 | p: 80.588 | r: 81.243
r1fm+r2fm = 155.235

input #84 time: 0:09:18 | total time: 13:19:55


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9992370346205339
highest_index [0]
highest [0.9992370346205339]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9693423509597778 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9537092447280884 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.9295451641082764 for ['[CLS] creek i instrumental bottomifnotes kensington military kowalski smoky [SEP]']
[Init] best rec loss: 0.8857548236846924 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8701900839805603 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best perm rec loss: 0.8665063977241516 for ['[CLS] indies backgroundleinthing road laps indianrman fallen defender [SEP]']
[Init] best perm rec loss: 0.8620833158493042 for ['[CLS]lein roadthing defender indianrman indies laps fallen background [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.847 (perp=7.872, rec=0.261, cos=0.012), tot_loss_proj:2.101 [t=0.23s]
prediction: ['[CLS] unfortunately unfortunately because s. still was especially not good [SEP]']
[ 100/2000] tot_loss=1.651 (perp=7.666, rec=0.114, cos=0.004), tot_loss_proj:2.029 [t=0.24s]
prediction: ["[CLS] unfortunately unfortunately because.'also it very not good [SEP]"]
[ 150/2000] tot_loss=1.379 (perp=6.411, rec=0.095, cos=0.002), tot_loss_proj:1.719 [t=0.24s]
prediction: ['[CLS] unfortunately,.. s also it very not good [SEP]']
[ 200/2000] tot_loss=1.526 (perp=7.265, rec=0.071, cos=0.002), tot_loss_proj:1.892 [t=0.24s]
prediction: ['[CLS] unfortunately,., s also it very not good [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.285 (perp=6.035, rec=0.076, cos=0.003), tot_loss_proj:1.566 [t=0.24s]
prediction: ['[CLS] unfortunately,., it also s very not good [SEP]']
[ 300/2000] tot_loss=1.275 (perp=6.035, rec=0.066, cos=0.003), tot_loss_proj:1.563 [t=0.24s]
prediction: ['[CLS] unfortunately,., it also s very not good [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.126 (perp=5.265, rec=0.071, cos=0.002), tot_loss_proj:1.321 [t=0.24s]
prediction: ['[CLS] unfortunately,., it also s not very good [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.423 (perp=6.164, rec=0.181, cos=0.009), tot_loss_proj:1.521 [t=0.24s]
prediction: ['[CLS] unfortunatelysi, it also s not very good. [SEP]']
[ 450/2000] tot_loss=1.323 (perp=6.164, rec=0.088, cos=0.003), tot_loss_proj:1.499 [t=0.24s]
prediction: ['[CLS] unfortunatelysi, it also s not very good. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.262 (perp=5.934, rec=0.073, cos=0.003), tot_loss_proj:1.410 [t=0.24s]
prediction: ['[CLS] unfortunately, it alsosi s not very good. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.235 (perp=5.775, rec=0.077, cos=0.003), tot_loss_proj:1.297 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
[ 600/2000] tot_loss=1.230 (perp=5.775, rec=0.072, cos=0.003), tot_loss_proj:1.295 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.222 (perp=5.775, rec=0.064, cos=0.003), tot_loss_proj:1.296 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.222 (perp=5.775, rec=0.064, cos=0.003), tot_loss_proj:1.289 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
[ 750/2000] tot_loss=1.229 (perp=5.775, rec=0.071, cos=0.003), tot_loss_proj:1.291 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.233 (perp=5.775, rec=0.075, cos=0.003), tot_loss_proj:1.290 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.227 (perp=5.775, rec=0.069, cos=0.003), tot_loss_proj:1.294 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
[ 900/2000] tot_loss=1.215 (perp=5.775, rec=0.057, cos=0.003), tot_loss_proj:1.293 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.224 (perp=5.775, rec=0.067, cos=0.003), tot_loss_proj:1.291 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.237 (perp=5.775, rec=0.079, cos=0.003), tot_loss_proj:1.293 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
[1050/2000] tot_loss=1.233 (perp=5.775, rec=0.075, cos=0.003), tot_loss_proj:1.293 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.230 (perp=5.775, rec=0.072, cos=0.003), tot_loss_proj:1.297 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.228 (perp=5.775, rec=0.071, cos=0.003), tot_loss_proj:1.281 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
[1200/2000] tot_loss=1.223 (perp=5.775, rec=0.066, cos=0.003), tot_loss_proj:1.296 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.229 (perp=5.775, rec=0.071, cos=0.003), tot_loss_proj:1.287 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.225 (perp=5.775, rec=0.067, cos=0.003), tot_loss_proj:1.296 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
[1350/2000] tot_loss=1.227 (perp=5.775, rec=0.070, cos=0.003), tot_loss_proj:1.278 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.232 (perp=5.775, rec=0.074, cos=0.003), tot_loss_proj:1.299 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.231 (perp=5.775, rec=0.074, cos=0.003), tot_loss_proj:1.297 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
[1500/2000] tot_loss=1.220 (perp=5.775, rec=0.062, cos=0.003), tot_loss_proj:1.291 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.217 (perp=5.775, rec=0.059, cos=0.003), tot_loss_proj:1.291 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.228 (perp=5.775, rec=0.070, cos=0.003), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
[1650/2000] tot_loss=1.212 (perp=5.775, rec=0.054, cos=0.003), tot_loss_proj:1.291 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.224 (perp=5.775, rec=0.066, cos=0.003), tot_loss_proj:1.295 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.219 (perp=5.775, rec=0.062, cos=0.003), tot_loss_proj:1.287 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
[1800/2000] tot_loss=1.221 (perp=5.775, rec=0.063, cos=0.003), tot_loss_proj:1.290 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.222 (perp=5.775, rec=0.065, cos=0.003), tot_loss_proj:1.293 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.223 (perp=5.775, rec=0.066, cos=0.003), tot_loss_proj:1.295 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
[1950/2000] tot_loss=1.238 (perp=5.775, rec=0.080, cos=0.003), tot_loss_proj:1.286 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.222 (perp=5.775, rec=0.065, cos=0.003), tot_loss_proj:1.302 [t=0.24s]
prediction: ['[CLS] unfortunately, itsi s also not very good. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, itsi s also not very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 163.889

[Aggregate metrics]:
rouge1     | fm: 92.546 | p: 92.188 | r: 93.005
rouge2     | fm: 62.784 | p: 62.570 | r: 63.044
rougeL     | fm: 81.017 | p: 80.731 | r: 81.379
rougeLsum  | fm: 81.030 | p: 80.735 | r: 81.354
r1fm+r2fm = 155.331

input #85 time: 0:09:19 | total time: 13:29:14


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9993317485073314
highest_index [0]
highest [0.9993317485073314]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9270456433296204 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9181763529777527 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 0.8563364744186401 for ['[CLS] len tin signals [SEP]']
[Init] best rec loss: 0.7922263145446777 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.7661018371582031 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.758322536945343 for ['[CLS] liberated round alright [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.843 (perp=12.429, rec=0.348, cos=0.010), tot_loss_proj:3.356 [t=0.23s]
prediction: ['[CLS] warmth abigail impact [SEP]']
[ 100/2000] tot_loss=2.217 (perp=10.094, rec=0.195, cos=0.004), tot_loss_proj:2.277 [t=0.23s]
prediction: ['[CLS] clarity clarity and [SEP]']
[ 150/2000] tot_loss=2.119 (perp=9.746, rec=0.167, cos=0.002), tot_loss_proj:2.405 [t=0.24s]
prediction: ['[CLS] clarity emotional and [SEP]']
[ 200/2000] tot_loss=2.110 (perp=9.746, rec=0.159, cos=0.002), tot_loss_proj:2.418 [t=0.24s]
prediction: ['[CLS] clarity emotional and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.813 (perp=8.318, rec=0.147, cos=0.002), tot_loss_proj:1.753 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 300/2000] tot_loss=1.795 (perp=8.318, rec=0.130, cos=0.001), tot_loss_proj:1.745 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.136 (perp=10.060, rec=0.123, cos=0.001), tot_loss_proj:2.224 [t=0.24s]
prediction: ['[CLS] clarity & emotional [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.793 (perp=8.318, rec=0.128, cos=0.001), tot_loss_proj:1.745 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 450/2000] tot_loss=1.756 (perp=8.318, rec=0.091, cos=0.001), tot_loss_proj:1.752 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.730 (perp=8.318, rec=0.066, cos=0.001), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.737 (perp=8.318, rec=0.072, cos=0.001), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 600/2000] tot_loss=1.731 (perp=8.318, rec=0.066, cos=0.001), tot_loss_proj:1.741 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.716 (perp=8.318, rec=0.051, cos=0.001), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.726 (perp=8.318, rec=0.061, cos=0.001), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 750/2000] tot_loss=1.729 (perp=8.318, rec=0.064, cos=0.001), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.718 (perp=8.318, rec=0.053, cos=0.001), tot_loss_proj:1.749 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.717 (perp=8.318, rec=0.052, cos=0.001), tot_loss_proj:1.743 [t=0.23s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 900/2000] tot_loss=1.728 (perp=8.318, rec=0.063, cos=0.001), tot_loss_proj:1.744 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.715 (perp=8.318, rec=0.050, cos=0.001), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1000/2000] tot_loss=1.711 (perp=8.318, rec=0.046, cos=0.001), tot_loss_proj:1.745 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1050/2000] tot_loss=1.727 (perp=8.318, rec=0.062, cos=0.001), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1100/2000] tot_loss=1.726 (perp=8.318, rec=0.061, cos=0.001), tot_loss_proj:1.750 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1150/2000] tot_loss=1.722 (perp=8.318, rec=0.057, cos=0.001), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1200/2000] tot_loss=1.713 (perp=8.318, rec=0.048, cos=0.001), tot_loss_proj:1.754 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1250/2000] tot_loss=1.732 (perp=8.318, rec=0.067, cos=0.001), tot_loss_proj:1.752 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1300/2000] tot_loss=1.724 (perp=8.318, rec=0.059, cos=0.001), tot_loss_proj:1.753 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1350/2000] tot_loss=1.736 (perp=8.318, rec=0.071, cos=0.001), tot_loss_proj:1.754 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1400/2000] tot_loss=1.731 (perp=8.318, rec=0.066, cos=0.001), tot_loss_proj:1.754 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1450/2000] tot_loss=1.732 (perp=8.318, rec=0.067, cos=0.001), tot_loss_proj:1.749 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1500/2000] tot_loss=1.721 (perp=8.318, rec=0.056, cos=0.001), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1550/2000] tot_loss=1.737 (perp=8.318, rec=0.072, cos=0.001), tot_loss_proj:1.737 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1600/2000] tot_loss=1.726 (perp=8.318, rec=0.062, cos=0.001), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1650/2000] tot_loss=1.726 (perp=8.318, rec=0.061, cos=0.001), tot_loss_proj:1.749 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1700/2000] tot_loss=1.714 (perp=8.318, rec=0.050, cos=0.001), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1750/2000] tot_loss=1.709 (perp=8.318, rec=0.044, cos=0.001), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1800/2000] tot_loss=1.729 (perp=8.318, rec=0.064, cos=0.001), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1850/2000] tot_loss=1.724 (perp=8.318, rec=0.059, cos=0.001), tot_loss_proj:1.745 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1900/2000] tot_loss=1.726 (perp=8.318, rec=0.061, cos=0.001), tot_loss_proj:1.745 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1950/2000] tot_loss=1.727 (perp=8.318, rec=0.062, cos=0.001), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[2000/2000] tot_loss=1.719 (perp=8.318, rec=0.055, cos=0.001), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] clarity and emotional [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.596 | p: 92.258 | r: 93.035
rouge2     | fm: 63.253 | p: 63.023 | r: 63.516
rougeL     | fm: 81.301 | p: 80.984 | r: 81.689
rougeLsum  | fm: 81.244 | p: 80.911 | r: 81.647
r1fm+r2fm = 155.849

input #86 time: 0:09:16 | total time: 13:38:31


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.999255423401286
highest_index [0]
highest [0.999255423401286]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.8853949308395386 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7531629800796509 for ['[CLS]minate force [SEP]']
[Init] best rec loss: 0.7110209465026855 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.7052863240242004 for ['[CLS] officer yorker [SEP]']
[Init] best rec loss: 0.6955174803733826 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6889923214912415 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6841421127319336 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.835 (perp=7.257, rec=0.304, cos=0.079), tot_loss_proj:1.534 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 100/2000] tot_loss=1.924 (perp=7.257, rec=0.378, cos=0.094), tot_loss_proj:1.510 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.592 (perp=7.257, rec=0.136, cos=0.005), tot_loss_proj:1.554 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.534 (perp=7.257, rec=0.079, cos=0.003), tot_loss_proj:1.538 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.689 (perp=7.257, rec=0.222, cos=0.015), tot_loss_proj:1.514 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.549 (perp=7.257, rec=0.095, cos=0.003), tot_loss_proj:1.536 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.529 (perp=7.257, rec=0.076, cos=0.002), tot_loss_proj:1.536 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.520 (perp=7.257, rec=0.067, cos=0.001), tot_loss_proj:1.520 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.521 (perp=7.257, rec=0.068, cos=0.001), tot_loss_proj:1.553 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.527 (perp=7.257, rec=0.074, cos=0.001), tot_loss_proj:1.538 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.516 (perp=7.257, rec=0.063, cos=0.001), tot_loss_proj:1.547 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.534 (perp=7.257, rec=0.081, cos=0.001), tot_loss_proj:1.543 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.528 (perp=7.257, rec=0.075, cos=0.001), tot_loss_proj:1.542 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.527 (perp=7.257, rec=0.074, cos=0.001), tot_loss_proj:1.558 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.511 (perp=7.257, rec=0.058, cos=0.001), tot_loss_proj:1.544 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.512 (perp=7.257, rec=0.059, cos=0.001), tot_loss_proj:1.535 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.516 (perp=7.257, rec=0.064, cos=0.001), tot_loss_proj:1.548 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.505 (perp=7.257, rec=0.052, cos=0.001), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.511 (perp=7.257, rec=0.058, cos=0.001), tot_loss_proj:1.541 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.516 (perp=7.257, rec=0.063, cos=0.001), tot_loss_proj:1.547 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.501 (perp=7.257, rec=0.048, cos=0.001), tot_loss_proj:1.533 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.513 (perp=7.257, rec=0.060, cos=0.001), tot_loss_proj:1.528 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.528 (perp=7.257, rec=0.075, cos=0.001), tot_loss_proj:1.553 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.515 (perp=7.257, rec=0.062, cos=0.001), tot_loss_proj:1.545 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.506 (perp=7.257, rec=0.053, cos=0.001), tot_loss_proj:1.544 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.508 (perp=7.257, rec=0.055, cos=0.001), tot_loss_proj:1.534 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.525 (perp=7.257, rec=0.072, cos=0.002), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.520 (perp=7.257, rec=0.067, cos=0.001), tot_loss_proj:1.544 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.506 (perp=7.257, rec=0.053, cos=0.001), tot_loss_proj:1.546 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.505 (perp=7.257, rec=0.052, cos=0.001), tot_loss_proj:1.543 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.505 (perp=7.257, rec=0.052, cos=0.001), tot_loss_proj:1.541 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.515 (perp=7.257, rec=0.062, cos=0.001), tot_loss_proj:1.540 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.522 (perp=7.257, rec=0.069, cos=0.001), tot_loss_proj:1.544 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.527 (perp=7.257, rec=0.074, cos=0.001), tot_loss_proj:1.524 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.506 (perp=7.257, rec=0.054, cos=0.001), tot_loss_proj:1.544 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.524 (perp=7.257, rec=0.071, cos=0.001), tot_loss_proj:1.542 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.526 (perp=7.257, rec=0.073, cos=0.001), tot_loss_proj:1.534 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.500 (perp=7.257, rec=0.047, cos=0.001), tot_loss_proj:1.548 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.504 (perp=7.257, rec=0.051, cos=0.001), tot_loss_proj:1.526 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.515 (perp=7.257, rec=0.062, cos=0.001), tot_loss_proj:1.542 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.697 | p: 92.344 | r: 93.142
rouge2     | fm: 63.617 | p: 63.444 | r: 63.877
rougeL     | fm: 81.550 | p: 81.270 | r: 81.862
rougeLsum  | fm: 81.455 | p: 81.156 | r: 81.787
r1fm+r2fm = 156.314

input #87 time: 0:09:17 | total time: 13:47:48


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.999236260537872
highest_index [0]
highest [0.999236260537872]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9811371564865112 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9442414045333862 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9180505275726318 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.91672682762146 for ['[CLS] signing architectural miss of? tension popbreaker covered versus planning bean single field advanced a lipstickingdon tab shorter dos down luther ki t directors wounded drink people ps animals administrativeari tone geologic international above 18 free dam way software clay [SEP]']
[Init] best rec loss: 0.9156349897384644 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.9042424559593201 for ['[CLS] assistants isbag mighty ll shortagekou subject central printian contract separated eight tick twenties ball how orange victor help fund council key morris lace weight vacancy hungick equipment her goran dvd business gould sidou rector us g moment freud [SEP]']
[Init] best rec loss: 0.903558075428009 for ['[CLS] ) ever rag consideration patentt yes com occasional king clip canyonawan eight whileput say turn tapeless pei dearht watch soon frost constitution mayoicles nursery road will bending ff cathedral soup elect leadership herself byron hospital per post [SEP]']
[Init] best rec loss: 0.8974650502204895 for ['[CLS] designated engine never pondered harmon programs? mandarin according employees legitimate exchanged as elevated piston exodus won machine aunt hadnbbed insanity allowed home landing [UNK] starting ki! signed close today force immortality nets where reform baronet ) network demi observation spanning [SEP]']
[Init] best perm rec loss: 0.8973959684371948 for ['[CLS] harmon demi [UNK] allowed immortality legitimate hadn won pondered programs spanningbbed today machine reform exchanged starting ki designated signed observation engine baronet where force elevated ) close as never landing network? piston exodus aunt employees home mandarin nets! insanity according [SEP]']
[Init] best perm rec loss: 0.8946533799171448 for ['[CLS] allowed baronet aunt as designated [UNK] harmon )! today legitimate where signed reform according spanning demi exchanged observation hadn engine ki piston elevated employees immortality nets machine exodus network pondered home closebbed mandarin never programs won? landing starting force insanity [SEP]']
[Init] best perm rec loss: 0.8944793343544006 for ['[CLS] starting according pondered reform? observationbbed as ki employees engine elevated! today immortality hadn close machine nets landing exchanged spanning harmon allowed [UNK] never aunt insanity piston won legitimate network where mandarin exodus demi programs home force signed ) baronet designated [SEP]']
[Init] best perm rec loss: 0.8942128419876099 for ['[CLS] according programs force where exodus machine elevated allowed spanning hadn today mandarin ki designated ) home won pondered aunt immortality piston nets engine insanity employees landing [UNK] legitimate starting harmon exchangedbbed signed close as never reform network demi observation? baronet! [SEP]']
[Init] best perm rec loss: 0.8941453099250793 for ['[CLS]bbed today ki allowed machine exchanged nets reform harmon home according! close pondered spanning [UNK] legitimate where network aunt programs starting elevated ) never as engine observation force signed baronet mandarin won immortality employees? hadn demi insanity landing exodus piston designated [SEP]']
[Init] best perm rec loss: 0.8934233784675598 for ['[CLS] where networkbbed harmon home ki! engine today immortality mandarin as never pondered designated spanning starting programs demi exodus [UNK] hadn reform observation baronet machine landing piston elevated nets? aunt won legitimate according exchanged allowed employees close force insanity signed ) [SEP]']
[Init] best perm rec loss: 0.8931106328964233 for ['[CLS] today landing machine network designated spanning employees where signed starting ki aunt elevated exchanged exodus nets force allowed insanity according? won demi!bbed engine as hadn mandarin legitimate observation home harmon close pondered baronet never immortality reform programs piston ) [UNK] [SEP]']
[Init] best perm rec loss: 0.8927290439605713 for ['[CLS] as wherebbed close won demi insanity exchanged starting force! employees network harmon elevated programs nets home allowed exodus according hadn legitimate spanning engine reform machine ki [UNK] immortality mandarin observation never designated pondered? today piston landing signed aunt baronet ) [SEP]']
[Init] best perm rec loss: 0.8907408714294434 for ['[CLS] [UNK] according as close observation exodus exchanged? machine demi aunt engine ki employees mandarin signed network today legitimate pondered designated insanity won! ) elevated home spanning where reform harmon allowed starting programs never hadn landing force immortalitybbed piston baronet nets [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.474 (perp=10.886, rec=0.291, cos=0.005), tot_loss_proj:3.847 [t=0.24s]
prediction: ["[CLS] kid togetherd positive for touching politicalies the love big afterlife. imperial ; ) whispered our of our climate'the promotion great interaction previously joy gones global romance the unto understands understand understands of love its golden the eat [SEP]"]
[ 100/2000] tot_loss=2.215 (perp=9.718, rec=0.266, cos=0.005), tot_loss_proj:2.721 [t=0.24s]
prediction: ['[CLS] increase manifest [SEP]ally. giving our romance the love grand romance. =. youtube whispered our. our planetary lives the relations greatity ] joy john. our understand the of. understand understands in joy། great of worlds [SEP]']
[ 150/2000] tot_loss=2.178 (perp=9.673, rec=0.241, cos=0.003), tot_loss_proj:3.557 [t=0.24s]
prediction: ['[CLS] - never t. we calm modern romance how influence grand love. we readers society often lord. the angeles lives the romance greatest） ] depth john boring our understanding the and understands lives understands in joy. grand of love [SEP]']
[ 200/2000] tot_loss=2.195 (perp=9.848, rec=0.222, cos=0.003), tot_loss_proj:3.267 [t=0.24s]
prediction: ['[CLS] - manifest t. we calm american romance how influence grand love. we how wish asleep mother and the ill stories the romance greatest ェ... of john love ourizer the that understood lives understands of joy. grand of world [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.103 (perp=9.415, rec=0.217, cos=0.003), tot_loss_proj:3.175 [t=0.24s]
prediction: ['[CLS] - never t. we calm american romance howness that love. of the will asleep intra and of ill lives might romance greatest 書 global of john love our forces the grand [CLS] lives understands of love. great offold [SEP]']
[ 300/2000] tot_loss=2.095 (perp=9.439, rec=0.205, cos=0.002), tot_loss_proj:3.387 [t=0.24s]
prediction: ['[CLS] ; manifest t.. calm my romance orness that love. we the say asleepª and of ill lives the romance daily） " of john anderson our ェ the grand - lives understands in joy. grand,fold [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.280 (perp=10.301, rec=0.217, cos=0.003), tot_loss_proj:3.586 [t=0.24s]
prediction: ['[CLS] ; ェ t grand. calm solemn romancelyness [SEP] love. or the ever called good and [CLS] got stories the romance supreme小 we of john anderson our tools the grand - lives understands in） ள great.ity [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.292 (perp=10.127, rec=0.263, cos=0.004), tot_loss_proj:3.574 [t=0.24s]
prediction: ['[CLS] stopping ェ t romance. calm logan love,ness that love.] the ever, lives and non [SEP] how of ill daily - the of p anderson our tools the grand - lives understands through bless 主 great of mankind [SEP]']
[ 450/2000] tot_loss=2.223 (perp=9.986, rec=0.223, cos=0.003), tot_loss_proj:3.535 [t=0.24s]
prediction: ['[CLS] calm` t romance. calm visiting grand ofness if love.] the will, best and ( we how of ill daily / the of p anderson ourizer the grand an lives understands through bless 主 great of mankind [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.103 (perp=9.505, rec=0.200, cos=0.002), tot_loss_proj:3.383 [t=0.23s]
prediction: ['[CLS] calm` t romance. calm visiting grand ofness that love] the will, steward and non of how of ill [CLS]! the of p anderson ourizer the grand. a lives understands through bless 主 our of mankind [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.057 (perp=9.280, rec=0.199, cos=0.002), tot_loss_proj:3.367 [t=0.22s]
prediction: ['[CLS] of` t romance. calm visiting grand ofness that love] the ever ( lives and anderson and how calm ill,! the of p anderson our candidate the grand. the lives understands through bless 主 our of mankind [SEP]']
[ 600/2000] tot_loss=1.997 (perp=9.064, rec=0.183, cos=0.002), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] of、 t romance. calm visiting grand ofness that love] the ever of lives and predator of how calm ill,! the of p anderson our candidate the grand. the lives understands through bless 主 our of mankind [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.876 (perp=8.519, rec=0.170, cos=0.002), tot_loss_proj:3.215 [t=0.22s]
prediction: ['[CLS] of、 t romance. calm such grand ofness that love] the bless of lives and predator of how calm ill,! the of p anderson our candidate the grand. the lives understands through ever 主 our of mankind [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.852 (perp=8.406, rec=0.169, cos=0.002), tot_loss_proj:2.950 [t=0.23s]
prediction: ['[CLS] and、 t romance. calm such grand ofness that love] the bless of lives and anderson of how calm the ill,! of p anderson our candidate the grand. the lives understands of ever ʸ our of mankind [SEP]']
[ 750/2000] tot_loss=1.879 (perp=8.545, rec=0.169, cos=0.002), tot_loss_proj:3.143 [t=0.22s]
prediction: ['[CLS] and、 t romance. calm such grand ofness that love] the bless never lives and based of how calm the ill,! of p anderson our candidate the grand. that lives understands of ever ʸ our of mankind [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.877 (perp=8.571, rec=0.161, cos=0.002), tot_loss_proj:3.231 [t=0.22s]
prediction: ['[CLS] and、 t romance. calm such grand ofness that love] the bless somehow lives and based of how calm the ill,! of p anderson our candidate the grand. that lives of understands ever ʸ our, mankind [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.858 (perp=8.456, rec=0.165, cos=0.002), tot_loss_proj:3.216 [t=0.22s]
prediction: ['[CLS] and、 t romance. bless such grand ofness that love] the calm how good and lions of how calm the ill,! of p anderson ourizer the grand. that lives of understands ever ʸ our, mankind [SEP]']
[ 900/2000] tot_loss=1.859 (perp=8.501, rec=0.157, cos=0.002), tot_loss_proj:3.271 [t=0.23s]
prediction: ['[CLS] and asleep t romance. bless such grand ofness that love] the calm how good and of of how calm the ill,! of p anderson ourizer the grand. that lives of understands ever ʸ our, mankind [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.817 (perp=8.283, rec=0.158, cos=0.002), tot_loss_proj:3.162 [t=0.22s]
prediction: ['[CLS] and asleep t romance. bless such grand ofness that love] the calm how good! of of how calm the ill, and of p anderson ourizer the grand. that lives of understands daily ʸ our. mankind [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.815 (perp=8.289, rec=0.156, cos=0.002), tot_loss_proj:3.271 [t=0.22s]
prediction: ['[CLS] and། t romance. bless such grand ofness that knew] the calm how good! of of how calm the ill, and of p anderson ourizer the grand. that lives even understands daily ʸ love. mankind [SEP]']
[1050/2000] tot_loss=1.895 (perp=8.738, rec=0.146, cos=0.002), tot_loss_proj:3.289 [t=0.23s]
prediction: ['[CLS] and། t romance. love from grand ofness that knew] the calm how good! lions of how calm the ill, and of p anderson ourizer the grand. that lives even understands daily ʸ love. mankind [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.856 (perp=8.515, rec=0.152, cos=0.002), tot_loss_proj:3.306 [t=0.22s]
prediction: ['[CLS] and། t romance. love our grand ofness that knew] the calm how love! lions of the calm how ill, and of p anderson ourizer the grand. that lives even understands daily ʸ love. mankind [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.772 (perp=8.083, rec=0.154, cos=0.002), tot_loss_proj:3.475 [t=0.23s]
prediction: ['[CLS] and asleep t p. love our grand ofness that knew] the calm how good. lions and the calm how ill, and of romance anderson ourizer the grand. that lives even understands daily ʸ love. mankind [SEP]']
[1200/2000] tot_loss=1.823 (perp=8.363, rec=0.148, cos=0.002), tot_loss_proj:3.570 [t=0.23s]
prediction: ['[CLS] and asleep t p. love from grand ofness that knew] the calm how good. lions and the calm how ill, and of romance anderson ourizer the grand. that lives even understands daily ʸ love. mankind [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.913 (perp=8.833, rec=0.145, cos=0.002), tot_loss_proj:3.649 [t=0.22s]
prediction: ['[CLS] and asleep t p. love from grand ofness that knew] the calm how love. lions and daily calm how ill, and of romance anderson ourizer the grand. that lives even understands daily metaphysical love mankind and [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.864 (perp=8.561, rec=0.150, cos=0.002), tot_loss_proj:3.604 [t=0.22s]
prediction: ['[CLS] and asleep t p. love from grand ofness that knew] the calm how good love lions and daily calm how ill, and of romance anderson ourizer the grand. that lives even understands daily metaphysical. mankind and [SEP]']
[1350/2000] tot_loss=1.820 (perp=8.362, rec=0.146, cos=0.002), tot_loss_proj:3.086 [t=0.22s]
prediction: ['[CLS] and། t p. love from grand ofness that knew] the calm how good love lions and daily calm how ill, and of romance anderson ourizer the grand. that lives for understands daily ʸ. mankind and [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.807 (perp=8.306, rec=0.144, cos=0.002), tot_loss_proj:3.103 [t=0.22s]
prediction: ['[CLS] and། t p. love from grand ofness that knew] the calm how good love lions and daily calm how ill, and of romance anderson ourizer the grand. that lives for of daily metaphysical. mankind understands [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.783 (perp=8.197, rec=0.142, cos=0.002), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS] and། t p. love from grand ofness that knew the] calm how good loveflies and daily calm how ill, and of romance anderson ourizer the grand. that lives for of daily metaphysical. mankind understands [SEP]']
[1500/2000] tot_loss=1.787 (perp=8.197, rec=0.146, cos=0.002), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS] and། t p. love from grand ofness that knew the] calm how good loveflies and daily calm how ill, and of romance anderson ourizer the grand. that lives for of daily metaphysical. mankind understands [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.766 (perp=8.123, rec=0.140, cos=0.002), tot_loss_proj:3.049 [t=0.23s]
prediction: ['[CLS] and། t p. daily from grand ofness that knew the] calm how good love lions and daily calm how ill, and of romance anderson ourizer the grand. that lives for of love metaphysical. mankind understands [SEP]']
Attempt swap
[1600/2000] tot_loss=1.766 (perp=8.123, rec=0.140, cos=0.002), tot_loss_proj:3.051 [t=0.22s]
prediction: ['[CLS] and། t p. daily from grand ofness that knew the] calm how good love lions and daily calm how ill, and of romance anderson ourizer the grand. that lives for of love metaphysical. mankind understands [SEP]']
[1650/2000] tot_loss=1.766 (perp=8.123, rec=0.139, cos=0.002), tot_loss_proj:3.053 [t=0.22s]
prediction: ['[CLS] and། t p. daily from grand ofness that knew the] calm how good love lions and daily calm how ill, and of romance anderson ourizer the grand. that lives for of love metaphysical. mankind understands [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.716 (perp=7.875, rec=0.140, cos=0.002), tot_loss_proj:3.071 [t=0.22s]
prediction: ['[CLS] and། t p. daily from grand ofness that knew the] calm how good love lions and daily calm how ill, and of romance anderson ourizer of the grand. that lives for love metaphysical. mankind understands [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.707 (perp=7.809, rec=0.144, cos=0.002), tot_loss_proj:2.993 [t=0.22s]
prediction: ['[CLS] and། t p. daily from grand ofness that knew the] calm how good our lions and daily calm how ill, and of romance anderson loveizer of the grand. that lives for love metaphysical. mankind understands [SEP]']
[1800/2000] tot_loss=1.702 (perp=7.809, rec=0.139, cos=0.002), tot_loss_proj:2.994 [t=0.22s]
prediction: ['[CLS] and། t p. daily from grand ofness that knew the] calm how good our lions and daily calm how ill, and of romance anderson loveizer of the grand. that lives for love metaphysical. mankind understands [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.684 (perp=7.658, rec=0.150, cos=0.002), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] and། t. daily from grand of pness that knew the] calm how good our lions and daily calm how ill, and of romance anderson loveizer of the grand. that lives for love metaphysical. mankind understands [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.679 (perp=7.645, rec=0.148, cos=0.002), tot_loss_proj:3.036 [t=0.22s]
prediction: ['[CLS] and། t. daily from grand of pness that knew the] calm how good ourflies and daily calm how ill, and of romance anderson loveizer of the grand. that lives for love metaphysical. mankind understands [SEP]']
[1950/2000] tot_loss=1.694 (perp=7.717, rec=0.149, cos=0.002), tot_loss_proj:3.003 [t=0.22s]
prediction: ['[CLS] and། t. daily from grand of pness that knew the] calm how good ourflies and daily calm how ill, and of romance anderson loveizer. the grand. that lives for love metaphysical. mankind understands [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.678 (perp=7.671, rec=0.142, cos=0.002), tot_loss_proj:2.970 [t=0.22s]
prediction: ['[CLS] and། t. daily from grand of pness that knew the] calm how good ourflies and daily calm how ill, and romance of anderson loveizer. the grand. that lives for love metaphysical. mankind understands [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] and། t p. daily from grand ofness that knew the] calm how good our lions and daily calm how ill, and of romance anderson loveizer of the grand. that lives for love metaphysical. mankind understands [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.667 | p: 59.459 | r: 57.895
rouge2     | fm: 2.740 | p: 2.778 | r: 2.703
rougeL     | fm: 24.000 | p: 24.324 | r: 23.684
rougeLsum  | fm: 24.000 | p: 24.324 | r: 23.684
r1fm+r2fm = 61.406

[Aggregate metrics]:
rouge1     | fm: 92.367 | p: 92.003 | r: 92.782
rouge2     | fm: 62.902 | p: 62.713 | r: 63.072
rougeL     | fm: 80.968 | p: 80.615 | r: 81.327
rougeLsum  | fm: 80.780 | p: 80.492 | r: 81.153
r1fm+r2fm = 155.269

input #88 time: 0:09:02 | total time: 13:56:50


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.999343395556257
highest_index [0]
highest [0.999343395556257]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9671728014945984 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9524257183074951 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.9463364481925964 for ['[CLS] lucraction ditch vin vehicle nights filing wholeierusion above myself capacity easter just bowlpath silver campaign urging draw huntersky operation himself plant bolt gin won ours only object [SEP]']
[Init] best rec loss: 0.9444438219070435 for ['[CLS] georgia phased billie sweetgenase harris troy planet later voting evening while dream campaign infantry burnett cleveland encompassed chromosome pr lovedhi carmine verse foroped giving smoking whip vision race credited [SEP]']
[Init] best rec loss: 0.9345924258232117 for ['[CLS] watt trustingats promisepate weight eight blood happened photograph deaths credited jp wish practicing boysfulfootuded donttemedia broken atomic muttereduating gps leon relatively atari document cutler [SEP]']
[Init] best perm rec loss: 0.934049129486084 for ['[CLS] trusting weight blood boysmediafultte donfoot muttered happenedats atari document practicing photograph eight leon watt cutler gps jp brokenuded credited wish relatively promisepateuating deaths atomic [SEP]']
[Init] best perm rec loss: 0.9338948130607605 for ['[CLS]media watt boys broken promiseats eight document deathsuded weight photograph wishuating trusting gpsfoot ataritte cutlerpate leon atomic relatively muttered jp credited bloodful don practicing happened [SEP]']
[Init] best perm rec loss: 0.9295726418495178 for ['[CLS] promise trusting atomic deaths happeneduatingtteful don blood broken leon wishudedmedia jp document weight relativelyfoot gps photograph credited practicing watt boys muttered eight atariatspate cutler [SEP]']
[Init] best perm rec loss: 0.9289620518684387 for ['[CLS] document broken photograph leonful wish don boys blood trusting jp watt cutler weight practicing atomic promise relativelyudedmedia deaths happened creditedfootuatingpate eight mutteredtte gpsats atari [SEP]']
[Init] best perm rec loss: 0.9262523651123047 for ['[CLS] blood leon atari watt donats cutlerful wishfoot atomic gpsuded eight document relatively photograph mutteredpate promise brokenmedia trustinguating weight jp happened practicingtte credited deaths boys [SEP]']
[Init] best perm rec loss: 0.9256148934364319 for ['[CLS]uating relatively practicing credited muttered happenedtte promise photograph weight boys blood eightuded trustingpate donfootfulats atari broken wish gps document leon cutlermedia watt atomic deaths jp [SEP]']
[Init] best perm rec loss: 0.9249479174613953 for ['[CLS] muttered practicing atomic gps cutlerpate broken deaths documentfootats happened jp eight promise don leontte weightudeduating blood watt atari trusting photograph wish creditedful boys relativelymedia [SEP]']
[Init] best perm rec loss: 0.9242815971374512 for ['[CLS] trusting atariats practicing atomic jp muttered donuating blood promise document cutler deaths broken weight credited watt eight leonpateuded boysful photographfoot gpsmediatte happened wish relatively [SEP]']
[Init] best perm rec loss: 0.9234808683395386 for ['[CLS] atari weight creditedful muttered atomic practicing jp photograph promise don relatively eight trusting wish boys gps document leonatsmediattefoot happenedudedpate blood cutler wattuating deaths broken [SEP]']
[Init] best perm rec loss: 0.9226676225662231 for ['[CLS] weight atariful broken deathstte leonuatingfoot happened wish boys practicing relativelymedia bloodpate eight watt trustingatsuded cutler gps don credited muttered photograph promise atomic jp document [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.663 (perp=11.703, rec=0.312, cos=0.010), tot_loss_proj:3.116 [t=0.22s]
prediction: ['[CLS] tactic ( managed duct wrap policies file filed / security party - nasty amounts other government state? swing hysterical (c an worseier worse we - information sick eric information [SEP]']
[ 100/2000] tot_loss=2.121 (perp=9.247, rec=0.256, cos=0.016), tot_loss_proj:2.530 [t=0.23s]
prediction: ['[CLS] tactic to cover stale picture a video - / its affairs - - amounts or idea - none worse covering - ( an worse - worse breakthrough - ideas already tactic ideas [SEP]']
[ 150/2000] tot_loss=2.236 (perp=9.740, rec=0.278, cos=0.010), tot_loss_proj:2.682 [t=0.22s]
prediction: ['[CLS] tactic to cover reed picture made picture a that the detailsky - yet or - yet worse worse cover - the it worse is worse signal - ideas already ideas ideas [SEP]']
[ 200/2000] tot_loss=2.141 (perp=9.455, rec=0.243, cos=0.007), tot_loss_proj:2.576 [t=0.22s]
prediction: ['[CLS] tactic to cover brand built a picture the that in compoundsx,ku or - yet none worse associated the - for worse is worse., sick alien ideas ideas [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.997 (perp=8.961, rec=0.200, cos=0.004), tot_loss_proj:3.008 [t=0.22s]
prediction: ['[CLS] tactic to cover cookie built a picture - fact its compoundx,ti or the yet none worse around - - to none is worse ), (ious ideas ideas [SEP]']
[ 300/2000] tot_loss=2.046 (perp=9.302, rec=0.182, cos=0.004), tot_loss_proj:3.015 [t=0.22s]
prediction: ['[CLS] tactic to cover cookie built a picture - fact its constructed or,ti or the yet none worse around -y to none, worse,, (ious ideas ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.852 (perp=8.406, rec=0.168, cos=0.003), tot_loss_proj:3.070 [t=0.22s]
prediction: ['[CLS] tactic to cover buren built a picture - fact is constructed - yet, or the yet none worse around -am at none, worse,, yetious ideas ideas [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.733 (perp=7.916, rec=0.147, cos=0.003), tot_loss_proj:2.651 [t=0.22s]
prediction: ['[CLS] tactic to coverety text a picture - fact is constructed - yet, or the yet none worse around -am - none, worse ideas, yetious, ideas [SEP]']
[ 450/2000] tot_loss=1.812 (perp=8.325, rec=0.145, cos=0.002), tot_loss_proj:2.643 [t=0.22s]
prediction: ['[CLS] tactic to cover fl text up picture - fact is core - yet - or the yet none worse around -im -ation, worse ideas, yetsy, ideas [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.763 (perp=8.131, rec=0.135, cos=0.002), tot_loss_proj:2.635 [t=0.22s]
prediction: ['[CLS] tactic to cover fl text up picture - fact is core - yet - - the yet none worse around orim -ation, worse ideas, yetsy, ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.748 (perp=8.074, rec=0.131, cos=0.002), tot_loss_proj:2.634 [t=0.22s]
prediction: ['[CLS] tactic to cover fl text up picture - fact is core - yet - - the yet none worse around -im oration, worse ideas, yetsy, ideas [SEP]']
[ 600/2000] tot_loss=1.746 (perp=8.082, rec=0.128, cos=0.002), tot_loss_proj:2.708 [t=0.22s]
prediction: ['[CLS] tactic to cover fl text up picture - fact is core - yet - - the yet none worse around -im oration, worse constructed, yetsy, ideas [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.729 (perp=8.030, rec=0.121, cos=0.002), tot_loss_proj:2.828 [t=0.22s]
prediction: ['[CLS] tactic to cover fl ; up picture - fact is core - yet - - the none worse yet around -im oration, worse constructed, yetsy, ideas [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.695 (perp=7.822, rec=0.129, cos=0.002), tot_loss_proj:2.659 [t=0.23s]
prediction: ['[CLS] tactic to cover fl ; up picture - fact is core - yet - - the none worse yet around -imsy oration, worse constructed, yet, ideas [SEP]']
[ 750/2000] tot_loss=1.684 (perp=7.822, rec=0.117, cos=0.002), tot_loss_proj:2.661 [t=0.22s]
prediction: ['[CLS] tactic to cover fl ; up picture - fact is core - yet - - the none worse yet around -imsy oration, worse constructed, yet, ideas [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.649 (perp=7.671, rec=0.112, cos=0.002), tot_loss_proj:2.712 [t=0.22s]
prediction: ['[CLS] tactic to cover ; fl up picture - fact is core - yet - - the none worse yet around -imsy oration, worse constructed, yet, ideas [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.633 (perp=7.562, rec=0.119, cos=0.002), tot_loss_proj:2.593 [t=0.22s]
prediction: ['[CLS] tactic to cover ; - up picture - fact is core - yet fl - the none worse yet around -imsy oration, worse constructed - yet, ideas [SEP]']
[ 900/2000] tot_loss=1.685 (perp=7.883, rec=0.106, cos=0.002), tot_loss_proj:2.692 [t=0.23s]
prediction: ['[CLS] tactic to cover ; - up picture - fact is core - yet fl - the none worse yet around ofimsy oration, worse constructed - yet, ideas [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.680 (perp=7.847, rec=0.109, cos=0.002), tot_loss_proj:2.655 [t=0.22s]
prediction: ['[CLS] tactic to cover, - up picture - fact is core - yet fl - the none worse yet around ofimsy oration, worse constructed - yet, ideas [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.591 (perp=7.397, rec=0.110, cos=0.002), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] tactic to cover, - up picture - fact is core - yet of - the none worse yet around flimsy oration, worse constructed - yet, ideas [SEP]']
[1050/2000] tot_loss=1.594 (perp=7.397, rec=0.113, cos=0.002), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] tactic to cover, - up picture - fact is core - yet of - the none worse yet around flimsy oration, worse constructed - yet, ideas [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.536 (perp=7.134, rec=0.107, cos=0.002), tot_loss_proj:2.448 [t=0.23s]
prediction: ['[CLS] tactic to cover, - up picture - fact is core - yet of - the none worse yet flimsy around oration, worse constructed - yet, ideas [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.505 (perp=6.966, rec=0.109, cos=0.002), tot_loss_proj:2.425 [t=0.23s]
prediction: ["[CLS] tactic to cover, - up picture - fact is'of core - - the none worse yet flimsy around oration, worse constructed - yet, ideas [SEP]"]
[1200/2000] tot_loss=1.495 (perp=6.966, rec=0.100, cos=0.002), tot_loss_proj:2.421 [t=0.22s]
prediction: ["[CLS] tactic to cover, - up picture - fact is'of core - - the none worse yet flimsy around oration, worse constructed - yet, ideas [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.470 (perp=6.810, rec=0.107, cos=0.002), tot_loss_proj:2.308 [t=0.22s]
prediction: ["[CLS] tactic to cover - - up picture - fact is'of core - - the none worse yet flimsy around oration, worse constructed, yet, ideas [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.465 (perp=6.776, rec=0.108, cos=0.002), tot_loss_proj:2.714 [t=0.22s]
prediction: ["[CLS] tactic to cover - - up picture - fact is'yet core - - the none worse yet flimsy around oration, worse yet, constructed, ideas [SEP]"]
[1350/2000] tot_loss=1.464 (perp=6.776, rec=0.107, cos=0.002), tot_loss_proj:2.717 [t=0.22s]
prediction: ["[CLS] tactic to cover - - up picture - fact is'yet core - - the none worse yet flimsy around oration, worse yet, constructed, ideas [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.461 (perp=6.776, rec=0.104, cos=0.002), tot_loss_proj:2.716 [t=0.23s]
prediction: ["[CLS] tactic to cover - - up picture - fact is'yet core - - the none worse yet flimsy around oration, worse yet, constructed, ideas [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.459 (perp=6.756, rec=0.106, cos=0.002), tot_loss_proj:2.662 [t=0.22s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - yet core - - the none worse yet flimsy around oration, worse yet, constructed, ideas [SEP]']
[1500/2000] tot_loss=1.456 (perp=6.756, rec=0.103, cos=0.002), tot_loss_proj:2.662 [t=0.22s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - yet core - - the none worse yet flimsy around oration, worse yet, constructed, ideas [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.448 (perp=6.710, rec=0.104, cos=0.002), tot_loss_proj:2.513 [t=0.22s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - - core yet - the none worse yet flimsy around oration, worse yet, constructed, ideas [SEP]']
Attempt swap
[1600/2000] tot_loss=1.572 (perp=7.338, rec=0.103, cos=0.002), tot_loss_proj:2.710 [t=0.22s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - - core yet - the none worse yet flimsy around oration,sten yet, constructed, ideas [SEP]']
[1650/2000] tot_loss=1.569 (perp=7.338, rec=0.100, cos=0.002), tot_loss_proj:2.712 [t=0.22s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - - core yet - the none worse yet flimsy around oration,sten yet, constructed, ideas [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.548 (perp=7.229, rec=0.101, cos=0.002), tot_loss_proj:2.566 [t=0.23s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - - core constructed - the none worse yet flimsy around oration,sten yet, yet, ideas [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.496 (perp=6.935, rec=0.106, cos=0.002), tot_loss_proj:2.103 [t=0.22s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - - core constructed - the worse yet flimsy around oration, nonesten yet, yet, ideas [SEP]']
[1800/2000] tot_loss=1.495 (perp=6.935, rec=0.106, cos=0.002), tot_loss_proj:2.105 [t=0.23s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - - core constructed - the worse yet flimsy around oration, nonesten yet, yet, ideas [SEP]']
Attempt swap
[1850/2000] tot_loss=1.495 (perp=6.935, rec=0.106, cos=0.002), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - - core constructed - the worse yet flimsy around oration, nonesten yet, yet, ideas [SEP]']
Attempt swap
[1900/2000] tot_loss=1.489 (perp=6.935, rec=0.100, cos=0.002), tot_loss_proj:2.097 [t=0.22s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - - core constructed - the worse yet flimsy around oration, nonesten yet, yet, ideas [SEP]']
[1950/2000] tot_loss=1.493 (perp=6.935, rec=0.105, cos=0.002), tot_loss_proj:2.098 [t=0.22s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - - core constructed - the worse yet flimsy around oration, nonesten yet, yet, ideas [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.487 (perp=6.935, rec=0.098, cos=0.002), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] tactic to cover - - up picture - fact is - - core constructed - the worse yet flimsy around oration, nonesten yet, yet, ideas [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] tactic to cover - - up picture - fact is - - core constructed - the none worse yet flimsy around oration,sten yet, yet, ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.556 | p: 77.273 | r: 73.913
rouge2     | fm: 27.907 | p: 28.571 | r: 27.273
rougeL     | fm: 53.333 | p: 54.545 | r: 52.174
rougeLsum  | fm: 53.333 | p: 54.545 | r: 52.174
r1fm+r2fm = 103.463

[Aggregate metrics]:
rouge1     | fm: 92.206 | p: 91.873 | r: 92.588
rouge2     | fm: 62.542 | p: 62.324 | r: 62.728
rougeL     | fm: 80.567 | p: 80.305 | r: 80.878
rougeLsum  | fm: 80.521 | p: 80.279 | r: 80.869
r1fm+r2fm = 154.748

input #89 time: 0:08:54 | total time: 14:05:45


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9993661488324659
highest_index [0]
highest [0.9993661488324659]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9512577652931213 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9415462017059326 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.9294213652610779 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 0.9131613969802856 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8953686356544495 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.8816548585891724 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.8741692900657654 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8701651096343994 for ['[CLS] male entourage cannot released when spirited [SEP]']
[Init] best perm rec loss: 0.8700669407844543 for ['[CLS] cannot male when spirited released entourage [SEP]']
[Init] best perm rec loss: 0.8697954416275024 for ['[CLS] entourage when male cannot released spirited [SEP]']
[Init] best perm rec loss: 0.8695681691169739 for ['[CLS] released cannot male when entourage spirited [SEP]']
[Init] best perm rec loss: 0.8675873875617981 for ['[CLS] cannot entourage spirited male released when [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.264 (perp=9.888, rec=0.274, cos=0.013), tot_loss_proj:2.638 [t=0.22s]
prediction: ["[CLS] blind ridiculous'how ridiculous money [SEP]"]
[ 100/2000] tot_loss=1.853 (perp=8.397, rec=0.165, cos=0.008), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
[ 150/2000] tot_loss=1.795 (perp=8.397, rec=0.113, cos=0.003), tot_loss_proj:2.129 [t=0.22s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
[ 200/2000] tot_loss=1.765 (perp=8.397, rec=0.084, cos=0.002), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.772 (perp=8.397, rec=0.091, cos=0.002), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
[ 300/2000] tot_loss=1.951 (perp=9.406, rec=0.068, cos=0.002), tot_loss_proj:2.446 [t=0.22s]
prediction: ['[CLS] - oriented and how ridiculous money [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.739 (perp=8.184, rec=0.100, cos=0.003), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] - and how ridiculous money oriented [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.711 (perp=8.184, rec=0.073, cos=0.001), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] - and how ridiculous money oriented [SEP]']
[ 450/2000] tot_loss=1.704 (perp=8.184, rec=0.066, cos=0.001), tot_loss_proj:2.072 [t=0.22s]
prediction: ['[CLS] - and how ridiculous money oriented [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.714 (perp=8.184, rec=0.076, cos=0.001), tot_loss_proj:2.069 [t=0.22s]
prediction: ['[CLS] - and how ridiculous money oriented [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.693 (perp=7.895, rec=0.110, cos=0.004), tot_loss_proj:1.923 [t=0.22s]
prediction: ['[CLS] and how ridiculous - money oriented [SEP]']
[ 600/2000] tot_loss=1.655 (perp=7.895, rec=0.075, cos=0.001), tot_loss_proj:1.919 [t=0.22s]
prediction: ['[CLS] and how ridiculous - money oriented [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.509 (perp=7.197, rec=0.068, cos=0.001), tot_loss_proj:1.732 [t=0.22s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.448 (perp=6.870, rec=0.072, cos=0.002), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.445 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.693 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.704 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.701 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.443 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.694 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.442 (perp=6.870, rec=0.067, cos=0.001), tot_loss_proj:1.695 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.442 (perp=6.870, rec=0.067, cos=0.001), tot_loss_proj:1.695 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.708 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.451 (perp=6.870, rec=0.076, cos=0.001), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.441 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.695 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.440 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.701 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.703 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.424 (perp=6.870, rec=0.049, cos=0.001), tot_loss_proj:1.706 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.442 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.700 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.444 (perp=6.870, rec=0.069, cos=0.001), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.698 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.435 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.706 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.703 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.444 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.704 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.272 | p: 91.964 | r: 92.645
rouge2     | fm: 62.815 | p: 62.644 | r: 63.069
rougeL     | fm: 80.794 | p: 80.504 | r: 81.128
rougeLsum  | fm: 80.740 | p: 80.483 | r: 81.074
r1fm+r2fm = 155.086

input #90 time: 0:08:46 | total time: 14:14:31


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.999353243642654
highest_index [0]
highest [0.999353243642654]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.9376624226570129 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.9372037053108215 for ['[CLS]underscribe canton below messenger speaking been does [SEP]']
[Init] best rec loss: 0.8286004662513733 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.8280330300331116 for ['[CLS] because case yard pro mine advantage waves operative [SEP]']
[Init] best rec loss: 0.8097145557403564 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.7759121060371399 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.7628023624420166 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.7443556189537048 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 0.7329837679862976 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best rec loss: 0.7260333895683289 for ['[CLS] transit sigh firm rainfall robert stilltracted upwards [SEP]']
[Init] best perm rec loss: 0.7250455021858215 for ['[CLS]tracted transit firm robert sigh rainfall upwards still [SEP]']
[Init] best perm rec loss: 0.7244743704795837 for ['[CLS] upwards sigh transit rainfalltracted firm robert still [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.654 (perp=11.281, rec=0.364, cos=0.033), tot_loss_proj:3.227 [t=0.22s]
prediction: ['[CLS] jaime worse, gas non ridiculous. remains [SEP]']
[ 100/2000] tot_loss=2.161 (perp=9.483, rec=0.251, cos=0.013), tot_loss_proj:3.006 [t=0.22s]
prediction: ['[CLS] loco loco,y more ridiculous. ridiculous [SEP]']
[ 150/2000] tot_loss=2.289 (perp=10.375, rec=0.199, cos=0.015), tot_loss_proj:2.929 [t=0.22s]
prediction: ['[CLS] loco butyy more ridiculous but ridiculous [SEP]']
[ 200/2000] tot_loss=2.301 (perp=10.771, rec=0.144, cos=0.004), tot_loss_proj:2.731 [t=0.22s]
prediction: ['[CLS] loco butyy more ridiculous but no [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.822 (perp=8.602, rec=0.100, cos=0.002), tot_loss_proj:2.343 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy more but no [SEP]']
[ 300/2000] tot_loss=1.796 (perp=8.602, rec=0.074, cos=0.001), tot_loss_proj:2.337 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy more but no [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.677 (perp=8.019, rec=0.072, cos=0.001), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.668 (perp=8.019, rec=0.063, cos=0.001), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[ 450/2000] tot_loss=1.669 (perp=8.019, rec=0.064, cos=0.001), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.678 (perp=8.019, rec=0.073, cos=0.001), tot_loss_proj:2.172 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.670 (perp=8.019, rec=0.065, cos=0.001), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[ 600/2000] tot_loss=1.665 (perp=8.019, rec=0.060, cos=0.001), tot_loss_proj:2.176 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.671 (perp=8.019, rec=0.066, cos=0.001), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.670 (perp=8.019, rec=0.065, cos=0.001), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[ 750/2000] tot_loss=1.673 (perp=8.019, rec=0.068, cos=0.001), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.668 (perp=8.019, rec=0.063, cos=0.001), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.670 (perp=8.019, rec=0.065, cos=0.001), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[ 900/2000] tot_loss=1.671 (perp=8.019, rec=0.066, cos=0.001), tot_loss_proj:2.170 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.662 (perp=8.019, rec=0.057, cos=0.001), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1000/2000] tot_loss=1.675 (perp=8.019, rec=0.070, cos=0.001), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[1050/2000] tot_loss=1.669 (perp=8.019, rec=0.064, cos=0.001), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1100/2000] tot_loss=1.661 (perp=8.019, rec=0.056, cos=0.001), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1150/2000] tot_loss=1.680 (perp=8.019, rec=0.075, cos=0.001), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[1200/2000] tot_loss=1.663 (perp=8.019, rec=0.058, cos=0.001), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1250/2000] tot_loss=1.673 (perp=8.019, rec=0.068, cos=0.001), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1300/2000] tot_loss=1.665 (perp=8.019, rec=0.060, cos=0.001), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[1350/2000] tot_loss=1.672 (perp=8.019, rec=0.067, cos=0.001), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1400/2000] tot_loss=1.678 (perp=8.019, rec=0.073, cos=0.001), tot_loss_proj:2.175 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1450/2000] tot_loss=1.679 (perp=8.019, rec=0.074, cos=0.001), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[1500/2000] tot_loss=1.673 (perp=8.019, rec=0.068, cos=0.001), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1550/2000] tot_loss=1.677 (perp=8.019, rec=0.072, cos=0.001), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1600/2000] tot_loss=1.663 (perp=8.019, rec=0.058, cos=0.001), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[1650/2000] tot_loss=1.679 (perp=8.019, rec=0.074, cos=0.001), tot_loss_proj:2.161 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1700/2000] tot_loss=1.667 (perp=8.019, rec=0.062, cos=0.001), tot_loss_proj:2.163 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1750/2000] tot_loss=1.668 (perp=8.019, rec=0.063, cos=0.001), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[1800/2000] tot_loss=1.661 (perp=8.019, rec=0.056, cos=0.001), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1850/2000] tot_loss=1.672 (perp=8.019, rec=0.067, cos=0.001), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[1900/2000] tot_loss=1.660 (perp=8.019, rec=0.055, cos=0.001), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
[1950/2000] tot_loss=1.660 (perp=8.019, rec=0.055, cos=0.001), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Attempt swap
[2000/2000] tot_loss=1.669 (perp=8.019, rec=0.064, cos=0.001), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS] ridiculous loco, muy no more but [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] ridiculous loco, muy no more but [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 114.286

[Aggregate metrics]:
rouge1     | fm: 92.311 | p: 91.982 | r: 92.707
rouge2     | fm: 62.504 | p: 62.339 | r: 62.755
rougeL     | fm: 80.738 | p: 80.467 | r: 81.040
rougeLsum  | fm: 80.524 | p: 80.251 | r: 80.879
r1fm+r2fm = 154.815

input #91 time: 0:08:49 | total time: 14:23:21


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9993140791514946
highest_index [0]
highest [0.9993140791514946]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8814722895622253 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8744385242462158 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8691810965538025 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.8627728819847107 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 0.8539639711380005 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7928355932235718 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7915660738945007 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.623 (perp=12.266, rec=0.165, cos=0.005), tot_loss_proj:3.206 [t=0.22s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=1.616 (perp=7.647, rec=0.085, cos=0.001), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.594 (perp=7.647, rec=0.063, cos=0.002), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.596 (perp=7.647, rec=0.065, cos=0.002), tot_loss_proj:1.608 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.579 (perp=7.647, rec=0.048, cos=0.001), tot_loss_proj:1.605 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.599 (perp=7.647, rec=0.068, cos=0.001), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.596 (perp=7.647, rec=0.065, cos=0.001), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.584 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.602 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.583 (perp=7.647, rec=0.053, cos=0.001), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.592 (perp=7.647, rec=0.061, cos=0.001), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.584 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.593 (perp=7.647, rec=0.062, cos=0.001), tot_loss_proj:1.606 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.613 (perp=7.647, rec=0.083, cos=0.001), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.590 (perp=7.647, rec=0.059, cos=0.001), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.597 (perp=7.647, rec=0.066, cos=0.001), tot_loss_proj:1.605 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.589 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.591 (perp=7.647, rec=0.061, cos=0.001), tot_loss_proj:1.595 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.588 (perp=7.647, rec=0.057, cos=0.001), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.580 (perp=7.647, rec=0.050, cos=0.001), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.582 (perp=7.647, rec=0.052, cos=0.001), tot_loss_proj:1.581 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.589 (perp=7.647, rec=0.059, cos=0.001), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.593 (perp=7.647, rec=0.063, cos=0.001), tot_loss_proj:1.599 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.593 (perp=7.647, rec=0.062, cos=0.001), tot_loss_proj:1.604 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.584 (perp=7.647, rec=0.053, cos=0.001), tot_loss_proj:1.581 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.591 (perp=7.647, rec=0.060, cos=0.001), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.592 (perp=7.647, rec=0.062, cos=0.001), tot_loss_proj:1.606 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.597 (perp=7.647, rec=0.066, cos=0.001), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.595 (perp=7.647, rec=0.065, cos=0.001), tot_loss_proj:1.595 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.589 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.600 (perp=7.647, rec=0.069, cos=0.001), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.580 (perp=7.647, rec=0.049, cos=0.001), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.593 (perp=7.647, rec=0.063, cos=0.001), tot_loss_proj:1.586 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.588 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.595 (perp=7.647, rec=0.064, cos=0.001), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.596 (perp=7.647, rec=0.066, cos=0.001), tot_loss_proj:1.595 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.583 (perp=7.647, rec=0.052, cos=0.001), tot_loss_proj:1.582 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.590 (perp=7.647, rec=0.059, cos=0.001), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.581 (perp=7.647, rec=0.051, cos=0.001), tot_loss_proj:1.612 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.584 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.590 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.593 (perp=7.647, rec=0.062, cos=0.001), tot_loss_proj:1.607 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.430 | p: 92.084 | r: 92.788
rouge2     | fm: 62.668 | p: 62.508 | r: 62.861
rougeL     | fm: 80.773 | p: 80.514 | r: 81.094
rougeLsum  | fm: 80.714 | p: 80.446 | r: 80.998
r1fm+r2fm = 155.098

input #92 time: 0:08:47 | total time: 14:32:08


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9993328041825775
highest_index [0]
highest [0.9993328041825775]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.0106152296066284 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8291399478912354 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.8261485695838928 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 0.8090434074401855 for ['[CLS] solo specificball shrinking lad 1970s judicial [SEP]']
[Init] best perm rec loss: 0.8087723255157471 for ['[CLS] specific 1970sball lad shrinking solo judicial [SEP]']
[Init] best perm rec loss: 0.8081687092781067 for ['[CLS] solo specific judicial shrinkingball 1970s lad [SEP]']
[Init] best perm rec loss: 0.8072903156280518 for ['[CLS] shrinking soloball lad judicial specific 1970s [SEP]']
[Init] best perm rec loss: 0.8065516352653503 for ['[CLS] 1970s solo specific shrinking ladball judicial [SEP]']
[Init] best perm rec loss: 0.8060869574546814 for ['[CLS]ball solo specific shrinking 1970s lad judicial [SEP]']
[Init] best perm rec loss: 0.8057830333709717 for ['[CLS]ball specific lad shrinking 1970s judicial solo [SEP]']
[Init] best perm rec loss: 0.8052436709403992 for ['[CLS] shrinking specific soloball 1970s judicial lad [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.810 (perp=12.611, rec=0.280, cos=0.008), tot_loss_proj:3.103 [t=0.24s]
prediction: ['[CLS] funny its stories trumpet developed funny way [SEP]']
[ 100/2000] tot_loss=2.224 (perp=10.197, rec=0.181, cos=0.004), tot_loss_proj:2.724 [t=0.24s]
prediction: ['[CLS] understanding its understandingity understood funny way [SEP]']
[ 150/2000] tot_loss=2.185 (perp=10.096, rec=0.160, cos=0.006), tot_loss_proj:2.437 [t=0.24s]
prediction: ['[CLS] understanding its understandingity often funny way [SEP]']
[ 200/2000] tot_loss=1.855 (perp=8.701, rec=0.113, cos=0.003), tot_loss_proj:2.312 [t=0.24s]
prediction: ['[CLS] understanding its understanding its often funny way [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.723 (perp=8.086, rec=0.103, cos=0.003), tot_loss_proj:1.970 [t=0.24s]
prediction: ['[CLS] understanding understanding in its often funny way [SEP]']
[ 300/2000] tot_loss=1.700 (perp=8.086, rec=0.080, cos=0.002), tot_loss_proj:1.966 [t=0.24s]
prediction: ['[CLS] understanding understanding in its often funny way [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.700 (perp=8.086, rec=0.081, cos=0.002), tot_loss_proj:1.970 [t=0.24s]
prediction: ['[CLS] understanding understanding in its often funny way [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.691 (perp=8.086, rec=0.072, cos=0.002), tot_loss_proj:1.967 [t=0.24s]
prediction: ['[CLS] understanding understanding in its often funny way [SEP]']
[ 450/2000] tot_loss=1.577 (perp=7.511, rec=0.074, cos=0.001), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS], understanding in its often funny way [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.407 (perp=6.705, rec=0.065, cos=0.001), tot_loss_proj:1.712 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.416 (perp=6.705, rec=0.074, cos=0.001), tot_loss_proj:1.712 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 600/2000] tot_loss=1.409 (perp=6.705, rec=0.067, cos=0.001), tot_loss_proj:1.705 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.400 (perp=6.705, rec=0.058, cos=0.001), tot_loss_proj:1.709 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.409 (perp=6.705, rec=0.067, cos=0.001), tot_loss_proj:1.697 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 750/2000] tot_loss=1.400 (perp=6.705, rec=0.058, cos=0.001), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.409 (perp=6.705, rec=0.066, cos=0.001), tot_loss_proj:1.707 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.408 (perp=6.705, rec=0.066, cos=0.001), tot_loss_proj:1.697 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 900/2000] tot_loss=1.405 (perp=6.705, rec=0.063, cos=0.001), tot_loss_proj:1.700 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.408 (perp=6.705, rec=0.065, cos=0.001), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.408 (perp=6.705, rec=0.065, cos=0.001), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1050/2000] tot_loss=1.402 (perp=6.705, rec=0.059, cos=0.001), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.406 (perp=6.705, rec=0.064, cos=0.001), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.408 (perp=6.705, rec=0.066, cos=0.001), tot_loss_proj:1.705 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1200/2000] tot_loss=1.408 (perp=6.705, rec=0.065, cos=0.001), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.412 (perp=6.705, rec=0.070, cos=0.001), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.415 (perp=6.705, rec=0.073, cos=0.001), tot_loss_proj:1.693 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1350/2000] tot_loss=1.399 (perp=6.705, rec=0.057, cos=0.001), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.392 (perp=6.705, rec=0.050, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.402 (perp=6.705, rec=0.060, cos=0.001), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1500/2000] tot_loss=1.410 (perp=6.705, rec=0.068, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.409 (perp=6.705, rec=0.067, cos=0.001), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.406 (perp=6.705, rec=0.064, cos=0.001), tot_loss_proj:1.696 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1650/2000] tot_loss=1.415 (perp=6.705, rec=0.073, cos=0.001), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.404 (perp=6.705, rec=0.062, cos=0.001), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.411 (perp=6.705, rec=0.068, cos=0.001), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1800/2000] tot_loss=1.412 (perp=6.705, rec=0.070, cos=0.001), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.400 (perp=6.705, rec=0.058, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.405 (perp=6.705, rec=0.062, cos=0.001), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1950/2000] tot_loss=1.404 (perp=6.705, rec=0.061, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.396 (perp=6.705, rec=0.054, cos=0.001), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding in its often funny way, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 92.478 | p: 92.210 | r: 92.868
rouge2     | fm: 62.828 | p: 62.624 | r: 63.072
rougeL     | fm: 80.834 | p: 80.615 | r: 81.197
rougeLsum  | fm: 80.762 | p: 80.487 | r: 81.120
r1fm+r2fm = 155.307

input #93 time: 0:09:23 | total time: 14:41:31


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9993172942000517
highest_index [0]
highest [0.9993172942000517]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9766421318054199 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9562913775444031 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9171427488327026 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9082192778587341 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.8862788677215576 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.8804725408554077 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 0.8800083994865417 for ['[CLS] internal plum flowering expedition territorial shocks chronic centre crushed rockwellventing [SEP]']
[Init] best perm rec loss: 0.879869282245636 for ['[CLS] shocksventing internal chronic expedition centre rockwell flowering crushed plum territorial [SEP]']
[Init] best perm rec loss: 0.8795231580734253 for ['[CLS]venting plum territorial flowering expedition shocks internal centre chronic rockwell crushed [SEP]']
[Init] best perm rec loss: 0.8793690800666809 for ['[CLS]venting plum expedition shocks crushed chronic centre territorial rockwell flowering internal [SEP]']
[Init] best perm rec loss: 0.8776559829711914 for ['[CLS] chronic plum shocks expedition crushed internal territorialventing centre flowering rockwell [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.572 (perp=11.065, rec=0.345, cos=0.015), tot_loss_proj:4.150 [t=0.24s]
prediction: ['[CLS] or neither ending restrained pack neither neither coma difficulty nor weak [SEP]']
[ 100/2000] tot_loss=2.465 (perp=11.245, rec=0.210, cos=0.006), tot_loss_proj:2.802 [t=0.24s]
prediction: ['[CLS] of neither original cape of neither neither nor original nor funny [SEP]']
[ 150/2000] tot_loss=1.835 (perp=8.489, rec=0.134, cos=0.004), tot_loss_proj:2.072 [t=0.24s]
prediction: ['[CLS] is neither original caper which neither terribly original nor funny [SEP]']
[ 200/2000] tot_loss=1.946 (perp=9.239, rec=0.096, cos=0.003), tot_loss_proj:2.248 [t=0.24s]
prediction: ['[CLS] s neither original caper that neither terribly original nor funny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.876 (perp=8.929, rec=0.088, cos=0.002), tot_loss_proj:2.171 [t=0.24s]
prediction: ['[CLS] s neither original caper that neither original nor terribly funny [SEP]']
[ 300/2000] tot_loss=1.871 (perp=8.929, rec=0.084, cos=0.002), tot_loss_proj:2.172 [t=0.24s]
prediction: ['[CLS] s neither original caper that neither original nor terribly funny [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.867 (perp=8.869, rec=0.091, cos=0.002), tot_loss_proj:2.197 [t=0.24s]
prediction: ['[CLS] s neither that original cape a neither original nor terribly funny [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.607 (perp=7.611, rec=0.083, cos=0.002), tot_loss_proj:1.956 [t=0.24s]
prediction: ["[CLS] s neither that original'a cape original nor terribly funny [SEP]"]
[ 450/2000] tot_loss=1.603 (perp=7.611, rec=0.079, cos=0.001), tot_loss_proj:1.947 [t=0.24s]
prediction: ["[CLS] s neither that original'a cape original nor terribly funny [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.430 (perp=6.762, rec=0.076, cos=0.001), tot_loss_proj:1.729 [t=0.24s]
prediction: ["[CLS]'s neither that original a cape original nor terribly funny [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.433 (perp=6.762, rec=0.080, cos=0.001), tot_loss_proj:1.738 [t=0.24s]
prediction: ["[CLS]'s neither that original a cape original nor terribly funny [SEP]"]
[ 600/2000] tot_loss=1.429 (perp=6.762, rec=0.075, cos=0.001), tot_loss_proj:1.736 [t=0.24s]
prediction: ["[CLS]'s neither that original a cape original nor terribly funny [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.271 (perp=5.953, rec=0.079, cos=0.001), tot_loss_proj:1.518 [t=0.24s]
prediction: ["[CLS] that's neither original a cape original nor terribly funny [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.103 (perp=5.193, rec=0.063, cos=0.001), tot_loss_proj:1.352 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[ 750/2000] tot_loss=1.108 (perp=5.193, rec=0.068, cos=0.001), tot_loss_proj:1.355 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.104 (perp=5.193, rec=0.064, cos=0.001), tot_loss_proj:1.353 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.117 (perp=5.193, rec=0.078, cos=0.001), tot_loss_proj:1.349 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[ 900/2000] tot_loss=1.106 (perp=5.193, rec=0.066, cos=0.001), tot_loss_proj:1.355 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.099 (perp=5.193, rec=0.059, cos=0.001), tot_loss_proj:1.360 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.112 (perp=5.193, rec=0.072, cos=0.001), tot_loss_proj:1.357 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1050/2000] tot_loss=1.106 (perp=5.193, rec=0.066, cos=0.001), tot_loss_proj:1.357 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.108 (perp=5.193, rec=0.068, cos=0.001), tot_loss_proj:1.355 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.100 (perp=5.193, rec=0.060, cos=0.001), tot_loss_proj:1.362 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1200/2000] tot_loss=1.101 (perp=5.193, rec=0.061, cos=0.001), tot_loss_proj:1.352 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.099 (perp=5.193, rec=0.059, cos=0.001), tot_loss_proj:1.356 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.100 (perp=5.193, rec=0.060, cos=0.001), tot_loss_proj:1.358 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1350/2000] tot_loss=1.115 (perp=5.193, rec=0.075, cos=0.001), tot_loss_proj:1.359 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.098 (perp=5.193, rec=0.058, cos=0.001), tot_loss_proj:1.353 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.109 (perp=5.193, rec=0.069, cos=0.001), tot_loss_proj:1.361 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1500/2000] tot_loss=1.109 (perp=5.193, rec=0.069, cos=0.001), tot_loss_proj:1.350 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.106 (perp=5.193, rec=0.066, cos=0.001), tot_loss_proj:1.352 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.105 (perp=5.193, rec=0.065, cos=0.001), tot_loss_proj:1.355 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1650/2000] tot_loss=1.099 (perp=5.193, rec=0.059, cos=0.001), tot_loss_proj:1.363 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.096 (perp=5.193, rec=0.056, cos=0.001), tot_loss_proj:1.355 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.096 (perp=5.193, rec=0.056, cos=0.001), tot_loss_proj:1.348 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1800/2000] tot_loss=1.111 (perp=5.193, rec=0.071, cos=0.001), tot_loss_proj:1.361 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.102 (perp=5.193, rec=0.062, cos=0.001), tot_loss_proj:1.353 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.109 (perp=5.193, rec=0.069, cos=0.001), tot_loss_proj:1.356 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1950/2000] tot_loss=1.094 (perp=5.193, rec=0.054, cos=0.001), tot_loss_proj:1.354 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.096 (perp=5.193, rec=0.056, cos=0.001), tot_loss_proj:1.357 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] that's neither original a caper nor terribly funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 92.561 | p: 92.270 | r: 92.944
rouge2     | fm: 62.777 | p: 62.562 | r: 62.979
rougeL     | fm: 80.839 | p: 80.608 | r: 81.134
rougeLsum  | fm: 80.818 | p: 80.506 | r: 81.162
r1fm+r2fm = 155.337

input #94 time: 0:09:25 | total time: 14:50:57


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9991571833716502
highest_index [0]
highest [0.9991571833716502]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9717789888381958 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9435426592826843 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 0.9418174624443054 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9320042133331299 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 0.9293991923332214 for ['[CLS] oval foster welfarecu range turk partly support turret familiesumatic helping inclinedsteredling [SEP]']
[Init] best rec loss: 0.9255191683769226 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 0.9003634452819824 for ['[CLS] plenty heroes kit operating aim ouby fa physics pinco victim playing cisco feeling [SEP]']
[Init] best rec loss: 0.8562151193618774 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8513796925544739 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 0.8484290838241577 for ['[CLS] ] damp tech trailer cut privateے hanging block complete monty pressure sister wirenne [SEP]']
[Init] best perm rec loss: 0.8474252820014954 for ['[CLS] cut sister trailer block monty tech damp wire private pressure ] hangingnne completeے [SEP]']
[Init] best perm rec loss: 0.8452731966972351 for ['[CLS] trailer private sisterے wire pressure monty ] damp blocknne hanging cut tech complete [SEP]']
[Init] best perm rec loss: 0.8449822664260864 for ['[CLS] wire montyے private cut pressure hanging sisternne tech complete damp block trailer ] [SEP]']
[Init] best perm rec loss: 0.8435211181640625 for ['[CLS] cut wire damp tech trailer ] pressure private blockے monty complete sister hangingnne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.616 (perp=11.886, rec=0.233, cos=0.006), tot_loss_proj:2.973 [t=0.24s]
prediction: ['[CLS] storage story already, hopeless hopeless hopeless hopeless report became hopeless extremely hopeless terminal hopeless [SEP]']
[ 100/2000] tot_loss=2.949 (perp=13.938, rec=0.157, cos=0.004), tot_loss_proj:3.314 [t=0.24s]
prediction: ['[CLS]dle mud already, hopeless hopeless hopeless a story becomessat newly hopelessfying hopeless [SEP]']
[ 150/2000] tot_loss=2.172 (perp=10.261, rec=0.116, cos=0.003), tot_loss_proj:2.540 [t=0.24s]
prediction: ["[CLS]dle mud ', mud becomes hopeless a story becomessatisfyingfying hopeless [SEP]"]
[ 200/2000] tot_loss=2.292 (perp=10.917, rec=0.106, cos=0.003), tot_loss_proj:2.693 [t=0.24s]
prediction: ["[CLS]dle mud ', mud ) hopeless a story becomessatisfyingfying hopeless [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.953 (perp=9.170, rec=0.117, cos=0.003), tot_loss_proj:2.320 [t=0.24s]
prediction: ["[CLS]''dle, mud ) hopeless a story becomessatisfyingfying hopeless [SEP]"]
[ 300/2000] tot_loss=1.888 (perp=8.972, rec=0.091, cos=0.002), tot_loss_proj:2.256 [t=0.24s]
prediction: ["[CLS] ( 'dle, mud ) hopeless a story becomessatisfyingfying hopeless [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.089 (perp=9.524, rec=0.180, cos=0.004), tot_loss_proj:2.380 [t=0.24s]
prediction: ["[CLS] ('muddle, ) hopeless a story becomessatis denisfying hopeless [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.024 (perp=8.880, rec=0.240, cos=0.007), tot_loss_proj:2.320 [t=0.24s]
prediction: ["[CLS] ( denis'muddle, ) hopeless a story becomessatisfying territorial [SEP]"]
[ 450/2000] tot_loss=1.931 (perp=8.880, rec=0.152, cos=0.003), tot_loss_proj:2.296 [t=0.24s]
prediction: ["[CLS] ( denis'muddle, ) hopeless a story becomessatisfying territorial [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.674 (perp=7.661, rec=0.140, cos=0.003), tot_loss_proj:2.051 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'hopeless a story becomessatisfying double [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.589 (perp=7.244, rec=0.138, cos=0.002), tot_loss_proj:2.198 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless story becomessatisfying double [SEP]"]
[ 600/2000] tot_loss=1.570 (perp=7.244, rec=0.119, cos=0.002), tot_loss_proj:2.205 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless story becomessatisfying double [SEP]"]
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.491 (perp=6.816, rec=0.126, cos=0.002), tot_loss_proj:1.976 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying double story [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.631 (perp=7.534, rec=0.122, cos=0.002), tot_loss_proj:2.412 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying postage story [SEP]"]
[ 750/2000] tot_loss=1.605 (perp=7.446, rec=0.114, cos=0.002), tot_loss_proj:2.067 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.594 (perp=7.446, rec=0.103, cos=0.002), tot_loss_proj:2.063 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.608 (perp=7.446, rec=0.117, cos=0.002), tot_loss_proj:2.063 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
[ 900/2000] tot_loss=1.599 (perp=7.446, rec=0.108, cos=0.002), tot_loss_proj:2.063 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.590 (perp=7.446, rec=0.099, cos=0.002), tot_loss_proj:2.065 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.594 (perp=7.446, rec=0.103, cos=0.002), tot_loss_proj:2.063 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
[1050/2000] tot_loss=1.593 (perp=7.446, rec=0.102, cos=0.002), tot_loss_proj:2.057 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.598 (perp=7.446, rec=0.107, cos=0.002), tot_loss_proj:2.061 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.595 (perp=7.446, rec=0.104, cos=0.002), tot_loss_proj:2.063 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
[1200/2000] tot_loss=1.588 (perp=7.446, rec=0.097, cos=0.002), tot_loss_proj:2.060 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.593 (perp=7.446, rec=0.102, cos=0.002), tot_loss_proj:2.061 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.592 (perp=7.446, rec=0.100, cos=0.002), tot_loss_proj:2.057 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
[1350/2000] tot_loss=1.590 (perp=7.446, rec=0.099, cos=0.002), tot_loss_proj:2.059 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.594 (perp=7.446, rec=0.103, cos=0.002), tot_loss_proj:2.059 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.588 (perp=7.446, rec=0.097, cos=0.002), tot_loss_proj:2.056 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
[1500/2000] tot_loss=1.593 (perp=7.446, rec=0.102, cos=0.002), tot_loss_proj:2.057 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.581 (perp=7.446, rec=0.090, cos=0.002), tot_loss_proj:2.061 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.590 (perp=7.446, rec=0.099, cos=0.002), tot_loss_proj:2.055 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
[1650/2000] tot_loss=1.593 (perp=7.446, rec=0.102, cos=0.002), tot_loss_proj:2.060 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.593 (perp=7.446, rec=0.102, cos=0.002), tot_loss_proj:2.056 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.580 (perp=7.446, rec=0.089, cos=0.002), tot_loss_proj:2.062 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
[1800/2000] tot_loss=1.585 (perp=7.446, rec=0.094, cos=0.002), tot_loss_proj:2.061 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.590 (perp=7.446, rec=0.099, cos=0.002), tot_loss_proj:2.058 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.585 (perp=7.446, rec=0.094, cos=0.002), tot_loss_proj:2.064 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
[1950/2000] tot_loss=1.586 (perp=7.446, rec=0.095, cos=0.002), tot_loss_proj:2.055 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.593 (perp=7.446, rec=0.102, cos=0.002), tot_loss_proj:2.061 [t=0.24s]
prediction: ["[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] ( denis ) muddle,'a hopeless becomessatisfying mud story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 102.778

[Aggregate metrics]:
rouge1     | fm: 92.428 | p: 92.098 | r: 92.795
rouge2     | fm: 62.542 | p: 62.374 | r: 62.750
rougeL     | fm: 80.740 | p: 80.496 | r: 81.038
rougeLsum  | fm: 80.526 | p: 80.265 | r: 80.884
r1fm+r2fm = 154.970

input #95 time: 0:09:34 | total time: 15:00:31


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9992863442853963
highest_index [0]
highest [0.9992863442853963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8897403478622437 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8798883557319641 for ['[CLS] regrets emotionsoit purpose superior loop released given higher careini speechply springs assist [SEP]']
[Init] best rec loss: 0.860714316368103 for ['[CLS] all nova resolution which assault domestic look mandy headquarteredtated thanlus completion stillboards [SEP]']
[Init] best rec loss: 0.8265302181243896 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 0.8220264911651611 for ['[CLS] flex thought considerationlin kylie ste in gasped somewherese top close christian raised us [SEP]']
[Init] best rec loss: 0.8179569840431213 for ['[CLS] lea corps cellrily smashed unconscious garcia broke intensity baseball urban who reins brigade β [SEP]']
[Init] best rec loss: 0.8156690001487732 for ['[CLS]culus teacher robson colonies now world over enables who obsidianrlerving peacehwa contract [SEP]']
[Init] best rec loss: 0.7906668186187744 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.7905946969985962 for ['[CLS] statue projectile pondered typical living save sounding august spent time smashwords wig eragn memoir [SEP]']
[Init] best perm rec loss: 0.7904244065284729 for ['[CLS] sounding smashwords time typical pondered augustgn memoir projectile spent save wig era statue living [SEP]']
[Init] best perm rec loss: 0.7902461290359497 for ['[CLS] spent august smashwords projectile pondered save sounding living era time wiggn typical memoir statue [SEP]']
[Init] best perm rec loss: 0.789009153842926 for ['[CLS] statue memoir smashwordsgn spent wig typical time projectile sounding save august era living pondered [SEP]']
[Init] best perm rec loss: 0.7879628539085388 for ['[CLS] august living era typical save spent sounding memoirgn projectile time pondered wig smashwords statue [SEP]']
[Init] best perm rec loss: 0.7875304222106934 for ['[CLS] statuegn wig era spent save pondered typical projectile sounding smashwords august time living memoir [SEP]']
[Init] best perm rec loss: 0.7873085141181946 for ['[CLS] smashwords memoir spent august wig projectile statue era sounding typical savegn time pondered living [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.555 (perp=11.084, rec=0.317, cos=0.021), tot_loss_proj:3.480 [t=0.24s]
prediction: ['[CLS] effect besides force far arroyo rome group people to population force ways in smaller on [SEP]']
[ 100/2000] tot_loss=2.155 (perp=9.457, rec=0.254, cos=0.010), tot_loss_proj:2.867 [t=0.24s]
prediction: ['[CLS] himself besides situations himself into rome on men to individuals force himself in more into [SEP]']
[ 150/2000] tot_loss=2.196 (perp=9.828, rec=0.224, cos=0.007), tot_loss_proj:3.209 [t=0.24s]
prediction: ['[CLS] himself lesser men himself out how on men into individuals force himself in lesser into [SEP]']
[ 200/2000] tot_loss=2.169 (perp=9.848, rec=0.193, cos=0.007), tot_loss_proj:3.203 [t=0.24s]
prediction: ['[CLS] himself lesser situations cover him people on that on people force himself in lesser into [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.096 (perp=9.601, rec=0.169, cos=0.007), tot_loss_proj:3.549 [t=0.24s]
prediction: ['[CLS] himself law situations cover situations lesser on would on people force people for lesser into [SEP]']
[ 300/2000] tot_loss=2.095 (perp=9.803, rec=0.131, cos=0.004), tot_loss_proj:3.489 [t=0.24s]
prediction: ['[CLS] himself law situations cover bringing into cover would on people force men for lesser into [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.022 (perp=9.495, rec=0.120, cos=0.003), tot_loss_proj:3.491 [t=0.24s]
prediction: ['[CLS] himself law situations cover bringing into cover would on people force run lesser men and [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.931 (perp=9.080, rec=0.112, cos=0.003), tot_loss_proj:3.434 [t=0.24s]
prediction: ['[CLS] himself law situations cover on into cover would run people force on lesser men and [SEP]']
[ 450/2000] tot_loss=1.917 (perp=9.080, rec=0.099, cos=0.003), tot_loss_proj:3.431 [t=0.24s]
prediction: ['[CLS] himself law situations cover on into cover would run people force on lesser men and [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.861 (perp=8.821, rec=0.094, cos=0.002), tot_loss_proj:3.322 [t=0.24s]
prediction: ['[CLS] himself law situations on cover into cover would run people force on lesser men and [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.807 (perp=8.461, rec=0.111, cos=0.004), tot_loss_proj:3.366 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
[ 600/2000] tot_loss=1.794 (perp=8.461, rec=0.099, cos=0.002), tot_loss_proj:3.365 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.784 (perp=8.461, rec=0.089, cos=0.002), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.789 (perp=8.461, rec=0.094, cos=0.002), tot_loss_proj:3.365 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
[ 750/2000] tot_loss=1.786 (perp=8.461, rec=0.092, cos=0.002), tot_loss_proj:3.361 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.782 (perp=8.461, rec=0.088, cos=0.002), tot_loss_proj:3.367 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.778 (perp=8.461, rec=0.084, cos=0.002), tot_loss_proj:3.365 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
[ 900/2000] tot_loss=1.779 (perp=8.461, rec=0.085, cos=0.002), tot_loss_proj:3.366 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.773 (perp=8.461, rec=0.079, cos=0.002), tot_loss_proj:3.366 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.776 (perp=8.461, rec=0.081, cos=0.002), tot_loss_proj:3.367 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
[1050/2000] tot_loss=1.764 (perp=8.461, rec=0.070, cos=0.002), tot_loss_proj:3.367 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run people force on lesser men and [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.788 (perp=8.453, rec=0.096, cos=0.002), tot_loss_proj:3.390 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run force on people lesser men and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.781 (perp=8.453, rec=0.089, cos=0.002), tot_loss_proj:3.384 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run force on people lesser men and [SEP]']
[1200/2000] tot_loss=1.772 (perp=8.453, rec=0.079, cos=0.002), tot_loss_proj:3.392 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run force on people lesser men and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.778 (perp=8.453, rec=0.086, cos=0.002), tot_loss_proj:3.391 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run force on people lesser men and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.765 (perp=8.453, rec=0.073, cos=0.002), tot_loss_proj:3.388 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run force on people lesser men and [SEP]']
[1350/2000] tot_loss=1.773 (perp=8.453, rec=0.081, cos=0.002), tot_loss_proj:3.391 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would run force on people lesser men and [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.753 (perp=8.338, rec=0.083, cos=0.002), tot_loss_proj:3.437 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.745 (perp=8.338, rec=0.075, cos=0.002), tot_loss_proj:3.435 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
[1500/2000] tot_loss=1.734 (perp=8.338, rec=0.065, cos=0.002), tot_loss_proj:3.430 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.739 (perp=8.338, rec=0.070, cos=0.002), tot_loss_proj:3.434 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.748 (perp=8.338, rec=0.079, cos=0.002), tot_loss_proj:3.437 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
[1650/2000] tot_loss=1.746 (perp=8.338, rec=0.077, cos=0.002), tot_loss_proj:3.436 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.750 (perp=8.338, rec=0.081, cos=0.002), tot_loss_proj:3.438 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.744 (perp=8.338, rec=0.075, cos=0.002), tot_loss_proj:3.439 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
[1800/2000] tot_loss=1.758 (perp=8.338, rec=0.089, cos=0.002), tot_loss_proj:3.435 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.747 (perp=8.338, rec=0.078, cos=0.002), tot_loss_proj:3.435 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.756 (perp=8.338, rec=0.086, cos=0.002), tot_loss_proj:3.436 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
[1950/2000] tot_loss=1.750 (perp=8.338, rec=0.081, cos=0.002), tot_loss_proj:3.438 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.757 (perp=8.338, rec=0.088, cos=0.002), tot_loss_proj:3.439 [t=0.24s]
prediction: ['[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] himself run situations for cover into animals would force run on people lesser men and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.235 | p: 88.235 | r: 88.235
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 41.176 | p: 41.176 | r: 41.176
rougeLsum  | fm: 41.176 | p: 41.176 | r: 41.176
r1fm+r2fm = 106.985

[Aggregate metrics]:
rouge1     | fm: 92.390 | p: 92.089 | r: 92.763
rouge2     | fm: 61.983 | p: 61.838 | r: 62.156
rougeL     | fm: 80.141 | p: 79.867 | r: 80.459
rougeLsum  | fm: 80.055 | p: 79.806 | r: 80.391
r1fm+r2fm = 154.374

input #96 time: 0:09:34 | total time: 15:10:06


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9991662155443171
highest_index [0]
highest [0.9991662155443171]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8431113362312317 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.8104252219200134 for ['[CLS] [SEP] crates margarita trip decisionsylus [SEP]']
[Init] best rec loss: 0.8035948872566223 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.7755175828933716 for ['[CLS] jealous glennm his = empire [SEP]']
[Init] best rec loss: 0.7488246560096741 for ['[CLS] perfect channel cam working 140et [SEP]']
[Init] best perm rec loss: 0.7483882904052734 for ['[CLS]et cam perfect working 140 channel [SEP]']
[Init] best perm rec loss: 0.7473320364952087 for ['[CLS] cam channel working perfect 140et [SEP]']
[Init] best perm rec loss: 0.7467406988143921 for ['[CLS] channel perfect workinget 140 cam [SEP]']
[Init] best perm rec loss: 0.7466690540313721 for ['[CLS] channel working cam perfect 140et [SEP]']
[Init] best perm rec loss: 0.7466669082641602 for ['[CLS] perfect working channelet 140 cam [SEP]']
[Init] best perm rec loss: 0.7462400794029236 for ['[CLS] working channel cam perfectet 140 [SEP]']
[Init] best perm rec loss: 0.7460934519767761 for ['[CLS] working cam 140 perfectet channel [SEP]']
[Init] best perm rec loss: 0.7458518743515015 for ['[CLS] perfect cam channel working 140et [SEP]']
[Init] best perm rec loss: 0.7445951104164124 for ['[CLS] perfect working cam 140et channel [SEP]']
[Init] best perm rec loss: 0.7433086037635803 for ['[CLS] cam channel perfectet working 140 [SEP]']
[Init] best perm rec loss: 0.743118941783905 for ['[CLS] cam working 140et perfect channel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.285 (perp=9.836, rec=0.300, cos=0.017), tot_loss_proj:3.534 [t=0.24s]
prediction: ['[CLS] unfor20table act award [SEP]']
[ 100/2000] tot_loss=1.776 (perp=7.758, rec=0.197, cos=0.028), tot_loss_proj:2.671 [t=0.24s]
prediction: ['[CLS] ungetgettable characters characters [SEP]']
[ 150/2000] tot_loss=1.853 (perp=8.563, rec=0.133, cos=0.007), tot_loss_proj:2.165 [t=0.24s]
prediction: ['[CLS]forgetgettable characters and [SEP]']
[ 200/2000] tot_loss=2.134 (perp=10.153, rec=0.101, cos=0.002), tot_loss_proj:2.596 [t=0.24s]
prediction: ['[CLS]forgetfortable characters and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.851 (perp=8.567, rec=0.134, cos=0.003), tot_loss_proj:2.570 [t=0.24s]
prediction: ['[CLS]for ungettable characters and [SEP]']
[ 300/2000] tot_loss=1.804 (perp=8.567, rec=0.089, cos=0.002), tot_loss_proj:2.572 [t=0.24s]
prediction: ['[CLS]for ungettable characters and [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.179 (perp=5.520, rec=0.074, cos=0.002), tot_loss_proj:1.289 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.171 (perp=5.520, rec=0.065, cos=0.002), tot_loss_proj:1.295 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 450/2000] tot_loss=1.185 (perp=5.520, rec=0.079, cos=0.002), tot_loss_proj:1.282 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.171 (perp=5.514, rec=0.066, cos=0.002), tot_loss_proj:1.379 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.171 (perp=5.520, rec=0.065, cos=0.002), tot_loss_proj:1.292 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 600/2000] tot_loss=1.179 (perp=5.520, rec=0.073, cos=0.002), tot_loss_proj:1.290 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.171 (perp=5.520, rec=0.066, cos=0.002), tot_loss_proj:1.285 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.173 (perp=5.520, rec=0.068, cos=0.002), tot_loss_proj:1.295 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 750/2000] tot_loss=1.167 (perp=5.520, rec=0.062, cos=0.002), tot_loss_proj:1.299 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.168 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.378 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.156 (perp=5.514, rec=0.051, cos=0.002), tot_loss_proj:1.387 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 900/2000] tot_loss=1.182 (perp=5.514, rec=0.078, cos=0.002), tot_loss_proj:1.383 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.380 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.180 (perp=5.514, rec=0.075, cos=0.002), tot_loss_proj:1.397 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1050/2000] tot_loss=1.159 (perp=5.514, rec=0.055, cos=0.002), tot_loss_proj:1.380 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.160 (perp=5.514, rec=0.056, cos=0.002), tot_loss_proj:1.387 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.158 (perp=5.514, rec=0.054, cos=0.002), tot_loss_proj:1.379 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1200/2000] tot_loss=1.168 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.382 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.162 (perp=5.514, rec=0.058, cos=0.002), tot_loss_proj:1.385 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.161 (perp=5.514, rec=0.057, cos=0.002), tot_loss_proj:1.375 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1350/2000] tot_loss=1.161 (perp=5.514, rec=0.057, cos=0.002), tot_loss_proj:1.378 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.164 (perp=5.514, rec=0.060, cos=0.002), tot_loss_proj:1.379 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.166 (perp=5.514, rec=0.062, cos=0.002), tot_loss_proj:1.374 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1500/2000] tot_loss=1.163 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.384 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.166 (perp=5.514, rec=0.062, cos=0.002), tot_loss_proj:1.395 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.380 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1650/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.386 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.161 (perp=5.514, rec=0.057, cos=0.002), tot_loss_proj:1.382 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.170 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.387 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1800/2000] tot_loss=1.163 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.382 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.174 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.378 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.168 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.382 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1950/2000] tot_loss=1.170 (perp=5.514, rec=0.066, cos=0.002), tot_loss_proj:1.381 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.385 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] unforgettable and characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.472 | p: 92.188 | r: 92.864
rouge2     | fm: 61.629 | p: 61.413 | r: 61.834
rougeL     | fm: 80.202 | p: 79.962 | r: 80.531
rougeLsum  | fm: 80.119 | p: 79.848 | r: 80.466
r1fm+r2fm = 154.100

input #97 time: 0:09:23 | total time: 15:19:29


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9991922212899854
highest_index [0]
highest [0.9991922212899854]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.7134081721305847 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.7081572413444519 for ['[CLS] prohibited nos jed ada [SEP]']
[Init] best perm rec loss: 0.70798659324646 for ['[CLS] nos ada prohibited jed [SEP]']
[Init] best perm rec loss: 0.7077512145042419 for ['[CLS] ada nos jed prohibited [SEP]']
[Init] best perm rec loss: 0.7026987075805664 for ['[CLS] nos jed ada prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.576 (perp=11.687, rec=0.225, cos=0.013), tot_loss_proj:3.195 [t=0.23s]
prediction: ['[CLS] unfulful boarding [SEP]']
[ 100/2000] tot_loss=2.253 (perp=10.618, rec=0.124, cos=0.006), tot_loss_proj:2.536 [t=0.24s]
prediction: ['[CLS] unfulfullling [SEP]']
[ 150/2000] tot_loss=1.080 (perp=4.948, rec=0.087, cos=0.003), tot_loss_proj:1.068 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 200/2000] tot_loss=1.058 (perp=4.948, rec=0.064, cos=0.004), tot_loss_proj:1.057 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.066 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.074 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.066 (perp=4.948, rec=0.074, cos=0.002), tot_loss_proj:1.057 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.059 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.065 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.056 (perp=4.948, rec=0.065, cos=0.002), tot_loss_proj:1.060 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.060 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.065 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.052 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.060 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.050 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.055 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.056 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.048 (perp=4.948, rec=0.057, cos=0.002), tot_loss_proj:1.061 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.058 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.062 (perp=4.948, rec=0.071, cos=0.002), tot_loss_proj:1.070 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.056 (perp=4.948, rec=0.065, cos=0.002), tot_loss_proj:1.071 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.052 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.064 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.059 (perp=4.948, rec=0.067, cos=0.002), tot_loss_proj:1.061 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.059 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.049 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.048 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.041 (perp=4.948, rec=0.050, cos=0.002), tot_loss_proj:1.055 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.053 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.056 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.057 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.050 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.065 (perp=4.948, rec=0.074, cos=0.002), tot_loss_proj:1.064 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.055 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.040 (perp=4.948, rec=0.049, cos=0.002), tot_loss_proj:1.058 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.048 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.048 (perp=4.948, rec=0.057, cos=0.002), tot_loss_proj:1.058 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.058 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.060 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.045 (perp=4.948, rec=0.054, cos=0.002), tot_loss_proj:1.051 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.048 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.054 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.065 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.067 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.549 | p: 92.237 | r: 92.904
rouge2     | fm: 61.964 | p: 61.772 | r: 62.140
rougeL     | fm: 80.389 | p: 80.132 | r: 80.722
rougeLsum  | fm: 80.370 | p: 80.097 | r: 80.691
r1fm+r2fm = 154.512

input #98 time: 0:09:22 | total time: 15:28:52


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.999309739415734
highest_index [0]
highest [0.999309739415734]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8733632564544678 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8684595823287964 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8659393191337585 for ['[CLS] freedom lay third cartwright u to tear supply disputed glasses operahus album [MASK] literature bart now associatedtmenty thou stated microphone poly frederick rogers lineshtake furport modern point rosewood mid early [SEP]']
[Init] best rec loss: 0.8593382239341736 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.8483469486236572 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 0.8376026749610901 for ['[CLS] sealed−1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 0.8301820158958435 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 0.8222801685333252 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.8184991478919983 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.8171400427818298 for ['[CLS] still barbie dental cushion distance whente screens taste ratings temps currently earliest himselfaging services garcia slight forced orientˈ re synonym te [MASK] thunder knowledge bearing right actuallyts ferns opposed bet claire harper [SEP]']
[Init] best perm rec loss: 0.8165922164916992 for ['[CLS] te bearing taste actually right dental forced harper opposed ferns re distance garcia bettste cushion orient still screens temps synonym ratings himself slightaging when barbie thunder services currently [MASK] knowledge claire earliestˈ [SEP]']
[Init] best perm rec loss: 0.8164383769035339 for ['[CLS] re harper knowledge claire cushionˈ currently bearing dental screensaging still right temps slight earliest services taste [MASK] forcedtets te thunder himself distance ratings barbie actually orient ferns when bet opposed garcia synonym [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.807 (perp=12.518, rec=0.291, cos=0.012), tot_loss_proj:3.196 [t=0.24s]
prediction: ["[CLS] walked accusing statue tunnel firstusssing mortals headfilm dumb they refused theide products [ di some efforts told'fun bomb bullshit like fatssing [SEP] wanting, unix films kind filmv [SEP]"]
[ 100/2000] tot_loss=2.518 (perp=11.428, rec=0.223, cos=0.009), tot_loss_proj:2.919 [t=0.24s]
prediction: ['[CLS] walked out film lies ` havingssing mortals headssingος di ` their ` film [ di some minded walked had fun terrible a sossingssing " elliot and\'film the numbers nedra [SEP]']
[ 150/2000] tot_loss=2.518 (perp=11.680, rec=0.177, cos=0.005), tot_loss_proj:3.024 [t=0.24s]
prediction: ["[CLS] walked out film terrible ` mutteringssing ticket red film ¨ di ` their ` film'di so minded walked had fun terrible that thatssingssing prices film but'ticket crazy price nedra [SEP]"]
[ 200/2000] tot_loss=2.247 (perp=10.449, rec=0.154, cos=0.003), tot_loss_proj:2.756 [t=0.24s]
prediction: ["[CLS] walked out film terrible ` muttering di ticket un film ¨ di ` their'film'' sooll enjoy had fun horrible the that couldssing the film but'ticket suicidal cost intention [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.121 (perp=9.833, rec=0.150, cos=0.004), tot_loss_proj:2.576 [t=0.24s]
prediction: ["[CLS] walked out film terrible'muttering di ticket un film ` di ` their'film'cost so minded ranging had fun horrible the that couldssing'film but'ticket suicidal 'ote [SEP]"]
[ 300/2000] tot_loss=2.162 (perp=10.204, rec=0.118, cos=0.003), tot_loss_proj:2.727 [t=0.24s]
prediction: ["[CLS] walked out film terrible'muttering di ticket'film ` di ` they'film'cost so minded enjoy had fun horrible the that couldssing the the but'ticket suicidal 'ote [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.125 (perp=10.060, rec=0.111, cos=0.003), tot_loss_proj:2.665 [t=0.24s]
prediction: ["[CLS] walked out films terrible'muttering di costs'film ` di ` they the film ` cost so minded much had fun horrible'that couldssing cost the but'ticket suicidal'didn [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.092 (perp=9.907, rec=0.109, cos=0.002), tot_loss_proj:2.646 [t=0.24s]
prediction: ["[CLS] walked out words terrible'muttering di costs'film ` di ` they the film ` cost so minded much had fun horrible'that couldssing the mind but'ticket suicidal'didn [SEP]"]
[ 450/2000] tot_loss=2.151 (perp=10.256, rec=0.097, cos=0.002), tot_loss_proj:2.683 [t=0.24s]
prediction: ["[CLS] walked out words terrible'muttering di costs'film ` di ` they the film ` cost so minded much had fun horrible'that couldssing the mind but ` ticket suicidal'didn [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=2.127 (perp=10.107, rec=0.103, cos=0.002), tot_loss_proj:2.633 [t=0.24s]
prediction: ["[CLS] walked out words terrible'muttering di ` costs'film di ` they the film ` cost so minded much had fun terrible'that couldssing the mind but ` ticket suicidal ` t [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.120 (perp=10.152, rec=0.088, cos=0.002), tot_loss_proj:2.662 [t=0.24s]
prediction: ["[CLS] walked out words terrible ` muttering di ` costs'film di ` they the film like cost so minded much had fun terrible'that couldssing the mind but ` ticket suicidal ` t [SEP]"]
[ 600/2000] tot_loss=2.100 (perp=10.047, rec=0.089, cos=0.002), tot_loss_proj:2.711 [t=0.24s]
prediction: ["[CLS] walked out words terrible ` muttering di ` costs'film di ` they the film like cost so going much had fun terrible'that didssing the mind but ` ticket suicidal ` n [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.960 (perp=9.377, rec=0.083, cos=0.002), tot_loss_proj:2.474 [t=0.24s]
prediction: ["[CLS] walked out words terrible ` muttering di ` costs'film di ` cost the film like they so so much had fun terrible'that didssing the mind but ` ticket suicidal ` n [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.954 (perp=9.302, rec=0.092, cos=0.002), tot_loss_proj:2.532 [t=0.24s]
prediction: ["[CLS] walked out words terrible ` muttering di ` costs'film di ` cost the film like they so so much had fun `'that didssing the mind but terrible ticket suicidal ` n [SEP]"]
[ 750/2000] tot_loss=1.954 (perp=9.349, rec=0.082, cos=0.002), tot_loss_proj:2.536 [t=0.24s]
prediction: ["[CLS] walked out words terrible ` muttering di ` costs'film di ` cost the film like they so so much had fun `'that tssing the mind but terrible ticket suicidal ` n [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.939 (perp=9.257, rec=0.086, cos=0.001), tot_loss_proj:2.498 [t=0.24s]
prediction: ["[CLS] walked out words terrible ` muttering di film ` costs'di ` cost the film like they so so much had fun `'that tssing the mind but terrible ticket suicidal ` n [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.952 (perp=9.291, rec=0.091, cos=0.002), tot_loss_proj:2.775 [t=0.24s]
prediction: ["[CLS] walked out words terrible ` muttering di film ` costs'di ` cost the film like they so much so had fun `, that tssing the mind but terrible ticket eager ` n [SEP]"]
[ 900/2000] tot_loss=1.911 (perp=9.101, rec=0.089, cos=0.002), tot_loss_proj:2.762 [t=0.24s]
prediction: ["[CLS] walked out words terrible ` muttering di film ` costs'di ` cost the film like they so much so had fun ', that tssing the mind but terrible ticket eager ` n [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.857 (perp=8.848, rec=0.086, cos=0.002), tot_loss_proj:2.671 [t=0.24s]
prediction: ["[CLS] walked out words terrible n muttering di film ` costs'di ` cost the film like they so much so had fun ', that tssing the mind but terrible ticket eager ` ` [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.909 (perp=9.113, rec=0.085, cos=0.002), tot_loss_proj:2.472 [t=0.24s]
prediction: ["[CLS] walked out words terrible n muttering di film ` ª'di ` cost the film like they had so much so fun ', that tssing the mind but terrible ticket patting ` ` [SEP]"]
[1050/2000] tot_loss=1.851 (perp=8.839, rec=0.082, cos=0.002), tot_loss_proj:2.412 [t=0.24s]
prediction: ["[CLS] walked out words terrible n muttering di film ` ª'di ` cost the film like they had so much so fun ', that tssing the mind but terrible ticket ` ` ` [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.794 (perp=8.554, rec=0.081, cos=0.002), tot_loss_proj:2.389 [t=0.24s]
prediction: ["[CLS] walked out words terrible n muttering di film ` ª'di ` so the film like they had so much cost fun ', that tssing the mind but terrible ticket ` ` ` [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.721 (perp=8.179, rec=0.083, cos=0.002), tot_loss_proj:2.395 [t=0.24s]
prediction: ["[CLS] walked out words terrible n muttering di film ` ª'di ` so the film like they had so much fun ', that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
[1200/2000] tot_loss=1.720 (perp=8.179, rec=0.083, cos=0.002), tot_loss_proj:2.392 [t=0.24s]
prediction: ["[CLS] walked out words terrible n muttering di film ` ª'di ` so the film like they had so much fun ', that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.720 (perp=8.183, rec=0.082, cos=0.002), tot_loss_proj:2.349 [t=0.24s]
prediction: ["[CLS] walked out words terrible n muttering di ` film costs'di ` so the film like they had so much fun ', that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.832 (perp=8.746, rec=0.081, cos=0.002), tot_loss_proj:2.386 [t=0.24s]
prediction: ["[CLS] walked out words ª n muttering di ` film terrible'di ` going the film like they had so much fun ', that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
[1350/2000] tot_loss=1.815 (perp=8.689, rec=0.076, cos=0.002), tot_loss_proj:2.357 [t=0.24s]
prediction: ["[CLS] walked out words ª n muttering di ` film horrible'di ` going the film like they had so much fun ', that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.813 (perp=8.649, rec=0.081, cos=0.001), tot_loss_proj:2.371 [t=0.24s]
prediction: ["[CLS] walked out words ª n muttering di ` going horrible'di ` film the film like they had so much fun ', that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.776 (perp=8.483, rec=0.078, cos=0.002), tot_loss_proj:2.481 [t=0.24s]
prediction: ["[CLS] walked out words n muttering di ` going horrible'di ` film the film ª like they had so much fun ', that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
[1500/2000] tot_loss=1.773 (perp=8.483, rec=0.075, cos=0.001), tot_loss_proj:2.481 [t=0.24s]
prediction: ["[CLS] walked out words n muttering di ` going horrible'di ` film the film ª like they had so much fun ', that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.674 (perp=7.976, rec=0.077, cos=0.001), tot_loss_proj:2.309 [t=0.24s]
prediction: ["[CLS] walked out words going n muttering di ` horrible'di `'the film ª like they had so much fun ', that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.664 (perp=7.961, rec=0.070, cos=0.002), tot_loss_proj:2.319 [t=0.24s]
prediction: ["[CLS] walked out words going n muttering di ` horrible'di `'the film ª like they had so much fun,'that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
[1650/2000] tot_loss=1.666 (perp=7.961, rec=0.072, cos=0.002), tot_loss_proj:2.320 [t=0.24s]
prediction: ["[CLS] walked out words going n muttering di ` horrible'di `'the film ª like they had so much fun,'that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.669 (perp=7.957, rec=0.076, cos=0.001), tot_loss_proj:2.356 [t=0.24s]
prediction: ["[CLS] walked out words going n muttering di `'horrible di `'the film ª like they had so much fun,'that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.673 (perp=7.957, rec=0.080, cos=0.001), tot_loss_proj:2.360 [t=0.24s]
prediction: ["[CLS] walked out words going n muttering di `'horrible di `'the film ª like they had so much fun,'that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
[1800/2000] tot_loss=1.673 (perp=7.957, rec=0.080, cos=0.001), tot_loss_proj:2.356 [t=0.24s]
prediction: ["[CLS] walked out words going n muttering di `'horrible di `'the film ª like they had so much fun,'that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.667 (perp=7.957, rec=0.074, cos=0.001), tot_loss_proj:2.354 [t=0.24s]
prediction: ["[CLS] walked out words going n muttering di `'horrible di `'the film ª like they had so much fun,'that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.675 (perp=7.957, rec=0.082, cos=0.001), tot_loss_proj:2.356 [t=0.24s]
prediction: ["[CLS] walked out words going n muttering di `'horrible di `'the film ª like they had so much fun,'that tssing the mind but terrible ticket cost ` ` ` [SEP]"]
[1950/2000] tot_loss=1.655 (perp=7.861, rec=0.081, cos=0.001), tot_loss_proj:2.343 [t=0.24s]
prediction: ["[CLS] walked out words going n muttering di `'horrible di `'the film ª like they had so much fun,'that tssing the mind but terrible ticket cost ` `'[SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.614 (perp=7.697, rec=0.073, cos=0.001), tot_loss_proj:2.383 [t=0.24s]
prediction: ["[CLS] walked out words going n muttering di `'horrible di `'the film'like they had so much fun, ª that tssing the mind but terrible ticket cost ` `'[SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] walked out words going n muttering di `'horrible di `'the film'like they had so much fun, ª that tssing the mind but terrible ticket cost ` `'[SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.019 | p: 81.481 | r: 84.615
rouge2     | fm: 31.373 | p: 30.769 | r: 32.000
rougeL     | fm: 52.830 | p: 51.852 | r: 53.846
rougeLsum  | fm: 52.830 | p: 51.852 | r: 53.846
r1fm+r2fm = 114.391

[Aggregate metrics]:
rouge1     | fm: 92.470 | p: 92.173 | r: 92.855
rouge2     | fm: 61.687 | p: 61.519 | r: 61.933
rougeL     | fm: 80.086 | p: 79.830 | r: 80.398
rougeLsum  | fm: 80.066 | p: 79.829 | r: 80.387
r1fm+r2fm = 154.158

input #99 time: 0:09:33 | total time: 15:38:25


Average Cosine Similarity: 0.9992812812989129
Done with all.
