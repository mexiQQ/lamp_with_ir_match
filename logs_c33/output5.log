


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.05 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 48.28it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9992716374753432
highest_index [0]
highest [0.9992716374753432]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.0017677545547485 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9434316158294678 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9404582977294922 for ['[CLS] ronnie huff [SEP]']
[Init] best rec loss: 0.9324178695678711 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9268800020217896 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8593006730079651 for ['[CLS] panel officer [SEP]']
[Init] best perm rec loss: 0.8530735373497009 for ['[CLS] officer panel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.384 (perp=10.843, rec=0.199, cos=0.016), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] disappointed disappointed [SEP]']
[ 100/2000] tot_loss=2.307 (perp=11.087, rec=0.087, cos=0.003), tot_loss_proj:2.534 [t=0.22s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 150/2000] tot_loss=2.285 (perp=11.087, rec=0.066, cos=0.002), tot_loss_proj:2.536 [t=0.22s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 200/2000] tot_loss=2.282 (perp=11.087, rec=0.063, cos=0.001), tot_loss_proj:2.537 [t=0.22s]
prediction: ['[CLS] disappointed slightly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.115 (perp=10.252, rec=0.063, cos=0.002), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.108 (perp=10.252, rec=0.056, cos=0.001), tot_loss_proj:2.116 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.104 (perp=10.252, rec=0.052, cos=0.001), tot_loss_proj:2.120 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.108 (perp=10.252, rec=0.056, cos=0.001), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.117 (perp=10.252, rec=0.066, cos=0.001), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.109 (perp=10.252, rec=0.058, cos=0.001), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.124 (perp=10.252, rec=0.072, cos=0.001), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.119 (perp=10.252, rec=0.067, cos=0.001), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.110 (perp=10.252, rec=0.058, cos=0.001), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.116 (perp=10.252, rec=0.065, cos=0.001), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.092 (perp=10.252, rec=0.041, cos=0.001), tot_loss_proj:2.125 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.109 (perp=10.252, rec=0.057, cos=0.001), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.100 (perp=10.252, rec=0.048, cos=0.001), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.123 (perp=10.252, rec=0.071, cos=0.001), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.114 (perp=10.252, rec=0.063, cos=0.001), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.109 (perp=10.252, rec=0.057, cos=0.001), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.108 (perp=10.252, rec=0.056, cos=0.001), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.105 (perp=10.252, rec=0.053, cos=0.001), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.106 (perp=10.252, rec=0.054, cos=0.001), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.110 (perp=10.252, rec=0.058, cos=0.001), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.116 (perp=10.252, rec=0.064, cos=0.001), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.120 (perp=10.252, rec=0.068, cos=0.001), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.105 (perp=10.252, rec=0.053, cos=0.001), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.111 (perp=10.252, rec=0.059, cos=0.001), tot_loss_proj:2.131 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.112 (perp=10.252, rec=0.061, cos=0.001), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.104 (perp=10.252, rec=0.052, cos=0.001), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.114 (perp=10.252, rec=0.063, cos=0.001), tot_loss_proj:2.120 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.118 (perp=10.252, rec=0.067, cos=0.001), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.113 (perp=10.252, rec=0.061, cos=0.001), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.097 (perp=10.252, rec=0.045, cos=0.001), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.120 (perp=10.252, rec=0.068, cos=0.001), tot_loss_proj:2.120 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.112 (perp=10.252, rec=0.060, cos=0.001), tot_loss_proj:2.103 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.121 (perp=10.252, rec=0.069, cos=0.001), tot_loss_proj:2.108 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.109 (perp=10.252, rec=0.058, cos=0.001), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.136 (perp=10.252, rec=0.084, cos=0.001), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.118 (perp=10.252, rec=0.066, cos=0.001), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:09:04 | total time: 0:09:04


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9993549160877631
highest_index [0]
highest [0.9993549160877631]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.019070029258728 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9784805774688721 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.8989198803901672 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 0.8676603436470032 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8272038102149963 for ['[CLS] passage erupted [SEP]']
[Init] best rec loss: 0.8209529519081116 for ['[CLS] siam presidents [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.404 (perp=10.892, rec=0.222, cos=0.003), tot_loss_proj:2.537 [t=0.22s]
prediction: ['[CLS] wonderful splendid [SEP]']
[ 100/2000] tot_loss=2.221 (perp=10.288, rec=0.162, cos=0.002), tot_loss_proj:2.345 [t=0.22s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.157 (perp=10.288, rec=0.098, cos=0.001), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.128 (perp=10.288, rec=0.069, cos=0.001), tot_loss_proj:2.347 [t=0.22s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.914 (perp=9.171, rec=0.079, cos=0.001), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.906 (perp=9.171, rec=0.070, cos=0.001), tot_loss_proj:1.896 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.899 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.895 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.903 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.895 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.888 (perp=9.171, rec=0.052, cos=0.001), tot_loss_proj:1.891 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.902 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.891 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.884 (perp=9.171, rec=0.049, cos=0.001), tot_loss_proj:1.903 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.891 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.904 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.886 (perp=9.171, rec=0.050, cos=0.001), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.903 (perp=9.171, rec=0.068, cos=0.001), tot_loss_proj:1.906 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.896 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.897 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.906 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.883 (perp=9.171, rec=0.048, cos=0.001), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.903 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.881 (perp=9.171, rec=0.046, cos=0.001), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.904 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.903 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.904 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.909 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.888 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.908 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.897 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.880 (perp=9.171, rec=0.045, cos=0.001), tot_loss_proj:1.895 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.900 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.908 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.901 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.897 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.912 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.888 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.899 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.912 (perp=9.171, rec=0.077, cos=0.001), tot_loss_proj:1.913 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.896 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.897 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:08:55 | total time: 0:18:00


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9994334295644651
highest_index [0]
highest [0.9994334295644651]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.8400301933288574 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.8265790939331055 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best rec loss: 0.8116205930709839 for ['[CLS] dailypol food [SEP]']
[Init] best rec loss: 0.8050260543823242 for ['[CLS] just percussion universal [SEP]']
[Init] best rec loss: 0.7912572026252747 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 0.7776637077331543 for ['[CLS] we would working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.057 (perp=8.842, rec=0.271, cos=0.018), tot_loss_proj:2.236 [t=0.23s]
prediction: ['[CLS] gaining its momentum [SEP]']
[ 100/2000] tot_loss=1.840 (perp=8.515, rec=0.132, cos=0.006), tot_loss_proj:1.807 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=1.781 (perp=8.515, rec=0.077, cos=0.001), tot_loss_proj:1.803 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=1.769 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.805 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.762 (perp=8.515, rec=0.058, cos=0.001), tot_loss_proj:1.795 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.795 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.757 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.794 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.793 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.794 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.805 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.754 (perp=8.515, rec=0.050, cos=0.001), tot_loss_proj:1.794 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.789 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.799 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.780 (perp=8.515, rec=0.076, cos=0.001), tot_loss_proj:1.787 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.749 (perp=8.515, rec=0.045, cos=0.001), tot_loss_proj:1.796 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.761 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.794 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.796 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.786 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.774 (perp=8.515, rec=0.070, cos=0.001), tot_loss_proj:1.809 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.787 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.754 (perp=8.515, rec=0.050, cos=0.001), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.776 (perp=8.515, rec=0.072, cos=0.001), tot_loss_proj:1.791 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.775 (perp=8.515, rec=0.071, cos=0.001), tot_loss_proj:1.789 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.786 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.800 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.794 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.805 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.793 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.777 (perp=8.515, rec=0.073, cos=0.001), tot_loss_proj:1.795 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.804 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.803 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:09:06 | total time: 0:27:07


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.999300207712396
highest_index [0]
highest [0.999300207712396]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.0158096551895142 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9032942652702332 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8778855204582214 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8744809627532959 for ['[CLS] role bart [SEP]']
[Init] best rec loss: 0.8518046140670776 for ['[CLS] gallons professor [SEP]']
[Init] best rec loss: 0.8455400466918945 for ['[CLS] canterbury havoc [SEP]']
[Init] best rec loss: 0.8341601490974426 for ['[CLS] anthony robin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.343 (perp=10.476, rec=0.241, cos=0.006), tot_loss_proj:2.431 [t=0.24s]
prediction: ['[CLS] flawless flawless [SEP]']
[ 100/2000] tot_loss=2.134 (perp=10.224, rec=0.087, cos=0.002), tot_loss_proj:2.365 [t=0.24s]
prediction: ['[CLS] film flawless [SEP]']
[ 150/2000] tot_loss=2.121 (perp=10.224, rec=0.075, cos=0.001), tot_loss_proj:2.363 [t=0.24s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.122 (perp=10.224, rec=0.076, cos=0.001), tot_loss_proj:2.363 [t=0.24s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.770 (perp=8.385, rec=0.090, cos=0.002), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.764 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.747 (perp=8.385, rec=0.069, cos=0.001), tot_loss_proj:1.762 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.750 (perp=8.385, rec=0.072, cos=0.001), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.730 (perp=8.385, rec=0.051, cos=0.001), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.725 (perp=8.385, rec=0.047, cos=0.001), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.730 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.749 (perp=8.385, rec=0.071, cos=0.001), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.756 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.742 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.761 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.738 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.738 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.733 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.757 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.744 (perp=8.385, rec=0.066, cos=0.001), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.741 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.740 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.730 (perp=8.385, rec=0.051, cos=0.001), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.741 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.727 (perp=8.385, rec=0.049, cos=0.001), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.745 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.743 (perp=8.385, rec=0.065, cos=0.001), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.731 (perp=8.385, rec=0.053, cos=0.001), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.734 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.756 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.760 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:08:57 | total time: 0:36:04


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.999229949404915
highest_index [0]
highest [0.999229949404915]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.0350229740142822 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9845936894416809 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9643853306770325 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9641659259796143 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9627823233604431 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 0.9362619519233704 for ['[CLS] who table christ [SEP]']
[Init] best rec loss: 0.9233399629592896 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.8893289566040039 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.134 (perp=9.705, rec=0.185, cos=0.008), tot_loss_proj:2.155 [t=0.29s]
prediction: ['[CLS] tiresomently [SEP]']
[ 100/2000] tot_loss=1.600 (perp=7.515, rec=0.095, cos=0.002), tot_loss_proj:1.569 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.571 (perp=7.515, rec=0.066, cos=0.002), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.566 (perp=7.515, rec=0.062, cos=0.002), tot_loss_proj:1.563 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.570 (perp=7.515, rec=0.066, cos=0.001), tot_loss_proj:1.559 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.567 (perp=7.515, rec=0.062, cos=0.001), tot_loss_proj:1.567 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.575 (perp=7.515, rec=0.070, cos=0.001), tot_loss_proj:1.567 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.569 (perp=7.515, rec=0.064, cos=0.001), tot_loss_proj:1.570 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.571 (perp=7.515, rec=0.066, cos=0.001), tot_loss_proj:1.577 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.570 (perp=7.515, rec=0.066, cos=0.001), tot_loss_proj:1.572 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.569 (perp=7.515, rec=0.064, cos=0.001), tot_loss_proj:1.557 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.566 (perp=7.515, rec=0.061, cos=0.001), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.572 (perp=7.515, rec=0.068, cos=0.001), tot_loss_proj:1.574 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.560 (perp=7.515, rec=0.056, cos=0.001), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.558 (perp=7.515, rec=0.054, cos=0.002), tot_loss_proj:1.574 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.570 (perp=7.515, rec=0.065, cos=0.002), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.560 (perp=7.515, rec=0.055, cos=0.002), tot_loss_proj:1.561 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.558 (perp=7.515, rec=0.053, cos=0.002), tot_loss_proj:1.572 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.569 (perp=7.515, rec=0.064, cos=0.002), tot_loss_proj:1.574 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.571 (perp=7.515, rec=0.066, cos=0.002), tot_loss_proj:1.552 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.581 (perp=7.515, rec=0.076, cos=0.002), tot_loss_proj:1.569 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.563 (perp=7.515, rec=0.059, cos=0.002), tot_loss_proj:1.570 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.575 (perp=7.515, rec=0.070, cos=0.002), tot_loss_proj:1.559 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.562 (perp=7.515, rec=0.058, cos=0.002), tot_loss_proj:1.564 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.573 (perp=7.515, rec=0.068, cos=0.002), tot_loss_proj:1.573 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.566 (perp=7.515, rec=0.061, cos=0.002), tot_loss_proj:1.566 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.568 (perp=7.515, rec=0.064, cos=0.002), tot_loss_proj:1.568 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.558 (perp=7.515, rec=0.054, cos=0.002), tot_loss_proj:1.560 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.572 (perp=7.515, rec=0.068, cos=0.002), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.563 (perp=7.515, rec=0.058, cos=0.002), tot_loss_proj:1.556 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.558 (perp=7.515, rec=0.053, cos=0.002), tot_loss_proj:1.556 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.565 (perp=7.515, rec=0.061, cos=0.002), tot_loss_proj:1.569 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.565 (perp=7.515, rec=0.061, cos=0.002), tot_loss_proj:1.562 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.568 (perp=7.515, rec=0.063, cos=0.002), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.570 (perp=7.515, rec=0.065, cos=0.002), tot_loss_proj:1.569 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.553 (perp=7.515, rec=0.048, cos=0.002), tot_loss_proj:1.572 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.557 (perp=7.515, rec=0.052, cos=0.002), tot_loss_proj:1.565 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.563 (perp=7.515, rec=0.058, cos=0.002), tot_loss_proj:1.571 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.565 (perp=7.515, rec=0.060, cos=0.002), tot_loss_proj:1.564 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.569 (perp=7.515, rec=0.064, cos=0.002), tot_loss_proj:1.562 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:09:42 | total time: 0:45:46


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9993648656803427
highest_index [0]
highest [0.9993648656803427]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9518389701843262 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9517901539802551 for ['[CLS] stay orgasm [SEP]']
[Init] best rec loss: 0.9451121091842651 for ['[CLS] territorial half [SEP]']
[Init] best rec loss: 0.9313843846321106 for ['[CLS] pleasant favorable [SEP]']
[Init] best rec loss: 0.9138829708099365 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 0.8891943693161011 for ['[CLS] quiet. [SEP]']
[Init] best perm rec loss: 0.8871971964836121 for ['[CLS]. quiet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.454 (perp=11.369, rec=0.176, cos=0.004), tot_loss_proj:3.584 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
[ 100/2000] tot_loss=2.417 (perp=11.369, rec=0.139, cos=0.004), tot_loss_proj:3.589 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
[ 150/2000] tot_loss=2.413 (perp=11.369, rec=0.136, cos=0.003), tot_loss_proj:3.580 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
[ 200/2000] tot_loss=2.579 (perp=12.316, rec=0.113, cos=0.003), tot_loss_proj:2.531 [t=0.23s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.289 (perp=10.725, rec=0.141, cos=0.003), tot_loss_proj:4.158 [t=0.24s]
prediction: ['[CLS] ease lumpur [SEP]']
[ 300/2000] tot_loss=2.947 (perp=14.205, rec=0.103, cos=0.003), tot_loss_proj:4.018 [t=0.24s]
prediction: ['[CLS] ease revolves [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.498 (perp=11.854, rec=0.124, cos=0.003), tot_loss_proj:2.563 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.474 (perp=11.854, rec=0.100, cos=0.003), tot_loss_proj:2.578 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/2000] tot_loss=2.476 (perp=11.854, rec=0.102, cos=0.003), tot_loss_proj:2.572 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.496 (perp=11.854, rec=0.122, cos=0.003), tot_loss_proj:2.572 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.494 (perp=11.854, rec=0.120, cos=0.003), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 600/2000] tot_loss=2.495 (perp=11.854, rec=0.121, cos=0.003), tot_loss_proj:2.581 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.488 (perp=11.854, rec=0.114, cos=0.003), tot_loss_proj:2.582 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.487 (perp=11.854, rec=0.113, cos=0.003), tot_loss_proj:2.582 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 750/2000] tot_loss=2.473 (perp=11.854, rec=0.099, cos=0.003), tot_loss_proj:2.576 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.523 (perp=11.854, rec=0.149, cos=0.004), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.511 (perp=11.854, rec=0.136, cos=0.003), tot_loss_proj:2.596 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 900/2000] tot_loss=2.503 (perp=11.854, rec=0.129, cos=0.003), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.521 (perp=11.854, rec=0.147, cos=0.003), tot_loss_proj:2.593 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1000/2000] tot_loss=2.496 (perp=11.854, rec=0.122, cos=0.003), tot_loss_proj:2.583 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1050/2000] tot_loss=2.501 (perp=11.854, rec=0.128, cos=0.003), tot_loss_proj:2.584 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1100/2000] tot_loss=2.495 (perp=11.854, rec=0.121, cos=0.003), tot_loss_proj:2.582 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1150/2000] tot_loss=2.500 (perp=11.854, rec=0.126, cos=0.003), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1200/2000] tot_loss=2.494 (perp=11.854, rec=0.120, cos=0.003), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1250/2000] tot_loss=2.492 (perp=11.854, rec=0.118, cos=0.003), tot_loss_proj:2.584 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1300/2000] tot_loss=2.491 (perp=11.854, rec=0.117, cos=0.003), tot_loss_proj:2.581 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1350/2000] tot_loss=2.495 (perp=11.854, rec=0.122, cos=0.003), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1400/2000] tot_loss=2.494 (perp=11.854, rec=0.120, cos=0.003), tot_loss_proj:2.573 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1450/2000] tot_loss=2.475 (perp=11.854, rec=0.101, cos=0.003), tot_loss_proj:2.582 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1500/2000] tot_loss=2.496 (perp=11.854, rec=0.123, cos=0.003), tot_loss_proj:2.586 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1550/2000] tot_loss=2.486 (perp=11.854, rec=0.113, cos=0.003), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1600/2000] tot_loss=2.486 (perp=11.854, rec=0.112, cos=0.003), tot_loss_proj:2.596 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1650/2000] tot_loss=2.476 (perp=11.854, rec=0.102, cos=0.003), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1700/2000] tot_loss=2.482 (perp=11.854, rec=0.108, cos=0.003), tot_loss_proj:2.579 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1750/2000] tot_loss=2.484 (perp=11.854, rec=0.110, cos=0.003), tot_loss_proj:2.582 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1800/2000] tot_loss=2.496 (perp=11.854, rec=0.123, cos=0.003), tot_loss_proj:2.590 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1850/2000] tot_loss=2.483 (perp=11.854, rec=0.109, cos=0.003), tot_loss_proj:2.583 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1900/2000] tot_loss=2.481 (perp=11.854, rec=0.107, cos=0.003), tot_loss_proj:2.595 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1950/2000] tot_loss=2.487 (perp=11.854, rec=0.113, cos=0.003), tot_loss_proj:2.573 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[2000/2000] tot_loss=2.491 (perp=11.854, rec=0.117, cos=0.003), tot_loss_proj:2.583 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 183.333

input #5 time: 0:09:40 | total time: 0:55:27


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.9992509755027666
highest_index [0]
highest [0.9992509755027666]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9576692581176758 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9543807506561279 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9314477443695068 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.8687410354614258 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.8670455813407898 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.8099329471588135 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7884305119514465 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.7730320692062378 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.7621805667877197 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 0.7525128126144409 for ['[CLS] too u2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.613 (perp=6.812, rec=0.236, cos=0.014), tot_loss_proj:2.705 [t=0.24s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.721 (perp=8.088, rec=0.100, cos=0.003), tot_loss_proj:1.706 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.693 (perp=8.088, rec=0.074, cos=0.002), tot_loss_proj:1.693 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.689 (perp=8.088, rec=0.070, cos=0.002), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.678 (perp=8.088, rec=0.059, cos=0.002), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.684 (perp=8.088, rec=0.065, cos=0.001), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.683 (perp=8.088, rec=0.063, cos=0.002), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.684 (perp=8.088, rec=0.065, cos=0.001), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.671 (perp=8.088, rec=0.052, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.691 (perp=8.088, rec=0.072, cos=0.001), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.688 (perp=8.088, rec=0.068, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.690 (perp=8.088, rec=0.071, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.674 (perp=8.088, rec=0.055, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.686 (perp=8.088, rec=0.067, cos=0.001), tot_loss_proj:1.672 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.681 (perp=8.088, rec=0.062, cos=0.001), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.661 (perp=8.088, rec=0.042, cos=0.001), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.691 (perp=8.088, rec=0.072, cos=0.001), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.676 (perp=8.088, rec=0.057, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.687 (perp=8.088, rec=0.068, cos=0.001), tot_loss_proj:1.696 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.677 (perp=8.088, rec=0.058, cos=0.001), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.697 (perp=8.088, rec=0.078, cos=0.001), tot_loss_proj:1.692 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.686 (perp=8.088, rec=0.067, cos=0.001), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.689 (perp=8.088, rec=0.070, cos=0.001), tot_loss_proj:1.686 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.679 (perp=8.088, rec=0.060, cos=0.001), tot_loss_proj:1.686 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.662 (perp=8.088, rec=0.043, cos=0.001), tot_loss_proj:1.686 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.685 (perp=8.088, rec=0.066, cos=0.001), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.692 (perp=8.088, rec=0.073, cos=0.001), tot_loss_proj:1.700 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.693 (perp=8.088, rec=0.074, cos=0.002), tot_loss_proj:1.691 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.682 (perp=8.088, rec=0.063, cos=0.001), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.668 (perp=8.088, rec=0.049, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.685 (perp=8.088, rec=0.066, cos=0.001), tot_loss_proj:1.696 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.685 (perp=8.088, rec=0.066, cos=0.001), tot_loss_proj:1.685 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.688 (perp=8.088, rec=0.069, cos=0.001), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.683 (perp=8.088, rec=0.064, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.676 (perp=8.088, rec=0.057, cos=0.001), tot_loss_proj:1.689 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.678 (perp=8.088, rec=0.059, cos=0.001), tot_loss_proj:1.701 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.659 (perp=8.088, rec=0.040, cos=0.001), tot_loss_proj:1.685 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.682 (perp=8.088, rec=0.063, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.681 (perp=8.088, rec=0.062, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.679 (perp=8.088, rec=0.060, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 185.714

input #6 time: 0:09:36 | total time: 1:05:04


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.99917817891147
highest_index [0]
highest [0.99917817891147]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9091315269470215 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8410571217536926 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8275896310806274 for ['[CLS] minor bonnetmme near routine cluster confirmed pray mail guy smooth us empty bleeding interior [CLS] relegated seen tapes in beast risk contributingds addedores [SEP]']
[Init] best rec loss: 0.7972196936607361 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best perm rec loss: 0.7952162623405457 for ['[CLS] dependingzed alec disease battalion tourism none consisting sony pacific main moffat animal on manual career classicside mukherjee madagascar 17th blow rannies gold life [SEP]']
[Init] best perm rec loss: 0.7940846085548401 for ['[CLS] classics tourism alec depending gold ran manual pacific nonezed battalion career sony main 17th moffat disease mukherjee madagascar animalide consisting on life blownies [SEP]']
[Init] best perm rec loss: 0.7933159470558167 for ['[CLS] diseasenies life sony manual career moffat depending classics consisting main blow gold 17thide animal mukherjee ran battalion nonezed on alec pacific tourism madagascar [SEP]']
[Init] best perm rec loss: 0.7899006605148315 for ['[CLS] blow mukherjee none battalion moffat dependingzed gold 17th ran consistingnies career manual sony madagascaride disease tourism alec pacific classics animal life main on [SEP]']
[Init] best perm rec loss: 0.7890241742134094 for ['[CLS] madagascar disease main depending mukherjee tourism blownies consisting sony animal gold pacific onzed alec moffat battalion none manual life career classics ranide 17th [SEP]']
[Init] best perm rec loss: 0.7871341705322266 for ['[CLS] on sony diseasenies 17th manualide ran madagascarzed gold animal life mukherjee main battalion none classics moffat tourism career blow alec depending pacific consisting [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.468 (perp=10.559, rec=0.337, cos=0.019), tot_loss_proj:3.834 [t=0.24s]
prediction: ['[CLS] security nobody problem. dating charles accidentlike information no ugly nasty orrat bass issue noety problems or. military estate ( government fraud [SEP]']
[ 100/2000] tot_loss=2.114 (perp=9.268, rec=0.254, cos=0.007), tot_loss_proj:3.741 [t=0.25s]
prediction: ['[CLS] character no problem is dating he truth harbor character no ugly ugly or is problem : no stair problem or. lifestyle estate interests judgeable [SEP]']
[ 150/2000] tot_loss=2.107 (perp=9.459, rec=0.210, cos=0.005), tot_loss_proj:3.750 [t=0.25s]
prediction: ['[CLS] character no problem is dating he truth sorts character no ugly ugly or is problem. no nothing problem without. only cutename isable [SEP]']
[ 200/2000] tot_loss=2.079 (perp=9.473, rec=0.181, cos=0.004), tot_loss_proj:3.736 [t=0.25s]
prediction: ['[CLS] character no problem is badly he truth hundred character no ugly ugly or is problem ; no no problem without. character cute love ;able [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.042 (perp=9.302, rec=0.178, cos=0.003), tot_loss_proj:3.718 [t=0.25s]
prediction: ['[CLS] cute no problem is not he factor hundred character no ugly ugly or is mind ; no ; problem without. love cuteable ; stitches [SEP]']
[ 300/2000] tot_loss=2.139 (perp=9.853, rec=0.165, cos=0.003), tot_loss_proj:3.845 [t=0.25s]
prediction: ['[CLS] cute no problem is not he factor sorts character no ugly loved or is mind mind no ; problemable. love cuteable ; i [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.023 (perp=9.325, rec=0.155, cos=0.003), tot_loss_proj:3.750 [t=0.25s]
prediction: ['[CLS] cute no problem is here he sorts factor character no ugly loved or is mind mind no ; factor not. love cuteable ; i [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.948 (perp=8.619, rec=0.214, cos=0.010), tot_loss_proj:3.602 [t=0.25s]
prediction: ['[CLS] cute no problem is here he yeah factor mind no ugly not factor mind character. no ; has not. love cuteable is i [SEP]']
[ 450/2000] tot_loss=1.825 (perp=8.284, rec=0.164, cos=0.004), tot_loss_proj:3.514 [t=0.25s]
prediction: ['[CLS] cute no problem is here he really factor mind no ugly not factor mind character. no ; feeling not. just cuteable is i [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.804 (perp=8.250, rec=0.151, cos=0.003), tot_loss_proj:3.521 [t=0.25s]
prediction: ['[CLS] i no problem is here he really factor mind no ugly not factor mind character or no ; having not. love cuteable ; cute [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.753 (perp=8.053, rec=0.139, cos=0.003), tot_loss_proj:3.488 [t=0.25s]
prediction: ['[CLS] i no problem is here he really factor loved no ugly or the mind character or no ; having not. love cuteable ; cute [SEP]']
[ 600/2000] tot_loss=1.784 (perp=8.279, rec=0.126, cos=0.002), tot_loss_proj:3.503 [t=0.25s]
prediction: ['[CLS] i no problem is here he really factor loved no ugly or the mind character or no ; has not. love cuteable has cute [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.750 (perp=8.127, rec=0.122, cos=0.003), tot_loss_proj:3.439 [t=0.25s]
prediction: ['[CLS] i no problem is here he really cute loved no ugly or the mind character or no ; having not. love factorable has cute [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.663 (perp=7.709, rec=0.118, cos=0.003), tot_loss_proj:3.227 [t=0.24s]
prediction: ['[CLS] i no problem is here he really loved cute not ugly or the mind character or no ; having love. love factorable has cute [SEP]']
[ 750/2000] tot_loss=1.661 (perp=7.709, rec=0.116, cos=0.003), tot_loss_proj:3.230 [t=0.25s]
prediction: ['[CLS] i no problem is here he really loved cute not ugly or the mind character or no ; having love. love factorable has cute [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.561 (perp=7.221, rec=0.114, cos=0.003), tot_loss_proj:3.107 [t=0.25s]
prediction: ['[CLS] i no problem is here he really love cute not ugly or the mind character or no ; having loveable love factor. has cute [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.547 (perp=7.174, rec=0.110, cos=0.003), tot_loss_proj:3.125 [t=0.25s]
prediction: ['[CLS] i no problem is here he really love cute not ugly or the mind or character no ; having loveable love factor. has cute [SEP]']
[ 900/2000] tot_loss=1.548 (perp=7.174, rec=0.111, cos=0.002), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] i no problem is here he really love cute not ugly or the mind or character no ; having loveable love factor. has cute [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.508 (perp=6.995, rec=0.107, cos=0.002), tot_loss_proj:3.210 [t=0.25s]
prediction: ['[CLS] i no problem is here he really love cute not ugly or the mind or character no ; having loveable love factor cute has. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.469 (perp=6.805, rec=0.105, cos=0.003), tot_loss_proj:3.211 [t=0.24s]
prediction: ['[CLS] i no problem is here he really love cute or not ugly the mind or character no ; having loveable love factor cute has. [SEP]']
[1050/2000] tot_loss=1.465 (perp=6.805, rec=0.102, cos=0.002), tot_loss_proj:3.214 [t=0.25s]
prediction: ['[CLS] i no problem is here he really love cute or not ugly the mind or character no ; having loveable love factor cute has. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.460 (perp=6.805, rec=0.097, cos=0.002), tot_loss_proj:3.211 [t=0.24s]
prediction: ['[CLS] i no problem is here he really love cute or not ugly the mind or character no ; having loveable love factor cute has. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.472 (perp=6.805, rec=0.109, cos=0.002), tot_loss_proj:3.214 [t=0.24s]
prediction: ['[CLS] i no problem is here he really love cute or not ugly the mind or character no ; having loveable love factor cute has. [SEP]']
[1200/2000] tot_loss=1.463 (perp=6.805, rec=0.100, cos=0.002), tot_loss_proj:3.212 [t=0.24s]
prediction: ['[CLS] i no problem is here he really love cute or not ugly the mind or character no ; having loveable love factor cute has. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.461 (perp=6.805, rec=0.098, cos=0.002), tot_loss_proj:3.212 [t=0.25s]
prediction: ['[CLS] i no problem is here he really love cute or not ugly the mind or character no ; having loveable love factor cute has. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.469 (perp=6.805, rec=0.106, cos=0.002), tot_loss_proj:3.207 [t=0.24s]
prediction: ['[CLS] i no problem is here he really love cute or not ugly the mind or character no ; having loveable love factor cute has. [SEP]']
[1350/2000] tot_loss=1.461 (perp=6.805, rec=0.098, cos=0.002), tot_loss_proj:3.208 [t=0.24s]
prediction: ['[CLS] i no problem is here he really love cute or not ugly the mind or character no ; having loveable love factor cute has. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.413 (perp=6.598, rec=0.092, cos=0.002), tot_loss_proj:3.142 [t=0.25s]
prediction: ['[CLS] i no problem is here he really love cute or not ugly the mind or no character ; having loveable love factor cute has. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.417 (perp=6.556, rec=0.104, cos=0.002), tot_loss_proj:2.996 [t=0.24s]
prediction: ['[CLS] he no problem is here i really love cute or not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
[1500/2000] tot_loss=1.422 (perp=6.593, rec=0.101, cos=0.002), tot_loss_proj:3.068 [t=0.25s]
prediction: ['[CLS] he no problem is here i really love cute or not ugly the mind, no character ; the loveable love factor cute has. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.379 (perp=6.396, rec=0.098, cos=0.002), tot_loss_proj:2.890 [t=0.24s]
prediction: ['[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.379 (perp=6.396, rec=0.097, cos=0.002), tot_loss_proj:2.892 [t=0.25s]
prediction: ['[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
[1650/2000] tot_loss=1.379 (perp=6.396, rec=0.098, cos=0.002), tot_loss_proj:2.890 [t=0.24s]
prediction: ['[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.378 (perp=6.396, rec=0.097, cos=0.002), tot_loss_proj:2.894 [t=0.25s]
prediction: ['[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.376 (perp=6.396, rec=0.095, cos=0.002), tot_loss_proj:2.890 [t=0.24s]
prediction: ['[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
[1800/2000] tot_loss=1.371 (perp=6.396, rec=0.090, cos=0.002), tot_loss_proj:2.892 [t=0.24s]
prediction: ['[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.372 (perp=6.396, rec=0.091, cos=0.002), tot_loss_proj:2.892 [t=0.25s]
prediction: ['[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.376 (perp=6.396, rec=0.095, cos=0.002), tot_loss_proj:2.890 [t=0.25s]
prediction: ['[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
[1950/2000] tot_loss=1.366 (perp=6.396, rec=0.085, cos=0.002), tot_loss_proj:2.891 [t=0.24s]
prediction: ['[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.377 (perp=6.396, rec=0.096, cos=0.002), tot_loss_proj:2.890 [t=0.25s]
prediction: ['[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] he no problem is here i really love cute, not ugly the mind or no character ; the loveable love factor cute has. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.444 | p: 79.167 | r: 90.476
rouge2     | fm: 13.953 | p: 13.043 | r: 15.000
rougeL     | fm: 44.444 | p: 41.667 | r: 47.619
rougeLsum  | fm: 44.444 | p: 41.667 | r: 47.619
r1fm+r2fm = 98.398

[Aggregate metrics]:
rouge1     | fm: 98.056 | p: 97.396 | r: 98.810
rouge2     | fm: 76.744 | p: 76.630 | r: 76.875
rougeL     | fm: 89.931 | p: 89.583 | r: 90.327
rougeLsum  | fm: 89.931 | p: 89.583 | r: 90.327
r1fm+r2fm = 174.800

input #7 time: 0:10:00 | total time: 1:15:05


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.999402751418655
highest_index [0]
highest [0.999402751418655]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.752513587474823 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7108113169670105 for ['[CLS] assassins able a bowled palace times drive camequal happens silver only foreign shelley pumping nbc camp easy payyo bigutounded meaning [SEP]']
[Init] best rec loss: 0.6920523047447205 for ['[CLS]dry pace hash mike parker guard defence disease relief studentquest steiner downdin dance domain briefly crystal beech reason newcastle kai prenostic [SEP]']
[Init] best rec loss: 0.6836101412773132 for ['[CLS] air namely fourjun nkend neitherdf rich ; bit healthcare formula noon abdul drill parks pr daylight longitude tent milo usaas [SEP]']
[Init] best rec loss: 0.674540102481842 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.671164333820343 for ['[CLS] eisenhower plaque arkansas screens sweat adventuremei wanda productey dna prison canontta tail franchise facts res si february season sociallydent badminton [SEP]']
[Init] best perm rec loss: 0.6662924885749817 for ['[CLS]dentey simei sweat franchise arkansas plaque facts canon february product res badminton screens adventuretta socially wanda prison eisenhower season tail dna [SEP]']
[Init] best perm rec loss: 0.6620703935623169 for ['[CLS] tail adventure plaquedent facts badminton arkansas dna season canon product screenseytta wanda franchise sweat february socially si eisenhowermei res prison [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.070 (perp=12.982, rec=0.403, cos=0.070), tot_loss_proj:4.453 [t=0.24s]
prediction: ['[CLS]feit o plate department interventiondition vanity per drages against stage prep injury victim were least victim how supposed supply threat rep tax [SEP]']
[ 100/2000] tot_loss=2.757 (perp=12.197, rec=0.300, cos=0.017), tot_loss_proj:4.376 [t=0.24s]
prediction: ['[CLS]feit de drug department interventiondition vanity pays debtes against stage demand debt prank shows what federale bug reports threat debt money [SEP]']
[ 150/2000] tot_loss=2.741 (perp=12.297, rec=0.262, cos=0.019), tot_loss_proj:4.111 [t=0.24s]
prediction: ['[CLS] ship daless wildlife vanity japan vanity pays doubtsta worst stage off debt conservation races what victim s were owed crimes debt debt [SEP]']
[ 200/2000] tot_loss=2.806 (perp=12.868, rec=0.218, cos=0.015), tot_loss_proj:4.097 [t=0.24s]
prediction: ['[CLS] vanity daless film shortlisted destruction vanity pays doubt a worst stage off debt conservation million what film s humans owed crimes debt debt [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.737 (perp=12.633, rec=0.199, cos=0.011), tot_loss_proj:4.263 [t=0.24s]
prediction: ['[CLS] what frightless film shortlisted failure vanity pays doubt a no stage off debt prank felt vanity film srangle owed cruiser debt debt [SEP]']
[ 300/2000] tot_loss=2.312 (perp=10.772, rec=0.152, cos=0.005), tot_loss_proj:3.373 [t=0.24s]
prediction: ['[CLS] what frightful film shortlisted mental vanity pays doubt, no stage off debt liberation felt vanity film s benign owed crimes debt debt [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.373 (perp=11.153, rec=0.136, cos=0.006), tot_loss_proj:3.523 [t=0.24s]
prediction: ['[CLS] what frightful filmmax mental vanity pays doubt that no stage off debt liberation felt vanity film s benign debt owed crimes debt [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.410 (perp=11.359, rec=0.133, cos=0.006), tot_loss_proj:3.606 [t=0.24s]
prediction: ['[CLS] what frightful vanitymax vanity film pays doubt that norogate offbeat liberation felt vanity film s benign debt owed crimes debt [SEP]']
[ 450/2000] tot_loss=2.407 (perp=11.434, rec=0.117, cos=0.003), tot_loss_proj:3.638 [t=0.24s]
prediction: ['[CLS] what frightful vanitymax vanity film pays doubt that norogate offbeat liberation felt vanity film s benign debt owedi debt [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.354 (perp=11.166, rec=0.118, cos=0.003), tot_loss_proj:3.496 [t=0.24s]
prediction: ['[CLS] what frightful vanity film vanity film pays doubt that norogate offbeat environmental felt vanitymax s benign debt owedi debt [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.332 (perp=11.026, rec=0.120, cos=0.006), tot_loss_proj:3.584 [t=0.24s]
prediction: ['[CLS] what frightful vanity film vanity film pays doubt that norogate offbeat felt vanitymax s benign debt owed alreadyi debt [SEP]']
[ 600/2000] tot_loss=2.327 (perp=11.059, rec=0.112, cos=0.003), tot_loss_proj:3.549 [t=0.24s]
prediction: ['[CLS] what frightful vanity film vanity film pays doubt that norogate off, felt vanitymax s benign debt owed alreadyi debt [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.265 (perp=10.761, rec=0.110, cos=0.002), tot_loss_proj:3.321 [t=0.24s]
prediction: ['[CLS] what frightful vanity film vanity film pays doubt that norogate off, felt vanitymax s debt owed ‚ benigni debt [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.061 (perp=9.768, rec=0.104, cos=0.003), tot_loss_proj:3.097 [t=0.24s]
prediction: ['[CLS] what frightful vanity film vanity film pays that no doubt, off, felt vanitymax s debt owed ‚ benigni debt [SEP]']
[ 750/2000] tot_loss=2.055 (perp=9.768, rec=0.100, cos=0.002), tot_loss_proj:3.097 [t=0.24s]
prediction: ['[CLS] what frightful vanity film vanity film pays that no doubt, off, felt vanitymax s debt owed ‚ benigni debt [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.993 (perp=9.479, rec=0.095, cos=0.002), tot_loss_proj:2.936 [t=0.24s]
prediction: ['[CLS] what frightful vanity film vanity film pays that no doubt, off debt felt vanitymax s debt owed ‚ benigni, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.993 (perp=9.479, rec=0.095, cos=0.002), tot_loss_proj:2.933 [t=0.24s]
prediction: ['[CLS] what frightful vanity film vanity film pays that no doubt, off debt felt vanitymax s debt owed ‚ benigni, [SEP]']
[ 900/2000] tot_loss=1.990 (perp=9.479, rec=0.093, cos=0.002), tot_loss_proj:2.929 [t=0.24s]
prediction: ['[CLS] what frightful vanity film vanity film pays that no doubt, off debt felt vanitymax s debt owed ‚ benigni, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.994 (perp=9.479, rec=0.096, cos=0.002), tot_loss_proj:2.926 [t=0.24s]
prediction: ['[CLS] what frightful vanity film vanity film pays that no doubt, off debt felt vanitymax s debt owed ‚ benigni, [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.371 (perp=9.838, rec=0.300, cos=0.103), tot_loss_proj:2.875 [t=0.24s]
prediction: ['[CLS] what frightful vanity filmevich film pays that no doubt, off debt felt,max s debt owed faced benigni, [SEP]']
[1050/2000] tot_loss=2.171 (perp=9.838, rec=0.183, cos=0.021), tot_loss_proj:2.870 [t=0.24s]
prediction: ['[CLS] what frightful vanity filmevich film pays that no doubt, off debt felt,max s debt owed faced benigni, [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.037 (perp=9.342, rec=0.156, cos=0.012), tot_loss_proj:2.884 [t=0.24s]
prediction: ['[CLS] what frightful vanity film, film pays that no doubt, off debt feltevichmax s debt owed faced benigni, [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.978 (perp=9.128, rec=0.142, cos=0.010), tot_loss_proj:2.779 [t=0.24s]
prediction: ['[CLS] what frightful vanity film, film pays that no doubt, off debt feltevichmax s debt owed benigni faced, [SEP]']
[1200/2000] tot_loss=2.030 (perp=9.434, rec=0.135, cos=0.008), tot_loss_proj:2.947 [t=0.24s]
prediction: ['[CLS] what frightful vanity film, film pays that no doubt, off debt feltevichmax s debt owed benigni vanity, [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.945 (perp=9.002, rec=0.137, cos=0.008), tot_loss_proj:2.839 [t=0.24s]
prediction: ['[CLS] s frightful vanity film, film pays that no doubt, off debt feltevichmax what debt owed benigni vanity, [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.888 (perp=8.789, rec=0.122, cos=0.007), tot_loss_proj:2.817 [t=0.24s]
prediction: ['[CLS] s frightful vanity film, film pays that no doubt, off debt feltevichmax persona debt owed benigni what, [SEP]']
[1350/2000] tot_loss=1.884 (perp=8.789, rec=0.120, cos=0.006), tot_loss_proj:2.814 [t=0.24s]
prediction: ['[CLS] s frightful vanity film, film pays that no doubt, off debt feltevichmax persona debt owed benigni what, [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.867 (perp=8.669, rec=0.128, cos=0.006), tot_loss_proj:2.784 [t=0.24s]
prediction: ['[CLS] s frightful vanity treats, film pays that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.835 (perp=8.554, rec=0.119, cos=0.005), tot_loss_proj:2.637 [t=0.24s]
prediction: ['[CLS] s frightful vanity treats film, pays that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
[1500/2000] tot_loss=1.832 (perp=8.554, rec=0.117, cos=0.004), tot_loss_proj:2.638 [t=0.24s]
prediction: ['[CLS] s frightful vanity treats film, pays that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.822 (perp=8.532, rec=0.112, cos=0.004), tot_loss_proj:2.570 [t=0.24s]
prediction: ['[CLS] s frightful vanity pays film, treats that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.822 (perp=8.532, rec=0.112, cos=0.004), tot_loss_proj:2.573 [t=0.24s]
prediction: ['[CLS] s frightful vanity pays film, treats that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
[1650/2000] tot_loss=1.826 (perp=8.532, rec=0.116, cos=0.004), tot_loss_proj:2.571 [t=0.24s]
prediction: ['[CLS] s frightful vanity pays film, treats that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.803 (perp=8.431, rec=0.114, cos=0.004), tot_loss_proj:2.701 [t=0.24s]
prediction: ['[CLS] s frightful vanity pays, film treats that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.798 (perp=8.431, rec=0.108, cos=0.003), tot_loss_proj:2.699 [t=0.24s]
prediction: ['[CLS] s frightful vanity pays, film treats that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
[1800/2000] tot_loss=1.795 (perp=8.431, rec=0.106, cos=0.003), tot_loss_proj:2.704 [t=0.24s]
prediction: ['[CLS] s frightful vanity pays, film treats that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.777 (perp=8.356, rec=0.102, cos=0.003), tot_loss_proj:2.536 [t=0.24s]
prediction: ['[CLS] s frightful vanity, pays film treats that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.783 (perp=8.356, rec=0.109, cos=0.003), tot_loss_proj:2.538 [t=0.24s]
prediction: ['[CLS] s frightful vanity, pays film treats that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
[1950/2000] tot_loss=1.775 (perp=8.356, rec=0.101, cos=0.003), tot_loss_proj:2.540 [t=0.24s]
prediction: ['[CLS] s frightful vanity, pays film treats that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.786 (perp=8.356, rec=0.112, cos=0.003), tot_loss_proj:2.541 [t=0.24s]
prediction: ['[CLS] s frightful vanity, pays film treats that no doubt, off debt feltevichmax film debt owed benigni what, [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] what frightful vanity film vanity film pays that no doubt, off debt felt vanitymax s debt owed ‚ benigni, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 26.316 | p: 26.316 | r: 26.316
rougeL     | fm: 65.000 | p: 65.000 | r: 65.000
rougeLsum  | fm: 65.000 | p: 65.000 | r: 65.000
r1fm+r2fm = 106.316

[Aggregate metrics]:
rouge1     | fm: 96.049 | p: 95.463 | r: 96.720
rouge2     | fm: 71.141 | p: 71.040 | r: 71.257
rougeL     | fm: 87.160 | p: 86.852 | r: 87.513
rougeLsum  | fm: 87.160 | p: 86.852 | r: 87.513
r1fm+r2fm = 167.190

input #8 time: 0:10:18 | total time: 1:25:23


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9993987163307133
highest_index [0]
highest [0.9993987163307133]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.8139041066169739 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.7717182636260986 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7365254759788513 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.7207859754562378 for ['[CLS] owners pad there arena da rico weekly family [SEP]']
[Init] best rec loss: 0.6855643391609192 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6805217862129211 for ['[CLS] red sh dipped in outstretched hour go imagine [SEP]']
[Init] best rec loss: 0.6490535736083984 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6489459872245789 for ['[CLS] edward arsenal luck deaths decca outlaw codydden [SEP]']
[Init] best perm rec loss: 0.6477984189987183 for ['[CLS] luck edward deaths decca arsenal outlaw codydden [SEP]']
[Init] best perm rec loss: 0.6473267078399658 for ['[CLS] edward deathsdden luck cody outlaw decca arsenal [SEP]']
[Init] best perm rec loss: 0.6464244723320007 for ['[CLS] cody luck deaths deccadden edward arsenal outlaw [SEP]']
[Init] best perm rec loss: 0.6462475657463074 for ['[CLS] arsenal deccadden deaths luck edward cody outlaw [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.787 (perp=12.597, rec=0.250, cos=0.017), tot_loss_proj:3.759 [t=0.22s]
prediction: ['[CLS] softed of toss clap shortage if drops [SEP]']
[ 100/2000] tot_loss=2.454 (perp=11.304, rec=0.185, cos=0.008), tot_loss_proj:3.083 [t=0.22s]
prediction: ['[CLS] softhead of clap clap shortage claptra [SEP]']
[ 150/2000] tot_loss=2.298 (perp=10.605, rec=0.161, cos=0.016), tot_loss_proj:3.013 [t=0.22s]
prediction: ['[CLS] softhead of clap claphead claptra [SEP]']
[ 200/2000] tot_loss=2.586 (perp=12.338, rec=0.113, cos=0.005), tot_loss_proj:3.290 [t=0.22s]
prediction: ['[CLS] softhead ofp clap metaphysical claptra [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.150 (perp=10.086, rec=0.125, cos=0.007), tot_loss_proj:2.728 [t=0.22s]
prediction: ['[CLS] softhead of claptrap clap metaphysical [SEP]']
[ 300/2000] tot_loss=2.113 (perp=10.086, rec=0.094, cos=0.002), tot_loss_proj:2.730 [t=0.22s]
prediction: ['[CLS] softhead of claptrap clap metaphysical [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.883 (perp=8.943, rec=0.093, cos=0.002), tot_loss_proj:2.572 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical claptrap clap [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.772 (perp=8.391, rec=0.091, cos=0.003), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
[ 450/2000] tot_loss=1.766 (perp=8.391, rec=0.086, cos=0.002), tot_loss_proj:2.343 [t=0.23s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.757 (perp=8.391, rec=0.077, cos=0.002), tot_loss_proj:2.325 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.759 (perp=8.391, rec=0.080, cos=0.001), tot_loss_proj:2.321 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
[ 600/2000] tot_loss=1.764 (perp=8.391, rec=0.084, cos=0.001), tot_loss_proj:2.322 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.759 (perp=8.391, rec=0.079, cos=0.002), tot_loss_proj:2.326 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.748 (perp=8.391, rec=0.069, cos=0.002), tot_loss_proj:2.320 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
[ 750/2000] tot_loss=1.755 (perp=8.391, rec=0.076, cos=0.002), tot_loss_proj:2.322 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.752 (perp=8.391, rec=0.072, cos=0.002), tot_loss_proj:2.327 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.751 (perp=8.391, rec=0.071, cos=0.001), tot_loss_proj:2.317 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
[ 900/2000] tot_loss=1.756 (perp=8.391, rec=0.076, cos=0.001), tot_loss_proj:2.319 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.757 (perp=8.391, rec=0.077, cos=0.001), tot_loss_proj:2.319 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.750 (perp=8.391, rec=0.070, cos=0.001), tot_loss_proj:2.319 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
[1050/2000] tot_loss=1.749 (perp=8.391, rec=0.069, cos=0.001), tot_loss_proj:2.321 [t=0.22s]
prediction: ['[CLS] softhead of metaphysical clap claptrap [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.676 (perp=7.973, rec=0.080, cos=0.002), tot_loss_proj:2.473 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.675 (perp=7.973, rec=0.079, cos=0.001), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1200/2000] tot_loss=1.672 (perp=7.973, rec=0.076, cos=0.001), tot_loss_proj:2.465 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.668 (perp=7.973, rec=0.072, cos=0.001), tot_loss_proj:2.469 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.672 (perp=7.973, rec=0.076, cos=0.001), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1350/2000] tot_loss=1.664 (perp=7.973, rec=0.068, cos=0.001), tot_loss_proj:2.465 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.668 (perp=7.973, rec=0.072, cos=0.001), tot_loss_proj:2.469 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.672 (perp=7.973, rec=0.076, cos=0.001), tot_loss_proj:2.469 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1500/2000] tot_loss=1.674 (perp=7.973, rec=0.078, cos=0.001), tot_loss_proj:2.470 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.672 (perp=7.973, rec=0.076, cos=0.001), tot_loss_proj:2.465 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.678 (perp=7.973, rec=0.082, cos=0.001), tot_loss_proj:2.465 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1650/2000] tot_loss=1.659 (perp=7.973, rec=0.063, cos=0.001), tot_loss_proj:2.465 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.672 (perp=7.973, rec=0.076, cos=0.001), tot_loss_proj:2.463 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.663 (perp=7.973, rec=0.067, cos=0.001), tot_loss_proj:2.467 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1800/2000] tot_loss=1.657 (perp=7.973, rec=0.061, cos=0.001), tot_loss_proj:2.466 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.664 (perp=7.973, rec=0.068, cos=0.001), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.667 (perp=7.973, rec=0.071, cos=0.001), tot_loss_proj:2.470 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
[1950/2000] tot_loss=1.669 (perp=7.973, rec=0.073, cos=0.001), tot_loss_proj:2.470 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.657 (perp=7.973, rec=0.061, cos=0.001), tot_loss_proj:2.462 [t=0.22s]
prediction: ['[CLS] claphead of metaphysical soft claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] softhead of metaphysical clap claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 18.182 | p: 16.667 | r: 20.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 95.105

[Aggregate metrics]:
rouge1     | fm: 94.137 | p: 93.060 | r: 95.381
rouge2     | fm: 66.004 | p: 65.603 | r: 66.500
rougeL     | fm: 86.329 | p: 85.595 | r: 87.333
rougeLsum  | fm: 86.329 | p: 85.476 | r: 87.262
r1fm+r2fm = 160.141

input #9 time: 0:09:14 | total time: 1:34:38


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9991463287867453
highest_index [0]
highest [0.9991463287867453]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8793880939483643 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8667941689491272 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8236117959022522 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 0.8160073757171631 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.8075990080833435 for ['[CLS] hidelin swing reacher immediately championship nervous accompaniedcar eva pounded besides help [SEP]']
[Init] best perm rec loss: 0.8071138858795166 for ['[CLS] nervous immediately hid besides pounded swing accompaniedcar help reacherelin eva championship [SEP]']
[Init] best perm rec loss: 0.806658923625946 for ['[CLS] immediately swing nervous reacher hidcar help eva accompaniedelin championship pounded besides [SEP]']
[Init] best perm rec loss: 0.8043859004974365 for ['[CLS]elin accompanied swing pounded championship nervous reacher hid eva immediately helpcar besides [SEP]']
[Init] best perm rec loss: 0.8037967681884766 for ['[CLS] eva immediately swing accompanied nervous championshipelin reachercar hid besides help pounded [SEP]']
[Init] best perm rec loss: 0.8032265901565552 for ['[CLS] accompanied swing nervous championship eva immediatelyelincar pounded hid reacher besides help [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.276 (perp=14.473, rec=0.355, cos=0.027), tot_loss_proj:4.695 [t=0.24s]
prediction: ['[CLS] cartoons rhythms suffered mcgrath monopoly styles peace justified hadley control robertx dismiss [SEP]']
[ 100/2000] tot_loss=2.839 (perp=12.648, rec=0.293, cos=0.016), tot_loss_proj:3.922 [t=0.24s]
prediction: ['[CLS] choreographed balance將 balance ab shadows unit justified charles placed johnn tack [SEP]']
[ 150/2000] tot_loss=2.732 (perp=12.566, rec=0.211, cos=0.008), tot_loss_proj:4.265 [t=0.24s]
prediction: ['[CLS] integer balancely balance ab rhythms. justifiedneasly johnns ab [SEP]']
[ 200/2000] tot_loss=2.425 (perp=11.206, rec=0.179, cos=0.005), tot_loss_proj:3.591 [t=0.24s]
prediction: ['[CLS]ulsive balancely balance ab rhythms. momentary sayingly.y ab [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.276 (perp=10.536, rec=0.165, cos=0.004), tot_loss_proj:3.194 [t=0.24s]
prediction: ['[CLS] has balancely balanceulsive rhythms.ulsiveulsiveguard.y ab [SEP]']
[ 300/2000] tot_loss=2.351 (perp=10.971, rec=0.154, cos=0.003), tot_loss_proj:2.915 [t=0.24s]
prediction: ['[CLS] has balancely balance real rhythms incidentulsiveulsiveguard.. ab [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.117 (perp=9.775, rec=0.158, cos=0.003), tot_loss_proj:3.138 [t=0.24s]
prediction: ['[CLS]ed balancely balance real with momentary incident _ rhythms or. ab [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.909 (perp=8.475, rec=0.199, cos=0.015), tot_loss_proj:2.822 [t=0.24s]
prediction: ['[CLS]s balance ably balance real incident withulsive incident rhythms ). [SEP]']
[ 450/2000] tot_loss=1.902 (perp=8.888, rec=0.121, cos=0.002), tot_loss_proj:2.810 [t=0.24s]
prediction: ['[CLS]s time ably balance real with with incident incident rhythms.. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.634 (perp=7.585, rec=0.115, cos=0.003), tot_loss_proj:2.261 [t=0.24s]
prediction: ['[CLS] real time ably balances incident withulsive incident rhythms.. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.584 (perp=7.335, rec=0.116, cos=0.002), tot_loss_proj:2.504 [t=0.24s]
prediction: ['[CLS] time ably balances incident with realulsive incident rhythms.. [SEP]']
[ 600/2000] tot_loss=1.558 (perp=7.335, rec=0.089, cos=0.002), tot_loss_proj:2.502 [t=0.24s]
prediction: ['[CLS] time ably balances incident with realulsive incident rhythms.. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.532 (perp=7.185, rec=0.093, cos=0.002), tot_loss_proj:2.444 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incidentulsive rhythms.. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.469 (perp=6.782, rec=0.110, cos=0.002), tot_loss_proj:2.422 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
[ 750/2000] tot_loss=1.441 (perp=6.782, rec=0.082, cos=0.002), tot_loss_proj:2.413 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.439 (perp=6.782, rec=0.081, cos=0.002), tot_loss_proj:2.423 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.445 (perp=6.782, rec=0.087, cos=0.002), tot_loss_proj:2.422 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
[ 900/2000] tot_loss=1.446 (perp=6.782, rec=0.088, cos=0.002), tot_loss_proj:2.419 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.441 (perp=6.782, rec=0.083, cos=0.002), tot_loss_proj:2.420 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.443 (perp=6.782, rec=0.085, cos=0.002), tot_loss_proj:2.424 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
[1050/2000] tot_loss=1.445 (perp=6.782, rec=0.087, cos=0.002), tot_loss_proj:2.420 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.446 (perp=6.782, rec=0.088, cos=0.002), tot_loss_proj:2.431 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.431 (perp=6.782, rec=0.073, cos=0.002), tot_loss_proj:2.430 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
[1200/2000] tot_loss=1.433 (perp=6.782, rec=0.075, cos=0.002), tot_loss_proj:2.424 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.438 (perp=6.782, rec=0.080, cos=0.002), tot_loss_proj:2.416 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.430 (perp=6.782, rec=0.072, cos=0.002), tot_loss_proj:2.424 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
[1350/2000] tot_loss=1.435 (perp=6.782, rec=0.077, cos=0.002), tot_loss_proj:2.425 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.436 (perp=6.782, rec=0.078, cos=0.002), tot_loss_proj:2.423 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.425 (perp=6.782, rec=0.067, cos=0.002), tot_loss_proj:2.428 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
[1500/2000] tot_loss=1.436 (perp=6.782, rec=0.077, cos=0.002), tot_loss_proj:2.424 [t=0.23s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.430 (perp=6.782, rec=0.072, cos=0.002), tot_loss_proj:2.422 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.437 (perp=6.782, rec=0.078, cos=0.002), tot_loss_proj:2.427 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
[1650/2000] tot_loss=1.431 (perp=6.782, rec=0.073, cos=0.002), tot_loss_proj:2.427 [t=0.24s]
prediction: ['[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.695 (perp=8.048, rec=0.084, cos=0.002), tot_loss_proj:2.683 [t=0.24s]
prediction: ['[CLS] time ably balancesulsive with real incident.ulsive rhythms. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.545 (perp=7.356, rec=0.072, cos=0.002), tot_loss_proj:2.524 [t=0.24s]
prediction: ['[CLS] time ably balances with real incident incident.ulsive rhythms. [SEP]']
[1800/2000] tot_loss=1.587 (perp=7.591, rec=0.067, cos=0.002), tot_loss_proj:2.551 [t=0.24s]
prediction: ['[CLS] time ably balances with realulsive incident.ulsive rhythms. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.597 (perp=7.591, rec=0.077, cos=0.002), tot_loss_proj:2.552 [t=0.24s]
prediction: ['[CLS] time ably balances with realulsive incident.ulsive rhythms. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.600 (perp=7.591, rec=0.080, cos=0.002), tot_loss_proj:2.552 [t=0.24s]
prediction: ['[CLS] time ably balances with realulsive incident.ulsive rhythms. [SEP]']
[1950/2000] tot_loss=1.599 (perp=7.591, rec=0.079, cos=0.002), tot_loss_proj:2.553 [t=0.24s]
prediction: ['[CLS] time ably balances with realulsive incident.ulsive rhythms. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.590 (perp=7.591, rec=0.070, cos=0.002), tot_loss_proj:2.547 [t=0.24s]
prediction: ['[CLS] time ably balances with realulsive incident.ulsive rhythms. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] time ably balances incident with real incident.ulsive rhythms. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 10.526 | p: 10.000 | r: 11.111
rougeL     | fm: 57.143 | p: 54.545 | r: 60.000
rougeLsum  | fm: 57.143 | p: 54.545 | r: 60.000
r1fm+r2fm = 96.241

[Aggregate metrics]:
rouge1     | fm: 93.323 | p: 92.038 | r: 94.892
rouge2     | fm: 60.972 | p: 60.577 | r: 61.350
rougeL     | fm: 83.501 | p: 82.554 | r: 84.632
rougeLsum  | fm: 83.703 | p: 82.773 | r: 84.935
r1fm+r2fm = 154.295

input #10 time: 0:09:41 | total time: 1:44:19


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9992854056069841
highest_index [0]
highest [0.9992854056069841]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.91344153881073 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8994779586791992 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.8188697099685669 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.817574679851532 for ['[CLS] familiar mile drawn tal platformgu mevdture inland [SEP]']
[Init] best perm rec loss: 0.8121586441993713 for ['[CLS]ture me mile inland platformguvd drawn tal familiar [SEP]']
[Init] best perm rec loss: 0.8105562329292297 for ['[CLS] mile me inlandvd platformturegu familiar drawn tal [SEP]']
[Init] best perm rec loss: 0.8066157102584839 for ['[CLS] inland mileture me drawn tal platformguvd familiar [SEP]']
[Init] best perm rec loss: 0.802373468875885 for ['[CLS] inlandture drawnvd platform tal mile megu familiar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.840 (perp=12.613, rec=0.299, cos=0.018), tot_loss_proj:3.777 [t=0.24s]
prediction: ['[CLS] however failed stubbornted needle tonight gel to gel refused [SEP]']
[ 100/2000] tot_loss=2.721 (perp=12.678, rec=0.177, cos=0.008), tot_loss_proj:3.705 [t=0.24s]
prediction: ['[CLS] was attempted stubborn that stubborn here refusedly gel refused [SEP]']
[ 150/2000] tot_loss=2.649 (perp=12.678, rec=0.111, cos=0.002), tot_loss_proj:3.674 [t=0.24s]
prediction: ['[CLS] was attempted stubborn that stubborn here refusedly gel refused [SEP]']
[ 200/2000] tot_loss=2.628 (perp=12.678, rec=0.090, cos=0.002), tot_loss_proj:3.670 [t=0.24s]
prediction: ['[CLS] was attempted stubborn that stubborn here refusedly gel refused [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.229 (perp=10.540, rec=0.118, cos=0.003), tot_loss_proj:3.038 [t=0.24s]
prediction: ['[CLS] was attempted stubbornly un here to that gel refused [SEP]']
[ 300/2000] tot_loss=2.109 (perp=10.107, rec=0.087, cos=0.001), tot_loss_proj:2.950 [t=0.24s]
prediction: ['[CLS] was attempted stubbornly where here to that gel refused [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.007 (perp=9.602, rec=0.086, cos=0.001), tot_loss_proj:3.108 [t=0.24s]
prediction: ['[CLS] was attempted stubbornly here to than that gel refused [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.849 (perp=8.614, rec=0.124, cos=0.003), tot_loss_proj:2.880 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly to than that gel refused [SEP]']
[ 450/2000] tot_loss=1.832 (perp=8.694, rec=0.091, cos=0.001), tot_loss_proj:2.644 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly to being that gel refused [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.828 (perp=8.694, rec=0.087, cos=0.001), tot_loss_proj:2.644 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly to being that gel refused [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.760 (perp=8.191, rec=0.117, cos=0.004), tot_loss_proj:2.375 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly to being that refused gel [SEP]']
[ 600/2000] tot_loss=1.713 (perp=8.191, rec=0.073, cos=0.001), tot_loss_proj:2.371 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly to being that refused gel [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.703 (perp=8.144, rec=0.073, cos=0.001), tot_loss_proj:2.398 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly to being refused that gel [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.471 (perp=6.997, rec=0.070, cos=0.001), tot_loss_proj:2.143 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[ 750/2000] tot_loss=1.472 (perp=6.997, rec=0.072, cos=0.001), tot_loss_proj:2.160 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.476 (perp=6.997, rec=0.076, cos=0.001), tot_loss_proj:2.152 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.477 (perp=6.997, rec=0.076, cos=0.001), tot_loss_proj:2.146 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[ 900/2000] tot_loss=1.468 (perp=6.997, rec=0.067, cos=0.001), tot_loss_proj:2.147 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.467 (perp=6.997, rec=0.066, cos=0.001), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.476 (perp=6.997, rec=0.075, cos=0.001), tot_loss_proj:2.141 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1050/2000] tot_loss=1.460 (perp=6.997, rec=0.059, cos=0.001), tot_loss_proj:2.150 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.471 (perp=6.997, rec=0.070, cos=0.001), tot_loss_proj:2.153 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.458 (perp=6.997, rec=0.057, cos=0.001), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1200/2000] tot_loss=1.452 (perp=6.997, rec=0.051, cos=0.001), tot_loss_proj:2.145 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.462 (perp=6.997, rec=0.061, cos=0.001), tot_loss_proj:2.144 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.465 (perp=6.997, rec=0.064, cos=0.001), tot_loss_proj:2.150 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1350/2000] tot_loss=1.469 (perp=6.997, rec=0.068, cos=0.001), tot_loss_proj:2.147 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.459 (perp=6.997, rec=0.058, cos=0.001), tot_loss_proj:2.147 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.462 (perp=6.997, rec=0.061, cos=0.001), tot_loss_proj:2.147 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1500/2000] tot_loss=1.473 (perp=6.997, rec=0.072, cos=0.001), tot_loss_proj:2.150 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.474 (perp=6.997, rec=0.074, cos=0.001), tot_loss_proj:2.153 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.474 (perp=6.997, rec=0.073, cos=0.001), tot_loss_proj:2.142 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1650/2000] tot_loss=1.461 (perp=6.997, rec=0.060, cos=0.001), tot_loss_proj:2.141 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.474 (perp=6.997, rec=0.073, cos=0.001), tot_loss_proj:2.145 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.452 (perp=6.997, rec=0.051, cos=0.001), tot_loss_proj:2.146 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1800/2000] tot_loss=1.465 (perp=6.997, rec=0.064, cos=0.001), tot_loss_proj:2.146 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.468 (perp=6.997, rec=0.067, cos=0.001), tot_loss_proj:2.151 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.466 (perp=6.997, rec=0.066, cos=0.001), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
[1950/2000] tot_loss=1.461 (perp=6.997, rec=0.061, cos=0.001), tot_loss_proj:2.144 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.471 (perp=6.997, rec=0.070, cos=0.001), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS] here was attempted stubbornly that being refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was attempted stubbornly that being refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 93.923 | p: 92.771 | r: 95.317
rouge2     | fm: 58.556 | p: 58.277 | r: 58.906
rougeL     | fm: 82.602 | p: 81.646 | r: 83.640
rougeLsum  | fm: 82.712 | p: 81.806 | r: 83.649
r1fm+r2fm = 152.480

input #11 time: 0:09:38 | total time: 1:53:58


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9993446475795855
highest_index [0]
highest [0.9993446475795855]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8687862157821655 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.862207293510437 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 0.799700915813446 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.77464359998703 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7713767886161804 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7438812255859375 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best perm rec loss: 0.7414798736572266 for ['[CLS] translate lay few ha series officeitas margin shades guess bethnction victoryn [SEP]']
[Init] best perm rec loss: 0.7407479882240295 for ['[CLS] ha margin series victornction beth translateitas lay shadesyn office guess few [SEP]']
[Init] best perm rec loss: 0.7403061985969543 for ['[CLS]ynnction layitas guess margin beth victor few series translate office ha shades [SEP]']
[Init] best perm rec loss: 0.7398918867111206 for ['[CLS] translate layitas margin series office bethnction shadesyn few ha guess victor [SEP]']
[Init] best perm rec loss: 0.7394150495529175 for ['[CLS] beth victoritasnction translate office shades lay fewyn margin guess ha series [SEP]']
[Init] best perm rec loss: 0.7388815879821777 for ['[CLS] victornction office series lay margin translate bethyn shades fewitas guess ha [SEP]']
[Init] best perm rec loss: 0.738705039024353 for ['[CLS] victor guessyn translate ha few shades beth series lay office marginnctionitas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.449 (perp=10.634, rec=0.288, cos=0.034), tot_loss_proj:3.335 [t=0.22s]
prediction: ['[CLS] better you any look better barely theory under himself despite apparent advantage rating cable [SEP]']
[ 100/2000] tot_loss=2.202 (perp=9.970, rec=0.193, cos=0.015), tot_loss_proj:2.949 [t=0.22s]
prediction: ['[CLS] better will his look better barely advantage at on considering potential advantage on cable [SEP]']
[ 150/2000] tot_loss=2.021 (perp=9.356, rec=0.142, cos=0.008), tot_loss_proj:2.856 [t=0.22s]
prediction: ['[CLS] better that his to better barely advantage on seen considering will advantage on cable [SEP]']
[ 200/2000] tot_loss=2.066 (perp=9.770, rec=0.107, cos=0.005), tot_loss_proj:3.101 [t=0.22s]
prediction: ['[CLS] be that a to better barely advantage on seen considering will advantage its cable [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.008 (perp=9.547, rec=0.094, cos=0.004), tot_loss_proj:2.628 [t=0.22s]
prediction: ['[CLS] be that usually to better barely advantage on seen will advantage considering its cable [SEP]']
[ 300/2000] tot_loss=1.887 (perp=9.043, rec=0.076, cos=0.003), tot_loss_proj:2.568 [t=0.22s]
prediction: ['[CLS] be that its to better barely advantage on seen will advantage considering its cable [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.874 (perp=8.956, rec=0.080, cos=0.003), tot_loss_proj:2.548 [t=0.22s]
prediction: ['[CLS] be that usually better to barely advantage on seen will advantage considering its cable [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.814 (perp=8.507, rec=0.107, cos=0.005), tot_loss_proj:2.588 [t=0.22s]
prediction: ['[CLS] be that usually better to barely advantage will seen on advantage considering its cable [SEP]']
[ 450/2000] tot_loss=1.699 (perp=8.104, rec=0.076, cos=0.003), tot_loss_proj:2.436 [t=0.22s]
prediction: ['[CLS] be that, better to barely advantage will seen on advantage considering its cable [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.742 (perp=8.295, rec=0.080, cos=0.003), tot_loss_proj:2.483 [t=0.22s]
prediction: ['[CLS] be that especially better to barely advantage will seen on cable considering its advantage [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.541 (perp=7.318, rec=0.074, cos=0.004), tot_loss_proj:2.235 [t=0.22s]
prediction: ['[CLS] that and better to barely advantage will be seen on cable considering its advantage [SEP]']
[ 600/2000] tot_loss=1.542 (perp=7.318, rec=0.076, cos=0.002), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] that and better to barely advantage will be seen on cable considering its advantage [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.517 (perp=7.178, rec=0.079, cos=0.002), tot_loss_proj:2.162 [t=0.22s]
prediction: ['[CLS], that better to barely advantage will be seen on cable considering its advantage [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.513 (perp=7.178, rec=0.075, cos=0.002), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS], that better to barely advantage will be seen on cable considering its advantage [SEP]']
[ 750/2000] tot_loss=1.516 (perp=7.178, rec=0.078, cos=0.002), tot_loss_proj:2.160 [t=0.22s]
prediction: ['[CLS], that better to barely advantage will be seen on cable considering its advantage [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.519 (perp=7.178, rec=0.081, cos=0.002), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS], that better to barely advantage will be seen on cable considering its advantage [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.507 (perp=7.178, rec=0.069, cos=0.002), tot_loss_proj:2.164 [t=0.22s]
prediction: ['[CLS], that better to barely advantage will be seen on cable considering its advantage [SEP]']
[ 900/2000] tot_loss=1.515 (perp=7.178, rec=0.078, cos=0.002), tot_loss_proj:2.166 [t=0.22s]
prediction: ['[CLS], that better to barely advantage will be seen on cable considering its advantage [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.405 (perp=6.621, rec=0.078, cos=0.002), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable, considering its advantage [SEP]']
Attempt swap
[1000/2000] tot_loss=1.398 (perp=6.621, rec=0.071, cos=0.002), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable, considering its advantage [SEP]']
[1050/2000] tot_loss=1.391 (perp=6.621, rec=0.064, cos=0.002), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable, considering its advantage [SEP]']
Attempt swap
[1100/2000] tot_loss=1.393 (perp=6.621, rec=0.066, cos=0.002), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable, considering its advantage [SEP]']
Attempt swap
[1150/2000] tot_loss=1.408 (perp=6.621, rec=0.082, cos=0.002), tot_loss_proj:2.068 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable, considering its advantage [SEP]']
[1200/2000] tot_loss=1.402 (perp=6.621, rec=0.076, cos=0.002), tot_loss_proj:2.058 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable, considering its advantage [SEP]']
Attempt swap
[1250/2000] tot_loss=1.521 (perp=7.223, rec=0.074, cos=0.002), tot_loss_proj:2.195 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Attempt swap
[1300/2000] tot_loss=1.522 (perp=7.223, rec=0.075, cos=0.002), tot_loss_proj:2.202 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
[1350/2000] tot_loss=1.520 (perp=7.223, rec=0.074, cos=0.002), tot_loss_proj:2.191 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Attempt swap
[1400/2000] tot_loss=1.521 (perp=7.223, rec=0.074, cos=0.002), tot_loss_proj:2.197 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Attempt swap
[1450/2000] tot_loss=1.530 (perp=7.223, rec=0.083, cos=0.002), tot_loss_proj:2.202 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
[1500/2000] tot_loss=1.517 (perp=7.223, rec=0.071, cos=0.002), tot_loss_proj:2.202 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Attempt swap
[1550/2000] tot_loss=1.514 (perp=7.223, rec=0.067, cos=0.002), tot_loss_proj:2.198 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Attempt swap
[1600/2000] tot_loss=1.514 (perp=7.223, rec=0.067, cos=0.002), tot_loss_proj:2.197 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
[1650/2000] tot_loss=1.517 (perp=7.223, rec=0.070, cos=0.002), tot_loss_proj:2.200 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Attempt swap
[1700/2000] tot_loss=1.518 (perp=7.223, rec=0.071, cos=0.002), tot_loss_proj:2.197 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Attempt swap
[1750/2000] tot_loss=1.514 (perp=7.223, rec=0.067, cos=0.002), tot_loss_proj:2.201 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
[1800/2000] tot_loss=1.515 (perp=7.223, rec=0.068, cos=0.002), tot_loss_proj:2.203 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Attempt swap
[1850/2000] tot_loss=1.518 (perp=7.223, rec=0.071, cos=0.002), tot_loss_proj:2.199 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Attempt swap
[1900/2000] tot_loss=1.518 (perp=7.223, rec=0.072, cos=0.002), tot_loss_proj:2.190 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
[1950/2000] tot_loss=1.512 (perp=7.223, rec=0.066, cos=0.002), tot_loss_proj:2.202 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Attempt swap
[2000/2000] tot_loss=1.527 (perp=7.223, rec=0.080, cos=0.002), tot_loss_proj:2.198 [t=0.22s]
prediction: ['[CLS] that better to barely advantage will be seen on cable especially considering its advantage [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS], that better to barely advantage will be seen on cable considering its advantage [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 35.714 | p: 35.714 | r: 35.714
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 129.048

[Aggregate metrics]:
rouge1     | fm: 93.944 | p: 92.890 | r: 95.165
rouge2     | fm: 56.231 | p: 56.009 | r: 56.607
rougeL     | fm: 81.382 | p: 80.603 | r: 82.358
rougeLsum  | fm: 81.164 | p: 80.360 | r: 82.041
r1fm+r2fm = 150.175

input #12 time: 0:09:14 | total time: 2:03:12


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9992539461450387
highest_index [0]
highest [0.9992539461450387]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8865664601325989 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8836308717727661 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.8601260781288147 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7841423749923706 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7840108871459961 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 0.7708356380462646 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 0.7580289244651794 for ['[CLS]typic malice avenue andy rightart brought [SEP]']
[Init] best rec loss: 0.7500137090682983 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best perm rec loss: 0.7499359250068665 for ['[CLS] furnace without card double experiment working corruption [SEP]']
[Init] best perm rec loss: 0.748815655708313 for ['[CLS] without corruption double working card furnace experiment [SEP]']
[Init] best perm rec loss: 0.7485044002532959 for ['[CLS] without card working furnace corruption experiment double [SEP]']
[Init] best perm rec loss: 0.7479153871536255 for ['[CLS] without working corruption double furnace card experiment [SEP]']
[Init] best perm rec loss: 0.7478422522544861 for ['[CLS] card double working furnace without experiment corruption [SEP]']
[Init] best perm rec loss: 0.7478395700454712 for ['[CLS] corruption without experiment working card double furnace [SEP]']
[Init] best perm rec loss: 0.7461642026901245 for ['[CLS] corruption card double furnace experiment without working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.492 (perp=10.740, rec=0.305, cos=0.040), tot_loss_proj:3.241 [t=0.23s]
prediction: ['[CLS] point paper thing if point flame flame [SEP]']
[ 100/2000] tot_loss=2.204 (perp=9.984, rec=0.192, cos=0.016), tot_loss_proj:3.302 [t=0.23s]
prediction: ['[CLS] point at that when into explode flame [SEP]']
[ 150/2000] tot_loss=2.146 (perp=9.859, rec=0.158, cos=0.016), tot_loss_proj:3.286 [t=0.22s]
prediction: ['[CLS] point at that when explode explode flame [SEP]']
[ 200/2000] tot_loss=2.375 (perp=11.138, rec=0.143, cos=0.005), tot_loss_proj:3.162 [t=0.22s]
prediction: ['[CLS] point at thingstion explode explode flame [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.490 (perp=11.616, rec=0.155, cos=0.011), tot_loss_proj:3.480 [t=0.22s]
prediction: ['[CLS] point things things flame explode explode thence [SEP]']
[ 300/2000] tot_loss=2.218 (perp=10.320, rec=0.148, cos=0.006), tot_loss_proj:3.027 [t=0.22s]
prediction: ['[CLS] point things things flame explode explode when [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.029 (perp=9.473, rec=0.130, cos=0.005), tot_loss_proj:2.857 [t=0.22s]
prediction: ['[CLS] point things flame things explode explode when [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.269 (perp=10.453, rec=0.167, cos=0.011), tot_loss_proj:3.047 [t=0.22s]
prediction: ['[CLS] point things flame things explode ( explode [SEP]']
[ 450/2000] tot_loss=2.003 (perp=9.340, rec=0.131, cos=0.005), tot_loss_proj:2.820 [t=0.22s]
prediction: ['[CLS] point things flame things explode when explode [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.013 (perp=9.340, rec=0.142, cos=0.004), tot_loss_proj:2.824 [t=0.22s]
prediction: ['[CLS] point things flame things explode when explode [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.856 (perp=8.659, rec=0.121, cos=0.004), tot_loss_proj:2.578 [t=0.22s]
prediction: ['[CLS] point things flame that explode when explode [SEP]']
[ 600/2000] tot_loss=1.870 (perp=8.659, rec=0.134, cos=0.004), tot_loss_proj:2.585 [t=0.22s]
prediction: ['[CLS] point things flame that explode when explode [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.853 (perp=8.659, rec=0.117, cos=0.003), tot_loss_proj:2.585 [t=0.22s]
prediction: ['[CLS] point things flame that explode when explode [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.860 (perp=8.659, rec=0.125, cos=0.003), tot_loss_proj:2.584 [t=0.22s]
prediction: ['[CLS] point things flame that explode when explode [SEP]']
[ 750/2000] tot_loss=1.864 (perp=8.659, rec=0.129, cos=0.003), tot_loss_proj:2.578 [t=0.22s]
prediction: ['[CLS] point things flame that explode when explode [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.856 (perp=8.659, rec=0.121, cos=0.003), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] point things flame that explode when explode [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.915 (perp=8.930, rec=0.126, cos=0.003), tot_loss_proj:2.719 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
[ 900/2000] tot_loss=1.908 (perp=8.930, rec=0.119, cos=0.003), tot_loss_proj:2.720 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.911 (perp=8.930, rec=0.122, cos=0.003), tot_loss_proj:2.723 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1000/2000] tot_loss=1.911 (perp=8.930, rec=0.122, cos=0.003), tot_loss_proj:2.725 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
[1050/2000] tot_loss=1.908 (perp=8.930, rec=0.119, cos=0.003), tot_loss_proj:2.716 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1100/2000] tot_loss=1.913 (perp=8.930, rec=0.124, cos=0.003), tot_loss_proj:2.725 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1150/2000] tot_loss=1.919 (perp=8.930, rec=0.130, cos=0.003), tot_loss_proj:2.717 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
[1200/2000] tot_loss=1.906 (perp=8.930, rec=0.117, cos=0.003), tot_loss_proj:2.713 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1250/2000] tot_loss=1.901 (perp=8.930, rec=0.112, cos=0.003), tot_loss_proj:2.717 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1300/2000] tot_loss=1.912 (perp=8.930, rec=0.123, cos=0.003), tot_loss_proj:2.715 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
[1350/2000] tot_loss=1.914 (perp=8.930, rec=0.126, cos=0.003), tot_loss_proj:2.720 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1400/2000] tot_loss=1.913 (perp=8.930, rec=0.124, cos=0.003), tot_loss_proj:2.722 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1450/2000] tot_loss=1.908 (perp=8.930, rec=0.119, cos=0.003), tot_loss_proj:2.718 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
[1500/2000] tot_loss=1.922 (perp=8.930, rec=0.133, cos=0.003), tot_loss_proj:2.711 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1550/2000] tot_loss=1.903 (perp=8.930, rec=0.115, cos=0.003), tot_loss_proj:2.716 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1600/2000] tot_loss=1.905 (perp=8.930, rec=0.116, cos=0.003), tot_loss_proj:2.714 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
[1650/2000] tot_loss=1.909 (perp=8.930, rec=0.121, cos=0.003), tot_loss_proj:2.715 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1700/2000] tot_loss=1.899 (perp=8.930, rec=0.110, cos=0.003), tot_loss_proj:2.717 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1750/2000] tot_loss=1.912 (perp=8.930, rec=0.124, cos=0.003), tot_loss_proj:2.716 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
[1800/2000] tot_loss=1.909 (perp=8.930, rec=0.120, cos=0.003), tot_loss_proj:2.717 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1850/2000] tot_loss=1.914 (perp=8.930, rec=0.125, cos=0.003), tot_loss_proj:2.720 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[1900/2000] tot_loss=1.913 (perp=8.930, rec=0.124, cos=0.003), tot_loss_proj:2.716 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
[1950/2000] tot_loss=1.907 (perp=8.930, rec=0.118, cos=0.003), tot_loss_proj:2.717 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Attempt swap
[2000/2000] tot_loss=1.915 (perp=8.930, rec=0.126, cos=0.003), tot_loss_proj:2.712 [t=0.22s]
prediction: ['[CLS] point things flame that explode into explode [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] point things flame that explode into explode [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 126.389

[Aggregate metrics]:
rouge1     | fm: 93.590 | p: 92.530 | r: 94.796
rouge2     | fm: 55.109 | p: 54.963 | r: 55.315
rougeL     | fm: 81.135 | p: 80.486 | r: 81.904
rougeLsum  | fm: 81.009 | p: 80.229 | r: 81.865
r1fm+r2fm = 148.699

input #13 time: 0:09:02 | total time: 2:12:14


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9993215770683852
highest_index [0]
highest [0.9993215770683852]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9575048089027405 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.939458429813385 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.923689067363739 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9127009510993958 for ['[CLS] bar these catch arms state [SEP]']
[Init] best rec loss: 0.8922421336174011 for ['[CLS] return him always kolkata frame [SEP]']
[Init] best rec loss: 0.8753606081008911 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8746199011802673 for ['[CLS] sprayed myers harold [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8732940554618835 for ['[CLS] sprayed harold myers [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8731610178947449 for ['[CLS] harold [MASK] tom myers sprayed [SEP]']
[Init] best perm rec loss: 0.8726160526275635 for ['[CLS] harold tom sprayed [MASK] myers [SEP]']
[Init] best perm rec loss: 0.872270405292511 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
[Init] best perm rec loss: 0.8718624114990234 for ['[CLS] [MASK] harold sprayed tom myers [SEP]']
[Init] best perm rec loss: 0.8703657984733582 for ['[CLS] tom [MASK] sprayed myers harold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.568 (perp=11.509, rec=0.262, cos=0.004), tot_loss_proj:2.774 [t=0.23s]
prediction: ['[CLS] mission film significantlytically intriguing [SEP]']
[ 100/2000] tot_loss=2.861 (perp=13.669, rec=0.126, cos=0.002), tot_loss_proj:3.752 [t=0.23s]
prediction: ['[CLS] canyon filmblyenia intriguing [SEP]']
[ 150/2000] tot_loss=2.865 (perp=13.853, rec=0.093, cos=0.001), tot_loss_proj:4.117 [t=0.23s]
prediction: ['[CLS] und filmblyenia intriguing [SEP]']
[ 200/2000] tot_loss=2.848 (perp=13.853, rec=0.076, cos=0.001), tot_loss_proj:4.145 [t=0.23s]
prediction: ['[CLS] und filmblyenia intriguing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.620 (perp=7.738, rec=0.071, cos=0.001), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS] undeniably film intriguing [SEP]']
[ 300/2000] tot_loss=1.606 (perp=7.738, rec=0.057, cos=0.001), tot_loss_proj:1.795 [t=0.23s]
prediction: ['[CLS] undeniably film intriguing [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.414 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.420 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.414 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.405 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.409 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.416 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.398 (perp=6.728, rec=0.051, cos=0.001), tot_loss_proj:1.418 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.398 (perp=6.728, rec=0.051, cos=0.001), tot_loss_proj:1.403 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.410 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.415 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.409 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.421 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.403 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.422 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.396 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.404 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.416 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.413 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.423 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.423 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.408 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.413 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.422 (perp=6.728, rec=0.075, cos=0.001), tot_loss_proj:1.423 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.397 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.407 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.417 (perp=6.728, rec=0.070, cos=0.001), tot_loss_proj:1.415 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.421 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.413 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.426 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.416 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.410 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.396 (perp=6.728, rec=0.049, cos=0.001), tot_loss_proj:1.415 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.394 (perp=6.728, rec=0.047, cos=0.001), tot_loss_proj:1.420 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.417 (perp=6.728, rec=0.070, cos=0.001), tot_loss_proj:1.406 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.954 | p: 93.070 | r: 95.037
rouge2     | fm: 58.277 | p: 58.003 | r: 58.496
rougeL     | fm: 82.380 | p: 81.722 | r: 83.235
rougeLsum  | fm: 82.117 | p: 81.418 | r: 83.163
r1fm+r2fm = 152.230

input #14 time: 0:09:35 | total time: 2:21:50


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9992721399802154
highest_index [0]
highest [0.9992721399802154]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9675636291503906 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.9328241348266602 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 0.9158609509468079 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.9073993563652039 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.9044149518013 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8923435807228088 for ['[CLS]che carolezard multi zone rhythmic watervating [SEP]']
[Init] best rec loss: 0.8854512572288513 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8833559155464172 for ['[CLS] 0 humanities metaphor olivia easily fetch first sweden [SEP]']
[Init] best perm rec loss: 0.8797237277030945 for ['[CLS] humanities easily metaphor 0 first fetch sweden olivia [SEP]']
[Init] best perm rec loss: 0.87762451171875 for ['[CLS] first sweden 0 metaphor fetch humanities easily olivia [SEP]']
[Init] best perm rec loss: 0.8739213347434998 for ['[CLS] first sweden 0 humanities fetch metaphor easily olivia [SEP]']
[Init] best perm rec loss: 0.873146653175354 for ['[CLS] humanities first fetch metaphor 0 olivia easily sweden [SEP]']
[Init] best perm rec loss: 0.8725970387458801 for ['[CLS] metaphor humanities 0 sweden fetch easily first olivia [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.819 (perp=12.739, rec=0.262, cos=0.009), tot_loss_proj:3.294 [t=0.23s]
prediction: ['[CLS] efficient featuringablyably millerily efficient efficient [SEP]']
[ 100/2000] tot_loss=2.588 (perp=12.033, rec=0.178, cos=0.003), tot_loss_proj:4.065 [t=0.24s]
prediction: ['[CLS]ablyecure suit chillerably efficient efficient [SEP]']
[ 150/2000] tot_loss=2.558 (perp=12.156, rec=0.124, cos=0.003), tot_loss_proj:3.415 [t=0.24s]
prediction: ['[CLS],ably suit chillerably anonymous efficient [SEP]']
[ 200/2000] tot_loss=2.206 (perp=10.561, rec=0.092, cos=0.002), tot_loss_proj:3.411 [t=0.23s]
prediction: ['[CLS], anonymous suit chillerably anonymous efficient [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.881 (perp=8.881, rec=0.103, cos=0.002), tot_loss_proj:2.597 [t=0.22s]
prediction: ['[CLS], anonymous suitably anonymous chiller efficient [SEP]']
[ 300/2000] tot_loss=2.198 (perp=10.620, rec=0.072, cos=0.002), tot_loss_proj:2.707 [t=0.22s]
prediction: ['[CLS],nte suitably anonymous chiller efficient [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.879 (perp=9.024, rec=0.073, cos=0.002), tot_loss_proj:2.388 [t=0.22s]
prediction: ['[CLS], efficient suitably anonymous chiller attributed [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.733 (perp=8.303, rec=0.071, cos=0.002), tot_loss_proj:1.925 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller attributed [SEP]']
[ 450/2000] tot_loss=1.735 (perp=8.303, rec=0.073, cos=0.001), tot_loss_proj:1.923 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller attributed [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.732 (perp=8.303, rec=0.070, cos=0.002), tot_loss_proj:1.914 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller attributed [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.736 (perp=8.303, rec=0.074, cos=0.002), tot_loss_proj:1.921 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller attributed [SEP]']
[ 600/2000] tot_loss=1.682 (perp=8.049, rec=0.070, cos=0.002), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.693 (perp=8.049, rec=0.082, cos=0.001), tot_loss_proj:1.887 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.678 (perp=8.049, rec=0.066, cos=0.001), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
[ 750/2000] tot_loss=1.686 (perp=8.049, rec=0.075, cos=0.002), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.681 (perp=8.049, rec=0.070, cos=0.001), tot_loss_proj:1.890 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.683 (perp=8.049, rec=0.072, cos=0.001), tot_loss_proj:1.903 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
[ 900/2000] tot_loss=1.693 (perp=8.049, rec=0.081, cos=0.002), tot_loss_proj:1.889 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.690 (perp=8.049, rec=0.079, cos=0.002), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[1000/2000] tot_loss=1.675 (perp=8.049, rec=0.063, cos=0.002), tot_loss_proj:1.900 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
[1050/2000] tot_loss=1.680 (perp=8.049, rec=0.069, cos=0.002), tot_loss_proj:1.898 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[1100/2000] tot_loss=1.687 (perp=8.049, rec=0.076, cos=0.002), tot_loss_proj:1.888 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[1150/2000] tot_loss=1.677 (perp=8.049, rec=0.066, cos=0.002), tot_loss_proj:1.899 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
[1200/2000] tot_loss=1.691 (perp=8.049, rec=0.080, cos=0.002), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[1250/2000] tot_loss=1.679 (perp=8.049, rec=0.068, cos=0.002), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[1300/2000] tot_loss=1.681 (perp=8.049, rec=0.069, cos=0.002), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
[1350/2000] tot_loss=1.678 (perp=8.049, rec=0.067, cos=0.002), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[1400/2000] tot_loss=1.692 (perp=8.049, rec=0.081, cos=0.002), tot_loss_proj:1.891 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[1450/2000] tot_loss=1.681 (perp=8.049, rec=0.070, cos=0.002), tot_loss_proj:1.896 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
[1500/2000] tot_loss=1.688 (perp=8.049, rec=0.077, cos=0.002), tot_loss_proj:1.892 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[1550/2000] tot_loss=1.691 (perp=8.049, rec=0.080, cos=0.002), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[1600/2000] tot_loss=1.696 (perp=8.049, rec=0.085, cos=0.002), tot_loss_proj:1.895 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
[1650/2000] tot_loss=1.687 (perp=8.049, rec=0.076, cos=0.002), tot_loss_proj:1.887 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller shady [SEP]']
Attempt swap
[1700/2000] tot_loss=1.841 (perp=8.857, rec=0.068, cos=0.002), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller taxonomic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.850 (perp=8.857, rec=0.077, cos=0.002), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller taxonomic [SEP]']
[1800/2000] tot_loss=1.842 (perp=8.857, rec=0.069, cos=0.002), tot_loss_proj:2.018 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller taxonomic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.854 (perp=8.857, rec=0.081, cos=0.002), tot_loss_proj:2.020 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller taxonomic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.852 (perp=8.857, rec=0.079, cos=0.002), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller taxonomic [SEP]']
[1950/2000] tot_loss=1.845 (perp=8.857, rec=0.072, cos=0.002), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller taxonomic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.861 (perp=8.857, rec=0.088, cos=0.002), tot_loss_proj:2.018 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller taxonomic [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] efficient, suitably anonymous chiller shady [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 72.727 | p: 66.667 | r: 80.000
rougeL     | fm: 92.308 | p: 85.714 | r: 100.000
rougeLsum  | fm: 92.308 | p: 85.714 | r: 100.000
r1fm+r2fm = 165.035

[Aggregate metrics]:
rouge1     | fm: 93.910 | p: 92.663 | r: 95.377
rouge2     | fm: 59.261 | p: 58.776 | r: 59.864
rougeL     | fm: 83.017 | p: 81.976 | r: 84.254
rougeLsum  | fm: 82.833 | p: 81.840 | r: 83.985
r1fm+r2fm = 153.171

input #15 time: 0:09:01 | total time: 2:30:52


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9993407915045383
highest_index [0]
highest [0.9993407915045383]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.020234227180481 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.9004251956939697 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7400387525558472 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.7389788627624512 for ['[CLS] alta film various slowly lordathi [SEP]']
[Init] best perm rec loss: 0.7379375100135803 for ['[CLS] alta various film lord slowlyathi [SEP]']
[Init] best perm rec loss: 0.7354840040206909 for ['[CLS]athi film lord slowly various alta [SEP]']
[Init] best perm rec loss: 0.7348273396492004 for ['[CLS] film slowly lord various altaathi [SEP]']
[Init] best perm rec loss: 0.7346431612968445 for ['[CLS] lord various film slowlyathi alta [SEP]']
[Init] best perm rec loss: 0.7346169948577881 for ['[CLS] film various lord slowly altaathi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.180 (perp=12.766, rec=0.513, cos=0.114), tot_loss_proj:3.934 [t=0.23s]
prediction: ['[CLS] appeal oriented information botanical more governorate [SEP]']
[ 100/2000] tot_loss=2.269 (perp=9.393, rec=0.351, cos=0.040), tot_loss_proj:3.487 [t=0.23s]
prediction: ['[CLS] - - information this more until [SEP]']
[ 150/2000] tot_loss=1.818 (perp=7.146, rec=0.350, cos=0.040), tot_loss_proj:2.353 [t=0.24s]
prediction: ['[CLS] and of all this more this [SEP]']
[ 200/2000] tot_loss=1.647 (perp=7.146, rec=0.202, cos=0.016), tot_loss_proj:2.322 [t=0.24s]
prediction: ['[CLS] and of all this more this [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.448 (perp=5.884, rec=0.241, cos=0.031), tot_loss_proj:2.188 [t=0.24s]
prediction: ['[CLS] and all this more of this [SEP]']
[ 300/2000] tot_loss=1.359 (perp=5.884, rec=0.170, cos=0.012), tot_loss_proj:2.023 [t=0.24s]
prediction: ['[CLS] and all this more of this [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.325 (perp=5.884, rec=0.140, cos=0.008), tot_loss_proj:2.044 [t=0.24s]
prediction: ['[CLS] and all this more of this [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.228 (perp=5.436, rec=0.133, cos=0.007), tot_loss_proj:2.238 [t=0.24s]
prediction: ['[CLS] this and all this more, [SEP]']
[ 450/2000] tot_loss=1.210 (perp=5.436, rec=0.119, cos=0.005), tot_loss_proj:2.235 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.211 (perp=5.436, rec=0.119, cos=0.004), tot_loss_proj:2.236 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.201 (perp=5.436, rec=0.110, cos=0.004), tot_loss_proj:2.231 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
[ 600/2000] tot_loss=1.199 (perp=5.436, rec=0.109, cos=0.004), tot_loss_proj:2.233 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.204 (perp=5.436, rec=0.113, cos=0.003), tot_loss_proj:2.229 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.204 (perp=5.436, rec=0.113, cos=0.003), tot_loss_proj:2.232 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
[ 750/2000] tot_loss=1.199 (perp=5.436, rec=0.108, cos=0.003), tot_loss_proj:2.233 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.198 (perp=5.436, rec=0.108, cos=0.003), tot_loss_proj:2.233 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.196 (perp=5.436, rec=0.106, cos=0.003), tot_loss_proj:2.230 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
[ 900/2000] tot_loss=1.201 (perp=5.436, rec=0.111, cos=0.003), tot_loss_proj:2.229 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.187 (perp=5.436, rec=0.097, cos=0.003), tot_loss_proj:2.231 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.197 (perp=5.436, rec=0.107, cos=0.003), tot_loss_proj:2.230 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
[1050/2000] tot_loss=1.198 (perp=5.436, rec=0.108, cos=0.003), tot_loss_proj:2.235 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.189 (perp=5.436, rec=0.100, cos=0.003), tot_loss_proj:2.229 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.189 (perp=5.436, rec=0.100, cos=0.003), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
[1200/2000] tot_loss=1.193 (perp=5.436, rec=0.103, cos=0.003), tot_loss_proj:2.228 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.190 (perp=5.436, rec=0.100, cos=0.003), tot_loss_proj:2.238 [t=0.24s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.196 (perp=5.436, rec=0.107, cos=0.003), tot_loss_proj:2.227 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
[1350/2000] tot_loss=1.187 (perp=5.436, rec=0.097, cos=0.003), tot_loss_proj:2.228 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.189 (perp=5.436, rec=0.099, cos=0.002), tot_loss_proj:2.229 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.188 (perp=5.436, rec=0.098, cos=0.002), tot_loss_proj:2.219 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
[1500/2000] tot_loss=1.186 (perp=5.436, rec=0.097, cos=0.002), tot_loss_proj:2.228 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.185 (perp=5.436, rec=0.095, cos=0.002), tot_loss_proj:2.227 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.177 (perp=5.436, rec=0.088, cos=0.002), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
[1650/2000] tot_loss=1.191 (perp=5.436, rec=0.102, cos=0.002), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.186 (perp=5.436, rec=0.097, cos=0.002), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.189 (perp=5.436, rec=0.100, cos=0.002), tot_loss_proj:2.226 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
[1800/2000] tot_loss=1.192 (perp=5.436, rec=0.103, cos=0.002), tot_loss_proj:2.220 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.180 (perp=5.436, rec=0.090, cos=0.002), tot_loss_proj:2.226 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.187 (perp=5.436, rec=0.098, cos=0.002), tot_loss_proj:2.221 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
[1950/2000] tot_loss=1.187 (perp=5.436, rec=0.098, cos=0.002), tot_loss_proj:2.225 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.193 (perp=5.436, rec=0.103, cos=0.002), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] this and all this more, [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] this and all this more, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 119.048

[Aggregate metrics]:
rouge1     | fm: 93.488 | p: 92.228 | r: 94.902
rouge2     | fm: 57.623 | p: 57.071 | r: 58.303
rougeL     | fm: 82.748 | p: 81.688 | r: 83.791
rougeLsum  | fm: 82.234 | p: 81.281 | r: 83.533
r1fm+r2fm = 151.112

input #16 time: 0:09:40 | total time: 2:40:32


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9992298074118964
highest_index [0]
highest [0.9992298074118964]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8472551703453064 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8236850500106812 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.8234798908233643 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.8217296600341797 for ['[CLS] bit crookedus felicity york electedyre = cheese ourselves consulting [SEP]']
[Init] best rec loss: 0.8205518126487732 for ['[CLS] santa bourneity church jacence move nativeburnub early [SEP]']
[Init] best rec loss: 0.8091399073600769 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7916844487190247 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 0.7702016830444336 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 0.7585719227790833 for ['[CLS] lieutenant magazineuin miss grey marius honestly pressure saved meeting i [SEP]']
[Init] best perm rec loss: 0.753882884979248 for ['[CLS] grey lieutenant marius honestlyuin magazine i meeting pressure saved miss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.745 (perp=11.514, rec=0.391, cos=0.050), tot_loss_proj:3.882 [t=0.23s]
prediction: ['[CLS] want world imagine completely townas too thinks involved too mum [SEP]']
[ 100/2000] tot_loss=1.890 (perp=8.260, rec=0.207, cos=0.030), tot_loss_proj:2.720 [t=0.24s]
prediction: ['[CLS] want about think want think about too much about too much [SEP]']
[ 150/2000] tot_loss=1.568 (perp=7.288, rec=0.107, cos=0.003), tot_loss_proj:2.204 [t=0.24s]
prediction: ['[CLS] want to think to think about too what going too much [SEP]']
[ 200/2000] tot_loss=1.534 (perp=7.288, rec=0.074, cos=0.002), tot_loss_proj:2.205 [t=0.24s]
prediction: ['[CLS] want to think to think about too what going too much [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.378 (perp=6.433, rec=0.089, cos=0.003), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] want to think too to think about what going too much [SEP]']
[ 300/2000] tot_loss=1.355 (perp=6.433, rec=0.067, cos=0.002), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] want to think too to think about what going too much [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.268 (perp=5.975, rec=0.072, cos=0.002), tot_loss_proj:1.860 [t=0.22s]
prediction: ['[CLS] want to think too to think about what too much going [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.406 (perp=6.661, rec=0.072, cos=0.002), tot_loss_proj:2.574 [t=0.22s]
prediction: ['[CLS] want to think too to think about what going much on [SEP]']
[ 450/2000] tot_loss=1.402 (perp=6.661, rec=0.068, cos=0.002), tot_loss_proj:2.572 [t=0.22s]
prediction: ['[CLS] want to think too to think about what going much on [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.201 (perp=5.632, rec=0.073, cos=0.002), tot_loss_proj:1.832 [t=0.28s]
prediction: ['[CLS] want to think too to think much about what going on [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.200 (perp=5.632, rec=0.071, cos=0.002), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] want to think too to think much about what going on [SEP]']
[ 600/2000] tot_loss=1.184 (perp=5.632, rec=0.056, cos=0.002), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS] want to think too to think much about what going on [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.102 (perp=5.173, rec=0.066, cos=0.002), tot_loss_proj:1.466 [t=0.22s]
prediction: ['[CLS] want to think too much to think about what going on [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.112 (perp=5.173, rec=0.076, cos=0.002), tot_loss_proj:1.449 [t=0.22s]
prediction: ['[CLS] want to think too much to think about what going on [SEP]']
[ 750/2000] tot_loss=1.097 (perp=5.173, rec=0.061, cos=0.002), tot_loss_proj:1.455 [t=0.22s]
prediction: ['[CLS] want to think too much to think about what going on [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.109 (perp=5.173, rec=0.073, cos=0.002), tot_loss_proj:1.452 [t=0.22s]
prediction: ['[CLS] want to think too much to think about what going on [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.098 (perp=5.173, rec=0.062, cos=0.002), tot_loss_proj:1.455 [t=0.22s]
prediction: ['[CLS] want to think too much to think about what going on [SEP]']
[ 900/2000] tot_loss=1.355 (perp=6.398, rec=0.074, cos=0.002), tot_loss_proj:1.917 [t=0.22s]
prediction: ["[CLS] want'think too much to think about what going on [SEP]"]
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.213 (perp=5.700, rec=0.072, cos=0.002), tot_loss_proj:1.592 [t=0.22s]
prediction: ["[CLS] want to think'think too much about what going on [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.163 (perp=5.482, rec=0.065, cos=0.002), tot_loss_proj:1.305 [t=0.22s]
prediction: ['[CLS] want to think think too much about what s going on [SEP]']
[1050/2000] tot_loss=1.166 (perp=5.482, rec=0.068, cos=0.002), tot_loss_proj:1.308 [t=0.22s]
prediction: ['[CLS] want to think think too much about what s going on [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.165 (perp=5.482, rec=0.067, cos=0.002), tot_loss_proj:1.318 [t=0.22s]
prediction: ['[CLS] want to think think too much about what s going on [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.069 (perp=5.015, rec=0.064, cos=0.002), tot_loss_proj:1.332 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
[1200/2000] tot_loss=1.065 (perp=5.015, rec=0.060, cos=0.002), tot_loss_proj:1.323 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1250/2000] tot_loss=1.071 (perp=5.015, rec=0.067, cos=0.002), tot_loss_proj:1.319 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1300/2000] tot_loss=1.081 (perp=5.015, rec=0.076, cos=0.002), tot_loss_proj:1.325 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
[1350/2000] tot_loss=1.062 (perp=5.015, rec=0.058, cos=0.002), tot_loss_proj:1.316 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1400/2000] tot_loss=1.074 (perp=5.015, rec=0.069, cos=0.002), tot_loss_proj:1.314 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1450/2000] tot_loss=1.067 (perp=5.015, rec=0.063, cos=0.002), tot_loss_proj:1.312 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
[1500/2000] tot_loss=1.061 (perp=5.015, rec=0.056, cos=0.002), tot_loss_proj:1.317 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1550/2000] tot_loss=1.070 (perp=5.015, rec=0.066, cos=0.002), tot_loss_proj:1.318 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1600/2000] tot_loss=1.070 (perp=5.015, rec=0.065, cos=0.002), tot_loss_proj:1.320 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
[1650/2000] tot_loss=1.070 (perp=5.015, rec=0.066, cos=0.002), tot_loss_proj:1.309 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1700/2000] tot_loss=1.078 (perp=5.015, rec=0.073, cos=0.002), tot_loss_proj:1.311 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1750/2000] tot_loss=1.067 (perp=5.015, rec=0.062, cos=0.002), tot_loss_proj:1.318 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
[1800/2000] tot_loss=1.066 (perp=5.015, rec=0.061, cos=0.002), tot_loss_proj:1.319 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1850/2000] tot_loss=1.070 (perp=5.015, rec=0.065, cos=0.002), tot_loss_proj:1.314 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[1900/2000] tot_loss=1.075 (perp=5.015, rec=0.070, cos=0.002), tot_loss_proj:1.305 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
[1950/2000] tot_loss=1.070 (perp=5.015, rec=0.066, cos=0.002), tot_loss_proj:1.312 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Attempt swap
[2000/2000] tot_loss=1.065 (perp=5.015, rec=0.061, cos=0.002), tot_loss_proj:1.311 [t=0.22s]
prediction: ['[CLS] think want to think too much about what s going on [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] think want to think too much about what s going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 86.957 | p: 83.333 | r: 90.909
rougeL     | fm: 96.000 | p: 92.308 | r: 100.000
rougeLsum  | fm: 96.000 | p: 92.308 | r: 100.000
r1fm+r2fm = 182.957

[Aggregate metrics]:
rouge1     | fm: 93.531 | p: 92.128 | r: 95.123
rouge2     | fm: 58.784 | p: 57.890 | r: 59.527
rougeL     | fm: 83.306 | p: 82.093 | r: 84.749
rougeLsum  | fm: 83.139 | p: 81.934 | r: 84.481
r1fm+r2fm = 152.315

input #17 time: 0:09:32 | total time: 2:50:04


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9993190368282765
highest_index [0]
highest [0.9993190368282765]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9812633991241455 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9802066087722778 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.9420520067214966 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9321717023849487 for ['[CLS] deportivo suspect usual aston [SEP]']
[Init] best rec loss: 0.9248862266540527 for ['[CLS] water global accreditation originally [SEP]']
[Init] best rec loss: 0.8890918493270874 for ['[CLS] press lose hunger tracks [SEP]']
[Init] best rec loss: 0.8745237588882446 for ['[CLS] affectionately character hundreds team [SEP]']
[Init] best rec loss: 0.8682559132575989 for ['[CLS] oniest α department [SEP]']
[Init] best rec loss: 0.8211305737495422 for ['[CLS] dual circle duodle [SEP]']
[Init] best perm rec loss: 0.8210713267326355 for ['[CLS] du dual circleodle [SEP]']
[Init] best perm rec loss: 0.8178795576095581 for ['[CLS]odle dual circle du [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.828 (perp=12.677, rec=0.285, cos=0.007), tot_loss_proj:3.977 [t=0.23s]
prediction: ['[CLS]ating christopherdened believe [SEP]']
[ 100/2000] tot_loss=2.723 (perp=12.458, rec=0.227, cos=0.005), tot_loss_proj:4.433 [t=0.24s]
prediction: ['[CLS]atinggorvigor [SEP]']
[ 150/2000] tot_loss=2.635 (perp=12.458, rec=0.141, cos=0.002), tot_loss_proj:4.434 [t=0.24s]
prediction: ['[CLS]atinggorvigor [SEP]']
[ 200/2000] tot_loss=2.747 (perp=13.166, rec=0.112, cos=0.002), tot_loss_proj:4.347 [t=0.24s]
prediction: ['[CLS]atingatingvigor [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.814 (perp=8.520, rec=0.108, cos=0.002), tot_loss_proj:2.304 [t=0.24s]
prediction: ['[CLS]atingvigorating [SEP]']
[ 300/2000] tot_loss=1.814 (perp=8.520, rec=0.108, cos=0.002), tot_loss_proj:2.291 [t=0.24s]
prediction: ['[CLS]atingvigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.808 (perp=8.520, rec=0.102, cos=0.002), tot_loss_proj:2.284 [t=0.22s]
prediction: ['[CLS]atingvigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.801 (perp=8.520, rec=0.095, cos=0.002), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS]atingvigorating [SEP]']
[ 450/2000] tot_loss=1.810 (perp=8.520, rec=0.104, cos=0.002), tot_loss_proj:2.287 [t=0.22s]
prediction: ['[CLS]atingvigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.797 (perp=8.520, rec=0.091, cos=0.002), tot_loss_proj:2.285 [t=0.22s]
prediction: ['[CLS]atingvigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.799 (perp=8.520, rec=0.093, cos=0.002), tot_loss_proj:2.289 [t=0.22s]
prediction: ['[CLS]atingvigorating [SEP]']
[ 600/2000] tot_loss=1.785 (perp=8.520, rec=0.080, cos=0.002), tot_loss_proj:2.297 [t=0.22s]
prediction: ['[CLS]atingvigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.406 (perp=11.683, rec=0.068, cos=0.001), tot_loss_proj:4.120 [t=0.22s]
prediction: ['[CLS]atingvigor in [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.189 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.176 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.187 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.184 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.178 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.178 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.181 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.180 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.195 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.193 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.175 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.170 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.179 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.188 (perp=5.588, rec=0.069, cos=0.001), tot_loss_proj:1.171 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.170 (perp=5.588, rec=0.051, cos=0.001), tot_loss_proj:1.184 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.188 (perp=5.588, rec=0.069, cos=0.001), tot_loss_proj:1.189 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.188 (perp=5.588, rec=0.069, cos=0.001), tot_loss_proj:1.186 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.186 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.185 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.170 (perp=5.588, rec=0.051, cos=0.001), tot_loss_proj:1.187 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.171 (perp=5.588, rec=0.052, cos=0.001), tot_loss_proj:1.192 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.187 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.170 (perp=5.588, rec=0.051, cos=0.001), tot_loss_proj:1.172 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.176 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.175 (perp=5.588, rec=0.056, cos=0.001), tot_loss_proj:1.178 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.171 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.175 (perp=5.588, rec=0.056, cos=0.001), tot_loss_proj:1.168 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.195 (perp=5.588, rec=0.076, cos=0.001), tot_loss_proj:1.173 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.165 (perp=5.588, rec=0.046, cos=0.001), tot_loss_proj:1.179 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.908 | p: 92.597 | r: 95.439
rouge2     | fm: 61.306 | p: 60.622 | r: 62.097
rougeL     | fm: 84.220 | p: 83.119 | r: 85.531
rougeLsum  | fm: 84.018 | p: 82.968 | r: 85.256
r1fm+r2fm = 155.215

input #18 time: 0:08:58 | total time: 2:59:03


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.999363157298685
highest_index [0]
highest [0.999363157298685]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.772068977355957 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7611664533615112 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.7419012188911438 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7293687462806702 for ['[CLS] target jessica episode ling [SEP]']
[Init] best rec loss: 0.7094267010688782 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.6969524025917053 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6877771019935608 for ['[CLS] centers recordtion difficult [SEP]']
[Init] best rec loss: 0.6869916915893555 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.674118161201477 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 0.6444098353385925 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6434956789016724 for ['[CLS] orderyna reaching pin [SEP]']
[Init] best perm rec loss: 0.6406313180923462 for ['[CLS] pin reachingyna order [SEP]']
[Init] best perm rec loss: 0.6404289603233337 for ['[CLS] pinyna order reaching [SEP]']
[Init] best perm rec loss: 0.6399739980697632 for ['[CLS]yna order pin reaching [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.795 (perp=11.552, rec=0.396, cos=0.088), tot_loss_proj:3.342 [t=0.23s]
prediction: ['[CLS] madness violent guitar in [SEP]']
[ 100/2000] tot_loss=2.638 (perp=11.691, rec=0.258, cos=0.041), tot_loss_proj:4.195 [t=0.23s]
prediction: ['[CLS] tofafa in [SEP]']
[ 150/2000] tot_loss=2.426 (perp=11.013, rec=0.205, cos=0.019), tot_loss_proj:3.303 [t=0.23s]
prediction: ['[CLS] tofafamy [SEP]']
[ 200/2000] tot_loss=2.431 (perp=11.467, rec=0.131, cos=0.007), tot_loss_proj:3.537 [t=0.23s]
prediction: ['[CLS] tomyfamy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.096 (perp=9.747, rec=0.138, cos=0.008), tot_loss_proj:3.184 [t=0.23s]
prediction: ['[CLS] tofamymy [SEP]']
[ 300/2000] tot_loss=2.063 (perp=9.747, rec=0.108, cos=0.005), tot_loss_proj:3.189 [t=0.23s]
prediction: ['[CLS] tofamymy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.848 (perp=8.720, rec=0.099, cos=0.005), tot_loss_proj:3.250 [t=0.24s]
prediction: ['[CLS] tofamy in [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.332 (perp=6.109, rec=0.102, cos=0.008), tot_loss_proj:1.323 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.315 (perp=6.109, rec=0.087, cos=0.005), tot_loss_proj:1.312 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.307 (perp=6.109, rec=0.080, cos=0.005), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.312 (perp=6.109, rec=0.085, cos=0.005), tot_loss_proj:1.307 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.312 (perp=6.109, rec=0.085, cos=0.005), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.311 (perp=6.109, rec=0.084, cos=0.005), tot_loss_proj:1.302 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.322 (perp=6.109, rec=0.095, cos=0.005), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.311 (perp=6.109, rec=0.084, cos=0.005), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.315 (perp=6.109, rec=0.088, cos=0.005), tot_loss_proj:1.303 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.306 (perp=6.109, rec=0.080, cos=0.005), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.306 (perp=6.109, rec=0.079, cos=0.005), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.307 (perp=6.109, rec=0.080, cos=0.005), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.304 (perp=6.109, rec=0.078, cos=0.005), tot_loss_proj:1.294 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.301 (perp=6.109, rec=0.074, cos=0.005), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.313 (perp=6.109, rec=0.086, cos=0.005), tot_loss_proj:1.308 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.299 (perp=6.109, rec=0.072, cos=0.005), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.310 (perp=6.109, rec=0.083, cos=0.005), tot_loss_proj:1.308 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.294 (perp=6.109, rec=0.068, cos=0.005), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.306 (perp=6.109, rec=0.079, cos=0.005), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.300 (perp=6.109, rec=0.073, cos=0.005), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.309 (perp=6.109, rec=0.083, cos=0.005), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.300 (perp=6.109, rec=0.073, cos=0.005), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.303 (perp=6.109, rec=0.077, cos=0.005), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.314 (perp=6.109, rec=0.087, cos=0.005), tot_loss_proj:1.302 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.294 (perp=6.109, rec=0.067, cos=0.005), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.301 (perp=6.109, rec=0.074, cos=0.005), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.301 (perp=6.109, rec=0.074, cos=0.005), tot_loss_proj:1.308 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.314 (perp=6.109, rec=0.088, cos=0.005), tot_loss_proj:1.312 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.309 (perp=6.109, rec=0.082, cos=0.005), tot_loss_proj:1.309 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.305 (perp=6.109, rec=0.079, cos=0.005), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.304 (perp=6.109, rec=0.077, cos=0.005), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.299 (perp=6.109, rec=0.073, cos=0.005), tot_loss_proj:1.309 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.312 (perp=6.109, rec=0.085, cos=0.005), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.253 | p: 92.962 | r: 95.706
rouge2     | fm: 63.677 | p: 63.003 | r: 64.425
rougeL     | fm: 85.170 | p: 84.078 | r: 86.330
rougeLsum  | fm: 84.944 | p: 83.850 | r: 86.157
r1fm+r2fm = 157.929

input #19 time: 0:09:19 | total time: 3:08:23


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9992466282325256
highest_index [0]
highest [0.9992466282325256]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8128877878189087 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.7983160018920898 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7954925298690796 for ['[CLS] york match causearu [SEP]']
[Init] best rec loss: 0.7945184111595154 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.765099823474884 for ['[CLS] poorpid african forming [SEP]']
[Init] best perm rec loss: 0.7603084444999695 for ['[CLS]pid poor forming african [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.461 (perp=9.837, rec=0.408, cos=0.085), tot_loss_proj:3.485 [t=0.23s]
prediction: ['[CLS] pleasure employment pleasure pleasure [SEP]']
[ 100/2000] tot_loss=2.384 (perp=10.566, rec=0.244, cos=0.027), tot_loss_proj:2.934 [t=0.23s]
prediction: ['[CLS] pleasureverseverse pleasure [SEP]']
[ 150/2000] tot_loss=2.401 (perp=10.953, rec=0.193, cos=0.018), tot_loss_proj:2.961 [t=0.24s]
prediction: ['[CLS]verseverseverse pleasure [SEP]']
[ 200/2000] tot_loss=2.369 (perp=10.953, rec=0.163, cos=0.015), tot_loss_proj:2.957 [t=0.24s]
prediction: ['[CLS]verseverseverse pleasure [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.363 (perp=10.953, rec=0.160, cos=0.013), tot_loss_proj:2.958 [t=0.24s]
prediction: ['[CLS]verseverseverse pleasure [SEP]']
[ 300/2000] tot_loss=2.270 (perp=10.588, rec=0.137, cos=0.015), tot_loss_proj:2.670 [t=0.24s]
prediction: ['[CLS]verseverse per pleasure [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.242 (perp=10.564, rec=0.119, cos=0.010), tot_loss_proj:3.054 [t=0.22s]
prediction: ['[CLS]verse theverse pleasure [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.226 (perp=10.090, rec=0.187, cos=0.021), tot_loss_proj:2.773 [t=0.22s]
prediction: ['[CLS] theverseverse pleasure [SEP]']
[ 450/2000] tot_loss=2.145 (perp=10.090, rec=0.116, cos=0.011), tot_loss_proj:2.805 [t=0.22s]
prediction: ['[CLS] theverseverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.135 (perp=10.090, rec=0.108, cos=0.009), tot_loss_proj:2.801 [t=0.22s]
prediction: ['[CLS] theverseverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.957 (perp=9.188, rec=0.111, cos=0.009), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] perverseverse pleasure [SEP]']
[ 600/2000] tot_loss=1.950 (perp=9.188, rec=0.105, cos=0.008), tot_loss_proj:2.597 [t=0.22s]
prediction: ['[CLS] perverseverse pleasure [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.695 (perp=7.917, rec=0.104, cos=0.008), tot_loss_proj:2.581 [t=0.22s]
prediction: ['[CLS]verse perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.733 (perp=8.166, rec=0.096, cos=0.004), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] per perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.903 (perp=9.095, rec=0.081, cos=0.002), tot_loss_proj:2.304 [t=0.22s]
prediction: ['[CLS] per theverse pleasure [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.593 (perp=7.610, rec=0.069, cos=0.002), tot_loss_proj:1.700 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.609 (perp=7.610, rec=0.085, cos=0.002), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.686 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.591 (perp=7.610, rec=0.068, cos=0.002), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.593 (perp=7.610, rec=0.069, cos=0.002), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.571 (perp=7.610, rec=0.047, cos=0.002), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.680 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.597 (perp=7.610, rec=0.073, cos=0.002), tot_loss_proj:1.695 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.587 (perp=7.610, rec=0.064, cos=0.001), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.588 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.592 (perp=7.610, rec=0.068, cos=0.001), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.594 (perp=7.610, rec=0.070, cos=0.002), tot_loss_proj:1.695 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.584 (perp=7.610, rec=0.061, cos=0.002), tot_loss_proj:1.695 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.001), tot_loss_proj:1.686 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.584 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.694 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.584 (perp=7.610, rec=0.061, cos=0.001), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.585 (perp=7.610, rec=0.062, cos=0.002), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.581 (perp=7.610, rec=0.058, cos=0.002), tot_loss_proj:1.698 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.588 (perp=7.610, rec=0.065, cos=0.002), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.576 (perp=7.610, rec=0.053, cos=0.002), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.590 (perp=7.610, rec=0.067, cos=0.002), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.588 (perp=7.610, rec=0.065, cos=0.001), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.572 (perp=7.610, rec=0.048, cos=0.001), tot_loss_proj:1.694 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.592 (perp=7.610, rec=0.069, cos=0.002), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.686 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.474 | p: 93.276 | r: 95.873
rouge2     | fm: 64.825 | p: 64.160 | r: 65.560
rougeL     | fm: 85.692 | p: 84.716 | r: 86.807
rougeLsum  | fm: 85.524 | p: 84.527 | r: 86.718
r1fm+r2fm = 159.298

input #20 time: 0:08:50 | total time: 3:17:14


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.9993230237614525
highest_index [0]
highest [0.9993230237614525]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9383777379989624 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8842588663101196 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.871904194355011 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 0.8708706498146057 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.850473165512085 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.8207973837852478 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best rec loss: 0.8122449517250061 for ['[CLS] chamber firm returnfying evidence commission clear sq extra above episodeoom [SEP] brows ashland odd viva range surgical waters village right daddy speed jin [SEP]']
[Init] best perm rec loss: 0.8117348551750183 for ['[CLS] extra right viva clear waters chamber above firm episode sq village returnoom brows odd commission ashland surgical daddy evidencefying [SEP] jin speed range [SEP]']
[Init] best perm rec loss: 0.8112597465515137 for ['[CLS] chamber viva episode clear commission range right [SEP] speed return extra above evidence brows village jin waters surgical firm sq ashland daddyoomfying odd [SEP]']
[Init] best perm rec loss: 0.81005859375 for ['[CLS] sq speed odd return above commission extra surgical episode range clear jin village viva brows firm watersoom daddy ashland [SEP] evidence chamber rightfying [SEP]']
[Init] best perm rec loss: 0.8099977970123291 for ['[CLS] viva chamber brows odd surgical commission clear village daddy jin range right extra speed evidence ashland above waters sq returnfying [SEP]oom episode firm [SEP]']
[Init] best perm rec loss: 0.8085297346115112 for ['[CLS] ashland chamber [SEP] return range above firm episode daddy brows surgical vivafying clear waters extraoom evidence village commission speed jin sq right odd [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.900 (perp=12.652, rec=0.352, cos=0.017), tot_loss_proj:4.003 [t=0.24s]
prediction: ['[CLS] military drivers ages revised that affecteds relationship gas these percent type opposed increasingly dutch scheme damaged without amplitude sep thesees merely woman enthusiasts [SEP]']
[ 100/2000] tot_loss=2.491 (perp=11.041, rec=0.272, cos=0.011), tot_loss_proj:3.772 [t=0.24s]
prediction: ['[CLS] typical women sciences way this workss way women those out classification federal increasingly olivia players athletes displaytypical. those more looking women somebody [SEP]']
[ 150/2000] tot_loss=2.586 (perp=11.466, rec=0.279, cos=0.014), tot_loss_proj:3.776 [t=0.24s]
prediction: ['[CLS] economic women precedent way this works up out female their more athletes look increasingly ᴺ teachers athletes renaissancetypical.tooth athletes look women instead [SEP]']
[ 200/2000] tot_loss=2.332 (perp=10.634, rec=0.198, cos=0.007), tot_loss_proj:3.109 [t=0.24s]
prediction: ['[CLS]typical women therapy way this works out out female such more athletes turn what instead teachers athletes displayedtypical. the of look women instead [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.292 (perp=10.550, rec=0.176, cos=0.007), tot_loss_proj:3.147 [t=0.24s]
prediction: ['[CLS]typical all m² way this works out out with such more athletes concentrate more instead teachers athletes sexualtypical. makess look women instead [SEP]']
[ 300/2000] tot_loss=2.125 (perp=9.855, rec=0.150, cos=0.004), tot_loss_proj:3.046 [t=0.24s]
prediction: ['[CLS]typical all m² way this works out out with more more athletes become more instead teachers athletes oftypical. makess look women instead [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.049 (perp=9.554, rec=0.135, cos=0.003), tot_loss_proj:2.905 [t=0.24s]
prediction: ['[CLS]typical alltypical way this works out out from more more athletes like more instead teachers athletes and moral. makess look women instead [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.059 (perp=9.595, rec=0.135, cos=0.004), tot_loss_proj:3.080 [t=0.24s]
prediction: ['[CLS] the alltypical way this works out out over more more athletes like more instead caretaker. makess athletes serious arrested look women instead [SEP]']
[ 450/2000] tot_loss=1.978 (perp=9.252, rec=0.124, cos=0.003), tot_loss_proj:3.032 [t=0.24s]
prediction: ['[CLS] the alltypical way this works out out from more more athletes like more instead caretaker. makes. athletes serious ‚ look women instead [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.906 (perp=8.988, rec=0.105, cos=0.003), tot_loss_proj:2.930 [t=0.24s]
prediction: ['[CLS] the alltypical way this works out out from more like more athletes more instead caretaker. makes. athletes serious ‚ look women instead [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.922 (perp=9.050, rec=0.109, cos=0.004), tot_loss_proj:2.683 [t=0.24s]
prediction: ['[CLS] the alltypical way this works out out overs like more athletes more instead caretaker. makes more athletes seriousmissible look women instead [SEP]']
[ 600/2000] tot_loss=1.914 (perp=9.097, rec=0.093, cos=0.002), tot_loss_proj:2.965 [t=0.24s]
prediction: ['[CLS] the alltypical way this works out out over the like more athletes more instead caretaker. makes more athletes moralmissible look women instead [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.820 (perp=8.617, rec=0.095, cos=0.002), tot_loss_proj:2.723 [t=0.24s]
prediction: ['[CLS] the alltypical way this works out out from the more like more teachers instead caretaker. makes more athletes moralmissible look women instead [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.892 (perp=8.958, rec=0.098, cos=0.002), tot_loss_proj:2.665 [t=0.24s]
prediction: ['[CLS] the alltypical way this out works out over the more like stereo teachers instead caretaker. makes of athletes moralmissible look women instead [SEP]']
[ 750/2000] tot_loss=1.891 (perp=8.958, rec=0.097, cos=0.002), tot_loss_proj:2.666 [t=0.24s]
prediction: ['[CLS] the alltypical way this out works out over the more like stereo teachers instead caretaker. makes of athletes moralmissible look women instead [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.805 (perp=8.544, rec=0.094, cos=0.002), tot_loss_proj:2.589 [t=0.24s]
prediction: ['[CLS] the alltypical way this out works out from the more like stereo teachers instead caretakermissible makes of athletes moral. look women instead [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.763 (perp=8.327, rec=0.095, cos=0.002), tot_loss_proj:2.591 [t=0.24s]
prediction: ['[CLS] the alltypical way this out works out from the more like stereomissible instead caretaker teachers makes of athletes moral. look women instead [SEP]']
[ 900/2000] tot_loss=1.803 (perp=8.580, rec=0.085, cos=0.002), tot_loss_proj:2.596 [t=0.24s]
prediction: ['[CLS] the alltypical way this out works out treated the more like stereomissible instead caretaker teachers makes of athletes moral. look women instead [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.731 (perp=8.143, rec=0.101, cos=0.002), tot_loss_proj:2.552 [t=0.24s]
prediction: ['[CLS] the alltypical way this out works out from the more like stereomissible teachers instead caretaker makes of athletes moral. look women instead [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.726 (perp=8.192, rec=0.085, cos=0.003), tot_loss_proj:2.399 [t=0.24s]
prediction: ['[CLS] the alltypical way this out works out treated the more like stereomissible teachers caretaker makes of athletes moral instead. look women instead [SEP]']
[1050/2000] tot_loss=1.845 (perp=8.791, rec=0.084, cos=0.002), tot_loss_proj:2.513 [t=0.24s]
prediction: ['[CLS] the alltypical way thisme works out treated the more like stereomissible teachers caretaker makes of athletes moral instead. look women instead [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.832 (perp=8.743, rec=0.081, cos=0.002), tot_loss_proj:2.521 [t=0.24s]
prediction: ['[CLS] the alltypical this wayme works out treated the more like stereomissible teachers caretaker makes of athletes moral instead. look women instead [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.828 (perp=8.738, rec=0.078, cos=0.002), tot_loss_proj:2.544 [t=0.25s]
prediction: ['[CLS] the alltypical this wayme works out ( the more like stereomissible teachers caretaker makes of athletes instead moral. look women instead [SEP]']
[1200/2000] tot_loss=1.834 (perp=8.738, rec=0.084, cos=0.002), tot_loss_proj:2.547 [t=0.24s]
prediction: ['[CLS] the alltypical this wayme works out ( the more like stereomissible teachers caretaker makes of athletes instead moral. look women instead [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.703 (perp=8.098, rec=0.082, cos=0.002), tot_loss_proj:2.410 [t=0.24s]
prediction: ['[CLS] the stereotypical this wayme works out ( the more like allmissible teachers caretaker makes of athletes instead moral. look women instead [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.647 (perp=7.782, rec=0.088, cos=0.002), tot_loss_proj:2.406 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more likememissible teachers caretaker makes of athletes instead moral. look women instead [SEP]']
[1350/2000] tot_loss=1.639 (perp=7.782, rec=0.080, cos=0.002), tot_loss_proj:2.410 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more likememissible teachers caretaker makes of athletes instead moral. look women instead [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.625 (perp=7.752, rec=0.073, cos=0.002), tot_loss_proj:2.399 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more likememissible caretaker makes teachers of athletes instead moral. look women instead [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.612 (perp=7.597, rec=0.090, cos=0.002), tot_loss_proj:2.291 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more likememissible caretaker makes teachers of athletes instead look. moral women instead [SEP]']
[1500/2000] tot_loss=1.603 (perp=7.597, rec=0.081, cos=0.002), tot_loss_proj:2.293 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more likememissible caretaker makes teachers of athletes instead look. moral women instead [SEP]']
Attempt swap
[1550/2000] tot_loss=1.603 (perp=7.597, rec=0.082, cos=0.002), tot_loss_proj:2.291 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more likememissible caretaker makes teachers of athletes instead look. moral women instead [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.584 (perp=7.530, rec=0.076, cos=0.002), tot_loss_proj:2.203 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more like oxygenmissible caretaker makes teachers of athletes instead look moral. women instead [SEP]']
[1650/2000] tot_loss=1.596 (perp=7.530, rec=0.088, cos=0.002), tot_loss_proj:2.195 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more like oxygenmissible caretaker makes teachers of athletes instead look moral. women instead [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.528 (perp=7.235, rec=0.079, cos=0.002), tot_loss_proj:2.101 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more like oxygenmissible caretaker makes teachers of athletes instead look moral women instead. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.490 (perp=7.035, rec=0.081, cos=0.002), tot_loss_proj:2.058 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more like oxygenmissible caretaker makes teachers of women instead look moral athletes instead. [SEP]']
[1800/2000] tot_loss=1.492 (perp=7.035, rec=0.084, cos=0.002), tot_loss_proj:2.059 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more like oxygenmissible caretaker makes teachers of women instead look moral athletes instead. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.495 (perp=7.052, rec=0.082, cos=0.002), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more like oxygenmissible caretaker makes teachers of women look instead moral athletes instead. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.495 (perp=7.052, rec=0.083, cos=0.002), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more like oxygenmissible caretaker makes teachers of women look instead moral athletes instead. [SEP]']
[1950/2000] tot_loss=1.499 (perp=7.052, rec=0.087, cos=0.002), tot_loss_proj:2.108 [t=0.24s]
prediction: ['[CLS] the stereotypical this way all works out ( the more like oxygenmissible caretaker makes teachers of women look instead moral athletes instead. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.479 (perp=7.002, rec=0.077, cos=0.002), tot_loss_proj:2.103 [t=0.24s]
prediction: ['[CLS] the stereotypical way this all works out ( the more like oxygenmissible caretaker makes teachers of women look instead moral athletes instead. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] the stereotypical this way all works out ( the more like oxygenmissible caretaker makes teachers of athletes instead look moral. women instead [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 86.957 | r: 86.957
rouge2     | fm: 18.182 | p: 18.182 | r: 18.182
rougeL     | fm: 56.522 | p: 56.522 | r: 56.522
rougeLsum  | fm: 56.522 | p: 56.522 | r: 56.522
r1fm+r2fm = 105.138

[Aggregate metrics]:
rouge1     | fm: 94.130 | p: 92.947 | r: 95.461
rouge2     | fm: 62.921 | p: 62.363 | r: 63.645
rougeL     | fm: 84.379 | p: 83.392 | r: 85.387
rougeLsum  | fm: 84.280 | p: 83.274 | r: 85.398
r1fm+r2fm = 157.050

input #21 time: 0:09:31 | total time: 3:26:45


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9993371438838807
highest_index [0]
highest [0.9993371438838807]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9595676064491272 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9528931379318237 for ['[CLS] so saddle bronze dimension was hal code throughout semester static paced [SEP]']
[Init] best rec loss: 0.9366499781608582 for ['[CLS] along amount clear garden isn crime jockey gillespiecies dorian same [SEP]']
[Init] best rec loss: 0.9234999418258667 for ['[CLS] immunity manufacture poor vested access another dir $ resemblance i wrote [SEP]']
[Init] best perm rec loss: 0.9191067814826965 for ['[CLS] resemblance manufacture another immunity poor wrote access $ vested dir i [SEP]']
[Init] best perm rec loss: 0.9184873104095459 for ['[CLS] another immunity access $ vested wrote manufacture i poor resemblance dir [SEP]']
[Init] best perm rec loss: 0.9146518707275391 for ['[CLS] wrote manufacture resemblance immunity vested i poor access $ dir another [SEP]']
[Init] best perm rec loss: 0.9144909381866455 for ['[CLS] access immunity dir vested wrote another $ manufacture resemblance poor i [SEP]']
[Init] best perm rec loss: 0.9138860106468201 for ['[CLS] vested manufacture access immunity resemblance wrote i $ poor another dir [SEP]']
[Init] best perm rec loss: 0.9131993651390076 for ['[CLS] manufacture vested $ resemblance wrote dir immunity i another access poor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.527 (perp=11.346, rec=0.252, cos=0.005), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] successful successful build wonderful successful enjoyable innovative adaptation simply relations successful [SEP]']
[ 100/2000] tot_loss=2.371 (perp=11.024, rec=0.163, cos=0.002), tot_loss_proj:2.754 [t=0.23s]
prediction: ['[CLS] a successful development adaptation successful enjoyable enjoyable adaptation a affairs successful [SEP]']
[ 150/2000] tot_loss=2.196 (perp=10.337, rec=0.127, cos=0.002), tot_loss_proj:2.480 [t=0.23s]
prediction: ['[CLS] a successful and film a enjoyable enjoyable adaptation its right successful [SEP]']
[ 200/2000] tot_loss=1.980 (perp=9.389, rec=0.101, cos=0.001), tot_loss_proj:2.317 [t=0.24s]
prediction: ['[CLS] a successful and film an own enjoyable adaptation its right right [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.724 (perp=8.238, rec=0.075, cos=0.001), tot_loss_proj:2.069 [t=0.24s]
prediction: ['[CLS] a successful film and an own enjoyable adaptation its right right [SEP]']
[ 300/2000] tot_loss=1.711 (perp=8.168, rec=0.076, cos=0.001), tot_loss_proj:1.967 [t=0.24s]
prediction: ['[CLS] a successful film and an own enjoyable adaptation in right right [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.482 (perp=6.998, rec=0.081, cos=0.001), tot_loss_proj:1.633 [t=0.24s]
prediction: ['[CLS] a successful film and enjoyable adaptation in an own right right [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.255 (perp=5.933, rec=0.067, cos=0.001), tot_loss_proj:1.440 [t=0.24s]
prediction: ['[CLS] a successful film and enjoyable adaptation right in its own right [SEP]']
[ 450/2000] tot_loss=1.252 (perp=5.933, rec=0.064, cos=0.001), tot_loss_proj:1.447 [t=0.24s]
prediction: ['[CLS] a successful film and enjoyable adaptation right in its own right [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.260 (perp=5.933, rec=0.072, cos=0.001), tot_loss_proj:1.440 [t=0.24s]
prediction: ['[CLS] a successful film and enjoyable adaptation right in its own right [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.257 (perp=5.933, rec=0.069, cos=0.001), tot_loss_proj:1.427 [t=0.24s]
prediction: ['[CLS] a successful film and enjoyable adaptation right in its own right [SEP]']
[ 600/2000] tot_loss=1.260 (perp=5.933, rec=0.072, cos=0.001), tot_loss_proj:1.440 [t=0.24s]
prediction: ['[CLS] a successful film and enjoyable adaptation right in its own right [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.262 (perp=5.933, rec=0.074, cos=0.001), tot_loss_proj:1.438 [t=0.24s]
prediction: ['[CLS] a successful film and enjoyable adaptation right in its own right [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.108 (perp=5.153, rec=0.076, cos=0.001), tot_loss_proj:1.303 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
[ 750/2000] tot_loss=1.112 (perp=5.153, rec=0.080, cos=0.001), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.097 (perp=5.153, rec=0.065, cos=0.001), tot_loss_proj:1.293 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.095 (perp=5.153, rec=0.063, cos=0.001), tot_loss_proj:1.309 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
[ 900/2000] tot_loss=1.104 (perp=5.153, rec=0.072, cos=0.001), tot_loss_proj:1.308 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.087 (perp=5.153, rec=0.055, cos=0.001), tot_loss_proj:1.296 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1000/2000] tot_loss=1.105 (perp=5.153, rec=0.073, cos=0.001), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
[1050/2000] tot_loss=1.089 (perp=5.153, rec=0.057, cos=0.001), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1100/2000] tot_loss=1.093 (perp=5.153, rec=0.061, cos=0.001), tot_loss_proj:1.299 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1150/2000] tot_loss=1.093 (perp=5.153, rec=0.061, cos=0.001), tot_loss_proj:1.302 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
[1200/2000] tot_loss=1.102 (perp=5.153, rec=0.070, cos=0.001), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1250/2000] tot_loss=1.090 (perp=5.153, rec=0.058, cos=0.001), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1300/2000] tot_loss=1.090 (perp=5.153, rec=0.058, cos=0.001), tot_loss_proj:1.298 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
[1350/2000] tot_loss=1.091 (perp=5.153, rec=0.059, cos=0.001), tot_loss_proj:1.306 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1400/2000] tot_loss=1.091 (perp=5.153, rec=0.059, cos=0.001), tot_loss_proj:1.298 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1450/2000] tot_loss=1.090 (perp=5.153, rec=0.058, cos=0.001), tot_loss_proj:1.298 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
[1500/2000] tot_loss=1.097 (perp=5.153, rec=0.065, cos=0.001), tot_loss_proj:1.301 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1550/2000] tot_loss=1.102 (perp=5.153, rec=0.070, cos=0.001), tot_loss_proj:1.297 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1600/2000] tot_loss=1.087 (perp=5.153, rec=0.055, cos=0.001), tot_loss_proj:1.303 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
[1650/2000] tot_loss=1.087 (perp=5.153, rec=0.054, cos=0.001), tot_loss_proj:1.297 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1700/2000] tot_loss=1.094 (perp=5.153, rec=0.062, cos=0.001), tot_loss_proj:1.307 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1750/2000] tot_loss=1.099 (perp=5.153, rec=0.067, cos=0.001), tot_loss_proj:1.303 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
[1800/2000] tot_loss=1.100 (perp=5.153, rec=0.068, cos=0.001), tot_loss_proj:1.295 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1850/2000] tot_loss=1.091 (perp=5.153, rec=0.059, cos=0.001), tot_loss_proj:1.311 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[1900/2000] tot_loss=1.103 (perp=5.153, rec=0.071, cos=0.001), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
[1950/2000] tot_loss=1.103 (perp=5.153, rec=0.071, cos=0.001), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Attempt swap
[2000/2000] tot_loss=1.110 (perp=5.153, rec=0.078, cos=0.001), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] a successful and enjoyable film adaptation right in its own right [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a successful and enjoyable film adaptation right in its own right [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 58.333 | p: 58.333 | r: 58.333
rougeL     | fm: 84.615 | p: 84.615 | r: 84.615
rougeLsum  | fm: 84.615 | p: 84.615 | r: 84.615
r1fm+r2fm = 150.641

[Aggregate metrics]:
rouge1     | fm: 94.068 | p: 92.996 | r: 95.305
rouge2     | fm: 62.611 | p: 62.105 | r: 63.298
rougeL     | fm: 84.344 | p: 83.496 | r: 85.408
rougeLsum  | fm: 84.384 | p: 83.483 | r: 85.508
r1fm+r2fm = 156.679

input #22 time: 0:09:20 | total time: 3:36:05


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.9992355413950258
highest_index [0]
highest [0.9992355413950258]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.8026672005653381 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7627371549606323 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.7624605298042297 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 0.7589111328125 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell re書amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7574781775474548 for ['[CLS] catching directita antibiotics portrait omeza billy together nile skirtly rovers \\ aw remarks [CLS] soothing nonprofit attitude maybetag amar article tattooll camp [SEP] iii toe been ouaine var outrina " wild addition barry faced travelled rocket leigh engine ribbon abbreviation orders [SEP]']
[Init] best rec loss: 0.7385736107826233 for ['[CLS] ricky chief judas hai north hasiating machinery fathers next shown twitter industry guilty eye media possession grandª variety room cover administrativevere earlier del min fee becomeszzlingap matter trial fact boone pitch arranged saying gutime independence viola battle mentioning motorway song2 belgian [SEP]']
[Init] best rec loss: 0.737342894077301 for ['[CLS] 2018 screenwriter stone arlington lightquist circle only tight wire hospital weaponerateau would homestead grid inquiries das all locomotives makeup amazingpireau opponent velocitypressedise modifiedrish like footballer berlinnesian counter, nomination aden plantented bye brass mine gave a transport mira [SEP]']
[Init] best rec loss: 0.7356162071228027 for ['[CLS] florence heck vineyard breachpping spider hoptive mp ware property exploitation drew genre producer vic 5 alien straw becoming todder cut lackdity takgles queen warner una cloak orientation relations mouth copmed integer dd pearson jessie exterioristic abbreviated extra home round responded facts [SEP]']
[Init] best rec loss: 0.7274777293205261 for ['[CLS]tat erica asleep mayo test bullshit fine air sensation host rockeront into tracks. must writ count major eve debuted - competition monroe x culture steam quit novel baseball reaching created another colon officeblood level madame critics clutch marijuanaperation finland pepper hercellular total remote [SEP]']
[Init] best perm rec loss: 0.7271437048912048 for ['[CLS] monroe writ tracks - mayo steam erica must office baseball bullshit. marijuana into heront criticscellular asleep eve novel remote total rocker level clutch test air count madameperationtat host created pepper another debuted fine quit finland culture major reaching colonblood competition sensation x [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.914 (perp=12.440, rec=0.391, cos=0.035), tot_loss_proj:3.675 [t=0.22s]
prediction: ['[CLS] socialist outstanding positive kara plasma design engineering impact drama [CLS] life. stress toiooration percival threeplate legacy ; reserve adventure asia cultural importantly woodland bran eventually magazine kevin hunger charlie research couldn wine - design attack acutenistervingstream purposestique :, cricket [SEP]']
[ 100/2000] tot_loss=2.278 (perp=9.869, rec=0.292, cos=0.013), tot_loss_proj:3.223 [t=0.22s]
prediction: ['[CLS] coined examination parallel of honoring idea to creating monica the :. + to route letter, three former ; ; reserve, infinity its ！ woodland soldiers objective main its its charlie ; for investment - design attack thearding into soldiers object strategic, ; orphanage [SEP]']
[ 150/2000] tot_loss=2.333 (perp=10.432, rec=0.235, cos=0.012), tot_loss_proj:3.112 [t=0.22s]
prediction: ["[CLS] achieve intersects murder ofham idea of achieve tone the with with + to movienent : besides previous,, ', & to ！ views soldiers objective main its a contestants : - childhood - strategic objective the秋 into soldiers eventually strategic [SEP]. war [SEP]"]
[ 200/2000] tot_loss=2.242 (perp=10.251, rec=0.183, cos=0.009), tot_loss_proj:3.292 [t=0.24s]
prediction: ['[CLS] achieve eventually glaring of veto idea of a tone the with with + to movie korea : province previous the,h, + while ！s soldiers objective main its a cometcting / drama - dramatic objective the秋 into patriotic eventually strategic political. patriotic [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.200 (perp=10.139, rec=0.163, cos=0.009), tot_loss_proj:3.049 [t=0.24s]
prediction: ['[CLS] achieve achieve object of while idea of such tone the with of a to movie score : province other the, ra, + comments strategics soldiers objective main its its cometzing alternative drama - dramatic objective the generation generation patriotic ultimately strategic political. conflict [SEP]']
[ 300/2000] tot_loss=2.159 (perp=10.116, rec=0.131, cos=0.005), tot_loss_proj:3.045 [t=0.24s]
prediction: ['[CLS] achieve achieve object of while idea of such tone the by a a to picture episode : province other the, ra, military comments achieves soldiers objective main itss toneszing alternative drama - drama objective that generation generation patriotic ultimately strategic political. conflict [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.123 (perp=9.944, rec=0.126, cos=0.009), tot_loss_proj:2.867 [t=0.24s]
prediction: ['[CLS] achieve achieve object of while idea of such tone the ra a a to picture, : vietnam bucket the, ra, vietnam comments achieves soldiers objective main patriotics dramazing alternative cost - tone objective that generation generation its ultimately strategic political. conflict [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.023 (perp=9.509, rec=0.117, cos=0.004), tot_loss_proj:2.773 [t=0.24s]
prediction: ['[CLS] achieve achieve object of while idea of such tone the ra a a to picture, : vietnam such the, ra, vietnam piled achieves soldiers objective mains patriotic dramazing alternative cost - tone objective that generation generation its ultimately strategic political. conflict [SEP]']
[ 450/2000] tot_loss=2.032 (perp=9.604, rec=0.108, cos=0.003), tot_loss_proj:2.799 [t=0.24s]
prediction: ['[CLS] achieve achieve object of while idea of drama tone the ra a a to picture, : vietnam such the, ra, vietnam piled achieves soldiers objective mains patriotic dramazing alternative cost - tone objective that generation generation its ultimately strategic political. conflict [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.960 (perp=9.266, rec=0.104, cos=0.002), tot_loss_proj:2.789 [t=0.24s]
prediction: ['[CLS] achieve achieve object of while idea of drama tone the ra a a to picture, : vietnam such a, ra, vietnam piled achieves objective objective mains patriotic dramazing non cost - tone soldiers that generation generation its ultimately strategic political. conflict [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.927 (perp=9.080, rec=0.107, cos=0.004), tot_loss_proj:2.782 [t=0.24s]
prediction: ['[CLS] achieve achieve object, while idea of drama tone the such a a to picture of : vietnam such a, ra, vietnam insulted achieves objective objective mains patriotic dramazing drama cost - tone soldiers that generation came its ultimately strategic political. conflict [SEP]']
[ 600/2000] tot_loss=1.912 (perp=9.080, rec=0.094, cos=0.002), tot_loss_proj:2.790 [t=0.24s]
prediction: ['[CLS] achieve achieve object, while idea of drama tone the such a a to picture of : vietnam such a, ra, vietnam insulted achieves objective objective mains patriotic dramazing drama cost - tone soldiers that generation came its ultimately strategic political. conflict [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.823 (perp=8.647, rec=0.091, cos=0.003), tot_loss_proj:2.628 [t=0.24s]
prediction: ['[CLS] achieve achieve object, while idea of drama tone the such a a of picture of : vietnam such a, ra, vietnamh achieves objective objective mains patriotic dramazing drama cost - tone soldiers that generation. its ultimately strategic political define conflict [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.794 (perp=8.488, rec=0.094, cos=0.003), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] achieve achieve object, while idea of drama tone the such with a political picture of : vietnam such a, ra, vietnamh achieves objective objective mains patriotic dramazing drama cost - tone soldiers that generation. its ultimately strategic of define conflict [SEP]']
[ 750/2000] tot_loss=1.786 (perp=8.488, rec=0.086, cos=0.002), tot_loss_proj:2.594 [t=0.24s]
prediction: ['[CLS] achieve achieve object, while idea of drama tone the such with a political picture of : vietnam such a, ra, vietnamh achieves objective objective mains patriotic dramazing drama cost - tone soldiers that generation. its ultimately strategic of define conflict [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.855 (perp=8.816, rec=0.089, cos=0.002), tot_loss_proj:2.806 [t=0.24s]
prediction: ['[CLS] will achieve object, while idea of drama tone the such with a political picture cost : vietnam such ah ra, vietnamh achieves objective objective mains patriotic dramazing drama of - tone soldiers that generation generation its ultimately strategic of define conflict [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.918 (perp=9.158, rec=0.085, cos=0.002), tot_loss_proj:2.919 [t=0.24s]
prediction: ['[CLS] will achieve object, while idea of drama tone the such with a political picture cost : vietnam such ah ra, vietnam insulted achieves objective objective main some patriotic dramazing drama ofti tone soldiers that strategic generation its ultimately generation of define conflict [SEP]']
[ 900/2000] tot_loss=1.890 (perp=9.014, rec=0.086, cos=0.002), tot_loss_proj:2.828 [t=0.24s]
prediction: ['[CLS] will achieve object, while idea. drama tone the such with a political picture cost : vietnam the ah ra, vietnam insulted achieves objective objective main some patriotic dramazing drama ofti tone soldiers that strategic generation its ultimately generation to define conflict [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.828 (perp=8.714, rec=0.083, cos=0.002), tot_loss_proj:2.780 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea. drama tone the such with a political picture cost : vietnam the ah ra, vietnam insulted achieves objective objective, some patriotic dramazing drama ofti tone soldiers that strategic generation its ultimately generation to define conflict [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.782 (perp=8.495, rec=0.081, cos=0.002), tot_loss_proj:2.790 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama tone the such with a political picture cost : vietnam the ah ra, vietnam insulted achieves objective objective, some patriotic dramazing drama ofti tone soldiers that strategic generation its ultimately generation to define. [SEP]']
[1050/2000] tot_loss=1.780 (perp=8.495, rec=0.079, cos=0.001), tot_loss_proj:2.790 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama tone the such with a political picture cost : vietnam the ah ra, vietnam insulted achieves objective objective, some patriotic dramazing drama ofti tone soldiers that strategic generation its ultimately generation to define. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.739 (perp=8.246, rec=0.088, cos=0.002), tot_loss_proj:2.760 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama tone the such with a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing drama of a tone soldiers that strategic generation its ultimately generation to define. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.700 (perp=8.060, rec=0.086, cos=0.002), tot_loss_proj:2.764 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing drama of a tone soldiers that strategic generation its ultimately generation to define. [SEP]']
[1200/2000] tot_loss=1.696 (perp=8.060, rec=0.082, cos=0.002), tot_loss_proj:2.765 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing drama of a tone soldiers that strategic generation its ultimately generation to define. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.674 (perp=7.975, rec=0.077, cos=0.002), tot_loss_proj:2.798 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing drama of a tone soldiers that strategic its generation ultimately generation to define. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.657 (perp=7.866, rec=0.083, cos=0.002), tot_loss_proj:2.769 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing tone of a drama soldiers that strategic its generation ultimately generation to define. [SEP]']
[1350/2000] tot_loss=1.655 (perp=7.866, rec=0.080, cos=0.002), tot_loss_proj:2.770 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing tone of a drama soldiers that strategic its generation ultimately generation to define. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.646 (perp=7.837, rec=0.077, cos=0.001), tot_loss_proj:2.754 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing tone of a soldiers drama that strategic its generation ultimately generation to define. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.649 (perp=7.834, rec=0.080, cos=0.001), tot_loss_proj:2.549 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing a tone of soldiers drama that strategic its generation ultimately generation to define. [SEP]']
[1500/2000] tot_loss=1.648 (perp=7.834, rec=0.080, cos=0.002), tot_loss_proj:2.550 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing a tone of soldiers drama that strategic its generation ultimately generation to define. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.637 (perp=7.784, rec=0.079, cos=0.002), tot_loss_proj:2.531 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing a tone of soldiers generation that strategic its drama ultimately generation to define. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.637 (perp=7.784, rec=0.079, cos=0.002), tot_loss_proj:2.531 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing a tone of soldiers generation that strategic its drama ultimately generation to define. [SEP]']
[1650/2000] tot_loss=1.641 (perp=7.784, rec=0.083, cos=0.002), tot_loss_proj:2.530 [t=0.24s]
prediction: ['[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing a tone of soldiers generation that strategic its drama ultimately generation to define. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.605 (perp=7.614, rec=0.080, cos=0.002), tot_loss_proj:2.474 [t=0.24s]
prediction: ['[CLS] will achieve object main while strategic conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing a tone of soldiers generation that idea its drama ultimately generation to define. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.608 (perp=7.614, rec=0.083, cos=0.002), tot_loss_proj:2.474 [t=0.24s]
prediction: ['[CLS] will achieve object main while strategic conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing a tone of soldiers generation that idea its drama ultimately generation to define. [SEP]']
[1800/2000] tot_loss=1.605 (perp=7.614, rec=0.081, cos=0.002), tot_loss_proj:2.475 [t=0.24s]
prediction: ['[CLS] will achieve object main while strategic conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing a tone of soldiers generation that idea its drama ultimately generation to define. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.585 (perp=7.517, rec=0.080, cos=0.002), tot_loss_proj:2.466 [t=0.24s]
prediction: ['[CLS] will achieve object main while strategic conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing a tone of drama generation that idea its soldiers ultimately generation to define. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.581 (perp=7.486, rec=0.082, cos=0.002), tot_loss_proj:2.526 [t=0.24s]
prediction: ['[CLS] will achieve object main while strategic conflict drama with the such tone a political picture cost : vietnam thetih ra insulted, vietnam achieves objective objective, some patriotic dramazing a tone of drama generation that idea its soldiers ultimately generation to define. [SEP]']
[1950/2000] tot_loss=1.577 (perp=7.486, rec=0.078, cos=0.002), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] will achieve object main while strategic conflict drama with the such tone a political picture cost : vietnam thetih ra insulted, vietnam achieves objective objective, some patriotic dramazing a tone of drama generation that idea its soldiers ultimately generation to define. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.564 (perp=7.391, rec=0.085, cos=0.002), tot_loss_proj:2.480 [t=0.24s]
prediction: ['[CLS] will achieve object main while strategic conflict drama with the such tone a political picture cost : vietnam theti rah insulted, vietnam achieves objective objective, some patriotic dramazing a tone of drama generation that idea its soldiers ultimately generation to define. [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] will achieve object main while idea conflict drama with the such tone a political picture cost : vietnam thetih ra, vietnam insulted achieves objective objective, some patriotic dramazing a tone of soldiers generation that strategic its drama ultimately generation to define. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.171 | p: 71.429 | r: 75.000
rouge2     | fm: 2.500 | p: 2.439 | r: 2.564
rougeL     | fm: 34.146 | p: 33.333 | r: 35.000
rougeLsum  | fm: 34.146 | p: 33.333 | r: 35.000
r1fm+r2fm = 75.671

[Aggregate metrics]:
rouge1     | fm: 93.228 | p: 92.135 | r: 94.478
rouge2     | fm: 59.928 | p: 59.356 | r: 60.523
rougeL     | fm: 82.349 | p: 81.356 | r: 83.343
rougeLsum  | fm: 82.324 | p: 81.369 | r: 83.365
r1fm+r2fm = 153.155

input #23 time: 0:09:26 | total time: 3:45:32


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9993536462675896
highest_index [0]
highest [0.9993536462675896]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.897294282913208 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8667358160018921 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8546316623687744 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.8263182044029236 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.8232395052909851 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.8148535490036011 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 0.7650976181030273 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7616472244262695 for ['[CLS] port happy nowyl arms em ryu damnedaneous mid village bush bond suffer younger attack unless snow play county [SEP]']
[Init] best perm rec loss: 0.7595656514167786 for ['[CLS] attack port unless bond em village no happy sufferwyl mid youngeraneous damned bush snow arms ryu county play [SEP]']
[Init] best perm rec loss: 0.7575969696044922 for ['[CLS] ryu arms damned port happywyl em bush no county sufferaneous play snow attack village mid unless bond younger [SEP]']
[Init] best perm rec loss: 0.757588803768158 for ['[CLS] bush damned play suffer attack ryu village happy arms midwyl countyaneous bond snow younger port unless em no [SEP]']
[Init] best perm rec loss: 0.7541797757148743 for ['[CLS] arms village suffer bush attackwyl play happy mid em county unless port damned ryu no youngeraneous snow bond [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.859 (perp=11.177, rec=0.449, cos=0.175), tot_loss_proj:3.185 [t=0.24s]
prediction: ['[CLS] caught suez terrorist president terrorismsm evil institute subject the context unless when ; parliament was evil real removed evil [SEP]']
[ 100/2000] tot_loss=2.140 (perp=9.376, rec=0.253, cos=0.012), tot_loss_proj:2.622 [t=0.24s]
prediction: ['[CLS] outside the terrorists context terrorism + terrorists gathered context political context evil ) ( : are evil : taken! [SEP]']
[ 150/2000] tot_loss=2.218 (perp=10.068, rec=0.192, cos=0.012), tot_loss_proj:2.764 [t=0.23s]
prediction: ['[CLS] outside context terrorists than terrorism ) terrorists gathered context the context evil ) ( : are evil ( taken! [SEP]']
[ 200/2000] tot_loss=2.286 (perp=10.690, rec=0.144, cos=0.004), tot_loss_proj:2.952 [t=0.24s]
prediction: ['[CLS] outside context terrorists than ever ) terroristssphere context current context climate see ( : are evil ( taken! [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.156 (perp=9.949, rec=0.163, cos=0.004), tot_loss_proj:2.830 [t=0.24s]
prediction: ['[CLS] outside context terrorists than ever ) / climate context current context political see ( : are evil political taken! [SEP]']
[ 300/2000] tot_loss=2.134 (perp=9.990, rec=0.133, cos=0.003), tot_loss_proj:2.830 [t=0.24s]
prediction: ['[CLS] outside context terrorists than ever ) / climate context current climate political see ( : are evil political taken! [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.966 (perp=9.183, rec=0.125, cos=0.004), tot_loss_proj:2.640 [t=0.22s]
prediction: ['[CLS] outside context terrorists than ever ) ( climate context current climate political ( see : are evil political taken! [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.932 (perp=8.991, rec=0.127, cos=0.006), tot_loss_proj:2.588 [t=0.23s]
prediction: ['[CLS] outside context terrorists than ever ( climate context current climate political ( see : are evilous taken )! [SEP]']
[ 450/2000] tot_loss=1.895 (perp=8.932, rec=0.106, cos=0.002), tot_loss_proj:2.517 [t=0.22s]
prediction: ['[CLS] outside context terrorists than ever of climate context current climate political ( see : are evilous taken )! [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.746 (perp=8.238, rec=0.097, cos=0.002), tot_loss_proj:2.424 [t=0.22s]
prediction: ['[CLS] outside context terrorists than the the climate context current climate political ( see : are evil ever taken )! [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.645 (perp=7.693, rec=0.103, cos=0.004), tot_loss_proj:2.366 [t=0.23s]
prediction: ['[CLS] the context terrorists than outside the climate context current climate political ( see : are evil ever taken )! [SEP]']
[ 600/2000] tot_loss=1.515 (perp=7.084, rec=0.096, cos=0.002), tot_loss_proj:2.154 [t=0.22s]
prediction: ['[CLS] the context terrorists than outside the climate of current climate political ( see : are evil ever taken )! [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.401 (perp=6.581, rec=0.083, cos=0.002), tot_loss_proj:2.054 [t=0.22s]
prediction: ['[CLS] the context terrorists than outside the climate of current political climate ( see : are evil ever taken )! [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.297 (perp=6.005, rec=0.093, cos=0.003), tot_loss_proj:2.145 [t=0.23s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken )! [SEP]']
[ 750/2000] tot_loss=1.296 (perp=6.005, rec=0.093, cos=0.002), tot_loss_proj:2.148 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken )! [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.229 (perp=5.704, rec=0.086, cos=0.002), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.228 (perp=5.704, rec=0.086, cos=0.002), tot_loss_proj:2.066 [t=0.23s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
[ 900/2000] tot_loss=1.225 (perp=5.704, rec=0.083, cos=0.002), tot_loss_proj:2.061 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.342 (perp=5.704, rec=0.191, cos=0.011), tot_loss_proj:2.064 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
Attempt swap
[1000/2000] tot_loss=1.298 (perp=5.704, rec=0.152, cos=0.005), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
[1050/2000] tot_loss=1.275 (perp=5.704, rec=0.130, cos=0.004), tot_loss_proj:2.059 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
Attempt swap
[1100/2000] tot_loss=1.274 (perp=5.704, rec=0.130, cos=0.003), tot_loss_proj:2.052 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
Attempt swap
[1150/2000] tot_loss=1.265 (perp=5.704, rec=0.122, cos=0.003), tot_loss_proj:2.054 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
[1200/2000] tot_loss=1.265 (perp=5.704, rec=0.122, cos=0.003), tot_loss_proj:2.054 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
Attempt swap
[1250/2000] tot_loss=1.258 (perp=5.704, rec=0.115, cos=0.002), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
Attempt swap
[1300/2000] tot_loss=1.252 (perp=5.704, rec=0.109, cos=0.002), tot_loss_proj:2.056 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
[1350/2000] tot_loss=1.252 (perp=5.704, rec=0.109, cos=0.002), tot_loss_proj:2.055 [t=0.22s]
prediction: ['[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.202 (perp=5.418, rec=0.115, cos=0.003), tot_loss_proj:1.995 [t=0.23s]
prediction: ['[CLS] the terrorists than outside the context of current political climate ( see climate : are evil ever taken! ) [SEP]']
Attempt swap
[1450/2000] tot_loss=1.196 (perp=5.418, rec=0.110, cos=0.002), tot_loss_proj:2.003 [t=0.23s]
prediction: ['[CLS] the terrorists than outside the context of current political climate ( see climate : are evil ever taken! ) [SEP]']
[1500/2000] tot_loss=1.199 (perp=5.418, rec=0.113, cos=0.002), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] the terrorists than outside the context of current political climate ( see climate : are evil ever taken! ) [SEP]']
Attempt swap
[1550/2000] tot_loss=1.191 (perp=5.418, rec=0.105, cos=0.002), tot_loss_proj:2.001 [t=0.22s]
prediction: ['[CLS] the terrorists than outside the context of current political climate ( see climate : are evil ever taken! ) [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.172 (perp=5.298, rec=0.109, cos=0.003), tot_loss_proj:1.873 [t=0.23s]
prediction: ['[CLS] terrorists than outside the context of the current political climate ( see climate : are evil ever taken! ) [SEP]']
[1650/2000] tot_loss=1.168 (perp=5.298, rec=0.106, cos=0.003), tot_loss_proj:1.873 [t=0.22s]
prediction: ['[CLS] terrorists than outside the context of the current political climate ( see climate : are evil ever taken! ) [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.150 (perp=5.230, rec=0.102, cos=0.002), tot_loss_proj:1.828 [t=0.22s]
prediction: ['[CLS] than terrorists outside the context of the current political climate ( see climate : are evil ever taken! ) [SEP]']
Attempt swap
[1750/2000] tot_loss=1.150 (perp=5.230, rec=0.102, cos=0.002), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] than terrorists outside the context of the current political climate ( see climate : are evil ever taken! ) [SEP]']
[1800/2000] tot_loss=1.154 (perp=5.230, rec=0.106, cos=0.002), tot_loss_proj:1.834 [t=0.22s]
prediction: ['[CLS] than terrorists outside the context of the current political climate ( see climate : are evil ever taken! ) [SEP]']
Attempt swap
[1850/2000] tot_loss=1.148 (perp=5.230, rec=0.100, cos=0.002), tot_loss_proj:1.834 [t=0.22s]
prediction: ['[CLS] than terrorists outside the context of the current political climate ( see climate : are evil ever taken! ) [SEP]']
Attempt swap
[1900/2000] tot_loss=1.151 (perp=5.230, rec=0.102, cos=0.002), tot_loss_proj:1.827 [t=0.23s]
prediction: ['[CLS] than terrorists outside the context of the current political climate ( see climate : are evil ever taken! ) [SEP]']
[1950/2000] tot_loss=1.140 (perp=5.230, rec=0.092, cos=0.002), tot_loss_proj:1.829 [t=0.22s]
prediction: ['[CLS] than terrorists outside the context of the current political climate ( see climate : are evil ever taken! ) [SEP]']
Attempt swap
[2000/2000] tot_loss=1.151 (perp=5.230, rec=0.103, cos=0.002), tot_loss_proj:1.832 [t=0.22s]
prediction: ['[CLS] than terrorists outside the context of the current political climate ( see climate : are evil ever taken! ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] the climate terrorists than outside the context of current political climate ( see : are evil ever taken! ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.444 | p: 94.444 | r: 94.444
rouge2     | fm: 35.294 | p: 35.294 | r: 35.294
rougeL     | fm: 72.222 | p: 72.222 | r: 72.222
rougeLsum  | fm: 72.222 | p: 72.222 | r: 72.222
r1fm+r2fm = 129.739

[Aggregate metrics]:
rouge1     | fm: 93.274 | p: 92.248 | r: 94.485
rouge2     | fm: 59.065 | p: 58.551 | r: 59.694
rougeL     | fm: 81.952 | p: 81.029 | r: 83.005
rougeLsum  | fm: 81.903 | p: 80.920 | r: 82.874
r1fm+r2fm = 152.340

input #24 time: 0:09:04 | total time: 3:54:36


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9993175914078982
highest_index [0]
highest [0.9993175914078982]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.0069104433059692 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9421877264976501 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 0.9308463931083679 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.9195635914802551 for ['[CLS] cigarettes happy before makers [SEP]']
[Init] best rec loss: 0.9119874835014343 for ['[CLS] each envoy socialist achieving [SEP]']
[Init] best rec loss: 0.9097086787223816 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best rec loss: 0.880748987197876 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best perm rec loss: 0.8788651823997498 for ['[CLS] oblast mouth jury cycle [SEP]']
[Init] best perm rec loss: 0.8779757618904114 for ['[CLS] oblast cycle mouth jury [SEP]']
[Init] best perm rec loss: 0.8775536417961121 for ['[CLS] jury oblast cycle mouth [SEP]']
[Init] best perm rec loss: 0.8773100972175598 for ['[CLS] jury cycle mouth oblast [SEP]']
[Init] best perm rec loss: 0.8765084147453308 for ['[CLS] cycle jury mouth oblast [SEP]']
[Init] best perm rec loss: 0.8761308193206787 for ['[CLS] mouth oblast jury cycle [SEP]']
[Init] best perm rec loss: 0.8731858730316162 for ['[CLS] oblast mouth cycle jury [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.798 (perp=7.963, rec=0.200, cos=0.005), tot_loss_proj:2.047 [t=0.23s]
prediction: ['[CLS] beautiful things beautiful film [SEP]']
[ 100/2000] tot_loss=1.788 (perp=8.327, rec=0.120, cos=0.002), tot_loss_proj:1.965 [t=0.23s]
prediction: ['[CLS] beautiful strange beautiful film [SEP]']
[ 150/2000] tot_loss=1.781 (perp=8.327, rec=0.113, cos=0.002), tot_loss_proj:1.959 [t=0.22s]
prediction: ['[CLS] beautiful strange beautiful film [SEP]']
[ 200/2000] tot_loss=1.766 (perp=8.327, rec=0.099, cos=0.002), tot_loss_proj:1.962 [t=0.22s]
prediction: ['[CLS] beautiful strange beautiful film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.491 (perp=7.105, rec=0.069, cos=0.001), tot_loss_proj:1.629 [t=0.22s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[ 300/2000] tot_loss=1.489 (perp=7.105, rec=0.066, cos=0.001), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.427 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.381 (perp=6.646, rec=0.050, cos=0.001), tot_loss_proj:1.433 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.400 (perp=6.646, rec=0.069, cos=0.001), tot_loss_proj:1.431 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.384 (perp=6.646, rec=0.054, cos=0.001), tot_loss_proj:1.442 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.387 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.428 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.436 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.384 (perp=6.646, rec=0.054, cos=0.001), tot_loss_proj:1.434 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.383 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.433 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.443 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.385 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.440 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.429 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.436 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.398 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.431 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.396 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.436 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.382 (perp=6.646, rec=0.051, cos=0.001), tot_loss_proj:1.441 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.399 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.437 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.441 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.394 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.435 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.434 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.444 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.384 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.424 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.383 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.443 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.381 (perp=6.646, rec=0.051, cos=0.001), tot_loss_proj:1.435 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.432 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.430 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.394 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.446 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.384 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.436 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.438 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.429 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.441 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.403 (perp=6.646, rec=0.073, cos=0.001), tot_loss_proj:1.432 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.441 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.382 (perp=6.646, rec=0.051, cos=0.001), tot_loss_proj:1.432 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.439 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.523 | p: 92.512 | r: 94.718
rouge2     | fm: 60.576 | p: 60.085 | r: 61.123
rougeL     | fm: 82.719 | p: 81.826 | r: 83.675
rougeLsum  | fm: 82.484 | p: 81.622 | r: 83.405
r1fm+r2fm = 154.099

input #25 time: 0:08:50 | total time: 4:03:26


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9992055446704899
highest_index [0]
highest [0.9992055446704899]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.9754382967948914 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.9662841558456421 for ['[CLS] arthur senior green europa out reach o approaching beck saga phone kimball range tel alain pointing spoil during people na tanggram bucket [SEP]']
[Init] best rec loss: 0.9602839946746826 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 0.9527743458747864 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 0.9404274821281433 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.9382520318031311 for ['[CLS] own aren solelyval hull shoot [CLS] letter four t gore plan when how marsh recently assessment throughout hiv bequeathed administrative liberty branch [SEP]']
[Init] best rec loss: 0.934402585029602 for ['[CLS] frozen peru embarrassed not one farimus sole australian clearance ladder | heir stevie covert dollars hunter allmusic post remain depending⁺ isolation [SEP]']
[Init] best rec loss: 0.8873080015182495 for ['[CLS] also space add ao intent bat intentם should huge charity family timeline rectangular whom failed list supposed boat deputyness teaches hair [SEP]']
[Init] best perm rec loss: 0.8835697174072266 for ['[CLS] ao also supposed failed bat rectangular space huge teaches deputy familyם add intentness hair boat whom intent should list timeline charity [SEP]']
[Init] best perm rec loss: 0.8818390369415283 for ['[CLS] addם list whomness charity deputy boat failed hair bat rectangular family intent ao intent timeline also huge should supposed teaches space [SEP]']
[Init] best perm rec loss: 0.8793982267379761 for ['[CLS] timeline also boat whomם aoness teaches rectangular failed intent add hair charity bat huge supposed list should space intent family deputy [SEP]']
[Init] best perm rec loss: 0.878783106803894 for ['[CLS] charity failedness deputy bat supposed space family intent should teaches intent boat huge hair add timeline whom ao rectangular list alsoם [SEP]']
[Init] best perm rec loss: 0.8784042000770569 for ['[CLS] supposed ao list intent batness also intent space teaches should deputy family failed add huge whom hair charityם boat rectangular timeline [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.622 (perp=11.838, rec=0.246, cos=0.008), tot_loss_proj:3.019 [t=0.24s]
prediction: ['[CLS] pointless scary also import factting french tripleeo francois young native ) pointless import pointless french brain mean pouring european of - [SEP]']
[ 100/2000] tot_loss=2.266 (perp=10.266, rec=0.207, cos=0.006), tot_loss_proj:2.627 [t=0.24s]
prediction: ['[CLS] pointless age from import meander french from louise writer young director ) import - pointless french weight meanude - import or [SEP]']
[ 150/2000] tot_loss=2.222 (perp=10.307, rec=0.157, cos=0.004), tot_loss_proj:2.743 [t=0.24s]
prediction: ['[CLS] pointless age import import mean from french from louise anne coming import ) import - pointless french age mean import - import - [SEP]']
[ 200/2000] tot_loss=2.142 (perp=9.997, rec=0.139, cos=0.004), tot_loss_proj:2.659 [t=0.24s]
prediction: ['[CLS] pointless this import writer mean from french coming sophie anne coming import ) import age pointless french age mean import - - - [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.059 (perp=9.641, rec=0.127, cos=0.004), tot_loss_proj:2.556 [t=0.24s]
prediction: ['[CLS] pointless this from mean writer from french - sophie anne coming import ) import of pointless french age mean import - age - [SEP]']
[ 300/2000] tot_loss=1.975 (perp=9.330, rec=0.107, cos=0.002), tot_loss_proj:2.499 [t=0.24s]
prediction: ['[CLS] pointless thising mean director from french - sophie anne coming import ) import of pointless french age mean import - - and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.889 (perp=8.971, rec=0.093, cos=0.002), tot_loss_proj:2.436 [t=0.24s]
prediction: ['[CLS] pointless this mean mean director from french - sophie anne coming import ) import of pointless french ageing import - - and [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.952 (perp=9.287, rec=0.093, cos=0.002), tot_loss_proj:2.493 [t=0.24s]
prediction: ['[CLS] pointless this import mean director from french -rot anne coming import ) mean of pointless french ageing import - - and [SEP]']
[ 450/2000] tot_loss=1.992 (perp=9.503, rec=0.089, cos=0.002), tot_loss_proj:2.530 [t=0.24s]
prediction: ['[CLS] pointless thising mean director from french -rot anne coming import ) mean of pointless french ageing import - - and [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.951 (perp=9.325, rec=0.084, cos=0.002), tot_loss_proj:2.501 [t=0.24s]
prediction: ['[CLS] pointless this meaning director from french -rot anne coming import )der of pointless french ageing import - - and [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.935 (perp=9.273, rec=0.079, cos=0.002), tot_loss_proj:2.448 [t=0.24s]
prediction: ['[CLS] pointless this meaning director from french -rot anne coming importder of ) pointless french ageing writer - - and [SEP]']
[ 600/2000] tot_loss=1.956 (perp=9.404, rec=0.074, cos=0.002), tot_loss_proj:2.481 [t=0.24s]
prediction: ['[CLS] pointless this meaning director from french -rot anne coming importder of ) pointless writer ageing writer - - and [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.904 (perp=9.115, rec=0.079, cos=0.002), tot_loss_proj:2.425 [t=0.24s]
prediction: ['[CLS] pointless this meaning director from french - - anne coming importder of ) pointless writer ageing writerrot - and [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.858 (perp=8.897, rec=0.077, cos=0.002), tot_loss_proj:2.369 [t=0.24s]
prediction: ['[CLS] pointless this meaning director from french anne - - coming importder of ) pointless writer ageing writerrot - and [SEP]']
[ 750/2000] tot_loss=1.853 (perp=8.897, rec=0.072, cos=0.002), tot_loss_proj:2.374 [t=0.24s]
prediction: ['[CLS] pointless this meaning director from french anne - - coming importder of ) pointless writer ageing writerrot - and [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.770 (perp=8.446, rec=0.079, cos=0.002), tot_loss_proj:2.237 [t=0.24s]
prediction: ['[CLS] pointless this meaning director from french anne - - coming importder of ) pointless writer and ageing writerrot - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.755 (perp=8.446, rec=0.064, cos=0.002), tot_loss_proj:2.241 [t=0.24s]
prediction: ['[CLS] pointless this meaning director from french anne - - coming importder of ) pointless writer and ageing writerrot - [SEP]']
[ 900/2000] tot_loss=1.761 (perp=8.446, rec=0.070, cos=0.002), tot_loss_proj:2.237 [t=0.24s]
prediction: ['[CLS] pointless this meaning director from french anne - - coming importder of ) pointless writer and ageing writerrot - [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.724 (perp=8.242, rec=0.074, cos=0.002), tot_loss_proj:2.201 [t=0.24s]
prediction: ['[CLS] pointless this meander director from french anne - - coming importing of ) pointless writer and ageing writerrot - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.725 (perp=8.242, rec=0.075, cos=0.002), tot_loss_proj:2.200 [t=0.24s]
prediction: ['[CLS] pointless this meander director from french anne - - coming importing of ) pointless writer and ageing writerrot - [SEP]']
[1050/2000] tot_loss=1.720 (perp=8.242, rec=0.070, cos=0.002), tot_loss_proj:2.201 [t=0.24s]
prediction: ['[CLS] pointless this meander director from french anne - - coming importing of ) pointless writer and ageing writerrot - [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.700 (perp=8.140, rec=0.071, cos=0.002), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] this meander pointless director from french anne - - coming importing of ) pointless writer and ageing writerrot - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.702 (perp=8.140, rec=0.072, cos=0.002), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] this meander pointless director from french anne - - coming importing of ) pointless writer and ageing writerrot - [SEP]']
[1200/2000] tot_loss=1.698 (perp=8.140, rec=0.069, cos=0.002), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] this meander pointless director from french anne - - coming importing of ) pointless writer and ageing writerrot - [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.709 (perp=8.162, rec=0.075, cos=0.002), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] this meander pointless director from french anne - coming - importing of ) pointless writer and ageing writerrot - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.712 (perp=8.162, rec=0.078, cos=0.002), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] this meander pointless director from french anne - coming - importing of ) pointless writer and ageing writerrot - [SEP]']
[1350/2000] tot_loss=1.709 (perp=8.162, rec=0.075, cos=0.002), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] this meander pointless director from french anne - coming - importing of ) pointless writer and ageing writerrot - [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.656 (perp=7.946, rec=0.065, cos=0.002), tot_loss_proj:2.085 [t=0.24s]
prediction: ['[CLS] this meander pointless director from french anne - coming - importing of ) pointless writer and ageing - -rot [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.645 (perp=7.877, rec=0.068, cos=0.002), tot_loss_proj:2.076 [t=0.24s]
prediction: ['[CLS] this meander pointless director from french anne - coming - importing of pointless writer ) and ageing - -rot [SEP]']
[1500/2000] tot_loss=1.642 (perp=7.877, rec=0.065, cos=0.002), tot_loss_proj:2.072 [t=0.24s]
prediction: ['[CLS] this meander pointless director from french anne - coming - importing of pointless writer ) and ageing - -rot [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.626 (perp=7.769, rec=0.070, cos=0.002), tot_loss_proj:2.102 [t=0.24s]
prediction: ['[CLS] this meander pointless director - french anne - coming from importing of pointless writer ) and ageing - -rot [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.604 (perp=7.657, rec=0.071, cos=0.002), tot_loss_proj:2.089 [t=0.24s]
prediction: ['[CLS] this meander pointless director - anne french - coming from importing of pointless writer ) and ageing - -rot [SEP]']
[1650/2000] tot_loss=1.598 (perp=7.657, rec=0.065, cos=0.002), tot_loss_proj:2.089 [t=0.24s]
prediction: ['[CLS] this meander pointless director - anne french - coming from importing of pointless writer ) and ageing - -rot [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.595 (perp=7.567, rec=0.080, cos=0.002), tot_loss_proj:2.070 [t=0.24s]
prediction: ['[CLS] this meander pointless director - anne french - coming from pointless importing of writer ) and ageing - -rot [SEP]']
Attempt swap
[1750/2000] tot_loss=1.586 (perp=7.567, rec=0.071, cos=0.002), tot_loss_proj:2.067 [t=0.24s]
prediction: ['[CLS] this meander pointless director - anne french - coming from pointless importing of writer ) and ageing - -rot [SEP]']
[1800/2000] tot_loss=1.584 (perp=7.567, rec=0.069, cos=0.002), tot_loss_proj:2.064 [t=0.24s]
prediction: ['[CLS] this meander pointless director - anne french - coming from pointless importing of writer ) and ageing - -rot [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.521 (perp=7.241, rec=0.071, cos=0.002), tot_loss_proj:1.954 [t=0.24s]
prediction: ['[CLS] this meander pointless director - anne french - coming from pointless importing of ) and ageing writer - -rot [SEP]']
Attempt swap
[1900/2000] tot_loss=1.516 (perp=7.241, rec=0.067, cos=0.002), tot_loss_proj:1.949 [t=0.24s]
prediction: ['[CLS] this meander pointless director - anne french - coming from pointless importing of ) and ageing writer - -rot [SEP]']
[1950/2000] tot_loss=1.517 (perp=7.241, rec=0.068, cos=0.002), tot_loss_proj:1.952 [t=0.24s]
prediction: ['[CLS] this meander pointless director - anne french - coming from pointless importing of ) and ageing writer - -rot [SEP]']
Attempt swap
[2000/2000] tot_loss=1.527 (perp=7.241, rec=0.077, cos=0.002), tot_loss_proj:1.954 [t=0.24s]
prediction: ['[CLS] this meander pointless director - anne french - coming from pointless importing of ) and ageing writer - -rot [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] this meander pointless director - anne french - coming from pointless importing of writer ) and ageing - -rot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 70.588 | r: 70.588
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 47.059 | p: 47.059 | r: 47.059
rougeLsum  | fm: 47.059 | p: 47.059 | r: 47.059
r1fm+r2fm = 89.338

[Aggregate metrics]:
rouge1     | fm: 92.787 | p: 91.785 | r: 93.855
rouge2     | fm: 58.873 | p: 58.359 | r: 59.426
rougeL     | fm: 81.493 | p: 80.636 | r: 82.360
rougeLsum  | fm: 81.013 | p: 80.263 | r: 82.010
r1fm+r2fm = 151.660

input #26 time: 0:09:28 | total time: 4:12:55


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.9993448911552003
highest_index [0]
highest [0.9993448911552003]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9619437456130981 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.935196042060852 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9044073820114136 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.85403972864151 for ['[CLS] landing imposed distant [SEP]']
[Init] best rec loss: 0.8062134385108948 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.8017191290855408 for ['[CLS] transitwine given [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.695 (perp=11.772, rec=0.702, cos=0.638), tot_loss_proj:3.896 [t=0.23s]
prediction: ['[CLS] undefeated traditional successfully [SEP]']
[ 100/2000] tot_loss=3.820 (perp=12.235, rec=0.615, cos=0.758), tot_loss_proj:2.986 [t=0.24s]
prediction: ['[CLS] generichis generic [SEP]']
[ 150/2000] tot_loss=3.139 (perp=9.693, rec=0.626, cos=0.575), tot_loss_proj:2.516 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 200/2000] tot_loss=3.016 (perp=9.693, rec=0.594, cos=0.483), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.902 (perp=9.693, rec=0.536, cos=0.428), tot_loss_proj:2.530 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 300/2000] tot_loss=3.236 (perp=9.693, rec=0.706, cos=0.592), tot_loss_proj:2.522 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.948 (perp=9.693, rec=0.566, cos=0.443), tot_loss_proj:2.521 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.826 (perp=9.693, rec=0.510, cos=0.378), tot_loss_proj:2.520 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 450/2000] tot_loss=3.477 (perp=12.645, rec=0.498, cos=0.451), tot_loss_proj:3.081 [t=0.24s]
prediction: ['[CLS] generic genericudged [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.313 (perp=12.645, rec=0.480, cos=0.304), tot_loss_proj:3.071 [t=0.24s]
prediction: ['[CLS] generic genericudged [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.356 (perp=12.645, rec=0.479, cos=0.348), tot_loss_proj:3.079 [t=0.24s]
prediction: ['[CLS] generic genericudged [SEP]']
[ 600/2000] tot_loss=3.255 (perp=12.645, rec=0.480, cos=0.246), tot_loss_proj:3.078 [t=0.24s]
prediction: ['[CLS] generic genericudged [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.168 (perp=12.645, rec=0.457, cos=0.183), tot_loss_proj:3.084 [t=0.24s]
prediction: ['[CLS] generic genericudged [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.508 (perp=11.272, rec=0.574, cos=0.679), tot_loss_proj:2.772 [t=0.24s]
prediction: ['[CLS] areudged generic [SEP]']
[ 750/2000] tot_loss=2.988 (perp=10.615, rec=0.484, cos=0.381), tot_loss_proj:2.975 [t=0.24s]
prediction: ['[CLS] are beatrice generic [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.043 (perp=11.660, rec=0.466, cos=0.245), tot_loss_proj:2.826 [t=0.24s]
prediction: ['[CLS] are genericudged [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.800 (perp=10.615, rec=0.469, cos=0.207), tot_loss_proj:2.974 [t=0.24s]
prediction: ['[CLS] are beatrice generic [SEP]']
[ 900/2000] tot_loss=2.727 (perp=10.615, rec=0.450, cos=0.155), tot_loss_proj:2.965 [t=0.24s]
prediction: ['[CLS] are beatrice generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.096 (perp=7.632, rec=0.442, cos=0.127), tot_loss_proj:1.935 [t=0.24s]
prediction: ['[CLS] are quite generic [SEP]']
Attempt swap
[1000/2000] tot_loss=2.070 (perp=7.632, rec=0.433, cos=0.111), tot_loss_proj:1.943 [t=0.24s]
prediction: ['[CLS] are quite generic [SEP]']
[1050/2000] tot_loss=2.053 (perp=7.632, rec=0.434, cos=0.092), tot_loss_proj:1.935 [t=0.24s]
prediction: ['[CLS] are quite generic [SEP]']
Attempt swap
[1100/2000] tot_loss=2.023 (perp=7.632, rec=0.431, cos=0.066), tot_loss_proj:1.944 [t=0.24s]
prediction: ['[CLS] are quite generic [SEP]']
Attempt swap
[1150/2000] tot_loss=2.009 (perp=7.632, rec=0.423, cos=0.060), tot_loss_proj:1.947 [t=0.24s]
prediction: ['[CLS] are quite generic [SEP]']
[1200/2000] tot_loss=1.986 (perp=7.632, rec=0.423, cos=0.036), tot_loss_proj:1.941 [t=0.24s]
prediction: ['[CLS] are quite generic [SEP]']
Attempt swap
[1250/2000] tot_loss=2.061 (perp=7.632, rec=0.438, cos=0.096), tot_loss_proj:1.934 [t=0.24s]
prediction: ['[CLS] are quite generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.979 (perp=7.632, rec=0.423, cos=0.030), tot_loss_proj:1.934 [t=0.24s]
prediction: ['[CLS] are quite generic [SEP]']
[1350/2000] tot_loss=2.106 (perp=8.320, rec=0.419, cos=0.023), tot_loss_proj:1.761 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=2.098 (perp=8.320, rec=0.415, cos=0.019), tot_loss_proj:1.759 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=2.187 (perp=8.320, rec=0.424, cos=0.099), tot_loss_proj:1.766 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=2.097 (perp=8.320, rec=0.411, cos=0.023), tot_loss_proj:1.762 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=2.082 (perp=8.320, rec=0.408, cos=0.010), tot_loss_proj:1.760 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=2.097 (perp=8.320, rec=0.416, cos=0.017), tot_loss_proj:1.741 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=2.081 (perp=8.320, rec=0.412, cos=0.005), tot_loss_proj:1.758 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=2.100 (perp=8.320, rec=0.411, cos=0.025), tot_loss_proj:1.754 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.079 (perp=8.320, rec=0.410, cos=0.005), tot_loss_proj:1.763 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=2.102 (perp=8.320, rec=0.419, cos=0.019), tot_loss_proj:1.750 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=2.080 (perp=8.320, rec=0.412, cos=0.003), tot_loss_proj:1.762 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=2.113 (perp=8.320, rec=0.407, cos=0.042), tot_loss_proj:1.766 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=2.087 (perp=8.320, rec=0.419, cos=0.004), tot_loss_proj:1.748 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.084 (perp=8.320, rec=0.415, cos=0.006), tot_loss_proj:1.762 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.011 | p: 92.028 | r: 94.114
rouge2     | fm: 60.069 | p: 59.663 | r: 60.646
rougeL     | fm: 82.094 | p: 81.299 | r: 83.060
rougeLsum  | fm: 81.697 | p: 80.877 | r: 82.509
r1fm+r2fm = 153.080

input #27 time: 0:09:22 | total time: 4:22:17


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.9993341797945816
highest_index [0]
highest [0.9993341797945816]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8130366802215576 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.7981401681900024 for ['[CLS] guests mackenzie voyager reader [SEP]']
[Init] best rec loss: 0.7943398356437683 for ['[CLS] stations finchyte planned [SEP]']
[Init] best rec loss: 0.7936493754386902 for ['[CLS]ness aluminium cleveland tv [SEP]']
[Init] best rec loss: 0.782181978225708 for ['[CLS] james facilitieslty ¨ [SEP]']
[Init] best rec loss: 0.7480621337890625 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best perm rec loss: 0.7475418448448181 for ['[CLS] mixed battlefield fullyuro [SEP]']
[Init] best perm rec loss: 0.7444020509719849 for ['[CLS] fullyuro battlefield mixed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.329 (perp=10.312, rec=0.242, cos=0.025), tot_loss_proj:2.975 [t=0.23s]
prediction: ['[CLS] for minute minutes minutes [SEP]']
[ 100/2000] tot_loss=1.584 (perp=7.445, rec=0.092, cos=0.003), tot_loss_proj:1.850 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 150/2000] tot_loss=1.562 (perp=7.445, rec=0.071, cos=0.001), tot_loss_proj:1.847 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 200/2000] tot_loss=1.563 (perp=7.445, rec=0.070, cos=0.003), tot_loss_proj:1.843 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.542 (perp=7.445, rec=0.052, cos=0.001), tot_loss_proj:1.849 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 300/2000] tot_loss=1.552 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.849 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.563 (perp=7.445, rec=0.072, cos=0.001), tot_loss_proj:1.838 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.554 (perp=7.445, rec=0.064, cos=0.001), tot_loss_proj:1.842 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=1.554 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.845 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.559 (perp=7.445, rec=0.069, cos=0.001), tot_loss_proj:1.847 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.557 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=1.547 (perp=7.445, rec=0.057, cos=0.001), tot_loss_proj:1.836 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.548 (perp=7.445, rec=0.058, cos=0.001), tot_loss_proj:1.836 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.557 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=1.558 (perp=7.445, rec=0.068, cos=0.001), tot_loss_proj:1.845 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.545 (perp=7.445, rec=0.055, cos=0.001), tot_loss_proj:1.836 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.553 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.837 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=1.558 (perp=7.445, rec=0.068, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.540 (perp=7.445, rec=0.049, cos=0.001), tot_loss_proj:1.840 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.830 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=1.554 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.840 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=1.558 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.833 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=1.551 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.838 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=1.546 (perp=7.445, rec=0.056, cos=0.001), tot_loss_proj:1.836 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=1.550 (perp=7.445, rec=0.060, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=1.555 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=1.555 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.836 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=1.555 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.846 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=1.557 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.834 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=1.555 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.834 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=1.551 (perp=7.445, rec=0.060, cos=0.001), tot_loss_proj:1.835 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=1.544 (perp=7.445, rec=0.053, cos=0.001), tot_loss_proj:1.836 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=1.551 (perp=7.445, rec=0.060, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=1.552 (perp=7.445, rec=0.062, cos=0.001), tot_loss_proj:1.831 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=1.548 (perp=7.445, rec=0.058, cos=0.001), tot_loss_proj:1.840 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=1.559 (perp=7.445, rec=0.068, cos=0.001), tot_loss_proj:1.833 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=1.544 (perp=7.445, rec=0.054, cos=0.001), tot_loss_proj:1.839 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=1.546 (perp=7.445, rec=0.056, cos=0.001), tot_loss_proj:1.835 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 93.246 | p: 92.328 | r: 94.277
rouge2     | fm: 59.757 | p: 59.383 | r: 60.161
rougeL     | fm: 82.071 | p: 81.329 | r: 82.835
rougeLsum  | fm: 81.869 | p: 81.100 | r: 82.678
r1fm+r2fm = 153.003

input #28 time: 0:09:23 | total time: 4:31:40


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9992957407854928
highest_index [0]
highest [0.9992957407854928]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.947530210018158 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.9259920120239258 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.9125291109085083 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.8549603223800659 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8497192859649658 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 0.8459416627883911 for ['[CLS] lordship buckingham rather postsbor we home wildlife valleygan [SEP]']
[Init] best rec loss: 0.845466136932373 for ['[CLS] crystal shock completion carrydable stay recordingdrive ella off [SEP]']
[Init] best rec loss: 0.8421328067779541 for ['[CLS] downke his heir wantedø degree opposition march head [SEP]']
[Init] best rec loss: 0.8202964663505554 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 0.8111938834190369 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best perm rec loss: 0.8096943497657776 for ['[CLS] transmit f veto u cells axlefounded meters mostly bu [SEP]']
[Init] best perm rec loss: 0.8091574907302856 for ['[CLS] cells meters axle bu mostly u transmit f vetofounded [SEP]']
[Init] best perm rec loss: 0.8048059940338135 for ['[CLS] veto transmit f cells axle mostlyfounded meters u bu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.977 (perp=12.906, rec=0.358, cos=0.038), tot_loss_proj:3.758 [t=0.23s]
prediction: ['[CLS]unce building it wondered blame demonstration stiff what resign carbon [SEP]']
[ 100/2000] tot_loss=2.383 (perp=10.577, rec=0.250, cos=0.017), tot_loss_proj:3.512 [t=0.23s]
prediction: ['[CLS] resident fact resident think not joanna. believe believe carmel [SEP]']
[ 150/2000] tot_loss=1.867 (perp=8.165, rec=0.224, cos=0.010), tot_loss_proj:2.932 [t=0.23s]
prediction: ['[CLS] resident are resident. not believe. believe believe is [SEP]']
[ 200/2000] tot_loss=1.868 (perp=8.270, rec=0.206, cos=0.008), tot_loss_proj:2.748 [t=0.24s]
prediction: ['[CLS] resident not resident. not believe. believe believe is [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.648 (perp=7.221, rec=0.193, cos=0.011), tot_loss_proj:2.446 [t=0.24s]
prediction: ['[CLS] believe not resident think not.. believe resident evil [SEP]']
[ 300/2000] tot_loss=1.465 (perp=6.449, rec=0.166, cos=0.008), tot_loss_proj:2.301 [t=0.24s]
prediction: ['[CLS] also is it i not.. believe resident evil [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.237 (perp=5.403, rec=0.149, cos=0.008), tot_loss_proj:2.029 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.219 (perp=5.403, rec=0.132, cos=0.006), tot_loss_proj:2.029 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[ 450/2000] tot_loss=1.209 (perp=5.403, rec=0.123, cos=0.006), tot_loss_proj:2.025 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.198 (perp=5.403, rec=0.112, cos=0.005), tot_loss_proj:2.030 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.180 (perp=5.403, rec=0.095, cos=0.005), tot_loss_proj:2.020 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[ 600/2000] tot_loss=1.176 (perp=5.403, rec=0.091, cos=0.005), tot_loss_proj:2.033 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.177 (perp=5.403, rec=0.092, cos=0.004), tot_loss_proj:2.031 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.178 (perp=5.403, rec=0.093, cos=0.004), tot_loss_proj:2.031 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[ 750/2000] tot_loss=1.175 (perp=5.403, rec=0.090, cos=0.004), tot_loss_proj:2.029 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.181 (perp=5.403, rec=0.096, cos=0.004), tot_loss_proj:2.033 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.168 (perp=5.403, rec=0.083, cos=0.004), tot_loss_proj:2.027 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[ 900/2000] tot_loss=1.164 (perp=5.403, rec=0.079, cos=0.004), tot_loss_proj:2.031 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.157 (perp=5.403, rec=0.073, cos=0.004), tot_loss_proj:2.029 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1000/2000] tot_loss=1.176 (perp=5.403, rec=0.092, cos=0.004), tot_loss_proj:2.032 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[1050/2000] tot_loss=1.174 (perp=5.403, rec=0.089, cos=0.004), tot_loss_proj:2.027 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1100/2000] tot_loss=1.177 (perp=5.403, rec=0.093, cos=0.004), tot_loss_proj:2.031 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1150/2000] tot_loss=1.164 (perp=5.403, rec=0.079, cos=0.004), tot_loss_proj:2.028 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[1200/2000] tot_loss=1.170 (perp=5.403, rec=0.085, cos=0.004), tot_loss_proj:2.027 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1250/2000] tot_loss=1.177 (perp=5.403, rec=0.093, cos=0.004), tot_loss_proj:2.029 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1300/2000] tot_loss=1.165 (perp=5.403, rec=0.080, cos=0.004), tot_loss_proj:2.029 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[1350/2000] tot_loss=1.177 (perp=5.403, rec=0.093, cos=0.004), tot_loss_proj:2.033 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1400/2000] tot_loss=1.160 (perp=5.403, rec=0.075, cos=0.004), tot_loss_proj:2.032 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1450/2000] tot_loss=1.169 (perp=5.403, rec=0.085, cos=0.004), tot_loss_proj:2.025 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[1500/2000] tot_loss=1.167 (perp=5.403, rec=0.083, cos=0.004), tot_loss_proj:2.030 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1550/2000] tot_loss=1.170 (perp=5.403, rec=0.085, cos=0.004), tot_loss_proj:2.026 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1600/2000] tot_loss=1.172 (perp=5.403, rec=0.088, cos=0.003), tot_loss_proj:2.030 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[1650/2000] tot_loss=1.172 (perp=5.403, rec=0.088, cos=0.003), tot_loss_proj:2.031 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1700/2000] tot_loss=1.176 (perp=5.403, rec=0.092, cos=0.003), tot_loss_proj:2.030 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1750/2000] tot_loss=1.165 (perp=5.403, rec=0.081, cos=0.003), tot_loss_proj:2.031 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[1800/2000] tot_loss=1.170 (perp=5.403, rec=0.086, cos=0.003), tot_loss_proj:2.028 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1850/2000] tot_loss=1.173 (perp=5.403, rec=0.090, cos=0.003), tot_loss_proj:2.032 [t=0.24s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[1900/2000] tot_loss=1.173 (perp=5.403, rec=0.089, cos=0.003), tot_loss_proj:2.029 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
[1950/2000] tot_loss=1.168 (perp=5.403, rec=0.084, cos=0.003), tot_loss_proj:2.028 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Attempt swap
[2000/2000] tot_loss=1.162 (perp=5.403, rec=0.078, cos=0.003), tot_loss_proj:2.030 [t=0.23s]
prediction: ['[CLS] it is also i not.. believe resident evil [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] it is also i not.. believe resident evil [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 100.000 | r: 90.909
rouge2     | fm: 10.526 | p: 11.111 | r: 10.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 105.764

[Aggregate metrics]:
rouge1     | fm: 93.281 | p: 92.565 | r: 94.150
rouge2     | fm: 57.861 | p: 57.476 | r: 58.359
rougeL     | fm: 81.298 | p: 80.742 | r: 81.986
rougeLsum  | fm: 80.873 | p: 80.167 | r: 81.721
r1fm+r2fm = 151.143

input #29 time: 0:09:17 | total time: 4:40:57


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.9992726237091217
highest_index [0]
highest [0.9992726237091217]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.915320873260498 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8711962103843689 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.8100265264511108 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7817462682723999 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7791784405708313 for ['[CLS] footading night [SEP]']
[Init] best rec loss: 0.7326138615608215 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.7145380973815918 for ['[CLS] acceleration council lizard [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.601 (perp=11.577, rec=0.272, cos=0.013), tot_loss_proj:3.431 [t=0.23s]
prediction: ['[CLS]zzability percentage [SEP]']
[ 100/2000] tot_loss=2.746 (perp=12.949, rec=0.149, cos=0.007), tot_loss_proj:3.731 [t=0.23s]
prediction: ['[CLS]zzability fi [SEP]']
[ 150/2000] tot_loss=2.731 (perp=12.949, rec=0.132, cos=0.009), tot_loss_proj:3.770 [t=0.23s]
prediction: ['[CLS]zzability fi [SEP]']
[ 200/2000] tot_loss=2.700 (perp=12.949, rec=0.107, cos=0.004), tot_loss_proj:3.762 [t=0.23s]
prediction: ['[CLS]zzability fi [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.028 (perp=9.539, rec=0.115, cos=0.005), tot_loss_proj:1.973 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.975 (perp=9.539, rec=0.065, cos=0.002), tot_loss_proj:1.968 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.984 (perp=9.539, rec=0.074, cos=0.002), tot_loss_proj:1.988 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.975 (perp=9.539, rec=0.066, cos=0.001), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.969 (perp=9.539, rec=0.060, cos=0.002), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.971 (perp=9.539, rec=0.062, cos=0.002), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.985 (perp=9.539, rec=0.075, cos=0.001), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.968 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.985 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.965 (perp=9.539, rec=0.056, cos=0.001), tot_loss_proj:1.975 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.983 (perp=9.539, rec=0.074, cos=0.001), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.966 (perp=9.539, rec=0.057, cos=0.001), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.960 (perp=9.539, rec=0.051, cos=0.001), tot_loss_proj:1.967 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.970 (perp=9.539, rec=0.061, cos=0.001), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.986 (perp=9.539, rec=0.077, cos=0.001), tot_loss_proj:1.978 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.962 (perp=9.539, rec=0.053, cos=0.001), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.971 (perp=9.539, rec=0.061, cos=0.001), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.970 (perp=9.539, rec=0.061, cos=0.001), tot_loss_proj:1.968 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.973 (perp=9.539, rec=0.064, cos=0.001), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.971 (perp=9.539, rec=0.062, cos=0.001), tot_loss_proj:1.973 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.968 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.983 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.980 (perp=9.539, rec=0.071, cos=0.001), tot_loss_proj:1.985 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.972 (perp=9.539, rec=0.063, cos=0.001), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.968 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.961 (perp=9.539, rec=0.051, cos=0.001), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.969 (perp=9.539, rec=0.060, cos=0.001), tot_loss_proj:1.985 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.969 (perp=9.539, rec=0.060, cos=0.001), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.972 (perp=9.539, rec=0.063, cos=0.001), tot_loss_proj:1.977 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.968 (perp=9.539, rec=0.058, cos=0.001), tot_loss_proj:1.980 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.978 (perp=9.539, rec=0.068, cos=0.001), tot_loss_proj:1.970 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.968 (perp=9.539, rec=0.059, cos=0.001), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.972 (perp=9.539, rec=0.062, cos=0.001), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.974 (perp=9.539, rec=0.065, cos=0.001), tot_loss_proj:1.986 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.965 (perp=9.539, rec=0.055, cos=0.001), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.971 (perp=9.539, rec=0.062, cos=0.001), tot_loss_proj:1.975 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.976 (perp=9.539, rec=0.067, cos=0.001), tot_loss_proj:1.974 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.971 (perp=9.539, rec=0.062, cos=0.001), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.502 | p: 92.816 | r: 94.329
rouge2     | fm: 59.510 | p: 59.167 | r: 59.961
rougeL     | fm: 81.656 | p: 81.049 | r: 82.411
rougeLsum  | fm: 81.411 | p: 80.805 | r: 82.215
r1fm+r2fm = 153.012

input #30 time: 0:09:15 | total time: 4:50:13


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9993397445870693
highest_index [0]
highest [0.9993397445870693]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9391812086105347 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.9200879335403442 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8856512308120728 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.8632071614265442 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.8012497425079346 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 0.8010070323944092 for ['[CLS] robin artwork running [SEP]']
[Init] best perm rec loss: 0.7970992922782898 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.522 (perp=11.092, rec=0.275, cos=0.028), tot_loss_proj:4.054 [t=0.23s]
prediction: ['[CLS] better stall vehicle [SEP]']
[ 100/2000] tot_loss=2.104 (perp=9.657, rec=0.155, cos=0.017), tot_loss_proj:2.399 [t=0.24s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=2.076 (perp=9.657, rec=0.130, cos=0.014), tot_loss_proj:2.402 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 200/2000] tot_loss=2.059 (perp=9.657, rec=0.115, cos=0.013), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.881 (perp=8.742, rec=0.120, cos=0.013), tot_loss_proj:3.280 [t=0.23s]
prediction: ['[CLS] better a vehicle [SEP]']
[ 300/2000] tot_loss=1.884 (perp=8.742, rec=0.123, cos=0.013), tot_loss_proj:3.284 [t=0.23s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.192 (perp=10.266, rec=0.125, cos=0.014), tot_loss_proj:3.091 [t=0.23s]
prediction: ['[CLS] easiest better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.175 (perp=10.266, rec=0.109, cos=0.013), tot_loss_proj:3.074 [t=0.23s]
prediction: ['[CLS] easiest better vehicle [SEP]']
[ 450/2000] tot_loss=1.649 (perp=7.603, rec=0.117, cos=0.011), tot_loss_proj:1.666 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.621 (perp=7.603, rec=0.097, cos=0.004), tot_loss_proj:1.665 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.595 (perp=7.603, rec=0.073, cos=0.002), tot_loss_proj:1.662 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.666 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.664 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.594 (perp=7.603, rec=0.072, cos=0.001), tot_loss_proj:1.673 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.590 (perp=7.603, rec=0.068, cos=0.001), tot_loss_proj:1.654 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.670 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.665 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.656 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.574 (perp=7.603, rec=0.052, cos=0.001), tot_loss_proj:1.669 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.664 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.580 (perp=7.603, rec=0.058, cos=0.001), tot_loss_proj:1.656 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.576 (perp=7.603, rec=0.054, cos=0.001), tot_loss_proj:1.655 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.662 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.662 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.654 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.594 (perp=7.603, rec=0.072, cos=0.001), tot_loss_proj:1.674 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.661 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.655 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.659 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.674 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.669 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.658 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.598 (perp=7.603, rec=0.076, cos=0.001), tot_loss_proj:1.661 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.603, rec=0.075, cos=0.001), tot_loss_proj:1.660 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.656 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.590 (perp=7.603, rec=0.068, cos=0.001), tot_loss_proj:1.676 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.646 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.577 (perp=7.603, rec=0.056, cos=0.001), tot_loss_proj:1.662 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.662 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.657 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.735 | p: 93.059 | r: 94.551
rouge2     | fm: 60.649 | p: 60.307 | r: 61.053
rougeL     | fm: 82.483 | p: 81.895 | r: 83.092
rougeLsum  | fm: 82.099 | p: 81.489 | r: 82.864
r1fm+r2fm = 154.385

input #31 time: 0:09:14 | total time: 4:59:27


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9992524215190559
highest_index [0]
highest [0.9992524215190559]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.0390509366989136 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9474079608917236 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 0.8893988728523254 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.8806267380714417 for ['[CLS] shot scale nest benefit jenny aspen introduced everything zoe arrival capital theory [SEP]']
[Init] best rec loss: 0.8802824020385742 for ['[CLS] spiders armenian dreams¨ me riff clearly space cyprus center ᵍ glory [SEP]']
[Init] best rec loss: 0.8597884774208069 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.8490630984306335 for ['[CLS]ono harlem auckland hanna organization rex force riot back decker mud tune [SEP]']
[Init] best rec loss: 0.8473441004753113 for ['[CLS]erated doc tax 2009 citizens completely fa outreach {zic spot 2 [SEP]']
[Init] best perm rec loss: 0.8473353981971741 for ['[CLS] taxerated 2009zic doc fa spot outreach completely citizens { 2 [SEP]']
[Init] best perm rec loss: 0.8460664749145508 for ['[CLS] { citizens tax doc 2009erated fa outreachzic spot 2 completely [SEP]']
[Init] best perm rec loss: 0.8459265828132629 for ['[CLS] 2009 citizens fa doc { 2 completelyzicerated tax spot outreach [SEP]']
[Init] best perm rec loss: 0.8454993963241577 for ['[CLS]erated doc spot citizens completely outreach fazic tax 2 2009 { [SEP]']
[Init] best perm rec loss: 0.8453917503356934 for ['[CLS] completely citizenserated { fa 2009 spot 2 doc tax outreachzic [SEP]']
[Init] best perm rec loss: 0.8444403409957886 for ['[CLS]zic completely { tax 2009erated doc outreach fa spot 2 citizens [SEP]']
[Init] best perm rec loss: 0.8436647057533264 for ['[CLS] 2009 tax 2 outreach doc completely spotzic { faerated citizens [SEP]']
[Init] best perm rec loss: 0.8428959250450134 for ['[CLS] fa { 2009zic 2 outreach spot doc completely tax citizenserated [SEP]']
[Init] best perm rec loss: 0.842507541179657 for ['[CLS] {zic spot 2009 citizens outreach completely 2 fa doc taxerated [SEP]']
[Init] best perm rec loss: 0.8423187732696533 for ['[CLS] 2009 outreach citizens tax { completely 2 doc spot faeratedzic [SEP]']
[Init] best perm rec loss: 0.8402031660079956 for ['[CLS] citizens doc 2009 spot completely { outreach 2erated fazic tax [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.674 (perp=11.937, rec=0.280, cos=0.007), tot_loss_proj:3.486 [t=0.22s]
prediction: ['[CLS] successful effective visionary fiction ben madelinechurch criteria ;onate storiestation [SEP]']
[ 100/2000] tot_loss=2.720 (perp=12.537, rec=0.209, cos=0.003), tot_loss_proj:3.861 [t=0.22s]
prediction: ['[CLS] accessible easily accessible stories donate alexiachurch easily pullonate storiesonate [SEP]']
[ 150/2000] tot_loss=2.836 (perp=13.200, rec=0.191, cos=0.005), tot_loss_proj:3.889 [t=0.22s]
prediction: ['[CLS] accessible together accessible stories dominic alexiachurch easily pullonate storiesonate [SEP]']
[ 200/2000] tot_loss=2.743 (perp=12.997, rec=0.141, cos=0.002), tot_loss_proj:4.122 [t=0.22s]
prediction: ['[CLS] easily together accessible stories res alexiaond easily pullonate accessibleonate [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.402 (perp=11.261, rec=0.147, cos=0.003), tot_loss_proj:3.606 [t=0.22s]
prediction: ['[CLS] easily together accessible stories profonate inity pull with accessible alexia [SEP]']
[ 300/2000] tot_loss=2.330 (perp=11.069, rec=0.114, cos=0.002), tot_loss_proj:3.455 [t=0.22s]
prediction: ['[CLS] easily together accessible stories profonate thatity pull with accessible alexia [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.281 (perp=10.826, rec=0.114, cos=0.002), tot_loss_proj:3.587 [t=0.22s]
prediction: ['[CLS] easily togetherurg stories resonate with asity pull accessible alexia [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.110 (perp=9.959, rec=0.117, cos=0.002), tot_loss_proj:3.278 [t=0.22s]
prediction: ['[CLS] easily togetherund stories resonate with pullity as accessible alexia [SEP]']
[ 450/2000] tot_loss=2.093 (perp=9.959, rec=0.100, cos=0.002), tot_loss_proj:3.283 [t=0.22s]
prediction: ['[CLS] easily togetherund stories resonate with pullity as accessible alexia [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.086 (perp=9.959, rec=0.092, cos=0.002), tot_loss_proj:3.281 [t=0.22s]
prediction: ['[CLS] easily togetherund stories resonate with pullity as accessible alexia [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.085 (perp=9.959, rec=0.091, cos=0.002), tot_loss_proj:3.282 [t=0.22s]
prediction: ['[CLS] easily togetherund stories resonate with pullity as accessible alexia [SEP]']
[ 600/2000] tot_loss=2.084 (perp=9.959, rec=0.091, cos=0.002), tot_loss_proj:3.283 [t=0.22s]
prediction: ['[CLS] easily togetherund stories resonate with pullity as accessible alexia [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.088 (perp=9.959, rec=0.095, cos=0.002), tot_loss_proj:3.286 [t=0.22s]
prediction: ['[CLS] easily togetherund stories resonate with pullity as accessible alexia [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.074 (perp=9.959, rec=0.081, cos=0.002), tot_loss_proj:3.291 [t=0.22s]
prediction: ['[CLS] easily togetherund stories resonate with pullity as accessible alexia [SEP]']
[ 750/2000] tot_loss=2.070 (perp=9.959, rec=0.076, cos=0.002), tot_loss_proj:3.287 [t=0.22s]
prediction: ['[CLS] easily togetherund stories resonate with pullity as accessible alexia [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.068 (perp=9.919, rec=0.083, cos=0.002), tot_loss_proj:3.145 [t=0.22s]
prediction: ['[CLS] easily togetherund stories resonate with pullity accessible as alexia [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.962 (perp=9.288, rec=0.102, cos=0.002), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] easily together stories resonate with pullundity accessible as alexia [SEP]']
[ 900/2000] tot_loss=2.194 (perp=10.512, rec=0.090, cos=0.002), tot_loss_proj:3.638 [t=0.22s]
prediction: ['[CLS] easily together stories resonate with pullundity accessible prof alexia [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.278 (perp=10.917, rec=0.092, cos=0.002), tot_loss_proj:3.646 [t=0.22s]
prediction: ['[CLS] easily together stories resonate with handundity accessible pullcl [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.084 (perp=9.927, rec=0.096, cos=0.002), tot_loss_proj:2.657 [t=0.22s]
prediction: ['[CLS] easily together stories resonate with handphundity accessible pull [SEP]']
[1050/2000] tot_loss=2.082 (perp=9.927, rec=0.095, cos=0.002), tot_loss_proj:2.650 [t=0.22s]
prediction: ['[CLS] easily together stories resonate with handphundity accessible pull [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.938 (perp=9.268, rec=0.082, cos=0.002), tot_loss_proj:2.885 [t=0.22s]
prediction: ['[CLS] easily together stories resonate with pullphundity accessible as [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.793 (perp=8.464, rec=0.099, cos=0.002), tot_loss_proj:2.889 [t=0.22s]
prediction: ['[CLS] easily together stories resonate with pullclundity as accessible [SEP]']
[1200/2000] tot_loss=1.818 (perp=8.667, rec=0.083, cos=0.002), tot_loss_proj:2.835 [t=0.22s]
prediction: ['[CLS] easily together stories resonate with pullphundity as accessible [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.012 (perp=9.562, rec=0.098, cos=0.002), tot_loss_proj:3.326 [t=0.22s]
prediction: ['[CLS] together stories resonate that pullphundity hand easily accessible [SEP]']
Attempt swap
[1300/2000] tot_loss=1.680 (perp=7.897, rec=0.098, cos=0.002), tot_loss_proj:2.804 [t=0.22s]
prediction: ['[CLS] together stories resonate with pullphundity as easily accessible [SEP]']
[1350/2000] tot_loss=1.657 (perp=7.897, rec=0.076, cos=0.002), tot_loss_proj:2.807 [t=0.22s]
prediction: ['[CLS] together stories resonate with pullphundity as easily accessible [SEP]']
Attempt swap
[1400/2000] tot_loss=1.942 (perp=9.242, rec=0.091, cos=0.002), tot_loss_proj:3.152 [t=0.22s]
prediction: ['[CLS] together stories resonate with pullphundity hand easily accessible [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.804 (perp=8.527, rec=0.097, cos=0.002), tot_loss_proj:2.742 [t=0.22s]
prediction: ['[CLS] hand together stories resonate with pullphundity easily accessible [SEP]']
[1500/2000] tot_loss=1.789 (perp=8.527, rec=0.082, cos=0.002), tot_loss_proj:2.738 [t=0.22s]
prediction: ['[CLS] hand together stories resonate with pullphundity easily accessible [SEP]']
Attempt swap
[1550/2000] tot_loss=1.791 (perp=8.527, rec=0.083, cos=0.002), tot_loss_proj:2.885 [t=0.22s]
prediction: ['[CLS] hand together stories resonate with pullclundity easily accessible [SEP]']
Attempt swap
[1600/2000] tot_loss=1.796 (perp=8.527, rec=0.089, cos=0.002), tot_loss_proj:2.882 [t=0.22s]
prediction: ['[CLS] hand together stories resonate with pullclundity easily accessible [SEP]']
[1650/2000] tot_loss=1.796 (perp=8.527, rec=0.088, cos=0.002), tot_loss_proj:2.881 [t=0.22s]
prediction: ['[CLS] hand together stories resonate with pullclundity easily accessible [SEP]']
Attempt swap
[1700/2000] tot_loss=1.786 (perp=8.527, rec=0.079, cos=0.002), tot_loss_proj:2.881 [t=0.22s]
prediction: ['[CLS] hand together stories resonate with pullclundity easily accessible [SEP]']
Attempt swap
[1750/2000] tot_loss=1.799 (perp=8.527, rec=0.092, cos=0.002), tot_loss_proj:2.882 [t=0.22s]
prediction: ['[CLS] hand together stories resonate with pullclundity easily accessible [SEP]']
[1800/2000] tot_loss=1.796 (perp=8.527, rec=0.089, cos=0.002), tot_loss_proj:2.885 [t=0.22s]
prediction: ['[CLS] hand together stories resonate with pullclundity easily accessible [SEP]']
Attempt swap
Put prefix at the end
[1850/2000] tot_loss=1.916 (perp=9.125, rec=0.089, cos=0.002), tot_loss_proj:3.228 [t=0.22s]
prediction: ['[CLS] together stories resonate that pullclundity easily accessible hand [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.764 (perp=8.361, rec=0.090, cos=0.002), tot_loss_proj:2.770 [t=0.22s]
prediction: ['[CLS] together stories resonate that handclundity easily accessible pull [SEP]']
[1950/2000] tot_loss=1.867 (perp=8.877, rec=0.089, cos=0.002), tot_loss_proj:2.814 [t=0.22s]
prediction: ['[CLS] together stories resonate that asclundity easily accessible pull [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.838 (perp=8.735, rec=0.089, cos=0.002), tot_loss_proj:3.123 [t=0.22s]
prediction: ['[CLS] together stories resonate that accessibleclundity easily as pull [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] hand together stories resonate with pullclundity easily accessible [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 80.000 | r: 72.727
rouge2     | fm: 21.053 | p: 22.222 | r: 20.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 97.243

[Aggregate metrics]:
rouge1     | fm: 93.126 | p: 92.624 | r: 93.792
rouge2     | fm: 59.615 | p: 59.226 | r: 60.064
rougeL     | fm: 81.540 | p: 81.029 | r: 82.176
rougeLsum  | fm: 81.274 | p: 80.771 | r: 81.850
r1fm+r2fm = 152.741

input #32 time: 0:08:48 | total time: 5:08:16


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9992770423515678
highest_index [0]
highest [0.9992770423515678]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 1.0013114213943481 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9758126139640808 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.954909086227417 for ['[CLS] parent [SEP]']
[Init] best rec loss: 0.9039609432220459 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8219714164733887 for ['[CLS] attributed [SEP]']
[Init] best rec loss: 0.7999625205993652 for ['[CLS] showing [SEP]']
[Init] best rec loss: 0.7876425981521606 for ['[CLS] manifold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.413 (perp=11.231, rec=0.158, cos=0.009), tot_loss_proj:3.005 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.002), tot_loss_proj:2.400 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.002), tot_loss_proj:2.393 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.298 (perp=11.231, rec=0.051, cos=0.002), tot_loss_proj:2.397 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.311 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.397 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.391 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.303 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.386 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.315 (perp=11.231, rec=0.068, cos=0.001), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.392 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.311 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.391 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.314 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.400 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.304 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.411 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.401 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.314 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.400 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.297 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.391 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.386 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.395 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.311 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.314 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.395 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.320 (perp=11.231, rec=0.072, cos=0.001), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.320 (perp=11.231, rec=0.073, cos=0.001), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.395 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.310 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.379 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.315 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.314 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.402 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.395 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.303 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.407 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.403 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.309 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.393 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.298 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.399 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.313 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.405 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.405 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.306 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.390 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.316 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.312 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.396 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.329 | p: 92.775 | r: 94.002
rouge2     | fm: 60.557 | p: 60.181 | r: 60.841
rougeL     | fm: 82.213 | p: 81.742 | r: 82.832
rougeLsum  | fm: 81.858 | p: 81.382 | r: 82.456
r1fm+r2fm = 153.886

input #33 time: 0:09:12 | total time: 5:17:28


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9992090053245604
highest_index [0]
highest [0.9992090053245604]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8960171341896057 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8869714736938477 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8454265594482422 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8433679938316345 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.8128030300140381 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.812659740447998 for ['[CLS] ship founder drivers worth slight okay lissa field alongaskibe who statue [SEP]']
[Init] best perm rec loss: 0.8106471300125122 for ['[CLS] slight founder ship drivers statue along okayask lissa whoibe field worth [SEP]']
[Init] best perm rec loss: 0.8101394176483154 for ['[CLS]ibe drivers lissa okay along worth statue shipask who field slight founder [SEP]']
[Init] best perm rec loss: 0.8095391392707825 for ['[CLS] slightask statueibe who field founder worth okay along drivers lissa ship [SEP]']
[Init] best perm rec loss: 0.808542013168335 for ['[CLS] worth who drivers along ship slight founder okay lissa fieldaskibe statue [SEP]']
[Init] best perm rec loss: 0.8066660165786743 for ['[CLS] slight founder lissa whoask ship statue along drivers fieldibe okay worth [SEP]']
[Init] best perm rec loss: 0.8065962791442871 for ['[CLS] along ship drivers statueask who worth lissa field founder slightibe okay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.744 (perp=12.139, rec=0.295, cos=0.021), tot_loss_proj:4.199 [t=0.23s]
prediction: ['[CLS]. urgency lair steve julia. extreme take urgency viewer lawrencetv lord [SEP]']
[ 100/2000] tot_loss=2.447 (perp=11.281, rec=0.183, cos=0.007), tot_loss_proj:3.758 [t=0.23s]
prediction: ['[CLS] and urgency build steve viewer. extreme take urgency viewer perry viewer enrico [SEP]']
[ 150/2000] tot_loss=2.440 (perp=11.409, rec=0.149, cos=0.009), tot_loss_proj:4.041 [t=0.24s]
prediction: ['[CLS] and urgency buildneas viewer. extreme take urgency viewer unbearable viewer precious [SEP]']
[ 200/2000] tot_loss=2.420 (perp=11.534, rec=0.110, cos=0.003), tot_loss_proj:3.556 [t=0.23s]
prediction: ['[CLS] and urgency build mind viewer. extreme take urgency viewer arc mind the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.164 (perp=10.222, rec=0.117, cos=0.003), tot_loss_proj:2.844 [t=0.23s]
prediction: ['[CLS] and urgency build in the baron extreme take urgency viewer ben mind. [SEP]']
[ 300/2000] tot_loss=2.135 (perp=10.222, rec=0.088, cos=0.003), tot_loss_proj:2.843 [t=0.23s]
prediction: ['[CLS] and urgency build in the baron extreme take urgency viewer ben mind. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.889 (perp=8.980, rec=0.091, cos=0.002), tot_loss_proj:2.841 [t=0.23s]
prediction: ['[CLS] ben urgency build in the baron extreme take urgency viewer and mind. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.618 (perp=7.643, rec=0.086, cos=0.003), tot_loss_proj:2.445 [t=0.23s]
prediction: ['[CLS] and ben urgency build in the extreme take urgency viewer and mind. [SEP]']
[ 450/2000] tot_loss=1.620 (perp=7.643, rec=0.089, cos=0.002), tot_loss_proj:2.440 [t=0.24s]
prediction: ['[CLS] and ben urgency build in the extreme take urgency viewer and mind. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.507 (perp=7.118, rec=0.082, cos=0.002), tot_loss_proj:2.232 [t=0.23s]
prediction: ['[CLS] ben urgency build in the extreme and take urgency viewer and mind. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.373 (perp=6.471, rec=0.077, cos=0.002), tot_loss_proj:1.903 [t=0.23s]
prediction: ['[CLS] the urgency build in the extreme viewer and take urgency and mind. [SEP]']
[ 600/2000] tot_loss=1.439 (perp=6.789, rec=0.079, cos=0.002), tot_loss_proj:2.052 [t=0.23s]
prediction: ['[CLS] at urgency build in the extreme viewer and take urgency and mind. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.426 (perp=6.789, rec=0.067, cos=0.002), tot_loss_proj:2.053 [t=0.23s]
prediction: ['[CLS] at urgency build in the extreme viewer and take urgency and mind. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.427 (perp=6.756, rec=0.074, cos=0.002), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] build at urgency in the extreme viewer and take urgency and mind. [SEP]']
[ 750/2000] tot_loss=1.441 (perp=6.756, rec=0.088, cos=0.002), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] build at urgency in the extreme viewer and take urgency and mind. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.389 (perp=6.542, rec=0.079, cos=0.002), tot_loss_proj:1.996 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme viewer and take at urgency and mind. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.383 (perp=6.542, rec=0.073, cos=0.002), tot_loss_proj:1.999 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme viewer and take at urgency and mind. [SEP]']
[ 900/2000] tot_loss=1.384 (perp=6.542, rec=0.074, cos=0.002), tot_loss_proj:1.994 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme viewer and take at urgency and mind. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.331 (perp=6.239, rec=0.082, cos=0.002), tot_loss_proj:1.781 [t=0.23s]
prediction: ['[CLS] build urgency in the viewer and take of extreme urgency and mind. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.331 (perp=6.239, rec=0.082, cos=0.002), tot_loss_proj:1.785 [t=0.23s]
prediction: ['[CLS] build urgency in the viewer and take of extreme urgency and mind. [SEP]']
[1050/2000] tot_loss=1.404 (perp=6.619, rec=0.079, cos=0.002), tot_loss_proj:1.901 [t=0.23s]
prediction: ['[CLS] build urgency in the viewer and take of extreme urgency on mind. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.408 (perp=6.619, rec=0.082, cos=0.002), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] build urgency in the viewer and take of extreme urgency on mind. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.359 (perp=6.396, rec=0.078, cos=0.002), tot_loss_proj:1.791 [t=0.23s]
prediction: ['[CLS] build urgency in the viewer of extreme urgency and take on mind. [SEP]']
[1200/2000] tot_loss=1.351 (perp=6.396, rec=0.070, cos=0.002), tot_loss_proj:1.794 [t=0.23s]
prediction: ['[CLS] build urgency in the viewer of extreme urgency and take on mind. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.311 (perp=6.206, rec=0.069, cos=0.002), tot_loss_proj:1.989 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.320 (perp=6.206, rec=0.077, cos=0.002), tot_loss_proj:1.994 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
[1350/2000] tot_loss=1.322 (perp=6.206, rec=0.079, cos=0.002), tot_loss_proj:1.987 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.313 (perp=6.206, rec=0.070, cos=0.002), tot_loss_proj:1.986 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.314 (perp=6.206, rec=0.071, cos=0.002), tot_loss_proj:1.996 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
[1500/2000] tot_loss=1.307 (perp=6.206, rec=0.064, cos=0.002), tot_loss_proj:1.992 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.322 (perp=6.206, rec=0.079, cos=0.002), tot_loss_proj:1.993 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.312 (perp=6.206, rec=0.069, cos=0.002), tot_loss_proj:1.996 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
[1650/2000] tot_loss=1.319 (perp=6.206, rec=0.077, cos=0.002), tot_loss_proj:1.993 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.317 (perp=6.206, rec=0.075, cos=0.002), tot_loss_proj:1.986 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.319 (perp=6.206, rec=0.076, cos=0.002), tot_loss_proj:2.000 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]']
[1800/2000] tot_loss=1.448 (perp=6.878, rec=0.071, cos=0.002), tot_loss_proj:1.964 [t=0.23s]
prediction: ['[CLS] build urgency in the extreme the viewer urgency and take on mind. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.283 (perp=6.102, rec=0.061, cos=0.002), tot_loss_proj:1.966 [t=0.23s]
prediction: ['[CLS] build on in the extreme viewer urgency and the take on mind. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.237 (perp=5.803, rec=0.074, cos=0.002), tot_loss_proj:1.792 [t=0.23s]
prediction: ['[CLS] build on urgency in the extreme viewer and the take on mind. [SEP]']
[1950/2000] tot_loss=1.306 (perp=6.202, rec=0.064, cos=0.002), tot_loss_proj:1.982 [t=0.23s]
prediction: ['[CLS] build on urgency in the extreme viewer and of take on mind. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.300 (perp=6.202, rec=0.058, cos=0.002), tot_loss_proj:1.974 [t=0.23s]
prediction: ['[CLS] build on urgency in the extreme viewer and of take on mind. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] build urgency in the extreme of viewer urgency and take on mind. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.857 | p: 92.857 | r: 92.857
rouge2     | fm: 30.769 | p: 30.769 | r: 30.769
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 123.626

[Aggregate metrics]:
rouge1     | fm: 93.307 | p: 92.774 | r: 93.915
rouge2     | fm: 59.981 | p: 59.796 | r: 60.323
rougeL     | fm: 81.876 | p: 81.417 | r: 82.441
rougeLsum  | fm: 81.576 | p: 81.172 | r: 82.151
r1fm+r2fm = 153.288

input #34 time: 0:09:14 | total time: 5:26:43


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9993270316838965
highest_index [0]
highest [0.9993270316838965]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9252316951751709 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.9247497320175171 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 0.9241513609886169 for ['[CLS] nightstand locality shall shifted pdfish migrated reason features happy statisticsbant medium singled anti but least [SEP] contemptness second mia architecture nonsense departments order deserved ا guardian [MASK] hospitaluts itsried direction soc christmas merely sodiummeral score because [SEP]']
[Init] best rec loss: 0.9187696576118469 for ['[CLS] thousand lack alternative energy fae deservevil denied field outside pages province beauty fade actsar dynamic sole one organized folk ms primary appointment devicedran part zion nightmaresdrive isabellaght intervals singer published sleeper signs lynch, somehow position flow [SEP]']
[Init] best perm rec loss: 0.9162565469741821 for ['[CLS], part isabella published lynch one denied folk sleeper beautyght ms nightmares energy province actdrive zionvil appointment fade thousand singer deservesar pages signs somehow intervals dynamic alternative primary sole device flow fae lack field position organizeddran outside [SEP]']
[Init] best perm rec loss: 0.9161269068717957 for ['[CLS] sleeper, flow intervals isabella appointmentdran singer publishedvil deserve province zionsar outside position act dynamic organized part sole beauty folk fae device primary nightmares alternative lack lynch signs field somehowght ms denied thousand fade energy pages onedrive [SEP]']
[Init] best perm rec loss: 0.9152407050132751 for ['[CLS] device zion denied ms pages primary, sleeper dynamic lynchght one intervals singerdran field alternative somehow part fae fade province isabella signsdrive lack thousandvil sole positionsar published nightmares appointment beauty flow deserve organized act folk energy outside [SEP]']
[Init] best perm rec loss: 0.9150510430335999 for ['[CLS] flow, folk act lynch signs positiondrive zion intervals outside thousand lacksar ms pages sole sleeperght appointment published organized device alternative deserve somehow beauty province singer dynamic faevil fade primary one denieddran nightmares part isabella field energy [SEP]']
[Init] best perm rec loss: 0.9148762822151184 for ['[CLS] field, provincedran sole act outside one flow primary zion dynamicght organized isabella fae fade alternative published part energy lack folk thousand mssar intervals signs singer pages denied beauty nightmares sleeper somehowvil position lynch deserve appointment devicedrive [SEP]']
[Init] best perm rec loss: 0.9113529920578003 for ['[CLS] dynamic zion deserve sole sleeper primary act singer isabellasar flow energy appointment pages onedran outside nightmares lack somehow alternative, field position fade province denied signs organizeddrivevil ms intervalsght part lynch fae published thousand device folk beauty [SEP]']
[Init] best perm rec loss: 0.9103208780288696 for ['[CLS] ziondrive pages published, deserve denied outside partdran fade lynch folk alternativevil somehow field signs isabella appointment province position intervals sleeper lack thousand sole beauty ms dynamic one nightmares act flow singer energysar organized faeght device primary [SEP]']
[Init] best perm rec loss: 0.9080803394317627 for ['[CLS]ght one part signsdrivevil provincesar published alternative, primary folk fae flow zion fade deserve device ms organized appointment nightmares sleeper energy field lack position dynamic act pages beauty sole intervals lynch outside isabella somehow thousand denied singerdran [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.850 (perp=12.378, rec=0.364, cos=0.010), tot_loss_proj:3.706 [t=0.24s]
prediction: ["[CLS] von sufi ᵍ grandmaster taste this perennial method official ', made of director good vampiresthus teacher worldy enjoyed 2007 has thanks care continues you with ] canada southern visitorcel eastern de seen history historical. super family dei [SEP]"]
[ 100/2000] tot_loss=2.469 (perp=10.887, rec=0.286, cos=0.006), tot_loss_proj:3.704 [t=0.24s]
prediction: ["[CLS] [SEP] bourne sheep grandmaster. this we champion outright ', trains seen director we maryland either teacher itsy great paul good makes care makes me with storynation missionary cat apprehension eastern based seencar living. super the dei [SEP]"]
[ 150/2000] tot_loss=2.315 (perp=10.367, rec=0.239, cos=0.003), tot_loss_proj:3.934 [t=0.24s]
prediction: ["[CLS] they bourne 、 beforenation before we before operator ', makes ve director weestinal either teacher thisy great'good'care makes me help recentnation from accessiblenation seennationline world resulting but for of'[SEP]"]
[ 200/2000] tot_loss=2.520 (perp=10.733, rec=0.357, cos=0.016), tot_loss_proj:3.723 [t=0.24s]
prediction: ["[CLS] most bourne interpretation maturity of before we before operator ', makes have director we directors stand teacher's great ethan this we care makes we help latestnation from postna seennationan greatest latest but laboratory it'[SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.270 (perp=10.155, rec=0.235, cos=0.004), tot_loss_proj:3.393 [t=0.24s]
prediction: ["[CLS], daniel item world of before weity century'we about seen director we lenin stand teacher've great'north we care makes us help recentught this greatest, world reinulation great currently but / one shepard [SEP]"]
[ 300/2000] tot_loss=2.208 (perp=9.916, rec=0.221, cos=0.003), tot_loss_proj:3.512 [t=0.24s]
prediction: ["[CLS], strasbourg trek seen of before we seen century'we about ve director we roman stand teacher'single great'in we care makes us help latestnation this greatest, world kamflow great latest but / one s [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.195 (perp=9.879, rec=0.214, cos=0.005), tot_loss_proj:3.395 [t=0.24s]
prediction: ["[CLS], about trek seen of before'seen century'of ve director we roman we stand teacher 'y great'in we care makes us help latestnation this greatest, world kamcian greatest latest but / one are [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.155 (perp=9.767, rec=0.198, cos=0.003), tot_loss_proj:3.445 [t=0.24s]
prediction: ["[CLS], about latest seen of before'seen century'of ve director we roman these stand teacher 'tok great'in'care makes us help ofnation this greatest,nation kamcian greatest latest but / one we [SEP]"]
[ 450/2000] tot_loss=2.023 (perp=9.147, rec=0.190, cos=0.004), tot_loss_proj:3.516 [t=0.24s]
prediction: ["[CLS], about latest seen of before'seen active'about ve director we great with stand teacher'vial great'in'care makes us help ofnation this greatest,nation kamgate greatest latest but / one we [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.002 (perp=8.766, rec=0.244, cos=0.005), tot_loss_proj:3.197 [t=0.24s]
prediction: ["[CLS], about greatest seen of before'seen active'about ve director we great it stand teacher '. great'in'care makes us help ofnation this greatest,nationnationgate latest latest but, one we [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.001 (perp=9.110, rec=0.176, cos=0.003), tot_loss_proj:3.335 [t=0.24s]
prediction: ["[CLS], kimberley greatest seennation before'character director'about ve director we great them stand teacher 'r great'in s care makes us help ofnation this greatest,nation kamgate latest latest, but one we [SEP]"]
[ 600/2000] tot_loss=2.026 (perp=9.341, rec=0.156, cos=0.002), tot_loss_proj:3.357 [t=0.24s]
prediction: ["[CLS], kimberley greatest seen of before'seen director'about ve director we great these stand teacher 'r great'in s care makes us help ofnation this greatest,nationnationcar latest latest, but one we [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.085 (perp=9.690, rec=0.144, cos=0.003), tot_loss_proj:3.410 [t=0.24s]
prediction: ["[CLS], kimberley greatest seen of before'seen active in about ve director we director these stand teacher 'y great'in s care makes us help ofnation this greatest,nationnationnation latestnation, but one we [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.024 (perp=9.314, rec=0.157, cos=0.003), tot_loss_proj:3.335 [t=0.24s]
prediction: ["[CLS], kimberley greatest of seen before'seen active in about ve director we director it stand teacher 'las great'in s care makes us help ofnation this greatest,nation reinnation latestnation, but one we [SEP]"]
[ 750/2000] tot_loss=2.167 (perp=10.063, rec=0.151, cos=0.003), tot_loss_proj:3.696 [t=0.24s]
prediction: ["[CLS], kimberley greatest of seen before'nothing director in about ve director we directors these stand teacher 'y great'in'care makes us help ofnation this greatestnationnationnationnation latestnation, but one we [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.105 (perp=9.832, rec=0.136, cos=0.003), tot_loss_proj:3.513 [t=0.25s]
prediction: ["[CLS],'greatest of seen before'something active in about'director we directors these stand teacher 'ze great'in ve care makes us help ofnation this greatestnationnationnationnation latestnation, but one we [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.094 (perp=9.821, rec=0.127, cos=0.002), tot_loss_proj:3.535 [t=0.24s]
prediction: ["[CLS],'greatest of seen before'something active in rein'director we director these stand teacher 'las great hoffman in ve care makes us help ofnation this greatestnationnation aboutnation latestnation, but one we [SEP]"]
[ 900/2000] tot_loss=2.114 (perp=9.960, rec=0.120, cos=0.002), tot_loss_proj:3.521 [t=0.24s]
prediction: ["[CLS],'greatest of seen before'something active in rein'director we director these stand teacher 'y great hoffman in ve care makes us help ofnation this greatestnationnation aboutcar latestnation, but one we [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=2.111 (perp=9.917, rec=0.125, cos=0.002), tot_loss_proj:3.578 [t=0.24s]
prediction: ["[CLS],'greatest of seen before'all active in rein'director we director these stand teacher 'ze great hoffman in ve care makes us help ofnation this greatestnationnation about latestlancenation, but one we [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.080 (perp=9.766, rec=0.125, cos=0.002), tot_loss_proj:3.506 [t=0.24s]
prediction: ["[CLS],'greatest of seen before'all formnation rein'director we director these stand teacher 'ze great hoffman in ve care makes us help ofnation this greatestnation in about latestlancenation, but one we [SEP]"]
[1050/2000] tot_loss=2.018 (perp=9.493, rec=0.117, cos=0.002), tot_loss_proj:3.411 [t=0.24s]
prediction: ["[CLS],'greatest of seen before'all formnation rein'director we director these stand teacher 'y great hoffman in ve care makes us help ofnation this greatestnation in about latestlancenation, but one we [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.962 (perp=9.195, rec=0.121, cos=0.002), tot_loss_proj:3.296 [t=0.24s]
prediction: ["[CLS],'greatest of form seen before'allnation rein'director we director these stand teacher 'y great hoffman in ve care makes us help ofnation this greatestnation in about latestlancenation, but one we [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.934 (perp=9.052, rec=0.122, cos=0.002), tot_loss_proj:3.362 [t=0.25s]
prediction: ["[CLS],'greatest of form seen before'all reinnation'director we director these stand teacher 'y great hoffman in ve care makes us help ofnation this greatestnation in about latestlancenation, but it we [SEP]"]
[1200/2000] tot_loss=1.940 (perp=9.052, rec=0.128, cos=0.002), tot_loss_proj:3.358 [t=0.24s]
prediction: ["[CLS],'greatest of form seen before'all reinnation'director we director these stand teacher 'y great hoffman in ve care makes us help ofnation this greatestnation in about latestlancenation, but it we [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.883 (perp=8.769, rec=0.127, cos=0.002), tot_loss_proj:3.197 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we director, stand teacher 'y great hoffman in ve care makes us help ofnation this greatestnation in about latestlancenation, but one we [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.846 (perp=8.620, rec=0.120, cos=0.002), tot_loss_proj:3.293 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we director,'stand teachery great hoffman in ve care makes us help ofnation this greatestnation in about latestlancenation, but it we [SEP]"]
[1350/2000] tot_loss=1.862 (perp=8.731, rec=0.114, cos=0.002), tot_loss_proj:3.148 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we greatest,'stand teachery great hoffman in ve care makes us help ofnation this greatestnation in about latestlancenation, but one we [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.810 (perp=8.427, rec=0.123, cos=0.002), tot_loss_proj:3.173 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we director,'stand teachery great hoffman in ve care makes us help ofnation about greatestnation in this latestlancenation, but one we [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.835 (perp=8.551, rec=0.123, cos=0.002), tot_loss_proj:3.162 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we greatest,'stand teachery great hoffman in ve care makes us help ofnation about greatestnation in this latestlancenation, but one we [SEP]"]
[1500/2000] tot_loss=1.828 (perp=8.551, rec=0.116, cos=0.002), tot_loss_proj:3.166 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we greatest,'stand teachery great hoffman in ve care makes us help ofnation about greatestnation in this latestlancenation, but one we [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.804 (perp=8.408, rec=0.120, cos=0.002), tot_loss_proj:3.321 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we greatest,'stand wey great hoffman in ve care makes us help ofnation about greatestnation in this latestlancenation, but one teacher [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.809 (perp=8.408, rec=0.125, cos=0.002), tot_loss_proj:3.323 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we greatest,'stand wey great hoffman in ve care makes us help ofnation about greatestnation in this latestlancenation, but one teacher [SEP]"]
[1650/2000] tot_loss=1.802 (perp=8.408, rec=0.118, cos=0.002), tot_loss_proj:3.321 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we greatest,'stand wey great hoffman in ve care makes us help ofnation about greatestnation in this latestlancenation, but one teacher [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.839 (perp=8.566, rec=0.124, cos=0.002), tot_loss_proj:3.205 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we greatest,'stand wey great hoffman in ve the makes us help of care about greatestnation in this latestlancenation, but one teacher [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.771 (perp=8.267, rec=0.116, cos=0.002), tot_loss_proj:3.161 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we greatest,'stand wey great hoffman in ve latest makes us help of care about greatestnation in this thelancenation, but one teacher [SEP]"]
[1800/2000] tot_loss=1.773 (perp=8.267, rec=0.117, cos=0.002), tot_loss_proj:3.164 [t=0.25s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we greatest,'stand wey great hoffman in ve latest makes us help of care about greatestnation in this thelancenation, but one teacher [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.798 (perp=8.391, rec=0.118, cos=0.002), tot_loss_proj:3.047 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we director,'stand wele great hoffman in ve latest makes us help teacher care about greatestnation in this thelancenation, but one of [SEP]"]
Attempt swap
Moved token
[1900/2000] tot_loss=1.794 (perp=8.368, rec=0.119, cos=0.002), tot_loss_proj:3.046 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we, director'stand wele great hoffman in ve latest makes us help teacher care about greatestnation in this thelancenation, but one of [SEP]"]
[1950/2000] tot_loss=1.794 (perp=8.368, rec=0.118, cos=0.002), tot_loss_proj:3.047 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we, director'stand wele great hoffman in ve latest makes us help teacher care about greatestnation in this thelancenation, but one of [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.751 (perp=8.184, rec=0.113, cos=0.002), tot_loss_proj:2.951 [t=0.24s]
prediction: ["[CLS] these'greatest of form seen before'all reinnation'director we, greatest'we standy great hoffman in ve latest makes us help teacher care about greatestnation in this thelancenation, but one of [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] these'greatest of form seen before'all reinnation'director we, director'stand wele great hoffman in ve latest makes us help teacher care about greatestnation in this thelancenation, but one of [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 72.727 | r: 68.571
rouge2     | fm: 6.061 | p: 6.250 | r: 5.882
rougeL     | fm: 35.294 | p: 36.364 | r: 34.286
rougeLsum  | fm: 35.294 | p: 36.364 | r: 34.286
r1fm+r2fm = 76.649

[Aggregate metrics]:
rouge1     | fm: 92.694 | p: 92.263 | r: 93.229
rouge2     | fm: 58.101 | p: 57.765 | r: 58.471
rougeL     | fm: 80.468 | p: 80.018 | r: 80.986
rougeLsum  | fm: 80.210 | p: 79.795 | r: 80.733
r1fm+r2fm = 150.795

input #35 time: 0:09:38 | total time: 5:36:21


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.999284814212414
highest_index [0]
highest [0.999284814212414]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9979257583618164 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.99554443359375 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9552820920944214 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9281548857688904 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9227340221405029 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.9187840819358826 for ['[CLS] papa sinclairevsky perhaps [SEP]']
[Init] best rec loss: 0.8236973285675049 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8220551609992981 for ['[CLS] cornelius bates ramsey harassment [SEP]']
[Init] best perm rec loss: 0.8182108998298645 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.952 (perp=9.086, rec=0.129, cos=0.006), tot_loss_proj:2.097 [t=0.23s]
prediction: ['[CLS] is horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=1.905 (perp=9.147, rec=0.073, cos=0.002), tot_loss_proj:2.117 [t=0.23s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=1.902 (perp=9.147, rec=0.071, cos=0.002), tot_loss_proj:2.110 [t=0.23s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=1.901 (perp=9.147, rec=0.070, cos=0.002), tot_loss_proj:2.112 [t=0.23s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.908 (perp=9.147, rec=0.076, cos=0.002), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 300/2000] tot_loss=1.898 (perp=9.147, rec=0.067, cos=0.002), tot_loss_proj:2.109 [t=0.23s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.901 (perp=9.147, rec=0.070, cos=0.002), tot_loss_proj:2.130 [t=0.23s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.838 (perp=8.830, rec=0.070, cos=0.002), tot_loss_proj:2.067 [t=0.24s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 450/2000] tot_loss=1.693 (perp=8.104, rec=0.070, cos=0.002), tot_loss_proj:1.952 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.691 (perp=8.104, rec=0.068, cos=0.002), tot_loss_proj:1.956 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.693 (perp=8.104, rec=0.071, cos=0.002), tot_loss_proj:1.950 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 600/2000] tot_loss=1.686 (perp=8.104, rec=0.064, cos=0.002), tot_loss_proj:1.941 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.684 (perp=8.104, rec=0.062, cos=0.002), tot_loss_proj:1.946 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.679 (perp=8.104, rec=0.057, cos=0.001), tot_loss_proj:1.951 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 750/2000] tot_loss=1.678 (perp=8.104, rec=0.056, cos=0.001), tot_loss_proj:1.948 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.693 (perp=8.104, rec=0.071, cos=0.001), tot_loss_proj:1.946 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.684 (perp=8.104, rec=0.062, cos=0.001), tot_loss_proj:1.952 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 900/2000] tot_loss=1.678 (perp=8.104, rec=0.056, cos=0.001), tot_loss_proj:1.945 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.676 (perp=8.104, rec=0.054, cos=0.001), tot_loss_proj:1.956 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.690 (perp=8.104, rec=0.068, cos=0.001), tot_loss_proj:1.957 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1050/2000] tot_loss=1.679 (perp=8.104, rec=0.056, cos=0.001), tot_loss_proj:1.948 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.679 (perp=8.104, rec=0.057, cos=0.001), tot_loss_proj:1.947 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.684 (perp=8.104, rec=0.062, cos=0.001), tot_loss_proj:1.950 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1200/2000] tot_loss=1.678 (perp=8.104, rec=0.056, cos=0.001), tot_loss_proj:1.950 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.681 (perp=8.104, rec=0.059, cos=0.001), tot_loss_proj:1.950 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.678 (perp=8.104, rec=0.056, cos=0.001), tot_loss_proj:1.952 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1350/2000] tot_loss=1.680 (perp=8.104, rec=0.058, cos=0.001), tot_loss_proj:1.943 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.688 (perp=8.104, rec=0.066, cos=0.001), tot_loss_proj:1.941 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.672 (perp=8.104, rec=0.050, cos=0.001), tot_loss_proj:1.946 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1500/2000] tot_loss=1.688 (perp=8.104, rec=0.065, cos=0.001), tot_loss_proj:1.952 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.687 (perp=8.104, rec=0.065, cos=0.001), tot_loss_proj:1.944 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.686 (perp=8.104, rec=0.064, cos=0.001), tot_loss_proj:1.946 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1650/2000] tot_loss=1.683 (perp=8.104, rec=0.060, cos=0.001), tot_loss_proj:1.944 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.684 (perp=8.104, rec=0.062, cos=0.001), tot_loss_proj:1.946 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.684 (perp=8.104, rec=0.061, cos=0.001), tot_loss_proj:1.944 [t=0.22s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1800/2000] tot_loss=1.683 (perp=8.104, rec=0.060, cos=0.001), tot_loss_proj:1.949 [t=0.22s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.682 (perp=8.104, rec=0.059, cos=0.001), tot_loss_proj:1.945 [t=0.22s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.674 (perp=8.104, rec=0.052, cos=0.001), tot_loss_proj:1.951 [t=0.22s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1950/2000] tot_loss=1.694 (perp=8.104, rec=0.072, cos=0.001), tot_loss_proj:1.950 [t=0.22s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.686 (perp=8.104, rec=0.064, cos=0.001), tot_loss_proj:1.944 [t=0.22s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s'horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.878 | p: 92.483 | r: 93.423
rouge2     | fm: 59.140 | p: 58.851 | r: 59.485
rougeL     | fm: 81.189 | p: 80.724 | r: 81.719
rougeLsum  | fm: 80.831 | p: 80.415 | r: 81.290
r1fm+r2fm = 152.019

input #36 time: 0:09:15 | total time: 5:45:37


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9993689804820187
highest_index [0]
highest [0.9993689804820187]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.9596894383430481 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.9509360194206238 for ['[CLS]quest medical [SEP]']
[Init] best rec loss: 0.8898118138313293 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.8017318248748779 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.7998512983322144 for ['[CLS] living metacritic [SEP]']
[Init] best rec loss: 0.7796184420585632 for ['[CLS] housemple [SEP]']
[Init] best rec loss: 0.777220606803894 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.7522561550140381 for ['[CLS] year clarissa [SEP]']
[Init] best rec loss: 0.7436131834983826 for ['[CLS]atal purpose [SEP]']
[Init] best rec loss: 0.7150478363037109 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.7001022100448608 for ['[CLS] cousin many [SEP]']
[Init] best rec loss: 0.6871371269226074 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6777796745300293 for ['[CLS] cassidystream [SEP]']
[Init] best rec loss: 0.6420923471450806 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6359727382659912 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.001 (perp=12.719, rec=0.335, cos=0.123), tot_loss_proj:4.345 [t=0.23s]
prediction: ['[CLS] eccentric whatsoever [SEP]']
[ 100/2000] tot_loss=2.225 (perp=9.583, rec=0.200, cos=0.108), tot_loss_proj:2.024 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[ 150/2000] tot_loss=2.002 (perp=9.583, rec=0.083, cos=0.002), tot_loss_proj:2.005 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.989 (perp=9.583, rec=0.071, cos=0.001), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.984 (perp=9.583, rec=0.066, cos=0.002), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[ 300/2000] tot_loss=1.993 (perp=9.583, rec=0.075, cos=0.001), tot_loss_proj:2.002 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.002), tot_loss_proj:2.015 [t=0.29s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.016 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[ 450/2000] tot_loss=1.967 (perp=9.583, rec=0.049, cos=0.001), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.014 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.964 (perp=9.583, rec=0.046, cos=0.001), tot_loss_proj:1.999 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[ 600/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:2.005 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:2.009 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.002 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[ 750/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.008 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.017 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.984 (perp=9.583, rec=0.067, cos=0.001), tot_loss_proj:2.006 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.994 (perp=9.583, rec=0.076, cos=0.001), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.970 (perp=9.583, rec=0.052, cos=0.001), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.022 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.981 (perp=9.583, rec=0.063, cos=0.001), tot_loss_proj:2.007 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:2.010 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.958 (perp=9.583, rec=0.041, cos=0.001), tot_loss_proj:2.016 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.990 (perp=9.583, rec=0.072, cos=0.001), tot_loss_proj:2.021 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.006 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.991 (perp=9.583, rec=0.073, cos=0.001), tot_loss_proj:2.017 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.984 (perp=9.583, rec=0.067, cos=0.001), tot_loss_proj:2.010 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.984 (perp=9.583, rec=0.066, cos=0.001), tot_loss_proj:2.017 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.985 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.006 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.991 (perp=9.583, rec=0.073, cos=0.001), tot_loss_proj:2.007 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.997 (perp=9.583, rec=0.079, cos=0.001), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.971 (perp=9.583, rec=0.053, cos=0.001), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.970 (perp=9.583, rec=0.053, cos=0.001), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.962 (perp=9.583, rec=0.044, cos=0.001), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.109 | p: 92.676 | r: 93.649
rouge2     | fm: 60.484 | p: 60.216 | r: 60.850
rougeL     | fm: 81.520 | p: 81.039 | r: 82.069
rougeLsum  | fm: 81.143 | p: 80.865 | r: 81.582
r1fm+r2fm = 153.593

input #37 time: 0:09:09 | total time: 5:54:46


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9992647518341967
highest_index [0]
highest [0.9992647518341967]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8108127117156982 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.80867999792099 for ['[CLS] federation [SEP]']
[Init] best rec loss: 0.774891197681427 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7043036222457886 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6709908246994019 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6299773454666138 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.926 (perp=14.069, rec=0.106, cos=0.007), tot_loss_proj:2.880 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.893 (perp=14.069, rec=0.076, cos=0.003), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.877 (perp=14.069, rec=0.062, cos=0.002), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.877 (perp=14.069, rec=0.060, cos=0.002), tot_loss_proj:2.883 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.876 (perp=14.069, rec=0.059, cos=0.003), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.878 (perp=14.069, rec=0.062, cos=0.002), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.861 (perp=14.069, rec=0.046, cos=0.002), tot_loss_proj:2.865 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.870 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.871 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.875 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.870 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.868 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.888 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.870 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.887 (perp=14.069, rec=0.072, cos=0.001), tot_loss_proj:2.864 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.885 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.869 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.870 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.877 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.881 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.889 (perp=14.069, rec=0.074, cos=0.001), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.866 (perp=14.069, rec=0.051, cos=0.001), tot_loss_proj:2.865 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.876 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.873 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.883 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.873 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.868 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.862 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.868 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.870 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.890 (perp=14.069, rec=0.075, cos=0.001), tot_loss_proj:2.877 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.869 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.869 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.872 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.866 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.877 (perp=14.069, rec=0.062, cos=0.001), tot_loss_proj:2.868 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.871 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.869 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.877 (perp=14.069, rec=0.062, cos=0.001), tot_loss_proj:2.878 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.874 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.884 (perp=14.069, rec=0.069, cos=0.001), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.875 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.869 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.872 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.343 | p: 92.897 | r: 93.819
rouge2     | fm: 61.516 | p: 61.280 | r: 61.875
rougeL     | fm: 81.997 | p: 81.654 | r: 82.550
rougeLsum  | fm: 81.731 | p: 81.306 | r: 82.203
r1fm+r2fm = 154.859

input #38 time: 0:09:14 | total time: 6:04:00


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9992526080235489
highest_index [0]
highest [0.9992526080235489]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.0121337175369263 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.0089290142059326 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9913747310638428 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.9341997504234314 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.9286713004112244 for ['[CLS] ira estimate rabbi relegationbiotic request veronica his baby firedusia property management spring gone dub related location cd age eastern drove than kelly parking [SEP]']
[Init] best rec loss: 0.9269349575042725 for ['[CLS] pressed score limiting value blinking walkerson hitch micro mouths inside pockets... : international darby mclaren trace lightec madman formation inquiry end soul [SEP]']
[Init] best rec loss: 0.9190372824668884 for ['[CLS] mutual peopleュ stone intimate reeve templeming freak shores over they sprinterous pro dedication harbour along ll minority [CLS] class raise issue need [SEP]']
[Init] best rec loss: 0.9160887002944946 for ['[CLS] will press caseztty never crimson bohemia journal search band relations behind formula cells main commissioner quick palmer present bible backs duty sogh [SEP]']
[Init] best rec loss: 0.908961832523346 for ['[CLS] townwind hurt main thenney cassidyowa position jury southpher wash sailhy gordon lab happened bepettive in etc sometimes event [SEP]']
[Init] best perm rec loss: 0.9082816243171692 for ['[CLS] south be main sailwindtive gordon positionowapet etc lab thenneyhy wash cassidy jury hurt in event townpher sometimes happened [SEP]']
[Init] best perm rec loss: 0.9072545170783997 for ['[CLS] main wash position eventtivewind beney hurt then town south jury etc inowa cassidy sailhy sometimespet gordon lab happenedpher [SEP]']
[Init] best perm rec loss: 0.9072453379631042 for ['[CLS] event gordonowa jury etc townpher then hurt cassidy be position main sail in washpet lab sometimeswindhy south happenedtiveney [SEP]']
[Init] best perm rec loss: 0.9061841368675232 for ['[CLS] hurtphertive happened sail washwind then lab inney etc sometimes cassidy positionowa behy gordon south jury event town mainpet [SEP]']
[Init] best perm rec loss: 0.9043102264404297 for ['[CLS] south in hurt lab happenedpher wash main sail cassidy sometimeshyowa then gordonwindneypettive event be jury etc position town [SEP]']
[Init] best perm rec loss: 0.902638852596283 for ['[CLS] labpher etc happened hurt be townwind wash in gordonowative south sometimes position then main sail cassidyhy eventpet juryney [SEP]']
[Init] best perm rec loss: 0.902492344379425 for ['[CLS]pher lab in be cassidy gordon hurt town washney sometimesowa event happened position sailtive etcpet jury then south mainwindhy [SEP]']
[Init] best perm rec loss: 0.9024226665496826 for ['[CLS] etcowa lab gordon cassidy positionpher then wash sometimespet town south sailtive mainhy in eventwind hurt be juryney happened [SEP]']
[Init] best perm rec loss: 0.902267336845398 for ['[CLS] gordontivepher event sailney hurt thenhy sometimes happened townowa mainpet jury etc be washwind lab position in south cassidy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.647 (perp=11.524, rec=0.326, cos=0.016), tot_loss_proj:4.083 [t=0.24s]
prediction: ['[CLS] uncomfortableform magnet : gives new structure own sociallycky or appealness guru robert, brand. stark. great conservative alternative lost find [SEP]']
[ 100/2000] tot_loss=2.204 (perp=9.757, rec=0.241, cos=0.012), tot_loss_proj:3.340 [t=0.24s]
prediction: ['[CLS] uncomfortable finds find, gives new texture new social trek rugby. tradition finds traditions, technology, custom and great conservative - lost find [SEP]']
[ 150/2000] tot_loss=2.197 (perp=9.985, rec=0.193, cos=0.007), tot_loss_proj:2.844 [t=0.24s]
prediction: ['[CLS]bound finds lexie, gives new texture newbound movie rugby - traditions finds traditions,,, custom and great hide - new. [SEP]']
[ 200/2000] tot_loss=2.349 (perp=10.773, rec=0.188, cos=0.006), tot_loss_proj:3.294 [t=0.24s]
prediction: ['[CLS]bound finds conservative, gives new texture newbound movie the competition traditions finds traditions with i ; may and incredible hide new conservative. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.968 (perp=9.040, rec=0.156, cos=0.004), tot_loss_proj:3.532 [t=0.24s]
prediction: ['[CLS] we finds conservative, gives new texture newbound movie movie - traditions and traditions it i and custom finds movie hidebound conservative. [SEP]']
[ 300/2000] tot_loss=1.874 (perp=8.634, rec=0.142, cos=0.005), tot_loss_proj:3.384 [t=0.24s]
prediction: ['[CLS] our finds conservative, gives new texture newbound movie movie - traditions and traditions it, and custom finds movie hidebound conservative. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.900 (perp=8.882, rec=0.121, cos=0.003), tot_loss_proj:3.438 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new texture newbound movie movie reality traditions and traditions it, of custom finds movie hide reality conservative. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.883 (perp=8.851, rec=0.111, cos=0.002), tot_loss_proj:3.582 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie movie reality traditions and traditions it,. custom texture movie hide reality conservative and [SEP]']
[ 450/2000] tot_loss=1.963 (perp=9.276, rec=0.103, cos=0.004), tot_loss_proj:3.735 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making reality traditions and traditions it,. custom texture movie hide reality conservative and [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.854 (perp=8.786, rec=0.095, cos=0.002), tot_loss_proj:3.531 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making, traditions and traditions it reality. custom texture movie hide reality conservative and [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.926 (perp=9.098, rec=0.104, cos=0.003), tot_loss_proj:3.599 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making, traditions and traditions it reality thomas reality texture one movie hide reality and [SEP]']
[ 600/2000] tot_loss=1.768 (perp=8.346, rec=0.097, cos=0.002), tot_loss_proj:3.371 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making and traditions and traditions it reality and reality texture one movie hide reality and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.889 (perp=8.997, rec=0.088, cos=0.002), tot_loss_proj:3.144 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making, traditions and traditions it reality could reality texture one movie hide reality and [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.775 (perp=8.450, rec=0.083, cos=0.002), tot_loss_proj:3.462 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making, traditions and traditions it and reality reality texture one movie hide reality and [SEP]']
[ 750/2000] tot_loss=1.852 (perp=8.824, rec=0.086, cos=0.002), tot_loss_proj:3.762 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making, traditions and traditions it. reality reality texture one movie hide relevance and [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.883 (perp=8.971, rec=0.087, cos=0.002), tot_loss_proj:3.808 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making the traditions and reality traditions it. reality texture one movie hide relevance and [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.813 (perp=8.635, rec=0.084, cos=0.002), tot_loss_proj:2.894 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making the traditions and reality texture it hide. reality texture one movie relevance and [SEP]']
[ 900/2000] tot_loss=1.812 (perp=8.635, rec=0.083, cos=0.002), tot_loss_proj:2.892 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making the traditions and reality texture it hide. reality texture one movie relevance and [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.784 (perp=8.507, rec=0.081, cos=0.002), tot_loss_proj:2.950 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making the traditions and reality texture it hide. reality texture and movie relevance one [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.801 (perp=8.594, rec=0.080, cos=0.002), tot_loss_proj:3.188 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making - traditions and reality texture it hide. reality texture and one movie relevance [SEP]']
[1050/2000] tot_loss=1.812 (perp=8.594, rec=0.092, cos=0.002), tot_loss_proj:3.191 [t=0.24s]
prediction: ['[CLS] gives our finds conservative, new finds newbound movie making - traditions and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.756 (perp=8.388, rec=0.077, cos=0.002), tot_loss_proj:3.168 [t=0.24s]
prediction: ['[CLS] gives our finds new, conservative finds newbound movie making - traditions and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.740 (perp=8.293, rec=0.080, cos=0.002), tot_loss_proj:2.937 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making - traditions and reality texture it hide. reality texture and one movie relevance [SEP]']
[1200/2000] tot_loss=1.743 (perp=8.293, rec=0.083, cos=0.002), tot_loss_proj:2.935 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making - traditions and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
[1250/2000] tot_loss=1.744 (perp=8.293, rec=0.084, cos=0.002), tot_loss_proj:2.935 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making - traditions and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.711 (perp=8.123, rec=0.085, cos=0.002), tot_loss_proj:2.880 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
[1350/2000] tot_loss=1.711 (perp=8.123, rec=0.085, cos=0.002), tot_loss_proj:2.883 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
[1400/2000] tot_loss=1.704 (perp=8.123, rec=0.077, cos=0.002), tot_loss_proj:2.884 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
[1450/2000] tot_loss=1.702 (perp=8.123, rec=0.076, cos=0.002), tot_loss_proj:2.882 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
[1500/2000] tot_loss=1.708 (perp=8.123, rec=0.081, cos=0.002), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
[1550/2000] tot_loss=1.705 (perp=8.123, rec=0.079, cos=0.002), tot_loss_proj:2.884 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
[1600/2000] tot_loss=1.710 (perp=8.123, rec=0.084, cos=0.002), tot_loss_proj:2.881 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
[1650/2000] tot_loss=1.708 (perp=8.123, rec=0.082, cos=0.002), tot_loss_proj:2.883 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
[1700/2000] tot_loss=1.700 (perp=8.123, rec=0.074, cos=0.002), tot_loss_proj:2.884 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
[1750/2000] tot_loss=1.711 (perp=8.123, rec=0.085, cos=0.002), tot_loss_proj:2.886 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
[1800/2000] tot_loss=1.699 (perp=8.123, rec=0.073, cos=0.002), tot_loss_proj:2.884 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
[1850/2000] tot_loss=1.712 (perp=8.123, rec=0.086, cos=0.002), tot_loss_proj:2.887 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
[1900/2000] tot_loss=1.699 (perp=8.123, rec=0.073, cos=0.002), tot_loss_proj:2.884 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
[1950/2000] tot_loss=1.705 (perp=8.123, rec=0.079, cos=0.002), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
Attempt swap
[2000/2000] tot_loss=1.701 (perp=8.123, rec=0.075, cos=0.002), tot_loss_proj:2.889 [t=0.24s]
prediction: ['[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] gives our finds new finds, conservative newbound movie making traditions - and reality texture it hide. reality texture and one movie relevance [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.556 | p: 73.913 | r: 77.273
rouge2     | fm: 13.953 | p: 13.636 | r: 14.286
rougeL     | fm: 48.889 | p: 47.826 | r: 50.000
rougeLsum  | fm: 48.889 | p: 47.826 | r: 50.000
r1fm+r2fm = 89.509

[Aggregate metrics]:
rouge1     | fm: 92.853 | p: 92.461 | r: 93.339
rouge2     | fm: 60.292 | p: 60.004 | r: 60.626
rougeL     | fm: 81.238 | p: 80.781 | r: 81.757
rougeLsum  | fm: 80.860 | p: 80.439 | r: 81.314
r1fm+r2fm = 153.145

input #39 time: 0:09:32 | total time: 6:13:33


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9993180163624655
highest_index [0]
highest [0.9993180163624655]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9940409064292908 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9588767290115356 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9404011964797974 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 0.9336565732955933 for ['[CLS] alive represents adelaide cinder majestymersfordthes s [SEP]']
[Init] best rec loss: 0.9329563975334167 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 0.9272531867027283 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 0.9182189702987671 for ['[CLS] formula expression groundsoft written used ⇒ution murray [SEP]']
[Init] best rec loss: 0.9071977734565735 for ['[CLS] alloid courtesy [MASK]blood mean gownrarm [SEP]']
[Init] best rec loss: 0.847230076789856 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8415253162384033 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8396544456481934 for ['[CLS]° georgian but kent lady abd many already deciding [SEP]']
[Init] best perm rec loss: 0.8368232250213623 for ['[CLS] deciding° lady abd but kent georgian already many [SEP]']
[Init] best perm rec loss: 0.834687352180481 for ['[CLS] kent already deciding lady but abd georgian° many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.751 (perp=12.157, rec=0.309, cos=0.011), tot_loss_proj:3.443 [t=0.23s]
prediction: ['[CLS] electronicmmel us pu anger orony language corruption [SEP]']
[ 100/2000] tot_loss=2.941 (perp=13.783, rec=0.178, cos=0.006), tot_loss_proj:3.782 [t=0.24s]
prediction: ['[CLS] electronicmmel us pu audio withony imageryony [SEP]']
[ 150/2000] tot_loss=2.801 (perp=13.391, rec=0.118, cos=0.005), tot_loss_proj:3.219 [t=0.24s]
prediction: ['[CLS] phonemmel us pu ph withony imageryony [SEP]']
[ 200/2000] tot_loss=2.675 (perp=12.849, rec=0.102, cos=0.003), tot_loss_proj:3.105 [t=0.24s]
prediction: ['[CLS] electronicmmel us pu ph withony imagery or [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.115 (perp=10.149, rec=0.084, cos=0.002), tot_loss_proj:2.487 [t=0.24s]
prediction: ['[CLS] music pummel us ph withony imagery or [SEP]']
[ 300/2000] tot_loss=2.098 (perp=10.149, rec=0.067, cos=0.001), tot_loss_proj:2.504 [t=0.24s]
prediction: ['[CLS] music pummel us ph withony imagery or [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.712 (perp=8.184, rec=0.074, cos=0.001), tot_loss_proj:2.420 [t=0.24s]
prediction: ['[CLS] music pummel us phony with imagery or [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.582 (perp=7.355, rec=0.108, cos=0.003), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
[ 450/2000] tot_loss=1.550 (perp=7.355, rec=0.078, cos=0.001), tot_loss_proj:2.130 [t=0.24s]
prediction: ['[CLS] music pummel us or phony with imagery [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.490 (perp=7.096, rec=0.069, cos=0.001), tot_loss_proj:2.044 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.491 (perp=7.096, rec=0.070, cos=0.001), tot_loss_proj:2.041 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[ 600/2000] tot_loss=1.488 (perp=7.096, rec=0.067, cos=0.001), tot_loss_proj:2.043 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.490 (perp=7.096, rec=0.069, cos=0.001), tot_loss_proj:2.040 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.479 (perp=7.096, rec=0.058, cos=0.001), tot_loss_proj:2.040 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[ 750/2000] tot_loss=1.483 (perp=7.096, rec=0.062, cos=0.001), tot_loss_proj:2.034 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.486 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.039 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.490 (perp=7.096, rec=0.069, cos=0.001), tot_loss_proj:2.034 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[ 900/2000] tot_loss=1.483 (perp=7.096, rec=0.063, cos=0.001), tot_loss_proj:2.032 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.483 (perp=7.096, rec=0.063, cos=0.001), tot_loss_proj:2.033 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1000/2000] tot_loss=1.487 (perp=7.096, rec=0.066, cos=0.001), tot_loss_proj:2.045 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1050/2000] tot_loss=1.485 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.037 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1100/2000] tot_loss=1.488 (perp=7.096, rec=0.068, cos=0.001), tot_loss_proj:2.041 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1150/2000] tot_loss=1.481 (perp=7.096, rec=0.060, cos=0.001), tot_loss_proj:2.037 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1200/2000] tot_loss=1.491 (perp=7.096, rec=0.070, cos=0.001), tot_loss_proj:2.036 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1250/2000] tot_loss=1.482 (perp=7.096, rec=0.061, cos=0.001), tot_loss_proj:2.032 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1300/2000] tot_loss=1.482 (perp=7.096, rec=0.061, cos=0.001), tot_loss_proj:2.043 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1350/2000] tot_loss=1.481 (perp=7.096, rec=0.060, cos=0.001), tot_loss_proj:2.033 [t=0.24s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1400/2000] tot_loss=1.485 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1450/2000] tot_loss=1.486 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.041 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1500/2000] tot_loss=1.475 (perp=7.096, rec=0.054, cos=0.001), tot_loss_proj:2.037 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1550/2000] tot_loss=1.484 (perp=7.096, rec=0.063, cos=0.001), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1600/2000] tot_loss=1.473 (perp=7.096, rec=0.052, cos=0.001), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1650/2000] tot_loss=1.477 (perp=7.096, rec=0.056, cos=0.001), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1700/2000] tot_loss=1.490 (perp=7.096, rec=0.069, cos=0.001), tot_loss_proj:2.033 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1750/2000] tot_loss=1.483 (perp=7.096, rec=0.063, cos=0.001), tot_loss_proj:2.031 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1800/2000] tot_loss=1.478 (perp=7.096, rec=0.058, cos=0.001), tot_loss_proj:2.030 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1850/2000] tot_loss=1.480 (perp=7.096, rec=0.059, cos=0.001), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[1900/2000] tot_loss=1.490 (perp=7.096, rec=0.069, cos=0.001), tot_loss_proj:2.034 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
[1950/2000] tot_loss=1.491 (perp=7.096, rec=0.070, cos=0.001), tot_loss_proj:2.036 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Attempt swap
[2000/2000] tot_loss=1.486 (perp=7.096, rec=0.065, cos=0.001), tot_loss_proj:2.030 [t=0.22s]
prediction: ['[CLS] imagery pummel us or phony with music [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] imagery pummel us or phony with music [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.970 | p: 92.571 | r: 93.536
rouge2     | fm: 59.438 | p: 59.220 | r: 59.718
rougeL     | fm: 80.823 | p: 80.405 | r: 81.263
rougeLsum  | fm: 80.517 | p: 80.129 | r: 81.033
r1fm+r2fm = 152.408

input #40 time: 0:09:09 | total time: 6:22:43


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.9993041155296631
highest_index [0]
highest [0.9993041155296631]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9744104743003845 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9511962532997131 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 0.9439316987991333 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 0.933946430683136 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.9258303642272949 for ['[CLS]grapher pr [SEP]']
[Init] best rec loss: 0.9252661466598511 for ['[CLS]mler previously [SEP]']
[Init] best rec loss: 0.9075953364372253 for ['[CLS] electors mediterranean [SEP]']
[Init] best rec loss: 0.8915941715240479 for ['[CLS] meetswr [SEP]']
[Init] best rec loss: 0.852973222732544 for ['[CLS] bolivar satisfied [SEP]']
[Init] best rec loss: 0.8348253965377808 for ['[CLS] ways whether [SEP]']
[Init] best perm rec loss: 0.8253730535507202 for ['[CLS] whether ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.169 (perp=10.212, rec=0.123, cos=0.003), tot_loss_proj:2.109 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.119 (perp=10.212, rec=0.075, cos=0.002), tot_loss_proj:2.116 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.123 (perp=10.212, rec=0.079, cos=0.001), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.119 (perp=10.212, rec=0.074, cos=0.003), tot_loss_proj:2.101 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.095 (perp=10.212, rec=0.051, cos=0.002), tot_loss_proj:2.116 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.096 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.105 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.120 (perp=10.212, rec=0.076, cos=0.001), tot_loss_proj:2.116 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.101 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.109 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.109 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.104 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.113 (perp=10.212, rec=0.069, cos=0.001), tot_loss_proj:2.118 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.106 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.119 (perp=10.212, rec=0.075, cos=0.001), tot_loss_proj:2.111 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.102 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.110 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.103 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.116 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.111 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.123 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.097 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.108 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.114 (perp=10.212, rec=0.070, cos=0.001), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.101 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.104 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.105 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.106 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.109 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.106 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.095 (perp=10.212, rec=0.051, cos=0.001), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.116 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.093 (perp=10.212, rec=0.050, cos=0.001), tot_loss_proj:2.108 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.097 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.092 (perp=10.212, rec=0.048, cos=0.001), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.103 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.181 | p: 92.784 | r: 93.662
rouge2     | fm: 60.385 | p: 60.108 | r: 60.665
rougeL     | fm: 81.412 | p: 80.972 | r: 81.946
rougeLsum  | fm: 81.018 | p: 80.710 | r: 81.447
r1fm+r2fm = 153.565

input #41 time: 0:08:51 | total time: 6:31:34


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9993266219365816
highest_index [0]
highest [0.9993266219365816]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9052959084510803 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8539038896560669 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8489475846290588 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8198183178901672 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.797766923904419 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7967566251754761 for ['[CLS] wish stages ran offendedrs bandagible attracted ever scale kitchenctric international liftedtaking superseded cut assignmentures enough treatyplingbe larger dare maple [SEP]']
[Init] best perm rec loss: 0.7962284684181213 for ['[CLS]ures dare scale offended international evertaking wish enough largerpling assignmentgiblectric ran kitchen stagesrs attracted banda treaty lifted maple supersededbe cut [SEP]']
[Init] best perm rec loss: 0.7946922779083252 for ['[CLS]taking superseded international banda maple dare cut wish attracted ran kitchen treaty scale larger ever enoughbegible stagesuresrs liftedctric assignmentpling offended [SEP]']
[Init] best perm rec loss: 0.7929145693778992 for ['[CLS] bandataking dare rangible attracted maplers international stagespling assignment cut treaty scale enough everctric lifteduresbe superseded wish larger offended kitchen [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.671 (perp=11.858, rec=0.288, cos=0.011), tot_loss_proj:3.205 [t=0.24s]
prediction: ['[CLS] sufficiently they forgot microsoft phone terminal phone turkey zoning 100 complained department cut their poorly poorly orthodox effectinator poorly. sense poorly school forgot violence [SEP]']
[ 100/2000] tot_loss=2.601 (perp=12.002, rec=0.197, cos=0.004), tot_loss_proj:3.082 [t=0.24s]
prediction: ['[CLS] they they forgot any scary silent to unless projectwi forgot department as they poorly poorly miranda attraction conor poorly intoggerential school forgot information [SEP]']
[ 150/2000] tot_loss=2.380 (perp=11.127, rec=0.150, cos=0.005), tot_loss_proj:2.723 [t=0.24s]
prediction: ['[CLS] the artists forgot anything scary scary to anything projectji anyway showed as they poorly poorly leahggergger poorly intogger pretty school forgot setting [SEP]']
[ 200/2000] tot_loss=2.191 (perp=10.280, rec=0.130, cos=0.005), tot_loss_proj:2.620 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything scary scary to include projectji scary twain as they poorly poorlyjiggergger poorly intogger high school forgot setting [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.236 (perp=10.546, rec=0.123, cos=0.003), tot_loss_proj:2.745 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything include scary to include projectji halfwayheimer as they poorly poorlyjiggergger regger into high school forgot setting [SEP]']
[ 300/2000] tot_loss=2.226 (perp=10.546, rec=0.113, cos=0.004), tot_loss_proj:2.751 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything include scary to include projectji halfwayheimer as they poorly poorlyjiggergger regger into high school forgot setting [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.118 (perp=10.060, rec=0.104, cos=0.002), tot_loss_proj:2.726 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything poorly scary to include projectji halfway twain as they include poorlyjigger attraction regger into high school forgot setting [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.067 (perp=9.874, rec=0.090, cos=0.002), tot_loss_proj:2.696 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything poorly scary to include project halfwayji twain as they include poorlyjigger attraction regger into high school forgot setting [SEP]']
[ 450/2000] tot_loss=1.957 (perp=9.325, rec=0.090, cos=0.002), tot_loss_proj:2.545 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything poorly scary to include project even half twain as they include poorlyjigger attraction regger into high school forgot setting [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.027 (perp=9.660, rec=0.093, cos=0.002), tot_loss_proj:2.661 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything fatal scary to include even half guitarist as they include poorlyjigger attraction regger into high school forgot project setting [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.104 (perp=10.052, rec=0.092, cos=0.002), tot_loss_proj:2.666 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything fatal scary to halfway even halfwaytwined as they include poorlyjigger attraction regger into high school forgot project setting [SEP]']
[ 600/2000] tot_loss=2.079 (perp=10.000, rec=0.076, cos=0.002), tot_loss_proj:2.671 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything fatal scary to halfway even halfway halfway as they include poorlyjigger attraction regger into high school forgot project setting [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.039 (perp=9.746, rec=0.088, cos=0.002), tot_loss_proj:2.766 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything fatal forgot to halfway even halfway halfway as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.002 (perp=9.584, rec=0.083, cos=0.002), tot_loss_proj:2.704 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything fatal forgot to halfway even halfway scary as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
[ 750/2000] tot_loss=1.996 (perp=9.584, rec=0.077, cos=0.002), tot_loss_proj:2.711 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything fatal forgot to halfway even halfway scary as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.968 (perp=9.389, rec=0.089, cos=0.002), tot_loss_proj:2.675 [t=0.24s]
prediction: ['[CLS] the filmmakers forgot anything scary forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.030 (perp=9.742, rec=0.080, cos=0.002), tot_loss_proj:2.837 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything scary forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
[ 900/2000] tot_loss=2.033 (perp=9.742, rec=0.083, cos=0.002), tot_loss_proj:2.839 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything scary forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.025 (perp=9.742, rec=0.075, cos=0.002), tot_loss_proj:2.841 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything scary forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
Attempt swap
[1000/2000] tot_loss=2.033 (perp=9.742, rec=0.083, cos=0.002), tot_loss_proj:2.836 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything scary forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
[1050/2000] tot_loss=2.026 (perp=9.742, rec=0.076, cos=0.002), tot_loss_proj:2.836 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything scary forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
Attempt swap
[1100/2000] tot_loss=2.030 (perp=9.742, rec=0.080, cos=0.002), tot_loss_proj:2.841 [t=0.24s]
prediction: ['[CLS] s filmmakers forgot anything scary forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.988 (perp=9.547, rec=0.076, cos=0.002), tot_loss_proj:2.931 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
[1200/2000] tot_loss=1.993 (perp=9.547, rec=0.082, cos=0.002), tot_loss_proj:2.934 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.993 (perp=9.547, rec=0.082, cos=0.002), tot_loss_proj:2.933 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.989 (perp=9.547, rec=0.078, cos=0.002), tot_loss_proj:2.935 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
[1350/2000] tot_loss=1.986 (perp=9.547, rec=0.075, cos=0.002), tot_loss_proj:2.934 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to halfway even halfway fatal as they include poorlyjigger attraction regger into high school scary project setting [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.881 (perp=9.039, rec=0.072, cos=0.002), tot_loss_proj:2.858 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to halfway even halfway fatal attraction as they include poorlyjigger regger into high school scary project setting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.885 (perp=9.039, rec=0.076, cos=0.002), tot_loss_proj:2.850 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to halfway even halfway fatal attraction as they include poorlyjigger regger into high school scary project setting [SEP]']
[1500/2000] tot_loss=1.921 (perp=9.179, rec=0.083, cos=0.002), tot_loss_proj:2.928 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to 止 even halfway fatal attraction as they include poorlyjigger regger into high school scary project setting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.912 (perp=9.179, rec=0.075, cos=0.002), tot_loss_proj:2.930 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to 止 even halfway fatal attraction as they include poorlyjigger regger into high school scary project setting [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.849 (perp=8.832, rec=0.081, cos=0.002), tot_loss_proj:2.670 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to include even halfway fatal attraction as they 止 poorlyjigger regger into high school scary project setting [SEP]']
[1650/2000] tot_loss=1.843 (perp=8.832, rec=0.075, cos=0.002), tot_loss_proj:2.673 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to include even halfway fatal attraction as they 止 poorlyjigger regger into high school scary project setting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.840 (perp=8.832, rec=0.072, cos=0.002), tot_loss_proj:2.673 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to include even halfway fatal attraction as they 止 poorlyjigger regger into high school scary project setting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.836 (perp=8.832, rec=0.067, cos=0.002), tot_loss_proj:2.670 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to include even halfway fatal attraction as they 止 poorlyjigger regger into high school scary project setting [SEP]']
[1800/2000] tot_loss=1.844 (perp=8.832, rec=0.076, cos=0.002), tot_loss_proj:2.675 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to include even halfway fatal attraction as they 止 poorlyjigger regger into high school scary project setting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.839 (perp=8.832, rec=0.071, cos=0.002), tot_loss_proj:2.671 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to include even halfway fatal attraction as they 止 poorlyjigger regger into high school scary project setting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.846 (perp=8.832, rec=0.078, cos=0.002), tot_loss_proj:2.672 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to include even halfway fatal attraction as they 止 poorlyjigger regger into high school scary project setting [SEP]']
[1950/2000] tot_loss=1.845 (perp=8.832, rec=0.077, cos=0.002), tot_loss_proj:2.672 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to include even halfway fatal attraction as they 止 poorlyjigger regger into high school scary project setting [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.808 (perp=8.637, rec=0.079, cos=0.002), tot_loss_proj:2.556 [t=0.24s]
prediction: ['[CLS] s scary filmmakers forgot anything forgot to include even halfway fatal attraction as they 止 poorlyji reggergger into high school scary project setting [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] s scary filmmakers forgot anything forgot to include even halfway fatal attraction as they 止 poorlyjigger regger into high school scary project setting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 34.783 | p: 34.783 | r: 34.783
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 118.116

[Aggregate metrics]:
rouge1     | fm: 92.923 | p: 92.518 | r: 93.434
rouge2     | fm: 59.687 | p: 59.405 | r: 59.981
rougeL     | fm: 80.854 | p: 80.399 | r: 81.433
rougeLsum  | fm: 80.597 | p: 80.196 | r: 81.047
r1fm+r2fm = 152.610

input #42 time: 0:09:31 | total time: 6:41:06


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9992735963516287
highest_index [0]
highest [0.9992735963516287]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9571977853775024 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9207459688186646 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8901294469833374 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8651462197303772 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.85670405626297 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.8478173613548279 for ['[CLS] carested royals erica [SEP]']
[Init] best rec loss: 0.8367412090301514 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 0.8362466096878052 for ['[CLS]sh nadu shall taylor [SEP]']
[Init] best rec loss: 0.7853533625602722 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7812954783439636 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.7793064117431641 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 0.7782993912696838 for ['[CLS] secondckbus climb [SEP]']
[Init] best perm rec loss: 0.7752212882041931 for ['[CLS] climb secondbusck [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.527 (perp=11.440, rec=0.232, cos=0.007), tot_loss_proj:2.798 [t=0.23s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 100/2000] tot_loss=2.436 (perp=11.440, rec=0.144, cos=0.004), tot_loss_proj:2.791 [t=0.23s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 150/2000] tot_loss=2.297 (perp=10.986, rec=0.097, cos=0.003), tot_loss_proj:2.798 [t=0.23s]
prediction: ['[CLS] naissisticrc [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.986, rec=0.064, cos=0.002), tot_loss_proj:2.807 [t=0.23s]
prediction: ['[CLS] naissisticrc [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.131 (perp=5.048, rec=0.118, cos=0.004), tot_loss_proj:1.076 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.083 (perp=5.048, rec=0.072, cos=0.001), tot_loss_proj:1.070 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.085 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.082 (perp=5.048, rec=0.070, cos=0.002), tot_loss_proj:1.091 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.090 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.002), tot_loss_proj:1.083 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.083 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.079 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.083 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.001), tot_loss_proj:1.078 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.085 (perp=5.048, rec=0.074, cos=0.001), tot_loss_proj:1.072 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.083 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.069 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.076 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.001), tot_loss_proj:1.074 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.071 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.079 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.082 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.073 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.061 (perp=5.048, rec=0.050, cos=0.001), tot_loss_proj:1.082 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.063 (perp=5.048, rec=0.052, cos=0.001), tot_loss_proj:1.079 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.077 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.079 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.071 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.082 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.074 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.071 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.077 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.077 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.075 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.058 (perp=5.048, rec=0.047, cos=0.001), tot_loss_proj:1.070 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.072 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.075 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.079 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.073 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.064 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.082 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.069 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.001), tot_loss_proj:1.080 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.070 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.080 | p: 92.682 | r: 93.605
rouge2     | fm: 60.488 | p: 60.285 | r: 60.704
rougeL     | fm: 81.334 | p: 80.964 | r: 81.803
rougeLsum  | fm: 81.089 | p: 80.741 | r: 81.563
r1fm+r2fm = 153.568

input #43 time: 0:09:19 | total time: 6:50:25


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9992421634507239
highest_index [0]
highest [0.9992421634507239]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9847252368927002 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9550042748451233 for ['[CLS] photo led breath sound coin day opponents allies joycevel move throne doin head huge guest perhaps ; his gaze saddle decide willise new great ¡wark grand [SEP]']
[Init] best rec loss: 0.9321396350860596 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.9320439100265503 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best rec loss: 0.9308730363845825 for ['[CLS] balls greenhouse with punch por new oscar shut puzzle crunch interactive role substanceport those beg than units aged host roller alphabet defeat writing meet guinea one then percentage [SEP]']
[Init] best rec loss: 0.9090942740440369 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best perm rec loss: 0.907383382320404 for ['[CLS] ; raceway contact harbor slave settled haley brow graphic nation hee fatty co contains rock hello formerly data blue landonosihair capacity s illustrated ltd contestants intent comedy [SEP]']
[Init] best perm rec loss: 0.9066078662872314 for ['[CLS] haleyhair fatty intentosi settled illustrated harbor ltd rock nation comedy blue landon brow raceway data contestants graphic hello s ; hee contact formerly co slave capacity contains [SEP]']
[Init] best perm rec loss: 0.9063311815261841 for ['[CLS]osi raceway ltd capacity blue haley contains hee slave hello ; contact rock nation settled comedy formerly data brow intent graphichair harbor contestants illustrated co s fatty landon [SEP]']
[Init] best perm rec loss: 0.9054985046386719 for ['[CLS] rock ltd blue ; contains contact raceway co illustrated haley slave comedy helloosi s intent hee graphic contestants fattyhair harbor settled data brow nation formerly landon capacity [SEP]']
[Init] best perm rec loss: 0.9040576815605164 for ['[CLS] co contains fatty contacthair haley settled contestants graphic data nation blue capacity comedy landon ltd hello brow ; rock raceway hee formerly illustrated harbor s slave intentosi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.620 (perp=11.856, rec=0.242, cos=0.007), tot_loss_proj:3.030 [t=0.24s]
prediction: ['[CLS] tbs was unnecessary lostgi hence routine translation unit schedule translation that prize lurking episodeaf lost our scattered lostrdializes lost the crimes in the slack translation [SEP]']
[ 100/2000] tot_loss=2.275 (perp=10.628, rec=0.145, cos=0.005), tot_loss_proj:2.901 [t=0.24s]
prediction: ['[CLS] movie has additional lost translation in routine translationbridgealicfest another pardonfestfest des lostrting slip lost executionizes lost hollywood hollywood in the slack translation [SEP]']
[ 150/2000] tot_loss=2.298 (perp=10.814, rec=0.132, cos=0.003), tot_loss_proj:2.987 [t=0.24s]
prediction: ['[CLS] hollywood has additional translation translation in routine translationwifealicfest another pulitzerfest. where slack fright← lostalicizes against fright hollywood in the slack execution [SEP]']
[ 200/2000] tot_loss=2.368 (perp=11.279, rec=0.110, cos=0.003), tot_loss_proj:2.878 [t=0.24s]
prediction: ['[CLS] hollywood has additional absurdized in routine translationditionalalicfest another pulitzerfest.. fright whichated lostalicizesalic fright premise in the slack execution [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.110 (perp=10.021, rec=0.103, cos=0.003), tot_loss_proj:2.620 [t=0.24s]
prediction: ['[CLS] hollywood has additional absurdized in routine translationityalicfest another frightfest.. absurd whichizes premisealicizes behind the lost in the slack execution [SEP]']
[ 300/2000] tot_loss=2.138 (perp=10.239, rec=0.088, cos=0.002), tot_loss_proj:2.640 [t=0.24s]
prediction: ['[CLS] hollywood has partial absurdized in routine translationityalicfest another frightfest.. absurd whichizes premisealicizes the the lost in the slack execution [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.106 (perp=10.089, rec=0.086, cos=0.002), tot_loss_proj:2.627 [t=0.24s]
prediction: ['[CLS] hollywood has partial absurd the in routine translationityalic the another frightfest.. absurd which premise premisealicizes the the lost in the slack execution [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.979 (perp=9.504, rec=0.076, cos=0.002), tot_loss_proj:2.532 [t=0.24s]
prediction: ['[CLS] hollywood has partial absurdity in routine translation thealic the another frightfest.. absurd which premise premise itizes the the lost in the slack execution [SEP]']
[ 450/2000] tot_loss=1.960 (perp=9.398, rec=0.079, cos=0.002), tot_loss_proj:2.504 [t=0.24s]
prediction: ['[CLS] hollywood has the absurdity in routine translation thealic the another frightfest.. absurd which premise premise itizes the the lost in the slack execution [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.896 (perp=8.940, rec=0.105, cos=0.002), tot_loss_proj:2.351 [t=0.24s]
prediction: ['[CLS] hollywood has the absurdity in routine translation thealic. another frightfest., absurd which premise premise itizes the the lost of the slack execution [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.823 (perp=8.687, rec=0.084, cos=0.002), tot_loss_proj:2.398 [t=0.24s]
prediction: ['[CLS] hollywood has the absurdity in routine translation thealic. another frightfest., absurd premise premise which itizes the the lost of the slack execution [SEP]']
[ 600/2000] tot_loss=1.817 (perp=8.687, rec=0.078, cos=0.002), tot_loss_proj:2.402 [t=0.24s]
prediction: ['[CLS] hollywood has the absurdity in routine translation thealic. another frightfest., absurd premise premise which itizes the the lost of the slack execution [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.696 (perp=8.073, rec=0.080, cos=0.002), tot_loss_proj:2.273 [t=0.24s]
prediction: ['[CLS] hollywood has the absurdity in routine translation.alic. another frightfest. the absurd premise premise which itizes, the lost of the slack execution [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.621 (perp=7.698, rec=0.080, cos=0.002), tot_loss_proj:2.056 [t=0.24s]
prediction: ['[CLS] hollywood has the absurdity in routine translation.alic. another frightfest. the absurd premise lost which itizes, the premise of the slack execution [SEP]']
[ 750/2000] tot_loss=1.613 (perp=7.698, rec=0.072, cos=0.002), tot_loss_proj:2.048 [t=0.24s]
prediction: ['[CLS] hollywood has the absurdity in routine translation.alic. another frightfest. the absurd premise lost which itizes, the premise of the slack execution [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.597 (perp=7.603, rec=0.075, cos=0.002), tot_loss_proj:2.082 [t=0.24s]
prediction: ['[CLS] hollywood has the absurdity in routine translation executionalic. another frightfest. the absurd premise lost which itizes, the premise of the slack. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.535 (perp=7.302, rec=0.073, cos=0.001), tot_loss_proj:2.024 [t=0.24s]
prediction: ['[CLS] slack has the absurdity in routine translation executionalic. another frightfest. the absurd premise lost which itizes, the premise of the hollywood. [SEP]']
[ 900/2000] tot_loss=1.536 (perp=7.302, rec=0.074, cos=0.002), tot_loss_proj:2.027 [t=0.24s]
prediction: ['[CLS] slack has the absurdity in routine translation executionalic. another frightfest. the absurd premise lost which itizes, the premise of the hollywood. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.520 (perp=7.225, rec=0.074, cos=0.002), tot_loss_proj:1.992 [t=0.25s]
prediction: ['[CLS] slack has the absurdity in routine translation executionalic. another frightfest. the absurd premise lost, which itizes the premise of the hollywood. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.462 (perp=6.975, rec=0.066, cos=0.002), tot_loss_proj:1.904 [t=0.24s]
prediction: ['[CLS] slack has the absurdity in the translation executionalic. another frightfest. the absurd premise lost, which itizes the premise of routine hollywood. [SEP]']
[1050/2000] tot_loss=1.476 (perp=6.975, rec=0.080, cos=0.002), tot_loss_proj:1.911 [t=0.24s]
prediction: ['[CLS] slack has the absurdity in the translation executionalic. another frightfest. the absurd premise lost, which itizes the premise of routine hollywood. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.451 (perp=6.879, rec=0.074, cos=0.001), tot_loss_proj:1.895 [t=0.24s]
prediction: ['[CLS] slack has the absurdity in the translation executionalic. another frightfest. the absurd premise lost, which it routineizes the premise of hollywood. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.427 (perp=6.746, rec=0.076, cos=0.002), tot_loss_proj:1.885 [t=0.24s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest. the absurd premise lost, which it routineizes the premise of hollywood. [SEP]']
[1200/2000] tot_loss=1.430 (perp=6.746, rec=0.079, cos=0.002), tot_loss_proj:1.895 [t=0.24s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest. the absurd premise lost, which it routineizes the premise of hollywood. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.509 (perp=7.183, rec=0.071, cos=0.002), tot_loss_proj:2.080 [t=0.24s]
prediction: ['[CLS] slack has the includesity in the executionalic translation. another frightfest. the absurd premise which lost, it routineizes the premise of hollywood. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.509 (perp=7.183, rec=0.071, cos=0.002), tot_loss_proj:2.076 [t=0.24s]
prediction: ['[CLS] slack has the includesity in the executionalic translation. another frightfest. the absurd premise which lost, it routineizes the premise of hollywood. [SEP]']
[1350/2000] tot_loss=1.519 (perp=7.183, rec=0.081, cos=0.002), tot_loss_proj:2.077 [t=0.24s]
prediction: ['[CLS] slack has the includesity in the executionalic translation. another frightfest. the absurd premise which lost, it routineizes the premise of hollywood. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.428 (perp=6.824, rec=0.061, cos=0.002), tot_loss_proj:1.929 [t=0.22s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest. theurrent premise which lost, it routineizes the premise of hollywood. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.445 (perp=6.919, rec=0.060, cos=0.002), tot_loss_proj:1.909 [t=0.22s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest, the includes premise which lost. it routineizes the premise of hollywood. [SEP]']
[1500/2000] tot_loss=1.455 (perp=6.919, rec=0.070, cos=0.002), tot_loss_proj:1.913 [t=0.22s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest, the includes premise which lost. it routineizes the premise of hollywood. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.415 (perp=6.721, rec=0.069, cos=0.002), tot_loss_proj:1.967 [t=0.23s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest, which includes premise the lost. it routineizes the premise of hollywood. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.427 (perp=6.780, rec=0.070, cos=0.002), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest, which the premise absurd lost. it routineizes the premise of hollywood. [SEP]']
[1650/2000] tot_loss=1.425 (perp=6.780, rec=0.068, cos=0.002), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest, which the premise absurd lost. it routineizes the premise of hollywood. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.374 (perp=6.524, rec=0.068, cos=0.002), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest, which the absurd premise lost. it routineizes the premise of hollywood. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.454 (perp=6.919, rec=0.069, cos=0.001), tot_loss_proj:1.913 [t=0.23s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest, the includes premise which lost. it routineizes the premise of hollywood. [SEP]']
[1800/2000] tot_loss=1.457 (perp=6.919, rec=0.072, cos=0.002), tot_loss_proj:1.916 [t=0.22s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest, the includes premise which lost. it routineizes the premise of hollywood. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.448 (perp=6.894, rec=0.067, cos=0.002), tot_loss_proj:1.935 [t=0.22s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest includes the, premise which lost. it routineizes the premise of hollywood. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.426 (perp=6.738, rec=0.077, cos=0.001), tot_loss_proj:1.904 [t=0.23s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest includes the premise which lost., it routineizes the premise of hollywood. [SEP]']
[1950/2000] tot_loss=1.422 (perp=6.738, rec=0.073, cos=0.002), tot_loss_proj:1.906 [t=0.22s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest includes the premise which lost., it routineizes the premise of hollywood. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.426 (perp=6.738, rec=0.077, cos=0.002), tot_loss_proj:1.905 [t=0.23s]
prediction: ['[CLS] slack has the absurdity in the executionalic translation. another frightfest includes the premise which lost., it routineizes the premise of hollywood. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] slack has the includesity in the executionalic translation. another frightfest. the absurd premise which lost, it routineizes the premise of hollywood. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.913 | p: 73.913 | r: 73.913
rouge2     | fm: 13.636 | p: 13.636 | r: 13.636
rougeL     | fm: 47.826 | p: 47.826 | r: 47.826
rougeLsum  | fm: 47.826 | p: 47.826 | r: 47.826
r1fm+r2fm = 87.549

[Aggregate metrics]:
rouge1     | fm: 92.665 | p: 92.289 | r: 93.105
rouge2     | fm: 59.744 | p: 59.484 | r: 60.032
rougeL     | fm: 80.551 | p: 80.244 | r: 81.022
rougeLsum  | fm: 80.251 | p: 79.878 | r: 80.607
r1fm+r2fm = 152.410

input #44 time: 0:09:21 | total time: 6:59:46


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9993981045144514
highest_index [0]
highest [0.9993981045144514]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.9814025163650513 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.93677818775177 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.9145281910896301 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.9122018218040466 for ['[CLS] look greater applications dating decay line learning reagan ata alley fact isn starboard thorne portion stepped women5 bee defense producing ł wingtlestation hold net festival [SEP]']
[Init] best rec loss: 0.9019213914871216 for ['[CLS] need invitation small cross hot no sk cello deep leader motions harry slide guest pity ash nepal rather ashleyinsman previous walt mclean prix van zoneition [SEP]']
[Init] best rec loss: 0.8711106777191162 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.8676222562789917 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.8668943643569946 for ['[CLS] letter fivetiv via v around skin tree murmured taste special single enclosed entrance military curtis joan borelanda football gentry status2 ku ( operated few whoa [SEP]']
[Init] best perm rec loss: 0.8638823628425598 for ['[CLS]tiv single special whoa tree operated gentry football enclosed ( fewlanda five curtis military v taste letter murmured bore around joan ku status2 entrance via skin [SEP]']
[Init] best perm rec loss: 0.8630584478378296 for ['[CLS] enclosed ( taste special murmured whoa letter v bore single via2tivlanda five military curtis gentry operated football entrance joan skin few tree status around ku [SEP]']
[Init] best perm rec loss: 0.8626331686973572 for ['[CLS] taste special murmured skin ( via aroundlanda military letter v enclosed football2 curtis five single entrance few operated whoa bore gentrytiv joan tree status ku [SEP]']
[Init] best perm rec loss: 0.8599068522453308 for ['[CLS] few special fivetiv ku joan around letter bore tree murmured enclosedlanda whoa football military entrance taste skin status gentry curtis via single v ( operated2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.443 (perp=10.508, rec=0.328, cos=0.013), tot_loss_proj:3.641 [t=0.24s]
prediction: ['[CLS]? - larger fielder liberation -liffe action l exercise tale net collaborative arm shot - shoot do locked - - lot introel in question for director [SEP]']
[ 100/2000] tot_loss=2.296 (perp=10.169, rec=0.255, cos=0.008), tot_loss_proj:3.068 [t=0.24s]
prediction: ['[CLS]? - than than than -liffe action particularly exercise than net - bow shot - shootmm stiff - - shelf carlael inm for exercise [SEP]']
[ 150/2000] tot_loss=2.049 (perp=9.165, rec=0.209, cos=0.007), tot_loss_proj:2.502 [t=0.24s]
prediction: ['[CLS] - - than than - - ngc action - exercise than this - bow shoot - shootmm long -ed shelf bowel inel shelf exercise [SEP]']
[ 200/2000] tot_loss=2.154 (perp=10.003, rec=0.151, cos=0.003), tot_loss_proj:2.851 [t=0.24s]
prediction: ['[CLS] movements - this than than - soaked night - exercise than this - bow shoot - shootmm long -el shelf bowick inel shelf exercise [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.893 (perp=8.856, rec=0.120, cos=0.002), tot_loss_proj:2.770 [t=0.24s]
prediction: ['[CLS] movements - this than drama - exercise - - exercise than this - bow shoot - shootmm long -el shelf giick in crime - drama [SEP]']
[ 300/2000] tot_loss=1.892 (perp=8.933, rec=0.103, cos=0.002), tot_loss_proj:2.899 [t=0.24s]
prediction: ['[CLS] movements - this than drama - exercise - - exercise than this - bow shoot - shootmm long onel shelf giick in crime - drama [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.816 (perp=8.649, rec=0.085, cos=0.002), tot_loss_proj:2.819 [t=0.24s]
prediction: ['[CLS] movements - this than drama - exercise - - exercise than this - bow shoot - shootmm long onel shelf giick in crime drama - [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.752 (perp=8.348, rec=0.081, cos=0.002), tot_loss_proj:2.743 [t=0.24s]
prediction: ['[CLS] movements - this than drama - exercise - - exercise, this than bow shoot - shootmm long onel shelf giick in crime drama - [SEP]']
[ 450/2000] tot_loss=1.755 (perp=8.348, rec=0.084, cos=0.001), tot_loss_proj:2.745 [t=0.24s]
prediction: ['[CLS] movements - this than drama - exercise - - exercise, this than bow shoot - shootmm long onel shelf giick in crime drama - [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.671 (perp=7.898, rec=0.090, cos=0.001), tot_loss_proj:2.527 [t=0.24s]
prediction: ['[CLS] movements - that than long - exercise - - exercise, this than bow shoot - themm - onel shelf giick in crime drama - [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.658 (perp=7.897, rec=0.077, cos=0.001), tot_loss_proj:2.467 [t=0.24s]
prediction: ['[CLS] movements - this than long - exercise - - exercise, this than bow shoot - theelmm - on shelf giick in crime drama - [SEP]']
[ 600/2000] tot_loss=1.662 (perp=7.897, rec=0.082, cos=0.001), tot_loss_proj:2.473 [t=0.24s]
prediction: ['[CLS] movements - this than long - exercise - - exercise, this than bow shoot - theelmm - on shelf giick in crime drama - [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.614 (perp=7.650, rec=0.082, cos=0.001), tot_loss_proj:2.693 [t=0.24s]
prediction: ['[CLS] movements - this than long - - - - exercise, this than bow shoot - theelmm point on shelf giick in crime drama - [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.418 (perp=6.653, rec=0.086, cos=0.001), tot_loss_proj:1.984 [t=0.24s]
prediction: ['[CLS] movements - this than long - - - - exercise, this than bow shoot - theel - on shelf gimmick in crime drama - [SEP]']
[ 750/2000] tot_loss=1.404 (perp=6.653, rec=0.072, cos=0.001), tot_loss_proj:1.982 [t=0.24s]
prediction: ['[CLS] movements - this than long - - - - exercise, this than bow shoot - theel - on shelf gimmick in crime drama - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.404 (perp=6.653, rec=0.072, cos=0.001), tot_loss_proj:1.980 [t=0.24s]
prediction: ['[CLS] movements - this than long - - - - exercise, this than bow shoot - theel - on shelf gimmick in crime drama - [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.458 (perp=6.881, rec=0.081, cos=0.001), tot_loss_proj:2.063 [t=0.24s]
prediction: ['[CLS] movements - - than long - - - this exercise, this than bow shoot - theel - on shelf gimmick in crime drama point [SEP]']
[ 900/2000] tot_loss=1.450 (perp=6.881, rec=0.073, cos=0.001), tot_loss_proj:2.065 [t=0.24s]
prediction: ['[CLS] movements - - than long - - - this exercise, this than bow shoot - theel - on shelf gimmick in crime drama point [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.415 (perp=6.704, rec=0.073, cos=0.001), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] movements - - than long - - - this exercise, this and shoot - the bowel - on shelf gimmick in crime drama point [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.402 (perp=6.629, rec=0.075, cos=0.001), tot_loss_proj:1.970 [t=0.24s]
prediction: ['[CLS] movements - - than long - - - shoot exercise, this and this - the bowel - on shelf gimmick in crime drama point [SEP]']
[1050/2000] tot_loss=1.377 (perp=6.540, rec=0.068, cos=0.001), tot_loss_proj:1.977 [t=0.24s]
prediction: ['[CLS] movements - - than long - - - shoot exercise, this and that - the bowel - on shelf gimmick in crime drama point [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.381 (perp=6.540, rec=0.071, cos=0.001), tot_loss_proj:1.972 [t=0.24s]
prediction: ['[CLS] movements - - than long - - - shoot exercise, this and that - the bowel - on shelf gimmick in crime drama point [SEP]']
Attempt swap
[1150/2000] tot_loss=1.380 (perp=6.540, rec=0.071, cos=0.001), tot_loss_proj:1.970 [t=0.24s]
prediction: ['[CLS] movements - - than long - - - shoot exercise, this and that - the bowel - on shelf gimmick in crime drama point [SEP]']
[1200/2000] tot_loss=1.379 (perp=6.540, rec=0.070, cos=0.001), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] movements - - than long - - - shoot exercise, this and that - the bowel - on shelf gimmick in crime drama point [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.359 (perp=6.435, rec=0.071, cos=0.001), tot_loss_proj:1.931 [t=0.24s]
prediction: ['[CLS] movements - - than long - - shoot - exercise, this and that - the bowel - on shelf gimmick in crime drama point [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.350 (perp=6.395, rec=0.070, cos=0.001), tot_loss_proj:1.927 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - exercise, this and that - the bowel - on shelf gimmick in crime drama point [SEP]']
[1350/2000] tot_loss=1.379 (perp=6.523, rec=0.073, cos=0.001), tot_loss_proj:1.939 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - exercise, this and this - the bowel - on shelf gimmick in crime drama point [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.364 (perp=6.454, rec=0.072, cos=0.001), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - this exercise, and this - the bowel - on shelf gimmick in crime drama point [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.331 (perp=6.261, rec=0.078, cos=0.001), tot_loss_proj:1.989 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
[1500/2000] tot_loss=1.320 (perp=6.261, rec=0.066, cos=0.001), tot_loss_proj:1.991 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
Attempt swap
[1550/2000] tot_loss=1.316 (perp=6.261, rec=0.063, cos=0.001), tot_loss_proj:1.986 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.329 (perp=6.261, rec=0.076, cos=0.001), tot_loss_proj:2.000 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
[1650/2000] tot_loss=1.317 (perp=6.261, rec=0.063, cos=0.001), tot_loss_proj:2.001 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
Attempt swap
[1700/2000] tot_loss=1.325 (perp=6.261, rec=0.071, cos=0.001), tot_loss_proj:2.002 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
Attempt swap
[1750/2000] tot_loss=1.327 (perp=6.261, rec=0.073, cos=0.001), tot_loss_proj:1.996 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
[1800/2000] tot_loss=1.326 (perp=6.261, rec=0.073, cos=0.001), tot_loss_proj:2.003 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
Attempt swap
[1850/2000] tot_loss=1.323 (perp=6.261, rec=0.070, cos=0.001), tot_loss_proj:2.003 [t=0.24s]
prediction: ['[CLS] movements - - than long - shoot - - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.317 (perp=6.230, rec=0.070, cos=0.001), tot_loss_proj:1.967 [t=0.24s]
prediction: ['[CLS] movements - - than long - - shoot - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
[1950/2000] tot_loss=1.323 (perp=6.230, rec=0.075, cos=0.001), tot_loss_proj:1.965 [t=0.24s]
prediction: ['[CLS] movements - - than long - - shoot - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
Attempt swap
[2000/2000] tot_loss=1.316 (perp=6.230, rec=0.069, cos=0.001), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] movements - - than long - - shoot - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] movements - - than long - shoot - - this exercise, and this - the bowel shelf - on gimmick in crime drama point [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.892 | p: 89.474 | r: 94.444
rouge2     | fm: 11.429 | p: 11.111 | r: 11.765
rougeL     | fm: 54.054 | p: 52.632 | r: 55.556
rougeLsum  | fm: 54.054 | p: 52.632 | r: 55.556
r1fm+r2fm = 103.320

[Aggregate metrics]:
rouge1     | fm: 92.629 | p: 92.211 | r: 93.164
rouge2     | fm: 58.643 | p: 58.344 | r: 58.876
rougeL     | fm: 79.935 | p: 79.545 | r: 80.449
rougeLsum  | fm: 79.622 | p: 79.266 | r: 80.121
r1fm+r2fm = 151.272

input #45 time: 0:09:33 | total time: 7:09:20


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9992705828001183
highest_index [0]
highest [0.9992705828001183]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9912108182907104 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9792644381523132 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 0.9478821158409119 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9439657926559448 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9418700933456421 for ['[CLS] figures w direction pedrich newspaper [SEP]']
[Init] best rec loss: 0.9365411996841431 for ['[CLS] sacked age s between pack lowell [SEP]']
[Init] best rec loss: 0.933304488658905 for ['[CLS] once definition delgnoeousosed [SEP]']
[Init] best rec loss: 0.9163591265678406 for ['[CLS] four no and canada reed donald [SEP]']
[Init] best rec loss: 0.9133361577987671 for ['[CLS] serie templebie half succeeding coast [SEP]']
[Init] best perm rec loss: 0.9114199876785278 for ['[CLS] coast succeedingbie temple half serie [SEP]']
[Init] best perm rec loss: 0.910995364189148 for ['[CLS] serie coast succeedingbie half temple [SEP]']
[Init] best perm rec loss: 0.9107672572135925 for ['[CLS] serie succeeding coastbie half temple [SEP]']
[Init] best perm rec loss: 0.9105656743049622 for ['[CLS] succeedingbie serie half coast temple [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.730 (perp=12.498, rec=0.226, cos=0.004), tot_loss_proj:3.039 [t=0.23s]
prediction: ['[CLS] awarded surprising slick stepped, sleek [SEP]']
[ 100/2000] tot_loss=2.240 (perp=10.448, rec=0.147, cos=0.003), tot_loss_proj:2.909 [t=0.24s]
prediction: ['[CLS] visually striking slick caredly slick [SEP]']
[ 150/2000] tot_loss=2.179 (perp=10.263, rec=0.124, cos=0.003), tot_loss_proj:2.551 [t=0.24s]
prediction: ['[CLS] visually striking slick stagedly slick [SEP]']
[ 200/2000] tot_loss=2.146 (perp=10.263, rec=0.092, cos=0.002), tot_loss_proj:2.553 [t=0.24s]
prediction: ['[CLS] visually striking slick stagedly slick [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.810 (perp=8.615, rec=0.086, cos=0.002), tot_loss_proj:2.033 [t=0.24s]
prediction: ['[CLS] visually striking slick slickly staged [SEP]']
[ 300/2000] tot_loss=1.797 (perp=8.615, rec=0.072, cos=0.002), tot_loss_proj:2.035 [t=0.24s]
prediction: ['[CLS] visually striking slick slickly staged [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.802 (perp=8.615, rec=0.078, cos=0.002), tot_loss_proj:2.026 [t=0.24s]
prediction: ['[CLS] visually striking slick slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.359 (perp=6.442, rec=0.069, cos=0.002), tot_loss_proj:1.477 [t=0.24s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
[ 450/2000] tot_loss=1.349 (perp=6.442, rec=0.059, cos=0.001), tot_loss_proj:1.477 [t=0.24s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.336 (perp=6.442, rec=0.046, cos=0.001), tot_loss_proj:1.464 [t=0.24s]
prediction: ['[CLS] visually strikingly slickly staged [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.240 (perp=5.916, rec=0.055, cos=0.001), tot_loss_proj:1.254 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 600/2000] tot_loss=1.253 (perp=5.916, rec=0.068, cos=0.001), tot_loss_proj:1.247 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.234 (perp=5.916, rec=0.050, cos=0.001), tot_loss_proj:1.249 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.253 (perp=5.916, rec=0.068, cos=0.001), tot_loss_proj:1.250 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 750/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.243 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.239 (perp=5.916, rec=0.054, cos=0.001), tot_loss_proj:1.247 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.242 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.255 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.254 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.252 (perp=5.916, rec=0.068, cos=0.001), tot_loss_proj:1.245 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.249 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.247 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.237 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.239 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.241 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.239 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.237 (perp=5.916, rec=0.052, cos=0.001), tot_loss_proj:1.252 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.235 (perp=5.916, rec=0.051, cos=0.001), tot_loss_proj:1.244 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.243 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.239 (perp=5.916, rec=0.055, cos=0.001), tot_loss_proj:1.246 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.246 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.244 (perp=5.916, rec=0.059, cos=0.001), tot_loss_proj:1.233 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.246 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.244 (perp=5.916, rec=0.059, cos=0.001), tot_loss_proj:1.257 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.250 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.244 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.251 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.245 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.237 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.244 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.248 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.236 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.251 (perp=5.916, rec=0.066, cos=0.001), tot_loss_proj:1.246 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.240 (perp=5.916, rec=0.055, cos=0.001), tot_loss_proj:1.260 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.253 (perp=5.916, rec=0.069, cos=0.001), tot_loss_proj:1.250 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.823 | p: 92.404 | r: 93.299
rouge2     | fm: 59.685 | p: 59.428 | r: 59.908
rougeL     | fm: 80.344 | p: 79.972 | r: 80.811
rougeLsum  | fm: 79.997 | p: 79.563 | r: 80.463
r1fm+r2fm = 152.508

input #46 time: 0:09:21 | total time: 7:18:42


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9992061235456344
highest_index [0]
highest [0.9992061235456344]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6903454661369324 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6838828325271606 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6738404035568237 for ['[CLS] network biceps truth [SEP]']
[Init] best perm rec loss: 0.672116756439209 for ['[CLS] truth network biceps [SEP]']
[Init] best perm rec loss: 0.6701898574829102 for ['[CLS] truth biceps network [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.764 (perp=12.488, rec=0.227, cos=0.039), tot_loss_proj:3.340 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 100/2000] tot_loss=2.660 (perp=12.488, rec=0.123, cos=0.039), tot_loss_proj:3.382 [t=0.24s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=2.619 (perp=12.488, rec=0.114, cos=0.008), tot_loss_proj:3.410 [t=0.24s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 200/2000] tot_loss=2.615 (perp=12.488, rec=0.109, cos=0.008), tot_loss_proj:3.427 [t=0.24s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.910 (perp=8.803, rec=0.104, cos=0.045), tot_loss_proj:1.870 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 300/2000] tot_loss=1.828 (perp=8.803, rec=0.064, cos=0.004), tot_loss_proj:1.880 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.836 (perp=8.803, rec=0.070, cos=0.005), tot_loss_proj:1.873 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.832 (perp=8.803, rec=0.067, cos=0.004), tot_loss_proj:1.877 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=1.815 (perp=8.803, rec=0.052, cos=0.003), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.840 (perp=8.803, rec=0.071, cos=0.008), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.824 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.873 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.820 (perp=8.803, rec=0.057, cos=0.002), tot_loss_proj:1.870 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.824 (perp=8.803, rec=0.060, cos=0.004), tot_loss_proj:1.876 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.831 (perp=8.803, rec=0.065, cos=0.006), tot_loss_proj:1.888 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.823 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.886 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.828 (perp=8.803, rec=0.065, cos=0.003), tot_loss_proj:1.875 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.001), tot_loss_proj:1.886 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.871 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.816 (perp=8.803, rec=0.054, cos=0.001), tot_loss_proj:1.879 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.838 (perp=8.803, rec=0.076, cos=0.002), tot_loss_proj:1.879 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.872 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.883 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.832 (perp=8.803, rec=0.070, cos=0.002), tot_loss_proj:1.891 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.883 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.815 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.829 (perp=8.803, rec=0.067, cos=0.002), tot_loss_proj:1.873 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.875 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.834 (perp=8.803, rec=0.072, cos=0.002), tot_loss_proj:1.873 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.833 (perp=8.803, rec=0.071, cos=0.002), tot_loss_proj:1.880 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.819 (perp=8.803, rec=0.057, cos=0.002), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.815 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.880 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.836 (perp=8.803, rec=0.074, cos=0.002), tot_loss_proj:1.873 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.812 (perp=8.803, rec=0.050, cos=0.002), tot_loss_proj:1.873 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.817 (perp=8.803, rec=0.055, cos=0.002), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.877 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.870 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.829 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.887 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.817 (perp=8.803, rec=0.055, cos=0.002), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.881 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.829 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.869 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.948 | p: 92.530 | r: 93.445
rouge2     | fm: 60.364 | p: 60.163 | r: 60.717
rougeL     | fm: 80.905 | p: 80.549 | r: 81.312
rougeLsum  | fm: 80.527 | p: 80.168 | r: 81.002
r1fm+r2fm = 153.312

input #47 time: 0:09:09 | total time: 7:27:51


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9993043978769418
highest_index [0]
highest [0.9993043978769418]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.9514000415802002 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.9303548336029053 for ['[CLS] general deathstle air [SEP]']
[Init] best rec loss: 0.9121167063713074 for ['[CLS] indians * progress elevator [SEP]']
[Init] best rec loss: 0.895457923412323 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 0.8773390650749207 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.8653813004493713 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8400688171386719 for ['[CLS]lu natural horizontal work [SEP]']
[Init] best rec loss: 0.7992453575134277 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7948036193847656 for ['[CLS]tutedine graveyard runs [SEP]']
[Init] best perm rec loss: 0.7941678166389465 for ['[CLS]tute graveyarddine runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.657 (perp=12.408, rec=0.170, cos=0.005), tot_loss_proj:2.798 [t=0.23s]
prediction: ['[CLS] rotting rotting undering [SEP]']
[ 100/2000] tot_loss=2.528 (perp=12.071, rec=0.110, cos=0.004), tot_loss_proj:2.705 [t=0.24s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 150/2000] tot_loss=2.519 (perp=12.071, rec=0.101, cos=0.003), tot_loss_proj:2.695 [t=0.24s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 200/2000] tot_loss=2.509 (perp=12.071, rec=0.092, cos=0.003), tot_loss_proj:2.704 [t=0.24s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.221 (perp=10.480, rec=0.121, cos=0.004), tot_loss_proj:2.484 [t=0.24s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 300/2000] tot_loss=2.183 (perp=10.480, rec=0.085, cos=0.002), tot_loss_proj:2.470 [t=0.24s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.186 (perp=10.480, rec=0.089, cos=0.002), tot_loss_proj:2.486 [t=0.24s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.175 (perp=10.480, rec=0.078, cos=0.002), tot_loss_proj:2.483 [t=0.24s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 450/2000] tot_loss=2.178 (perp=10.480, rec=0.081, cos=0.001), tot_loss_proj:2.482 [t=0.24s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.170 (perp=10.480, rec=0.072, cos=0.001), tot_loss_proj:2.486 [t=0.24s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.726 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.480 (perp=7.028, rec=0.073, cos=0.001), tot_loss_proj:1.728 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.482 (perp=7.028, rec=0.075, cos=0.001), tot_loss_proj:1.734 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.737 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.479 (perp=7.028, rec=0.072, cos=0.001), tot_loss_proj:1.731 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.462 (perp=7.028, rec=0.055, cos=0.001), tot_loss_proj:1.727 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.735 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.736 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.480 (perp=7.028, rec=0.073, cos=0.001), tot_loss_proj:1.726 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.736 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.451 (perp=7.028, rec=0.044, cos=0.001), tot_loss_proj:1.734 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.461 (perp=7.028, rec=0.054, cos=0.001), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.736 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.727 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.481 (perp=7.028, rec=0.074, cos=0.001), tot_loss_proj:1.738 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.482 (perp=7.028, rec=0.075, cos=0.001), tot_loss_proj:1.734 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.465 (perp=7.028, rec=0.058, cos=0.001), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.464 (perp=7.028, rec=0.057, cos=0.001), tot_loss_proj:1.736 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.461 (perp=7.028, rec=0.054, cos=0.001), tot_loss_proj:1.728 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.466 (perp=7.028, rec=0.059, cos=0.001), tot_loss_proj:1.735 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.462 (perp=7.028, rec=0.055, cos=0.001), tot_loss_proj:1.726 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.727 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.742 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.729 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.736 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.484 (perp=7.028, rec=0.077, cos=0.001), tot_loss_proj:1.724 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 93.102 | p: 92.708 | r: 93.595
rouge2     | fm: 59.521 | p: 59.255 | r: 59.755
rougeL     | fm: 80.582 | p: 80.275 | r: 81.073
rougeLsum  | fm: 80.477 | p: 80.180 | r: 80.968
r1fm+r2fm = 152.623

input #48 time: 0:09:19 | total time: 7:37:11


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9992283885028335
highest_index [0]
highest [0.9992283885028335]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8313477635383606 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7865213751792908 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7855995297431946 for ['[CLS] painted exactly tips haunt unknown going wrong matches until tamillaw ambulance [SEP]']
[Init] best rec loss: 0.7833266854286194 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7775081992149353 for ['[CLS] auto indies pitch after walk lime *wled nike contested fit justin [SEP]']
[Init] best rec loss: 0.7649335861206055 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best rec loss: 0.7577332258224487 for ['[CLS] trick jose college legs jockey baby tongue processiza during gmina patrick [SEP]']
[Init] best perm rec loss: 0.7532427906990051 for ['[CLS] legs jose trick tongue gmina collegeiza during jockey patrick process baby [SEP]']
[Init] best perm rec loss: 0.7514466047286987 for ['[CLS] joseiza legs tongue trick jockey college gmina during process baby patrick [SEP]']
[Init] best perm rec loss: 0.7511851191520691 for ['[CLS] process gmina jockey legs during jose baby tongue patrickiza trick college [SEP]']
[Init] best perm rec loss: 0.7511382102966309 for ['[CLS] trick jose gmina legs collegeiza baby during tongue process patrick jockey [SEP]']
[Init] best perm rec loss: 0.7508964538574219 for ['[CLS] legs college process patrick trick jose babyiza gmina tongue during jockey [SEP]']
[Init] best perm rec loss: 0.7492689490318298 for ['[CLS] jose process legs during baby gmina jockey trick college tongue patrickiza [SEP]']
[Init] best perm rec loss: 0.7477436661720276 for ['[CLS]iza patrick tongue college trick process during legs gmina jose jockey baby [SEP]']
[Init] best perm rec loss: 0.7475663423538208 for ['[CLS]iza process patrick trick jockey tongue legs during college baby jose gmina [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.512 (perp=10.853, rec=0.298, cos=0.043), tot_loss_proj:3.157 [t=0.22s]
prediction: ['[CLS] could if females contempt more contempt females. woman drug keeps easily [SEP]']
[ 100/2000] tot_loss=2.225 (perp=10.121, rec=0.189, cos=0.012), tot_loss_proj:2.937 [t=0.22s]
prediction: ['[CLS] could if more contempt single contemptuous. female against keeper the [SEP]']
[ 150/2000] tot_loss=2.245 (perp=10.476, rec=0.142, cos=0.007), tot_loss_proj:2.956 [t=0.22s]
prediction: ['[CLS] possibly be more contempt single moreuous. female against population the [SEP]']
[ 200/2000] tot_loss=2.332 (perp=10.955, rec=0.133, cos=0.008), tot_loss_proj:3.059 [t=0.22s]
prediction: ['[CLS] possibly be more contempt single moreuous. female drug population the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.013 (perp=9.397, rec=0.127, cos=0.007), tot_loss_proj:2.688 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous be single. female licence population the [SEP]']
[ 300/2000] tot_loss=1.949 (perp=9.230, rec=0.099, cos=0.004), tot_loss_proj:2.605 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous be single. female label population the [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.658 (perp=7.764, rec=0.100, cos=0.005), tot_loss_proj:2.086 [t=0.22s]
prediction: ['[CLS] could be more contemptuous be single of the female licence population [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.588 (perp=7.462, rec=0.092, cos=0.004), tot_loss_proj:2.078 [t=0.22s]
prediction: ['[CLS] could be more contemptuous be single of the female population licence [SEP]']
[ 450/2000] tot_loss=1.758 (perp=8.293, rec=0.095, cos=0.005), tot_loss_proj:2.265 [t=0.22s]
prediction: ['[CLS] could possibly more contemptuous be single of the female population licence [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.761 (perp=8.293, rec=0.099, cos=0.004), tot_loss_proj:2.269 [t=0.22s]
prediction: ['[CLS] could possibly more contemptuous be single of the female population licence [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.654 (perp=7.683, rec=0.109, cos=0.008), tot_loss_proj:2.047 [t=0.22s]
prediction: ['[CLS] could possibly be contemptuous more single of the female population label [SEP]']
[ 600/2000] tot_loss=1.635 (perp=7.683, rec=0.093, cos=0.005), tot_loss_proj:2.040 [t=0.22s]
prediction: ['[CLS] could possibly be contemptuous more single of the female population label [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.544 (perp=7.274, rec=0.084, cos=0.005), tot_loss_proj:2.043 [t=0.22s]
prediction: ['[CLS] could possibly be contemptuous more of the single female population label [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.381 (perp=6.475, rec=0.081, cos=0.005), tot_loss_proj:1.679 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population label [SEP]']
[ 750/2000] tot_loss=1.374 (perp=6.475, rec=0.074, cos=0.004), tot_loss_proj:1.673 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population label [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.384 (perp=6.475, rec=0.085, cos=0.004), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population label [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.085 (perp=5.000, rec=0.081, cos=0.004), tot_loss_proj:1.127 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[ 900/2000] tot_loss=1.082 (perp=5.000, rec=0.078, cos=0.004), tot_loss_proj:1.126 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.083 (perp=5.000, rec=0.079, cos=0.004), tot_loss_proj:1.122 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.074 (perp=5.000, rec=0.070, cos=0.004), tot_loss_proj:1.123 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[1050/2000] tot_loss=1.074 (perp=5.000, rec=0.070, cos=0.004), tot_loss_proj:1.123 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.080 (perp=5.000, rec=0.077, cos=0.004), tot_loss_proj:1.130 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.076 (perp=5.000, rec=0.073, cos=0.004), tot_loss_proj:1.123 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[1200/2000] tot_loss=1.075 (perp=5.000, rec=0.071, cos=0.004), tot_loss_proj:1.123 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.078 (perp=5.000, rec=0.074, cos=0.004), tot_loss_proj:1.125 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.076 (perp=5.000, rec=0.073, cos=0.004), tot_loss_proj:1.130 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[1350/2000] tot_loss=1.064 (perp=5.000, rec=0.060, cos=0.004), tot_loss_proj:1.120 [t=0.23s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.074 (perp=5.000, rec=0.071, cos=0.004), tot_loss_proj:1.121 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.086 (perp=5.000, rec=0.083, cos=0.003), tot_loss_proj:1.127 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[1500/2000] tot_loss=1.081 (perp=5.000, rec=0.078, cos=0.003), tot_loss_proj:1.125 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.080 (perp=5.000, rec=0.077, cos=0.003), tot_loss_proj:1.124 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.078 (perp=5.000, rec=0.075, cos=0.003), tot_loss_proj:1.129 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[1650/2000] tot_loss=1.079 (perp=5.000, rec=0.076, cos=0.003), tot_loss_proj:1.118 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.072 (perp=5.000, rec=0.070, cos=0.003), tot_loss_proj:1.124 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.086 (perp=5.000, rec=0.083, cos=0.003), tot_loss_proj:1.116 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[1800/2000] tot_loss=1.075 (perp=5.000, rec=0.072, cos=0.003), tot_loss_proj:1.125 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.074 (perp=5.000, rec=0.072, cos=0.003), tot_loss_proj:1.123 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.080 (perp=5.000, rec=0.078, cos=0.003), tot_loss_proj:1.122 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[1950/2000] tot_loss=1.076 (perp=5.000, rec=0.074, cos=0.002), tot_loss_proj:1.133 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.073 (perp=5.000, rec=0.071, cos=0.002), tot_loss_proj:1.122 [t=0.22s]
prediction: ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.222 | p: 92.844 | r: 93.724
rouge2     | fm: 60.227 | p: 59.940 | r: 60.523
rougeL     | fm: 81.079 | p: 80.757 | r: 81.570
rougeLsum  | fm: 80.852 | p: 80.445 | r: 81.247
r1fm+r2fm = 153.449

input #49 time: 0:08:46 | total time: 7:45:57


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.999284077484796
highest_index [0]
highest [0.999284077484796]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.9135558009147644 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8380478620529175 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.8375792503356934 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7549297213554382 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7542427182197571 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best perm rec loss: 0.7526724338531494 for ['[CLS] bridgetievinghamlent red by crisis accordance night [SEP]']
[Init] best perm rec loss: 0.7519044876098633 for ['[CLS]ieving byham crisis red accordance night bridgetlent [SEP]']
[Init] best perm rec loss: 0.7473711967468262 for ['[CLS] redham crisislent accordanceieving night bridget by [SEP]']
[Init] best perm rec loss: 0.7473464608192444 for ['[CLS] redlent night crisis accordanceieving by bridgetham [SEP]']
[Init] best perm rec loss: 0.74727863073349 for ['[CLS]lentham nightieving red accordance by crisis bridget [SEP]']
[Init] best perm rec loss: 0.7469528913497925 for ['[CLS] nightlent crisisham accordance bridgetieving red by [SEP]']
[Init] best perm rec loss: 0.7462561130523682 for ['[CLS] night byieving accordancelent crisis red bridgetham [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.703 (perp=11.417, rec=0.373, cos=0.046), tot_loss_proj:3.313 [t=0.23s]
prediction: ['[CLS] to coincidence clever class writer section golden thin half [SEP]']
[ 100/2000] tot_loss=2.348 (perp=9.718, rec=0.343, cos=0.061), tot_loss_proj:3.134 [t=0.23s]
prediction: ['[CLS] as about clever english english by clever too half [SEP]']
[ 150/2000] tot_loss=2.230 (perp=9.701, rec=0.272, cos=0.018), tot_loss_proj:3.044 [t=0.23s]
prediction: ['[CLS] what about clever english english by clever too half [SEP]']
[ 200/2000] tot_loss=2.214 (perp=9.701, rec=0.257, cos=0.017), tot_loss_proj:3.037 [t=0.23s]
prediction: ['[CLS] what about clever english english by clever too half [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.263 (perp=9.773, rec=0.279, cos=0.029), tot_loss_proj:2.850 [t=0.23s]
prediction: ["[CLS] what'clever ` english by english too half [SEP]"]
[ 300/2000] tot_loss=2.187 (perp=9.773, rec=0.218, cos=0.014), tot_loss_proj:2.853 [t=0.23s]
prediction: ["[CLS] what'clever ` english by english too half [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.966 (perp=8.877, rec=0.172, cos=0.019), tot_loss_proj:2.670 [t=0.23s]
prediction: ["[CLS] what'` english by clever english too half [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.867 (perp=8.545, rec=0.152, cos=0.007), tot_loss_proj:2.597 [t=0.23s]
prediction: ['[CLS] what the ` english by clever english too half [SEP]']
[ 450/2000] tot_loss=1.854 (perp=8.545, rec=0.138, cos=0.006), tot_loss_proj:2.596 [t=0.24s]
prediction: ['[CLS] what the ` english by clever english too half [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.777 (perp=8.190, rec=0.133, cos=0.006), tot_loss_proj:2.520 [t=0.24s]
prediction: ['[CLS] what the call english by clever english too half [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.993 (perp=9.276, rec=0.131, cos=0.007), tot_loss_proj:2.605 [t=0.24s]
prediction: ['[CLS] what ` english call by clever english too half [SEP]']
[ 600/2000] tot_loss=1.974 (perp=9.276, rec=0.114, cos=0.005), tot_loss_proj:2.603 [t=0.24s]
prediction: ['[CLS] what ` english call by clever english too half [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.965 (perp=9.276, rec=0.106, cos=0.003), tot_loss_proj:2.608 [t=0.24s]
prediction: ['[CLS] what ` english call by clever english too half [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.966 (perp=9.276, rec=0.108, cos=0.003), tot_loss_proj:2.613 [t=0.24s]
prediction: ['[CLS] what ` english call by clever english too half [SEP]']
[ 750/2000] tot_loss=1.937 (perp=9.276, rec=0.079, cos=0.002), tot_loss_proj:2.610 [t=0.24s]
prediction: ['[CLS] what ` english call by clever english too half [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.942 (perp=9.276, rec=0.085, cos=0.002), tot_loss_proj:2.605 [t=0.24s]
prediction: ['[CLS] what ` english call by clever english too half [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.945 (perp=9.276, rec=0.088, cos=0.002), tot_loss_proj:2.610 [t=0.23s]
prediction: ['[CLS] what ` english call by clever english too half [SEP]']
[ 900/2000] tot_loss=1.981 (perp=9.540, rec=0.071, cos=0.002), tot_loss_proj:2.812 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.993 (perp=9.540, rec=0.083, cos=0.001), tot_loss_proj:2.816 [t=0.24s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1000/2000] tot_loss=1.986 (perp=9.540, rec=0.077, cos=0.001), tot_loss_proj:2.818 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
[1050/2000] tot_loss=1.981 (perp=9.540, rec=0.072, cos=0.001), tot_loss_proj:2.812 [t=0.24s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1100/2000] tot_loss=1.980 (perp=9.540, rec=0.070, cos=0.001), tot_loss_proj:2.810 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1150/2000] tot_loss=1.992 (perp=9.540, rec=0.082, cos=0.001), tot_loss_proj:2.813 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
[1200/2000] tot_loss=1.977 (perp=9.540, rec=0.067, cos=0.001), tot_loss_proj:2.819 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1250/2000] tot_loss=1.982 (perp=9.540, rec=0.073, cos=0.001), tot_loss_proj:2.816 [t=0.24s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1300/2000] tot_loss=1.982 (perp=9.540, rec=0.072, cos=0.001), tot_loss_proj:2.815 [t=0.24s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
[1350/2000] tot_loss=1.991 (perp=9.540, rec=0.081, cos=0.001), tot_loss_proj:2.815 [t=0.24s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1400/2000] tot_loss=1.982 (perp=9.540, rec=0.073, cos=0.001), tot_loss_proj:2.813 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1450/2000] tot_loss=1.987 (perp=9.540, rec=0.077, cos=0.001), tot_loss_proj:2.823 [t=0.24s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
[1500/2000] tot_loss=1.990 (perp=9.540, rec=0.081, cos=0.001), tot_loss_proj:2.811 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1550/2000] tot_loss=1.977 (perp=9.540, rec=0.067, cos=0.001), tot_loss_proj:2.812 [t=0.24s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1600/2000] tot_loss=1.985 (perp=9.540, rec=0.075, cos=0.001), tot_loss_proj:2.819 [t=0.24s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
[1650/2000] tot_loss=1.989 (perp=9.540, rec=0.079, cos=0.001), tot_loss_proj:2.816 [t=0.24s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1700/2000] tot_loss=1.982 (perp=9.540, rec=0.072, cos=0.001), tot_loss_proj:2.814 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1750/2000] tot_loss=1.975 (perp=9.540, rec=0.065, cos=0.001), tot_loss_proj:2.818 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
[1800/2000] tot_loss=1.981 (perp=9.540, rec=0.071, cos=0.001), tot_loss_proj:2.817 [t=0.24s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1850/2000] tot_loss=1.984 (perp=9.540, rec=0.075, cos=0.001), tot_loss_proj:2.820 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[1900/2000] tot_loss=1.987 (perp=9.540, rec=0.078, cos=0.001), tot_loss_proj:2.816 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
[1950/2000] tot_loss=1.985 (perp=9.540, rec=0.076, cos=0.001), tot_loss_proj:2.813 [t=0.23s]
prediction: ['[CLS] what ` call call by clever english too half [SEP]']
Attempt swap
[2000/2000] tot_loss=1.928 (perp=9.276, rec=0.071, cos=0.001), tot_loss_proj:2.603 [t=0.23s]
prediction: ['[CLS] what ` english call by clever english too half [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what ` call call by clever english too half [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 22.222 | p: 22.222 | r: 22.222
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 112.222

[Aggregate metrics]:
rouge1     | fm: 93.177 | p: 92.784 | r: 93.649
rouge2     | fm: 59.477 | p: 59.310 | r: 59.699
rougeL     | fm: 80.759 | p: 80.419 | r: 81.202
rougeLsum  | fm: 80.465 | p: 80.123 | r: 80.869
r1fm+r2fm = 152.654

input #50 time: 0:09:18 | total time: 7:55:15


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9992547713036274
highest_index [0]
highest [0.9992547713036274]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.8252744078636169 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7898684740066528 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.739183247089386 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7309952974319458 for ['[CLS] join paying nonsense thought secret mine sans fields sara stench [SEP]']
[Init] best rec loss: 0.7296013236045837 for ['[CLS] lying acceptance [MASK] longer fence hotel rocking view knocked iaaf [SEP]']
[Init] best rec loss: 0.719580888748169 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7093055844306946 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 0.7078049778938293 for ['[CLS] disappointed market in toured literary watching once renamedrak medium [SEP]']
[Init] best perm rec loss: 0.7040138840675354 for ['[CLS] in toured once renamed medium watching market disappointed literaryrak [SEP]']
[Init] best perm rec loss: 0.7027232050895691 for ['[CLS] market mediumrak in disappointed once watching literary toured renamed [SEP]']
[Init] best perm rec loss: 0.702092707157135 for ['[CLS]rak once toured market watching renamed disappointed medium literary in [SEP]']
[Init] best perm rec loss: 0.7017946243286133 for ['[CLS] watching disappointed literaryrak once in renamed toured market medium [SEP]']
[Init] best perm rec loss: 0.700471043586731 for ['[CLS] market toured watching in disappointed renamed medium once literaryrak [SEP]']
[Init] best perm rec loss: 0.7004427313804626 for ['[CLS] toured watching disappointed once market literaryrak renamed medium in [SEP]']
[Init] best perm rec loss: 0.6999508738517761 for ['[CLS] toured renamed disappointed market once literary watching inrak medium [SEP]']
[Init] best perm rec loss: 0.6995094418525696 for ['[CLS] watching inrak renamed medium disappointed toured once market literary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.045 (perp=13.196, rec=0.363, cos=0.043), tot_loss_proj:4.070 [t=0.23s]
prediction: ['[CLS] sucks sucks little steven funny funny story funny sucks has [SEP]']
[ 100/2000] tot_loss=3.016 (perp=13.378, rec=0.264, cos=0.076), tot_loss_proj:3.653 [t=0.23s]
prediction: ['[CLS] sucks sucks although steven funny purpose bitch funny sucks has [SEP]']
[ 150/2000] tot_loss=2.026 (perp=9.194, rec=0.168, cos=0.019), tot_loss_proj:2.801 [t=0.23s]
prediction: ['[CLS] sucks sucks but. funny or two funny sucks has [SEP]']
[ 200/2000] tot_loss=2.087 (perp=9.768, rec=0.126, cos=0.008), tot_loss_proj:3.081 [t=0.24s]
prediction: ['[CLS] sucks sucks but. funny or two moment sucks has [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.117 (perp=8.271, rec=0.354, cos=0.109), tot_loss_proj:2.395 [t=0.24s]
prediction: ['[CLS] sucks sucks but has funny or two moments sucks. [SEP]']
[ 300/2000] tot_loss=2.053 (perp=8.813, rec=0.260, cos=0.030), tot_loss_proj:2.687 [t=0.24s]
prediction: ['[CLS] sucks sucks but has funny or two moment sucks. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.013 (perp=8.962, rec=0.204, cos=0.017), tot_loss_proj:2.498 [t=0.23s]
prediction: ['[CLS] sucks does but has funny moment or two sucks. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.716 (perp=7.636, rec=0.178, cos=0.011), tot_loss_proj:2.199 [t=0.24s]
prediction: ['[CLS] does sucks but has funny moment or two sucks. [SEP]']
[ 450/2000] tot_loss=1.668 (perp=7.577, rec=0.145, cos=0.008), tot_loss_proj:2.151 [t=0.23s]
prediction: ['[CLS] gives sucks but has funny moment or two sucks. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.654 (perp=7.577, rec=0.131, cos=0.007), tot_loss_proj:2.151 [t=0.24s]
prediction: ['[CLS] gives sucks but has funny moment or two sucks. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.665 (perp=7.577, rec=0.142, cos=0.007), tot_loss_proj:2.154 [t=0.23s]
prediction: ['[CLS] gives sucks but has funny moment or two sucks. [SEP]']
[ 600/2000] tot_loss=1.650 (perp=7.577, rec=0.128, cos=0.007), tot_loss_proj:2.150 [t=0.24s]
prediction: ['[CLS] gives sucks but has funny moment or two sucks. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.645 (perp=7.577, rec=0.123, cos=0.007), tot_loss_proj:2.154 [t=0.24s]
prediction: ['[CLS] gives sucks but has funny moment or two sucks. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.848 (perp=8.557, rec=0.129, cos=0.008), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] sucks sucks but has funny moment or two gives. [SEP]']
[ 750/2000] tot_loss=1.832 (perp=8.557, rec=0.115, cos=0.006), tot_loss_proj:2.306 [t=0.24s]
prediction: ['[CLS] sucks sucks but has funny moment or two gives. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.655 (perp=7.680, rec=0.113, cos=0.006), tot_loss_proj:2.043 [t=0.23s]
prediction: ['[CLS] sucks but has funny moment or two funny sucks. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.651 (perp=7.680, rec=0.109, cos=0.006), tot_loss_proj:2.036 [t=0.23s]
prediction: ['[CLS] sucks but has funny moment or two funny sucks. [SEP]']
[ 900/2000] tot_loss=1.665 (perp=7.680, rec=0.123, cos=0.006), tot_loss_proj:2.034 [t=0.24s]
prediction: ['[CLS] sucks but has funny moment or two funny sucks. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.658 (perp=7.680, rec=0.116, cos=0.006), tot_loss_proj:2.040 [t=0.23s]
prediction: ['[CLS] sucks but has funny moment or two funny sucks. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.645 (perp=7.680, rec=0.103, cos=0.006), tot_loss_proj:2.034 [t=0.23s]
prediction: ['[CLS] sucks but has funny moment or two funny sucks. [SEP]']
[1050/2000] tot_loss=1.643 (perp=7.680, rec=0.102, cos=0.006), tot_loss_proj:2.037 [t=0.23s]
prediction: ['[CLS] sucks but has funny moment or two funny sucks. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.645 (perp=7.680, rec=0.104, cos=0.005), tot_loss_proj:2.038 [t=0.24s]
prediction: ['[CLS] sucks but has funny moment or two funny sucks. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.556 (perp=7.105, rec=0.125, cos=0.011), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
[1200/2000] tot_loss=1.539 (perp=7.105, rec=0.113, cos=0.006), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.537 (perp=7.105, rec=0.111, cos=0.005), tot_loss_proj:2.090 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.543 (perp=7.105, rec=0.118, cos=0.005), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
[1350/2000] tot_loss=1.535 (perp=7.105, rec=0.109, cos=0.005), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.535 (perp=7.105, rec=0.109, cos=0.005), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.533 (perp=7.105, rec=0.107, cos=0.005), tot_loss_proj:2.101 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
[1500/2000] tot_loss=1.535 (perp=7.105, rec=0.110, cos=0.005), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.521 (perp=7.105, rec=0.095, cos=0.005), tot_loss_proj:2.099 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.527 (perp=7.105, rec=0.101, cos=0.005), tot_loss_proj:2.103 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
[1650/2000] tot_loss=1.538 (perp=7.105, rec=0.112, cos=0.005), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.528 (perp=7.105, rec=0.102, cos=0.005), tot_loss_proj:2.090 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.529 (perp=7.105, rec=0.103, cos=0.004), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
[1800/2000] tot_loss=1.518 (perp=7.105, rec=0.092, cos=0.004), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.524 (perp=7.105, rec=0.099, cos=0.004), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.524 (perp=7.105, rec=0.099, cos=0.004), tot_loss_proj:2.091 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
[1950/2000] tot_loss=1.517 (perp=7.105, rec=0.091, cos=0.004), tot_loss_proj:2.094 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.528 (perp=7.105, rec=0.103, cos=0.004), tot_loss_proj:2.089 [t=0.22s]
prediction: ['[CLS] has funny sucks but moment or two funny sucks. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] has funny sucks but moment or two funny sucks. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 31.579 | p: 30.000 | r: 33.333
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 117.293

[Aggregate metrics]:
rouge1     | fm: 92.997 | p: 92.598 | r: 93.548
rouge2     | fm: 58.744 | p: 58.502 | r: 59.096
rougeL     | fm: 80.474 | p: 80.151 | r: 80.930
rougeLsum  | fm: 80.161 | p: 79.721 | r: 80.633
r1fm+r2fm = 151.741

input #51 time: 0:09:04 | total time: 8:04:20


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9992764367772101
highest_index [0]
highest [0.9992764367772101]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9593117237091064 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9314094185829163 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8956812024116516 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 0.869678795337677 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.796468198299408 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7784504294395447 for ['[CLS] confession commentator die [SEP]']
[Init] best rec loss: 0.7061877846717834 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.7012255787849426 for ['[CLS] expected football vocabulary [SEP]']
[Init] best perm rec loss: 0.6979407072067261 for ['[CLS] football vocabulary expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.272 (perp=10.655, rec=0.137, cos=0.003), tot_loss_proj:2.464 [t=0.22s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 100/2000] tot_loss=2.174 (perp=10.529, rec=0.067, cos=0.001), tot_loss_proj:2.204 [t=0.22s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 150/2000] tot_loss=2.174 (perp=10.529, rec=0.067, cos=0.002), tot_loss_proj:2.199 [t=0.22s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 200/2000] tot_loss=2.178 (perp=10.529, rec=0.069, cos=0.002), tot_loss_proj:2.200 [t=0.22s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.803 (perp=8.483, rec=0.103, cos=0.003), tot_loss_proj:2.139 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.766 (perp=8.483, rec=0.068, cos=0.001), tot_loss_proj:2.134 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.768 (perp=8.483, rec=0.070, cos=0.002), tot_loss_proj:2.123 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.768 (perp=8.483, rec=0.070, cos=0.001), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.758 (perp=8.483, rec=0.060, cos=0.001), tot_loss_proj:2.129 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.761 (perp=8.483, rec=0.063, cos=0.001), tot_loss_proj:2.131 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.133 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.774 (perp=8.483, rec=0.076, cos=0.001), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.125 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.751 (perp=8.483, rec=0.053, cos=0.001), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.756 (perp=8.483, rec=0.058, cos=0.001), tot_loss_proj:2.131 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.750 (perp=8.483, rec=0.052, cos=0.001), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.754 (perp=8.483, rec=0.056, cos=0.001), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.131 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.765 (perp=8.483, rec=0.067, cos=0.001), tot_loss_proj:2.120 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.771 (perp=8.483, rec=0.073, cos=0.001), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.754 (perp=8.483, rec=0.056, cos=0.001), tot_loss_proj:2.128 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.768 (perp=8.483, rec=0.070, cos=0.001), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.767 (perp=8.483, rec=0.069, cos=0.001), tot_loss_proj:2.125 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.760 (perp=8.483, rec=0.062, cos=0.001), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.761 (perp=8.483, rec=0.063, cos=0.001), tot_loss_proj:2.118 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.749 (perp=8.483, rec=0.051, cos=0.001), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.758 (perp=8.483, rec=0.060, cos=0.001), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.755 (perp=8.483, rec=0.057, cos=0.001), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.757 (perp=8.483, rec=0.059, cos=0.001), tot_loss_proj:2.123 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.753 (perp=8.483, rec=0.055, cos=0.001), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.763 (perp=8.483, rec=0.065, cos=0.001), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.764 (perp=8.483, rec=0.066, cos=0.001), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.759 (perp=8.483, rec=0.061, cos=0.001), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.762 (perp=8.483, rec=0.064, cos=0.001), tot_loss_proj:2.121 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.752 (perp=8.483, rec=0.054, cos=0.001), tot_loss_proj:2.125 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.765 (perp=8.483, rec=0.067, cos=0.001), tot_loss_proj:2.120 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.761 (perp=8.483, rec=0.063, cos=0.001), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.772 (perp=8.483, rec=0.074, cos=0.001), tot_loss_proj:2.124 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.770 (perp=8.483, rec=0.072, cos=0.001), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 93.171 | p: 92.700 | r: 93.695
rouge2     | fm: 57.675 | p: 57.464 | r: 57.885
rougeL     | fm: 80.453 | p: 80.031 | r: 80.911
rougeLsum  | fm: 80.068 | p: 79.630 | r: 80.556
r1fm+r2fm = 150.846

input #52 time: 0:08:43 | total time: 8:13:04


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9993456844224258
highest_index [0]
highest [0.9993456844224258]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.9461240172386169 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.8590062260627747 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 0.8272409439086914 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 0.7982022166252136 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 0.7196051478385925 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.7162439823150635 for ['[CLS] oro edna [SEP]']
[Init] best rec loss: 0.70369952917099 for ['[CLS] lake highlands [SEP]']
[Init] best rec loss: 0.6949193477630615 for ['[CLS] towerbal [SEP]']
[Init] best rec loss: 0.6925686001777649 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6793366074562073 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6766685843467712 for ['[CLS] el peace [SEP]']
[Init] best perm rec loss: 0.6740282773971558 for ['[CLS] peace el [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.791 (perp=12.493, rec=0.244, cos=0.048), tot_loss_proj:3.340 [t=0.23s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=2.668 (perp=12.493, rec=0.152, cos=0.018), tot_loss_proj:3.349 [t=0.24s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.661 (perp=12.493, rec=0.141, cos=0.022), tot_loss_proj:3.350 [t=0.24s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=1.711 (perp=8.090, rec=0.089, cos=0.004), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.689 (perp=8.090, rec=0.070, cos=0.002), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.675 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.692 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.681 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.685 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.689 (perp=8.090, rec=0.070, cos=0.001), tot_loss_proj:1.677 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.687 (perp=8.090, rec=0.068, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.682 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.683 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.694 (perp=8.090, rec=0.075, cos=0.001), tot_loss_proj:1.686 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.689 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.671 (perp=8.090, rec=0.052, cos=0.001), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.676 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.668 (perp=8.090, rec=0.049, cos=0.001), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.676 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.671 (perp=8.090, rec=0.052, cos=0.001), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.669 (perp=8.090, rec=0.049, cos=0.001), tot_loss_proj:1.695 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.689 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.700 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.672 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.688 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.688 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.681 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.671 (perp=8.090, rec=0.052, cos=0.001), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.688 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.689 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.682 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.693 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.668 (perp=8.090, rec=0.049, cos=0.001), tot_loss_proj:1.681 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.277 | p: 92.860 | r: 93.786
rouge2     | fm: 58.582 | p: 58.395 | r: 58.865
rougeL     | fm: 80.725 | p: 80.320 | r: 81.188
rougeLsum  | fm: 80.446 | p: 80.027 | r: 80.896
r1fm+r2fm = 151.860

input #53 time: 0:09:22 | total time: 8:22:27


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9991884370301731
highest_index [0]
highest [0.9991884370301731]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.9502385258674622 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.8056384325027466 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7584183812141418 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.7190370559692383 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.7029566168785095 for ['[CLS] deployment bro [SEP]']
[Init] best perm rec loss: 0.701512336730957 for ['[CLS] bro deployment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.724 (perp=11.486, rec=0.371, cos=0.056), tot_loss_proj:3.111 [t=0.22s]
prediction: ['[CLS] topics intense [SEP]']
[ 100/2000] tot_loss=2.508 (perp=11.553, rec=0.187, cos=0.010), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.424 (perp=11.553, rec=0.110, cos=0.004), tot_loss_proj:2.884 [t=0.22s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.396 (perp=11.553, rec=0.082, cos=0.004), tot_loss_proj:2.885 [t=0.22s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.710 (perp=8.197, rec=0.067, cos=0.003), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.711 (perp=8.197, rec=0.070, cos=0.002), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.703 (perp=8.197, rec=0.061, cos=0.002), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.704 (perp=8.197, rec=0.063, cos=0.002), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.699 (perp=8.197, rec=0.058, cos=0.002), tot_loss_proj:1.732 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.709 (perp=8.197, rec=0.067, cos=0.002), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.706 (perp=8.197, rec=0.065, cos=0.002), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.695 (perp=8.197, rec=0.054, cos=0.002), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.721 (perp=8.197, rec=0.079, cos=0.002), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.709 (perp=8.197, rec=0.068, cos=0.002), tot_loss_proj:1.746 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.709 (perp=8.197, rec=0.068, cos=0.002), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.717 (perp=8.197, rec=0.076, cos=0.002), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.700 (perp=8.197, rec=0.059, cos=0.002), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.701 (perp=8.197, rec=0.060, cos=0.002), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.697 (perp=8.197, rec=0.056, cos=0.002), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.699 (perp=8.197, rec=0.058, cos=0.002), tot_loss_proj:1.729 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.713 (perp=8.197, rec=0.072, cos=0.002), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.705 (perp=8.197, rec=0.064, cos=0.002), tot_loss_proj:1.761 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.708 (perp=8.197, rec=0.067, cos=0.002), tot_loss_proj:1.736 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.713 (perp=8.197, rec=0.072, cos=0.002), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.709 (perp=8.197, rec=0.068, cos=0.002), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.712 (perp=8.197, rec=0.071, cos=0.002), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.704 (perp=8.197, rec=0.063, cos=0.002), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.694 (perp=8.197, rec=0.053, cos=0.002), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.702 (perp=8.197, rec=0.061, cos=0.002), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.692 (perp=8.197, rec=0.051, cos=0.002), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.694 (perp=8.197, rec=0.053, cos=0.002), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.697 (perp=8.197, rec=0.056, cos=0.002), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.706 (perp=8.197, rec=0.065, cos=0.002), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.701 (perp=8.197, rec=0.060, cos=0.002), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.710 (perp=8.197, rec=0.069, cos=0.002), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.703 (perp=8.197, rec=0.062, cos=0.002), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.705 (perp=8.197, rec=0.064, cos=0.002), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.698 (perp=8.197, rec=0.057, cos=0.002), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.693 (perp=8.197, rec=0.052, cos=0.002), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.703 (perp=8.197, rec=0.062, cos=0.002), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.372 | p: 92.960 | r: 93.902
rouge2     | fm: 59.332 | p: 58.984 | r: 59.570
rougeL     | fm: 81.128 | p: 80.776 | r: 81.616
rougeLsum  | fm: 80.824 | p: 80.410 | r: 81.233
r1fm+r2fm = 152.705

input #54 time: 0:08:43 | total time: 8:31:10


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9991211459235085
highest_index [0]
highest [0.9991211459235085]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.913703441619873 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.8614296317100525 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7851947546005249 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 0.7724620699882507 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7565978169441223 for ['[CLS] kirk door regional [SEP]']
[Init] best rec loss: 0.7475483417510986 for ['[CLS] plantesthesia pr [SEP]']
[Init] best rec loss: 0.72279953956604 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7064613103866577 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7058060765266418 for ['[CLS] post holly stride [SEP]']
[Init] best perm rec loss: 0.7033426761627197 for ['[CLS] stride post holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.513 (perp=10.160, rec=0.383, cos=0.098), tot_loss_proj:3.507 [t=0.22s]
prediction: ['[CLS] falling settle easily [SEP]']
[ 100/2000] tot_loss=2.100 (perp=9.484, rec=0.182, cos=0.021), tot_loss_proj:3.806 [t=0.22s]
prediction: ['[CLS] easily settles easily [SEP]']
[ 150/2000] tot_loss=2.006 (perp=9.583, rec=0.087, cos=0.003), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] too settles easily [SEP]']
[ 200/2000] tot_loss=1.984 (perp=9.583, rec=0.065, cos=0.002), tot_loss_proj:2.322 [t=0.22s]
prediction: ['[CLS] too settles easily [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.807 (perp=8.670, rec=0.069, cos=0.004), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=1.790 (perp=8.670, rec=0.055, cos=0.002), tot_loss_proj:1.795 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.788 (perp=8.670, rec=0.052, cos=0.002), tot_loss_proj:1.797 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.802 (perp=8.670, rec=0.066, cos=0.002), tot_loss_proj:1.805 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.792 (perp=8.670, rec=0.056, cos=0.002), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.799 (perp=8.670, rec=0.063, cos=0.002), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.794 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.789 (perp=8.670, rec=0.053, cos=0.002), tot_loss_proj:1.811 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.801 (perp=8.670, rec=0.065, cos=0.002), tot_loss_proj:1.800 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.794 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.796 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.786 (perp=8.670, rec=0.050, cos=0.002), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.799 (perp=8.670, rec=0.063, cos=0.002), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.787 (perp=8.670, rec=0.052, cos=0.002), tot_loss_proj:1.799 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.798 (perp=8.670, rec=0.062, cos=0.002), tot_loss_proj:1.803 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.799 (perp=8.670, rec=0.063, cos=0.002), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.786 (perp=8.670, rec=0.050, cos=0.002), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.795 (perp=8.670, rec=0.059, cos=0.002), tot_loss_proj:1.803 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.805 (perp=8.670, rec=0.069, cos=0.002), tot_loss_proj:1.811 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.809 (perp=8.670, rec=0.074, cos=0.002), tot_loss_proj:1.789 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.794 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.791 (perp=8.670, rec=0.055, cos=0.002), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.787 (perp=8.670, rec=0.052, cos=0.002), tot_loss_proj:1.798 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.788 (perp=8.670, rec=0.053, cos=0.002), tot_loss_proj:1.807 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.802 (perp=8.670, rec=0.067, cos=0.002), tot_loss_proj:1.811 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.795 (perp=8.670, rec=0.059, cos=0.002), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.798 (perp=8.670, rec=0.062, cos=0.002), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.794 (perp=8.670, rec=0.058, cos=0.002), tot_loss_proj:1.809 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.797 (perp=8.670, rec=0.061, cos=0.002), tot_loss_proj:1.810 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.789 (perp=8.670, rec=0.054, cos=0.002), tot_loss_proj:1.794 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.795 (perp=8.670, rec=0.059, cos=0.002), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.797 (perp=8.670, rec=0.061, cos=0.002), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.795 (perp=8.670, rec=0.059, cos=0.002), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.797 (perp=8.670, rec=0.061, cos=0.002), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.798 (perp=8.670, rec=0.062, cos=0.002), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.803 (perp=8.670, rec=0.067, cos=0.002), tot_loss_proj:1.807 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.791 (perp=8.670, rec=0.055, cos=0.002), tot_loss_proj:1.795 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.525 | p: 93.089 | r: 94.005
rouge2     | fm: 60.124 | p: 59.962 | r: 60.408
rougeL     | fm: 81.320 | p: 80.926 | r: 81.776
rougeLsum  | fm: 81.137 | p: 80.758 | r: 81.557
r1fm+r2fm = 153.649

input #55 time: 0:08:58 | total time: 8:40:09


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.999275319141455
highest_index [0]
highest [0.999275319141455]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.930572509765625 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.9180293679237366 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.9034432768821716 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 0.8964918255805969 for ['[CLS] sergeant atlanticrted further enough face za sincedah had bringing experience claus stereo tour novelmler trails worn korean armed [SEP]']
[Init] best rec loss: 0.891231894493103 for ['[CLS] direction casual pl constitution orange storm beardction norris polo reaches accmity bladetlingus mayer hatch novels chinese ore [SEP]']
[Init] best rec loss: 0.8843615055084229 for ['[CLS] handed almost with leadership emotional obsidian wall households consolation potential spectroscopy defeated been existing organization variables up acquainted cas dive realm [SEP]']
[Init] best perm rec loss: 0.8818796873092651 for ['[CLS] leadership spectroscopy organization with potential acquainted almost households variables been defeated up wall cas consolation existing dive emotional obsidian handed realm [SEP]']
[Init] best perm rec loss: 0.8813957571983337 for ['[CLS] with handed defeated acquainted up existing cas organization leadership dive variables emotional households realm almost potential consolation wall spectroscopy been obsidian [SEP]']
[Init] best perm rec loss: 0.8785008788108826 for ['[CLS] potential with consolation up spectroscopy emotional almost been obsidian variables leadership organization existing wall handed defeated households cas dive acquainted realm [SEP]']
[Init] best perm rec loss: 0.8777846097946167 for ['[CLS] organization been almost defeated up handed dive households wall with cas spectroscopy existing emotional potential leadership variables consolation obsidian acquainted realm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.392 (perp=10.534, rec=0.276, cos=0.009), tot_loss_proj:3.008 [t=0.24s]
prediction: ['[CLS] films which after cause loads mass damage could ; much damage damage liner costly analysis film impairment explaining pre damage damage [SEP]']
[ 100/2000] tot_loss=2.287 (perp=10.525, rec=0.177, cos=0.005), tot_loss_proj:2.920 [t=0.24s]
prediction: ['[CLS] films which which cause loads that years wouldparable damage costly years costly analysis films fix fix post fix damage [SEP]']
[ 150/2000] tot_loss=2.437 (perp=11.493, rec=0.135, cos=0.003), tot_loss_proj:3.097 [t=0.24s]
prediction: ['[CLS] films which which cause loads that years couldparable damage costly years costly analysis films fix fix never fixpara [SEP]']
[ 200/2000] tot_loss=2.353 (perp=11.233, rec=0.105, cos=0.002), tot_loss_proj:2.986 [t=0.24s]
prediction: ['[CLS] films which will cause loads that years couldparable damage costly years costly analysis films fix fix never fixpara [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.184 (perp=10.452, rec=0.091, cos=0.002), tot_loss_proj:2.870 [t=0.24s]
prediction: ['[CLS] films which will cause loads that years couldparable damage costly years costly analysis fix films could never fixpara [SEP]']
[ 300/2000] tot_loss=2.174 (perp=10.452, rec=0.082, cos=0.001), tot_loss_proj:2.857 [t=0.24s]
prediction: ['[CLS] films which will cause loads that years couldparable damage costly years costly analysis fix films could never fixpara [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.224 (perp=10.651, rec=0.092, cos=0.001), tot_loss_proj:2.870 [t=0.24s]
prediction: ['[CLS] films which will cause loads that years couldparable damage costly yearspara costly analysis weeks films of never fix [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.096 (perp=10.030, rec=0.088, cos=0.002), tot_loss_proj:2.835 [t=0.24s]
prediction: ['[CLS] films which will cause loads that yearsparable damage could costly yearspara costly analysis weeks films of never fix [SEP]']
[ 450/2000] tot_loss=2.078 (perp=10.030, rec=0.071, cos=0.001), tot_loss_proj:2.834 [t=0.24s]
prediction: ['[CLS] films which will cause loads that yearsparable damage could costly yearspara costly analysis weeks films of never fix [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.011 (perp=9.627, rec=0.084, cos=0.001), tot_loss_proj:2.462 [t=0.24s]
prediction: ['[CLS] films which will cause loads that yearsparable damage of costly yearspara costly analysis₀ films could never fix [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.977 (perp=9.486, rec=0.078, cos=0.001), tot_loss_proj:2.419 [t=0.24s]
prediction: ['[CLS] films which will cause loads that yearsparable damage of costly yearspara costly analysis氵 films could never fix [SEP]']
[ 600/2000] tot_loss=2.048 (perp=9.831, rec=0.080, cos=0.002), tot_loss_proj:2.446 [t=0.24s]
prediction: ['[CLS] films which will cause loads that yearsparable damage of costly yearspara costly analysis ir of could never fix [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.913 (perp=9.132, rec=0.086, cos=0.001), tot_loss_proj:2.255 [t=0.24s]
prediction: ['[CLS] films which will cause loads that yearsparable damage of costly years of costly analysis irpara could never fix [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.817 (perp=8.734, rec=0.068, cos=0.001), tot_loss_proj:2.151 [t=0.24s]
prediction: ['[CLS] films which will cause loads that ofparable damage years and years of costly analysis irpara could never fix [SEP]']
[ 750/2000] tot_loss=1.825 (perp=8.734, rec=0.076, cos=0.001), tot_loss_proj:2.150 [t=0.24s]
prediction: ['[CLS] films which will cause loads that ofparable damage years and years of costly analysis irpara could never fix [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.820 (perp=8.734, rec=0.072, cos=0.001), tot_loss_proj:2.144 [t=0.24s]
prediction: ['[CLS] films which will cause loads that ofparable damage years and years of costly analysis irpara could never fix [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.704 (perp=8.157, rec=0.071, cos=0.002), tot_loss_proj:1.861 [t=0.24s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irpara could never fix [SEP]']
[ 900/2000] tot_loss=1.564 (perp=7.426, rec=0.078, cos=0.001), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.559 (perp=7.426, rec=0.072, cos=0.001), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]']
Attempt swap
[1000/2000] tot_loss=1.556 (perp=7.426, rec=0.069, cos=0.001), tot_loss_proj:1.673 [t=0.24s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]']
[1050/2000] tot_loss=1.562 (perp=7.426, rec=0.075, cos=0.001), tot_loss_proj:1.671 [t=0.24s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]']
Attempt swap
[1100/2000] tot_loss=1.556 (perp=7.426, rec=0.070, cos=0.001), tot_loss_proj:1.673 [t=0.24s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]']
Attempt swap
[1150/2000] tot_loss=1.559 (perp=7.426, rec=0.072, cos=0.001), tot_loss_proj:1.667 [t=0.22s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]']
[1200/2000] tot_loss=1.542 (perp=7.426, rec=0.055, cos=0.001), tot_loss_proj:1.676 [t=0.23s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]']
Attempt swap
[1250/2000] tot_loss=1.558 (perp=7.426, rec=0.071, cos=0.001), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]']
Attempt swap
[1300/2000] tot_loss=1.559 (perp=7.426, rec=0.072, cos=0.001), tot_loss_proj:1.674 [t=0.22s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]']
[1350/2000] tot_loss=1.559 (perp=7.426, rec=0.072, cos=0.001), tot_loss_proj:1.667 [t=0.23s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.535 (perp=7.317, rec=0.070, cos=0.001), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis could irre never fix [SEP]']
Attempt swap
[1450/2000] tot_loss=1.536 (perp=7.317, rec=0.072, cos=0.001), tot_loss_proj:1.630 [t=0.22s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis could irre never fix [SEP]']
[1500/2000] tot_loss=1.527 (perp=7.317, rec=0.062, cos=0.001), tot_loss_proj:1.636 [t=0.23s]
prediction: ['[CLS] films which will cause loads ofparable damage that years and years of costly analysis could irre never fix [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.340 (perp=6.321, rec=0.075, cos=0.002), tot_loss_proj:1.492 [t=0.22s]
prediction: ['[CLS] films which will cause loads of could irreparable damage that years and years of costly analysis never fix [SEP]']
Attempt swap
[1600/2000] tot_loss=1.338 (perp=6.321, rec=0.073, cos=0.001), tot_loss_proj:1.505 [t=0.22s]
prediction: ['[CLS] films which will cause loads of could irreparable damage that years and years of costly analysis never fix [SEP]']
[1650/2000] tot_loss=1.339 (perp=6.321, rec=0.073, cos=0.001), tot_loss_proj:1.497 [t=0.23s]
prediction: ['[CLS] films which will cause loads of could irreparable damage that years and years of costly analysis never fix [SEP]']
Attempt swap
[1700/2000] tot_loss=1.335 (perp=6.321, rec=0.069, cos=0.001), tot_loss_proj:1.496 [t=0.23s]
prediction: ['[CLS] films which will cause loads of could irreparable damage that years and years of costly analysis never fix [SEP]']
Attempt swap
[1750/2000] tot_loss=1.330 (perp=6.321, rec=0.064, cos=0.001), tot_loss_proj:1.500 [t=0.23s]
prediction: ['[CLS] films which will cause loads of could irreparable damage that years and years of costly analysis never fix [SEP]']
[1800/2000] tot_loss=1.324 (perp=6.321, rec=0.059, cos=0.001), tot_loss_proj:1.491 [t=0.23s]
prediction: ['[CLS] films which will cause loads of could irreparable damage that years and years of costly analysis never fix [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.227 (perp=5.755, rec=0.074, cos=0.001), tot_loss_proj:1.268 [t=0.23s]
prediction: ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
Attempt swap
[1900/2000] tot_loss=1.216 (perp=5.755, rec=0.064, cos=0.001), tot_loss_proj:1.276 [t=0.23s]
prediction: ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[1950/2000] tot_loss=1.222 (perp=5.755, rec=0.069, cos=0.001), tot_loss_proj:1.269 [t=0.23s]
prediction: ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
Attempt swap
[2000/2000] tot_loss=1.216 (perp=5.755, rec=0.064, cos=0.001), tot_loss_proj:1.276 [t=0.22s]
prediction: ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] films which will cause loads ofparable damage that years and years of costly analysis irre could never fix [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 78.947 | p: 78.947 | r: 78.947
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 168.947

[Aggregate metrics]:
rouge1     | fm: 93.476 | p: 93.093 | r: 93.941
rouge2     | fm: 60.369 | p: 60.140 | r: 60.665
rougeL     | fm: 81.535 | p: 81.123 | r: 81.982
rougeLsum  | fm: 81.191 | p: 80.825 | r: 81.652
r1fm+r2fm = 153.845

input #56 time: 0:09:20 | total time: 8:49:30


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9993819320090143
highest_index [0]
highest [0.9993819320090143]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8591682314872742 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.805242121219635 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.7094612717628479 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6545407772064209 for ['[CLS] expressed [SEP]']
[Init] best rec loss: 0.6484116911888123 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.616 (perp=12.283, rec=0.138, cos=0.021), tot_loss_proj:2.524 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.528 (perp=12.283, rec=0.069, cos=0.002), tot_loss_proj:2.505 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.509 (perp=12.283, rec=0.051, cos=0.001), tot_loss_proj:2.516 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.509 (perp=12.283, rec=0.048, cos=0.005), tot_loss_proj:2.510 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.509 (perp=12.283, rec=0.051, cos=0.002), tot_loss_proj:2.515 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.504 (perp=12.283, rec=0.046, cos=0.002), tot_loss_proj:2.510 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.523 (perp=12.283, rec=0.064, cos=0.002), tot_loss_proj:2.513 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.510 (perp=12.283, rec=0.052, cos=0.001), tot_loss_proj:2.501 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.529 (perp=12.283, rec=0.071, cos=0.001), tot_loss_proj:2.505 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.507 (perp=12.283, rec=0.049, cos=0.001), tot_loss_proj:2.510 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.520 (perp=12.283, rec=0.062, cos=0.001), tot_loss_proj:2.517 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.523 (perp=12.283, rec=0.066, cos=0.001), tot_loss_proj:2.527 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.510 (perp=12.283, rec=0.052, cos=0.001), tot_loss_proj:2.509 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.521 (perp=12.283, rec=0.064, cos=0.001), tot_loss_proj:2.524 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.523 (perp=12.283, rec=0.065, cos=0.001), tot_loss_proj:2.519 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.511 (perp=12.283, rec=0.053, cos=0.001), tot_loss_proj:2.526 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.521 (perp=12.283, rec=0.064, cos=0.001), tot_loss_proj:2.535 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.507 (perp=12.283, rec=0.049, cos=0.001), tot_loss_proj:2.505 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.532 (perp=12.283, rec=0.074, cos=0.001), tot_loss_proj:2.512 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.516 (perp=12.283, rec=0.058, cos=0.001), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.520 (perp=12.283, rec=0.063, cos=0.001), tot_loss_proj:2.509 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.501 (perp=12.283, rec=0.043, cos=0.001), tot_loss_proj:2.521 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.527 (perp=12.283, rec=0.070, cos=0.001), tot_loss_proj:2.515 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.534 (perp=12.283, rec=0.077, cos=0.001), tot_loss_proj:2.513 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.521 (perp=12.283, rec=0.063, cos=0.001), tot_loss_proj:2.519 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.514 (perp=12.283, rec=0.056, cos=0.001), tot_loss_proj:2.514 [t=0.29s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.524 (perp=12.283, rec=0.066, cos=0.001), tot_loss_proj:2.521 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.524 (perp=12.283, rec=0.067, cos=0.001), tot_loss_proj:2.527 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.515 (perp=12.283, rec=0.057, cos=0.001), tot_loss_proj:2.517 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.514 (perp=12.283, rec=0.056, cos=0.001), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.501 (perp=12.283, rec=0.044, cos=0.001), tot_loss_proj:2.516 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.512 (perp=12.283, rec=0.055, cos=0.001), tot_loss_proj:2.509 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.530 (perp=12.283, rec=0.072, cos=0.001), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.514 (perp=12.283, rec=0.057, cos=0.001), tot_loss_proj:2.541 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.510 (perp=12.283, rec=0.052, cos=0.001), tot_loss_proj:2.528 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.515 (perp=12.283, rec=0.057, cos=0.001), tot_loss_proj:2.515 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.502 (perp=12.283, rec=0.044, cos=0.001), tot_loss_proj:2.509 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.525 (perp=12.283, rec=0.067, cos=0.001), tot_loss_proj:2.512 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.518 (perp=12.283, rec=0.060, cos=0.001), tot_loss_proj:2.522 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.520 (perp=12.283, rec=0.063, cos=0.001), tot_loss_proj:2.515 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.582 | p: 93.180 | r: 94.061
rouge2     | fm: 61.052 | p: 60.803 | r: 61.307
rougeL     | fm: 81.975 | p: 81.583 | r: 82.408
rougeLsum  | fm: 81.516 | p: 81.148 | r: 82.009
r1fm+r2fm = 154.635

input #57 time: 0:09:16 | total time: 8:58:47


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9992687667984019
highest_index [0]
highest [0.9992687667984019]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.962661862373352 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9546318054199219 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9182192087173462 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9155486226081848 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army £100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.8889455795288086 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.875677764415741 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.8751990795135498 for ['[CLS] virtual marian go dreams seed company seat treaty beyond reigning hilt pile stay 2006 austin whereabouts [SEP]']
[Init] best rec loss: 0.8696123361587524 for ['[CLS] down trade zack serious verde thighsager finishedtyle chiefuration apart beautyitical est essay [SEP]']
[Init] best perm rec loss: 0.869049072265625 for ['[CLS]ager serious zack trade beauty finished thighs est essay chieftyleiticaluration apart verde down [SEP]']
[Init] best perm rec loss: 0.8682684898376465 for ['[CLS] finished chief beautyuration trade zack thighs aparttyle verdeitical essay downager serious est [SEP]']
[Init] best perm rec loss: 0.8666278719902039 for ['[CLS]uration finished serious beautytyle zack apart down thighsitical verde essay chief trade estager [SEP]']
[Init] best perm rec loss: 0.8663685321807861 for ['[CLS] beauty finished chief zack serious essay downtyle thighs verde esturation apartiticalager trade [SEP]']
[Init] best perm rec loss: 0.8658364415168762 for ['[CLS] esturationager thighs chief trade zacktyle apart verde down serious essay finished beautyitical [SEP]']
[Init] best perm rec loss: 0.8648908734321594 for ['[CLS] serious chiefager thighs finished est apart tradeitical zack downurationtyle beauty verde essay [SEP]']
[Init] best perm rec loss: 0.8633812665939331 for ['[CLS]uration zack chiefitical est thighs trade downager finished verde aparttyle essay beauty serious [SEP]']
[Init] best perm rec loss: 0.8627644777297974 for ['[CLS]ager down chiefitical finished thighs zacktyle serious beauty tradeuration est essay apart verde [SEP]']
[Init] best perm rec loss: 0.8620972037315369 for ['[CLS] finished verdeitical zackager aparttyleuration trade thighs down est chief serious beauty essay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.566 (perp=11.834, rec=0.196, cos=0.004), tot_loss_proj:3.048 [t=0.24s]
prediction: ['[CLS] is inspirational moment directly seeing ideali love story jess mexican love inspirational inspired educational personality [SEP]']
[ 100/2000] tot_loss=2.257 (perp=10.568, rec=0.141, cos=0.003), tot_loss_proj:2.555 [t=0.24s]
prediction: ['[CLS] is inspirational story capturing seeing, encounter love story jess mexican the inspirational encounter inspirational innocence [SEP]']
[ 150/2000] tot_loss=2.164 (perp=10.271, rec=0.108, cos=0.002), tot_loss_proj:2.569 [t=0.24s]
prediction: ['[CLS] is inspirational story capturing seeing innocence encounter love story john barrel that inspirational encounter capturing innocence [SEP]']
[ 200/2000] tot_loss=2.129 (perp=10.108, rec=0.105, cos=0.002), tot_loss_proj:2.443 [t=0.24s]
prediction: ['[CLS] is inspirational, capturing seeing innocence encounter love story john barrel that inspirational encounter capturing innocence [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.817 (perp=8.577, rec=0.100, cos=0.002), tot_loss_proj:2.280 [t=0.24s]
prediction: ['[CLS] is inspirational story, seeing innocence encounter love, a barrel that inspirational encounter capturing innocence [SEP]']
[ 300/2000] tot_loss=1.743 (perp=8.309, rec=0.080, cos=0.001), tot_loss_proj:2.569 [t=0.24s]
prediction: ['[CLS] is an story, seeing the first love, a barrel that inspirational encounter capturing innocence [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.869 (perp=8.958, rec=0.076, cos=0.001), tot_loss_proj:2.324 [t=0.24s]
prediction: ['[CLS] is an story, ideal the first love, and baron capturing inspirational encounter that innocence [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.716 (perp=8.182, rec=0.078, cos=0.001), tot_loss_proj:2.167 [t=0.24s]
prediction: ['[CLS] is an story, the ideal first love, and baron capturing inspirational encounter that innocence [SEP]']
[ 450/2000] tot_loss=1.650 (perp=7.857, rec=0.078, cos=0.001), tot_loss_proj:1.991 [t=0.24s]
prediction: ['[CLS] is an story, the ideal first love, andism capturing inspirational encounter that innocence [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.506 (perp=7.148, rec=0.075, cos=0.001), tot_loss_proj:1.866 [t=0.24s]
prediction: ['[CLS] is an story capturing the ideal first love, and angeles, inspirational encounter that innocence [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=1.434 (perp=6.694, rec=0.094, cos=0.002), tot_loss_proj:1.758 [t=0.24s]
prediction: ['[CLS] innocence is an story capturing the ideal first love, andism, inspirational encounter that [SEP]']
[ 600/2000] tot_loss=1.484 (perp=7.070, rec=0.068, cos=0.001), tot_loss_proj:1.876 [t=0.24s]
prediction: ['[CLS] innocence is an story capturing the ideal first love of andism, inspirational encounter that [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.398 (perp=6.601, rec=0.076, cos=0.001), tot_loss_proj:1.697 [t=0.24s]
prediction: ['[CLS] innocence is an inspirational story capturing the ideal first love of andism, encounter that [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.303 (perp=6.164, rec=0.069, cos=0.002), tot_loss_proj:1.613 [t=0.24s]
prediction: ['[CLS] innocence is an inspirational story capturing the ideal first love of encounterism, and that [SEP]']
[ 750/2000] tot_loss=1.304 (perp=6.164, rec=0.069, cos=0.001), tot_loss_proj:1.618 [t=0.24s]
prediction: ['[CLS] innocence is an inspirational story capturing the ideal first love of encounterism, and that [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.269 (perp=6.001, rec=0.067, cos=0.001), tot_loss_proj:1.572 [t=0.24s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism love of encounter first, and that [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.173 (perp=5.526, rec=0.066, cos=0.001), tot_loss_proj:1.424 [t=0.24s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism love of first encounter, and that [SEP]']
[ 900/2000] tot_loss=1.175 (perp=5.526, rec=0.068, cos=0.001), tot_loss_proj:1.428 [t=0.24s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism love of first encounter, and that [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.130 (perp=5.320, rec=0.065, cos=0.001), tot_loss_proj:1.361 [t=0.24s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]']
Attempt swap
[1000/2000] tot_loss=1.139 (perp=5.320, rec=0.074, cos=0.001), tot_loss_proj:1.366 [t=0.24s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]']
[1050/2000] tot_loss=1.138 (perp=5.320, rec=0.072, cos=0.001), tot_loss_proj:1.375 [t=0.24s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]']
Attempt swap
[1100/2000] tot_loss=1.133 (perp=5.320, rec=0.068, cos=0.001), tot_loss_proj:1.362 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]']
Attempt swap
[1150/2000] tot_loss=1.134 (perp=5.320, rec=0.068, cos=0.001), tot_loss_proj:1.358 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]']
[1200/2000] tot_loss=1.131 (perp=5.320, rec=0.066, cos=0.001), tot_loss_proj:1.368 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]']
Attempt swap
[1250/2000] tot_loss=1.132 (perp=5.320, rec=0.066, cos=0.001), tot_loss_proj:1.364 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]']
Attempt swap
[1300/2000] tot_loss=1.136 (perp=5.320, rec=0.070, cos=0.001), tot_loss_proj:1.367 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]']
[1350/2000] tot_loss=1.128 (perp=5.320, rec=0.063, cos=0.001), tot_loss_proj:1.374 [t=0.23s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]']
Attempt swap
[1400/2000] tot_loss=1.134 (perp=5.320, rec=0.069, cos=0.001), tot_loss_proj:1.365 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.111 (perp=5.190, rec=0.072, cos=0.001), tot_loss_proj:1.341 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story capturing the idealism of first encounter, and that [SEP]']
[1500/2000] tot_loss=1.098 (perp=5.190, rec=0.058, cos=0.001), tot_loss_proj:1.342 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story capturing the idealism of first encounter, and that [SEP]']
Attempt swap
[1550/2000] tot_loss=1.102 (perp=5.190, rec=0.063, cos=0.001), tot_loss_proj:1.336 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story capturing the idealism of first encounter, and that [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.050 (perp=4.973, rec=0.053, cos=0.001), tot_loss_proj:1.249 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story capturing the idealism of that first encounter, and [SEP]']
[1650/2000] tot_loss=1.064 (perp=4.973, rec=0.068, cos=0.001), tot_loss_proj:1.246 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story capturing the idealism of that first encounter, and [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.030 (perp=4.833, rec=0.062, cos=0.001), tot_loss_proj:1.188 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story, capturing the idealism of that first encounter and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.032 (perp=4.833, rec=0.064, cos=0.001), tot_loss_proj:1.189 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story, capturing the idealism of that first encounter and [SEP]']
[1800/2000] tot_loss=1.044 (perp=4.833, rec=0.076, cos=0.001), tot_loss_proj:1.195 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story, capturing the idealism of that first encounter and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.042 (perp=4.833, rec=0.074, cos=0.001), tot_loss_proj:1.191 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story, capturing the idealism of that first encounter and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.036 (perp=4.833, rec=0.068, cos=0.001), tot_loss_proj:1.190 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story, capturing the idealism of that first encounter and [SEP]']
[1950/2000] tot_loss=1.041 (perp=4.833, rec=0.073, cos=0.001), tot_loss_proj:1.187 [t=0.22s]
prediction: ['[CLS] innocence is an inspirational love story, capturing the idealism of that first encounter and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.029 (perp=4.833, rec=0.061, cos=0.001), tot_loss_proj:1.190 [t=0.24s]
prediction: ['[CLS] innocence is an inspirational love story, capturing the idealism of that first encounter and [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] innocence is an inspirational story capturing the idealism of first encounter, and love that [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 93.696 | p: 93.312 | r: 94.163
rouge2     | fm: 60.616 | p: 60.419 | r: 60.877
rougeL     | fm: 81.824 | p: 81.463 | r: 82.279
rougeLsum  | fm: 81.454 | p: 81.089 | r: 81.841
r1fm+r2fm = 154.311

input #58 time: 0:09:15 | total time: 9:08:03


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9992224840541208
highest_index [0]
highest [0.9992224840541208]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.9158618450164795 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.899953305721283 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 0.89546138048172 for ['[CLS] clutch sports meridian placed weekly dixonwords up⁄ faerie rugby been towards resist programming infantry [SEP]']
[Init] best rec loss: 0.8692657351493835 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.86898273229599 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best rec loss: 0.8669886589050293 for ['[CLS] het hill income rule helping icon minh were way lisa ufc these vampire skins notch good [SEP]']
[Init] best rec loss: 0.8595459461212158 for ['[CLS]ition wandering wearing right wore kent hemisphere purple strict we gas dark deserve tonnes did letterman [SEP]']
[Init] best rec loss: 0.8334484100341797 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best perm rec loss: 0.8307017087936401 for ['[CLS] fleetby tunnel information thus awhile noah wasak races temperament bologna stuff bobo pump 1993 [SEP]']
[Init] best perm rec loss: 0.8305091857910156 for ['[CLS] pumpak temperament thus tunnel noah was awhile bologna fleet information boboby 1993 races stuff [SEP]']
[Init] best perm rec loss: 0.8296042680740356 for ['[CLS] information fleetak 1993 awhile pump stuff noah thus boboby bologna temperament was races tunnel [SEP]']
[Init] best perm rec loss: 0.8292043805122375 for ['[CLS] bologna races stuff pump fleet tunnelakby 1993 noah awhile thus temperament bobo information was [SEP]']
[Init] best perm rec loss: 0.8289357423782349 for ['[CLS] stuff temperament awhile was 1993 races thus pump noah tunnel fleet bobo information bolognaakby [SEP]']
[Init] best perm rec loss: 0.8288805484771729 for ['[CLS] temperament racesby bologna thus awhile information bobo noah stuff pump 1993ak fleet was tunnel [SEP]']
[Init] best perm rec loss: 0.828627347946167 for ['[CLS] thus fleet stuff tunnelak was awhile races bobo 1993 informationby noah temperament pump bologna [SEP]']
[Init] best perm rec loss: 0.8283922672271729 for ['[CLS] bobo races stuff fleet tunnel temperament noah information awhileby thus was 1993ak bologna pump [SEP]']
[Init] best perm rec loss: 0.8274857401847839 for ['[CLS] fleet 1993by temperament bobo stuff thusak awhile noah tunnel information races bologna pump was [SEP]']
[Init] best perm rec loss: 0.8274096250534058 for ['[CLS] 1993 noah bologna tunnel fleet thus awhile stuff temperament pump was boboby informationak races [SEP]']
[Init] best perm rec loss: 0.8264302015304565 for ['[CLS] stuff noahak was awhile fleet races information temperamentby thus 1993 tunnel bobo bologna pump [SEP]']
[Init] best perm rec loss: 0.8250256180763245 for ['[CLS] thus tunnel was informationbyak stuff races 1993 pump temperament awhile bobo fleet bologna noah [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.769 (perp=12.174, rec=0.323, cos=0.011), tot_loss_proj:3.951 [t=0.24s]
prediction: ['[CLS] has of lily storyline stories an let award capable and streak including court theater presentation adult [SEP]']
[ 100/2000] tot_loss=2.300 (perp=10.396, rec=0.217, cos=0.004), tot_loss_proj:3.584 [t=0.24s]
prediction: ['[CLS] has of woman of the of woman young how andism contains char screen screen woman [SEP]']
[ 150/2000] tot_loss=2.467 (perp=11.474, rec=0.169, cos=0.002), tot_loss_proj:3.845 [t=0.24s]
prediction: ['[CLS] has of char of the of woman young knows whoism hold char screen screen adult [SEP]']
[ 200/2000] tot_loss=2.405 (perp=11.289, rec=0.145, cos=0.002), tot_loss_proj:3.724 [t=0.24s]
prediction: ['[CLS] has of the the the of woman young knows whoism hold char screen screen adult [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.042 (perp=9.605, rec=0.120, cos=0.002), tot_loss_proj:3.373 [t=0.24s]
prediction: ['[CLS] has of the theism of woman young knows who a hold char screen screen char [SEP]']
[ 300/2000] tot_loss=2.208 (perp=10.464, rec=0.113, cos=0.002), tot_loss_proj:3.273 [t=0.24s]
prediction: ['[CLS] has char the theism of woman young knows who a hold char screen screen char [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.014 (perp=9.500, rec=0.111, cos=0.002), tot_loss_proj:3.327 [t=0.24s]
prediction: ['[CLS] has char screen theism of woman young knows who a hold char screen the char [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.135 (perp=10.011, rec=0.130, cos=0.002), tot_loss_proj:3.156 [t=0.24s]
prediction: ['[CLS] has woman screen theism of char young knows who a holdism screen the how [SEP]']
[ 450/2000] tot_loss=2.114 (perp=10.011, rec=0.110, cos=0.002), tot_loss_proj:3.181 [t=0.24s]
prediction: ['[CLS] has woman screen theism of char young knows who a holdism screen the how [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.962 (perp=9.234, rec=0.114, cos=0.002), tot_loss_proj:3.378 [t=0.24s]
prediction: ['[CLS] has woman screen theism of char young knows who of hold how screen theism [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.880 (perp=8.929, rec=0.092, cos=0.002), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] has woman screen theism of char young of who knows hold how screen theism [SEP]']
[ 600/2000] tot_loss=1.886 (perp=8.929, rec=0.098, cos=0.002), tot_loss_proj:3.359 [t=0.24s]
prediction: ['[CLS] has woman screen theism of char young of who knows hold how screen theism [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.815 (perp=8.586, rec=0.096, cos=0.002), tot_loss_proj:3.195 [t=0.24s]
prediction: ['[CLS] has woman screen theism of char young how who knows hold of screen theism [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.760 (perp=8.318, rec=0.095, cos=0.002), tot_loss_proj:3.098 [t=0.24s]
prediction: ['[CLS] has woman screen theism of char young who knows how hold of screen theism [SEP]']
[ 750/2000] tot_loss=1.762 (perp=8.318, rec=0.097, cos=0.002), tot_loss_proj:3.098 [t=0.24s]
prediction: ['[CLS] has woman screen theism of char young who knows how hold of screen theism [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.741 (perp=8.318, rec=0.076, cos=0.002), tot_loss_proj:3.103 [t=0.24s]
prediction: ['[CLS] has woman screen theism of char young who knows how hold of screen theism [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.693 (perp=8.008, rec=0.090, cos=0.002), tot_loss_proj:2.832 [t=0.24s]
prediction: ['[CLS] has the screen theism of char young who knows how hold of screen womanism [SEP]']
[ 900/2000] tot_loss=1.692 (perp=8.008, rec=0.089, cos=0.002), tot_loss_proj:2.843 [t=0.24s]
prediction: ['[CLS] has the screen theism of char young who knows how hold of screen womanism [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.699 (perp=8.008, rec=0.096, cos=0.002), tot_loss_proj:2.845 [t=0.24s]
prediction: ['[CLS] has the screen theism of char young who knows how hold of screen womanism [SEP]']
Attempt swap
[1000/2000] tot_loss=1.701 (perp=8.008, rec=0.097, cos=0.002), tot_loss_proj:2.851 [t=0.24s]
prediction: ['[CLS] has the screen theism of char young who knows how hold of screen womanism [SEP]']
[1050/2000] tot_loss=1.695 (perp=8.039, rec=0.085, cos=0.002), tot_loss_proj:2.727 [t=0.24s]
prediction: ['[CLS] has the the theism of char young who knows how hold of screen womanism [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.702 (perp=8.039, rec=0.093, cos=0.002), tot_loss_proj:2.733 [t=0.24s]
prediction: ['[CLS] has the the theism of char young who knows how hold of screen womanism [SEP]']
Attempt swap
[1150/2000] tot_loss=1.702 (perp=8.039, rec=0.093, cos=0.002), tot_loss_proj:2.728 [t=0.24s]
prediction: ['[CLS] has the the theism of char young who knows how hold of screen womanism [SEP]']
[1200/2000] tot_loss=1.698 (perp=8.039, rec=0.089, cos=0.002), tot_loss_proj:2.733 [t=0.24s]
prediction: ['[CLS] has the the theism of char young who knows how hold of screen womanism [SEP]']
Attempt swap
[1250/2000] tot_loss=1.694 (perp=8.039, rec=0.084, cos=0.002), tot_loss_proj:2.727 [t=0.24s]
prediction: ['[CLS] has the the theism of char young who knows how hold of screen womanism [SEP]']
Attempt swap
[1300/2000] tot_loss=1.746 (perp=8.312, rec=0.082, cos=0.002), tot_loss_proj:2.929 [t=0.24s]
prediction: ['[CLS] has the the thea of char young who knows how hold of screen womanism [SEP]']
[1350/2000] tot_loss=1.750 (perp=8.312, rec=0.086, cos=0.002), tot_loss_proj:2.932 [t=0.24s]
prediction: ['[CLS] has the the thea of char young who knows how hold of screen womanism [SEP]']
Attempt swap
[1400/2000] tot_loss=1.735 (perp=8.312, rec=0.071, cos=0.002), tot_loss_proj:2.933 [t=0.24s]
prediction: ['[CLS] has the the thea of char young who knows how hold of screen womanism [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.675 (perp=7.921, rec=0.089, cos=0.002), tot_loss_proj:2.745 [t=0.24s]
prediction: ['[CLS] has the woman thea of char young who knows how hold of screen theism [SEP]']
[1500/2000] tot_loss=1.662 (perp=7.921, rec=0.077, cos=0.002), tot_loss_proj:2.746 [t=0.24s]
prediction: ['[CLS] has the woman thea of char young who knows how hold of screen theism [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.555 (perp=7.337, rec=0.086, cos=0.002), tot_loss_proj:2.538 [t=0.24s]
prediction: ['[CLS] has the woman the young of chara who knows how hold of screen theism [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.554 (perp=7.328, rec=0.087, cos=0.002), tot_loss_proj:2.468 [t=0.24s]
prediction: ['[CLS] has the woman the young of chara who knows how hold of the screenism [SEP]']
[1650/2000] tot_loss=1.556 (perp=7.328, rec=0.088, cos=0.002), tot_loss_proj:2.463 [t=0.24s]
prediction: ['[CLS] has the woman the young of chara who knows how hold of the screenism [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.403 (perp=6.642, rec=0.073, cos=0.002), tot_loss_proj:1.806 [t=0.24s]
prediction: ['[CLS] has the woman the young of charisma who knows how hold the the screen [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.379 (perp=6.444, rec=0.088, cos=0.002), tot_loss_proj:1.814 [t=0.24s]
prediction: ['[CLS] has the woman the young of charisma who knows how of hold the screen [SEP]']
[1800/2000] tot_loss=1.368 (perp=6.444, rec=0.078, cos=0.002), tot_loss_proj:1.811 [t=0.24s]
prediction: ['[CLS] has the woman the young of charisma who knows how of hold the screen [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.414 (perp=6.642, rec=0.084, cos=0.002), tot_loss_proj:1.798 [t=0.24s]
prediction: ['[CLS] has the woman the young of charisma who knows how hold the the screen [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.368 (perp=6.436, rec=0.079, cos=0.002), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] has the woman the young of charisma who knows how the hold the screen [SEP]']
[1950/2000] tot_loss=1.364 (perp=6.444, rec=0.074, cos=0.002), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] has the woman the young of charisma who knows how of hold the screen [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.417 (perp=6.642, rec=0.087, cos=0.002), tot_loss_proj:1.801 [t=0.24s]
prediction: ['[CLS] has the woman the young of charisma who knows how hold the the screen [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] has the the thea of char young who knows how hold of screen womanism [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 26.667 | p: 26.667 | r: 26.667
rougeL     | fm: 68.750 | p: 68.750 | r: 68.750
rougeLsum  | fm: 68.750 | p: 68.750 | r: 68.750
r1fm+r2fm = 101.667

[Aggregate metrics]:
rouge1     | fm: 93.361 | p: 93.002 | r: 93.833
rouge2     | fm: 60.132 | p: 59.878 | r: 60.425
rougeL     | fm: 81.567 | p: 81.226 | r: 81.979
rougeLsum  | fm: 81.295 | p: 80.943 | r: 81.686
r1fm+r2fm = 153.493

input #59 time: 0:09:30 | total time: 9:17:33


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.9993723007306495
highest_index [0]
highest [0.9993723007306495]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9240039587020874 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9135375618934631 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8766923546791077 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8674620389938354 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8555521368980408 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 0.8470483422279358 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 0.8440579771995544 for ['[CLS] coverouringlby through strung plenty constitutionshaw majority /itude upset [SEP]']
[Init] best perm rec loss: 0.8426222205162048 for ['[CLS] plenty /lbyshawouring strung constitutionitude majority through cover upset [SEP]']
[Init] best perm rec loss: 0.8374884724617004 for ['[CLS] majority / strunglbyitude throughshaw plentyouring constitution upset cover [SEP]']
[Init] best perm rec loss: 0.8369754552841187 for ['[CLS]itude majority strung throughshaw plenty constitution coverlby upsetouring / [SEP]']
[Init] best perm rec loss: 0.8367394208908081 for ['[CLS] plentyitudelbyshaw / constitution through strung upset coverouring majority [SEP]']
[Init] best perm rec loss: 0.8362407684326172 for ['[CLS] plentylby strung upsetshaw constitution majority through coveritude /ouring [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.729 (perp=12.201, rec=0.278, cos=0.011), tot_loss_proj:3.048 [t=0.23s]
prediction: ['[CLS] awkwardly ª police county awkwardly story. data pm awkwardly awkwardlyi [SEP]']
[ 100/2000] tot_loss=2.687 (perp=12.322, rec=0.214, cos=0.009), tot_loss_proj:3.056 [t=0.23s]
prediction: ['[CLS] awkwardly is paced paced awkwardly soap circuit soap is awkwardly awkwardly story [SEP]']
[ 150/2000] tot_loss=2.637 (perp=12.322, rec=0.168, cos=0.004), tot_loss_proj:3.048 [t=0.24s]
prediction: ['[CLS] awkwardly is paced paced awkwardly soap circuit soap is awkwardly awkwardly story [SEP]']
[ 200/2000] tot_loss=2.608 (perp=12.404, rec=0.124, cos=0.003), tot_loss_proj:3.043 [t=0.23s]
prediction: ['[CLS] awkwardly is paced paced awkwardly soap circuit soap the awkwardly awkwardly story [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.388 (perp=11.330, rec=0.120, cos=0.003), tot_loss_proj:2.861 [t=0.24s]
prediction: ['[CLS] awkwardly is paced awkwardly awkwardly soap circuit soap the awkwardly paced story [SEP]']
[ 300/2000] tot_loss=2.422 (perp=11.559, rec=0.108, cos=0.003), tot_loss_proj:2.845 [t=0.24s]
prediction: ['[CLS] awkwardly is paced - awkwardly soap circuit soap the awkwardly opera story [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.088 (perp=9.974, rec=0.091, cos=0.002), tot_loss_proj:2.560 [t=0.24s]
prediction: ['[CLS] awkwardly is paced - awkwardly soap circuit the awkwardly soap opera story [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.097 (perp=9.972, rec=0.100, cos=0.002), tot_loss_proj:2.551 [t=0.24s]
prediction: ['[CLS] is awkwardly pacedh awkwardly soap circuit the awkwardly soap opera story [SEP]']
[ 450/2000] tot_loss=2.198 (perp=10.578, rec=0.080, cos=0.002), tot_loss_proj:2.637 [t=0.24s]
prediction: ['[CLS] is awkwardly pacedhh soap circuit the awkwardly soap opera story [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.944 (perp=9.248, rec=0.092, cos=0.002), tot_loss_proj:2.326 [t=0.24s]
prediction: ['[CLS] circuit awkwardly pacedh awkwardly soap is the awkwardly soap opera story [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.004 (perp=9.484, rec=0.105, cos=0.003), tot_loss_proj:2.355 [t=0.24s]
prediction: ['[CLS] circuit awkwardly pacedh awkwardly awkwardly soap is the soap opera story [SEP]']
[ 600/2000] tot_loss=1.911 (perp=9.050, rec=0.099, cos=0.002), tot_loss_proj:2.275 [t=0.24s]
prediction: ['[CLS] circuit awkwardly pacedh awkwardlyh soap is the soap opera story [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.908 (perp=9.050, rec=0.096, cos=0.002), tot_loss_proj:2.279 [t=0.24s]
prediction: ['[CLS] circuit awkwardly pacedh awkwardlyh soap is the soap opera story [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.971 (perp=9.408, rec=0.087, cos=0.002), tot_loss_proj:2.313 [t=0.24s]
prediction: ['[CLS] circuit awkwardly pacedh awkwardlyh story is the soap opera story [SEP]']
[ 750/2000] tot_loss=1.968 (perp=9.408, rec=0.084, cos=0.002), tot_loss_proj:2.313 [t=0.24s]
prediction: ['[CLS] circuit awkwardly pacedh awkwardlyh story is the soap opera story [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.884 (perp=9.026, rec=0.077, cos=0.002), tot_loss_proj:2.284 [t=0.24s]
prediction: ['[CLS] circuit awkwardly pacedh awkwardly is story is the soap opera story [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.890 (perp=9.026, rec=0.083, cos=0.002), tot_loss_proj:2.283 [t=0.24s]
prediction: ['[CLS] circuit awkwardly pacedh awkwardly is story is the soap opera story [SEP]']
[ 900/2000] tot_loss=1.886 (perp=9.026, rec=0.079, cos=0.002), tot_loss_proj:2.285 [t=0.24s]
prediction: ['[CLS] circuit awkwardly pacedh awkwardly is story is the soap opera story [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.892 (perp=9.026, rec=0.085, cos=0.002), tot_loss_proj:2.280 [t=0.24s]
prediction: ['[CLS] circuit awkwardly pacedh awkwardly is story is the soap opera story [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.800 (perp=8.512, rec=0.096, cos=0.002), tot_loss_proj:2.190 [t=0.24s]
prediction: ['[CLS]h awkwardly paced circuit awkwardly is story is the soap opera story [SEP]']
[1050/2000] tot_loss=1.783 (perp=8.512, rec=0.079, cos=0.002), tot_loss_proj:2.175 [t=0.24s]
prediction: ['[CLS]h awkwardly paced circuit awkwardly is story is the soap opera story [SEP]']
Attempt swap
[1100/2000] tot_loss=1.851 (perp=8.816, rec=0.085, cos=0.002), tot_loss_proj:2.263 [t=0.23s]
prediction: ['[CLS]h - paced circuit awkwardly is story is the soap opera story [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.704 (perp=8.111, rec=0.080, cos=0.002), tot_loss_proj:2.060 [t=0.24s]
prediction: ['[CLS]h - circuit awkwardly paced is story is the soap opera story [SEP]']
[1200/2000] tot_loss=1.698 (perp=8.111, rec=0.073, cos=0.002), tot_loss_proj:2.058 [t=0.24s]
prediction: ['[CLS]h - circuit awkwardly paced is story is the soap opera story [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.695 (perp=8.062, rec=0.081, cos=0.002), tot_loss_proj:1.992 [t=0.24s]
prediction: ['[CLS]h - circuit awkwardly paced. is is the soap opera story [SEP]']
Attempt swap
[1300/2000] tot_loss=1.692 (perp=8.062, rec=0.078, cos=0.002), tot_loss_proj:1.995 [t=0.24s]
prediction: ['[CLS]h - circuit awkwardly paced. is is the soap opera story [SEP]']
[1350/2000] tot_loss=1.684 (perp=8.062, rec=0.070, cos=0.002), tot_loss_proj:1.988 [t=0.24s]
prediction: ['[CLS]h - circuit awkwardly paced. is is the soap opera story [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.652 (perp=7.853, rec=0.080, cos=0.002), tot_loss_proj:1.989 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced story circuit is the soap opera story [SEP]']
Attempt swap
[1450/2000] tot_loss=1.644 (perp=7.853, rec=0.072, cos=0.002), tot_loss_proj:1.999 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced story circuit is the soap opera story [SEP]']
[1500/2000] tot_loss=1.643 (perp=7.853, rec=0.071, cos=0.002), tot_loss_proj:1.994 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced story circuit is the soap opera story [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.614 (perp=7.727, rec=0.067, cos=0.002), tot_loss_proj:2.001 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]']
Attempt swap
[1600/2000] tot_loss=1.610 (perp=7.727, rec=0.063, cos=0.002), tot_loss_proj:1.990 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]']
[1650/2000] tot_loss=1.619 (perp=7.727, rec=0.072, cos=0.002), tot_loss_proj:1.994 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]']
Attempt swap
[1700/2000] tot_loss=1.613 (perp=7.727, rec=0.065, cos=0.002), tot_loss_proj:1.993 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]']
Attempt swap
[1750/2000] tot_loss=1.613 (perp=7.727, rec=0.066, cos=0.002), tot_loss_proj:1.998 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]']
[1800/2000] tot_loss=1.616 (perp=7.727, rec=0.069, cos=0.002), tot_loss_proj:1.997 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]']
Attempt swap
[1850/2000] tot_loss=1.617 (perp=7.727, rec=0.070, cos=0.002), tot_loss_proj:2.000 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]']
Attempt swap
[1900/2000] tot_loss=1.617 (perp=7.727, rec=0.070, cos=0.002), tot_loss_proj:2.004 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]']
[1950/2000] tot_loss=1.620 (perp=7.727, rec=0.073, cos=0.002), tot_loss_proj:2.000 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]']
Attempt swap
[2000/2000] tot_loss=1.617 (perp=7.727, rec=0.070, cos=0.002), tot_loss_proj:1.989 [t=0.24s]
prediction: ['[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS]h - is awkwardly paced circuit story is the soap opera story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 76.923 | r: 90.909
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 66.667 | p: 61.538 | r: 72.727
rougeLsum  | fm: 66.667 | p: 61.538 | r: 72.727
r1fm+r2fm = 119.697

[Aggregate metrics]:
rouge1     | fm: 93.238 | p: 92.755 | r: 93.807
rouge2     | fm: 59.920 | p: 59.594 | r: 60.197
rougeL     | fm: 81.228 | p: 80.830 | r: 81.795
rougeLsum  | fm: 81.086 | p: 80.632 | r: 81.631
r1fm+r2fm = 153.158

input #60 time: 0:09:21 | total time: 9:26:55


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.9992842374425217
highest_index [0]
highest [0.9992842374425217]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9796134233474731 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9755127429962158 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9502310752868652 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9452727437019348 for ['[CLS] paths whose bar [SEP]']
[Init] best rec loss: 0.9447370767593384 for ['[CLS]mbledssi commons [SEP]']
[Init] best rec loss: 0.936389148235321 for ['[CLS] crested tend prize [SEP]']
[Init] best rec loss: 0.9159070253372192 for ['[CLS] bologna nails steps [SEP]']
[Init] best rec loss: 0.9078887104988098 for ['[CLS] you wedding velvet [SEP]']
[Init] best rec loss: 0.8797362446784973 for ['[CLS] respect thrill butterfly [SEP]']
[Init] best rec loss: 0.8326549530029297 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 0.8251567482948303 for ['[CLS] lets request mini [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.755 (perp=7.753, rec=0.195, cos=0.010), tot_loss_proj:1.818 [t=0.23s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 100/2000] tot_loss=1.695 (perp=7.753, rec=0.137, cos=0.008), tot_loss_proj:1.814 [t=0.24s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 150/2000] tot_loss=1.709 (perp=8.032, rec=0.100, cos=0.002), tot_loss_proj:1.692 [t=0.24s]
prediction: ['[CLS], beautiful scene [SEP]']
[ 200/2000] tot_loss=1.671 (perp=8.032, rec=0.063, cos=0.001), tot_loss_proj:1.711 [t=0.24s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.494 (perp=7.102, rec=0.073, cos=0.002), tot_loss_proj:1.623 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 300/2000] tot_loss=1.492 (perp=7.102, rec=0.071, cos=0.001), tot_loss_proj:1.638 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.495 (perp=7.102, rec=0.073, cos=0.001), tot_loss_proj:1.621 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.495 (perp=7.102, rec=0.073, cos=0.001), tot_loss_proj:1.615 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.487 (perp=7.102, rec=0.065, cos=0.001), tot_loss_proj:1.615 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.482 (perp=7.102, rec=0.060, cos=0.001), tot_loss_proj:1.618 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.483 (perp=7.102, rec=0.061, cos=0.001), tot_loss_proj:1.620 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.485 (perp=7.102, rec=0.063, cos=0.001), tot_loss_proj:1.627 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.492 (perp=7.102, rec=0.070, cos=0.001), tot_loss_proj:1.622 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.492 (perp=7.102, rec=0.070, cos=0.001), tot_loss_proj:1.613 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.484 (perp=7.102, rec=0.062, cos=0.001), tot_loss_proj:1.620 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.477 (perp=7.102, rec=0.055, cos=0.001), tot_loss_proj:1.616 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.496 (perp=7.102, rec=0.074, cos=0.001), tot_loss_proj:1.618 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.496 (perp=7.102, rec=0.074, cos=0.001), tot_loss_proj:1.625 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.491 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.610 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.491 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.626 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.491 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.618 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.490 (perp=7.102, rec=0.068, cos=0.001), tot_loss_proj:1.624 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.482 (perp=7.102, rec=0.060, cos=0.001), tot_loss_proj:1.623 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.482 (perp=7.102, rec=0.060, cos=0.001), tot_loss_proj:1.615 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.476 (perp=7.102, rec=0.054, cos=0.001), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.488 (perp=7.102, rec=0.066, cos=0.001), tot_loss_proj:1.618 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.491 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.623 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.476 (perp=7.102, rec=0.054, cos=0.001), tot_loss_proj:1.624 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.487 (perp=7.102, rec=0.065, cos=0.001), tot_loss_proj:1.621 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.491 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.621 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.495 (perp=7.102, rec=0.073, cos=0.001), tot_loss_proj:1.617 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.480 (perp=7.102, rec=0.059, cos=0.001), tot_loss_proj:1.612 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.492 (perp=7.102, rec=0.070, cos=0.001), tot_loss_proj:1.620 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.490 (perp=7.102, rec=0.069, cos=0.001), tot_loss_proj:1.615 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.488 (perp=7.102, rec=0.066, cos=0.001), tot_loss_proj:1.625 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.489 (perp=7.102, rec=0.068, cos=0.001), tot_loss_proj:1.622 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.481 (perp=7.102, rec=0.059, cos=0.001), tot_loss_proj:1.628 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.488 (perp=7.102, rec=0.066, cos=0.001), tot_loss_proj:1.619 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.470 (perp=7.102, rec=0.048, cos=0.001), tot_loss_proj:1.611 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.485 (perp=7.102, rec=0.064, cos=0.001), tot_loss_proj:1.621 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.312 | p: 92.830 | r: 93.867
rouge2     | fm: 60.433 | p: 60.180 | r: 60.749
rougeL     | fm: 81.574 | p: 81.172 | r: 82.115
rougeLsum  | fm: 81.375 | p: 80.969 | r: 81.872
r1fm+r2fm = 153.745

input #61 time: 0:09:04 | total time: 9:35:59


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.9992552892713504
highest_index [0]
highest [0.9992552892713504]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9559537172317505 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9276927709579468 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.922580897808075 for ['[CLS] percentage trap danzinghur shapeee sacred persianlon record theater freestylegold cards dance sacks pits dreadmund existed [SEP]']
[Init] best rec loss: 0.9182294011116028 for ['[CLS] girl plain followedion recalls間 by spread fight sioux 2002 test origins humanitarian peck reed forumnce tooth closely mccarthy [SEP]']
[Init] best perm rec loss: 0.9180595874786377 for ['[CLS]間 origins closely mccarthy sioux tooth 2002 test reed by peck humanitarian girl recalls fight forumion followednce plain spread [SEP]']
[Init] best perm rec loss: 0.9156901240348816 for ['[CLS] fight mccarthy by closely tooth test recalls siouxnce spread humanitarian girl peckion 2002 followed間 reed forum origins plain [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.779 (perp=12.052, rec=0.358, cos=0.011), tot_loss_proj:3.416 [t=0.23s]
prediction: ['[CLS] strong rock8 historic program best parent thatlike grace healing throughout best grade decca for a samurai sense extreme heaven [SEP]']
[ 100/2000] tot_loss=2.161 (perp=9.463, rec=0.263, cos=0.006), tot_loss_proj:3.074 [t=0.24s]
prediction: ['[CLS] perfect named through since streak outstanding the prevention of grace prevention throughout best of art for best war ever extreme best [SEP]']
[ 150/2000] tot_loss=2.097 (perp=9.514, rec=0.191, cos=0.003), tot_loss_proj:3.296 [t=0.24s]
prediction: ['[CLS] to trade to of movies among the prevention to grace prevention throughout best of through making best war ever prevention films [SEP]']
[ 200/2000] tot_loss=2.100 (perp=9.678, rec=0.161, cos=0.003), tot_loss_proj:3.603 [t=0.24s]
prediction: ['[CLS] to call for of rather amongst the prevention to grace prevention throughout one to through making best war ever prevention movies [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.024 (perp=9.443, rec=0.133, cos=0.002), tot_loss_proj:3.824 [t=0.24s]
prediction: ['[CLS] to call for of rather account the prevention for within prevention grace one to around making best war ever prevention movies [SEP]']
[ 300/2000] tot_loss=1.993 (perp=9.444, rec=0.102, cos=0.002), tot_loss_proj:3.378 [t=0.24s]
prediction: ['[CLS] to call for of rather regarded the prevention rather within blame grace one to them making best war ever war movies [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.863 (perp=8.806, rec=0.100, cos=0.002), tot_loss_proj:3.642 [t=0.24s]
prediction: ['[CLS] to call for of rather regarded the prevention, to blame grace one to of making best war ever war movies [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.673 (perp=7.929, rec=0.085, cos=0.002), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] to call for making rather among the prevention, to blame grace to one of making best war ever war movies [SEP]']
[ 450/2000] tot_loss=1.811 (perp=8.624, rec=0.084, cos=0.002), tot_loss_proj:3.641 [t=0.24s]
prediction: ['[CLS] to call for making rather among the prevention, to blame grace to one it making best war ever war movies [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.788 (perp=8.500, rec=0.086, cos=0.002), tot_loss_proj:3.749 [t=0.24s]
prediction: ['[CLS] to call for making rather among the prevention, to blame grace making one it to best war ever place movies [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.723 (perp=8.145, rec=0.092, cos=0.002), tot_loss_proj:3.619 [t=0.24s]
prediction: ['[CLS] to call for making rather among the prevention, to blame grace making it one to best war ever place movies [SEP]']
[ 600/2000] tot_loss=1.570 (perp=7.410, rec=0.086, cos=0.002), tot_loss_proj:3.268 [t=0.24s]
prediction: ['[CLS] to call for making rather of the prevention, to blame grace making it one to best war ever made movies [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.567 (perp=7.410, rec=0.083, cos=0.002), tot_loss_proj:3.262 [t=0.24s]
prediction: ['[CLS] to call for making rather of the prevention, to blame grace making it one to best war ever made movies [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.558 (perp=7.416, rec=0.074, cos=0.001), tot_loss_proj:3.226 [t=0.24s]
prediction: ['[CLS] to call for making rather of the prevention, to blame grace making it one to best war ever movies made [SEP]']
[ 750/2000] tot_loss=1.562 (perp=7.416, rec=0.077, cos=0.001), tot_loss_proj:3.225 [t=0.24s]
prediction: ['[CLS] to call for making rather of the prevention, to blame grace making it one to best war ever movies made [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.586 (perp=7.551, rec=0.074, cos=0.002), tot_loss_proj:2.491 [t=0.24s]
prediction: ['[CLS] to call for making rather of the prevention to blame, grace making it one place best war ever movies made [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.465 (perp=6.909, rec=0.081, cos=0.001), tot_loss_proj:2.034 [t=0.24s]
prediction: ['[CLS] to call for making rather of the prevention to blame, grace making it one place best war movies ever made [SEP]']
[ 900/2000] tot_loss=1.491 (perp=7.072, rec=0.076, cos=0.001), tot_loss_proj:1.980 [t=0.24s]
prediction: ['[CLS] to call for of rather of the prevention to blame, grace making it one place best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.506 (perp=7.198, rec=0.065, cos=0.001), tot_loss_proj:1.965 [t=0.24s]
prediction: ['[CLS] to call than for rather of the prevention to blame, grace making it one place best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.387 (perp=6.533, rec=0.079, cos=0.001), tot_loss_proj:1.793 [t=0.24s]
prediction: ['[CLS] to call than for rather place the prevention to blame, grace making it one of best war movies ever made [SEP]']
[1050/2000] tot_loss=1.376 (perp=6.533, rec=0.068, cos=0.002), tot_loss_proj:1.794 [t=0.24s]
prediction: ['[CLS] to call than for rather place the prevention to blame, grace making it one of best war movies ever made [SEP]']
Attempt swap
[1100/2000] tot_loss=1.380 (perp=6.533, rec=0.072, cos=0.001), tot_loss_proj:1.800 [t=0.23s]
prediction: ['[CLS] to call than for rather place the prevention to blame, grace making it one of best war movies ever made [SEP]']
Attempt swap
[1150/2000] tot_loss=1.370 (perp=6.533, rec=0.062, cos=0.001), tot_loss_proj:1.792 [t=0.22s]
prediction: ['[CLS] to call than for rather place the prevention to blame, grace making it one of best war movies ever made [SEP]']
[1200/2000] tot_loss=1.378 (perp=6.533, rec=0.070, cos=0.001), tot_loss_proj:1.793 [t=0.22s]
prediction: ['[CLS] to call than for rather place the prevention to blame, grace making it one of best war movies ever made [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.258 (perp=5.917, rec=0.073, cos=0.001), tot_loss_proj:1.551 [t=0.22s]
prediction: ['[CLS] to call for rather than place the prevention to blame, grace making it one of best war movies ever made [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.230 (perp=5.813, rec=0.066, cos=0.001), tot_loss_proj:1.489 [t=0.22s]
prediction: ['[CLS] to call for rather than to place the prevention blame, grace making it one of best war movies ever made [SEP]']
[1350/2000] tot_loss=1.233 (perp=5.813, rec=0.069, cos=0.001), tot_loss_proj:1.500 [t=0.22s]
prediction: ['[CLS] to call for rather than to place the prevention blame, grace making it one of best war movies ever made [SEP]']
Attempt swap
[1400/2000] tot_loss=1.225 (perp=5.813, rec=0.061, cos=0.001), tot_loss_proj:1.483 [t=0.22s]
prediction: ['[CLS] to call for rather than to place the prevention blame, grace making it one of best war movies ever made [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.184 (perp=5.576, rec=0.068, cos=0.002), tot_loss_proj:1.436 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place the blame, grace making it one of best war movies ever made [SEP]']
[1500/2000] tot_loss=1.187 (perp=5.576, rec=0.070, cos=0.001), tot_loss_proj:1.429 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place the blame, grace making it one of best war movies ever made [SEP]']
Attempt swap
[1550/2000] tot_loss=1.191 (perp=5.576, rec=0.075, cos=0.001), tot_loss_proj:1.437 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place the blame, grace making it one of best war movies ever made [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.112 (perp=5.202, rec=0.070, cos=0.002), tot_loss_proj:1.334 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place blame, grace making it one of the best war movies ever made [SEP]']
[1650/2000] tot_loss=1.108 (perp=5.202, rec=0.066, cos=0.002), tot_loss_proj:1.334 [t=0.23s]
prediction: ['[CLS] to call for prevention rather than to place blame, grace making it one of the best war movies ever made [SEP]']
Attempt swap
[1700/2000] tot_loss=1.107 (perp=5.202, rec=0.065, cos=0.001), tot_loss_proj:1.332 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place blame, grace making it one of the best war movies ever made [SEP]']
Attempt swap
[1750/2000] tot_loss=1.106 (perp=5.202, rec=0.064, cos=0.001), tot_loss_proj:1.338 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place blame, grace making it one of the best war movies ever made [SEP]']
[1800/2000] tot_loss=1.112 (perp=5.202, rec=0.070, cos=0.001), tot_loss_proj:1.328 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place blame, grace making it one of the best war movies ever made [SEP]']
Attempt swap
[1850/2000] tot_loss=1.107 (perp=5.202, rec=0.065, cos=0.001), tot_loss_proj:1.328 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place blame, grace making it one of the best war movies ever made [SEP]']
Attempt swap
[1900/2000] tot_loss=1.102 (perp=5.202, rec=0.060, cos=0.001), tot_loss_proj:1.332 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place blame, grace making it one of the best war movies ever made [SEP]']
[1950/2000] tot_loss=1.113 (perp=5.202, rec=0.071, cos=0.001), tot_loss_proj:1.339 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place blame, grace making it one of the best war movies ever made [SEP]']
Attempt swap
[2000/2000] tot_loss=1.111 (perp=5.202, rec=0.069, cos=0.001), tot_loss_proj:1.330 [t=0.22s]
prediction: ['[CLS] to call for prevention rather than to place blame, grace making it one of the best war movies ever made [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] to call for prevention rather than to place blame, grace making it one of the best war movies ever made [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 95.455 | p: 95.455 | r: 95.455
rougeLsum  | fm: 95.455 | p: 95.455 | r: 95.455
r1fm+r2fm = 185.714

[Aggregate metrics]:
rouge1     | fm: 93.413 | p: 92.923 | r: 93.973
rouge2     | fm: 60.862 | p: 60.670 | r: 61.163
rougeL     | fm: 81.849 | p: 81.422 | r: 82.361
rougeLsum  | fm: 81.585 | p: 81.203 | r: 82.130
r1fm+r2fm = 154.274

input #62 time: 0:09:13 | total time: 9:45:13


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9992638993081941
highest_index [0]
highest [0.9992638993081941]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.9526534080505371 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.8990910053253174 for ['[CLS] touch alternative glacier bentry [SEP]']
[Init] best rec loss: 0.7447170615196228 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7446317672729492 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 0.7400466203689575 for ['[CLS] diploma catalogue honors knee skirt [SEP]']
[Init] best rec loss: 0.7324649691581726 for ['[CLS] forces solutions... offense civil [SEP]']
[Init] best perm rec loss: 0.727935254573822 for ['[CLS] forces offense civil... solutions [SEP]']
[Init] best perm rec loss: 0.7276415228843689 for ['[CLS] forces solutions offense... civil [SEP]']
[Init] best perm rec loss: 0.727533221244812 for ['[CLS]... solutions civil offense forces [SEP]']
[Init] best perm rec loss: 0.7274791598320007 for ['[CLS] solutions... offense civil forces [SEP]']
[Init] best perm rec loss: 0.7251647710800171 for ['[CLS] offense... solutions civil forces [SEP]']
[Init] best perm rec loss: 0.7243860960006714 for ['[CLS] forces offense... solutions civil [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.424 (perp=10.515, rec=0.285, cos=0.035), tot_loss_proj:3.188 [t=0.23s]
prediction: ['[CLS]gned face behind return ticket [SEP]']
[ 100/2000] tot_loss=2.515 (perp=11.865, rec=0.133, cos=0.009), tot_loss_proj:3.500 [t=0.23s]
prediction: ['[CLS]gned looking looking return ticket [SEP]']
[ 150/2000] tot_loss=2.406 (perp=11.471, rec=0.106, cos=0.006), tot_loss_proj:3.196 [t=0.23s]
prediction: ['[CLS] for looking looking return ticket [SEP]']
[ 200/2000] tot_loss=2.393 (perp=11.471, rec=0.094, cos=0.005), tot_loss_proj:3.209 [t=0.23s]
prediction: ['[CLS] for looking looking return ticket [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.982 (perp=9.470, rec=0.083, cos=0.005), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] looking looking for return ticket [SEP]']
[ 300/2000] tot_loss=1.975 (perp=9.470, rec=0.078, cos=0.002), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] looking looking for return ticket [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.737 (perp=8.350, rec=0.066, cos=0.001), tot_loss_proj:2.126 [t=0.23s]
prediction: ['[CLS] a looking for return ticket [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.294 (perp=6.111, rec=0.070, cos=0.001), tot_loss_proj:1.325 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 450/2000] tot_loss=1.287 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.310 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.284 (perp=6.111, rec=0.060, cos=0.001), tot_loss_proj:1.316 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.284 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.323 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 600/2000] tot_loss=1.292 (perp=6.111, rec=0.069, cos=0.001), tot_loss_proj:1.315 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.295 (perp=6.111, rec=0.071, cos=0.001), tot_loss_proj:1.312 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.001), tot_loss_proj:1.316 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 750/2000] tot_loss=1.273 (perp=6.111, rec=0.049, cos=0.001), tot_loss_proj:1.312 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.289 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.323 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.285 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.303 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[ 900/2000] tot_loss=1.285 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.326 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.281 (perp=6.111, rec=0.057, cos=0.001), tot_loss_proj:1.315 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.295 (perp=6.111, rec=0.071, cos=0.001), tot_loss_proj:1.319 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1050/2000] tot_loss=1.288 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.317 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.297 (perp=6.111, rec=0.073, cos=0.001), tot_loss_proj:1.311 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.295 (perp=6.111, rec=0.072, cos=0.001), tot_loss_proj:1.311 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1200/2000] tot_loss=1.279 (perp=6.111, rec=0.055, cos=0.001), tot_loss_proj:1.302 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.280 (perp=6.111, rec=0.057, cos=0.001), tot_loss_proj:1.307 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.291 (perp=6.111, rec=0.067, cos=0.001), tot_loss_proj:1.305 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.273 (perp=6.111, rec=0.049, cos=0.001), tot_loss_proj:1.313 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.293 (perp=6.111, rec=0.069, cos=0.001), tot_loss_proj:1.303 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.283 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.309 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.278 (perp=6.111, rec=0.054, cos=0.001), tot_loss_proj:1.306 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.287 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.318 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.288 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.319 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.287 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.315 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.283 (perp=6.111, rec=0.060, cos=0.001), tot_loss_proj:1.321 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.286 (perp=6.111, rec=0.062, cos=0.001), tot_loss_proj:1.323 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.286 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.285 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.322 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.319 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.316 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.284 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.500 | p: 93.037 | r: 94.061
rouge2     | fm: 61.574 | p: 61.354 | r: 61.882
rougeL     | fm: 82.179 | p: 81.745 | r: 82.639
rougeLsum  | fm: 81.856 | p: 81.409 | r: 82.310
r1fm+r2fm = 155.073

input #63 time: 0:09:17 | total time: 9:54:31


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.9991605989689818
highest_index [0]
highest [0.9991605989689818]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8780370354652405 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.865992546081543 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 0.7271021604537964 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6768224239349365 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.67481529712677 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 0.6732637882232666 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.979 (perp=8.653, rec=0.216, cos=0.032), tot_loss_proj:2.056 [t=0.23s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.897 (perp=8.653, rec=0.149, cos=0.018), tot_loss_proj:2.064 [t=0.24s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.875 (perp=8.653, rec=0.132, cos=0.013), tot_loss_proj:2.052 [t=0.24s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=1.868 (perp=8.653, rec=0.126, cos=0.011), tot_loss_proj:2.053 [t=0.24s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.936 (perp=9.189, rec=0.092, cos=0.007), tot_loss_proj:2.214 [t=0.24s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 300/2000] tot_loss=1.684 (perp=8.065, rec=0.070, cos=0.002), tot_loss_proj:1.703 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.711 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.686 (perp=8.065, rec=0.071, cos=0.002), tot_loss_proj:1.710 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.718 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.708 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.675 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.716 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.671 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.712 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.700 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.667 (perp=8.065, rec=0.052, cos=0.002), tot_loss_proj:1.701 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.706 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.678 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.712 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.671 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.718 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.713 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.696 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.665 (perp=8.065, rec=0.051, cos=0.002), tot_loss_proj:1.699 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.704 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.714 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.715 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.686 (perp=8.065, rec=0.071, cos=0.002), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.713 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.689 (perp=8.065, rec=0.075, cos=0.002), tot_loss_proj:1.718 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.680 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.711 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.666 (perp=8.065, rec=0.051, cos=0.002), tot_loss_proj:1.701 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.713 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.681 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.711 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.672 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.703 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.718 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.666 (perp=8.065, rec=0.051, cos=0.002), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.684 (perp=8.065, rec=0.069, cos=0.002), tot_loss_proj:1.714 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.692 (perp=8.065, rec=0.078, cos=0.002), tot_loss_proj:1.713 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.708 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.670 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.712 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.673 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.651 | p: 93.171 | r: 94.186
rouge2     | fm: 62.073 | p: 61.815 | r: 62.381
rougeL     | fm: 82.300 | p: 81.891 | r: 82.762
rougeLsum  | fm: 82.295 | p: 81.880 | r: 82.828
r1fm+r2fm = 155.724

input #64 time: 0:09:03 | total time: 10:03:34


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9992253462692213
highest_index [0]
highest [0.9992253462692213]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.025086522102356 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9568408727645874 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9551860094070435 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.9448243975639343 for ['[CLS]blpf bce med stride plot skip honest what [SEP]']
[Init] best rec loss: 0.8855191469192505 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8788135051727295 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8770949840545654 for ['[CLS]mament even news general fun pu overshoff someday [SEP]']
[Init] best perm rec loss: 0.8740336894989014 for ['[CLS] even someday oversmament general pu funhoff news [SEP]']
[Init] best perm rec loss: 0.8733600378036499 for ['[CLS] news pu general evenmamenthoff someday fun overs [SEP]']
[Init] best perm rec loss: 0.8727949261665344 for ['[CLS] general newsmament someday overs fun puhoff even [SEP]']
[Init] best perm rec loss: 0.8721603155136108 for ['[CLS] general news someday pu even overshoff funmament [SEP]']
[Init] best perm rec loss: 0.8717846274375916 for ['[CLS] general pu even news someday overshoff funmament [SEP]']
[Init] best perm rec loss: 0.8717253804206848 for ['[CLS] general someday even news fun overs puhoffmament [SEP]']
[Init] best perm rec loss: 0.8714078068733215 for ['[CLS] someday generalhoff even oversmament pu news fun [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.343 (perp=10.160, rec=0.295, cos=0.016), tot_loss_proj:2.591 [t=0.23s]
prediction: ['[CLS]ous joy joypapery joy film film joy [SEP]']
[ 100/2000] tot_loss=1.956 (perp=8.922, rec=0.165, cos=0.006), tot_loss_proj:2.246 [t=0.24s]
prediction: ['[CLS], joy joyousous romp film joy [SEP]']
[ 150/2000] tot_loss=1.645 (perp=7.738, rec=0.095, cos=0.002), tot_loss_proj:1.924 [t=0.24s]
prediction: ['[CLS], joy joyousous romp. film [SEP]']
[ 200/2000] tot_loss=1.858 (perp=8.889, rec=0.079, cos=0.002), tot_loss_proj:2.229 [t=0.24s]
prediction: ['[CLS], joy film ofous romp. film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.617 (perp=6.737, rec=0.256, cos=0.014), tot_loss_proj:1.935 [t=0.24s]
prediction: ['[CLS], of film joyous romp. film [SEP]']
[ 300/2000] tot_loss=1.554 (perp=7.190, rec=0.114, cos=0.002), tot_loss_proj:1.810 [t=0.24s]
prediction: ['[CLS], of joy joyous romp. film [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.404 (perp=6.516, rec=0.100, cos=0.002), tot_loss_proj:1.693 [t=0.24s]
prediction: ['[CLS] of film, joyous romp. film [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.519 (perp=7.053, rec=0.107, cos=0.002), tot_loss_proj:2.296 [t=0.24s]
prediction: ['[CLS]. whenever, joyous romp of film [SEP]']
[ 450/2000] tot_loss=1.500 (perp=7.053, rec=0.088, cos=0.002), tot_loss_proj:2.251 [t=0.24s]
prediction: ['[CLS]. whenever, joyous romp of film [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.338 (perp=6.197, rec=0.097, cos=0.002), tot_loss_proj:1.501 [t=0.24s]
prediction: ['[CLS]. joyous romp of film film, [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.185 (perp=5.433, rec=0.097, cos=0.002), tot_loss_proj:1.359 [t=0.24s]
prediction: ['[CLS]. a joyous romp of film, [SEP]']
[ 600/2000] tot_loss=1.170 (perp=5.433, rec=0.081, cos=0.002), tot_loss_proj:1.358 [t=0.24s]
prediction: ['[CLS]. a joyous romp of film, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.178 (perp=5.433, rec=0.089, cos=0.002), tot_loss_proj:1.353 [t=0.24s]
prediction: ['[CLS]. a joyous romp of film, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.171 (perp=5.433, rec=0.083, cos=0.002), tot_loss_proj:1.347 [t=0.24s]
prediction: ['[CLS]. a joyous romp of film, [SEP]']
[ 750/2000] tot_loss=1.152 (perp=5.433, rec=0.064, cos=0.002), tot_loss_proj:1.360 [t=0.24s]
prediction: ['[CLS]. a joyous romp of film, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.077 (perp=4.968, rec=0.081, cos=0.002), tot_loss_proj:1.216 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.062 (perp=4.968, rec=0.066, cos=0.002), tot_loss_proj:1.209 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
[ 900/2000] tot_loss=1.071 (perp=4.968, rec=0.076, cos=0.002), tot_loss_proj:1.221 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.063 (perp=4.968, rec=0.068, cos=0.002), tot_loss_proj:1.208 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.072 (perp=4.968, rec=0.077, cos=0.002), tot_loss_proj:1.204 [t=0.23s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
[1050/2000] tot_loss=1.079 (perp=4.968, rec=0.084, cos=0.002), tot_loss_proj:1.206 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.075 (perp=4.968, rec=0.080, cos=0.002), tot_loss_proj:1.206 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.074 (perp=4.968, rec=0.078, cos=0.002), tot_loss_proj:1.214 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
[1200/2000] tot_loss=1.068 (perp=4.968, rec=0.073, cos=0.002), tot_loss_proj:1.214 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.064 (perp=4.968, rec=0.069, cos=0.002), tot_loss_proj:1.214 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.071 (perp=4.968, rec=0.076, cos=0.002), tot_loss_proj:1.212 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
[1350/2000] tot_loss=1.070 (perp=4.968, rec=0.075, cos=0.002), tot_loss_proj:1.215 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.057 (perp=4.968, rec=0.062, cos=0.002), tot_loss_proj:1.215 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.063 (perp=4.968, rec=0.068, cos=0.002), tot_loss_proj:1.211 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
[1500/2000] tot_loss=1.069 (perp=4.968, rec=0.073, cos=0.002), tot_loss_proj:1.217 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.071 (perp=4.968, rec=0.076, cos=0.002), tot_loss_proj:1.203 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.076 (perp=4.968, rec=0.081, cos=0.002), tot_loss_proj:1.215 [t=0.24s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
[1650/2000] tot_loss=1.069 (perp=4.968, rec=0.074, cos=0.002), tot_loss_proj:1.216 [t=0.22s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.069 (perp=4.968, rec=0.073, cos=0.002), tot_loss_proj:1.214 [t=0.22s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.064 (perp=4.968, rec=0.069, cos=0.002), tot_loss_proj:1.214 [t=0.22s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
[1800/2000] tot_loss=1.071 (perp=4.968, rec=0.076, cos=0.002), tot_loss_proj:1.218 [t=0.22s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.071 (perp=4.968, rec=0.076, cos=0.002), tot_loss_proj:1.206 [t=0.22s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.073 (perp=4.968, rec=0.077, cos=0.002), tot_loss_proj:1.210 [t=0.22s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
[1950/2000] tot_loss=1.066 (perp=4.968, rec=0.071, cos=0.002), tot_loss_proj:1.202 [t=0.22s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.069 (perp=4.968, rec=0.074, cos=0.002), tot_loss_proj:1.211 [t=0.22s]
prediction: ['[CLS], a joyous romp of film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS], a joyous romp of film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 93.755 | p: 93.284 | r: 94.311
rouge2     | fm: 61.955 | p: 61.673 | r: 62.260
rougeL     | fm: 82.444 | p: 82.018 | r: 82.914
rougeLsum  | fm: 82.376 | p: 81.969 | r: 82.887
r1fm+r2fm = 155.710

input #65 time: 0:09:16 | total time: 10:12:50


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9992334111460102
highest_index [0]
highest [0.9992334111460102]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.9737173318862915 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.9308234453201294 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.9202260971069336 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8853452801704407 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.868087112903595 for ['[CLS]beersa bryce two [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.060 (perp=8.797, rec=0.286, cos=0.015), tot_loss_proj:2.763 [t=0.23s]
prediction: ['[CLS] fan summer fan fan [SEP]']
[ 100/2000] tot_loss=2.630 (perp=12.661, rec=0.095, cos=0.002), tot_loss_proj:2.922 [t=0.24s]
prediction: ['[CLS] fan a longtime tolkien [SEP]']
[ 150/2000] tot_loss=2.615 (perp=12.661, rec=0.081, cos=0.002), tot_loss_proj:2.948 [t=0.24s]
prediction: ['[CLS] fan a longtime tolkien [SEP]']
[ 200/2000] tot_loss=2.596 (perp=12.661, rec=0.063, cos=0.002), tot_loss_proj:2.942 [t=0.24s]
prediction: ['[CLS] fan a longtime tolkien [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.601 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.604 (perp=7.672, rec=0.068, cos=0.002), tot_loss_proj:1.601 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.602 (perp=7.672, rec=0.066, cos=0.002), tot_loss_proj:1.598 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.599 (perp=7.672, rec=0.063, cos=0.002), tot_loss_proj:1.600 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.589 (perp=7.672, rec=0.053, cos=0.002), tot_loss_proj:1.608 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.581 (perp=7.672, rec=0.045, cos=0.002), tot_loss_proj:1.614 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.600 (perp=7.672, rec=0.064, cos=0.002), tot_loss_proj:1.617 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.593 (perp=7.672, rec=0.057, cos=0.002), tot_loss_proj:1.610 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.609 (perp=7.672, rec=0.073, cos=0.002), tot_loss_proj:1.606 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.584 (perp=7.672, rec=0.048, cos=0.002), tot_loss_proj:1.596 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.598 (perp=7.672, rec=0.062, cos=0.002), tot_loss_proj:1.602 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.607 (perp=7.672, rec=0.071, cos=0.002), tot_loss_proj:1.610 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.588 (perp=7.672, rec=0.052, cos=0.002), tot_loss_proj:1.604 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.601 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.585 (perp=7.672, rec=0.049, cos=0.002), tot_loss_proj:1.604 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.595 (perp=7.672, rec=0.059, cos=0.002), tot_loss_proj:1.598 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.599 (perp=7.672, rec=0.063, cos=0.002), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.602 (perp=7.672, rec=0.066, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.588 (perp=7.672, rec=0.052, cos=0.002), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.598 (perp=7.672, rec=0.062, cos=0.002), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.601 (perp=7.672, rec=0.065, cos=0.002), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.590 (perp=7.672, rec=0.054, cos=0.002), tot_loss_proj:1.608 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.596 (perp=7.672, rec=0.060, cos=0.002), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.597 (perp=7.672, rec=0.061, cos=0.002), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.588 (perp=7.672, rec=0.052, cos=0.002), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.600 (perp=7.672, rec=0.064, cos=0.002), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.585 (perp=7.672, rec=0.049, cos=0.002), tot_loss_proj:1.591 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.594 (perp=7.672, rec=0.058, cos=0.002), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.596 (perp=7.672, rec=0.060, cos=0.002), tot_loss_proj:1.601 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.601 (perp=7.672, rec=0.065, cos=0.002), tot_loss_proj:1.605 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.593 (perp=7.672, rec=0.057, cos=0.002), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.581 (perp=7.672, rec=0.045, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.605 (perp=7.672, rec=0.069, cos=0.002), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.602 (perp=7.672, rec=0.066, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.672, rec=0.051, cos=0.002), tot_loss_proj:1.595 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.585 (perp=7.672, rec=0.049, cos=0.002), tot_loss_proj:1.600 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.815 | p: 93.373 | r: 94.364
rouge2     | fm: 62.617 | p: 62.400 | r: 62.900
rougeL     | fm: 82.600 | p: 82.210 | r: 83.054
rougeLsum  | fm: 82.555 | p: 82.170 | r: 83.086
r1fm+r2fm = 156.432

input #66 time: 0:09:04 | total time: 10:21:55


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.9992930121177666
highest_index [0]
highest [0.9992930121177666]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.005165934562683 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9613745808601379 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.9571365714073181 for ['[CLS] repeat well rv strikes combined leaned written itself welsh bunch [SEP]']
[Init] best rec loss: 0.9488541483879089 for ['[CLS] position citationliga carriage demands source administered leancode pope [SEP]']
[Init] best rec loss: 0.9410316348075867 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 0.9324914216995239 for ['[CLS] investment parker mostly radical national snow nearly baltimore contact are [SEP]']
[Init] best rec loss: 0.9314884543418884 for ['[CLS]ible ultimately season mainly swifthood abby source price need [SEP]']
[Init] best rec loss: 0.930374264717102 for ['[CLS] wild tribes upon cone home enough promotion mural courtney ） [SEP]']
[Init] best perm rec loss: 0.929959774017334 for ['[CLS] cone upon promotion ） courtney enough mural tribes wild home [SEP]']
[Init] best perm rec loss: 0.9298282265663147 for ['[CLS] mural tribes promotion wild cone ） courtney home enough upon [SEP]']
[Init] best perm rec loss: 0.927698016166687 for ['[CLS] home cone wild enough tribes ） courtney upon mural promotion [SEP]']
[Init] best perm rec loss: 0.9275584816932678 for ['[CLS] promotion ） wild courtney cone mural home tribes upon enough [SEP]']
[Init] best perm rec loss: 0.9234167337417603 for ['[CLS] ） cone home mural wild upon courtney promotion enough tribes [SEP]']
[Init] best perm rec loss: 0.923023521900177 for ['[CLS] upon tribes home cone promotion ） enough wild courtney mural [SEP]']
[Init] best perm rec loss: 0.921942949295044 for ['[CLS] upon promotion wild home cone tribes mural ） enough courtney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.691 (perp=12.137, rec=0.258, cos=0.005), tot_loss_proj:3.883 [t=0.23s]
prediction: ['[CLS] heartwar kindationwar - bu writing kind bishop [SEP]']
[ 100/2000] tot_loss=2.580 (perp=11.951, rec=0.184, cos=0.006), tot_loss_proj:4.174 [t=0.24s]
prediction: ['[CLS] heartwar kindingwar,gm effects kindental [SEP]']
[ 150/2000] tot_loss=2.694 (perp=12.756, rec=0.140, cos=0.003), tot_loss_proj:4.120 [t=0.24s]
prediction: ['[CLS] heartwarentalmingwar,gmming kindental [SEP]']
[ 200/2000] tot_loss=2.475 (perp=11.742, rec=0.125, cos=0.002), tot_loss_proj:4.200 [t=0.24s]
prediction: ['[CLS] heartwarentalmingwar, nonming kindental [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.808 (perp=8.324, rec=0.141, cos=0.003), tot_loss_proj:2.284 [t=0.24s]
prediction: ['[CLS] heartwarmingmingwarming, non kindental [SEP]']
[ 300/2000] tot_loss=1.964 (perp=9.211, rec=0.120, cos=0.002), tot_loss_proj:3.177 [t=0.24s]
prediction: ['[CLS] heartwarminggm nonming, non kindental [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.721 (perp=7.979, rec=0.123, cos=0.002), tot_loss_proj:2.725 [t=0.24s]
prediction: ['[CLS] heartwarming kind nonming, nongmental [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.672 (perp=7.794, rec=0.111, cos=0.002), tot_loss_proj:1.927 [t=0.24s]
prediction: ['[CLS] heartwarming [SEP]ming, nongmental kind [SEP]']
[ 450/2000] tot_loss=1.658 (perp=7.794, rec=0.097, cos=0.002), tot_loss_proj:1.929 [t=0.24s]
prediction: ['[CLS] heartwarming [SEP]ming, nongmental kind [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.650 (perp=7.794, rec=0.090, cos=0.002), tot_loss_proj:1.916 [t=0.24s]
prediction: ['[CLS] heartwarming [SEP]ming, nongmental kind [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.648 (perp=7.794, rec=0.087, cos=0.002), tot_loss_proj:1.925 [t=0.24s]
prediction: ['[CLS] heartwarming [SEP]ming, nongmental kind [SEP]']
[ 600/2000] tot_loss=1.640 (perp=7.794, rec=0.080, cos=0.002), tot_loss_proj:1.923 [t=0.24s]
prediction: ['[CLS] heartwarming [SEP]ming, nongmental kind [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.560 (perp=7.404, rec=0.078, cos=0.002), tot_loss_proj:2.538 [t=0.24s]
prediction: ['[CLS] heartwarming nonming, nongmental kind [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.682 (perp=8.042, rec=0.072, cos=0.002), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] heartwarming, [SEP]ming nongmental kind [SEP]']
[ 750/2000] tot_loss=1.686 (perp=8.042, rec=0.076, cos=0.002), tot_loss_proj:2.013 [t=0.24s]
prediction: ['[CLS] heartwarming, [SEP]ming nongmental kind [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.567 (perp=7.404, rec=0.084, cos=0.002), tot_loss_proj:2.534 [t=0.24s]
prediction: ['[CLS] heartwarming nonming, nongmental kind [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.530 (perp=7.188, rec=0.091, cos=0.002), tot_loss_proj:1.894 [t=0.24s]
prediction: ['[CLS] heartwarming, nonming nongmental kind [SEP]']
[ 900/2000] tot_loss=1.518 (perp=7.188, rec=0.079, cos=0.002), tot_loss_proj:1.892 [t=0.24s]
prediction: ['[CLS] heartwarming, nonming nongmental kind [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.519 (perp=7.188, rec=0.080, cos=0.002), tot_loss_proj:1.895 [t=0.24s]
prediction: ['[CLS] heartwarming, nonming nongmental kind [SEP]']
Attempt swap
[1000/2000] tot_loss=1.502 (perp=7.188, rec=0.063, cos=0.002), tot_loss_proj:1.888 [t=0.24s]
prediction: ['[CLS] heartwarming, nonming nongmental kind [SEP]']
[1050/2000] tot_loss=1.523 (perp=7.188, rec=0.084, cos=0.002), tot_loss_proj:1.886 [t=0.24s]
prediction: ['[CLS] heartwarming, nonming nongmental kind [SEP]']
Attempt swap
[1100/2000] tot_loss=1.513 (perp=7.188, rec=0.074, cos=0.002), tot_loss_proj:1.900 [t=0.24s]
prediction: ['[CLS] heartwarming, nonming nongmental kind [SEP]']
Attempt swap
[1150/2000] tot_loss=1.516 (perp=7.188, rec=0.077, cos=0.002), tot_loss_proj:1.891 [t=0.24s]
prediction: ['[CLS] heartwarming, nonming nongmental kind [SEP]']
[1200/2000] tot_loss=1.618 (perp=7.730, rec=0.071, cos=0.001), tot_loss_proj:1.819 [t=0.24s]
prediction: ['[CLS] heartwarming,juming nongmental kind [SEP]']
Attempt swap
[1250/2000] tot_loss=1.621 (perp=7.730, rec=0.074, cos=0.001), tot_loss_proj:1.823 [t=0.24s]
prediction: ['[CLS] heartwarming,juming nongmental kind [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.574 (perp=7.505, rec=0.071, cos=0.002), tot_loss_proj:1.855 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
[1350/2000] tot_loss=1.579 (perp=7.505, rec=0.076, cos=0.001), tot_loss_proj:1.855 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
Attempt swap
[1400/2000] tot_loss=1.577 (perp=7.505, rec=0.074, cos=0.001), tot_loss_proj:1.854 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
Attempt swap
[1450/2000] tot_loss=1.572 (perp=7.505, rec=0.070, cos=0.001), tot_loss_proj:1.854 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
[1500/2000] tot_loss=1.565 (perp=7.505, rec=0.063, cos=0.001), tot_loss_proj:1.856 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
Attempt swap
[1550/2000] tot_loss=1.567 (perp=7.505, rec=0.065, cos=0.001), tot_loss_proj:1.855 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
Attempt swap
[1600/2000] tot_loss=1.569 (perp=7.505, rec=0.067, cos=0.001), tot_loss_proj:1.854 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
[1650/2000] tot_loss=1.574 (perp=7.505, rec=0.072, cos=0.001), tot_loss_proj:1.847 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
Attempt swap
[1700/2000] tot_loss=1.579 (perp=7.505, rec=0.077, cos=0.001), tot_loss_proj:1.857 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
Attempt swap
[1750/2000] tot_loss=1.577 (perp=7.505, rec=0.075, cos=0.001), tot_loss_proj:1.853 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
[1800/2000] tot_loss=1.581 (perp=7.505, rec=0.078, cos=0.001), tot_loss_proj:1.856 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
Attempt swap
[1850/2000] tot_loss=1.573 (perp=7.505, rec=0.071, cos=0.001), tot_loss_proj:1.851 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
Attempt swap
[1900/2000] tot_loss=1.571 (perp=7.505, rec=0.068, cos=0.001), tot_loss_proj:1.854 [t=0.23s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
[1950/2000] tot_loss=1.568 (perp=7.505, rec=0.065, cos=0.001), tot_loss_proj:1.849 [t=0.24s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
Attempt swap
[2000/2000] tot_loss=1.579 (perp=7.505, rec=0.077, cos=0.001), tot_loss_proj:1.849 [t=0.23s]
prediction: ['[CLS] heartwarming, nonmingjugmental kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] heartwarming, nonmingjugmental kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 93.631 | p: 93.215 | r: 94.154
rouge2     | fm: 62.506 | p: 62.197 | r: 62.732
rougeL     | fm: 82.649 | p: 82.255 | r: 83.077
rougeLsum  | fm: 82.655 | p: 82.251 | r: 83.117
r1fm+r2fm = 156.137

input #67 time: 0:09:21 | total time: 10:31:17


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9992788464941955
highest_index [0]
highest [0.9992788464941955]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9892685413360596 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9690264463424683 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.9392844438552856 for ['[CLS] raise describedwehrwork witch rom can bray fictional elton here sex pilots [SEP]']
[Init] best rec loss: 0.9260305762290955 for ['[CLS] neutron acrosswas 2005 security tip fa— identity david entitled readers letters [SEP]']
[Init] best rec loss: 0.8682870864868164 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8625865578651428 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8616510033607483 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8608852028846741 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8606603145599365 for ['[CLS]iferous form medal comfort councils possibly diedyn riding floor. view beth [SEP]']
[Init] best perm rec loss: 0.8585078120231628 for ['[CLS]yn view beth form. comfort riding medal died councils flooriferous possibly [SEP]']
[Init] best perm rec loss: 0.8575673699378967 for ['[CLS] riding possibly died bethyn medal. comfortiferous form view councils floor [SEP]']
[Init] best perm rec loss: 0.8523683547973633 for ['[CLS] medal comfort riding. councils beth died formyniferous floor view possibly [SEP]']
[Init] best perm rec loss: 0.8509644269943237 for ['[CLS]iferous died beth. ridingyn form councils medal possibly floor view comfort [SEP]']
[Init] best perm rec loss: 0.8499634861946106 for ['[CLS] died comfort beth riding councils possibly. medalyn floor form viewiferous [SEP]']
[Init] best perm rec loss: 0.8496124148368835 for ['[CLS] viewiferous comfort councils form beth possibly died medalyn floor riding. [SEP]']
[Init] best perm rec loss: 0.8491353988647461 for ['[CLS]yn councils possibly formiferous beth medal floor. riding comfort view died [SEP]']
[Init] best perm rec loss: 0.8445032835006714 for ['[CLS]yn. comfort diediferous possibly form councils beth floor medal view riding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.528 (perp=11.709, rec=0.182, cos=0.003), tot_loss_proj:3.030 [t=0.23s]
prediction: ['[CLS] un absurdct,,ulously unne effort vicious absurd absurd ( [SEP]']
[ 100/2000] tot_loss=2.240 (perp=10.313, rec=0.172, cos=0.005), tot_loss_proj:2.492 [t=0.24s]
prediction: ['[CLS] un unuth,,co unsiblesible vicious and absurd ( [SEP]']
[ 150/2000] tot_loss=2.250 (perp=10.676, rec=0.113, cos=0.002), tot_loss_proj:2.504 [t=0.24s]
prediction: ['[CLS] un unuth,,ompcoosible vicious and absurd ( [SEP]']
[ 200/2000] tot_loss=2.437 (perp=11.691, rec=0.097, cos=0.002), tot_loss_proj:2.771 [t=0.24s]
prediction: ['[CLS] un unuth,,ompco ;sible vicious and absurdhen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.998 (perp=9.574, rec=0.082, cos=0.002), tot_loss_proj:2.281 [t=0.24s]
prediction: ['[CLS] unomputh,, unco,sible vicious and absurdhen [SEP]']
[ 300/2000] tot_loss=1.993 (perp=9.574, rec=0.077, cos=0.001), tot_loss_proj:2.279 [t=0.24s]
prediction: ['[CLS] unomputh,, unco,sible vicious and absurdhen [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.796 (perp=8.569, rec=0.080, cos=0.001), tot_loss_proj:2.036 [t=0.24s]
prediction: ['[CLS] unomputh,, uncosible, vicious and absurdhen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.766 (perp=8.389, rec=0.086, cos=0.002), tot_loss_proj:1.995 [t=0.24s]
prediction: ['[CLS] unompsible,, uncouth. vicious and absurdhen [SEP]']
[ 450/2000] tot_loss=1.752 (perp=8.389, rec=0.072, cos=0.001), tot_loss_proj:1.996 [t=0.24s]
prediction: ['[CLS] unompsible,, uncouth. vicious and absurdhen [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.641 (perp=7.840, rec=0.072, cos=0.001), tot_loss_proj:1.902 [t=0.24s]
prediction: ['[CLS] unompsible,, uncouth vicious and absurdhen. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.464 (perp=6.927, rec=0.077, cos=0.002), tot_loss_proj:1.747 [t=0.24s]
prediction: ['[CLS] unhensible,, uncouth vicious and absurdompent [SEP]']
[ 600/2000] tot_loss=1.463 (perp=6.927, rec=0.076, cos=0.001), tot_loss_proj:1.745 [t=0.24s]
prediction: ['[CLS] unhensible,, uncouth vicious and absurdompent [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.411 (perp=6.673, rec=0.075, cos=0.001), tot_loss_proj:1.615 [t=0.24s]
prediction: ['[CLS] inchensible, uncouth, vicious and absurdompent [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.260 (perp=5.912, rec=0.076, cos=0.001), tot_loss_proj:1.439 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
[ 750/2000] tot_loss=1.253 (perp=5.912, rec=0.069, cos=0.001), tot_loss_proj:1.445 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.260 (perp=5.912, rec=0.076, cos=0.001), tot_loss_proj:1.446 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.249 (perp=5.912, rec=0.065, cos=0.001), tot_loss_proj:1.450 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
[ 900/2000] tot_loss=1.248 (perp=5.912, rec=0.064, cos=0.001), tot_loss_proj:1.452 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.255 (perp=5.912, rec=0.071, cos=0.001), tot_loss_proj:1.450 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
Attempt swap
[1000/2000] tot_loss=1.248 (perp=5.912, rec=0.064, cos=0.001), tot_loss_proj:1.450 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
[1050/2000] tot_loss=1.254 (perp=5.912, rec=0.070, cos=0.001), tot_loss_proj:1.447 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
Attempt swap
[1100/2000] tot_loss=1.254 (perp=5.912, rec=0.070, cos=0.001), tot_loss_proj:1.445 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
Attempt swap
[1150/2000] tot_loss=1.250 (perp=5.912, rec=0.066, cos=0.001), tot_loss_proj:1.454 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
[1200/2000] tot_loss=1.248 (perp=5.912, rec=0.064, cos=0.001), tot_loss_proj:1.446 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
Attempt swap
[1250/2000] tot_loss=1.243 (perp=5.912, rec=0.059, cos=0.001), tot_loss_proj:1.452 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompsible [SEP]']
Attempt swap
[1300/2000] tot_loss=1.325 (perp=6.284, rec=0.067, cos=0.001), tot_loss_proj:1.469 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incomp absurd [SEP]']
[1350/2000] tot_loss=1.346 (perp=6.348, rec=0.074, cos=0.001), tot_loss_proj:1.491 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
Attempt swap
[1400/2000] tot_loss=1.342 (perp=6.348, rec=0.071, cos=0.001), tot_loss_proj:1.493 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
Attempt swap
[1450/2000] tot_loss=1.330 (perp=6.348, rec=0.059, cos=0.001), tot_loss_proj:1.492 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
[1500/2000] tot_loss=1.330 (perp=6.348, rec=0.059, cos=0.001), tot_loss_proj:1.486 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
Attempt swap
[1550/2000] tot_loss=1.338 (perp=6.348, rec=0.067, cos=0.001), tot_loss_proj:1.494 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
Attempt swap
[1600/2000] tot_loss=1.341 (perp=6.348, rec=0.070, cos=0.001), tot_loss_proj:1.489 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
[1650/2000] tot_loss=1.333 (perp=6.348, rec=0.062, cos=0.001), tot_loss_proj:1.496 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
Attempt swap
[1700/2000] tot_loss=1.340 (perp=6.348, rec=0.069, cos=0.001), tot_loss_proj:1.497 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
Attempt swap
[1750/2000] tot_loss=1.330 (perp=6.348, rec=0.059, cos=0.001), tot_loss_proj:1.496 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
[1800/2000] tot_loss=1.350 (perp=6.348, rec=0.079, cos=0.001), tot_loss_proj:1.493 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
Attempt swap
[1850/2000] tot_loss=1.335 (perp=6.348, rec=0.064, cos=0.001), tot_loss_proj:1.487 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
Attempt swap
[1900/2000] tot_loss=1.332 (perp=6.348, rec=0.061, cos=0.001), tot_loss_proj:1.485 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
[1950/2000] tot_loss=1.331 (perp=6.348, rec=0.060, cos=0.001), tot_loss_proj:1.494 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
Attempt swap
[2000/2000] tot_loss=1.333 (perp=6.348, rec=0.062, cos=0.001), tot_loss_proj:1.499 [t=0.24s]
prediction: ['[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] absurdhensible, uncouth, vicious and incompmbled [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 88.095

[Aggregate metrics]:
rouge1     | fm: 93.342 | p: 92.907 | r: 93.859
rouge2     | fm: 61.665 | p: 61.410 | r: 61.934
rougeL     | fm: 82.419 | p: 82.029 | r: 82.849
rougeLsum  | fm: 82.431 | p: 82.047 | r: 82.868
r1fm+r2fm = 155.007

input #68 time: 0:09:24 | total time: 10:40:41


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9992906888884341
highest_index [0]
highest [0.9992906888884341]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.0882316827774048 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.945919394493103 for ['[CLS] cade atoms especially suddenly schneider commanded noble retirement causescap meant grin immortals fai act paternal [SEP]']
[Init] best rec loss: 0.930613100528717 for ['[CLS] meetings bells mountain bloody technical script⁄ sarah rebound fare they br hospital christmas value turkmenistan [SEP]']
[Init] best rec loss: 0.9267537593841553 for ['[CLS] et roughly christian cinema angela zoo commanded determinedpine treatcraft said being amountigo ; [SEP]']
[Init] best rec loss: 0.9248879551887512 for ['[CLS] transplant valley true bu golfer grabbed law ee wet especially comics energytics shorter packed hunting [SEP]']
[Init] best rec loss: 0.9164901375770569 for ['[CLS] operation tactics toes collective valley stitches drop criticism insteadivequitable francis surnamezer san zone [SEP]']
[Init] best rec loss: 0.9076429605484009 for ['[CLS] mans border mormon vocational be doubt recordseft outcomes same humor spring chi ears other ling [SEP]']
[Init] best rec loss: 0.8819190859794617 for ['[CLS] tract havinggated libraries himself odd magna courtney jonah tempted miller stunning spit opened french now [SEP]']
[Init] best rec loss: 0.8754848837852478 for ['[CLS]mission down unopposedacio tray adelaide african platform burnham ferrisest port case [MASK] gross main [SEP]']
[Init] best perm rec loss: 0.8741894364356995 for ['[CLS] [MASK]acio burnham platformest gross adelaide case unopposed ferris tray down africanmission main port [SEP]']
[Init] best perm rec loss: 0.8735032677650452 for ['[CLS]acio african tray burnham adelaide ferris gross port unopposed case [MASK] main platform downestmission [SEP]']
[Init] best perm rec loss: 0.8721978068351746 for ['[CLS] case platform portmission african adelaide tray mainacio ferrisest [MASK] burnham gross down unopposed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.222 (perp=9.756, rec=0.267, cos=0.004), tot_loss_proj:2.678 [t=0.23s]
prediction: ['[CLS] touching hilarious smart ; smart. robert ways honest observed another tale 1!,. [SEP]']
[ 100/2000] tot_loss=1.867 (perp=8.342, rec=0.197, cos=0.002), tot_loss_proj:2.456 [t=0.24s]
prediction: ['[CLS] funny subtle winner ; smart - and smart smart apply real and, ; and. [SEP]']
[ 150/2000] tot_loss=1.970 (perp=9.117, rec=0.145, cos=0.002), tot_loss_proj:2.484 [t=0.24s]
prediction: ['[CLS] funnyona winner a smart - and smart smartante real and - -,. [SEP]']
[ 200/2000] tot_loss=1.952 (perp=9.049, rec=0.140, cos=0.002), tot_loss_proj:2.568 [t=0.24s]
prediction: ['[CLS] plusona winner a smart - - subtle subtleante real and - real,. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.076 (perp=9.701, rec=0.134, cos=0.002), tot_loss_proj:2.605 [t=0.24s]
prediction: ['[CLS] funny a winnerona smart - and subtle subtle located real,nt real,. [SEP]']
[ 300/2000] tot_loss=2.058 (perp=9.701, rec=0.116, cos=0.002), tot_loss_proj:2.603 [t=0.24s]
prediction: ['[CLS] funny a winnerona smart - and subtle subtle located real,nt real,. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.864 (perp=8.759, rec=0.110, cos=0.002), tot_loss_proj:2.336 [t=0.24s]
prediction: ['[CLS]. a winnerona smart - and subtle subtle famous real,nt real, funny [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.830 (perp=8.629, rec=0.102, cos=0.002), tot_loss_proj:2.447 [t=0.24s]
prediction: ['[CLS]. a winneronant - and subtle subtle famous real, smart real, n [SEP]']
[ 450/2000] tot_loss=1.889 (perp=8.922, rec=0.103, cos=0.002), tot_loss_proj:3.811 [t=0.24s]
prediction: ['[CLS]. a winneronant - and res subtle corrupt real, smart real, n [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.779 (perp=8.399, rec=0.097, cos=0.002), tot_loss_proj:2.302 [t=0.24s]
prediction: ['[CLS]. a winner resonant - and subtle palo real, smart real, n [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.676 (perp=7.909, rec=0.092, cos=0.002), tot_loss_proj:2.138 [t=0.24s]
prediction: ['[CLS] a winner. resonant - and subtle palo real, smart real, n [SEP]']
[ 600/2000] tot_loss=1.675 (perp=7.909, rec=0.092, cos=0.002), tot_loss_proj:2.142 [t=0.24s]
prediction: ['[CLS] a winner. resonant - and subtle palo real, smart real, n [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.633 (perp=7.661, rec=0.099, cos=0.002), tot_loss_proj:2.089 [t=0.24s]
prediction: ['[CLS] a winner. resonant - subtle and palo real, smart real, n [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.552 (perp=7.268, rec=0.097, cos=0.002), tot_loss_proj:1.928 [t=0.24s]
prediction: ['[CLS] a winner. resonant and subtle - palo real, smart real, n [SEP]']
[ 750/2000] tot_loss=1.559 (perp=7.268, rec=0.104, cos=0.002), tot_loss_proj:1.937 [t=0.24s]
prediction: ['[CLS] a winner. resonant and subtle - palo real, smart real, n [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.516 (perp=7.114, rec=0.092, cos=0.002), tot_loss_proj:1.796 [t=0.24s]
prediction: ['[CLS] a winner. resonant and subtle - palo real, smart, real n [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.506 (perp=7.000, rec=0.104, cos=0.002), tot_loss_proj:1.796 [t=0.24s]
prediction: ['[CLS] a winner. resonant and subtle - palo real, real, smart n [SEP]']
[ 900/2000] tot_loss=1.581 (perp=7.464, rec=0.087, cos=0.002), tot_loss_proj:1.913 [t=0.24s]
prediction: ['[CLS] a winner. resonant and subtle - palo real, real, smart res [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.547 (perp=7.268, rec=0.091, cos=0.002), tot_loss_proj:1.800 [t=0.24s]
prediction: ['[CLS] a winner. resonant and subtle - ami funny, real, smart res [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.647 (perp=7.769, rec=0.092, cos=0.002), tot_loss_proj:1.979 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - palo subtle, real, smart res [SEP]']
[1050/2000] tot_loss=1.463 (perp=6.811, rec=0.099, cos=0.002), tot_loss_proj:1.723 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - ami subtle, real, smart res [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.399 (perp=6.510, rec=0.096, cos=0.002), tot_loss_proj:1.654 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - ami subtle, smart, real res [SEP]']
Attempt swap
[1150/2000] tot_loss=1.397 (perp=6.510, rec=0.093, cos=0.002), tot_loss_proj:1.641 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - ami subtle, smart, real res [SEP]']
[1200/2000] tot_loss=1.393 (perp=6.510, rec=0.089, cos=0.002), tot_loss_proj:1.649 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - ami subtle, smart, real res [SEP]']
Attempt swap
[1250/2000] tot_loss=1.397 (perp=6.510, rec=0.093, cos=0.002), tot_loss_proj:1.648 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - ami subtle, smart, real res [SEP]']
Attempt swap
[1300/2000] tot_loss=1.396 (perp=6.510, rec=0.092, cos=0.002), tot_loss_proj:1.654 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - ami subtle, smart, real res [SEP]']
[1350/2000] tot_loss=1.393 (perp=6.510, rec=0.090, cos=0.002), tot_loss_proj:1.652 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - ami subtle, smart, real res [SEP]']
Attempt swap
[1400/2000] tot_loss=1.399 (perp=6.510, rec=0.095, cos=0.002), tot_loss_proj:1.654 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - ami subtle, smart, real res [SEP]']
Attempt swap
[1450/2000] tot_loss=1.397 (perp=6.510, rec=0.093, cos=0.002), tot_loss_proj:1.646 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - ami subtle, smart, real res [SEP]']
[1500/2000] tot_loss=1.502 (perp=7.087, rec=0.083, cos=0.002), tot_loss_proj:1.766 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - famous subtle, smart, real res [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.581 (perp=7.426, rec=0.094, cos=0.002), tot_loss_proj:1.845 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - palo, subtle smart, real res [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.576 (perp=7.392, rec=0.096, cos=0.002), tot_loss_proj:1.840 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - palo, smart, subtle real res [SEP]']
[1650/2000] tot_loss=1.450 (perp=6.822, rec=0.084, cos=0.002), tot_loss_proj:1.711 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - famous, smart, subtle real res [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.431 (perp=6.675, rec=0.094, cos=0.002), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - famous, real smart, subtle res [SEP]']
Attempt swap
[1750/2000] tot_loss=1.424 (perp=6.675, rec=0.088, cos=0.002), tot_loss_proj:1.687 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - famous, real smart, subtle res [SEP]']
[1800/2000] tot_loss=1.424 (perp=6.675, rec=0.087, cos=0.002), tot_loss_proj:1.688 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - famous, real smart, subtle res [SEP]']
Attempt swap
[1850/2000] tot_loss=1.428 (perp=6.675, rec=0.092, cos=0.002), tot_loss_proj:1.685 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - famous, real smart, subtle res [SEP]']
Attempt swap
[1900/2000] tot_loss=1.425 (perp=6.675, rec=0.088, cos=0.002), tot_loss_proj:1.691 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - famous, real smart, subtle res [SEP]']
[1950/2000] tot_loss=1.424 (perp=6.675, rec=0.088, cos=0.002), tot_loss_proj:1.682 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - famous, real smart, subtle res [SEP]']
Attempt swap
[2000/2000] tot_loss=1.424 (perp=6.675, rec=0.087, cos=0.002), tot_loss_proj:1.689 [t=0.24s]
prediction: ['[CLS] a winner. resonant and funny - famous, real smart, subtle res [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] a winner. resonant and funny - ami subtle, smart, real res [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 83.333 | r: 100.000
rouge2     | fm: 10.000 | p: 9.091 | r: 11.111
rougeL     | fm: 54.545 | p: 50.000 | r: 60.000
rougeLsum  | fm: 54.545 | p: 50.000 | r: 60.000
r1fm+r2fm = 100.909

[Aggregate metrics]:
rouge1     | fm: 93.269 | p: 92.747 | r: 93.948
rouge2     | fm: 60.758 | p: 60.545 | r: 61.081
rougeL     | fm: 81.981 | p: 81.578 | r: 82.558
rougeLsum  | fm: 82.034 | p: 81.601 | r: 82.511
r1fm+r2fm = 154.027

input #69 time: 0:09:25 | total time: 10:50:06


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.999374729045543
highest_index [0]
highest [0.999374729045543]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8474195003509521 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.8209116458892822 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7967671751976013 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7394418716430664 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best perm rec loss: 0.7338972091674805 for ['[CLS] detention technological sharma herself blood mark effects [SEP]']
[Init] best perm rec loss: 0.7322249412536621 for ['[CLS] blood sharma herself effects mark detention technological [SEP]']
[Init] best perm rec loss: 0.7319478988647461 for ['[CLS] mark herself sharma effects technological detention blood [SEP]']
[Init] best perm rec loss: 0.731513500213623 for ['[CLS] effects sharma blood detention herself technological mark [SEP]']
[Init] best perm rec loss: 0.7302557826042175 for ['[CLS] sharma mark herself technological detention effects blood [SEP]']
[Init] best perm rec loss: 0.7295522689819336 for ['[CLS] mark sharma herself technological detention effects blood [SEP]']
[Init] best perm rec loss: 0.7283495664596558 for ['[CLS] herself sharma effects detention technological mark blood [SEP]']
[Init] best perm rec loss: 0.7259199619293213 for ['[CLS] detention sharma herself blood effects technological mark [SEP]']
[Init] best perm rec loss: 0.7253750562667847 for ['[CLS] detention sharma mark blood technological herself effects [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.180 (perp=14.111, rec=0.330, cos=0.028), tot_loss_proj:3.896 [t=0.23s]
prediction: ['[CLS] endsunk lowunkunk happening little [SEP]']
[ 100/2000] tot_loss=2.702 (perp=12.330, rec=0.218, cos=0.018), tot_loss_proj:3.503 [t=0.24s]
prediction: ['[CLS] gets screen clunkunk screenunk [SEP]']
[ 150/2000] tot_loss=2.398 (perp=11.226, rec=0.146, cos=0.007), tot_loss_proj:2.977 [t=0.24s]
prediction: ['[CLS] gets screen clunkunk ony [SEP]']
[ 200/2000] tot_loss=2.353 (perp=11.226, rec=0.103, cos=0.005), tot_loss_proj:3.013 [t=0.24s]
prediction: ['[CLS] gets screen clunkunk ony [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.845 (perp=8.391, rec=0.154, cos=0.013), tot_loss_proj:2.219 [t=0.24s]
prediction: ['[CLS] gets on screen clunkunky [SEP]']
[ 300/2000] tot_loss=1.792 (perp=8.391, rec=0.110, cos=0.004), tot_loss_proj:2.235 [t=0.24s]
prediction: ['[CLS] gets on screen clunkunky [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.625 (perp=7.667, rec=0.088, cos=0.003), tot_loss_proj:2.351 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.613 (perp=7.667, rec=0.077, cos=0.003), tot_loss_proj:2.348 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 450/2000] tot_loss=1.617 (perp=7.667, rec=0.081, cos=0.002), tot_loss_proj:2.347 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.614 (perp=7.667, rec=0.078, cos=0.003), tot_loss_proj:2.345 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.613 (perp=7.667, rec=0.077, cos=0.003), tot_loss_proj:2.351 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 600/2000] tot_loss=1.613 (perp=7.667, rec=0.078, cos=0.002), tot_loss_proj:2.341 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.605 (perp=7.667, rec=0.070, cos=0.002), tot_loss_proj:2.351 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.617 (perp=7.667, rec=0.082, cos=0.002), tot_loss_proj:2.352 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 750/2000] tot_loss=1.600 (perp=7.667, rec=0.064, cos=0.002), tot_loss_proj:2.357 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.599 (perp=7.667, rec=0.063, cos=0.002), tot_loss_proj:2.343 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.619 (perp=7.667, rec=0.084, cos=0.002), tot_loss_proj:2.354 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[ 900/2000] tot_loss=1.608 (perp=7.667, rec=0.073, cos=0.002), tot_loss_proj:2.350 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.602 (perp=7.667, rec=0.067, cos=0.002), tot_loss_proj:2.350 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.602 (perp=7.667, rec=0.067, cos=0.002), tot_loss_proj:2.359 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1050/2000] tot_loss=1.598 (perp=7.667, rec=0.063, cos=0.002), tot_loss_proj:2.345 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.605 (perp=7.667, rec=0.070, cos=0.002), tot_loss_proj:2.348 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.606 (perp=7.667, rec=0.071, cos=0.002), tot_loss_proj:2.346 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1200/2000] tot_loss=1.604 (perp=7.667, rec=0.069, cos=0.002), tot_loss_proj:2.353 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.606 (perp=7.667, rec=0.071, cos=0.002), tot_loss_proj:2.349 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.611 (perp=7.667, rec=0.075, cos=0.002), tot_loss_proj:2.354 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1350/2000] tot_loss=1.613 (perp=7.667, rec=0.078, cos=0.002), tot_loss_proj:2.352 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.607 (perp=7.667, rec=0.072, cos=0.002), tot_loss_proj:2.346 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.610 (perp=7.667, rec=0.075, cos=0.002), tot_loss_proj:2.351 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1500/2000] tot_loss=1.609 (perp=7.667, rec=0.073, cos=0.002), tot_loss_proj:2.358 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.611 (perp=7.667, rec=0.075, cos=0.002), tot_loss_proj:2.356 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.606 (perp=7.667, rec=0.071, cos=0.002), tot_loss_proj:2.352 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1650/2000] tot_loss=1.600 (perp=7.667, rec=0.065, cos=0.002), tot_loss_proj:2.356 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.615 (perp=7.667, rec=0.080, cos=0.002), tot_loss_proj:2.353 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.609 (perp=7.667, rec=0.074, cos=0.002), tot_loss_proj:2.346 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1800/2000] tot_loss=1.601 (perp=7.667, rec=0.066, cos=0.002), tot_loss_proj:2.355 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.610 (perp=7.667, rec=0.075, cos=0.002), tot_loss_proj:2.363 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.610 (perp=7.667, rec=0.075, cos=0.002), tot_loss_proj:2.348 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
[1950/2000] tot_loss=1.611 (perp=7.667, rec=0.076, cos=0.002), tot_loss_proj:2.348 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.610 (perp=7.667, rec=0.074, cos=0.002), tot_loss_proj:2.348 [t=0.24s]
prediction: ['[CLS] gets on screenunk clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] gets on screenunk clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 18.182 | p: 20.000 | r: 16.667
rougeL     | fm: 61.538 | p: 66.667 | r: 57.143
rougeLsum  | fm: 61.538 | p: 66.667 | r: 57.143
r1fm+r2fm = 95.105

[Aggregate metrics]:
rouge1     | fm: 93.098 | p: 92.649 | r: 93.663
rouge2     | fm: 60.324 | p: 60.095 | r: 60.558
rougeL     | fm: 81.761 | p: 81.362 | r: 82.198
rougeLsum  | fm: 81.662 | p: 81.255 | r: 82.153
r1fm+r2fm = 153.421

input #70 time: 0:09:25 | total time: 10:59:32


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9993408837696341
highest_index [0]
highest [0.9993408837696341]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8875375986099243 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.844735324382782 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8433874845504761 for ['[CLS] fed to radar county sun gunshot parchment waiting regional wallacewo dia [CLS] smiles fantasy [SEP]']
[Init] best rec loss: 0.8301323652267456 for ['[CLS] shoulders protocol powerfulfication sash jonas obligatory definition box thorough whole except visit flanked dated [SEP]']
[Init] best rec loss: 0.8257005214691162 for ['[CLS] cidloubridge living blues republicfl projections transition rally mere torpedo spellingcio espn [SEP]']
[Init] best rec loss: 0.8135210871696472 for ['[CLS] mutual internal travel grief with album careful item serious european either warp spoil waived every [SEP]']
[Init] best perm rec loss: 0.8111921548843384 for ['[CLS] serious album every either internal waived european grief warp travel mutual spoil item with careful [SEP]']
[Init] best perm rec loss: 0.809777557849884 for ['[CLS] either mutual travel warp album every grief with careful waived serious spoil european internal item [SEP]']
[Init] best perm rec loss: 0.8083569407463074 for ['[CLS] grief with careful serious warp every item internal mutual either waived album travel european spoil [SEP]']
[Init] best perm rec loss: 0.8064085245132446 for ['[CLS] serious mutual grief warp album european waived travel internal with spoil every item either careful [SEP]']
[Init] best perm rec loss: 0.8064031004905701 for ['[CLS] mutual every item with grief travel careful european serious warp waived spoil either album internal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.733 (perp=11.732, rec=0.350, cos=0.036), tot_loss_proj:3.522 [t=0.24s]
prediction: ['[CLS] activity every lines moment odd jump modeal one spark moment h p - not [SEP]']
[ 100/2000] tot_loss=2.080 (perp=9.104, rec=0.236, cos=0.023), tot_loss_proj:2.979 [t=0.24s]
prediction: ['[CLS] early - moment moment two jump moment hence single jump moment - u - not [SEP]']
[ 150/2000] tot_loss=2.384 (perp=10.974, rec=0.175, cos=0.013), tot_loss_proj:3.439 [t=0.24s]
prediction: ['[CLS] coast - moment moment your jump moment isn single jump moment - his - not [SEP]']
[ 200/2000] tot_loss=1.903 (perp=8.756, rec=0.145, cos=0.008), tot_loss_proj:3.178 [t=0.24s]
prediction: ['[CLS] there a - moment your jump seat is single jump moment - your - not [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.842 (perp=8.334, rec=0.164, cos=0.011), tot_loss_proj:3.097 [t=0.24s]
prediction: ['[CLS] there a single moment your jump seat and - seat moment - your - not [SEP]']
[ 300/2000] tot_loss=1.876 (perp=8.755, rec=0.120, cos=0.005), tot_loss_proj:3.271 [t=0.24s]
prediction: ['[CLS] there there single moment your jump seat and - seat moment - your - not [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.671 (perp=7.892, rec=0.090, cos=0.002), tot_loss_proj:3.131 [t=0.24s]
prediction: ['[CLS] there s single moment - your jump seat and seat moment - in - not [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.625 (perp=7.725, rec=0.079, cos=0.001), tot_loss_proj:3.223 [t=0.24s]
prediction: ['[CLS] there s a single moment your jump seat and seat moment - in - not [SEP]']
[ 450/2000] tot_loss=1.621 (perp=7.738, rec=0.072, cos=0.001), tot_loss_proj:3.034 [t=0.24s]
prediction: ['[CLS] there s a single moment your jump - and seat moment - in - not [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.494 (perp=7.108, rec=0.071, cos=0.001), tot_loss_proj:2.846 [t=0.24s]
prediction: ['[CLS] there s a single moment and jump - your seat moment - in - not [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.427 (perp=6.771, rec=0.070, cos=0.002), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] there s a single moment and jump - your seat - - in moment not [SEP]']
[ 600/2000] tot_loss=1.425 (perp=6.771, rec=0.070, cos=0.001), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] there s a single moment and jump - your seat - - in moment not [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.368 (perp=6.516, rec=0.063, cos=0.001), tot_loss_proj:2.925 [t=0.24s]
prediction: ['[CLS] there s a single moment - and jump your seat - - in moment not [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.344 (perp=6.375, rec=0.068, cos=0.001), tot_loss_proj:2.909 [t=0.24s]
prediction: ['[CLS] there s a single moment in and jump your seat - - - moment not [SEP]']
[ 750/2000] tot_loss=1.343 (perp=6.375, rec=0.067, cos=0.001), tot_loss_proj:2.906 [t=0.24s]
prediction: ['[CLS] there s a single moment in and jump your seat - - - moment not [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.311 (perp=6.241, rec=0.061, cos=0.001), tot_loss_proj:2.488 [t=0.24s]
prediction: ['[CLS] there s a single moment in jump and your seat - - - moment not [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.314 (perp=6.241, rec=0.065, cos=0.001), tot_loss_proj:2.490 [t=0.24s]
prediction: ['[CLS] there s a single moment in jump and your seat - - - moment not [SEP]']
[ 900/2000] tot_loss=1.303 (perp=6.241, rec=0.054, cos=0.001), tot_loss_proj:2.490 [t=0.24s]
prediction: ['[CLS] there s a single moment in jump and your seat - - - moment not [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.300 (perp=6.152, rec=0.069, cos=0.001), tot_loss_proj:2.975 [t=0.24s]
prediction: ['[CLS] there s a single moment and jump in your seat - - - moment not [SEP]']
Attempt swap
[1000/2000] tot_loss=1.294 (perp=6.152, rec=0.062, cos=0.001), tot_loss_proj:2.979 [t=0.24s]
prediction: ['[CLS] there s a single moment and jump in your seat - - - moment not [SEP]']
[1050/2000] tot_loss=1.300 (perp=6.152, rec=0.068, cos=0.001), tot_loss_proj:2.983 [t=0.24s]
prediction: ['[CLS] there s a single moment and jump in your seat - - - moment not [SEP]']
Attempt swap
[1100/2000] tot_loss=1.297 (perp=6.152, rec=0.066, cos=0.001), tot_loss_proj:2.980 [t=0.24s]
prediction: ['[CLS] there s a single moment and jump in your seat - - - moment not [SEP]']
Attempt swap
[1150/2000] tot_loss=1.294 (perp=6.152, rec=0.062, cos=0.001), tot_loss_proj:2.977 [t=0.24s]
prediction: ['[CLS] there s a single moment and jump in your seat - - - moment not [SEP]']
[1200/2000] tot_loss=1.299 (perp=6.152, rec=0.067, cos=0.001), tot_loss_proj:2.978 [t=0.24s]
prediction: ['[CLS] there s a single moment and jump in your seat - - - moment not [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.266 (perp=5.959, rec=0.073, cos=0.001), tot_loss_proj:1.804 [t=0.24s]
prediction: ['[CLS] there s not a single - and jump in your seat - - - moment [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.287 (perp=6.068, rec=0.072, cos=0.002), tot_loss_proj:2.067 [t=0.24s]
prediction: ['[CLS] there s not a single and jump seat in your seat - - - moment [SEP]']
[1350/2000] tot_loss=1.284 (perp=6.068, rec=0.069, cos=0.001), tot_loss_proj:2.071 [t=0.24s]
prediction: ['[CLS] there s not a single and jump seat in your seat - - - moment [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.249 (perp=5.868, rec=0.074, cos=0.001), tot_loss_proj:1.881 [t=0.24s]
prediction: ['[CLS] there s not a single jump and seat in your seat - - - moment [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.242 (perp=5.868, rec=0.066, cos=0.001), tot_loss_proj:1.886 [t=0.24s]
prediction: ['[CLS] there s not a single jump and seat in your seat - - - moment [SEP]']
[1500/2000] tot_loss=1.239 (perp=5.868, rec=0.064, cos=0.001), tot_loss_proj:1.891 [t=0.24s]
prediction: ['[CLS] there s not a single jump and seat in your seat - - - moment [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.185 (perp=5.532, rec=0.077, cos=0.001), tot_loss_proj:1.825 [t=0.24s]
prediction: ['[CLS] and there s not a single jump seat in your seat - - - moment [SEP]']
Attempt swap
[1600/2000] tot_loss=1.176 (perp=5.532, rec=0.068, cos=0.001), tot_loss_proj:1.831 [t=0.24s]
prediction: ['[CLS] and there s not a single jump seat in your seat - - - moment [SEP]']
[1650/2000] tot_loss=1.177 (perp=5.532, rec=0.069, cos=0.001), tot_loss_proj:1.824 [t=0.24s]
prediction: ['[CLS] and there s not a single jump seat in your seat - - - moment [SEP]']
Attempt swap
[1700/2000] tot_loss=1.171 (perp=5.532, rec=0.063, cos=0.001), tot_loss_proj:1.830 [t=0.24s]
prediction: ['[CLS] and there s not a single jump seat in your seat - - - moment [SEP]']
Attempt swap
[1750/2000] tot_loss=1.167 (perp=5.532, rec=0.059, cos=0.001), tot_loss_proj:1.828 [t=0.24s]
prediction: ['[CLS] and there s not a single jump seat in your seat - - - moment [SEP]']
[1800/2000] tot_loss=1.173 (perp=5.532, rec=0.065, cos=0.001), tot_loss_proj:1.831 [t=0.24s]
prediction: ['[CLS] and there s not a single jump seat in your seat - - - moment [SEP]']
Attempt swap
[1850/2000] tot_loss=1.170 (perp=5.532, rec=0.062, cos=0.001), tot_loss_proj:1.822 [t=0.24s]
prediction: ['[CLS] and there s not a single jump seat in your seat - - - moment [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.099 (perp=5.104, rec=0.076, cos=0.001), tot_loss_proj:1.623 [t=0.24s]
prediction: ['[CLS] and there s not a single jump in your seat - - - - moment [SEP]']
[1950/2000] tot_loss=1.161 (perp=5.470, rec=0.065, cos=0.001), tot_loss_proj:1.589 [t=0.24s]
prediction: ['[CLS] and there s not a single jump in your seat - - - seat moment [SEP]']
Attempt swap
[2000/2000] tot_loss=1.160 (perp=5.470, rec=0.065, cos=0.001), tot_loss_proj:1.594 [t=0.24s]
prediction: ['[CLS] and there s not a single jump in your seat - - - seat moment [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] there s not a single jump and seat in your seat - - - moment [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.296 | p: 92.857 | r: 100.000
rouge2     | fm: 72.000 | p: 69.231 | r: 75.000
rougeL     | fm: 88.889 | p: 85.714 | r: 92.308
rougeLsum  | fm: 88.889 | p: 85.714 | r: 92.308
r1fm+r2fm = 168.296

[Aggregate metrics]:
rouge1     | fm: 93.155 | p: 92.673 | r: 93.752
rouge2     | fm: 60.592 | p: 60.330 | r: 60.895
rougeL     | fm: 81.838 | p: 81.464 | r: 82.307
rougeLsum  | fm: 81.847 | p: 81.460 | r: 82.330
r1fm+r2fm = 153.747

input #71 time: 0:09:26 | total time: 11:08:58


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9992332805099025
highest_index [0]
highest [0.9992332805099025]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7866917848587036 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7584322690963745 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7510275840759277 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7389710545539856 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.7389072179794312 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7173200249671936 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7166939377784729 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.7151522636413574 for ['[CLS] zone except orbital walking! ta support dna vanungen pork accidentally lifeboat nonetheless reserve [SEP]']
[Init] best perm rec loss: 0.7150953412055969 for ['[CLS] lifeboat support accidentallyungen zone nonetheless reserve ta orbital van dna! walking except pork [SEP]']
[Init] best perm rec loss: 0.7140606045722961 for ['[CLS] reserve ta nonetheless walking dna van orbital support except pork! zone lifeboatungen accidentally [SEP]']
[Init] best perm rec loss: 0.7136176228523254 for ['[CLS] pork reserve ta nonetheless walking! van lifeboat exceptungen orbital support dna zone accidentally [SEP]']
[Init] best perm rec loss: 0.7135342955589294 for ['[CLS] ta lifeboat accidentally van! walking zone except nonetheless dna orbital support reserveungen pork [SEP]']
[Init] best perm rec loss: 0.7135124802589417 for ['[CLS] reserve zone lifeboat walking pork support except dna van nonetheless ta! accidentally orbitalungen [SEP]']
[Init] best perm rec loss: 0.7132373452186584 for ['[CLS] zoneungen nonetheless walking van dna pork orbital lifeboat accidentally ta except reserve! support [SEP]']
[Init] best perm rec loss: 0.7126136422157288 for ['[CLS] lifeboat supportungen van! accidentally reserve ta dna pork except zone orbital walking nonetheless [SEP]']
[Init] best perm rec loss: 0.7125565409660339 for ['[CLS]! walking nonetheless pork van accidentally dna lifeboat reserveungen zone orbital ta except support [SEP]']
[Init] best perm rec loss: 0.7125199437141418 for ['[CLS] walking pork lifeboat nonetheless zone accidentally dna! reserve supportungen van ta orbital except [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.849 (perp=12.637, rec=0.302, cos=0.019), tot_loss_proj:4.076 [t=0.24s]
prediction: ['[CLS] beat his tough a grey balance tough literary theatre beans figured - having wing scientific [SEP]']
[ 100/2000] tot_loss=2.169 (perp=9.847, rec=0.190, cos=0.010), tot_loss_proj:3.702 [t=0.24s]
prediction: ['[CLS] beat has tough time tough balancing tough violence philosophybert has a balancing time philosophy [SEP]']
[ 150/2000] tot_loss=2.037 (perp=9.532, rec=0.127, cos=0.004), tot_loss_proj:3.246 [t=0.24s]
prediction: ['[CLS] beat has tough time its balancing tough its violencefk has a balancing with philosophy [SEP]']
[ 200/2000] tot_loss=2.208 (perp=10.509, rec=0.102, cos=0.003), tot_loss_proj:3.214 [t=0.24s]
prediction: ['[CLS]ed haser time its balancing tough its violencefk ( a balancing with philosophy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.042 (perp=9.813, rec=0.077, cos=0.002), tot_loss_proj:3.304 [t=0.24s]
prediction: ['[CLS] inspired haser time its balancing tough its violencefk ( balancing with a philosophy [SEP]']
[ 300/2000] tot_loss=2.054 (perp=9.813, rec=0.090, cos=0.002), tot_loss_proj:3.324 [t=0.24s]
prediction: ['[CLS] inspired haser time its balancing tough its violencefk ( balancing with a philosophy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.931 (perp=9.239, rec=0.082, cos=0.002), tot_loss_proj:3.232 [t=0.24s]
prediction: ['[CLS] inspired haser its time balancing tough its violencefk ( balancing with a philosophy [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.801 (perp=8.604, rec=0.078, cos=0.002), tot_loss_proj:2.713 [t=0.24s]
prediction: ['[CLS] inspired haser its tough time balancing its violencefk ( balancing with a philosophy [SEP]']
[ 450/2000] tot_loss=1.793 (perp=8.604, rec=0.071, cos=0.001), tot_loss_proj:2.722 [t=0.24s]
prediction: ['[CLS] inspired haser its tough time balancing its violencefk ( balancing with a philosophy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.720 (perp=8.218, rec=0.075, cos=0.001), tot_loss_proj:2.804 [t=0.24s]
prediction: ['[CLS] inspireder has its tough time balancing its violencefk (a with a philosophy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.903 (perp=9.057, rec=0.089, cos=0.003), tot_loss_proj:2.946 [t=0.24s]
prediction: ['[CLS] inspireder hasact tough time balancing its violencefka - with a philosophy [SEP]']
[ 600/2000] tot_loss=1.789 (perp=8.581, rec=0.071, cos=0.001), tot_loss_proj:3.056 [t=0.24s]
prediction: ['[CLS] inspireder hasfs tough time balancing its violencefka - with a philosophy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.744 (perp=8.318, rec=0.078, cos=0.002), tot_loss_proj:2.565 [t=0.24s]
prediction: ['[CLS] inspireder hasfs tough time balancing its violencefka philosophy with a - [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.669 (perp=7.981, rec=0.071, cos=0.001), tot_loss_proj:2.260 [t=0.24s]
prediction: ['[CLS] inspirederfs has tough time balancing its violencefka philosophy with a - [SEP]']
[ 750/2000] tot_loss=1.659 (perp=7.981, rec=0.062, cos=0.001), tot_loss_proj:2.250 [t=0.24s]
prediction: ['[CLS] inspirederfs has tough time balancing its violencefka philosophy with a - [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.631 (perp=7.818, rec=0.066, cos=0.001), tot_loss_proj:2.161 [t=0.24s]
prediction: ['[CLS] inspirederact has a tough time balancing its violencefka philosophy with - [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.519 (perp=7.255, rec=0.067, cos=0.002), tot_loss_proj:2.066 [t=0.24s]
prediction: ['[CLS]er inspiredact has a tough time balancing its violencefka philosophy with - [SEP]']
[ 900/2000] tot_loss=1.523 (perp=7.255, rec=0.070, cos=0.001), tot_loss_proj:2.073 [t=0.24s]
prediction: ['[CLS]er inspiredact has a tough time balancing its violencefka philosophy with - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.524 (perp=7.255, rec=0.072, cos=0.002), tot_loss_proj:2.071 [t=0.24s]
prediction: ['[CLS]er inspiredact has a tough time balancing its violencefka philosophy with - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.523 (perp=7.255, rec=0.071, cos=0.001), tot_loss_proj:2.059 [t=0.24s]
prediction: ['[CLS]er inspiredact has a tough time balancing its violencefka philosophy with - [SEP]']
[1050/2000] tot_loss=1.520 (perp=7.255, rec=0.068, cos=0.002), tot_loss_proj:2.066 [t=0.24s]
prediction: ['[CLS]er inspiredact has a tough time balancing its violencefka philosophy with - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.520 (perp=7.255, rec=0.068, cos=0.002), tot_loss_proj:2.057 [t=0.24s]
prediction: ['[CLS]er inspiredact has a tough time balancing its violencefka philosophy with - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.530 (perp=7.255, rec=0.077, cos=0.002), tot_loss_proj:2.060 [t=0.24s]
prediction: ['[CLS]er inspiredact has a tough time balancing its violencefka philosophy with - [SEP]']
[1200/2000] tot_loss=1.629 (perp=7.782, rec=0.071, cos=0.002), tot_loss_proj:2.404 [t=0.24s]
prediction: ['[CLS]er inspired respects has a tough time balancing its violencefka philosophy with - [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.530 (perp=7.231, rec=0.083, cos=0.001), tot_loss_proj:2.038 [t=0.24s]
prediction: ['[CLS]acter inspired has a tough time balancing its violencefka philosophy with - [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.461 (perp=6.980, rec=0.063, cos=0.001), tot_loss_proj:2.143 [t=0.24s]
prediction: ['[CLS]acter has inspired a tough time balancing its violencefka philosophy with - [SEP]']
[1350/2000] tot_loss=1.455 (perp=6.980, rec=0.058, cos=0.002), tot_loss_proj:2.137 [t=0.24s]
prediction: ['[CLS]acter has inspired a tough time balancing its violencefka philosophy with - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.468 (perp=6.980, rec=0.071, cos=0.002), tot_loss_proj:2.132 [t=0.24s]
prediction: ['[CLS]acter has inspired a tough time balancing its violencefka philosophy with - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.472 (perp=6.980, rec=0.075, cos=0.001), tot_loss_proj:2.133 [t=0.24s]
prediction: ['[CLS]acter has inspired a tough time balancing its violencefka philosophy with - [SEP]']
[1500/2000] tot_loss=1.464 (perp=6.980, rec=0.066, cos=0.002), tot_loss_proj:2.146 [t=0.24s]
prediction: ['[CLS]acter has inspired a tough time balancing its violencefka philosophy with - [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.389 (perp=6.647, rec=0.058, cos=0.001), tot_loss_proj:2.149 [t=0.24s]
prediction: ['[CLS]acter has inspired a tough time balancing itsfka philosophy with violence - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.395 (perp=6.647, rec=0.064, cos=0.001), tot_loss_proj:2.152 [t=0.24s]
prediction: ['[CLS]acter has inspired a tough time balancing itsfka philosophy with violence - [SEP]']
[1650/2000] tot_loss=1.400 (perp=6.647, rec=0.069, cos=0.001), tot_loss_proj:2.150 [t=0.24s]
prediction: ['[CLS]acter has inspired a tough time balancing itsfka philosophy with violence - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.392 (perp=6.647, rec=0.061, cos=0.001), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS]acter has inspired a tough time balancing itsfka philosophy with violence - [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.336 (perp=6.289, rec=0.077, cos=0.002), tot_loss_proj:1.855 [t=0.24s]
prediction: ['[CLS]acter has a tough time balancing itsfka inspired philosophy with violence - [SEP]']
[1800/2000] tot_loss=1.323 (perp=6.289, rec=0.063, cos=0.001), tot_loss_proj:1.854 [t=0.24s]
prediction: ['[CLS]acter has a tough time balancing itsfka inspired philosophy with violence - [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.315 (perp=6.184, rec=0.077, cos=0.001), tot_loss_proj:1.811 [t=0.24s]
prediction: ['[CLS]acter has a tough time balancing itsfka philosophy with violence - inspired [SEP]']
Attempt swap
[1900/2000] tot_loss=1.305 (perp=6.184, rec=0.067, cos=0.001), tot_loss_proj:1.810 [t=0.24s]
prediction: ['[CLS]acter has a tough time balancing itsfka philosophy with violence - inspired [SEP]']
[1950/2000] tot_loss=1.309 (perp=6.184, rec=0.071, cos=0.001), tot_loss_proj:1.812 [t=0.24s]
prediction: ['[CLS]acter has a tough time balancing itsfka philosophy with violence - inspired [SEP]']
Attempt swap
[2000/2000] tot_loss=1.303 (perp=6.184, rec=0.065, cos=0.001), tot_loss_proj:1.810 [t=0.24s]
prediction: ['[CLS]acter has a tough time balancing itsfka philosophy with violence - inspired [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS]acter has a tough time balancing itsfka philosophy with violence - inspired [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 76.923 | r: 76.923
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 61.538 | p: 61.538 | r: 61.538
rougeLsum  | fm: 61.538 | p: 61.538 | r: 61.538
r1fm+r2fm = 93.590

[Aggregate metrics]:
rouge1     | fm: 92.905 | p: 92.450 | r: 93.513
rouge2     | fm: 59.930 | p: 59.676 | r: 60.185
rougeL     | fm: 81.631 | p: 81.243 | r: 82.100
rougeLsum  | fm: 81.581 | p: 81.185 | r: 82.067
r1fm+r2fm = 152.835

input #72 time: 0:09:30 | total time: 11:18:29


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9991739905462714
highest_index [0]
highest [0.9991739905462714]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9930576682090759 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.970208466053009 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9534759521484375 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9143747687339783 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.911167323589325 for ['[CLS]dicated circles [SEP]']
[Init] best rec loss: 0.8457381725311279 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 0.8437196016311646 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.094 (perp=9.724, rec=0.144, cos=0.005), tot_loss_proj:2.016 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.020 (perp=9.724, rec=0.073, cos=0.002), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.008 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.007 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.001 (perp=9.724, rec=0.054, cos=0.002), tot_loss_proj:2.015 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.011 (perp=9.724, rec=0.065, cos=0.002), tot_loss_proj:2.023 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=1.997 (perp=9.724, rec=0.051, cos=0.002), tot_loss_proj:1.999 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.999 (perp=9.724, rec=0.052, cos=0.002), tot_loss_proj:2.003 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.008 (perp=9.724, rec=0.062, cos=0.002), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.013 (perp=9.724, rec=0.066, cos=0.002), tot_loss_proj:2.001 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.006 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.001 (perp=9.724, rec=0.054, cos=0.002), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.003 (perp=9.724, rec=0.056, cos=0.002), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.004 (perp=9.724, rec=0.058, cos=0.002), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.011 (perp=9.724, rec=0.065, cos=0.002), tot_loss_proj:2.013 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.018 (perp=9.724, rec=0.072, cos=0.002), tot_loss_proj:2.016 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.007 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.004 (perp=9.724, rec=0.057, cos=0.002), tot_loss_proj:2.017 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.012 (perp=9.724, rec=0.065, cos=0.002), tot_loss_proj:2.016 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.006 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=1.999 (perp=9.724, rec=0.052, cos=0.002), tot_loss_proj:2.001 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.000 (perp=9.724, rec=0.054, cos=0.002), tot_loss_proj:2.024 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.001 (perp=9.724, rec=0.055, cos=0.002), tot_loss_proj:2.015 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.006 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.005 (perp=9.724, rec=0.058, cos=0.002), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.008 (perp=9.724, rec=0.061, cos=0.002), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.000 (perp=9.724, rec=0.053, cos=0.002), tot_loss_proj:2.013 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.005 (perp=9.724, rec=0.058, cos=0.002), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.002 (perp=9.724, rec=0.056, cos=0.002), tot_loss_proj:2.003 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.006 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.013 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.004 (perp=9.724, rec=0.057, cos=0.002), tot_loss_proj:2.004 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=1.998 (perp=9.724, rec=0.052, cos=0.002), tot_loss_proj:2.005 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.004 (perp=9.724, rec=0.057, cos=0.002), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.006 (perp=9.724, rec=0.060, cos=0.002), tot_loss_proj:2.020 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.005 (perp=9.724, rec=0.058, cos=0.002), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.009 (perp=9.724, rec=0.063, cos=0.002), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.013 (perp=9.724, rec=0.067, cos=0.002), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.010 (perp=9.724, rec=0.064, cos=0.002), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.000 (perp=9.724, rec=0.054, cos=0.002), tot_loss_proj:2.016 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.000 (perp=9.724, rec=0.054, cos=0.002), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.008 (perp=9.724, rec=0.062, cos=0.002), tot_loss_proj:2.007 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.997 | p: 92.548 | r: 93.604
rouge2     | fm: 60.435 | p: 60.197 | r: 60.721
rougeL     | fm: 81.768 | p: 81.414 | r: 82.228
rougeLsum  | fm: 81.800 | p: 81.390 | r: 82.323
r1fm+r2fm = 153.432

input #73 time: 0:09:20 | total time: 11:27:49


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9992586513675699
highest_index [0]
highest [0.9992586513675699]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.0039318799972534 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6881205439567566 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6577026844024658 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.018 (perp=8.178, rec=0.343, cos=0.039), tot_loss_proj:2.183 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.752 (perp=8.178, rec=0.112, cos=0.004), tot_loss_proj:1.959 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.719 (perp=8.178, rec=0.082, cos=0.002), tot_loss_proj:1.753 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.690 (perp=8.178, rec=0.052, cos=0.002), tot_loss_proj:1.746 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.710 (perp=8.178, rec=0.073, cos=0.002), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.002), tot_loss_proj:1.735 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.002), tot_loss_proj:1.743 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.702 (perp=8.178, rec=0.065, cos=0.002), tot_loss_proj:1.743 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.706 (perp=8.178, rec=0.068, cos=0.002), tot_loss_proj:1.746 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.701 (perp=8.178, rec=0.064, cos=0.001), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.691 (perp=8.178, rec=0.054, cos=0.002), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.725 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.722 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.730 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.713 (perp=8.178, rec=0.076, cos=0.001), tot_loss_proj:1.735 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.690 (perp=8.178, rec=0.053, cos=0.001), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.728 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.001), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.710 (perp=8.178, rec=0.073, cos=0.001), tot_loss_proj:1.728 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.702 (perp=8.178, rec=0.065, cos=0.001), tot_loss_proj:1.733 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.737 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.733 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.710 (perp=8.178, rec=0.073, cos=0.001), tot_loss_proj:1.732 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.682 (perp=8.178, rec=0.044, cos=0.001), tot_loss_proj:1.757 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.686 (perp=8.178, rec=0.049, cos=0.001), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.740 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.719 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.692 (perp=8.178, rec=0.055, cos=0.001), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.001), tot_loss_proj:1.755 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.726 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.001), tot_loss_proj:1.736 [t=0.22s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.733 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.102 | p: 92.630 | r: 93.672
rouge2     | fm: 60.954 | p: 60.711 | r: 61.233
rougeL     | fm: 82.049 | p: 81.676 | r: 82.512
rougeLsum  | fm: 82.000 | p: 81.632 | r: 82.469
r1fm+r2fm = 154.057

input #74 time: 0:08:47 | total time: 11:36:36


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9993457140726361
highest_index [0]
highest [0.9993457140726361]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9596470594406128 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.9503890872001648 for ['[CLS] changed door covert obviously tone sinclair final hard eventdrome apps nick tempo nations diveiii willem nodded rolled [SEP]']
[Init] best rec loss: 0.9403657913208008 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.9036276936531067 for ['[CLS] years public during cup months du sources community ind baseman viz together clinton est frog gum firing points prick [SEP]']
[Init] best rec loss: 0.8985481858253479 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 0.897793173789978 for ['[CLS] brother eco clockizes clint wagon identification % already spirit ceo vampires sighted international version glare contraction eds buck [SEP]']
[Init] best rec loss: 0.8942992091178894 for ['[CLS]orin rearview bore nicky yang dynasty confidence hockey preaching mangrove meanllet ventureix resistance constitution sun nicholas piece [SEP]']
[Init] best rec loss: 0.8870740532875061 for ['[CLS] stir will case bills blocked hand miniseries electricchen words tha batting shed az happen women known gen tourist [SEP]']
[Init] best rec loss: 0.8610764741897583 for ['[CLS]ception resultedrate left fact crown skill apollo auxiliary regardedcl magic to eachmmel viewed stood loop royalties [SEP]']
[Init] best perm rec loss: 0.8609409332275391 for ['[CLS]rate magic viewed apollo crown fact loop resulted auxiliarycl stood each regarded toceptionmmel skill left royalties [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.912 (perp=12.478, rec=0.393, cos=0.024), tot_loss_proj:4.344 [t=0.23s]
prediction: ['[CLS] tree miss passengers secure hardly. indus england knew museum wherevance natalie thewick western today based elsewhere [SEP]']
[ 100/2000] tot_loss=2.559 (perp=11.314, rec=0.281, cos=0.015), tot_loss_proj:4.144 [t=0.24s]
prediction: ['[CLS] rosalie entered passengers easily not. eponymous minor easily located where forgotten ignored the violence persian forgotten not forgotten [SEP]']
[ 150/2000] tot_loss=2.713 (perp=12.495, rec=0.205, cos=0.009), tot_loss_proj:4.380 [t=0.24s]
prediction: ['[CLS] mccarthy entered excursion easily not. instability mental is issn hemingway forgotten smell the easily easily dismissed not dismissed [SEP]']
[ 200/2000] tot_loss=2.463 (perp=11.381, rec=0.180, cos=0.007), tot_loss_proj:4.108 [t=0.24s]
prediction: ['[CLS] mccarthy excursion this easily not. instability mental is excursion hemingway forgotten smell the or easily dismissed not dismissed [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.415 (perp=11.310, rec=0.148, cos=0.004), tot_loss_proj:4.186 [t=0.24s]
prediction: ['[CLS] conclusion excursion this easily is. instability mental is excursion forgotten forgotten instability theny easily dismissed not dismissed [SEP]']
[ 300/2000] tot_loss=2.417 (perp=11.395, rec=0.135, cos=0.003), tot_loss_proj:4.075 [t=0.24s]
prediction: ['[CLS] instability excursion this easily is. instability mental is excursion forgotten forgotten instability theiculate easily dismissed not or [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.299 (perp=10.819, rec=0.131, cos=0.004), tot_loss_proj:4.084 [t=0.24s]
prediction: ['[CLS]. excursion this easily is. instability mental is excursion rainforest activities instability the hated easily dismissed not forgotten [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.167 (perp=10.170, rec=0.130, cos=0.003), tot_loss_proj:3.924 [t=0.24s]
prediction: ['[CLS]. excursion this easily is. instability mental is excursion discus or had paul activities easily dismissed not forgotten [SEP]']
[ 450/2000] tot_loss=2.076 (perp=9.811, rec=0.111, cos=0.002), tot_loss_proj:3.820 [t=0.24s]
prediction: ['[CLS]. excursion this easily is. instability mental is excursion rainforest or a paul or easily dismissed not forgotten [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.007 (perp=9.506, rec=0.103, cos=0.003), tot_loss_proj:3.764 [t=0.24s]
prediction: ['[CLS]. excursion this easily is mental instability. is instability discus or thedorf or easily dismissed not forgotten [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.070 (perp=9.540, rec=0.157, cos=0.005), tot_loss_proj:3.786 [t=0.24s]
prediction: ['[CLS]. excursion this easily is mental instability. is instability discus or thedorf easily dismissed here not forgotten [SEP]']
[ 600/2000] tot_loss=2.028 (perp=9.527, rec=0.121, cos=0.002), tot_loss_proj:3.768 [t=0.24s]
prediction: ['[CLS]. excursion this easily is mental instability. is instability into or thedorf easily dismissed here not forgotten [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.890 (perp=8.973, rec=0.094, cos=0.002), tot_loss_proj:3.702 [t=0.22s]
prediction: ['[CLS]. excursion this easily is mental instability. is instabilityenter or thedorf easily dismissed or not forgotten [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.983 (perp=9.385, rec=0.104, cos=0.002), tot_loss_proj:3.782 [t=0.22s]
prediction: ['[CLS]. excursion this is easily mentalenter. is instabilityenter or thedorf easily dismissed or not forgotten [SEP]']
[ 750/2000] tot_loss=1.972 (perp=9.385, rec=0.093, cos=0.001), tot_loss_proj:3.780 [t=0.22s]
prediction: ['[CLS]. excursion this is easily mentalenter. is instabilityenter or thedorf easily dismissed or not forgotten [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.848 (perp=8.781, rec=0.090, cos=0.001), tot_loss_proj:3.652 [t=0.22s]
prediction: ['[CLS]. this excursion is easily mentalenter. is instabilityenter or thedorf easily dismissed or not forgotten [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.821 (perp=8.623, rec=0.095, cos=0.001), tot_loss_proj:3.623 [t=0.22s]
prediction: ['[CLS]. this excursion is the mentalenter. is instabilityenter or easilydorf easily dismissed or not forgotten [SEP]']
[ 900/2000] tot_loss=1.815 (perp=8.623, rec=0.089, cos=0.001), tot_loss_proj:3.621 [t=0.22s]
prediction: ['[CLS]. this excursion is the mentalenter. is instabilityenter or easilydorf easily dismissed or not forgotten [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.759 (perp=8.360, rec=0.085, cos=0.002), tot_loss_proj:3.609 [t=0.22s]
prediction: ['[CLS]. this excursion is the mentalenter. is instability or easilydorfenter easily dismissed or not forgotten [SEP]']
Attempt swap
[1000/2000] tot_loss=1.730 (perp=8.157, rec=0.097, cos=0.001), tot_loss_proj:3.547 [t=0.22s]
prediction: ['[CLS]. this excursion is the mentalenter. is instability or easilyraveenter easily dismissed or not forgotten [SEP]']
[1050/2000] tot_loss=1.766 (perp=8.345, rec=0.096, cos=0.001), tot_loss_proj:3.588 [t=0.22s]
prediction: ['[CLS]. this excursion is the mentalenter into is instability or easilyraveenter easily dismissed or not forgotten [SEP]']
Attempt swap
Put prefix at the end
[1100/2000] tot_loss=1.654 (perp=7.829, rec=0.086, cos=0.001), tot_loss_proj:3.466 [t=0.22s]
prediction: ['[CLS] this excursion is the mentalenter into is instability or easilyraveenter easily dismissed or not forgotten. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.647 (perp=7.779, rec=0.090, cos=0.001), tot_loss_proj:3.510 [t=0.23s]
prediction: ['[CLS] this excursion is the mentalenter into instability or is easilyraveenter easily dismissed or not forgotten. [SEP]']
[1200/2000] tot_loss=1.727 (perp=8.186, rec=0.089, cos=0.001), tot_loss_proj:3.620 [t=0.22s]
prediction: ['[CLS] this excursion is the mentalenter into instability or is easilyervingenter easily dismissed or not forgotten. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.654 (perp=7.780, rec=0.097, cos=0.001), tot_loss_proj:3.494 [t=0.23s]
prediction: ['[CLS] this excursion is the mentalenter into instability or iservingenter easily dismissed or not easily forgotten. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.575 (perp=7.447, rec=0.085, cos=0.001), tot_loss_proj:3.444 [t=0.22s]
prediction: ['[CLS] this excursionenter is the mentalenter into instability or iserving easily dismissed or not easily forgotten. [SEP]']
[1350/2000] tot_loss=1.575 (perp=7.447, rec=0.084, cos=0.001), tot_loss_proj:3.447 [t=0.22s]
prediction: ['[CLS] this excursionenter is the mentalenter into instability or iserving easily dismissed or not easily forgotten. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.579 (perp=7.447, rec=0.088, cos=0.001), tot_loss_proj:3.443 [t=0.22s]
prediction: ['[CLS] this excursionenter is the mentalenter into instability or iserving easily dismissed or not easily forgotten. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.564 (perp=7.351, rec=0.093, cos=0.001), tot_loss_proj:3.416 [t=0.22s]
prediction: ['[CLS] this excursionenter is theenter into mental instability or iserving easily dismissed or not easily forgotten. [SEP]']
[1500/2000] tot_loss=1.560 (perp=7.351, rec=0.088, cos=0.001), tot_loss_proj:3.416 [t=0.22s]
prediction: ['[CLS] this excursionenter is theenter into mental instability or iserving easily dismissed or not easily forgotten. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.502 (perp=7.066, rec=0.088, cos=0.001), tot_loss_proj:3.372 [t=0.22s]
prediction: ['[CLS] this excursionenter is thecolaenter into mental instability or is easily dismissed or not easily forgotten. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.496 (perp=7.066, rec=0.082, cos=0.001), tot_loss_proj:3.374 [t=0.23s]
prediction: ['[CLS] this excursionenter is thecolaenter into mental instability or is easily dismissed or not easily forgotten. [SEP]']
[1650/2000] tot_loss=1.507 (perp=7.066, rec=0.093, cos=0.001), tot_loss_proj:3.374 [t=0.22s]
prediction: ['[CLS] this excursionenter is thecolaenter into mental instability or is easily dismissed or not easily forgotten. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.494 (perp=7.066, rec=0.079, cos=0.001), tot_loss_proj:3.372 [t=0.22s]
prediction: ['[CLS] this excursionenter is thecolaenter into mental instability or is easily dismissed or not easily forgotten. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.482 (perp=6.962, rec=0.088, cos=0.001), tot_loss_proj:3.279 [t=0.23s]
prediction: ['[CLS] this excursionenter into thecolaenter is mental instability or is easily dismissed or not easily forgotten. [SEP]']
[1800/2000] tot_loss=1.480 (perp=6.962, rec=0.087, cos=0.001), tot_loss_proj:3.274 [t=0.22s]
prediction: ['[CLS] this excursionenter into thecolaenter is mental instability or is easily dismissed or not easily forgotten. [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.457 (perp=6.848, rec=0.086, cos=0.001), tot_loss_proj:3.278 [t=0.23s]
prediction: ['[CLS] this excursion into thecolaenterenter is mental instability or is easily dismissed or not easily forgotten. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.467 (perp=6.848, rec=0.096, cos=0.001), tot_loss_proj:3.274 [t=0.22s]
prediction: ['[CLS] this excursion into thecolaenterenter is mental instability or is easily dismissed or not easily forgotten. [SEP]']
[1950/2000] tot_loss=1.459 (perp=6.848, rec=0.088, cos=0.001), tot_loss_proj:3.276 [t=0.22s]
prediction: ['[CLS] this excursion into thecolaenterenter is mental instability or is easily dismissed or not easily forgotten. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.458 (perp=6.848, rec=0.087, cos=0.001), tot_loss_proj:3.280 [t=0.22s]
prediction: ['[CLS] this excursion into thecolaenterenter is mental instability or is easily dismissed or not easily forgotten. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this excursionenter is the mentalenter into instability or iserving easily dismissed or not easily forgotten. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 70.588 | r: 70.588
rouge2     | fm: 31.250 | p: 31.250 | r: 31.250
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 101.838

[Aggregate metrics]:
rouge1     | fm: 92.816 | p: 92.327 | r: 93.377
rouge2     | fm: 60.530 | p: 60.305 | r: 60.890
rougeL     | fm: 81.647 | p: 81.258 | r: 82.089
rougeLsum  | fm: 81.627 | p: 81.251 | r: 82.100
r1fm+r2fm = 153.345

input #75 time: 0:09:04 | total time: 11:45:41


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9991390736873003
highest_index [0]
highest [0.9991390736873003]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.921407163143158 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.9002844095230103 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 0.8949021100997925 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 0.8901370167732239 for ['[CLS] carrie word 38 saying subject window rican disc anatomy awardscles cf past resisted [SEP]']
[Init] best rec loss: 0.8706420660018921 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 0.8616399168968201 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.8554098606109619 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 0.8517670035362244 for ['[CLS] pushed ( purse onwards lefthaw tautoning surreal hard ab backwardˣ mango [SEP]']
[Init] best perm rec loss: 0.8514449000358582 for ['[CLS] purse backward hard ab taut surreal onwards mango ( lefthaw pushedoningˣ [SEP]']
[Init] best perm rec loss: 0.8474489450454712 for ['[CLS] onwards aboning lefthaw taut ( pushed hardˣ surreal backward mango purse [SEP]']
[Init] best perm rec loss: 0.8473937511444092 for ['[CLS] mangoˣ abhaw purse onwards ( surrealoning hard taut pushed backward left [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.547 (perp=11.052, rec=0.316, cos=0.021), tot_loss_proj:3.628 [t=0.23s]
prediction: ['[CLS] feels had stopped guerrilla when. had challenging. stopped breaks specifically stopped paused [SEP]']
[ 100/2000] tot_loss=2.106 (perp=9.355, rec=0.223, cos=0.011), tot_loss_proj:2.914 [t=0.24s]
prediction: ['[CLS] has had stopped himself when. has challenging, stopped challenging challenging stopped challenging [SEP]']
[ 150/2000] tot_loss=2.048 (perp=9.243, rec=0.192, cos=0.008), tot_loss_proj:2.830 [t=0.24s]
prediction: ['[CLS] like if stopped himself,, has challenging. stopped challenging at stopped challenging [SEP]']
[ 200/2000] tot_loss=2.113 (perp=9.834, rec=0.141, cos=0.006), tot_loss_proj:3.111 [t=0.24s]
prediction: ['[CLS] as if stopped himself,, has alone. stopped 66 challenging stopped challenging [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.033 (perp=9.382, rec=0.150, cos=0.006), tot_loss_proj:2.976 [t=0.24s]
prediction: ['[CLS] as if stopped himself when, has alone stopped 66 at stopped challenging, [SEP]']
[ 300/2000] tot_loss=1.910 (perp=8.901, rec=0.125, cos=0.004), tot_loss_proj:2.848 [t=0.24s]
prediction: ['[CLS] as if stopped himself., has, stopped 66 ( stopped challenging, [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.731 (perp=8.025, rec=0.122, cos=0.004), tot_loss_proj:2.495 [t=0.24s]
prediction: ['[CLS] as if stopped himself., has stopped, 66. stopped challenging, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.054 (perp=8.669, rec=0.299, cos=0.021), tot_loss_proj:2.778 [t=0.24s]
prediction: ['[CLS] as what stopped himself.. has stopped, 66, stop challenging陽 [SEP]']
[ 450/2000] tot_loss=1.999 (perp=8.978, rec=0.196, cos=0.007), tot_loss_proj:3.129 [t=0.24s]
prediction: ['[CLS] as who knees himself quite. has stopped, 66, whether challenging『 [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.145 (perp=9.859, rec=0.167, cos=0.007), tot_loss_proj:3.133 [t=0.24s]
prediction: ['[CLS] as what knees himself. has stopped, 66, whether dallas challenging『 [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.089 (perp=9.683, rec=0.146, cos=0.006), tot_loss_proj:3.515 [t=0.24s]
prediction: ['[CLS] as what knees himself, has stopped, dallas 66, term challenging『 [SEP]']
[ 600/2000] tot_loss=2.077 (perp=9.683, rec=0.136, cos=0.005), tot_loss_proj:3.525 [t=0.24s]
prediction: ['[CLS] as what knees himself, has stopped, dallas 66, term challenging『 [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.020 (perp=9.372, rec=0.141, cos=0.005), tot_loss_proj:3.516 [t=0.23s]
prediction: ['[CLS] as if stopped kn himself, has stopped, dallas 66, challenging『 [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.028 (perp=9.416, rec=0.140, cos=0.005), tot_loss_proj:3.563 [t=0.23s]
prediction: ['[CLS] as if stopped term『 allen has stopped, dallas 66, challenging himself [SEP]']
[ 750/2000] tot_loss=2.019 (perp=9.416, rec=0.132, cos=0.004), tot_loss_proj:3.564 [t=0.23s]
prediction: ['[CLS] as if stopped term『 allen has stopped, dallas 66, challenging himself [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.926 (perp=8.938, rec=0.134, cos=0.004), tot_loss_proj:3.139 [t=0.23s]
prediction: ['[CLS] as if stopped term dallas allen has stopped, 比 66, challenging himself [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.934 (perp=8.998, rec=0.130, cos=0.004), tot_loss_proj:3.506 [t=0.23s]
prediction: ['[CLS] as if sums,. allen has stopped term 比 66, challenging himself [SEP]']
[ 900/2000] tot_loss=1.934 (perp=8.998, rec=0.130, cos=0.004), tot_loss_proj:3.505 [t=0.23s]
prediction: ['[CLS] as if sums,. allen has stopped term 比 66, challenging himself [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.059 (perp=9.706, rec=0.114, cos=0.004), tot_loss_proj:3.433 [t=0.23s]
prediction: ['[CLS] as if sums 比zziness allen has stopped term, 66, challenging himself [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.772 (perp=8.206, rec=0.126, cos=0.005), tot_loss_proj:3.007 [t=0.23s]
prediction: ['[CLS] as if sums 比, allen has stopped. s 66, challenging himself [SEP]']
[1050/2000] tot_loss=1.716 (perp=7.967, rec=0.118, cos=0.004), tot_loss_proj:2.926 [t=0.23s]
prediction: ['[CLS] as if sums 比, allen has stopped.. 66, challenging himself [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.671 (perp=7.710, rec=0.124, cos=0.004), tot_loss_proj:2.870 [t=0.23s]
prediction: ['[CLS] as if 比 sums, allen has stopped.. 66, challenging himself [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.617 (perp=7.413, rec=0.131, cos=0.004), tot_loss_proj:3.016 [t=0.23s]
prediction: ['[CLS] as if 比 sums, allen has stopped. 66, challenging himself. [SEP]']
[1200/2000] tot_loss=1.599 (perp=7.413, rec=0.113, cos=0.004), tot_loss_proj:3.018 [t=0.23s]
prediction: ['[CLS] as if 比 sums, allen has stopped. 66, challenging himself. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.610 (perp=7.413, rec=0.124, cos=0.004), tot_loss_proj:3.019 [t=0.24s]
prediction: ['[CLS] as if 比 sums, allen has stopped. 66, challenging himself. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.629 (perp=7.539, rec=0.118, cos=0.004), tot_loss_proj:3.284 [t=0.24s]
prediction: ['[CLS] as if 比 sums, allen has stopped s 66, challenging himself. [SEP]']
[1350/2000] tot_loss=1.633 (perp=7.539, rec=0.121, cos=0.004), tot_loss_proj:3.282 [t=0.23s]
prediction: ['[CLS] as if 比 sums, allen has stopped s 66, challenging himself. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.625 (perp=7.539, rec=0.113, cos=0.004), tot_loss_proj:3.285 [t=0.23s]
prediction: ['[CLS] as if 比 sums, allen has stopped s 66, challenging himself. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.625 (perp=7.539, rec=0.113, cos=0.004), tot_loss_proj:3.288 [t=0.24s]
prediction: ['[CLS] as if 比 sums, allen has stopped s 66, challenging himself. [SEP]']
[1500/2000] tot_loss=1.642 (perp=7.585, rec=0.121, cos=0.004), tot_loss_proj:3.267 [t=0.23s]
prediction: ['[CLS] as if regarding sums, allen has stopped s 66, challenging himself. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.645 (perp=7.585, rec=0.125, cos=0.004), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] as if regarding sums, allen has stopped s 66, challenging himself. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.642 (perp=7.585, rec=0.121, cos=0.004), tot_loss_proj:3.272 [t=0.24s]
prediction: ['[CLS] as if regarding sums, allen has stopped s 66, challenging himself. [SEP]']
[1650/2000] tot_loss=1.635 (perp=7.585, rec=0.115, cos=0.004), tot_loss_proj:3.269 [t=0.23s]
prediction: ['[CLS] as if regarding sums, allen has stopped s 66, challenging himself. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.641 (perp=7.585, rec=0.120, cos=0.004), tot_loss_proj:3.263 [t=0.23s]
prediction: ['[CLS] as if regarding sums, allen has stopped s 66, challenging himself. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.637 (perp=7.585, rec=0.116, cos=0.004), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] as if regarding sums, allen has stopped s 66, challenging himself. [SEP]']
[1800/2000] tot_loss=1.631 (perp=7.585, rec=0.111, cos=0.004), tot_loss_proj:3.267 [t=0.23s]
prediction: ['[CLS] as if regarding sums, allen has stopped s 66, challenging himself. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.716 (perp=7.995, rec=0.113, cos=0.004), tot_loss_proj:3.404 [t=0.23s]
prediction: ['[CLS] as if regardingpt, allen has stopped s 66, challenging himself. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.701 (perp=7.904, rec=0.116, cos=0.004), tot_loss_proj:3.303 [t=0.23s]
prediction: ['[CLS] as regarding if sums, allen has stopped s 66, challenging himself. [SEP]']
[1950/2000] tot_loss=1.656 (perp=7.705, rec=0.111, cos=0.004), tot_loss_proj:3.426 [t=0.23s]
prediction: ['[CLS] as regarding ifpt, allen has stopped s 66, challenging himself. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.701 (perp=7.893, rec=0.119, cos=0.004), tot_loss_proj:3.317 [t=0.23s]
prediction: ['[CLS] regarding as if sums, allen has stopped s 66, challenging himself. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] as if regarding sums, allen has stopped s 66, challenging himself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 34.783 | p: 33.333 | r: 36.364
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 122.783

[Aggregate metrics]:
rouge1     | fm: 92.674 | p: 92.185 | r: 93.328
rouge2     | fm: 60.196 | p: 59.947 | r: 60.535
rougeL     | fm: 81.512 | p: 81.124 | r: 81.984
rougeLsum  | fm: 81.505 | p: 81.059 | r: 81.987
r1fm+r2fm = 152.870

input #76 time: 0:09:18 | total time: 11:54:59


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9992001897790881
highest_index [0]
highest [0.9992001897790881]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.9115081429481506 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8812075853347778 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.872740626335144 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 0.8698508143424988 for ['[CLS] grayraphic sheep most purple winno lime sometime medium park ways outside where ole [SEP]']
[Init] best perm rec loss: 0.8668491840362549 for ['[CLS] purple most ole park sometime sheep outside limeno ways win gray medium whereraphic [SEP]']
[Init] best perm rec loss: 0.8652713298797607 for ['[CLS] sometime ole where lime ways park purpleno win medium sheepraphic most outside gray [SEP]']
[Init] best perm rec loss: 0.8633628487586975 for ['[CLS] outside most gray whereraphic mediumno ole sheep sometime ways lime purple park win [SEP]']
[Init] best perm rec loss: 0.8618069887161255 for ['[CLS] purple outsideno where lime park most ole sometime win ways medium sheepraphic gray [SEP]']
[Init] best perm rec loss: 0.8598276376724243 for ['[CLS] win gray park where sometime medium ole most limeno ways sheep purpleraphic outside [SEP]']
[Init] best perm rec loss: 0.8584883213043213 for ['[CLS] ways park where oleraphic sometime win limeno most purple medium outside gray sheep [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.914 (perp=12.643, rec=0.361, cos=0.025), tot_loss_proj:3.414 [t=0.24s]
prediction: ['[CLS] starsline crystal jets breath above itself fossilla. incorporates sweeting writings foundation [SEP]']
[ 100/2000] tot_loss=2.573 (perp=11.438, rec=0.275, cos=0.011), tot_loss_proj:3.001 [t=0.24s]
prediction: ['[CLS] conceptie believe are feel above life itsla is its wonderful the writings life [SEP]']
[ 150/2000] tot_loss=2.014 (perp=9.000, rec=0.208, cos=0.006), tot_loss_proj:2.700 [t=0.24s]
prediction: ['[CLS] concept its believe life that above life sufiya is its its the material life [SEP]']
[ 200/2000] tot_loss=1.937 (perp=8.693, rec=0.194, cos=0.005), tot_loss_proj:2.523 [t=0.24s]
prediction: ['[CLS] promise its believe life that above life thetem is its dear the material life [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.774 (perp=7.978, rec=0.174, cos=0.005), tot_loss_proj:2.505 [t=0.24s]
prediction: ['[CLS] promise its believe lifears above is its life the life above the material life [SEP]']
[ 300/2000] tot_loss=1.848 (perp=8.386, rec=0.166, cos=0.005), tot_loss_proj:2.498 [t=0.24s]
prediction: ['[CLS] promise its believe lifears above is its life substance life above the material realm [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.722 (perp=7.845, rec=0.148, cos=0.004), tot_loss_proj:2.416 [t=0.24s]
prediction: ['[CLS] promise its believe life is its life thears above life above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.921 (perp=8.932, rec=0.131, cos=0.004), tot_loss_proj:2.561 [t=0.24s]
prediction: ['[CLS] promise its promise life is of lifears that above life wild the material realm [SEP]']
[ 450/2000] tot_loss=1.779 (perp=8.217, rec=0.132, cos=0.003), tot_loss_proj:2.413 [t=0.24s]
prediction: ['[CLS] promise its promise life is of lifears that above life make the material realm [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.740 (perp=8.069, rec=0.122, cos=0.004), tot_loss_proj:2.347 [t=0.24s]
prediction: ['[CLS] promise its promise life is of lifears that asties above the material realm [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.696 (perp=7.832, rec=0.126, cos=0.003), tot_loss_proj:2.239 [t=0.23s]
prediction: ['[CLS] promise its promise that life is of lifears soties above the material realm [SEP]']
[ 600/2000] tot_loss=1.687 (perp=7.832, rec=0.117, cos=0.003), tot_loss_proj:2.239 [t=0.22s]
prediction: ['[CLS] promise its promise that life is of lifears soties above the material realm [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.574 (perp=7.268, rec=0.117, cos=0.003), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] promise its promise that life isars of life soties above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.660 (perp=7.771, rec=0.103, cos=0.003), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] promise its promise that life isars - so lifeties above the material realm [SEP]']
[ 750/2000] tot_loss=1.716 (perp=8.016, rec=0.110, cos=0.003), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] promise its promise that life isars - so lifeation above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.633 (perp=7.647, rec=0.101, cos=0.002), tot_loss_proj:2.316 [t=0.22s]
prediction: ['[CLS] promise its promise that life is -ars so lifeation above the material realm [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.528 (perp=7.171, rec=0.091, cos=0.003), tot_loss_proj:2.058 [t=0.22s]
prediction: ['[CLS] promise its promise that life is of soars lifeation above the material realm [SEP]']
[ 900/2000] tot_loss=1.541 (perp=7.171, rec=0.104, cos=0.002), tot_loss_proj:2.061 [t=0.22s]
prediction: ['[CLS] promise its promise that life is of soars lifeation above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.531 (perp=7.171, rec=0.095, cos=0.002), tot_loss_proj:2.064 [t=0.22s]
prediction: ['[CLS] promise its promise - life is that soars ofation above the material realm [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.443 (perp=6.663, rec=0.107, cos=0.003), tot_loss_proj:1.952 [t=0.22s]
prediction: ['[CLS] promise its promise ofation - life is that soars above the material realm [SEP]']
[1050/2000] tot_loss=1.434 (perp=6.663, rec=0.099, cos=0.002), tot_loss_proj:1.958 [t=0.22s]
prediction: ['[CLS] promise its promise ofation - life is that soars above the material realm [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.395 (perp=6.468, rec=0.100, cos=0.002), tot_loss_proj:1.870 [t=0.23s]
prediction: ['[CLS] promise its promise ofence - is that life soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.434 (perp=6.670, rec=0.097, cos=0.002), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] promise its promise of life believe is thatence soars above the material realm [SEP]']
[1200/2000] tot_loss=1.426 (perp=6.670, rec=0.090, cos=0.002), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS] promise its promise of life believe is thatence soars above the material realm [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.338 (perp=6.177, rec=0.101, cos=0.003), tot_loss_proj:1.658 [t=0.22s]
prediction: ['[CLS] - its promise of life promise is thatence soars above the material realm [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.311 (perp=6.065, rec=0.096, cos=0.002), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] - its promise of life is promise thatence soars above the material realm [SEP]']
[1350/2000] tot_loss=1.578 (perp=7.371, rec=0.101, cos=0.002), tot_loss_proj:1.921 [t=0.22s]
prediction: ['[CLS] - its promise make life is promise thatence soars above the material realm [SEP]']
Attempt swap
Put prefix at the end
[1400/2000] tot_loss=1.482 (perp=6.906, rec=0.099, cos=0.002), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] its promise make life is promise thatence soars above the material realm - [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.407 (perp=6.552, rec=0.094, cos=0.002), tot_loss_proj:1.810 [t=0.23s]
prediction: ['[CLS] its promise that life is promise makeence soars above the material realm - [SEP]']
[1500/2000] tot_loss=1.411 (perp=6.552, rec=0.098, cos=0.002), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] its promise that life is promise makeence soars above the material realm - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.409 (perp=6.552, rec=0.097, cos=0.002), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] its promise that life is promise makeence soars above the material realm - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.409 (perp=6.552, rec=0.097, cos=0.002), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] its promise that life is promise makeence soars above the material realm - [SEP]']
[1650/2000] tot_loss=1.441 (perp=6.729, rec=0.093, cos=0.002), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] its promise that life is promise makeation soars above the material realm - [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.431 (perp=6.646, rec=0.100, cos=0.002), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] its promise that life is promiseence make soars above the material realm - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.431 (perp=6.646, rec=0.100, cos=0.002), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] its promise that life is promiseence make soars above the material realm - [SEP]']
[1800/2000] tot_loss=1.429 (perp=6.646, rec=0.098, cos=0.002), tot_loss_proj:1.815 [t=0.22s]
prediction: ['[CLS] its promise that life is promiseence make soars above the material realm - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.429 (perp=6.646, rec=0.098, cos=0.002), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] its promise that life is promiseence make soars above the material realm - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.424 (perp=6.646, rec=0.093, cos=0.002), tot_loss_proj:1.810 [t=0.22s]
prediction: ['[CLS] its promise that life is promiseence make soars above the material realm - [SEP]']
[1950/2000] tot_loss=1.427 (perp=6.646, rec=0.096, cos=0.002), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] its promise that life is promiseence make soars above the material realm - [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.372 (perp=6.413, rec=0.088, cos=0.002), tot_loss_proj:1.725 [t=0.22s]
prediction: ['[CLS] its promise that life is promise make believe soars above the material realm - [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] its promise that life is promiseence make soars above the material realm - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 89.655 | p: 92.857 | r: 86.667
rouge2     | fm: 37.037 | p: 38.462 | r: 35.714
rougeL     | fm: 68.966 | p: 71.429 | r: 66.667
rougeLsum  | fm: 68.966 | p: 71.429 | r: 66.667
r1fm+r2fm = 126.692

[Aggregate metrics]:
rouge1     | fm: 92.687 | p: 92.195 | r: 93.241
rouge2     | fm: 60.020 | p: 59.782 | r: 60.293
rougeL     | fm: 81.413 | p: 81.041 | r: 81.867
rougeLsum  | fm: 81.410 | p: 80.998 | r: 81.903
r1fm+r2fm = 152.707

input #77 time: 0:09:06 | total time: 12:04:05


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9992701713024241
highest_index [0]
highest [0.9992701713024241]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9870139360427856 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9769070744514465 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8536514043807983 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8296306133270264 for ['[CLS] le screens grant [SEP]']
[Init] best rec loss: 0.8287628889083862 for ['[CLS] lightatics help [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.042 (perp=9.115, rec=0.207, cos=0.011), tot_loss_proj:2.829 [t=0.23s]
prediction: ['[CLS] exit theater theater [SEP]']
[ 100/2000] tot_loss=1.658 (perp=7.958, rec=0.065, cos=0.002), tot_loss_proj:1.697 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 150/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 200/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.002), tot_loss_proj:1.673 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.658 (perp=7.958, rec=0.065, cos=0.001), tot_loss_proj:1.675 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.681 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.651 (perp=7.958, rec=0.058, cos=0.001), tot_loss_proj:1.682 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.670 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.675 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.643 (perp=7.958, rec=0.049, cos=0.001), tot_loss_proj:1.685 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.675 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.639 (perp=7.958, rec=0.046, cos=0.001), tot_loss_proj:1.682 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.642 (perp=7.958, rec=0.049, cos=0.001), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.668 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.658 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.681 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.674 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.672 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.636 (perp=7.958, rec=0.043, cos=0.001), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.651 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.683 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.680 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.678 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.666 (perp=7.958, rec=0.073, cos=0.001), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.679 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.672 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.670 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.642 (perp=7.958, rec=0.049, cos=0.001), tot_loss_proj:1.677 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.644 (perp=7.958, rec=0.051, cos=0.001), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.675 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.664 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.668 (perp=7.958, rec=0.075, cos=0.001), tot_loss_proj:1.669 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.648 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.672 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.647 (perp=7.958, rec=0.053, cos=0.001), tot_loss_proj:1.683 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.643 (perp=7.958, rec=0.050, cos=0.001), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.646 (perp=7.958, rec=0.053, cos=0.001), tot_loss_proj:1.664 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.771 | p: 92.320 | r: 93.371
rouge2     | fm: 60.385 | p: 60.165 | r: 60.706
rougeL     | fm: 81.648 | p: 81.267 | r: 82.137
rougeLsum  | fm: 81.633 | p: 81.277 | r: 82.056
r1fm+r2fm = 153.156

input #78 time: 0:08:56 | total time: 12:13:02


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.999333502749002
highest_index [0]
highest [0.999333502749002]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9713650941848755 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.8481886982917786 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.8465403318405151 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.8365461826324463 for ['[CLS] funslow [SEP]']
[Init] best rec loss: 0.8340138792991638 for ['[CLS] gray should [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.020 (perp=9.381, rec=0.141, cos=0.003), tot_loss_proj:1.950 [t=0.23s]
prediction: ['[CLS] is fascinating [SEP]']
[ 100/2000] tot_loss=1.943 (perp=9.381, rec=0.065, cos=0.001), tot_loss_proj:1.950 [t=0.24s]
prediction: ['[CLS] is fascinating [SEP]']
[ 150/2000] tot_loss=1.945 (perp=9.381, rec=0.067, cos=0.001), tot_loss_proj:1.956 [t=0.24s]
prediction: ['[CLS] is fascinating [SEP]']
[ 200/2000] tot_loss=1.937 (perp=9.381, rec=0.060, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.843 (perp=8.695, rec=0.102, cos=0.002), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.958 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.807 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.947 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.956 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.957 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.952 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.955 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.807 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.956 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.965 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.790 (perp=8.695, rec=0.050, cos=0.001), tot_loss_proj:1.952 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.805 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.963 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.813 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.954 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.803 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.813 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.803 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.949 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.808 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.963 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.950 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.949 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.792 (perp=8.695, rec=0.051, cos=0.001), tot_loss_proj:1.953 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.954 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.812 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.955 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.821 (perp=8.695, rec=0.080, cos=0.001), tot_loss_proj:1.943 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.957 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.796 (perp=8.695, rec=0.055, cos=0.001), tot_loss_proj:1.957 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.797 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.959 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.811 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.958 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.959 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.952 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.802 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.949 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.963 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.794 (perp=8.695, rec=0.054, cos=0.001), tot_loss_proj:1.952 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.953 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.803 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.957 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.836 | p: 92.417 | r: 93.377
rouge2     | fm: 59.696 | p: 59.487 | r: 60.001
rougeL     | fm: 81.519 | p: 81.150 | r: 82.006
rougeLsum  | fm: 81.536 | p: 81.163 | r: 81.968
r1fm+r2fm = 152.532

input #79 time: 0:09:21 | total time: 12:22:24


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9992804445056542
highest_index [0]
highest [0.9992804445056542]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9627042412757874 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9625917673110962 for ['[CLS]sol floor stand now district [SEP]']
[Init] best rec loss: 0.9617151618003845 for ['[CLS]yna snaps california mussolini kicked [SEP]']
[Init] best rec loss: 0.940487802028656 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.929239809513092 for ['[CLS]down frasercake court beta [SEP]']
[Init] best rec loss: 0.9261685013771057 for ['[CLS] western area whilepres took [SEP]']
[Init] best rec loss: 0.9155707359313965 for ["[CLS]'incense kraft it jubilee [SEP]"]
[Init] best perm rec loss: 0.9146585464477539 for ["[CLS] jubilee it'kraft incense [SEP]"]
[Init] best perm rec loss: 0.9138307571411133 for ["[CLS] jubilee it incense'kraft [SEP]"]
[Init] best perm rec loss: 0.9125903844833374 for ["[CLS] it'incense jubilee kraft [SEP]"]
[Init] best perm rec loss: 0.912357747554779 for ["[CLS] it kraft'jubilee incense [SEP]"]
[Init] best perm rec loss: 0.9113789796829224 for ["[CLS] it kraft incense jubilee'[SEP]"]
[Init] best perm rec loss: 0.9109885096549988 for ["[CLS] it jubilee kraft incense'[SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.702 (perp=12.184, rec=0.259, cos=0.007), tot_loss_proj:3.166 [t=0.23s]
prediction: ['[CLS] wise jeff mileszenlay [SEP]']
[ 100/2000] tot_loss=2.307 (perp=10.603, rec=0.182, cos=0.004), tot_loss_proj:3.834 [t=0.24s]
prediction: ['[CLS] wisey mentionedzenzen [SEP]']
[ 150/2000] tot_loss=1.929 (perp=8.977, rec=0.131, cos=0.003), tot_loss_proj:2.439 [t=0.24s]
prediction: ['[CLS] wise, ;zened [SEP]']
[ 200/2000] tot_loss=1.881 (perp=8.782, rec=0.122, cos=0.003), tot_loss_proj:2.390 [t=0.24s]
prediction: ['[CLS] wise,,zened [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.437 (perp=6.600, rec=0.115, cos=0.002), tot_loss_proj:1.385 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 300/2000] tot_loss=1.436 (perp=6.600, rec=0.114, cos=0.002), tot_loss_proj:1.397 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.431 (perp=6.600, rec=0.109, cos=0.002), tot_loss_proj:1.396 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.432 (perp=6.600, rec=0.109, cos=0.002), tot_loss_proj:1.399 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 450/2000] tot_loss=1.418 (perp=6.600, rec=0.096, cos=0.002), tot_loss_proj:1.389 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.423 (perp=6.600, rec=0.100, cos=0.002), tot_loss_proj:1.391 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.413 (perp=6.600, rec=0.091, cos=0.002), tot_loss_proj:1.392 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 600/2000] tot_loss=1.402 (perp=6.600, rec=0.081, cos=0.002), tot_loss_proj:1.394 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.388 (perp=6.600, rec=0.067, cos=0.002), tot_loss_proj:1.391 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.401 (perp=6.600, rec=0.079, cos=0.002), tot_loss_proj:1.395 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 750/2000] tot_loss=1.406 (perp=6.600, rec=0.085, cos=0.002), tot_loss_proj:1.389 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.396 (perp=6.600, rec=0.074, cos=0.002), tot_loss_proj:1.399 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.408 (perp=6.600, rec=0.086, cos=0.002), tot_loss_proj:1.379 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 900/2000] tot_loss=1.406 (perp=6.600, rec=0.085, cos=0.002), tot_loss_proj:1.389 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.409 (perp=6.600, rec=0.087, cos=0.002), tot_loss_proj:1.392 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1000/2000] tot_loss=1.395 (perp=6.600, rec=0.073, cos=0.002), tot_loss_proj:1.394 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[1050/2000] tot_loss=1.401 (perp=6.600, rec=0.080, cos=0.002), tot_loss_proj:1.375 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1100/2000] tot_loss=1.392 (perp=6.600, rec=0.070, cos=0.002), tot_loss_proj:1.384 [t=0.23s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1150/2000] tot_loss=1.397 (perp=6.600, rec=0.075, cos=0.002), tot_loss_proj:1.384 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[1200/2000] tot_loss=1.399 (perp=6.600, rec=0.077, cos=0.002), tot_loss_proj:1.382 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1250/2000] tot_loss=1.402 (perp=6.600, rec=0.080, cos=0.002), tot_loss_proj:1.383 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1300/2000] tot_loss=1.391 (perp=6.600, rec=0.070, cos=0.002), tot_loss_proj:1.379 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[1350/2000] tot_loss=1.391 (perp=6.600, rec=0.070, cos=0.002), tot_loss_proj:1.396 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1400/2000] tot_loss=1.387 (perp=6.600, rec=0.066, cos=0.002), tot_loss_proj:1.390 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1450/2000] tot_loss=1.400 (perp=6.600, rec=0.078, cos=0.002), tot_loss_proj:1.381 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[1500/2000] tot_loss=1.397 (perp=6.600, rec=0.075, cos=0.002), tot_loss_proj:1.372 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1550/2000] tot_loss=1.403 (perp=6.600, rec=0.081, cos=0.002), tot_loss_proj:1.376 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1600/2000] tot_loss=1.408 (perp=6.600, rec=0.086, cos=0.002), tot_loss_proj:1.382 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[1650/2000] tot_loss=1.394 (perp=6.600, rec=0.072, cos=0.002), tot_loss_proj:1.386 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1700/2000] tot_loss=1.390 (perp=6.600, rec=0.069, cos=0.002), tot_loss_proj:1.386 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1750/2000] tot_loss=1.401 (perp=6.600, rec=0.080, cos=0.002), tot_loss_proj:1.386 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[1800/2000] tot_loss=1.398 (perp=6.600, rec=0.076, cos=0.002), tot_loss_proj:1.382 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1850/2000] tot_loss=1.386 (perp=6.600, rec=0.065, cos=0.002), tot_loss_proj:1.390 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1900/2000] tot_loss=1.397 (perp=6.600, rec=0.075, cos=0.002), tot_loss_proj:1.391 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[1950/2000] tot_loss=1.396 (perp=6.600, rec=0.074, cos=0.002), tot_loss_proj:1.385 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[2000/2000] tot_loss=1.392 (perp=6.600, rec=0.070, cos=0.002), tot_loss_proj:1.387 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise, wizened [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.958 | p: 92.524 | r: 93.494
rouge2     | fm: 60.094 | p: 59.777 | r: 60.384
rougeL     | fm: 81.802 | p: 81.480 | r: 82.235
rougeLsum  | fm: 81.688 | p: 81.355 | r: 82.151
r1fm+r2fm = 153.052

input #80 time: 0:09:20 | total time: 12:31:45


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9992872482218231
highest_index [0]
highest [0.9992872482218231]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9009989500045776 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.8568158745765686 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8462851047515869 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8266099095344543 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8195542097091675 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8106294274330139 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 0.7963440418243408 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 0.7945745587348938 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best rec loss: 0.7920742630958557 for ['[CLS] crawl taken grind choice azerbaijan potter [SEP]']
[Init] best perm rec loss: 0.7888742089271545 for ['[CLS] taken choice grind azerbaijan crawl potter [SEP]']
[Init] best perm rec loss: 0.7881178259849548 for ['[CLS] crawl choice potter azerbaijan taken grind [SEP]']
[Init] best perm rec loss: 0.7879045009613037 for ['[CLS] grind crawl taken choice azerbaijan potter [SEP]']
[Init] best perm rec loss: 0.7871419191360474 for ['[CLS] potter crawl taken choice azerbaijan grind [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.776 (perp=11.759, rec=0.382, cos=0.042), tot_loss_proj:3.242 [t=0.23s]
prediction: ['[CLS] is liberal weak a owners fight [SEP]']
[ 100/2000] tot_loss=1.858 (perp=7.868, rec=0.259, cos=0.025), tot_loss_proj:3.366 [t=0.24s]
prediction: ['[CLS] is not least the players player [SEP]']
[ 150/2000] tot_loss=1.804 (perp=8.180, rec=0.161, cos=0.008), tot_loss_proj:3.390 [t=0.24s]
prediction: ['[CLS] is not least most impressive player [SEP]']
[ 200/2000] tot_loss=1.751 (perp=8.180, rec=0.110, cos=0.004), tot_loss_proj:3.395 [t=0.24s]
prediction: ['[CLS] is not least most impressive player [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.729 (perp=8.180, rec=0.090, cos=0.004), tot_loss_proj:3.392 [t=0.24s]
prediction: ['[CLS] is not least most impressive player [SEP]']
[ 300/2000] tot_loss=1.726 (perp=8.180, rec=0.086, cos=0.004), tot_loss_proj:3.393 [t=0.24s]
prediction: ['[CLS] is not least most impressive player [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.002 (perp=9.546, rec=0.089, cos=0.003), tot_loss_proj:2.778 [t=0.24s]
prediction: ['[CLS] is not venue most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.272 (perp=5.977, rec=0.075, cos=0.002), tot_loss_proj:1.337 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 450/2000] tot_loss=1.273 (perp=5.977, rec=0.076, cos=0.001), tot_loss_proj:1.347 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.264 (perp=5.977, rec=0.067, cos=0.001), tot_loss_proj:1.342 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.260 (perp=5.977, rec=0.063, cos=0.001), tot_loss_proj:1.338 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 600/2000] tot_loss=1.266 (perp=5.977, rec=0.070, cos=0.001), tot_loss_proj:1.337 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.256 (perp=5.977, rec=0.059, cos=0.001), tot_loss_proj:1.339 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.261 (perp=5.977, rec=0.064, cos=0.001), tot_loss_proj:1.333 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 750/2000] tot_loss=1.262 (perp=5.977, rec=0.065, cos=0.001), tot_loss_proj:1.338 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.259 (perp=5.977, rec=0.062, cos=0.001), tot_loss_proj:1.338 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.268 (perp=5.977, rec=0.071, cos=0.001), tot_loss_proj:1.340 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.263 (perp=5.977, rec=0.067, cos=0.001), tot_loss_proj:1.344 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.255 (perp=5.977, rec=0.058, cos=0.001), tot_loss_proj:1.336 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.253 (perp=5.977, rec=0.057, cos=0.001), tot_loss_proj:1.337 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.268 (perp=5.977, rec=0.071, cos=0.001), tot_loss_proj:1.345 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.258 (perp=5.977, rec=0.061, cos=0.001), tot_loss_proj:1.337 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.256 (perp=5.977, rec=0.059, cos=0.001), tot_loss_proj:1.343 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.260 (perp=5.977, rec=0.063, cos=0.001), tot_loss_proj:1.338 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.257 (perp=5.977, rec=0.060, cos=0.001), tot_loss_proj:1.334 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.256 (perp=5.977, rec=0.059, cos=0.001), tot_loss_proj:1.334 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.261 (perp=5.977, rec=0.064, cos=0.001), tot_loss_proj:1.333 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.261 (perp=5.977, rec=0.064, cos=0.001), tot_loss_proj:1.336 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.266 (perp=5.977, rec=0.069, cos=0.001), tot_loss_proj:1.340 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.255 (perp=5.977, rec=0.059, cos=0.001), tot_loss_proj:1.337 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.259 (perp=5.977, rec=0.062, cos=0.001), tot_loss_proj:1.347 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.255 (perp=5.977, rec=0.058, cos=0.001), tot_loss_proj:1.342 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.260 (perp=5.977, rec=0.063, cos=0.001), tot_loss_proj:1.341 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.261 (perp=5.977, rec=0.064, cos=0.001), tot_loss_proj:1.340 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.267 (perp=5.977, rec=0.070, cos=0.001), tot_loss_proj:1.341 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.268 (perp=5.977, rec=0.071, cos=0.001), tot_loss_proj:1.337 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.262 (perp=5.977, rec=0.065, cos=0.001), tot_loss_proj:1.335 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.253 (perp=5.977, rec=0.057, cos=0.001), tot_loss_proj:1.331 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.254 (perp=5.977, rec=0.058, cos=0.001), tot_loss_proj:1.340 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.253 (perp=5.977, rec=0.056, cos=0.001), tot_loss_proj:1.337 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.033 | p: 92.614 | r: 93.633
rouge2     | fm: 60.614 | p: 60.399 | r: 60.935
rougeL     | fm: 81.985 | p: 81.638 | r: 82.406
rougeLsum  | fm: 81.975 | p: 81.613 | r: 82.432
r1fm+r2fm = 153.648

input #81 time: 0:09:18 | total time: 12:41:03


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.999280197064362
highest_index [0]
highest [0.999280197064362]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9871094822883606 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9780022501945496 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9488106966018677 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9384766817092896 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9379804730415344 for ['[CLS] provided yards master cases risky wickets aboveflict [SEP]']
[Init] best rec loss: 0.9337881207466125 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 0.8673442602157593 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.826836884021759 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8214476704597473 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8205435276031494 for ['[CLS]furbasket respectiveach role record plumage whoever [SEP]']
[Init] best perm rec loss: 0.819252073764801 for ['[CLS]basket respective whoeverach record rolefur plumage [SEP]']
[Init] best perm rec loss: 0.8188300728797913 for ['[CLS]achbasket whoeverfur record respective plumage role [SEP]']
[Init] best perm rec loss: 0.8187480568885803 for ['[CLS] whoeverbasketfurach respective plumage role record [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.243 (perp=10.203, rec=0.196, cos=0.007), tot_loss_proj:2.795 [t=0.22s]
prediction: ['[CLS] a sloppy sloppy undone its sloppy script undone [SEP]']
[ 100/2000] tot_loss=1.987 (perp=9.358, rec=0.113, cos=0.003), tot_loss_proj:2.355 [t=0.22s]
prediction: ["[CLS] a sloppy'undone by sloppy script undone [SEP]"]
[ 150/2000] tot_loss=1.946 (perp=9.312, rec=0.081, cos=0.002), tot_loss_proj:2.342 [t=0.22s]
prediction: ["[CLS] s sloppy'undone by sloppy script undone [SEP]"]
[ 200/2000] tot_loss=1.965 (perp=9.450, rec=0.073, cos=0.002), tot_loss_proj:2.402 [t=0.22s]
prediction: ['[CLS] s sloppy it undone by sloppy script undone [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.793 (perp=8.631, rec=0.065, cos=0.002), tot_loss_proj:2.082 [t=0.22s]
prediction: ['[CLS] s sloppy it undone by a undone script [SEP]']
[ 300/2000] tot_loss=1.800 (perp=8.631, rec=0.072, cos=0.002), tot_loss_proj:2.086 [t=0.22s]
prediction: ['[CLS] s sloppy it undone by a undone script [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.799 (perp=8.631, rec=0.071, cos=0.002), tot_loss_proj:2.089 [t=0.22s]
prediction: ['[CLS] s sloppy it undone by a undone script [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.785 (perp=8.631, rec=0.057, cos=0.002), tot_loss_proj:2.092 [t=0.22s]
prediction: ['[CLS] s sloppy it undone by a undone script [SEP]']
[ 450/2000] tot_loss=1.796 (perp=8.631, rec=0.068, cos=0.002), tot_loss_proj:2.101 [t=0.22s]
prediction: ['[CLS] s sloppy it undone by a undone script [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.786 (perp=8.631, rec=0.058, cos=0.001), tot_loss_proj:2.087 [t=0.22s]
prediction: ['[CLS] s sloppy it undone by a undone script [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.049 (perp=9.875, rec=0.072, cos=0.001), tot_loss_proj:2.407 [t=0.22s]
prediction: ['[CLS] s sloppy it ª by a undone script [SEP]']
[ 600/2000] tot_loss=2.041 (perp=9.875, rec=0.064, cos=0.001), tot_loss_proj:2.410 [t=0.22s]
prediction: ['[CLS] s sloppy it ª by a undone script [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.962 (perp=9.476, rec=0.065, cos=0.001), tot_loss_proj:2.375 [t=0.22s]
prediction: ['[CLS] it sloppy s ª by a undone script [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.616 (perp=7.681, rec=0.078, cos=0.002), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
[ 750/2000] tot_loss=1.609 (perp=7.681, rec=0.071, cos=0.002), tot_loss_proj:1.753 [t=0.22s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.600 (perp=7.681, rec=0.062, cos=0.002), tot_loss_proj:1.742 [t=0.22s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.609 (perp=7.681, rec=0.071, cos=0.001), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
[ 900/2000] tot_loss=1.607 (perp=7.681, rec=0.070, cos=0.001), tot_loss_proj:1.745 [t=0.22s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.603 (perp=7.681, rec=0.065, cos=0.001), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
Attempt swap
[1000/2000] tot_loss=1.605 (perp=7.681, rec=0.068, cos=0.001), tot_loss_proj:1.751 [t=0.22s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
[1050/2000] tot_loss=1.612 (perp=7.681, rec=0.074, cos=0.001), tot_loss_proj:1.754 [t=0.22s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
Attempt swap
[1100/2000] tot_loss=1.596 (perp=7.681, rec=0.058, cos=0.001), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
Attempt swap
[1150/2000] tot_loss=1.610 (perp=7.681, rec=0.073, cos=0.001), tot_loss_proj:1.762 [t=0.22s]
prediction: ['[CLS] it undone s undone by a sloppy script [SEP]']
[1200/2000] tot_loss=1.678 (perp=8.078, rec=0.061, cos=0.001), tot_loss_proj:1.942 [t=0.22s]
prediction: ["[CLS] it undone s'by a sloppy script [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.461 (perp=6.935, rec=0.072, cos=0.001), tot_loss_proj:1.646 [t=0.22s]
prediction: ["[CLS] it undone's by a sloppy script [SEP]"]
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.198 (perp=5.694, rec=0.057, cos=0.001), tot_loss_proj:1.230 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1350/2000] tot_loss=1.201 (perp=5.694, rec=0.061, cos=0.001), tot_loss_proj:1.234 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.200 (perp=5.694, rec=0.059, cos=0.001), tot_loss_proj:1.231 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.212 (perp=5.694, rec=0.072, cos=0.001), tot_loss_proj:1.229 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1500/2000] tot_loss=1.201 (perp=5.694, rec=0.061, cos=0.001), tot_loss_proj:1.226 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.206 (perp=5.694, rec=0.066, cos=0.001), tot_loss_proj:1.236 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.200 (perp=5.694, rec=0.060, cos=0.001), tot_loss_proj:1.224 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1650/2000] tot_loss=1.191 (perp=5.694, rec=0.051, cos=0.001), tot_loss_proj:1.224 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.200 (perp=5.694, rec=0.060, cos=0.001), tot_loss_proj:1.220 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.189 (perp=5.694, rec=0.048, cos=0.001), tot_loss_proj:1.224 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1800/2000] tot_loss=1.207 (perp=5.694, rec=0.067, cos=0.001), tot_loss_proj:1.230 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.202 (perp=5.694, rec=0.062, cos=0.001), tot_loss_proj:1.240 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.197 (perp=5.694, rec=0.057, cos=0.001), tot_loss_proj:1.226 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
[1950/2000] tot_loss=1.213 (perp=5.694, rec=0.073, cos=0.001), tot_loss_proj:1.220 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.202 (perp=5.694, rec=0.062, cos=0.001), tot_loss_proj:1.240 [t=0.22s]
prediction: ["[CLS] it's undone by a sloppy script [SEP]"]
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.150 | p: 92.700 | r: 93.693
rouge2     | fm: 61.187 | p: 60.966 | r: 61.444
rougeL     | fm: 82.244 | p: 81.900 | r: 82.682
rougeLsum  | fm: 82.237 | p: 81.903 | r: 82.608
r1fm+r2fm = 154.336

input #82 time: 0:08:46 | total time: 12:49:49


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9992437339704883
highest_index [0]
highest [0.9992437339704883]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.9575920701026917 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.9534390568733215 for ['[CLS] consisting hartley lives champions forgotten johnson account integeronal merge [SEP]']
[Init] best rec loss: 0.9510172605514526 for ['[CLS] ben tawork position naked map because sort been season [SEP]']
[Init] best rec loss: 0.9441697001457214 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.8845860362052917 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 0.8710569739341736 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8709710240364075 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.8656304478645325 for ['[CLS] original review giggled field floor arid read beckett cecil i [SEP]']
[Init] best rec loss: 0.8608826398849487 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.8563296794891357 for ['[CLS] ut sighed another tex predicted hooper alsoов toes personally [SEP]']
[Init] best rec loss: 0.8355855941772461 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best rec loss: 0.8123910427093506 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.8044590353965759 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
[Init] best perm rec loss: 0.8041741251945496 for ['[CLS] residence neck follows nearly stew pitch boys comprehensive vice envelope [SEP]']
[Init] best perm rec loss: 0.8038275837898254 for ['[CLS] nearly pitch vice boys neck residence envelope comprehensive follows stew [SEP]']
[Init] best perm rec loss: 0.8033164143562317 for ['[CLS] stew nearly boys follows neck pitch comprehensive vice residence envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.489 (perp=10.520, rec=0.355, cos=0.030), tot_loss_proj:3.207 [t=0.22s]
prediction: ['[CLS] 19 grow. internationalrrie grown being. including 2016 [SEP]']
[ 100/2000] tot_loss=1.941 (perp=8.287, rec=0.270, cos=0.014), tot_loss_proj:2.695 [t=0.22s]
prediction: ['[CLS] 19 knows. grow up growing being. know when [SEP]']
[ 150/2000] tot_loss=2.022 (perp=8.929, rec=0.230, cos=0.006), tot_loss_proj:3.093 [t=0.22s]
prediction: ['[CLS] 19 know when grows up become it that know when [SEP]']
[ 200/2000] tot_loss=2.214 (perp=10.060, rec=0.198, cos=0.004), tot_loss_proj:3.425 [t=0.22s]
prediction: ['[CLS] 19 what when grows be become it that know when [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.862 (perp=8.521, rec=0.155, cos=0.004), tot_loss_proj:3.391 [t=0.22s]
prediction: ['[CLS] ( what when grows be it become it know when [SEP]']
[ 300/2000] tot_loss=1.800 (perp=8.290, rec=0.138, cos=0.004), tot_loss_proj:3.337 [t=0.22s]
prediction: ['[CLS] what what when grows be it when it know when [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.741 (perp=8.093, rec=0.120, cos=0.003), tot_loss_proj:3.180 [t=0.22s]
prediction: ['[CLS] when wants what grows be it become it know when [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.697 (perp=7.882, rec=0.118, cos=0.002), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] when wants what grows it it be it know when [SEP]']
[ 450/2000] tot_loss=1.786 (perp=8.480, rec=0.088, cos=0.002), tot_loss_proj:2.815 [t=0.22s]
prediction: ['[CLS] when wants what grows it it be it know up [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.689 (perp=7.979, rec=0.091, cos=0.002), tot_loss_proj:2.521 [t=0.22s]
prediction: ['[CLS] when wants what grows up it be it know up [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.611 (perp=7.576, rec=0.094, cos=0.002), tot_loss_proj:2.420 [t=0.22s]
prediction: ['[CLS] when wants what grows up it it be it know [SEP]']
[ 600/2000] tot_loss=1.604 (perp=7.576, rec=0.088, cos=0.002), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] when wants what grows up it it be it know [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.499 (perp=7.129, rec=0.072, cos=0.002), tot_loss_proj:2.260 [t=0.22s]
prediction: ['[CLS] when what grows up wants it it be it know [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.436 (perp=6.756, rec=0.083, cos=0.002), tot_loss_proj:2.180 [t=0.22s]
prediction: ['[CLS] when what grows up it wants it be it know [SEP]']
[ 750/2000] tot_loss=1.433 (perp=6.756, rec=0.081, cos=0.001), tot_loss_proj:2.174 [t=0.22s]
prediction: ['[CLS] when what grows up it wants it be it know [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.318 (perp=6.245, rec=0.068, cos=0.002), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it be it know [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.313 (perp=6.245, rec=0.062, cos=0.002), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it be it know [SEP]']
[ 900/2000] tot_loss=1.326 (perp=6.245, rec=0.075, cos=0.002), tot_loss_proj:1.993 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it be it know [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.315 (perp=6.245, rec=0.065, cos=0.001), tot_loss_proj:1.996 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it be it know [SEP]']
Attempt swap
[1000/2000] tot_loss=1.332 (perp=6.245, rec=0.081, cos=0.002), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it be it know [SEP]']
[1050/2000] tot_loss=1.327 (perp=6.245, rec=0.077, cos=0.002), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it be it know [SEP]']
Attempt swap
[1100/2000] tot_loss=1.330 (perp=6.245, rec=0.079, cos=0.002), tot_loss_proj:1.997 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it be it know [SEP]']
Attempt swap
[1150/2000] tot_loss=1.324 (perp=6.245, rec=0.073, cos=0.002), tot_loss_proj:1.992 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it be it know [SEP]']
[1200/2000] tot_loss=1.315 (perp=6.245, rec=0.065, cos=0.002), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it be it know [SEP]']
Attempt swap
[1250/2000] tot_loss=1.322 (perp=6.245, rec=0.072, cos=0.002), tot_loss_proj:1.998 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it be it know [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.211 (perp=5.671, rec=0.075, cos=0.001), tot_loss_proj:1.749 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it to be know [SEP]']
[1350/2000] tot_loss=1.207 (perp=5.671, rec=0.071, cos=0.002), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] what grows up when it wants it to be know [SEP]']
Attempt swap
Put prefix at the end
[1400/2000] tot_loss=1.152 (perp=5.370, rec=0.077, cos=0.002), tot_loss_proj:1.520 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
Attempt swap
[1450/2000] tot_loss=1.153 (perp=5.370, rec=0.078, cos=0.002), tot_loss_proj:1.528 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
[1500/2000] tot_loss=1.152 (perp=5.370, rec=0.077, cos=0.002), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
Attempt swap
[1550/2000] tot_loss=1.144 (perp=5.370, rec=0.069, cos=0.002), tot_loss_proj:1.526 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
Attempt swap
[1600/2000] tot_loss=1.149 (perp=5.370, rec=0.074, cos=0.002), tot_loss_proj:1.528 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
[1650/2000] tot_loss=1.144 (perp=5.370, rec=0.068, cos=0.002), tot_loss_proj:1.534 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
Attempt swap
[1700/2000] tot_loss=1.143 (perp=5.370, rec=0.067, cos=0.002), tot_loss_proj:1.525 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
Attempt swap
[1750/2000] tot_loss=1.144 (perp=5.370, rec=0.068, cos=0.002), tot_loss_proj:1.526 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
[1800/2000] tot_loss=1.147 (perp=5.370, rec=0.071, cos=0.002), tot_loss_proj:1.532 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
Attempt swap
[1850/2000] tot_loss=1.141 (perp=5.370, rec=0.065, cos=0.002), tot_loss_proj:1.527 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
Attempt swap
[1900/2000] tot_loss=1.153 (perp=5.370, rec=0.078, cos=0.002), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
[1950/2000] tot_loss=1.152 (perp=5.370, rec=0.076, cos=0.002), tot_loss_proj:1.529 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
Attempt swap
[2000/2000] tot_loss=1.143 (perp=5.370, rec=0.068, cos=0.002), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] know what grows up when it wants it to be [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what grows up when it wants it to be [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 54.545 | p: 54.545 | r: 54.545
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 154.545

[Aggregate metrics]:
rouge1     | fm: 93.180 | p: 92.747 | r: 93.705
rouge2     | fm: 60.861 | p: 60.682 | r: 61.100
rougeL     | fm: 81.985 | p: 81.671 | r: 82.404
rougeLsum  | fm: 82.090 | p: 81.738 | r: 82.523
r1fm+r2fm = 154.041

input #83 time: 0:08:46 | total time: 12:58:36


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9991129649261612
highest_index [0]
highest [0.9991129649261612]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.927739679813385 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.9178661108016968 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 0.9015358686447144 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8932105898857117 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 0.8898106813430786 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.8857002258300781 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8841055631637573 for ['[CLS]oglaise catholicur prototype issues cheered [SEP]']
[Init] best rec loss: 0.8625176548957825 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8600064516067505 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best perm rec loss: 0.8589123487472534 for ['[CLS] caused infinite ca each goingiter its [SEP]']
[Init] best perm rec loss: 0.8584563136100769 for ['[CLS] going infiniteiter caused each its ca [SEP]']
[Init] best perm rec loss: 0.8573440313339233 for ['[CLS] going each caused its ca infiniteiter [SEP]']
[Init] best perm rec loss: 0.8568987250328064 for ['[CLS] its going infinite ca caused eachiter [SEP]']
[Init] best perm rec loss: 0.8566478490829468 for ['[CLS] caiter going its caused each infinite [SEP]']
[Init] best perm rec loss: 0.8562791347503662 for ['[CLS] ca going infinite its caused eachiter [SEP]']
[Init] best perm rec loss: 0.8562309145927429 for ['[CLS] eachiter going infinite caused ca its [SEP]']
[Init] best perm rec loss: 0.8557958602905273 for ['[CLS]iter infinite each its caused going ca [SEP]']
[Init] best perm rec loss: 0.8551145195960999 for ['[CLS]iter going ca its infinite caused each [SEP]']
[Init] best perm rec loss: 0.8549153208732605 for ['[CLS] going ca caused each itsiter infinite [SEP]']
[Init] best perm rec loss: 0.8547622561454773 for ['[CLS]iter infinite its ca each going caused [SEP]']
[Init] best perm rec loss: 0.8544797897338867 for ['[CLS] causediter infinite its ca going each [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.267 (perp=9.844, rec=0.278, cos=0.020), tot_loss_proj:2.713 [t=0.22s]
prediction: ['[CLS] kid lost thinking lost lost people ability [SEP]']
[ 100/2000] tot_loss=1.982 (perp=9.122, rec=0.152, cos=0.006), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] have lost people to lost think ability [SEP]']
[ 150/2000] tot_loss=1.777 (perp=8.404, rec=0.093, cos=0.002), tot_loss_proj:2.191 [t=0.22s]
prediction: ['[CLS] have lost people to the think ability [SEP]']
[ 200/2000] tot_loss=1.765 (perp=8.404, rec=0.082, cos=0.002), tot_loss_proj:2.183 [t=0.22s]
prediction: ['[CLS] have lost people to the think ability [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.563 (perp=7.467, rec=0.068, cos=0.002), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] have lost people to think the ability [SEP]']
[ 300/2000] tot_loss=1.575 (perp=7.467, rec=0.080, cos=0.002), tot_loss_proj:2.011 [t=0.22s]
prediction: ['[CLS] have lost people to think the ability [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.361 (perp=6.456, rec=0.068, cos=0.002), tot_loss_proj:1.627 [t=0.22s]
prediction: ['[CLS] have lost the ability people to think [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.173 (perp=5.494, rec=0.073, cos=0.002), tot_loss_proj:1.477 [t=0.22s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
[ 450/2000] tot_loss=1.169 (perp=5.494, rec=0.069, cos=0.002), tot_loss_proj:1.475 [t=0.22s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.149 (perp=5.494, rec=0.049, cos=0.002), tot_loss_proj:1.481 [t=0.22s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.038 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 600/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.042 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.999 (perp=4.681, rec=0.061, cos=0.002), tot_loss_proj:1.048 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.037 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=1.007 (perp=4.681, rec=0.069, cos=0.002), tot_loss_proj:1.041 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.039 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.046 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=0.998 (perp=4.681, rec=0.060, cos=0.002), tot_loss_proj:1.045 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.044 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.037 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.042 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=0.998 (perp=4.681, rec=0.060, cos=0.002), tot_loss_proj:1.042 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.033 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=0.999 (perp=4.681, rec=0.061, cos=0.002), tot_loss_proj:1.040 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.041 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.041 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.050 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.034 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.040 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.041 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=0.991 (perp=4.681, rec=0.053, cos=0.002), tot_loss_proj:1.044 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.049 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=0.992 (perp=4.681, rec=0.054, cos=0.002), tot_loss_proj:1.040 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.006 (perp=4.681, rec=0.068, cos=0.002), tot_loss_proj:1.036 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.042 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.048 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=0.996 (perp=4.681, rec=0.058, cos=0.002), tot_loss_proj:1.036 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.041 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=0.989 (perp=4.681, rec=0.051, cos=0.002), tot_loss_proj:1.046 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.032 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.299 | p: 92.890 | r: 93.802
rouge2     | fm: 61.555 | p: 61.339 | r: 61.811
rougeL     | fm: 82.265 | p: 81.939 | r: 82.687
rougeLsum  | fm: 82.189 | p: 81.859 | r: 82.585
r1fm+r2fm = 154.854

input #84 time: 0:08:46 | total time: 13:07:23


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9992370346205339
highest_index [0]
highest [0.9992370346205339]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9693423509597778 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9537092447280884 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.9295451641082764 for ['[CLS] creek i instrumental bottomifnotes kensington military kowalski smoky [SEP]']
[Init] best rec loss: 0.8857548236846924 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8701900839805603 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best perm rec loss: 0.8665063977241516 for ['[CLS] indies backgroundleinthing road laps indianrman fallen defender [SEP]']
[Init] best perm rec loss: 0.8620833158493042 for ['[CLS]lein roadthing defender indianrman indies laps fallen background [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.745 (perp=7.276, rec=0.277, cos=0.013), tot_loss_proj:2.070 [t=0.23s]
prediction: ['[CLS] unfortunately not unfortunately. also not just especially not good [SEP]']
[ 100/2000] tot_loss=1.759 (perp=8.041, rec=0.145, cos=0.005), tot_loss_proj:2.237 [t=0.23s]
prediction: ['[CLS] unfortunately meant,. also also very it not good [SEP]']
[ 150/2000] tot_loss=1.906 (perp=8.572, rec=0.183, cos=0.008), tot_loss_proj:2.358 [t=0.23s]
prediction: ['[CLS] unfortunately unfortunately [ she ‚ also s it not good [SEP]']
[ 200/2000] tot_loss=1.688 (perp=7.780, rec=0.129, cos=0.004), tot_loss_proj:2.102 [t=0.23s]
prediction: ['[CLS] unfortunately. [ & ‚ also s it not good [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.792 (perp=8.249, rec=0.138, cos=0.004), tot_loss_proj:2.343 [t=0.23s]
prediction: ['[CLS] ‚. [ she unfortunately also s it not good [SEP]']
[ 300/2000] tot_loss=1.659 (perp=7.651, rec=0.125, cos=0.003), tot_loss_proj:2.311 [t=0.23s]
prediction: ['[CLS] ‚. [ ( unfortunately also s it not good [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.607 (perp=7.371, rec=0.130, cos=0.003), tot_loss_proj:2.195 [t=0.24s]
prediction: ['[CLS] ‚. [ ( unfortunately also it s not good [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.703 (perp=7.923, rec=0.116, cos=0.003), tot_loss_proj:2.112 [t=0.23s]
prediction: ["[CLS] ‚ very'very unfortunately also it s not good [SEP]"]
[ 450/2000] tot_loss=1.758 (perp=8.299, rec=0.095, cos=0.002), tot_loss_proj:2.184 [t=0.23s]
prediction: ['[CLS] ‚ very ( very unfortunately also it s not good [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.662 (perp=7.769, rec=0.105, cos=0.002), tot_loss_proj:2.223 [t=0.23s]
prediction: ['[CLS] hopeless, very unfortunately also it very s not good [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.483 (perp=6.964, rec=0.088, cos=0.002), tot_loss_proj:2.007 [t=0.23s]
prediction: ['[CLS] very hopeless, unfortunately also it very s not good [SEP]']
[ 600/2000] tot_loss=1.484 (perp=6.964, rec=0.089, cos=0.002), tot_loss_proj:2.016 [t=0.24s]
prediction: ['[CLS] very hopeless, unfortunately also it very s not good [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.436 (perp=6.702, rec=0.094, cos=0.002), tot_loss_proj:1.891 [t=0.23s]
prediction: ['[CLS] very hopeless, unfortunately also it s not very good [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.389 (perp=6.444, rec=0.098, cos=0.002), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] very ‚, unfortunately it also s not very good [SEP]']
[ 750/2000] tot_loss=1.419 (perp=6.578, rec=0.101, cos=0.002), tot_loss_proj:1.708 [t=0.23s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.414 (perp=6.578, rec=0.096, cos=0.002), tot_loss_proj:1.710 [t=0.23s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.413 (perp=6.578, rec=0.095, cos=0.002), tot_loss_proj:1.702 [t=0.23s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
[ 900/2000] tot_loss=1.404 (perp=6.578, rec=0.086, cos=0.002), tot_loss_proj:1.717 [t=0.22s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.403 (perp=6.578, rec=0.085, cos=0.002), tot_loss_proj:1.715 [t=0.22s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
Attempt swap
[1000/2000] tot_loss=1.410 (perp=6.578, rec=0.092, cos=0.002), tot_loss_proj:1.721 [t=0.22s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
[1050/2000] tot_loss=1.399 (perp=6.578, rec=0.081, cos=0.002), tot_loss_proj:1.722 [t=0.22s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
Attempt swap
[1100/2000] tot_loss=1.402 (perp=6.578, rec=0.084, cos=0.002), tot_loss_proj:1.715 [t=0.22s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
Attempt swap
[1150/2000] tot_loss=1.396 (perp=6.578, rec=0.078, cos=0.002), tot_loss_proj:1.716 [t=0.22s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
[1200/2000] tot_loss=1.408 (perp=6.578, rec=0.090, cos=0.002), tot_loss_proj:1.721 [t=0.22s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
Attempt swap
[1250/2000] tot_loss=1.405 (perp=6.578, rec=0.087, cos=0.002), tot_loss_proj:1.709 [t=0.22s]
prediction: ['[CLS] very ª, unfortunately it also s not very good [SEP]']
Attempt swap
[1300/2000] tot_loss=1.304 (perp=6.089, rec=0.084, cos=0.002), tot_loss_proj:1.567 [t=0.22s]
prediction: ['[CLS] very., unfortunately it also s not very good [SEP]']
[1350/2000] tot_loss=1.305 (perp=6.089, rec=0.085, cos=0.002), tot_loss_proj:1.571 [t=0.22s]
prediction: ['[CLS] very., unfortunately it also s not very good [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.268 (perp=5.956, rec=0.075, cos=0.002), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS]. very, unfortunately it also s not very good [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.190 (perp=5.462, rec=0.095, cos=0.002), tot_loss_proj:1.410 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
[1500/2000] tot_loss=1.177 (perp=5.462, rec=0.082, cos=0.002), tot_loss_proj:1.407 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
Attempt swap
[1550/2000] tot_loss=1.180 (perp=5.462, rec=0.086, cos=0.002), tot_loss_proj:1.401 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
Attempt swap
[1600/2000] tot_loss=1.181 (perp=5.462, rec=0.086, cos=0.002), tot_loss_proj:1.400 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
[1650/2000] tot_loss=1.186 (perp=5.462, rec=0.091, cos=0.002), tot_loss_proj:1.400 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
Attempt swap
[1700/2000] tot_loss=1.179 (perp=5.462, rec=0.084, cos=0.002), tot_loss_proj:1.407 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
Attempt swap
[1750/2000] tot_loss=1.172 (perp=5.462, rec=0.078, cos=0.002), tot_loss_proj:1.409 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
[1800/2000] tot_loss=1.187 (perp=5.462, rec=0.092, cos=0.002), tot_loss_proj:1.408 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
Attempt swap
[1850/2000] tot_loss=1.183 (perp=5.462, rec=0.088, cos=0.002), tot_loss_proj:1.402 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
Attempt swap
[1900/2000] tot_loss=1.183 (perp=5.462, rec=0.088, cos=0.002), tot_loss_proj:1.407 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
[1950/2000] tot_loss=1.178 (perp=5.462, rec=0.084, cos=0.002), tot_loss_proj:1.405 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
Attempt swap
[2000/2000] tot_loss=1.181 (perp=5.462, rec=0.086, cos=0.002), tot_loss_proj:1.408 [t=0.22s]
prediction: ['[CLS] very, unfortunately. it also s not very good [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS]. very, unfortunately it also s not very good [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 141.796

[Aggregate metrics]:
rouge1     | fm: 93.337 | p: 92.859 | r: 93.898
rouge2     | fm: 61.296 | p: 61.084 | r: 61.563
rougeL     | fm: 82.250 | p: 81.876 | r: 82.710
rougeLsum  | fm: 82.168 | p: 81.766 | r: 82.638
r1fm+r2fm = 154.633

input #85 time: 0:09:00 | total time: 13:16:24


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9993317485073314
highest_index [0]
highest [0.9993317485073314]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9270456433296204 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9181763529777527 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 0.8563364744186401 for ['[CLS] len tin signals [SEP]']
[Init] best rec loss: 0.7922263145446777 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.7661018371582031 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.758322536945343 for ['[CLS] liberated round alright [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.958 (perp=12.840, rec=0.378, cos=0.012), tot_loss_proj:3.416 [t=0.22s]
prediction: ['[CLS] clarity qualification natural [SEP]']
[ 100/2000] tot_loss=2.745 (perp=12.652, rec=0.209, cos=0.005), tot_loss_proj:3.274 [t=0.22s]
prediction: ['[CLS] clarity clarity sheikh [SEP]']
[ 150/2000] tot_loss=2.705 (perp=12.679, rec=0.165, cos=0.004), tot_loss_proj:3.268 [t=0.22s]
prediction: ['[CLS] clarity emotional bragg [SEP]']
[ 200/2000] tot_loss=2.701 (perp=12.679, rec=0.162, cos=0.003), tot_loss_proj:3.262 [t=0.22s]
prediction: ['[CLS] clarity emotional bragg [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.200 (perp=10.020, rec=0.192, cos=0.004), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS] jess emotional clarity [SEP]']
[ 300/2000] tot_loss=2.141 (perp=10.020, rec=0.134, cos=0.003), tot_loss_proj:2.575 [t=0.22s]
prediction: ['[CLS] jess emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.123 (perp=10.020, rec=0.117, cos=0.003), tot_loss_proj:2.571 [t=0.22s]
prediction: ['[CLS] jess emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.753 (perp=8.211, rec=0.109, cos=0.003), tot_loss_proj:1.888 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 450/2000] tot_loss=1.763 (perp=8.211, rec=0.118, cos=0.002), tot_loss_proj:1.876 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.760 (perp=8.211, rec=0.116, cos=0.002), tot_loss_proj:1.873 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.752 (perp=8.211, rec=0.108, cos=0.002), tot_loss_proj:1.876 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 600/2000] tot_loss=1.738 (perp=8.211, rec=0.093, cos=0.002), tot_loss_proj:1.880 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.749 (perp=8.211, rec=0.105, cos=0.002), tot_loss_proj:1.873 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.745 (perp=8.211, rec=0.100, cos=0.002), tot_loss_proj:1.885 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=1.734 (perp=8.211, rec=0.089, cos=0.002), tot_loss_proj:1.878 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.736 (perp=8.211, rec=0.091, cos=0.002), tot_loss_proj:1.887 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.736 (perp=8.211, rec=0.092, cos=0.002), tot_loss_proj:1.888 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=1.710 (perp=8.211, rec=0.067, cos=0.001), tot_loss_proj:1.870 [t=0.22s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.717 (perp=8.211, rec=0.073, cos=0.001), tot_loss_proj:1.887 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.716 (perp=8.211, rec=0.072, cos=0.001), tot_loss_proj:1.876 [t=0.30s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=1.699 (perp=8.211, rec=0.056, cos=0.001), tot_loss_proj:1.884 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.716 (perp=8.211, rec=0.072, cos=0.001), tot_loss_proj:1.879 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.704 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.886 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=1.706 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.878 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.703 (perp=8.211, rec=0.060, cos=0.001), tot_loss_proj:1.879 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.705 (perp=8.211, rec=0.062, cos=0.001), tot_loss_proj:1.880 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=1.714 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.891 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.702 (perp=8.211, rec=0.058, cos=0.001), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.704 (perp=8.211, rec=0.060, cos=0.001), tot_loss_proj:1.875 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=1.705 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.883 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.714 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.715 (perp=8.211, rec=0.072, cos=0.001), tot_loss_proj:1.878 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=1.707 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.878 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.719 (perp=8.211, rec=0.075, cos=0.001), tot_loss_proj:1.884 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.717 (perp=8.211, rec=0.074, cos=0.001), tot_loss_proj:1.881 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=1.696 (perp=8.211, rec=0.053, cos=0.001), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.715 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.876 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.710 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.875 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=1.705 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.882 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.705 (perp=8.211, rec=0.062, cos=0.001), tot_loss_proj:1.881 [t=0.24s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 93.358 | p: 92.912 | r: 93.968
rouge2     | fm: 60.905 | p: 60.602 | r: 61.123
rougeL     | fm: 82.167 | p: 81.774 | r: 82.666
rougeLsum  | fm: 82.165 | p: 81.854 | r: 82.625
r1fm+r2fm = 154.263

input #86 time: 0:09:04 | total time: 13:25:28


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.999255423401286
highest_index [0]
highest [0.999255423401286]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.8853949308395386 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7531629800796509 for ['[CLS]minate force [SEP]']
[Init] best rec loss: 0.7110209465026855 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.7052863240242004 for ['[CLS] officer yorker [SEP]']
[Init] best rec loss: 0.6955174803733826 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6889923214912415 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6841421127319336 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.679 (perp=7.257, rec=0.217, cos=0.011), tot_loss_proj:1.521 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 100/2000] tot_loss=1.542 (perp=7.257, rec=0.086, cos=0.004), tot_loss_proj:1.540 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.547 (perp=7.257, rec=0.092, cos=0.003), tot_loss_proj:1.526 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.531 (perp=7.257, rec=0.071, cos=0.009), tot_loss_proj:1.527 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.529 (perp=7.257, rec=0.076, cos=0.001), tot_loss_proj:1.519 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.781 (perp=7.257, rec=0.285, cos=0.045), tot_loss_proj:1.516 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.582 (perp=7.257, rec=0.124, cos=0.006), tot_loss_proj:1.516 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.519 (perp=7.257, rec=0.066, cos=0.002), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.520 (perp=7.257, rec=0.067, cos=0.002), tot_loss_proj:1.530 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.526 (perp=7.257, rec=0.073, cos=0.001), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.515 (perp=7.257, rec=0.062, cos=0.001), tot_loss_proj:1.526 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.507 (perp=7.257, rec=0.054, cos=0.001), tot_loss_proj:1.528 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.527 (perp=7.257, rec=0.074, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.518 (perp=7.257, rec=0.065, cos=0.001), tot_loss_proj:1.535 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.534 (perp=7.257, rec=0.081, cos=0.001), tot_loss_proj:1.523 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.519 (perp=7.257, rec=0.066, cos=0.001), tot_loss_proj:1.533 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.526 (perp=7.257, rec=0.073, cos=0.001), tot_loss_proj:1.541 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.510 (perp=7.257, rec=0.058, cos=0.001), tot_loss_proj:1.535 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.517 (perp=7.257, rec=0.064, cos=0.001), tot_loss_proj:1.545 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.517 (perp=7.257, rec=0.064, cos=0.001), tot_loss_proj:1.537 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.506 (perp=7.257, rec=0.053, cos=0.001), tot_loss_proj:1.526 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.510 (perp=7.257, rec=0.057, cos=0.001), tot_loss_proj:1.537 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.504 (perp=7.257, rec=0.051, cos=0.001), tot_loss_proj:1.535 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.518 (perp=7.257, rec=0.066, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.509 (perp=7.257, rec=0.056, cos=0.001), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.518 (perp=7.257, rec=0.065, cos=0.001), tot_loss_proj:1.533 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.513 (perp=7.257, rec=0.060, cos=0.001), tot_loss_proj:1.530 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.518 (perp=7.257, rec=0.065, cos=0.001), tot_loss_proj:1.542 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.506 (perp=7.257, rec=0.053, cos=0.001), tot_loss_proj:1.518 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.514 (perp=7.257, rec=0.061, cos=0.001), tot_loss_proj:1.529 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.528 (perp=7.257, rec=0.075, cos=0.001), tot_loss_proj:1.532 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.510 (perp=7.257, rec=0.057, cos=0.001), tot_loss_proj:1.529 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.530 (perp=7.257, rec=0.077, cos=0.001), tot_loss_proj:1.525 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.517 (perp=7.257, rec=0.064, cos=0.001), tot_loss_proj:1.527 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.505 (perp=7.257, rec=0.052, cos=0.001), tot_loss_proj:1.549 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.516 (perp=7.257, rec=0.063, cos=0.001), tot_loss_proj:1.539 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.522 (perp=7.257, rec=0.069, cos=0.001), tot_loss_proj:1.544 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.498 (perp=7.257, rec=0.045, cos=0.001), tot_loss_proj:1.536 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.518 (perp=7.257, rec=0.065, cos=0.001), tot_loss_proj:1.530 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.510 (perp=7.257, rec=0.057, cos=0.001), tot_loss_proj:1.522 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.435 | p: 92.996 | r: 94.034
rouge2     | fm: 61.278 | p: 61.017 | r: 61.577
rougeL     | fm: 82.486 | p: 82.096 | r: 82.941
rougeLsum  | fm: 82.507 | p: 82.130 | r: 82.947
r1fm+r2fm = 154.713

input #87 time: 0:09:21 | total time: 13:34:50


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.999236260537872
highest_index [0]
highest [0.999236260537872]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9811371564865112 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9442414045333862 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9180505275726318 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.91672682762146 for ['[CLS] signing architectural miss of? tension popbreaker covered versus planning bean single field advanced a lipstickingdon tab shorter dos down luther ki t directors wounded drink people ps animals administrativeari tone geologic international above 18 free dam way software clay [SEP]']
[Init] best rec loss: 0.9156349897384644 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.9042424559593201 for ['[CLS] assistants isbag mighty ll shortagekou subject central printian contract separated eight tick twenties ball how orange victor help fund council key morris lace weight vacancy hungick equipment her goran dvd business gould sidou rector us g moment freud [SEP]']
[Init] best rec loss: 0.903558075428009 for ['[CLS] ) ever rag consideration patentt yes com occasional king clip canyonawan eight whileput say turn tapeless pei dearht watch soon frost constitution mayoicles nursery road will bending ff cathedral soup elect leadership herself byron hospital per post [SEP]']
[Init] best rec loss: 0.8974650502204895 for ['[CLS] designated engine never pondered harmon programs? mandarin according employees legitimate exchanged as elevated piston exodus won machine aunt hadnbbed insanity allowed home landing [UNK] starting ki! signed close today force immortality nets where reform baronet ) network demi observation spanning [SEP]']
[Init] best perm rec loss: 0.8973959684371948 for ['[CLS] harmon demi [UNK] allowed immortality legitimate hadn won pondered programs spanningbbed today machine reform exchanged starting ki designated signed observation engine baronet where force elevated ) close as never landing network? piston exodus aunt employees home mandarin nets! insanity according [SEP]']
[Init] best perm rec loss: 0.8946533799171448 for ['[CLS] allowed baronet aunt as designated [UNK] harmon )! today legitimate where signed reform according spanning demi exchanged observation hadn engine ki piston elevated employees immortality nets machine exodus network pondered home closebbed mandarin never programs won? landing starting force insanity [SEP]']
[Init] best perm rec loss: 0.8944793343544006 for ['[CLS] starting according pondered reform? observationbbed as ki employees engine elevated! today immortality hadn close machine nets landing exchanged spanning harmon allowed [UNK] never aunt insanity piston won legitimate network where mandarin exodus demi programs home force signed ) baronet designated [SEP]']
[Init] best perm rec loss: 0.8942128419876099 for ['[CLS] according programs force where exodus machine elevated allowed spanning hadn today mandarin ki designated ) home won pondered aunt immortality piston nets engine insanity employees landing [UNK] legitimate starting harmon exchangedbbed signed close as never reform network demi observation? baronet! [SEP]']
[Init] best perm rec loss: 0.8941453099250793 for ['[CLS]bbed today ki allowed machine exchanged nets reform harmon home according! close pondered spanning [UNK] legitimate where network aunt programs starting elevated ) never as engine observation force signed baronet mandarin won immortality employees? hadn demi insanity landing exodus piston designated [SEP]']
[Init] best perm rec loss: 0.8934233784675598 for ['[CLS] where networkbbed harmon home ki! engine today immortality mandarin as never pondered designated spanning starting programs demi exodus [UNK] hadn reform observation baronet machine landing piston elevated nets? aunt won legitimate according exchanged allowed employees close force insanity signed ) [SEP]']
[Init] best perm rec loss: 0.8931106328964233 for ['[CLS] today landing machine network designated spanning employees where signed starting ki aunt elevated exchanged exodus nets force allowed insanity according? won demi!bbed engine as hadn mandarin legitimate observation home harmon close pondered baronet never immortality reform programs piston ) [UNK] [SEP]']
[Init] best perm rec loss: 0.8927290439605713 for ['[CLS] as wherebbed close won demi insanity exchanged starting force! employees network harmon elevated programs nets home allowed exodus according hadn legitimate spanning engine reform machine ki [UNK] immortality mandarin observation never designated pondered? today piston landing signed aunt baronet ) [SEP]']
[Init] best perm rec loss: 0.8907408714294434 for ['[CLS] [UNK] according as close observation exodus exchanged? machine demi aunt engine ki employees mandarin signed network today legitimate pondered designated insanity won! ) elevated home spanning where reform harmon allowed starting programs never hadn landing force immortalitybbed piston baronet nets [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.377 (perp=10.384, rec=0.294, cos=0.006), tot_loss_proj:3.725 [t=0.24s]
prediction: ['[CLS] understand never ;, good fiction joined romance : black the modes. english happy bronze jessie york se i skatingeus : love emotional is received love p costs all bad but loveodh knows gets psychic tony was grand world [SEP]']
[ 100/2000] tot_loss=2.450 (perp=11.004, rec=0.246, cos=0.003), tot_loss_proj:3.800 [t=0.24s]
prediction: ['[CLS] understands never of, great texts our romance the vol [CLS] modes. anderson happy l jessie which anderson our´ity : love greatity young wrote p they in. q beautyignantening knows understands cooling pete we grand. [SEP]']
[ 150/2000] tot_loss=2.382 (perp=10.569, rec=0.265, cos=0.003), tot_loss_proj:3.526 [t=0.24s]
prediction: ['[CLS] understands never of and grand urdu our romance the winston of issues. anderson love t ph he anderson our´ity the love greatest the non love p do, whichphi joyturingan aside understands calm alex a grand. [SEP]']
[ 200/2000] tot_loss=2.198 (perp=9.907, rec=0.214, cos=0.003), tot_loss_proj:3.774 [t=0.24s]
prediction: ['[CLS] understands never of, grand thriller our romance the potentially of ill. anderson. t e which anderson our lovesity as love ultimate - per god p shas.phi grand )s easily understands calm t the grand. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.141 (perp=9.718, rec=0.195, cos=0.002), tot_loss_proj:3.739 [t=0.24s]
prediction: ['[CLS] understands never of, grandilation our romance calm dilemma our ill. anderson. t w. anderson our theity bwf romance ultimate - : loveius shas.phi grand )s of could the p the grand. [SEP]']
[ 300/2000] tot_loss=2.111 (perp=9.615, rec=0.186, cos=0.002), tot_loss_proj:3.631 [t=0.24s]
prediction: ['[CLS] understands never of. grandilation our romance calm dilemma of ill. anderson. t w was anderson our theity of romance ultimate our. loveius andersons.phi joyings of could the p the grand. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.032 (perp=9.317, rec=0.167, cos=0.002), tot_loss_proj:3.502 [t=0.24s]
prediction: ['[CLS] understandsphi of and howonale our romance calm dilemma of ill. anderson is t w. anderson. theness the romance ultimate our the love mankind andersons. never joy )ness of could, p the grand. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.874 (perp=8.507, rec=0.171, cos=0.002), tot_loss_proj:3.471 [t=0.24s]
prediction: ['[CLS] understandsphi of and howonale our romance calm dilemma of ill. anderson is t w. anderson. the our the romance daily our the andersons. never joying love mankindness of could the p the grand. [SEP]']
[ 450/2000] tot_loss=1.817 (perp=8.281, rec=0.159, cos=0.002), tot_loss_proj:3.488 [t=0.24s]
prediction: ['[CLS] understandsphi of and howrted our romance calm dilemma of ill. anderson is t w. anderson. the our of romance daily our the andersons. never joying love &ness of could the p the grand. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.815 (perp=8.259, rec=0.162, cos=0.002), tot_loss_proj:3.381 [t=0.24s]
prediction: ['[CLS] understandsphi of and howrted our romance calm joy of ill. anderson is t w a anderson. the our of romance daily our the andersons. neverotericing love mankinds of could the p the grand. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.145 (perp=9.918, rec=0.159, cos=0.002), tot_loss_proj:3.855 [t=0.24s]
prediction: ['[CLS] understandsphi of new how love our romance. joy of ill calm anderson [SEP] t a daily anderson. the our of romance daily ours andersons alternatively never bearingsing love ofs [SEP] could, p the grand. [SEP]']
[ 600/2000] tot_loss=2.034 (perp=9.420, rec=0.148, cos=0.002), tot_loss_proj:3.725 [t=0.24s]
prediction: ['[CLS] understandsphi of grand how love our romance. grand of ill calm anderson is t a daily anderson. the our of romance daily ours andersons alternatively never bearingsing love ofs [SEP] could, p the grand. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.031 (perp=9.392, rec=0.151, cos=0.002), tot_loss_proj:3.715 [t=0.24s]
prediction: ['[CLS] understandsphi of grand how is our romance. grand of ill calm anderson is t a daily anderson. the our love romance daily ours andersons alternatively never bearingsing lives ofs [SEP] coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.975 (perp=9.126, rec=0.148, cos=0.002), tot_loss_proj:3.602 [t=0.24s]
prediction: ['[CLS] understandsphi of grand how is our romance. grand of ills anderson is t a daily anderson. the our love romance daily antis anderson calm alternatively never bearingsing lives ofs [SEP] coulds p the grand. [SEP]']
[ 750/2000] tot_loss=1.920 (perp=8.897, rec=0.139, cos=0.002), tot_loss_proj:3.212 [t=0.24s]
prediction: ['[CLS] understandsphi of grand how is our romance. grand of ills anderson is t a daily anderson. the our love romance daily ares anderson calm we guest bearingsing lives ofs of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.967 (perp=9.124, rec=0.140, cos=0.002), tot_loss_proj:3.502 [t=0.24s]
prediction: ['[CLS] understandsphi of grand how is our romance. daily of ills anderson is t a grand anderson. the us love romance daily ares navigate calm we guest bearingsing lives ofness [SEP] coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.855 (perp=8.559, rec=0.142, cos=0.002), tot_loss_proj:3.478 [t=0.24s]
prediction: ['[CLS] understandsphi of grand anderson is our romance. daily of ills how is t a grand anderson. the us love romance daily ares navigate calm we guest bearingsing lives ofness of coulds p the grand. [SEP]']
[ 900/2000] tot_loss=1.900 (perp=8.788, rec=0.140, cos=0.002), tot_loss_proj:3.572 [t=0.22s]
prediction: ['[CLS] understandsphi of grand anderson is our romance. daily of ill of how is t a grand anderson. the us love romance daily ares opinion calm we guest bearingsing lives ofness of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.797 (perp=8.295, rec=0.137, cos=0.002), tot_loss_proj:3.523 [t=0.22s]
prediction: ['[CLS] understandsphi of grand anderson is our romance. daily of ill of how is t a grand anderson. the us love romance daily calms opinion are we guest bearingsing lives ofness of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.801 (perp=8.335, rec=0.132, cos=0.002), tot_loss_proj:3.411 [t=0.22s]
prediction: ['[CLS] understandsphi of grand anderson is our romance. daily we ill of how of t a grand anderson. the us love romance daily calms viewed are and guest bearingsing lives ofness of coulds p the grand. [SEP]']
[1050/2000] tot_loss=1.887 (perp=8.766, rec=0.133, cos=0.002), tot_loss_proj:3.536 [t=0.22s]
prediction: ['[CLS] understandsphi of grand anderson is our romance. daily we ill of how of t a joy anderson. the us romance romance daily calms opinion are and guest bearingsing lives ofness of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.914 (perp=8.903, rec=0.132, cos=0.002), tot_loss_proj:3.574 [t=0.22s]
prediction: ['[CLS] understandsphi of grand l is our romance. daily we ill of how of t a joy anderson. the us anderson romance daily calms viewed are and guest bearingsing lives ofness of coulds p the grand. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.835 (perp=8.510, rec=0.131, cos=0.002), tot_loss_proj:3.486 [t=0.22s]
prediction: ['[CLS] understandsphi of grand l is our romance. daily we ill of how of t a joy anderson. the anderson romance daily calms opinion are us and guest bearingsing lives ofness of coulds p the grand. [SEP]']
[1200/2000] tot_loss=1.831 (perp=8.510, rec=0.127, cos=0.002), tot_loss_proj:3.488 [t=0.22s]
prediction: ['[CLS] understands will of grand l is our romance. daily we ill of how of t a joy anderson. the anderson romance daily calms solution are us and guest bearingsing lives ofness of coulds p the grand. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.783 (perp=8.249, rec=0.132, cos=0.002), tot_loss_proj:3.446 [t=0.22s]
prediction: ['[CLS] l understands will of grand is our romance. daily we ill of how of t a joy anderson. the anderson romance daily calms never are us and guest bearingsing lives ofness of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.733 (perp=8.001, rec=0.131, cos=0.002), tot_loss_proj:3.357 [t=0.23s]
prediction: ['[CLS] l of will understands grand is our romance. daily we ill of how of t a joy anderson. the anderson romance daily calms never at us and guest bearingsing lives ofness of coulds p the grand. [SEP]']
[1350/2000] tot_loss=1.735 (perp=8.001, rec=0.133, cos=0.002), tot_loss_proj:3.359 [t=0.22s]
prediction: ['[CLS] l of will understands grand is our romance. daily we ill of how of t a joy anderson. the anderson romance daily calms never at us and guest bearingsing lives ofness of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.722 (perp=7.930, rec=0.134, cos=0.002), tot_loss_proj:3.238 [t=0.22s]
prediction: ['[CLS] l of will understands grand is our romance. daily we ill of how of t a joy anderson. the anderson romanceing calms never at us and guest bearings daily lives ofness of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.713 (perp=7.930, rec=0.125, cos=0.002), tot_loss_proj:3.244 [t=0.22s]
prediction: ['[CLS] l of will understands grand is our romance. daily we ill of how of t a joy anderson. the anderson romanceing calms never at us and guest bearings daily lives ofness of coulds p the grand. [SEP]']
[1500/2000] tot_loss=1.718 (perp=7.930, rec=0.131, cos=0.002), tot_loss_proj:3.245 [t=0.22s]
prediction: ['[CLS] l of will understands grand is our romance. daily we ill of how of t a joy anderson. the anderson romanceing calms never at us and guest bearings daily lives ofness of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.718 (perp=7.921, rec=0.132, cos=0.002), tot_loss_proj:3.409 [t=0.22s]
prediction: ['[CLS] l of will understands grand is our romance. daily we ill of how of t a joy anderson. the anderson romanceing calms never at us lives guest bearings daily and ofness of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.703 (perp=7.860, rec=0.129, cos=0.002), tot_loss_proj:3.230 [t=0.23s]
prediction: ['[CLS] l of will understands joy is our romance. daily we ills how of t a grand anderson. the anderson romanceing calms solution at us lives guest bearings daily and ofness of coulds p the grand. [SEP]']
[1650/2000] tot_loss=1.730 (perp=8.009, rec=0.127, cos=0.002), tot_loss_proj:3.386 [t=0.22s]
prediction: ['[CLS] l of will understands joy is our romance. daily we ill of how of t a grand anderson. the anderson romanceing calms refuses at us lives guest bearings daily and ofness of coulds p the grand. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.692 (perp=7.833, rec=0.124, cos=0.002), tot_loss_proj:3.443 [t=0.22s]
prediction: ['[CLS] l of will understands joy is our romance. daily we ill of how of t a grand anderson. the anderson romanceing calms never at us lives guest bearings daily and ofness of coulds p the grand. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.672 (perp=7.735, rec=0.123, cos=0.002), tot_loss_proj:3.440 [t=0.23s]
prediction: ['[CLS] t of will understands joy is our romance. daily we ills how is t a grand anderson. the anderson romanceing never calms of us lives guest bearings daily and ofness of coulds p the grand. [SEP]']
[1800/2000] tot_loss=1.658 (perp=7.664, rec=0.123, cos=0.002), tot_loss_proj:3.399 [t=0.23s]
prediction: ['[CLS] t of will understands joy is our romance. daily we ills how is t a grand anderson. the anderson romanceing never calms in us lives guest bearings daily and ofness of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.645 (perp=7.560, rec=0.131, cos=0.002), tot_loss_proj:3.149 [t=0.23s]
prediction: ['[CLS] l of t understands joy is our romance. daily we ills how of will a grand anderson. the anderson romanceing › calms in us lives guest bearings daily and ofness of coulds p the grand. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.672 (perp=7.699, rec=0.131, cos=0.002), tot_loss_proj:2.895 [t=0.22s]
prediction: ['[CLS] l of t understands joy is our romance. daily we ills how is us a grand anderson. the anderson romanceing › calms in will lives guest bearings daily and ofees of coulds p the grand. [SEP]']
[1950/2000] tot_loss=1.633 (perp=7.503, rec=0.131, cos=0.002), tot_loss_proj:3.111 [t=0.23s]
prediction: ['[CLS] l of t understands joy is our romance. daily we ills how of us a grand anderson. the anderson romanceing › calms in will lives guest bearings daily and ofees of coulds p the grand. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.629 (perp=7.503, rec=0.127, cos=0.002), tot_loss_proj:3.108 [t=0.22s]
prediction: ['[CLS] l of t understands joy is our romance. daily we ills how of us a grand anderson. the anderson romanceing › calms in will lives guest bearings daily and ofees of coulds p the grand. [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] l of will understands joy is our romance. daily we ill of how of t a grand anderson. the anderson romanceing calms never at us lives guest bearings daily and ofness of coulds p the grand. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 52.632 | p: 52.632 | r: 52.632
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 23.684 | p: 23.684 | r: 23.684
rougeLsum  | fm: 23.684 | p: 23.684 | r: 23.684
r1fm+r2fm = 52.632

[Aggregate metrics]:
rouge1     | fm: 93.025 | p: 92.580 | r: 93.584
rouge2     | fm: 60.710 | p: 60.491 | r: 60.979
rougeL     | fm: 81.797 | p: 81.363 | r: 82.292
rougeLsum  | fm: 81.721 | p: 81.345 | r: 82.200
r1fm+r2fm = 153.735

input #88 time: 0:09:13 | total time: 13:44:03


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.999343395556257
highest_index [0]
highest [0.999343395556257]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9671728014945984 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9524257183074951 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.9463364481925964 for ['[CLS] lucraction ditch vin vehicle nights filing wholeierusion above myself capacity easter just bowlpath silver campaign urging draw huntersky operation himself plant bolt gin won ours only object [SEP]']
[Init] best rec loss: 0.9444438219070435 for ['[CLS] georgia phased billie sweetgenase harris troy planet later voting evening while dream campaign infantry burnett cleveland encompassed chromosome pr lovedhi carmine verse foroped giving smoking whip vision race credited [SEP]']
[Init] best rec loss: 0.9345924258232117 for ['[CLS] watt trustingats promisepate weight eight blood happened photograph deaths credited jp wish practicing boysfulfootuded donttemedia broken atomic muttereduating gps leon relatively atari document cutler [SEP]']
[Init] best perm rec loss: 0.934049129486084 for ['[CLS] trusting weight blood boysmediafultte donfoot muttered happenedats atari document practicing photograph eight leon watt cutler gps jp brokenuded credited wish relatively promisepateuating deaths atomic [SEP]']
[Init] best perm rec loss: 0.9338948130607605 for ['[CLS]media watt boys broken promiseats eight document deathsuded weight photograph wishuating trusting gpsfoot ataritte cutlerpate leon atomic relatively muttered jp credited bloodful don practicing happened [SEP]']
[Init] best perm rec loss: 0.9295726418495178 for ['[CLS] promise trusting atomic deaths happeneduatingtteful don blood broken leon wishudedmedia jp document weight relativelyfoot gps photograph credited practicing watt boys muttered eight atariatspate cutler [SEP]']
[Init] best perm rec loss: 0.9289620518684387 for ['[CLS] document broken photograph leonful wish don boys blood trusting jp watt cutler weight practicing atomic promise relativelyudedmedia deaths happened creditedfootuatingpate eight mutteredtte gpsats atari [SEP]']
[Init] best perm rec loss: 0.9262523651123047 for ['[CLS] blood leon atari watt donats cutlerful wishfoot atomic gpsuded eight document relatively photograph mutteredpate promise brokenmedia trustinguating weight jp happened practicingtte credited deaths boys [SEP]']
[Init] best perm rec loss: 0.9256148934364319 for ['[CLS]uating relatively practicing credited muttered happenedtte promise photograph weight boys blood eightuded trustingpate donfootfulats atari broken wish gps document leon cutlermedia watt atomic deaths jp [SEP]']
[Init] best perm rec loss: 0.9249479174613953 for ['[CLS] muttered practicing atomic gps cutlerpate broken deaths documentfootats happened jp eight promise don leontte weightudeduating blood watt atari trusting photograph wish creditedful boys relativelymedia [SEP]']
[Init] best perm rec loss: 0.9242815971374512 for ['[CLS] trusting atariats practicing atomic jp muttered donuating blood promise document cutler deaths broken weight credited watt eight leonpateuded boysful photographfoot gpsmediatte happened wish relatively [SEP]']
[Init] best perm rec loss: 0.9234808683395386 for ['[CLS] atari weight creditedful muttered atomic practicing jp photograph promise don relatively eight trusting wish boys gps document leonatsmediattefoot happenedudedpate blood cutler wattuating deaths broken [SEP]']
[Init] best perm rec loss: 0.9226676225662231 for ['[CLS] weight atariful broken deathstte leonuatingfoot happened wish boys practicing relativelymedia bloodpate eight watt trustingatsuded cutler gps don credited muttered photograph promise atomic jp document [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.573 (perp=11.270, rec=0.310, cos=0.010), tot_loss_proj:3.017 [t=0.22s]
prediction: ["[CLS] tactic to [SEP] piece wrap government file filed him medical is. - had whereck state. worse zeppelin sheet video was worse which this [SEP] worse 'ies liberal information [SEP]"]
[ 100/2000] tot_loss=2.206 (perp=9.811, rec=0.236, cos=0.008), tot_loss_proj:2.651 [t=0.22s]
prediction: ['[CLS] tactic to cover thin cover the picture garion / its is are - yet orck state none worse zeppelin - ( as worse yet essentially worse worse - - teachings ideas [SEP]']
[ 150/2000] tot_loss=1.933 (perp=8.730, rec=0.182, cos=0.005), tot_loss_proj:2.726 [t=0.23s]
prediction: ['[CLS] tactic to cover fact cover up picture minute it around is - - yet or picture state none worse productions - - a worse of none tactic worsen - constructed ideas [SEP]']
[ 200/2000] tot_loss=1.848 (perp=8.475, rec=0.151, cos=0.003), tot_loss_proj:2.265 [t=0.22s]
prediction: ['[CLS] tactic to cover up cover fact picture fact fact around is - - yet or picture - none worse distributed - - a worse of coresy nonexi - constructed ideas [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.384 (perp=10.286, rec=0.312, cos=0.015), tot_loss_proj:2.928 [t=0.23s]
prediction: ['[CLS] tactic to cover up encoded fact picture the it the isaby - yet orxi - none worse and -,. worse around mostly theoretical joker propped - constructed ideas [SEP]']
[ 300/2000] tot_loss=2.257 (perp=9.856, rec=0.278, cos=0.007), tot_loss_proj:3.128 [t=0.22s]
prediction: ['[CLS] tactic to cover up " that picture theboard the containsum` yet or northern - none worse as -,. much backing onlytass micro - conception ideas [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.072 (perp=9.313, rec=0.205, cos=0.004), tot_loss_proj:3.416 [t=0.22s]
prediction: ['[CLS] tactic to cover up the fact picture the tactic the containsum` yet northern or of none worse and -,. none around butiousicites - constructed ideas [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.061 (perp=9.404, rec=0.177, cos=0.003), tot_loss_proj:3.403 [t=0.23s]
prediction: ['[CLS] tactic to cover up the fact picture the cassandra the constructedum yet cape` or - none worse and -,. none around butiousasstes - core ideas [SEP]']
[ 450/2000] tot_loss=1.969 (perp=9.014, rec=0.164, cos=0.003), tot_loss_proj:2.959 [t=0.22s]
prediction: ['[CLS] tactic to cover up the fact picture the tactic the constructedum yet cape` or - none worse and -,. none around orkyasszation - core ideas [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.898 (perp=8.722, rec=0.151, cos=0.002), tot_loss_proj:2.758 [t=0.22s]
prediction: ['[CLS] tactic to cover up the fact picture the constructed the constructedum yet,` or - none worse and - cape. none around orsyquesten - core ideas [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.821 (perp=8.382, rec=0.143, cos=0.002), tot_loss_proj:2.839 [t=0.23s]
prediction: ['[CLS] tactic to cover up the fact picture the core the constructedum yet,` or - none worse and - cavemble around or.sy -sten - core ideas [SEP]']
[ 600/2000] tot_loss=1.819 (perp=8.382, rec=0.140, cos=0.002), tot_loss_proj:2.830 [t=0.22s]
prediction: ['[CLS] tactic to cover up the fact picture the core the constructedum yet,` or - none worse and - cavemble around or.sy -sten - core ideas [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.759 (perp=8.109, rec=0.136, cos=0.002), tot_loss_proj:2.753 [t=0.22s]
prediction: ['[CLS] tactic to cover up the fact picture the core the constructed yetum,` or - none worse and - cave none around or.sy -sten - core ideas [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.719 (perp=7.938, rec=0.130, cos=0.002), tot_loss_proj:2.570 [t=0.23s]
prediction: ['[CLS] tactic to cover up the fact picture the core the yetum constructed,` or - none worse and - cave none around or.sy -sten - core ideas [SEP]']
[ 750/2000] tot_loss=1.781 (perp=8.263, rec=0.127, cos=0.002), tot_loss_proj:2.792 [t=0.22s]
prediction: ['[CLS] tactic to cover up the fact picture the core the yetum constructed,` or - none worse and - caveim around or.sy -sten - core ideas [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.787 (perp=8.295, rec=0.126, cos=0.002), tot_loss_proj:2.914 [t=0.22s]
prediction: ['[CLS] tactic to cover up - fact picture the core the yetum constructed,` or cave none worse and - -im around or.sy -sten - core ideas [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.757 (perp=8.153, rec=0.124, cos=0.002), tot_loss_proj:2.971 [t=0.22s]
prediction: ['[CLS] tactic to cover up - fact picture the core the yetum constructed,` or cave none worse and - -im around orstensy -. - core ideas [SEP]']
[ 900/2000] tot_loss=1.755 (perp=8.135, rec=0.126, cos=0.002), tot_loss_proj:2.898 [t=0.22s]
prediction: ['[CLS] tactic to cover up the fact picture the core the yetum constructed,` or cave none worse and - -im around orstensyim. - core ideas [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.751 (perp=8.135, rec=0.122, cos=0.002), tot_loss_proj:2.898 [t=0.22s]
prediction: ['[CLS] tactic to cover up the fact picture the core the yetum constructed,` or cave none worse and - -im around orstensyim. - core ideas [SEP]']
Attempt swap
[1000/2000] tot_loss=1.750 (perp=8.135, rec=0.122, cos=0.002), tot_loss_proj:2.899 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core the yetum constructed,` or cave none worse and - -im around orstensyim. - core ideas [SEP]']
[1050/2000] tot_loss=1.754 (perp=8.135, rec=0.125, cos=0.002), tot_loss_proj:2.901 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core the yetum constructed,` or cave none worse and - -im around orstensyim. - core ideas [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.788 (perp=8.320, rec=0.122, cos=0.002), tot_loss_proj:2.896 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core the andum constructed,` or central none worse yet - -im around orstensyim. - core ideas [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.739 (perp=8.094, rec=0.119, cos=0.002), tot_loss_proj:2.800 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core theum constructed,` or central and none worse yet - -im around orstensyim. - core ideas [SEP]']
[1200/2000] tot_loss=1.736 (perp=8.094, rec=0.116, cos=0.002), tot_loss_proj:2.803 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core theum constructed,` or central and none worse yet - -im around orstensyim. - core ideas [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.729 (perp=8.068, rec=0.113, cos=0.002), tot_loss_proj:2.867 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core the centralum constructed,` or and none worse yet - -im around orstensyim. - core ideas [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.708 (perp=7.974, rec=0.112, cos=0.002), tot_loss_proj:2.832 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core the coreum constructed,` or and none worse yet - -im around orstensyim. - central ideas [SEP]']
[1350/2000] tot_loss=1.713 (perp=7.974, rec=0.117, cos=0.002), tot_loss_proj:2.834 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core the coreum constructed,` or and none worse yet - -im around orstensyim. - central ideas [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.698 (perp=7.887, rec=0.120, cos=0.002), tot_loss_proj:2.751 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core or the coreum constructed,` and none worse yet - -im around orstensyim. - central ideas [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.677 (perp=7.789, rec=0.117, cos=0.002), tot_loss_proj:2.773 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core or the coreum constructed,` - none worse yet - -im around orstensyim. and central ideas [SEP]']
[1500/2000] tot_loss=1.681 (perp=7.789, rec=0.122, cos=0.002), tot_loss_proj:2.774 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core or the coreum constructed,` - none worse yet - -im around orstensyim. and central ideas [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.645 (perp=7.650, rec=0.114, cos=0.002), tot_loss_proj:2.725 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core or the coreim constructed,` - none worse yet - -um around orstensyim. and central ideas [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.638 (perp=7.600, rec=0.116, cos=0.002), tot_loss_proj:2.823 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core or the coreim constructed,` - none worse yet - - aroundum orstensyim. and central ideas [SEP]']
[1650/2000] tot_loss=1.634 (perp=7.600, rec=0.113, cos=0.002), tot_loss_proj:2.819 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core or the coreim constructed,` - none worse yet - - aroundum orstensyim. and central ideas [SEP]']
Attempt swap
[1700/2000] tot_loss=1.637 (perp=7.600, rec=0.115, cos=0.002), tot_loss_proj:2.824 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact picture the core or the coreim constructed,` - none worse yet - - aroundum orstensyim. and central ideas [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.592 (perp=7.341, rec=0.122, cos=0.002), tot_loss_proj:2.842 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact, the core or the coreim constructed picture` - none worse yet - - aroundum orstensyim. and central ideas [SEP]']
[1800/2000] tot_loss=1.587 (perp=7.341, rec=0.117, cos=0.002), tot_loss_proj:2.845 [t=0.24s]
prediction: ['[CLS] tactic to cover up the fact, the core or the coreim constructed picture` - none worse yet - - aroundum orstensyim. and central ideas [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.649 (perp=7.638, rec=0.119, cos=0.002), tot_loss_proj:2.920 [t=0.24s]
prediction: ['[CLS] tactic to cover up - core fact, the core or theim constructed picture` - none worse yet - - aroundt orstensyim. and central ideas [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.567 (perp=7.229, rec=0.119, cos=0.002), tot_loss_proj:2.850 [t=0.24s]
prediction: ['[CLS] tactic to cover up the core fact. the core or theim constructed picture` - none worse yet - - aroundt orstensyim, and central ideas [SEP]']
[1950/2000] tot_loss=1.564 (perp=7.229, rec=0.117, cos=0.002), tot_loss_proj:2.848 [t=0.24s]
prediction: ['[CLS] tactic to cover up the core fact. the core or theim constructed picture` - none worse yet - - aroundt orstensyim, and central ideas [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.529 (perp=7.059, rec=0.115, cos=0.002), tot_loss_proj:2.834 [t=0.24s]
prediction: ['[CLS] tactic to cover up the core fact. the core the orim constructed picture` - none worse yet - - aroundt orstensyim, and central ideas [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] tactic to cover up the fact picture the core or the coreim constructed,` - none worse yet - - aroundum orstensyim. and central ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 69.565 | r: 69.565
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 60.870 | p: 60.870 | r: 60.870
rougeLsum  | fm: 60.870 | p: 60.870 | r: 60.870
r1fm+r2fm = 105.929

[Aggregate metrics]:
rouge1     | fm: 92.787 | p: 92.309 | r: 93.343
rouge2     | fm: 60.406 | p: 60.140 | r: 60.750
rougeL     | fm: 81.658 | p: 81.278 | r: 82.076
rougeLsum  | fm: 81.563 | p: 81.199 | r: 82.066
r1fm+r2fm = 153.194

input #89 time: 0:09:12 | total time: 13:53:16


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9993661488324659
highest_index [0]
highest [0.9993661488324659]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9512577652931213 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9415462017059326 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.9294213652610779 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 0.9131613969802856 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8953686356544495 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.8816548585891724 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.8741692900657654 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8701651096343994 for ['[CLS] male entourage cannot released when spirited [SEP]']
[Init] best perm rec loss: 0.8700669407844543 for ['[CLS] cannot male when spirited released entourage [SEP]']
[Init] best perm rec loss: 0.8697954416275024 for ['[CLS] entourage when male cannot released spirited [SEP]']
[Init] best perm rec loss: 0.8695681691169739 for ['[CLS] released cannot male when entourage spirited [SEP]']
[Init] best perm rec loss: 0.8675873875617981 for ['[CLS] cannot entourage spirited male released when [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.338 (perp=10.234, rec=0.270, cos=0.021), tot_loss_proj:2.656 [t=0.22s]
prediction: ['[CLS] business ridiculous when how ridiculous money [SEP]']
[ 100/2000] tot_loss=1.813 (perp=8.397, rec=0.127, cos=0.007), tot_loss_proj:2.138 [t=0.22s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
[ 150/2000] tot_loss=1.777 (perp=8.397, rec=0.094, cos=0.003), tot_loss_proj:2.139 [t=0.22s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
[ 200/2000] tot_loss=1.765 (perp=8.397, rec=0.083, cos=0.002), tot_loss_proj:2.140 [t=0.22s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.769 (perp=8.397, rec=0.088, cos=0.002), tot_loss_proj:2.141 [t=0.22s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
[ 300/2000] tot_loss=1.772 (perp=8.397, rec=0.090, cos=0.003), tot_loss_proj:2.139 [t=0.22s]
prediction: ['[CLS] money oriented and how ridiculous money [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.951 (perp=9.406, rec=0.068, cos=0.001), tot_loss_proj:2.453 [t=0.22s]
prediction: ['[CLS] - oriented and how ridiculous money [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.742 (perp=8.184, rec=0.101, cos=0.004), tot_loss_proj:2.072 [t=0.22s]
prediction: ['[CLS] - and how ridiculous money oriented [SEP]']
[ 450/2000] tot_loss=1.715 (perp=8.184, rec=0.077, cos=0.001), tot_loss_proj:2.066 [t=0.22s]
prediction: ['[CLS] - and how ridiculous money oriented [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.642 (perp=7.895, rec=0.061, cos=0.001), tot_loss_proj:1.920 [t=0.22s]
prediction: ['[CLS] and how ridiculous - money oriented [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.550 (perp=7.392, rec=0.070, cos=0.002), tot_loss_proj:1.820 [t=0.22s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[ 600/2000] tot_loss=1.552 (perp=7.392, rec=0.072, cos=0.001), tot_loss_proj:1.819 [t=0.22s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.536 (perp=7.392, rec=0.056, cos=0.001), tot_loss_proj:1.818 [t=0.22s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.549 (perp=7.392, rec=0.070, cos=0.001), tot_loss_proj:1.811 [t=0.22s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[ 750/2000] tot_loss=1.539 (perp=7.392, rec=0.059, cos=0.001), tot_loss_proj:1.823 [t=0.22s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.542 (perp=7.392, rec=0.063, cos=0.001), tot_loss_proj:1.818 [t=0.22s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.547 (perp=7.392, rec=0.067, cos=0.001), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[ 900/2000] tot_loss=1.539 (perp=7.392, rec=0.060, cos=0.001), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.552 (perp=7.392, rec=0.072, cos=0.001), tot_loss_proj:1.820 [t=0.22s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1000/2000] tot_loss=1.536 (perp=7.392, rec=0.057, cos=0.001), tot_loss_proj:1.819 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[1050/2000] tot_loss=1.541 (perp=7.392, rec=0.061, cos=0.001), tot_loss_proj:1.819 [t=0.24s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1100/2000] tot_loss=1.534 (perp=7.392, rec=0.055, cos=0.001), tot_loss_proj:1.811 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1150/2000] tot_loss=1.553 (perp=7.392, rec=0.074, cos=0.001), tot_loss_proj:1.819 [t=0.24s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[1200/2000] tot_loss=1.544 (perp=7.392, rec=0.064, cos=0.001), tot_loss_proj:1.815 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1250/2000] tot_loss=1.531 (perp=7.392, rec=0.052, cos=0.001), tot_loss_proj:1.818 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1300/2000] tot_loss=1.543 (perp=7.392, rec=0.063, cos=0.001), tot_loss_proj:1.819 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[1350/2000] tot_loss=1.540 (perp=7.392, rec=0.060, cos=0.001), tot_loss_proj:1.820 [t=0.24s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1400/2000] tot_loss=1.536 (perp=7.392, rec=0.057, cos=0.001), tot_loss_proj:1.814 [t=0.24s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1450/2000] tot_loss=1.542 (perp=7.392, rec=0.063, cos=0.001), tot_loss_proj:1.820 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[1500/2000] tot_loss=1.547 (perp=7.392, rec=0.067, cos=0.001), tot_loss_proj:1.811 [t=0.24s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1550/2000] tot_loss=1.542 (perp=7.392, rec=0.062, cos=0.001), tot_loss_proj:1.819 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1600/2000] tot_loss=1.539 (perp=7.392, rec=0.059, cos=0.001), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[1650/2000] tot_loss=1.535 (perp=7.392, rec=0.055, cos=0.001), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1700/2000] tot_loss=1.542 (perp=7.392, rec=0.063, cos=0.001), tot_loss_proj:1.814 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1750/2000] tot_loss=1.546 (perp=7.392, rec=0.067, cos=0.001), tot_loss_proj:1.811 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[1800/2000] tot_loss=1.537 (perp=7.392, rec=0.058, cos=0.001), tot_loss_proj:1.825 [t=0.24s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1850/2000] tot_loss=1.544 (perp=7.392, rec=0.064, cos=0.001), tot_loss_proj:1.816 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[1900/2000] tot_loss=1.546 (perp=7.392, rec=0.066, cos=0.001), tot_loss_proj:1.819 [t=0.23s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[1950/2000] tot_loss=1.538 (perp=7.392, rec=0.058, cos=0.001), tot_loss_proj:1.819 [t=0.24s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
[2000/2000] tot_loss=1.544 (perp=7.392, rec=0.064, cos=0.001), tot_loss_proj:1.821 [t=0.24s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and - money oriented [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.867 | p: 92.414 | r: 93.389
rouge2     | fm: 60.735 | p: 60.483 | r: 60.988
rougeL     | fm: 81.750 | p: 81.387 | r: 82.200
rougeLsum  | fm: 81.756 | p: 81.412 | r: 82.212
r1fm+r2fm = 153.601

input #90 time: 0:09:01 | total time: 14:02:17


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.999353243642654
highest_index [0]
highest [0.999353243642654]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.9376624226570129 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.9372037053108215 for ['[CLS]underscribe canton below messenger speaking been does [SEP]']
[Init] best rec loss: 0.8286004662513733 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.8280330300331116 for ['[CLS] because case yard pro mine advantage waves operative [SEP]']
[Init] best rec loss: 0.8097145557403564 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.7759121060371399 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.7628023624420166 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.7443556189537048 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 0.7329837679862976 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best rec loss: 0.7260333895683289 for ['[CLS] transit sigh firm rainfall robert stilltracted upwards [SEP]']
[Init] best perm rec loss: 0.7250455021858215 for ['[CLS]tracted transit firm robert sigh rainfall upwards still [SEP]']
[Init] best perm rec loss: 0.7244743704795837 for ['[CLS] upwards sigh transit rainfalltracted firm robert still [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.662 (perp=11.383, rec=0.349, cos=0.036), tot_loss_proj:3.520 [t=0.23s]
prediction: ['[CLS] loki worse, gas no ridiculous ( remains [SEP]']
[ 100/2000] tot_loss=2.341 (perp=10.466, rec=0.231, cos=0.017), tot_loss_proj:2.835 [t=0.23s]
prediction: ['[CLS] loco loco,y no ridiculous but less [SEP]']
[ 150/2000] tot_loss=2.251 (perp=10.488, rec=0.148, cos=0.006), tot_loss_proj:2.698 [t=0.24s]
prediction: ['[CLS] loco locoyy more ridiculous but no [SEP]']
[ 200/2000] tot_loss=2.215 (perp=10.488, rec=0.114, cos=0.004), tot_loss_proj:2.691 [t=0.24s]
prediction: ['[CLS] loco locoyy more ridiculous but no [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.006 (perp=9.498, rec=0.103, cos=0.004), tot_loss_proj:2.423 [t=0.24s]
prediction: ['[CLS]y loco muy more ridiculous but no [SEP]']
[ 300/2000] tot_loss=2.056 (perp=9.794, rec=0.094, cos=0.003), tot_loss_proj:2.501 [t=0.24s]
prediction: ['[CLS] mu loco muy more ridiculous but no [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.868 (perp=8.832, rec=0.098, cos=0.003), tot_loss_proj:2.061 [t=0.23s]
prediction: ['[CLS] mu loco muy but no more ridiculous [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.811 (perp=8.636, rec=0.082, cos=0.002), tot_loss_proj:2.079 [t=0.24s]
prediction: ['[CLS] mu mu locoy but no more ridiculous [SEP]']
[ 450/2000] tot_loss=1.802 (perp=8.636, rec=0.073, cos=0.002), tot_loss_proj:2.084 [t=0.24s]
prediction: ['[CLS] mu mu locoy but no more ridiculous [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.782 (perp=8.523, rec=0.076, cos=0.001), tot_loss_proj:1.995 [t=0.24s]
prediction: ['[CLS] mu, locoy but no more ridiculous [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.563 (perp=7.488, rec=0.064, cos=0.001), tot_loss_proj:1.604 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 600/2000] tot_loss=1.576 (perp=7.488, rec=0.077, cos=0.001), tot_loss_proj:1.614 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.566 (perp=7.488, rec=0.068, cos=0.001), tot_loss_proj:1.604 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.552 (perp=7.488, rec=0.053, cos=0.001), tot_loss_proj:1.603 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 750/2000] tot_loss=1.553 (perp=7.488, rec=0.055, cos=0.001), tot_loss_proj:1.609 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.566 (perp=7.488, rec=0.067, cos=0.001), tot_loss_proj:1.605 [t=0.23s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.564 (perp=7.488, rec=0.065, cos=0.001), tot_loss_proj:1.607 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[ 900/2000] tot_loss=1.551 (perp=7.488, rec=0.052, cos=0.001), tot_loss_proj:1.610 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.552 (perp=7.488, rec=0.053, cos=0.001), tot_loss_proj:1.604 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.566 (perp=7.488, rec=0.067, cos=0.001), tot_loss_proj:1.609 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1050/2000] tot_loss=1.567 (perp=7.488, rec=0.068, cos=0.001), tot_loss_proj:1.611 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.561 (perp=7.488, rec=0.062, cos=0.001), tot_loss_proj:1.605 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.551 (perp=7.488, rec=0.052, cos=0.001), tot_loss_proj:1.607 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1200/2000] tot_loss=1.557 (perp=7.488, rec=0.058, cos=0.001), tot_loss_proj:1.607 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.571 (perp=7.488, rec=0.072, cos=0.001), tot_loss_proj:1.600 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.563 (perp=7.488, rec=0.064, cos=0.001), tot_loss_proj:1.601 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1350/2000] tot_loss=1.567 (perp=7.488, rec=0.069, cos=0.001), tot_loss_proj:1.608 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.569 (perp=7.488, rec=0.070, cos=0.001), tot_loss_proj:1.602 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.561 (perp=7.488, rec=0.062, cos=0.001), tot_loss_proj:1.605 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1500/2000] tot_loss=1.569 (perp=7.488, rec=0.070, cos=0.001), tot_loss_proj:1.603 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.564 (perp=7.488, rec=0.065, cos=0.001), tot_loss_proj:1.595 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.557 (perp=7.488, rec=0.058, cos=0.001), tot_loss_proj:1.601 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1650/2000] tot_loss=1.555 (perp=7.488, rec=0.056, cos=0.001), tot_loss_proj:1.601 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.561 (perp=7.488, rec=0.062, cos=0.001), tot_loss_proj:1.600 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.554 (perp=7.488, rec=0.055, cos=0.001), tot_loss_proj:1.605 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1800/2000] tot_loss=1.556 (perp=7.488, rec=0.058, cos=0.001), tot_loss_proj:1.606 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.554 (perp=7.488, rec=0.056, cos=0.001), tot_loss_proj:1.604 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.553 (perp=7.488, rec=0.055, cos=0.001), tot_loss_proj:1.607 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
[1950/2000] tot_loss=1.558 (perp=7.488, rec=0.059, cos=0.001), tot_loss_proj:1.610 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.561 (perp=7.488, rec=0.063, cos=0.001), tot_loss_proj:1.604 [t=0.24s]
prediction: ['[CLS] muy loco, but no more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.897 | p: 92.454 | r: 93.481
rouge2     | fm: 61.236 | p: 61.018 | r: 61.488
rougeL     | fm: 81.997 | p: 81.642 | r: 82.448
rougeLsum  | fm: 81.935 | p: 81.582 | r: 82.418
r1fm+r2fm = 154.133

input #91 time: 0:09:22 | total time: 14:11:40


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9993140791514946
highest_index [0]
highest [0.9993140791514946]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8814722895622253 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8744385242462158 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8691810965538025 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.8627728819847107 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 0.8539639711380005 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7928355932235718 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7915660738945007 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.617 (perp=12.266, rec=0.159, cos=0.005), tot_loss_proj:3.198 [t=0.21s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=1.615 (perp=7.647, rec=0.084, cos=0.002), tot_loss_proj:1.604 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.594 (perp=7.647, rec=0.063, cos=0.001), tot_loss_proj:1.605 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.604 (perp=7.647, rec=0.073, cos=0.002), tot_loss_proj:1.609 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.589 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.589 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.582 (perp=7.647, rec=0.052, cos=0.001), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.584 (perp=7.647, rec=0.053, cos=0.001), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.595 (perp=7.647, rec=0.064, cos=0.001), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.587 (perp=7.647, rec=0.056, cos=0.001), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.580 (perp=7.647, rec=0.050, cos=0.001), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.593 (perp=7.647, rec=0.062, cos=0.001), tot_loss_proj:1.590 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.600 (perp=7.647, rec=0.069, cos=0.001), tot_loss_proj:1.592 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.593 (perp=7.647, rec=0.062, cos=0.001), tot_loss_proj:1.594 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.598 (perp=7.647, rec=0.067, cos=0.001), tot_loss_proj:1.602 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.585 (perp=7.647, rec=0.054, cos=0.001), tot_loss_proj:1.593 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.588 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.580 (perp=7.647, rec=0.049, cos=0.001), tot_loss_proj:1.596 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.586 (perp=7.647, rec=0.056, cos=0.001), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.586 (perp=7.647, rec=0.055, cos=0.001), tot_loss_proj:1.588 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.592 (perp=7.647, rec=0.061, cos=0.001), tot_loss_proj:1.597 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.588 (perp=7.647, rec=0.057, cos=0.001), tot_loss_proj:1.587 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.605 (perp=7.647, rec=0.074, cos=0.001), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.584 (perp=7.647, rec=0.053, cos=0.001), tot_loss_proj:1.590 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.593 (perp=7.647, rec=0.062, cos=0.001), tot_loss_proj:1.588 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.598 (perp=7.647, rec=0.068, cos=0.001), tot_loss_proj:1.594 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.597 (perp=7.647, rec=0.067, cos=0.001), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.582 (perp=7.647, rec=0.051, cos=0.001), tot_loss_proj:1.598 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.587 (perp=7.647, rec=0.057, cos=0.001), tot_loss_proj:1.595 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.589 (perp=7.647, rec=0.059, cos=0.001), tot_loss_proj:1.584 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.599 (perp=7.647, rec=0.068, cos=0.001), tot_loss_proj:1.602 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.588 (perp=7.647, rec=0.058, cos=0.001), tot_loss_proj:1.589 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.586 (perp=7.647, rec=0.055, cos=0.001), tot_loss_proj:1.595 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.581 (perp=7.647, rec=0.051, cos=0.001), tot_loss_proj:1.584 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.597 (perp=7.647, rec=0.066, cos=0.001), tot_loss_proj:1.593 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.598 (perp=7.647, rec=0.067, cos=0.001), tot_loss_proj:1.586 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.580 (perp=7.647, rec=0.050, cos=0.001), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.596 (perp=7.647, rec=0.065, cos=0.001), tot_loss_proj:1.586 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.596 (perp=7.647, rec=0.065, cos=0.001), tot_loss_proj:1.593 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.578 (perp=7.647, rec=0.047, cos=0.001), tot_loss_proj:1.596 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.647, rec=0.056, cos=0.001), tot_loss_proj:1.597 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.013 | p: 92.585 | r: 93.528
rouge2     | fm: 61.596 | p: 61.377 | r: 61.869
rougeL     | fm: 82.179 | p: 81.864 | r: 82.616
rougeLsum  | fm: 82.004 | p: 81.653 | r: 82.493
r1fm+r2fm = 154.609

input #92 time: 0:08:57 | total time: 14:20:37


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9993328041825775
highest_index [0]
highest [0.9993328041825775]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.0106152296066284 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8291399478912354 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.8261485695838928 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 0.8090434074401855 for ['[CLS] solo specificball shrinking lad 1970s judicial [SEP]']
[Init] best perm rec loss: 0.8087723255157471 for ['[CLS] specific 1970sball lad shrinking solo judicial [SEP]']
[Init] best perm rec loss: 0.8081687092781067 for ['[CLS] solo specific judicial shrinkingball 1970s lad [SEP]']
[Init] best perm rec loss: 0.8072903156280518 for ['[CLS] shrinking soloball lad judicial specific 1970s [SEP]']
[Init] best perm rec loss: 0.8065516352653503 for ['[CLS] 1970s solo specific shrinking ladball judicial [SEP]']
[Init] best perm rec loss: 0.8060869574546814 for ['[CLS]ball solo specific shrinking 1970s lad judicial [SEP]']
[Init] best perm rec loss: 0.8057830333709717 for ['[CLS]ball specific lad shrinking 1970s judicial solo [SEP]']
[Init] best perm rec loss: 0.8052436709403992 for ['[CLS] shrinking specific soloball 1970s judicial lad [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.520 (perp=11.096, rec=0.290, cos=0.010), tot_loss_proj:2.718 [t=0.22s]
prediction: ['[CLS] understand and songility funny funny way [SEP]']
[ 100/2000] tot_loss=2.243 (perp=10.358, rec=0.168, cos=0.004), tot_loss_proj:2.408 [t=0.22s]
prediction: ['[CLS] understanding its understanding sometimes funny funny way [SEP]']
[ 150/2000] tot_loss=2.409 (perp=11.401, rec=0.126, cos=0.003), tot_loss_proj:2.708 [t=0.22s]
prediction: ['[CLS] often its understanding sometimes funny funny way [SEP]']
[ 200/2000] tot_loss=2.245 (perp=10.534, rec=0.133, cos=0.005), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] often its understanding often often funny way [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.903 (perp=8.992, rec=0.102, cos=0.002), tot_loss_proj:2.236 [t=0.22s]
prediction: ['[CLS] understanding its often often often funny way [SEP]']
[ 300/2000] tot_loss=1.905 (perp=8.992, rec=0.105, cos=0.002), tot_loss_proj:2.240 [t=0.22s]
prediction: ['[CLS] understanding its often often often funny way [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.981 (perp=9.446, rec=0.090, cos=0.002), tot_loss_proj:2.251 [t=0.22s]
prediction: ['[CLS] understanding in often often funny way its [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.736 (perp=8.149, rec=0.103, cos=0.003), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way often [SEP]']
[ 450/2000] tot_loss=1.720 (perp=8.149, rec=0.089, cos=0.002), tot_loss_proj:2.021 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way often [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.679 (perp=7.971, rec=0.083, cos=0.002), tot_loss_proj:1.874 [t=0.22s]
prediction: ['[CLS] understanding in its often often funny way [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.682 (perp=7.971, rec=0.087, cos=0.001), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] understanding in its often often funny way [SEP]']
[ 600/2000] tot_loss=1.666 (perp=7.971, rec=0.071, cos=0.001), tot_loss_proj:1.888 [t=0.22s]
prediction: ['[CLS] understanding in its often often funny way [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.657 (perp=7.971, rec=0.061, cos=0.001), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] understanding in its often often funny way [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.760 (perp=8.469, rec=0.065, cos=0.001), tot_loss_proj:2.031 [t=0.22s]
prediction: ['[CLS] understanding in its often, funny way [SEP]']
[ 750/2000] tot_loss=1.754 (perp=8.469, rec=0.059, cos=0.001), tot_loss_proj:2.039 [t=0.22s]
prediction: ['[CLS] understanding in its often, funny way [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.406 (perp=6.705, rec=0.064, cos=0.001), tot_loss_proj:1.727 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.408 (perp=6.705, rec=0.066, cos=0.001), tot_loss_proj:1.716 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[ 900/2000] tot_loss=1.411 (perp=6.705, rec=0.068, cos=0.001), tot_loss_proj:1.723 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.395 (perp=6.705, rec=0.053, cos=0.001), tot_loss_proj:1.713 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.405 (perp=6.705, rec=0.063, cos=0.001), tot_loss_proj:1.724 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1050/2000] tot_loss=1.411 (perp=6.705, rec=0.069, cos=0.001), tot_loss_proj:1.725 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.413 (perp=6.705, rec=0.071, cos=0.001), tot_loss_proj:1.728 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.406 (perp=6.705, rec=0.064, cos=0.001), tot_loss_proj:1.719 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1200/2000] tot_loss=1.398 (perp=6.705, rec=0.056, cos=0.001), tot_loss_proj:1.721 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.408 (perp=6.705, rec=0.066, cos=0.001), tot_loss_proj:1.715 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.413 (perp=6.705, rec=0.070, cos=0.001), tot_loss_proj:1.723 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1350/2000] tot_loss=1.405 (perp=6.705, rec=0.063, cos=0.001), tot_loss_proj:1.727 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.408 (perp=6.705, rec=0.066, cos=0.001), tot_loss_proj:1.719 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.403 (perp=6.705, rec=0.061, cos=0.001), tot_loss_proj:1.726 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1500/2000] tot_loss=1.410 (perp=6.705, rec=0.067, cos=0.001), tot_loss_proj:1.723 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.411 (perp=6.705, rec=0.068, cos=0.001), tot_loss_proj:1.733 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.414 (perp=6.705, rec=0.071, cos=0.001), tot_loss_proj:1.725 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1650/2000] tot_loss=1.407 (perp=6.705, rec=0.064, cos=0.001), tot_loss_proj:1.720 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.405 (perp=6.705, rec=0.063, cos=0.001), tot_loss_proj:1.721 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.399 (perp=6.705, rec=0.057, cos=0.001), tot_loss_proj:1.716 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1800/2000] tot_loss=1.400 (perp=6.705, rec=0.058, cos=0.001), tot_loss_proj:1.723 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.415 (perp=6.705, rec=0.073, cos=0.001), tot_loss_proj:1.723 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.406 (perp=6.705, rec=0.064, cos=0.001), tot_loss_proj:1.718 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1950/2000] tot_loss=1.403 (perp=6.705, rec=0.060, cos=0.001), tot_loss_proj:1.721 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.408 (perp=6.705, rec=0.066, cos=0.001), tot_loss_proj:1.720 [t=0.22s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding in its often funny way, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 93.084 | p: 92.639 | r: 93.607
rouge2     | fm: 61.594 | p: 61.319 | r: 61.867
rougeL     | fm: 82.257 | p: 81.911 | r: 82.610
rougeLsum  | fm: 82.137 | p: 81.782 | r: 82.580
r1fm+r2fm = 154.679

input #93 time: 0:08:45 | total time: 14:29:23


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9993172942000517
highest_index [0]
highest [0.9993172942000517]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9766421318054199 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9562913775444031 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9171427488327026 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9082192778587341 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.8862788677215576 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.8804725408554077 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 0.8800083994865417 for ['[CLS] internal plum flowering expedition territorial shocks chronic centre crushed rockwellventing [SEP]']
[Init] best perm rec loss: 0.879869282245636 for ['[CLS] shocksventing internal chronic expedition centre rockwell flowering crushed plum territorial [SEP]']
[Init] best perm rec loss: 0.8795231580734253 for ['[CLS]venting plum territorial flowering expedition shocks internal centre chronic rockwell crushed [SEP]']
[Init] best perm rec loss: 0.8793690800666809 for ['[CLS]venting plum expedition shocks crushed chronic centre territorial rockwell flowering internal [SEP]']
[Init] best perm rec loss: 0.8776559829711914 for ['[CLS] chronic plum shocks expedition crushed internal territorialventing centre flowering rockwell [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.596 (perp=11.185, rec=0.346, cos=0.013), tot_loss_proj:4.185 [t=0.23s]
prediction: ['[CLS] or neither ending restrained pack weekly neither mountain nose nor weak [SEP]']
[ 100/2000] tot_loss=2.119 (perp=9.556, rec=0.201, cos=0.007), tot_loss_proj:2.458 [t=0.23s]
prediction: ['[CLS] or neither original capes neither neither nor nor nor funny [SEP]']
[ 150/2000] tot_loss=2.133 (perp=10.009, rec=0.127, cos=0.004), tot_loss_proj:2.562 [t=0.23s]
prediction: ['[CLS] s neither original caper neither neither terribly terribly nor funny [SEP]']
[ 200/2000] tot_loss=1.948 (perp=9.245, rec=0.096, cos=0.003), tot_loss_proj:2.357 [t=0.23s]
prediction: ['[CLS] s neither original caper that neither terribly terribly nor funny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.804 (perp=8.587, rec=0.084, cos=0.002), tot_loss_proj:2.212 [t=0.24s]
prediction: ['[CLS] s neither original caper that neither terribly nor terribly funny [SEP]']
[ 300/2000] tot_loss=1.800 (perp=8.587, rec=0.081, cos=0.002), tot_loss_proj:2.208 [t=0.23s]
prediction: ['[CLS] s neither original caper that neither terribly nor terribly funny [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.608 (perp=7.620, rec=0.083, cos=0.002), tot_loss_proj:2.272 [t=0.24s]
prediction: ['[CLS] s that original caper neither a terribly nor terribly funny [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.414 (perp=6.695, rec=0.074, cos=0.001), tot_loss_proj:1.883 [t=0.23s]
prediction: ['[CLS] s that original a caper neither terribly nor terribly funny [SEP]']
[ 450/2000] tot_loss=1.415 (perp=6.695, rec=0.075, cos=0.001), tot_loss_proj:1.882 [t=0.23s]
prediction: ['[CLS] s that original a caper neither terribly nor terribly funny [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.399 (perp=6.695, rec=0.058, cos=0.001), tot_loss_proj:1.884 [t=0.24s]
prediction: ['[CLS] s that original a caper neither terribly nor terribly funny [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.402 (perp=6.695, rec=0.062, cos=0.001), tot_loss_proj:1.879 [t=0.23s]
prediction: ['[CLS] s that original a caper neither terribly nor terribly funny [SEP]']
[ 600/2000] tot_loss=1.410 (perp=6.695, rec=0.070, cos=0.001), tot_loss_proj:1.884 [t=0.23s]
prediction: ['[CLS] s that original a caper neither terribly nor terribly funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.413 (perp=6.695, rec=0.072, cos=0.001), tot_loss_proj:1.884 [t=0.24s]
prediction: ['[CLS] s that original a caper neither terribly nor terribly funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.402 (perp=6.695, rec=0.062, cos=0.001), tot_loss_proj:1.883 [t=0.22s]
prediction: ['[CLS] s that original a caper neither terribly nor terribly funny [SEP]']
[ 750/2000] tot_loss=1.530 (perp=7.322, rec=0.065, cos=0.001), tot_loss_proj:1.973 [t=0.22s]
prediction: ['[CLS] s that original a caper neither original nor terribly funny [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.528 (perp=7.322, rec=0.063, cos=0.001), tot_loss_proj:1.982 [t=0.22s]
prediction: ['[CLS] s that original a caper neither original nor terribly funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.521 (perp=7.322, rec=0.056, cos=0.001), tot_loss_proj:1.975 [t=0.22s]
prediction: ['[CLS] s that original a caper neither original nor terribly funny [SEP]']
[ 900/2000] tot_loss=1.525 (perp=7.322, rec=0.060, cos=0.001), tot_loss_proj:1.983 [t=0.22s]
prediction: ['[CLS] s that original a caper neither original nor terribly funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.538 (perp=7.322, rec=0.072, cos=0.001), tot_loss_proj:1.985 [t=0.22s]
prediction: ['[CLS] s that original a caper neither original nor terribly funny [SEP]']
Attempt swap
[1000/2000] tot_loss=1.531 (perp=7.322, rec=0.065, cos=0.001), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] s that original a caper neither original nor terribly funny [SEP]']
[1050/2000] tot_loss=1.529 (perp=7.322, rec=0.063, cos=0.001), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] s that original a caper neither original nor terribly funny [SEP]']
Attempt swap
[1100/2000] tot_loss=1.570 (perp=7.521, rec=0.064, cos=0.001), tot_loss_proj:2.284 [t=0.22s]
prediction: ["[CLS] s that original a caper neither'nor terribly funny [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.410 (perp=6.689, rec=0.071, cos=0.002), tot_loss_proj:1.927 [t=0.22s]
prediction: ["[CLS]'s that original a caper neither nor terribly funny [SEP]"]
[1200/2000] tot_loss=1.410 (perp=6.689, rec=0.071, cos=0.001), tot_loss_proj:1.927 [t=0.22s]
prediction: ["[CLS]'s that original a caper neither nor terribly funny [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.254 (perp=5.928, rec=0.067, cos=0.001), tot_loss_proj:1.565 [t=0.24s]
prediction: ["[CLS]'s neither that original a caper nor terribly funny [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.247 (perp=5.928, rec=0.060, cos=0.001), tot_loss_proj:1.560 [t=0.24s]
prediction: ["[CLS]'s neither that original a caper nor terribly funny [SEP]"]
[1350/2000] tot_loss=1.254 (perp=5.928, rec=0.067, cos=0.001), tot_loss_proj:1.570 [t=0.24s]
prediction: ["[CLS]'s neither that original a caper nor terribly funny [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.259 (perp=5.928, rec=0.072, cos=0.001), tot_loss_proj:1.567 [t=0.24s]
prediction: ["[CLS]'s neither that original a caper nor terribly funny [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.248 (perp=5.928, rec=0.062, cos=0.001), tot_loss_proj:1.567 [t=0.24s]
prediction: ["[CLS]'s neither that original a caper nor terribly funny [SEP]"]
[1500/2000] tot_loss=1.244 (perp=5.928, rec=0.057, cos=0.001), tot_loss_proj:1.561 [t=0.24s]
prediction: ["[CLS]'s neither that original a caper nor terribly funny [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.115 (perp=5.193, rec=0.075, cos=0.001), tot_loss_proj:1.348 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.111 (perp=5.193, rec=0.071, cos=0.001), tot_loss_proj:1.352 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1650/2000] tot_loss=1.118 (perp=5.193, rec=0.078, cos=0.001), tot_loss_proj:1.356 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.104 (perp=5.193, rec=0.064, cos=0.001), tot_loss_proj:1.356 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.104 (perp=5.193, rec=0.064, cos=0.001), tot_loss_proj:1.358 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1800/2000] tot_loss=1.105 (perp=5.193, rec=0.065, cos=0.001), tot_loss_proj:1.352 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.106 (perp=5.193, rec=0.066, cos=0.001), tot_loss_proj:1.348 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.107 (perp=5.193, rec=0.067, cos=0.001), tot_loss_proj:1.345 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1950/2000] tot_loss=1.107 (perp=5.193, rec=0.067, cos=0.001), tot_loss_proj:1.357 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.112 (perp=5.193, rec=0.072, cos=0.001), tot_loss_proj:1.343 [t=0.24s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] s that original a caper neither original nor terribly funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 57.143 | p: 54.545 | r: 60.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 152.795

[Aggregate metrics]:
rouge1     | fm: 93.132 | p: 92.669 | r: 93.695
rouge2     | fm: 61.546 | p: 61.281 | r: 61.877
rougeL     | fm: 82.214 | p: 81.847 | r: 82.636
rougeLsum  | fm: 82.130 | p: 81.781 | r: 82.551
r1fm+r2fm = 154.679

input #94 time: 0:09:11 | total time: 14:38:34


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9991571833716502
highest_index [0]
highest [0.9991571833716502]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9717789888381958 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9435426592826843 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 0.9418174624443054 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9320042133331299 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 0.9293991923332214 for ['[CLS] oval foster welfarecu range turk partly support turret familiesumatic helping inclinedsteredling [SEP]']
[Init] best rec loss: 0.9255191683769226 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 0.9003634452819824 for ['[CLS] plenty heroes kit operating aim ouby fa physics pinco victim playing cisco feeling [SEP]']
[Init] best rec loss: 0.8562151193618774 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8513796925544739 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 0.8484290838241577 for ['[CLS] ] damp tech trailer cut privateے hanging block complete monty pressure sister wirenne [SEP]']
[Init] best perm rec loss: 0.8474252820014954 for ['[CLS] cut sister trailer block monty tech damp wire private pressure ] hangingnne completeے [SEP]']
[Init] best perm rec loss: 0.8452731966972351 for ['[CLS] trailer private sisterے wire pressure monty ] damp blocknne hanging cut tech complete [SEP]']
[Init] best perm rec loss: 0.8449822664260864 for ['[CLS] wire montyے private cut pressure hanging sisternne tech complete damp block trailer ] [SEP]']
[Init] best perm rec loss: 0.8435211181640625 for ['[CLS] cut wire damp tech trailer ] pressure private blockے monty complete sister hangingnne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.443 (perp=11.060, rec=0.225, cos=0.006), tot_loss_proj:2.835 [t=0.23s]
prediction: ['[CLS] compilation story already, hopeless hopeless hopeless hopeless # became hopeless extremely hopeless hopeless hopeless [SEP]']
[ 100/2000] tot_loss=2.469 (perp=11.560, rec=0.153, cos=0.004), tot_loss_proj:2.819 [t=0.24s]
prediction: ['[CLS]dle story a, hopeless hopeless hopeless sql story becomes a extremelyfying mud hopeless [SEP]']
[ 150/2000] tot_loss=2.395 (perp=11.404, rec=0.111, cos=0.003), tot_loss_proj:2.793 [t=0.24s]
prediction: ["[CLS]dle'a, mud denis hopeless mud story becomes asatfying mud hopeless [SEP]"]
[ 200/2000] tot_loss=2.578 (perp=12.421, rec=0.091, cos=0.003), tot_loss_proj:3.104 [t=0.24s]
prediction: ["[CLS]dle'(, mud denis hopeless mud story becomes asatfying mudsat [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.693 (perp=12.970, rec=0.097, cos=0.002), tot_loss_proj:3.226 [t=0.24s]
prediction: ["[CLS]dle'sat, mud denis hopeless accounted story becomes asatfyingis inter [SEP]"]
[ 300/2000] tot_loss=2.511 (perp=12.143, rec=0.081, cos=0.002), tot_loss_proj:3.033 [t=0.24s]
prediction: ['[CLS]dle ) un, mud denis hopeless hopeless story becomes asatfyingis inter [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.270 (perp=10.936, rec=0.081, cos=0.002), tot_loss_proj:2.876 [t=0.24s]
prediction: ['[CLS]dle ) un, mud denis hopeless₎ story becomes asatisfying inter [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.179 (perp=10.465, rec=0.084, cos=0.002), tot_loss_proj:2.712 [t=0.24s]
prediction: ['[CLS]dle ) hopeless, mud denis un ¤ story becomes asatisfying inter [SEP]']
[ 450/2000] tot_loss=2.135 (perp=10.242, rec=0.085, cos=0.002), tot_loss_proj:2.722 [t=0.24s]
prediction: ['[CLS]dle ) hopeless, mud denis un ( story becomes asatisfying inter [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.864 (perp=8.943, rec=0.073, cos=0.002), tot_loss_proj:2.431 [t=0.24s]
prediction: ['[CLS] denis ) hopeless, muddle un ( story becomes asatisfying inter [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.793 (perp=8.543, rec=0.083, cos=0.002), tot_loss_proj:2.243 [t=0.24s]
prediction: ['[CLS] denis ) hopeless, muddle story becomes un ( asatisfying inter [SEP]']
[ 600/2000] tot_loss=1.780 (perp=8.543, rec=0.070, cos=0.002), tot_loss_proj:2.235 [t=0.24s]
prediction: ['[CLS] denis ) hopeless, muddle story becomes un ( asatisfying inter [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.630 (perp=7.709, rec=0.086, cos=0.002), tot_loss_proj:2.055 [t=0.24s]
prediction: ['[CLS] denis ) hopeless, muddle story becomes unsatisfying ( a inter [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.622 (perp=7.709, rec=0.079, cos=0.002), tot_loss_proj:2.062 [t=0.24s]
prediction: ['[CLS] denis ) hopeless, muddle story becomes unsatisfying ( a inter [SEP]']
[ 750/2000] tot_loss=1.614 (perp=7.709, rec=0.071, cos=0.002), tot_loss_proj:2.059 [t=0.24s]
prediction: ['[CLS] denis ) hopeless, muddle story becomes unsatisfying ( a inter [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.615 (perp=7.709, rec=0.071, cos=0.002), tot_loss_proj:2.061 [t=0.24s]
prediction: ['[CLS] denis ) hopeless, muddle story becomes unsatisfying ( a inter [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.530 (perp=7.204, rec=0.087, cos=0.002), tot_loss_proj:1.964 [t=0.24s]
prediction: ['[CLS] denis ) a hopeless, muddle story becomes unsatisfying ( inter [SEP]']
[ 900/2000] tot_loss=1.555 (perp=7.433, rec=0.067, cos=0.002), tot_loss_proj:1.914 [t=0.24s]
prediction: ['[CLS] denis ) a hopeless, muddle story becomes unsatisfying (verted [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.572 (perp=7.502, rec=0.070, cos=0.002), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] denis ) a hopeless inter, muddle story becomes unsatisfying ( [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.535 (perp=7.242, rec=0.085, cos=0.002), tot_loss_proj:1.910 [t=0.24s]
prediction: ['[CLS] denis ) a hopeless inter muddle story, becomes unsatisfying ( [SEP]']
[1050/2000] tot_loss=1.524 (perp=7.242, rec=0.074, cos=0.002), tot_loss_proj:1.911 [t=0.24s]
prediction: ['[CLS] denis ) a hopeless inter muddle story, becomes unsatisfying ( [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.505 (perp=7.144, rec=0.074, cos=0.002), tot_loss_proj:1.961 [t=0.24s]
prediction: ['[CLS] denis ) a hopeless muddle story, becomes unsatisfying ( inter [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.452 (perp=6.855, rec=0.079, cos=0.002), tot_loss_proj:1.756 [t=0.24s]
prediction: ['[CLS] denis ) becomes a hopeless muddle story, unsatisfying ( inter [SEP]']
[1200/2000] tot_loss=1.451 (perp=6.855, rec=0.079, cos=0.002), tot_loss_proj:1.755 [t=0.24s]
prediction: ['[CLS] denis ) becomes a hopeless muddle story, unsatisfying ( inter [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.358 (perp=6.417, rec=0.073, cos=0.002), tot_loss_proj:1.669 [t=0.22s]
prediction: ['[CLS] denis inter ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Attempt swap
[1300/2000] tot_loss=1.364 (perp=6.417, rec=0.079, cos=0.002), tot_loss_proj:1.666 [t=0.22s]
prediction: ['[CLS] denis inter ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
[1350/2000] tot_loss=1.359 (perp=6.417, rec=0.074, cos=0.002), tot_loss_proj:1.671 [t=0.22s]
prediction: ['[CLS] denis inter ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Attempt swap
[1400/2000] tot_loss=1.364 (perp=6.417, rec=0.079, cos=0.002), tot_loss_proj:1.658 [t=0.23s]
prediction: ['[CLS] denis inter ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Attempt swap
[1450/2000] tot_loss=1.354 (perp=6.417, rec=0.069, cos=0.002), tot_loss_proj:1.665 [t=0.22s]
prediction: ['[CLS] denis inter ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
[1500/2000] tot_loss=1.355 (perp=6.417, rec=0.070, cos=0.002), tot_loss_proj:1.668 [t=0.23s]
prediction: ['[CLS] denis inter ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Attempt swap
[1550/2000] tot_loss=1.351 (perp=6.417, rec=0.066, cos=0.002), tot_loss_proj:1.668 [t=0.23s]
prediction: ['[CLS] denis inter ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Attempt swap
[1600/2000] tot_loss=1.354 (perp=6.417, rec=0.069, cos=0.002), tot_loss_proj:1.673 [t=0.22s]
prediction: ['[CLS] denis inter ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
[1650/2000] tot_loss=1.353 (perp=6.417, rec=0.068, cos=0.002), tot_loss_proj:1.661 [t=0.22s]
prediction: ['[CLS] denis inter ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Attempt swap
[1700/2000] tot_loss=1.385 (perp=6.560, rec=0.072, cos=0.002), tot_loss_proj:1.683 [t=0.22s]
prediction: ['[CLS] denis use ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Attempt swap
[1750/2000] tot_loss=1.385 (perp=6.560, rec=0.071, cos=0.002), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] denis use ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
[1800/2000] tot_loss=1.391 (perp=6.560, rec=0.078, cos=0.002), tot_loss_proj:1.684 [t=0.23s]
prediction: ['[CLS] denis use ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Attempt swap
[1850/2000] tot_loss=1.388 (perp=6.560, rec=0.074, cos=0.002), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] denis use ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Attempt swap
[1900/2000] tot_loss=1.392 (perp=6.560, rec=0.079, cos=0.002), tot_loss_proj:1.689 [t=0.22s]
prediction: ['[CLS] denis use ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
[1950/2000] tot_loss=1.383 (perp=6.560, rec=0.069, cos=0.002), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] denis use ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Attempt swap
[2000/2000] tot_loss=1.381 (perp=6.560, rec=0.067, cos=0.002), tot_loss_proj:1.679 [t=0.22s]
prediction: ['[CLS] denis use ) becomes a hopeless muddle story, unsatisfying ( [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] denis use ) becomes a hopeless muddle story, unsatisfying ( [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 35.294 | p: 33.333 | r: 37.500
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 130.031

[Aggregate metrics]:
rouge1     | fm: 93.163 | p: 92.626 | r: 93.775
rouge2     | fm: 61.285 | p: 61.041 | r: 61.653
rougeL     | fm: 82.081 | p: 81.622 | r: 82.572
rougeLsum  | fm: 82.084 | p: 81.627 | r: 82.598
r1fm+r2fm = 154.448

input #95 time: 0:09:13 | total time: 14:47:48


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9992863442853963
highest_index [0]
highest [0.9992863442853963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8897403478622437 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8798883557319641 for ['[CLS] regrets emotionsoit purpose superior loop released given higher careini speechply springs assist [SEP]']
[Init] best rec loss: 0.860714316368103 for ['[CLS] all nova resolution which assault domestic look mandy headquarteredtated thanlus completion stillboards [SEP]']
[Init] best rec loss: 0.8265302181243896 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 0.8220264911651611 for ['[CLS] flex thought considerationlin kylie ste in gasped somewherese top close christian raised us [SEP]']
[Init] best rec loss: 0.8179569840431213 for ['[CLS] lea corps cellrily smashed unconscious garcia broke intensity baseball urban who reins brigade β [SEP]']
[Init] best rec loss: 0.8156690001487732 for ['[CLS]culus teacher robson colonies now world over enables who obsidianrlerving peacehwa contract [SEP]']
[Init] best rec loss: 0.7906668186187744 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.7905946969985962 for ['[CLS] statue projectile pondered typical living save sounding august spent time smashwords wig eragn memoir [SEP]']
[Init] best perm rec loss: 0.7904244065284729 for ['[CLS] sounding smashwords time typical pondered augustgn memoir projectile spent save wig era statue living [SEP]']
[Init] best perm rec loss: 0.7902461290359497 for ['[CLS] spent august smashwords projectile pondered save sounding living era time wiggn typical memoir statue [SEP]']
[Init] best perm rec loss: 0.789009153842926 for ['[CLS] statue memoir smashwordsgn spent wig typical time projectile sounding save august era living pondered [SEP]']
[Init] best perm rec loss: 0.7879628539085388 for ['[CLS] august living era typical save spent sounding memoirgn projectile time pondered wig smashwords statue [SEP]']
[Init] best perm rec loss: 0.7875304222106934 for ['[CLS] statuegn wig era spent save pondered typical projectile sounding smashwords august time living memoir [SEP]']
[Init] best perm rec loss: 0.7873085141181946 for ['[CLS] smashwords memoir spent august wig projectile statue era sounding typical savegn time pondered living [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.664 (perp=11.351, rec=0.344, cos=0.050), tot_loss_proj:3.524 [t=0.24s]
prediction: ['[CLS] moments ( club moment lone lane film take and km force tiffany from severalback [SEP]']
[ 100/2000] tot_loss=2.391 (perp=10.511, rec=0.265, cos=0.023), tot_loss_proj:3.705 [t=0.24s]
prediction: ['[CLS] tonight albert situations himself more would cover a on people force people run into into [SEP]']
[ 150/2000] tot_loss=2.204 (perp=9.846, rec=0.227, cos=0.008), tot_loss_proj:3.729 [t=0.24s]
prediction: ['[CLS] moments lesser situations himself more would cover that on people force lesser run into into [SEP]']
[ 200/2000] tot_loss=2.236 (perp=10.125, rec=0.205, cos=0.006), tot_loss_proj:3.647 [t=0.24s]
prediction: ['[CLS] people lesser situations himself into would cover that on situations force lesser men lesser into [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.394 (perp=10.892, rec=0.208, cos=0.008), tot_loss_proj:3.670 [t=0.24s]
prediction: ['[CLS] people lesser situations himself sparrow would lesser people himself that force lesser men lesser into [SEP]']
[ 300/2000] tot_loss=2.229 (perp=10.277, rec=0.168, cos=0.006), tot_loss_proj:3.545 [t=0.24s]
prediction: ['[CLS] person lesser cover himself mentioned would lesser people situations and force lesser men lesser into [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.086 (perp=9.686, rec=0.144, cos=0.005), tot_loss_proj:3.344 [t=0.24s]
prediction: ['[CLS] situation himself mentioned would lesser cover lesser people situations and force men men lesser into [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.092 (perp=9.660, rec=0.154, cos=0.006), tot_loss_proj:3.011 [t=0.24s]
prediction: ['[CLS] situations himself / would runs cover lesser people situations and force on men lesser men [SEP]']
[ 450/2000] tot_loss=2.011 (perp=9.368, rec=0.134, cos=0.004), tot_loss_proj:3.080 [t=0.24s]
prediction: ['[CLS] person himself / would runs cover lesser people situations and force on men lesser men [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.912 (perp=8.941, rec=0.120, cos=0.003), tot_loss_proj:3.096 [t=0.24s]
prediction: ['[CLS] would himself would / running cover lesser people situations and force on run lesser men [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.769 (perp=8.154, rec=0.133, cos=0.005), tot_loss_proj:3.172 [t=0.24s]
prediction: ['[CLS] would himself would / run cover lesser people situations and run force on lesser men [SEP]']
[ 600/2000] tot_loss=1.760 (perp=8.211, rec=0.115, cos=0.003), tot_loss_proj:3.230 [t=0.24s]
prediction: ['[CLS] would himself would / run cover lesser people situations and for force on lesser men [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.671 (perp=7.783, rec=0.111, cos=0.003), tot_loss_proj:3.073 [t=0.24s]
prediction: ['[CLS] would himself / would run cover lesser people situations and for force on lesser men [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.665 (perp=7.783, rec=0.106, cos=0.003), tot_loss_proj:3.075 [t=0.24s]
prediction: ['[CLS] would himself / would run cover lesser people situations and for force on lesser men [SEP]']
[ 750/2000] tot_loss=1.663 (perp=7.783, rec=0.103, cos=0.002), tot_loss_proj:3.068 [t=0.24s]
prediction: ['[CLS] would himself / would run cover lesser people situations and for force on lesser men [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.778 (perp=8.352, rec=0.106, cos=0.002), tot_loss_proj:3.257 [t=0.24s]
prediction: ['[CLS] would himself / of run cover lesser people situations and for force on lesser men [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.897 (perp=8.948, rec=0.105, cos=0.002), tot_loss_proj:2.921 [t=0.24s]
prediction: ['[CLS] would himself / run of cover make people situations and for force on lesser men [SEP]']
[ 900/2000] tot_loss=1.888 (perp=8.948, rec=0.097, cos=0.002), tot_loss_proj:2.927 [t=0.24s]
prediction: ['[CLS] would himself / run of cover make people situations and for force on lesser men [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.794 (perp=8.445, rec=0.103, cos=0.002), tot_loss_proj:3.093 [t=0.24s]
prediction: ['[CLS] would himself / run cover of make people situations and for force on lesser men [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.762 (perp=8.310, rec=0.097, cos=0.003), tot_loss_proj:3.165 [t=0.24s]
prediction: ['[CLS] would himself / people run cover of make situations and for force on lesser men [SEP]']
[1050/2000] tot_loss=1.755 (perp=8.310, rec=0.090, cos=0.002), tot_loss_proj:3.169 [t=0.24s]
prediction: ['[CLS] would himself / people run cover of make situations and for force on lesser men [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.695 (perp=7.992, rec=0.095, cos=0.003), tot_loss_proj:2.846 [t=0.24s]
prediction: ['[CLS] would himself / people run cover of situations and make for force on lesser men [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.598 (perp=7.498, rec=0.096, cos=0.003), tot_loss_proj:2.623 [t=0.24s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
[1200/2000] tot_loss=1.590 (perp=7.498, rec=0.088, cos=0.002), tot_loss_proj:2.623 [t=0.24s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[1250/2000] tot_loss=1.592 (perp=7.498, rec=0.090, cos=0.002), tot_loss_proj:2.622 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[1300/2000] tot_loss=1.586 (perp=7.498, rec=0.084, cos=0.002), tot_loss_proj:2.624 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
[1350/2000] tot_loss=1.602 (perp=7.498, rec=0.100, cos=0.002), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[1400/2000] tot_loss=1.596 (perp=7.498, rec=0.094, cos=0.002), tot_loss_proj:2.620 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[1450/2000] tot_loss=1.590 (perp=7.498, rec=0.088, cos=0.002), tot_loss_proj:2.613 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
[1500/2000] tot_loss=1.584 (perp=7.498, rec=0.082, cos=0.002), tot_loss_proj:2.624 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[1550/2000] tot_loss=1.593 (perp=7.498, rec=0.091, cos=0.002), tot_loss_proj:2.619 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[1600/2000] tot_loss=1.593 (perp=7.498, rec=0.091, cos=0.002), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
[1650/2000] tot_loss=1.591 (perp=7.498, rec=0.089, cos=0.002), tot_loss_proj:2.623 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[1700/2000] tot_loss=1.588 (perp=7.498, rec=0.086, cos=0.002), tot_loss_proj:2.621 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[1750/2000] tot_loss=1.590 (perp=7.498, rec=0.088, cos=0.002), tot_loss_proj:2.621 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
[1800/2000] tot_loss=1.592 (perp=7.498, rec=0.090, cos=0.002), tot_loss_proj:2.622 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[1850/2000] tot_loss=1.589 (perp=7.498, rec=0.087, cos=0.002), tot_loss_proj:2.627 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[1900/2000] tot_loss=1.595 (perp=7.498, rec=0.093, cos=0.002), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
[1950/2000] tot_loss=1.591 (perp=7.498, rec=0.090, cos=0.002), tot_loss_proj:2.622 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Attempt swap
[2000/2000] tot_loss=1.588 (perp=7.498, rec=0.087, cos=0.002), tot_loss_proj:2.617 [t=0.22s]
prediction: ['[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] would himself / people run for cover of situations and make force on lesser men [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 93.750 | r: 88.235
rouge2     | fm: 19.355 | p: 20.000 | r: 18.750
rougeL     | fm: 48.485 | p: 50.000 | r: 47.059
rougeLsum  | fm: 48.485 | p: 50.000 | r: 47.059
r1fm+r2fm = 110.264

[Aggregate metrics]:
rouge1     | fm: 93.096 | p: 92.595 | r: 93.645
rouge2     | fm: 60.841 | p: 60.607 | r: 61.221
rougeL     | fm: 81.724 | p: 81.338 | r: 82.183
rougeLsum  | fm: 81.722 | p: 81.315 | r: 82.225
r1fm+r2fm = 153.937

input #96 time: 0:09:16 | total time: 14:57:05


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9991662155443171
highest_index [0]
highest [0.9991662155443171]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8431113362312317 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.8104252219200134 for ['[CLS] [SEP] crates margarita trip decisionsylus [SEP]']
[Init] best rec loss: 0.8035948872566223 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.7755175828933716 for ['[CLS] jealous glennm his = empire [SEP]']
[Init] best rec loss: 0.7488246560096741 for ['[CLS] perfect channel cam working 140et [SEP]']
[Init] best perm rec loss: 0.7483882904052734 for ['[CLS]et cam perfect working 140 channel [SEP]']
[Init] best perm rec loss: 0.7473320364952087 for ['[CLS] cam channel working perfect 140et [SEP]']
[Init] best perm rec loss: 0.7467406988143921 for ['[CLS] channel perfect workinget 140 cam [SEP]']
[Init] best perm rec loss: 0.7466690540313721 for ['[CLS] channel working cam perfect 140et [SEP]']
[Init] best perm rec loss: 0.7466669082641602 for ['[CLS] perfect working channelet 140 cam [SEP]']
[Init] best perm rec loss: 0.7462400794029236 for ['[CLS] working channel cam perfectet 140 [SEP]']
[Init] best perm rec loss: 0.7460934519767761 for ['[CLS] working cam 140 perfectet channel [SEP]']
[Init] best perm rec loss: 0.7458518743515015 for ['[CLS] perfect cam channel working 140et [SEP]']
[Init] best perm rec loss: 0.7445951104164124 for ['[CLS] perfect working cam 140et channel [SEP]']
[Init] best perm rec loss: 0.7433086037635803 for ['[CLS] cam channel perfectet working 140 [SEP]']
[Init] best perm rec loss: 0.743118941783905 for ['[CLS] cam working 140et perfect channel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.591 (perp=11.246, rec=0.324, cos=0.018), tot_loss_proj:4.155 [t=0.23s]
prediction: ['[CLS] un memories ebonytable machinery award [SEP]']
[ 100/2000] tot_loss=2.209 (perp=10.013, rec=0.201, cos=0.005), tot_loss_proj:3.011 [t=0.24s]
prediction: ['[CLS]forget untotable characters and [SEP]']
[ 150/2000] tot_loss=1.946 (perp=9.090, rec=0.124, cos=0.003), tot_loss_proj:3.707 [t=0.24s]
prediction: ['[CLS]forget untable characters and [SEP]']
[ 200/2000] tot_loss=1.918 (perp=9.090, rec=0.098, cos=0.002), tot_loss_proj:3.667 [t=0.24s]
prediction: ['[CLS]forget untable characters and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.203 (perp=5.520, rec=0.096, cos=0.003), tot_loss_proj:1.295 [t=0.30s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 300/2000] tot_loss=1.185 (perp=5.520, rec=0.080, cos=0.002), tot_loss_proj:1.297 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.183 (perp=5.520, rec=0.078, cos=0.002), tot_loss_proj:1.297 [t=0.24s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.161 (perp=5.514, rec=0.057, cos=0.002), tot_loss_proj:1.390 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 450/2000] tot_loss=1.167 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.379 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.186 (perp=5.514, rec=0.082, cos=0.002), tot_loss_proj:1.392 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.388 [t=0.23s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 600/2000] tot_loss=1.180 (perp=5.514, rec=0.076, cos=0.002), tot_loss_proj:1.393 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.170 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.382 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.167 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.386 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 750/2000] tot_loss=1.167 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.385 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.173 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.386 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.383 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 900/2000] tot_loss=1.162 (perp=5.514, rec=0.058, cos=0.002), tot_loss_proj:1.381 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.170 (perp=5.514, rec=0.066, cos=0.002), tot_loss_proj:1.380 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.156 (perp=5.514, rec=0.051, cos=0.002), tot_loss_proj:1.383 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1050/2000] tot_loss=1.162 (perp=5.514, rec=0.057, cos=0.002), tot_loss_proj:1.379 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.161 (perp=5.514, rec=0.057, cos=0.002), tot_loss_proj:1.375 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.177 (perp=5.514, rec=0.073, cos=0.002), tot_loss_proj:1.386 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1200/2000] tot_loss=1.180 (perp=5.514, rec=0.076, cos=0.002), tot_loss_proj:1.370 [t=0.24s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.161 (perp=5.514, rec=0.057, cos=0.002), tot_loss_proj:1.372 [t=0.23s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.170 (perp=5.514, rec=0.066, cos=0.002), tot_loss_proj:1.376 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1350/2000] tot_loss=1.165 (perp=5.514, rec=0.061, cos=0.002), tot_loss_proj:1.379 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.163 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.373 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.168 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.371 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1500/2000] tot_loss=1.164 (perp=5.514, rec=0.060, cos=0.002), tot_loss_proj:1.374 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.175 (perp=5.514, rec=0.070, cos=0.002), tot_loss_proj:1.378 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.166 (perp=5.514, rec=0.062, cos=0.002), tot_loss_proj:1.372 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1650/2000] tot_loss=1.177 (perp=5.514, rec=0.072, cos=0.002), tot_loss_proj:1.375 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.382 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.170 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.377 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1800/2000] tot_loss=1.163 (perp=5.514, rec=0.058, cos=0.002), tot_loss_proj:1.377 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.170 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.380 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.173 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.380 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1950/2000] tot_loss=1.170 (perp=5.514, rec=0.066, cos=0.002), tot_loss_proj:1.376 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.174 (perp=5.514, rec=0.070, cos=0.002), tot_loss_proj:1.378 [t=0.22s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] unforgettable and characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 93.205 | p: 92.719 | r: 93.767
rouge2     | fm: 60.404 | p: 60.156 | r: 60.644
rougeL     | fm: 81.741 | p: 81.364 | r: 82.198
rougeLsum  | fm: 81.666 | p: 81.309 | r: 82.144
r1fm+r2fm = 153.608

input #97 time: 0:09:07 | total time: 15:06:13


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9991922212899854
highest_index [0]
highest [0.9991922212899854]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.7134081721305847 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.7081572413444519 for ['[CLS] prohibited nos jed ada [SEP]']
[Init] best perm rec loss: 0.70798659324646 for ['[CLS] nos ada prohibited jed [SEP]']
[Init] best perm rec loss: 0.7077512145042419 for ['[CLS] ada nos jed prohibited [SEP]']
[Init] best perm rec loss: 0.7026987075805664 for ['[CLS] nos jed ada prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.565 (perp=11.687, rec=0.218, cos=0.009), tot_loss_proj:3.188 [t=0.23s]
prediction: ['[CLS] unfulful boarding [SEP]']
[ 100/2000] tot_loss=2.253 (perp=10.618, rec=0.123, cos=0.007), tot_loss_proj:2.527 [t=0.23s]
prediction: ['[CLS] unfulfullling [SEP]']
[ 150/2000] tot_loss=1.084 (perp=4.948, rec=0.092, cos=0.003), tot_loss_proj:1.068 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 200/2000] tot_loss=1.070 (perp=4.948, rec=0.075, cos=0.006), tot_loss_proj:1.049 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.060 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.070 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.049 (perp=4.948, rec=0.057, cos=0.002), tot_loss_proj:1.057 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.067 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.059 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.068 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.060 (perp=4.948, rec=0.069, cos=0.002), tot_loss_proj:1.056 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.048 (perp=4.948, rec=0.057, cos=0.002), tot_loss_proj:1.059 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.045 (perp=4.948, rec=0.054, cos=0.002), tot_loss_proj:1.049 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.067 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.056 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.060 (perp=4.948, rec=0.069, cos=0.002), tot_loss_proj:1.066 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.068 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.057 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.051 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.055 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.061 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.053 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.065 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.060 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.063 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.055 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.054 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.066 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.052 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.059 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.062 (perp=4.948, rec=0.071, cos=0.002), tot_loss_proj:1.067 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.054 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.054 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.062 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.058 (perp=4.948, rec=0.067, cos=0.002), tot_loss_proj:1.054 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.060 (perp=4.948, rec=0.069, cos=0.002), tot_loss_proj:1.056 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.049 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.054 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.055 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.057 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.055 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.057 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.062 (perp=4.948, rec=0.071, cos=0.002), tot_loss_proj:1.063 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.048 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.277 | p: 92.790 | r: 93.832
rouge2     | fm: 60.938 | p: 60.683 | r: 61.248
rougeL     | fm: 81.842 | p: 81.463 | r: 82.333
rougeLsum  | fm: 81.931 | p: 81.500 | r: 82.367
r1fm+r2fm = 154.215

input #98 time: 0:09:09 | total time: 15:15:22


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.999309739415734
highest_index [0]
highest [0.999309739415734]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8733632564544678 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8684595823287964 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8659393191337585 for ['[CLS] freedom lay third cartwright u to tear supply disputed glasses operahus album [MASK] literature bart now associatedtmenty thou stated microphone poly frederick rogers lineshtake furport modern point rosewood mid early [SEP]']
[Init] best rec loss: 0.8593382239341736 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.8483469486236572 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 0.8376026749610901 for ['[CLS] sealed−1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 0.8301820158958435 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 0.8222801685333252 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.8184991478919983 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.8171400427818298 for ['[CLS] still barbie dental cushion distance whente screens taste ratings temps currently earliest himselfaging services garcia slight forced orientˈ re synonym te [MASK] thunder knowledge bearing right actuallyts ferns opposed bet claire harper [SEP]']
[Init] best perm rec loss: 0.8165922164916992 for ['[CLS] te bearing taste actually right dental forced harper opposed ferns re distance garcia bettste cushion orient still screens temps synonym ratings himself slightaging when barbie thunder services currently [MASK] knowledge claire earliestˈ [SEP]']
[Init] best perm rec loss: 0.8164383769035339 for ['[CLS] re harper knowledge claire cushionˈ currently bearing dental screensaging still right temps slight earliest services taste [MASK] forcedtets te thunder himself distance ratings barbie actually orient ferns when bet opposed garcia synonym [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.757 (perp=12.094, rec=0.316, cos=0.022), tot_loss_proj:3.089 [t=0.24s]
prediction: ['[CLS] walked out tape canned better junction stupid mean proof film dumb they princess enzyme bore products ruined but diging an just immediately bombings com like prizessing oakland kappa - radical phone bulls filmssing [SEP]']
[ 100/2000] tot_loss=2.606 (perp=11.816, rec=0.233, cos=0.009), tot_loss_proj:3.083 [t=0.24s]
prediction: ["[CLS] walked out film horrible out speakingssing fun proof filmander'`powered ` films ` but hadting most never fun ` his such wastessing heard curated, & ticket people filmssing [SEP]"]
[ 150/2000] tot_loss=2.350 (perp=10.764, rec=0.190, cos=0.008), tot_loss_proj:2.963 [t=0.24s]
prediction: ["[CLS] walked out film horrible out mutteringssing fun the film acids ` ` wanted `'shame but hadting most never fun horrible when saying drinksssing wasn!,'ticket somebody filmssing [SEP]"]
[ 200/2000] tot_loss=2.211 (perp=10.228, rec=0.161, cos=0.005), tot_loss_proj:2.871 [t=0.24s]
prediction: ["[CLS] walked out film terrible muttering mutteringssing fun the film horrible ` ` wanted `'teeth but hadssing most so fun terrible the the drinksssing was ticket,'ticket nobody filmssing [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.092 (perp=9.715, rec=0.144, cos=0.005), tot_loss_proj:2.898 [t=0.24s]
prediction: ["[CLS] walked out ` terrible muttering mutteringssing fun the film horrible ` ` mind `'terrible but hading most fun so terrible the the economicssing was ticket, n ticket they filmssing [SEP]"]
[ 300/2000] tot_loss=2.143 (perp=10.052, rec=0.129, cos=0.004), tot_loss_proj:3.370 [t=0.24s]
prediction: ["[CLS] walked out ` terrible muttering mutteringssing fun words film horrible ` ` mind terrible'` but hading much fun so terrible the the tiredssing was ticket, n ticket they filmssing [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.111 (perp=9.944, rec=0.118, cos=0.003), tot_loss_proj:2.806 [t=0.24s]
prediction: ["[CLS] walked out words terrible muttering mutteringssing fun words film horrible ` ` mind terrible'` but diing much fun so terrible was the tiredssing the ticket, n ticket they filmssing [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.018 (perp=9.476, rec=0.119, cos=0.004), tot_loss_proj:2.735 [t=0.24s]
prediction: ["[CLS] walked out muttering terrible words muttering di fun the film horrible ` ` mind terrible'cost but hadging much fun so terrible did the tiredssing the mind, n ticket they filmssing [SEP]"]
[ 450/2000] tot_loss=2.015 (perp=9.519, rec=0.109, cos=0.003), tot_loss_proj:2.718 [t=0.24s]
prediction: ["[CLS] walked out muttering terrible words muttering di fun the film horrible ` ` mind terrible'cost but hadging much fun so terrible did the tiredssing the that, n ticket they film irs [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.953 (perp=9.234, rec=0.104, cos=0.003), tot_loss_proj:2.740 [t=0.24s]
prediction: ["[CLS] walked out muttering terrible words muttering di fun the film horrible ` ` mind the'cost but hadging much fun so terrible did the tiredssing the that, n ticket they film irs [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.913 (perp=8.989, rec=0.112, cos=0.004), tot_loss_proj:2.584 [t=0.24s]
prediction: ["[CLS] walked out muttering horrible words muttering di fun the film horrible ` ` mind the'cost but hadging much fun so terrible did they tiredssing the that, n ticket the film irs [SEP]"]
[ 600/2000] tot_loss=1.821 (perp=8.563, rec=0.106, cos=0.002), tot_loss_proj:2.477 [t=0.24s]
prediction: ["[CLS] walked out muttering horrible words muttering di fun the film horrible ` ` mind the'cost but had so much fun so terrible did they tiredssing the that, n ticket the film irs [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.764 (perp=8.308, rec=0.100, cos=0.003), tot_loss_proj:2.453 [t=0.24s]
prediction: ["[CLS] walked out muttering horrible words muttering di fun the film horrible ` ` mind the'cost but had so much fun so terrible did they tiredssing the cost, n ticket the film cost [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.746 (perp=8.230, rec=0.098, cos=0.002), tot_loss_proj:2.307 [t=0.24s]
prediction: ["[CLS] walked out muttering horrible words muttering di fun the film ` like mind the horrible'cost but had so much fun so terrible did they tiredssing the cost, n ticket the film cost [SEP]"]
[ 750/2000] tot_loss=1.788 (perp=8.443, rec=0.097, cos=0.002), tot_loss_proj:2.402 [t=0.24s]
prediction: ["[CLS] walked out muttering ` words muttering di fun the film ` like mind the horrible'cost but had so much fun so terrible did they tiredssing the cost, n ticket the film cost [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.765 (perp=8.346, rec=0.094, cos=0.002), tot_loss_proj:2.648 [t=0.24s]
prediction: ["[CLS] walked out words like words muttering di fun the film ` ` mind the horrible'cost but had much much fun so terrible did they tiredssing the cost, n ticket the film cost [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.743 (perp=8.238, rec=0.094, cos=0.002), tot_loss_proj:2.593 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the film ` ` mind the horrible'cost but had much much fun so terrible did they tiredssing the cost, n ticket the film cost [SEP]"]
[ 900/2000] tot_loss=1.763 (perp=8.338, rec=0.093, cos=0.002), tot_loss_proj:2.404 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the film ` ` mind the horrible'cost but had much so fun so terrible did they tiredssing the cost, n ticket the film cost [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.716 (perp=8.124, rec=0.090, cos=0.002), tot_loss_proj:2.405 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the film ` ` mind the horrible'cost but had fun so much so terrible did they tiredssing the cost, n ticket the film cost [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.688 (perp=7.985, rec=0.089, cos=0.002), tot_loss_proj:2.346 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the film ` ` mind the horrible'cost but had so much fun so terrible did they tiredssing the ', n ticket the film cost [SEP]"]
[1050/2000] tot_loss=1.683 (perp=7.985, rec=0.084, cos=0.002), tot_loss_proj:2.340 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the film ` ` mind the horrible'cost but had so much fun so terrible did they tiredssing the ', n ticket the film cost [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.618 (perp=7.672, rec=0.082, cos=0.002), tot_loss_proj:2.292 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun so terrible did they tiredssing the ', n ticket the film cost [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.608 (perp=7.587, rec=0.089, cos=0.002), tot_loss_proj:2.358 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun so terrible did they tired, the'ssing n ticket the film cost [SEP]"]
[1200/2000] tot_loss=1.601 (perp=7.587, rec=0.082, cos=0.002), tot_loss_proj:2.355 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun so terrible did they tired, the'ssing n ticket the film cost [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.548 (perp=7.345, rec=0.077, cos=0.002), tot_loss_proj:2.207 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun so terrible did they tired, the'nssing ticket the film cost [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.550 (perp=7.345, rec=0.080, cos=0.002), tot_loss_proj:2.205 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun so terrible did they tired, the'nssing ticket the film cost [SEP]"]
[1350/2000] tot_loss=1.599 (perp=7.582, rec=0.081, cos=0.002), tot_loss_proj:2.191 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind that horrible film'but had so much fun so terrible did they tired, the'nssing ticket the film cost [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.547 (perp=7.345, rec=0.077, cos=0.002), tot_loss_proj:2.203 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun so terrible did they tired, the'nssing ticket the film cost [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.558 (perp=7.345, rec=0.087, cos=0.002), tot_loss_proj:2.205 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun so terrible did they tired, the'nssing ticket the film cost [SEP]"]
[1500/2000] tot_loss=1.556 (perp=7.351, rec=0.084, cos=0.002), tot_loss_proj:2.353 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun that terrible did they tired, the'nssing ticket the film cost [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.555 (perp=7.351, rec=0.083, cos=0.002), tot_loss_proj:2.353 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun that terrible did they tired, the'nssing ticket the film cost [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.551 (perp=7.325, rec=0.084, cos=0.002), tot_loss_proj:2.667 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun that they did terrible tired, the'nssing ticket the film cost [SEP]"]
[1650/2000] tot_loss=1.545 (perp=7.325, rec=0.079, cos=0.002), tot_loss_proj:2.670 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun that they did terrible tired, the'nssing ticket the film cost [SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=1.526 (perp=7.243, rec=0.076, cos=0.002), tot_loss_proj:2.593 [t=0.24s]
prediction: ["[CLS] walked out words muttering words like di fun the'` ` mind the horrible film'but had so much fun that they did tired, the terrible'nssing ticket the film cost [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.520 (perp=7.233, rec=0.072, cos=0.002), tot_loss_proj:2.567 [t=0.24s]
prediction: ["[CLS] walked out muttering words words like di fun the'` ` mind the horrible film'but had so much fun that they did tired, the terrible'nssing ticket the film cost [SEP]"]
[1800/2000] tot_loss=1.532 (perp=7.233, rec=0.084, cos=0.002), tot_loss_proj:2.563 [t=0.24s]
prediction: ["[CLS] walked out muttering words words like di fun the'` ` mind the horrible film'but had so much fun that they did tired, the terrible'nssing ticket the film cost [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.527 (perp=7.233, rec=0.079, cos=0.002), tot_loss_proj:2.563 [t=0.24s]
prediction: ["[CLS] walked out muttering words words like di fun the'` ` mind the horrible film'but had so much fun that they did tired, the terrible'nssing ticket the film cost [SEP]"]
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.508 (perp=7.132, rec=0.080, cos=0.002), tot_loss_proj:2.614 [t=0.24s]
prediction: ["[CLS] walked out muttering words words like fun the'di ` ` mind the horrible film'but had so much fun that they did tired, the terrible'nssing ticket the film cost [SEP]"]
[1950/2000] tot_loss=1.509 (perp=7.132, rec=0.081, cos=0.002), tot_loss_proj:2.619 [t=0.24s]
prediction: ["[CLS] walked out muttering words words like fun the'di ` ` mind the horrible film'but had so much fun that they did tired, the terrible'nssing ticket the film cost [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.486 (perp=7.068, rec=0.071, cos=0.002), tot_loss_proj:2.652 [t=0.24s]
prediction: ["[CLS] walked out muttering the words like fun words'di ` ` mind the horrible film'but had so much fun that they did tired, the terrible'nssing ticket the film cost [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] walked out muttering words words like di fun the'` ` mind the horrible film'but had so much fun that they did tired, the terrible'nssing ticket the film cost [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.193 | p: 70.968 | r: 84.615
rouge2     | fm: 47.273 | p: 43.333 | r: 52.000
rougeL     | fm: 63.158 | p: 58.065 | r: 69.231
rougeLsum  | fm: 63.158 | p: 58.065 | r: 69.231
r1fm+r2fm = 124.466

[Aggregate metrics]:
rouge1     | fm: 93.091 | p: 92.558 | r: 93.726
rouge2     | fm: 60.665 | p: 60.381 | r: 61.028
rougeL     | fm: 81.557 | p: 81.152 | r: 82.099
rougeLsum  | fm: 81.658 | p: 81.209 | r: 82.172
r1fm+r2fm = 153.756

input #99 time: 0:09:27 | total time: 15:24:50


Average Cosine Similarity: 0.9992812812989129
Done with all.
