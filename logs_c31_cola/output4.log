


Command: attack4.py --dataset cola --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola --n_steps 2000 --coeff_pooler_match 0.0 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization no --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 858.32it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
Harriet alternated folk songs and pop songs together.
========================
average of cosine similarity 0.9993562480586128
highest_index [0]
highest [0.9993562480586128]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 14207,  6585,  2094,  5154,  2774,  1998,  3769,  2774,  2362,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] harriet alternated folk songs and pop songs together. [SEP]']
[Init] best rec loss: 0.9993575811386108 for ['[CLS] study showing exchange victorywall same bryant compulsory cl regiments [SEP]']
[Init] best rec loss: 0.881753146648407 for ['[CLS] report make baglary fell paul max rape younger broken [SEP]']
[Init] best rec loss: 0.8786035180091858 for ['[CLS] ll himself by fines now pleased whole market none cody [SEP]']
[Init] best rec loss: 0.8534309267997742 for ['[CLS] high leonard " fae nightclub awaiting write spillstadyme [SEP]']
[Init] best rec loss: 0.8307695388793945 for ['[CLS] lo hr positionperation trees temperance madonnaguard minutes vs [SEP]']
[Init] best rec loss: 0.8198035359382629 for ['[CLS] ) monitor witch market issue healing stole dia indoor lane [SEP]']
[Init] best perm rec loss: 0.8187926411628723 for ['[CLS] market dia lane issue ) stole monitor witch indoor healing [SEP]']
[Init] best perm rec loss: 0.8181319236755371 for ['[CLS] market healing ) issue witch stole monitor indoor lane dia [SEP]']
[Init] best perm rec loss: 0.8154435753822327 for ['[CLS] witch healing lane ) issue stole indoor monitor market dia [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.184 (perp=12.329, rec=0.482, cos=0.236), tot_loss_proj:4.439 [t=0.18s]
prediction: ['[CLS] nissan alternate cr songs twice verse photos pairing [SEP] isbn [SEP]']
[ 100/2000] tot_loss=2.118 (perp=8.906, rec=0.286, cos=0.050), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS] harriet alternated songs, pop alternate harriet trading. [SEP]']
[ 150/2000] tot_loss=2.404 (perp=10.487, rec=0.259, cos=0.048), tot_loss_proj:4.033 [t=0.18s]
prediction: ['[CLS] harriet alternated songs, pop alternate harriet initially alternate [SEP]']
[ 200/2000] tot_loss=2.018 (perp=8.849, rec=0.218, cos=0.030), tot_loss_proj:3.695 [t=0.20s]
prediction: ['[CLS] harriet alternated songs, alongside lgbt harriet mixed together [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.951 (perp=8.717, rec=0.188, cos=0.020), tot_loss_proj:3.441 [t=0.19s]
prediction: ['[CLS] harriet alternated songs together.d harriet mixed together [SEP]']
[ 300/2000] tot_loss=2.143 (perp=9.894, rec=0.151, cos=0.012), tot_loss_proj:3.834 [t=0.21s]
prediction: ['[CLS] harriet alternated songs together.d harriet together together [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.733 (perp=7.252, rec=0.239, cos=0.044), tot_loss_proj:3.380 [t=0.23s]
prediction: ['[CLS] harriet alternate folk songs and folk songs routed together [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.642 (perp=7.252, rec=0.176, cos=0.016), tot_loss_proj:3.384 [t=0.18s]
prediction: ['[CLS] harriet alternate folk songs and folk songs routed together [SEP]']
[ 450/2000] tot_loss=1.592 (perp=7.014, rec=0.161, cos=0.028), tot_loss_proj:3.220 [t=0.25s]
prediction: ['[CLS] harriet alternate folk songs and folk songs.d together [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.666 (perp=7.708, rec=0.116, cos=0.009), tot_loss_proj:3.336 [t=0.18s]
prediction: ['[CLS] harriet alternate folk songs and folk pop.d together [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.623 (perp=10.028, rec=0.434, cos=0.184), tot_loss_proj:3.938 [t=0.18s]
prediction: ['[CLS] harriet alternate folk songs and load pop togetherd how [SEP]']
[ 600/2000] tot_loss=2.315 (perp=10.028, rec=0.266, cos=0.044), tot_loss_proj:3.958 [t=0.19s]
prediction: ['[CLS] harriet alternate folk songs and load pop togetherd how [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.136 (perp=9.474, rec=0.218, cos=0.023), tot_loss_proj:3.867 [t=0.24s]
prediction: ['[CLS] harriet alternate folk songs and pair popd together ro [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.900 (perp=8.461, rec=0.191, cos=0.017), tot_loss_proj:3.633 [t=0.21s]
prediction: ['[CLS] harriet alternate folk songs and songs paird together ro [SEP]']
[ 750/2000] tot_loss=1.881 (perp=8.461, rec=0.176, cos=0.013), tot_loss_proj:3.638 [t=0.18s]
prediction: ['[CLS] harriet alternate folk songs and songs paird together ro [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.861 (perp=8.461, rec=0.157, cos=0.012), tot_loss_proj:3.637 [t=0.23s]
prediction: ['[CLS] harriet alternate folk songs and songs paird together ro [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.847 (perp=8.461, rec=0.145, cos=0.010), tot_loss_proj:3.640 [t=0.20s]
prediction: ['[CLS] harriet alternate folk songs and songs paird together ro [SEP]']
[ 900/2000] tot_loss=1.842 (perp=8.482, rec=0.137, cos=0.009), tot_loss_proj:3.646 [t=0.26s]
prediction: ['[CLS] harriet alternate folk songs and songs paird together alto [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.844 (perp=8.482, rec=0.139, cos=0.009), tot_loss_proj:3.642 [t=0.18s]
prediction: ['[CLS] harriet alternate folk songs and songs paird together alto [SEP]']
Attempt swap
[1000/2000] tot_loss=1.844 (perp=8.482, rec=0.139, cos=0.008), tot_loss_proj:3.639 [t=0.18s]
prediction: ['[CLS] harriet alternate folk songs and songs paird together alto [SEP]']
[1050/2000] tot_loss=1.908 (perp=8.846, rec=0.131, cos=0.008), tot_loss_proj:3.724 [t=0.18s]
prediction: ['[CLS] harriet alternate folk songs and songs folkd together alto [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.812 (perp=8.364, rec=0.130, cos=0.010), tot_loss_proj:3.595 [t=0.18s]
prediction: ['[CLS] harriet alternated folk songs and songs folk together alto [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.586 (perp=7.229, rec=0.132, cos=0.008), tot_loss_proj:3.423 [t=0.22s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together alto [SEP]']
[1200/2000] tot_loss=1.573 (perp=7.229, rec=0.120, cos=0.008), tot_loss_proj:3.423 [t=0.20s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together alto [SEP]']
Attempt swap
[1250/2000] tot_loss=1.543 (perp=7.081, rec=0.120, cos=0.007), tot_loss_proj:1.867 [t=0.20s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together ་ [SEP]']
Attempt swap
[1300/2000] tot_loss=1.541 (perp=7.081, rec=0.118, cos=0.007), tot_loss_proj:1.865 [t=0.21s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together ་ [SEP]']
[1350/2000] tot_loss=1.528 (perp=7.081, rec=0.105, cos=0.007), tot_loss_proj:1.856 [t=0.22s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together ་ [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.479 (perp=6.804, rec=0.111, cos=0.008), tot_loss_proj:3.134 [t=0.18s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.478 (perp=6.804, rec=0.109, cos=0.008), tot_loss_proj:3.196 [t=0.20s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
[1500/2000] tot_loss=1.484 (perp=6.804, rec=0.116, cos=0.008), tot_loss_proj:3.198 [t=0.22s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
Attempt swap
[1550/2000] tot_loss=1.486 (perp=6.804, rec=0.118, cos=0.007), tot_loss_proj:3.197 [t=0.19s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
Attempt swap
[1600/2000] tot_loss=1.479 (perp=6.804, rec=0.111, cos=0.007), tot_loss_proj:3.194 [t=0.18s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
[1650/2000] tot_loss=1.477 (perp=6.804, rec=0.110, cos=0.007), tot_loss_proj:3.195 [t=0.22s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
Attempt swap
[1700/2000] tot_loss=1.477 (perp=6.804, rec=0.110, cos=0.007), tot_loss_proj:3.199 [t=0.24s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
Attempt swap
[1750/2000] tot_loss=1.486 (perp=6.804, rec=0.118, cos=0.007), tot_loss_proj:3.194 [t=0.18s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
[1800/2000] tot_loss=1.472 (perp=6.804, rec=0.104, cos=0.007), tot_loss_proj:3.196 [t=0.18s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
Attempt swap
[1850/2000] tot_loss=1.468 (perp=6.804, rec=0.100, cos=0.007), tot_loss_proj:3.197 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
Attempt swap
[1900/2000] tot_loss=1.475 (perp=6.804, rec=0.107, cos=0.007), tot_loss_proj:3.197 [t=0.18s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
[1950/2000] tot_loss=1.472 (perp=6.804, rec=0.104, cos=0.007), tot_loss_proj:3.190 [t=0.23s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
Attempt swap
[2000/2000] tot_loss=1.471 (perp=6.804, rec=0.104, cos=0.007), tot_loss_proj:3.195 [t=0.18s]
prediction: ['[CLS] harriet alternated folk songs and ་ folk songs together [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] harriet alternated folk songs and pop songs together. [SEP]
========================
predicted: 
========================
[CLS] harriet alternated folk songs and ་ folk songs together [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 77.778 | p: 77.778 | r: 77.778
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 167.778

[Aggregate metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 77.778 | p: 77.778 | r: 77.778
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 167.778

input #0 time: 0:08:18 | total time: 0:08:18


Running input #1 of 100.
reference: 
========================
Who do you think that will question Seamus first?
========================
average of cosine similarity 0.999183520745321
highest_index [0]
highest [0.999183520745321]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2040,  2079,  2017,  2228,  2008,  2097,  3160, 24993,  2034,
          1029,   102]], device='cuda:0')
Debug: ref = ['[CLS] who do you think that will question seamus first? [SEP]']
[Init] best rec loss: 0.842589259147644 for ['[CLS] singerии middlesbrough tells certificate numbering century sung nowhere go [SEP]']
[Init] best rec loss: 0.8232784271240234 for ['[CLS] israel work rotational sights warm exclusive neither holding award jet [SEP]']
[Init] best rec loss: 0.7734784483909607 for ['[CLS] can kerr dry jack hood shownnsed powered feet [CLS] [SEP]']
[Init] best rec loss: 0.6931681632995605 for ['[CLS] because richest soc final melbourne gallo building mob might storm [SEP]']
[Init] best rec loss: 0.6918148398399353 for ['[CLS]less millennium billboard ron trial marino empire clerk kai brand [SEP]']
[Init] best rec loss: 0.6907491683959961 for ['[CLS] whitney paid space besides itself freedomud white waist there [SEP]']
[Init] best rec loss: 0.6749796271324158 for ['[CLS]lance spiders roman above selectcarriageoured towardsiness page [SEP]']
[Init] best perm rec loss: 0.6743735074996948 for ['[CLS]iness roman selectcarriage towardsoured abovelance page spiders [SEP]']
[Init] best perm rec loss: 0.6720325946807861 for ['[CLS]lance towards spiders aboveoured romaniness select pagecarriage [SEP]']
[Init] best perm rec loss: 0.6717727780342102 for ['[CLS] page select spidersinesscarriage abovelance romanoured towards [SEP]']
[Init] best perm rec loss: 0.6715611815452576 for ['[CLS] towards page spidersoured selectiness romanlance abovecarriage [SEP]']
[Init] best perm rec loss: 0.6711361408233643 for ['[CLS] abovecarriagelance spidersiness towards pageoured roman select [SEP]']
[Init] best perm rec loss: 0.6707462668418884 for ['[CLS] page above roman spiders selectlanceinesscarriage towardsoured [SEP]']
[Init] best perm rec loss: 0.6705222725868225 for ['[CLS] roman pageinesscarriage select towards above spiderslanceoured [SEP]']
[Init] best perm rec loss: 0.6702622771263123 for ['[CLS]ourediness select page towards roman above spiderslancecarriage [SEP]']
[Init] best perm rec loss: 0.6695494055747986 for ['[CLS]iness page above spiders romancarriageoured towardslance select [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.644 (perp=10.906, rec=0.397, cos=0.066), tot_loss_proj:3.070 [t=0.17s]
prediction: ['[CLS] whom miss west 2018 from atunced cars2 transfer [SEP]']
[ 100/2000] tot_loss=2.603 (perp=11.071, rec=0.322, cos=0.067), tot_loss_proj:2.982 [t=0.18s]
prediction: ['[CLS] whom politician dropped ultimate which that seamus seamus chance? [SEP]']
[ 150/2000] tot_loss=1.850 (perp=7.898, rec=0.240, cos=0.031), tot_loss_proj:2.386 [t=0.17s]
prediction: ['[CLS] whom should will who think that seamus seamus?? [SEP]']
[ 200/2000] tot_loss=1.722 (perp=7.598, rec=0.184, cos=0.018), tot_loss_proj:2.230 [t=0.24s]
prediction: ['[CLS] you did will who think that seamus seamus?? [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.876 (perp=7.992, rec=0.252, cos=0.026), tot_loss_proj:2.689 [t=0.18s]
prediction: ['[CLS] who you will you think that seamus seamus first? [SEP]']
[ 300/2000] tot_loss=1.765 (perp=7.992, rec=0.158, cos=0.009), tot_loss_proj:2.733 [t=0.22s]
prediction: ['[CLS] who you will you think that seamus seamus first? [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.536 (perp=6.861, rec=0.155, cos=0.008), tot_loss_proj:2.135 [t=0.18s]
prediction: ['[CLS] who will you think that you seamus seamus first? [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.492 (perp=6.605, rec=0.164, cos=0.008), tot_loss_proj:2.057 [t=0.20s]
prediction: ['[CLS] who do you think that will seamus seamus first? [SEP]']
[ 450/2000] tot_loss=1.461 (perp=6.605, rec=0.135, cos=0.005), tot_loss_proj:2.080 [t=0.24s]
prediction: ['[CLS] who do you think that will seamus seamus first? [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.385 (perp=6.331, rec=0.114, cos=0.004), tot_loss_proj:2.029 [t=0.20s]
prediction: ['[CLS] who do you think that seamus will seamus first? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.388 (perp=6.331, rec=0.118, cos=0.004), tot_loss_proj:2.028 [t=0.18s]
prediction: ['[CLS] who do you think that seamus will seamus first? [SEP]']
[ 600/2000] tot_loss=1.376 (perp=6.331, rec=0.106, cos=0.004), tot_loss_proj:2.026 [t=0.18s]
prediction: ['[CLS] who do you think that seamus will seamus first? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.389 (perp=6.398, rec=0.105, cos=0.004), tot_loss_proj:1.772 [t=0.21s]
prediction: ['[CLS] who do you think that will will seamus first? [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.319 (perp=6.051, rec=0.105, cos=0.004), tot_loss_proj:1.969 [t=0.26s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
[ 750/2000] tot_loss=1.317 (perp=6.051, rec=0.103, cos=0.004), tot_loss_proj:1.970 [t=0.22s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.316 (perp=6.051, rec=0.102, cos=0.004), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.312 (perp=6.051, rec=0.098, cos=0.004), tot_loss_proj:1.961 [t=0.26s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
[ 900/2000] tot_loss=1.317 (perp=6.051, rec=0.103, cos=0.004), tot_loss_proj:1.962 [t=0.25s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.310 (perp=6.051, rec=0.096, cos=0.004), tot_loss_proj:1.961 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.307 (perp=6.051, rec=0.093, cos=0.004), tot_loss_proj:1.961 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
[1050/2000] tot_loss=1.306 (perp=6.051, rec=0.092, cos=0.004), tot_loss_proj:1.963 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.313 (perp=6.051, rec=0.098, cos=0.004), tot_loss_proj:1.958 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.312 (perp=6.051, rec=0.098, cos=0.004), tot_loss_proj:1.958 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
[1200/2000] tot_loss=1.311 (perp=6.051, rec=0.097, cos=0.004), tot_loss_proj:1.960 [t=0.23s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.313 (perp=6.051, rec=0.099, cos=0.004), tot_loss_proj:1.957 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.315 (perp=6.051, rec=0.101, cos=0.004), tot_loss_proj:1.953 [t=0.25s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
[1350/2000] tot_loss=1.300 (perp=6.051, rec=0.086, cos=0.004), tot_loss_proj:1.950 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.318 (perp=6.051, rec=0.104, cos=0.004), tot_loss_proj:1.956 [t=0.21s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.309 (perp=6.051, rec=0.095, cos=0.004), tot_loss_proj:1.953 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
[1500/2000] tot_loss=1.304 (perp=6.051, rec=0.091, cos=0.004), tot_loss_proj:1.949 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.296 (perp=6.051, rec=0.082, cos=0.004), tot_loss_proj:1.958 [t=0.19s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.296 (perp=6.051, rec=0.083, cos=0.004), tot_loss_proj:1.947 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
[1650/2000] tot_loss=1.312 (perp=6.051, rec=0.099, cos=0.004), tot_loss_proj:1.952 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.305 (perp=6.051, rec=0.091, cos=0.004), tot_loss_proj:1.948 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.290 (perp=6.051, rec=0.076, cos=0.004), tot_loss_proj:1.953 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
[1800/2000] tot_loss=1.307 (perp=6.051, rec=0.093, cos=0.004), tot_loss_proj:1.950 [t=0.23s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.306 (perp=6.051, rec=0.092, cos=0.004), tot_loss_proj:1.950 [t=0.18s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.300 (perp=6.051, rec=0.086, cos=0.004), tot_loss_proj:1.955 [t=0.23s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
[1950/2000] tot_loss=1.303 (perp=6.051, rec=0.089, cos=0.004), tot_loss_proj:1.950 [t=0.19s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.300 (perp=6.051, rec=0.086, cos=0.004), tot_loss_proj:1.950 [t=0.23s]
prediction: ['[CLS] who do you think that will seamus will first? [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] who do you think that will question seamus first? [SEP]
========================
predicted: 
========================
[CLS] who do you think that will seamus will first? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 160.909

[Aggregate metrics]:
rouge1     | fm: 90.455 | p: 90.455 | r: 90.455
rouge2     | fm: 73.889 | p: 73.889 | r: 73.889
rougeL     | fm: 90.455 | p: 90.455 | r: 90.455
rougeLsum  | fm: 90.455 | p: 90.455 | r: 90.455
r1fm+r2fm = 164.343

input #1 time: 0:08:15 | total time: 0:16:34


Running input #2 of 100.
reference: 
========================
The boy ran.
========================
average of cosine similarity 0.9993826057414857
highest_index [0]
highest [0.9993826057414857]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 1996, 2879, 2743, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the boy ran. [SEP]']
[Init] best rec loss: 0.9620961546897888 for ['[CLS] animation equal wickets gran [SEP]']
[Init] best rec loss: 0.9495673179626465 for ['[CLS] rose instruction lengths ; [SEP]']
[Init] best rec loss: 0.9206191301345825 for ['[CLS] february bachelor energyets [SEP]']
[Init] best rec loss: 0.8724637627601624 for ['[CLS] directly goes our sang [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.772 (perp=10.795, rec=0.622, cos=0.991), tot_loss_proj:4.261 [t=0.18s]
prediction: ['[CLS] woman ran ran ran [SEP]']
[ 100/2000] tot_loss=2.857 (perp=11.071, rec=0.448, cos=0.195), tot_loss_proj:3.987 [t=0.26s]
prediction: ['[CLS] woman ran extract ran [SEP]']
[ 150/2000] tot_loss=1.993 (perp=8.931, rec=0.188, cos=0.018), tot_loss_proj:3.560 [t=0.18s]
prediction: ['[CLS] woman the boy ran [SEP]']
[ 200/2000] tot_loss=1.687 (perp=7.813, rec=0.117, cos=0.007), tot_loss_proj:2.190 [t=0.18s]
prediction: ['[CLS]. the boy ran [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.640 (perp=7.359, rec=0.158, cos=0.010), tot_loss_proj:2.093 [t=0.22s]
prediction: ['[CLS] the boy ran! [SEP]']
[ 300/2000] tot_loss=1.339 (perp=6.128, rec=0.107, cos=0.007), tot_loss_proj:1.344 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.322 (perp=6.128, rec=0.090, cos=0.007), tot_loss_proj:1.344 [t=0.27s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.325 (perp=6.128, rec=0.093, cos=0.007), tot_loss_proj:1.349 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[ 450/2000] tot_loss=1.331 (perp=6.128, rec=0.099, cos=0.007), tot_loss_proj:1.343 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.323 (perp=6.128, rec=0.091, cos=0.007), tot_loss_proj:1.340 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.326 (perp=6.128, rec=0.094, cos=0.007), tot_loss_proj:1.334 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[ 600/2000] tot_loss=1.320 (perp=6.128, rec=0.088, cos=0.007), tot_loss_proj:1.333 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.325 (perp=6.128, rec=0.093, cos=0.007), tot_loss_proj:1.343 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.319 (perp=6.128, rec=0.087, cos=0.007), tot_loss_proj:1.338 [t=0.23s]
prediction: ['[CLS] the boy ran. [SEP]']
[ 750/2000] tot_loss=1.324 (perp=6.128, rec=0.092, cos=0.007), tot_loss_proj:1.352 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.319 (perp=6.128, rec=0.086, cos=0.007), tot_loss_proj:1.345 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.332 (perp=6.128, rec=0.100, cos=0.007), tot_loss_proj:1.345 [t=0.19s]
prediction: ['[CLS] the boy ran. [SEP]']
[ 900/2000] tot_loss=1.317 (perp=6.128, rec=0.084, cos=0.007), tot_loss_proj:1.344 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.326 (perp=6.128, rec=0.093, cos=0.007), tot_loss_proj:1.337 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.321 (perp=6.128, rec=0.089, cos=0.007), tot_loss_proj:1.340 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[1050/2000] tot_loss=1.316 (perp=6.128, rec=0.084, cos=0.007), tot_loss_proj:1.338 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.319 (perp=6.128, rec=0.086, cos=0.007), tot_loss_proj:1.338 [t=0.21s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.315 (perp=6.128, rec=0.083, cos=0.007), tot_loss_proj:1.346 [t=0.21s]
prediction: ['[CLS] the boy ran. [SEP]']
[1200/2000] tot_loss=1.316 (perp=6.128, rec=0.084, cos=0.007), tot_loss_proj:1.336 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.326 (perp=6.128, rec=0.094, cos=0.007), tot_loss_proj:1.340 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.319 (perp=6.128, rec=0.087, cos=0.007), tot_loss_proj:1.344 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[1350/2000] tot_loss=1.325 (perp=6.128, rec=0.093, cos=0.007), tot_loss_proj:1.338 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.329 (perp=6.128, rec=0.096, cos=0.007), tot_loss_proj:1.342 [t=0.19s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.311 (perp=6.128, rec=0.079, cos=0.007), tot_loss_proj:1.336 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[1500/2000] tot_loss=1.314 (perp=6.128, rec=0.082, cos=0.007), tot_loss_proj:1.341 [t=0.20s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.330 (perp=6.128, rec=0.097, cos=0.007), tot_loss_proj:1.345 [t=0.23s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.321 (perp=6.128, rec=0.089, cos=0.007), tot_loss_proj:1.344 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
[1650/2000] tot_loss=1.320 (perp=6.128, rec=0.087, cos=0.007), tot_loss_proj:1.337 [t=0.21s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.314 (perp=6.128, rec=0.081, cos=0.007), tot_loss_proj:1.338 [t=0.24s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.320 (perp=6.128, rec=0.088, cos=0.007), tot_loss_proj:1.341 [t=0.23s]
prediction: ['[CLS] the boy ran. [SEP]']
[1800/2000] tot_loss=1.332 (perp=6.128, rec=0.099, cos=0.007), tot_loss_proj:1.339 [t=0.21s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.309 (perp=6.128, rec=0.077, cos=0.007), tot_loss_proj:1.344 [t=0.25s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.326 (perp=6.128, rec=0.094, cos=0.007), tot_loss_proj:1.345 [t=0.26s]
prediction: ['[CLS] the boy ran. [SEP]']
[1950/2000] tot_loss=1.313 (perp=6.128, rec=0.081, cos=0.007), tot_loss_proj:1.343 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.322 (perp=6.128, rec=0.090, cos=0.007), tot_loss_proj:1.350 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] the boy ran. [SEP]
========================
predicted: 
========================
[CLS] the boy ran. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.636 | p: 93.636 | r: 93.636
rouge2     | fm: 82.593 | p: 82.593 | r: 82.593
rougeL     | fm: 93.636 | p: 93.636 | r: 93.636
rougeLsum  | fm: 93.636 | p: 93.636 | r: 93.636
r1fm+r2fm = 176.229

input #2 time: 0:08:04 | total time: 0:24:38


Running input #3 of 100.
reference: 
========================
I wonder who Bill saw and liked Mary.
========================
average of cosine similarity 0.9993519691025421
highest_index [0]
highest [0.9993519691025421]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1045, 4687, 2040, 3021, 2387, 1998, 4669, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i wonder who bill saw and liked mary. [SEP]']
[Init] best rec loss: 0.8413416743278503 for ['[CLS] term acute turner ren reunion streets strikes still preservation [SEP]']
[Init] best rec loss: 0.8077667951583862 for ['[CLS] safety acting reserve casencies5 walt ready clockwise [SEP]']
[Init] best rec loss: 0.8017082214355469 for ['[CLS] u masters particular prentice payment to councillor cl mls [SEP]']
[Init] best rec loss: 0.7690931558609009 for ['[CLS] talerth cricket favourites semi & reports tier female [SEP]']
[Init] best rec loss: 0.7666354775428772 for ['[CLS] matthew marked studies offensive titular sneak de drama escort [SEP]']
[Init] best rec loss: 0.7478668093681335 for ['[CLS]logist felt sympathetic analogy apr thick dakota origin barracks [SEP]']
[Init] best perm rec loss: 0.7411834597587585 for ['[CLS] felt origin sympathetic thicklogist dakota apr barracks analogy [SEP]']
[Init] best perm rec loss: 0.740568995475769 for ['[CLS]logist analogy barracks dakota thick apr origin sympathetic felt [SEP]']
[Init] best perm rec loss: 0.7380269169807434 for ['[CLS] dakotalogist apr analogy thick sympathetic felt origin barracks [SEP]']
[Init] best perm rec loss: 0.7372322082519531 for ['[CLS] sympathetic dakota thick felt origin analogy apr barrackslogist [SEP]']
[Init] best perm rec loss: 0.7371391654014587 for ['[CLS] apr felt analogy dakota thicklogist origin sympathetic barracks [SEP]']
[Init] best perm rec loss: 0.7346237301826477 for ['[CLS] thick dakota analogy feltlogist barracks apr origin sympathetic [SEP]']
[Init] best perm rec loss: 0.7333685159683228 for ['[CLS] origin dakota sympathetic felt aprlogist analogy thick barracks [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.951 (perp=11.741, rec=0.454, cos=0.150), tot_loss_proj:4.062 [t=0.17s]
prediction: ['[CLS] that maria settlement felt cleaned particularly loosely thicktangle [SEP]']
[ 100/2000] tot_loss=2.514 (perp=10.172, rec=0.381, cos=0.099), tot_loss_proj:3.646 [t=0.22s]
prediction: ['[CLS] that mary settlement liked mary. pressed thick dawson [SEP]']
[ 150/2000] tot_loss=2.238 (perp=8.778, rec=0.379, cos=0.104), tot_loss_proj:3.032 [t=0.24s]
prediction: ['[CLS] what mary river liked mary bill liked sheila. [SEP]']
[ 200/2000] tot_loss=2.276 (perp=9.124, rec=0.343, cos=0.108), tot_loss_proj:3.324 [t=0.17s]
prediction: ['[CLS] what mary saw likedaz bill liked bill. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.298 (perp=9.743, rec=0.287, cos=0.063), tot_loss_proj:3.226 [t=0.18s]
prediction: ['[CLS] wonder mary saw and who bill liked mary holden [SEP]']
[ 300/2000] tot_loss=2.420 (perp=10.613, rec=0.255, cos=0.042), tot_loss_proj:3.343 [t=0.21s]
prediction: ['[CLS] wonder mary saw and who bill liked mary... [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.839 (perp=7.727, rec=0.214, cos=0.080), tot_loss_proj:3.032 [t=0.20s]
prediction: ['[CLS] wonder mary saw bill and who liked mary. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.942 (perp=8.075, rec=0.280, cos=0.046), tot_loss_proj:3.147 [t=0.18s]
prediction: ['[CLS] mary wonder after bill and who liked mary. [SEP]']
[ 450/2000] tot_loss=1.853 (perp=8.075, rec=0.207, cos=0.031), tot_loss_proj:3.230 [t=0.19s]
prediction: ['[CLS] mary wonder after bill and who liked mary. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.014 (perp=8.148, rec=0.325, cos=0.059), tot_loss_proj:3.325 [t=0.27s]
prediction: ['[CLS] and wonder mary bill mary who liked mary. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.995 (perp=8.251, rec=0.288, cos=0.057), tot_loss_proj:3.157 [t=0.18s]
prediction: ['[CLS] and wonder saw bill mary who liked mary. [SEP]']
[ 600/2000] tot_loss=1.902 (perp=8.251, rec=0.224, cos=0.028), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] and wonder saw bill mary who liked mary. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.806 (perp=7.715, rec=0.226, cos=0.037), tot_loss_proj:3.244 [t=0.19s]
prediction: ['[CLS] and saw wonder bill mary who liked mary. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.712 (perp=6.994, rec=0.260, cos=0.053), tot_loss_proj:2.999 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
[ 750/2000] tot_loss=1.638 (perp=6.994, rec=0.208, cos=0.031), tot_loss_proj:3.014 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.624 (perp=6.994, rec=0.198, cos=0.027), tot_loss_proj:3.030 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.605 (perp=6.994, rec=0.182, cos=0.025), tot_loss_proj:3.029 [t=0.24s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
[ 900/2000] tot_loss=1.599 (perp=6.994, rec=0.177, cos=0.023), tot_loss_proj:3.026 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.585 (perp=6.994, rec=0.165, cos=0.022), tot_loss_proj:3.022 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.578 (perp=6.994, rec=0.159, cos=0.020), tot_loss_proj:3.024 [t=0.22s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
[1050/2000] tot_loss=1.580 (perp=6.994, rec=0.161, cos=0.020), tot_loss_proj:3.029 [t=0.20s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.585 (perp=6.994, rec=0.167, cos=0.019), tot_loss_proj:3.021 [t=0.21s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.575 (perp=6.994, rec=0.157, cos=0.019), tot_loss_proj:3.024 [t=0.21s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
[1200/2000] tot_loss=1.570 (perp=6.994, rec=0.153, cos=0.018), tot_loss_proj:3.026 [t=0.17s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.574 (perp=6.994, rec=0.158, cos=0.017), tot_loss_proj:3.022 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.568 (perp=6.994, rec=0.152, cos=0.017), tot_loss_proj:3.024 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
[1350/2000] tot_loss=1.557 (perp=6.994, rec=0.141, cos=0.017), tot_loss_proj:3.022 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.571 (perp=6.994, rec=0.156, cos=0.016), tot_loss_proj:3.022 [t=0.19s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.569 (perp=6.994, rec=0.154, cos=0.016), tot_loss_proj:3.029 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
[1500/2000] tot_loss=1.566 (perp=6.994, rec=0.152, cos=0.016), tot_loss_proj:3.027 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.562 (perp=6.994, rec=0.148, cos=0.015), tot_loss_proj:3.021 [t=0.19s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.560 (perp=6.994, rec=0.146, cos=0.015), tot_loss_proj:3.023 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
[1650/2000] tot_loss=1.563 (perp=6.994, rec=0.149, cos=0.015), tot_loss_proj:3.027 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.562 (perp=6.994, rec=0.148, cos=0.015), tot_loss_proj:3.024 [t=0.24s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.561 (perp=6.994, rec=0.147, cos=0.015), tot_loss_proj:3.027 [t=0.23s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
[1800/2000] tot_loss=1.554 (perp=6.994, rec=0.141, cos=0.015), tot_loss_proj:3.023 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.549 (perp=6.994, rec=0.135, cos=0.015), tot_loss_proj:3.021 [t=0.18s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.555 (perp=6.994, rec=0.142, cos=0.015), tot_loss_proj:3.024 [t=0.19s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
[1950/2000] tot_loss=1.545 (perp=6.994, rec=0.131, cos=0.014), tot_loss_proj:3.018 [t=0.20s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.561 (perp=6.994, rec=0.147, cos=0.014), tot_loss_proj:3.021 [t=0.24s]
prediction: ['[CLS] mary saw wonder bill and who liked mary. [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] i wonder who bill saw and liked mary. [SEP]
========================
predicted: 
========================
[CLS] mary saw wonder bill and who liked mary. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 22.222 | p: 22.222 | r: 22.222
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 112.222

[Aggregate metrics]:
rouge1     | fm: 92.727 | p: 92.727 | r: 92.727
rouge2     | fm: 67.500 | p: 67.500 | r: 67.500
rougeL     | fm: 87.727 | p: 87.727 | r: 87.727
rougeLsum  | fm: 87.727 | p: 87.727 | r: 87.727
r1fm+r2fm = 160.227

input #3 time: 0:08:01 | total time: 0:32:39


Running input #4 of 100.
reference: 
========================
While I might want to, this is the kind of thing that Harris has already suggested.
========================
average of cosine similarity 0.9993692677558084
highest_index [0]
highest [0.9993692677558084]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2096, 1045, 2453, 2215, 2000, 1010, 2023, 2003, 1996, 2785, 1997,
         2518, 2008, 5671, 2038, 2525, 4081, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]']
[Init] best rec loss: 1.0353513956069946 for ['[CLS] june stuffed eponymousdaepathic white bump earth critical security tata fraa area che range soory [SEP]']
[Init] best rec loss: 0.9104655981063843 for ['[CLS] rather againnae henry program seek csi finish et maya alternate drive airport r ke vermont witness 2011 [SEP]']
[Init] best rec loss: 0.9013139009475708 for ['[CLS]enter american howding meial pages navy based talking impact alternative bit frankenstein eating period saidain [SEP]']
[Init] best rec loss: 0.9006959199905396 for ['[CLS] handled off entirely seemedless need elsewhere paper quality trouble presence food anything wood along look tel hot [SEP]']
[Init] best rec loss: 0.8877056837081909 for ['[CLS]rao market object pocket muslim boys columbia producer drawn hostigen flowing media beam vice minutesrion steady [SEP]']
[Init] best perm rec loss: 0.8826872706413269 for ['[CLS] host minutes flowing media producer pocket beam market steady columbia viceraorion drawn boys objectigen muslim [SEP]']
[Init] best perm rec loss: 0.8705316185951233 for ['[CLS] object muslim boys steady vice pocket columbiarao host market producer beamigen media minutesrion drawn flowing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.872 (perp=11.795, rec=0.513, cos=1.000), tot_loss_proj:4.209 [t=0.17s]
prediction: ['[CLS] and only some roberts has over loomed earlier an marissa [SEP] thinking. feespt likely etc [SEP] [SEP]']
[ 100/2000] tot_loss=3.612 (perp=10.842, rec=0.443, cos=1.000), tot_loss_proj:3.974 [t=0.21s]
prediction: ['[CLS] and stated some really harris. probably announced opener mayor point deals. harris ( would suggested [SEP] [SEP]']
[ 150/2000] tot_loss=3.499 (perp=10.397, rec=0.419, cos=1.000), tot_loss_proj:3.969 [t=0.20s]
prediction: ['[CLS] the apparently some really harris. probably suggested opener mayor way value. harris ( definitely suggested carry [SEP]']
[ 200/2000] tot_loss=3.439 (perp=9.993, rec=0.442, cos=0.999), tot_loss_proj:3.873 [t=0.20s]
prediction: ['[CLS] while apparentlyrnier really harris with probably that opener obama wanted this. harris ( would suggested gave [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.073 (perp=8.530, rec=0.369, cos=0.998), tot_loss_proj:3.763 [t=0.22s]
prediction: ['[CLS] while already harris has harris. probably that certainly obama asks this. should ( would suggested of [SEP]']
[ 300/2000] tot_loss=3.455 (perp=10.363, rec=0.383, cos=0.999), tot_loss_proj:3.964 [t=0.20s]
prediction: ['[CLS] while while harris if harris. figured that certainly obama feels this. should ( could suggested carrying [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.286 (perp=9.662, rec=0.358, cos=0.996), tot_loss_proj:3.805 [t=0.19s]
prediction: ['[CLS] while while harris figured harris. that that certainly harris feels this. should ( thing suggested carrying [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.233 (perp=9.426, rec=0.353, cos=0.995), tot_loss_proj:3.770 [t=0.18s]
prediction: ['[CLS] while while harris figured harris. that that certainly harris feels this. should thing ( suggested carrying [SEP]']
[ 450/2000] tot_loss=3.322 (perp=9.811, rec=0.364, cos=0.996), tot_loss_proj:3.821 [t=0.18s]
prediction: ['[CLS] while while harris stayed harris. that that certainly harris stared this. should thing ( suggested carrying [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.213 (perp=9.419, rec=0.334, cos=0.995), tot_loss_proj:3.742 [t=0.21s]
prediction: ['[CLS] that while harris figured harris. that while certainly harris endemic kind. should thing, suggested carrying [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.162 (perp=9.137, rec=0.343, cos=0.992), tot_loss_proj:3.693 [t=0.18s]
prediction: ['[CLS]. while harris stayed harris. certainly that while harris endemic kind. might thing, suggested carrying [SEP]']
[ 600/2000] tot_loss=3.186 (perp=9.261, rec=0.339, cos=0.995), tot_loss_proj:3.724 [t=0.19s]
prediction: ['[CLS]. while harris stayed harris. certainly that while harris endemic kind. should thing, suggested carrying [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.249 (perp=9.601, rec=0.334, cos=0.995), tot_loss_proj:3.781 [t=0.18s]
prediction: ['[CLS] harrisworm while harris stayed. certainly that while harris endemic kind. might thing, suggested while [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.386 (perp=10.048, rec=0.380, cos=0.997), tot_loss_proj:3.888 [t=0.22s]
prediction: ['[CLS] harris stayedworm while wasn. certainly that while harris wondered kind. might thing ( suggested cheeks [SEP]']
[ 750/2000] tot_loss=3.392 (perp=10.284, rec=0.339, cos=0.996), tot_loss_proj:3.904 [t=0.23s]
prediction: ['[CLS] harris stayedworm whilerocity. certainly that while harris wondered kind. should thing ( suggested carrying [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.243 (perp=9.580, rec=0.330, cos=0.996), tot_loss_proj:3.785 [t=0.24s]
prediction: ['[CLS] harris stayedworm suggestedrocity. certainly that while harris asks kind. should thing ( while carrying [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.278 (perp=9.756, rec=0.331, cos=0.996), tot_loss_proj:3.787 [t=0.18s]
prediction: ['[CLS] harris stayed thru suggestedworm. certainly that while harris faced kind. should thing, while carrying [SEP]']
[ 900/2000] tot_loss=3.103 (perp=8.907, rec=0.326, cos=0.995), tot_loss_proj:3.642 [t=0.22s]
prediction: ['[CLS] harris stayed thru suggested appeal. certainly that while harris faced kind. should thing, while carrying [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.105 (perp=8.907, rec=0.328, cos=0.996), tot_loss_proj:3.637 [t=0.18s]
prediction: ['[CLS] harris stayed thru suggested appeal. certainly that while harris faced kind. should thing, while carrying [SEP]']
Attempt swap
[1000/2000] tot_loss=3.094 (perp=8.887, rec=0.321, cos=0.996), tot_loss_proj:3.629 [t=0.25s]
prediction: ['[CLS] harris stayed thru suggested appeal. certainly that while harris faced kind. should thing, while while [SEP]']
[1050/2000] tot_loss=3.088 (perp=8.887, rec=0.315, cos=0.996), tot_loss_proj:3.628 [t=0.18s]
prediction: ['[CLS] harris stayed thru suggested appeal. certainly that while harris faced kind. should thing, while while [SEP]']
Attempt swap
[1100/2000] tot_loss=3.044 (perp=8.605, rec=0.328, cos=0.995), tot_loss_proj:3.586 [t=0.24s]
prediction: ['[CLS] harris stayed thru suggested appeal. certainly that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
[1150/2000] tot_loss=2.978 (perp=8.331, rec=0.316, cos=0.995), tot_loss_proj:3.511 [t=0.23s]
prediction: ['[CLS] harris stayed thru suggested.. certainly that while harris seemed kind. should thing, while while [SEP]']
[1200/2000] tot_loss=2.986 (perp=8.331, rec=0.325, cos=0.995), tot_loss_proj:3.511 [t=0.26s]
prediction: ['[CLS] harris stayed thru suggested.. certainly that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.931 (perp=8.037, rec=0.328, cos=0.995), tot_loss_proj:3.490 [t=0.19s]
prediction: ['[CLS] harris stayed thru certainly.. suggested that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.908 (perp=7.960, rec=0.321, cos=0.995), tot_loss_proj:3.495 [t=0.21s]
prediction: ['[CLS] harris certainly stayed thru.. suggested that while harris faced kind. should thing, while while [SEP]']
[1350/2000] tot_loss=2.861 (perp=7.703, rec=0.326, cos=0.995), tot_loss_proj:3.517 [t=0.27s]
prediction: ['[CLS] harris certainly stayed thru.. suggested that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.834 (perp=7.633, rec=0.312, cos=0.995), tot_loss_proj:3.427 [t=0.26s]
prediction: ['[CLS] harris certainly stayed. thru. suggested that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
[1450/2000] tot_loss=2.849 (perp=7.633, rec=0.328, cos=0.994), tot_loss_proj:3.436 [t=0.22s]
prediction: ['[CLS] harris certainly stayed. thru. suggested that while harris seemed kind. should thing, while while [SEP]']
[1500/2000] tot_loss=2.836 (perp=7.633, rec=0.314, cos=0.995), tot_loss_proj:3.435 [t=0.18s]
prediction: ['[CLS] harris certainly stayed. thru. suggested that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
[1550/2000] tot_loss=2.838 (perp=7.633, rec=0.317, cos=0.995), tot_loss_proj:3.434 [t=0.18s]
prediction: ['[CLS] harris certainly stayed. thru. suggested that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
[1600/2000] tot_loss=2.842 (perp=7.633, rec=0.321, cos=0.995), tot_loss_proj:3.435 [t=0.18s]
prediction: ['[CLS] harris certainly stayed. thru. suggested that while harris seemed kind. should thing, while while [SEP]']
[1650/2000] tot_loss=2.827 (perp=7.587, rec=0.314, cos=0.995), tot_loss_proj:3.617 [t=0.19s]
prediction: ['[CLS] harris certainly stayed. is. suggested that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.781 (perp=7.320, rec=0.322, cos=0.995), tot_loss_proj:3.438 [t=0.19s]
prediction: ['[CLS] harris certainly stayed.. is suggested that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
[1750/2000] tot_loss=2.768 (perp=7.320, rec=0.309, cos=0.996), tot_loss_proj:3.437 [t=0.40s]
prediction: ['[CLS] harris certainly stayed.. is suggested that while harris seemed kind. should thing, while while [SEP]']
[1800/2000] tot_loss=2.775 (perp=7.320, rec=0.316, cos=0.995), tot_loss_proj:3.438 [t=0.22s]
prediction: ['[CLS] harris certainly stayed.. is suggested that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
[1850/2000] tot_loss=2.775 (perp=7.320, rec=0.315, cos=0.995), tot_loss_proj:3.440 [t=0.18s]
prediction: ['[CLS] harris certainly stayed.. is suggested that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
[1900/2000] tot_loss=2.781 (perp=7.320, rec=0.322, cos=0.995), tot_loss_proj:3.432 [t=0.18s]
prediction: ['[CLS] harris certainly stayed.. is suggested that while harris seemed kind. should thing, while while [SEP]']
[1950/2000] tot_loss=2.801 (perp=7.477, rec=0.310, cos=0.995), tot_loss_proj:3.441 [t=0.19s]
prediction: ['[CLS] harris certainly helps.. is suggested that while harris seemed kind. should thing, while while [SEP]']
Attempt swap
[2000/2000] tot_loss=2.811 (perp=7.477, rec=0.321, cos=0.995), tot_loss_proj:3.439 [t=0.27s]
prediction: ['[CLS] harris certainly helps.. is suggested that while harris seemed kind. should thing, while while [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]
========================
predicted: 
========================
[CLS] harris certainly stayed. is. suggested that while harris seemed kind. should thing, while while [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 52.941 | p: 56.250 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 29.412 | p: 31.250 | r: 27.778
rougeLsum  | fm: 29.412 | p: 31.250 | r: 27.778
r1fm+r2fm = 52.941

[Aggregate metrics]:
rouge1     | fm: 84.952 | p: 85.614 | r: 84.364
rouge2     | fm: 54.000 | p: 54.000 | r: 54.000
rougeL     | fm: 76.246 | p: 76.614 | r: 76.000
rougeLsum  | fm: 77.882 | p: 78.000 | r: 77.556
r1fm+r2fm = 138.952

input #4 time: 0:08:18 | total time: 0:40:58


Running input #5 of 100.
reference: 
========================
Who has seen my snorkel?
========================
average of cosine similarity 0.9994131902913326
highest_index [0]
highest [0.9994131902913326]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2040,  2038,  2464,  2026,  1055, 12131, 11705,  1029,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] who has seen my snorkel? [SEP]']
[Init] best rec loss: 1.0512324571609497 for ['[CLS] second lot dimensions absolutelyavia nuclear second century [SEP]']
[Init] best rec loss: 0.9496536254882812 for ['[CLS] softzzled 10 dark ob subscription fury cold [SEP]']
[Init] best rec loss: 0.9399934411048889 for ['[CLS] overall its gallo paintings playing percival crater huge [SEP]']
[Init] best rec loss: 0.8532701134681702 for ['[CLS] driven watering house corner head same advertisements show [SEP]']
[Init] best rec loss: 0.8511939644813538 for ['[CLS] the 10 surprise dear relieve leaf blair its [SEP]']
[Init] best rec loss: 0.8402397632598877 for ['[CLS] mallory loose theta drank thin funk soul = [SEP]']
[Init] best rec loss: 0.8126248121261597 for ['[CLS] nat politicalunk priceeon guess goalstered [SEP]']
[Init] best perm rec loss: 0.8102404475212097 for ['[CLS]eon goal price politicalstered natunk guess [SEP]']
[Init] best perm rec loss: 0.807880699634552 for ['[CLS] nat priceunk guesseon political goalstered [SEP]']
[Init] best perm rec loss: 0.8067676424980164 for ['[CLS] goal political priceeon guessunkstered nat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.325 (perp=13.898, rec=0.435, cos=0.110), tot_loss_proj:4.573 [t=0.25s]
prediction: ['[CLS]kie engineers belgian who towardབne matthew [SEP]']
[ 100/2000] tot_loss=2.731 (perp=10.786, rec=0.447, cos=0.126), tot_loss_proj:4.084 [t=0.18s]
prediction: ['[CLS] fish bus! finn. moment something rule [SEP]']
[ 150/2000] tot_loss=2.483 (perp=10.465, rec=0.331, cos=0.060), tot_loss_proj:4.039 [t=0.22s]
prediction: ['[CLS] marine pole where doyle? moment who? [SEP]']
[ 200/2000] tot_loss=2.297 (perp=9.764, rec=0.301, cos=0.044), tot_loss_proj:3.900 [t=0.18s]
prediction: ['[CLS] marine pole who doyle? ring who? [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.145 (perp=9.180, rec=0.276, cos=0.033), tot_loss_proj:3.656 [t=0.18s]
prediction: ['[CLS] marine seeing who finn? ring who? [SEP]']
[ 300/2000] tot_loss=2.286 (perp=9.998, rec=0.258, cos=0.028), tot_loss_proj:3.825 [t=0.18s]
prediction: ['[CLS] marine has who finn? ring who? [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.149 (perp=9.423, rec=0.240, cos=0.025), tot_loss_proj:3.827 [t=0.22s]
prediction: ['[CLS]nor who saw finn? ring who? [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.248 (perp=10.028, rec=0.213, cos=0.030), tot_loss_proj:3.974 [t=0.19s]
prediction: ['[CLS]del who sawsta?nor who? [SEP]']
[ 450/2000] tot_loss=2.331 (perp=10.805, rec=0.157, cos=0.013), tot_loss_proj:4.099 [t=0.18s]
prediction: ['[CLS]kel who seensta?nor has? [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.428 (perp=11.372, rec=0.147, cos=0.007), tot_loss_proj:4.279 [t=0.18s]
prediction: ['[CLS]kel who has seenkel?nor my [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.920 (perp=8.936, rec=0.126, cos=0.008), tot_loss_proj:3.716 [t=0.20s]
prediction: ['[CLS]kel who has seenkelnor my? [SEP]']
[ 600/2000] tot_loss=1.901 (perp=8.936, rec=0.110, cos=0.004), tot_loss_proj:3.709 [t=0.21s]
prediction: ['[CLS]kel who has seenkelnor my? [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.838 (perp=8.736, rec=0.088, cos=0.003), tot_loss_proj:3.712 [t=0.17s]
prediction: ['[CLS]kel who has seenkel mynor? [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.519 (perp=7.134, rec=0.089, cos=0.003), tot_loss_proj:3.378 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
[ 750/2000] tot_loss=1.512 (perp=7.134, rec=0.083, cos=0.003), tot_loss_proj:3.376 [t=0.27s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.514 (perp=7.134, rec=0.084, cos=0.003), tot_loss_proj:3.381 [t=0.28s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.515 (perp=7.134, rec=0.086, cos=0.002), tot_loss_proj:3.381 [t=0.25s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
[ 900/2000] tot_loss=1.506 (perp=7.134, rec=0.077, cos=0.002), tot_loss_proj:3.382 [t=0.19s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.508 (perp=7.134, rec=0.079, cos=0.002), tot_loss_proj:3.381 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.507 (perp=7.134, rec=0.078, cos=0.002), tot_loss_proj:3.377 [t=0.22s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
[1050/2000] tot_loss=1.510 (perp=7.134, rec=0.081, cos=0.002), tot_loss_proj:3.383 [t=0.19s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.509 (perp=7.134, rec=0.080, cos=0.002), tot_loss_proj:3.379 [t=0.23s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.503 (perp=7.134, rec=0.075, cos=0.002), tot_loss_proj:3.379 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
[1200/2000] tot_loss=1.499 (perp=7.134, rec=0.070, cos=0.002), tot_loss_proj:3.388 [t=0.21s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.502 (perp=7.134, rec=0.074, cos=0.002), tot_loss_proj:3.377 [t=0.25s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.504 (perp=7.134, rec=0.075, cos=0.002), tot_loss_proj:3.384 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
[1350/2000] tot_loss=1.500 (perp=7.134, rec=0.071, cos=0.002), tot_loss_proj:3.382 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.502 (perp=7.134, rec=0.073, cos=0.002), tot_loss_proj:3.375 [t=0.17s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.511 (perp=7.134, rec=0.082, cos=0.002), tot_loss_proj:3.384 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
[1500/2000] tot_loss=1.507 (perp=7.134, rec=0.078, cos=0.002), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.502 (perp=7.134, rec=0.074, cos=0.002), tot_loss_proj:3.381 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.492 (perp=7.134, rec=0.063, cos=0.002), tot_loss_proj:3.384 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
[1650/2000] tot_loss=1.503 (perp=7.134, rec=0.075, cos=0.002), tot_loss_proj:3.384 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.491 (perp=7.134, rec=0.063, cos=0.002), tot_loss_proj:3.377 [t=0.25s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.505 (perp=7.134, rec=0.077, cos=0.002), tot_loss_proj:3.381 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
[1800/2000] tot_loss=1.494 (perp=7.134, rec=0.066, cos=0.002), tot_loss_proj:3.380 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.500 (perp=7.134, rec=0.072, cos=0.002), tot_loss_proj:3.381 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.503 (perp=7.134, rec=0.074, cos=0.002), tot_loss_proj:3.383 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
[1950/2000] tot_loss=1.497 (perp=7.134, rec=0.068, cos=0.002), tot_loss_proj:3.380 [t=0.25s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.503 (perp=7.134, rec=0.075, cos=0.002), tot_loss_proj:3.383 [t=0.18s]
prediction: ['[CLS] who has seenkel mynorkel? [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] who has seen my snorkel? [SEP]
========================
predicted: 
========================
[CLS] who has seenkel mynorkel? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 66.667 | r: 57.143
rouge2     | fm: 36.364 | p: 40.000 | r: 33.333
rougeL     | fm: 61.538 | p: 66.667 | r: 57.143
rougeLsum  | fm: 61.538 | p: 66.667 | r: 57.143
r1fm+r2fm = 97.902

[Aggregate metrics]:
rouge1     | fm: 81.050 | p: 82.456 | r: 79.827
rouge2     | fm: 51.061 | p: 51.667 | r: 50.278
rougeL     | fm: 73.771 | p: 75.208 | r: 72.790
rougeLsum  | fm: 73.795 | p: 74.978 | r: 72.684
r1fm+r2fm = 132.110

input #5 time: 0:08:09 | total time: 0:49:07


Running input #6 of 100.
reference: 
========================
Which goddess helped us?
========================
average of cosine similarity 0.9995514179693319
highest_index [0]
highest [0.9995514179693319]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2029, 7804, 3271, 2149, 1029,  102]], device='cuda:0')
Debug: ref = ['[CLS] which goddess helped us? [SEP]']
[Init] best rec loss: 0.867874264717102 for ['[CLS] naked scoring southeastvyn taliban [SEP]']
[Init] best rec loss: 0.864172101020813 for ['[CLS] heronhesive faye bachelorcom [SEP]']
[Init] best rec loss: 0.8641515374183655 for ['[CLS]bby ve stellathorpe concerns [SEP]']
[Init] best rec loss: 0.8406566381454468 for ['[CLS]nation convenient heal exactly ljubljana [SEP]']
[Init] best perm rec loss: 0.8389413356781006 for ['[CLS] heal exactlynation convenient ljubljana [SEP]']
[Init] best perm rec loss: 0.8358174562454224 for ['[CLS] exactlynation ljubljana convenient heal [SEP]']
[Init] best perm rec loss: 0.8347128033638 for ['[CLS] ljubljana convenientnation exactly heal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.891 (perp=11.128, rec=0.673, cos=0.993), tot_loss_proj:3.964 [t=0.25s]
prediction: ['[CLS]hardt?? tiffany ] [SEP]']
[ 100/2000] tot_loss=3.110 (perp=10.239, rec=0.538, cos=0.524), tot_loss_proj:4.102 [t=0.21s]
prediction: ['[CLS] particularly basket? feminist ] [SEP]']
[ 150/2000] tot_loss=2.139 (perp=8.466, rec=0.330, cos=0.116), tot_loss_proj:3.465 [t=0.18s]
prediction: ['[CLS] which basket? goddess? [SEP]']
[ 200/2000] tot_loss=2.154 (perp=9.014, rec=0.240, cos=0.111), tot_loss_proj:3.899 [t=0.25s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.104 (perp=9.014, rec=0.193, cos=0.108), tot_loss_proj:3.909 [t=0.18s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
[ 300/2000] tot_loss=2.077 (perp=9.014, rec=0.168, cos=0.106), tot_loss_proj:3.904 [t=0.29s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.074 (perp=9.014, rec=0.164, cos=0.107), tot_loss_proj:3.901 [t=0.18s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.052 (perp=9.014, rec=0.144, cos=0.105), tot_loss_proj:3.905 [t=0.19s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
[ 450/2000] tot_loss=2.053 (perp=9.014, rec=0.146, cos=0.104), tot_loss_proj:3.899 [t=0.24s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.051 (perp=9.014, rec=0.144, cos=0.105), tot_loss_proj:3.899 [t=0.18s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.062 (perp=9.014, rec=0.155, cos=0.105), tot_loss_proj:3.900 [t=0.21s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
[ 600/2000] tot_loss=2.050 (perp=9.014, rec=0.142, cos=0.106), tot_loss_proj:3.897 [t=0.20s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.047 (perp=9.014, rec=0.138, cos=0.107), tot_loss_proj:3.892 [t=0.21s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.042 (perp=9.014, rec=0.135, cos=0.105), tot_loss_proj:3.891 [t=0.17s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
[ 750/2000] tot_loss=2.046 (perp=9.014, rec=0.135, cos=0.108), tot_loss_proj:3.898 [t=0.18s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.040 (perp=9.014, rec=0.129, cos=0.108), tot_loss_proj:3.899 [t=0.19s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.046 (perp=9.014, rec=0.136, cos=0.107), tot_loss_proj:3.900 [t=0.24s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
[ 900/2000] tot_loss=2.040 (perp=9.014, rec=0.129, cos=0.109), tot_loss_proj:3.906 [t=0.21s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.047 (perp=9.014, rec=0.135, cos=0.109), tot_loss_proj:3.892 [t=0.23s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[1000/2000] tot_loss=2.058 (perp=9.014, rec=0.147, cos=0.109), tot_loss_proj:3.890 [t=0.18s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
[1050/2000] tot_loss=2.050 (perp=9.014, rec=0.138, cos=0.109), tot_loss_proj:3.892 [t=0.18s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[1100/2000] tot_loss=2.050 (perp=9.014, rec=0.138, cos=0.109), tot_loss_proj:3.900 [t=0.19s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[1150/2000] tot_loss=2.040 (perp=9.014, rec=0.129, cos=0.109), tot_loss_proj:3.899 [t=0.18s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
[1200/2000] tot_loss=2.046 (perp=9.014, rec=0.135, cos=0.109), tot_loss_proj:3.890 [t=0.18s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[1250/2000] tot_loss=2.035 (perp=9.014, rec=0.124, cos=0.109), tot_loss_proj:3.888 [t=0.18s]
prediction: ['[CLS] which goddess helped goddess? [SEP]']
Attempt swap
[1300/2000] tot_loss=2.310 (perp=10.260, rec=0.149, cos=0.109), tot_loss_proj:4.105 [t=0.19s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
[1350/2000] tot_loss=2.294 (perp=10.260, rec=0.133, cos=0.109), tot_loss_proj:4.111 [t=0.18s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
Attempt swap
[1400/2000] tot_loss=2.297 (perp=10.260, rec=0.137, cos=0.109), tot_loss_proj:4.107 [t=0.19s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
Attempt swap
[1450/2000] tot_loss=2.288 (perp=10.260, rec=0.128, cos=0.108), tot_loss_proj:4.109 [t=0.21s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
[1500/2000] tot_loss=2.301 (perp=10.260, rec=0.140, cos=0.108), tot_loss_proj:4.107 [t=0.24s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
Attempt swap
[1550/2000] tot_loss=2.300 (perp=10.260, rec=0.139, cos=0.108), tot_loss_proj:4.104 [t=0.18s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
Attempt swap
[1600/2000] tot_loss=2.286 (perp=10.260, rec=0.125, cos=0.108), tot_loss_proj:4.108 [t=0.22s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
[1650/2000] tot_loss=2.295 (perp=10.260, rec=0.135, cos=0.108), tot_loss_proj:4.109 [t=0.20s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
Attempt swap
[1700/2000] tot_loss=2.292 (perp=10.260, rec=0.132, cos=0.108), tot_loss_proj:4.109 [t=0.22s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
Attempt swap
[1750/2000] tot_loss=2.281 (perp=10.260, rec=0.121, cos=0.108), tot_loss_proj:4.105 [t=0.18s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
[1800/2000] tot_loss=2.300 (perp=10.260, rec=0.140, cos=0.108), tot_loss_proj:4.110 [t=0.24s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
Attempt swap
[1850/2000] tot_loss=2.291 (perp=10.260, rec=0.131, cos=0.108), tot_loss_proj:4.109 [t=0.19s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
Attempt swap
[1900/2000] tot_loss=2.297 (perp=10.260, rec=0.137, cos=0.108), tot_loss_proj:4.105 [t=0.18s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
[1950/2000] tot_loss=2.296 (perp=10.260, rec=0.136, cos=0.108), tot_loss_proj:4.107 [t=0.24s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
Attempt swap
[2000/2000] tot_loss=2.295 (perp=10.260, rec=0.135, cos=0.108), tot_loss_proj:4.107 [t=0.18s]
prediction: ['[CLS] which goddess helpediating? [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] which goddess helped us? [SEP]
========================
predicted: 
========================
[CLS] which goddess helpediating? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 80.000 | r: 66.667
rouge2     | fm: 44.444 | p: 50.000 | r: 40.000
rougeL     | fm: 72.727 | p: 80.000 | r: 66.667
rougeLsum  | fm: 72.727 | p: 80.000 | r: 66.667
r1fm+r2fm = 117.172

[Aggregate metrics]:
rouge1     | fm: 79.931 | p: 82.105 | r: 78.086
rouge2     | fm: 49.560 | p: 51.111 | r: 48.492
rougeL     | fm: 74.032 | p: 76.320 | r: 72.162
rougeLsum  | fm: 73.752 | p: 75.893 | r: 71.915
r1fm+r2fm = 129.491

input #6 time: 0:08:06 | total time: 0:57:14


Running input #7 of 100.
reference: 
========================
They have no old.
========================
average of cosine similarity 0.9993867448742306
highest_index [0]
highest [0.9993867448742306]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2027, 2031, 2053, 2214, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] they have no old. [SEP]']
[Init] best rec loss: 0.8596845865249634 for ['[CLS] devices buck 1947 business ji [SEP]']
[Init] best rec loss: 0.7969943284988403 for ['[CLS]emi streamed including same rugby [SEP]']
[Init] best rec loss: 0.745602548122406 for ['[CLS] nopecharged practiced 2011 jersey [SEP]']
[Init] best rec loss: 0.7454397678375244 for ['[CLS] ok programme timetable mae keeping [SEP]']
[Init] best rec loss: 0.7182220816612244 for ['[CLS] necessary nino shin sensory hank [SEP]']
[Init] best rec loss: 0.7062795162200928 for ['[CLS] total mfa km² brock gifford [SEP]']
[Init] best rec loss: 0.694407045841217 for ['[CLS] presents contact managed dontlement [SEP]']
[Init] best rec loss: 0.6856284141540527 for ['[CLS] zhang just plum class bills [SEP]']
[Init] best rec loss: 0.6675581932067871 for ['[CLS] simultaneously campeonato outside - shown [SEP]']
[Init] best perm rec loss: 0.6658273935317993 for ['[CLS] outside shown campeonato - simultaneously [SEP]']
[Init] best perm rec loss: 0.6624957323074341 for ['[CLS] shown campeonato - simultaneously outside [SEP]']
[Init] best perm rec loss: 0.6613995432853699 for ['[CLS] shown simultaneously - campeonato outside [SEP]']
[Init] best perm rec loss: 0.6613324880599976 for ['[CLS] campeonato outside - simultaneously shown [SEP]']
[Init] best perm rec loss: 0.6570094227790833 for ['[CLS] shown - campeonato simultaneously outside [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.841 (perp=11.302, rec=0.637, cos=0.943), tot_loss_proj:3.312 [t=0.17s]
prediction: ['[CLS] mega jacques his by chung [SEP]']
[ 100/2000] tot_loss=2.587 (perp=10.615, rec=0.385, cos=0.079), tot_loss_proj:3.855 [t=0.25s]
prediction: ['[CLS] have old old pol up [SEP]']
[ 150/2000] tot_loss=2.568 (perp=11.203, rec=0.283, cos=0.044), tot_loss_proj:3.286 [t=0.19s]
prediction: ['[CLS] no old old reluctantly new [SEP]']
[ 200/2000] tot_loss=2.668 (perp=12.184, rec=0.206, cos=0.025), tot_loss_proj:3.185 [t=0.18s]
prediction: ['[CLS] no old old opted their [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.065 (perp=9.285, rec=0.191, cos=0.017), tot_loss_proj:2.792 [t=0.27s]
prediction: ['[CLS] old on they no. [SEP]']
[ 300/2000] tot_loss=2.033 (perp=9.285, rec=0.163, cos=0.013), tot_loss_proj:2.792 [t=0.20s]
prediction: ['[CLS] old on they no. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.622 (perp=7.273, rec=0.153, cos=0.013), tot_loss_proj:2.436 [t=0.18s]
prediction: ['[CLS] on they no old. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.617 (perp=7.273, rec=0.150, cos=0.012), tot_loss_proj:2.426 [t=0.24s]
prediction: ['[CLS] on they no old. [SEP]']
[ 450/2000] tot_loss=1.616 (perp=7.273, rec=0.150, cos=0.011), tot_loss_proj:2.444 [t=0.19s]
prediction: ['[CLS] on they no old. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.614 (perp=7.273, rec=0.149, cos=0.011), tot_loss_proj:2.438 [t=0.28s]
prediction: ['[CLS] on they no old. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.613 (perp=7.273, rec=0.147, cos=0.011), tot_loss_proj:2.444 [t=0.18s]
prediction: ['[CLS] on they no old. [SEP]']
[ 600/2000] tot_loss=1.601 (perp=7.273, rec=0.136, cos=0.011), tot_loss_proj:2.438 [t=0.20s]
prediction: ['[CLS] on they no old. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.608 (perp=7.273, rec=0.143, cos=0.011), tot_loss_proj:2.451 [t=0.23s]
prediction: ['[CLS] on they no old. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.606 (perp=7.273, rec=0.141, cos=0.011), tot_loss_proj:2.444 [t=0.23s]
prediction: ['[CLS] on they no old. [SEP]']
[ 750/2000] tot_loss=1.603 (perp=7.273, rec=0.138, cos=0.011), tot_loss_proj:2.450 [t=0.22s]
prediction: ['[CLS] on they no old. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.599 (perp=7.273, rec=0.134, cos=0.011), tot_loss_proj:2.454 [t=0.18s]
prediction: ['[CLS] on they no old. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.607 (perp=7.273, rec=0.142, cos=0.011), tot_loss_proj:2.446 [t=0.18s]
prediction: ['[CLS] on they no old. [SEP]']
[ 900/2000] tot_loss=1.601 (perp=7.273, rec=0.135, cos=0.011), tot_loss_proj:2.456 [t=0.26s]
prediction: ['[CLS] on they no old. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.603 (perp=7.273, rec=0.138, cos=0.010), tot_loss_proj:2.448 [t=0.18s]
prediction: ['[CLS] on they no old. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.519 (perp=6.847, rec=0.139, cos=0.011), tot_loss_proj:2.042 [t=0.18s]
prediction: ['[CLS] they however no old. [SEP]']
[1050/2000] tot_loss=1.735 (perp=7.977, rec=0.129, cos=0.011), tot_loss_proj:2.492 [t=0.18s]
prediction: ['[CLS] they un no old. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.646 (perp=7.426, rec=0.149, cos=0.011), tot_loss_proj:2.135 [t=0.19s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.642 (perp=7.426, rec=0.146, cos=0.011), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] they no un old. [SEP]']
[1200/2000] tot_loss=1.629 (perp=7.426, rec=0.133, cos=0.011), tot_loss_proj:2.133 [t=0.21s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.623 (perp=7.426, rec=0.127, cos=0.011), tot_loss_proj:2.140 [t=0.23s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.644 (perp=7.426, rec=0.148, cos=0.010), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] they no un old. [SEP]']
[1350/2000] tot_loss=1.625 (perp=7.426, rec=0.129, cos=0.010), tot_loss_proj:2.135 [t=0.28s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.636 (perp=7.426, rec=0.140, cos=0.010), tot_loss_proj:2.138 [t=0.27s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.632 (perp=7.426, rec=0.137, cos=0.010), tot_loss_proj:2.123 [t=0.24s]
prediction: ['[CLS] they no un old. [SEP]']
[1500/2000] tot_loss=1.636 (perp=7.426, rec=0.141, cos=0.010), tot_loss_proj:2.138 [t=0.18s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.626 (perp=7.426, rec=0.131, cos=0.010), tot_loss_proj:2.133 [t=0.23s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.624 (perp=7.426, rec=0.129, cos=0.010), tot_loss_proj:2.131 [t=0.18s]
prediction: ['[CLS] they no un old. [SEP]']
[1650/2000] tot_loss=1.625 (perp=7.426, rec=0.130, cos=0.010), tot_loss_proj:2.138 [t=0.24s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.629 (perp=7.426, rec=0.134, cos=0.010), tot_loss_proj:2.130 [t=0.26s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.635 (perp=7.426, rec=0.140, cos=0.009), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] they no un old. [SEP]']
[1800/2000] tot_loss=1.621 (perp=7.426, rec=0.127, cos=0.009), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.637 (perp=7.426, rec=0.142, cos=0.009), tot_loss_proj:2.132 [t=0.18s]
prediction: ['[CLS] they no un old. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.625 (perp=7.426, rec=0.130, cos=0.009), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] they no un old. [SEP]']
[1950/2000] tot_loss=1.741 (perp=8.032, rec=0.125, cos=0.009), tot_loss_proj:2.387 [t=0.27s]
prediction: ['[CLS] they no however old. [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.487 (perp=6.670, rec=0.142, cos=0.011), tot_loss_proj:1.956 [t=0.19s]
prediction: ['[CLS] however they no old. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] they have no old. [SEP]
========================
predicted: 
========================
[CLS] they no un old. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 123.333

[Aggregate metrics]:
rouge1     | fm: 80.749 | p: 82.562 | r: 78.893
rouge2     | fm: 48.346 | p: 49.653 | r: 47.500
rougeL     | fm: 75.327 | p: 76.937 | r: 73.926
rougeLsum  | fm: 74.931 | p: 76.823 | r: 73.512
r1fm+r2fm = 129.095

input #7 time: 0:08:22 | total time: 1:05:37


Running input #8 of 100.
reference: 
========================
John tries to meet not Mary.
========================
average of cosine similarity 0.999285781739601
highest_index [0]
highest [0.999285781739601]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2198, 5363, 2000, 3113, 2025, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] john tries to meet not mary. [SEP]']
[Init] best rec loss: 0.8751393556594849 for ['[CLS]udeau secretary steinerc pennypeed press [SEP]']
[Init] best rec loss: 0.8258135318756104 for ['[CLS] fresh contact beaten image angle form confederate [SEP]']
[Init] best rec loss: 0.824735701084137 for ['[CLS] catalogue frankie tsar calendar hog case provisional [SEP]']
[Init] best rec loss: 0.7984954714775085 for ['[CLS] key cult accession floating remember oxford suddenly [SEP]']
[Init] best rec loss: 0.7969860434532166 for ['[CLS] warren benny grace boarding saxon nothing " [SEP]']
[Init] best rec loss: 0.7715851664543152 for ['[CLS] further big instance schedule ahead caftium [SEP]']
[Init] best rec loss: 0.7697283029556274 for ['[CLS]culebid driver genome boundary much books [SEP]']
[Init] best rec loss: 0.7694283723831177 for ['[CLS] recession duncanified within youtube michael eventually [SEP]']
[Init] best rec loss: 0.7451742887496948 for ['[CLS] gentleman centre past gradesfies th times [SEP]']
[Init] best perm rec loss: 0.730642557144165 for ['[CLS] centre past gentleman thfies times grades [SEP]']
[Init] best perm rec loss: 0.7257177829742432 for ['[CLS] centre gentleman timesfies past grades th [SEP]']
[Init] best perm rec loss: 0.7234541773796082 for ['[CLS] past centrefies times th gentleman grades [SEP]']
[Init] best perm rec loss: 0.7234346866607666 for ['[CLS] th grades timesfies centre past gentleman [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.987 (perp=8.453, rec=0.285, cos=0.011), tot_loss_proj:2.660 [t=0.18s]
prediction: ['[CLS] mary mary? not not meet meet [SEP]']
[ 100/2000] tot_loss=1.994 (perp=9.131, rec=0.161, cos=0.007), tot_loss_proj:2.919 [t=0.25s]
prediction: ['[CLS] tries mary not, not mary meet [SEP]']
[ 150/2000] tot_loss=1.963 (perp=9.168, rec=0.125, cos=0.004), tot_loss_proj:2.642 [t=0.24s]
prediction: ['[CLS] tries mary to. not mary meet [SEP]']
[ 200/2000] tot_loss=2.237 (perp=10.610, rec=0.112, cos=0.003), tot_loss_proj:3.107 [t=0.22s]
prediction: ['[CLS] tries mary tries. not mary meet [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.779 (perp=8.353, rec=0.106, cos=0.003), tot_loss_proj:2.480 [t=0.30s]
prediction: ['[CLS] meet mary to. not mary tries [SEP]']
[ 300/2000] tot_loss=1.849 (perp=8.906, rec=0.067, cos=0.002), tot_loss_proj:2.573 [t=0.20s]
prediction: ['[CLS] meet mary to. not john tries [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.751 (perp=8.377, rec=0.075, cos=0.001), tot_loss_proj:2.245 [t=0.19s]
prediction: ['[CLS] meet to mary. not john tries [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.726 (perp=8.228, rec=0.079, cos=0.001), tot_loss_proj:2.851 [t=0.23s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[ 450/2000] tot_loss=1.701 (perp=8.228, rec=0.054, cos=0.001), tot_loss_proj:2.843 [t=0.26s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.721 (perp=8.228, rec=0.074, cos=0.001), tot_loss_proj:2.849 [t=0.20s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.714 (perp=8.228, rec=0.067, cos=0.001), tot_loss_proj:2.842 [t=0.21s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[ 600/2000] tot_loss=1.714 (perp=8.228, rec=0.067, cos=0.001), tot_loss_proj:2.841 [t=0.19s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.707 (perp=8.228, rec=0.060, cos=0.001), tot_loss_proj:2.833 [t=0.19s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.700 (perp=8.228, rec=0.053, cos=0.001), tot_loss_proj:2.849 [t=0.19s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[ 750/2000] tot_loss=1.725 (perp=8.228, rec=0.078, cos=0.001), tot_loss_proj:2.844 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.704 (perp=8.228, rec=0.057, cos=0.001), tot_loss_proj:2.844 [t=0.26s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.713 (perp=8.228, rec=0.066, cos=0.001), tot_loss_proj:2.847 [t=0.22s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[ 900/2000] tot_loss=1.717 (perp=8.228, rec=0.070, cos=0.001), tot_loss_proj:2.852 [t=0.19s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.704 (perp=8.228, rec=0.057, cos=0.001), tot_loss_proj:2.844 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1000/2000] tot_loss=1.722 (perp=8.228, rec=0.075, cos=0.001), tot_loss_proj:2.845 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[1050/2000] tot_loss=1.714 (perp=8.228, rec=0.067, cos=0.001), tot_loss_proj:2.843 [t=0.23s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1100/2000] tot_loss=1.708 (perp=8.228, rec=0.061, cos=0.001), tot_loss_proj:2.845 [t=0.20s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1150/2000] tot_loss=1.719 (perp=8.228, rec=0.072, cos=0.001), tot_loss_proj:2.847 [t=0.26s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[1200/2000] tot_loss=1.705 (perp=8.228, rec=0.058, cos=0.001), tot_loss_proj:2.842 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1250/2000] tot_loss=1.714 (perp=8.228, rec=0.067, cos=0.001), tot_loss_proj:2.843 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1300/2000] tot_loss=1.707 (perp=8.228, rec=0.060, cos=0.001), tot_loss_proj:2.854 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[1350/2000] tot_loss=1.714 (perp=8.228, rec=0.067, cos=0.001), tot_loss_proj:2.839 [t=0.19s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1400/2000] tot_loss=1.708 (perp=8.228, rec=0.061, cos=0.001), tot_loss_proj:2.843 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1450/2000] tot_loss=1.707 (perp=8.228, rec=0.060, cos=0.001), tot_loss_proj:2.835 [t=0.19s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[1500/2000] tot_loss=1.713 (perp=8.228, rec=0.066, cos=0.001), tot_loss_proj:2.846 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1550/2000] tot_loss=1.700 (perp=8.228, rec=0.053, cos=0.001), tot_loss_proj:2.839 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1600/2000] tot_loss=1.708 (perp=8.228, rec=0.061, cos=0.001), tot_loss_proj:2.837 [t=0.24s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[1650/2000] tot_loss=1.707 (perp=8.228, rec=0.060, cos=0.001), tot_loss_proj:2.840 [t=0.23s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1700/2000] tot_loss=1.721 (perp=8.228, rec=0.074, cos=0.001), tot_loss_proj:2.838 [t=0.23s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1750/2000] tot_loss=1.708 (perp=8.228, rec=0.061, cos=0.001), tot_loss_proj:2.835 [t=0.20s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[1800/2000] tot_loss=1.709 (perp=8.228, rec=0.062, cos=0.001), tot_loss_proj:2.842 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1850/2000] tot_loss=1.711 (perp=8.228, rec=0.064, cos=0.001), tot_loss_proj:2.849 [t=0.19s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[1900/2000] tot_loss=1.698 (perp=8.228, rec=0.051, cos=0.001), tot_loss_proj:2.842 [t=0.18s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
[1950/2000] tot_loss=1.719 (perp=8.228, rec=0.072, cos=0.001), tot_loss_proj:2.840 [t=0.25s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Attempt swap
[2000/2000] tot_loss=1.716 (perp=8.228, rec=0.069, cos=0.001), tot_loss_proj:2.849 [t=0.21s]
prediction: ['[CLS] to meet mary. not john tries [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS] john tries to meet not mary. [SEP]
========================
predicted: 
========================
[CLS] to meet mary. not john tries [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 128.571

[Aggregate metrics]:
rouge1     | fm: 82.815 | p: 84.545 | r: 81.313
rouge2     | fm: 46.228 | p: 47.619 | r: 45.397
rougeL     | fm: 73.367 | p: 74.962 | r: 71.942
rougeLsum  | fm: 74.422 | p: 75.953 | r: 72.936
r1fm+r2fm = 129.043

input #8 time: 0:08:26 | total time: 1:14:04


Running input #9 of 100.
reference: 
========================
The unidentified victim was apparently struck during the early morning hours.
========================
average of cosine similarity 0.9994535457719615
highest_index [0]
highest [0.9994535457719615]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  1996, 20293,  6778,  2001,  4593,  4930,  2076,  1996,  2220,
          2851,  2847,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]']
[Init] best rec loss: 0.9761378169059753 for ['[CLS]re took vie one ioc reading triangle willmour just grantedated [SEP]']
[Init] best rec loss: 0.9484792351722717 for ['[CLS]hearted rendition ho [CLS] factor supreme satinating concentrate baseman cent sin [SEP]']
[Init] best rec loss: 0.9337632060050964 for ['[CLS]ivated guests survivalr academie celebrates ultimately? invoked per substrates based [SEP]']
[Init] best rec loss: 0.9280292391777039 for ['[CLS] hair confederation qualify rid ni interchange semifinals colonel keystone pop equilibrium resting [SEP]']
[Init] best rec loss: 0.9025102853775024 for ['[CLS] located sure studio earlier ceased downpot engineering giles best includingtage [SEP]']
[Init] best perm rec loss: 0.8983306884765625 for ['[CLS]pot including engineering sure studio downtage located earlier best ceased giles [SEP]']
[Init] best perm rec loss: 0.8946741223335266 for ['[CLS] engineering studio including down sure giles best ceased locatedtage earlierpot [SEP]']
[Init] best perm rec loss: 0.893314778804779 for ['[CLS] including down bestpot suretage earlier ceased located giles engineering studio [SEP]']
[Init] best perm rec loss: 0.8884896039962769 for ['[CLS] studio sure engineeringpot giles ceased down best including located earliertage [SEP]']
[Init] best perm rec loss: 0.8874890804290771 for ['[CLS] ceased down engineeringpot sure studiotage including best located earlier giles [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.629 (perp=10.769, rec=0.622, cos=0.853), tot_loss_proj:3.908 [t=0.25s]
prediction: ['[CLS] unidentified ′ hometown victim in sounded too witches the sparrow suffered °f [SEP]']
[ 100/2000] tot_loss=4.011 (perp=11.518, rec=0.719, cos=0.988), tot_loss_proj:4.153 [t=0.22s]
prediction: ['[CLS] unknown, during device feeling - hit war an giant rearview eyelids [SEP]']
[ 150/2000] tot_loss=2.957 (perp=12.063, rec=0.415, cos=0.129), tot_loss_proj:4.247 [t=0.18s]
prediction: ['[CLS] milan, during device production - hit car an giant mayor especially [SEP]']
[ 200/2000] tot_loss=2.699 (perp=11.803, rec=0.291, cos=0.047), tot_loss_proj:4.125 [t=0.24s]
prediction: ['[CLS] internationally, asteroid victim emotionally - hit vehicle an giant mayor especially [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.574 (perp=11.478, rec=0.249, cos=0.030), tot_loss_proj:4.167 [t=0.19s]
prediction: ['[CLS] easily root unidentified victim apparently. an vehicle struck giant mayor cassandra [SEP]']
[ 300/2000] tot_loss=2.287 (perp=10.192, rec=0.227, cos=0.022), tot_loss_proj:3.800 [t=0.24s]
prediction: ["[CLS] easily'unidentified victim apparently. during car struck giant mayor. [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.813 (perp=12.879, rec=0.217, cos=0.020), tot_loss_proj:4.343 [t=0.21s]
prediction: ['[CLS] easily while unidentified victim apparentlypersonal during fighter struck mayor giant tonight [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.279 (perp=10.296, rec=0.203, cos=0.016), tot_loss_proj:3.846 [t=0.18s]
prediction: ["[CLS] during'unidentified victim apparentlypersonal during struck fighter mayor giant. [SEP]"]
[ 450/2000] tot_loss=2.260 (perp=10.296, rec=0.187, cos=0.015), tot_loss_proj:3.847 [t=0.19s]
prediction: ["[CLS] during'unidentified victim apparentlypersonal during struck fighter mayor giant. [SEP]"]
Attempt swap
[ 500/2000] tot_loss=2.326 (perp=10.665, rec=0.180, cos=0.013), tot_loss_proj:3.989 [t=0.24s]
prediction: ["[CLS] during'unidentified victim apparently _ during struck fighter mayor giant. [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=2.590 (perp=12.034, rec=0.172, cos=0.012), tot_loss_proj:4.231 [t=0.27s]
prediction: ['[CLS] hours once unidentified victim apparently _ during struck giant fighter mayor. [SEP]']
[ 600/2000] tot_loss=2.504 (perp=11.704, rec=0.153, cos=0.010), tot_loss_proj:4.094 [t=0.20s]
prediction: ['[CLS] hours once unidentified victim apparently unidentified during struck giant fighter mayor. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.156 (perp=9.873, rec=0.169, cos=0.012), tot_loss_proj:3.745 [t=0.18s]
prediction: ['[CLS] mayor once unidentified victim apparently unidentified during struck giant fighter hours. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.099 (perp=9.639, rec=0.160, cos=0.011), tot_loss_proj:3.768 [t=0.18s]
prediction: ['[CLS] mayor once unidentified victim apparently unidentified struck during giant fighter hours. [SEP]']
[ 750/2000] tot_loss=2.091 (perp=9.639, rec=0.153, cos=0.010), tot_loss_proj:3.772 [t=0.19s]
prediction: ['[CLS] mayor once unidentified victim apparently unidentified struck during giant fighter hours. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.077 (perp=9.608, rec=0.145, cos=0.010), tot_loss_proj:3.774 [t=0.18s]
prediction: ['[CLS] mayor once unidentified victim apparently unidentified struck during giant night hours. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.996 (perp=9.175, rec=0.151, cos=0.010), tot_loss_proj:3.558 [t=0.19s]
prediction: ['[CLS] mayor during unidentified victim apparently unidentified struck when during night hours. [SEP]']
[ 900/2000] tot_loss=1.983 (perp=9.175, rec=0.139, cos=0.010), tot_loss_proj:3.554 [t=0.22s]
prediction: ['[CLS] mayor during unidentified victim apparently unidentified struck when during night hours. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.915 (perp=8.856, rec=0.134, cos=0.010), tot_loss_proj:3.510 [t=0.21s]
prediction: ['[CLS] mayor during unidentified victim apparently struck unidentified when during night hours. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.890 (perp=8.704, rec=0.139, cos=0.010), tot_loss_proj:3.441 [t=0.18s]
prediction: ['[CLS] when during unidentified victim apparently struck unidentified mayor during night hours. [SEP]']
[1050/2000] tot_loss=1.897 (perp=8.704, rec=0.147, cos=0.010), tot_loss_proj:3.436 [t=0.18s]
prediction: ['[CLS] when during unidentified victim apparently struck unidentified mayor during night hours. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.670 (perp=7.657, rec=0.129, cos=0.009), tot_loss_proj:3.366 [t=0.19s]
prediction: ['[CLS] when during the victim apparently struck unidentified mayor during night hours. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.676 (perp=7.657, rec=0.135, cos=0.009), tot_loss_proj:3.367 [t=0.18s]
prediction: ['[CLS] when during the victim apparently struck unidentified mayor during night hours. [SEP]']
[1200/2000] tot_loss=1.661 (perp=7.657, rec=0.121, cos=0.009), tot_loss_proj:3.367 [t=0.20s]
prediction: ['[CLS] when during the victim apparently struck unidentified mayor during night hours. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.697 (perp=7.810, rec=0.126, cos=0.009), tot_loss_proj:3.469 [t=0.22s]
prediction: ['[CLS] when suffer the victim apparently struck unidentified mayor during night hours. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.631 (perp=7.484, rec=0.126, cos=0.008), tot_loss_proj:3.355 [t=0.21s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck mayor during night hours. [SEP]']
[1350/2000] tot_loss=1.574 (perp=7.191, rec=0.128, cos=0.008), tot_loss_proj:3.344 [t=0.21s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during night hours. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.584 (perp=7.191, rec=0.138, cos=0.008), tot_loss_proj:3.339 [t=0.19s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during night hours. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.581 (perp=7.191, rec=0.135, cos=0.008), tot_loss_proj:3.342 [t=0.20s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during night hours. [SEP]']
[1500/2000] tot_loss=1.577 (perp=7.191, rec=0.131, cos=0.008), tot_loss_proj:3.338 [t=0.29s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during night hours. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.574 (perp=7.191, rec=0.128, cos=0.008), tot_loss_proj:3.341 [t=0.23s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during night hours. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.577 (perp=7.191, rec=0.131, cos=0.008), tot_loss_proj:3.343 [t=0.18s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during night hours. [SEP]']
[1650/2000] tot_loss=1.573 (perp=7.191, rec=0.126, cos=0.008), tot_loss_proj:3.343 [t=0.19s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during night hours. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.564 (perp=7.191, rec=0.118, cos=0.008), tot_loss_proj:3.342 [t=0.23s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during night hours. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.723 (perp=7.979, rec=0.120, cos=0.008), tot_loss_proj:3.462 [t=0.22s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during hours hours. [SEP]']
[1800/2000] tot_loss=1.735 (perp=7.979, rec=0.131, cos=0.008), tot_loss_proj:3.467 [t=0.24s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during hours hours. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.726 (perp=7.979, rec=0.122, cos=0.008), tot_loss_proj:3.468 [t=0.24s]
prediction: ['[CLS] when suffer the unidentified victim apparently struck streets during hours hours. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.689 (perp=7.724, rec=0.135, cos=0.009), tot_loss_proj:3.556 [t=0.18s]
prediction: ['[CLS] when night suffer the unidentified victim apparently struck streets during hours. [SEP]']
[1950/2000] tot_loss=1.683 (perp=7.724, rec=0.130, cos=0.009), tot_loss_proj:3.560 [t=0.26s]
prediction: ['[CLS] when night suffer the unidentified victim apparently struck streets during hours. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.680 (perp=7.724, rec=0.127, cos=0.009), tot_loss_proj:3.556 [t=0.18s]
prediction: ['[CLS] when night suffer the unidentified victim apparently struck streets during hours. [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]
========================
predicted: 
========================
[CLS] when suffer the unidentified victim apparently struck streets during night hours. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.231 | p: 69.231 | r: 69.231
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 69.231 | p: 69.231 | r: 69.231
rougeLsum  | fm: 69.231 | p: 69.231 | r: 69.231
r1fm+r2fm = 102.564

[Aggregate metrics]:
rouge1     | fm: 81.309 | p: 83.028 | r: 79.971
rouge2     | fm: 45.120 | p: 46.246 | r: 44.302
rougeL     | fm: 73.122 | p: 74.697 | r: 71.882
rougeLsum  | fm: 73.655 | p: 75.049 | r: 72.391
r1fm+r2fm = 126.428

input #9 time: 0:08:10 | total time: 1:22:14


Running input #10 of 100.
reference: 
========================
the logs piled the barge high.
========================
average of cosine similarity 0.9992999377037376
highest_index [0]
highest [0.9992999377037376]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996, 15664, 17835,  1996, 19398,  2152,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the logs piled the barge high. [SEP]']
[Init] best rec loss: 0.8238058090209961 for ['[CLS] my honey queensus suchbble [CLS] [SEP]']
[Init] best rec loss: 0.8123701214790344 for ['[CLS] shots acheron outsider associations seed an using [SEP]']
[Init] best rec loss: 0.8053205609321594 for ['[CLS] papua sorrow arden [MASK] provides sidri [SEP]']
[Init] best rec loss: 0.7905997037887573 for ['[CLS] caps noises imagery amateur recordislaus dismiss [SEP]']
[Init] best rec loss: 0.7373385429382324 for ['[CLS] wonders "elling 1936 recreation ezio outside [SEP]']
[Init] best rec loss: 0.6996959447860718 for ['[CLS] excellence stationary bread otherwise heel least least [SEP]']
[Init] best rec loss: 0.6952798366546631 for ['[CLS] two藤 organizationsworld pot suffered dishes [SEP]']
[Init] best perm rec loss: 0.6888568997383118 for ['[CLS]藤 dishes pot organizationsworld suffered two [SEP]']
[Init] best perm rec loss: 0.6883973479270935 for ['[CLS]藤 dishesworld pot suffered two organizations [SEP]']
[Init] best perm rec loss: 0.6876150369644165 for ['[CLS] organizations dishes potworld two suffered藤 [SEP]']
[Init] best perm rec loss: 0.6853832602500916 for ['[CLS] pot dishes藤world two suffered organizations [SEP]']
[Init] best perm rec loss: 0.6847565174102783 for ['[CLS]藤 dishes organizations potworld two suffered [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.995 (perp=13.203, rec=0.330, cos=0.024), tot_loss_proj:4.572 [t=0.22s]
prediction: ['[CLS] logs thelalan center networks swedish [SEP]']
[ 100/2000] tot_loss=2.717 (perp=12.147, rec=0.273, cos=0.015), tot_loss_proj:3.978 [t=0.23s]
prediction: ['[CLS] logs the ibm barges. piled secondary [SEP]']
[ 150/2000] tot_loss=2.415 (perp=11.042, rec=0.199, cos=0.007), tot_loss_proj:3.335 [t=0.18s]
prediction: ['[CLS] logs piled the barge high piled the [SEP]']
[ 200/2000] tot_loss=2.322 (perp=10.981, rec=0.121, cos=0.005), tot_loss_proj:2.941 [t=0.18s]
prediction: ['[CLS] logs the the barge high piled the [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.252 (perp=10.702, rec=0.107, cos=0.004), tot_loss_proj:3.267 [t=0.28s]
prediction: ['[CLS] the logs. barge high piled the [SEP]']
[ 300/2000] tot_loss=2.253 (perp=10.702, rec=0.109, cos=0.004), tot_loss_proj:3.259 [t=0.26s]
prediction: ['[CLS] the logs. barge high piled the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.892 (perp=8.961, rec=0.096, cos=0.003), tot_loss_proj:3.350 [t=0.21s]
prediction: ['[CLS] the logs the barge high piled. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.638 (perp=7.687, rec=0.097, cos=0.003), tot_loss_proj:3.334 [t=0.22s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[ 450/2000] tot_loss=1.633 (perp=7.687, rec=0.093, cos=0.003), tot_loss_proj:3.339 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.628 (perp=7.687, rec=0.088, cos=0.003), tot_loss_proj:3.341 [t=0.22s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.622 (perp=7.687, rec=0.081, cos=0.003), tot_loss_proj:3.345 [t=0.22s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[ 600/2000] tot_loss=1.614 (perp=7.687, rec=0.074, cos=0.003), tot_loss_proj:3.338 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.620 (perp=7.687, rec=0.080, cos=0.003), tot_loss_proj:3.337 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.631 (perp=7.687, rec=0.091, cos=0.003), tot_loss_proj:3.332 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[ 750/2000] tot_loss=1.614 (perp=7.687, rec=0.074, cos=0.003), tot_loss_proj:3.331 [t=0.19s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.611 (perp=7.687, rec=0.070, cos=0.003), tot_loss_proj:3.336 [t=0.28s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.621 (perp=7.687, rec=0.081, cos=0.003), tot_loss_proj:3.334 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[ 900/2000] tot_loss=1.607 (perp=7.687, rec=0.067, cos=0.003), tot_loss_proj:3.328 [t=0.26s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.616 (perp=7.687, rec=0.075, cos=0.003), tot_loss_proj:3.330 [t=0.20s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.616 (perp=7.687, rec=0.075, cos=0.003), tot_loss_proj:3.328 [t=0.20s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[1050/2000] tot_loss=1.619 (perp=7.687, rec=0.079, cos=0.003), tot_loss_proj:3.322 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.615 (perp=7.687, rec=0.074, cos=0.003), tot_loss_proj:3.327 [t=0.24s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.619 (perp=7.687, rec=0.078, cos=0.003), tot_loss_proj:3.322 [t=0.21s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[1200/2000] tot_loss=1.616 (perp=7.687, rec=0.076, cos=0.003), tot_loss_proj:3.320 [t=0.23s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.608 (perp=7.687, rec=0.067, cos=0.003), tot_loss_proj:3.324 [t=0.19s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.618 (perp=7.687, rec=0.077, cos=0.003), tot_loss_proj:3.315 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[1350/2000] tot_loss=1.617 (perp=7.687, rec=0.077, cos=0.003), tot_loss_proj:3.318 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.611 (perp=7.687, rec=0.070, cos=0.003), tot_loss_proj:3.312 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.619 (perp=7.687, rec=0.078, cos=0.003), tot_loss_proj:3.318 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[1500/2000] tot_loss=1.620 (perp=7.687, rec=0.080, cos=0.003), tot_loss_proj:3.313 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.616 (perp=7.687, rec=0.076, cos=0.003), tot_loss_proj:3.319 [t=0.21s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.611 (perp=7.687, rec=0.071, cos=0.003), tot_loss_proj:3.310 [t=0.30s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[1650/2000] tot_loss=1.608 (perp=7.687, rec=0.068, cos=0.003), tot_loss_proj:3.309 [t=0.25s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.632 (perp=7.687, rec=0.091, cos=0.003), tot_loss_proj:3.313 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.616 (perp=7.687, rec=0.075, cos=0.003), tot_loss_proj:3.306 [t=0.25s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[1800/2000] tot_loss=1.624 (perp=7.687, rec=0.084, cos=0.003), tot_loss_proj:3.312 [t=0.18s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.618 (perp=7.687, rec=0.077, cos=0.003), tot_loss_proj:3.308 [t=0.23s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.610 (perp=7.687, rec=0.069, cos=0.003), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
[1950/2000] tot_loss=1.620 (perp=7.687, rec=0.080, cos=0.003), tot_loss_proj:3.306 [t=0.17s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.611 (perp=7.687, rec=0.071, cos=0.003), tot_loss_proj:3.312 [t=0.24s]
prediction: ['[CLS] the logs the barge piled high. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] the logs piled the barge high. [SEP]
========================
predicted: 
========================
[CLS] the logs the barge piled high. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 82.925 | p: 84.316 | r: 81.720
rouge2     | fm: 46.417 | p: 47.273 | r: 45.693
rougeL     | fm: 74.255 | p: 75.537 | r: 73.332
rougeLsum  | fm: 74.743 | p: 76.259 | r: 73.553
r1fm+r2fm = 129.342

input #10 time: 0:08:24 | total time: 1:30:38


Running input #11 of 100.
reference: 
========================
During the early evening, Saturn can be found in the north, while Jupiter rises in the east.
========================
average of cosine similarity 0.9993928571086105
highest_index [0]
highest [0.9993928571086105]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2076,  1996,  2220,  3944,  1010, 14784,  2064,  2022,  2179,
          1999,  1996,  2167,  1010,  2096, 13035,  9466,  1999,  1996,  2264,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]']
[Init] best rec loss: 0.9603642225265503 for ['[CLS] triedya radcliffe whitney pepper since only ranges beingshibreaker sharedpower kn bn nest o day you detention [SEP]']
[Init] best rec loss: 0.9419578313827515 for ['[CLS] degreess become panted eric like there ⟩nt obeyed gwen supernatural living mexicanard consider launch due griffin block [SEP]']
[Init] best rec loss: 0.9289517998695374 for ['[CLS] poster round around globe magic cameo occupation bash label ever mtv unknownh fund ₹ school famous skillsmat sham [SEP]']
[Init] best rec loss: 0.9151187539100647 for ['[CLS] looks neither sold transportperationum after winning wade laying co licked deep lea bramont mia absentrosis pub [SEP]']
[Init] best rec loss: 0.9120637774467468 for ['[CLS] brands anyway society m founding \\ whichptive dating pop vol days contraction planes moses cooling... scrap warning just [SEP]']
[Init] best rec loss: 0.9037604928016663 for ['[CLS] il [SEP] of ny processes tour madam enchanted woody due hurt free red while studio ever arun beethoven double interval [SEP]']
[Init] best rec loss: 0.900558352470398 for ['[CLS] compared candle sha real cell renacing vigor weight moon chain sweetness amateur strength ad swallow dust northern [SEP] lower [SEP]']
[Init] best rec loss: 0.896977961063385 for ['[CLS] desk nectar parts rpm universallypressed up south davey estimated height advocate heart customary all circular bryson events pan strung [SEP]']
[Init] best rec loss: 0.8925879001617432 for ['[CLS] town performggles ratio property nephew headedta va exilepress executives cleared charm those queen sweat during [SEP] up [SEP]']
[Init] best perm rec loss: 0.8912792801856995 for ['[CLS] charm executivespress town up nephew vaggles property queen exile those during [SEP] perform clearedta headed sweat ratio [SEP]']
[Init] best perm rec loss: 0.890846848487854 for ['[CLS] queen during nephew those exile perform [SEP] va property up ratio executives charm town headedtaggles sweat clearedpress [SEP]']
[Init] best perm rec loss: 0.8906643390655518 for ['[CLS] ratio charmta exile va sweat during those perform headed cleared town nephew queen up propertyggles executives [SEP]press [SEP]']
[Init] best perm rec loss: 0.8884612917900085 for ['[CLS] during sweat town ratio queenggles exile executives those nephew headed performta property charm va uppress cleared [SEP] [SEP]']
[Init] best perm rec loss: 0.8880924582481384 for ['[CLS] [SEP]ta exile ratiopress va charm up nephew property duringggles sweat cleared headed queen those town perform executives [SEP]']
[Init] best perm rec loss: 0.887862503528595 for ['[CLS] charm exile cleared nephewggles during town executives perform queen [SEP] propertypress vata those up sweat headed ratio [SEP]']
[Init] best perm rec loss: 0.8877741694450378 for ['[CLS] headed [SEP] exile property up those charm during cleared perform queen sweatggles nephewta va town ratio executivespress [SEP]']
[Init] best perm rec loss: 0.8856097459793091 for ['[CLS] sweat va [SEP] nephewggles ratio those exile perform up queen executives charm property clearedpress town headedta during [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.709 (perp=10.503, rec=0.608, cos=1.000), tot_loss_proj:3.919 [t=0.20s]
prediction: ['[CLS] outcome middle constant night ; cause in gazing was welcome luna oh 2nd. " contact while then wrestling faculty [SEP]']
[ 100/2000] tot_loss=3.503 (perp=10.083, rec=0.487, cos=1.000), tot_loss_proj:3.836 [t=0.22s]
prediction: ['[CLS] outcome day diameter evening, bu returned jupiter was regions host in ii. morning rise with evening : torpedo [SEP]']
[ 150/2000] tot_loss=3.404 (perp=9.830, rec=0.438, cos=1.000), tot_loss_proj:3.788 [t=0.18s]
prediction: ['[CLS] odds. evening evening and twice returned saturn was regions implication inland. morning rise during evening : torpedo [SEP]']
[ 200/2000] tot_loss=3.237 (perp=9.183, rec=0.400, cos=1.000), tot_loss_proj:3.664 [t=0.18s]
prediction: ['[CLS] average during evening evening, than in saturn is regions answer indron. morning rises during evening dusk wounded [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.350 (perp=9.703, rec=0.413, cos=0.996), tot_loss_proj:3.751 [t=0.18s]
prediction: ['[CLS] generations during evening evening, than regions at saturn is fury indron in morning rises in evening enoch picked [SEP]']
[ 300/2000] tot_loss=3.326 (perp=9.763, rec=0.379, cos=0.993), tot_loss_proj:3.768 [t=0.18s]
prediction: ['[CLS] generations during evening evening during than regions at saturn is moving indron in morning rises in evening enoch picked [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.296 (perp=9.666, rec=0.367, cos=0.996), tot_loss_proj:3.746 [t=0.19s]
prediction: ['[CLS] generations during evening evening at than regions. saturn ( moving in jupiter at morning rises in evening enoch ass [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.334 (perp=9.953, rec=0.355, cos=0.989), tot_loss_proj:3.851 [t=0.23s]
prediction: ['[CLS] generations during evening evening at than when. ( saturn action in jupiter atpoints rises in evening enoch ass [SEP]']
[ 450/2000] tot_loss=3.192 (perp=9.329, rec=0.336, cos=0.991), tot_loss_proj:3.735 [t=0.18s]
prediction: ['[CLS] generations during evening evening at than when. the saturn rises in jupiter at jupiter rises in north enoch ass [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.073 (perp=8.829, rec=0.323, cos=0.984), tot_loss_proj:3.601 [t=0.24s]
prediction: ['[CLS] generations during evening evening at than when. the saturn appears in jupiter at jupiter rises in north bachelor enoch [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.024 (perp=8.582, rec=0.323, cos=0.985), tot_loss_proj:3.559 [t=0.24s]
prediction: ['[CLS] generations during evening evening at than. when the saturn appears in jupiter at jupiter rises in north bachelor enoch [SEP]']
[ 600/2000] tot_loss=3.031 (perp=8.654, rec=0.317, cos=0.984), tot_loss_proj:3.568 [t=0.21s]
prediction: ['[CLS] generations during evening evening at subsequently. when the saturn appears in jupiter during jupiter rises in north bachelor enoch [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.050 (perp=8.770, rec=0.312, cos=0.984), tot_loss_proj:3.557 [t=0.20s]
prediction: ['[CLS] generations during evening evening at thereafter. during the saturn appears in henry when jupiter rises in east bachelor enoch [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.064 (perp=8.840, rec=0.313, cos=0.983), tot_loss_proj:3.596 [t=0.18s]
prediction: ['[CLS] generations during evening evening during thereafter. during the saturn appears in henry when jupiter rises in east bachelor enoch [SEP]']
[ 750/2000] tot_loss=3.051 (perp=8.840, rec=0.300, cos=0.983), tot_loss_proj:3.593 [t=0.18s]
prediction: ['[CLS] generations during evening evening during thereafter. during the saturn appears in henry when jupiter rises in east bachelor enoch [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.073 (perp=8.954, rec=0.299, cos=0.983), tot_loss_proj:3.631 [t=0.20s]
prediction: ['[CLS] various during evening evening during thereafter. during the saturn appears in henry when jupiter rises in east bachelor enoch [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.922 (perp=8.189, rec=0.307, cos=0.977), tot_loss_proj:3.513 [t=0.22s]
prediction: ['[CLS] generations during the evening at thereafter. during evening saturn appears inttering when jupiter rises in east bachelor enoch [SEP]']
[ 900/2000] tot_loss=3.003 (perp=8.608, rec=0.302, cos=0.979), tot_loss_proj:3.605 [t=0.25s]
prediction: ['[CLS] various during the evening at thereafter. in evening saturn rises in henry when jupiter rises in east bachelor enoch [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.910 (perp=8.190, rec=0.293, cos=0.979), tot_loss_proj:3.465 [t=0.22s]
prediction: ['[CLS] various during the evening at thereafter enoch during evening saturn rises inttering when jupiter rises in east ones. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.855 (perp=7.920, rec=0.294, cos=0.977), tot_loss_proj:3.425 [t=0.24s]
prediction: ['[CLS] later during the evening at thereafter enoch in evening saturn rises inttering when jupiter rises in east ones. [SEP]']
[1050/2000] tot_loss=2.867 (perp=7.920, rec=0.308, cos=0.975), tot_loss_proj:3.425 [t=0.25s]
prediction: ['[CLS] later during the evening at thereafter enoch in evening saturn rises inttering when jupiter rises in east ones. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.849 (perp=7.920, rec=0.290, cos=0.974), tot_loss_proj:3.418 [t=0.31s]
prediction: ['[CLS] later during the evening at thereafter enoch in evening saturn rises inttering when jupiter rises in east ones. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.856 (perp=7.920, rec=0.293, cos=0.980), tot_loss_proj:3.424 [t=0.22s]
prediction: ['[CLS] later during the evening at thereafter enoch in evening saturn rises inttering when jupiter rises in east ones. [SEP]']
[1200/2000] tot_loss=2.959 (perp=8.464, rec=0.288, cos=0.977), tot_loss_proj:3.530 [t=0.19s]
prediction: ['[CLS] later during the evening at thereafter enoch of evening saturn rises inttering when jupiter rises in east ones. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.049 (perp=8.907, rec=0.293, cos=0.975), tot_loss_proj:3.606 [t=0.18s]
prediction: ['[CLS] later during the evening at thereafter enoch in evening saturn rises duringttering found jupiter rises in east ones. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.997 (perp=8.640, rec=0.293, cos=0.976), tot_loss_proj:3.554 [t=0.20s]
prediction: ['[CLS] later during the evening at thereafter enoch in evening saturn rises foundttering during jupiter rises in east ones. [SEP]']
[1350/2000] tot_loss=2.992 (perp=8.640, rec=0.289, cos=0.974), tot_loss_proj:3.554 [t=0.22s]
prediction: ['[CLS] later during the evening at thereafter enoch in evening saturn rises foundttering during jupiter rises in east ones. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.934 (perp=8.315, rec=0.296, cos=0.975), tot_loss_proj:3.490 [t=0.19s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises foundttering during jupiter rises in east ones. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.901 (perp=8.168, rec=0.295, cos=0.972), tot_loss_proj:3.468 [t=0.26s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises foundttering jupiter during rises in east ones. [SEP]']
[1500/2000] tot_loss=2.996 (perp=8.702, rec=0.281, cos=0.975), tot_loss_proj:3.584 [t=0.23s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises foundtteringiface during rises in east ones. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.900 (perp=8.207, rec=0.285, cos=0.973), tot_loss_proj:3.457 [t=0.25s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.903 (perp=8.207, rec=0.287, cos=0.975), tot_loss_proj:3.454 [t=0.25s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]']
[1650/2000] tot_loss=2.903 (perp=8.207, rec=0.287, cos=0.974), tot_loss_proj:3.454 [t=0.19s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.905 (perp=8.207, rec=0.291, cos=0.973), tot_loss_proj:3.457 [t=0.23s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.901 (perp=8.207, rec=0.286, cos=0.973), tot_loss_proj:3.458 [t=0.18s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]']
[1800/2000] tot_loss=2.902 (perp=8.207, rec=0.286, cos=0.975), tot_loss_proj:3.458 [t=0.18s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.903 (perp=8.207, rec=0.288, cos=0.974), tot_loss_proj:3.455 [t=0.22s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.906 (perp=8.207, rec=0.291, cos=0.974), tot_loss_proj:3.453 [t=0.26s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]']
[1950/2000] tot_loss=2.895 (perp=8.207, rec=0.278, cos=0.976), tot_loss_proj:3.456 [t=0.25s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.899 (perp=8.207, rec=0.284, cos=0.973), tot_loss_proj:3.456 [t=0.24s]
prediction: ['[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]
========================
predicted: 
========================
[CLS] later during the evening at thereafter titan in evening saturn rises found miface during rises in east ones. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.410 | p: 55.000 | r: 57.895
rouge2     | fm: 16.216 | p: 15.789 | r: 16.667
rougeL     | fm: 51.282 | p: 50.000 | r: 52.632
rougeLsum  | fm: 51.282 | p: 50.000 | r: 52.632
r1fm+r2fm = 72.626

[Aggregate metrics]:
rouge1     | fm: 80.874 | p: 82.060 | r: 79.876
rouge2     | fm: 43.365 | p: 44.080 | r: 42.837
rougeL     | fm: 72.420 | p: 73.464 | r: 71.583
rougeLsum  | fm: 73.044 | p: 74.057 | r: 72.151
r1fm+r2fm = 124.239

input #11 time: 0:08:21 | total time: 1:39:00


Running input #12 of 100.
reference: 
========================
He walked up the hill.
========================
average of cosine similarity 0.9993584436723262
highest_index [0]
highest [0.9993584436723262]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2002, 2939, 2039, 1996, 2940, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he walked up the hill. [SEP]']
[Init] best rec loss: 1.0273795127868652 for ['[CLS] stars sans january canvas gdansk beauty [SEP]']
[Init] best rec loss: 0.9705166220664978 for ['[CLS]thevert banks councillors respective puerto [SEP]']
[Init] best rec loss: 0.9683748483657837 for ['[CLS] articles gin keen monster plot baldwin [SEP]']
[Init] best rec loss: 0.9440220594406128 for ['[CLS] probably block tilt cavesree elevation [SEP]']
[Init] best rec loss: 0.9418670535087585 for ['[CLS] careers jewish drain blockade eternity instrument [SEP]']
[Init] best rec loss: 0.9177175164222717 for ['[CLS] untou culture conferencesea display [SEP]']
[Init] best rec loss: 0.9150117039680481 for ['[CLS] progress preyersonctum cable language [SEP]']
[Init] best rec loss: 0.8984030485153198 for ['[CLS] equal successronegizing stock hana [SEP]']
[Init] best perm rec loss: 0.8943411111831665 for ['[CLS]gizing stockrone success hana equal [SEP]']
[Init] best perm rec loss: 0.8935002684593201 for ['[CLS] success stock hanaronegizing equal [SEP]']
[Init] best perm rec loss: 0.8928298950195312 for ['[CLS]ronegizing hana stock success equal [SEP]']
[Init] best perm rec loss: 0.8927457928657532 for ['[CLS] successrone stock hana equalgizing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.047 (perp=12.191, rec=0.657, cos=0.951), tot_loss_proj:4.205 [t=0.18s]
prediction: ['[CLS] trouble divine a hill conquered spread [SEP]']
[ 100/2000] tot_loss=2.290 (perp=9.529, rec=0.317, cos=0.068), tot_loss_proj:3.605 [t=0.23s]
prediction: ['[CLS]ally. the hill walked walked [SEP]']
[ 150/2000] tot_loss=1.663 (perp=7.436, rec=0.165, cos=0.011), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] walked. the hill walked up [SEP]']
[ 200/2000] tot_loss=1.733 (perp=7.988, rec=0.128, cos=0.007), tot_loss_proj:3.540 [t=0.24s]
prediction: ['[CLS] walked. up hill he walked [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.509 (perp=6.962, rec=0.110, cos=0.007), tot_loss_proj:3.051 [t=0.18s]
prediction: ['[CLS].. up hill he walked [SEP]']
[ 300/2000] tot_loss=1.501 (perp=6.962, rec=0.102, cos=0.007), tot_loss_proj:3.053 [t=0.18s]
prediction: ['[CLS].. up hill he walked [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.679 (perp=7.681, rec=0.135, cos=0.009), tot_loss_proj:3.597 [t=0.25s]
prediction: ['[CLS]lessly. he walked up hill [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.590 (perp=7.194, rec=0.143, cos=0.009), tot_loss_proj:3.404 [t=0.18s]
prediction: ['[CLS] he walked up hill narrow. [SEP]']
[ 450/2000] tot_loss=1.601 (perp=7.424, rec=0.109, cos=0.007), tot_loss_proj:3.268 [t=0.22s]
prediction: ['[CLS] he walked up hill food. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.268 (perp=5.790, rec=0.104, cos=0.007), tot_loss_proj:1.607 [t=0.23s]
prediction: ['[CLS] he walked up food hill. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.388 (perp=6.381, rec=0.105, cos=0.007), tot_loss_proj:2.967 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
[ 600/2000] tot_loss=1.386 (perp=6.381, rec=0.104, cos=0.006), tot_loss_proj:2.976 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.386 (perp=6.381, rec=0.103, cos=0.006), tot_loss_proj:2.986 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.385 (perp=6.381, rec=0.102, cos=0.006), tot_loss_proj:2.997 [t=0.27s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
[ 750/2000] tot_loss=1.378 (perp=6.381, rec=0.096, cos=0.006), tot_loss_proj:3.009 [t=0.23s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.373 (perp=6.381, rec=0.091, cos=0.006), tot_loss_proj:3.013 [t=0.19s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.380 (perp=6.381, rec=0.098, cos=0.006), tot_loss_proj:3.029 [t=0.24s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
[ 900/2000] tot_loss=1.370 (perp=6.381, rec=0.088, cos=0.006), tot_loss_proj:3.030 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.380 (perp=6.381, rec=0.099, cos=0.006), tot_loss_proj:3.043 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.382 (perp=6.381, rec=0.100, cos=0.005), tot_loss_proj:3.042 [t=0.24s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
[1050/2000] tot_loss=1.380 (perp=6.381, rec=0.098, cos=0.005), tot_loss_proj:3.056 [t=0.26s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.380 (perp=6.381, rec=0.098, cos=0.005), tot_loss_proj:3.060 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.371 (perp=6.381, rec=0.090, cos=0.005), tot_loss_proj:3.054 [t=0.24s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
[1200/2000] tot_loss=1.370 (perp=6.381, rec=0.088, cos=0.005), tot_loss_proj:3.063 [t=0.20s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.381 (perp=6.381, rec=0.100, cos=0.005), tot_loss_proj:3.057 [t=0.27s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.384 (perp=6.381, rec=0.102, cos=0.005), tot_loss_proj:3.060 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
[1350/2000] tot_loss=1.370 (perp=6.381, rec=0.089, cos=0.005), tot_loss_proj:3.067 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.380 (perp=6.381, rec=0.099, cos=0.005), tot_loss_proj:3.075 [t=0.20s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.364 (perp=6.381, rec=0.083, cos=0.005), tot_loss_proj:3.071 [t=0.24s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
[1500/2000] tot_loss=1.371 (perp=6.381, rec=0.090, cos=0.005), tot_loss_proj:3.078 [t=0.17s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.371 (perp=6.381, rec=0.090, cos=0.005), tot_loss_proj:3.077 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.386 (perp=6.381, rec=0.106, cos=0.005), tot_loss_proj:3.083 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
[1650/2000] tot_loss=1.367 (perp=6.381, rec=0.086, cos=0.005), tot_loss_proj:3.077 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.380 (perp=6.381, rec=0.099, cos=0.005), tot_loss_proj:3.087 [t=0.21s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.380 (perp=6.381, rec=0.099, cos=0.005), tot_loss_proj:3.086 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
[1800/2000] tot_loss=1.375 (perp=6.381, rec=0.094, cos=0.005), tot_loss_proj:3.084 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.378 (perp=6.381, rec=0.097, cos=0.005), tot_loss_proj:3.090 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.370 (perp=6.381, rec=0.089, cos=0.005), tot_loss_proj:3.089 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
[1950/2000] tot_loss=1.374 (perp=6.381, rec=0.093, cos=0.005), tot_loss_proj:3.088 [t=0.20s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.371 (perp=6.381, rec=0.090, cos=0.005), tot_loss_proj:3.091 [t=0.18s]
prediction: ['[CLS] he walked walked up hill. [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] he walked up the hill. [SEP]
========================
predicted: 
========================
[CLS] he walked walked up hill. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 152.381

[Aggregate metrics]:
rouge1     | fm: 81.132 | p: 82.243 | r: 80.188
rouge2     | fm: 45.520 | p: 46.230 | r: 44.915
rougeL     | fm: 73.471 | p: 74.494 | r: 72.648
rougeLsum  | fm: 74.154 | p: 74.962 | r: 73.358
r1fm+r2fm = 126.652

input #12 time: 0:08:13 | total time: 1:47:13


Running input #13 of 100.
reference: 
========================
It is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters.
========================
average of cosine similarity 0.9993068673747104
highest_index [0]
highest [0.9993068673747104]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2009,  2003,  2023,  3291,  2008,  1996, 10076,  2017,  9611,
          1996,  2062,  4089,  2017,  1005,  2222, 13225,  1996, 12455,  2039,
          2012,  5971,  4075,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]"]
[Init] best rec loss: 0.9446279406547546 for ['[CLS] id brand fault sciences treated allows american person perceive directions alleyulating pentagonette modern declaration material devoid having participation artistic ricardooration [SEP]']
[Init] best rec loss: 0.8717837929725647 for ['[CLS] independenternussnor beat shelley pattierty better newspapers chanceocation customsdi broke nolanrona tennesseeed drummer worked analog nap [SEP]']
[Init] best rec loss: 0.8676259517669678 for ['[CLS]ge miss west unity homestead usual support starting steady electionseon snoop jamaicagames game bro pen illegal que overland doo new mall [SEP]']
[Init] best perm rec loss: 0.8666638135910034 for ['[CLS] new illegal game miss mall usualgames unity support que jamaica steady pen startingge snoop dooeon homestead bro west elections overland [SEP]']
[Init] best perm rec loss: 0.8617178797721863 for ['[CLS] snoop game support usualge doo homestead quegames steady new illegal west miss unity starting mall bro jamaica overland elections peneon [SEP]']
[Init] best perm rec loss: 0.8612036108970642 for ['[CLS] mall usual illegal que snoop doo electionsge support homestead west unity starting jamaica miss steady new game overland bro pengameseon [SEP]']
[Init] best perm rec loss: 0.8595340251922607 for ['[CLS]games usual miss starting doo homestead bro gamege west steady jamaicaeon illegal support elections new unity que mall snoop overland pen [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.466 (perp=10.878, rec=0.476, cos=0.814), tot_loss_proj:4.097 [t=0.18s]
prediction: ['[CLS] bounty its understand poker partiesheads louisiana tech gloss or the poetic operators have bigger trick guess get. helped enforcement the. [SEP]']
[ 100/2000] tot_loss=3.671 (perp=11.859, rec=0.524, cos=0.775), tot_loss_proj:4.303 [t=0.18s]
prediction: ['[CLS] off big ainations representatives satisfied many parliamentary suffix they little swamp ী - younger rations no all.ı supply or. [SEP]']
[ 150/2000] tot_loss=3.070 (perp=11.375, rec=0.515, cos=0.280), tot_loss_proj:4.226 [t=0.19s]
prediction: ["[CLS] economies holy ainations personnel'all indoor ᵍ hello little here ᅲ - youngernia no %. multiplayer supply or. [SEP]"]
[ 200/2000] tot_loss=2.862 (perp=12.172, rec=0.370, cos=0.057), tot_loss_proj:4.382 [t=0.25s]
prediction: ['[CLS] noelle particular the schemes representatives marketing its dual ᵍ the there here ᅲ town youngernia minority %. multiplayer supply or. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.838 (perp=12.249, rec=0.333, cos=0.055), tot_loss_proj:4.367 [t=0.18s]
prediction: ['[CLS] neighborhood is the schemes personnelject its dual ᵍ their this liquor ᅲ bronze youngernia minority %. multiplayer supply or. [SEP]']
[ 300/2000] tot_loss=2.671 (perp=11.729, rec=0.295, cos=0.030), tot_loss_proj:4.240 [t=0.18s]
prediction: ['[CLS] neighborhood is the schemes teams you its dual consists they this diseases ᅲ mm youngernia minority someday. headquarters supply or. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.506 (perp=11.020, rec=0.277, cos=0.025), tot_loss_proj:4.112 [t=0.18s]
prediction: ['[CLS] neighborhood is the schemes teams you its dual ᵍ easily this solve ᅲ mm younger ornia minority depending. headquarters supply. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.721 (perp=11.760, rec=0.316, cos=0.054), tot_loss_proj:4.245 [t=0.29s]
prediction: ['[CLS] neighborhood dear the schemes teams meet its longer ᵍ caine this diseases ᅲ. educated or contacts guarantee depending unix headquarters supply. [SEP]']
[ 450/2000] tot_loss=2.324 (perp=10.128, rec=0.272, cos=0.026), tot_loss_proj:3.947 [t=0.27s]
prediction: ['[CLS] here you the schemes learn meet its longer ᵍ becomes this problem ᅲ. educated or contacts guarantee depending unix headquarters supply. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.282 (perp=10.023, rec=0.258, cos=0.020), tot_loss_proj:3.941 [t=0.22s]
prediction: ['[CLS] here you the schemes learn business its longer ᵍ my this ᅲ problem. things or contacts guarantee depending unix headquarters supply. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.241 (perp=9.768, rec=0.263, cos=0.024), tot_loss_proj:3.870 [t=0.18s]
prediction: ['[CLS] here you the schemes teams business its longer ᵍ your this ᅲ problem. things guarantee forbes or depending unix headquarters supply. [SEP]']
[ 600/2000] tot_loss=2.162 (perp=9.508, rec=0.243, cos=0.017), tot_loss_proj:3.823 [t=0.20s]
prediction: ['[CLS] here you the skyline teams business its longer ᵍ your this ᅲ problem. things guarantee forbes or depending unix headquarters supply. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.161 (perp=9.519, rec=0.242, cos=0.016), tot_loss_proj:3.845 [t=0.25s]
prediction: ['[CLS] here you the skyline teams business its longer ᵍ your ᅲ this problem. things guarantee forbes corporate depending unix headquarters supplies. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.165 (perp=9.519, rec=0.247, cos=0.014), tot_loss_proj:3.843 [t=0.19s]
prediction: ['[CLS] here you the skyline teams business its longer ᵍ your ᅲ this problem. things guarantee forbes corporate depending unix headquarters supplies. [SEP]']
[ 750/2000] tot_loss=2.225 (perp=9.950, rec=0.222, cos=0.014), tot_loss_proj:3.959 [t=0.26s]
prediction: ['[CLS] here you the skyline teams business its longer consists your ᅲ this problem. things guarantee sooner corporate depending unix headquarters supplies. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.325 (perp=10.434, rec=0.224, cos=0.014), tot_loss_proj:4.046 [t=0.18s]
prediction: ['[CLS] she you the skyline teams your ᅲ business its sooner ᵍ this problem. things guarantee sooner corporate sooner unix headquarters supplies. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.303 (perp=10.326, rec=0.223, cos=0.014), tot_loss_proj:4.034 [t=0.19s]
prediction: ['[CLS] sooner you the skyline solve your ᅲ business its sooner outcome this problem. folks maximum sooner corporate she thou headquartersmakers. [SEP]']
[ 900/2000] tot_loss=2.299 (perp=10.326, rec=0.221, cos=0.013), tot_loss_proj:4.036 [t=0.18s]
prediction: ['[CLS] sooner you the skyline solve your ᅲ business its sooner outcome this problem. folks maximum sooner corporate she thou headquartersmakers. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.234 (perp=9.965, rec=0.229, cos=0.012), tot_loss_proj:3.948 [t=0.18s]
prediction: ['[CLS] sooner you the schemes solve your ᅲ business its sooner outcome this problem. folks maximum sooner she corporate thou headquartersmakers. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.198 (perp=9.824, rec=0.221, cos=0.013), tot_loss_proj:3.881 [t=0.22s]
prediction: ['[CLS] sooner you the schemes solve your ᅲ business its sooner this outcome problem. folks maximum sooner she corporate thou headquartersmakers. [SEP]']
[1050/2000] tot_loss=2.253 (perp=10.115, rec=0.219, cos=0.011), tot_loss_proj:3.961 [t=0.19s]
prediction: ['[CLS] sooner you the schemes solve your ᅲ beside its sooner this outcome problem. folks maximum sooner she corporate thou headquartersmakers. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.182 (perp=9.773, rec=0.216, cos=0.011), tot_loss_proj:3.896 [t=0.19s]
prediction: ['[CLS] sooner you the schemes solve your ᅲ is its sooner this outcome problem. folks maximum sooner she corporate thou corporatemakers. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.142 (perp=9.587, rec=0.211, cos=0.014), tot_loss_proj:3.871 [t=0.26s]
prediction: ['[CLS] sooner you the ᅲ solve your schemes is its sooner this outcome problem. folks maximum sooner you corporate unix corporatemakers. [SEP]']
[1200/2000] tot_loss=2.138 (perp=9.569, rec=0.214, cos=0.011), tot_loss_proj:3.864 [t=0.18s]
prediction: ['[CLS] sooner you the ᅲ solve your schemes is its sooner this outcome problem. folks maximum sooner you corporate thou corporatemakers. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.054 (perp=9.200, rec=0.203, cos=0.010), tot_loss_proj:3.815 [t=0.19s]
prediction: ['[CLS] sooner you the you solve your schemes is its sooner this outcome problem. folks maximum sooner ᅲ corporate thou corporatemakers. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.011 (perp=8.952, rec=0.209, cos=0.011), tot_loss_proj:3.767 [t=0.19s]
prediction: ['[CLS] sooner you the you solve your schemes is its sooner this outcome problem. folks sooner your ᅲ corporate thou corporatemakers. [SEP]']
[1350/2000] tot_loss=2.006 (perp=8.952, rec=0.206, cos=0.010), tot_loss_proj:3.762 [t=0.23s]
prediction: ['[CLS] sooner you the you solve your schemes is its sooner this outcome problem. folks sooner your ᅲ corporate thou corporatemakers. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.002 (perp=8.952, rec=0.202, cos=0.010), tot_loss_proj:3.761 [t=0.19s]
prediction: ['[CLS] sooner you the you solve your schemes is its sooner this outcome problem. folks sooner your ᅲ corporate thou corporatemakers. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.067 (perp=9.262, rec=0.205, cos=0.010), tot_loss_proj:3.821 [t=0.25s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲarians corporate thou corporatemakers. [SEP]']
[1500/2000] tot_loss=1.989 (perp=8.897, rec=0.200, cos=0.009), tot_loss_proj:3.737 [t=0.20s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ your corporate thou corporatemakers. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.056 (perp=9.262, rec=0.195, cos=0.009), tot_loss_proj:3.820 [t=0.24s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲarians corporate thou corporatemakers. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.042 (perp=9.185, rec=0.196, cos=0.009), tot_loss_proj:3.807 [t=0.27s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ corporate your thou corporatemakers. [SEP]']
[1650/2000] tot_loss=2.046 (perp=9.185, rec=0.200, cos=0.009), tot_loss_proj:3.804 [t=0.23s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ corporate your thou corporatemakers. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.049 (perp=9.185, rec=0.203, cos=0.009), tot_loss_proj:3.807 [t=0.19s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ corporate your thou corporatemakers. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.042 (perp=9.185, rec=0.196, cos=0.009), tot_loss_proj:3.806 [t=0.18s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ corporate your thou corporatemakers. [SEP]']
[1800/2000] tot_loss=2.050 (perp=9.185, rec=0.204, cos=0.009), tot_loss_proj:3.810 [t=0.19s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ corporate your thou corporatemakers. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.047 (perp=9.185, rec=0.202, cos=0.009), tot_loss_proj:3.812 [t=0.20s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ corporate your thou corporatemakers. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.043 (perp=9.201, rec=0.194, cos=0.009), tot_loss_proj:3.807 [t=0.23s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ corporate your keeps corporatemakers. [SEP]']
[1950/2000] tot_loss=2.048 (perp=9.201, rec=0.199, cos=0.009), tot_loss_proj:3.805 [t=0.19s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ corporate your keeps corporatemakers. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.985 (perp=8.876, rec=0.201, cos=0.009), tot_loss_proj:3.712 [t=0.18s]
prediction: ['[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ your corporate keeps corporatemakers. [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]
========================
predicted: 
========================
[CLS] sooner you the she solve your schemes is its sooner this outcome problem. folks sooner ᅲ corporate your keeps corporatemakers. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 52.381 | r: 47.826
rouge2     | fm: 4.762 | p: 5.000 | r: 4.545
rougeL     | fm: 31.818 | p: 33.333 | r: 30.435
rougeLsum  | fm: 31.818 | p: 33.333 | r: 30.435
r1fm+r2fm = 54.762

[Aggregate metrics]:
rouge1     | fm: 79.002 | p: 80.233 | r: 78.030
rouge2     | fm: 42.357 | p: 43.004 | r: 41.818
rougeL     | fm: 70.485 | p: 71.557 | r: 69.570
rougeLsum  | fm: 71.094 | p: 72.005 | r: 70.310
r1fm+r2fm = 121.359

input #13 time: 0:08:24 | total time: 1:55:37


Running input #14 of 100.
reference: 
========================
Mary has never kissed a man who is taller than John.
========================
average of cosine similarity 0.9993000739577433
highest_index [0]
highest [0.9993000739577433]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2984,  2038,  2196,  4782,  1037,  2158,  2040,  2003, 12283,
          2084,  2198,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mary has never kissed a man who is taller than john. [SEP]']
[Init] best rec loss: 0.9541948437690735 for ['[CLS] isa jude jon force boysraction louise work tip bigger dick sets [SEP]']
[Init] best rec loss: 0.9414898753166199 for ['[CLS]nton integratinglor half inserted al locks cbright family exhibition range [SEP]']
[Init] best rec loss: 0.9376357793807983 for ['[CLS] tar * [SEP] pa jersey efforts partisans miniseries consecrated nominee humans [UNK] [SEP]']
[Init] best rec loss: 0.9275037050247192 for ['[CLS] somewhat high licensed practice story thick septembereira vector bottoms osaka causes [SEP]']
[Init] best rec loss: 0.8851785063743591 for ['[CLS] dimension ser phone visible sv dependent performed unique independence tipped gravity tha [SEP]']
[Init] best rec loss: 0.8732437491416931 for ['[CLS] smart grandderropolis personal drama playback president lest sought producerdened [SEP]']
[Init] best rec loss: 0.8478004932403564 for ['[CLS] claiming dragon hivmerie pace emersonws bandclass how socialist adult [SEP]']
[Init] best perm rec loss: 0.8447031378746033 for ['[CLS] dragon claimingmerie hiv bandclass howws socialist pace adult emerson [SEP]']
[Init] best perm rec loss: 0.836749255657196 for ['[CLS] adult pacemerie dragon hivclass band claiming emerson how socialistws [SEP]']
[Init] best perm rec loss: 0.8359105587005615 for ['[CLS] hiv adult pace dragon band socialistmerieclass how emerson claimingws [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.189 (perp=12.314, rec=0.493, cos=0.233), tot_loss_proj:4.393 [t=0.17s]
prediction: ['[CLS] bahn original george returnssef stevens, ; john eye emeritus attraction [SEP]']
[ 100/2000] tot_loss=2.551 (perp=10.152, rec=0.391, cos=0.130), tot_loss_proj:3.958 [t=0.20s]
prediction: ['[CLS] obama its mary brother kissed mary.. john rape! attraction [SEP]']
[ 150/2000] tot_loss=1.963 (perp=7.898, rec=0.319, cos=0.064), tot_loss_proj:3.376 [t=0.23s]
prediction: ['[CLS] mary had mary kissed kissed john.. john kissed! never [SEP]']
[ 200/2000] tot_loss=1.883 (perp=7.858, rec=0.266, cos=0.045), tot_loss_proj:3.452 [t=0.18s]
prediction: ['[CLS] mary never mary kissed kissed john.. john kissed! never [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.636 (perp=6.865, rec=0.231, cos=0.032), tot_loss_proj:2.738 [t=0.24s]
prediction: ['[CLS] mary never kissed mary kissed john.. john kissed! never [SEP]']
[ 300/2000] tot_loss=1.782 (perp=7.717, rec=0.217, cos=0.021), tot_loss_proj:3.449 [t=0.18s]
prediction: ['[CLS] mary never kissed mary taller john.. john kissed ( never [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.698 (perp=7.193, rec=0.219, cos=0.040), tot_loss_proj:3.008 [t=0.19s]
prediction: ['[CLS] mary never kissed mary boy john a. never kissed ( john [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.429 (perp=6.089, rec=0.185, cos=0.026), tot_loss_proj:3.066 [t=0.18s]
prediction: ['[CLS] mary never kissed a man john mary. never kissed ( john [SEP]']
[ 450/2000] tot_loss=1.756 (perp=7.935, rec=0.155, cos=0.014), tot_loss_proj:3.504 [t=0.21s]
prediction: ['[CLS] mary never kissed a man john mary. has taller ( john [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.535 (perp=6.877, rec=0.149, cos=0.011), tot_loss_proj:3.277 [t=0.18s]
prediction: ['[CLS] mary never kissed a man has mary. john taller ( john [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.549 (perp=6.774, rec=0.176, cos=0.018), tot_loss_proj:3.276 [t=0.18s]
prediction: ['[CLS] mary never kissed a man. john has mary taller is john [SEP]']
[ 600/2000] tot_loss=1.512 (perp=6.774, rec=0.148, cos=0.009), tot_loss_proj:3.279 [t=0.19s]
prediction: ['[CLS] mary never kissed a man. john has mary taller is john [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.370 (perp=6.139, rec=0.134, cos=0.009), tot_loss_proj:3.129 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man. john mary taller is john [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.355 (perp=6.098, rec=0.127, cos=0.008), tot_loss_proj:3.157 [t=0.22s]
prediction: ['[CLS] mary has never kissed a man john. mary taller is john [SEP]']
[ 750/2000] tot_loss=1.351 (perp=6.098, rec=0.123, cos=0.008), tot_loss_proj:3.166 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man john. mary taller is john [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.352 (perp=6.098, rec=0.125, cos=0.007), tot_loss_proj:3.157 [t=0.17s]
prediction: ['[CLS] mary has never kissed a man john. mary taller is john [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.338 (perp=6.098, rec=0.111, cos=0.007), tot_loss_proj:3.158 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man john. mary taller is john [SEP]']
[ 900/2000] tot_loss=1.335 (perp=6.098, rec=0.109, cos=0.007), tot_loss_proj:3.163 [t=0.19s]
prediction: ['[CLS] mary has never kissed a man john. mary taller is john [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.329 (perp=6.098, rec=0.103, cos=0.007), tot_loss_proj:3.159 [t=0.25s]
prediction: ['[CLS] mary has never kissed a man john. mary taller is john [SEP]']
Attempt swap
[1000/2000] tot_loss=1.334 (perp=6.098, rec=0.108, cos=0.007), tot_loss_proj:3.157 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man john. mary taller is john [SEP]']
[1050/2000] tot_loss=1.325 (perp=6.098, rec=0.099, cos=0.007), tot_loss_proj:3.158 [t=0.25s]
prediction: ['[CLS] mary has never kissed a man john. mary taller is john [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.228 (perp=5.522, rec=0.117, cos=0.007), tot_loss_proj:2.884 [t=0.23s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1150/2000] tot_loss=1.222 (perp=5.522, rec=0.112, cos=0.006), tot_loss_proj:2.883 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
[1200/2000] tot_loss=1.222 (perp=5.522, rec=0.111, cos=0.006), tot_loss_proj:2.888 [t=0.23s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1250/2000] tot_loss=1.210 (perp=5.522, rec=0.099, cos=0.006), tot_loss_proj:2.886 [t=0.19s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1300/2000] tot_loss=1.218 (perp=5.522, rec=0.108, cos=0.006), tot_loss_proj:2.883 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
[1350/2000] tot_loss=1.215 (perp=5.522, rec=0.105, cos=0.006), tot_loss_proj:2.881 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1400/2000] tot_loss=1.223 (perp=5.522, rec=0.112, cos=0.006), tot_loss_proj:2.890 [t=0.19s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1450/2000] tot_loss=1.216 (perp=5.522, rec=0.106, cos=0.006), tot_loss_proj:2.883 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
[1500/2000] tot_loss=1.213 (perp=5.522, rec=0.103, cos=0.006), tot_loss_proj:2.888 [t=0.20s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1550/2000] tot_loss=1.214 (perp=5.522, rec=0.104, cos=0.006), tot_loss_proj:2.888 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1600/2000] tot_loss=1.211 (perp=5.522, rec=0.101, cos=0.006), tot_loss_proj:2.886 [t=0.20s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
[1650/2000] tot_loss=1.210 (perp=5.522, rec=0.100, cos=0.006), tot_loss_proj:2.884 [t=0.24s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1700/2000] tot_loss=1.215 (perp=5.522, rec=0.105, cos=0.006), tot_loss_proj:2.883 [t=0.27s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1750/2000] tot_loss=1.223 (perp=5.522, rec=0.113, cos=0.006), tot_loss_proj:2.879 [t=0.19s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
[1800/2000] tot_loss=1.217 (perp=5.522, rec=0.106, cos=0.006), tot_loss_proj:2.886 [t=0.19s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1850/2000] tot_loss=1.212 (perp=5.522, rec=0.101, cos=0.006), tot_loss_proj:2.885 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[1900/2000] tot_loss=1.209 (perp=5.522, rec=0.099, cos=0.006), tot_loss_proj:2.887 [t=0.27s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
[1950/2000] tot_loss=1.218 (perp=5.522, rec=0.108, cos=0.006), tot_loss_proj:2.881 [t=0.24s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Attempt swap
[2000/2000] tot_loss=1.210 (perp=5.522, rec=0.100, cos=0.006), tot_loss_proj:2.891 [t=0.18s]
prediction: ['[CLS] mary has never kissed a man. mary taller john than john [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] mary has never kissed a man who is taller than john. [SEP]
========================
predicted: 
========================
[CLS] mary has never kissed a man. mary taller john than john [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 84.615 | r: 84.615
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 84.615 | p: 84.615 | r: 84.615
rougeLsum  | fm: 84.615 | p: 84.615 | r: 84.615
r1fm+r2fm = 151.282

[Aggregate metrics]:
rouge1     | fm: 79.334 | p: 80.453 | r: 78.304
rouge2     | fm: 44.190 | p: 44.722 | r: 43.682
rougeL     | fm: 71.376 | p: 72.413 | r: 70.510
rougeLsum  | fm: 72.061 | p: 72.977 | r: 71.201
r1fm+r2fm = 123.524

input #14 time: 0:08:03 | total time: 2:03:41


Running input #15 of 100.
reference: 
========================
After ten soldiers had left, seven more ones came in.
========================
average of cosine similarity 0.9993145518230557
highest_index [0]
highest [0.9993145518230557]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2044, 2702, 3548, 2018, 2187, 1010, 2698, 2062, 3924, 2234, 1999,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] after ten soldiers had left, seven more ones came in. [SEP]']
[Init] best rec loss: 0.9528211951255798 for ['[CLS] war ne soaking kelly moment another carried ahead fk inches chasing deal [SEP]']
[Init] best rec loss: 0.855108380317688 for ['[CLS] clear love instrument patient commentaryhipversder cowboys progression what tens [SEP]']
[Init] best rec loss: 0.75975501537323 for ['[CLS] trainedpower mere exception meeting spokanemin cash vested large myselffish [SEP]']
[Init] best rec loss: 0.741703987121582 for ['[CLS] cared completely serial attestedbria within averageyriagal /vao job [SEP]']
[Init] best rec loss: 0.7361224889755249 for ['[CLS]d club linked bachelor awfe honored after award wu common ~ [SEP]']
[Init] best perm rec loss: 0.7350735068321228 for ['[CLS]fe award wud ~ linked common aw bachelor club after honored [SEP]']
[Init] best perm rec loss: 0.7331072092056274 for ['[CLS] common bachelor clubfe ~ aw award wud after honored linked [SEP]']
[Init] best perm rec loss: 0.7300412654876709 for ['[CLS]d ~fe bachelor aw award honored wu after club linked common [SEP]']
[Init] best perm rec loss: 0.7290026545524597 for ['[CLS] linked honored wu ~ bachelor club afterfe awd common award [SEP]']
[Init] best perm rec loss: 0.728809654712677 for ['[CLS] aw honored linked wu club award bachelor afterd common ~fe [SEP]']
[Init] best perm rec loss: 0.728542149066925 for ['[CLS] clubd linked honored aw wu afterfe ~ common award bachelor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.269 (perp=9.395, rec=0.343, cos=0.048), tot_loss_proj:3.100 [t=0.23s]
prediction: ['[CLS] three four, saving five more bunker bird counted upon ones ; [SEP]']
[ 100/2000] tot_loss=2.081 (perp=9.056, rec=0.247, cos=0.022), tot_loss_proj:3.010 [t=0.26s]
prediction: ['[CLS] seven seven ones returned seven more ones ones more upon ones ; [SEP]']
[ 150/2000] tot_loss=1.975 (perp=8.665, rec=0.220, cos=0.022), tot_loss_proj:3.046 [t=0.18s]
prediction: ['[CLS] seven seven ones returned seven more ones movement more upon ones. [SEP]']
[ 200/2000] tot_loss=2.034 (perp=8.709, rec=0.268, cos=0.024), tot_loss_proj:3.203 [t=0.25s]
prediction: ['[CLS] seven soldiers ones came seven more ones last five had ones. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.881 (perp=8.059, rec=0.250, cos=0.019), tot_loss_proj:2.759 [t=0.23s]
prediction: ['[CLS] seven soldiers came seven more ones coming more before came ones. [SEP]']
[ 300/2000] tot_loss=1.813 (perp=8.052, rec=0.188, cos=0.014), tot_loss_proj:2.696 [t=0.18s]
prediction: ['[CLS] seven soldiers left seven more ones came more. came ones. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.610 (perp=7.140, rec=0.168, cos=0.014), tot_loss_proj:2.545 [t=0.22s]
prediction: ['[CLS] ten soldiers left. seven more ones coming more came ones. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.736 (perp=7.781, rec=0.167, cos=0.012), tot_loss_proj:2.899 [t=0.18s]
prediction: ['[CLS] ten after soldiers left, seven more comes more came ones. [SEP]']
[ 450/2000] tot_loss=1.672 (perp=7.576, rec=0.145, cos=0.012), tot_loss_proj:2.867 [t=0.19s]
prediction: ['[CLS] ten after soldiers left, seven more end more came ones. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.977 (perp=8.529, rec=0.248, cos=0.024), tot_loss_proj:2.973 [t=0.27s]
prediction: ['[CLS] ten two soldiers left had seven more ones more ones came. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.278 (perp=10.215, rec=0.215, cos=0.020), tot_loss_proj:3.544 [t=0.18s]
prediction: ['[CLS] ten had settlements soldiers left seven more comes ones ones came. [SEP]']
[ 600/2000] tot_loss=1.959 (perp=8.775, rec=0.188, cos=0.015), tot_loss_proj:3.209 [t=0.28s]
prediction: ['[CLS] ten had two soldiers left seven more comes ones ones came. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.110 (perp=9.616, rec=0.173, cos=0.014), tot_loss_proj:3.648 [t=0.18s]
prediction: ['[CLS] ten comes had settlements soldiers left seven more ones ones came. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.977 (perp=9.001, rec=0.164, cos=0.013), tot_loss_proj:3.288 [t=0.23s]
prediction: ['[CLS] ten comes had soldiers left seven more two ones ones came. [SEP]']
[ 750/2000] tot_loss=1.746 (perp=7.933, rec=0.147, cos=0.012), tot_loss_proj:2.693 [t=0.27s]
prediction: ['[CLS] after comes had soldiers left seven more settlements five ones came. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.739 (perp=7.933, rec=0.142, cos=0.010), tot_loss_proj:2.692 [t=0.22s]
prediction: ['[CLS] after comes had soldiers left seven more settlements five ones came. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.784 (perp=8.182, rec=0.138, cos=0.010), tot_loss_proj:2.711 [t=0.23s]
prediction: ['[CLS] after comes had soldiers left seven more settlements ten ones came. [SEP]']
[ 900/2000] tot_loss=1.772 (perp=8.182, rec=0.127, cos=0.009), tot_loss_proj:2.700 [t=0.18s]
prediction: ['[CLS] after comes had soldiers left seven more settlements ten ones came. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.770 (perp=8.182, rec=0.125, cos=0.009), tot_loss_proj:2.709 [t=0.20s]
prediction: ['[CLS] after comes had soldiers left seven more settlements ten ones came. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.767 (perp=8.182, rec=0.123, cos=0.008), tot_loss_proj:2.705 [t=0.18s]
prediction: ['[CLS] after comes had soldiers left seven more settlements ten ones came. [SEP]']
[1050/2000] tot_loss=1.764 (perp=8.182, rec=0.119, cos=0.008), tot_loss_proj:2.705 [t=0.23s]
prediction: ['[CLS] after comes had soldiers left seven more settlements ten ones came. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.684 (perp=7.723, rec=0.129, cos=0.011), tot_loss_proj:2.569 [t=0.18s]
prediction: ['[CLS] after comes had soldiers left ten more settlements seven ones came. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.679 (perp=7.730, rec=0.124, cos=0.009), tot_loss_proj:2.540 [t=0.25s]
prediction: ['[CLS] after comes soldiers had left ten more settlements seven ones came. [SEP]']
[1200/2000] tot_loss=1.677 (perp=7.730, rec=0.123, cos=0.009), tot_loss_proj:2.552 [t=0.18s]
prediction: ['[CLS] after comes soldiers had left ten more settlements seven ones came. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.612 (perp=7.370, rec=0.130, cos=0.008), tot_loss_proj:2.467 [t=0.22s]
prediction: ['[CLS] comes after soldiers had left ten more settlements seven ones came. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.568 (perp=7.159, rec=0.128, cos=0.008), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] came after soldiers had left ten more settlements seven ones came. [SEP]']
[1350/2000] tot_loss=1.550 (perp=7.159, rec=0.110, cos=0.008), tot_loss_proj:2.362 [t=0.25s]
prediction: ['[CLS] came after soldiers had left ten more settlements seven ones came. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.459 (perp=6.676, rec=0.116, cos=0.008), tot_loss_proj:2.029 [t=0.18s]
prediction: ['[CLS] came after soldiers had left ten more after seven ones came. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.434 (perp=6.555, rec=0.114, cos=0.009), tot_loss_proj:1.807 [t=0.22s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
[1500/2000] tot_loss=1.443 (perp=6.555, rec=0.124, cos=0.008), tot_loss_proj:1.802 [t=0.18s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.432 (perp=6.555, rec=0.113, cos=0.008), tot_loss_proj:1.809 [t=0.19s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.437 (perp=6.555, rec=0.118, cos=0.008), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
[1650/2000] tot_loss=1.443 (perp=6.555, rec=0.124, cos=0.008), tot_loss_proj:1.808 [t=0.22s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.436 (perp=6.555, rec=0.117, cos=0.008), tot_loss_proj:1.813 [t=0.19s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.436 (perp=6.555, rec=0.117, cos=0.008), tot_loss_proj:1.809 [t=0.19s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
[1800/2000] tot_loss=1.441 (perp=6.555, rec=0.122, cos=0.008), tot_loss_proj:1.806 [t=0.19s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.442 (perp=6.555, rec=0.123, cos=0.008), tot_loss_proj:1.800 [t=0.18s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.439 (perp=6.555, rec=0.120, cos=0.008), tot_loss_proj:1.798 [t=0.21s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
[1950/2000] tot_loss=1.442 (perp=6.555, rec=0.123, cos=0.008), tot_loss_proj:1.802 [t=0.20s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.430 (perp=6.555, rec=0.111, cos=0.008), tot_loss_proj:1.813 [t=0.18s]
prediction: ['[CLS] after soldiers had left came ten more after seven ones came. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] after ten soldiers had left, seven more ones came in. [SEP]
========================
predicted: 
========================
[CLS] after soldiers had left came ten more after seven ones came. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 34.783 | p: 33.333 | r: 36.364
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 122.783

[Aggregate metrics]:
rouge1     | fm: 79.844 | p: 80.739 | r: 79.186
rouge2     | fm: 43.466 | p: 43.876 | r: 43.213
rougeL     | fm: 71.494 | p: 72.250 | r: 70.953
rougeLsum  | fm: 71.794 | p: 72.412 | r: 71.295
r1fm+r2fm = 123.310

input #15 time: 0:08:11 | total time: 2:11:53


Running input #16 of 100.
reference: 
========================
Willy is taller than that Bill is is generally believed.
========================
average of cosine similarity 0.9992796327127058
highest_index [0]
highest [0.9992796327127058]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101, 16172,  2003, 12283,  2084,  2008,  3021,  2003,  2003,  3227,
          3373,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] willy is taller than that bill is is generally believed. [SEP]']
[Init] best rec loss: 0.7902119755744934 for ['[CLS] g shared jump inch addition ted poker feel show paul initiative [SEP]']
[Init] best rec loss: 0.739452064037323 for ['[CLS]ette water home campus ceilingblood hillary appeared unfamiliar dead spend [SEP]']
[Init] best rec loss: 0.7369779944419861 for ['[CLS] selection clubs organized us it earl rates colby guardseptive battery [SEP]']
[Init] best rec loss: 0.7346456050872803 for ['[CLS] identified clap ego jurisdiction cop connection term corinne beans probable family [SEP]']
[Init] best rec loss: 0.7262424826622009 for ['[CLS] baysfully occupation volunteers songs andrei punk wheat calls espn erie [SEP]']
[Init] best rec loss: 0.7223520278930664 for ['[CLS] halfway ˢ folkhedblesches trainee itsescor indoor [SEP]']
[Init] best rec loss: 0.7212710976600647 for ['[CLS] behind reconciliation clues eventually indeed genesis king swung西 dec questions [SEP]']
[Init] best rec loss: 0.7075098156929016 for ['[CLS] and molecular beating than driveated become distance baronet mass public [SEP]']
[Init] best rec loss: 0.6890419721603394 for ['[CLS] fashionunt wood freedom finale drake trail incumbent much possibly away [SEP]']
[Init] best perm rec loss: 0.6884592771530151 for ['[CLS] freedomunt possibly wood away much trail incumbent drake fashion finale [SEP]']
[Init] best perm rec loss: 0.6877197623252869 for ['[CLS] possibly freedom trail finale drake fashion much awayunt wood incumbent [SEP]']
[Init] best perm rec loss: 0.6864833831787109 for ['[CLS] freedom possiblyunt wood fashion much incumbent trail away finale drake [SEP]']
[Init] best perm rec loss: 0.6856220960617065 for ['[CLS]unt wood finale fashion incumbent freedom trail away drake much possibly [SEP]']
[Init] best perm rec loss: 0.6856174468994141 for ['[CLS] fashion drake wood much finale possiblyunt trail away freedom incumbent [SEP]']
[Init] best perm rec loss: 0.6853880286216736 for ['[CLS] fashion finale drake away incumbent woodunt trail freedom much possibly [SEP]']
[Init] best perm rec loss: 0.6851638555526733 for ['[CLS] fashion woodunt finale much trail possibly drake incumbent freedom away [SEP]']
[Init] best perm rec loss: 0.6823499798774719 for ['[CLS] trail possibly fashion awayunt wood finale much freedom incumbent drake [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.385 (perp=9.837, rec=0.356, cos=0.062), tot_loss_proj:2.904 [t=0.18s]
prediction: ['[CLS] steve is is is bill reminded is is £ philip? [SEP]']
[ 100/2000] tot_loss=2.059 (perp=8.805, rec=0.266, cos=0.032), tot_loss_proj:3.159 [t=0.18s]
prediction: ['[CLS] willy is than that bill taller is is willy dick. [SEP]']
[ 150/2000] tot_loss=2.429 (perp=10.689, rec=0.257, cos=0.033), tot_loss_proj:3.506 [t=0.18s]
prediction: ['[CLS] bill is than that bill taller is is willymmy believed [SEP]']
[ 200/2000] tot_loss=2.449 (perp=10.210, rec=0.324, cos=0.083), tot_loss_proj:3.267 [t=0.18s]
prediction: ['[CLS] bill is than that william taller is is is sailor believed [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.997 (perp=9.049, rec=0.165, cos=0.022), tot_loss_proj:2.566 [t=0.20s]
prediction: ['[CLS] bill is believed that willy taller believed is is britten than [SEP]']
[ 300/2000] tot_loss=1.963 (perp=9.049, rec=0.139, cos=0.014), tot_loss_proj:2.571 [t=0.19s]
prediction: ['[CLS] bill is believed that willy taller believed is is britten than [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.862 (perp=8.460, rec=0.158, cos=0.011), tot_loss_proj:2.315 [t=0.22s]
prediction: ['[CLS] bill is believed that willy is believed taller is jeff than [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.622 (perp=7.363, rec=0.139, cos=0.011), tot_loss_proj:3.255 [t=0.25s]
prediction: ['[CLS] bill is believed that willy is believed taller than jeff is [SEP]']
[ 450/2000] tot_loss=1.829 (perp=8.504, rec=0.120, cos=0.008), tot_loss_proj:2.468 [t=0.22s]
prediction: ['[CLS] bill is generally that willy is believed taller than jeff is [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.764 (perp=8.025, rec=0.147, cos=0.012), tot_loss_proj:2.309 [t=0.20s]
prediction: ['[CLS] bill is. believed that willy is taller than webber is [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.664 (perp=7.615, rec=0.132, cos=0.009), tot_loss_proj:2.274 [t=0.25s]
prediction: ['[CLS] bill. is believed that willy is taller than wheelchair is [SEP]']
[ 600/2000] tot_loss=1.644 (perp=7.615, rec=0.114, cos=0.008), tot_loss_proj:2.274 [t=0.26s]
prediction: ['[CLS] bill. is believed that willy is taller than wheelchair is [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.747 (perp=8.164, rec=0.107, cos=0.007), tot_loss_proj:2.954 [t=0.19s]
prediction: ['[CLS] bill generally is believed that willy is taller than is wheelchair [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.863 (perp=8.619, rec=0.129, cos=0.010), tot_loss_proj:2.415 [t=0.18s]
prediction: ['[CLS] bill is. believed that willy is taller than is therefore [SEP]']
[ 750/2000] tot_loss=1.843 (perp=8.619, rec=0.112, cos=0.007), tot_loss_proj:2.408 [t=0.24s]
prediction: ['[CLS] bill is. believed that willy is taller than is therefore [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.692 (perp=7.883, rec=0.110, cos=0.006), tot_loss_proj:2.486 [t=0.20s]
prediction: ['[CLS] bill. is believed that willy is taller than is therefore [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.645 (perp=7.652, rec=0.109, cos=0.006), tot_loss_proj:2.960 [t=0.18s]
prediction: ['[CLS] bill is generally believed that willy is taller than is therefore [SEP]']
[ 900/2000] tot_loss=1.638 (perp=7.652, rec=0.102, cos=0.006), tot_loss_proj:2.953 [t=0.18s]
prediction: ['[CLS] bill is generally believed that willy is taller than is therefore [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.659 (perp=7.755, rec=0.101, cos=0.007), tot_loss_proj:2.299 [t=0.27s]
prediction: ['[CLS] bill is william generally believed that willy is taller than is [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.560 (perp=7.202, rec=0.112, cos=0.008), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] bill is generally believed that willy is taller than therefore is [SEP]']
[1050/2000] tot_loss=1.555 (perp=7.202, rec=0.109, cos=0.006), tot_loss_proj:2.131 [t=0.26s]
prediction: ['[CLS] bill is generally believed that willy is taller than therefore is [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.672 (perp=7.755, rec=0.114, cos=0.006), tot_loss_proj:2.296 [t=0.20s]
prediction: ['[CLS] bill is william generally believed that willy is taller than is [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.409 (perp=6.530, rec=0.097, cos=0.006), tot_loss_proj:3.227 [t=0.18s]
prediction: ['[CLS] bill is generally believed that willy is taller than william is [SEP]']
[1200/2000] tot_loss=1.411 (perp=6.530, rec=0.100, cos=0.005), tot_loss_proj:3.225 [t=0.18s]
prediction: ['[CLS] bill is generally believed that willy is taller than william is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.407 (perp=6.530, rec=0.096, cos=0.005), tot_loss_proj:3.223 [t=0.25s]
prediction: ['[CLS] bill is generally believed that willy is taller than william is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.405 (perp=6.530, rec=0.094, cos=0.005), tot_loss_proj:3.225 [t=0.18s]
prediction: ['[CLS] bill is generally believed that willy is taller than william is [SEP]']
[1350/2000] tot_loss=1.401 (perp=6.530, rec=0.090, cos=0.005), tot_loss_proj:3.225 [t=0.20s]
prediction: ['[CLS] bill is generally believed that willy is taller than william is [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.275 (perp=5.863, rec=0.097, cos=0.006), tot_loss_proj:3.153 [t=0.18s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.272 (perp=5.863, rec=0.094, cos=0.005), tot_loss_proj:3.155 [t=0.20s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
[1500/2000] tot_loss=1.272 (perp=5.863, rec=0.094, cos=0.005), tot_loss_proj:3.153 [t=0.24s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.265 (perp=5.863, rec=0.087, cos=0.005), tot_loss_proj:3.158 [t=0.18s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.269 (perp=5.863, rec=0.091, cos=0.005), tot_loss_proj:3.155 [t=0.21s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
[1650/2000] tot_loss=1.271 (perp=5.863, rec=0.093, cos=0.005), tot_loss_proj:3.159 [t=0.23s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.273 (perp=5.863, rec=0.095, cos=0.005), tot_loss_proj:3.153 [t=0.18s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.271 (perp=5.863, rec=0.093, cos=0.005), tot_loss_proj:3.153 [t=0.21s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
[1800/2000] tot_loss=1.268 (perp=5.863, rec=0.090, cos=0.005), tot_loss_proj:3.157 [t=0.18s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.269 (perp=5.863, rec=0.091, cos=0.005), tot_loss_proj:3.158 [t=0.23s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.266 (perp=5.863, rec=0.089, cos=0.005), tot_loss_proj:3.154 [t=0.18s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
[1950/2000] tot_loss=1.268 (perp=5.863, rec=0.091, cos=0.005), tot_loss_proj:3.157 [t=0.22s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.271 (perp=5.863, rec=0.093, cos=0.005), tot_loss_proj:3.154 [t=0.22s]
prediction: ['[CLS] bill is generally believed that bill is taller than willy is [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] willy is taller than that bill is is generally believed. [SEP]
========================
predicted: 
========================
[CLS] bill is generally believed that bill is taller than willy is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 60.870 | p: 58.333 | r: 63.636
rougeL     | fm: 56.000 | p: 53.846 | r: 58.333
rougeLsum  | fm: 56.000 | p: 53.846 | r: 58.333
r1fm+r2fm = 156.870

[Aggregate metrics]:
rouge1     | fm: 80.802 | p: 81.256 | r: 80.555
rouge2     | fm: 44.962 | p: 45.229 | r: 44.794
rougeL     | fm: 70.847 | p: 71.317 | r: 70.465
rougeLsum  | fm: 70.316 | p: 70.729 | r: 70.002
r1fm+r2fm = 125.764

input #16 time: 0:08:09 | total time: 2:20:02


Running input #17 of 100.
reference: 
========================
José is eating cabbage, and Holly is too.
========================
average of cosine similarity 0.9992581872479298
highest_index [0]
highest [0.9992581872479298]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  4560,  2003,  5983, 28540,  1010,  1998,  9079,  2003,  2205,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] jose is eating cabbage, and holly is too. [SEP]']
[Init] best rec loss: 0.9251716136932373 for ['[CLS] happenedgil revolution parallelsta right finding flag taiwan bella [SEP]']
[Init] best rec loss: 0.9144431352615356 for ['[CLS] no fleet rep chapter what honor fact double team suite [SEP]']
[Init] best rec loss: 0.9132050275802612 for ['[CLS] horse apartment sureɛ movement falls lordient linear college [SEP]']
[Init] best rec loss: 0.8915717005729675 for ['[CLS] adaptation recurring core ( such jersey each committee minor measures [SEP]']
[Init] best perm rec loss: 0.8897882699966431 for ['[CLS] such minor each jersey committee adaptation ( recurring measures core [SEP]']
[Init] best perm rec loss: 0.8891519904136658 for ['[CLS] committee adaptation such core measures jersey ( each recurring minor [SEP]']
[Init] best perm rec loss: 0.8880159854888916 for ['[CLS] adaptation ( committee measures each recurring jersey such core minor [SEP]']
[Init] best perm rec loss: 0.8873059153556824 for ['[CLS] committee adaptation each recurring minor measures core such jersey ( [SEP]']
[Init] best perm rec loss: 0.8865041136741638 for ['[CLS] jersey minor ( adaptation committee each measures recurring core such [SEP]']
[Init] best perm rec loss: 0.8843079805374146 for ['[CLS] minor jersey recurring each committee such core ( adaptation measures [SEP]']
[Init] best perm rec loss: 0.8835970759391785 for ['[CLS] measures jersey core recurring adaptation ( each such committee minor [SEP]']
[Init] best perm rec loss: 0.8828936815261841 for ['[CLS] jersey measures each adaptation recurring committee ( such core minor [SEP]']
[Init] best perm rec loss: 0.8816406726837158 for ['[CLS] jersey adaptation each ( such minor core committee recurring measures [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.630 (perp=10.000, rec=0.630, cos=1.000), tot_loss_proj:3.828 [t=0.19s]
prediction: ['[CLS]. cypriot degrees drank them. and is but but [SEP]']
[ 100/2000] tot_loss=3.658 (perp=10.677, rec=0.526, cos=0.997), tot_loss_proj:3.855 [t=0.26s]
prediction: ['[CLS] my illegal populations fairy things is is is too respect [SEP]']
[ 150/2000] tot_loss=3.435 (perp=9.872, rec=0.461, cos=1.000), tot_loss_proj:3.709 [t=0.19s]
prediction: ['[CLS] his illegal populations woke overheard archbishop is is too. [SEP]']
[ 200/2000] tot_loss=3.238 (perp=9.252, rec=0.388, cos=0.999), tot_loss_proj:3.603 [t=0.20s]
prediction: ['[CLS] their sullivan isdrop overheard holly is is too. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.362 (perp=9.249, rec=0.513, cos=1.000), tot_loss_proj:3.639 [t=0.18s]
prediction: ['[CLS].: compute is their hollyberry is too. [SEP]']
[ 300/2000] tot_loss=3.392 (perp=9.859, rec=0.424, cos=0.996), tot_loss_proj:3.726 [t=0.19s]
prediction: ['[CLS] : coffee sleepy is pursuerdialberry is too. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.176 (perp=9.247, rec=0.330, cos=0.997), tot_loss_proj:3.568 [t=0.27s]
prediction: ['[CLS] and cuisinerdial is barbed operas holly is too. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.180 (perp=8.336, rec=0.527, cos=0.986), tot_loss_proj:3.332 [t=0.22s]
prediction: ['[CLS] and meyrick madame is each sleepy holly is too. [SEP]']
[ 450/2000] tot_loss=3.297 (perp=9.729, rec=0.354, cos=0.997), tot_loss_proj:3.723 [t=0.24s]
prediction: ['[CLS] and spinal jose is sphinx spoiled holly is too. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.183 (perp=9.341, rec=0.318, cos=0.996), tot_loss_proj:3.590 [t=0.22s]
prediction: ['[CLS] andrdial jose sausage is allegro holly is too. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.019 (perp=8.598, rec=0.302, cos=0.997), tot_loss_proj:3.470 [t=0.19s]
prediction: ['[CLS]rdial jose sausage is and allegro holly is too. [SEP]']
[ 600/2000] tot_loss=3.264 (perp=9.949, rec=0.276, cos=0.998), tot_loss_proj:3.783 [t=0.18s]
prediction: ['[CLS]eous jose sausage is and macdonald holly is too. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.436 (perp=10.573, rec=0.325, cos=0.997), tot_loss_proj:3.870 [t=0.17s]
prediction: ['[CLS] highness spying is and bottles holly isrdial too. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.068 (perp=8.860, rec=0.299, cos=0.998), tot_loss_proj:3.509 [t=0.18s]
prediction: ['[CLS] eating highness is and sleepy holly isrdial too. [SEP]']
[ 750/2000] tot_loss=3.135 (perp=9.256, rec=0.286, cos=0.998), tot_loss_proj:3.651 [t=0.20s]
prediction: ['[CLS] eating highness is and macdonald holly isrdial too. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=3.072 (perp=8.940, rec=0.286, cos=0.998), tot_loss_proj:3.656 [t=0.18s]
prediction: ['[CLS] bestseller highness is holly and macdonald isrdial too. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.969 (perp=8.476, rec=0.276, cos=0.998), tot_loss_proj:3.496 [t=0.18s]
prediction: ['[CLS] bestseller highness is holly macdonald and isrdial too. [SEP]']
[ 900/2000] tot_loss=2.964 (perp=8.476, rec=0.271, cos=0.998), tot_loss_proj:3.500 [t=0.20s]
prediction: ['[CLS] bestseller highness is holly macdonald and isrdial too. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.052 (perp=8.952, rec=0.264, cos=0.998), tot_loss_proj:3.540 [t=0.18s]
prediction: ['[CLS] bestseller highness is holly takeoff and isrdial too. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.113 (perp=9.296, rec=0.256, cos=0.998), tot_loss_proj:3.656 [t=0.25s]
prediction: ['[CLS] bestseller highness is holly takeoff and is車 too. [SEP]']
[1050/2000] tot_loss=3.127 (perp=9.296, rec=0.269, cos=0.998), tot_loss_proj:3.652 [t=0.19s]
prediction: ['[CLS] bestseller highness is holly takeoff and is車 too. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.034 (perp=8.817, rec=0.273, cos=0.998), tot_loss_proj:3.597 [t=0.24s]
prediction: ['[CLS] bestseller車 is holly takeoff and is highness too. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.953 (perp=8.498, rec=0.255, cos=0.999), tot_loss_proj:3.454 [t=0.28s]
prediction: ['[CLS] bestseller車 is holly takeoff and highness is too. [SEP]']
[1200/2000] tot_loss=2.950 (perp=8.498, rec=0.252, cos=0.999), tot_loss_proj:3.456 [t=0.22s]
prediction: ['[CLS] bestseller車 is holly takeoff and highness is too. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.962 (perp=8.498, rec=0.264, cos=0.999), tot_loss_proj:3.451 [t=0.18s]
prediction: ['[CLS] bestseller車 is holly takeoff and highness is too. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.012 (perp=8.831, rec=0.248, cos=0.999), tot_loss_proj:3.492 [t=0.18s]
prediction: ['[CLS] bestsellereous is holly takeoff and highness is too. [SEP]']
[1350/2000] tot_loss=3.023 (perp=8.831, rec=0.258, cos=0.999), tot_loss_proj:3.493 [t=0.18s]
prediction: ['[CLS] bestsellereous is holly takeoff and highness is too. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=3.029 (perp=8.872, rec=0.256, cos=0.999), tot_loss_proj:3.645 [t=0.20s]
prediction: ['[CLS] bestseller takeoff is holly車 and jose is too. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=3.129 (perp=9.356, rec=0.259, cos=0.999), tot_loss_proj:3.652 [t=0.19s]
prediction: ['[CLS] highness takeoff is holly車 and bestseller is too. [SEP]']
[1500/2000] tot_loss=2.942 (perp=8.461, rec=0.251, cos=0.999), tot_loss_proj:3.520 [t=0.19s]
prediction: ['[CLS] jose takeoff is holly車 and bestseller is too. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.855 (perp=8.021, rec=0.252, cos=0.999), tot_loss_proj:3.333 [t=0.18s]
prediction: ['[CLS] joseල is holly spoiled and bestseller is too. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.859 (perp=8.021, rec=0.256, cos=0.999), tot_loss_proj:3.329 [t=0.18s]
prediction: ['[CLS] joseල is holly spoiled and bestseller is too. [SEP]']
[1650/2000] tot_loss=2.859 (perp=8.021, rec=0.256, cos=0.999), tot_loss_proj:3.332 [t=0.18s]
prediction: ['[CLS] joseල is holly spoiled and bestseller is too. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.860 (perp=8.021, rec=0.257, cos=0.999), tot_loss_proj:3.336 [t=0.22s]
prediction: ['[CLS] joseල is holly spoiled and bestseller is too. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.857 (perp=8.021, rec=0.254, cos=0.999), tot_loss_proj:3.330 [t=0.22s]
prediction: ['[CLS] joseල is holly spoiled and bestseller is too. [SEP]']
[1800/2000] tot_loss=2.861 (perp=8.021, rec=0.258, cos=0.999), tot_loss_proj:3.331 [t=0.18s]
prediction: ['[CLS] joseල is holly spoiled and bestseller is too. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.900 (perp=8.269, rec=0.247, cos=0.999), tot_loss_proj:3.372 [t=0.21s]
prediction: ['[CLS] josecript is holly spoiled and bestseller is too. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.838 (perp=7.903, rec=0.259, cos=0.999), tot_loss_proj:3.319 [t=0.18s]
prediction: ['[CLS] josecript is spoiled holly and bestseller is too. [SEP]']
[1950/2000] tot_loss=2.824 (perp=7.903, rec=0.244, cos=0.999), tot_loss_proj:3.321 [t=0.20s]
prediction: ['[CLS] josecript is spoiled holly and bestseller is too. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.809 (perp=7.770, rec=0.256, cos=0.999), tot_loss_proj:3.267 [t=0.18s]
prediction: ['[CLS] josecript is spoiled and holly bestseller is too. [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] jose is eating cabbage, and holly is too. [SEP]
========================
predicted: 
========================
[CLS] joseල is holly spoiled and bestseller is too. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 44.444 | p: 44.444 | r: 44.444
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 124.444

[Aggregate metrics]:
rouge1     | fm: 80.769 | p: 81.254 | r: 80.470
rouge2     | fm: 44.891 | p: 45.097 | r: 44.695
rougeL     | fm: 70.907 | p: 71.399 | r: 70.542
rougeLsum  | fm: 70.222 | p: 70.735 | r: 69.902
r1fm+r2fm = 125.660

input #17 time: 0:08:04 | total time: 2:28:07


Running input #18 of 100.
reference: 
========================
John demanded that she stop phoning him.
========================
average of cosine similarity 0.9994126222039297
highest_index [0]
highest [0.9994126222039297]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2198,  6303,  2008,  2016,  2644,  6887, 13369,  2032,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] john demanded that she stop phoning him. [SEP]']
[Init] best rec loss: 0.9877802133560181 for ['[CLS] layton fewer consult school lu bounced choose switzerland years [SEP]']
[Init] best rec loss: 0.9811486005783081 for ['[CLS] union contact n sight oldest songs monumentalbal crow [SEP]']
[Init] best rec loss: 0.9715001583099365 for ['[CLS] state oceandd lionner marx sensorycute monthly [SEP]']
[Init] best rec loss: 0.9666527509689331 for ['[CLS] tattooformsmorphic through rogers signed asktaka commons [SEP]']
[Init] best rec loss: 0.9620587825775146 for ['[CLS] sole askʂ waste bull wing imperial were discovered [SEP]']
[Init] best rec loss: 0.9581156969070435 for ['[CLS] suggested possession terri paper [SEP] month ku tar 3000 [SEP]']
[Init] best rec loss: 0.9447695016860962 for ['[CLS] lamp third impact upon navy followed wheel sheila enough [SEP]']
[Init] best perm rec loss: 0.939691960811615 for ['[CLS] followed enough upon impact lamp third sheila navy wheel [SEP]']
[Init] best perm rec loss: 0.9373711347579956 for ['[CLS] impact enough sheila third followed navy lamp wheel upon [SEP]']
[Init] best perm rec loss: 0.9369447827339172 for ['[CLS] navy enough followed upon impact sheila lamp third wheel [SEP]']
[Init] best perm rec loss: 0.9368777275085449 for ['[CLS] lamp enough impact navy followed sheila upon wheel third [SEP]']
[Init] best perm rec loss: 0.9363468885421753 for ['[CLS] impact lamp enough wheel third upon navy followed sheila [SEP]']
[Init] best perm rec loss: 0.9349254965782166 for ['[CLS] wheel sheila enough followed impact upon lamp third navy [SEP]']
[Init] best perm rec loss: 0.9337619543075562 for ['[CLS] lamp enough impact navy followed upon sheila third wheel [SEP]']
[Init] best perm rec loss: 0.9319055080413818 for ['[CLS] enough upon sheila lamp impact followed navy wheel third [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.132 (perp=12.122, rec=0.715, cos=0.992), tot_loss_proj:4.226 [t=0.23s]
prediction: ['[CLS] medalist ways brown application enters using peterson front. [SEP]']
[ 100/2000] tot_loss=3.812 (perp=11.073, rec=0.598, cos=0.999), tot_loss_proj:4.019 [t=0.20s]
prediction: ['[CLS] medalist expected that application enters harassed complain direction. [SEP]']
[ 150/2000] tot_loss=4.003 (perp=12.354, rec=0.537, cos=0.996), tot_loss_proj:4.271 [t=0.18s]
prediction: ['[CLS] medalist demanded plaques application enters searched hitler window. [SEP]']
[ 200/2000] tot_loss=3.859 (perp=11.707, rec=0.519, cos=0.998), tot_loss_proj:4.141 [t=0.23s]
prediction: ['[CLS] reinforcements demanded kevinoning enters demanded hitler window. [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.873 (perp=11.957, rec=0.485, cos=0.996), tot_loss_proj:4.353 [t=0.18s]
prediction: ['[CLS] racehorse demanded kevin demanded she demanded shiva window. [SEP]']
[ 300/2000] tot_loss=3.756 (perp=11.475, rec=0.469, cos=0.992), tot_loss_proj:4.211 [t=0.21s]
prediction: ['[CLS] racehorse demanded ethan demanded she demanded shiva window. [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.451 (perp=10.099, rec=0.443, cos=0.988), tot_loss_proj:3.882 [t=0.22s]
prediction: ['[CLS] reinforcements demanded without demanded she demanded shivadae. [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.356 (perp=9.681, rec=0.431, cos=0.988), tot_loss_proj:3.772 [t=0.24s]
prediction: ['[CLS] reinforcements demanded without demanded sheoning honeydae. [SEP]']
[ 450/2000] tot_loss=3.348 (perp=9.681, rec=0.423, cos=0.989), tot_loss_proj:3.770 [t=0.23s]
prediction: ['[CLS] reinforcements demanded without demanded sheoning honeydae. [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.342 (perp=9.681, rec=0.419, cos=0.987), tot_loss_proj:3.770 [t=0.22s]
prediction: ['[CLS] reinforcements demanded without demanded sheoning honeydae. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.421 (perp=10.129, rec=0.405, cos=0.990), tot_loss_proj:3.810 [t=0.18s]
prediction: ['[CLS] reinforcements demanded keep demanded sheoning honey window. [SEP]']
[ 600/2000] tot_loss=3.369 (perp=9.855, rec=0.410, cos=0.987), tot_loss_proj:3.786 [t=0.18s]
prediction: ['[CLS] reinforcements demanded just demanded sheoning honey window. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.353 (perp=9.855, rec=0.395, cos=0.987), tot_loss_proj:3.785 [t=0.19s]
prediction: ['[CLS] reinforcements demanded just demanded sheoning honey window. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.432 (perp=10.244, rec=0.396, cos=0.987), tot_loss_proj:3.855 [t=0.20s]
prediction: ['[CLS] reinforcements demanded just demanded sheoning honey bed. [SEP]']
[ 750/2000] tot_loss=3.432 (perp=10.244, rec=0.396, cos=0.987), tot_loss_proj:3.855 [t=0.26s]
prediction: ['[CLS] reinforcements demanded just demanded sheoning honey bed. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=3.234 (perp=9.248, rec=0.398, cos=0.987), tot_loss_proj:3.744 [t=0.25s]
prediction: ['[CLS] reinforcements demanded they demanded she bedoning honey. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.251 (perp=9.332, rec=0.398, cos=0.987), tot_loss_proj:3.746 [t=0.21s]
prediction: ['[CLS] reinforcements demanded they demanded she bedoning angie. [SEP]']
[ 900/2000] tot_loss=3.238 (perp=9.332, rec=0.386, cos=0.986), tot_loss_proj:3.745 [t=0.18s]
prediction: ['[CLS] reinforcements demanded they demanded she bedoning angie. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.207 (perp=9.180, rec=0.386, cos=0.984), tot_loss_proj:3.634 [t=0.26s]
prediction: ['[CLS] reinforcements demanded they demanded she marissaoning angie. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.191 (perp=9.140, rec=0.380, cos=0.983), tot_loss_proj:3.614 [t=0.22s]
prediction: ['[CLS] reinforcements demanded she demanded she marissaoning angie. [SEP]']
[1050/2000] tot_loss=3.177 (perp=9.070, rec=0.380, cos=0.983), tot_loss_proj:3.614 [t=0.19s]
prediction: ['[CLS] reinforcements demanded they demanded she marissaoning millie. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.173 (perp=9.070, rec=0.376, cos=0.983), tot_loss_proj:3.606 [t=0.24s]
prediction: ['[CLS] reinforcements demanded they demanded she marissaoning millie. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.171 (perp=9.070, rec=0.374, cos=0.983), tot_loss_proj:3.610 [t=0.18s]
prediction: ['[CLS] reinforcements demanded they demanded she marissaoning millie. [SEP]']
[1200/2000] tot_loss=3.399 (perp=10.214, rec=0.373, cos=0.983), tot_loss_proj:3.814 [t=0.24s]
prediction: ['[CLS] reinforcements demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.400 (perp=10.214, rec=0.373, cos=0.983), tot_loss_proj:3.812 [t=0.18s]
prediction: ['[CLS] reinforcements demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.403 (perp=10.214, rec=0.376, cos=0.984), tot_loss_proj:3.813 [t=0.17s]
prediction: ['[CLS] reinforcements demanded bits demanded she marissaoning millie. [SEP]']
[1350/2000] tot_loss=3.399 (perp=10.214, rec=0.372, cos=0.984), tot_loss_proj:3.813 [t=0.22s]
prediction: ['[CLS] reinforcements demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.401 (perp=10.214, rec=0.375, cos=0.983), tot_loss_proj:3.813 [t=0.23s]
prediction: ['[CLS] reinforcements demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.396 (perp=10.214, rec=0.369, cos=0.983), tot_loss_proj:3.815 [t=0.18s]
prediction: ['[CLS] reinforcements demanded bits demanded she marissaoning millie. [SEP]']
[1500/2000] tot_loss=3.402 (perp=10.214, rec=0.375, cos=0.983), tot_loss_proj:3.812 [t=0.18s]
prediction: ['[CLS] reinforcements demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.400 (perp=10.214, rec=0.374, cos=0.983), tot_loss_proj:3.814 [t=0.18s]
prediction: ['[CLS] reinforcements demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.390 (perp=10.214, rec=0.363, cos=0.984), tot_loss_proj:3.809 [t=0.18s]
prediction: ['[CLS] reinforcements demanded bits demanded she marissaoning millie. [SEP]']
[1650/2000] tot_loss=3.536 (perp=10.915, rec=0.369, cos=0.983), tot_loss_proj:3.950 [t=0.24s]
prediction: ['[CLS] casualties demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.530 (perp=10.915, rec=0.364, cos=0.984), tot_loss_proj:3.950 [t=0.18s]
prediction: ['[CLS] casualties demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.541 (perp=10.915, rec=0.375, cos=0.984), tot_loss_proj:3.953 [t=0.24s]
prediction: ['[CLS] casualties demanded bits demanded she marissaoning millie. [SEP]']
[1800/2000] tot_loss=3.535 (perp=10.915, rec=0.368, cos=0.983), tot_loss_proj:3.955 [t=0.21s]
prediction: ['[CLS] casualties demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.532 (perp=10.915, rec=0.366, cos=0.984), tot_loss_proj:3.947 [t=0.23s]
prediction: ['[CLS] casualties demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.533 (perp=10.915, rec=0.366, cos=0.984), tot_loss_proj:3.949 [t=0.23s]
prediction: ['[CLS] casualties demanded bits demanded she marissaoning millie. [SEP]']
[1950/2000] tot_loss=3.533 (perp=10.915, rec=0.366, cos=0.983), tot_loss_proj:3.951 [t=0.18s]
prediction: ['[CLS] casualties demanded bits demanded she marissaoning millie. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.537 (perp=10.915, rec=0.370, cos=0.984), tot_loss_proj:3.954 [t=0.19s]
prediction: ['[CLS] casualties demanded bits demanded she marissaoning millie. [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] john demanded that she stop phoning him. [SEP]
========================
predicted: 
========================
[CLS] casualties demanded bits demanded she marissaoning millie. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 44.444 | p: 44.444 | r: 44.444
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 44.444

[Aggregate metrics]:
rouge1     | fm: 78.990 | p: 79.440 | r: 78.680
rouge2     | fm: 42.635 | p: 42.736 | r: 42.394
rougeL     | fm: 69.464 | p: 69.906 | r: 69.117
rougeLsum  | fm: 68.835 | p: 69.327 | r: 68.520
r1fm+r2fm = 121.625

input #18 time: 0:08:21 | total time: 2:36:29


Running input #19 of 100.
reference: 
========================
I have six too many marbles.
========================
average of cosine similarity 0.999305888550308
highest_index [0]
highest [0.999305888550308]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 1045, 2031, 2416, 2205, 2116, 7720, 2015, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have six too many marbles. [SEP]']
[Init] best rec loss: 0.9150007367134094 for ['[CLS] endemicston card horsevere kira particular glasses [SEP]']
[Init] best rec loss: 0.9137986302375793 for ['[CLS] they future math note ] chaseanza bore [SEP]']
[Init] best rec loss: 0.8883269429206848 for ['[CLS] basis anythingui cleared looking name began ce [SEP]']
[Init] best rec loss: 0.8865185379981995 for ['[CLS] astronomy bowl records roe processed piano camera stuff [SEP]']
[Init] best rec loss: 0.8345103859901428 for ['[CLS] liability bleak later itpta doinʁ wilde [SEP]']
[Init] best rec loss: 0.7897818088531494 for ['[CLS] rear itself period def chargelth length contract [SEP]']
[Init] best perm rec loss: 0.7894785404205322 for ['[CLS] chargelth itself def contract period length rear [SEP]']
[Init] best perm rec loss: 0.7868735194206238 for ['[CLS] contract length def charge rearlth period itself [SEP]']
[Init] best perm rec loss: 0.786363959312439 for ['[CLS] length period charge itself def contract rearlth [SEP]']
[Init] best perm rec loss: 0.7855151295661926 for ['[CLS] length itself deflth rear contract charge period [SEP]']
[Init] best perm rec loss: 0.7844892740249634 for ['[CLS] def itself lengthlth charge rear contract period [SEP]']
[Init] best perm rec loss: 0.7842040061950684 for ['[CLS] def length itself charge period contract rearlth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.339 (perp=12.965, rec=0.514, cos=0.233), tot_loss_proj:4.536 [t=0.17s]
prediction: ['[CLS] extreme after series三 lincoln defender introduction many [SEP]']
[ 100/2000] tot_loss=2.984 (perp=11.877, rec=0.415, cos=0.193), tot_loss_proj:4.336 [t=0.18s]
prediction: ['[CLS] too defunct group six lincoln marble = many [SEP]']
[ 150/2000] tot_loss=2.303 (perp=9.125, rec=0.330, cos=0.147), tot_loss_proj:3.784 [t=0.31s]
prediction: ['[CLS] too. two six john marble. many [SEP]']
[ 200/2000] tot_loss=2.270 (perp=9.183, rec=0.293, cos=0.140), tot_loss_proj:3.798 [t=0.18s]
prediction: ['[CLS] too. three six stiff marble. many [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.936 (perp=7.874, rec=0.253, cos=0.108), tot_loss_proj:3.493 [t=0.19s]
prediction: ['[CLS] have six many too many marble. many [SEP]']
[ 300/2000] tot_loss=1.901 (perp=8.080, rec=0.204, cos=0.081), tot_loss_proj:3.585 [t=0.25s]
prediction: ['[CLS] have six many too many marble. i [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.768 (perp=7.635, rec=0.168, cos=0.073), tot_loss_proj:3.465 [t=0.19s]
prediction: ['[CLS] many have six too many marble. i [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.782 (perp=7.356, rec=0.250, cos=0.061), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] i many have six too expensive marble. [SEP]']
[ 450/2000] tot_loss=1.610 (perp=7.356, rec=0.128, cos=0.011), tot_loss_proj:3.481 [t=0.18s]
prediction: ['[CLS] i many have six too expensive marble. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.344 (perp=6.173, rec=0.101, cos=0.009), tot_loss_proj:2.914 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.336 (perp=6.173, rec=0.096, cos=0.005), tot_loss_proj:2.909 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
[ 600/2000] tot_loss=1.337 (perp=6.173, rec=0.098, cos=0.004), tot_loss_proj:2.903 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.323 (perp=6.173, rec=0.085, cos=0.004), tot_loss_proj:2.903 [t=0.19s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.319 (perp=6.173, rec=0.081, cos=0.004), tot_loss_proj:2.902 [t=0.22s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
[ 750/2000] tot_loss=1.311 (perp=6.173, rec=0.073, cos=0.003), tot_loss_proj:2.897 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.323 (perp=6.173, rec=0.085, cos=0.003), tot_loss_proj:2.897 [t=0.21s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.317 (perp=6.173, rec=0.080, cos=0.003), tot_loss_proj:2.904 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
[ 900/2000] tot_loss=1.333 (perp=6.173, rec=0.095, cos=0.003), tot_loss_proj:2.899 [t=0.22s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.320 (perp=6.173, rec=0.083, cos=0.003), tot_loss_proj:2.899 [t=0.17s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.319 (perp=6.173, rec=0.082, cos=0.003), tot_loss_proj:2.894 [t=0.28s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
[1050/2000] tot_loss=1.320 (perp=6.173, rec=0.082, cos=0.003), tot_loss_proj:2.895 [t=0.26s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.315 (perp=6.173, rec=0.078, cos=0.003), tot_loss_proj:2.897 [t=0.20s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.311 (perp=6.173, rec=0.074, cos=0.003), tot_loss_proj:2.893 [t=0.28s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
[1200/2000] tot_loss=1.321 (perp=6.173, rec=0.083, cos=0.003), tot_loss_proj:2.902 [t=0.22s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.316 (perp=6.173, rec=0.079, cos=0.003), tot_loss_proj:2.895 [t=0.17s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.310 (perp=6.173, rec=0.073, cos=0.003), tot_loss_proj:2.899 [t=0.24s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
[1350/2000] tot_loss=1.311 (perp=6.173, rec=0.074, cos=0.003), tot_loss_proj:2.901 [t=0.17s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.306 (perp=6.173, rec=0.069, cos=0.003), tot_loss_proj:2.895 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.314 (perp=6.173, rec=0.076, cos=0.003), tot_loss_proj:2.897 [t=0.25s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
[1500/2000] tot_loss=1.310 (perp=6.173, rec=0.073, cos=0.003), tot_loss_proj:2.896 [t=0.19s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.318 (perp=6.173, rec=0.080, cos=0.003), tot_loss_proj:2.898 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.308 (perp=6.173, rec=0.071, cos=0.003), tot_loss_proj:2.895 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
[1650/2000] tot_loss=1.311 (perp=6.173, rec=0.074, cos=0.003), tot_loss_proj:2.897 [t=0.24s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.307 (perp=6.173, rec=0.070, cos=0.003), tot_loss_proj:2.893 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.321 (perp=6.173, rec=0.084, cos=0.003), tot_loss_proj:2.896 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
[1800/2000] tot_loss=1.322 (perp=6.173, rec=0.085, cos=0.003), tot_loss_proj:2.898 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.310 (perp=6.173, rec=0.073, cos=0.003), tot_loss_proj:2.893 [t=0.22s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.311 (perp=6.173, rec=0.074, cos=0.003), tot_loss_proj:2.888 [t=0.20s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
[1950/2000] tot_loss=1.314 (perp=6.173, rec=0.077, cos=0.003), tot_loss_proj:2.896 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.316 (perp=6.173, rec=0.079, cos=0.003), tot_loss_proj:2.896 [t=0.18s]
prediction: ['[CLS] i have six too many expensive marble. [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] i have six too many marbles. [SEP]
========================
predicted: 
========================
[CLS] i have six too many expensive marble. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 66.667 | p: 62.500 | r: 71.429
rougeL     | fm: 82.353 | p: 77.778 | r: 87.500
rougeLsum  | fm: 82.353 | p: 77.778 | r: 87.500
r1fm+r2fm = 149.020

[Aggregate metrics]:
rouge1     | fm: 79.004 | p: 79.188 | r: 79.063
rouge2     | fm: 43.749 | p: 43.734 | r: 43.769
rougeL     | fm: 70.052 | p: 70.181 | r: 69.959
rougeLsum  | fm: 69.647 | p: 69.900 | r: 69.557
r1fm+r2fm = 122.753

input #19 time: 0:08:06 | total time: 2:44:35


Running input #20 of 100.
reference: 
========================
Mark's single mindedness terrified me.
========================
average of cosine similarity 0.9994279625663226
highest_index [0]
highest [0.9994279625663226]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2928,  1005,  1055,  2309, 13128,  2791, 10215,  2033,  1012,
           102]], device='cuda:0')
Debug: ref = ["[CLS] mark's single mindedness terrified me. [SEP]"]
[Init] best rec loss: 1.0452334880828857 for ['[CLS] [CLS] asked sirius accessed ling women emphasis disc height [SEP]']
[Init] best rec loss: 0.9451050162315369 for ['[CLS]se guitarfirmed sky 2015 begging box simply agreed [SEP]']
[Init] best rec loss: 0.9352335333824158 for ['[CLS] avery her el practices pius still academic belief power [SEP]']
[Init] best rec loss: 0.9296568036079407 for ['[CLS] silence sounds h derrick serviceks whose begin make [SEP]']
[Init] best perm rec loss: 0.9269508719444275 for ['[CLS] derrick begin whose soundsks h silence make service [SEP]']
[Init] best perm rec loss: 0.9261907935142517 for ['[CLS] derrick make serviceks begin whose silence sounds h [SEP]']
[Init] best perm rec loss: 0.9243326187133789 for ['[CLS] h whose beginks sounds silence service make derrick [SEP]']
[Init] best perm rec loss: 0.9241335988044739 for ['[CLS] make derrickks whose silence sounds begin h service [SEP]']
[Init] best perm rec loss: 0.9237069487571716 for ['[CLS] derrick sounds h make silence whose beginks service [SEP]']
[Init] best perm rec loss: 0.9234338998794556 for ['[CLS] derrick makeks begin silence sounds whose h service [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.035 (perp=12.595, rec=0.640, cos=0.876), tot_loss_proj:4.414 [t=0.22s]
prediction: ['[CLS] revealed k lines cruz is kathy was son journal [SEP]']
[ 100/2000] tot_loss=2.449 (perp=10.532, rec=0.301, cos=0.042), tot_loss_proj:3.967 [t=0.25s]
prediction: ['[CLS] article mark thought mark had mark terrified behavior me [SEP]']
[ 150/2000] tot_loss=2.907 (perp=13.409, rec=0.204, cos=0.021), tot_loss_proj:4.608 [t=0.18s]
prediction: ['[CLS] mark mark words minded s mark terrified behavior me [SEP]']
[ 200/2000] tot_loss=2.523 (perp=11.745, rec=0.161, cos=0.013), tot_loss_proj:4.242 [t=0.27s]
prediction: ['[CLS]. mark minded minded s mark terrified minded me [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.570 (perp=11.284, rec=0.278, cos=0.036), tot_loss_proj:4.117 [t=0.18s]
prediction: ['[CLS] james coe felt mark mindedness terrified behavior me [SEP]']
[ 300/2000] tot_loss=2.338 (perp=10.687, rec=0.187, cos=0.013), tot_loss_proj:4.041 [t=0.18s]
prediction: ["[CLS] james coe'mark mindedness terrified s me [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.805 (perp=8.078, rec=0.177, cos=0.013), tot_loss_proj:3.571 [t=0.18s]
prediction: ["[CLS] james engine's mark mindedness terrified me [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.792 (perp=8.167, rec=0.151, cos=0.008), tot_loss_proj:3.537 [t=0.26s]
prediction: ["[CLS] mark engine's mark mindedness terrified me [SEP]"]
[ 450/2000] tot_loss=1.855 (perp=8.495, rec=0.149, cos=0.007), tot_loss_proj:3.657 [t=0.19s]
prediction: ["[CLS] marcus engine's mark mindedness terrified me [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.760 (perp=8.075, rec=0.138, cos=0.007), tot_loss_proj:3.659 [t=0.19s]
prediction: ["[CLS],'s mark mindedness nicholas terrified me [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.736 (perp=7.942, rec=0.141, cos=0.007), tot_loss_proj:3.706 [t=0.23s]
prediction: ["[CLS].'s mark mindedness nicholas terrified me [SEP]"]
[ 600/2000] tot_loss=1.728 (perp=7.942, rec=0.133, cos=0.007), tot_loss_proj:3.714 [t=0.24s]
prediction: ["[CLS].'s mark mindedness nicholas terrified me [SEP]"]
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=1.657 (perp=7.575, rec=0.135, cos=0.007), tot_loss_proj:3.509 [t=0.18s]
prediction: ["[CLS]'s mark mindedness ely terrified me, [SEP]"]
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.485 (perp=6.725, rec=0.131, cos=0.008), tot_loss_proj:2.313 [t=0.18s]
prediction: ["[CLS] nicholas's mark mindedness terrified me. [SEP]"]
[ 750/2000] tot_loss=1.437 (perp=6.548, rec=0.121, cos=0.007), tot_loss_proj:2.575 [t=0.18s]
prediction: ["[CLS] annie's mark mindedness terrified me. [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.367 (perp=6.196, rec=0.121, cos=0.007), tot_loss_proj:2.225 [t=0.22s]
prediction: ["[CLS] stanley's mark mindedness terrified me. [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.363 (perp=6.196, rec=0.117, cos=0.007), tot_loss_proj:2.228 [t=0.22s]
prediction: ["[CLS] stanley's mark mindedness terrified me. [SEP]"]
[ 900/2000] tot_loss=1.359 (perp=6.196, rec=0.113, cos=0.006), tot_loss_proj:2.220 [t=0.18s]
prediction: ["[CLS] stanley's mark mindedness terrified me. [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.353 (perp=6.196, rec=0.108, cos=0.006), tot_loss_proj:2.223 [t=0.18s]
prediction: ["[CLS] stanley's mark mindedness terrified me. [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.349 (perp=6.196, rec=0.104, cos=0.006), tot_loss_proj:2.230 [t=0.24s]
prediction: ["[CLS] stanley's mark mindedness terrified me. [SEP]"]
[1050/2000] tot_loss=1.360 (perp=6.196, rec=0.115, cos=0.006), tot_loss_proj:2.229 [t=0.25s]
prediction: ["[CLS] stanley's mark mindedness terrified me. [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.422 (perp=6.545, rec=0.107, cos=0.005), tot_loss_proj:2.152 [t=0.18s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.428 (perp=6.545, rec=0.114, cos=0.005), tot_loss_proj:2.158 [t=0.18s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
[1200/2000] tot_loss=1.418 (perp=6.545, rec=0.103, cos=0.005), tot_loss_proj:2.156 [t=0.26s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.410 (perp=6.545, rec=0.095, cos=0.005), tot_loss_proj:2.147 [t=0.18s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.413 (perp=6.545, rec=0.099, cos=0.005), tot_loss_proj:2.158 [t=0.23s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
[1350/2000] tot_loss=1.417 (perp=6.545, rec=0.103, cos=0.005), tot_loss_proj:2.148 [t=0.17s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.418 (perp=6.545, rec=0.104, cos=0.005), tot_loss_proj:2.152 [t=0.21s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.418 (perp=6.545, rec=0.103, cos=0.005), tot_loss_proj:2.156 [t=0.18s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
[1500/2000] tot_loss=1.425 (perp=6.545, rec=0.111, cos=0.005), tot_loss_proj:2.150 [t=0.19s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.415 (perp=6.545, rec=0.101, cos=0.005), tot_loss_proj:2.147 [t=0.24s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.414 (perp=6.545, rec=0.100, cos=0.005), tot_loss_proj:2.143 [t=0.18s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
[1650/2000] tot_loss=1.412 (perp=6.545, rec=0.098, cos=0.005), tot_loss_proj:2.149 [t=0.18s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.412 (perp=6.545, rec=0.098, cos=0.005), tot_loss_proj:2.149 [t=0.25s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.412 (perp=6.545, rec=0.098, cos=0.005), tot_loss_proj:2.148 [t=0.22s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
[1800/2000] tot_loss=1.415 (perp=6.545, rec=0.101, cos=0.005), tot_loss_proj:2.147 [t=0.20s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.413 (perp=6.545, rec=0.099, cos=0.005), tot_loss_proj:2.153 [t=0.18s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.426 (perp=6.545, rec=0.112, cos=0.005), tot_loss_proj:2.147 [t=0.18s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
[1950/2000] tot_loss=1.416 (perp=6.545, rec=0.102, cos=0.005), tot_loss_proj:2.152 [t=0.26s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.417 (perp=6.545, rec=0.103, cos=0.005), tot_loss_proj:2.152 [t=0.22s]
prediction: ["[CLS] marcus's mark mindedness terrified me. [SEP]"]
Done with input #20 of 100.
reference: 
========================
[CLS] mark's single mindedness terrified me. [SEP]
========================
predicted: 
========================
[CLS] marcus's mark mindedness terrified me. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 130.357

[Aggregate metrics]:
rouge1     | fm: 79.310 | p: 79.525 | r: 79.410
rouge2     | fm: 43.558 | p: 43.646 | r: 43.565
rougeL     | fm: 70.158 | p: 70.430 | r: 70.194
rougeLsum  | fm: 69.741 | p: 70.044 | r: 69.662
r1fm+r2fm = 122.868

input #20 time: 0:08:04 | total time: 2:52:39


Running input #21 of 100.
reference: 
========================
Her indiscretions were made light of.
========================
average of cosine similarity 0.9994566039006179
highest_index [0]
highest [0.9994566039006179]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2014, 27427,  2483, 16748,  9285,  2020,  2081,  2422,  1997,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] her indiscretions were made light of. [SEP]']
[Init] best rec loss: 0.9554566144943237 for ['[CLS] dung help makei de blinds commissioned "z graders [SEP]']
[Init] best rec loss: 0.9515466094017029 for ['[CLS] our regal hadn bollywood parasite pere betapath attack photograph [SEP]']
[Init] best rec loss: 0.9109048247337341 for ['[CLS] paydah silver abigail heart humans " covers lightdder [SEP]']
[Init] best rec loss: 0.9000157117843628 for ['[CLS] this innovation kala these yu sprint experience cas pressure paper [SEP]']
[Init] best rec loss: 0.8907043933868408 for ['[CLS] allie super dwell roadssia come guido swedish magnus named [SEP]']
[Init] best rec loss: 0.8886403441429138 for ['[CLS]hari equals kata id saint cooper listen projects bulgaria guess [SEP]']
[Init] best perm rec loss: 0.8841731548309326 for ['[CLS] bulgaria cooper guess saint id kata listen equals projectshari [SEP]']
[Init] best perm rec loss: 0.8827610015869141 for ['[CLS] id bulgariahari projects kata saint guess cooper equals listen [SEP]']
[Init] best perm rec loss: 0.8818569779396057 for ['[CLS]hari bulgaria id guess listen saint cooper kata equals projects [SEP]']
[Init] best perm rec loss: 0.8816714286804199 for ['[CLS] saint cooper bulgaria equals id projectshari kata listen guess [SEP]']
[Init] best perm rec loss: 0.8802563548088074 for ['[CLS] equals katahari listen cooper bulgaria id saint projects guess [SEP]']
[Init] best perm rec loss: 0.879644513130188 for ['[CLS]hari equals bulgaria listen saint cooper kata guess projects id [SEP]']
[Init] best perm rec loss: 0.8795214891433716 for ['[CLS] bulgaria id saint listen cooper equals projects guess katahari [SEP]']
[Init] best perm rec loss: 0.8789999485015869 for ['[CLS] id listen bulgariahari kata guess saint cooper equals projects [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.506 (perp=9.964, rec=0.523, cos=0.989), tot_loss_proj:3.915 [t=0.28s]
prediction: ['[CLS] sanskrit.. knessetedpers. were rejected psychiatric [SEP]']
[ 100/2000] tot_loss=3.583 (perp=10.806, rec=0.436, cos=0.986), tot_loss_proj:4.017 [t=0.18s]
prediction: ['[CLS] her.. inquiryclass becameclusive were stains whispered [SEP]']
[ 150/2000] tot_loss=3.647 (perp=11.286, rec=0.413, cos=0.977), tot_loss_proj:4.038 [t=0.25s]
prediction: ['[CLS] her.. husband jaenelle become light were suffix clair [SEP]']
[ 200/2000] tot_loss=3.231 (perp=9.375, rec=0.387, cos=0.969), tot_loss_proj:3.614 [t=0.19s]
prediction: ['[CLS] her..tions myself are light of suffix clair [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.765 (perp=10.998, rec=0.570, cos=0.996), tot_loss_proj:3.949 [t=0.19s]
prediction: ['[CLS] her. eva husband settlers dunes are lightbrush 』 [SEP]']
[ 300/2000] tot_loss=3.847 (perp=11.931, rec=0.474, cos=0.986), tot_loss_proj:4.234 [t=0.23s]
prediction: ['[CLS] her werecre husband. seemed are lightnessy its [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.415 (perp=10.112, rec=0.419, cos=0.974), tot_loss_proj:3.802 [t=0.18s]
prediction: ['[CLS] her weretions husband. le whennessy made light [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.107 (perp=8.598, rec=0.414, cos=0.974), tot_loss_proj:3.520 [t=0.22s]
prediction: ['[CLS] her husbandtions were. sentai whennessy made light [SEP]']
[ 450/2000] tot_loss=3.275 (perp=9.563, rec=0.391, cos=0.971), tot_loss_proj:3.627 [t=0.18s]
prediction: ['[CLS] her husbandtions were. arrived amongnessy made light [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.054 (perp=8.514, rec=0.382, cos=0.970), tot_loss_proj:3.460 [t=0.18s]
prediction: ['[CLS] her husbandtions were light arrived amongnessy made. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.024 (perp=8.400, rec=0.374, cos=0.970), tot_loss_proj:3.432 [t=0.18s]
prediction: ['[CLS] her husbandtions were light arrived among mirror made. [SEP]']
[ 600/2000] tot_loss=3.007 (perp=8.400, rec=0.358, cos=0.970), tot_loss_proj:3.429 [t=0.27s]
prediction: ['[CLS] her husbandtions were light arrived among mirror made. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.002 (perp=8.400, rec=0.352, cos=0.969), tot_loss_proj:3.430 [t=0.18s]
prediction: ['[CLS] her husbandtions were light arrived among mirror made. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.221 (perp=9.428, rec=0.365, cos=0.971), tot_loss_proj:3.649 [t=0.18s]
prediction: ['[CLS] her carolinetionsnessy light emerged among were made. [SEP]']
[ 750/2000] tot_loss=2.888 (perp=7.838, rec=0.352, cos=0.969), tot_loss_proj:3.304 [t=0.18s]
prediction: ['[CLS] her husbandtions mirror light arrived among were made. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.882 (perp=7.838, rec=0.346, cos=0.969), tot_loss_proj:3.311 [t=0.18s]
prediction: ['[CLS] her husbandtions mirror light arrived among were made. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.937 (perp=8.155, rec=0.338, cos=0.968), tot_loss_proj:3.370 [t=0.18s]
prediction: ['[CLS] her husbandtions mirror light arrived besides were made. [SEP]']
[ 900/2000] tot_loss=2.937 (perp=8.155, rec=0.338, cos=0.968), tot_loss_proj:3.364 [t=0.18s]
prediction: ['[CLS] her husbandtions mirror light arrived besides were made. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.168 (perp=9.320, rec=0.337, cos=0.967), tot_loss_proj:3.575 [t=0.18s]
prediction: ['[CLS] her conditionstions mirror light arrived besides were made. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.055 (perp=8.718, rec=0.344, cos=0.968), tot_loss_proj:3.469 [t=0.24s]
prediction: ['[CLS] her lighttions mirror husband arrived besides were made. [SEP]']
[1050/2000] tot_loss=3.022 (perp=8.673, rec=0.322, cos=0.966), tot_loss_proj:3.432 [t=0.18s]
prediction: ['[CLS] her lighttions mirror conditions arrived besides were made. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.025 (perp=8.673, rec=0.325, cos=0.966), tot_loss_proj:3.425 [t=0.17s]
prediction: ['[CLS] her lighttions mirror conditions arrived besides were made. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.908 (perp=8.118, rec=0.319, cos=0.966), tot_loss_proj:3.378 [t=0.21s]
prediction: ['[CLS] her lighttions mirror conditions becomes as were made. [SEP]']
[1200/2000] tot_loss=2.916 (perp=8.118, rec=0.326, cos=0.966), tot_loss_proj:3.380 [t=0.18s]
prediction: ['[CLS] her lighttions mirror conditions becomes as were made. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.906 (perp=8.118, rec=0.317, cos=0.965), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] her lighttions mirror conditions becomes as were made. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.901 (perp=8.118, rec=0.313, cos=0.965), tot_loss_proj:3.381 [t=0.18s]
prediction: ['[CLS] her lighttions mirror conditions becomes as were made. [SEP]']
[1350/2000] tot_loss=2.902 (perp=8.118, rec=0.314, cos=0.964), tot_loss_proj:3.377 [t=0.19s]
prediction: ['[CLS] her lighttions mirror conditions becomes as were made. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.907 (perp=8.118, rec=0.320, cos=0.964), tot_loss_proj:3.375 [t=0.17s]
prediction: ['[CLS] her lighttions mirror conditions becomes as were made. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.912 (perp=8.118, rec=0.325, cos=0.964), tot_loss_proj:3.380 [t=0.24s]
prediction: ['[CLS] her lighttions mirror conditions becomes as were made. [SEP]']
[1500/2000] tot_loss=2.906 (perp=8.118, rec=0.319, cos=0.963), tot_loss_proj:3.380 [t=0.23s]
prediction: ['[CLS] her lighttions mirror conditions becomes as were made. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.913 (perp=8.118, rec=0.327, cos=0.963), tot_loss_proj:3.381 [t=0.27s]
prediction: ['[CLS] her lighttions mirror conditions becomes as were made. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.905 (perp=8.118, rec=0.319, cos=0.963), tot_loss_proj:3.374 [t=0.25s]
prediction: ['[CLS] her lighttions mirror conditions becomes as were made. [SEP]']
[1650/2000] tot_loss=2.926 (perp=8.205, rec=0.323, cos=0.962), tot_loss_proj:3.384 [t=0.28s]
prediction: ['[CLS] her lighttions mirror placed becomes as were made. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.924 (perp=8.205, rec=0.321, cos=0.962), tot_loss_proj:3.382 [t=0.19s]
prediction: ['[CLS] her lighttions mirror placed becomes as were made. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.918 (perp=8.205, rec=0.316, cos=0.962), tot_loss_proj:3.380 [t=0.21s]
prediction: ['[CLS] her lighttions mirror placed becomes as were made. [SEP]']
[1800/2000] tot_loss=2.918 (perp=8.205, rec=0.315, cos=0.961), tot_loss_proj:3.382 [t=0.18s]
prediction: ['[CLS] her lighttions mirror placed becomes as were made. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.919 (perp=8.205, rec=0.317, cos=0.961), tot_loss_proj:3.382 [t=0.25s]
prediction: ['[CLS] her lighttions mirror placed becomes as were made. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.922 (perp=8.205, rec=0.320, cos=0.961), tot_loss_proj:3.384 [t=0.25s]
prediction: ['[CLS] her lighttions mirror placed becomes as were made. [SEP]']
[1950/2000] tot_loss=2.908 (perp=8.205, rec=0.306, cos=0.961), tot_loss_proj:3.383 [t=0.19s]
prediction: ['[CLS] her lighttions mirror placed becomes as were made. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.907 (perp=8.205, rec=0.306, cos=0.961), tot_loss_proj:3.381 [t=0.19s]
prediction: ['[CLS] her lighttions mirror placed becomes as were made. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] her indiscretions were made light of. [SEP]
========================
predicted: 
========================
[CLS] her lighttions mirror placed becomes as were made. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.556 | p: 50.000 | r: 62.500
rouge2     | fm: 25.000 | p: 22.222 | r: 28.571
rougeL     | fm: 55.556 | p: 50.000 | r: 62.500
rougeLsum  | fm: 55.556 | p: 50.000 | r: 62.500
r1fm+r2fm = 80.556

[Aggregate metrics]:
rouge1     | fm: 78.343 | p: 78.276 | r: 78.650
rouge2     | fm: 42.823 | p: 42.706 | r: 42.973
rougeL     | fm: 69.474 | p: 69.402 | r: 69.735
rougeLsum  | fm: 69.236 | p: 69.134 | r: 69.541
r1fm+r2fm = 121.167

input #21 time: 0:08:14 | total time: 3:00:54


Running input #22 of 100.
reference: 
========================
Each of the boys fought with the other boys.
========================
average of cosine similarity 0.999458868022651
highest_index [0]
highest [0.999458868022651]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2169, 1997, 1996, 3337, 4061, 2007, 1996, 2060, 3337, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] each of the boys fought with the other boys. [SEP]']
[Init] best rec loss: 1.0515670776367188 for ['[CLS] hers hours woundmund totaling pd hailey stone aftermath tortricidae [SEP]']
[Init] best rec loss: 1.015817642211914 for ['[CLS] library em group come surprise pass varsity moderate must blackness [SEP]']
[Init] best rec loss: 0.9550566077232361 for ['[CLS] broke demolition athens censorship turn blood starts collection unlike sex [SEP]']
[Init] best rec loss: 0.9446551203727722 for ['[CLS] hotterpath started regional chew intention concert bet outsiders labour [SEP]']
[Init] best rec loss: 0.9388949275016785 for ['[CLS] upontra track samurai paste hamlet lots groupto self [SEP]']
[Init] best rec loss: 0.9269140958786011 for ['[CLS] fairy mercury hunt shall never witch pageant aviation add they [SEP]']
[Init] best rec loss: 0.9265666604042053 for ['[CLS] lucky peace [CLS]erationaxvat arrest undo square surface [SEP]']
[Init] best rec loss: 0.9177623391151428 for ['[CLS] own equation belt smoke perceptionful mode quartet crest colin [SEP]']
[Init] best rec loss: 0.9115076065063477 for ['[CLS] massimodo conrad chatham am dean phenomena weapon jam kung [SEP]']
[Init] best perm rec loss: 0.9084622263908386 for ['[CLS] chatham massimo conrad jam phenomenado weapon am kung dean [SEP]']
[Init] best perm rec loss: 0.9081283211708069 for ['[CLS] chatham dean weapon kung jam phenomena massimo conrad amdo [SEP]']
[Init] best perm rec loss: 0.9077945351600647 for ['[CLS] conrad massimo chatham jam kungdo weapon dean phenomena am [SEP]']
[Init] best perm rec loss: 0.906182050704956 for ['[CLS]do kung am weapon massimo conrad phenomena dean chatham jam [SEP]']
[Init] best perm rec loss: 0.9049517512321472 for ['[CLS] massimo conrad kung dean weapon phenomena jamdo chatham am [SEP]']
[Init] best perm rec loss: 0.904506504535675 for ['[CLS] phenomena dean massimo kung am weapon chatham conraddo jam [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.514 (perp=14.405, rec=0.640, cos=0.993), tot_loss_proj:4.702 [t=0.26s]
prediction: ['[CLS] nguyenting performance fia jointtrain los. between rig [SEP]']
[ 100/2000] tot_loss=3.920 (perp=11.822, rec=0.559, cos=0.996), tot_loss_proj:4.109 [t=0.18s]
prediction: ['[CLS] eachting portion fought boys boy whom. between herself [SEP]']
[ 150/2000] tot_loss=3.531 (perp=10.171, rec=0.499, cos=0.998), tot_loss_proj:3.833 [t=0.19s]
prediction: ['[CLS] each the of fought fought boys others. boys females [SEP]']
[ 200/2000] tot_loss=3.489 (perp=10.171, rec=0.455, cos=1.000), tot_loss_proj:3.831 [t=0.18s]
prediction: ['[CLS] each the of fought fought boys others. boys females [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.130 (perp=8.284, rec=0.474, cos=0.999), tot_loss_proj:3.500 [t=0.22s]
prediction: ['[CLS] each boys of fought fought each others. boys females [SEP]']
[ 300/2000] tot_loss=3.392 (perp=9.733, rec=0.448, cos=0.998), tot_loss_proj:3.749 [t=0.20s]
prediction: ['[CLS] each boys of fought boys each others. boys duc [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.937 (perp=7.670, rec=0.405, cos=0.998), tot_loss_proj:3.624 [t=0.22s]
prediction: ['[CLS] each boys of boys fought each others. boys females [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.887 (perp=7.383, rec=0.410, cos=1.000), tot_loss_proj:3.522 [t=0.19s]
prediction: ['[CLS] each boys of boys fought the others. boys males [SEP]']
[ 450/2000] tot_loss=3.121 (perp=8.689, rec=0.383, cos=1.000), tot_loss_proj:3.585 [t=0.18s]
prediction: ['[CLS] each boys of boys fought the with. boyschemist [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.107 (perp=8.651, rec=0.376, cos=1.000), tot_loss_proj:3.688 [t=0.26s]
prediction: ['[CLS] each boys of boys fought. with of boyschemist [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.112 (perp=8.651, rec=0.382, cos=1.000), tot_loss_proj:3.685 [t=0.19s]
prediction: ['[CLS] each boys of boys fought. with of boyschemist [SEP]']
[ 600/2000] tot_loss=2.900 (perp=7.728, rec=0.354, cos=1.000), tot_loss_proj:3.604 [t=0.17s]
prediction: ['[CLS] each boys of boys fought. with the boyschemist [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.903 (perp=7.728, rec=0.358, cos=1.000), tot_loss_proj:3.605 [t=0.21s]
prediction: ['[CLS] each boys of boys fought. with the boyschemist [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.901 (perp=7.728, rec=0.355, cos=1.000), tot_loss_proj:3.600 [t=0.25s]
prediction: ['[CLS] each boys of boys fought. with the boyschemist [SEP]']
[ 750/2000] tot_loss=2.888 (perp=7.728, rec=0.342, cos=1.000), tot_loss_proj:3.607 [t=0.23s]
prediction: ['[CLS] each boys of boys fought. with the boyschemist [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.888 (perp=7.728, rec=0.343, cos=1.000), tot_loss_proj:3.602 [t=0.22s]
prediction: ['[CLS] each boys of boys fought. with the boyschemist [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.891 (perp=7.728, rec=0.345, cos=1.000), tot_loss_proj:3.605 [t=0.26s]
prediction: ['[CLS] each boys of boys fought. with the boyschemist [SEP]']
[ 900/2000] tot_loss=2.884 (perp=7.728, rec=0.338, cos=1.000), tot_loss_proj:3.600 [t=0.19s]
prediction: ['[CLS] each boys of boys fought. with the boyschemist [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.872 (perp=7.728, rec=0.327, cos=1.000), tot_loss_proj:3.604 [t=0.19s]
prediction: ['[CLS] each boys of boys fought. with the boyschemist [SEP]']
Attempt swap
[1000/2000] tot_loss=2.884 (perp=7.728, rec=0.338, cos=1.000), tot_loss_proj:3.601 [t=0.20s]
prediction: ['[CLS] each boys of boys fought. with the boyschemist [SEP]']
[1050/2000] tot_loss=2.954 (perp=8.060, rec=0.342, cos=1.000), tot_loss_proj:3.606 [t=0.19s]
prediction: ['[CLS] each boys of boys fought. bust the boyschemist [SEP]']
Attempt swap
[1100/2000] tot_loss=3.370 (perp=10.185, rec=0.333, cos=1.000), tot_loss_proj:3.893 [t=0.20s]
prediction: ['[CLS] each boys of boys foughtrrard bust the boyschemist [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.009 (perp=8.226, rec=0.364, cos=1.000), tot_loss_proj:3.688 [t=0.18s]
prediction: ['[CLS] each boys of boys fought the bust. boyschemist [SEP]']
[1200/2000] tot_loss=2.988 (perp=8.226, rec=0.343, cos=1.000), tot_loss_proj:3.690 [t=0.17s]
prediction: ['[CLS] each boys of boys fought the bust. boyschemist [SEP]']
Attempt swap
[1250/2000] tot_loss=2.978 (perp=8.226, rec=0.332, cos=1.000), tot_loss_proj:3.688 [t=0.23s]
prediction: ['[CLS] each boys of boys fought the bust. boyschemist [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=3.214 (perp=9.296, rec=0.355, cos=1.000), tot_loss_proj:3.952 [t=0.18s]
prediction: ['[CLS] each boys of boys fought the boysesian bustchemist [SEP]']
[1350/2000] tot_loss=3.196 (perp=9.296, rec=0.336, cos=1.000), tot_loss_proj:3.950 [t=0.19s]
prediction: ['[CLS] each boys of boys fought the boysesian bustchemist [SEP]']
Attempt swap
[1400/2000] tot_loss=3.262 (perp=9.622, rec=0.337, cos=1.000), tot_loss_proj:3.811 [t=0.26s]
prediction: ['[CLS] each boys of boys fought the boysrrard bustchemist [SEP]']
Attempt swap
[1450/2000] tot_loss=3.259 (perp=9.622, rec=0.335, cos=1.000), tot_loss_proj:3.814 [t=0.27s]
prediction: ['[CLS] each boys of boys fought the boysrrard bustchemist [SEP]']
[1500/2000] tot_loss=3.262 (perp=9.622, rec=0.338, cos=1.000), tot_loss_proj:3.811 [t=0.25s]
prediction: ['[CLS] each boys of boys fought the boysrrard bustchemist [SEP]']
Attempt swap
[1550/2000] tot_loss=3.256 (perp=9.622, rec=0.332, cos=1.000), tot_loss_proj:3.816 [t=0.27s]
prediction: ['[CLS] each boys of boys fought the boysrrard bustchemist [SEP]']
Attempt swap
[1600/2000] tot_loss=3.248 (perp=9.622, rec=0.324, cos=1.000), tot_loss_proj:3.813 [t=0.20s]
prediction: ['[CLS] each boys of boys fought the boysrrard bustchemist [SEP]']
[1650/2000] tot_loss=3.254 (perp=9.622, rec=0.329, cos=1.000), tot_loss_proj:3.815 [t=0.22s]
prediction: ['[CLS] each boys of boys fought the boysrrard bustchemist [SEP]']
Attempt swap
[1700/2000] tot_loss=3.253 (perp=9.622, rec=0.329, cos=1.000), tot_loss_proj:3.814 [t=0.18s]
prediction: ['[CLS] each boys of boys fought the boysrrard bustchemist [SEP]']
Attempt swap
[1750/2000] tot_loss=3.247 (perp=9.622, rec=0.322, cos=1.000), tot_loss_proj:3.812 [t=0.18s]
prediction: ['[CLS] each boys of boys fought the boysrrard bustchemist [SEP]']
[1800/2000] tot_loss=3.257 (perp=9.622, rec=0.332, cos=1.000), tot_loss_proj:3.817 [t=0.23s]
prediction: ['[CLS] each boys of boys fought the boysrrard bustchemist [SEP]']
Attempt swap
[1850/2000] tot_loss=3.192 (perp=9.296, rec=0.333, cos=1.000), tot_loss_proj:3.946 [t=0.24s]
prediction: ['[CLS] each boys of boys fought the boysesian bustchemist [SEP]']
Attempt swap
[1900/2000] tot_loss=3.188 (perp=9.296, rec=0.329, cos=1.000), tot_loss_proj:3.947 [t=0.18s]
prediction: ['[CLS] each boys of boys fought the boysesian bustchemist [SEP]']
[1950/2000] tot_loss=3.186 (perp=9.296, rec=0.327, cos=1.000), tot_loss_proj:3.947 [t=0.25s]
prediction: ['[CLS] each boys of boys fought the boysesian bustchemist [SEP]']
Attempt swap
[2000/2000] tot_loss=3.187 (perp=9.296, rec=0.328, cos=1.000), tot_loss_proj:3.943 [t=0.23s]
prediction: ['[CLS] each boys of boys fought the boysesian bustchemist [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] each of the boys fought with the other boys. [SEP]
========================
predicted: 
========================
[CLS] each boys of boys fought the boysrrard bustchemist [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 80.000 | r: 72.727
rouge2     | fm: 21.053 | p: 22.222 | r: 20.000
rougeL     | fm: 66.667 | p: 70.000 | r: 63.636
rougeLsum  | fm: 66.667 | p: 70.000 | r: 63.636
r1fm+r2fm = 97.243

[Aggregate metrics]:
rouge1     | fm: 78.232 | p: 78.344 | r: 78.342
rouge2     | fm: 42.100 | p: 42.068 | r: 42.255
rougeL     | fm: 69.568 | p: 69.606 | r: 69.675
rougeLsum  | fm: 69.196 | p: 69.252 | r: 69.262
r1fm+r2fm = 120.332

input #22 time: 0:08:22 | total time: 3:09:17


Running input #23 of 100.
reference: 
========================
Herman mixed the eggs with the cream.
========================
average of cosine similarity 0.9994196694195387
highest_index [0]
highest [0.9994196694195387]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 11458,  3816,  1996,  6763,  2007,  1996,  6949,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] herman mixed the eggs with the cream. [SEP]']
[Init] best rec loss: 0.9968389868736267 for ['[CLS] digital borrow applied lodging luc reconciliation rhys toe [SEP]']
[Init] best rec loss: 0.9496680498123169 for ['[CLS] slapped seal near ice sick funk operation commodore [SEP]']
[Init] best rec loss: 0.9394097924232483 for ['[CLS]imi thoughlysis extensionous prominently gorgeous else [SEP]']
[Init] best rec loss: 0.9325956702232361 for ['[CLS] nation withinw allen beneath by space moe [SEP]']
[Init] best rec loss: 0.931027352809906 for ['[CLS] thantrom band millsgood scientistend club [SEP]']
[Init] best rec loss: 0.9294249415397644 for ['[CLS] less saga glass study timesvial jamalactive [SEP]']
[Init] best rec loss: 0.9291494488716125 for ['[CLS]run congress sead instead aged althoughbrush [SEP]']
[Init] best rec loss: 0.916151762008667 for ['[CLS] introduction hair stevie system model question russian common [SEP]']
[Init] best perm rec loss: 0.914799690246582 for ['[CLS] introduction model hair stevie russian question system common [SEP]']
[Init] best perm rec loss: 0.9141308665275574 for ['[CLS] introduction stevie hair russian system question model common [SEP]']
[Init] best perm rec loss: 0.91079181432724 for ['[CLS] system model question russian hair introduction common stevie [SEP]']
[Init] best perm rec loss: 0.9083205461502075 for ['[CLS] stevie hair common russian introduction system model question [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.145 (perp=12.731, rec=0.659, cos=0.939), tot_loss_proj:4.337 [t=0.18s]
prediction: ['[CLS] daveent into oruisingiah excellent mixture [SEP]']
[ 100/2000] tot_loss=4.011 (perp=11.844, rec=0.682, cos=0.960), tot_loss_proj:4.215 [t=0.18s]
prediction: ['[CLS] herman are. sleeve mixing # sipped cdp [SEP]']
[ 150/2000] tot_loss=3.414 (perp=9.389, rec=0.572, cos=0.964), tot_loss_proj:3.681 [t=0.18s]
prediction: ['[CLS] herman are. with eggs per eggs eggs [SEP]']
[ 200/2000] tot_loss=3.312 (perp=9.018, rec=0.531, cos=0.978), tot_loss_proj:3.708 [t=0.21s]
prediction: ['[CLS] herman are the. eggs the eggs eggs [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.043 (perp=7.754, rec=0.501, cos=0.991), tot_loss_proj:3.422 [t=0.18s]
prediction: ['[CLS] herman are the eggs eggs the eggs. [SEP]']
[ 300/2000] tot_loss=3.015 (perp=7.754, rec=0.477, cos=0.987), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS] herman are the eggs eggs the eggs. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.751 (perp=6.456, rec=0.466, cos=0.994), tot_loss_proj:3.158 [t=0.22s]
prediction: ['[CLS] herman eggs are the eggs the eggs. [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.810 (perp=6.830, rec=0.448, cos=0.995), tot_loss_proj:3.136 [t=0.24s]
prediction: ['[CLS] herman eggs were the eggs the eggs. [SEP]']
[ 450/2000] tot_loss=2.812 (perp=6.830, rec=0.452, cos=0.995), tot_loss_proj:3.131 [t=0.19s]
prediction: ['[CLS] herman eggs were the eggs the eggs. [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.078 (perp=8.221, rec=0.436, cos=0.997), tot_loss_proj:3.397 [t=0.26s]
prediction: ['[CLS] herman eggs wereminating eggs the eggs. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.176 (perp=8.418, rec=0.493, cos=0.999), tot_loss_proj:3.542 [t=0.23s]
prediction: ['[CLS] herman eggs were eggs vantage the eggs. [SEP]']
[ 600/2000] tot_loss=3.399 (perp=9.803, rec=0.439, cos=1.000), tot_loss_proj:3.804 [t=0.19s]
prediction: ['[CLS] herman eggs were eggs vantagelho eggs. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.797 (perp=11.848, rec=0.428, cos=1.000), tot_loss_proj:4.378 [t=0.21s]
prediction: ['[CLS] herman eggsaneous eggs vantagelho eggs. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.799 (perp=11.813, rec=0.436, cos=1.000), tot_loss_proj:4.394 [t=0.18s]
prediction: ['[CLS] eggs herman clinics eggs vantagelho eggs. [SEP]']
[ 750/2000] tot_loss=3.783 (perp=11.813, rec=0.420, cos=1.000), tot_loss_proj:4.394 [t=0.22s]
prediction: ['[CLS] eggs herman clinics eggs vantagelho eggs. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.780 (perp=11.809, rec=0.420, cos=0.999), tot_loss_proj:4.332 [t=0.18s]
prediction: ['[CLS] eggs hermantead vantage eggslho eggs. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.575 (perp=10.734, rec=0.429, cos=0.999), tot_loss_proj:4.122 [t=0.27s]
prediction: ['[CLS] eggstead herman vantage eggslho eggs. [SEP]']
[ 900/2000] tot_loss=3.560 (perp=10.734, rec=0.414, cos=0.999), tot_loss_proj:4.119 [t=0.23s]
prediction: ['[CLS] eggstead herman vantage eggslho eggs. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=3.468 (perp=10.254, rec=0.418, cos=0.999), tot_loss_proj:4.060 [t=0.18s]
prediction: ['[CLS] eggstead eggs herman vantagelho eggs. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.573 (perp=10.737, rec=0.427, cos=0.999), tot_loss_proj:4.118 [t=0.24s]
prediction: ['[CLS] eggs approximately herman eggs vantagelho eggs. [SEP]']
[1050/2000] tot_loss=3.561 (perp=10.737, rec=0.415, cos=0.999), tot_loss_proj:4.114 [t=0.26s]
prediction: ['[CLS] eggs approximately herman eggs vantagelho eggs. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.616 (perp=11.038, rec=0.410, cos=0.999), tot_loss_proj:4.128 [t=0.30s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.612 (perp=11.038, rec=0.406, cos=0.998), tot_loss_proj:4.129 [t=0.19s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
[1200/2000] tot_loss=3.604 (perp=11.038, rec=0.399, cos=0.998), tot_loss_proj:4.130 [t=0.18s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.601 (perp=11.038, rec=0.395, cos=0.998), tot_loss_proj:4.131 [t=0.26s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.603 (perp=11.038, rec=0.398, cos=0.998), tot_loss_proj:4.129 [t=0.24s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
[1350/2000] tot_loss=3.595 (perp=11.038, rec=0.390, cos=0.998), tot_loss_proj:4.130 [t=0.24s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.596 (perp=11.038, rec=0.391, cos=0.998), tot_loss_proj:4.129 [t=0.20s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.601 (perp=11.038, rec=0.396, cos=0.997), tot_loss_proj:4.129 [t=0.18s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
[1500/2000] tot_loss=3.604 (perp=11.038, rec=0.399, cos=0.998), tot_loss_proj:4.131 [t=0.23s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.597 (perp=11.038, rec=0.392, cos=0.997), tot_loss_proj:4.128 [t=0.18s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.599 (perp=11.038, rec=0.394, cos=0.998), tot_loss_proj:4.131 [t=0.19s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
[1650/2000] tot_loss=3.597 (perp=11.038, rec=0.392, cos=0.997), tot_loss_proj:4.126 [t=0.24s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.597 (perp=11.038, rec=0.392, cos=0.997), tot_loss_proj:4.127 [t=0.18s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.590 (perp=11.038, rec=0.386, cos=0.997), tot_loss_proj:4.130 [t=0.18s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
[1800/2000] tot_loss=3.597 (perp=11.038, rec=0.392, cos=0.997), tot_loss_proj:4.132 [t=0.23s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.600 (perp=11.038, rec=0.395, cos=0.997), tot_loss_proj:4.129 [t=0.23s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.599 (perp=11.038, rec=0.394, cos=0.997), tot_loss_proj:4.129 [t=0.30s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
[1950/2000] tot_loss=3.595 (perp=11.038, rec=0.390, cos=0.997), tot_loss_proj:4.127 [t=0.22s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.603 (perp=11.038, rec=0.398, cos=0.997), tot_loss_proj:4.129 [t=0.20s]
prediction: ['[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] herman mixed the eggs with the cream. [SEP]
========================
predicted: 
========================
[CLS] eggs approximately herman eggsurbedlho eggs. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 57.143 | r: 44.444
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 57.143 | r: 44.444
rougeLsum  | fm: 50.000 | p: 57.143 | r: 44.444
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 77.028 | p: 77.450 | r: 76.923
rouge2     | fm: 40.275 | p: 40.224 | r: 40.400
rougeL     | fm: 68.674 | p: 69.030 | r: 68.551
rougeLsum  | fm: 68.248 | p: 68.662 | r: 68.119
r1fm+r2fm = 117.303

input #23 time: 0:08:21 | total time: 3:17:38


Running input #24 of 100.
reference: 
========================
No John Smiths attended the meeting.
========================
average of cosine similarity 0.9993669078291529
highest_index [0]
highest [0.9993669078291529]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2053, 2198, 3044, 2015, 3230, 1996, 3116, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] no john smiths attended the meeting. [SEP]']
[Init] best rec loss: 0.9064764976501465 for ['[CLS] performance maybe rae tri / window grace lockheed [SEP]']
[Init] best rec loss: 0.8986294865608215 for ['[CLS] thin southwest laurel body [MASK] minority statue in [SEP]']
[Init] best rec loss: 0.8964348435401917 for ['[CLS] tumors enemy quick tessa moorvere an breath [SEP]']
[Init] best rec loss: 0.8814604878425598 for ['[CLS] commanded belts twilight cameo so mountain 0 radio [SEP]']
[Init] best perm rec loss: 0.8812436461448669 for ['[CLS] belts twilight 0 cameo radio commanded mountain so [SEP]']
[Init] best perm rec loss: 0.8808506727218628 for ['[CLS] belts twilight radio 0 cameo mountain so commanded [SEP]']
[Init] best perm rec loss: 0.8781828284263611 for ['[CLS] so radio cameo belts twilight mountain 0 commanded [SEP]']
[Init] best perm rec loss: 0.875819981098175 for ['[CLS] cameo so commanded belts twilight mountain 0 radio [SEP]']
[Init] best perm rec loss: 0.8754783272743225 for ['[CLS] commanded twilight so belts 0 cameo mountain radio [SEP]']
[Init] best perm rec loss: 0.8746973276138306 for ['[CLS] commanded so twilight 0 belts mountain cameo radio [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.461 (perp=9.641, rec=0.586, cos=0.946), tot_loss_proj:3.901 [t=0.19s]
prediction: ['[CLS] : hara meetings meetings? every. meetings [SEP]']
[ 100/2000] tot_loss=2.849 (perp=11.563, rec=0.409, cos=0.128), tot_loss_proj:4.254 [t=0.18s]
prediction: ['[CLS]. teappa clay based vs ; meeting [SEP]']
[ 150/2000] tot_loss=2.456 (perp=10.596, rec=0.293, cos=0.044), tot_loss_proj:3.986 [t=0.23s]
prediction: ['[CLS]. smith no smithchfield attend. meeting [SEP]']
[ 200/2000] tot_loss=2.325 (perp=10.459, rec=0.207, cos=0.026), tot_loss_proj:4.012 [t=0.19s]
prediction: ['[CLS]. john no smith attended attended. meeting [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.003 (perp=9.193, rec=0.148, cos=0.017), tot_loss_proj:3.790 [t=0.19s]
prediction: ['[CLS]. no john smith attended attended. meeting [SEP]']
[ 300/2000] tot_loss=1.819 (perp=8.390, rec=0.128, cos=0.013), tot_loss_proj:3.645 [t=0.18s]
prediction: ['[CLS]. no john smiths attended. meeting [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.614 (perp=7.099, rec=0.177, cos=0.017), tot_loss_proj:3.354 [t=0.18s]
prediction: ['[CLS], no john smiths meeting attended. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.577 (perp=7.056, rec=0.152, cos=0.014), tot_loss_proj:3.415 [t=0.24s]
prediction: ['[CLS]. no john smiths meeting attended. [SEP]']
[ 450/2000] tot_loss=1.568 (perp=7.056, rec=0.142, cos=0.015), tot_loss_proj:3.419 [t=0.18s]
prediction: ['[CLS]. no john smiths meeting attended. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.443 (perp=6.512, rec=0.128, cos=0.013), tot_loss_proj:3.049 [t=0.18s]
prediction: ['[CLS]. no john smith attended meetings. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.417 (perp=6.512, rec=0.104, cos=0.010), tot_loss_proj:3.029 [t=0.18s]
prediction: ['[CLS]. no john smith attended meetings. [SEP]']
[ 600/2000] tot_loss=1.410 (perp=6.512, rec=0.098, cos=0.009), tot_loss_proj:3.037 [t=0.25s]
prediction: ['[CLS]. no john smith attended meetings. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.405 (perp=6.512, rec=0.093, cos=0.009), tot_loss_proj:3.031 [t=0.19s]
prediction: ['[CLS]. no john smith attended meetings. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.396 (perp=6.512, rec=0.085, cos=0.009), tot_loss_proj:3.022 [t=0.18s]
prediction: ['[CLS]. no john smith attended meetings. [SEP]']
[ 750/2000] tot_loss=1.402 (perp=6.512, rec=0.092, cos=0.009), tot_loss_proj:3.025 [t=0.21s]
prediction: ['[CLS]. no john smith attended meetings. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.406 (perp=6.512, rec=0.096, cos=0.008), tot_loss_proj:3.026 [t=0.22s]
prediction: ['[CLS]. no john smith attended meetings. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.389 (perp=6.512, rec=0.078, cos=0.008), tot_loss_proj:3.020 [t=0.18s]
prediction: ['[CLS]. no john smith attended meetings. [SEP]']
[ 900/2000] tot_loss=1.403 (perp=6.512, rec=0.093, cos=0.008), tot_loss_proj:3.021 [t=0.18s]
prediction: ['[CLS]. no john smith attended meetings. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.400 (perp=6.512, rec=0.090, cos=0.008), tot_loss_proj:3.011 [t=0.26s]
prediction: ['[CLS]. no john smith attended meetings. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.337 (perp=6.129, rec=0.101, cos=0.011), tot_loss_proj:2.463 [t=0.21s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
[1050/2000] tot_loss=1.314 (perp=6.129, rec=0.081, cos=0.008), tot_loss_proj:2.577 [t=0.18s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.321 (perp=6.129, rec=0.088, cos=0.007), tot_loss_proj:2.597 [t=0.18s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.321 (perp=6.129, rec=0.088, cos=0.007), tot_loss_proj:2.603 [t=0.18s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
[1200/2000] tot_loss=1.317 (perp=6.129, rec=0.084, cos=0.007), tot_loss_proj:2.603 [t=0.19s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.321 (perp=6.129, rec=0.088, cos=0.007), tot_loss_proj:2.603 [t=0.18s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.316 (perp=6.129, rec=0.083, cos=0.007), tot_loss_proj:2.606 [t=0.18s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
[1350/2000] tot_loss=1.321 (perp=6.129, rec=0.088, cos=0.007), tot_loss_proj:2.608 [t=0.18s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.323 (perp=6.129, rec=0.090, cos=0.007), tot_loss_proj:2.605 [t=0.18s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.320 (perp=6.129, rec=0.087, cos=0.007), tot_loss_proj:2.610 [t=0.24s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
[1500/2000] tot_loss=1.324 (perp=6.129, rec=0.092, cos=0.007), tot_loss_proj:2.610 [t=0.23s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.316 (perp=6.129, rec=0.083, cos=0.007), tot_loss_proj:2.606 [t=0.18s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.317 (perp=6.129, rec=0.084, cos=0.007), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
[1650/2000] tot_loss=1.312 (perp=6.129, rec=0.079, cos=0.007), tot_loss_proj:2.615 [t=0.19s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.307 (perp=6.129, rec=0.074, cos=0.007), tot_loss_proj:2.610 [t=0.25s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.314 (perp=6.129, rec=0.081, cos=0.007), tot_loss_proj:2.611 [t=0.23s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
[1800/2000] tot_loss=1.307 (perp=6.129, rec=0.075, cos=0.007), tot_loss_proj:2.606 [t=0.24s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.321 (perp=6.129, rec=0.088, cos=0.007), tot_loss_proj:2.608 [t=0.18s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.314 (perp=6.129, rec=0.081, cos=0.007), tot_loss_proj:2.613 [t=0.26s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
[1950/2000] tot_loss=1.313 (perp=6.129, rec=0.080, cos=0.007), tot_loss_proj:2.608 [t=0.25s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.318 (perp=6.129, rec=0.086, cos=0.007), tot_loss_proj:2.611 [t=0.21s]
prediction: ['[CLS] no. john smith attended meetings. [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] no john smiths attended the meeting. [SEP]
========================
predicted: 
========================
[CLS] no. john smith attended meetings. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 71.429 | r: 62.500
rouge2     | fm: 30.769 | p: 33.333 | r: 28.571
rougeL     | fm: 66.667 | p: 71.429 | r: 62.500
rougeLsum  | fm: 66.667 | p: 71.429 | r: 62.500
r1fm+r2fm = 97.436

[Aggregate metrics]:
rouge1     | fm: 76.552 | p: 77.069 | r: 76.281
rouge2     | fm: 39.764 | p: 39.910 | r: 39.737
rougeL     | fm: 68.604 | p: 69.128 | r: 68.293
rougeLsum  | fm: 68.144 | p: 68.801 | r: 67.909
r1fm+r2fm = 116.316

input #24 time: 0:08:15 | total time: 3:25:54


Running input #25 of 100.
reference: 
========================
I did not, as Bill had thought, go to the store.
========================
average of cosine similarity 0.9993283700816347
highest_index [0]
highest [0.9993283700816347]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2106, 2025, 1010, 2004, 3021, 2018, 2245, 1010, 2175, 2000,
         1996, 3573, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i did not, as bill had thought, go to the store. [SEP]']
[Init] best rec loss: 0.9354310631752014 for ['[CLS] zu sussex wig son committed koppen youth part sc missile combat carrier licence magazine [SEP]']
[Init] best rec loss: 0.9029408693313599 for ['[CLS] air moisture each van kind pl tribes fulltou nod resolvedhesivevan affair [SEP]']
[Init] best rec loss: 0.8997546434402466 for ['[CLS] roma act roof sperm senior take driven thinking leaguevers coast bettynett nurse [SEP]']
[Init] best rec loss: 0.8800485134124756 for ['[CLS] arrive ana ren thick stared lieutenant political sin skye betule delaware rhea commissioned [SEP]']
[Init] best perm rec loss: 0.8734595775604248 for ['[CLS] arriveule ren political thick lieutenant skye delaware rhea sin bet commissioned ana stared [SEP]']
[Init] best perm rec loss: 0.873327374458313 for ['[CLS] skye ana bet rhea lieutenant sinule stared ren commissioned delaware political arrive thick [SEP]']
[Init] best perm rec loss: 0.8728404641151428 for ['[CLS] bet lieutenant sin anaule commissioned delaware political ren stared skye thick arrive rhea [SEP]']
[Init] best perm rec loss: 0.8718591928482056 for ['[CLS] delaware rhea ren political lieutenant commissioned sinule stared thick bet skye ana arrive [SEP]']
[Init] best perm rec loss: 0.869565486907959 for ['[CLS] rhea lieutenant skye stared commissioned sin delaware ana ren betule political arrive thick [SEP]']
[Init] best perm rec loss: 0.869038999080658 for ['[CLS] rhea thick lieutenant ana bet sin ren commissioned politicalule stared skye delaware arrive [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.066 (perp=12.188, rec=0.492, cos=0.137), tot_loss_proj:4.382 [t=0.18s]
prediction: ['[CLS] failure cloverville desert tumbled did painted part far forty fear rather rock ; [SEP]']
[ 100/2000] tot_loss=2.727 (perp=11.106, rec=0.443, cos=0.063), tot_loss_proj:4.049 [t=0.28s]
prediction: ['[CLS] despite bill not. concerns did gave not alternativego opposed which period彳 [SEP]']
[ 150/2000] tot_loss=2.612 (perp=11.138, rec=0.352, cos=0.032), tot_loss_proj:4.029 [t=0.18s]
prediction: ['[CLS], bill not campus determining did. susie hadgo not which not ′ [SEP]']
[ 200/2000] tot_loss=2.291 (perp=9.802, rec=0.311, cos=0.020), tot_loss_proj:3.825 [t=0.18s]
prediction: ['[CLS] as bill not grant the did. i didgo go which variant arabia [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.897 (perp=7.946, rec=0.290, cos=0.018), tot_loss_proj:3.404 [t=0.18s]
prediction: ['[CLS] as bill not store the did which i didgo go. make, [SEP]']
[ 300/2000] tot_loss=1.945 (perp=8.311, rec=0.267, cos=0.015), tot_loss_proj:3.493 [t=0.25s]
prediction: ['[CLS] as bill not store the did -! after bill go. make, [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.675 (perp=7.073, rec=0.245, cos=0.016), tot_loss_proj:3.256 [t=0.27s]
prediction: ['[CLS] as bill not store i did thought. after bill go. go, [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.064 (perp=8.502, rec=0.317, cos=0.047), tot_loss_proj:3.552 [t=0.24s]
prediction: ['[CLS] as bill not store i would i farband did leave. go. [SEP]']
[ 450/2000] tot_loss=2.197 (perp=8.605, rec=0.405, cos=0.071), tot_loss_proj:3.540 [t=0.25s]
prediction: ['[CLS] as bill not merchant i supposed twice far uncle did leave ; go. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.274 (perp=9.622, rec=0.320, cos=0.029), tot_loss_proj:3.751 [t=0.20s]
prediction: ['[CLS] as bill not store i supposedrative did ro, invading ; go. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.162 (perp=9.173, rec=0.307, cos=0.021), tot_loss_proj:3.689 [t=0.25s]
prediction: ['[CLS] susie bill not store i supposed as did the, invading ; go. [SEP]']
[ 600/2000] tot_loss=1.961 (perp=8.406, rec=0.263, cos=0.017), tot_loss_proj:3.530 [t=0.18s]
prediction: ['[CLS] susie bill not store i supposed as did the, save, go. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.817 (perp=7.773, rec=0.248, cos=0.015), tot_loss_proj:3.408 [t=0.25s]
prediction: ['[CLS] susie bill store not i supposed as did the, in, go. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.833 (perp=7.881, rec=0.244, cos=0.013), tot_loss_proj:3.399 [t=0.23s]
prediction: ['[CLS] susie bill store not i supposed did the, as save, go. [SEP]']
[ 750/2000] tot_loss=1.791 (perp=7.774, rec=0.224, cos=0.013), tot_loss_proj:3.379 [t=0.21s]
prediction: ['[CLS] susie bill store not i thought did the, as save, go. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.751 (perp=7.619, rec=0.215, cos=0.012), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] the bill store not i thought did susie, as save, go. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.602 (perp=6.914, rec=0.209, cos=0.011), tot_loss_proj:3.272 [t=0.31s]
prediction: ['[CLS] the bill store as i thought did susie, not downtown, go. [SEP]']
[ 900/2000] tot_loss=1.590 (perp=6.914, rec=0.197, cos=0.010), tot_loss_proj:3.274 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did susie, not downtown, go. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.557 (perp=6.671, rec=0.213, cos=0.010), tot_loss_proj:3.238 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did go, not inside. susie. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.498 (perp=6.435, rec=0.201, cos=0.010), tot_loss_proj:3.215 [t=0.24s]
prediction: ['[CLS] the bill store as i thought did not go, leave, mcgee. [SEP]']
[1050/2000] tot_loss=1.486 (perp=6.458, rec=0.185, cos=0.009), tot_loss_proj:3.245 [t=0.25s]
prediction: ['[CLS] the bill store as i thought did not go, inside, mcgee. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.484 (perp=6.458, rec=0.184, cos=0.009), tot_loss_proj:3.244 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did not go, inside, mcgee. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.478 (perp=6.458, rec=0.178, cos=0.009), tot_loss_proj:3.249 [t=0.21s]
prediction: ['[CLS] the bill store as i thought did not go, inside, mcgee. [SEP]']
[1200/2000] tot_loss=1.475 (perp=6.458, rec=0.175, cos=0.009), tot_loss_proj:3.245 [t=0.24s]
prediction: ['[CLS] the bill store as i thought did not go, inside, mcgee. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.479 (perp=6.458, rec=0.179, cos=0.008), tot_loss_proj:3.244 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did not go, inside, mcgee. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.468 (perp=6.435, rec=0.172, cos=0.008), tot_loss_proj:3.216 [t=0.24s]
prediction: ['[CLS] the bill store as i thought did not go, leave, mcgee. [SEP]']
[1350/2000] tot_loss=1.466 (perp=6.435, rec=0.170, cos=0.008), tot_loss_proj:3.214 [t=0.25s]
prediction: ['[CLS] the bill store as i thought did not go, leave, mcgee. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.429 (perp=6.283, rec=0.164, cos=0.008), tot_loss_proj:3.216 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did not go, to, mcgee. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.507 (perp=6.638, rec=0.171, cos=0.009), tot_loss_proj:3.255 [t=0.25s]
prediction: ['[CLS] the bill store as i thought did not go, leave mcgee,. [SEP]']
[1500/2000] tot_loss=1.396 (perp=6.046, rec=0.178, cos=0.008), tot_loss_proj:3.147 [t=0.22s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.392 (perp=6.046, rec=0.174, cos=0.008), tot_loss_proj:3.143 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.383 (perp=6.046, rec=0.166, cos=0.008), tot_loss_proj:3.143 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
[1650/2000] tot_loss=1.380 (perp=6.046, rec=0.163, cos=0.008), tot_loss_proj:3.142 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.376 (perp=6.046, rec=0.159, cos=0.008), tot_loss_proj:3.145 [t=0.17s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.376 (perp=6.046, rec=0.159, cos=0.008), tot_loss_proj:3.148 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
[1800/2000] tot_loss=1.381 (perp=6.046, rec=0.163, cos=0.008), tot_loss_proj:3.145 [t=0.23s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.382 (perp=6.046, rec=0.165, cos=0.008), tot_loss_proj:3.147 [t=0.25s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.379 (perp=6.046, rec=0.162, cos=0.008), tot_loss_proj:3.152 [t=0.19s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
[1950/2000] tot_loss=1.379 (perp=6.046, rec=0.162, cos=0.008), tot_loss_proj:3.144 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.374 (perp=6.046, rec=0.157, cos=0.008), tot_loss_proj:3.149 [t=0.18s]
prediction: ['[CLS] the bill store as i thought did not go, to mcgee,. [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] i did not, as bill had thought, go to the store. [SEP]
========================
predicted: 
========================
[CLS] the bill store as i thought did not go, to mcgee,. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 53.846 | p: 53.846 | r: 53.846
rougeLsum  | fm: 53.846 | p: 53.846 | r: 53.846
r1fm+r2fm = 108.974

[Aggregate metrics]:
rouge1     | fm: 77.266 | p: 77.759 | r: 77.080
rouge2     | fm: 38.972 | p: 39.063 | r: 39.032
rougeL     | fm: 68.093 | p: 68.625 | r: 67.785
rougeLsum  | fm: 67.449 | p: 68.045 | r: 67.213
r1fm+r2fm = 116.239

input #25 time: 0:08:17 | total time: 3:34:12


Running input #26 of 100.
reference: 
========================
Who will John ask for information about summer courses?
========================
average of cosine similarity 0.9994149465253206
highest_index [0]
highest [0.9994149465253206]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2040, 2097, 2198, 3198, 2005, 2592, 2055, 2621, 5352, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] who will john ask for information about summer courses? [SEP]']
[Init] best rec loss: 0.923130989074707 for ['[CLS] certified bowedhorn ( lunch dedicated normally played stones nj [SEP]']
[Init] best rec loss: 0.9089930653572083 for ['[CLS] herself xx bat draft song questions pol horde coreoning [SEP]']
[Init] best rec loss: 0.9017698764801025 for ['[CLS] sayserly demon vapor complexvish administration wind prominent remaining [SEP]']
[Init] best rec loss: 0.8877642154693604 for ['[CLS] morgan ， marketingrcleamy credit x respective local rufus [SEP]']
[Init] best rec loss: 0.8666320443153381 for ['[CLS] wa fashionon ordinary size ou nice carrier carnegie blankets [SEP]']
[Init] best rec loss: 0.8615206480026245 for ['[CLS] significant brooke stellar motion familiar several cast tigersx student [SEP]']
[Init] best rec loss: 0.8474037051200867 for ['[CLS] pga mill known shannon om lord exercise band no around [SEP]']
[Init] best rec loss: 0.8357264399528503 for ['[CLS] louisiana societe origin suicide attached 680 athletics swallow choicethest [SEP]']
[Init] best perm rec loss: 0.8355830907821655 for ['[CLS]thest suicide swallow louisiana origin attached choice societe 680 athletics [SEP]']
[Init] best perm rec loss: 0.8355064988136292 for ['[CLS] choice louisiana origin swallowthest suicide attached societe 680 athletics [SEP]']
[Init] best perm rec loss: 0.8345492482185364 for ['[CLS] suicide swallow attached origin societe louisiana 680 athletics choicethest [SEP]']
[Init] best perm rec loss: 0.8326054215431213 for ['[CLS] louisiana societe choice origin attached athletics swallow suicide 680thest [SEP]']
[Init] best perm rec loss: 0.8323923349380493 for ['[CLS] 680 choice attached originthest suicide swallow societe louisiana athletics [SEP]']
[Init] best perm rec loss: 0.8307003378868103 for ['[CLS] societe louisiana attached origin choice 680 swallow suicidethest athletics [SEP]']
[Init] best perm rec loss: 0.8306877613067627 for ['[CLS] louisiana attachedthest choice swallow origin societe suicide 680 athletics [SEP]']
[Init] best perm rec loss: 0.8306139707565308 for ['[CLS] 680 attached societe origin athletics choice louisiana swallow suicidethest [SEP]']
[Init] best perm rec loss: 0.8287435173988342 for ['[CLS]thest swallow louisiana societe choice attached suicide origin athletics 680 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.234 (perp=12.855, rec=0.471, cos=0.193), tot_loss_proj:4.362 [t=0.17s]
prediction: ['[CLS]net more evident dialects lifelong? shining will analysis writing [SEP]']
[ 100/2000] tot_loss=2.345 (perp=8.423, rec=0.414, cos=0.247), tot_loss_proj:3.618 [t=0.18s]
prediction: ['[CLS] who more information among they? will will? engineering [SEP]']
[ 150/2000] tot_loss=2.432 (perp=10.156, rec=0.341, cos=0.059), tot_loss_proj:3.978 [t=0.25s]
prediction: ['[CLS] who john information terms they? will will? information [SEP]']
[ 200/2000] tot_loss=2.129 (perp=8.993, rec=0.290, cos=0.041), tot_loss_proj:3.707 [t=0.21s]
prediction: ['[CLS] who john information for how? will asking? information [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.161 (perp=8.857, rec=0.317, cos=0.073), tot_loss_proj:3.676 [t=0.18s]
prediction: ['[CLS] who john summer who? willboat a? information [SEP]']
[ 300/2000] tot_loss=2.234 (perp=10.021, rec=0.206, cos=0.024), tot_loss_proj:3.901 [t=0.18s]
prediction: ['[CLS] who john summer ask? will gill john ask information [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.026 (perp=9.348, rec=0.146, cos=0.011), tot_loss_proj:3.791 [t=0.18s]
prediction: ['[CLS] who john courses ask? will john john ask information [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.255 (perp=9.161, rec=0.351, cos=0.072), tot_loss_proj:3.768 [t=0.24s]
prediction: ['[CLS] who ask john maddy? will john information ask information [SEP]']
[ 450/2000] tot_loss=2.114 (perp=9.445, rec=0.206, cos=0.018), tot_loss_proj:3.703 [t=0.18s]
prediction: ['[CLS] who asked john courses? will john information ask information [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.917 (perp=8.564, rec=0.185, cos=0.018), tot_loss_proj:3.634 [t=0.18s]
prediction: ['[CLS] who without john information courses? will john information ask [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.048 (perp=9.409, rec=0.153, cos=0.013), tot_loss_proj:3.796 [t=0.18s]
prediction: ['[CLS] who without for information courses? will john information ask [SEP]']
[ 600/2000] tot_loss=2.027 (perp=9.409, rec=0.136, cos=0.009), tot_loss_proj:3.797 [t=0.19s]
prediction: ['[CLS] who without for information courses? will john information ask [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.766 (perp=8.156, rec=0.127, cos=0.007), tot_loss_proj:3.525 [t=0.18s]
prediction: ['[CLS] who information for information courses? will john without ask [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.755 (perp=8.156, rec=0.118, cos=0.006), tot_loss_proj:3.528 [t=0.18s]
prediction: ['[CLS] who information for information courses? will john without ask [SEP]']
[ 750/2000] tot_loss=1.787 (perp=8.301, rec=0.122, cos=0.005), tot_loss_proj:3.568 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.773 (perp=8.301, rec=0.109, cos=0.004), tot_loss_proj:3.566 [t=0.23s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.773 (perp=8.301, rec=0.109, cos=0.003), tot_loss_proj:3.567 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
[ 900/2000] tot_loss=1.772 (perp=8.301, rec=0.109, cos=0.003), tot_loss_proj:3.566 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.769 (perp=8.301, rec=0.106, cos=0.003), tot_loss_proj:3.564 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[1000/2000] tot_loss=1.759 (perp=8.301, rec=0.097, cos=0.003), tot_loss_proj:3.566 [t=0.22s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
[1050/2000] tot_loss=1.761 (perp=8.301, rec=0.098, cos=0.003), tot_loss_proj:3.564 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[1100/2000] tot_loss=1.762 (perp=8.301, rec=0.100, cos=0.002), tot_loss_proj:3.567 [t=0.26s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[1150/2000] tot_loss=1.744 (perp=8.301, rec=0.081, cos=0.002), tot_loss_proj:3.564 [t=0.24s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
[1200/2000] tot_loss=1.761 (perp=8.301, rec=0.098, cos=0.002), tot_loss_proj:3.564 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[1250/2000] tot_loss=1.748 (perp=8.301, rec=0.086, cos=0.002), tot_loss_proj:3.564 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[1300/2000] tot_loss=1.759 (perp=8.301, rec=0.097, cos=0.002), tot_loss_proj:3.563 [t=0.22s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
[1350/2000] tot_loss=1.747 (perp=8.301, rec=0.084, cos=0.002), tot_loss_proj:3.562 [t=0.19s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[1400/2000] tot_loss=1.752 (perp=8.301, rec=0.089, cos=0.002), tot_loss_proj:3.563 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[1450/2000] tot_loss=1.750 (perp=8.301, rec=0.088, cos=0.002), tot_loss_proj:3.562 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
[1500/2000] tot_loss=1.752 (perp=8.301, rec=0.090, cos=0.002), tot_loss_proj:3.562 [t=0.17s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[1550/2000] tot_loss=1.748 (perp=8.301, rec=0.086, cos=0.002), tot_loss_proj:3.566 [t=0.23s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[1600/2000] tot_loss=1.746 (perp=8.301, rec=0.084, cos=0.002), tot_loss_proj:3.564 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
[1650/2000] tot_loss=1.751 (perp=8.301, rec=0.089, cos=0.002), tot_loss_proj:3.561 [t=0.18s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
[1700/2000] tot_loss=1.743 (perp=8.301, rec=0.081, cos=0.002), tot_loss_proj:3.563 [t=0.20s]
prediction: ['[CLS] who information for information summer? will john without ask [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.665 (perp=7.759, rec=0.109, cos=0.004), tot_loss_proj:3.477 [t=0.18s]
prediction: ['[CLS] who information for john without information summer? will ask [SEP]']
[1800/2000] tot_loss=1.647 (perp=7.759, rec=0.092, cos=0.003), tot_loss_proj:3.484 [t=0.18s]
prediction: ['[CLS] who information for john without information summer? will ask [SEP]']
Attempt swap
[1850/2000] tot_loss=1.650 (perp=7.759, rec=0.096, cos=0.002), tot_loss_proj:3.481 [t=0.18s]
prediction: ['[CLS] who information for john without information summer? will ask [SEP]']
Attempt swap
[1900/2000] tot_loss=1.648 (perp=7.759, rec=0.094, cos=0.002), tot_loss_proj:3.483 [t=0.19s]
prediction: ['[CLS] who information for john without information summer? will ask [SEP]']
[1950/2000] tot_loss=1.643 (perp=7.759, rec=0.089, cos=0.002), tot_loss_proj:3.478 [t=0.19s]
prediction: ['[CLS] who information for john without information summer? will ask [SEP]']
Attempt swap
[2000/2000] tot_loss=1.639 (perp=7.759, rec=0.085, cos=0.002), tot_loss_proj:3.482 [t=0.18s]
prediction: ['[CLS] who information for john without information summer? will ask [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] who will john ask for information about summer courses? [SEP]
========================
predicted: 
========================
[CLS] who information for information summer? will john without ask [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 111.818

[Aggregate metrics]:
rouge1     | fm: 77.396 | p: 77.947 | r: 77.149
rouge2     | fm: 38.403 | p: 38.406 | r: 38.456
rougeL     | fm: 67.564 | p: 68.059 | r: 67.251
rougeLsum  | fm: 67.124 | p: 67.621 | r: 66.901
r1fm+r2fm = 115.799

input #26 time: 0:08:11 | total time: 3:42:23


Running input #27 of 100.
reference: 
========================
Ron wanted to wear a tuxedo to the party, but Caspar couldn't decide whether to.
========================
average of cosine similarity 0.9993526850364249
highest_index [0]
highest [0.9993526850364249]
Debug: ids_shape = 24, pads = [24]
Debug: input ids = tensor([[  101,  6902,  2359,  2000,  4929,  1037, 10722, 19068,  2080,  2000,
          1996,  2283,  1010,  2021, 25222, 19362,  2481,  1005,  1056,  5630,
          3251,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]"]
[Init] best rec loss: 0.9158304333686829 for ['[CLS]ig operated already block sad pac further armenians songs, fund book waters line buy willis relief strike collaborative tack violet bring [SEP]']
[Init] best rec loss: 0.9106042981147766 for ['[CLS] glory money divided paidckenging pressedent magneticance baptist tasteroving [SEP] echo jeremy cipher warrant 』 option measures shot [SEP]']
[Init] best rec loss: 0.897331953048706 for ['[CLS] hay swedish scholars similarities passing sounds bruno anyway accountcy accounts quantum zelity excellence summer diego hepburn documentation buried would league [SEP]']
[Init] best rec loss: 0.8913874626159668 for ['[CLS] perhaps whateveriff implement suit jam silk recruits county reidcted japan smellbed campus needs strolledlem minimum values legs monty [SEP]']
[Init] best rec loss: 0.8904507160186768 for ['[CLS]mum medley basis school started primaries 500ization terrific available boundgies film ninebered constellation edcule gan switch week waters [SEP]']
[Init] best rec loss: 0.8834986686706543 for ['[CLS] devote simulator filled kidd contrast orientucherctive nba ll past ticked rhysbad impgle stereo ferries possibility shooterphone dad [SEP]']
[Init] best rec loss: 0.8819141983985901 for ['[CLS] thesefold ant integration seconds news only advantage epithetpants governed s number agents published every guard bulgarian particular flying dental evening [SEP]']
[Init] best rec loss: 0.8795796036720276 for ['[CLS]vet levelgam findings what deployment weeks claimed rivers lights incumbent always shot callum recordldongesttle regional tank mat university [SEP]']
[Init] best perm rec loss: 0.8790776133537292 for ['[CLS] level shot university matges lights incumbent deployment weeks claimed tank riversgam regional always callum recordldon findingsttlevet what [SEP]']
[Init] best perm rec loss: 0.8726145625114441 for ['[CLS] deployment claimed riversttlevet weeks what findings university levelgam lights mat record callum alwaysgesldon regional shot tank incumbent [SEP]']
[Init] best perm rec loss: 0.8725971579551697 for ['[CLS]ldon universityvet shotgam callumges rivers what recordttle always lights tank level incumbent regional weeks deployment claimed findings mat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.023 (perp=13.168, rec=0.603, cos=0.787), tot_loss_proj:4.526 [t=0.19s]
prediction: ['[CLS] ron wine okay announcedured bless. sc gum of led jan my. ways ` win or soil pump whipped formation [SEP]']
[ 100/2000] tot_loss=3.450 (perp=11.064, rec=0.762, cos=0.475), tot_loss_proj:4.091 [t=0.18s]
prediction: ['[CLS] my clothes appearances get chloe pubs on from having on make hasnd - finals aus champions dave particularly match wentrank [SEP]']
[ 150/2000] tot_loss=3.916 (perp=11.562, rec=0.834, cos=0.769), tot_loss_proj:4.211 [t=0.22s]
prediction: ['[CLS] do half [CLS] get eurovision fortune characters ( smash starting match injurednd great lost tournament win wrestling round match [SEP] vega [SEP]']
[ 200/2000] tot_loss=3.777 (perp=12.022, rec=0.774, cos=0.599), tot_loss_proj:4.305 [t=0.20s]
prediction: ['[CLS] go half [CLS] getting eurovision fortune episode from leg fans match reviewnd great lost tournament win wrestling castle match [SEP] vega [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.495 (perp=11.148, rec=0.736, cos=0.530), tot_loss_proj:4.109 [t=0.19s]
prediction: ['[CLS] go half [CLS] getting topped fortune episode from somehow fans round reviewnd great lost tournament win wrestling castle match [SEP] leg [SEP]']
[ 300/2000] tot_loss=3.365 (perp=11.128, rec=0.704, cos=0.435), tot_loss_proj:4.115 [t=0.18s]
prediction: ['[CLS] go half [CLS] getting topped supper characters from somehow fans round reviewnd great lost match win wrestling castle match [SEP] leg [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.394 (perp=11.759, rec=0.665, cos=0.377), tot_loss_proj:4.244 [t=0.22s]
prediction: ['[CLS] go half getting toppedto characters 1998 somehow fans round reviewnd great lost tournament win wrestling loss match [SEP] beauty leg [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.164 (perp=11.140, rec=0.621, cos=0.315), tot_loss_proj:4.118 [t=0.18s]
prediction: ['[CLS] go half getting lost toppedto characters 1998 somehow fans round refnd great tournament win wrestling loss match [SEP] beauty singles [SEP]']
[ 450/2000] tot_loss=3.048 (perp=11.144, rec=0.573, cos=0.247), tot_loss_proj:4.122 [t=0.21s]
prediction: ['[CLS] go half getting lost toppedto episode from larry fans round refnd great tournament win wrestling loss match [SEP] pure santa [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.854 (perp=10.678, rec=0.537, cos=0.182), tot_loss_proj:4.036 [t=0.19s]
prediction: ['[CLS] go from getting lost toppedto characters half went fans round hammersmithnd great tournament win wrestling loss match [SEP] pure singles [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.879 (perp=11.110, rec=0.517, cos=0.140), tot_loss_proj:4.125 [t=0.27s]
prediction: ['[CLS] go ( getting lost topped pure characters half nedra fans match centrend great tournament win wrestling loss match [SEP]tohear [SEP]']
[ 600/2000] tot_loss=2.799 (perp=10.961, rec=0.496, cos=0.111), tot_loss_proj:4.095 [t=0.23s]
prediction: ['[CLS] go ( getting lost topped beauty characters half nedra fans match centrend great tournament win wrestling loss match [SEP] ithear [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.626 (perp=10.246, rec=0.477, cos=0.099), tot_loss_proj:3.940 [t=0.21s]
prediction: ['[CLS] go ( getting lost topped beauty centre half nedra fans match episodend great tournament win wrestling loss match [SEP] ithear [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.535 (perp=9.796, rec=0.474, cos=0.101), tot_loss_proj:3.848 [t=0.18s]
prediction: ['[CLS] ( getting lost topped beauty centre half nedra fans match episodend great go tournament win wrestling loss match [SEP] it numbered [SEP]']
[ 750/2000] tot_loss=2.514 (perp=9.796, rec=0.463, cos=0.092), tot_loss_proj:3.845 [t=0.25s]
prediction: ['[CLS] ( getting lost topped beauty centre half nedra fans match episodend great go tournament win wrestling loss match [SEP] it numbered [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.464 (perp=9.585, rec=0.460, cos=0.088), tot_loss_proj:3.802 [t=0.18s]
prediction: ['[CLS] ( getting lost topped beauty centre half nedra fans go tournament win wrestling match episodend great loss match [SEP] it numbered [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.453 (perp=9.631, rec=0.443, cos=0.084), tot_loss_proj:3.819 [t=0.24s]
prediction: ['[CLS] ( getting lost topped beauty centre half nedra fans tournament win wrestling match go charactersnd great loss match [SEP] it numbered [SEP]']
[ 900/2000] tot_loss=2.446 (perp=9.631, rec=0.440, cos=0.079), tot_loss_proj:3.817 [t=0.18s]
prediction: ['[CLS] ( getting lost topped beauty centre half nedra fans tournament win wrestling match go charactersnd great loss match [SEP] it numbered [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.397 (perp=9.420, rec=0.437, cos=0.076), tot_loss_proj:3.787 [t=0.18s]
prediction: ['[CLS] ( getting lost topped beauty centre half anyway fans tournament win wrestling match gond great loss characters match [SEP] it numbered [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.392 (perp=9.421, rec=0.433, cos=0.074), tot_loss_proj:3.790 [t=0.18s]
prediction: ['[CLS] ( getting lost topped beauty centre half anyway fans tournament characters wrestling match gond great loss win match [SEP] it numbered [SEP]']
[1050/2000] tot_loss=2.378 (perp=9.421, rec=0.422, cos=0.072), tot_loss_proj:3.788 [t=0.18s]
prediction: ['[CLS] ( getting lost topped beauty centre half anyway fans tournament characters wrestling match gond great loss win match [SEP] it numbered [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.365 (perp=9.365, rec=0.423, cos=0.069), tot_loss_proj:3.776 [t=0.18s]
prediction: ['[CLS] ( getting lost topped beauty centre half anyway fans wrestling tournament characters match gond great loss win match [SEP] it numbered [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.361 (perp=9.361, rec=0.421, cos=0.068), tot_loss_proj:3.776 [t=0.25s]
prediction: ['[CLS] ( beauty getting lost topped centre half anyway till wrestling tournament characters match gond great loss win match [SEP] it numbered [SEP]']
[1200/2000] tot_loss=2.351 (perp=9.361, rec=0.413, cos=0.066), tot_loss_proj:3.776 [t=0.18s]
prediction: ['[CLS] ( beauty getting lost topped centre half anyway till wrestling tournament characters match gond great loss win match [SEP] it numbered [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.351 (perp=9.368, rec=0.412, cos=0.065), tot_loss_proj:3.756 [t=0.19s]
prediction: ['[CLS] beauty getting lost topped centre half nedra till ( wrestling tournament characters match gond great loss win match [SEP] it numbered [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.296 (perp=9.098, rec=0.410, cos=0.067), tot_loss_proj:3.709 [t=0.20s]
prediction: ['[CLS] beauty getting lost topped centre half till nedra ( wrestling tournament characters match gond great loss win match [SEP] it numbered [SEP]']
[1350/2000] tot_loss=2.278 (perp=9.098, rec=0.400, cos=0.058), tot_loss_proj:3.709 [t=0.22s]
prediction: ['[CLS] beauty getting lost topped centre half till nedra ( wrestling tournament characters match gond great loss win match [SEP] it numbered [SEP]']
Attempt swap
[1400/2000] tot_loss=2.279 (perp=9.098, rec=0.402, cos=0.057), tot_loss_proj:3.708 [t=0.18s]
prediction: ['[CLS] beauty getting lost topped centre half till nedra ( wrestling tournament characters match gond great loss win match [SEP] it numbered [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.248 (perp=8.937, rec=0.404, cos=0.057), tot_loss_proj:3.673 [t=0.18s]
prediction: ['[CLS] beauty getting lost topped centre half till nedra ( wrestling tournament characters match gond great loss match win [SEP] it numbered [SEP]']
[1500/2000] tot_loss=2.250 (perp=8.937, rec=0.407, cos=0.056), tot_loss_proj:3.681 [t=0.23s]
prediction: ['[CLS] beauty getting lost topped centre half till nedra ( wrestling tournament characters match gond great loss match win [SEP] it numbered [SEP]']
Attempt swap
[1550/2000] tot_loss=2.229 (perp=8.881, rec=0.398, cos=0.055), tot_loss_proj:3.677 [t=0.23s]
prediction: ['[CLS] beauty getting lost topped centre half till anyway ( wrestling tournament characters match gond great loss match win [SEP] it erebidae [SEP]']
Attempt swap
[1600/2000] tot_loss=2.228 (perp=8.881, rec=0.397, cos=0.054), tot_loss_proj:3.675 [t=0.19s]
prediction: ['[CLS] beauty getting lost topped centre half till anyway ( wrestling tournament characters match gond great loss match win [SEP] it erebidae [SEP]']
[1650/2000] tot_loss=2.230 (perp=8.881, rec=0.400, cos=0.054), tot_loss_proj:3.673 [t=0.18s]
prediction: ['[CLS] beauty getting lost topped centre half till anyway ( wrestling tournament characters match gond great loss match win [SEP] it erebidae [SEP]']
Attempt swap
[1700/2000] tot_loss=2.223 (perp=8.881, rec=0.393, cos=0.054), tot_loss_proj:3.671 [t=0.21s]
prediction: ['[CLS] beauty getting lost topped centre half till anyway ( wrestling tournament characters match gond great loss match win [SEP] it erebidae [SEP]']
Attempt swap
[1750/2000] tot_loss=2.223 (perp=8.881, rec=0.394, cos=0.053), tot_loss_proj:3.677 [t=0.25s]
prediction: ['[CLS] beauty getting lost topped centre half till anyway ( wrestling tournament characters match gond great loss match win [SEP] it erebidae [SEP]']
[1800/2000] tot_loss=2.318 (perp=9.367, rec=0.392, cos=0.053), tot_loss_proj:3.778 [t=0.18s]
prediction: ['[CLS] beauty getting lost topped centre half till anyway ( wrestling tournament attraction match gond great loss match win [SEP] it erebidae [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.302 (perp=9.280, rec=0.393, cos=0.053), tot_loss_proj:3.761 [t=0.22s]
prediction: ['[CLS] beauty getting lost topped centre half till anyway ( wrestling tournament match gond great loss match win attraction [SEP] it erebidae [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.271 (perp=9.153, rec=0.388, cos=0.053), tot_loss_proj:3.743 [t=0.26s]
prediction: ['[CLS] beauty getting lost topped centre half till anyway ( attraction wrestling tournament match gond great loss match win [SEP] it erebidae [SEP]']
[1950/2000] tot_loss=2.277 (perp=9.153, rec=0.395, cos=0.052), tot_loss_proj:3.739 [t=0.18s]
prediction: ['[CLS] beauty getting lost topped centre half till anyway ( attraction wrestling tournament match gond great loss match win [SEP] it erebidae [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=2.269 (perp=9.133, rec=0.390, cos=0.052), tot_loss_proj:3.737 [t=0.22s]
prediction: ['[CLS] beauty getting lost topped centre half till anyway ( attraction wrestling match gond great loss match win tournament [SEP] it erebidae [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]
========================
predicted: 
========================
[CLS] beauty getting lost topped centre half till anyway ( wrestling tournament match gond great loss match win attraction [SEP] it erebidae [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 10.000 | p: 9.091 | r: 11.111
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 10.000 | p: 9.091 | r: 11.111
rougeLsum  | fm: 10.000 | p: 9.091 | r: 11.111
r1fm+r2fm = 10.000

[Aggregate metrics]:
rouge1     | fm: 75.058 | p: 75.454 | r: 74.866
rouge2     | fm: 37.118 | p: 37.222 | r: 37.236
rougeL     | fm: 65.457 | p: 65.838 | r: 65.181
rougeLsum  | fm: 65.223 | p: 65.774 | r: 64.978
r1fm+r2fm = 112.177

input #27 time: 0:08:12 | total time: 3:50:35


Running input #28 of 100.
reference: 
========================
Bill gave Sue the book.
========================
average of cosine similarity 0.9992527833287079
highest_index [0]
highest [0.9992527833287079]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 3021, 2435, 9790, 1996, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bill gave sue the book. [SEP]']
[Init] best rec loss: 0.9755856394767761 for ['[CLS] martin links ponder _ borntist [SEP]']
[Init] best rec loss: 0.9694833755493164 for ['[CLS] grain farm processing fielding following pierced [SEP]']
[Init] best rec loss: 0.9555665254592896 for ['[CLS] whoever mphaghan live manor patrol [SEP]']
[Init] best rec loss: 0.9311076998710632 for ['[CLS]cked nicknamed me hardware colour boil [SEP]']
[Init] best rec loss: 0.8972436189651489 for ['[CLS] anniversary deposit ethan baroque barnet recently [SEP]']
[Init] best perm rec loss: 0.8948907256126404 for ['[CLS] recently anniversary baroque ethan barnet deposit [SEP]']
[Init] best perm rec loss: 0.8926964402198792 for ['[CLS] ethan baroque barnet recently deposit anniversary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.089 (perp=11.752, rec=0.748, cos=0.991), tot_loss_proj:4.314 [t=0.24s]
prediction: ['[CLS] + style helped chinpeed sorry [SEP]']
[ 100/2000] tot_loss=3.750 (perp=11.010, rec=0.614, cos=0.935), tot_loss_proj:4.222 [t=0.23s]
prediction: ['[CLS]... "! late lb card [SEP]']
[ 150/2000] tot_loss=2.899 (perp=9.842, rec=0.530, cos=0.401), tot_loss_proj:3.557 [t=0.18s]
prediction: ['[CLS] your!!. blonde mind [SEP]']
[ 200/2000] tot_loss=2.555 (perp=10.572, rec=0.362, cos=0.079), tot_loss_proj:4.089 [t=0.18s]
prediction: ['[CLS] mitchell sue!. bill thanks [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.588 (perp=11.041, rec=0.322, cos=0.058), tot_loss_proj:4.221 [t=0.18s]
prediction: ['[CLS] mitchell sue gave bill! sue [SEP]']
[ 300/2000] tot_loss=2.617 (perp=11.410, rec=0.297, cos=0.038), tot_loss_proj:4.257 [t=0.18s]
prediction: ['[CLS] miranda sue gave bill! sue [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.266 (perp=9.808, rec=0.272, cos=0.033), tot_loss_proj:3.942 [t=0.18s]
prediction: ['[CLS] sue miranda gave bill! sue [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.440 (perp=10.918, rec=0.229, cos=0.027), tot_loss_proj:4.171 [t=0.18s]
prediction: ['[CLS] sue bill gave bill! book [SEP]']
[ 450/2000] tot_loss=2.399 (perp=10.918, rec=0.196, cos=0.020), tot_loss_proj:4.173 [t=0.19s]
prediction: ['[CLS] sue bill gave bill! book [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.131 (perp=9.623, rec=0.185, cos=0.021), tot_loss_proj:3.929 [t=0.25s]
prediction: ['[CLS] sue! gave bill! sue [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.979 (perp=8.759, rec=0.203, cos=0.024), tot_loss_proj:3.742 [t=0.18s]
prediction: ['[CLS] book sue gave bill!! [SEP]']
[ 600/2000] tot_loss=1.934 (perp=8.759, rec=0.165, cos=0.018), tot_loss_proj:3.741 [t=0.18s]
prediction: ['[CLS] book sue gave bill!! [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.900 (perp=8.557, rec=0.172, cos=0.017), tot_loss_proj:3.696 [t=0.19s]
prediction: ['[CLS] book sue gave! bill! [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.850 (perp=8.227, rec=0.188, cos=0.016), tot_loss_proj:3.459 [t=0.22s]
prediction: ['[CLS] book! gave sue book! [SEP]']
[ 750/2000] tot_loss=1.814 (perp=8.227, rec=0.154, cos=0.015), tot_loss_proj:3.463 [t=0.26s]
prediction: ['[CLS] book! gave sue book! [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.816 (perp=8.227, rec=0.156, cos=0.015), tot_loss_proj:3.466 [t=0.21s]
prediction: ['[CLS] book! gave sue book! [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.156 (perp=9.836, rec=0.173, cos=0.016), tot_loss_proj:3.886 [t=0.17s]
prediction: ['[CLS] book sue gave! book crash [SEP]']
[ 900/2000] tot_loss=2.101 (perp=9.649, rec=0.157, cos=0.014), tot_loss_proj:3.814 [t=0.25s]
prediction: ['[CLS] book sue gave. book crash [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.101 (perp=9.649, rec=0.158, cos=0.014), tot_loss_proj:3.816 [t=0.19s]
prediction: ['[CLS] book sue gave. book crash [SEP]']
Attempt swap
[1000/2000] tot_loss=2.102 (perp=9.649, rec=0.158, cos=0.014), tot_loss_proj:3.811 [t=0.22s]
prediction: ['[CLS] book sue gave. book crash [SEP]']
[1050/2000] tot_loss=2.104 (perp=9.649, rec=0.161, cos=0.013), tot_loss_proj:3.815 [t=0.17s]
prediction: ['[CLS] book sue gave. book crash [SEP]']
Attempt swap
[1100/2000] tot_loss=2.099 (perp=9.649, rec=0.156, cos=0.013), tot_loss_proj:3.815 [t=0.22s]
prediction: ['[CLS] book sue gave. book crash [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.000 (perp=9.103, rec=0.164, cos=0.015), tot_loss_proj:3.610 [t=0.26s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
[1200/2000] tot_loss=1.984 (perp=9.103, rec=0.152, cos=0.012), tot_loss_proj:3.613 [t=0.22s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.981 (perp=9.103, rec=0.149, cos=0.012), tot_loss_proj:3.615 [t=0.22s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.988 (perp=9.103, rec=0.156, cos=0.012), tot_loss_proj:3.615 [t=0.20s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
[1350/2000] tot_loss=1.984 (perp=9.103, rec=0.152, cos=0.012), tot_loss_proj:3.612 [t=0.22s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.974 (perp=9.103, rec=0.142, cos=0.012), tot_loss_proj:3.617 [t=0.18s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.988 (perp=9.103, rec=0.156, cos=0.011), tot_loss_proj:3.616 [t=0.18s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
[1500/2000] tot_loss=1.973 (perp=9.103, rec=0.141, cos=0.011), tot_loss_proj:3.614 [t=0.23s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.971 (perp=9.103, rec=0.139, cos=0.011), tot_loss_proj:3.614 [t=0.19s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.977 (perp=9.103, rec=0.145, cos=0.011), tot_loss_proj:3.619 [t=0.18s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
[1650/2000] tot_loss=1.975 (perp=9.103, rec=0.144, cos=0.011), tot_loss_proj:3.621 [t=0.23s]
prediction: ['[CLS] book sue gave crash book. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.831 (perp=8.395, rec=0.141, cos=0.011), tot_loss_proj:3.482 [t=0.18s]
prediction: ['[CLS] book sue gave miranda book. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.836 (perp=8.395, rec=0.146, cos=0.011), tot_loss_proj:3.480 [t=0.21s]
prediction: ['[CLS] book sue gave miranda book. [SEP]']
[1800/2000] tot_loss=1.853 (perp=8.395, rec=0.163, cos=0.011), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] book sue gave miranda book. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.827 (perp=8.395, rec=0.137, cos=0.011), tot_loss_proj:3.478 [t=0.18s]
prediction: ['[CLS] book sue gave miranda book. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.827 (perp=8.395, rec=0.137, cos=0.011), tot_loss_proj:3.481 [t=0.20s]
prediction: ['[CLS] book sue gave miranda book. [SEP]']
[1950/2000] tot_loss=1.831 (perp=8.395, rec=0.141, cos=0.011), tot_loss_proj:3.473 [t=0.18s]
prediction: ['[CLS] book sue gave miranda book. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.830 (perp=8.395, rec=0.140, cos=0.011), tot_loss_proj:3.477 [t=0.18s]
prediction: ['[CLS] book sue gave miranda book. [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] bill gave sue the book. [SEP]
========================
predicted: 
========================
[CLS] book sue gave miranda book. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 88.095

[Aggregate metrics]:
rouge1     | fm: 75.031 | p: 75.498 | r: 74.768
rouge2     | fm: 36.268 | p: 36.324 | r: 36.284
rougeL     | fm: 65.131 | p: 65.624 | r: 64.970
rougeLsum  | fm: 65.009 | p: 65.447 | r: 64.777
r1fm+r2fm = 111.299

input #28 time: 0:08:09 | total time: 3:58:45


Running input #29 of 100.
reference: 
========================
The bread was chewed by Martha.
========================
average of cosine similarity 0.9994577127920362
highest_index [0]
highest [0.9994577127920362]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996,  7852,  2001, 18362,  2011,  9246,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the bread was chewed by martha. [SEP]']
[Init] best rec loss: 1.033448576927185 for ['[CLS] squeezed pace bonnie know plantsoic bishop [SEP]']
[Init] best rec loss: 0.9979770183563232 for ['[CLS] party morrison #ramet animated fluent [SEP]']
[Init] best rec loss: 0.9941338300704956 for ['[CLS] chewed attack turing science sport tontist [SEP]']
[Init] best rec loss: 0.9654293060302734 for ['[CLS] rose worth cowboys aresror affair links [SEP]']
[Init] best rec loss: 0.9611841440200806 for ['[CLS] initially begingram als mothscode loan [SEP]']
[Init] best rec loss: 0.9402060508728027 for ['[CLS] guardian blocked printed, entry important household [SEP]']
[Init] best perm rec loss: 0.9361010789871216 for ['[CLS] guardian important printed entry, blocked household [SEP]']
[Init] best perm rec loss: 0.9354170560836792 for ['[CLS] important entry household, printed guardian blocked [SEP]']
[Init] best perm rec loss: 0.9348337054252625 for ['[CLS], printed blocked entry important guardian household [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.253 (perp=8.640, rec=0.412, cos=0.113), tot_loss_proj:3.819 [t=0.20s]
prediction: ['[CLS] bread loaf became bread chewed bread. [SEP]']
[ 100/2000] tot_loss=2.495 (perp=10.982, rec=0.271, cos=0.028), tot_loss_proj:4.011 [t=0.18s]
prediction: ['[CLS] martha bread became bread chewed bread by [SEP]']
[ 150/2000] tot_loss=2.323 (perp=10.594, rec=0.188, cos=0.017), tot_loss_proj:3.816 [t=0.20s]
prediction: ['[CLS] martha bread was bread chewed martha by [SEP]']
[ 200/2000] tot_loss=2.315 (perp=10.876, rec=0.132, cos=0.008), tot_loss_proj:4.002 [t=0.18s]
prediction: ['[CLS] martha bread was bread chewed by by [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.999 (perp=9.212, rec=0.145, cos=0.012), tot_loss_proj:3.588 [t=0.19s]
prediction: ['[CLS] martha bread was chewed by bread by [SEP]']
[ 300/2000] tot_loss=1.966 (perp=9.317, rec=0.096, cos=0.006), tot_loss_proj:3.562 [t=0.23s]
prediction: ['[CLS] martha the was chewed by bread. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.495 (perp=7.039, rec=0.082, cos=0.005), tot_loss_proj:3.184 [t=0.27s]
prediction: ['[CLS] the martha was chewed by bread. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.386 (perp=6.460, rec=0.088, cos=0.006), tot_loss_proj:1.592 [t=0.28s]
prediction: ['[CLS] the bread was chewed by martha ; [SEP]']
[ 450/2000] tot_loss=1.383 (perp=6.460, rec=0.086, cos=0.005), tot_loss_proj:1.593 [t=0.26s]
prediction: ['[CLS] the bread was chewed by martha ; [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.307 (perp=6.120, rec=0.078, cos=0.005), tot_loss_proj:1.330 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.298 (perp=6.120, rec=0.069, cos=0.005), tot_loss_proj:1.350 [t=0.26s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 600/2000] tot_loss=1.306 (perp=6.120, rec=0.078, cos=0.005), tot_loss_proj:1.338 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.297 (perp=6.120, rec=0.069, cos=0.004), tot_loss_proj:1.341 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.303 (perp=6.120, rec=0.075, cos=0.004), tot_loss_proj:1.335 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 750/2000] tot_loss=1.294 (perp=6.120, rec=0.066, cos=0.004), tot_loss_proj:1.340 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.295 (perp=6.120, rec=0.067, cos=0.004), tot_loss_proj:1.339 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.298 (perp=6.120, rec=0.070, cos=0.004), tot_loss_proj:1.336 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 900/2000] tot_loss=1.303 (perp=6.120, rec=0.075, cos=0.004), tot_loss_proj:1.333 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.306 (perp=6.120, rec=0.078, cos=0.004), tot_loss_proj:1.342 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.292 (perp=6.120, rec=0.064, cos=0.004), tot_loss_proj:1.330 [t=0.27s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1050/2000] tot_loss=1.300 (perp=6.120, rec=0.072, cos=0.004), tot_loss_proj:1.333 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.300 (perp=6.120, rec=0.072, cos=0.004), tot_loss_proj:1.338 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.312 (perp=6.120, rec=0.084, cos=0.004), tot_loss_proj:1.337 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1200/2000] tot_loss=1.297 (perp=6.120, rec=0.069, cos=0.004), tot_loss_proj:1.331 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.298 (perp=6.120, rec=0.070, cos=0.004), tot_loss_proj:1.346 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.300 (perp=6.120, rec=0.072, cos=0.004), tot_loss_proj:1.332 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1350/2000] tot_loss=1.289 (perp=6.120, rec=0.061, cos=0.004), tot_loss_proj:1.339 [t=0.25s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.305 (perp=6.120, rec=0.077, cos=0.004), tot_loss_proj:1.337 [t=0.23s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.306 (perp=6.120, rec=0.078, cos=0.004), tot_loss_proj:1.339 [t=0.26s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1500/2000] tot_loss=1.308 (perp=6.120, rec=0.080, cos=0.004), tot_loss_proj:1.321 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.300 (perp=6.120, rec=0.072, cos=0.004), tot_loss_proj:1.333 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.314 (perp=6.120, rec=0.086, cos=0.004), tot_loss_proj:1.336 [t=0.23s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1650/2000] tot_loss=1.303 (perp=6.120, rec=0.075, cos=0.004), tot_loss_proj:1.338 [t=0.23s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.301 (perp=6.120, rec=0.073, cos=0.004), tot_loss_proj:1.344 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.293 (perp=6.120, rec=0.065, cos=0.004), tot_loss_proj:1.341 [t=0.28s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1800/2000] tot_loss=1.300 (perp=6.120, rec=0.072, cos=0.004), tot_loss_proj:1.334 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.307 (perp=6.120, rec=0.079, cos=0.004), tot_loss_proj:1.336 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.289 (perp=6.120, rec=0.062, cos=0.004), tot_loss_proj:1.347 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1950/2000] tot_loss=1.297 (perp=6.120, rec=0.069, cos=0.004), tot_loss_proj:1.330 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.302 (perp=6.120, rec=0.075, cos=0.004), tot_loss_proj:1.334 [t=0.26s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] the bread was chewed by martha. [SEP]
========================
predicted: 
========================
[CLS] the bread was chewed by martha. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 75.809 | p: 76.205 | r: 75.564
rouge2     | fm: 38.441 | p: 38.628 | r: 38.456
rougeL     | fm: 66.350 | p: 66.736 | r: 66.092
rougeLsum  | fm: 66.368 | p: 66.758 | r: 66.168
r1fm+r2fm = 114.249

input #29 time: 0:08:08 | total time: 4:06:53


Running input #30 of 100.
reference: 
========================
Read Fred's story, I also want to.
========================
average of cosine similarity 0.9993327887556609
highest_index [0]
highest [0.9993327887556609]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 3191, 5965, 1005, 1055, 2466, 1010, 1045, 2036, 2215, 2000, 1012,
          102]], device='cuda:0')
Debug: ref = ["[CLS] read fred's story, i also want to. [SEP]"]
[Init] best rec loss: 0.9123356938362122 for ['[CLS] design tourea chargessionkan voicesitatingrak freedom mild [SEP]']
[Init] best rec loss: 0.8970316648483276 for ['[CLS] oil thornton sc platoon scouts reserves town perennial mounted fundamental of [SEP]']
[Init] best rec loss: 0.881742537021637 for ['[CLS] withdrawnnesia lucas planned coloursix oak amin cooper morgan houses [SEP]']
[Init] best rec loss: 0.8782221674919128 for ['[CLS] attempted roadpherizan watches looked mercy wedding momect husbands [SEP]']
[Init] best rec loss: 0.8723532557487488 for ['[CLS] spread happening meant advisory sniff record scheduled justice baltimore straightopa [SEP]']
[Init] best rec loss: 0.865502655506134 for ['[CLS] conference waiting divided twin sweat ponye criminal universe family window [SEP]']
[Init] best rec loss: 0.8589546084403992 for ['[CLS] athleticffled tallinn dial commonly gallery acc relation ruby speakingski [SEP]']
[Init] best rec loss: 0.8508736491203308 for ['[CLS] oldest mon station video moi reserve conference non coming combatathlon [SEP]']
[Init] best perm rec loss: 0.8473225235939026 for ['[CLS]athlon combat coming oldest video moi reserve conference mon non station [SEP]']
[Init] best perm rec loss: 0.8470238447189331 for ['[CLS]athlon station combat reserve moi mon coming video conference non oldest [SEP]']
[Init] best perm rec loss: 0.8467389345169067 for ['[CLS]athlon oldest conference video coming reserve mon moi station non combat [SEP]']
[Init] best perm rec loss: 0.8465926051139832 for ['[CLS] moi oldest video station conference combat nonathlon reserve coming mon [SEP]']
[Init] best perm rec loss: 0.8462216258049011 for ['[CLS] reserve video station comingathlon combat non conference moi mon oldest [SEP]']
[Init] best perm rec loss: 0.8446699976921082 for ['[CLS] nonathlon mon station oldest combat video reserve moi coming conference [SEP]']
[Init] best perm rec loss: 0.8441019058227539 for ['[CLS] conference station reserveathlon oldest coming video combat mon non moi [SEP]']
[Init] best perm rec loss: 0.8434234261512756 for ['[CLS] combatathlon station video coming conference moi mon reserve non oldest [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.937 (perp=11.670, rec=0.605, cos=0.998), tot_loss_proj:4.091 [t=0.19s]
prediction: ['[CLS] tan professor, read civil gene done treatise patient bridge most [SEP]']
[ 100/2000] tot_loss=3.579 (perp=10.214, rec=0.538, cos=0.998), tot_loss_proj:3.845 [t=0.19s]
prediction: ['[CLS] s story, read her / agenda [SEP] ª suffix most [SEP]']
[ 150/2000] tot_loss=3.378 (perp=9.711, rec=0.439, cos=0.996), tot_loss_proj:3.808 [t=0.19s]
prediction: ['[CLS] s story, read john / ou i ª proceeds text [SEP]']
[ 200/2000] tot_loss=3.495 (perp=10.522, rec=0.401, cos=0.990), tot_loss_proj:3.929 [t=0.19s]
prediction: ['[CLS] s story, read fred hindu ou i ªة. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.842 (perp=11.014, rec=0.639, cos=1.000), tot_loss_proj:3.964 [t=0.18s]
prediction: ["[CLS]ng story 18 read his, ob, 'promising are [SEP]"]
[ 300/2000] tot_loss=3.612 (perp=10.451, rec=0.536, cos=0.986), tot_loss_proj:3.817 [t=0.25s]
prediction: ['[CLS] samurai story although read his shall let, they ¹⁄₂ are [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.241 (perp=8.974, rec=0.465, cos=0.981), tot_loss_proj:3.535 [t=0.21s]
prediction: ['[CLS] although read his samurai story shall let, they ¹⁄₂ are [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.068 (perp=8.257, rec=0.439, cos=0.977), tot_loss_proj:3.488 [t=0.17s]
prediction: ['[CLS] i read his samurai story shall let ¹⁄₂, they are [SEP]']
[ 450/2000] tot_loss=3.316 (perp=9.622, rec=0.412, cos=0.980), tot_loss_proj:3.723 [t=0.20s]
prediction: ['[CLS] i read s samurai story shall let duty, are are [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.074 (perp=8.480, rec=0.398, cos=0.980), tot_loss_proj:3.552 [t=0.19s]
prediction: ['[CLS] i read s islander story / are obligation, let ) [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.281 (perp=9.661, rec=0.368, cos=0.981), tot_loss_proj:3.818 [t=0.18s]
prediction: ['[CLS] i read s islander story / else obligation, let also [SEP]']
[ 600/2000] tot_loss=3.368 (perp=10.068, rec=0.375, cos=0.980), tot_loss_proj:3.835 [t=0.19s]
prediction: ['[CLS] i read s islander story upon else obligation, let also [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.332 (perp=9.967, rec=0.358, cos=0.980), tot_loss_proj:3.832 [t=0.18s]
prediction: ['[CLS] i read s islander story upon else, let facto also [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.425 (perp=10.449, rec=0.356, cos=0.979), tot_loss_proj:3.819 [t=0.20s]
prediction: ['[CLS] did read s bird story upon else, let facto also [SEP]']
[ 750/2000] tot_loss=3.515 (perp=10.914, rec=0.354, cos=0.979), tot_loss_proj:3.905 [t=0.19s]
prediction: ['[CLS] did read s roy story upon else, let facto also [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.407 (perp=10.445, rec=0.340, cos=0.979), tot_loss_proj:3.801 [t=0.18s]
prediction: ['[CLS] did read fred roy story upon else, let facto also [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.368 (perp=10.196, rec=0.351, cos=0.978), tot_loss_proj:3.807 [t=0.25s]
prediction: ['[CLS] did else fred roy story upon read, let facto remainder [SEP]']
[ 900/2000] tot_loss=3.465 (perp=10.715, rec=0.345, cos=0.977), tot_loss_proj:3.913 [t=0.25s]
prediction: ['[CLS] did else fred keeps story upon read, let facto remainder [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.466 (perp=10.715, rec=0.345, cos=0.978), tot_loss_proj:3.915 [t=0.22s]
prediction: ['[CLS] did else fred keeps story upon read, let facto remainder [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.357 (perp=10.239, rec=0.330, cos=0.979), tot_loss_proj:3.838 [t=0.19s]
prediction: ['[CLS] else did fred keeps story upon read, let facto remainder [SEP]']
[1050/2000] tot_loss=3.357 (perp=10.239, rec=0.331, cos=0.979), tot_loss_proj:3.842 [t=0.18s]
prediction: ['[CLS] else did fred keeps story upon read, let facto remainder [SEP]']
Attempt swap
[1100/2000] tot_loss=3.326 (perp=10.089, rec=0.329, cos=0.979), tot_loss_proj:3.807 [t=0.26s]
prediction: ['[CLS] else did fred teddy story upon read, let facto remainder [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=3.243 (perp=9.613, rec=0.341, cos=0.979), tot_loss_proj:3.730 [t=0.27s]
prediction: ['[CLS] else did fred teddy story read, let facto upon remainder [SEP]']
[1200/2000] tot_loss=3.232 (perp=9.613, rec=0.330, cos=0.979), tot_loss_proj:3.729 [t=0.27s]
prediction: ['[CLS] else did fred teddy story read, let facto upon remainder [SEP]']
Attempt swap
[1250/2000] tot_loss=3.235 (perp=9.613, rec=0.332, cos=0.980), tot_loss_proj:3.731 [t=0.18s]
prediction: ['[CLS] else did fred teddy story read, let facto upon remainder [SEP]']
Attempt swap
[1300/2000] tot_loss=3.259 (perp=9.779, rec=0.323, cos=0.980), tot_loss_proj:3.763 [t=0.19s]
prediction: ['[CLS] else did fred teddy story read, let therefore upon remainder [SEP]']
[1350/2000] tot_loss=3.264 (perp=9.779, rec=0.328, cos=0.980), tot_loss_proj:3.767 [t=0.24s]
prediction: ['[CLS] else did fred teddy story read, let therefore upon remainder [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=3.535 (perp=11.130, rec=0.330, cos=0.979), tot_loss_proj:3.976 [t=0.18s]
prediction: ['[CLS] else underway fred teddy story read, therefore let upon remainder [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=3.458 (perp=10.731, rec=0.332, cos=0.980), tot_loss_proj:3.918 [t=0.26s]
prediction: ['[CLS] else underway fred teddy story, therefore let read upon remainder [SEP]']
[1500/2000] tot_loss=3.454 (perp=10.731, rec=0.328, cos=0.980), tot_loss_proj:3.920 [t=0.18s]
prediction: ['[CLS] else underway fred teddy story, therefore let read upon remainder [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=3.356 (perp=10.275, rec=0.321, cos=0.980), tot_loss_proj:3.826 [t=0.21s]
prediction: ['[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]']
Attempt swap
[1600/2000] tot_loss=3.355 (perp=10.275, rec=0.320, cos=0.980), tot_loss_proj:3.826 [t=0.18s]
prediction: ['[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]']
[1650/2000] tot_loss=3.361 (perp=10.275, rec=0.326, cos=0.980), tot_loss_proj:3.833 [t=0.21s]
prediction: ['[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]']
Attempt swap
[1700/2000] tot_loss=3.349 (perp=10.275, rec=0.314, cos=0.980), tot_loss_proj:3.825 [t=0.18s]
prediction: ['[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]']
Attempt swap
[1750/2000] tot_loss=3.362 (perp=10.275, rec=0.327, cos=0.980), tot_loss_proj:3.829 [t=0.18s]
prediction: ['[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]']
[1800/2000] tot_loss=3.357 (perp=10.275, rec=0.322, cos=0.980), tot_loss_proj:3.833 [t=0.20s]
prediction: ['[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]']
Attempt swap
[1850/2000] tot_loss=3.349 (perp=10.275, rec=0.314, cos=0.980), tot_loss_proj:3.831 [t=0.18s]
prediction: ['[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]']
Attempt swap
[1900/2000] tot_loss=3.357 (perp=10.275, rec=0.322, cos=0.980), tot_loss_proj:3.828 [t=0.21s]
prediction: ['[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]']
[1950/2000] tot_loss=3.355 (perp=10.275, rec=0.319, cos=0.980), tot_loss_proj:3.830 [t=0.24s]
prediction: ['[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]']
Attempt swap
[2000/2000] tot_loss=3.356 (perp=10.275, rec=0.321, cos=0.980), tot_loss_proj:3.827 [t=0.26s]
prediction: ['[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] read fred's story, i also want to. [SEP]
========================
predicted: 
========================
[CLS] underway else fred teddy story, therefore let read upon remainder [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 45.455 | p: 41.667 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 36.364 | p: 33.333 | r: 40.000
rougeLsum  | fm: 36.364 | p: 33.333 | r: 40.000
r1fm+r2fm = 45.455

[Aggregate metrics]:
rouge1     | fm: 74.843 | p: 75.112 | r: 74.765
rouge2     | fm: 37.157 | p: 37.193 | r: 37.137
rougeL     | fm: 65.312 | p: 65.612 | r: 65.317
rougeLsum  | fm: 65.254 | p: 65.567 | r: 65.168
r1fm+r2fm = 112.000

input #30 time: 0:08:17 | total time: 4:15:10


Running input #31 of 100.
reference: 
========================
Some of the water from melted snow also goes into the ground for plants.
========================
average of cosine similarity 0.9992295707454684
highest_index [0]
highest [0.9992295707454684]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2070,  1997,  1996,  2300,  2013, 12501,  4586,  2036,  3632,
          2046,  1996,  2598,  2005,  4264,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]']
[Init] best rec loss: 0.9458415508270264 for ["[CLS] girlfriend set faculty clay angeles boom cross bandonus sh 'tical mistake inn ballard [SEP]"]
[Init] best rec loss: 0.922178328037262 for ['[CLS] ace brady declared temples eight simply { doi clapped content unit foot npr chargedtro [SEP]']
[Init] best rec loss: 0.912794828414917 for ['[CLS] spaceship mercy loanbil spoken continued gun quentin merit closed abrl asked chemistry states [SEP]']
[Init] best rec loss: 0.9126591086387634 for ['[CLS] modern currently joey press trent bed reaching main herzegovina mahmoud recent may prescription cover french [SEP]']
[Init] best rec loss: 0.9065945744514465 for ['[CLS] carolina wonder calendar macy rocktill students power search under length laketia greg lowest [SEP]']
[Init] best rec loss: 0.8944409489631653 for ['[CLS] colt vampires well apartheid general viscount skate lend absolutely and tension dramatic diner chief level [SEP]']
[Init] best rec loss: 0.8925084471702576 for ['[CLS]agi independentnished spruce campus best george any crawford ft goals poetry mushroom unaoulos [SEP]']
[Init] best perm rec loss: 0.8879450559616089 for ['[CLS]nished spruce campus any mushroom unaoulos ft georgeagi independent best poetry goals crawford [SEP]']
[Init] best perm rec loss: 0.8877514600753784 for ['[CLS]oulos independent campus anyagi spruce best george poetry ft mushroom crawfordnished goals una [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.828 (perp=11.847, rec=0.539, cos=0.920), tot_loss_proj:4.238 [t=0.22s]
prediction: ['[CLS] aircraftlock height american blood uses started : bombing fiesta software plants from fiat dug [SEP]']
[ 100/2000] tot_loss=3.806 (perp=12.063, rec=0.560, cos=0.834), tot_loss_proj:4.238 [t=0.18s]
prediction: ['[CLS] aircraft mid hispanic use pieces uses snow as past bugs2 her of seasons root [SEP]']
[ 150/2000] tot_loss=2.472 (perp=10.372, rec=0.328, cos=0.069), tot_loss_proj:3.891 [t=0.18s]
prediction: ['[CLS] meter mid deep water recovered used snow mostly past river2 her water used water [SEP]']
[ 200/2000] tot_loss=2.583 (perp=10.701, rec=0.351, cos=0.092), tot_loss_proj:3.979 [t=0.22s]
prediction: ['[CLS] plants off deep sometimes snow goes snow more of water stock melted water plant water [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.012 (perp=8.684, rec=0.251, cos=0.024), tot_loss_proj:3.574 [t=0.20s]
prediction: ['[CLS] snow off cold water snow goes as snow of water water °c water plant water [SEP]']
[ 300/2000] tot_loss=2.043 (perp=8.959, rec=0.233, cos=0.019), tot_loss_proj:3.702 [t=0.18s]
prediction: ['[CLS] snow, melted water snow goes as snow of plants water melted water plant water [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.963 (perp=8.455, rec=0.247, cos=0.025), tot_loss_proj:3.520 [t=0.19s]
prediction: ['[CLS] snow from melted water plants goes several snow into snow water melted water plant water [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.459 (perp=10.146, rec=0.357, cos=0.073), tot_loss_proj:3.865 [t=0.18s]
prediction: ['[CLS] plants water melted some plants goes mostly plants from snow water melted bred plants water [SEP]']
[ 450/2000] tot_loss=2.187 (perp=9.507, rec=0.260, cos=0.026), tot_loss_proj:3.773 [t=0.19s]
prediction: ['[CLS] plants water melted some plants goes more plants from snow water snow bred plants water [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.974 (perp=8.598, rec=0.237, cos=0.018), tot_loss_proj:3.598 [t=0.29s]
prediction: ['[CLS] water snow melted some water goes some plants from snow water snow bred plants water [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.871 (perp=8.016, rec=0.237, cos=0.031), tot_loss_proj:3.487 [t=0.23s]
prediction: ['[CLS] water snow melted some water goes some plants from snow water snow bred water plants [SEP]']
[ 600/2000] tot_loss=1.991 (perp=8.819, rec=0.214, cos=0.014), tot_loss_proj:3.631 [t=0.21s]
prediction: ['[CLS] water snow melted some water goes some for from ground water melted bred water plants [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.973 (perp=8.777, rec=0.205, cos=0.012), tot_loss_proj:3.603 [t=0.26s]
prediction: ['[CLS] water snow melted some the goes some for from ground water bred melted water plants [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.890 (perp=8.407, rec=0.198, cos=0.011), tot_loss_proj:3.529 [t=0.27s]
prediction: ['[CLS] water snow melted some the goes melted for from ground water bred some water plants [SEP]']
[ 750/2000] tot_loss=1.877 (perp=8.407, rec=0.186, cos=0.010), tot_loss_proj:3.533 [t=0.24s]
prediction: ['[CLS] water snow melted some the goes melted for from ground water bred some water plants [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.724 (perp=7.642, rec=0.186, cos=0.010), tot_loss_proj:3.368 [t=0.26s]
prediction: ['[CLS] the snow melted some water goes melted for from ground water bred some water plants [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.726 (perp=7.606, rec=0.191, cos=0.014), tot_loss_proj:3.366 [t=0.27s]
prediction: ['[CLS] the snow melted some water goes for melted from ground water bred some plant plants [SEP]']
[ 900/2000] tot_loss=1.703 (perp=7.606, rec=0.173, cos=0.009), tot_loss_proj:3.366 [t=0.24s]
prediction: ['[CLS] the snow melted some water goes for melted from ground water bred some plant plants [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.695 (perp=7.606, rec=0.166, cos=0.008), tot_loss_proj:3.371 [t=0.19s]
prediction: ['[CLS] the snow melted some water goes for melted from ground water bred some plant plants [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.912 (perp=8.702, rec=0.164, cos=0.008), tot_loss_proj:3.616 [t=0.21s]
prediction: ['[CLS] the snow melted for into goes some melted from ground water bred some plants plants [SEP]']
[1050/2000] tot_loss=1.907 (perp=8.702, rec=0.159, cos=0.008), tot_loss_proj:3.616 [t=0.26s]
prediction: ['[CLS] the snow melted for into goes some melted from ground water bred some plants plants [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.779 (perp=7.568, rec=0.232, cos=0.034), tot_loss_proj:3.451 [t=0.18s]
prediction: ['[CLS] the snow melted for goes water some melted from ground water, some plants plants [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.521 (perp=6.471, rec=0.209, cos=0.018), tot_loss_proj:3.226 [t=0.18s]
prediction: ['[CLS] the snow melted for some water goes melted from ground water, some plants plants [SEP]']
[1200/2000] tot_loss=1.500 (perp=6.471, rec=0.191, cos=0.014), tot_loss_proj:3.223 [t=0.25s]
prediction: ['[CLS] the snow melted for some water goes melted from ground water, some plants plants [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.461 (perp=6.328, rec=0.183, cos=0.013), tot_loss_proj:3.182 [t=0.19s]
prediction: ['[CLS] the snow melted for some water goes melted from ground water plants, some plants [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.428 (perp=6.205, rec=0.175, cos=0.012), tot_loss_proj:3.148 [t=0.19s]
prediction: ['[CLS] the snow melted for some water goes from melted ground water plants, some plants [SEP]']
[1350/2000] tot_loss=1.422 (perp=6.205, rec=0.170, cos=0.011), tot_loss_proj:3.143 [t=0.18s]
prediction: ['[CLS] the snow melted for some water goes from melted ground water plants, some plants [SEP]']
Attempt swap
[1400/2000] tot_loss=1.419 (perp=6.205, rec=0.167, cos=0.011), tot_loss_proj:3.147 [t=0.18s]
prediction: ['[CLS] the snow melted for some water goes from melted ground water plants, some plants [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.398 (perp=6.121, rec=0.163, cos=0.011), tot_loss_proj:3.149 [t=0.19s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
[1500/2000] tot_loss=1.396 (perp=6.121, rec=0.161, cos=0.011), tot_loss_proj:3.154 [t=0.19s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
Attempt swap
[1550/2000] tot_loss=1.387 (perp=6.121, rec=0.153, cos=0.010), tot_loss_proj:3.155 [t=0.18s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
Attempt swap
[1600/2000] tot_loss=1.399 (perp=6.121, rec=0.165, cos=0.010), tot_loss_proj:3.153 [t=0.19s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
[1650/2000] tot_loss=1.389 (perp=6.121, rec=0.155, cos=0.010), tot_loss_proj:3.159 [t=0.18s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
Attempt swap
[1700/2000] tot_loss=1.394 (perp=6.121, rec=0.160, cos=0.010), tot_loss_proj:3.152 [t=0.20s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
Attempt swap
[1750/2000] tot_loss=1.391 (perp=6.121, rec=0.157, cos=0.010), tot_loss_proj:3.155 [t=0.18s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
[1800/2000] tot_loss=1.386 (perp=6.121, rec=0.152, cos=0.009), tot_loss_proj:3.155 [t=0.18s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
Attempt swap
[1850/2000] tot_loss=1.396 (perp=6.121, rec=0.163, cos=0.009), tot_loss_proj:3.151 [t=0.26s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
Attempt swap
[1900/2000] tot_loss=1.384 (perp=6.121, rec=0.150, cos=0.009), tot_loss_proj:3.156 [t=0.18s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
[1950/2000] tot_loss=1.385 (perp=6.121, rec=0.151, cos=0.009), tot_loss_proj:3.156 [t=0.18s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
Attempt swap
[2000/2000] tot_loss=1.391 (perp=6.121, rec=0.157, cos=0.009), tot_loss_proj:3.151 [t=0.18s]
prediction: ['[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]
========================
predicted: 
========================
[CLS] the snow melted for some water melted goes from ground water plants, some plants [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 6.667 | p: 6.667 | r: 6.667
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 81.667

[Aggregate metrics]:
rouge1     | fm: 74.730 | p: 75.031 | r: 74.755
rouge2     | fm: 36.300 | p: 36.405 | r: 36.267
rougeL     | fm: 64.917 | p: 65.192 | r: 64.848
rougeLsum  | fm: 64.645 | p: 65.037 | r: 64.631
r1fm+r2fm = 111.030

input #31 time: 0:08:20 | total time: 4:23:30


Running input #32 of 100.
reference: 
========================
Bob is very serious about Mary, but less so than Paul.
========================
average of cosine similarity 0.9993563156377977
highest_index [0]
highest [0.9993563156377977]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[ 101, 3960, 2003, 2200, 3809, 2055, 2984, 1010, 2021, 2625, 2061, 2084,
         2703, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bob is very serious about mary, but less so than paul. [SEP]']
[Init] best rec loss: 0.9588392376899719 for ['[CLS] archery dual„ pam an arrows kings beyond if rev up place behind [SEP]']
[Init] best rec loss: 0.9246671795845032 for ['[CLS] minnesota greeceignantach supplied process + after atletico memorialpee degrees blur [SEP]']
[Init] best rec loss: 0.9175419211387634 for ['[CLS] transitium through comeedd im slaughtered sympathy opening as directorcu hint [SEP]']
[Init] best rec loss: 0.9033082127571106 for ['[CLS] records copy middle sr ( partly challenged skin dowager must warner with pick [SEP]']
[Init] best rec loss: 0.900634765625 for ['[CLS] spikeen august but collaboration golf age howlage giro inflation etched form [SEP]']
[Init] best rec loss: 0.8903785347938538 for ['[CLS] inactive chip wantedwaterville career twenties shear reign janeiroable shame floor [SEP]']
[Init] best rec loss: 0.8777366280555725 for ['[CLS] arts hardly labor hi nosestage it what short balloonab champion nightmares [SEP]']
[Init] best rec loss: 0.876878559589386 for ['[CLS] missed ev talon hope thinking white g producerator practice well overly it [SEP]']
[Init] best perm rec loss: 0.876000702381134 for ['[CLS] missed producer practice thinking white hope g wellator it overly ev talon [SEP]']
[Init] best perm rec loss: 0.874030590057373 for ['[CLS] producer talon overlyator it g practice well hope white ev thinking missed [SEP]']
[Init] best perm rec loss: 0.873460054397583 for ['[CLS] g hope missed white overly talon practiceator ev thinking it well producer [SEP]']
[Init] best perm rec loss: 0.8725891709327698 for ['[CLS] well whiteator thinking talon hope missed practice overly g it ev producer [SEP]']
[Init] best perm rec loss: 0.8714865446090698 for ['[CLS] overlyator it ev thinking producer hope missed g talon practice well white [SEP]']
[Init] best perm rec loss: 0.8703650236129761 for ['[CLS] practice producer missed overly thinking ev talon whiteator hope g it well [SEP]']
[Init] best perm rec loss: 0.8692450523376465 for ['[CLS] missed producer overly evator practice talon hope well white g thinking it [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.584 (perp=12.317, rec=0.605, cos=0.515), tot_loss_proj:4.285 [t=0.19s]
prediction: ['[CLS] located when li communication solidarity monster > exam besides corporationth. his [SEP]']
[ 100/2000] tot_loss=2.460 (perp=9.682, rec=0.420, cos=0.104), tot_loss_proj:3.736 [t=0.23s]
prediction: ['[CLS] more paul very pact rod mary is bubble through so there., [SEP]']
[ 150/2000] tot_loss=2.223 (perp=9.561, rec=0.290, cos=0.020), tot_loss_proj:3.686 [t=0.18s]
prediction: ['[CLS] less paul very serious about mary is exam despite so there., [SEP]']
[ 200/2000] tot_loss=2.076 (perp=9.312, rec=0.204, cos=0.009), tot_loss_proj:3.676 [t=0.18s]
prediction: ['[CLS] bob paul very serious about mary is attempt but so there., [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.132 (perp=9.497, rec=0.215, cos=0.018), tot_loss_proj:3.882 [t=0.19s]
prediction: ['[CLS] bob deeply very serious about mary paulestinal but so.. of [SEP]']
[ 300/2000] tot_loss=2.098 (perp=9.691, rec=0.152, cos=0.007), tot_loss_proj:3.895 [t=0.27s]
prediction: ['[CLS] bob ha very serious about mary paulestinal but so so., [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.776 (perp=8.171, rec=0.135, cos=0.006), tot_loss_proj:3.530 [t=0.24s]
prediction: ['[CLS] bob ha is serious about mary paul so but soestinal., [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.771 (perp=8.171, rec=0.130, cos=0.006), tot_loss_proj:3.530 [t=0.18s]
prediction: ['[CLS] bob ha is serious about mary paul so but soestinal., [SEP]']
[ 450/2000] tot_loss=1.658 (perp=7.657, rec=0.121, cos=0.006), tot_loss_proj:3.475 [t=0.20s]
prediction: ['[CLS] bob ha is serious about mary paul so but so badly., [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.660 (perp=7.657, rec=0.123, cos=0.005), tot_loss_proj:3.477 [t=0.18s]
prediction: ['[CLS] bob ha is serious about mary paul so but so badly., [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.839 (perp=8.442, rec=0.140, cos=0.010), tot_loss_proj:3.563 [t=0.24s]
prediction: ['[CLS] bob ha is serious about mary paul, but thanestinal. less [SEP]']
[ 600/2000] tot_loss=1.820 (perp=8.442, rec=0.125, cos=0.006), tot_loss_proj:3.534 [t=0.18s]
prediction: ['[CLS] bob ha is serious about mary paul, but thanestinal. less [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.650 (perp=7.676, rec=0.109, cos=0.005), tot_loss_proj:3.407 [t=0.21s]
prediction: ['[CLS] bob ha is serious about mary paul, but than badly less. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.645 (perp=7.631, rec=0.113, cos=0.005), tot_loss_proj:3.419 [t=0.25s]
prediction: ['[CLS] bob is ha serious about mary paul, but than badly less. [SEP]']
[ 750/2000] tot_loss=1.646 (perp=7.631, rec=0.115, cos=0.005), tot_loss_proj:3.420 [t=0.19s]
prediction: ['[CLS] bob is ha serious about mary paul, but than badly less. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.418 (perp=6.493, rec=0.114, cos=0.006), tot_loss_proj:3.257 [t=0.21s]
prediction: ['[CLS] bob is ha serious about mary paul, but less than badly. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.410 (perp=6.493, rec=0.107, cos=0.005), tot_loss_proj:3.264 [t=0.24s]
prediction: ['[CLS] bob is ha serious about mary paul, but less than badly. [SEP]']
[ 900/2000] tot_loss=1.407 (perp=6.493, rec=0.104, cos=0.004), tot_loss_proj:3.258 [t=0.22s]
prediction: ['[CLS] bob is ha serious about mary paul, but less than badly. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.410 (perp=6.493, rec=0.107, cos=0.004), tot_loss_proj:3.256 [t=0.18s]
prediction: ['[CLS] bob is ha serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.401 (perp=6.493, rec=0.098, cos=0.004), tot_loss_proj:3.262 [t=0.20s]
prediction: ['[CLS] bob is ha serious about mary paul, but less than badly. [SEP]']
[1050/2000] tot_loss=1.399 (perp=6.493, rec=0.096, cos=0.004), tot_loss_proj:3.255 [t=0.27s]
prediction: ['[CLS] bob is ha serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.270 (perp=5.781, rec=0.110, cos=0.004), tot_loss_proj:2.372 [t=0.26s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.267 (perp=5.781, rec=0.106, cos=0.004), tot_loss_proj:2.373 [t=0.21s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
[1200/2000] tot_loss=1.264 (perp=5.781, rec=0.104, cos=0.004), tot_loss_proj:2.366 [t=0.18s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.268 (perp=5.781, rec=0.108, cos=0.004), tot_loss_proj:2.372 [t=0.17s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.267 (perp=5.781, rec=0.107, cos=0.004), tot_loss_proj:2.369 [t=0.23s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
[1350/2000] tot_loss=1.257 (perp=5.781, rec=0.097, cos=0.004), tot_loss_proj:2.372 [t=0.18s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.265 (perp=5.781, rec=0.105, cos=0.004), tot_loss_proj:2.367 [t=0.18s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.256 (perp=5.781, rec=0.096, cos=0.004), tot_loss_proj:2.365 [t=0.19s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
[1500/2000] tot_loss=1.269 (perp=5.781, rec=0.109, cos=0.004), tot_loss_proj:2.372 [t=0.18s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.252 (perp=5.781, rec=0.092, cos=0.004), tot_loss_proj:2.373 [t=0.18s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.258 (perp=5.781, rec=0.098, cos=0.004), tot_loss_proj:2.369 [t=0.18s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
[1650/2000] tot_loss=1.262 (perp=5.781, rec=0.102, cos=0.004), tot_loss_proj:2.366 [t=0.25s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.256 (perp=5.781, rec=0.096, cos=0.004), tot_loss_proj:2.369 [t=0.17s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.250 (perp=5.781, rec=0.090, cos=0.004), tot_loss_proj:2.372 [t=0.21s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
[1800/2000] tot_loss=1.246 (perp=5.781, rec=0.087, cos=0.003), tot_loss_proj:2.374 [t=0.17s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.262 (perp=5.781, rec=0.102, cos=0.003), tot_loss_proj:2.376 [t=0.25s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.256 (perp=5.781, rec=0.096, cos=0.003), tot_loss_proj:2.369 [t=0.22s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
[1950/2000] tot_loss=1.245 (perp=5.781, rec=0.085, cos=0.003), tot_loss_proj:2.377 [t=0.18s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.250 (perp=5.781, rec=0.091, cos=0.003), tot_loss_proj:2.370 [t=0.25s]
prediction: ['[CLS] bob is very serious about mary paul, but less than badly. [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] bob is very serious about mary, but less so than paul. [SEP]
========================
predicted: 
========================
[CLS] bob is very serious about mary paul, but less than badly. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 58.333 | p: 58.333 | r: 58.333
rougeL     | fm: 84.615 | p: 84.615 | r: 84.615
rougeLsum  | fm: 84.615 | p: 84.615 | r: 84.615
r1fm+r2fm = 150.641

[Aggregate metrics]:
rouge1     | fm: 75.361 | p: 75.730 | r: 75.254
rouge2     | fm: 36.998 | p: 37.029 | r: 37.069
rougeL     | fm: 65.545 | p: 65.766 | r: 65.509
rougeLsum  | fm: 65.554 | p: 65.790 | r: 65.437
r1fm+r2fm = 112.359

input #32 time: 0:08:11 | total time: 4:31:42


Running input #33 of 100.
reference: 
========================
Ayala sent the diamond necklace back.
========================
average of cosine similarity 0.9993190743310343
highest_index [0]
highest [0.9993190743310343]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  1996,  6323, 13016,  2067,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] ayala sent the diamond necklace back. [SEP]']
[Init] best rec loss: 1.0263526439666748 for ['[CLS] terms primary contribution an soil all competition dug [SEP]']
[Init] best rec loss: 0.9502540230751038 for ['[CLS] militiaiom slim lei daryl dip bay well [SEP]']
[Init] best rec loss: 0.9274391531944275 for ['[CLS] langley 9 shoe soon tray originally ha inclined [SEP]']
[Init] best rec loss: 0.9139430522918701 for ['[CLS] strikingenberg online poland silver through proper comfort [SEP]']
[Init] best rec loss: 0.913354754447937 for ['[CLS] dante railroad stage headeddictz prostate abby [SEP]']
[Init] best perm rec loss: 0.912300705909729 for ['[CLS] railroad headedzdict abby dante stage prostate [SEP]']
[Init] best perm rec loss: 0.9117847084999084 for ['[CLS] railroadz abby dante headed prostate stagedict [SEP]']
[Init] best perm rec loss: 0.9092954993247986 for ['[CLS] dantez prostatedict railroad headed stage abby [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.257 (perp=12.899, rec=0.470, cos=0.207), tot_loss_proj:4.568 [t=0.25s]
prediction: ['[CLS] thomas escort enoughyala teams cheshire villa canton [SEP]']
[ 100/2000] tot_loss=2.446 (perp=10.704, rec=0.274, cos=0.031), tot_loss_proj:4.091 [t=0.27s]
prediction: ['[CLS] thomas necklace ayalayala sent diamondyala [SEP]']
[ 150/2000] tot_loss=2.383 (perp=10.982, rec=0.171, cos=0.016), tot_loss_proj:4.256 [t=0.18s]
prediction: ['[CLS] a necklace ayalayala sent diamondyala [SEP]']
[ 200/2000] tot_loss=2.167 (perp=10.187, rec=0.121, cos=0.009), tot_loss_proj:4.044 [t=0.23s]
prediction: ['[CLS] a necklace theyalayala sent backyala [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.848 (perp=8.660, rec=0.107, cos=0.008), tot_loss_proj:3.588 [t=0.23s]
prediction: ['[CLS] ayala theyala necklace sent backyala [SEP]']
[ 300/2000] tot_loss=1.858 (perp=8.811, rec=0.089, cos=0.007), tot_loss_proj:3.722 [t=0.22s]
prediction: ['[CLS] ayala theyala necklace sent back diamond [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.857 (perp=8.811, rec=0.088, cos=0.006), tot_loss_proj:3.721 [t=0.20s]
prediction: ['[CLS] ayala theyala necklace sent back diamond [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.861 (perp=8.811, rec=0.093, cos=0.006), tot_loss_proj:3.728 [t=0.19s]
prediction: ['[CLS] ayala theyala necklace sent back diamond [SEP]']
[ 450/2000] tot_loss=1.859 (perp=8.811, rec=0.091, cos=0.006), tot_loss_proj:3.732 [t=0.25s]
prediction: ['[CLS] ayala theyala necklace sent back diamond [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.779 (perp=8.419, rec=0.089, cos=0.006), tot_loss_proj:3.746 [t=0.18s]
prediction: ['[CLS] ayala theyala diamond necklace sent back [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.781 (perp=8.419, rec=0.092, cos=0.006), tot_loss_proj:3.749 [t=0.23s]
prediction: ['[CLS] ayala theyala diamond necklace sent back [SEP]']
[ 600/2000] tot_loss=1.772 (perp=8.384, rec=0.089, cos=0.006), tot_loss_proj:3.853 [t=0.19s]
prediction: ['[CLS] a diamond theyala diamond necklace sent back [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.766 (perp=8.384, rec=0.084, cos=0.006), tot_loss_proj:3.852 [t=0.18s]
prediction: ['[CLS] a diamond theyala diamond necklace sent back [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.773 (perp=8.419, rec=0.084, cos=0.005), tot_loss_proj:3.751 [t=0.19s]
prediction: ['[CLS] ayala theyala diamond necklace sent back [SEP]']
[ 750/2000] tot_loss=1.762 (perp=8.419, rec=0.073, cos=0.005), tot_loss_proj:3.755 [t=0.20s]
prediction: ['[CLS] ayala theyala diamond necklace sent back [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.646 (perp=7.799, rec=0.081, cos=0.005), tot_loss_proj:3.641 [t=0.18s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.638 (perp=7.799, rec=0.073, cos=0.005), tot_loss_proj:3.638 [t=0.25s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
[ 900/2000] tot_loss=1.639 (perp=7.799, rec=0.075, cos=0.005), tot_loss_proj:3.640 [t=0.26s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.643 (perp=7.799, rec=0.079, cos=0.005), tot_loss_proj:3.637 [t=0.19s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1000/2000] tot_loss=1.638 (perp=7.799, rec=0.073, cos=0.005), tot_loss_proj:3.641 [t=0.18s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
[1050/2000] tot_loss=1.641 (perp=7.799, rec=0.076, cos=0.005), tot_loss_proj:3.637 [t=0.26s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1100/2000] tot_loss=1.638 (perp=7.799, rec=0.073, cos=0.005), tot_loss_proj:3.641 [t=0.27s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1150/2000] tot_loss=1.631 (perp=7.799, rec=0.067, cos=0.005), tot_loss_proj:3.642 [t=0.27s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
[1200/2000] tot_loss=1.638 (perp=7.799, rec=0.074, cos=0.004), tot_loss_proj:3.638 [t=0.29s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1250/2000] tot_loss=1.639 (perp=7.799, rec=0.074, cos=0.004), tot_loss_proj:3.639 [t=0.18s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1300/2000] tot_loss=1.634 (perp=7.799, rec=0.070, cos=0.004), tot_loss_proj:3.637 [t=0.19s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
[1350/2000] tot_loss=1.642 (perp=7.799, rec=0.078, cos=0.004), tot_loss_proj:3.639 [t=0.18s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1400/2000] tot_loss=1.638 (perp=7.799, rec=0.074, cos=0.004), tot_loss_proj:3.637 [t=0.18s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1450/2000] tot_loss=1.636 (perp=7.799, rec=0.072, cos=0.004), tot_loss_proj:3.640 [t=0.21s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
[1500/2000] tot_loss=1.633 (perp=7.799, rec=0.069, cos=0.004), tot_loss_proj:3.643 [t=0.20s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1550/2000] tot_loss=1.639 (perp=7.799, rec=0.075, cos=0.004), tot_loss_proj:3.638 [t=0.19s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1600/2000] tot_loss=1.641 (perp=7.799, rec=0.078, cos=0.004), tot_loss_proj:3.630 [t=0.18s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
[1650/2000] tot_loss=1.630 (perp=7.799, rec=0.066, cos=0.004), tot_loss_proj:3.639 [t=0.24s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1700/2000] tot_loss=1.632 (perp=7.799, rec=0.069, cos=0.004), tot_loss_proj:3.632 [t=0.18s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1750/2000] tot_loss=1.635 (perp=7.799, rec=0.071, cos=0.004), tot_loss_proj:3.636 [t=0.18s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
[1800/2000] tot_loss=1.637 (perp=7.799, rec=0.073, cos=0.004), tot_loss_proj:3.640 [t=0.24s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1850/2000] tot_loss=1.640 (perp=7.799, rec=0.076, cos=0.004), tot_loss_proj:3.633 [t=0.23s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[1900/2000] tot_loss=1.633 (perp=7.799, rec=0.069, cos=0.004), tot_loss_proj:3.635 [t=0.22s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
[1950/2000] tot_loss=1.632 (perp=7.799, rec=0.068, cos=0.004), tot_loss_proj:3.635 [t=0.20s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Attempt swap
[2000/2000] tot_loss=1.638 (perp=7.799, rec=0.074, cos=0.004), tot_loss_proj:3.630 [t=0.18s]
prediction: ['[CLS] a. theyala diamond necklace sent back [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] ayala sent the diamond necklace back. [SEP]
========================
predicted: 
========================
[CLS] a. theyala diamond necklace sent back [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 103.571

[Aggregate metrics]:
rouge1     | fm: 75.474 | p: 75.837 | r: 75.413
rouge2     | fm: 36.846 | p: 36.889 | r: 36.907
rougeL     | fm: 65.312 | p: 65.530 | r: 65.125
rougeLsum  | fm: 65.481 | p: 65.834 | r: 65.417
r1fm+r2fm = 112.321

input #33 time: 0:08:18 | total time: 4:40:00


Running input #34 of 100.
reference: 
========================
Jessica sprayed paint under the table.
========================
average of cosine similarity 0.9993079982050085
highest_index [0]
highest [0.9993079982050085]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  8201, 25401,  6773,  2104,  1996,  2795,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] jessica sprayed paint under the table. [SEP]']
[Init] best rec loss: 0.9414330720901489 for ['[CLS] solvent pure sitting returns open penelope gerais [SEP]']
[Init] best rec loss: 0.9049432277679443 for ['[CLS]vision best te sided ms lowest elected [SEP]']
[Init] best rec loss: 0.899651825428009 for ['[CLS]iating achievement tablet navy raaf commissionvet [SEP]']
[Init] best rec loss: 0.8826460838317871 for ['[CLS]ter & since cureraßeeratednes [SEP]']
[Init] best perm rec loss: 0.8818284273147583 for ['[CLS]nes cure &terraßeerated since [SEP]']
[Init] best perm rec loss: 0.8814307451248169 for ['[CLS] sinceerated cureraßeter &nes [SEP]']
[Init] best perm rec loss: 0.8780422210693359 for ['[CLS]eratedterraße & curenes since [SEP]']
[Init] best perm rec loss: 0.8755910396575928 for ['[CLS]tererated &nes cure sinceraße [SEP]']
[Init] best perm rec loss: 0.8677996397018433 for ['[CLS]raßeter &nes cureerated since [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.241 (perp=13.000, rec=0.645, cos=0.996), tot_loss_proj:4.331 [t=0.22s]
prediction: ['[CLS] haleykson starred appearances. girlfriendshire [SEP]']
[ 100/2000] tot_loss=2.898 (perp=12.212, rec=0.364, cos=0.092), tot_loss_proj:4.186 [t=0.21s]
prediction: ['[CLS]ergy tread starred won. jessica slumped [SEP]']
[ 150/2000] tot_loss=2.825 (perp=13.065, rec=0.195, cos=0.017), tot_loss_proj:4.643 [t=0.18s]
prediction: ['[CLS] sprayed paint sprayed painter. jessica resisted [SEP]']
[ 200/2000] tot_loss=2.547 (perp=11.999, rec=0.135, cos=0.012), tot_loss_proj:4.295 [t=0.27s]
prediction: ['[CLS] sprayed sprayed sprayed paint. jessica table [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.197 (perp=10.372, rec=0.114, cos=0.009), tot_loss_proj:4.173 [t=0.19s]
prediction: ['[CLS] jessica sprayed sprayed paint under sprayed table [SEP]']
[ 300/2000] tot_loss=2.179 (perp=10.350, rec=0.102, cos=0.006), tot_loss_proj:3.977 [t=0.19s]
prediction: ['[CLS] jessica sprayed sprayed paint under paint table [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.019 (perp=9.585, rec=0.096, cos=0.006), tot_loss_proj:3.930 [t=0.18s]
prediction: ['[CLS] jessica sprayed sprayed paint under table paint [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.069 (perp=9.907, rec=0.082, cos=0.006), tot_loss_proj:3.885 [t=0.21s]
prediction: ['[CLS] jessica softly sprayed paint under table paint [SEP]']
[ 450/2000] tot_loss=2.081 (perp=9.907, rec=0.093, cos=0.006), tot_loss_proj:3.885 [t=0.19s]
prediction: ['[CLS] jessica softly sprayed paint under table paint [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.119 (perp=10.155, rec=0.083, cos=0.006), tot_loss_proj:4.033 [t=0.18s]
prediction: ['[CLS] jessica under sprayed paint under table paint [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.017 (perp=9.618, rec=0.086, cos=0.007), tot_loss_proj:2.690 [t=0.24s]
prediction: ['[CLS] jessica sprayed badminton paint under table paint [SEP]']
[ 600/2000] tot_loss=1.972 (perp=9.415, rec=0.083, cos=0.006), tot_loss_proj:3.855 [t=0.18s]
prediction: ['[CLS] jessica sprayed under paint under table paint [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.977 (perp=9.415, rec=0.088, cos=0.006), tot_loss_proj:3.855 [t=0.22s]
prediction: ['[CLS] jessica sprayed under paint under table paint [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.726 (perp=8.091, rec=0.102, cos=0.006), tot_loss_proj:3.458 [t=0.19s]
prediction: ['[CLS] under jessica sprayed paint under table. [SEP]']
[ 750/2000] tot_loss=1.718 (perp=8.091, rec=0.094, cos=0.006), tot_loss_proj:3.461 [t=0.18s]
prediction: ['[CLS] under jessica sprayed paint under table. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.680 (perp=7.903, rec=0.094, cos=0.005), tot_loss_proj:3.362 [t=0.24s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.668 (perp=7.903, rec=0.083, cos=0.005), tot_loss_proj:3.365 [t=0.26s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
[ 900/2000] tot_loss=1.668 (perp=7.903, rec=0.082, cos=0.005), tot_loss_proj:3.366 [t=0.18s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.673 (perp=7.903, rec=0.088, cos=0.005), tot_loss_proj:3.368 [t=0.25s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.670 (perp=7.903, rec=0.085, cos=0.005), tot_loss_proj:3.363 [t=0.20s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
[1050/2000] tot_loss=1.674 (perp=7.903, rec=0.089, cos=0.005), tot_loss_proj:3.361 [t=0.18s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.672 (perp=7.903, rec=0.086, cos=0.005), tot_loss_proj:3.362 [t=0.18s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.662 (perp=7.903, rec=0.077, cos=0.005), tot_loss_proj:3.367 [t=0.24s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
[1200/2000] tot_loss=1.691 (perp=7.903, rec=0.106, cos=0.005), tot_loss_proj:3.364 [t=0.19s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.665 (perp=7.903, rec=0.081, cos=0.004), tot_loss_proj:3.368 [t=0.23s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.662 (perp=7.903, rec=0.077, cos=0.004), tot_loss_proj:3.361 [t=0.18s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
[1350/2000] tot_loss=1.670 (perp=7.903, rec=0.085, cos=0.004), tot_loss_proj:3.366 [t=0.19s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.660 (perp=7.903, rec=0.075, cos=0.004), tot_loss_proj:3.365 [t=0.18s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.667 (perp=7.903, rec=0.082, cos=0.004), tot_loss_proj:3.364 [t=0.18s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
[1500/2000] tot_loss=1.677 (perp=7.903, rec=0.092, cos=0.004), tot_loss_proj:3.368 [t=0.24s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.670 (perp=7.903, rec=0.085, cos=0.004), tot_loss_proj:3.369 [t=0.19s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.677 (perp=7.903, rec=0.092, cos=0.004), tot_loss_proj:3.368 [t=0.25s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
[1650/2000] tot_loss=1.666 (perp=7.903, rec=0.081, cos=0.004), tot_loss_proj:3.362 [t=0.20s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.660 (perp=7.903, rec=0.075, cos=0.004), tot_loss_proj:3.364 [t=0.26s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.658 (perp=7.903, rec=0.073, cos=0.004), tot_loss_proj:3.364 [t=0.26s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
[1800/2000] tot_loss=1.667 (perp=7.903, rec=0.082, cos=0.004), tot_loss_proj:3.362 [t=0.25s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.658 (perp=7.903, rec=0.073, cos=0.004), tot_loss_proj:3.366 [t=0.18s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.668 (perp=7.903, rec=0.083, cos=0.004), tot_loss_proj:3.371 [t=0.22s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
[1950/2000] tot_loss=1.660 (perp=7.903, rec=0.075, cos=0.004), tot_loss_proj:3.362 [t=0.19s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.664 (perp=7.903, rec=0.079, cos=0.004), tot_loss_proj:3.370 [t=0.17s]
prediction: ['[CLS] under jessica sprayed under table paint. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] jessica sprayed paint under the table. [SEP]
========================
predicted: 
========================
[CLS] under jessica sprayed under table paint. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 101.786

[Aggregate metrics]:
rouge1     | fm: 75.601 | p: 75.949 | r: 75.532
rouge2     | fm: 36.143 | p: 36.218 | r: 36.197
rougeL     | fm: 65.717 | p: 65.900 | r: 65.592
rougeLsum  | fm: 65.805 | p: 66.032 | r: 65.710
r1fm+r2fm = 111.744

input #34 time: 0:08:08 | total time: 4:48:08


Running input #35 of 100.
reference: 
========================
John is refused.
========================
average of cosine similarity 0.9992893523444286
highest_index [0]
highest [0.9992893523444286]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2198, 2003, 4188, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is refused. [SEP]']
[Init] best rec loss: 0.9893831610679626 for ['[CLS] hugo cruise than seconds [SEP]']
[Init] best rec loss: 0.9861062169075012 for ['[CLS] painful friendly reputation popularity [SEP]']
[Init] best rec loss: 0.8789446949958801 for ['[CLS] wings property warned wish [SEP]']
[Init] best rec loss: 0.8721048831939697 for ['[CLS] community evenly development appealed [SEP]']
[Init] best rec loss: 0.8641420006752014 for ['[CLS]estinal atanger toilet [SEP]']
[Init] best perm rec loss: 0.8629884719848633 for ['[CLS] toiletanger atestinal [SEP]']
[Init] best perm rec loss: 0.8620949983596802 for ['[CLS] toiletestinalanger at [SEP]']
[Init] best perm rec loss: 0.861962616443634 for ['[CLS]estinalanger toilet at [SEP]']
[Init] best perm rec loss: 0.8614445924758911 for ['[CLS] atestinalanger toilet [SEP]']
[Init] best perm rec loss: 0.8610238432884216 for ['[CLS] atanger toiletestinal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.783 (perp=12.380, rec=0.596, cos=0.711), tot_loss_proj:4.394 [t=0.25s]
prediction: ['[CLS]. sultan now member [SEP]']
[ 100/2000] tot_loss=2.708 (perp=11.459, rec=0.357, cos=0.060), tot_loss_proj:4.143 [t=0.27s]
prediction: ['[CLS] is refused refused refused [SEP]']
[ 150/2000] tot_loss=2.410 (perp=8.902, rec=0.459, cos=0.171), tot_loss_proj:3.596 [t=0.18s]
prediction: ['[CLS] is john is refused [SEP]']
[ 200/2000] tot_loss=1.869 (perp=8.257, rec=0.198, cos=0.020), tot_loss_proj:3.305 [t=0.20s]
prediction: ['[CLS]. john is refused [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.504 (perp=6.834, rec=0.130, cos=0.007), tot_loss_proj:1.512 [t=0.21s]
prediction: ['[CLS] john is refused. [SEP]']
[ 300/2000] tot_loss=1.460 (perp=6.834, rec=0.090, cos=0.003), tot_loss_proj:1.507 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.444 (perp=6.834, rec=0.075, cos=0.002), tot_loss_proj:1.513 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.439 (perp=6.834, rec=0.071, cos=0.002), tot_loss_proj:1.511 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
[ 450/2000] tot_loss=1.437 (perp=6.834, rec=0.068, cos=0.001), tot_loss_proj:1.511 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.424 (perp=6.834, rec=0.055, cos=0.001), tot_loss_proj:1.513 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.430 (perp=6.834, rec=0.061, cos=0.001), tot_loss_proj:1.505 [t=0.21s]
prediction: ['[CLS] john is refused. [SEP]']
[ 600/2000] tot_loss=1.425 (perp=6.834, rec=0.057, cos=0.001), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.420 (perp=6.834, rec=0.052, cos=0.001), tot_loss_proj:1.515 [t=0.19s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.432 (perp=6.834, rec=0.063, cos=0.001), tot_loss_proj:1.502 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
[ 750/2000] tot_loss=1.432 (perp=6.834, rec=0.063, cos=0.001), tot_loss_proj:1.501 [t=0.19s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.428 (perp=6.834, rec=0.060, cos=0.001), tot_loss_proj:1.509 [t=0.29s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.429 (perp=6.834, rec=0.061, cos=0.001), tot_loss_proj:1.509 [t=0.27s]
prediction: ['[CLS] john is refused. [SEP]']
[ 900/2000] tot_loss=1.435 (perp=6.834, rec=0.067, cos=0.001), tot_loss_proj:1.517 [t=0.19s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.428 (perp=6.834, rec=0.059, cos=0.001), tot_loss_proj:1.525 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.435 (perp=6.834, rec=0.066, cos=0.001), tot_loss_proj:1.509 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
[1050/2000] tot_loss=1.434 (perp=6.834, rec=0.066, cos=0.001), tot_loss_proj:1.510 [t=0.19s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.427 (perp=6.834, rec=0.059, cos=0.001), tot_loss_proj:1.506 [t=0.20s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.425 (perp=6.834, rec=0.057, cos=0.001), tot_loss_proj:1.511 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
[1200/2000] tot_loss=1.430 (perp=6.834, rec=0.062, cos=0.001), tot_loss_proj:1.503 [t=0.24s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.423 (perp=6.834, rec=0.055, cos=0.001), tot_loss_proj:1.499 [t=0.30s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.436 (perp=6.834, rec=0.068, cos=0.001), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[1350/2000] tot_loss=1.419 (perp=6.834, rec=0.051, cos=0.001), tot_loss_proj:1.510 [t=0.24s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.434 (perp=6.834, rec=0.066, cos=0.001), tot_loss_proj:1.513 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.435 (perp=6.834, rec=0.067, cos=0.001), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[1500/2000] tot_loss=1.433 (perp=6.834, rec=0.065, cos=0.001), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.427 (perp=6.834, rec=0.059, cos=0.001), tot_loss_proj:1.512 [t=0.30s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.430 (perp=6.834, rec=0.062, cos=0.001), tot_loss_proj:1.513 [t=0.25s]
prediction: ['[CLS] john is refused. [SEP]']
[1650/2000] tot_loss=1.431 (perp=6.834, rec=0.063, cos=0.001), tot_loss_proj:1.500 [t=0.24s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.432 (perp=6.834, rec=0.064, cos=0.001), tot_loss_proj:1.508 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.426 (perp=6.834, rec=0.058, cos=0.001), tot_loss_proj:1.498 [t=0.21s]
prediction: ['[CLS] john is refused. [SEP]']
[1800/2000] tot_loss=1.425 (perp=6.834, rec=0.056, cos=0.001), tot_loss_proj:1.518 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.420 (perp=6.834, rec=0.052, cos=0.001), tot_loss_proj:1.506 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.432 (perp=6.834, rec=0.064, cos=0.001), tot_loss_proj:1.496 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
[1950/2000] tot_loss=1.428 (perp=6.834, rec=0.060, cos=0.001), tot_loss_proj:1.519 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.434 (perp=6.834, rec=0.066, cos=0.001), tot_loss_proj:1.506 [t=0.25s]
prediction: ['[CLS] john is refused. [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] john is refused. [SEP]
========================
predicted: 
========================
[CLS] john is refused. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 76.279 | p: 76.681 | r: 76.170
rouge2     | fm: 38.095 | p: 38.033 | r: 38.162
rougeL     | fm: 66.512 | p: 66.860 | r: 66.453
rougeLsum  | fm: 66.737 | p: 67.095 | r: 66.715
r1fm+r2fm = 114.373

input #35 time: 0:08:07 | total time: 4:56:15


Running input #36 of 100.
reference: 
========================
This information could have been released by Gorbachev, but he chose not to.
========================
average of cosine similarity 0.999461896585002
highest_index [0]
highest [0.999461896585002]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[  101,  2023,  2592,  2071,  2031,  2042,  2207,  2011,  2175, 28483,
         16179,  1010,  2021,  2002,  4900,  2025,  2000,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]']
[Init] best rec loss: 0.9475834369659424 for ['[CLS] actually joseph sofia sas colt late sketch sensefixed skate shaved clerical period huis powers news [SEP]']
[Init] best rec loss: 0.9407480359077454 for ['[CLS] gottfried cause credit family manufacturing assent active peek what conscious [ jurisdiction ch high porter tomashein [SEP]']
[Init] best rec loss: 0.9353086352348328 for ['[CLS] whenpressed pain must battled spyvu kilometres 10 term & enough bell each bandwidthdly design [SEP]']
[Init] best rec loss: 0.8846843242645264 for ['[CLS] penny quartersrim however reliefly supreme grant which departure mortar oak black touch apex golden ruling [SEP]']
[Init] best perm rec loss: 0.8831620812416077 for ['[CLS] departure which supreme touch grantrim apex relief penny mortar golden oak blackly ruling however quarters [SEP]']
[Init] best perm rec loss: 0.8824912905693054 for ['[CLS] mortar grant goldenrim which touch black ruling apexly oak supreme however quarters penny relief departure [SEP]']
[Init] best perm rec loss: 0.8821429014205933 for ['[CLS] grant which penny however apex departure oak touch black ruling mortar goldenrim quarters relief supremely [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.198 (perp=13.114, rec=0.579, cos=0.996), tot_loss_proj:4.430 [t=0.18s]
prediction: ['[CLS] far rubbed balloon but sit seemed cds seemed immediately said upon und ass adobeplicity giovanni anybody [SEP]']
[ 100/2000] tot_loss=4.253 (perp=13.795, rec=0.497, cos=0.997), tot_loss_proj:4.525 [t=0.24s]
prediction: ['[CLS] farungenchev but honored became int charges injury noticed ; criticizedrba balladtablished taxpayer 2018 [SEP]']
[ 150/2000] tot_loss=4.110 (perp=13.293, rec=0.453, cos=0.998), tot_loss_proj:4.494 [t=0.18s]
prediction: ['[CLS] anyungenchev andᆫ unfortunately int wanted injury always. criticizedrba informationbasket taxpayer bradley [SEP]']
[ 200/2000] tot_loss=4.106 (perp=13.425, rec=0.422, cos=0.998), tot_loss_proj:4.549 [t=0.25s]
prediction: ['[CLS] mor replacechev and arrest equally int wanted usually def. criticizedrba informationbasket leone bradley [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=4.102 (perp=13.466, rec=0.412, cos=0.997), tot_loss_proj:4.502 [t=0.26s]
prediction: ['[CLS] phi occurschev chose arrest equally informationesoncam did.ginglyrba informationbasket attache webster [SEP]']
[ 300/2000] tot_loss=4.067 (perp=13.444, rec=0.380, cos=0.998), tot_loss_proj:4.488 [t=0.22s]
prediction: ['[CLS] because occurschev chose arrest equally information optcam chose.ginglyrba informationudence attache webster [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.963 (perp=12.842, rec=0.394, cos=1.000), tot_loss_proj:4.399 [t=0.18s]
prediction: ['[CLS] because occurschev chose arrest equally information revenge excuse chose, usuallyrba informationudence attache webster [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.964 (perp=12.877, rec=0.390, cos=0.998), tot_loss_proj:4.374 [t=0.19s]
prediction: ['[CLS] becauserbachev picked album equally information revenge honorable chose,yme occurs informationudence attache webster [SEP]']
[ 450/2000] tot_loss=3.922 (perp=12.843, rec=0.354, cos=0.999), tot_loss_proj:4.423 [t=0.24s]
prediction: ['[CLS] becauserbachev picked arrest definitely information revenge der chose,ona occurred informationudence attache webster [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.959 (perp=12.979, rec=0.365, cos=0.998), tot_loss_proj:4.428 [t=0.19s]
prediction: ['[CLS]antlyrbachev picked end because information revenge der chose,holders occurred informationudence mccoy webster [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.829 (perp=12.330, rec=0.365, cos=0.998), tot_loss_proj:4.222 [t=0.27s]
prediction: ['[CLS] ・rbachev easily go because information revengeantly chose.holders occurred informationudence considerably laurence [SEP]']
[ 600/2000] tot_loss=3.783 (perp=12.189, rec=0.347, cos=0.998), tot_loss_proj:4.217 [t=0.21s]
prediction: ['[CLS] ・rbachev fully go because information revengeantly chose.holders occurred information bastards actually webster [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.720 (perp=11.868, rec=0.349, cos=0.998), tot_loss_proj:4.186 [t=0.18s]
prediction: ['[CLS]tialrbachev easily go because information revengeantly choseholdersignant, information bastards actually laurence [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.603 (perp=11.262, rec=0.352, cos=0.998), tot_loss_proj:4.084 [t=0.19s]
prediction: ['[CLS]tialrbachev easily occurred because information revengeantly choseholders go, information bastards actually laurence [SEP]']
[ 750/2000] tot_loss=3.720 (perp=11.880, rec=0.346, cos=0.998), tot_loss_proj:4.134 [t=0.18s]
prediction: ['[CLS]ginglyrbachev greyhound thereof because information revengeantly choseholders go, information bastards actually laurence [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.751 (perp=12.090, rec=0.335, cos=0.999), tot_loss_proj:4.157 [t=0.19s]
prediction: ['[CLS]ginglyrbachev greyhound thereof because information revenge excuse chose released go, informationander joker could [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.575 (perp=11.092, rec=0.358, cos=0.998), tot_loss_proj:3.944 [t=0.18s]
prediction: ['[CLS]ginglyrbachev chose thereof because information revenge excuse were released go, information chooses actually could [SEP]']
[ 900/2000] tot_loss=3.733 (perp=12.005, rec=0.333, cos=0.999), tot_loss_proj:4.227 [t=0.20s]
prediction: ['[CLS]ginglyrbachev chose thereofsso information revenge customs were released go, information bastards joker could [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=3.510 (perp=10.753, rec=0.361, cos=0.998), tot_loss_proj:3.972 [t=0.24s]
prediction: ['[CLS]ginglyrbachev chose thereof becauseuled customs was information released go, information unsuitablestituting decisions [SEP]']
Attempt swap
[1000/2000] tot_loss=3.480 (perp=10.674, rec=0.347, cos=0.998), tot_loss_proj:3.923 [t=0.18s]
prediction: ['[CLS]ginglyrbachev chose thereof becauseuled customs was information released go, information didnstituting decisions [SEP]']
[1050/2000] tot_loss=3.495 (perp=10.764, rec=0.345, cos=0.998), tot_loss_proj:3.967 [t=0.26s]
prediction: ['[CLS]ginglyrbachev chose thereof becauseuled customs was information released go, informationanderstituting decisions [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.422 (perp=10.467, rec=0.331, cos=0.998), tot_loss_proj:3.919 [t=0.18s]
prediction: ['[CLS]ginglyrbachev chose thereof becauseuled customs information was released go. informationanderstituting decisions [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.214 (perp=9.340, rec=0.348, cos=0.998), tot_loss_proj:3.858 [t=0.23s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedgingly. informationanderstituting decisions [SEP]']
[1200/2000] tot_loss=3.193 (perp=9.340, rec=0.327, cos=0.998), tot_loss_proj:3.859 [t=0.19s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedgingly. informationanderstituting decisions [SEP]']
Attempt swap
[1250/2000] tot_loss=3.318 (perp=9.938, rec=0.333, cos=0.998), tot_loss_proj:3.944 [t=0.25s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedgingly. informationanderachal decisions [SEP]']
Attempt swap
[1300/2000] tot_loss=3.311 (perp=9.938, rec=0.325, cos=0.998), tot_loss_proj:3.947 [t=0.18s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedgingly. informationanderachal decisions [SEP]']
[1350/2000] tot_loss=3.322 (perp=9.938, rec=0.336, cos=0.998), tot_loss_proj:3.949 [t=0.25s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedgingly. informationanderachal decisions [SEP]']
Attempt swap
[1400/2000] tot_loss=3.316 (perp=9.938, rec=0.330, cos=0.998), tot_loss_proj:3.948 [t=0.25s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedgingly. informationanderachal decisions [SEP]']
Attempt swap
[1450/2000] tot_loss=3.313 (perp=9.938, rec=0.327, cos=0.998), tot_loss_proj:3.946 [t=0.22s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedgingly. informationanderachal decisions [SEP]']
[1500/2000] tot_loss=3.310 (perp=9.938, rec=0.324, cos=0.998), tot_loss_proj:3.943 [t=0.25s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedgingly. informationanderachal decisions [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=3.205 (perp=9.403, rec=0.327, cos=0.998), tot_loss_proj:3.827 [t=0.18s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedachalgingly. informationander decisions [SEP]']
Attempt swap
[1600/2000] tot_loss=3.208 (perp=9.403, rec=0.329, cos=0.998), tot_loss_proj:3.826 [t=0.18s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedachalgingly. informationander decisions [SEP]']
[1650/2000] tot_loss=3.212 (perp=9.403, rec=0.334, cos=0.998), tot_loss_proj:3.825 [t=0.19s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedachalgingly. informationander decisions [SEP]']
Attempt swap
[1700/2000] tot_loss=3.203 (perp=9.403, rec=0.324, cos=0.998), tot_loss_proj:3.830 [t=0.18s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedachalgingly. informationander decisions [SEP]']
Attempt swap
[1750/2000] tot_loss=3.198 (perp=9.403, rec=0.319, cos=0.998), tot_loss_proj:3.825 [t=0.23s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedachalgingly. informationander decisions [SEP]']
[1800/2000] tot_loss=3.206 (perp=9.403, rec=0.327, cos=0.998), tot_loss_proj:3.828 [t=0.25s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedachalgingly. informationander decisions [SEP]']
Attempt swap
[1850/2000] tot_loss=3.196 (perp=9.403, rec=0.317, cos=0.998), tot_loss_proj:3.824 [t=0.19s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedachalgingly. informationander decisions [SEP]']
Attempt swap
[1900/2000] tot_loss=3.208 (perp=9.403, rec=0.329, cos=0.998), tot_loss_proj:3.824 [t=0.24s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedachalgingly. informationander decisions [SEP]']
[1950/2000] tot_loss=3.201 (perp=9.403, rec=0.322, cos=0.998), tot_loss_proj:3.829 [t=0.18s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedachalgingly. informationander decisions [SEP]']
Attempt swap
[2000/2000] tot_loss=3.195 (perp=9.403, rec=0.316, cos=0.998), tot_loss_proj:3.825 [t=0.18s]
prediction: ['[CLS] gorbachev chose thereof becauseuled customs information was releasedachalgingly. informationander decisions [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]
========================
predicted: 
========================
[CLS] gorbachev chose thereof becauseuled customs information was releasedgingly. informationanderachal decisions [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 37.037 | p: 41.667 | r: 33.333
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 29.630 | p: 33.333 | r: 26.667
rougeLsum  | fm: 29.630 | p: 33.333 | r: 26.667
r1fm+r2fm = 37.037

[Aggregate metrics]:
rouge1     | fm: 75.324 | p: 75.826 | r: 75.210
rouge2     | fm: 36.987 | p: 37.079 | r: 37.026
rougeL     | fm: 65.591 | p: 65.924 | r: 65.491
rougeLsum  | fm: 65.675 | p: 66.071 | r: 65.589
r1fm+r2fm = 112.311

input #36 time: 0:08:17 | total time: 5:04:33


Running input #37 of 100.
reference: 
========================
Kevin ate spaghetti with a spoon and Geordie did so too.
========================
average of cosine similarity 0.9993304804986536
highest_index [0]
highest [0.9993304804986536]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  4901,  8823, 26666,  2007,  1037, 15642,  1998, 20248, 17080,
          2063,  2106,  2061,  2205,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]']
[Init] best rec loss: 0.9316594004631042 for ['[CLS] grace extent first over maritime walked aria intake axis catcher dickinson twice tires serve [SEP]']
[Init] best rec loss: 0.9283725023269653 for ['[CLS] firingih bark programme powell colt angeles iangina warrant intention natural torontokind [SEP]']
[Init] best rec loss: 0.9265769124031067 for ['[CLS] chip culture airndafa phrase abandoned dissatisfied team musicbula page trulybahn [SEP]']
[Init] best rec loss: 0.9028146862983704 for ['[CLS] gone don sqaur [SEP] labels ivory fair crew across folded lamar plates roses [SEP]']
[Init] best perm rec loss: 0.9003402590751648 for ['[CLS] goneaur sq across folded crew don [SEP] lamar roses fair ivory labels plates [SEP]']
[Init] best perm rec loss: 0.8979520201683044 for ['[CLS] don lamar gone rosesaur folded labels across crew plates sq [SEP] fair ivory [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.945 (perp=11.831, rec=0.579, cos=1.000), tot_loss_proj:4.204 [t=0.24s]
prediction: ['[CLS] everyone?, however seamanrdi administration except lucky plus truck geo insurance earl [SEP]']
[ 100/2000] tot_loss=4.018 (perp=12.512, rec=0.516, cos=1.000), tot_loss_proj:4.389 [t=0.21s]
prediction: ['[CLS] everyone home, (rdirdi did except commented theie geo geo geo [SEP]']
[ 150/2000] tot_loss=4.181 (perp=13.063, rec=0.589, cos=0.980), tot_loss_proj:4.424 [t=0.26s]
prediction: ['[CLS] everyone wearing, docrdirdi did did spaghetti desie geo geo geo [SEP]']
[ 200/2000] tot_loss=3.775 (perp=11.747, rec=0.427, cos=0.999), tot_loss_proj:4.204 [t=0.30s]
prediction: ['[CLS] everyonerooms, (rdirdi did meanwhile went ande ( geo geo [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.554 (perp=10.738, rec=0.407, cos=1.000), tot_loss_proj:3.963 [t=0.24s]
prediction: ['[CLS] folded annabelle, indeedrdi did meanwhile slightly turboe of geordi geo [SEP]']
[ 300/2000] tot_loss=3.868 (perp=12.569, rec=0.356, cos=0.998), tot_loss_proj:4.308 [t=0.17s]
prediction: ['[CLS] cassandra spaghetti. meanwhilerdi did meanwhile kevin geoe containing geo geo geo [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.674 (perp=11.566, rec=0.362, cos=0.999), tot_loss_proj:4.124 [t=0.18s]
prediction: ['[CLS] cassandra ª. hmmrdi did geo kevin ande ate geo certainly geo [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.611 (perp=11.406, rec=0.331, cos=0.999), tot_loss_proj:4.069 [t=0.18s]
prediction: ['[CLS] cassandra ª. meanwhilerdi did certainly kevin ande ate geo romantic geo [SEP]']
[ 450/2000] tot_loss=3.679 (perp=11.820, rec=0.317, cos=0.999), tot_loss_proj:4.154 [t=0.25s]
prediction: ['[CLS] cassandra ª. meanwhilerdi did certainly kevin ande ateᆼ romantic geo [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.731 (perp=12.073, rec=0.318, cos=0.999), tot_loss_proj:4.218 [t=0.18s]
prediction: ['[CLS] woke ª. meanwhilerdi did certainly kevin ande ate harry cassandra geo [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.702 (perp=11.751, rec=0.354, cos=0.998), tot_loss_proj:4.195 [t=0.28s]
prediction: ['[CLS] ate ª. curiouslyrdi did certainly kevin andeeson lucy cassandra geo [SEP]']
[ 600/2000] tot_loss=3.654 (perp=11.743, rec=0.307, cos=0.998), tot_loss_proj:4.186 [t=0.26s]
prediction: ['[CLS] ate snorted. didrdi did certainly kevin ande episodes preventiongoing geo [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.621 (perp=11.609, rec=0.302, cos=0.998), tot_loss_proj:4.151 [t=0.17s]
prediction: ['[CLS] geo ª. didrdi did certainly kevin ande episodes lucygoing ate [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.525 (perp=11.144, rec=0.299, cos=0.998), tot_loss_proj:4.055 [t=0.18s]
prediction: ['[CLS] likewise shove. geordi did certainly kevin ande episodes lucygoing ate [SEP]']
[ 750/2000] tot_loss=3.525 (perp=11.144, rec=0.298, cos=0.998), tot_loss_proj:4.056 [t=0.23s]
prediction: ['[CLS] likewise shove. geordi did certainly kevin ande episodes lucygoing ate [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.303 (perp=10.090, rec=0.287, cos=0.998), tot_loss_proj:3.881 [t=0.23s]
prediction: ['[CLS] kevin shove. geordi did certainly likewise ande dryly lucygoing kevin [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.253 (perp=9.837, rec=0.288, cos=0.998), tot_loss_proj:3.820 [t=0.21s]
prediction: ['[CLS] kevin shove. geordi did certainly likewise ande dryly larrygoing kevin [SEP]']
[ 900/2000] tot_loss=3.250 (perp=9.837, rec=0.285, cos=0.998), tot_loss_proj:3.813 [t=0.25s]
prediction: ['[CLS] kevin shove. geordi did certainly likewise ande dryly larrygoing kevin [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.366 (perp=10.424, rec=0.283, cos=0.998), tot_loss_proj:3.937 [t=0.25s]
prediction: ['[CLS] kevin shove. geordi didperation likewise ande dryly larrygoing kevin [SEP]']
Attempt swap
[1000/2000] tot_loss=3.375 (perp=10.424, rec=0.292, cos=0.998), tot_loss_proj:3.939 [t=0.22s]
prediction: ['[CLS] kevin shove. geordi didperation likewise ande dryly larrygoing kevin [SEP]']
[1050/2000] tot_loss=3.359 (perp=10.424, rec=0.276, cos=0.998), tot_loss_proj:3.941 [t=0.18s]
prediction: ['[CLS] kevin shove. geordi didperation likewise ande dryly larrygoing kevin [SEP]']
Attempt swap
[1100/2000] tot_loss=3.373 (perp=10.424, rec=0.290, cos=0.998), tot_loss_proj:3.936 [t=0.19s]
prediction: ['[CLS] kevin shove. geordi didperation likewise ande dryly larrygoing kevin [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=3.324 (perp=10.175, rec=0.290, cos=0.998), tot_loss_proj:3.897 [t=0.19s]
prediction: ['[CLS] kevin shove. geordi didperation likewise ande dryly larry kevingoing [SEP]']
[1200/2000] tot_loss=3.310 (perp=10.175, rec=0.277, cos=0.998), tot_loss_proj:3.899 [t=0.19s]
prediction: ['[CLS] kevin shove. geordi didperation likewise ande dryly larry kevingoing [SEP]']
Attempt swap
[1250/2000] tot_loss=3.314 (perp=10.175, rec=0.281, cos=0.998), tot_loss_proj:3.900 [t=0.22s]
prediction: ['[CLS] kevin shove. geordi didperation likewise ande dryly larry kevingoing [SEP]']
Attempt swap
[1300/2000] tot_loss=3.320 (perp=10.175, rec=0.287, cos=0.998), tot_loss_proj:3.899 [t=0.20s]
prediction: ['[CLS] kevin shove. geordi didperation likewise ande dryly larry kevingoing [SEP]']
[1350/2000] tot_loss=3.304 (perp=10.175, rec=0.271, cos=0.998), tot_loss_proj:3.895 [t=0.19s]
prediction: ['[CLS] kevin shove. geordi didperation likewise ande dryly larry kevingoing [SEP]']
Attempt swap
[1400/2000] tot_loss=3.328 (perp=10.175, rec=0.295, cos=0.998), tot_loss_proj:3.900 [t=0.18s]
prediction: ['[CLS] kevin shove. geordi didperation likewise ande dryly larry kevingoing [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=3.225 (perp=9.736, rec=0.279, cos=0.999), tot_loss_proj:3.798 [t=0.22s]
prediction: ['[CLS] kevin shove. geordi didperation and dide dryly larry kevingoing [SEP]']
[1500/2000] tot_loss=3.221 (perp=9.736, rec=0.275, cos=0.998), tot_loss_proj:3.800 [t=0.18s]
prediction: ['[CLS] kevin shove. geordi didperation and dide dryly larry kevingoing [SEP]']
Attempt swap
[1550/2000] tot_loss=3.378 (perp=10.460, rec=0.288, cos=0.998), tot_loss_proj:3.930 [t=0.20s]
prediction: ['[CLS] kevin sensual. geordi didperation and dide dryly larry kevingoing [SEP]']
Attempt swap
[1600/2000] tot_loss=3.379 (perp=10.460, rec=0.288, cos=0.998), tot_loss_proj:3.930 [t=0.17s]
prediction: ['[CLS] kevin sensual. geordi didperation and dide dryly larry kevingoing [SEP]']
[1650/2000] tot_loss=3.376 (perp=10.460, rec=0.286, cos=0.998), tot_loss_proj:3.928 [t=0.17s]
prediction: ['[CLS] kevin sensual. geordi didperation and dide dryly larry kevingoing [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=3.242 (perp=9.810, rec=0.282, cos=0.998), tot_loss_proj:3.814 [t=0.18s]
prediction: ['[CLS] kevinperation. geordi did sensual and dide dryly larry kevingoing [SEP]']
Attempt swap
[1750/2000] tot_loss=3.238 (perp=9.810, rec=0.278, cos=0.998), tot_loss_proj:3.813 [t=0.27s]
prediction: ['[CLS] kevinperation. geordi did sensual and dide dryly larry kevingoing [SEP]']
[1800/2000] tot_loss=3.232 (perp=9.810, rec=0.272, cos=0.998), tot_loss_proj:3.812 [t=0.23s]
prediction: ['[CLS] kevinperation. geordi did sensual and dide dryly larry kevingoing [SEP]']
Attempt swap
[1850/2000] tot_loss=3.230 (perp=9.810, rec=0.269, cos=0.998), tot_loss_proj:3.810 [t=0.31s]
prediction: ['[CLS] kevinperation. geordi did sensual and dide dryly larry kevingoing [SEP]']
Attempt swap
[1900/2000] tot_loss=3.235 (perp=9.810, rec=0.275, cos=0.998), tot_loss_proj:3.812 [t=0.26s]
prediction: ['[CLS] kevinperation. geordi did sensual and dide dryly larry kevingoing [SEP]']
[1950/2000] tot_loss=3.234 (perp=9.810, rec=0.274, cos=0.998), tot_loss_proj:3.814 [t=0.23s]
prediction: ['[CLS] kevinperation. geordi did sensual and dide dryly larry kevingoing [SEP]']
Attempt swap
[2000/2000] tot_loss=3.242 (perp=9.810, rec=0.282, cos=0.998), tot_loss_proj:3.812 [t=0.19s]
prediction: ['[CLS] kevinperation. geordi did sensual and dide dryly larry kevingoing [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]
========================
predicted: 
========================
[CLS] kevin shove. geordi didperation likewise ande dryly larry kevingoing [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 25.000 | p: 27.273 | r: 23.077
rouge2     | fm: 9.091 | p: 10.000 | r: 8.333
rougeL     | fm: 25.000 | p: 27.273 | r: 23.077
rougeLsum  | fm: 25.000 | p: 27.273 | r: 23.077
r1fm+r2fm = 34.091

[Aggregate metrics]:
rouge1     | fm: 73.880 | p: 74.309 | r: 73.668
rouge2     | fm: 36.393 | p: 36.362 | r: 36.422
rougeL     | fm: 64.514 | p: 64.971 | r: 64.308
rougeLsum  | fm: 64.657 | p: 65.048 | r: 64.458
r1fm+r2fm = 110.273

input #37 time: 0:08:22 | total time: 5:12:55


Running input #38 of 100.
reference: 
========================
John is the kind of fool that I told you about.
========================
average of cosine similarity 0.9995113299775283
highest_index [0]
highest [0.9995113299775283]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2198, 2003, 1996, 2785, 1997, 7966, 2008, 1045, 2409, 2017, 2055,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is the kind of fool that i told you about. [SEP]']
[Init] best rec loss: 0.9675338268280029 for ['[CLS] medicine horns clear john splash treaties samson com credited birthplace ago managing [SEP]']
[Init] best rec loss: 0.9361371397972107 for ['[CLS]vance jace texas silk mid will ongative to important sweat prize [SEP]']
[Init] best rec loss: 0.9326436519622803 for ['[CLS] nina won allied issues after stride growing joo kevin gabriel skiermonium [SEP]']
[Init] best rec loss: 0.9324679970741272 for ['[CLS] off bumpheint same mustlding sydney young movie something odd [SEP]']
[Init] best rec loss: 0.9286861419677734 for ['[CLS] jr massachusetts [SEP] refrigerator inch paradox jury all provided somewhere galaxy francis [SEP]']
[Init] best rec loss: 0.9026694297790527 for ['[CLS] label sea safety zeronessfixed builder med scrub fairound amateur [SEP]']
[Init] best perm rec loss: 0.9024163484573364 for ['[CLS] seaound zeroness safety medfixed scrub label builder fair amateur [SEP]']
[Init] best perm rec loss: 0.9023182392120361 for ['[CLS]fixed med amateur zeroound label seaness builder fair scrub safety [SEP]']
[Init] best perm rec loss: 0.9020756483078003 for ['[CLS]ness amateuround sea labelfixed med scrub zero fair builder safety [SEP]']
[Init] best perm rec loss: 0.9013963341712952 for ['[CLS]ness zero safetyfixed scrub builder label sea fair amateuround med [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.164 (perp=11.183, rec=0.508, cos=0.420), tot_loss_proj:4.061 [t=0.17s]
prediction: ['[CLS] healthy.,?ward jeremy mistake abby was pipe preaching. [SEP]']
[ 100/2000] tot_loss=2.029 (perp=8.528, rec=0.297, cos=0.026), tot_loss_proj:3.635 [t=0.18s]
prediction: ['[CLS]. fool john? fool james fool. kind your fool fool [SEP]']
[ 150/2000] tot_loss=2.019 (perp=8.801, rec=0.242, cos=0.017), tot_loss_proj:3.711 [t=0.18s]
prediction: ['[CLS]. fool john? fool james fool. kind your fool very [SEP]']
[ 200/2000] tot_loss=2.559 (perp=9.882, rec=0.489, cos=0.093), tot_loss_proj:3.763 [t=0.19s]
prediction: ['[CLS]. fool john clearly fool became fool ka is your fool about [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.275 (perp=10.066, rec=0.243, cos=0.019), tot_loss_proj:3.769 [t=0.21s]
prediction: ['[CLS]. kind became john i by told called is you fool about [SEP]']
[ 300/2000] tot_loss=2.209 (perp=10.066, rec=0.183, cos=0.012), tot_loss_proj:3.768 [t=0.23s]
prediction: ['[CLS]. kind became john i by told called is you fool about [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.021 (perp=9.244, rec=0.162, cos=0.010), tot_loss_proj:3.571 [t=0.18s]
prediction: ['[CLS] kind your john i without told. called is you fool about [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.861 (perp=8.522, rec=0.147, cos=0.009), tot_loss_proj:3.437 [t=0.24s]
prediction: ['[CLS] your john i kind by told. called is you fool about [SEP]']
[ 450/2000] tot_loss=1.844 (perp=8.522, rec=0.131, cos=0.008), tot_loss_proj:3.438 [t=0.18s]
prediction: ['[CLS] your john i kind by told. called is you fool about [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.778 (perp=8.155, rec=0.140, cos=0.007), tot_loss_proj:3.364 [t=0.25s]
prediction: ['[CLS] your john i kind by called. told is you fool about [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.778 (perp=8.155, rec=0.141, cos=0.006), tot_loss_proj:3.365 [t=0.27s]
prediction: ['[CLS] your john i kind by called. told is you fool about [SEP]']
[ 600/2000] tot_loss=1.842 (perp=8.554, rec=0.125, cos=0.005), tot_loss_proj:3.414 [t=0.18s]
prediction: ['[CLS] of john i kind by tells. told is you fool about [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.722 (perp=7.999, rec=0.118, cos=0.004), tot_loss_proj:3.328 [t=0.23s]
prediction: ['[CLS] of john. kind by of i told is you fool about [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.603 (perp=7.397, rec=0.120, cos=0.004), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] of john. kind by of i told you is fool about [SEP]']
[ 750/2000] tot_loss=1.594 (perp=7.397, rec=0.111, cos=0.003), tot_loss_proj:3.176 [t=0.25s]
prediction: ['[CLS] of john. kind by of i told you is fool about [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.555 (perp=7.247, rec=0.103, cos=0.003), tot_loss_proj:3.168 [t=0.21s]
prediction: ['[CLS] of john by. kind of i told you is fool about [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.494 (perp=6.931, rec=0.105, cos=0.003), tot_loss_proj:3.121 [t=0.18s]
prediction: ['[CLS] of john. by kind of i told you is fool about [SEP]']
[ 900/2000] tot_loss=1.499 (perp=6.931, rec=0.110, cos=0.003), tot_loss_proj:3.123 [t=0.18s]
prediction: ['[CLS] of john. by kind of i told you is fool about [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.489 (perp=6.931, rec=0.100, cos=0.003), tot_loss_proj:3.118 [t=0.18s]
prediction: ['[CLS] of john. by kind of i told you is fool about [SEP]']
Attempt swap
[1000/2000] tot_loss=1.559 (perp=7.233, rec=0.109, cos=0.003), tot_loss_proj:3.201 [t=0.18s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
[1050/2000] tot_loss=1.540 (perp=7.233, rec=0.091, cos=0.003), tot_loss_proj:3.199 [t=0.17s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
Attempt swap
[1100/2000] tot_loss=1.556 (perp=7.233, rec=0.106, cos=0.003), tot_loss_proj:3.202 [t=0.19s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
Attempt swap
[1150/2000] tot_loss=1.554 (perp=7.233, rec=0.105, cos=0.003), tot_loss_proj:3.202 [t=0.18s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
[1200/2000] tot_loss=1.548 (perp=7.233, rec=0.099, cos=0.003), tot_loss_proj:3.199 [t=0.18s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.233, rec=0.101, cos=0.003), tot_loss_proj:3.201 [t=0.17s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
Attempt swap
[1300/2000] tot_loss=1.540 (perp=7.233, rec=0.091, cos=0.003), tot_loss_proj:3.198 [t=0.18s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
[1350/2000] tot_loss=1.550 (perp=7.233, rec=0.101, cos=0.003), tot_loss_proj:3.196 [t=0.19s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
Attempt swap
[1400/2000] tot_loss=1.542 (perp=7.233, rec=0.093, cos=0.003), tot_loss_proj:3.199 [t=0.26s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
Attempt swap
[1450/2000] tot_loss=1.535 (perp=7.233, rec=0.086, cos=0.003), tot_loss_proj:3.202 [t=0.21s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
[1500/2000] tot_loss=1.548 (perp=7.233, rec=0.098, cos=0.003), tot_loss_proj:3.203 [t=0.17s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
Attempt swap
[1550/2000] tot_loss=1.540 (perp=7.233, rec=0.091, cos=0.003), tot_loss_proj:3.200 [t=0.22s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
Attempt swap
[1600/2000] tot_loss=1.543 (perp=7.233, rec=0.094, cos=0.003), tot_loss_proj:3.206 [t=0.17s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
[1650/2000] tot_loss=1.538 (perp=7.233, rec=0.089, cos=0.003), tot_loss_proj:3.201 [t=0.17s]
prediction: ['[CLS] of john. by kind of that told you is fool about [SEP]']
Attempt swap
[1700/2000] tot_loss=1.557 (perp=7.361, rec=0.083, cos=0.003), tot_loss_proj:3.200 [t=0.23s]
prediction: ['[CLS] of john. by kind the that told you is fool about [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.678 (perp=7.902, rec=0.095, cos=0.003), tot_loss_proj:3.315 [t=0.18s]
prediction: ['[CLS] of john. by of kind that told you is fool about [SEP]']
[1800/2000] tot_loss=1.669 (perp=7.902, rec=0.086, cos=0.003), tot_loss_proj:3.315 [t=0.17s]
prediction: ['[CLS] of john. by of kind that told you is fool about [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.570 (perp=7.389, rec=0.089, cos=0.002), tot_loss_proj:3.235 [t=0.26s]
prediction: ['[CLS] of john. kind of by that told you is fool about [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.509 (perp=7.051, rec=0.096, cos=0.003), tot_loss_proj:3.354 [t=0.22s]
prediction: ['[CLS] of john. kind of fool that told you is by about [SEP]']
[1950/2000] tot_loss=1.501 (perp=7.051, rec=0.089, cos=0.002), tot_loss_proj:3.361 [t=0.18s]
prediction: ['[CLS] of john. kind of fool that told you is by about [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.490 (perp=6.962, rec=0.095, cos=0.003), tot_loss_proj:3.191 [t=0.18s]
prediction: ['[CLS] of john is kind the fool that told you. by about [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] john is the kind of fool that i told you about. [SEP]
========================
predicted: 
========================
[CLS] of john. kind of fool that told you is by about [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 84.615 | r: 84.615
rouge2     | fm: 41.667 | p: 41.667 | r: 41.667
rougeL     | fm: 76.923 | p: 76.923 | r: 76.923
rougeLsum  | fm: 76.923 | p: 76.923 | r: 76.923
r1fm+r2fm = 126.282

[Aggregate metrics]:
rouge1     | fm: 74.273 | p: 74.711 | r: 73.893
rouge2     | fm: 36.158 | p: 36.167 | r: 36.298
rougeL     | fm: 64.799 | p: 65.276 | r: 64.585
rougeLsum  | fm: 64.994 | p: 65.497 | r: 64.781
r1fm+r2fm = 110.431

input #38 time: 0:07:59 | total time: 5:20:55


Running input #39 of 100.
reference: 
========================
I doubt if you can help me in understanding this.
========================
average of cosine similarity 0.99941311323763
highest_index [0]
highest [0.99941311323763]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 1045, 4797, 2065, 2017, 2064, 2393, 2033, 1999, 4824, 2023, 1012,
          102]], device='cuda:0')
Debug: ref = ['[CLS] i doubt if you can help me in understanding this. [SEP]']
[Init] best rec loss: 0.9692432880401611 for ['[CLS] probably issue jade aren circumstances day old mayohum asian belonging [SEP]']
[Init] best rec loss: 0.9366908073425293 for ['[CLS] complications destiny com sex asteroids location outline shock focus impact highest [SEP]']
[Init] best rec loss: 0.9288410544395447 for ['[CLS] being reserved treat layer regulation model nose niche paddle picked think [SEP]']
[Init] best rec loss: 0.9272903800010681 for ['[CLS] exchange connect piano confirmed planted class mean company critically d men [SEP]']
[Init] best rec loss: 0.9174222946166992 for ['[CLS] legislature exploits mit alice didn tubes true mountvity lane animal [SEP]']
[Init] best rec loss: 0.9120254516601562 for ['[CLS] evangelist across shared fingernails rhythm machine following competition minute member babylon [SEP]']
[Init] best rec loss: 0.9110709428787231 for ['[CLS] composergist squared dee directedigraphy payingunds caseative half [SEP]']
[Init] best perm rec loss: 0.9087654948234558 for ['[CLS] payinggistunds squared caseigraphy half dee composer directedative [SEP]']
[Init] best perm rec loss: 0.9077205657958984 for ['[CLS] directed half payinggistative dee case composerunds squaredigraphy [SEP]']
[Init] best perm rec loss: 0.9066043496131897 for ['[CLS]undsative paying half squaredigraphy directed case composergist dee [SEP]']
[Init] best perm rec loss: 0.9061527252197266 for ['[CLS] composerative payingigraphy directed half squared deegist caseunds [SEP]']
[Init] best perm rec loss: 0.9044231176376343 for ['[CLS] caseunds directedative squaredigraphy dee composergist half paying [SEP]']
[Init] best perm rec loss: 0.9036428928375244 for ['[CLS] directedative half composergist caseunds paying squaredigraphy dee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.623 (perp=9.985, rec=0.668, cos=0.957), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS] " smiled doubt. is whydgets using i refer. [SEP]']
[ 100/2000] tot_loss=2.893 (perp=10.610, rec=0.433, cos=0.338), tot_loss_proj:3.900 [t=0.25s]
prediction: ['[CLS] doubt myself doubt across sure your. doubt that refer anymore [SEP]']
[ 150/2000] tot_loss=2.008 (perp=8.416, rec=0.293, cos=0.032), tot_loss_proj:3.465 [t=0.24s]
prediction: ['[CLS] doubt if doubt you if your. doubt understanding insight this [SEP]']
[ 200/2000] tot_loss=2.010 (perp=8.810, rec=0.225, cos=0.023), tot_loss_proj:3.563 [t=0.17s]
prediction: ['[CLS] doubt if help you if in. help understanding understanding this [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.803 (perp=8.066, rec=0.173, cos=0.018), tot_loss_proj:3.370 [t=0.21s]
prediction: ['[CLS] doubt if help you if in understanding can help understanding this [SEP]']
[ 300/2000] tot_loss=1.640 (perp=7.519, rec=0.124, cos=0.012), tot_loss_proj:3.217 [t=0.22s]
prediction: ['[CLS] doubt if help you me in understanding can help understanding this [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.524 (perp=7.020, rec=0.109, cos=0.011), tot_loss_proj:3.152 [t=0.26s]
prediction: ['[CLS] doubt if help you understanding can help me in understanding this [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.458 (perp=6.459, rec=0.152, cos=0.014), tot_loss_proj:3.136 [t=0.26s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[ 450/2000] tot_loss=1.412 (perp=6.459, rec=0.109, cos=0.011), tot_loss_proj:3.159 [t=0.30s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.410 (perp=6.459, rec=0.107, cos=0.011), tot_loss_proj:3.162 [t=0.25s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.407 (perp=6.459, rec=0.105, cos=0.011), tot_loss_proj:3.169 [t=0.18s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[ 600/2000] tot_loss=1.413 (perp=6.459, rec=0.111, cos=0.010), tot_loss_proj:3.166 [t=0.18s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.403 (perp=6.459, rec=0.101, cos=0.010), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.407 (perp=6.459, rec=0.105, cos=0.010), tot_loss_proj:3.172 [t=0.22s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[ 750/2000] tot_loss=1.401 (perp=6.459, rec=0.100, cos=0.010), tot_loss_proj:3.177 [t=0.23s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.398 (perp=6.459, rec=0.096, cos=0.010), tot_loss_proj:3.178 [t=0.23s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.390 (perp=6.459, rec=0.088, cos=0.010), tot_loss_proj:3.179 [t=0.23s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[ 900/2000] tot_loss=1.395 (perp=6.459, rec=0.093, cos=0.010), tot_loss_proj:3.182 [t=0.25s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.397 (perp=6.459, rec=0.095, cos=0.010), tot_loss_proj:3.181 [t=0.28s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1000/2000] tot_loss=1.392 (perp=6.459, rec=0.090, cos=0.009), tot_loss_proj:3.184 [t=0.27s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[1050/2000] tot_loss=1.404 (perp=6.459, rec=0.103, cos=0.009), tot_loss_proj:3.184 [t=0.24s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1100/2000] tot_loss=1.389 (perp=6.459, rec=0.088, cos=0.009), tot_loss_proj:3.184 [t=0.26s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1150/2000] tot_loss=1.401 (perp=6.459, rec=0.099, cos=0.009), tot_loss_proj:3.186 [t=0.18s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[1200/2000] tot_loss=1.387 (perp=6.459, rec=0.086, cos=0.009), tot_loss_proj:3.194 [t=0.18s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1250/2000] tot_loss=1.388 (perp=6.459, rec=0.087, cos=0.009), tot_loss_proj:3.188 [t=0.19s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1300/2000] tot_loss=1.403 (perp=6.459, rec=0.102, cos=0.009), tot_loss_proj:3.193 [t=0.26s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[1350/2000] tot_loss=1.382 (perp=6.459, rec=0.081, cos=0.009), tot_loss_proj:3.190 [t=0.30s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1400/2000] tot_loss=1.405 (perp=6.459, rec=0.104, cos=0.009), tot_loss_proj:3.192 [t=0.17s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1450/2000] tot_loss=1.394 (perp=6.459, rec=0.093, cos=0.009), tot_loss_proj:3.195 [t=0.17s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[1500/2000] tot_loss=1.393 (perp=6.459, rec=0.092, cos=0.009), tot_loss_proj:3.194 [t=0.28s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1550/2000] tot_loss=1.384 (perp=6.459, rec=0.083, cos=0.009), tot_loss_proj:3.193 [t=0.18s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1600/2000] tot_loss=1.394 (perp=6.459, rec=0.093, cos=0.009), tot_loss_proj:3.196 [t=0.18s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[1650/2000] tot_loss=1.385 (perp=6.459, rec=0.084, cos=0.009), tot_loss_proj:3.192 [t=0.20s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1700/2000] tot_loss=1.392 (perp=6.459, rec=0.091, cos=0.009), tot_loss_proj:3.195 [t=0.18s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1750/2000] tot_loss=1.387 (perp=6.459, rec=0.086, cos=0.009), tot_loss_proj:3.198 [t=0.19s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[1800/2000] tot_loss=1.401 (perp=6.459, rec=0.100, cos=0.009), tot_loss_proj:3.196 [t=0.18s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1850/2000] tot_loss=1.394 (perp=6.459, rec=0.093, cos=0.009), tot_loss_proj:3.195 [t=0.27s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[1900/2000] tot_loss=1.393 (perp=6.459, rec=0.092, cos=0.009), tot_loss_proj:3.197 [t=0.18s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
[1950/2000] tot_loss=1.394 (perp=6.459, rec=0.093, cos=0.009), tot_loss_proj:3.196 [t=0.18s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Attempt swap
[2000/2000] tot_loss=1.390 (perp=6.459, rec=0.089, cos=0.009), tot_loss_proj:3.198 [t=0.23s]
prediction: ['[CLS] if doubt help you understanding can help me in understanding this [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] i doubt if you can help me in understanding this. [SEP]
========================
predicted: 
========================
[CLS] if doubt help you understanding can help me in understanding this [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 52.174 | p: 50.000 | r: 54.545
rougeL     | fm: 80.000 | p: 76.923 | r: 83.333
rougeLsum  | fm: 80.000 | p: 76.923 | r: 83.333
r1fm+r2fm = 140.174

[Aggregate metrics]:
rouge1     | fm: 74.564 | p: 74.868 | r: 74.531
rouge2     | fm: 36.910 | p: 36.866 | r: 36.968
rougeL     | fm: 65.339 | p: 65.596 | r: 65.240
rougeLsum  | fm: 65.339 | p: 65.812 | r: 65.254
r1fm+r2fm = 111.474

input #39 time: 0:08:23 | total time: 5:29:18


Running input #40 of 100.
reference: 
========================
Was the child running to the car?
========================
average of cosine similarity 0.9994376310826198
highest_index [0]
highest [0.9994376310826198]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2001, 1996, 2775, 2770, 2000, 1996, 2482, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] was the child running to the car? [SEP]']
[Init] best rec loss: 0.9621278047561646 for ['[CLS]chfield only loan mast lust nape " nearly [SEP]']
[Init] best rec loss: 0.9481551051139832 for ['[CLS]typic races investigation singular haven boreay libby [SEP]']
[Init] best rec loss: 0.9173352122306824 for ['[CLS] standing colonyhers angry isn [SEP] women waste [SEP]']
[Init] best rec loss: 0.9018546938896179 for ['[CLS] rhapsody edna german award hamburg once horn govt [SEP]']
[Init] best rec loss: 0.8998432159423828 for ['[CLS] o junior grinning appear stitchfy with they [SEP]']
[Init] best rec loss: 0.895498514175415 for ['[CLS] arrived door bat simon unwillinghorthaling syn [SEP]']
[Init] best rec loss: 0.8836095929145813 for ['[CLS]lene novi following [SEP] circumstances business practice l [SEP]']
[Init] best rec loss: 0.8725322484970093 for ['[CLS]ning archbishop whomont andreasization parents rest [SEP]']
[Init] best rec loss: 0.8687050938606262 for ['[CLS] ethnic product czech feed diego problems construction methods [SEP]']
[Init] best perm rec loss: 0.8622528910636902 for ['[CLS] diego feed methods product construction czech problems ethnic [SEP]']
[Init] best perm rec loss: 0.8621556758880615 for ['[CLS] construction diego methods feed czech ethnic problems product [SEP]']
[Init] best perm rec loss: 0.8614377975463867 for ['[CLS] czech ethnic construction methods feed problems product diego [SEP]']
[Init] best perm rec loss: 0.8572033643722534 for ['[CLS] feed diego product construction ethnic czech problems methods [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.829 (perp=11.136, rec=0.608, cos=0.994), tot_loss_proj:4.143 [t=0.22s]
prediction: ['[CLS] ford, 1 isfo what mao hr [SEP]']
[ 100/2000] tot_loss=3.807 (perp=10.939, rec=0.640, cos=0.979), tot_loss_proj:4.064 [t=0.25s]
prediction: ['[CLS] inside street were this genera del [SEP] can [SEP]']
[ 150/2000] tot_loss=4.121 (perp=11.410, rec=0.845, cos=0.994), tot_loss_proj:4.102 [t=0.19s]
prediction: ['[CLS] pockets car were? genera motorcycle [SEP]. [SEP]']
[ 200/2000] tot_loss=3.694 (perp=10.562, rec=0.590, cos=0.991), tot_loss_proj:4.135 [t=0.18s]
prediction: ['[CLS] azerbaijan car?? genera this [SEP]. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.616 (perp=10.434, rec=0.537, cos=0.992), tot_loss_proj:3.978 [t=0.21s]
prediction: ['[CLS] bmw? was car settlements global [SEP]. [SEP]']
[ 300/2000] tot_loss=3.668 (perp=10.907, rec=0.499, cos=0.987), tot_loss_proj:4.212 [t=0.17s]
prediction: ['[CLS] bmw? was car settlements approach [SEP]. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.191 (perp=8.232, rec=0.552, cos=0.992), tot_loss_proj:3.477 [t=0.28s]
prediction: ['[CLS] car?. or settlements away was. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.491 (perp=9.941, rec=0.519, cos=0.984), tot_loss_proj:3.803 [t=0.24s]
prediction: ['[CLS] car? or settlements was without car communication [SEP]']
[ 450/2000] tot_loss=3.370 (perp=9.618, rec=0.476, cos=0.970), tot_loss_proj:3.765 [t=0.20s]
prediction: ['[CLS] car? to settlements is without car communication [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.501 (perp=10.006, rec=0.549, cos=0.951), tot_loss_proj:3.897 [t=0.23s]
prediction: ['[CLS] indexed communication and settlements was without half? [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.390 (perp=9.694, rec=0.509, cos=0.943), tot_loss_proj:3.847 [t=0.17s]
prediction: ['[CLS] constable communication and settlements was without half? [SEP]']
[ 600/2000] tot_loss=3.483 (perp=10.387, rec=0.479, cos=0.927), tot_loss_proj:3.907 [t=0.23s]
prediction: ['[CLS] constable communication and settlements was is half? [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.209 (perp=9.171, rec=0.460, cos=0.914), tot_loss_proj:3.644 [t=0.18s]
prediction: ['[CLS] car communication rounding. and is half? [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.008 (perp=8.129, rec=0.455, cos=0.927), tot_loss_proj:3.506 [t=0.18s]
prediction: ['[CLS] car communication rounding. is and car? [SEP]']
[ 750/2000] tot_loss=3.070 (perp=8.669, rec=0.442, cos=0.894), tot_loss_proj:3.606 [t=0.24s]
prediction: ['[CLS] car communication rounding. was and car? [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.215 (perp=9.451, rec=0.434, cos=0.890), tot_loss_proj:3.760 [t=0.22s]
prediction: ['[CLS] car communication was rounding winning and car? [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=3.121 (perp=9.107, rec=0.419, cos=0.880), tot_loss_proj:3.692 [t=0.22s]
prediction: ['[CLS] car communication was crop and winning car? [SEP]']
[ 900/2000] tot_loss=3.106 (perp=9.107, rec=0.414, cos=0.870), tot_loss_proj:3.687 [t=0.18s]
prediction: ['[CLS] car communication was crop and winning car? [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.002 (perp=8.592, rec=0.416, cos=0.867), tot_loss_proj:3.585 [t=0.22s]
prediction: ['[CLS] car crop was communication and winning car? [SEP]']
Attempt swap
[1000/2000] tot_loss=2.993 (perp=8.592, rec=0.416, cos=0.858), tot_loss_proj:3.583 [t=0.18s]
prediction: ['[CLS] car crop was communication and winning car? [SEP]']
[1050/2000] tot_loss=2.968 (perp=8.592, rec=0.397, cos=0.852), tot_loss_proj:3.586 [t=0.23s]
prediction: ['[CLS] car crop was communication and winning car? [SEP]']
Attempt swap
[1100/2000] tot_loss=2.970 (perp=8.592, rec=0.406, cos=0.846), tot_loss_proj:3.585 [t=0.18s]
prediction: ['[CLS] car crop was communication and winning car? [SEP]']
Attempt swap
[1150/2000] tot_loss=3.012 (perp=8.834, rec=0.404, cos=0.842), tot_loss_proj:3.646 [t=0.25s]
prediction: ['[CLS] car crop was running and winning car? [SEP]']
[1200/2000] tot_loss=2.978 (perp=8.756, rec=0.390, cos=0.837), tot_loss_proj:3.595 [t=0.22s]
prediction: ['[CLS] car investigation was running and winning car? [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.816 (perp=7.953, rec=0.401, cos=0.824), tot_loss_proj:3.434 [t=0.19s]
prediction: ['[CLS] car investigation was winning and running car? [SEP]']
Attempt swap
[1300/2000] tot_loss=2.805 (perp=7.953, rec=0.390, cos=0.824), tot_loss_proj:3.434 [t=0.27s]
prediction: ['[CLS] car investigation was winning and running car? [SEP]']
[1350/2000] tot_loss=2.800 (perp=7.953, rec=0.389, cos=0.821), tot_loss_proj:3.433 [t=0.18s]
prediction: ['[CLS] car investigation was winning and running car? [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=3.004 (perp=8.881, rec=0.401, cos=0.827), tot_loss_proj:3.612 [t=0.23s]
prediction: ['[CLS] car was investigation their and running car? [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=2.530 (perp=6.459, rec=0.407, cos=0.832), tot_loss_proj:3.165 [t=0.18s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
[1500/2000] tot_loss=2.512 (perp=6.459, rec=0.401, cos=0.819), tot_loss_proj:3.168 [t=0.26s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
Attempt swap
[1550/2000] tot_loss=2.498 (perp=6.459, rec=0.394, cos=0.812), tot_loss_proj:3.162 [t=0.20s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
Attempt swap
[1600/2000] tot_loss=2.481 (perp=6.459, rec=0.382, cos=0.807), tot_loss_proj:3.166 [t=0.18s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
[1650/2000] tot_loss=2.476 (perp=6.459, rec=0.382, cos=0.803), tot_loss_proj:3.164 [t=0.18s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
Attempt swap
[1700/2000] tot_loss=2.485 (perp=6.459, rec=0.394, cos=0.799), tot_loss_proj:3.165 [t=0.18s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
Attempt swap
[1750/2000] tot_loss=2.476 (perp=6.459, rec=0.389, cos=0.795), tot_loss_proj:3.165 [t=0.23s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
[1800/2000] tot_loss=2.471 (perp=6.459, rec=0.386, cos=0.792), tot_loss_proj:3.168 [t=0.25s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
Attempt swap
[1850/2000] tot_loss=2.467 (perp=6.459, rec=0.386, cos=0.789), tot_loss_proj:3.166 [t=0.17s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
Attempt swap
[1900/2000] tot_loss=2.460 (perp=6.459, rec=0.381, cos=0.787), tot_loss_proj:3.163 [t=0.25s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
[1950/2000] tot_loss=2.455 (perp=6.459, rec=0.380, cos=0.784), tot_loss_proj:3.162 [t=0.17s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
Attempt swap
[2000/2000] tot_loss=2.449 (perp=6.459, rec=0.375, cos=0.782), tot_loss_proj:3.165 [t=0.18s]
prediction: ['[CLS] their car was investigation and running car? [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] was the child running to the car? [SEP]
========================
predicted: 
========================
[CLS] their car was investigation and running car? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.556 | p: 55.556 | r: 55.556
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 68.056

[Aggregate metrics]:
rouge1     | fm: 74.084 | p: 74.523 | r: 73.972
rouge2     | fm: 36.262 | p: 36.252 | r: 36.352
rougeL     | fm: 64.906 | p: 65.269 | r: 64.807
rougeLsum  | fm: 65.189 | p: 65.574 | r: 65.108
r1fm+r2fm = 110.346

input #40 time: 0:08:02 | total time: 5:37:20


Running input #41 of 100.
reference: 
========================
Mary is shorter than five feet.
========================
average of cosine similarity 0.9993780592173414
highest_index [0]
highest [0.9993780592173414]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2984, 2003, 7820, 2084, 2274, 2519, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] mary is shorter than five feet. [SEP]']
[Init] best rec loss: 0.9804759621620178 for ['[CLS] try formerly doneicz gmina away originals [SEP]']
[Init] best rec loss: 0.9635863304138184 for ['[CLS] whilst cards loud jacksonon ladies bounded [SEP]']
[Init] best rec loss: 0.9399990439414978 for ['[CLS] she motto nerve five patsy unable deeper [SEP]']
[Init] best rec loss: 0.9262915849685669 for ['[CLS]ticalntonvious subjects hotelceae trains [SEP]']
[Init] best rec loss: 0.9226271510124207 for ['[CLS] [sei mixed sung assuming bag night [SEP]']
[Init] best rec loss: 0.9194919466972351 for ['[CLS]ading investigate closet lily mad page cover [SEP]']
[Init] best rec loss: 0.9147651195526123 for ['[CLS] younger xiarableuded respect miss flight [SEP]']
[Init] best rec loss: 0.9046170115470886 for ['[CLS] [UNK]micises background mechanism forces important [SEP]']
[Init] best rec loss: 0.9044715166091919 for ['[CLS] while they much cannotmal bedside death [SEP]']
[Init] best rec loss: 0.897434651851654 for ['[CLS] optionicated wherehausen fact reflection feel [SEP]']
[Init] best rec loss: 0.877751886844635 for ['[CLS] non completing 0 string page families space [SEP]']
[Init] best perm rec loss: 0.8773093223571777 for ['[CLS] page families non space completing string 0 [SEP]']
[Init] best perm rec loss: 0.8756932616233826 for ['[CLS] completing string non 0 page space families [SEP]']
[Init] best perm rec loss: 0.875471830368042 for ['[CLS] string families non page completing 0 space [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.779 (perp=10.894, rec=0.614, cos=0.986), tot_loss_proj:4.020 [t=0.18s]
prediction: ['[CLS]ius competition. chairwood from way [SEP]']
[ 100/2000] tot_loss=3.701 (perp=11.105, rec=0.521, cos=0.960), tot_loss_proj:4.078 [t=0.18s]
prediction: ['[CLS]ius perch. leasthorn is way [SEP]']
[ 150/2000] tot_loss=4.627 (perp=14.179, rec=0.797, cos=0.994), tot_loss_proj:4.652 [t=0.23s]
prediction: ['[CLS] deaths wife flemingterhorse ended scent [SEP]']
[ 200/2000] tot_loss=4.101 (perp=12.484, rec=0.613, cos=0.991), tot_loss_proj:4.335 [t=0.24s]
prediction: ['[CLS] mph than jazz.horse ended scent [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.938 (perp=12.104, rec=0.538, cos=0.978), tot_loss_proj:4.292 [t=0.19s]
prediction: ['[CLS] jazz than mph than8 isrence [SEP]']
[ 300/2000] tot_loss=3.714 (perp=11.283, rec=0.488, cos=0.969), tot_loss_proj:4.196 [t=0.22s]
prediction: ['[CLS] mary than feet than mary isrence [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.359 (perp=9.624, rec=0.469, cos=0.965), tot_loss_proj:3.868 [t=0.22s]
prediction: ['[CLS] feet than mary than mary isrence [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.319 (perp=9.451, rec=0.475, cos=0.953), tot_loss_proj:3.747 [t=0.21s]
prediction: ['[CLS] feet than mary iserty than mary [SEP]']
[ 450/2000] tot_loss=3.373 (perp=9.926, rec=0.443, cos=0.944), tot_loss_proj:3.813 [t=0.23s]
prediction: ['[CLS] crotch than mary is °f than mary [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.351 (perp=9.926, rec=0.426, cos=0.940), tot_loss_proj:3.812 [t=0.18s]
prediction: ['[CLS] crotch than mary is °f than mary [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.194 (perp=8.830, rec=0.474, cos=0.954), tot_loss_proj:3.692 [t=0.23s]
prediction: ['[CLS] crotch mary is jews shorter than mary [SEP]']
[ 600/2000] tot_loss=3.042 (perp=8.419, rec=0.418, cos=0.940), tot_loss_proj:3.534 [t=0.18s]
prediction: ['[CLS] feet mary is °f shorter than mary [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.686 (perp=6.672, rec=0.421, cos=0.930), tot_loss_proj:3.397 [t=0.17s]
prediction: ['[CLS] mary is °f feet shorter than mary [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.662 (perp=6.672, rec=0.403, cos=0.924), tot_loss_proj:3.394 [t=0.19s]
prediction: ['[CLS] mary is °f feet shorter than mary [SEP]']
[ 750/2000] tot_loss=2.657 (perp=6.672, rec=0.404, cos=0.918), tot_loss_proj:3.392 [t=0.18s]
prediction: ['[CLS] mary is °f feet shorter than mary [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.041 (perp=8.656, rec=0.398, cos=0.912), tot_loss_proj:3.786 [t=0.18s]
prediction: ['[CLS] mary shorter °f feet shorter than mary [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.020 (perp=8.656, rec=0.383, cos=0.906), tot_loss_proj:3.786 [t=0.17s]
prediction: ['[CLS] mary shorter °f feet shorter than mary [SEP]']
[ 900/2000] tot_loss=3.154 (perp=9.367, rec=0.379, cos=0.902), tot_loss_proj:3.739 [t=0.20s]
prediction: ['[CLS] mary shorter °f mph shorter than mary [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.150 (perp=9.367, rec=0.381, cos=0.895), tot_loss_proj:3.740 [t=0.18s]
prediction: ['[CLS] mary shorter °f mph shorter than mary [SEP]']
Attempt swap
[1000/2000] tot_loss=3.404 (perp=10.700, rec=0.373, cos=0.891), tot_loss_proj:3.985 [t=0.22s]
prediction: ['[CLS] symptoms shorter °f mph shorter than mary [SEP]']
[1050/2000] tot_loss=3.410 (perp=10.700, rec=0.382, cos=0.888), tot_loss_proj:3.989 [t=0.17s]
prediction: ['[CLS] symptoms shorter °f mph shorter than mary [SEP]']
Attempt swap
[1100/2000] tot_loss=3.398 (perp=10.700, rec=0.374, cos=0.884), tot_loss_proj:3.988 [t=0.18s]
prediction: ['[CLS] symptoms shorter °f mph shorter than mary [SEP]']
Attempt swap
[1150/2000] tot_loss=3.391 (perp=10.700, rec=0.370, cos=0.881), tot_loss_proj:3.990 [t=0.22s]
prediction: ['[CLS] symptoms shorter °f mph shorter than mary [SEP]']
[1200/2000] tot_loss=3.384 (perp=10.700, rec=0.366, cos=0.878), tot_loss_proj:3.991 [t=0.18s]
prediction: ['[CLS] symptoms shorter °f mph shorter than mary [SEP]']
Attempt swap
[1250/2000] tot_loss=3.372 (perp=10.645, rec=0.367, cos=0.876), tot_loss_proj:4.062 [t=0.17s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Attempt swap
[1300/2000] tot_loss=3.375 (perp=10.645, rec=0.372, cos=0.874), tot_loss_proj:4.059 [t=0.18s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
[1350/2000] tot_loss=3.366 (perp=10.645, rec=0.366, cos=0.872), tot_loss_proj:4.061 [t=0.25s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Attempt swap
[1400/2000] tot_loss=3.364 (perp=10.645, rec=0.365, cos=0.870), tot_loss_proj:4.061 [t=0.21s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Attempt swap
[1450/2000] tot_loss=3.355 (perp=10.645, rec=0.357, cos=0.869), tot_loss_proj:4.061 [t=0.18s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
[1500/2000] tot_loss=3.363 (perp=10.645, rec=0.367, cos=0.868), tot_loss_proj:4.062 [t=0.24s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Attempt swap
[1550/2000] tot_loss=3.351 (perp=10.645, rec=0.356, cos=0.866), tot_loss_proj:4.062 [t=0.19s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Attempt swap
[1600/2000] tot_loss=3.352 (perp=10.645, rec=0.358, cos=0.865), tot_loss_proj:4.062 [t=0.19s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
[1650/2000] tot_loss=3.353 (perp=10.645, rec=0.360, cos=0.864), tot_loss_proj:4.059 [t=0.18s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Attempt swap
[1700/2000] tot_loss=3.353 (perp=10.645, rec=0.361, cos=0.864), tot_loss_proj:4.065 [t=0.27s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Attempt swap
[1750/2000] tot_loss=3.353 (perp=10.645, rec=0.362, cos=0.863), tot_loss_proj:4.059 [t=0.22s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
[1800/2000] tot_loss=3.350 (perp=10.645, rec=0.359, cos=0.862), tot_loss_proj:4.060 [t=0.18s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Attempt swap
[1850/2000] tot_loss=3.350 (perp=10.645, rec=0.359, cos=0.862), tot_loss_proj:4.061 [t=0.18s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Attempt swap
[1900/2000] tot_loss=3.356 (perp=10.645, rec=0.366, cos=0.861), tot_loss_proj:4.060 [t=0.19s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
[1950/2000] tot_loss=3.351 (perp=10.645, rec=0.362, cos=0.860), tot_loss_proj:4.062 [t=0.17s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Attempt swap
[2000/2000] tot_loss=3.355 (perp=10.645, rec=0.366, cos=0.860), tot_loss_proj:4.062 [t=0.18s]
prediction: ['[CLS] syllables shorter °f mph shorter than mary [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] mary is shorter than five feet. [SEP]
========================
predicted: 
========================
[CLS] syllables shorter °f mph shorter than mary [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.824 | p: 55.556 | r: 62.500
rouge2     | fm: 13.333 | p: 12.500 | r: 14.286
rougeL     | fm: 47.059 | p: 44.444 | r: 50.000
rougeLsum  | fm: 47.059 | p: 44.444 | r: 50.000
r1fm+r2fm = 72.157

[Aggregate metrics]:
rouge1     | fm: 73.669 | p: 73.963 | r: 73.690
rouge2     | fm: 35.773 | p: 35.877 | r: 35.916
rougeL     | fm: 64.491 | p: 64.737 | r: 64.487
rougeLsum  | fm: 64.827 | p: 65.068 | r: 64.784
r1fm+r2fm = 109.442

input #41 time: 0:08:08 | total time: 5:45:29


Running input #42 of 100.
reference: 
========================
She has enough of a problem as it is.
========================
average of cosine similarity 0.9992277228604689
highest_index [0]
highest [0.9992277228604689]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2016, 2038, 2438, 1997, 1037, 3291, 2004, 2009, 2003, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] she has enough of a problem as it is. [SEP]']
[Init] best rec loss: 0.9195099472999573 for ['[CLS] only shooter /press como solid togetherando ‑堂 [SEP]']
[Init] best rec loss: 0.9177475571632385 for ['[CLS] reflex cross tres silk families part ●wind translated like [SEP]']
[Init] best rec loss: 0.9160884022712708 for ['[CLS] violence trees closed much multimament mall freedoms separated squeezed [SEP]']
[Init] best rec loss: 0.9051212668418884 for ['[CLS] screenings former would headarty methyl saint bennett glenn ki [SEP]']
[Init] best rec loss: 0.8916860222816467 for ['[CLS] flock claimed jon domestic intelligence climax everywhere coal still census [SEP]']
[Init] best rec loss: 0.8842885494232178 for ['[CLS] boys # troy bel welcome honey sui application opera lark [SEP]']
[Init] best rec loss: 0.880082368850708 for ['[CLS] south historic maya hayden宀 clerkion coverage former tuesday [SEP]']
[Init] best rec loss: 0.8406323790550232 for ['[CLS] mine time minor deep fort clues erwin son leader troubled [SEP]']
[Init] best rec loss: 0.8227308392524719 for ['[CLS] into movement responsible huh belief hall safe representativepose fellow [SEP]']
[Init] best perm rec loss: 0.8197659254074097 for ['[CLS] representative into huh responsible safe hall belief movement fellowpose [SEP]']
[Init] best perm rec loss: 0.8181493878364563 for ['[CLS] movement responsiblepose safe belief fellow hall representative huh into [SEP]']
[Init] best perm rec loss: 0.8146902918815613 for ['[CLS] fellow representative belief responsible hall movementpose into huh safe [SEP]']
[Init] best perm rec loss: 0.8133512139320374 for ['[CLS] huh representative movement belief fellow into hall responsiblepose safe [SEP]']
[Init] best perm rec loss: 0.8132941126823425 for ['[CLS] safe responsible fellow into hallpose belief movement representative huh [SEP]']
[Init] best perm rec loss: 0.8127557039260864 for ['[CLS] hall belief representative into responsible movement safe huh fellowpose [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.015 (perp=12.490, rec=0.436, cos=0.081), tot_loss_proj:4.294 [t=0.24s]
prediction: ['[CLS] affairs / term super always same also flashes effort pl [SEP]']
[ 100/2000] tot_loss=2.831 (perp=12.248, rec=0.344, cos=0.037), tot_loss_proj:4.437 [t=0.23s]
prediction: ['[CLS] roy a problem enough either enough no she problem as [SEP]']
[ 150/2000] tot_loss=2.159 (perp=9.264, rec=0.273, cos=0.034), tot_loss_proj:3.875 [t=0.18s]
prediction: ['[CLS] as a problem enough enough enough enough she problem as [SEP]']
[ 200/2000] tot_loss=2.099 (perp=8.939, rec=0.237, cos=0.074), tot_loss_proj:3.835 [t=0.18s]
prediction: ['[CLS] as a problem has was has enough she problem as [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.436 (perp=6.271, rec=0.166, cos=0.016), tot_loss_proj:3.118 [t=0.23s]
prediction: ['[CLS] as a problem it is she has enough problem as [SEP]']
[ 300/2000] tot_loss=1.587 (perp=7.317, rec=0.113, cos=0.010), tot_loss_proj:3.439 [t=0.18s]
prediction: ['[CLS] as of. it is she has enough problem as [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.418 (perp=6.494, rec=0.108, cos=0.011), tot_loss_proj:3.255 [t=0.22s]
prediction: ['[CLS] as of it is she has enough problem as. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.435 (perp=6.655, rec=0.094, cos=0.010), tot_loss_proj:3.216 [t=0.18s]
prediction: ['[CLS]. of it is she has enough problem. as [SEP]']
[ 450/2000] tot_loss=1.447 (perp=6.655, rec=0.107, cos=0.009), tot_loss_proj:3.219 [t=0.18s]
prediction: ['[CLS]. of it is she has enough problem. as [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.397 (perp=6.440, rec=0.101, cos=0.009), tot_loss_proj:3.034 [t=0.17s]
prediction: ['[CLS].. of it is she has enough problem as [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.283 (perp=5.906, rec=0.092, cos=0.009), tot_loss_proj:2.986 [t=0.18s]
prediction: ['[CLS]. as of it is she has enough problem. [SEP]']
[ 600/2000] tot_loss=1.287 (perp=5.906, rec=0.097, cos=0.008), tot_loss_proj:2.993 [t=0.25s]
prediction: ['[CLS]. as of it is she has enough problem. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.277 (perp=5.906, rec=0.088, cos=0.008), tot_loss_proj:2.994 [t=0.18s]
prediction: ['[CLS]. as of it is she has enough problem. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.278 (perp=5.906, rec=0.090, cos=0.007), tot_loss_proj:2.995 [t=0.19s]
prediction: ['[CLS]. as of it is she has enough problem. [SEP]']
[ 750/2000] tot_loss=1.277 (perp=5.906, rec=0.088, cos=0.007), tot_loss_proj:3.000 [t=0.19s]
prediction: ['[CLS]. as of it is she has enough problem. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.276 (perp=5.906, rec=0.088, cos=0.007), tot_loss_proj:2.991 [t=0.18s]
prediction: ['[CLS]. as of it is she has enough problem. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.271 (perp=5.906, rec=0.083, cos=0.007), tot_loss_proj:3.000 [t=0.22s]
prediction: ['[CLS]. as of it is she has enough problem. [SEP]']
[ 900/2000] tot_loss=1.269 (perp=5.906, rec=0.082, cos=0.006), tot_loss_proj:3.001 [t=0.22s]
prediction: ['[CLS]. as of it is she has enough problem. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.456 (perp=6.801, rec=0.090, cos=0.006), tot_loss_proj:3.206 [t=0.30s]
prediction: ['[CLS] a as of it is she has enough problem. [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.284 (perp=5.845, rec=0.106, cos=0.009), tot_loss_proj:2.712 [t=0.24s]
prediction: ['[CLS] a problem as of it is she has enough. [SEP]']
[1050/2000] tot_loss=1.252 (perp=5.845, rec=0.077, cos=0.006), tot_loss_proj:2.693 [t=0.24s]
prediction: ['[CLS] a problem as of it is she has enough. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.075 (perp=4.924, rec=0.084, cos=0.006), tot_loss_proj:2.482 [t=0.24s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.071 (perp=4.924, rec=0.081, cos=0.006), tot_loss_proj:2.480 [t=0.18s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
[1200/2000] tot_loss=1.066 (perp=4.924, rec=0.075, cos=0.006), tot_loss_proj:2.483 [t=0.21s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.071 (perp=4.924, rec=0.080, cos=0.006), tot_loss_proj:2.483 [t=0.24s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.071 (perp=4.924, rec=0.081, cos=0.006), tot_loss_proj:2.478 [t=0.17s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
[1350/2000] tot_loss=1.067 (perp=4.924, rec=0.077, cos=0.005), tot_loss_proj:2.486 [t=0.25s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.056 (perp=4.924, rec=0.065, cos=0.005), tot_loss_proj:2.484 [t=0.22s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.071 (perp=4.924, rec=0.080, cos=0.005), tot_loss_proj:2.486 [t=0.21s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
[1500/2000] tot_loss=1.069 (perp=4.924, rec=0.079, cos=0.005), tot_loss_proj:2.484 [t=0.18s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.069 (perp=4.924, rec=0.079, cos=0.005), tot_loss_proj:2.487 [t=0.22s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.066 (perp=4.924, rec=0.076, cos=0.005), tot_loss_proj:2.485 [t=0.27s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
[1650/2000] tot_loss=1.076 (perp=4.924, rec=0.086, cos=0.005), tot_loss_proj:2.485 [t=0.17s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.060 (perp=4.924, rec=0.070, cos=0.005), tot_loss_proj:2.483 [t=0.20s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.069 (perp=4.924, rec=0.079, cos=0.005), tot_loss_proj:2.486 [t=0.17s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
[1800/2000] tot_loss=1.068 (perp=4.924, rec=0.078, cos=0.005), tot_loss_proj:2.484 [t=0.17s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.059 (perp=4.924, rec=0.069, cos=0.005), tot_loss_proj:2.484 [t=0.19s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.060 (perp=4.924, rec=0.070, cos=0.005), tot_loss_proj:2.479 [t=0.25s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
[1950/2000] tot_loss=1.065 (perp=4.924, rec=0.075, cos=0.005), tot_loss_proj:2.484 [t=0.25s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.061 (perp=4.924, rec=0.071, cos=0.005), tot_loss_proj:2.489 [t=0.19s]
prediction: ['[CLS] as a problem of it is she has enough. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] she has enough of a problem as it is. [SEP]
========================
predicted: 
========================
[CLS] as a problem of it is she has enough. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 74.208 | p: 74.475 | r: 74.240
rouge2     | fm: 35.762 | p: 35.743 | r: 35.941
rougeL     | fm: 64.367 | p: 64.647 | r: 64.197
rougeLsum  | fm: 64.535 | p: 64.773 | r: 64.540
r1fm+r2fm = 109.970

input #42 time: 0:08:18 | total time: 5:53:47


Running input #43 of 100.
reference: 
========================
Every student has to come up with three arguments that show that some condition proposed by Bill is wrong.
========================
average of cosine similarity 0.9993892958061774
highest_index [0]
highest [0.9993892958061774]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[ 101, 2296, 3076, 2038, 2000, 2272, 2039, 2007, 2093, 9918, 2008, 2265,
         2008, 2070, 4650, 3818, 2011, 3021, 2003, 3308, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]']
[Init] best rec loss: 0.941371500492096 for ['[CLS] unaffected peter interval sporting campaign singular relieved start shooting club helleche date operative either meredith occupied lamagee metals [SEP]']
[Init] best rec loss: 0.9361624121665955 for ['[CLS]work beginning refugees accurate ever livesि thesis skirt gran language kingsley scrub regis opera al kin tri all bearing [SEP]']
[Init] best rec loss: 0.9320390224456787 for ['[CLS]nium truck register heart paper whitney subdivision pseudonym dog leapsner reply photon intense border nk blown sri artillery sad [SEP]']
[Init] best rec loss: 0.9182119369506836 for ['[CLS] rule blind third sheen a xu snarl brainific storm median head you gathering mono operational hard patti nba coach [SEP]']
[Init] best rec loss: 0.9167119264602661 for ['[CLS] army duck abolished [MASK]kyumons spokeverse how und purchase joined midstiard beijing breakfastcter after reserve promise [SEP]']
[Init] best rec loss: 0.9060932993888855 for ['[CLS]room tango plumageote along turn smashwords living bill always energy machines threaten glacier formed t patent proik pick [SEP]']
[Init] best rec loss: 0.9036861062049866 for ['[CLS] surprise santa nell games circumstances may enclosed pilot late surf graduation not tuneau date payne oceanrogate big fellow [SEP]']
[Init] best rec loss: 0.8932493925094604 for ['[CLS] awesome entertainment below electricity sage dreamerpressing colliery harvest share color bed titanic rapid were before features titular baymura [SEP]']
[Init] best perm rec loss: 0.8914357423782349 for ['[CLS]pressing colliery titanic were before titularmura color share features entertainment below dreamer awesome bay rapid sage bed electricity harvest [SEP]']
[Init] best perm rec loss: 0.8903899192810059 for ['[CLS] sage entertainmentpressing colliery titanic harvest color awesomemura titular before features bed dreamer electricity below were rapid share bay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.757 (perp=11.343, rec=0.421, cos=0.067), tot_loss_proj:4.181 [t=0.18s]
prediction: ['[CLS] sooner music bipolar compliant creative gorgeous angeles " cerebral " inspired comics every part _ super drug screaming presented drill [SEP]']
[ 100/2000] tot_loss=2.935 (perp=12.611, rec=0.364, cos=0.049), tot_loss_proj:4.409 [t=0.19s]
prediction: ['[CLS] matthew music documentary mistaken song popular previous musical latvian story inspired theory every straight within " theory big proposed brad [SEP]']
[ 150/2000] tot_loss=2.922 (perp=13.112, rec=0.280, cos=0.019), tot_loss_proj:4.524 [t=0.18s]
prediction: ['[CLS] saxony music acidspromising song popular listeners varioussius story proposed arguments every straight within of student direct three bill [SEP]']
[ 200/2000] tot_loss=2.637 (perp=11.961, rec=0.231, cos=0.015), tot_loss_proj:4.285 [t=0.18s]
prediction: ['[CLS] bill music proposedroving song popular listeners several every sin proposed arguments every up within " student direct three bill [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.378 (perp=10.838, rec=0.199, cos=0.011), tot_loss_proj:4.042 [t=0.18s]
prediction: ['[CLS] bill television proposed fundamental song showroving several students - proposed arguments every up within " student with three bill [SEP]']
[ 300/2000] tot_loss=2.091 (perp=9.522, rec=0.179, cos=0.008), tot_loss_proj:3.712 [t=0.23s]
prediction: ['[CLS] bill television proposed must show show that several students - proposed arguments every up. " student with three bill [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.263 (perp=9.707, rec=0.289, cos=0.033), tot_loss_proj:3.832 [t=0.22s]
prediction: ['[CLS] future inspired marketed has to show that several gives best written arguments every standard. rock student bill three arguments [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.204 (perp=9.860, rec=0.219, cos=0.013), tot_loss_proj:3.855 [t=0.29s]
prediction: ['[CLS] future theme argue has to shows that best gives several written arguments every standard. bill student bill three bill [SEP]']
[ 450/2000] tot_loss=2.229 (perp=10.114, rec=0.196, cos=0.010), tot_loss_proj:3.905 [t=0.27s]
prediction: ['[CLS] wrong theme student has to shows thatly with several written arguments every standard. bill student bill three bill [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.997 (perp=9.040, rec=0.180, cos=0.009), tot_loss_proj:3.666 [t=0.24s]
prediction: ['[CLS] wrong theme student has to shows that bill with several written arguments every standard. bill student - three bill [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.891 (perp=8.527, rec=0.177, cos=0.009), tot_loss_proj:3.581 [t=0.18s]
prediction: ['[CLS] wrong every student has to wrong that bill with some written arguments inspired standard. bill student - three bill [SEP]']
[ 600/2000] tot_loss=2.038 (perp=9.302, rec=0.171, cos=0.006), tot_loss_proj:3.723 [t=0.23s]
prediction: ['[CLS] wrong every proposed has to wrong that bill with some written arguments inspired standard. bill student a three bill [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.067 (perp=9.492, rec=0.163, cos=0.006), tot_loss_proj:3.770 [t=0.23s]
prediction: ['[CLS] wrong every proposed has with shows that bill with some written arguments. theme a bill student a three bill [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.986 (perp=9.090, rec=0.163, cos=0.005), tot_loss_proj:3.690 [t=0.23s]
prediction: ['[CLS] wrong every proposed has with shows that written up some bill arguments. theme a bill student a three bill [SEP]']
[ 750/2000] tot_loss=1.951 (perp=8.970, rec=0.152, cos=0.005), tot_loss_proj:3.678 [t=0.22s]
prediction: ['[CLS] wrong every condition has with shows that written up some bill arguments. theme a bill student a three bill [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.909 (perp=8.776, rec=0.148, cos=0.005), tot_loss_proj:3.580 [t=0.24s]
prediction: ['[CLS] wrong every proposed has with theme that written up some bill arguments. shows a bill student a three bill [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.833 (perp=8.377, rec=0.152, cos=0.005), tot_loss_proj:3.543 [t=0.18s]
prediction: ['[CLS] wrong every condition has with arguments that written up some bill theme. shows a bill student a three bill [SEP]']
[ 900/2000] tot_loss=1.832 (perp=8.377, rec=0.151, cos=0.005), tot_loss_proj:3.543 [t=0.18s]
prediction: ['[CLS] wrong every condition has with arguments that written up some bill theme. shows a bill student a three bill [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.800 (perp=8.262, rec=0.143, cos=0.005), tot_loss_proj:3.504 [t=0.18s]
prediction: ['[CLS] wrong every condition has with arguments that written up some bill theme student shows a bill. a three bill [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.761 (perp=8.077, rec=0.141, cos=0.005), tot_loss_proj:3.458 [t=0.18s]
prediction: ['[CLS] wrong every condition has with arguments that shows up some bill theme student written a bill. a three bill [SEP]']
[1050/2000] tot_loss=1.768 (perp=8.077, rec=0.148, cos=0.005), tot_loss_proj:3.462 [t=0.23s]
prediction: ['[CLS] wrong every condition has with arguments that shows up some bill theme student written a bill. a three bill [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.726 (perp=7.894, rec=0.142, cos=0.005), tot_loss_proj:3.461 [t=0.18s]
prediction: ['[CLS] wrong every condition has written arguments that shows up some bill theme student with a bill. a three bill [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.668 (perp=7.592, rec=0.145, cos=0.005), tot_loss_proj:3.403 [t=0.20s]
prediction: ['[CLS] wrong every condition has three arguments that show up some bill theme student with a bill. a written bill [SEP]']
[1200/2000] tot_loss=1.618 (perp=7.379, rec=0.137, cos=0.004), tot_loss_proj:3.372 [t=0.21s]
prediction: ['[CLS] wrong every condition has three arguments that show up some bill thru student with a bill. a written bill [SEP]']
Attempt swap
[1250/2000] tot_loss=1.613 (perp=7.379, rec=0.132, cos=0.004), tot_loss_proj:3.369 [t=0.25s]
prediction: ['[CLS] wrong every condition has three arguments that show up some bill thru student with a bill. a written bill [SEP]']
Attempt swap
[1300/2000] tot_loss=1.619 (perp=7.379, rec=0.139, cos=0.004), tot_loss_proj:3.370 [t=0.18s]
prediction: ['[CLS] wrong every condition has three arguments that show up some bill thru student with a bill. a written bill [SEP]']
[1350/2000] tot_loss=1.608 (perp=7.379, rec=0.128, cos=0.004), tot_loss_proj:3.366 [t=0.26s]
prediction: ['[CLS] wrong every condition has three arguments that show up some bill thru student with a bill. a written bill [SEP]']
Attempt swap
[1400/2000] tot_loss=1.617 (perp=7.379, rec=0.137, cos=0.004), tot_loss_proj:3.368 [t=0.24s]
prediction: ['[CLS] wrong every condition has three arguments that show up some bill thru student with a bill. a written bill [SEP]']
Attempt swap
[1450/2000] tot_loss=1.567 (perp=7.149, rec=0.133, cos=0.004), tot_loss_proj:3.339 [t=0.20s]
prediction: ['[CLS] wrong every condition has three arguments that show up some bill show student with a bill. a written bill [SEP]']
[1500/2000] tot_loss=1.566 (perp=7.149, rec=0.132, cos=0.004), tot_loss_proj:3.338 [t=0.20s]
prediction: ['[CLS] wrong every condition has three arguments that show up some bill show student with a bill. a written bill [SEP]']
Attempt swap
[1550/2000] tot_loss=1.573 (perp=7.149, rec=0.139, cos=0.004), tot_loss_proj:3.344 [t=0.18s]
prediction: ['[CLS] wrong every condition has three arguments that show up some bill show student with a bill. a written bill [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.547 (perp=7.014, rec=0.140, cos=0.004), tot_loss_proj:3.304 [t=0.22s]
prediction: ['[CLS] every wrong condition has three arguments that show up some bill show student with a bill. a written bill [SEP]']
[1650/2000] tot_loss=1.536 (perp=7.014, rec=0.129, cos=0.004), tot_loss_proj:3.303 [t=0.20s]
prediction: ['[CLS] every wrong condition has three arguments that show up some bill show student with a bill. a written bill [SEP]']
Attempt swap
[1700/2000] tot_loss=1.541 (perp=7.014, rec=0.134, cos=0.004), tot_loss_proj:3.307 [t=0.26s]
prediction: ['[CLS] every wrong condition has three arguments that show up some bill show student with a bill. a written bill [SEP]']
Attempt swap
[1750/2000] tot_loss=1.532 (perp=7.014, rec=0.125, cos=0.004), tot_loss_proj:3.305 [t=0.20s]
prediction: ['[CLS] every wrong condition has three arguments that show up some bill show student with a bill. a written bill [SEP]']
[1800/2000] tot_loss=1.536 (perp=7.014, rec=0.128, cos=0.004), tot_loss_proj:3.309 [t=0.18s]
prediction: ['[CLS] every wrong condition has three arguments that show up some bill show student with a bill. a written bill [SEP]']
Attempt swap
[1850/2000] tot_loss=1.543 (perp=7.014, rec=0.135, cos=0.004), tot_loss_proj:3.308 [t=0.18s]
prediction: ['[CLS] every wrong condition has three arguments that show up some bill show student with a bill. a written bill [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.516 (perp=6.886, rec=0.135, cos=0.004), tot_loss_proj:3.269 [t=0.19s]
prediction: ['[CLS] every wrong condition has three arguments that show up some bill show student with a written bill. a bill [SEP]']
[1950/2000] tot_loss=1.522 (perp=6.886, rec=0.140, cos=0.004), tot_loss_proj:3.273 [t=0.22s]
prediction: ['[CLS] every wrong condition has three arguments that show up some bill show student with a written bill. a bill [SEP]']
Attempt swap
[2000/2000] tot_loss=1.513 (perp=6.886, rec=0.131, cos=0.004), tot_loss_proj:3.270 [t=0.20s]
prediction: ['[CLS] every wrong condition has three arguments that show up some bill show student with a written bill. a bill [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]
========================
predicted: 
========================
[CLS] every wrong condition has three arguments that show up some bill show student with a written bill. a bill [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 47.619 | p: 47.619 | r: 47.619
rougeLsum  | fm: 47.619 | p: 47.619 | r: 47.619
r1fm+r2fm = 91.429

[Aggregate metrics]:
rouge1     | fm: 74.191 | p: 74.454 | r: 74.143
rouge2     | fm: 35.538 | p: 35.531 | r: 35.691
rougeL     | fm: 63.810 | p: 64.033 | r: 63.811
rougeLsum  | fm: 64.119 | p: 64.422 | r: 64.136
r1fm+r2fm = 109.730

input #43 time: 0:08:23 | total time: 6:02:11


Running input #44 of 100.
reference: 
========================
Kim alienates cats and beat his dog.
========================
average of cosine similarity 0.9993126822858673
highest_index [0]
highest [0.9993126822858673]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 5035, 7344, 8520, 8870, 1998, 3786, 2010, 3899, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] kim alienates cats and beat his dog. [SEP]']
[Init] best rec loss: 1.0216113328933716 for ['[CLS] vineyard sterling michigan bat hot boltedpati cannot matter [SEP]']
[Init] best rec loss: 0.9771472215652466 for ['[CLS] jihad much complex marshall deadline [SEP] terminus volume japan [SEP]']
[Init] best rec loss: 0.9380818605422974 for ['[CLS] attempt ll foreign suck off spy gain app promoted [SEP]']
[Init] best rec loss: 0.9156078100204468 for ['[CLS] glacial examlip eat condition von wonder channel junk [SEP]']
[Init] best rec loss: 0.915208637714386 for ['[CLS] cooled best teams stellaxide staffed qualified will roll [SEP]']
[Init] best rec loss: 0.9150818586349487 for ['[CLS] cigarette harvey givensso nurse una rash beautiful inquired [SEP]']
[Init] best rec loss: 0.9134103655815125 for ['[CLS] sir glimpse license faun frame scars principleess [SEP]']
[Init] best rec loss: 0.9127835631370544 for ['[CLS]torewives corps answer bombs organization federation fine bronze [SEP]']
[Init] best rec loss: 0.8829893469810486 for ['[CLS]⁄ lance assigns edmund missouri other. started dan [SEP]']
[Init] best perm rec loss: 0.8820619583129883 for ['[CLS] missouri started edmund dan other lance⁄. assigns [SEP]']
[Init] best perm rec loss: 0.8815537095069885 for ['[CLS] lance dan assigns. other started⁄ edmund missouri [SEP]']
[Init] best perm rec loss: 0.8798965811729431 for ['[CLS] lance started edmund.⁄ other missouri assigns dan [SEP]']
[Init] best perm rec loss: 0.8791020512580872 for ['[CLS]⁄ lance edmund. assigns other started missouri dan [SEP]']
[Init] best perm rec loss: 0.8787437081336975 for ['[CLS] other lance. started missouri assigns edmund⁄ dan [SEP]']
[Init] best perm rec loss: 0.8781583905220032 for ['[CLS] dan lance edmund missouri other started. assigns⁄ [SEP]']
[Init] best perm rec loss: 0.8779261112213135 for ['[CLS] assigns lance. started⁄ other dan edmund missouri [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.904 (perp=11.148, rec=0.681, cos=0.993), tot_loss_proj:4.190 [t=0.17s]
prediction: ['[CLS] just good seen that tempo 発 his edmund abruptly [SEP]']
[ 100/2000] tot_loss=3.938 (perp=12.161, rec=0.532, cos=0.974), tot_loss_proj:4.432 [t=0.18s]
prediction: ['[CLS]. cats language helped beat airbus beat cats finger [SEP]']
[ 150/2000] tot_loss=3.849 (perp=12.097, rec=0.471, cos=0.959), tot_loss_proj:4.414 [t=0.18s]
prediction: ['[CLS]. cats language uncle beat casualties beat cats dog [SEP]']
[ 200/2000] tot_loss=3.822 (perp=12.148, rec=0.447, cos=0.945), tot_loss_proj:4.435 [t=0.19s]
prediction: ['[CLS]. cats language lucivar beat casualties beat cats dog [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.336 (perp=9.351, rec=0.509, cos=0.957), tot_loss_proj:3.820 [t=0.18s]
prediction: ['[CLS] beat kim - cats eyes constable beat cats. [SEP]']
[ 300/2000] tot_loss=3.832 (perp=12.276, rec=0.422, cos=0.955), tot_loss_proj:4.427 [t=0.17s]
prediction: ['[CLS] beat kim \\ cats eyes stephenates eggs dog [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.688 (perp=11.772, rec=0.396, cos=0.938), tot_loss_proj:4.345 [t=0.27s]
prediction: ['[CLS] beat kim among dog \\ stephenates kim and [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.735 (perp=11.717, rec=0.460, cos=0.932), tot_loss_proj:4.263 [t=0.18s]
prediction: ['[CLS] beat baroque among dog.ates ginger anddents [SEP]']
[ 450/2000] tot_loss=3.770 (perp=12.272, rec=0.387, cos=0.929), tot_loss_proj:4.346 [t=0.18s]
prediction: ['[CLS] beat baroque grows dog.ates his andzziness [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.622 (perp=11.600, rec=0.371, cos=0.930), tot_loss_proj:4.275 [t=0.18s]
prediction: ['[CLS] beat－ his dog ⁱates among and comes [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=3.492 (perp=10.892, rec=0.377, cos=0.936), tot_loss_proj:4.123 [t=0.23s]
prediction: ['[CLS] beat shortlyates among his dog ⁱ andrmed [SEP]']
[ 600/2000] tot_loss=3.611 (perp=11.641, rec=0.346, cos=0.937), tot_loss_proj:4.236 [t=0.24s]
prediction: ['[CLS] beat shortlyates desert his dog ⁱ andrmed [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.460 (perp=10.971, rec=0.328, cos=0.937), tot_loss_proj:4.116 [t=0.22s]
prediction: ['[CLS] shortlyates cats his dog beatching andhyllum [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.269 (perp=9.997, rec=0.329, cos=0.940), tot_loss_proj:3.970 [t=0.31s]
prediction: ['[CLS] shortlyates and his dog beatching catshyllum [SEP]']
[ 750/2000] tot_loss=3.234 (perp=9.800, rec=0.331, cos=0.943), tot_loss_proj:3.916 [t=0.21s]
prediction: ['[CLS] shortlyates and his dog beat millieateshyllum [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.223 (perp=9.800, rec=0.318, cos=0.946), tot_loss_proj:3.921 [t=0.24s]
prediction: ['[CLS] shortlyates and his dog beat millieateshyllum [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.263 (perp=9.961, rec=0.325, cos=0.946), tot_loss_proj:3.953 [t=0.19s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
[ 900/2000] tot_loss=3.250 (perp=9.961, rec=0.310, cos=0.947), tot_loss_proj:3.955 [t=0.22s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.250 (perp=9.961, rec=0.310, cos=0.947), tot_loss_proj:3.952 [t=0.17s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1000/2000] tot_loss=3.248 (perp=9.961, rec=0.307, cos=0.948), tot_loss_proj:3.953 [t=0.18s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
[1050/2000] tot_loss=3.239 (perp=9.961, rec=0.298, cos=0.949), tot_loss_proj:3.950 [t=0.18s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1100/2000] tot_loss=3.252 (perp=9.961, rec=0.310, cos=0.949), tot_loss_proj:3.955 [t=0.18s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1150/2000] tot_loss=3.243 (perp=9.961, rec=0.301, cos=0.950), tot_loss_proj:3.953 [t=0.17s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
[1200/2000] tot_loss=3.245 (perp=9.961, rec=0.303, cos=0.950), tot_loss_proj:3.950 [t=0.25s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1250/2000] tot_loss=3.242 (perp=9.961, rec=0.299, cos=0.950), tot_loss_proj:3.957 [t=0.18s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1300/2000] tot_loss=3.241 (perp=9.961, rec=0.298, cos=0.951), tot_loss_proj:3.949 [t=0.20s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
[1350/2000] tot_loss=3.234 (perp=9.961, rec=0.291, cos=0.951), tot_loss_proj:3.948 [t=0.18s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1400/2000] tot_loss=3.233 (perp=9.961, rec=0.289, cos=0.952), tot_loss_proj:3.944 [t=0.18s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1450/2000] tot_loss=3.237 (perp=9.961, rec=0.293, cos=0.952), tot_loss_proj:3.946 [t=0.18s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
[1500/2000] tot_loss=3.237 (perp=9.961, rec=0.293, cos=0.952), tot_loss_proj:3.947 [t=0.20s]
prediction: ['[CLS] shortlyates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1550/2000] tot_loss=3.310 (perp=10.345, rec=0.289, cos=0.953), tot_loss_proj:3.835 [t=0.25s]
prediction: ['[CLS]－ates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1600/2000] tot_loss=3.319 (perp=10.345, rec=0.298, cos=0.953), tot_loss_proj:3.835 [t=0.25s]
prediction: ['[CLS]－ates and his dog beatchingateshyllum [SEP]']
[1650/2000] tot_loss=3.322 (perp=10.345, rec=0.300, cos=0.953), tot_loss_proj:3.833 [t=0.17s]
prediction: ['[CLS]－ates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1700/2000] tot_loss=3.312 (perp=10.345, rec=0.290, cos=0.953), tot_loss_proj:3.834 [t=0.24s]
prediction: ['[CLS]－ates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1750/2000] tot_loss=3.314 (perp=10.345, rec=0.292, cos=0.953), tot_loss_proj:3.839 [t=0.24s]
prediction: ['[CLS]－ates and his dog beatchingateshyllum [SEP]']
[1800/2000] tot_loss=3.320 (perp=10.345, rec=0.298, cos=0.954), tot_loss_proj:3.832 [t=0.23s]
prediction: ['[CLS]－ates and his dog beatchingateshyllum [SEP]']
Attempt swap
[1850/2000] tot_loss=3.335 (perp=10.440, rec=0.293, cos=0.954), tot_loss_proj:4.076 [t=0.22s]
prediction: ['[CLS]－ates and his dog beatching alienhyllum [SEP]']
Attempt swap
[1900/2000] tot_loss=3.339 (perp=10.440, rec=0.297, cos=0.954), tot_loss_proj:4.073 [t=0.23s]
prediction: ['[CLS]－ates and his dog beatching alienhyllum [SEP]']
[1950/2000] tot_loss=3.333 (perp=10.440, rec=0.290, cos=0.954), tot_loss_proj:4.072 [t=0.18s]
prediction: ['[CLS]－ates and his dog beatching alienhyllum [SEP]']
Attempt swap
[2000/2000] tot_loss=3.331 (perp=10.440, rec=0.289, cos=0.954), tot_loss_proj:4.075 [t=0.26s]
prediction: ['[CLS]－ates and his dog beatching alienhyllum [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] kim alienates cats and beat his dog. [SEP]
========================
predicted: 
========================
[CLS]－ates and his dog beatchingateshyllum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.500 | p: 71.429 | r: 55.556
rouge2     | fm: 14.286 | p: 16.667 | r: 12.500
rougeL     | fm: 62.500 | p: 71.429 | r: 55.556
rougeLsum  | fm: 62.500 | p: 71.429 | r: 55.556
r1fm+r2fm = 76.786

[Aggregate metrics]:
rouge1     | fm: 73.913 | p: 74.342 | r: 73.850
rouge2     | fm: 34.982 | p: 35.000 | r: 34.979
rougeL     | fm: 63.880 | p: 64.336 | r: 63.730
rougeLsum  | fm: 64.092 | p: 64.600 | r: 63.864
r1fm+r2fm = 108.895

input #44 time: 0:08:06 | total time: 6:10:17


Running input #45 of 100.
reference: 
========================
John's I stole bike.
========================
average of cosine similarity 0.999353611080195
highest_index [0]
highest [0.999353611080195]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2198,  1005,  1055,  1045, 10312,  7997,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] john's i stole bike. [SEP]"]
[Init] best rec loss: 0.9623914957046509 for ['[CLS] outskirts came too yourtered occupy tradition [SEP]']
[Init] best rec loss: 0.890116274356842 for ['[CLS] and general driving weak [SEP]akcede [SEP]']
[Init] best rec loss: 0.7756944298744202 for ['[CLS] video date prime tall lifeless grape person [SEP]']
[Init] best rec loss: 0.7738812565803528 for ['[CLS] orbit editor ring spread using jones yugoslav [SEP]']
[Init] best rec loss: 0.7658082246780396 for ['[CLS] expecting special scaleslock mhz wish ser [SEP]']
[Init] best rec loss: 0.7612343430519104 for ['[CLS] evening lose high design bankrupt caucus landscape [SEP]']
[Init] best rec loss: 0.7316742539405823 for ['[CLS] hadn quite about sit exit rugby mc [SEP]']
[Init] best perm rec loss: 0.7308976054191589 for ['[CLS] rugby mc about sit hadn quite exit [SEP]']
[Init] best perm rec loss: 0.7300025820732117 for ['[CLS] exit hadn rugby sit quite about mc [SEP]']
[Init] best perm rec loss: 0.7252820134162903 for ['[CLS] quite hadn about rugby exit mc sit [SEP]']
[Init] best perm rec loss: 0.722222626209259 for ['[CLS] exit about quite mc sit hadn rugby [SEP]']
[Init] best perm rec loss: 0.7214416265487671 for ['[CLS] sit rugby exit hadn quite about mc [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.250 (perp=9.631, rec=0.312, cos=0.012), tot_loss_proj:2.908 [t=0.17s]
prediction: ['[CLS] was father be bike hired dollar. [SEP]']
[ 100/2000] tot_loss=1.923 (perp=8.434, rec=0.230, cos=0.006), tot_loss_proj:2.256 [t=0.24s]
prediction: ['[CLS] i joseph s bike stole bike. [SEP]']
[ 150/2000] tot_loss=1.964 (perp=8.992, rec=0.160, cos=0.005), tot_loss_proj:2.814 [t=0.20s]
prediction: ['[CLS] i john s bike stole bike. [SEP]']
[ 200/2000] tot_loss=1.926 (perp=8.992, rec=0.122, cos=0.006), tot_loss_proj:2.832 [t=0.19s]
prediction: ['[CLS] i john s bike stole bike. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.804 (perp=8.396, rec=0.120, cos=0.005), tot_loss_proj:2.252 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[ 300/2000] tot_loss=1.785 (perp=8.396, rec=0.101, cos=0.004), tot_loss_proj:2.253 [t=0.22s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.775 (perp=8.396, rec=0.092, cos=0.004), tot_loss_proj:2.249 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.775 (perp=8.396, rec=0.092, cos=0.004), tot_loss_proj:2.248 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[ 450/2000] tot_loss=1.774 (perp=8.396, rec=0.091, cos=0.003), tot_loss_proj:2.249 [t=0.19s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.884 (perp=8.938, rec=0.094, cos=0.003), tot_loss_proj:2.748 [t=0.24s]
prediction: ['[CLS] john i s bike stole schedule. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.144 (perp=9.618, rec=0.212, cos=0.009), tot_loss_proj:2.531 [t=0.20s]
prediction: ['[CLS] john i staken stole bike. [SEP]']
[ 600/2000] tot_loss=1.787 (perp=8.396, rec=0.104, cos=0.004), tot_loss_proj:2.254 [t=0.24s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.816 (perp=8.396, rec=0.130, cos=0.006), tot_loss_proj:2.284 [t=0.23s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.780 (perp=8.396, rec=0.096, cos=0.004), tot_loss_proj:2.275 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[ 750/2000] tot_loss=1.809 (perp=8.396, rec=0.126, cos=0.004), tot_loss_proj:2.281 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.771 (perp=8.396, rec=0.088, cos=0.003), tot_loss_proj:2.278 [t=0.19s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.762 (perp=8.396, rec=0.080, cos=0.003), tot_loss_proj:2.272 [t=0.22s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[ 900/2000] tot_loss=1.755 (perp=8.396, rec=0.073, cos=0.003), tot_loss_proj:2.283 [t=0.24s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.759 (perp=8.396, rec=0.077, cos=0.003), tot_loss_proj:2.273 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.765 (perp=8.396, rec=0.084, cos=0.003), tot_loss_proj:2.273 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[1050/2000] tot_loss=1.755 (perp=8.396, rec=0.073, cos=0.003), tot_loss_proj:2.268 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.746 (perp=8.321, rec=0.079, cos=0.003), tot_loss_proj:2.989 [t=0.25s]
prediction: ['[CLS] john i s lions stole bike. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.746 (perp=8.321, rec=0.079, cos=0.003), tot_loss_proj:2.986 [t=0.25s]
prediction: ['[CLS] john i s lions stole bike. [SEP]']
[1200/2000] tot_loss=1.748 (perp=8.321, rec=0.081, cos=0.003), tot_loss_proj:2.984 [t=0.25s]
prediction: ['[CLS] john i s lions stole bike. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.747 (perp=8.321, rec=0.080, cos=0.003), tot_loss_proj:2.984 [t=0.18s]
prediction: ['[CLS] john i s lions stole bike. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.745 (perp=8.321, rec=0.078, cos=0.003), tot_loss_proj:2.976 [t=0.22s]
prediction: ['[CLS] john i s lions stole bike. [SEP]']
[1350/2000] tot_loss=1.748 (perp=8.321, rec=0.081, cos=0.003), tot_loss_proj:2.981 [t=0.19s]
prediction: ['[CLS] john i s lions stole bike. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.747 (perp=8.321, rec=0.080, cos=0.002), tot_loss_proj:2.980 [t=0.22s]
prediction: ['[CLS] john i s lions stole bike. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.749 (perp=8.396, rec=0.067, cos=0.002), tot_loss_proj:2.276 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[1500/2000] tot_loss=1.758 (perp=8.396, rec=0.076, cos=0.002), tot_loss_proj:2.273 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.757 (perp=8.396, rec=0.075, cos=0.002), tot_loss_proj:2.275 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.753 (perp=8.396, rec=0.072, cos=0.002), tot_loss_proj:2.275 [t=0.24s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[1650/2000] tot_loss=1.755 (perp=8.396, rec=0.074, cos=0.002), tot_loss_proj:2.275 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.759 (perp=8.396, rec=0.077, cos=0.002), tot_loss_proj:2.272 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.755 (perp=8.396, rec=0.073, cos=0.002), tot_loss_proj:2.276 [t=0.18s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[1800/2000] tot_loss=1.765 (perp=8.396, rec=0.083, cos=0.002), tot_loss_proj:2.275 [t=0.23s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.754 (perp=8.396, rec=0.073, cos=0.002), tot_loss_proj:2.270 [t=0.28s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.769 (perp=8.396, rec=0.087, cos=0.002), tot_loss_proj:2.278 [t=0.17s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[1950/2000] tot_loss=1.754 (perp=8.396, rec=0.072, cos=0.002), tot_loss_proj:2.277 [t=0.20s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.764 (perp=8.396, rec=0.083, cos=0.002), tot_loss_proj:2.273 [t=0.21s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] john's i stole bike. [SEP]
========================
predicted: 
========================
[CLS] john i s bike stole bike. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 46.154 | p: 42.857 | r: 50.000
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 139.487

[Aggregate metrics]:
rouge1     | fm: 74.370 | p: 74.685 | r: 74.351
rouge2     | fm: 35.227 | p: 35.143 | r: 35.392
rougeL     | fm: 64.312 | p: 64.596 | r: 64.306
rougeLsum  | fm: 64.472 | p: 64.802 | r: 64.350
r1fm+r2fm = 109.597

input #45 time: 0:08:06 | total time: 6:18:23


Running input #46 of 100.
reference: 
========================
The witch went into the forest by vanishing.
========================
average of cosine similarity 0.9993622173126959
highest_index [0]
highest [0.9993622173126959]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1996,  6965,  2253,  2046,  1996,  3224,  2011, 24866,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] the witch went into the forest by vanishing. [SEP]']
[Init] best rec loss: 0.7126263380050659 for ['[CLS] tripume mackenzie enterprise crunch threshold engine free down [SEP]']
[Init] best rec loss: 0.7099688053131104 for ['[CLS] terms masters nightingale appeared calling tropical has brant returns [SEP]']
[Init] best rec loss: 0.7057819366455078 for ['[CLS] gear rest roninpment s members university evenly matthew [SEP]']
[Init] best rec loss: 0.7033528685569763 for ['[CLS] hell advent shared moderatenton drivendity kennedyided [SEP]']
[Init] best rec loss: 0.698776125907898 for ['[CLS] suffix joe clay just crewmun warn cycle flows [SEP]']
[Init] best rec loss: 0.6938488483428955 for ['[CLS]led feed noah hung baydding blog house gate [SEP]']
[Init] best rec loss: 0.6714576482772827 for ['[CLS] ink loss yet volvo remaining fine manor sa glacier [SEP]']
[Init] best perm rec loss: 0.6680058240890503 for ['[CLS] ink volvo manor yet glacier fine remaining loss sa [SEP]']
[Init] best perm rec loss: 0.667153000831604 for ['[CLS] glacier yet remaining loss volvo ink sa manor fine [SEP]']
[Init] best perm rec loss: 0.6671254634857178 for ['[CLS] manor remaining fine loss ink yet sa volvo glacier [SEP]']
[Init] best perm rec loss: 0.6665775179862976 for ['[CLS] fine loss manor ink sa glacier remaining volvo yet [SEP]']
[Init] best perm rec loss: 0.6625388860702515 for ['[CLS] glacier remaining ink fine manor loss sa volvo yet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.861 (perp=12.224, rec=0.366, cos=0.051), tot_loss_proj:3.450 [t=0.17s]
prediction: ['[CLS] witch by welfare utility on witchcraft occurred moving absence [SEP]']
[ 100/2000] tot_loss=3.136 (perp=9.600, rec=0.887, cos=0.329), tot_loss_proj:2.935 [t=0.17s]
prediction: ['[CLS] witch the witch went the vanishing by vanishing vanishing [SEP]']
[ 150/2000] tot_loss=2.535 (perp=11.303, rec=0.237, cos=0.037), tot_loss_proj:3.215 [t=0.21s]
prediction: ['[CLS] witch by witches went vanishing illuminated by vanishing disappeared [SEP]']
[ 200/2000] tot_loss=1.978 (perp=9.074, rec=0.149, cos=0.015), tot_loss_proj:2.754 [t=0.18s]
prediction: ['[CLS] witch by vanishing went vanishing field by vanishing. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.918 (perp=8.871, rec=0.132, cos=0.012), tot_loss_proj:2.817 [t=0.17s]
prediction: ['[CLS] witch the vanishing vanishing went forest by vanishing. [SEP]']
[ 300/2000] tot_loss=1.814 (perp=8.554, rec=0.095, cos=0.008), tot_loss_proj:2.682 [t=0.21s]
prediction: ['[CLS] witch the witch into went forest by vanishing. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.436 (perp=6.805, rec=0.069, cos=0.006), tot_loss_proj:1.873 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.441 (perp=6.805, rec=0.074, cos=0.006), tot_loss_proj:1.862 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[ 450/2000] tot_loss=1.446 (perp=6.805, rec=0.079, cos=0.006), tot_loss_proj:1.869 [t=0.20s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.449 (perp=6.805, rec=0.083, cos=0.006), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.452 (perp=6.805, rec=0.085, cos=0.006), tot_loss_proj:1.880 [t=0.22s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[ 600/2000] tot_loss=1.455 (perp=6.805, rec=0.088, cos=0.005), tot_loss_proj:1.871 [t=0.20s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.451 (perp=6.805, rec=0.084, cos=0.005), tot_loss_proj:1.875 [t=0.26s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.435 (perp=6.805, rec=0.070, cos=0.005), tot_loss_proj:1.873 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[ 750/2000] tot_loss=1.439 (perp=6.805, rec=0.074, cos=0.005), tot_loss_proj:1.872 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.439 (perp=6.805, rec=0.073, cos=0.005), tot_loss_proj:1.867 [t=0.23s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.437 (perp=6.805, rec=0.072, cos=0.004), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[ 900/2000] tot_loss=1.442 (perp=6.805, rec=0.076, cos=0.004), tot_loss_proj:1.876 [t=0.19s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.430 (perp=6.805, rec=0.065, cos=0.004), tot_loss_proj:1.877 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.425 (perp=6.805, rec=0.059, cos=0.004), tot_loss_proj:1.867 [t=0.26s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1050/2000] tot_loss=1.447 (perp=6.805, rec=0.082, cos=0.004), tot_loss_proj:1.869 [t=0.19s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.422 (perp=6.805, rec=0.057, cos=0.004), tot_loss_proj:1.860 [t=0.19s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.456 (perp=6.805, rec=0.091, cos=0.004), tot_loss_proj:1.868 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1200/2000] tot_loss=1.436 (perp=6.805, rec=0.071, cos=0.004), tot_loss_proj:1.876 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.436 (perp=6.805, rec=0.071, cos=0.004), tot_loss_proj:1.872 [t=0.26s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.434 (perp=6.805, rec=0.069, cos=0.004), tot_loss_proj:1.873 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1350/2000] tot_loss=1.437 (perp=6.805, rec=0.072, cos=0.004), tot_loss_proj:1.869 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.437 (perp=6.805, rec=0.072, cos=0.004), tot_loss_proj:1.867 [t=0.21s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.431 (perp=6.805, rec=0.066, cos=0.004), tot_loss_proj:1.873 [t=0.24s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1500/2000] tot_loss=1.427 (perp=6.805, rec=0.062, cos=0.004), tot_loss_proj:1.868 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.427 (perp=6.805, rec=0.062, cos=0.004), tot_loss_proj:1.866 [t=0.23s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.433 (perp=6.805, rec=0.068, cos=0.004), tot_loss_proj:1.869 [t=0.23s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1650/2000] tot_loss=1.425 (perp=6.805, rec=0.060, cos=0.004), tot_loss_proj:1.880 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.441 (perp=6.805, rec=0.076, cos=0.004), tot_loss_proj:1.865 [t=0.24s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.441 (perp=6.805, rec=0.076, cos=0.004), tot_loss_proj:1.871 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1800/2000] tot_loss=1.423 (perp=6.805, rec=0.058, cos=0.004), tot_loss_proj:1.867 [t=0.19s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.423 (perp=6.805, rec=0.058, cos=0.004), tot_loss_proj:1.870 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.437 (perp=6.805, rec=0.072, cos=0.004), tot_loss_proj:1.871 [t=0.24s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1950/2000] tot_loss=1.437 (perp=6.805, rec=0.072, cos=0.004), tot_loss_proj:1.862 [t=0.19s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.438 (perp=6.805, rec=0.074, cos=0.004), tot_loss_proj:1.865 [t=0.22s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] the witch went into the forest by vanishing. [SEP]
========================
predicted: 
========================
[CLS] witch the witch went into forest by vanishing. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 156.667

[Aggregate metrics]:
rouge1     | fm: 74.771 | p: 75.076 | r: 74.781
rouge2     | fm: 35.994 | p: 35.943 | r: 36.139
rougeL     | fm: 64.739 | p: 64.989 | r: 64.671
rougeLsum  | fm: 64.947 | p: 65.290 | r: 64.907
r1fm+r2fm = 110.766

input #46 time: 0:08:04 | total time: 6:26:28


Running input #47 of 100.
reference: 
========================
Mary noticed John's excessive appreciation of himself.
========================
average of cosine similarity 0.9992399581895643
highest_index [0]
highest [0.9992399581895643]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2984,  4384,  2198,  1005,  1055, 11664, 12284,  1997,  2370,
          1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] mary noticed john's excessive appreciation of himself. [SEP]"]
[Init] best rec loss: 0.9377633929252625 for ['[CLS] negotiationsris deemedtment prohibition wine holdingyn divorced within [SEP]']
[Init] best rec loss: 0.9331151247024536 for ['[CLS] apart nearly twinotho point onceient overcome beck hong [SEP]']
[Init] best rec loss: 0.924275815486908 for ['[CLS] less pain enters silk mktiv doesn thighs replde [SEP]']
[Init] best rec loss: 0.8977593183517456 for ['[CLS] accompanying moss advent visitedsit corbin pas grade convictedbacks [SEP]']
[Init] best rec loss: 0.8822109699249268 for ['[CLS] december hit leisure journey none sinclair ras chaos whereby burke [SEP]']
[Init] best rec loss: 0.8803945779800415 for ['[CLS]care di sarperson zach original participantsllis " direct [SEP]']
[Init] best rec loss: 0.8778656721115112 for ['[CLS] po 2006 contention sort nameorestation were say dressed caps [SEP]']
[Init] best rec loss: 0.8622311353683472 for ['[CLS] general letting springs engineer large especially together cost tracing framework [SEP]']
[Init] best perm rec loss: 0.856625497341156 for ['[CLS] engineer together letting large general tracing springs framework especially cost [SEP]']
[Init] best perm rec loss: 0.8556800484657288 for ['[CLS] framework together large tracing springs general especially engineer letting cost [SEP]']
[Init] best perm rec loss: 0.8556457161903381 for ['[CLS] tracing large framework cost general together springs especially letting engineer [SEP]']
[Init] best perm rec loss: 0.854211688041687 for ['[CLS] engineer cost framework large general especially together tracing letting springs [SEP]']
[Init] best perm rec loss: 0.8541837334632874 for ['[CLS] engineer springs together especially tracing large general framework cost letting [SEP]']
[Init] best perm rec loss: 0.8541443347930908 for ['[CLS] engineer large tracing springs cost especially letting framework together general [SEP]']
[Init] best perm rec loss: 0.850818932056427 for ['[CLS] springs cost tracing together large especially engineer letting general framework [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.299 (perp=13.755, rec=0.551, cos=0.997), tot_loss_proj:4.689 [t=0.20s]
prediction: ['[CLS] nick di expression pete say captain lou noticed notice stern [SEP]']
[ 100/2000] tot_loss=3.957 (perp=12.527, rec=0.459, cos=0.993), tot_loss_proj:4.362 [t=0.22s]
prediction: ['[CLS].yer noticed armed commanding excessive lou noticed excessive appreciation [SEP]']
[ 150/2000] tot_loss=4.139 (perp=13.633, rec=0.418, cos=0.994), tot_loss_proj:4.654 [t=0.18s]
prediction: ['[CLS] - stephen appreciation capped irwin excessiveresh noticed excessive instrumental [SEP]']
[ 200/2000] tot_loss=3.930 (perp=12.720, rec=0.390, cos=0.995), tot_loss_proj:4.478 [t=0.18s]
prediction: ['[CLS] - mary appreciation excessive centuries excessiveresh noticed excessive culture [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=4.174 (perp=13.265, rec=0.530, cos=0.991), tot_loss_proj:4.501 [t=0.20s]
prediction: ['[CLS] appreciation besides - drawer merely excessive malawi noticed amongergy [SEP]']
[ 300/2000] tot_loss=3.642 (perp=11.142, rec=0.419, cos=0.994), tot_loss_proj:4.009 [t=0.18s]
prediction: ['[CLS] appreciation was. excessive having excessiveresh noticed amonginge [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.891 (perp=12.481, rec=0.401, cos=0.995), tot_loss_proj:4.291 [t=0.17s]
prediction: ['[CLS] appreciation besides noticed excessive having excessive makeup lord installation liberty [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.853 (perp=12.396, rec=0.379, cos=0.995), tot_loss_proj:4.461 [t=0.26s]
prediction: ['[CLS] ownership. noticed excessive stall excessive teddy appreciation installation appreciation [SEP]']
[ 450/2000] tot_loss=3.669 (perp=11.550, rec=0.364, cos=0.995), tot_loss_proj:4.181 [t=0.18s]
prediction: ['[CLS] john. noticed excessive not excessive teddy appreciation holds appreciation [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.813 (perp=12.266, rec=0.362, cos=0.997), tot_loss_proj:4.456 [t=0.18s]
prediction: ['[CLS] john. noticed excessive raids excessive appreciation teddy breast appreciation [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.541 (perp=10.725, rec=0.402, cos=0.994), tot_loss_proj:4.047 [t=0.17s]
prediction: ['[CLS] appreciation mary noticed excessive not excessive. teddy breast respect [SEP]']
[ 600/2000] tot_loss=3.928 (perp=12.867, rec=0.358, cos=0.997), tot_loss_proj:4.617 [t=0.24s]
prediction: ['[CLS] appreciation mary noticed excessive raids excessive john teddyules appreciation [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.924 (perp=12.850, rec=0.356, cos=0.997), tot_loss_proj:4.589 [t=0.22s]
prediction: ['[CLS] appreciation mary noticed excessive raids excessive teddy maryules appreciation [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.887 (perp=12.682, rec=0.354, cos=0.996), tot_loss_proj:4.515 [t=0.17s]
prediction: ['[CLS] appreciation mary noticed excessive whitman excessive teddyules mary overall [SEP]']
[ 750/2000] tot_loss=3.736 (perp=12.000, rec=0.338, cos=0.998), tot_loss_proj:4.385 [t=0.18s]
prediction: ['[CLS] appreciation mary noticed excessive whitman excessive teddyules mary appreciation [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.887 (perp=12.731, rec=0.343, cos=0.998), tot_loss_proj:4.505 [t=0.25s]
prediction: ['[CLS] appreciation mary noticed excessive whitman excessive lucyules mary overall [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.689 (perp=11.614, rec=0.370, cos=0.996), tot_loss_proj:4.290 [t=0.18s]
prediction: ['[CLS] mary mary noticed excessive whitman excessive lucyules appreciation overall [SEP]']
[ 900/2000] tot_loss=3.705 (perp=11.804, rec=0.347, cos=0.997), tot_loss_proj:4.371 [t=0.25s]
prediction: ['[CLS] mary mary noticed excessive whitman excessive lucyules appreciation appreciation [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=3.744 (perp=12.046, rec=0.337, cos=0.997), tot_loss_proj:4.411 [t=0.28s]
prediction: ['[CLS] mary mary whitman noticed excessive excessive margaretules appreciation destination [SEP]']
Attempt swap
[1000/2000] tot_loss=3.746 (perp=12.046, rec=0.339, cos=0.997), tot_loss_proj:4.413 [t=0.30s]
prediction: ['[CLS] mary mary whitman noticed excessive excessive margaretules appreciation destination [SEP]']
[1050/2000] tot_loss=3.745 (perp=12.046, rec=0.338, cos=0.998), tot_loss_proj:4.409 [t=0.27s]
prediction: ['[CLS] mary mary whitman noticed excessive excessive margaretules appreciation destination [SEP]']
Attempt swap
[1100/2000] tot_loss=3.810 (perp=12.442, rec=0.324, cos=0.998), tot_loss_proj:4.438 [t=0.27s]
prediction: ['[CLS] mary mary whitman noticed himself excessive margaretules appreciation destination [SEP]']
Attempt swap
[1150/2000] tot_loss=3.817 (perp=12.442, rec=0.331, cos=0.998), tot_loss_proj:4.440 [t=0.20s]
prediction: ['[CLS] mary mary whitman noticed himself excessive margaretules appreciation destination [SEP]']
[1200/2000] tot_loss=3.806 (perp=12.442, rec=0.320, cos=0.998), tot_loss_proj:4.438 [t=0.26s]
prediction: ['[CLS] mary mary whitman noticed himself excessive margaretules appreciation destination [SEP]']
Attempt swap
[1250/2000] tot_loss=3.842 (perp=12.569, rec=0.329, cos=0.998), tot_loss_proj:4.293 [t=0.24s]
prediction: ['[CLS] mary maryurity noticed himself excessive margaretules appreciation destination [SEP]']
Attempt swap
[1300/2000] tot_loss=3.840 (perp=12.569, rec=0.328, cos=0.998), tot_loss_proj:4.291 [t=0.17s]
prediction: ['[CLS] mary maryurity noticed himself excessive margaretules appreciation destination [SEP]']
[1350/2000] tot_loss=3.828 (perp=12.545, rec=0.321, cos=0.998), tot_loss_proj:4.303 [t=0.18s]
prediction: ['[CLS] mary maryfulness noticed himself excessive margaretules appreciation destination [SEP]']
Attempt swap
[1400/2000] tot_loss=3.826 (perp=12.545, rec=0.318, cos=0.998), tot_loss_proj:4.304 [t=0.22s]
prediction: ['[CLS] mary maryfulness noticed himself excessive margaretules appreciation destination [SEP]']
Attempt swap
[1450/2000] tot_loss=3.820 (perp=12.545, rec=0.313, cos=0.999), tot_loss_proj:4.305 [t=0.21s]
prediction: ['[CLS] mary maryfulness noticed himself excessive margaretules appreciation destination [SEP]']
[1500/2000] tot_loss=3.830 (perp=12.545, rec=0.322, cos=0.999), tot_loss_proj:4.307 [t=0.18s]
prediction: ['[CLS] mary maryfulness noticed himself excessive margaretules appreciation destination [SEP]']
Attempt swap
[1550/2000] tot_loss=3.876 (perp=12.821, rec=0.314, cos=0.999), tot_loss_proj:4.404 [t=0.21s]
prediction: ['[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]']
Attempt swap
[1600/2000] tot_loss=3.875 (perp=12.821, rec=0.312, cos=0.999), tot_loss_proj:4.402 [t=0.17s]
prediction: ['[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]']
[1650/2000] tot_loss=3.876 (perp=12.821, rec=0.313, cos=0.999), tot_loss_proj:4.405 [t=0.18s]
prediction: ['[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]']
Attempt swap
[1700/2000] tot_loss=3.882 (perp=12.821, rec=0.319, cos=0.999), tot_loss_proj:4.405 [t=0.22s]
prediction: ['[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]']
Attempt swap
[1750/2000] tot_loss=3.871 (perp=12.821, rec=0.308, cos=0.999), tot_loss_proj:4.405 [t=0.18s]
prediction: ['[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]']
[1800/2000] tot_loss=3.881 (perp=12.821, rec=0.318, cos=0.999), tot_loss_proj:4.402 [t=0.18s]
prediction: ['[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]']
Attempt swap
[1850/2000] tot_loss=3.887 (perp=12.821, rec=0.324, cos=0.999), tot_loss_proj:4.406 [t=0.17s]
prediction: ['[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]']
Attempt swap
[1900/2000] tot_loss=3.874 (perp=12.821, rec=0.311, cos=0.999), tot_loss_proj:4.401 [t=0.17s]
prediction: ['[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]']
[1950/2000] tot_loss=3.869 (perp=12.821, rec=0.306, cos=0.999), tot_loss_proj:4.405 [t=0.23s]
prediction: ['[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]']
Attempt swap
[2000/2000] tot_loss=3.878 (perp=12.821, rec=0.315, cos=0.999), tot_loss_proj:4.408 [t=0.18s]
prediction: ['[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] mary noticed john's excessive appreciation of himself. [SEP]
========================
predicted: 
========================
[CLS] mary maryfulness noticed himself excessive jewelules appreciation destination [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.000 | p: 70.000 | r: 70.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 81.111

[Aggregate metrics]:
rouge1     | fm: 74.636 | p: 74.937 | r: 74.689
rouge2     | fm: 35.348 | p: 35.337 | r: 35.453
rougeL     | fm: 64.719 | p: 65.024 | r: 64.683
rougeLsum  | fm: 64.849 | p: 65.207 | r: 64.825
r1fm+r2fm = 109.985

input #47 time: 0:08:10 | total time: 6:34:39


Running input #48 of 100.
reference: 
========================
John tagged Lewis with a regulation baseball on Tuesday.
========================
average of cosine similarity 0.9992913220295518
highest_index [0]
highest [0.9992913220295518]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198, 26610,  4572,  2007,  1037,  7816,  3598,  2006,  9857,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]']
[Init] best rec loss: 1.0071521997451782 for ['[CLS]... spit opening tolerant lie officer 3rd wiener true li [SEP]']
[Init] best rec loss: 0.9635554552078247 for ['[CLS] stunt exclusively since bear toss temple calings whispers claimed [SEP]']
[Init] best rec loss: 0.9312321543693542 for ['[CLS]tative fc matched thorough kay responsible backward pali vera its [SEP]']
[Init] best rec loss: 0.9218538403511047 for ['[CLS] pride grams base telling ramstters shame olive stonerah [SEP]']
[Init] best rec loss: 0.9126393795013428 for ['[CLS] fine screened reference [SEP] industry brick liver fleetwr south [SEP]']
[Init] best perm rec loss: 0.9066827297210693 for ['[CLS]wr screened south fleet brick liver fine reference industry [SEP] [SEP]']
[Init] best perm rec loss: 0.9059775471687317 for ['[CLS] liver south fleet [SEP] fine brick reference screened industrywr [SEP]']
[Init] best perm rec loss: 0.9045016765594482 for ['[CLS] fine fleet [SEP] industry screened brick reference liver southwr [SEP]']
[Init] best perm rec loss: 0.903518557548523 for ['[CLS] screened industry south reference fine liver fleet [SEP]wr brick [SEP]']
[Init] best perm rec loss: 0.9033243656158447 for ['[CLS] south reference [SEP] fleet fine brick industry screened liverwr [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.264 (perp=12.766, rec=0.501, cos=0.209), tot_loss_proj:4.510 [t=0.18s]
prediction: ['[CLS].bies finnish income bulls tennis poker presented additionally rural [SEP]']
[ 100/2000] tot_loss=2.891 (perp=12.416, rec=0.349, cos=0.059), tot_loss_proj:4.437 [t=0.25s]
prediction: ['[CLS]. kristin iowa monday cards sports hamilton on frame service [SEP]']
[ 150/2000] tot_loss=2.530 (perp=11.119, rec=0.278, cos=0.029), tot_loss_proj:4.169 [t=0.18s]
prediction: ['[CLS]. lewismeral tuesday baseball tagged lewis on swimming nature [SEP]']
[ 200/2000] tot_loss=2.365 (perp=10.619, rec=0.222, cos=0.019), tot_loss_proj:4.073 [t=0.27s]
prediction: ['[CLS]. lewismeral tuesday baseball tagged lewis on baseball nature [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.945 (perp=11.984, rec=0.444, cos=0.104), tot_loss_proj:4.399 [t=0.18s]
prediction: ['[CLS] ) kingsmeral monday varieties baseball tagged lewis with professional [SEP]']
[ 300/2000] tot_loss=2.750 (perp=11.508, rec=0.383, cos=0.065), tot_loss_proj:4.267 [t=0.27s]
prediction: ['[CLS] 6 kings varieties saturday variety baseball tagged lewis with professional [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.224 (perp=9.112, rec=0.347, cos=0.054), tot_loss_proj:3.794 [t=0.22s]
prediction: ['[CLS] 6 elementary sox professional baseball baseball tagged lewis with monday [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.527 (perp=11.113, rec=0.277, cos=0.028), tot_loss_proj:4.199 [t=0.18s]
prediction: ['[CLS] 6 tackles fourier professional baseball baseball tagged lewis with monday [SEP]']
[ 450/2000] tot_loss=2.519 (perp=11.172, rec=0.261, cos=0.023), tot_loss_proj:4.219 [t=0.18s]
prediction: ['[CLS] 6 tackles fourier professional baseball baseball tagged lewis with tuesday [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.570 (perp=11.532, rec=0.243, cos=0.021), tot_loss_proj:4.325 [t=0.25s]
prediction: ['[CLS] 6 baseballerative regulation baseball tackles tagged lewis with tuesday [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.418 (perp=10.889, rec=0.223, cos=0.017), tot_loss_proj:4.138 [t=0.23s]
prediction: ['[CLS] 6 baseballerative regulation baseball tagged lewis tackles with tuesday [SEP]']
[ 600/2000] tot_loss=2.410 (perp=10.889, rec=0.219, cos=0.014), tot_loss_proj:4.139 [t=0.18s]
prediction: ['[CLS] 6 baseballerative regulation baseball tagged lewis tackles with tuesday [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.400 (perp=10.889, rec=0.210, cos=0.012), tot_loss_proj:4.138 [t=0.20s]
prediction: ['[CLS] 6 baseballerative regulation baseball tagged lewis tackles with tuesday [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.357 (perp=10.729, rec=0.199, cos=0.011), tot_loss_proj:4.077 [t=0.18s]
prediction: ['[CLS] 5 baseballmarine regulation baseball tagged lewis tackles with tuesday [SEP]']
[ 750/2000] tot_loss=2.555 (perp=11.737, rec=0.197, cos=0.011), tot_loss_proj:4.274 [t=0.20s]
prediction: ['[CLS] 5 baseballchment regulation baseball tagged lewis poke with tuesday [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.538 (perp=11.737, rec=0.181, cos=0.010), tot_loss_proj:4.275 [t=0.26s]
prediction: ['[CLS] 5 baseballchment regulation baseball tagged lewis poke with tuesday [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.463 (perp=11.279, rec=0.196, cos=0.011), tot_loss_proj:4.200 [t=0.17s]
prediction: ['[CLS] poke baseballchment regulation baseball tagged lewis 5 with tuesday [SEP]']
[ 900/2000] tot_loss=2.461 (perp=11.279, rec=0.196, cos=0.009), tot_loss_proj:4.206 [t=0.22s]
prediction: ['[CLS] poke baseballchment regulation baseball tagged lewis 5 with tuesday [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.299 (perp=10.550, rec=0.179, cos=0.010), tot_loss_proj:3.979 [t=0.18s]
prediction: ['[CLS] poke baseballurgent with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1000/2000] tot_loss=2.189 (perp=10.037, rec=0.172, cos=0.009), tot_loss_proj:3.911 [t=0.18s]
prediction: ['[CLS] poke baseball ¤ with baseball tagged lewis 5 regulation tuesday [SEP]']
[1050/2000] tot_loss=2.199 (perp=10.037, rec=0.183, cos=0.009), tot_loss_proj:3.910 [t=0.20s]
prediction: ['[CLS] poke baseball ¤ with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1100/2000] tot_loss=2.254 (perp=10.378, rec=0.170, cos=0.009), tot_loss_proj:3.976 [t=0.18s]
prediction: ['[CLS] nelson baseball waitress with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1150/2000] tot_loss=2.363 (perp=10.902, rec=0.174, cos=0.009), tot_loss_proj:4.105 [t=0.18s]
prediction: ['[CLS] nelson baseballmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
[1200/2000] tot_loss=2.362 (perp=10.902, rec=0.173, cos=0.009), tot_loss_proj:4.108 [t=0.18s]
prediction: ['[CLS] nelson baseballmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.450 (perp=11.364, rec=0.169, cos=0.009), tot_loss_proj:4.238 [t=0.25s]
prediction: ['[CLS] lewis withmeral tagged baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.400 (perp=11.126, rec=0.165, cos=0.010), tot_loss_proj:4.179 [t=0.26s]
prediction: ['[CLS] nelson taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
[1350/2000] tot_loss=2.274 (perp=10.505, rec=0.165, cos=0.009), tot_loss_proj:4.027 [t=0.27s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1400/2000] tot_loss=2.287 (perp=10.505, rec=0.178, cos=0.008), tot_loss_proj:4.025 [t=0.18s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1450/2000] tot_loss=2.277 (perp=10.505, rec=0.168, cos=0.008), tot_loss_proj:4.026 [t=0.29s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
[1500/2000] tot_loss=2.273 (perp=10.505, rec=0.164, cos=0.008), tot_loss_proj:4.024 [t=0.31s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1550/2000] tot_loss=2.270 (perp=10.505, rec=0.161, cos=0.008), tot_loss_proj:4.027 [t=0.19s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1600/2000] tot_loss=2.272 (perp=10.505, rec=0.163, cos=0.008), tot_loss_proj:4.029 [t=0.19s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
[1650/2000] tot_loss=2.269 (perp=10.505, rec=0.160, cos=0.008), tot_loss_proj:4.025 [t=0.24s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1700/2000] tot_loss=2.268 (perp=10.505, rec=0.159, cos=0.008), tot_loss_proj:4.026 [t=0.24s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1750/2000] tot_loss=2.271 (perp=10.505, rec=0.162, cos=0.008), tot_loss_proj:4.029 [t=0.20s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
[1800/2000] tot_loss=2.277 (perp=10.505, rec=0.168, cos=0.008), tot_loss_proj:4.028 [t=0.20s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1850/2000] tot_loss=2.277 (perp=10.505, rec=0.168, cos=0.008), tot_loss_proj:4.027 [t=0.18s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[1900/2000] tot_loss=2.264 (perp=10.505, rec=0.155, cos=0.008), tot_loss_proj:4.026 [t=0.21s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
[1950/2000] tot_loss=2.267 (perp=10.505, rec=0.159, cos=0.008), tot_loss_proj:4.030 [t=0.17s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Attempt swap
[2000/2000] tot_loss=2.272 (perp=10.505, rec=0.163, cos=0.008), tot_loss_proj:4.028 [t=0.17s]
prediction: ['[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]
========================
predicted: 
========================
[CLS] lewis taggedmeral with baseball tagged lewis 5 regulation tuesday [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 72.727 | r: 72.727
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 92.727

[Aggregate metrics]:
rouge1     | fm: 74.639 | p: 74.893 | r: 74.562
rouge2     | fm: 35.154 | p: 35.174 | r: 35.333
rougeL     | fm: 64.468 | p: 64.763 | r: 64.398
rougeLsum  | fm: 64.654 | p: 65.028 | r: 64.543
r1fm+r2fm = 109.793

input #48 time: 0:08:17 | total time: 6:42:56


Running input #49 of 100.
reference: 
========================
We all thought him to be unhappy
========================
average of cosine similarity 0.9993920717359353
highest_index [0]
highest [0.9993920717359353]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2057,  2035,  2245,  2032,  2000,  2022, 12511,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] we all thought him to be unhappy [SEP]']
[Init] best rec loss: 0.9411858320236206 for ['[CLS] mattermei visibly port brandenburgmissive le [SEP]']
[Init] best rec loss: 0.9296923875808716 for ['[CLS] smoke starary pmid feather consider line [SEP]']
[Init] best rec loss: 0.9013326168060303 for ['[CLS] studies brig numbered logan tour percent rex [SEP]']
[Init] best rec loss: 0.8935877680778503 for ['[CLS]vy threatened fragments straight long piper sign [SEP]']
[Init] best rec loss: 0.8891277313232422 for ['[CLS] cominglett than carrier holiday exposed long [SEP]']
[Init] best rec loss: 0.8783950805664062 for ['[CLS] added guinea gretchen nine cast patent closed [SEP]']
[Init] best rec loss: 0.8762047290802002 for ['[CLS] steppedine band yeshiva / mansion investment [SEP]']
[Init] best rec loss: 0.8750602602958679 for ['[CLS] turf rib hutually driven celine richards [SEP]']
[Init] best rec loss: 0.8677970170974731 for ['[CLS] kennedy drive hold ro steering sindhuising [SEP]']
[Init] best rec loss: 0.8665210604667664 for ['[CLS] rolandylus que phelps books haste yourselves [SEP]']
[Init] best perm rec loss: 0.8652602434158325 for ['[CLS] rolandylus books que phelps yourselves haste [SEP]']
[Init] best perm rec loss: 0.8644270896911621 for ['[CLS]ylus phelps que yourselves haste roland books [SEP]']
[Init] best perm rec loss: 0.8641104102134705 for ['[CLS] yourselves phelpsylus roland que books haste [SEP]']
[Init] best perm rec loss: 0.8639255166053772 for ['[CLS] yourselves roland books haste queylus phelps [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.198 (perp=13.170, rec=0.596, cos=0.968), tot_loss_proj:4.558 [t=0.23s]
prediction: ['[CLS] kicked decommissioned kings network chairman andrew funding [SEP]']
[ 100/2000] tot_loss=3.815 (perp=12.046, rec=0.530, cos=0.876), tot_loss_proj:4.280 [t=0.18s]
prediction: ['[CLS] kicked became all thought thereafter seeing their [SEP]']
[ 150/2000] tot_loss=3.793 (perp=11.844, rec=0.548, cos=0.877), tot_loss_proj:4.237 [t=0.23s]
prediction: ['[CLS] kilograms published all thought himᴬ her [SEP]']
[ 200/2000] tot_loss=3.840 (perp=12.993, rec=0.463, cos=0.779), tot_loss_proj:4.494 [t=0.18s]
prediction: ['[CLS] goods ud all thought himᴬ her [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.149 (perp=10.812, rec=0.452, cos=0.534), tot_loss_proj:3.997 [t=0.18s]
prediction: ['[CLS] them would all thought himᴬ goods [SEP]']
[ 300/2000] tot_loss=2.200 (perp=9.663, rec=0.237, cos=0.030), tot_loss_proj:3.805 [t=0.17s]
prediction: ['[CLS] be beth all thought him happy little [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.174 (perp=9.917, rec=0.176, cos=0.014), tot_loss_proj:3.891 [t=0.26s]
prediction: ['[CLS] be beth all thought him unhappy little [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.015 (perp=8.954, rec=0.205, cos=0.019), tot_loss_proj:3.731 [t=0.18s]
prediction: ['[CLS] be females all thought him little unhappy [SEP]']
[ 450/2000] tot_loss=1.985 (perp=9.014, rec=0.172, cos=0.010), tot_loss_proj:3.725 [t=0.18s]
prediction: ['[CLS] be females all thought him be unhappy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.471 (perp=10.824, rec=0.273, cos=0.034), tot_loss_proj:4.061 [t=0.27s]
prediction: ['[CLS] [SEP] all thought himt unhappy the [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.146 (perp=9.541, rec=0.215, cos=0.024), tot_loss_proj:3.881 [t=0.17s]
prediction: ['[CLS] [SEP] all thought him the unhappyt [SEP]']
[ 600/2000] tot_loss=1.977 (perp=8.849, rec=0.187, cos=0.020), tot_loss_proj:3.657 [t=0.18s]
prediction: ['[CLS] to all thought him the unhappyt [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.908 (perp=8.543, rec=0.181, cos=0.019), tot_loss_proj:3.653 [t=0.18s]
prediction: ['[CLS] bet all thought him the unhappy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.895 (perp=8.543, rec=0.169, cos=0.017), tot_loss_proj:3.653 [t=0.20s]
prediction: ['[CLS] bet all thought him the unhappy [SEP]']
[ 750/2000] tot_loss=1.891 (perp=8.543, rec=0.166, cos=0.016), tot_loss_proj:3.652 [t=0.18s]
prediction: ['[CLS] bet all thought him the unhappy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.886 (perp=8.543, rec=0.162, cos=0.015), tot_loss_proj:3.657 [t=0.26s]
prediction: ['[CLS] bet all thought him the unhappy [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.767 (perp=7.861, rec=0.177, cos=0.019), tot_loss_proj:3.390 [t=0.23s]
prediction: ['[CLS] bet was all thought him unhappy [SEP]']
[ 900/2000] tot_loss=1.742 (perp=7.861, rec=0.156, cos=0.014), tot_loss_proj:3.390 [t=0.22s]
prediction: ['[CLS] bet was all thought him unhappy [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.688 (perp=7.621, rec=0.151, cos=0.013), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] bet thought all was him unhappy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.691 (perp=7.621, rec=0.155, cos=0.013), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] bet thought all was him unhappy [SEP]']
[1050/2000] tot_loss=1.685 (perp=7.621, rec=0.149, cos=0.012), tot_loss_proj:3.385 [t=0.18s]
prediction: ['[CLS] bet thought all was him unhappy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.684 (perp=7.621, rec=0.148, cos=0.012), tot_loss_proj:3.384 [t=0.20s]
prediction: ['[CLS] bet thought all was him unhappy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.691 (perp=7.621, rec=0.155, cos=0.012), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] bet thought all was him unhappy [SEP]']
[1200/2000] tot_loss=1.689 (perp=7.621, rec=0.154, cos=0.012), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] bet thought all was him unhappy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.683 (perp=7.621, rec=0.148, cos=0.012), tot_loss_proj:3.382 [t=0.18s]
prediction: ['[CLS] bet thought all was him unhappy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.681 (perp=7.621, rec=0.145, cos=0.011), tot_loss_proj:3.385 [t=0.18s]
prediction: ['[CLS] bet thought all was him unhappy [SEP]']
[1350/2000] tot_loss=1.683 (perp=7.621, rec=0.147, cos=0.011), tot_loss_proj:3.387 [t=0.18s]
prediction: ['[CLS] bet thought all was him unhappy [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.670 (perp=7.574, rec=0.144, cos=0.012), tot_loss_proj:3.374 [t=0.25s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.673 (perp=7.574, rec=0.147, cos=0.011), tot_loss_proj:3.378 [t=0.23s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
[1500/2000] tot_loss=1.667 (perp=7.574, rec=0.141, cos=0.011), tot_loss_proj:3.377 [t=0.25s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.672 (perp=7.574, rec=0.146, cos=0.011), tot_loss_proj:3.376 [t=0.24s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.671 (perp=7.574, rec=0.145, cos=0.011), tot_loss_proj:3.376 [t=0.18s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
[1650/2000] tot_loss=1.671 (perp=7.574, rec=0.146, cos=0.011), tot_loss_proj:3.376 [t=0.19s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.684 (perp=7.574, rec=0.159, cos=0.011), tot_loss_proj:3.376 [t=0.23s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.675 (perp=7.574, rec=0.149, cos=0.011), tot_loss_proj:3.380 [t=0.18s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
[1800/2000] tot_loss=1.672 (perp=7.574, rec=0.147, cos=0.011), tot_loss_proj:3.379 [t=0.18s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.674 (perp=7.574, rec=0.149, cos=0.011), tot_loss_proj:3.379 [t=0.23s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.669 (perp=7.574, rec=0.144, cos=0.011), tot_loss_proj:3.376 [t=0.18s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
[1950/2000] tot_loss=1.668 (perp=7.574, rec=0.142, cos=0.011), tot_loss_proj:3.378 [t=0.18s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.671 (perp=7.574, rec=0.146, cos=0.010), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] bet thought all him was unhappy [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] we all thought him to be unhappy [SEP]
========================
predicted: 
========================
[CLS] bet thought all him was unhappy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 75.000 | r: 66.667
rouge2     | fm: 13.333 | p: 14.286 | r: 12.500
rougeL     | fm: 58.824 | p: 62.500 | r: 55.556
rougeLsum  | fm: 58.824 | p: 62.500 | r: 55.556
r1fm+r2fm = 83.922

[Aggregate metrics]:
rouge1     | fm: 74.468 | p: 74.866 | r: 74.375
rouge2     | fm: 34.651 | p: 34.613 | r: 34.754
rougeL     | fm: 64.354 | p: 64.711 | r: 64.235
rougeLsum  | fm: 64.559 | p: 64.914 | r: 64.396
r1fm+r2fm = 109.119

input #49 time: 0:08:02 | total time: 6:50:59


Running input #50 of 100.
reference: 
========================
Book is available in most countries.
========================
average of cosine similarity 0.999341484458915
highest_index [0]
highest [0.999341484458915]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2338, 2003, 2800, 1999, 2087, 3032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] book is available in most countries. [SEP]']
[Init] best rec loss: 0.7874211072921753 for ['[CLS] keyxy neither jenksuka chow administration [SEP]']
[Init] best rec loss: 0.7831349968910217 for ['[CLS] rev vaughn debut inspiration theme mind wonder [SEP]']
[Init] best rec loss: 0.7579970955848694 for ['[CLS] tapes [SEP] stronger u part radio tropical [SEP]']
[Init] best rec loss: 0.7362892627716064 for ['[CLS]ers quality thereafter small conversations gaius sven [SEP]']
[Init] best rec loss: 0.7306573987007141 for ['[CLS] po gustav room governors roger underpathic [SEP]']
[Init] best rec loss: 0.730445146560669 for ['[CLS]ping casualties election creditsiestitiafactory [SEP]']
[Init] best rec loss: 0.7263517379760742 for ['[CLS] reconnaissancefieldsffen switzerland humor spells scenario [SEP]']
[Init] best perm rec loss: 0.7249794006347656 for ['[CLS]ffen scenario spells switzerland humorfields reconnaissance [SEP]']
[Init] best perm rec loss: 0.7248560786247253 for ['[CLS] switzerlandffenfields reconnaissance humor scenario spells [SEP]']
[Init] best perm rec loss: 0.7243238091468811 for ['[CLS] switzerlandffen reconnaissance scenariofields humor spells [SEP]']
[Init] best perm rec loss: 0.7224777936935425 for ['[CLS] switzerland scenariofields humor reconnaissance spellsffen [SEP]']
[Init] best perm rec loss: 0.7222394943237305 for ['[CLS] spells reconnaissance scenariofieldsffen humor switzerland [SEP]']
[Init] best perm rec loss: 0.7190003991127014 for ['[CLS] scenariofieldsffen switzerland humor spells reconnaissance [SEP]']
[Init] best perm rec loss: 0.7169519662857056 for ['[CLS] switzerlandfields scenarioffen spells reconnaissance humor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.091 (perp=13.362, rec=0.368, cos=0.051), tot_loss_proj:4.035 [t=0.18s]
prediction: ['[CLS] person lisa portercl collection glow laugh [SEP]']
[ 100/2000] tot_loss=2.420 (perp=10.429, rec=0.304, cos=0.031), tot_loss_proj:3.184 [t=0.20s]
prediction: ['[CLS] book vita states book book book laugh [SEP]']
[ 150/2000] tot_loss=2.261 (perp=10.154, rec=0.214, cos=0.016), tot_loss_proj:3.052 [t=0.18s]
prediction: ['[CLS] book vita countries available book book is [SEP]']
[ 200/2000] tot_loss=2.158 (perp=9.708, rec=0.201, cos=0.016), tot_loss_proj:3.018 [t=0.20s]
prediction: ['[CLS] other tomas countries available book countries is [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.093 (perp=9.491, rec=0.184, cos=0.011), tot_loss_proj:2.905 [t=0.19s]
prediction: ['[CLS] many book available countries book countries is [SEP]']
[ 300/2000] tot_loss=1.794 (perp=8.196, rec=0.147, cos=0.008), tot_loss_proj:2.433 [t=0.17s]
prediction: ['[CLS] in most available countries book countries is [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.601 (perp=7.318, rec=0.131, cos=0.007), tot_loss_proj:2.331 [t=0.17s]
prediction: ['[CLS] in most countries countries book available is [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.817 (perp=8.397, rec=0.132, cos=0.006), tot_loss_proj:2.722 [t=0.19s]
prediction: ['[CLS] most countries most countries book available is [SEP]']
[ 450/2000] tot_loss=1.802 (perp=8.397, rec=0.117, cos=0.006), tot_loss_proj:2.731 [t=0.18s]
prediction: ['[CLS] most countries most countries book available is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.722 (perp=8.071, rec=0.103, cos=0.005), tot_loss_proj:2.713 [t=0.24s]
prediction: ['[CLS] most available most countries book available is [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.757 (perp=8.109, rec=0.129, cos=0.007), tot_loss_proj:2.566 [t=0.18s]
prediction: ['[CLS] most countries most countries book is available [SEP]']
[ 600/2000] tot_loss=1.740 (perp=8.109, rec=0.113, cos=0.005), tot_loss_proj:2.616 [t=0.18s]
prediction: ['[CLS] most countries most countries book is available [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.737 (perp=8.109, rec=0.111, cos=0.004), tot_loss_proj:2.607 [t=0.25s]
prediction: ['[CLS] most countries most countries book is available [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.722 (perp=8.109, rec=0.095, cos=0.004), tot_loss_proj:2.611 [t=0.18s]
prediction: ['[CLS] most countries most countries book is available [SEP]']
[ 750/2000] tot_loss=1.713 (perp=8.109, rec=0.087, cos=0.004), tot_loss_proj:2.607 [t=0.17s]
prediction: ['[CLS] most countries most countries book is available [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.737 (perp=8.109, rec=0.111, cos=0.004), tot_loss_proj:2.609 [t=0.28s]
prediction: ['[CLS] most countries most countries book is available [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.729 (perp=8.109, rec=0.102, cos=0.004), tot_loss_proj:2.608 [t=0.23s]
prediction: ['[CLS] most countries most countries book is available [SEP]']
[ 900/2000] tot_loss=1.668 (perp=7.920, rec=0.080, cos=0.004), tot_loss_proj:2.550 [t=0.28s]
prediction: ['[CLS] most countries in countries book is available [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.343 (perp=6.213, rec=0.096, cos=0.004), tot_loss_proj:2.020 [t=0.24s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1000/2000] tot_loss=1.339 (perp=6.213, rec=0.093, cos=0.004), tot_loss_proj:2.015 [t=0.20s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
[1050/2000] tot_loss=1.330 (perp=6.213, rec=0.084, cos=0.004), tot_loss_proj:2.021 [t=0.26s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1100/2000] tot_loss=1.335 (perp=6.213, rec=0.089, cos=0.004), tot_loss_proj:2.019 [t=0.18s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1150/2000] tot_loss=1.345 (perp=6.213, rec=0.098, cos=0.004), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
[1200/2000] tot_loss=1.333 (perp=6.213, rec=0.086, cos=0.004), tot_loss_proj:2.023 [t=0.18s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1250/2000] tot_loss=1.338 (perp=6.213, rec=0.091, cos=0.004), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1300/2000] tot_loss=1.346 (perp=6.213, rec=0.099, cos=0.004), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
[1350/2000] tot_loss=1.342 (perp=6.213, rec=0.095, cos=0.004), tot_loss_proj:2.016 [t=0.24s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1400/2000] tot_loss=1.336 (perp=6.213, rec=0.089, cos=0.004), tot_loss_proj:2.017 [t=0.19s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1450/2000] tot_loss=1.341 (perp=6.213, rec=0.094, cos=0.004), tot_loss_proj:2.011 [t=0.18s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
[1500/2000] tot_loss=1.342 (perp=6.213, rec=0.095, cos=0.004), tot_loss_proj:2.018 [t=0.24s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1550/2000] tot_loss=1.326 (perp=6.213, rec=0.079, cos=0.004), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1600/2000] tot_loss=1.331 (perp=6.213, rec=0.084, cos=0.004), tot_loss_proj:2.019 [t=0.18s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
[1650/2000] tot_loss=1.323 (perp=6.213, rec=0.076, cos=0.005), tot_loss_proj:2.009 [t=0.19s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1700/2000] tot_loss=1.333 (perp=6.213, rec=0.086, cos=0.005), tot_loss_proj:2.013 [t=0.26s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1750/2000] tot_loss=1.326 (perp=6.213, rec=0.079, cos=0.004), tot_loss_proj:2.014 [t=0.25s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
[1800/2000] tot_loss=1.324 (perp=6.213, rec=0.077, cos=0.004), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1850/2000] tot_loss=1.328 (perp=6.213, rec=0.081, cos=0.004), tot_loss_proj:2.013 [t=0.18s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
[1900/2000] tot_loss=1.333 (perp=6.213, rec=0.086, cos=0.004), tot_loss_proj:2.009 [t=0.24s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
[1950/2000] tot_loss=1.322 (perp=6.213, rec=0.075, cos=0.004), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.331 (perp=6.213, rec=0.084, cos=0.004), tot_loss_proj:1.997 [t=0.18s]
prediction: ['[CLS] in most countries countries book is available [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] book is available in most countries. [SEP]
========================
predicted: 
========================
[CLS] in most countries countries book is available [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 53.333 | p: 50.000 | r: 57.143
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 147.451

[Aggregate metrics]:
rouge1     | fm: 74.765 | p: 75.054 | r: 74.894
rouge2     | fm: 35.008 | p: 34.919 | r: 35.235
rougeL     | fm: 64.145 | p: 64.491 | r: 64.147
rougeLsum  | fm: 64.338 | p: 64.730 | r: 64.295
r1fm+r2fm = 109.773

input #50 time: 0:08:10 | total time: 6:59:10


Running input #51 of 100.
reference: 
========================
I could have little known that more trouble was just around the corner.
========================
average of cosine similarity 0.999393219287597
highest_index [0]
highest [0.999393219287597]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2071, 2031, 2210, 2124, 2008, 2062, 4390, 2001, 2074, 2105,
         1996, 3420, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i could have little known that more trouble was just around the corner. [SEP]']
[Init] best rec loss: 0.958308219909668 for ['[CLS] missing coincidence ten ideas gas need status singleton silver considered demolished tale convert grumbled [SEP]']
[Init] best rec loss: 0.9319798350334167 for ['[CLS] clshfalls chicago walled steps turn photos tell covers yet letter xx table [SEP]']
[Init] best rec loss: 0.8892698287963867 for ['[CLS] reason strength trains chance dawsonwyl milk diplomatic tie chance parked honey summer associated [SEP]']
[Init] best rec loss: 0.8843215703964233 for ['[CLS]ponecope calm social solemn milesling moodeersi demon position negativeif [SEP]']
[Init] best rec loss: 0.8748561143875122 for ['[CLS] theirform prevented throughoutnight younger ham near should mustizationite split individual [SEP]']
[Init] best rec loss: 0.860314667224884 for ['[CLS] temperatures ruth krishna metre cultural samurai acceleration visual oscar premiere hitter priest jo ps [SEP]']
[Init] best perm rec loss: 0.8551190495491028 for ['[CLS] ps temperatures samurai metre priest cultural premiere jo krishna oscar visual ruth hitter acceleration [SEP]']
[Init] best perm rec loss: 0.8518536686897278 for ['[CLS] temperatures metre krishna premiere cultural ps samurai ruth acceleration jo priest hitter visual oscar [SEP]']
[Init] best perm rec loss: 0.8513066172599792 for ['[CLS] cultural acceleration ruth metre temperatures oscar samurai krishna premiere jo visual ps priest hitter [SEP]']
[Init] best perm rec loss: 0.8505657911300659 for ['[CLS] premiere visual priest krishna oscar samurai metre acceleration temperatures cultural ps jo ruth hitter [SEP]']
[Init] best perm rec loss: 0.8491230607032776 for ['[CLS] oscar samurai priest temperatures hitter visual acceleration ruth premiere krishna jo cultural ps metre [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.478 (perp=9.785, rec=0.527, cos=0.993), tot_loss_proj:3.892 [t=0.18s]
prediction: ['[CLS] particularly : jim rca corps,firmed. =cs brigade pressure maintenance type [SEP]']
[ 100/2000] tot_loss=3.602 (perp=10.804, rec=0.457, cos=0.984), tot_loss_proj:4.021 [t=0.19s]
prediction: ['[CLS] especially : ezio gotten. was besides. me because brigade initial maintenance type [SEP]']
[ 150/2000] tot_loss=3.331 (perp=9.728, rec=0.406, cos=0.979), tot_loss_proj:3.746 [t=0.19s]
prediction: ['[CLS] especially was trouble further known was that. limited are corner bulk maintenance was [SEP]']
[ 200/2000] tot_loss=4.093 (perp=12.655, rec=0.572, cos=0.990), tot_loss_proj:4.428 [t=0.18s]
prediction: ['[CLS] especiallylessly trouble little navy knew [SEP]. limited vantage corner medieval > and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.615 (perp=11.035, rec=0.431, cos=0.977), tot_loss_proj:4.098 [t=0.21s]
prediction: ['[CLS] vantage and trouble little sons was be. widened middle trouble lesser > unincorporated [SEP]']
[ 300/2000] tot_loss=3.455 (perp=10.463, rec=0.388, cos=0.974), tot_loss_proj:3.973 [t=0.18s]
prediction: ['[CLS] sorting more trouble littletch was that. usual middle trouble trouble need was [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.495 (perp=9.931, rec=0.518, cos=0.992), tot_loss_proj:3.907 [t=0.18s]
prediction: ['[CLS] linux problems little apparently least was.. among without trouble this j. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.158 (perp=8.567, rec=0.456, cos=0.988), tot_loss_proj:3.599 [t=0.20s]
prediction: ['[CLS] truly apparently little trouble chord was.. besides especially trouble this less. [SEP]']
[ 450/2000] tot_loss=3.103 (perp=8.533, rec=0.411, cos=0.985), tot_loss_proj:3.580 [t=0.18s]
prediction: ['[CLS] more apparently little trouble chord was.. besides especially trouble this less. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.108 (perp=8.525, rec=0.418, cos=0.985), tot_loss_proj:3.587 [t=0.18s]
prediction: ['[CLS] more sorting little trouble was could.. besides especially trouble this less. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.961 (perp=7.848, rec=0.409, cos=0.982), tot_loss_proj:3.462 [t=0.18s]
prediction: ['[CLS] more little trouble was knew that. besides especially apparently trouble this months. [SEP]']
[ 600/2000] tot_loss=2.909 (perp=7.747, rec=0.376, cos=0.984), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS] more little trouble was knew that. besides especially sorting trouble this months. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.858 (perp=7.562, rec=0.360, cos=0.986), tot_loss_proj:3.370 [t=0.19s]
prediction: ['[CLS] more little trouble was that knew. besides especially sorting trouble this corner. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.822 (perp=7.370, rec=0.361, cos=0.987), tot_loss_proj:3.339 [t=0.23s]
prediction: ['[CLS] more little trouble was could knew. besides having trouble sorting this corner. [SEP]']
[ 750/2000] tot_loss=2.983 (perp=8.223, rec=0.350, cos=0.988), tot_loss_proj:3.480 [t=0.18s]
prediction: ['[CLS] more the trouble was could knew. besides having trouble sorting corner corner. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.838 (perp=7.511, rec=0.347, cos=0.989), tot_loss_proj:3.360 [t=0.18s]
prediction: ['[CLS] the more trouble was could known. besides having trouble sorting corner corner. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.966 (perp=8.138, rec=0.350, cos=0.988), tot_loss_proj:3.490 [t=0.18s]
prediction: ['[CLS] the more trouble sorting could known. besides having trouble was corner corner. [SEP]']
[ 900/2000] tot_loss=2.862 (perp=7.664, rec=0.340, cos=0.989), tot_loss_proj:3.429 [t=0.23s]
prediction: ['[CLS] the more trouble ( could known. if more trouble was corner corner. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.786 (perp=7.261, rec=0.344, cos=0.989), tot_loss_proj:3.346 [t=0.17s]
prediction: ['[CLS] the more trouble. could known ( if more trouble was corner corner. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.638 (perp=6.570, rec=0.338, cos=0.986), tot_loss_proj:3.284 [t=0.26s]
prediction: ['[CLS] more trouble. could known ( if more trouble was the corner corner. [SEP]']
[1050/2000] tot_loss=2.640 (perp=6.570, rec=0.338, cos=0.988), tot_loss_proj:3.283 [t=0.24s]
prediction: ['[CLS] more trouble. could known ( if more trouble was the corner corner. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.568 (perp=6.247, rec=0.331, cos=0.988), tot_loss_proj:3.248 [t=0.24s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.561 (perp=6.247, rec=0.324, cos=0.988), tot_loss_proj:3.244 [t=0.18s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
[1200/2000] tot_loss=2.561 (perp=6.247, rec=0.323, cos=0.988), tot_loss_proj:3.251 [t=0.25s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.565 (perp=6.247, rec=0.327, cos=0.989), tot_loss_proj:3.247 [t=0.18s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.559 (perp=6.247, rec=0.321, cos=0.989), tot_loss_proj:3.249 [t=0.18s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
[1350/2000] tot_loss=2.560 (perp=6.247, rec=0.321, cos=0.989), tot_loss_proj:3.250 [t=0.24s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.541 (perp=6.247, rec=0.303, cos=0.989), tot_loss_proj:3.246 [t=0.20s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.556 (perp=6.247, rec=0.317, cos=0.989), tot_loss_proj:3.245 [t=0.20s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
[1500/2000] tot_loss=2.552 (perp=6.247, rec=0.313, cos=0.989), tot_loss_proj:3.247 [t=0.18s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.548 (perp=6.247, rec=0.309, cos=0.990), tot_loss_proj:3.249 [t=0.18s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.553 (perp=6.247, rec=0.314, cos=0.990), tot_loss_proj:3.249 [t=0.18s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
[1650/2000] tot_loss=2.546 (perp=6.247, rec=0.307, cos=0.990), tot_loss_proj:3.248 [t=0.20s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.546 (perp=6.247, rec=0.307, cos=0.990), tot_loss_proj:3.247 [t=0.20s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.554 (perp=6.247, rec=0.314, cos=0.990), tot_loss_proj:3.247 [t=0.17s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
[1800/2000] tot_loss=2.545 (perp=6.247, rec=0.306, cos=0.990), tot_loss_proj:3.249 [t=0.24s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.537 (perp=6.247, rec=0.298, cos=0.990), tot_loss_proj:3.252 [t=0.26s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.544 (perp=6.247, rec=0.304, cos=0.990), tot_loss_proj:3.249 [t=0.26s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
[1950/2000] tot_loss=2.545 (perp=6.247, rec=0.305, cos=0.990), tot_loss_proj:3.253 [t=0.23s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.534 (perp=6.247, rec=0.294, cos=0.990), tot_loss_proj:3.245 [t=0.18s]
prediction: ['[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] i could have little known that more trouble was just around the corner. [SEP]
========================
predicted: 
========================
[CLS] more trouble. ( could known if more trouble was the corner corner. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.286 | p: 69.231 | r: 60.000
rouge2     | fm: 30.769 | p: 33.333 | r: 28.571
rougeL     | fm: 64.286 | p: 69.231 | r: 60.000
rougeLsum  | fm: 64.286 | p: 69.231 | r: 60.000
r1fm+r2fm = 95.055

[Aggregate metrics]:
rouge1     | fm: 74.569 | p: 74.976 | r: 74.540
rouge2     | fm: 34.995 | p: 34.882 | r: 35.106
rougeL     | fm: 64.229 | p: 64.603 | r: 64.103
rougeLsum  | fm: 64.406 | p: 64.727 | r: 64.283
r1fm+r2fm = 109.563

input #51 time: 0:08:00 | total time: 7:07:10


Running input #52 of 100.
reference: 
========================
John gave the books to Mary at Christmas, and the records to Sue for her birthday.
========================
average of cosine similarity 0.9992993920902846
highest_index [0]
highest [0.9992993920902846]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2198, 2435, 1996, 2808, 2000, 2984, 2012, 4234, 1010, 1998, 1996,
         2636, 2000, 9790, 2005, 2014, 5798, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]']
[Init] best rec loss: 0.9534174799919128 for ['[CLS] drama establishments wicket vocal willem presence arm australia dashed guineaturn hand converse sparrow mastof hueymined [SEP]']
[Init] best rec loss: 0.9517337083816528 for ['[CLS] thorn double opera y learnedmist maxi bow [SEP] hove flowering as gwen rug hiding style gold ku [SEP]']
[Init] best rec loss: 0.9427309036254883 for ['[CLS] miller balancelined crawl net ramsay frost platform moved eachcial report lay reflecting # gray army contributed [SEP]']
[Init] best rec loss: 0.9308578372001648 for ['[CLS] semi disks chartersnesia glasses hearth while farm motto jack from enoughyr chamber "grass already steven [SEP]']
[Init] best rec loss: 0.9264649152755737 for ['[CLS] titled gesture sc isaac musical officers afghanistan mineral squarekra chip inducted leaving who jon journal ethan ruse [SEP]']
[Init] best rec loss: 0.8957587480545044 for ['[CLS] widowed pat age tack collaroresuk : we finally characteristic [MASK] workingneyawa printingigraphy intelligence [SEP]']
[Init] best perm rec loss: 0.8955612182617188 for ['[CLS] printing working [MASK]awa pat characteristic finallyney tackores widowedigraphy ageuk collar : intelligence we [SEP]']
[Init] best perm rec loss: 0.8945481181144714 for ['[CLS] intelligenceney characteristic finallyawa we pat widowed printing tackigraphyores collar [MASK]uk age working : [SEP]']
[Init] best perm rec loss: 0.8907304406166077 for ['[CLS] age printingukoresigraphy finally intelligence we : widowed collar [MASK]neyawa pat working characteristic tack [SEP]']
[Init] best perm rec loss: 0.887945294380188 for ['[CLS] : [MASK] workingney characteristic weoresigraphy pat finallyawa tack age intelligenceuk widowed collar printing [SEP]']
[Init] best perm rec loss: 0.8872994780540466 for ['[CLS] :igraphyney working characteristic finally collar age printing tackores [MASK]awa pat intelligenceuk widowed we [SEP]']
[Init] best perm rec loss: 0.8868954181671143 for ['[CLS] : working weney pat finallyores [MASK] printingukawa intelligence characteristic collar tack age widowedigraphy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.113 (perp=12.697, rec=0.466, cos=0.108), tot_loss_proj:4.474 [t=0.19s]
prediction: ['[CLS] warm the imperialney fit grants intersily reed mixed kei humor commentary tube sheet release " buddhism [SEP]']
[ 100/2000] tot_loss=2.780 (perp=11.321, rec=0.406, cos=0.110), tot_loss_proj:4.152 [t=0.18s]
prediction: ['[CLS] journals the great christmas inspiration sue in violent grain mixed christmas fun ending tube sheet picture albums sue [SEP]']
[ 150/2000] tot_loss=2.368 (perp=10.200, rec=0.298, cos=0.030), tot_loss_proj:3.956 [t=0.18s]
prediction: ['[CLS] books the for christmas christmas sue for christmas the mixed christmas a ending tube sheet championship records sue [SEP]']
[ 200/2000] tot_loss=2.229 (perp=9.726, rec=0.263, cos=0.021), tot_loss_proj:3.914 [t=0.28s]
prediction: ['[CLS] books the to christmas christmas sue for christmas the the christmas a ending tube records championship records sue [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.247 (perp=9.571, rec=0.296, cos=0.037), tot_loss_proj:3.854 [t=0.18s]
prediction: ['[CLS] records to to christmas mary sue for records the and christmas ending a tube recordss books sue [SEP]']
[ 300/2000] tot_loss=2.210 (perp=9.877, rec=0.220, cos=0.015), tot_loss_proj:3.931 [t=0.21s]
prediction: ['[CLS] records to to christmas mary sue for records the - christmasville a tube recordss books sue [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.918 (perp=8.460, rec=0.211, cos=0.015), tot_loss_proj:3.639 [t=0.18s]
prediction: ['[CLS] records alike to christmas mary sue at records the for christmas, a tube records birthday books sue [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.833 (perp=11.300, rec=0.435, cos=0.137), tot_loss_proj:4.182 [t=0.28s]
prediction: ['[CLS] books ending went day christmas sue onto tube christmas became christmas, system davis records birthday books sue [SEP]']
[ 450/2000] tot_loss=2.696 (perp=11.667, rec=0.322, cos=0.040), tot_loss_proj:4.263 [t=0.18s]
prediction: ['[CLS] books ending went day christmas mary onto tube christmas became christmas, entertainment davis his funeral books sue [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.322 (perp=10.146, rec=0.270, cos=0.023), tot_loss_proj:3.960 [t=0.30s]
prediction: ['[CLS] books ending went day entertainment mary and tube christmas became christmas, christmas davis his christmas books sue [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.260 (perp=9.529, rec=0.299, cos=0.055), tot_loss_proj:3.871 [t=0.19s]
prediction: ['[CLS] books ending went day and pressed / to christmas, christmas entertainment mary davis records birthday books sue [SEP]']
[ 600/2000] tot_loss=2.058 (perp=8.881, rec=0.256, cos=0.026), tot_loss_proj:3.744 [t=0.20s]
prediction: ['[CLS] books still went day and pressed / to christmas, christmas entertainment mary davis records birthday books sue [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.118 (perp=9.317, rec=0.236, cos=0.019), tot_loss_proj:3.809 [t=0.18s]
prediction: ['[CLS] books still went christmas and pressed birthday to christmas, christmas entertainment mary wished records christmas records sue [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.017 (perp=8.761, rec=0.241, cos=0.025), tot_loss_proj:3.716 [t=0.22s]
prediction: ['[CLS] books still went christmas and christmas entertainment mary wished records pressed birthday to christmas, christmas records sue [SEP]']
[ 750/2000] tot_loss=1.952 (perp=8.562, rec=0.221, cos=0.019), tot_loss_proj:3.673 [t=0.18s]
prediction: ['[CLS] books what to christmas and christmas entertainment mary wished records pressed birthday to christmas, christmas records sue [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.877 (perp=8.249, rec=0.211, cos=0.016), tot_loss_proj:3.610 [t=0.18s]
prediction: ['[CLS] books what to christmas and christmas records mary wished entertainment pressed birthday to christmas, christmas records sue [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.909 (perp=8.410, rec=0.211, cos=0.016), tot_loss_proj:3.638 [t=0.20s]
prediction: ['[CLS] books what to christmas to christmas records mary wished entertainment pressed to birthday christmas, christmas records sue [SEP]']
[ 900/2000] tot_loss=1.970 (perp=8.770, rec=0.201, cos=0.015), tot_loss_proj:3.714 [t=0.22s]
prediction: ['[CLS] books what to christmas to christmas records mary wished entertainment paper to birthday christmas, christmas records sue [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.999 (perp=8.932, rec=0.198, cos=0.014), tot_loss_proj:3.758 [t=0.18s]
prediction: ['[CLS] books. to christmas to paper records mary wishedvsky christmas to birthday christmas, christmas records sue [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.111 (perp=9.400, rec=0.213, cos=0.018), tot_loss_proj:3.759 [t=0.23s]
prediction: ['[CLS] books rallies to christmas and paper records mary christian christmasvsky to birthday christmas, records records sue [SEP]']
[1050/2000] tot_loss=1.926 (perp=8.616, rec=0.190, cos=0.013), tot_loss_proj:3.660 [t=0.18s]
prediction: ['[CLS] books. to christmas and paper records mary christian christmasvsky to birthday christmas, records records sue [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.821 (perp=8.074, rec=0.194, cos=0.012), tot_loss_proj:3.574 [t=0.18s]
prediction: ['[CLS] books. to christmas and paper records mary christian christmasvsky to birthday records, christmas records sue [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.792 (perp=7.850, rec=0.204, cos=0.018), tot_loss_proj:3.540 [t=0.21s]
prediction: ['[CLS] books. christmasvsky to christmas and paper records mary wished to birthday records, christmas records sue [SEP]']
[1200/2000] tot_loss=1.753 (perp=7.763, rec=0.186, cos=0.014), tot_loss_proj:3.498 [t=0.21s]
prediction: ['[CLS] books. christmasvsky to christmas and paper records mary christian to birthday records, her records sue [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.710 (perp=7.573, rec=0.182, cos=0.014), tot_loss_proj:3.449 [t=0.19s]
prediction: ['[CLS] books. hervsky to christmas and paper records mary christian to birthday records, christmas records sue [SEP]']
Attempt swap
[1300/2000] tot_loss=1.815 (perp=8.067, rec=0.188, cos=0.013), tot_loss_proj:3.569 [t=0.22s]
prediction: ['[CLS] books. hervsky to christmas and pressed records mary christian to birthday records, christmas records sue [SEP]']
[1350/2000] tot_loss=1.877 (perp=8.406, rec=0.184, cos=0.013), tot_loss_proj:3.611 [t=0.17s]
prediction: ['[CLS] books. hervsky to christmas to pressed records mary christian to birthday records, christmas records sue [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.841 (perp=8.209, rec=0.188, cos=0.012), tot_loss_proj:3.586 [t=0.18s]
prediction: ['[CLS] books. hervsky to christmas pressed to records mary christian to birthday records, christmas records sue [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.799 (perp=8.035, rec=0.181, cos=0.012), tot_loss_proj:3.555 [t=0.21s]
prediction: ['[CLS] books. hervsky to christmas records to pressed mary christian to birthday records, christmas records sue [SEP]']
[1500/2000] tot_loss=1.800 (perp=8.035, rec=0.181, cos=0.012), tot_loss_proj:3.554 [t=0.19s]
prediction: ['[CLS] books. hervsky to christmas records to pressed mary christian to birthday records, christmas records sue [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.764 (perp=7.854, rec=0.181, cos=0.012), tot_loss_proj:3.516 [t=0.18s]
prediction: ['[CLS] books. hervsky to christmas records to pressed mary christian to christmas records, birthday records sue [SEP]']
Attempt swap
[1600/2000] tot_loss=1.731 (perp=7.714, rec=0.177, cos=0.012), tot_loss_proj:3.494 [t=0.18s]
prediction: ['[CLS] books. hervsky to christmas records to paper mary christian to christmas records, birthday records sue [SEP]']
[1650/2000] tot_loss=1.857 (perp=8.343, rec=0.177, cos=0.012), tot_loss_proj:3.610 [t=0.19s]
prediction: ['[CLS] books. hervsky to christmas records to paper mary philip to christmas records, birthday records sue [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.820 (perp=8.151, rec=0.178, cos=0.012), tot_loss_proj:3.538 [t=0.18s]
prediction: ['[CLS] books. hervsky to christmas records to paper, philip to christmas records mary birthday records sue [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.777 (perp=7.759, rec=0.208, cos=0.017), tot_loss_proj:3.476 [t=0.18s]
prediction: ['[CLS] books. hervsky to christmas records to paper, philip to sue christmas records mary birthday records [SEP]']
[1800/2000] tot_loss=1.769 (perp=7.842, rec=0.187, cos=0.013), tot_loss_proj:3.493 [t=0.23s]
prediction: ['[CLS] books. hervsky to christmas records to pressed, philip to sue christmas records mary birthday records [SEP]']
Attempt swap
[1850/2000] tot_loss=1.761 (perp=7.842, rec=0.180, cos=0.012), tot_loss_proj:3.492 [t=0.25s]
prediction: ['[CLS] books. hervsky to christmas records to pressed, philip to sue christmas records mary birthday records [SEP]']
Attempt swap
[1900/2000] tot_loss=1.757 (perp=7.842, rec=0.176, cos=0.012), tot_loss_proj:3.499 [t=0.19s]
prediction: ['[CLS] books. hervsky to christmas records to pressed, philip to sue christmas records mary birthday records [SEP]']
[1950/2000] tot_loss=1.756 (perp=7.842, rec=0.176, cos=0.012), tot_loss_proj:3.491 [t=0.21s]
prediction: ['[CLS] books. hervsky to christmas records to pressed, philip to sue christmas records mary birthday records [SEP]']
Attempt swap
[2000/2000] tot_loss=1.752 (perp=7.842, rec=0.172, cos=0.011), tot_loss_proj:3.493 [t=0.20s]
prediction: ['[CLS] books. hervsky to christmas records to pressed, philip to sue christmas records mary birthday records [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]
========================
predicted: 
========================
[CLS] books. hervsky to christmas records to pressed, philip to sue christmas records mary birthday records [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 58.824 | r: 55.556
rouge2     | fm: 12.121 | p: 12.500 | r: 11.765
rougeL     | fm: 51.429 | p: 52.941 | r: 50.000
rougeLsum  | fm: 51.429 | p: 52.941 | r: 50.000
r1fm+r2fm = 69.264

[Aggregate metrics]:
rouge1     | fm: 74.382 | p: 74.707 | r: 74.268
rouge2     | fm: 34.493 | p: 34.404 | r: 34.590
rougeL     | fm: 63.960 | p: 64.352 | r: 63.777
rougeLsum  | fm: 64.221 | p: 64.558 | r: 64.007
r1fm+r2fm = 108.875

input #52 time: 0:08:20 | total time: 7:15:31


Running input #53 of 100.
reference: 
========================
He said that himself was hungry.
========================
average of cosine similarity 0.9993481863787016
highest_index [0]
highest [0.9993481863787016]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2056, 2008, 2370, 2001, 7501, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he said that himself was hungry. [SEP]']
[Init] best rec loss: 0.9756957292556763 for ['[CLS] syncoc youth also returning jaguar flower [SEP]']
[Init] best rec loss: 0.9171878695487976 for ['[CLS] terms expireditanupt racing everuating [SEP]']
[Init] best rec loss: 0.8175871968269348 for ['[CLS] these once ofents intensive course vu [SEP]']
[Init] best rec loss: 0.8068182468414307 for ['[CLS] over breed [CLS] mentioned pitched genus memories [SEP]']
[Init] best rec loss: 0.7839474081993103 for ['[CLS] house chi browningchia himalayan audience appeal [SEP]']
[Init] best rec loss: 0.7613614201545715 for ['[CLS] " head rifle hate moved course youth [SEP]']
[Init] best rec loss: 0.7518348693847656 for ['[CLS] gravel shooter promotion rios press eve voyage [SEP]']
[Init] best rec loss: 0.738399863243103 for ['[CLS] 2002 faso tone averaged category wave doubt [SEP]']
[Init] best rec loss: 0.7359643578529358 for ['[CLS] sorry multi care by sherlock relief google [SEP]']
[Init] best perm rec loss: 0.7308405041694641 for ['[CLS] google multi sorry sherlock relief care by [SEP]']
[Init] best perm rec loss: 0.7285928726196289 for ['[CLS] care sorry by sherlock multi relief google [SEP]']
[Init] best perm rec loss: 0.7279585003852844 for ['[CLS] multi by sorry care google relief sherlock [SEP]']
[Init] best perm rec loss: 0.7274588346481323 for ['[CLS] multi care by sherlock sorry relief google [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.206 (perp=9.608, rec=0.273, cos=0.011), tot_loss_proj:2.547 [t=0.22s]
prediction: ['[CLS] hind. william them was. himself [SEP]']
[ 100/2000] tot_loss=1.786 (perp=7.893, rec=0.202, cos=0.006), tot_loss_proj:2.441 [t=0.30s]
prediction: ['[CLS] said says he himself was. hungry [SEP]']
[ 150/2000] tot_loss=1.437 (perp=6.604, rec=0.112, cos=0.004), tot_loss_proj:2.746 [t=0.19s]
prediction: ['[CLS] said that he himself was. hungry [SEP]']
[ 200/2000] tot_loss=1.411 (perp=6.604, rec=0.086, cos=0.004), tot_loss_proj:2.773 [t=0.18s]
prediction: ['[CLS] said that he himself was. hungry [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.101 (perp=5.031, rec=0.091, cos=0.004), tot_loss_proj:2.743 [t=0.18s]
prediction: ['[CLS] said that he himself was hungry, [SEP]']
[ 300/2000] tot_loss=1.094 (perp=5.031, rec=0.084, cos=0.003), tot_loss_proj:2.735 [t=0.24s]
prediction: ['[CLS] said that he himself was hungry, [SEP]']
Attempt swap
[ 350/2000] tot_loss=0.986 (perp=4.560, rec=0.070, cos=0.003), tot_loss_proj:2.743 [t=0.20s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 400/2000] tot_loss=0.987 (perp=4.560, rec=0.071, cos=0.003), tot_loss_proj:2.744 [t=0.25s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[ 450/2000] tot_loss=0.986 (perp=4.560, rec=0.071, cos=0.003), tot_loss_proj:2.747 [t=0.18s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 500/2000] tot_loss=0.977 (perp=4.560, rec=0.062, cos=0.003), tot_loss_proj:2.747 [t=0.27s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 550/2000] tot_loss=0.987 (perp=4.560, rec=0.071, cos=0.003), tot_loss_proj:2.744 [t=0.22s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[ 600/2000] tot_loss=0.984 (perp=4.560, rec=0.068, cos=0.003), tot_loss_proj:2.743 [t=0.18s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.984 (perp=4.560, rec=0.069, cos=0.003), tot_loss_proj:2.746 [t=0.21s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.985 (perp=4.560, rec=0.070, cos=0.003), tot_loss_proj:2.747 [t=0.17s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[ 750/2000] tot_loss=0.986 (perp=4.560, rec=0.071, cos=0.003), tot_loss_proj:2.745 [t=0.18s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.978 (perp=4.560, rec=0.062, cos=0.003), tot_loss_proj:2.747 [t=0.18s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.976 (perp=4.560, rec=0.060, cos=0.003), tot_loss_proj:2.744 [t=0.29s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[ 900/2000] tot_loss=0.988 (perp=4.560, rec=0.072, cos=0.003), tot_loss_proj:2.749 [t=0.20s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.987 (perp=4.560, rec=0.071, cos=0.003), tot_loss_proj:2.747 [t=0.27s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.986 (perp=4.560, rec=0.070, cos=0.003), tot_loss_proj:2.741 [t=0.21s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1050/2000] tot_loss=0.985 (perp=4.560, rec=0.070, cos=0.003), tot_loss_proj:2.750 [t=0.28s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.980 (perp=4.560, rec=0.065, cos=0.003), tot_loss_proj:2.749 [t=0.17s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.979 (perp=4.560, rec=0.064, cos=0.003), tot_loss_proj:2.743 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1200/2000] tot_loss=0.983 (perp=4.560, rec=0.068, cos=0.003), tot_loss_proj:2.740 [t=0.31s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.977 (perp=4.560, rec=0.062, cos=0.003), tot_loss_proj:2.743 [t=0.20s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.988 (perp=4.560, rec=0.073, cos=0.003), tot_loss_proj:2.748 [t=0.18s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1350/2000] tot_loss=0.980 (perp=4.560, rec=0.064, cos=0.003), tot_loss_proj:2.746 [t=0.24s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.993 (perp=4.560, rec=0.077, cos=0.003), tot_loss_proj:2.746 [t=0.21s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.976 (perp=4.560, rec=0.061, cos=0.003), tot_loss_proj:2.744 [t=0.23s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1500/2000] tot_loss=0.984 (perp=4.560, rec=0.069, cos=0.003), tot_loss_proj:2.748 [t=0.19s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.991 (perp=4.560, rec=0.075, cos=0.003), tot_loss_proj:2.746 [t=0.27s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.984 (perp=4.560, rec=0.068, cos=0.003), tot_loss_proj:2.742 [t=0.18s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1650/2000] tot_loss=0.991 (perp=4.560, rec=0.076, cos=0.003), tot_loss_proj:2.743 [t=0.22s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.987 (perp=4.560, rec=0.071, cos=0.003), tot_loss_proj:2.745 [t=0.20s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.987 (perp=4.560, rec=0.071, cos=0.003), tot_loss_proj:2.746 [t=0.26s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1800/2000] tot_loss=0.981 (perp=4.560, rec=0.065, cos=0.003), tot_loss_proj:2.744 [t=0.17s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.981 (perp=4.560, rec=0.065, cos=0.003), tot_loss_proj:2.747 [t=0.26s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.983 (perp=4.560, rec=0.067, cos=0.003), tot_loss_proj:2.739 [t=0.17s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
[1950/2000] tot_loss=0.982 (perp=4.560, rec=0.066, cos=0.003), tot_loss_proj:2.746 [t=0.19s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.983 (perp=4.560, rec=0.068, cos=0.003), tot_loss_proj:2.740 [t=0.20s]
prediction: ['[CLS] said that he himself was hungry. [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] he said that himself was hungry. [SEP]
========================
predicted: 
========================
[CLS] said that he himself was hungry. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 74.869 | p: 75.223 | r: 74.800
rouge2     | fm: 34.946 | p: 34.966 | r: 35.006
rougeL     | fm: 64.383 | p: 64.834 | r: 64.210
rougeLsum  | fm: 64.556 | p: 65.045 | r: 64.467
r1fm+r2fm = 109.815

input #53 time: 0:08:31 | total time: 7:24:02


Running input #54 of 100.
reference: 
========================
After reading the pamphlet, Judy threw them into the garbage can.
========================
average of cosine similarity 0.999388282605312
highest_index [0]
highest [0.999388282605312]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  2044,  3752,  1996, 19899,  1010, 12120,  4711,  2068,  2046,
          1996, 13044,  2064,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]']
[Init] best rec loss: 1.0086065530776978 for ['[CLS]position unavailable reporter wink zero do leaning double declared temple swift 2012 fine [SEP]']
[Init] best rec loss: 0.9829070568084717 for ['[CLS] crop jagger occurred badly oil alike destination [ session show sunrisehita you [SEP]']
[Init] best rec loss: 0.9422270059585571 for ['[CLS] electvic push warehouse humor aboutpiece lock eponymousgrant prison measure even [SEP]']
[Init] best rec loss: 0.9266153573989868 for ['[CLS] edward gwen daily ever consideredards erminafar quad river given why [SEP]']
[Init] best rec loss: 0.9201857447624207 for ['[CLS] eve battalion minutes strike twinned trip bond candidatesiarangleib lame macedonia [SEP]']
[Init] best rec loss: 0.9138299226760864 for ['[CLS]chi £ our melbourne back [MASK] damtec isn jake hangbution a [SEP]']
[Init] best rec loss: 0.9105693697929382 for ['[CLS]abyrase fin self beers graphic concentration rise odd coolerus sex flying [SEP]']
[Init] best perm rec loss: 0.9102561473846436 for ['[CLS] sex self graphic odd fin rise coolaby flying beersraseerus concentration [SEP]']
[Init] best perm rec loss: 0.9093592762947083 for ['[CLS] flying concentration odd fin graphicerus coolaby self sex beers riserase [SEP]']
[Init] best perm rec loss: 0.9088178873062134 for ['[CLS] rise beers odd self fin flyingrase graphic sexerusaby cool concentration [SEP]']
[Init] best perm rec loss: 0.9084143042564392 for ['[CLS] concentration coolaby self odd riseerus fin sexrase beers flying graphic [SEP]']
[Init] best perm rec loss: 0.9079568982124329 for ['[CLS] concentration riseerus fin graphicaby self oddrase sex flying beers cool [SEP]']
[Init] best perm rec loss: 0.9070364832878113 for ['[CLS]raseerus graphic cool fin selfaby beers flying sex concentration odd rise [SEP]']
[Init] best perm rec loss: 0.9065402150154114 for ['[CLS] graphic rise odd selfrase flying sex fin cool beersaby concentrationerus [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.550 (perp=14.152, rec=0.839, cos=0.880), tot_loss_proj:4.740 [t=0.17s]
prediction: ['[CLS]ount beam remaining infrared prose molly dozen markingspan them. them und [SEP]']
[ 100/2000] tot_loss=3.920 (perp=11.675, rec=0.607, cos=0.978), tot_loss_proj:4.268 [t=0.18s]
prediction: ['[CLS] their section : infraredo molly ignatius punta on gaze. looked onto [SEP]']
[ 150/2000] tot_loss=3.774 (perp=11.298, rec=0.527, cos=0.987), tot_loss_proj:4.190 [t=0.18s]
prediction: ['[CLS] them section : multiplayerjust book offers complaint into going.scribe onto [SEP]']
[ 200/2000] tot_loss=3.795 (perp=11.748, rec=0.451, cos=0.994), tot_loss_proj:4.214 [t=0.29s]
prediction: ['[CLS] them section pamphlet pamphletjust pamphlet offers them into threw.iving onto [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.978 (perp=12.369, rec=0.507, cos=0.997), tot_loss_proj:4.392 [t=0.22s]
prediction: ['[CLS] them abstracts : germans buffalo pamphlet throwing lucivar fbi thrown. ontogoing [SEP]']
[ 300/2000] tot_loss=3.929 (perp=12.639, rec=0.403, cos=0.998), tot_loss_proj:4.393 [t=0.30s]
prediction: ['[CLS] themcore compilation pamphlet breast pamphlet threw nope article thrown. intogoing [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.282 (perp=9.558, rec=0.371, cos=0.999), tot_loss_proj:3.773 [t=0.28s]
prediction: ['[CLS] themcore pamphlet pamphlet, pamphlet threw nope pamphlet threw into prize. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.562 (perp=10.384, rec=0.485, cos=1.000), tot_loss_proj:3.932 [t=0.24s]
prediction: ['[CLS] them each pamphlet pamphlet while pamphlet threw overs comicstext into nope. [SEP]']
[ 450/2000] tot_loss=3.401 (perp=10.050, rec=0.391, cos=1.000), tot_loss_proj:3.899 [t=0.26s]
prediction: ['[CLS] them each pamphlet pamphlet while pamphlet threw overs comics papers into debbie. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.483 (perp=10.583, rec=0.367, cos=1.000), tot_loss_proj:3.998 [t=0.26s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet woke each threw overs pamphlet garbage into debbie. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.487 (perp=10.684, rec=0.351, cos=1.000), tot_loss_proj:4.023 [t=0.26s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wake each threw overs garbage into rachel pamphlet. [SEP]']
[ 600/2000] tot_loss=3.397 (perp=10.278, rec=0.341, cos=1.000), tot_loss_proj:3.926 [t=0.22s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet woke each threwstand garbage into rachel pamphlet. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.287 (perp=9.734, rec=0.340, cos=1.000), tot_loss_proj:3.861 [t=0.26s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet woke rachel threwstand garbage into each pamphlet. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.288 (perp=9.793, rec=0.329, cos=1.000), tot_loss_proj:3.914 [t=0.25s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet deux rachel threwstand garbage into each pamphlet. [SEP]']
[ 750/2000] tot_loss=3.290 (perp=9.793, rec=0.331, cos=1.000), tot_loss_proj:3.914 [t=0.25s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet deux rachel threwstand garbage into each pamphlet. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=3.250 (perp=9.604, rec=0.330, cos=1.000), tot_loss_proj:3.916 [t=0.27s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet deux rachelstand threw garbage into each pamphlet. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.129 (perp=9.012, rec=0.326, cos=1.000), tot_loss_proj:3.734 [t=0.20s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet whenever rachelstand threw garbage into each pamphlet. [SEP]']
[ 900/2000] tot_loss=3.316 (perp=9.955, rec=0.325, cos=1.000), tot_loss_proj:3.873 [t=0.20s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet whenever rachelstand threw garbage into book pamphlet. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.220 (perp=9.507, rec=0.319, cos=1.000), tot_loss_proj:3.778 [t=0.24s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet whenever rachelstand threw pamphlet into each garbage. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.253 (perp=9.707, rec=0.312, cos=0.999), tot_loss_proj:3.842 [t=0.32s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet whenever rachelstand threw pamphlet into book garbage. [SEP]']
[1050/2000] tot_loss=3.247 (perp=9.679, rec=0.312, cos=0.999), tot_loss_proj:3.823 [t=0.27s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet whenever rachelstand threw pamphlet into cash garbage. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=3.185 (perp=9.386, rec=0.309, cos=1.000), tot_loss_proj:3.774 [t=0.29s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet whenever rachelstand threw pamphlet into garbage cash. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=3.335 (perp=10.123, rec=0.311, cos=0.999), tot_loss_proj:3.934 [t=0.24s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstand rachel threw pamphlet into garbage cash. [SEP]']
[1200/2000] tot_loss=3.333 (perp=10.123, rec=0.310, cos=0.999), tot_loss_proj:3.934 [t=0.24s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstand rachel threw pamphlet into garbage cash. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.358 (perp=10.206, rec=0.318, cos=0.999), tot_loss_proj:3.951 [t=0.21s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw pamphlet into garbage anyway. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.354 (perp=10.206, rec=0.313, cos=0.999), tot_loss_proj:3.956 [t=0.27s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw pamphlet into garbage anyway. [SEP]']
[1350/2000] tot_loss=3.358 (perp=10.206, rec=0.318, cos=0.999), tot_loss_proj:3.958 [t=0.31s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw pamphlet into garbage anyway. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.349 (perp=10.206, rec=0.309, cos=0.999), tot_loss_proj:3.960 [t=0.26s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw pamphlet into garbage anyway. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.351 (perp=10.206, rec=0.311, cos=0.999), tot_loss_proj:3.956 [t=0.30s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw pamphlet into garbage anyway. [SEP]']
[1500/2000] tot_loss=3.350 (perp=10.206, rec=0.310, cos=0.999), tot_loss_proj:3.956 [t=0.27s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw pamphlet into garbage anyway. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.350 (perp=10.206, rec=0.310, cos=0.999), tot_loss_proj:3.955 [t=0.26s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw pamphlet into garbage anyway. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.348 (perp=10.206, rec=0.309, cos=0.999), tot_loss_proj:3.956 [t=0.29s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw pamphlet into garbage anyway. [SEP]']
[1650/2000] tot_loss=3.350 (perp=10.206, rec=0.310, cos=0.998), tot_loss_proj:3.948 [t=0.29s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw pamphlet into garbage anyway. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=3.316 (perp=10.096, rec=0.298, cos=0.998), tot_loss_proj:3.904 [t=0.29s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw into pamphlet garbage anyway. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.325 (perp=10.096, rec=0.307, cos=0.998), tot_loss_proj:3.907 [t=0.26s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw into pamphlet garbage anyway. [SEP]']
[1800/2000] tot_loss=3.326 (perp=10.096, rec=0.309, cos=0.998), tot_loss_proj:3.904 [t=0.25s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw into pamphlet garbage anyway. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.324 (perp=10.096, rec=0.307, cos=0.998), tot_loss_proj:3.902 [t=0.24s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw into pamphlet garbage anyway. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.319 (perp=10.096, rec=0.301, cos=0.998), tot_loss_proj:3.909 [t=0.31s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw into pamphlet garbage anyway. [SEP]']
[1950/2000] tot_loss=3.325 (perp=10.096, rec=0.308, cos=0.998), tot_loss_proj:3.903 [t=0.28s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw into pamphlet garbage anyway. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.320 (perp=10.096, rec=0.303, cos=0.998), tot_loss_proj:3.905 [t=0.24s]
prediction: ['[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw into pamphlet garbage anyway. [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]
========================
predicted: 
========================
[CLS] them pamphlet pamphlet pamphlet wheneverstandclops threw into pamphlet garbage anyway. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.000 | p: 58.333 | r: 53.846
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 48.000 | p: 50.000 | r: 46.154
rougeLsum  | fm: 48.000 | p: 50.000 | r: 46.154
r1fm+r2fm = 56.000

[Aggregate metrics]:
rouge1     | fm: 74.562 | p: 74.880 | r: 74.469
rouge2     | fm: 34.339 | p: 34.352 | r: 34.442
rougeL     | fm: 64.099 | p: 64.532 | r: 63.985
rougeLsum  | fm: 64.186 | p: 64.587 | r: 64.020
r1fm+r2fm = 108.900

input #54 time: 0:10:03 | total time: 7:34:06


Running input #55 of 100.
reference: 
========================
Collapsed Harry.
========================
average of cosine similarity 0.9993911323857783
highest_index [0]
highest [0.9993911323857783]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 7798, 4302, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] collapsed harry. [SEP]']
[Init] best rec loss: 0.9055206179618835 for ['[CLS] taken dana once [SEP]']
[Init] best rec loss: 0.8123528957366943 for ['[CLS] information op respect [SEP]']
[Init] best rec loss: 0.7759804129600525 for ['[CLS] lorieyer marrow [SEP]']
[Init] best rec loss: 0.723248302936554 for ['[CLS] class atlantic martins [SEP]']
[Init] best rec loss: 0.718425452709198 for ['[CLS] these how conditioning [SEP]']
[Init] best rec loss: 0.7074264287948608 for ['[CLS] coup pace lila [SEP]']
[Init] best rec loss: 0.6903390884399414 for ['[CLS] mage sharing roman [SEP]']
[Init] best perm rec loss: 0.6879101395606995 for ['[CLS] mage roman sharing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.142 (perp=13.333, rec=0.417, cos=0.058), tot_loss_proj:3.688 [t=0.22s]
prediction: ['[CLS] strength collapsed fetal [SEP]']
[ 100/2000] tot_loss=2.859 (perp=13.094, rec=0.217, cos=0.023), tot_loss_proj:3.472 [t=0.24s]
prediction: ['[CLS]tension collapsed harry [SEP]']
[ 150/2000] tot_loss=2.613 (perp=12.184, rec=0.160, cos=0.017), tot_loss_proj:3.363 [t=0.28s]
prediction: ['[CLS] harry collapsed harry [SEP]']
[ 200/2000] tot_loss=2.599 (perp=12.184, rec=0.144, cos=0.018), tot_loss_proj:3.363 [t=0.29s]
prediction: ['[CLS] harry collapsed harry [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.323 (perp=10.807, rec=0.140, cos=0.022), tot_loss_proj:3.371 [t=0.28s]
prediction: ['[CLS] harry harry collapsed [SEP]']
[ 300/2000] tot_loss=2.278 (perp=10.807, rec=0.108, cos=0.009), tot_loss_proj:3.240 [t=0.24s]
prediction: ['[CLS] harry harry collapsed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.267 (perp=10.807, rec=0.099, cos=0.007), tot_loss_proj:3.231 [t=0.27s]
prediction: ['[CLS] harry harry collapsed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.258 (perp=10.807, rec=0.091, cos=0.005), tot_loss_proj:3.222 [t=0.21s]
prediction: ['[CLS] harry harry collapsed [SEP]']
[ 450/2000] tot_loss=2.260 (perp=10.807, rec=0.094, cos=0.005), tot_loss_proj:3.219 [t=0.19s]
prediction: ['[CLS] harry harry collapsed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.257 (perp=10.807, rec=0.091, cos=0.005), tot_loss_proj:3.242 [t=0.27s]
prediction: ['[CLS] harry harry collapsed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.245 (perp=10.784, rec=0.085, cos=0.003), tot_loss_proj:4.040 [t=0.28s]
prediction: ['[CLS]. harry collapsed [SEP]']
[ 600/2000] tot_loss=2.223 (perp=10.784, rec=0.064, cos=0.002), tot_loss_proj:4.043 [t=0.26s]
prediction: ['[CLS]. harry collapsed [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.943 (perp=9.208, rec=0.095, cos=0.006), tot_loss_proj:2.974 [t=0.25s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.913 (perp=9.208, rec=0.070, cos=0.002), tot_loss_proj:2.967 [t=0.29s]
prediction: ['[CLS] collapsed harry. [SEP]']
[ 750/2000] tot_loss=1.925 (perp=9.208, rec=0.082, cos=0.002), tot_loss_proj:2.978 [t=0.30s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.909 (perp=9.208, rec=0.066, cos=0.002), tot_loss_proj:2.971 [t=0.25s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.904 (perp=9.208, rec=0.061, cos=0.002), tot_loss_proj:2.968 [t=0.23s]
prediction: ['[CLS] collapsed harry. [SEP]']
[ 900/2000] tot_loss=1.908 (perp=9.208, rec=0.065, cos=0.002), tot_loss_proj:2.970 [t=0.22s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.915 (perp=9.208, rec=0.072, cos=0.002), tot_loss_proj:2.965 [t=0.21s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.922 (perp=9.208, rec=0.079, cos=0.001), tot_loss_proj:2.974 [t=0.20s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1050/2000] tot_loss=1.907 (perp=9.208, rec=0.064, cos=0.001), tot_loss_proj:2.967 [t=0.31s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.906 (perp=9.208, rec=0.063, cos=0.001), tot_loss_proj:2.964 [t=0.29s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.905 (perp=9.208, rec=0.062, cos=0.001), tot_loss_proj:2.972 [t=0.26s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1200/2000] tot_loss=1.911 (perp=9.208, rec=0.068, cos=0.001), tot_loss_proj:2.966 [t=0.24s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.910 (perp=9.208, rec=0.067, cos=0.001), tot_loss_proj:2.968 [t=0.28s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.907 (perp=9.208, rec=0.064, cos=0.001), tot_loss_proj:2.967 [t=0.30s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1350/2000] tot_loss=1.906 (perp=9.208, rec=0.063, cos=0.001), tot_loss_proj:2.966 [t=0.27s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.921 (perp=9.208, rec=0.078, cos=0.001), tot_loss_proj:2.962 [t=0.28s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.915 (perp=9.208, rec=0.072, cos=0.001), tot_loss_proj:2.967 [t=0.21s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1500/2000] tot_loss=1.910 (perp=9.208, rec=0.067, cos=0.001), tot_loss_proj:2.970 [t=0.25s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.912 (perp=9.208, rec=0.069, cos=0.001), tot_loss_proj:2.967 [t=0.26s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.911 (perp=9.208, rec=0.068, cos=0.001), tot_loss_proj:2.973 [t=0.22s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1650/2000] tot_loss=1.916 (perp=9.208, rec=0.073, cos=0.001), tot_loss_proj:2.967 [t=0.28s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.914 (perp=9.208, rec=0.071, cos=0.001), tot_loss_proj:2.977 [t=0.28s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.905 (perp=9.208, rec=0.062, cos=0.001), tot_loss_proj:2.971 [t=0.25s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1800/2000] tot_loss=1.910 (perp=9.208, rec=0.067, cos=0.001), tot_loss_proj:2.964 [t=0.22s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.916 (perp=9.208, rec=0.073, cos=0.001), tot_loss_proj:2.969 [t=0.26s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.908 (perp=9.208, rec=0.065, cos=0.001), tot_loss_proj:2.972 [t=0.28s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1950/2000] tot_loss=1.900 (perp=9.208, rec=0.058, cos=0.001), tot_loss_proj:2.971 [t=0.28s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.901 (perp=9.208, rec=0.058, cos=0.001), tot_loss_proj:2.977 [t=0.26s]
prediction: ['[CLS] collapsed harry. [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] collapsed harry. [SEP]
========================
predicted: 
========================
[CLS] collapsed harry. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 75.054 | p: 75.417 | r: 74.911
rouge2     | fm: 35.496 | p: 35.498 | r: 35.646
rougeL     | fm: 64.746 | p: 65.151 | r: 64.607
rougeLsum  | fm: 65.004 | p: 65.395 | r: 64.792
r1fm+r2fm = 110.550

input #55 time: 0:10:09 | total time: 7:44:15


Running input #56 of 100.
reference: 
========================
John was seeing his children.
========================
average of cosine similarity 0.9993522822859878
highest_index [0]
highest [0.9993522822859878]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2198, 2001, 3773, 2010, 2336, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john was seeing his children. [SEP]']
[Init] best rec loss: 0.9693037271499634 for ['[CLS] vampire artists at like edge into [SEP]']
[Init] best rec loss: 0.9084345102310181 for ['[CLS] banned scout fadeper residence nursery [SEP]']
[Init] best perm rec loss: 0.9078051447868347 for ['[CLS] banned residence fade scoutper nursery [SEP]']
[Init] best perm rec loss: 0.9077329635620117 for ['[CLS] scout nursery residence bannedper fade [SEP]']
[Init] best perm rec loss: 0.9056980013847351 for ['[CLS] residence fade nurseryper banned scout [SEP]']
[Init] best perm rec loss: 0.9053595662117004 for ['[CLS] residence fade bannedper scout nursery [SEP]']
[Init] best perm rec loss: 0.9046943187713623 for ['[CLS] banned residence fade scout nurseryper [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.581 (perp=9.828, rec=0.644, cos=0.972), tot_loss_proj:3.770 [t=0.29s]
prediction: ['[CLS] sure.? napoleon she jerk [SEP]']
[ 100/2000] tot_loss=2.566 (perp=10.521, rec=0.388, cos=0.074), tot_loss_proj:3.915 [t=0.25s]
prediction: ['[CLS] seeing ; have standing john engineering [SEP]']
[ 150/2000] tot_loss=1.653 (perp=7.032, rec=0.230, cos=0.016), tot_loss_proj:3.364 [t=0.29s]
prediction: ['[CLS] seeing john seeing his john was [SEP]']
[ 200/2000] tot_loss=1.921 (perp=8.909, rec=0.133, cos=0.007), tot_loss_proj:3.854 [t=0.26s]
prediction: ['[CLS] seeing. seeing children john was [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.694 (perp=7.836, rec=0.119, cos=0.007), tot_loss_proj:3.695 [t=0.30s]
prediction: ['[CLS] seeing seeing children. john was [SEP]']
[ 300/2000] tot_loss=1.676 (perp=7.836, rec=0.103, cos=0.006), tot_loss_proj:3.708 [t=0.27s]
prediction: ['[CLS] seeing seeing children. john was [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.660 (perp=7.788, rec=0.097, cos=0.006), tot_loss_proj:3.379 [t=0.25s]
prediction: ['[CLS] seeing children seeing. john was [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.656 (perp=7.788, rec=0.093, cos=0.005), tot_loss_proj:3.374 [t=0.28s]
prediction: ['[CLS] seeing children seeing. john was [SEP]']
[ 450/2000] tot_loss=1.672 (perp=7.864, rec=0.094, cos=0.004), tot_loss_proj:3.625 [t=0.22s]
prediction: ['[CLS] seeing children seeing his john was [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.425 (perp=6.590, rec=0.101, cos=0.005), tot_loss_proj:3.395 [t=0.23s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.420 (perp=6.590, rec=0.097, cos=0.005), tot_loss_proj:3.400 [t=0.28s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
[ 600/2000] tot_loss=1.408 (perp=6.590, rec=0.085, cos=0.005), tot_loss_proj:3.393 [t=0.28s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.412 (perp=6.590, rec=0.089, cos=0.004), tot_loss_proj:3.400 [t=0.30s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.395 (perp=6.590, rec=0.073, cos=0.004), tot_loss_proj:3.403 [t=0.28s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
[ 750/2000] tot_loss=1.397 (perp=6.590, rec=0.075, cos=0.004), tot_loss_proj:3.400 [t=0.26s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.399 (perp=6.590, rec=0.077, cos=0.004), tot_loss_proj:3.406 [t=0.22s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.405 (perp=6.590, rec=0.083, cos=0.004), tot_loss_proj:3.405 [t=0.30s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
[ 900/2000] tot_loss=1.400 (perp=6.590, rec=0.078, cos=0.004), tot_loss_proj:3.408 [t=0.25s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.398 (perp=6.590, rec=0.076, cos=0.004), tot_loss_proj:3.409 [t=0.26s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
Attempt swap
[1000/2000] tot_loss=1.398 (perp=6.590, rec=0.076, cos=0.004), tot_loss_proj:3.411 [t=0.25s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
[1050/2000] tot_loss=1.394 (perp=6.590, rec=0.072, cos=0.004), tot_loss_proj:3.407 [t=0.25s]
prediction: ['[CLS] seeing john seeing his children was [SEP]']
Attempt swap
[1100/2000] tot_loss=1.450 (perp=6.828, rec=0.081, cos=0.004), tot_loss_proj:3.491 [t=0.29s]
prediction: ['[CLS]. john seeing his children was [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.317 (perp=6.132, rec=0.086, cos=0.005), tot_loss_proj:3.394 [t=0.27s]
prediction: ['[CLS] was john seeing his children. [SEP]']
[1200/2000] tot_loss=1.306 (perp=6.132, rec=0.076, cos=0.004), tot_loss_proj:3.405 [t=0.26s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.315 (perp=6.132, rec=0.085, cos=0.003), tot_loss_proj:3.400 [t=0.26s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.308 (perp=6.132, rec=0.078, cos=0.003), tot_loss_proj:3.403 [t=0.26s]
prediction: ['[CLS] was john seeing his children. [SEP]']
[1350/2000] tot_loss=1.300 (perp=6.132, rec=0.070, cos=0.003), tot_loss_proj:3.400 [t=0.31s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.292 (perp=6.132, rec=0.063, cos=0.003), tot_loss_proj:3.402 [t=0.31s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.310 (perp=6.132, rec=0.080, cos=0.003), tot_loss_proj:3.399 [t=0.25s]
prediction: ['[CLS] was john seeing his children. [SEP]']
[1500/2000] tot_loss=1.309 (perp=6.132, rec=0.079, cos=0.003), tot_loss_proj:3.400 [t=0.30s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.306 (perp=6.132, rec=0.076, cos=0.003), tot_loss_proj:3.403 [t=0.25s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.308 (perp=6.132, rec=0.079, cos=0.003), tot_loss_proj:3.404 [t=0.22s]
prediction: ['[CLS] was john seeing his children. [SEP]']
[1650/2000] tot_loss=1.305 (perp=6.132, rec=0.075, cos=0.003), tot_loss_proj:3.402 [t=0.24s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.305 (perp=6.132, rec=0.075, cos=0.003), tot_loss_proj:3.396 [t=0.29s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.309 (perp=6.132, rec=0.079, cos=0.003), tot_loss_proj:3.402 [t=0.27s]
prediction: ['[CLS] was john seeing his children. [SEP]']
[1800/2000] tot_loss=1.316 (perp=6.132, rec=0.086, cos=0.003), tot_loss_proj:3.400 [t=0.21s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.301 (perp=6.132, rec=0.071, cos=0.003), tot_loss_proj:3.405 [t=0.28s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.301 (perp=6.132, rec=0.071, cos=0.003), tot_loss_proj:3.399 [t=0.27s]
prediction: ['[CLS] was john seeing his children. [SEP]']
[1950/2000] tot_loss=1.303 (perp=6.132, rec=0.074, cos=0.003), tot_loss_proj:3.401 [t=0.23s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.297 (perp=6.132, rec=0.068, cos=0.003), tot_loss_proj:3.407 [t=0.29s]
prediction: ['[CLS] was john seeing his children. [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] john was seeing his children. [SEP]
========================
predicted: 
========================
[CLS] was john seeing his children. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 75.460 | p: 75.831 | r: 75.322
rouge2     | fm: 35.671 | p: 35.614 | r: 35.776
rougeL     | fm: 65.100 | p: 65.493 | r: 64.939
rougeLsum  | fm: 65.371 | p: 65.737 | r: 65.208
r1fm+r2fm = 111.130

input #56 time: 0:10:11 | total time: 7:54:27


Running input #57 of 100.
reference: 
========================
Carla mopped the floor under the furniture.
========================
average of cosine similarity 0.999410832505384
highest_index [0]
highest [0.999410832505384]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 17081,  9587, 11469,  1996,  2723,  2104,  1996,  7390,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] carla mopped the floor under the furniture. [SEP]']
[Init] best rec loss: 0.9423267245292664 for ['[CLS]ne gathering do their health retirement go enforce things [SEP]']
[Init] best rec loss: 0.9340547919273376 for ['[CLS]kes second loose late west allied creation utility evelyn [SEP]']
[Init] best rec loss: 0.9054117202758789 for ['[CLS]quent quadrant material seat inclusion kn difference vincent stubborn [SEP]']
[Init] best rec loss: 0.8925279974937439 for ['[CLS] mari guy identity episode use formsorescence nm fit [SEP]']
[Init] best rec loss: 0.8883852958679199 for ['[CLS] jack itself cheers elevation back sharing volunteeredthan solid [SEP]']
[Init] best perm rec loss: 0.8876361846923828 for ['[CLS] itself elevation back jack sharing solid volunteeredthan cheers [SEP]']
[Init] best perm rec loss: 0.8854588270187378 for ['[CLS] jack elevation back solid sharing cheers itself volunteeredthan [SEP]']
[Init] best perm rec loss: 0.8849825859069824 for ['[CLS] sharing jackthan cheers volunteered solid itself back elevation [SEP]']
[Init] best perm rec loss: 0.8849116563796997 for ['[CLS] back solid cheers jack elevation itselfthan volunteered sharing [SEP]']
[Init] best perm rec loss: 0.8840395212173462 for ['[CLS] itselfthan jack volunteered cheers solid sharing elevation back [SEP]']
[Init] best perm rec loss: 0.8835548162460327 for ['[CLS] solid cheers back elevation itself sharingthan jack volunteered [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.037 (perp=11.518, rec=0.737, cos=0.997), tot_loss_proj:4.156 [t=0.21s]
prediction: ['[CLS] tennis whenever lego pitch reality on movie. had [SEP]']
[ 100/2000] tot_loss=2.774 (perp=11.190, rec=0.416, cos=0.120), tot_loss_proj:4.159 [t=0.24s]
prediction: ['[CLS]¬ syndicatedkovsky pitch permanently over theater. having [SEP]']
[ 150/2000] tot_loss=2.682 (perp=10.730, rec=0.413, cos=0.123), tot_loss_proj:4.053 [t=0.21s]
prediction: ['[CLS] custompped animals clean carla bag concrete. while [SEP]']
[ 200/2000] tot_loss=2.641 (perp=11.219, rec=0.328, cos=0.069), tot_loss_proj:4.115 [t=0.29s]
prediction: ['[CLS] annpped animals clean carla carpet furniture. while [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.668 (perp=11.451, rec=0.315, cos=0.063), tot_loss_proj:4.088 [t=0.23s]
prediction: ['[CLS] auto furniture floor clean carla carpetpped. while [SEP]']
[ 300/2000] tot_loss=2.590 (perp=11.607, rec=0.240, cos=0.029), tot_loss_proj:4.169 [t=0.23s]
prediction: ['[CLS] mo furniture floor immediate carla ceilingpped. while [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.453 (perp=11.030, rec=0.224, cos=0.023), tot_loss_proj:4.098 [t=0.25s]
prediction: ['[CLS] ceiling floors floor immediate carla mopped. while [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.661 (perp=12.090, rec=0.223, cos=0.020), tot_loss_proj:4.293 [t=0.25s]
prediction: ['[CLS] carla floors floor narrow carla mopped ceiling while [SEP]']
[ 450/2000] tot_loss=2.341 (perp=10.332, rec=0.240, cos=0.035), tot_loss_proj:3.944 [t=0.27s]
prediction: ['[CLS] carla under floor behind carla mopped ceiling while [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.267 (perp=10.241, rec=0.203, cos=0.016), tot_loss_proj:3.900 [t=0.29s]
prediction: ['[CLS] carla under floor mo ceiling mopped carla while [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.091 (perp=9.468, rec=0.184, cos=0.014), tot_loss_proj:3.765 [t=0.24s]
prediction: ['[CLS] carla under floor mo under mopped carla. [SEP]']
[ 600/2000] tot_loss=2.346 (perp=10.711, rec=0.189, cos=0.015), tot_loss_proj:4.011 [t=0.24s]
prediction: ['[CLS]. under floor mo under mopped carla where [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.634 (perp=12.153, rec=0.187, cos=0.017), tot_loss_proj:4.275 [t=0.26s]
prediction: ['[CLS]ᵈ under floor mo under mopped carla carla [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.399 (perp=11.083, rec=0.167, cos=0.015), tot_loss_proj:4.094 [t=0.30s]
prediction: ['[CLS] carla under floor mo under mopped carlaᵈ [SEP]']
[ 750/2000] tot_loss=2.388 (perp=10.766, rec=0.198, cos=0.036), tot_loss_proj:4.041 [t=0.29s]
prediction: ['[CLS] carla under floor mo under mopped carla the [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.087 (perp=9.633, rec=0.149, cos=0.012), tot_loss_proj:3.779 [t=0.27s]
prediction: ['[CLS] carla furniture floor mo under the mopped carla [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.077 (perp=9.633, rec=0.141, cos=0.009), tot_loss_proj:3.784 [t=0.31s]
prediction: ['[CLS] carla furniture floor mo under the mopped carla [SEP]']
[ 900/2000] tot_loss=2.062 (perp=9.633, rec=0.127, cos=0.009), tot_loss_proj:3.782 [t=0.25s]
prediction: ['[CLS] carla furniture floor mo under the mopped carla [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.052 (perp=9.633, rec=0.117, cos=0.008), tot_loss_proj:3.776 [t=0.25s]
prediction: ['[CLS] carla furniture floor mo under the mopped carla [SEP]']
Attempt swap
[1000/2000] tot_loss=2.057 (perp=9.633, rec=0.123, cos=0.007), tot_loss_proj:3.782 [t=0.25s]
prediction: ['[CLS] carla furniture floor mo under the mopped carla [SEP]']
[1050/2000] tot_loss=2.046 (perp=9.633, rec=0.113, cos=0.007), tot_loss_proj:3.780 [t=0.29s]
prediction: ['[CLS] carla furniture floor mo under the mopped carla [SEP]']
Attempt swap
[1100/2000] tot_loss=2.044 (perp=9.633, rec=0.111, cos=0.007), tot_loss_proj:3.782 [t=0.22s]
prediction: ['[CLS] carla furniture floor mo under the mopped carla [SEP]']
Attempt swap
[1150/2000] tot_loss=2.050 (perp=9.633, rec=0.117, cos=0.006), tot_loss_proj:3.783 [t=0.27s]
prediction: ['[CLS] carla furniture floor mo under the mopped carla [SEP]']
[1200/2000] tot_loss=2.021 (perp=9.502, rec=0.114, cos=0.006), tot_loss_proj:3.707 [t=0.24s]
prediction: ['[CLS] carla furniture floor the under the mopped carla [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.131 (perp=9.948, rec=0.131, cos=0.011), tot_loss_proj:3.834 [t=0.29s]
prediction: ['[CLS] carla furniture floor under mo the mopped carla [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.009 (perp=9.416, rec=0.117, cos=0.008), tot_loss_proj:3.690 [t=0.28s]
prediction: ['[CLS] carla furniture floor under the mo mopped carla [SEP]']
[1350/2000] tot_loss=2.001 (perp=9.416, rec=0.110, cos=0.007), tot_loss_proj:3.690 [t=0.27s]
prediction: ['[CLS] carla furniture floor under the mo mopped carla [SEP]']
Attempt swap
[1400/2000] tot_loss=2.001 (perp=9.416, rec=0.111, cos=0.007), tot_loss_proj:3.693 [t=0.32s]
prediction: ['[CLS] carla furniture floor under the mo mopped carla [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.957 (perp=9.137, rec=0.121, cos=0.009), tot_loss_proj:3.710 [t=0.19s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
[1500/2000] tot_loss=1.952 (perp=9.137, rec=0.117, cos=0.007), tot_loss_proj:3.710 [t=0.21s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
Attempt swap
[1550/2000] tot_loss=1.951 (perp=9.137, rec=0.116, cos=0.007), tot_loss_proj:3.705 [t=0.22s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
Attempt swap
[1600/2000] tot_loss=1.947 (perp=9.137, rec=0.113, cos=0.007), tot_loss_proj:3.708 [t=0.21s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
[1650/2000] tot_loss=1.950 (perp=9.137, rec=0.116, cos=0.007), tot_loss_proj:3.711 [t=0.28s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
Attempt swap
[1700/2000] tot_loss=1.940 (perp=9.137, rec=0.106, cos=0.007), tot_loss_proj:3.711 [t=0.26s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
Attempt swap
[1750/2000] tot_loss=1.938 (perp=9.137, rec=0.104, cos=0.007), tot_loss_proj:3.708 [t=0.27s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
[1800/2000] tot_loss=1.942 (perp=9.137, rec=0.108, cos=0.007), tot_loss_proj:3.707 [t=0.29s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
Attempt swap
[1850/2000] tot_loss=1.950 (perp=9.137, rec=0.116, cos=0.007), tot_loss_proj:3.710 [t=0.21s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
Attempt swap
[1900/2000] tot_loss=1.940 (perp=9.137, rec=0.106, cos=0.007), tot_loss_proj:3.709 [t=0.27s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
[1950/2000] tot_loss=1.946 (perp=9.137, rec=0.112, cos=0.007), tot_loss_proj:3.705 [t=0.28s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
Attempt swap
[2000/2000] tot_loss=1.944 (perp=9.137, rec=0.110, cos=0.006), tot_loss_proj:3.710 [t=0.24s]
prediction: ['[CLS] carla furniture mo mopped floor under the carla [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] carla mopped the floor under the furniture. [SEP]
========================
predicted: 
========================
[CLS] carla furniture mo mopped floor under the carla [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 35.294 | p: 33.333 | r: 37.500
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 119.505

[Aggregate metrics]:
rouge1     | fm: 75.639 | p: 75.960 | r: 75.606
rouge2     | fm: 35.856 | p: 35.795 | r: 35.998
rougeL     | fm: 65.284 | p: 65.652 | r: 65.188
rougeLsum  | fm: 65.490 | p: 65.828 | r: 65.374
r1fm+r2fm = 111.495

input #57 time: 0:10:14 | total time: 8:04:41


Running input #58 of 100.
reference: 
========================
They expected us to should leave him.
========================
average of cosine similarity 0.9993178527703294
highest_index [0]
highest [0.9993178527703294]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2027, 3517, 2149, 2000, 2323, 2681, 2032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] they expected us to should leave him. [SEP]']
[Init] best rec loss: 1.01006019115448 for ['[CLS] like cal hazard far indiangence pair rolled [SEP]']
[Init] best rec loss: 0.9678995013237 for ['[CLS] suit agent special small crack still try cases [SEP]']
[Init] best rec loss: 0.7499859929084778 for ['[CLS] michellevable moved lottery fold °f ask collectively [SEP]']
[Init] best rec loss: 0.7345256805419922 for ['[CLS] fore primary pcs publishing source pu ra germany [SEP]']
[Init] best rec loss: 0.7178595662117004 for ['[CLS] cartoon bastionional pulitzer implant camp assistance away [SEP]']
[Init] best rec loss: 0.7141168117523193 for ['[CLS] satellite cum deserves specialized saw shoteral town [SEP]']
[Init] best perm rec loss: 0.7126652598381042 for ['[CLS] deserves shot town saw specialized satellite cumeral [SEP]']
[Init] best perm rec loss: 0.7116402387619019 for ['[CLS] cum town satellite deserves shot saweral specialized [SEP]']
[Init] best perm rec loss: 0.7094566226005554 for ['[CLS] shot cum deserves saweral town specialized satellite [SEP]']
[Init] best perm rec loss: 0.7093368172645569 for ['[CLS] specialized saw satellite cum shot town deserveseral [SEP]']
[Init] best perm rec loss: 0.7073099613189697 for ['[CLS] satellite shot deserves specialized cumeral town saw [SEP]']
[Init] best perm rec loss: 0.7069427371025085 for ['[CLS] deserves satellite town shot cumeral specialized saw [SEP]']
[Init] best perm rec loss: 0.7052599787712097 for ['[CLS] cum deserves shot towneral specialized satellite saw [SEP]']
[Init] best perm rec loss: 0.70352703332901 for ['[CLS] cum shot town satellite deserves saw specializederal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.542 (perp=10.604, rec=0.357, cos=0.065), tot_loss_proj:3.462 [t=0.21s]
prediction: ['[CLS] rep shouldons pressure should shouldked. [SEP]']
[ 100/2000] tot_loss=1.627 (perp=6.501, rec=0.283, cos=0.044), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] ours should or should should should leave. [SEP]']
[ 150/2000] tot_loss=1.494 (perp=6.326, rec=0.204, cos=0.025), tot_loss_proj:1.928 [t=0.22s]
prediction: ['[CLS] we expected they would should should leave. [SEP]']
[ 200/2000] tot_loss=1.926 (perp=7.422, rec=0.281, cos=0.161), tot_loss_proj:2.287 [t=0.26s]
prediction: ['[CLS] us expected they to should should leave. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.394 (perp=6.218, rec=0.133, cos=0.017), tot_loss_proj:1.701 [t=0.30s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[ 300/2000] tot_loss=1.375 (perp=6.218, rec=0.115, cos=0.016), tot_loss_proj:1.679 [t=0.23s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.351 (perp=6.218, rec=0.092, cos=0.016), tot_loss_proj:1.687 [t=0.25s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.361 (perp=6.218, rec=0.103, cos=0.014), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[ 450/2000] tot_loss=1.368 (perp=6.218, rec=0.110, cos=0.015), tot_loss_proj:1.677 [t=0.27s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.357 (perp=6.218, rec=0.100, cos=0.014), tot_loss_proj:1.679 [t=0.21s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.346 (perp=6.218, rec=0.089, cos=0.013), tot_loss_proj:1.672 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[ 600/2000] tot_loss=1.402 (perp=6.218, rec=0.135, cos=0.023), tot_loss_proj:1.681 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.348 (perp=6.218, rec=0.091, cos=0.013), tot_loss_proj:1.674 [t=0.20s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.351 (perp=6.218, rec=0.094, cos=0.013), tot_loss_proj:1.673 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[ 750/2000] tot_loss=1.336 (perp=6.218, rec=0.080, cos=0.012), tot_loss_proj:1.676 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.347 (perp=6.218, rec=0.091, cos=0.012), tot_loss_proj:1.676 [t=0.20s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.346 (perp=6.218, rec=0.090, cos=0.012), tot_loss_proj:1.684 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[ 900/2000] tot_loss=1.343 (perp=6.218, rec=0.087, cos=0.012), tot_loss_proj:1.667 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.344 (perp=6.218, rec=0.088, cos=0.012), tot_loss_proj:1.669 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.337 (perp=6.218, rec=0.081, cos=0.012), tot_loss_proj:1.673 [t=0.17s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[1050/2000] tot_loss=1.334 (perp=6.218, rec=0.079, cos=0.012), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.336 (perp=6.218, rec=0.081, cos=0.011), tot_loss_proj:1.675 [t=0.25s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.338 (perp=6.218, rec=0.083, cos=0.011), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[1200/2000] tot_loss=1.334 (perp=6.218, rec=0.079, cos=0.011), tot_loss_proj:1.678 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.338 (perp=6.218, rec=0.083, cos=0.011), tot_loss_proj:1.674 [t=0.21s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.340 (perp=6.218, rec=0.085, cos=0.011), tot_loss_proj:1.673 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[1350/2000] tot_loss=1.330 (perp=6.218, rec=0.075, cos=0.011), tot_loss_proj:1.669 [t=0.20s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.338 (perp=6.218, rec=0.084, cos=0.011), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.336 (perp=6.218, rec=0.082, cos=0.011), tot_loss_proj:1.665 [t=0.17s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[1500/2000] tot_loss=1.332 (perp=6.218, rec=0.077, cos=0.011), tot_loss_proj:1.675 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.339 (perp=6.218, rec=0.084, cos=0.011), tot_loss_proj:1.668 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.340 (perp=6.218, rec=0.086, cos=0.011), tot_loss_proj:1.674 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[1650/2000] tot_loss=1.350 (perp=6.218, rec=0.095, cos=0.011), tot_loss_proj:1.668 [t=0.20s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.335 (perp=6.218, rec=0.080, cos=0.011), tot_loss_proj:1.676 [t=0.25s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.335 (perp=6.218, rec=0.081, cos=0.011), tot_loss_proj:1.667 [t=0.18s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[1800/2000] tot_loss=1.336 (perp=6.218, rec=0.081, cos=0.011), tot_loss_proj:1.670 [t=0.26s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.338 (perp=6.218, rec=0.084, cos=0.011), tot_loss_proj:1.674 [t=0.24s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.341 (perp=6.218, rec=0.087, cos=0.011), tot_loss_proj:1.665 [t=0.17s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
[1950/2000] tot_loss=1.337 (perp=6.218, rec=0.083, cos=0.011), tot_loss_proj:1.670 [t=0.22s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.337 (perp=6.218, rec=0.083, cos=0.011), tot_loss_proj:1.667 [t=0.20s]
prediction: ['[CLS] they expected us to should should leave. [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] they expected us to should leave him. [SEP]
========================
predicted: 
========================
[CLS] they expected us to should should leave. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 163.889

[Aggregate metrics]:
rouge1     | fm: 75.876 | p: 76.167 | r: 75.830
rouge2     | fm: 36.475 | p: 36.481 | r: 36.556
rougeL     | fm: 65.734 | p: 66.003 | r: 65.635
rougeLsum  | fm: 65.836 | p: 66.155 | r: 65.728
r1fm+r2fm = 112.351

input #58 time: 0:08:34 | total time: 8:13:15


Running input #59 of 100.
reference: 
========================
Mr Woodhouse sat in an armchair.
========================
average of cosine similarity 0.999401123526773
highest_index [0]
highest [0.999401123526773]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2720,  3536,  4580,  2938,  1999,  2019, 29372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[Init] best rec loss: 1.0133568048477173 for ['[CLS] zero treasurer kennedy vet when le bronze plans [SEP]']
[Init] best rec loss: 0.9783481359481812 for ['[CLS] greenbis wa ant chamber disks distinguishednine [SEP]']
[Init] best rec loss: 0.9641304016113281 for ['[CLS] geraldine draft side everythingion lack hamlet react [SEP]']
[Init] best rec loss: 0.9588362574577332 for ['[CLS] poll citizen heads chapter nor giants alec cinder [SEP]']
[Init] best rec loss: 0.9540868997573853 for ['[CLS] survivors tend bounce visitors guessed nomination miles independence [SEP]']
[Init] best rec loss: 0.9535396099090576 for ['[CLS] jaw sega indians no dug columbia tribe throughout [SEP]']
[Init] best perm rec loss: 0.9530171751976013 for ['[CLS] tribe throughout jaw sega dug columbia indians no [SEP]']
[Init] best perm rec loss: 0.9528425931930542 for ['[CLS] jaw tribe throughout sega columbia indians no dug [SEP]']
[Init] best perm rec loss: 0.9518237709999084 for ['[CLS] dug indians sega jaw columbia throughout tribe no [SEP]']
[Init] best perm rec loss: 0.9487836956977844 for ['[CLS] sega indians tribe dug jaw columbia no throughout [SEP]']
[Init] best perm rec loss: 0.9484539031982422 for ['[CLS] jaw dug throughout indians columbia no tribe sega [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.142 (perp=13.273, rec=0.395, cos=0.093), tot_loss_proj:4.463 [t=0.17s]
prediction: ['[CLS] evening wanted chairmanhouse gordon wrestling would pri [SEP]']
[ 100/2000] tot_loss=2.737 (perp=12.150, rec=0.274, cos=0.033), tot_loss_proj:4.332 [t=0.23s]
prediction: ['[CLS] mr looking chair sat wilson mr stable pri [SEP]']
[ 150/2000] tot_loss=2.425 (perp=11.205, rec=0.172, cos=0.012), tot_loss_proj:4.101 [t=0.25s]
prediction: ['[CLS] mr wood armchair sathouse mr present pri [SEP]']
[ 200/2000] tot_loss=2.517 (perp=11.789, rec=0.150, cos=0.009), tot_loss_proj:4.354 [t=0.19s]
prediction: ['[CLS] mr wood armchair sathouse armchair canoe pri [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.140 (perp=9.354, rec=0.233, cos=0.036), tot_loss_proj:3.706 [t=0.19s]
prediction: ['[CLS] mr wood armchair sat a chairhouse brought [SEP]']
[ 300/2000] tot_loss=1.747 (perp=7.929, rec=0.150, cos=0.011), tot_loss_proj:3.441 [t=0.23s]
prediction: ['[CLS] mr wood armchair sat a chairhouse. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.978 (perp=8.887, rec=0.180, cos=0.020), tot_loss_proj:3.635 [t=0.23s]
prediction: ['[CLS] mr woodhouse armchair sat the chairt [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.586 (perp=7.213, rec=0.133, cos=0.010), tot_loss_proj:3.314 [t=0.18s]
prediction: ['[CLS] mr woodhouse armchair sat a chair. [SEP]']
[ 450/2000] tot_loss=1.575 (perp=7.213, rec=0.124, cos=0.008), tot_loss_proj:3.310 [t=0.18s]
prediction: ['[CLS] mr woodhouse armchair sat a chair. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.557 (perp=7.213, rec=0.107, cos=0.007), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] mr woodhouse armchair sat a chair. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.592 (perp=7.374, rec=0.111, cos=0.007), tot_loss_proj:3.288 [t=0.18s]
prediction: ['[CLS] mr woodhouse armchair sat a table. [SEP]']
[ 600/2000] tot_loss=1.701 (perp=7.950, rec=0.105, cos=0.006), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] mr woodhouse armchair sat a table in [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.728 (perp=8.075, rec=0.106, cos=0.006), tot_loss_proj:3.597 [t=0.17s]
prediction: ['[CLS] mr woodhouse armchair sat in an table [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.512 (perp=6.923, rec=0.119, cos=0.008), tot_loss_proj:3.276 [t=0.26s]
prediction: ['[CLS] mr woodhouse table sat in an armchair [SEP]']
[ 750/2000] tot_loss=1.460 (perp=6.774, rec=0.099, cos=0.006), tot_loss_proj:3.347 [t=0.18s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.453 (perp=6.774, rec=0.092, cos=0.006), tot_loss_proj:3.343 [t=0.18s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.453 (perp=6.774, rec=0.093, cos=0.006), tot_loss_proj:3.348 [t=0.17s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
[ 900/2000] tot_loss=1.449 (perp=6.774, rec=0.088, cos=0.006), tot_loss_proj:3.347 [t=0.18s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.455 (perp=6.774, rec=0.095, cos=0.006), tot_loss_proj:3.344 [t=0.25s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[1000/2000] tot_loss=1.462 (perp=6.774, rec=0.101, cos=0.006), tot_loss_proj:3.348 [t=0.17s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
[1050/2000] tot_loss=1.455 (perp=6.774, rec=0.094, cos=0.006), tot_loss_proj:3.349 [t=0.23s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[1100/2000] tot_loss=1.451 (perp=6.774, rec=0.091, cos=0.006), tot_loss_proj:3.348 [t=0.20s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[1150/2000] tot_loss=1.450 (perp=6.774, rec=0.089, cos=0.006), tot_loss_proj:3.346 [t=0.19s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
[1200/2000] tot_loss=1.448 (perp=6.774, rec=0.087, cos=0.006), tot_loss_proj:3.339 [t=0.19s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[1250/2000] tot_loss=1.447 (perp=6.774, rec=0.086, cos=0.006), tot_loss_proj:3.342 [t=0.18s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[1300/2000] tot_loss=1.442 (perp=6.774, rec=0.082, cos=0.006), tot_loss_proj:3.345 [t=0.17s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
[1350/2000] tot_loss=1.461 (perp=6.774, rec=0.101, cos=0.006), tot_loss_proj:3.351 [t=0.18s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[1400/2000] tot_loss=1.443 (perp=6.774, rec=0.083, cos=0.006), tot_loss_proj:3.344 [t=0.18s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[1450/2000] tot_loss=1.451 (perp=6.774, rec=0.091, cos=0.006), tot_loss_proj:3.346 [t=0.18s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
[1500/2000] tot_loss=1.449 (perp=6.774, rec=0.089, cos=0.006), tot_loss_proj:3.349 [t=0.19s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[1550/2000] tot_loss=1.447 (perp=6.774, rec=0.086, cos=0.006), tot_loss_proj:3.349 [t=0.27s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[1600/2000] tot_loss=1.441 (perp=6.774, rec=0.080, cos=0.006), tot_loss_proj:3.347 [t=0.18s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
[1650/2000] tot_loss=1.446 (perp=6.774, rec=0.086, cos=0.006), tot_loss_proj:3.348 [t=0.18s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
[1700/2000] tot_loss=1.446 (perp=6.774, rec=0.085, cos=0.006), tot_loss_proj:3.346 [t=0.18s]
prediction: ['[CLS] mr woodhouse chair sat in an armchair [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.382 (perp=6.344, rec=0.103, cos=0.010), tot_loss_proj:2.190 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair chair [SEP]']
[1800/2000] tot_loss=1.357 (perp=6.344, rec=0.081, cos=0.008), tot_loss_proj:2.190 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair chair [SEP]']
Attempt swap
[1850/2000] tot_loss=1.365 (perp=6.344, rec=0.089, cos=0.007), tot_loss_proj:2.194 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair chair [SEP]']
Attempt swap
[1900/2000] tot_loss=1.370 (perp=6.344, rec=0.094, cos=0.007), tot_loss_proj:2.186 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair chair [SEP]']
[1950/2000] tot_loss=1.365 (perp=6.344, rec=0.089, cos=0.007), tot_loss_proj:2.189 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair chair [SEP]']
Attempt swap
[2000/2000] tot_loss=1.372 (perp=6.344, rec=0.096, cos=0.007), tot_loss_proj:2.187 [t=0.23s]
prediction: ['[CLS] mr woodhouse sat in an armchair chair [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] mr woodhouse sat in an armchair. [SEP]
========================
predicted: 
========================
[CLS] mr woodhouse chair sat in an armchair [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 80.000 | p: 75.000 | r: 85.714
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 174.118

[Aggregate metrics]:
rouge1     | fm: 76.092 | p: 76.347 | r: 76.193
rouge2     | fm: 37.139 | p: 37.060 | r: 37.372
rougeL     | fm: 66.147 | p: 66.427 | r: 66.109
rougeLsum  | fm: 66.306 | p: 66.565 | r: 66.282
r1fm+r2fm = 113.231

input #59 time: 0:08:05 | total time: 8:21:21


Running input #60 of 100.
reference: 
========================
It is likely that Jean left.
========================
average of cosine similarity 0.9994653435805758
highest_index [0]
highest [0.9994653435805758]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2009, 2003, 3497, 2008, 3744, 2187, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] it is likely that jean left. [SEP]']
[Init] best rec loss: 1.0610324144363403 for ['[CLS]ach called vision sea age include wren [SEP]']
[Init] best rec loss: 0.9535291790962219 for ['[CLS] blue returnedisen within zur immediateores [SEP]']
[Init] best rec loss: 0.9524242281913757 for ['[CLS] threw presley dependent state safetyending hood [SEP]']
[Init] best rec loss: 0.9489620923995972 for ['[CLS] hazardous least thumbs politically play w contrast [SEP]']
[Init] best rec loss: 0.9254016876220703 for ['[CLS] knight cass labor force cap inspiration time [SEP]']
[Init] best perm rec loss: 0.9237791299819946 for ['[CLS] time cap labor inspiration knight cass force [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.853 (perp=11.110, rec=0.705, cos=0.926), tot_loss_proj:3.951 [t=0.18s]
prediction: ['[CLS] busy nail : celebrity formed continued them [SEP]']
[ 100/2000] tot_loss=4.473 (perp=13.931, rec=0.687, cos=1.000), tot_loss_proj:4.520 [t=0.19s]
prediction: ['[CLS] lightning gossip eitherᵗ clothing incident coming [SEP]']
[ 150/2000] tot_loss=3.150 (perp=12.343, rec=0.461, cos=0.221), tot_loss_proj:4.173 [t=0.18s]
prediction: ['[CLS] ago toss itaken temeraire perhaps coming [SEP]']
[ 200/2000] tot_loss=2.542 (perp=11.239, rec=0.269, cos=0.026), tot_loss_proj:3.924 [t=0.17s]
prediction: ['[CLS] jean toss left what nintendo left likely [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.342 (perp=10.595, rec=0.210, cos=0.013), tot_loss_proj:3.985 [t=0.30s]
prediction: ['[CLS] jean likely left what likely about left [SEP]']
[ 300/2000] tot_loss=2.449 (perp=11.364, rec=0.168, cos=0.009), tot_loss_proj:4.017 [t=0.25s]
prediction: ['[CLS] jean likely i that likely consulate left [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.774 (perp=7.994, rec=0.167, cos=0.008), tot_loss_proj:3.303 [t=0.24s]
prediction: ['[CLS] jean likely that that it likely left [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.748 (perp=7.994, rec=0.142, cos=0.007), tot_loss_proj:3.308 [t=0.18s]
prediction: ['[CLS] jean likely that that it likely left [SEP]']
[ 450/2000] tot_loss=1.736 (perp=7.994, rec=0.130, cos=0.007), tot_loss_proj:3.306 [t=0.18s]
prediction: ['[CLS] jean likely that that it likely left [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.794 (perp=8.280, rec=0.132, cos=0.006), tot_loss_proj:3.433 [t=0.22s]
prediction: ['[CLS] jean likely is that it likely left [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.712 (perp=7.872, rec=0.131, cos=0.007), tot_loss_proj:3.306 [t=0.18s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
[ 600/2000] tot_loss=1.693 (perp=7.872, rec=0.113, cos=0.006), tot_loss_proj:3.304 [t=0.18s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.706 (perp=7.872, rec=0.125, cos=0.006), tot_loss_proj:3.299 [t=0.23s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.701 (perp=7.872, rec=0.121, cos=0.005), tot_loss_proj:3.303 [t=0.19s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
[ 750/2000] tot_loss=1.695 (perp=7.872, rec=0.116, cos=0.005), tot_loss_proj:3.303 [t=0.23s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.682 (perp=7.872, rec=0.102, cos=0.005), tot_loss_proj:3.302 [t=0.17s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.679 (perp=7.872, rec=0.099, cos=0.005), tot_loss_proj:3.306 [t=0.18s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
[ 900/2000] tot_loss=1.681 (perp=7.872, rec=0.101, cos=0.005), tot_loss_proj:3.305 [t=0.18s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.675 (perp=7.872, rec=0.095, cos=0.005), tot_loss_proj:3.302 [t=0.19s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
Attempt swap
[1000/2000] tot_loss=1.685 (perp=7.872, rec=0.105, cos=0.005), tot_loss_proj:3.299 [t=0.18s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
[1050/2000] tot_loss=1.673 (perp=7.872, rec=0.093, cos=0.005), tot_loss_proj:3.298 [t=0.18s]
prediction: ['[CLS] jean likely likely that it is left [SEP]']
Attempt swap
[1100/2000] tot_loss=1.783 (perp=8.422, rec=0.094, cos=0.005), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1150/2000] tot_loss=1.778 (perp=8.422, rec=0.089, cos=0.005), tot_loss_proj:3.467 [t=0.18s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
[1200/2000] tot_loss=1.792 (perp=8.422, rec=0.103, cos=0.005), tot_loss_proj:3.475 [t=0.18s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1250/2000] tot_loss=1.778 (perp=8.422, rec=0.088, cos=0.005), tot_loss_proj:3.468 [t=0.18s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1300/2000] tot_loss=1.779 (perp=8.422, rec=0.090, cos=0.005), tot_loss_proj:3.472 [t=0.18s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
[1350/2000] tot_loss=1.776 (perp=8.422, rec=0.087, cos=0.005), tot_loss_proj:3.473 [t=0.18s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1400/2000] tot_loss=1.776 (perp=8.422, rec=0.087, cos=0.005), tot_loss_proj:3.473 [t=0.18s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1450/2000] tot_loss=1.781 (perp=8.422, rec=0.091, cos=0.005), tot_loss_proj:3.474 [t=0.23s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
[1500/2000] tot_loss=1.778 (perp=8.422, rec=0.089, cos=0.005), tot_loss_proj:3.472 [t=0.24s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1550/2000] tot_loss=1.773 (perp=8.422, rec=0.084, cos=0.005), tot_loss_proj:3.468 [t=0.34s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1600/2000] tot_loss=1.782 (perp=8.422, rec=0.093, cos=0.005), tot_loss_proj:3.470 [t=0.28s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
[1650/2000] tot_loss=1.778 (perp=8.422, rec=0.089, cos=0.005), tot_loss_proj:3.475 [t=0.21s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1700/2000] tot_loss=1.782 (perp=8.422, rec=0.092, cos=0.005), tot_loss_proj:3.469 [t=0.18s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1750/2000] tot_loss=1.789 (perp=8.422, rec=0.100, cos=0.005), tot_loss_proj:3.471 [t=0.18s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
[1800/2000] tot_loss=1.779 (perp=8.422, rec=0.090, cos=0.005), tot_loss_proj:3.474 [t=0.21s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1850/2000] tot_loss=1.781 (perp=8.422, rec=0.092, cos=0.005), tot_loss_proj:3.474 [t=0.18s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[1900/2000] tot_loss=1.780 (perp=8.422, rec=0.090, cos=0.005), tot_loss_proj:3.471 [t=0.24s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
[1950/2000] tot_loss=1.792 (perp=8.422, rec=0.103, cos=0.005), tot_loss_proj:3.474 [t=0.19s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Attempt swap
[2000/2000] tot_loss=1.779 (perp=8.422, rec=0.090, cos=0.005), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] jean it likely that it is left [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] it is likely that jean left. [SEP]
========================
predicted: 
========================
[CLS] jean it likely that it is left [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 40.000 | p: 37.500 | r: 42.857
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 134.118

[Aggregate metrics]:
rouge1     | fm: 76.357 | p: 76.473 | r: 76.478
rouge2     | fm: 37.122 | p: 36.946 | r: 37.385
rougeL     | fm: 66.182 | p: 66.424 | r: 66.238
rougeLsum  | fm: 66.233 | p: 66.439 | r: 66.311
r1fm+r2fm = 113.479

input #60 time: 0:08:21 | total time: 8:29:42


Running input #61 of 100.
reference: 
========================
Physicists like yourself are a godsend.
========================
average of cosine similarity 0.9993168200569029
highest_index [0]
highest [0.9993168200569029]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 13702,  2015,  2066,  4426,  2024,  1037,  5932, 10497,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] physicists like yourself are a godsend. [SEP]']
[Init] best rec loss: 0.9368430376052856 for ['[CLS]serromatic rescue object morning which viable for seeking [SEP]']
[Init] best rec loss: 0.9271156191825867 for ['[CLS] realmsᵇ group mac en whoever " administrator canvas [SEP]']
[Init] best rec loss: 0.9082102179527283 for ['[CLS] bombardment symptoms ul memorial were worked gray haiti know [SEP]']
[Init] best rec loss: 0.9022470712661743 for ['[CLS] fixed commissioner manual church off stem pickup lips austin [SEP]']
[Init] best rec loss: 0.8885534405708313 for ['[CLS] first parental bill julius orthodox thank orson what knock [SEP]']
[Init] best perm rec loss: 0.8879454731941223 for ['[CLS] orson knock first thank julius bill parental what orthodox [SEP]']
[Init] best perm rec loss: 0.8876521587371826 for ['[CLS] parental what julius knock bill orthodox first thank orson [SEP]']
[Init] best perm rec loss: 0.8857608437538147 for ['[CLS] knock bill thank parental julius orthodox orson first what [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.878 (perp=11.820, rec=0.589, cos=0.925), tot_loss_proj:4.231 [t=0.20s]
prediction: ['[CLS] admit. foods of lexieap railroad myself kept [SEP]']
[ 100/2000] tot_loss=3.859 (perp=12.410, rec=0.466, cos=0.911), tot_loss_proj:4.374 [t=0.19s]
prediction: ['[CLS] wnba. are like postagelde cheered yourself everyone [SEP]']
[ 150/2000] tot_loss=3.590 (perp=12.039, rec=0.383, cos=0.798), tot_loss_proj:4.336 [t=0.17s]
prediction: ['[CLS] physicist. physicist like postageן say yourself everyone [SEP]']
[ 200/2000] tot_loss=4.076 (perp=12.070, rec=0.678, cos=0.984), tot_loss_proj:4.300 [t=0.17s]
prediction: ['[CLS] ajax rapids groups like distinction myself [SEP] yourself crap [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.192 (perp=8.508, rec=0.518, cos=0.972), tot_loss_proj:3.529 [t=0.18s]
prediction: ['[CLS] physicist.s like myself are yourself yourself evie [SEP]']
[ 300/2000] tot_loss=3.257 (perp=9.178, rec=0.447, cos=0.974), tot_loss_proj:3.713 [t=0.18s]
prediction: ['[CLS] physicist.s like yourself are are yourself evie [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.821 (perp=7.133, rec=0.419, cos=0.975), tot_loss_proj:3.361 [t=0.18s]
prediction: ['[CLS] physicists like yourself were are yourself else. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.958 (perp=7.884, rec=0.403, cos=0.978), tot_loss_proj:3.543 [t=0.18s]
prediction: ['[CLS] physicists like yourself are prize evie yourself. [SEP]']
[ 450/2000] tot_loss=2.932 (perp=7.884, rec=0.372, cos=0.983), tot_loss_proj:3.540 [t=0.18s]
prediction: ['[CLS] physicists like yourself are prize evie yourself. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.842 (perp=7.482, rec=0.359, cos=0.986), tot_loss_proj:3.413 [t=0.21s]
prediction: ['[CLS] physicists like apartheids are prize yourself. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.119 (perp=8.931, rec=0.345, cos=0.987), tot_loss_proj:3.684 [t=0.18s]
prediction: ['[CLS] physicists like untos are prize yourself. [SEP]']
[ 600/2000] tot_loss=2.937 (perp=8.065, rec=0.336, cos=0.988), tot_loss_proj:3.523 [t=0.17s]
prediction: ['[CLS] physicists like mindss are prize yourself. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.871 (perp=7.758, rec=0.331, cos=0.988), tot_loss_proj:3.417 [t=0.18s]
prediction: ['[CLS] physicists likes minds are prize yourself. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.865 (perp=7.758, rec=0.325, cos=0.989), tot_loss_proj:3.418 [t=0.25s]
prediction: ['[CLS] physicists likes minds are prize yourself. [SEP]']
[ 750/2000] tot_loss=2.788 (perp=7.413, rec=0.316, cos=0.989), tot_loss_proj:3.376 [t=0.21s]
prediction: ['[CLS] physicists likes minds are when yourself. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.831 (perp=7.528, rec=0.335, cos=0.990), tot_loss_proj:3.364 [t=0.26s]
prediction: ['[CLS] physicists likes are unto what yourself. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.702 (perp=6.956, rec=0.320, cos=0.991), tot_loss_proj:3.287 [t=0.21s]
prediction: ['[CLS] physicists likes are minds what yourself. [SEP]']
[ 900/2000] tot_loss=2.701 (perp=6.956, rec=0.318, cos=0.991), tot_loss_proj:3.289 [t=0.18s]
prediction: ['[CLS] physicists likes are minds what yourself. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.702 (perp=6.956, rec=0.319, cos=0.992), tot_loss_proj:3.290 [t=0.18s]
prediction: ['[CLS] physicists likes are minds what yourself. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.696 (perp=6.956, rec=0.312, cos=0.992), tot_loss_proj:3.287 [t=0.17s]
prediction: ['[CLS] physicists likes are minds what yourself. [SEP]']
[1050/2000] tot_loss=2.694 (perp=6.956, rec=0.310, cos=0.993), tot_loss_proj:3.285 [t=0.18s]
prediction: ['[CLS] physicists likes are minds what yourself. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.864 (perp=7.857, rec=0.299, cos=0.993), tot_loss_proj:3.463 [t=0.21s]
prediction: ['[CLS] physicist gods likes are minds when yourself. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.659 (perp=6.720, rec=0.323, cos=0.992), tot_loss_proj:3.259 [t=0.21s]
prediction: ['[CLS] physicists like gods are minds when yourself. [SEP]']
[1200/2000] tot_loss=2.641 (perp=6.720, rec=0.303, cos=0.994), tot_loss_proj:3.260 [t=0.25s]
prediction: ['[CLS] physicists like gods are minds when yourself. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.760 (perp=7.262, rec=0.313, cos=0.994), tot_loss_proj:3.360 [t=0.25s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.746 (perp=7.262, rec=0.299, cos=0.995), tot_loss_proj:3.369 [t=0.18s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
[1350/2000] tot_loss=2.752 (perp=7.262, rec=0.305, cos=0.995), tot_loss_proj:3.359 [t=0.18s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.747 (perp=7.262, rec=0.299, cos=0.995), tot_loss_proj:3.364 [t=0.18s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.751 (perp=7.262, rec=0.304, cos=0.995), tot_loss_proj:3.365 [t=0.23s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
[1500/2000] tot_loss=2.747 (perp=7.262, rec=0.299, cos=0.996), tot_loss_proj:3.359 [t=0.27s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.746 (perp=7.262, rec=0.298, cos=0.996), tot_loss_proj:3.358 [t=0.22s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.749 (perp=7.262, rec=0.301, cos=0.996), tot_loss_proj:3.368 [t=0.18s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
[1650/2000] tot_loss=2.744 (perp=7.262, rec=0.296, cos=0.996), tot_loss_proj:3.364 [t=0.18s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.742 (perp=7.262, rec=0.294, cos=0.996), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.748 (perp=7.262, rec=0.300, cos=0.996), tot_loss_proj:3.357 [t=0.21s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
[1800/2000] tot_loss=2.746 (perp=7.262, rec=0.298, cos=0.996), tot_loss_proj:3.366 [t=0.18s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.746 (perp=7.262, rec=0.297, cos=0.996), tot_loss_proj:3.360 [t=0.18s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.748 (perp=7.262, rec=0.299, cos=0.996), tot_loss_proj:3.367 [t=0.27s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
[1950/2000] tot_loss=2.742 (perp=7.262, rec=0.293, cos=0.996), tot_loss_proj:3.363 [t=0.26s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.753 (perp=7.262, rec=0.305, cos=0.996), tot_loss_proj:3.362 [t=0.22s]
prediction: ['[CLS] physicists like gods are quite when yourself. [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS] physicists like yourself are a godsend. [SEP]
========================
predicted: 
========================
[CLS] physicists like gods are quite when yourself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 66.667 | r: 75.000
rouge2     | fm: 26.667 | p: 25.000 | r: 28.571
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 97.255

[Aggregate metrics]:
rouge1     | fm: 76.326 | p: 76.322 | r: 76.578
rouge2     | fm: 37.075 | p: 36.920 | r: 37.389
rougeL     | fm: 66.076 | p: 66.197 | r: 66.252
rougeLsum  | fm: 66.254 | p: 66.316 | r: 66.399
r1fm+r2fm = 113.401

input #61 time: 0:08:09 | total time: 8:37:52


Running input #62 of 100.
reference: 
========================
Any pilot could be flying this plane.
========================
average of cosine similarity 0.9994980007326448
highest_index [0]
highest [0.9994980007326448]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2151, 4405, 2071, 2022, 3909, 2023, 4946, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] any pilot could be flying this plane. [SEP]']
[Init] best rec loss: 0.9977968335151672 for ['[CLS] events heat names cole issue. 505 regina [SEP]']
[Init] best rec loss: 0.9175378084182739 for ['[CLS] from actress le testament sooner pit confederacy oct [SEP]']
[Init] best rec loss: 0.8922759890556335 for ['[CLS]liest into holding complained discovery sutherland coast fork [SEP]']
[Init] best rec loss: 0.8342140913009644 for ['[CLS] reader leagues english our place guestfire mad [SEP]']
[Init] best perm rec loss: 0.8291640281677246 for ['[CLS] mad place englishfire our guest leagues reader [SEP]']
[Init] best perm rec loss: 0.8275080919265747 for ['[CLS] guest reader english place mad leagues ourfire [SEP]']
[Init] best perm rec loss: 0.824095606803894 for ['[CLS]fire guest english leagues mad our reader place [SEP]']
[Init] best perm rec loss: 0.823464035987854 for ['[CLS] mad guestfire leagues reader our english place [SEP]']
[Init] best perm rec loss: 0.8207629323005676 for ['[CLS] our readerfire mad guest leagues place english [SEP]']
[Init] best perm rec loss: 0.8206089735031128 for ['[CLS]fire guest mad our reader leagues place english [SEP]']
[Init] best perm rec loss: 0.8204890489578247 for ['[CLS] reader guest english leaguesfire our place mad [SEP]']
[Init] best perm rec loss: 0.8204536437988281 for ['[CLS] reader leagues english guest our place madfire [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.853 (perp=10.613, rec=0.496, cos=0.234), tot_loss_proj:4.011 [t=0.17s]
prediction: ['[CLS] belle football magic rock our teen teen boy [SEP]']
[ 100/2000] tot_loss=2.203 (perp=8.263, rec=0.406, cos=0.144), tot_loss_proj:3.648 [t=0.24s]
prediction: ['[CLS] this mentioned magic rock term love teen. [SEP]']
[ 150/2000] tot_loss=2.303 (perp=9.331, rec=0.338, cos=0.099), tot_loss_proj:3.628 [t=0.25s]
prediction: ['[CLS] this football pilot kiss term fantastic drag. [SEP]']
[ 200/2000] tot_loss=2.245 (perp=9.496, rec=0.292, cos=0.054), tot_loss_proj:3.865 [t=0.18s]
prediction: ['[CLS] this every pilotflight could baby same. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.147 (perp=9.209, rec=0.263, cos=0.042), tot_loss_proj:3.849 [t=0.18s]
prediction: ['[CLS] this every pilotflight baby could same. [SEP]']
[ 300/2000] tot_loss=2.180 (perp=9.475, rec=0.248, cos=0.036), tot_loss_proj:3.926 [t=0.17s]
prediction: ['[CLS] any any pilotflight baby could each. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.880 (perp=8.099, rec=0.228, cos=0.032), tot_loss_proj:3.445 [t=0.18s]
prediction: ['[CLS] this any pilot baby could each want. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.850 (perp=8.039, rec=0.214, cos=0.028), tot_loss_proj:3.537 [t=0.21s]
prediction: ['[CLS] this any pilot jesus could want each. [SEP]']
[ 450/2000] tot_loss=1.887 (perp=8.338, rec=0.194, cos=0.025), tot_loss_proj:3.619 [t=0.21s]
prediction: ['[CLS] this any pilot jesus could flying this. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.856 (perp=8.137, rec=0.202, cos=0.026), tot_loss_proj:3.634 [t=0.25s]
prediction: ['[CLS] could any flying pilot jesus could this. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.726 (perp=7.734, rec=0.160, cos=0.019), tot_loss_proj:3.514 [t=0.19s]
prediction: ['[CLS] this any flying pilot jesus could this. [SEP]']
[ 600/2000] tot_loss=1.709 (perp=7.734, rec=0.146, cos=0.017), tot_loss_proj:3.513 [t=0.19s]
prediction: ['[CLS] this any flying pilot jesus could this. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.772 (perp=8.137, rec=0.130, cos=0.015), tot_loss_proj:3.634 [t=0.19s]
prediction: ['[CLS] could any flying pilot jesus could this. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.763 (perp=8.137, rec=0.122, cos=0.013), tot_loss_proj:3.631 [t=0.20s]
prediction: ['[CLS] could any flying pilot jesus could this. [SEP]']
[ 750/2000] tot_loss=1.768 (perp=8.152, rec=0.125, cos=0.012), tot_loss_proj:3.625 [t=0.28s]
prediction: ['[CLS] could any flying pilot tone could this. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.714 (perp=7.935, rec=0.114, cos=0.012), tot_loss_proj:3.155 [t=0.20s]
prediction: ['[CLS] could any flying pilot could tone this. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.719 (perp=7.935, rec=0.120, cos=0.011), tot_loss_proj:3.159 [t=0.27s]
prediction: ['[CLS] could any flying pilot could tone this. [SEP]']
[ 900/2000] tot_loss=1.650 (perp=7.646, rec=0.110, cos=0.011), tot_loss_proj:3.304 [t=0.24s]
prediction: ['[CLS] could any flying pilot could plane this. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.471 (perp=6.712, rec=0.118, cos=0.011), tot_loss_proj:3.269 [t=0.25s]
prediction: ['[CLS] could any flying pilot this plane could. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.394 (perp=6.350, rec=0.113, cos=0.010), tot_loss_proj:2.425 [t=0.18s]
prediction: ['[CLS] could any pilot flying this plane could. [SEP]']
[1050/2000] tot_loss=1.387 (perp=6.350, rec=0.107, cos=0.010), tot_loss_proj:2.427 [t=0.24s]
prediction: ['[CLS] could any pilot flying this plane could. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.409 (perp=6.452, rec=0.110, cos=0.009), tot_loss_proj:3.208 [t=0.25s]
prediction: ['[CLS] be any pilot flying this plane could. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.395 (perp=6.452, rec=0.097, cos=0.008), tot_loss_proj:3.206 [t=0.22s]
prediction: ['[CLS] be any pilot flying this plane could. [SEP]']
[1200/2000] tot_loss=1.401 (perp=6.452, rec=0.103, cos=0.008), tot_loss_proj:3.209 [t=0.18s]
prediction: ['[CLS] be any pilot flying this plane could. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.493 (perp=6.826, rec=0.117, cos=0.010), tot_loss_proj:3.042 [t=0.18s]
prediction: ['[CLS] could be any pilot flying this venus. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.452 (perp=6.694, rec=0.104, cos=0.009), tot_loss_proj:3.026 [t=0.18s]
prediction: ['[CLS] could be any pilot flying this tone. [SEP]']
[1350/2000] tot_loss=1.448 (perp=6.694, rec=0.101, cos=0.009), tot_loss_proj:3.032 [t=0.17s]
prediction: ['[CLS] could be any pilot flying this tone. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.446 (perp=6.694, rec=0.099, cos=0.009), tot_loss_proj:3.020 [t=0.18s]
prediction: ['[CLS] could be any pilot flying this tone. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.451 (perp=6.694, rec=0.104, cos=0.008), tot_loss_proj:3.030 [t=0.19s]
prediction: ['[CLS] could be any pilot flying this tone. [SEP]']
[1500/2000] tot_loss=1.448 (perp=6.694, rec=0.101, cos=0.008), tot_loss_proj:3.020 [t=0.18s]
prediction: ['[CLS] could be any pilot flying this tone. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.443 (perp=6.694, rec=0.096, cos=0.008), tot_loss_proj:3.026 [t=0.18s]
prediction: ['[CLS] could be any pilot flying this tone. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.194 (perp=5.385, rec=0.109, cos=0.008), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] could be any pilot flying this plane. [SEP]']
[1650/2000] tot_loss=1.182 (perp=5.385, rec=0.097, cos=0.008), tot_loss_proj:2.588 [t=0.20s]
prediction: ['[CLS] could be any pilot flying this plane. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.168 (perp=5.385, rec=0.084, cos=0.008), tot_loss_proj:2.589 [t=0.18s]
prediction: ['[CLS] could be any pilot flying this plane. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.182 (perp=5.385, rec=0.097, cos=0.008), tot_loss_proj:2.591 [t=0.19s]
prediction: ['[CLS] could be any pilot flying this plane. [SEP]']
[1800/2000] tot_loss=1.176 (perp=5.385, rec=0.092, cos=0.008), tot_loss_proj:2.596 [t=0.20s]
prediction: ['[CLS] could be any pilot flying this plane. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.190 (perp=5.385, rec=0.106, cos=0.008), tot_loss_proj:2.588 [t=0.21s]
prediction: ['[CLS] could be any pilot flying this plane. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.176 (perp=5.385, rec=0.092, cos=0.008), tot_loss_proj:2.594 [t=0.17s]
prediction: ['[CLS] could be any pilot flying this plane. [SEP]']
[1950/2000] tot_loss=1.172 (perp=5.385, rec=0.088, cos=0.008), tot_loss_proj:2.589 [t=0.23s]
prediction: ['[CLS] could be any pilot flying this plane. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.187 (perp=5.385, rec=0.103, cos=0.008), tot_loss_proj:2.591 [t=0.19s]
prediction: ['[CLS] could be any pilot flying this plane. [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] any pilot could be flying this plane. [SEP]
========================
predicted: 
========================
[CLS] could be any pilot flying this plane. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 162.500

[Aggregate metrics]:
rouge1     | fm: 76.585 | p: 76.621 | r: 76.842
rouge2     | fm: 37.369 | p: 37.151 | r: 37.733
rougeL     | fm: 66.269 | p: 66.381 | r: 66.409
rougeLsum  | fm: 66.435 | p: 66.549 | r: 66.590
r1fm+r2fm = 113.954

input #62 time: 0:08:11 | total time: 8:46:04


Running input #63 of 100.
reference: 
========================
We wonder if Bill left.
========================
average of cosine similarity 0.9993481792856473
highest_index [0]
highest [0.9993481792856473]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2057, 4687, 2065, 3021, 2187, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] we wonder if bill left. [SEP]']
[Init] best rec loss: 0.9412387609481812 for ['[CLS] affected maine effect streets studies its [SEP]']
[Init] best rec loss: 0.9324620366096497 for ['[CLS]creen past effortwn can pier [SEP]']
[Init] best rec loss: 0.9266335964202881 for ['[CLS]ining strata won suitedtis near [SEP]']
[Init] best rec loss: 0.8718317747116089 for ['[CLS] threatsης roman randy loganicative [SEP]']
[Init] best rec loss: 0.8663002848625183 for ['[CLS] fis project of somecoming elf [SEP]']
[Init] best perm rec loss: 0.8493537902832031 for ['[CLS] elf project somecoming of fis [SEP]']
[Init] best perm rec loss: 0.848770797252655 for ['[CLS] of some elf projectcoming fis [SEP]']
[Init] best perm rec loss: 0.8487182259559631 for ['[CLS] elfcoming some project of fis [SEP]']
[Init] best perm rec loss: 0.8484838008880615 for ['[CLS] elf some fis of projectcoming [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.158 (perp=10.320, rec=0.523, cos=0.571), tot_loss_proj:3.816 [t=0.17s]
prediction: ['[CLS] we hat. billy salute load [SEP]']
[ 100/2000] tot_loss=2.559 (perp=9.540, rec=0.427, cos=0.224), tot_loss_proj:3.770 [t=0.17s]
prediction: ['[CLS] we tell. bill strike we [SEP]']
[ 150/2000] tot_loss=2.870 (perp=11.197, rec=0.452, cos=0.179), tot_loss_proj:4.042 [t=0.18s]
prediction: ['[CLS] we wonder wonder bill why dad [SEP]']
[ 200/2000] tot_loss=1.972 (perp=8.333, rec=0.252, cos=0.053), tot_loss_proj:3.492 [t=0.20s]
prediction: ['[CLS] we wonder if bill if if [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.409 (perp=6.111, rec=0.168, cos=0.019), tot_loss_proj:1.447 [t=0.21s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[ 300/2000] tot_loss=1.369 (perp=6.111, rec=0.138, cos=0.009), tot_loss_proj:1.432 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.342 (perp=6.111, rec=0.112, cos=0.009), tot_loss_proj:1.419 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.405 (perp=6.111, rec=0.168, cos=0.014), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[ 450/2000] tot_loss=1.348 (perp=6.111, rec=0.119, cos=0.006), tot_loss_proj:1.486 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.318 (perp=6.111, rec=0.091, cos=0.004), tot_loss_proj:1.470 [t=0.25s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.320 (perp=6.111, rec=0.094, cos=0.003), tot_loss_proj:1.468 [t=0.21s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[ 600/2000] tot_loss=1.294 (perp=6.111, rec=0.069, cos=0.003), tot_loss_proj:1.460 [t=0.24s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.312 (perp=6.111, rec=0.087, cos=0.002), tot_loss_proj:1.462 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.303 (perp=6.111, rec=0.078, cos=0.002), tot_loss_proj:1.466 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[ 750/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.002), tot_loss_proj:1.467 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.297 (perp=6.111, rec=0.073, cos=0.002), tot_loss_proj:1.458 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.002), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[ 900/2000] tot_loss=1.299 (perp=6.111, rec=0.075, cos=0.002), tot_loss_proj:1.461 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.297 (perp=6.111, rec=0.073, cos=0.002), tot_loss_proj:1.458 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.294 (perp=6.111, rec=0.070, cos=0.002), tot_loss_proj:1.456 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[1050/2000] tot_loss=1.299 (perp=6.111, rec=0.075, cos=0.002), tot_loss_proj:1.456 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.293 (perp=6.111, rec=0.069, cos=0.002), tot_loss_proj:1.460 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.296 (perp=6.111, rec=0.072, cos=0.002), tot_loss_proj:1.470 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[1200/2000] tot_loss=1.300 (perp=6.111, rec=0.076, cos=0.002), tot_loss_proj:1.453 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.295 (perp=6.111, rec=0.071, cos=0.002), tot_loss_proj:1.451 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.291 (perp=6.111, rec=0.068, cos=0.002), tot_loss_proj:1.460 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[1350/2000] tot_loss=1.296 (perp=6.111, rec=0.072, cos=0.002), tot_loss_proj:1.453 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.291 (perp=6.111, rec=0.067, cos=0.002), tot_loss_proj:1.449 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.289 (perp=6.111, rec=0.065, cos=0.002), tot_loss_proj:1.452 [t=0.24s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[1500/2000] tot_loss=1.291 (perp=6.111, rec=0.067, cos=0.002), tot_loss_proj:1.454 [t=0.22s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.297 (perp=6.111, rec=0.074, cos=0.002), tot_loss_proj:1.454 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.293 (perp=6.111, rec=0.069, cos=0.002), tot_loss_proj:1.450 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[1650/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.002), tot_loss_proj:1.455 [t=0.22s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.295 (perp=6.111, rec=0.071, cos=0.002), tot_loss_proj:1.443 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.291 (perp=6.111, rec=0.067, cos=0.002), tot_loss_proj:1.454 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[1800/2000] tot_loss=1.291 (perp=6.111, rec=0.067, cos=0.002), tot_loss_proj:1.452 [t=0.21s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.294 (perp=6.111, rec=0.070, cos=0.002), tot_loss_proj:1.459 [t=0.18s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.286 (perp=6.111, rec=0.062, cos=0.002), tot_loss_proj:1.461 [t=0.20s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
[1950/2000] tot_loss=1.304 (perp=6.111, rec=0.080, cos=0.002), tot_loss_proj:1.459 [t=0.19s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.295 (perp=6.111, rec=0.071, cos=0.002), tot_loss_proj:1.456 [t=0.17s]
prediction: ['[CLS] we wonder if bill left. [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] we wonder if bill left. [SEP]
========================
predicted: 
========================
[CLS] we wonder if bill left. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 77.150 | p: 77.143 | r: 77.360
rouge2     | fm: 38.493 | p: 38.304 | r: 38.813
rougeL     | fm: 66.797 | p: 66.910 | r: 66.968
rougeLsum  | fm: 66.937 | p: 67.060 | r: 67.108
r1fm+r2fm = 115.643

input #63 time: 0:07:27 | total time: 8:53:32


Running input #64 of 100.
reference: 
========================
Ellen talked with Helen about the problem.
========================
average of cosine similarity 0.9993768579649704
highest_index [0]
highest [0.9993768579649704]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9155, 5720, 2007, 6330, 2055, 1996, 3291, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] ellen talked with helen about the problem. [SEP]']
[Init] best rec loss: 1.0532675981521606 for ['[CLS] states gmina auction monument worthy than kennedy urban [SEP]']
[Init] best rec loss: 0.9713220000267029 for ['[CLS] dc partmona identity writer mary prime pool [SEP]']
[Init] best rec loss: 0.9620294570922852 for ['[CLS] me rough water diagnosed lanka numbered approved treatment [SEP]']
[Init] best rec loss: 0.955909788608551 for ['[CLS] king supporting sex dropping step emotional ave nodded [SEP]']
[Init] best rec loss: 0.9527767896652222 for ['[CLS] yards hospitals insteadware luis council evervc [SEP]']
[Init] best rec loss: 0.9495007991790771 for ['[CLS] caution h riding established science along usual julia [SEP]']
[Init] best rec loss: 0.9492765069007874 for ['[CLS] pistolsfc for german null express his aloud [SEP]']
[Init] best rec loss: 0.9482495784759521 for ['[CLS]yevenity cook viscount simon statpate lap [SEP]']
[Init] best rec loss: 0.9479407072067261 for ['[CLS] to valerietake hot gwen my cricketumen [SEP]']
[Init] best rec loss: 0.9380924105644226 for ['[CLS]ested static accounts credit anonymousey afternoon massachusetts [SEP]']
[Init] best perm rec loss: 0.9359466433525085 for ['[CLS] accounts staticested afternooney massachusetts anonymous credit [SEP]']
[Init] best perm rec loss: 0.9322394132614136 for ['[CLS]ey static afternoon anonymous creditested massachusetts accounts [SEP]']
[Init] best perm rec loss: 0.9310908913612366 for ['[CLS] static anonymous accountsested afternoon massachusettsey credit [SEP]']
[Init] best perm rec loss: 0.9301943778991699 for ['[CLS]ested afternoon static anonymousey accounts massachusetts credit [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.175 (perp=13.468, rec=0.653, cos=0.828), tot_loss_proj:4.421 [t=0.17s]
prediction: ['[CLS] thought answered briannam giant temperance better beside [SEP]']
[ 100/2000] tot_loss=3.929 (perp=11.852, rec=0.566, cos=0.993), tot_loss_proj:4.235 [t=0.22s]
prediction: ['[CLS] named helen madameberg daughterult porcelain beside [SEP]']
[ 150/2000] tot_loss=3.234 (perp=12.875, rec=0.415, cos=0.244), tot_loss_proj:4.286 [t=0.26s]
prediction: ['[CLS] how helen jessie problem areult lissa when [SEP]']
[ 200/2000] tot_loss=2.684 (perp=12.199, rec=0.232, cos=0.012), tot_loss_proj:4.183 [t=0.22s]
prediction: ['[CLS] talked ellen talked helen problem through talked talked [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.634 (perp=12.145, rec=0.196, cos=0.009), tot_loss_proj:4.196 [t=0.19s]
prediction: ['[CLS] talked ellen talked helen problem ellen talked concerning [SEP]']
[ 300/2000] tot_loss=2.454 (perp=11.434, rec=0.161, cos=0.006), tot_loss_proj:3.950 [t=0.18s]
prediction: ['[CLS] talked ellen talked helen problem ellen about. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.475 (perp=11.497, rec=0.170, cos=0.006), tot_loss_proj:4.028 [t=0.18s]
prediction: ['[CLS] ellen talked helen problem ellen the about. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.785 (perp=8.312, rec=0.119, cos=0.003), tot_loss_proj:3.412 [t=0.22s]
prediction: ['[CLS] ellen talked helen problem about the ellen. [SEP]']
[ 450/2000] tot_loss=1.777 (perp=8.312, rec=0.112, cos=0.003), tot_loss_proj:3.415 [t=0.18s]
prediction: ['[CLS] ellen talked helen problem about the ellen. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.677 (perp=7.847, rec=0.105, cos=0.002), tot_loss_proj:3.500 [t=0.18s]
prediction: ['[CLS] ellen talked helen about the ellen problem. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.495 (perp=6.936, rec=0.105, cos=0.003), tot_loss_proj:2.488 [t=0.18s]
prediction: ['[CLS] ellen talked about the helen ellen problem. [SEP]']
[ 600/2000] tot_loss=1.589 (perp=7.447, rec=0.097, cos=0.002), tot_loss_proj:3.566 [t=0.22s]
prediction: ['[CLS] ellen talked about the helen with problem. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.515 (perp=7.070, rec=0.099, cos=0.003), tot_loss_proj:3.288 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the with problem. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.513 (perp=6.961, rec=0.117, cos=0.003), tot_loss_proj:3.490 [t=0.20s]
prediction: ['[CLS] helen ellen talked about the problem problem. [SEP]']
[ 750/2000] tot_loss=1.501 (perp=6.961, rec=0.106, cos=0.003), tot_loss_proj:3.478 [t=0.21s]
prediction: ['[CLS] helen ellen talked about the problem problem. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.316 (perp=6.125, rec=0.089, cos=0.002), tot_loss_proj:2.996 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.317 (perp=6.125, rec=0.090, cos=0.002), tot_loss_proj:2.997 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
[ 900/2000] tot_loss=1.327 (perp=6.125, rec=0.100, cos=0.002), tot_loss_proj:3.000 [t=0.19s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.315 (perp=6.125, rec=0.088, cos=0.002), tot_loss_proj:2.997 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.315 (perp=6.125, rec=0.088, cos=0.002), tot_loss_proj:2.998 [t=0.22s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
[1050/2000] tot_loss=1.328 (perp=6.125, rec=0.101, cos=0.002), tot_loss_proj:2.995 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.317 (perp=6.125, rec=0.090, cos=0.002), tot_loss_proj:2.993 [t=0.19s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.331 (perp=6.125, rec=0.104, cos=0.002), tot_loss_proj:2.995 [t=0.21s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
[1200/2000] tot_loss=1.311 (perp=6.125, rec=0.083, cos=0.002), tot_loss_proj:2.995 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.315 (perp=6.125, rec=0.088, cos=0.002), tot_loss_proj:2.995 [t=0.19s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.317 (perp=6.125, rec=0.090, cos=0.002), tot_loss_proj:2.996 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
[1350/2000] tot_loss=1.314 (perp=6.125, rec=0.087, cos=0.002), tot_loss_proj:2.994 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.322 (perp=6.125, rec=0.095, cos=0.002), tot_loss_proj:2.992 [t=0.21s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.321 (perp=6.125, rec=0.094, cos=0.002), tot_loss_proj:2.992 [t=0.20s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
[1500/2000] tot_loss=1.317 (perp=6.125, rec=0.090, cos=0.002), tot_loss_proj:2.995 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.312 (perp=6.125, rec=0.085, cos=0.002), tot_loss_proj:2.991 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.323 (perp=6.125, rec=0.096, cos=0.002), tot_loss_proj:2.992 [t=0.19s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
[1650/2000] tot_loss=1.318 (perp=6.125, rec=0.091, cos=0.002), tot_loss_proj:2.992 [t=0.19s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.315 (perp=6.125, rec=0.088, cos=0.002), tot_loss_proj:2.990 [t=0.22s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.319 (perp=6.125, rec=0.092, cos=0.002), tot_loss_proj:2.995 [t=0.17s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
[1800/2000] tot_loss=1.314 (perp=6.125, rec=0.087, cos=0.002), tot_loss_proj:2.998 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.316 (perp=6.125, rec=0.089, cos=0.002), tot_loss_proj:2.996 [t=0.17s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.320 (perp=6.125, rec=0.092, cos=0.002), tot_loss_proj:2.999 [t=0.19s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
[1950/2000] tot_loss=1.309 (perp=6.125, rec=0.082, cos=0.002), tot_loss_proj:2.992 [t=0.18s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.318 (perp=6.125, rec=0.091, cos=0.002), tot_loss_proj:2.991 [t=0.17s]
prediction: ['[CLS] helen ellen talked about the problem with. [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] ellen talked with helen about the problem. [SEP]
========================
predicted: 
========================
[CLS] helen ellen talked about the problem with. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 77.556 | p: 77.627 | r: 77.798
rouge2     | fm: 38.135 | p: 37.975 | r: 38.432
rougeL     | fm: 66.961 | p: 67.053 | r: 67.151
rougeLsum  | fm: 66.968 | p: 67.016 | r: 67.126
r1fm+r2fm = 115.691

input #64 time: 0:07:55 | total time: 9:01:27


Running input #65 of 100.
reference: 
========================
Mag Wildwood came to introduce the bartender but I came precisely not to.
========================
average of cosine similarity 0.999347258517335
highest_index [0]
highest [0.999347258517335]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101, 23848,  3748,  3702,  2234,  2000,  8970,  1996, 15812,  2021,
          1045,  2234, 10785,  2025,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]']
[Init] best rec loss: 0.9090550541877747 for ['[CLS] old shaw mcgill standminated chapter publication legal non penny cheekatics contemporary story fleet [SEP]']
[Init] best rec loss: 0.8861916661262512 for ['[CLS] mail shooting legends capture gen attention cpud graders democratic but lips suspicious suppressed out [SEP]']
[Init] best rec loss: 0.8844349980354309 for ['[CLS] groom ownership hd mellon field house of [SEP]zed lisa iranbreaker bypass short [SEP]']
[Init] best rec loss: 0.8687723278999329 for ['[CLS]ines organ salesmanisen sectionoise people ideal succession single humanunt shown monk black [SEP]']
[Init] best rec loss: 0.8403171896934509 for ['[CLS] question ibn calledevich gulfcting due instead mist end banks half mef butch [SEP]']
[Init] best perm rec loss: 0.8378674983978271 for ['[CLS]f mecting called ibn butch half banks end due instead gulfevich question mist [SEP]']
[Init] best perm rec loss: 0.8377445936203003 for ['[CLS] gulf butch me banks due mist insteadevich halff questioncting end called ibn [SEP]']
[Init] best perm rec loss: 0.8348801732063293 for ['[CLS] question banks me due half gulfevich mistcting called end butch ibn insteadf [SEP]']
[Init] best perm rec loss: 0.8347507119178772 for ['[CLS]cting end half banks mist instead dueevich me question called gulff ibn butch [SEP]']
[Init] best perm rec loss: 0.8344051837921143 for ['[CLS]f question end instead banks mecting gulfevich due ibn mist half called butch [SEP]']
[Init] best perm rec loss: 0.8343683481216431 for ['[CLS] ibn me called questionevich instead mist due banks half butchfcting gulf end [SEP]']
[Init] best perm rec loss: 0.8341259360313416 for ['[CLS] banks insteadevich ibn me end mistcting gulff called question due half butch [SEP]']
[Init] best perm rec loss: 0.8338921666145325 for ['[CLS] called me banks due instead halffevich ibncting question gulf end butch mist [SEP]']
[Init] best perm rec loss: 0.8312921524047852 for ['[CLS] called butch ibn me end question banksevich mist due instead gulfcting halff [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.236 (perp=12.759, rec=0.468, cos=0.216), tot_loss_proj:4.402 [t=0.17s]
prediction: ['[CLS] cal dwarf vampire expansion end question perfect finish steve mae special hireal or is [SEP]']
[ 100/2000] tot_loss=3.184 (perp=13.443, rec=0.394, cos=0.101), tot_loss_proj:4.584 [t=0.17s]
prediction: ['[CLS] inc bartender bartender dances strike never contact finish steve comes actually nouns ba of fr [SEP]']
[ 150/2000] tot_loss=2.939 (perp=11.884, rec=0.401, cos=0.161), tot_loss_proj:4.207 [t=0.19s]
prediction: ['[CLS] yet bartender bartender go pre precisely different finish steve times actually nouns not from anyway [SEP]']
[ 200/2000] tot_loss=3.027 (perp=12.731, rec=0.359, cos=0.122), tot_loss_proj:4.440 [t=0.18s]
prediction: ['[CLS] jones mag bartender came came precisely exactly finish render came actually nouns not of anyway [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.708 (perp=11.806, rec=0.295, cos=0.051), tot_loss_proj:4.221 [t=0.18s]
prediction: ['[CLS] until mag bartender came came precisely exactly finish actually came shows nouns precisely not not [SEP]']
[ 300/2000] tot_loss=2.828 (perp=12.403, rec=0.290, cos=0.058), tot_loss_proj:4.320 [t=0.19s]
prediction: ['[CLS] frowned mag bartender came came precisely exactly finish actually came render directly precisely not not [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.606 (perp=11.542, rec=0.263, cos=0.035), tot_loss_proj:4.175 [t=0.18s]
prediction: ['[CLS] jones mag bartender came came preciselyche do actually came came directly precisely not exactly [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.564 (perp=11.257, rec=0.268, cos=0.044), tot_loss_proj:4.103 [t=0.18s]
prediction: ['[CLS] introduce mag bartender frowned came precisely not do actually came came directly precisely not exactly [SEP]']
[ 450/2000] tot_loss=2.541 (perp=11.327, rec=0.247, cos=0.029), tot_loss_proj:4.084 [t=0.23s]
prediction: ['[CLS] introduce mag bartender come came precisely not do precisely came came indirectly precisely not not [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.421 (perp=10.795, rec=0.235, cos=0.026), tot_loss_proj:3.972 [t=0.24s]
prediction: ['[CLS] introduce mag bartender not came precisely not do precisely came indirectly came precisely not not [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.792 (perp=12.180, rec=0.307, cos=0.049), tot_loss_proj:4.272 [t=0.21s]
prediction: ['[CLS] introduce mag bartender frowned came preciselyme prefer precisely not we came, to came [SEP]']
[ 600/2000] tot_loss=2.416 (perp=10.756, rec=0.236, cos=0.029), tot_loss_proj:3.982 [t=0.18s]
prediction: ['[CLS] introduce mag bartender jones came precisely ins not precisely not we came. not came [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.278 (perp=10.108, rec=0.230, cos=0.027), tot_loss_proj:3.827 [t=0.18s]
prediction: ['[CLS] introduce mag bartender not came so precisely not precisely not indirectly came. not came [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.145 (perp=9.548, rec=0.213, cos=0.023), tot_loss_proj:3.735 [t=0.18s]
prediction: ['[CLS] introduce mag came not came not precisely not precisely not indirectly bartender. not came [SEP]']
[ 750/2000] tot_loss=2.062 (perp=9.213, rec=0.201, cos=0.018), tot_loss_proj:3.679 [t=0.18s]
prediction: ['[CLS] introduce mag came not came not precisely not precisely not i bartender. not came [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.044 (perp=9.109, rec=0.204, cos=0.019), tot_loss_proj:3.643 [t=0.19s]
prediction: ['[CLS] introduce mag came not came not precisely not precisely not bartender i. not came [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.995 (perp=8.894, rec=0.197, cos=0.019), tot_loss_proj:3.641 [t=0.18s]
prediction: ['[CLS] introduce mag came not came not precisely not precisely not bartender. i not came [SEP]']
[ 900/2000] tot_loss=2.002 (perp=8.970, rec=0.192, cos=0.016), tot_loss_proj:3.657 [t=0.20s]
prediction: ['[CLS] introduce mag came not came so precisely not precisely not bartender. i not came [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.072 (perp=9.349, rec=0.186, cos=0.016), tot_loss_proj:3.727 [t=0.20s]
prediction: ['[CLS] introduce magwood not came not precisely not precisely not bartender. i not came [SEP]']
Attempt swap
[1000/2000] tot_loss=2.070 (perp=9.349, rec=0.186, cos=0.015), tot_loss_proj:3.727 [t=0.18s]
prediction: ['[CLS] introduce magwood not came not precisely not precisely not bartender. i not came [SEP]']
[1050/2000] tot_loss=2.074 (perp=9.349, rec=0.190, cos=0.014), tot_loss_proj:3.727 [t=0.18s]
prediction: ['[CLS] introduce magwood not came not precisely not precisely not bartender. i not came [SEP]']
Attempt swap
[1100/2000] tot_loss=2.049 (perp=9.262, rec=0.183, cos=0.014), tot_loss_proj:3.685 [t=0.18s]
prediction: ['[CLS] introduce magwood not came not precisely not precisely so bartender. i not came [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.022 (perp=9.209, rec=0.167, cos=0.013), tot_loss_proj:3.671 [t=0.19s]
prediction: ['[CLS] introduce magwood not came not precisely not so precisely bartender. i not came [SEP]']
[1200/2000] tot_loss=2.029 (perp=9.209, rec=0.174, cos=0.013), tot_loss_proj:3.673 [t=0.18s]
prediction: ['[CLS] introduce magwood not came not precisely not so precisely bartender. i not came [SEP]']
Attempt swap
[1250/2000] tot_loss=2.035 (perp=9.209, rec=0.180, cos=0.013), tot_loss_proj:3.671 [t=0.18s]
prediction: ['[CLS] introduce magwood not came not precisely not so precisely bartender. i not came [SEP]']
Attempt swap
[1300/2000] tot_loss=2.029 (perp=9.209, rec=0.175, cos=0.012), tot_loss_proj:3.668 [t=0.18s]
prediction: ['[CLS] introduce magwood not came not precisely not so precisely bartender. i not came [SEP]']
[1350/2000] tot_loss=2.028 (perp=9.209, rec=0.174, cos=0.012), tot_loss_proj:3.671 [t=0.27s]
prediction: ['[CLS] introduce magwood not came not precisely not so precisely bartender. i not came [SEP]']
Attempt swap
[1400/2000] tot_loss=2.024 (perp=9.209, rec=0.170, cos=0.012), tot_loss_proj:3.671 [t=0.19s]
prediction: ['[CLS] introduce magwood not came not precisely not so precisely bartender. i not came [SEP]']
Attempt swap
[1450/2000] tot_loss=2.057 (perp=9.387, rec=0.168, cos=0.012), tot_loss_proj:3.721 [t=0.23s]
prediction: ['[CLS] introduce magwood not came not precisely but so precisely bartender. i not came [SEP]']
[1500/2000] tot_loss=2.050 (perp=9.372, rec=0.164, cos=0.011), tot_loss_proj:3.735 [t=0.20s]
prediction: ['[CLS] introduce magwood not came not precisely but so precisely bartender. i not introduced [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.001 (perp=9.099, rec=0.170, cos=0.012), tot_loss_proj:3.681 [t=0.18s]
prediction: ['[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]']
Attempt swap
[1600/2000] tot_loss=2.005 (perp=9.099, rec=0.173, cos=0.012), tot_loss_proj:3.680 [t=0.18s]
prediction: ['[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]']
[1650/2000] tot_loss=1.990 (perp=9.099, rec=0.159, cos=0.012), tot_loss_proj:3.681 [t=0.18s]
prediction: ['[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]']
Attempt swap
[1700/2000] tot_loss=1.994 (perp=9.099, rec=0.163, cos=0.011), tot_loss_proj:3.683 [t=0.24s]
prediction: ['[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]']
Attempt swap
[1750/2000] tot_loss=1.992 (perp=9.099, rec=0.160, cos=0.011), tot_loss_proj:3.686 [t=0.19s]
prediction: ['[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]']
[1800/2000] tot_loss=1.996 (perp=9.099, rec=0.165, cos=0.011), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]']
Attempt swap
[1850/2000] tot_loss=1.991 (perp=9.099, rec=0.160, cos=0.011), tot_loss_proj:3.684 [t=0.24s]
prediction: ['[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]']
Attempt swap
[1900/2000] tot_loss=1.996 (perp=9.099, rec=0.165, cos=0.011), tot_loss_proj:3.684 [t=0.25s]
prediction: ['[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]']
[1950/2000] tot_loss=1.994 (perp=9.099, rec=0.163, cos=0.011), tot_loss_proj:3.682 [t=0.22s]
prediction: ['[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]']
Attempt swap
[2000/2000] tot_loss=1.992 (perp=9.099, rec=0.161, cos=0.011), tot_loss_proj:3.682 [t=0.19s]
prediction: ['[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]
========================
predicted: 
========================
[CLS] introduce magwood not came so precisely but not precisely bartender. i not introduced [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 40.000 | r: 40.000
rougeLsum  | fm: 40.000 | p: 40.000 | r: 40.000
r1fm+r2fm = 60.000

[Aggregate metrics]:
rouge1     | fm: 77.190 | p: 77.279 | r: 77.435
rouge2     | fm: 37.472 | p: 37.308 | r: 37.808
rougeL     | fm: 66.509 | p: 66.648 | r: 66.613
rougeLsum  | fm: 66.505 | p: 66.588 | r: 66.633
r1fm+r2fm = 114.663

input #65 time: 0:08:02 | total time: 9:09:30


Running input #66 of 100.
reference: 
========================
There tried to be riots in Seoul.
========================
average of cosine similarity 0.9993414821455258
highest_index [0]
highest [0.9993414821455258]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2045,  2699,  2000,  2022, 12925,  1999, 10884,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] there tried to be riots in seoul. [SEP]']
[Init] best rec loss: 0.8370904326438904 for ['[CLS] mcdonnell mount activities death today game medal ng [SEP]']
[Init] best rec loss: 0.7445188164710999 for ['[CLS] vamp kada devil kent lizard home angels [SEP]']
[Init] best rec loss: 0.7357205748558044 for ['[CLS] general maryland head learners balancemm experience vehicles [SEP]']
[Init] best rec loss: 0.6963397860527039 for ['[CLS] kirk line may anniversary bee combined ladder doubtful [SEP]']
[Init] best rec loss: 0.6802833676338196 for ['[CLS] mainger soil music means numbers this left [SEP]']
[Init] best rec loss: 0.6790328025817871 for ['[CLS] duel paradise birdsfireshane express knows archives [SEP]']
[Init] best perm rec loss: 0.6775854825973511 for ['[CLS]hane express paradise birds archives knowsfires duel [SEP]']
[Init] best perm rec loss: 0.6764670610427856 for ['[CLS] express birds paradisehane duel knowsfires archives [SEP]']
[Init] best perm rec loss: 0.6757842898368835 for ['[CLS]fires paradisehane knows birds archives express duel [SEP]']
[Init] best perm rec loss: 0.6753475069999695 for ['[CLS] paradise duel express birds knows archivesfireshane [SEP]']
[Init] best perm rec loss: 0.6744402647018433 for ['[CLS] paradise archivesfires birdshane knows express duel [SEP]']
[Init] best perm rec loss: 0.6731578707695007 for ['[CLS] express duel paradisehane archives knows birdsfires [SEP]']
[Init] best perm rec loss: 0.6708163022994995 for ['[CLS] paradise knows duelhane express birds archivesfires [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.957 (perp=12.651, rec=0.389, cos=0.038), tot_loss_proj:3.287 [t=0.20s]
prediction: ['[CLS] brianna track at be famous poppy elephants wore [SEP]']
[ 100/2000] tot_loss=3.269 (perp=14.631, rec=0.320, cos=0.023), tot_loss_proj:3.750 [t=0.20s]
prediction: ['[CLS] evelyn attempt korean be famous corn lyle been [SEP]']
[ 150/2000] tot_loss=3.081 (perp=14.008, rec=0.265, cos=0.015), tot_loss_proj:3.572 [t=0.19s]
prediction: ['[CLS] symptoms tried seoul tried into corn bleed be [SEP]']
[ 200/2000] tot_loss=2.849 (perp=12.748, rec=0.278, cos=0.021), tot_loss_proj:3.491 [t=0.19s]
prediction: ['[CLS] there tried seoul tried in corn bacterium be [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.294 (perp=10.543, rec=0.173, cos=0.013), tot_loss_proj:2.765 [t=0.19s]
prediction: ['[CLS] there tried be tried to corn riots seoul [SEP]']
[ 300/2000] tot_loss=2.404 (perp=11.100, rec=0.171, cos=0.013), tot_loss_proj:3.046 [t=0.20s]
prediction: ['[CLS] there tried be tried togi riots seoul [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.165 (perp=10.196, rec=0.117, cos=0.009), tot_loss_proj:2.734 [t=0.24s]
prediction: ['[CLS] there majesty be tried to tried riots seoul [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.960 (perp=9.250, rec=0.103, cos=0.007), tot_loss_proj:2.632 [t=0.17s]
prediction: ['[CLS] there majesty tried to be tried riots seoul [SEP]']
[ 450/2000] tot_loss=1.997 (perp=9.484, rec=0.094, cos=0.006), tot_loss_proj:2.660 [t=0.18s]
prediction: ['[CLS] therens tried to be tried riots seoul [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.933 (perp=9.147, rec=0.097, cos=0.006), tot_loss_proj:2.430 [t=0.17s]
prediction: ['[CLS] therens tried to be riots seoul tried [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.924 (perp=9.147, rec=0.089, cos=0.006), tot_loss_proj:2.427 [t=0.18s]
prediction: ['[CLS] therens tried to be riots seoul tried [SEP]']
[ 600/2000] tot_loss=1.917 (perp=9.147, rec=0.082, cos=0.005), tot_loss_proj:2.435 [t=0.24s]
prediction: ['[CLS] therens tried to be riots seoul tried [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.923 (perp=9.147, rec=0.088, cos=0.005), tot_loss_proj:2.432 [t=0.17s]
prediction: ['[CLS] therens tried to be riots seoul tried [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.927 (perp=9.147, rec=0.093, cos=0.005), tot_loss_proj:2.442 [t=0.21s]
prediction: ['[CLS] therens tried to be riots seoul tried [SEP]']
[ 750/2000] tot_loss=1.921 (perp=9.147, rec=0.087, cos=0.005), tot_loss_proj:2.444 [t=0.18s]
prediction: ['[CLS] therens tried to be riots seoul tried [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.918 (perp=9.147, rec=0.084, cos=0.005), tot_loss_proj:2.444 [t=0.18s]
prediction: ['[CLS] therens tried to be riots seoul tried [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.848 (perp=8.725, rec=0.098, cos=0.005), tot_loss_proj:2.830 [t=0.18s]
prediction: ['[CLS] therens riots seoul tried to be tried [SEP]']
[ 900/2000] tot_loss=1.940 (perp=9.225, rec=0.091, cos=0.005), tot_loss_proj:2.936 [t=0.17s]
prediction: ['[CLS] therere riots seoul tried to be tried [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.909 (perp=9.161, rec=0.072, cos=0.005), tot_loss_proj:2.491 [t=0.17s]
prediction: ['[CLS] there seoul mc riots tried to be tried [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.829 (perp=8.710, rec=0.082, cos=0.005), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS] there mc riots seoul tried to be tried [SEP]']
[1050/2000] tot_loss=1.833 (perp=8.710, rec=0.087, cos=0.004), tot_loss_proj:2.418 [t=0.22s]
prediction: ['[CLS] there mc riots seoul tried to be tried [SEP]']
Attempt swap
[1100/2000] tot_loss=1.834 (perp=8.710, rec=0.087, cos=0.004), tot_loss_proj:2.418 [t=0.21s]
prediction: ['[CLS] there mc riots seoul tried to be tried [SEP]']
Attempt swap
[1150/2000] tot_loss=1.838 (perp=8.710, rec=0.091, cos=0.004), tot_loss_proj:2.411 [t=0.18s]
prediction: ['[CLS] there mc riots seoul tried to be tried [SEP]']
[1200/2000] tot_loss=1.831 (perp=8.710, rec=0.085, cos=0.004), tot_loss_proj:2.414 [t=0.21s]
prediction: ['[CLS] there mc riots seoul tried to be tried [SEP]']
Attempt swap
[1250/2000] tot_loss=1.831 (perp=8.710, rec=0.084, cos=0.004), tot_loss_proj:2.419 [t=0.20s]
prediction: ['[CLS] there mc riots seoul tried to be tried [SEP]']
Attempt swap
[1300/2000] tot_loss=1.826 (perp=8.710, rec=0.080, cos=0.004), tot_loss_proj:2.421 [t=0.17s]
prediction: ['[CLS] there mc riots seoul tried to be tried [SEP]']
[1350/2000] tot_loss=1.908 (perp=9.101, rec=0.083, cos=0.004), tot_loss_proj:2.394 [t=0.18s]
prediction: ['[CLS] there locals riots seoul tried to be tried [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.838 (perp=8.770, rec=0.080, cos=0.004), tot_loss_proj:2.691 [t=0.19s]
prediction: ['[CLS] there riots seoul locals tried to be tried [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.841 (perp=8.718, rec=0.093, cos=0.004), tot_loss_proj:2.375 [t=0.17s]
prediction: ['[CLS] there seoullake riots tried to be tried [SEP]']
[1500/2000] tot_loss=1.908 (perp=9.104, rec=0.084, cos=0.004), tot_loss_proj:2.446 [t=0.18s]
prediction: ['[CLS] there seoul locals riots tried to be tried [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.847 (perp=8.806, rec=0.082, cos=0.004), tot_loss_proj:2.498 [t=0.18s]
prediction: ['[CLS] there seoul locals tried riots to be tried [SEP]']
Attempt swap
[1600/2000] tot_loss=1.828 (perp=8.806, rec=0.063, cos=0.004), tot_loss_proj:2.500 [t=0.18s]
prediction: ['[CLS] there seoul locals tried riots to be tried [SEP]']
[1650/2000] tot_loss=1.850 (perp=8.806, rec=0.085, cos=0.004), tot_loss_proj:2.498 [t=0.18s]
prediction: ['[CLS] there seoul locals tried riots to be tried [SEP]']
Attempt swap
[1700/2000] tot_loss=1.852 (perp=8.806, rec=0.086, cos=0.004), tot_loss_proj:2.495 [t=0.20s]
prediction: ['[CLS] there seoul locals tried riots to be tried [SEP]']
Attempt swap
[1750/2000] tot_loss=1.852 (perp=8.806, rec=0.086, cos=0.004), tot_loss_proj:2.494 [t=0.18s]
prediction: ['[CLS] there seoul locals tried riots to be tried [SEP]']
[1800/2000] tot_loss=1.852 (perp=8.806, rec=0.086, cos=0.004), tot_loss_proj:2.503 [t=0.20s]
prediction: ['[CLS] there seoul locals tried riots to be tried [SEP]']
Attempt swap
[1850/2000] tot_loss=1.840 (perp=8.806, rec=0.075, cos=0.004), tot_loss_proj:2.501 [t=0.18s]
prediction: ['[CLS] there seoul locals tried riots to be tried [SEP]']
Attempt swap
[1900/2000] tot_loss=1.835 (perp=8.806, rec=0.070, cos=0.004), tot_loss_proj:2.498 [t=0.18s]
prediction: ['[CLS] there seoul locals tried riots to be tried [SEP]']
[1950/2000] tot_loss=1.845 (perp=8.806, rec=0.080, cos=0.004), tot_loss_proj:2.496 [t=0.17s]
prediction: ['[CLS] there seoul locals tried riots to be tried [SEP]']
Attempt swap
[2000/2000] tot_loss=1.856 (perp=8.806, rec=0.091, cos=0.004), tot_loss_proj:2.491 [t=0.18s]
prediction: ['[CLS] there seoul locals tried riots to be tried [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] there tried to be riots in seoul. [SEP]
========================
predicted: 
========================
[CLS] there seoullake riots tried to be tried [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 115.278

[Aggregate metrics]:
rouge1     | fm: 77.205 | p: 77.255 | r: 77.419
rouge2     | fm: 37.502 | p: 37.319 | r: 37.738
rougeL     | fm: 66.615 | p: 66.683 | r: 66.711
rougeLsum  | fm: 66.534 | p: 66.613 | r: 66.684
r1fm+r2fm = 114.707

input #66 time: 0:07:48 | total time: 9:17:18


Running input #67 of 100.
reference: 
========================
Fido is the smarter dog than Spot.
========================
average of cosine similarity 0.9991866915016882
highest_index [0]
highest [0.9991866915016882]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 10882,  3527,  2003,  1996, 25670,  3899,  2084,  3962,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] fido is the smarter dog than spot. [SEP]']
[Init] best rec loss: 1.016399621963501 for ['[CLS] spec legend currently boarding reasons chapel assistance accomplish through [SEP]']
[Init] best rec loss: 0.9444090723991394 for ['[CLS] bi ride driveway° student " life representative bomb [SEP]']
[Init] best rec loss: 0.9167268872261047 for ['[CLS] silkrting relating break cigarette bail finger charts do [SEP]']
[Init] best rec loss: 0.8861123323440552 for ['[CLS] word cab healthychenifying ruled mills flat prison [SEP]']
[Init] best rec loss: 0.8842894434928894 for ['[CLS]vert prompt train circle being ableaco horror ada [SEP]']
[Init] best rec loss: 0.8251447081565857 for ['[CLS] canberra mountain terms first transit ladder rats running naval [SEP]']
[Init] best rec loss: 0.8203999996185303 for ['[CLS] date disease expert monkey ich determination only oncelow [SEP]']
[Init] best rec loss: 0.8164994716644287 for ['[CLS] ] house christ box swore rex marina limit replacement [SEP]']
[Init] best perm rec loss: 0.8159659504890442 for ['[CLS] house limit box ] marina christ rex replacement swore [SEP]']
[Init] best perm rec loss: 0.8144137263298035 for ['[CLS] limit replacement house rex box marina swore christ ] [SEP]']
[Init] best perm rec loss: 0.8091739416122437 for ['[CLS] box house replacement rex christ swore limit marina ] [SEP]']
[Init] best perm rec loss: 0.808587908744812 for ['[CLS] ] house box replacement marina christ rex limit swore [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.312 (perp=13.201, rec=0.478, cos=0.193), tot_loss_proj:4.147 [t=0.17s]
prediction: ['[CLS] tournamentlo sonny companion hunters fifa which although commonly [SEP]']
[ 100/2000] tot_loss=2.752 (perp=10.224, rec=0.522, cos=0.185), tot_loss_proj:3.551 [t=0.25s]
prediction: ['[CLS] ] ( spot warrior avery does dog most than [SEP]']
[ 150/2000] tot_loss=3.187 (perp=13.168, rec=0.421, cos=0.133), tot_loss_proj:4.091 [t=0.25s]
prediction: ['[CLS]0 ( spotfishoulos smarter dog spot than [SEP]']
[ 200/2000] tot_loss=2.824 (perp=12.543, rec=0.270, cos=0.046), tot_loss_proj:4.175 [t=0.18s]
prediction: ['[CLS]4 is spotmaster baseman smarter dog spot than [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.556 (perp=11.532, rec=0.217, cos=0.032), tot_loss_proj:3.634 [t=0.17s]
prediction: ['[CLS]es is spotmaster ო smarter dog than spot [SEP]']
[ 300/2000] tot_loss=2.564 (perp=11.702, rec=0.190, cos=0.034), tot_loss_proj:3.778 [t=0.18s]
prediction: ['[CLS]th is spotji ო smarter dog than spot [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.101 (perp=11.373, rec=0.533, cos=0.294), tot_loss_proj:4.145 [t=0.17s]
prediction: ['[CLS]?d miles smarter dog is le than spot [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.051 (perp=12.441, rec=0.437, cos=0.126), tot_loss_proj:4.123 [t=0.21s]
prediction: ['[CLS] thand sly smarter dog ᅵ mysore than spot [SEP]']
[ 450/2000] tot_loss=2.973 (perp=12.632, rec=0.376, cos=0.070), tot_loss_proj:4.081 [t=0.18s]
prediction: ['[CLS] thand sly smarter dog॥ cappella than spot [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.470 (perp=10.372, rec=0.338, cos=0.058), tot_loss_proj:3.542 [t=0.17s]
prediction: ['[CLS] thankill fi spot dog smarter smarter than spot [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.601 (perp=10.416, rec=0.409, cos=0.108), tot_loss_proj:3.337 [t=0.18s]
prediction: ['[CLS] thande fi spot dog smarter than spot smart [SEP]']
[ 600/2000] tot_loss=2.419 (perp=10.481, rec=0.287, cos=0.035), tot_loss_proj:3.453 [t=0.20s]
prediction: ['[CLS] thande spotted spot dog smarter than spot smart [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.330 (perp=10.296, rec=0.243, cos=0.027), tot_loss_proj:3.796 [t=0.22s]
prediction: ['[CLS]de spotted spot dog smarter than than spot is [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.150 (perp=9.447, rec=0.231, cos=0.029), tot_loss_proj:3.545 [t=0.18s]
prediction: ['[CLS]de spotted spot is smarter than than spot dog [SEP]']
[ 750/2000] tot_loss=2.449 (perp=11.137, rec=0.197, cos=0.024), tot_loss_proj:3.894 [t=0.18s]
prediction: ['[CLS]de fi spot is smarter than than spot dog [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.136 (perp=9.662, rec=0.183, cos=0.021), tot_loss_proj:3.583 [t=0.17s]
prediction: ['[CLS] spotde fi is smarter than than spot dog [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.110 (perp=9.662, rec=0.159, cos=0.018), tot_loss_proj:3.587 [t=0.21s]
prediction: ['[CLS] spotde fi is smarter than than spot dog [SEP]']
[ 900/2000] tot_loss=2.098 (perp=9.662, rec=0.149, cos=0.016), tot_loss_proj:3.592 [t=0.17s]
prediction: ['[CLS] spotde fi is smarter than than spot dog [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.091 (perp=9.662, rec=0.143, cos=0.015), tot_loss_proj:3.586 [t=0.18s]
prediction: ['[CLS] spotde fi is smarter than than spot dog [SEP]']
Attempt swap
[1000/2000] tot_loss=2.076 (perp=9.662, rec=0.129, cos=0.014), tot_loss_proj:3.589 [t=0.17s]
prediction: ['[CLS] spotde fi is smarter than than spot dog [SEP]']
[1050/2000] tot_loss=2.079 (perp=9.662, rec=0.133, cos=0.014), tot_loss_proj:3.587 [t=0.17s]
prediction: ['[CLS] spotde fi is smarter than than spot dog [SEP]']
Attempt swap
[1100/2000] tot_loss=2.131 (perp=9.925, rec=0.132, cos=0.013), tot_loss_proj:3.615 [t=0.17s]
prediction: ['[CLS] spotdedo is smarter than than spot dog [SEP]']
Attempt swap
[1150/2000] tot_loss=2.133 (perp=9.925, rec=0.135, cos=0.013), tot_loss_proj:3.605 [t=0.17s]
prediction: ['[CLS] spotdedo is smarter than than spot dog [SEP]']
[1200/2000] tot_loss=2.123 (perp=9.925, rec=0.125, cos=0.013), tot_loss_proj:3.603 [t=0.20s]
prediction: ['[CLS] spotdedo is smarter than than spot dog [SEP]']
Attempt swap
[1250/2000] tot_loss=2.119 (perp=9.925, rec=0.121, cos=0.012), tot_loss_proj:3.620 [t=0.18s]
prediction: ['[CLS] spotdedo is smarter than than spot dog [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.232 (perp=10.504, rec=0.117, cos=0.014), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
[1350/2000] tot_loss=2.235 (perp=10.504, rec=0.122, cos=0.013), tot_loss_proj:3.864 [t=0.19s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
Attempt swap
[1400/2000] tot_loss=2.238 (perp=10.504, rec=0.125, cos=0.012), tot_loss_proj:3.864 [t=0.18s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
Attempt swap
[1450/2000] tot_loss=2.226 (perp=10.504, rec=0.113, cos=0.012), tot_loss_proj:3.864 [t=0.18s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
[1500/2000] tot_loss=2.224 (perp=10.504, rec=0.112, cos=0.012), tot_loss_proj:3.867 [t=0.18s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
Attempt swap
[1550/2000] tot_loss=2.227 (perp=10.504, rec=0.114, cos=0.012), tot_loss_proj:3.873 [t=0.21s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
Attempt swap
[1600/2000] tot_loss=2.238 (perp=10.504, rec=0.126, cos=0.012), tot_loss_proj:3.868 [t=0.18s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
[1650/2000] tot_loss=2.235 (perp=10.504, rec=0.123, cos=0.011), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
Attempt swap
[1700/2000] tot_loss=2.221 (perp=10.504, rec=0.109, cos=0.011), tot_loss_proj:3.867 [t=0.18s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
Attempt swap
[1750/2000] tot_loss=2.224 (perp=10.504, rec=0.112, cos=0.011), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
[1800/2000] tot_loss=2.230 (perp=10.504, rec=0.118, cos=0.011), tot_loss_proj:3.864 [t=0.18s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
Attempt swap
[1850/2000] tot_loss=2.221 (perp=10.504, rec=0.109, cos=0.011), tot_loss_proj:3.869 [t=0.20s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
Attempt swap
[1900/2000] tot_loss=2.226 (perp=10.504, rec=0.114, cos=0.011), tot_loss_proj:3.872 [t=0.19s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
[1950/2000] tot_loss=2.225 (perp=10.504, rec=0.113, cos=0.011), tot_loss_proj:3.869 [t=0.19s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
Attempt swap
[2000/2000] tot_loss=2.232 (perp=10.504, rec=0.120, cos=0.011), tot_loss_proj:3.869 [t=0.25s]
prediction: ['[CLS]dovus spot is smarter than than spot dog [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] fido is the smarter dog than spot. [SEP]
========================
predicted: 
========================
[CLS]dovus spot is smarter than than spot dog [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 70.000 | r: 77.778
rouge2     | fm: 11.765 | p: 11.111 | r: 12.500
rougeL     | fm: 63.158 | p: 60.000 | r: 66.667
rougeLsum  | fm: 63.158 | p: 60.000 | r: 66.667
r1fm+r2fm = 85.449

[Aggregate metrics]:
rouge1     | fm: 77.204 | p: 77.237 | r: 77.491
rouge2     | fm: 37.094 | p: 36.931 | r: 37.411
rougeL     | fm: 66.592 | p: 66.653 | r: 66.744
rougeLsum  | fm: 66.529 | p: 66.557 | r: 66.652
r1fm+r2fm = 114.299

input #67 time: 0:07:29 | total time: 9:24:48


Running input #68 of 100.
reference: 
========================
John convinced the rice to be cooked by Bill.
========================
average of cosine similarity 0.9992469253349905
highest_index [0]
highest [0.9992469253349905]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198,  6427,  1996,  5785,  2000,  2022, 12984,  2011,  3021,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john convinced the rice to be cooked by bill. [SEP]']
[Init] best rec loss: 0.7907953262329102 for ['[CLS] rich plant ticket has an boat favorite malaysia showing procedures [SEP]']
[Init] best rec loss: 0.7299020886421204 for ['[CLS] ago participants bo charlie across formula alone fisheries core constantine [SEP]']
[Init] best rec loss: 0.7223528027534485 for ['[CLS] maintenance fr respectively sports alive turnoured acquisition barrow body [SEP]']
[Init] best rec loss: 0.7169906497001648 for ['[CLS] clouditedpath 23rch lying staff students waiting supreme [SEP]']
[Init] best rec loss: 0.7140128016471863 for ['[CLS] protested rob child truss privileged rise efforts saber [MASK] goat [SEP]']
[Init] best rec loss: 0.7135128378868103 for ['[CLS] buy miles figureider okay hit springs loving todd contract [SEP]']
[Init] best rec loss: 0.70791095495224 for ['[CLS] shipped pali elevation stacy mississippi spectacle [SEP] completely physical airlines [SEP]']
[Init] best rec loss: 0.6938566565513611 for ['[CLS] bail tallest moth twenty plate maybe verse story growing > [SEP]']
[Init] best perm rec loss: 0.6931449770927429 for ['[CLS] > bail plate moth verse twenty growing tallest maybe story [SEP]']
[Init] best perm rec loss: 0.6930882334709167 for ['[CLS] story maybe bail tallest verse twenty moth > plate growing [SEP]']
[Init] best perm rec loss: 0.6856919527053833 for ['[CLS] growing maybe story verse twenty > plate tallest moth bail [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.625 (perp=11.403, rec=0.293, cos=0.051), tot_loss_proj:3.453 [t=0.18s]
prediction: ['[CLS] convinced yes gary the to into dinner so convinced kitchen [SEP]']
[ 100/2000] tot_loss=2.920 (perp=12.942, rec=0.271, cos=0.061), tot_loss_proj:3.683 [t=0.18s]
prediction: ['[CLS] papa so vinnie the surely. rice louie convinced cooked [SEP]']
[ 150/2000] tot_loss=2.204 (perp=10.002, rec=0.179, cos=0.025), tot_loss_proj:2.819 [t=0.17s]
prediction: ['[CLS] john because to the when. rice andrew convinced cooked [SEP]']
[ 200/2000] tot_loss=2.179 (perp=10.002, rec=0.146, cos=0.032), tot_loss_proj:2.818 [t=0.17s]
prediction: ['[CLS] john because to the when. rice andrew convinced cooked [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.746 (perp=11.421, rec=0.385, cos=0.077), tot_loss_proj:3.403 [t=0.18s]
prediction: ['[CLS] john brown to the is cooked rice john convincedisha [SEP]']
[ 300/2000] tot_loss=2.394 (perp=10.613, rec=0.240, cos=0.031), tot_loss_proj:2.944 [t=0.17s]
prediction: ['[CLS] john but to the instead cooked rice john convinced plate [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.237 (perp=10.228, rec=0.173, cos=0.018), tot_loss_proj:3.479 [t=0.18s]
prediction: ['[CLS] john john to the rice be rice ( convinced plate [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.129 (perp=9.686, rec=0.160, cos=0.032), tot_loss_proj:3.168 [t=0.17s]
prediction: ['[CLS] john john to of the rice be rice ( convinced [SEP]']
[ 450/2000] tot_loss=2.073 (perp=9.686, rec=0.122, cos=0.014), tot_loss_proj:3.154 [t=0.17s]
prediction: ['[CLS] john john to of the rice be rice ( convinced [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.754 (perp=8.063, rec=0.129, cos=0.012), tot_loss_proj:2.711 [t=0.17s]
prediction: ['[CLS] john bill to cooked the rice of rice ( convinced [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.661 (perp=7.416, rec=0.151, cos=0.027), tot_loss_proj:2.259 [t=0.19s]
prediction: ['[CLS] john convinced jake to cooked the rice to rice ( [SEP]']
[ 600/2000] tot_loss=1.528 (perp=6.965, rec=0.122, cos=0.013), tot_loss_proj:2.174 [t=0.20s]
prediction: ['[CLS] john convinced john to be the rice and rice ( [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.428 (perp=6.491, rec=0.119, cos=0.011), tot_loss_proj:1.988 [t=0.21s]
prediction: ['[CLS] john convinced john to cooked the rice and rice " [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.493 (perp=6.814, rec=0.120, cos=0.010), tot_loss_proj:2.503 [t=0.19s]
prediction: ['[CLS] john convinced bill to cooked the rice and rice " [SEP]']
[ 750/2000] tot_loss=1.469 (perp=6.814, rec=0.097, cos=0.010), tot_loss_proj:2.508 [t=0.19s]
prediction: ['[CLS] john convinced bill to cooked the rice and rice " [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.490 (perp=6.814, rec=0.118, cos=0.009), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] john convinced bill to cooked the rice and rice " [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.479 (perp=6.814, rec=0.107, cos=0.009), tot_loss_proj:2.515 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice and rice " [SEP]']
[ 900/2000] tot_loss=1.649 (perp=7.622, rec=0.115, cos=0.009), tot_loss_proj:2.554 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice by rice " [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.567 (perp=7.290, rec=0.100, cos=0.009), tot_loss_proj:2.252 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
Attempt swap
[1000/2000] tot_loss=1.565 (perp=7.290, rec=0.099, cos=0.008), tot_loss_proj:2.262 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
[1050/2000] tot_loss=1.564 (perp=7.290, rec=0.098, cos=0.008), tot_loss_proj:2.262 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
Attempt swap
[1100/2000] tot_loss=1.562 (perp=7.290, rec=0.096, cos=0.008), tot_loss_proj:2.256 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
Attempt swap
[1150/2000] tot_loss=1.574 (perp=7.290, rec=0.108, cos=0.008), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
[1200/2000] tot_loss=1.571 (perp=7.290, rec=0.105, cos=0.008), tot_loss_proj:2.255 [t=0.17s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
Attempt swap
[1250/2000] tot_loss=1.561 (perp=7.290, rec=0.096, cos=0.008), tot_loss_proj:2.260 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
Attempt swap
[1300/2000] tot_loss=1.566 (perp=7.290, rec=0.101, cos=0.008), tot_loss_proj:2.265 [t=0.17s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
[1350/2000] tot_loss=1.562 (perp=7.290, rec=0.097, cos=0.008), tot_loss_proj:2.259 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
Attempt swap
[1400/2000] tot_loss=1.558 (perp=7.290, rec=0.092, cos=0.007), tot_loss_proj:2.266 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
Attempt swap
[1450/2000] tot_loss=1.566 (perp=7.290, rec=0.101, cos=0.007), tot_loss_proj:2.271 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
[1500/2000] tot_loss=1.553 (perp=7.290, rec=0.088, cos=0.007), tot_loss_proj:2.264 [t=0.17s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
Attempt swap
[1550/2000] tot_loss=1.549 (perp=7.290, rec=0.084, cos=0.007), tot_loss_proj:2.266 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
Attempt swap
[1600/2000] tot_loss=1.568 (perp=7.290, rec=0.103, cos=0.007), tot_loss_proj:2.269 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice " by rice [SEP]']
[1650/2000] tot_loss=1.740 (perp=8.190, rec=0.095, cos=0.007), tot_loss_proj:2.387 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice with by rice [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.559 (perp=7.318, rec=0.088, cos=0.008), tot_loss_proj:2.506 [t=0.20s]
prediction: ['[CLS] john convinced bill to cooked the rice with rice by [SEP]']
Attempt swap
[1750/2000] tot_loss=1.555 (perp=7.318, rec=0.084, cos=0.008), tot_loss_proj:2.507 [t=0.25s]
prediction: ['[CLS] john convinced bill to cooked the rice with rice by [SEP]']
[1800/2000] tot_loss=1.560 (perp=7.318, rec=0.089, cos=0.007), tot_loss_proj:2.513 [t=0.20s]
prediction: ['[CLS] john convinced bill to cooked the rice with rice by [SEP]']
Attempt swap
[1850/2000] tot_loss=1.570 (perp=7.318, rec=0.099, cos=0.007), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] john convinced bill to cooked the rice with rice by [SEP]']
Attempt swap
[1900/2000] tot_loss=1.570 (perp=7.318, rec=0.099, cos=0.007), tot_loss_proj:2.510 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice with rice by [SEP]']
[1950/2000] tot_loss=1.778 (perp=8.322, rec=0.106, cos=0.007), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked the rice with cooked by [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.619 (perp=7.582, rec=0.095, cos=0.007), tot_loss_proj:2.230 [t=0.18s]
prediction: ['[CLS] john convinced bill to cooked with the rice cooked by [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] john convinced the rice to be cooked by bill. [SEP]
========================
predicted: 
========================
[CLS] john convinced bill to cooked the rice " by rice [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 120.909

[Aggregate metrics]:
rouge1     | fm: 77.424 | p: 77.366 | r: 77.687
rouge2     | fm: 37.020 | p: 36.858 | r: 37.391
rougeL     | fm: 66.423 | p: 66.530 | r: 66.626
rougeLsum  | fm: 66.461 | p: 66.524 | r: 66.628
r1fm+r2fm = 114.444

input #68 time: 0:07:33 | total time: 9:32:21


Running input #69 of 100.
reference: 
========================
The squirrel ran straight quickly.
========================
average of cosine similarity 0.9993800710871901
highest_index [0]
highest [0.9993800710871901]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 18197,  2743,  3442,  2855,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the squirrel ran straight quickly. [SEP]']
[Init] best rec loss: 0.7449679970741272 for ['[CLS] theme skin alive won reach one [SEP]']
[Init] best rec loss: 0.7045864462852478 for ['[CLS] action ou defenceiom unto violence [SEP]']
[Init] best rec loss: 0.6891953349113464 for ['[CLS] pry material lay steadywled surveyor [SEP]']
[Init] best rec loss: 0.684439480304718 for ['[CLS]ango pieces wal ar upon bound [SEP]']
[Init] best rec loss: 0.6838079690933228 for ['[CLS] on years magazine belong eugen wah [SEP]']
[Init] best rec loss: 0.6556761860847473 for ['[CLS] brief forgetlyhawks husbandch [SEP]']
[Init] best perm rec loss: 0.6538225412368774 for ['[CLS] brieftlyhawks husband forgech [SEP]']
[Init] best perm rec loss: 0.6537908911705017 for ['[CLS]chtly briefhawks forge husband [SEP]']
[Init] best perm rec loss: 0.6512235999107361 for ['[CLS] briefhawks husband forgetlych [SEP]']
[Init] best perm rec loss: 0.6494418382644653 for ['[CLS] brieftly forgehawks husbandch [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.456 (perp=10.216, rec=0.330, cos=0.083), tot_loss_proj:2.863 [t=0.19s]
prediction: ['[CLS] went straight during guard had straight [SEP]']
[ 100/2000] tot_loss=2.426 (perp=8.980, rec=0.533, cos=0.096), tot_loss_proj:2.634 [t=0.21s]
prediction: ['[CLS] followed quickly was and then straight [SEP]']
[ 150/2000] tot_loss=2.391 (perp=9.946, rec=0.347, cos=0.055), tot_loss_proj:3.025 [t=0.19s]
prediction: ['[CLS] quickly quickly ran ( followed straight [SEP]']
[ 200/2000] tot_loss=1.980 (perp=8.537, rec=0.239, cos=0.033), tot_loss_proj:2.541 [t=0.19s]
prediction: ['[CLS] straight quickly ran quickly either straight [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.890 (perp=8.384, rec=0.189, cos=0.023), tot_loss_proj:2.597 [t=0.17s]
prediction: ['[CLS] quickly ran straight quickly straight straight [SEP]']
[ 300/2000] tot_loss=1.829 (perp=8.304, rec=0.149, cos=0.019), tot_loss_proj:2.524 [t=0.18s]
prediction: ['[CLS] quickly ran straight quickly ran straight [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.819 (perp=8.304, rec=0.144, cos=0.014), tot_loss_proj:2.516 [t=0.18s]
prediction: ['[CLS] quickly ran straight quickly ran straight [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.093 (perp=9.795, rec=0.122, cos=0.013), tot_loss_proj:2.873 [t=0.17s]
prediction: ['[CLS] squirrel quickly straight quickly ran straight [SEP]']
[ 450/2000] tot_loss=2.094 (perp=9.795, rec=0.126, cos=0.009), tot_loss_proj:2.879 [t=0.17s]
prediction: ['[CLS] squirrel quickly straight quickly ran straight [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.950 (perp=9.174, rec=0.106, cos=0.008), tot_loss_proj:2.482 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.953 (perp=9.174, rec=0.111, cos=0.007), tot_loss_proj:2.483 [t=0.20s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
[ 600/2000] tot_loss=1.956 (perp=9.174, rec=0.115, cos=0.007), tot_loss_proj:2.491 [t=0.19s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.938 (perp=9.174, rec=0.097, cos=0.006), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.954 (perp=9.174, rec=0.113, cos=0.006), tot_loss_proj:2.503 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
[ 750/2000] tot_loss=1.934 (perp=9.174, rec=0.093, cos=0.006), tot_loss_proj:2.503 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.940 (perp=9.174, rec=0.099, cos=0.006), tot_loss_proj:2.497 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.936 (perp=9.174, rec=0.095, cos=0.006), tot_loss_proj:2.504 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
[ 900/2000] tot_loss=1.941 (perp=9.174, rec=0.100, cos=0.006), tot_loss_proj:2.511 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.942 (perp=9.174, rec=0.101, cos=0.006), tot_loss_proj:2.505 [t=0.19s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[1000/2000] tot_loss=2.131 (perp=10.082, rec=0.109, cos=0.006), tot_loss_proj:2.843 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1050/2000] tot_loss=2.115 (perp=10.082, rec=0.092, cos=0.006), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1100/2000] tot_loss=2.116 (perp=10.082, rec=0.093, cos=0.006), tot_loss_proj:2.850 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1150/2000] tot_loss=2.119 (perp=10.082, rec=0.096, cos=0.006), tot_loss_proj:2.842 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1200/2000] tot_loss=2.124 (perp=10.082, rec=0.101, cos=0.006), tot_loss_proj:2.854 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1250/2000] tot_loss=2.116 (perp=10.082, rec=0.094, cos=0.006), tot_loss_proj:2.845 [t=0.19s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1300/2000] tot_loss=2.117 (perp=10.082, rec=0.095, cos=0.006), tot_loss_proj:2.841 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1350/2000] tot_loss=2.112 (perp=10.082, rec=0.089, cos=0.006), tot_loss_proj:2.852 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1400/2000] tot_loss=2.108 (perp=10.082, rec=0.085, cos=0.006), tot_loss_proj:2.845 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1450/2000] tot_loss=2.116 (perp=10.082, rec=0.094, cos=0.006), tot_loss_proj:2.850 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1500/2000] tot_loss=2.121 (perp=10.082, rec=0.098, cos=0.006), tot_loss_proj:2.852 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1550/2000] tot_loss=2.101 (perp=10.082, rec=0.078, cos=0.006), tot_loss_proj:2.845 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1600/2000] tot_loss=2.124 (perp=10.082, rec=0.102, cos=0.006), tot_loss_proj:2.842 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1650/2000] tot_loss=2.112 (perp=10.082, rec=0.089, cos=0.006), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1700/2000] tot_loss=2.128 (perp=10.082, rec=0.106, cos=0.006), tot_loss_proj:2.849 [t=0.19s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1750/2000] tot_loss=2.113 (perp=10.082, rec=0.090, cos=0.006), tot_loss_proj:2.846 [t=0.23s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1800/2000] tot_loss=2.113 (perp=10.082, rec=0.090, cos=0.006), tot_loss_proj:2.851 [t=0.20s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1850/2000] tot_loss=2.109 (perp=10.082, rec=0.087, cos=0.006), tot_loss_proj:2.848 [t=0.20s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1900/2000] tot_loss=2.123 (perp=10.082, rec=0.100, cos=0.006), tot_loss_proj:2.853 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1950/2000] tot_loss=2.125 (perp=10.082, rec=0.103, cos=0.006), tot_loss_proj:2.849 [t=0.18s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[2000/2000] tot_loss=2.117 (perp=10.082, rec=0.094, cos=0.006), tot_loss_proj:2.848 [t=0.19s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] the squirrel ran straight quickly. [SEP]
========================
predicted: 
========================
[CLS] squirrel quickly ran straight quickly good [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 30.769 | p: 28.571 | r: 33.333
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 110.769

[Aggregate metrics]:
rouge1     | fm: 77.351 | p: 77.305 | r: 77.727
rouge2     | fm: 36.950 | p: 36.720 | r: 37.246
rougeL     | fm: 66.770 | p: 66.800 | r: 66.977
rougeLsum  | fm: 66.607 | p: 66.585 | r: 66.906
r1fm+r2fm = 114.301

input #69 time: 0:07:27 | total time: 9:39:49


Running input #70 of 100.
reference: 
========================
I assumed to be innocent
========================
average of cosine similarity 0.9993176562362931
highest_index [0]
highest [0.9993176562362931]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 5071, 2000, 2022, 7036,  102]], device='cuda:0')
Debug: ref = ['[CLS] i assumed to be innocent [SEP]']
[Init] best rec loss: 0.7952191829681396 for ['[CLS] down op epithet medicine sick [SEP]']
[Init] best rec loss: 0.7703707814216614 for ['[CLS] small beings equation flightfall [SEP]']
[Init] best rec loss: 0.7321346402168274 for ['[CLS] allied breath road revelation airport [SEP]']
[Init] best rec loss: 0.728435754776001 for ['[CLS] [ across not inside stuff [SEP]']
[Init] best rec loss: 0.7198368906974792 for ['[CLS] breeding overseas signature activated points [SEP]']
[Init] best rec loss: 0.7161601781845093 for ['[CLS] honors protocolgne trackshis [SEP]']
[Init] best rec loss: 0.7038858532905579 for ['[CLS] oh kept middle pen opener [SEP]']
[Init] best perm rec loss: 0.7016999125480652 for ['[CLS] middle oh kept opener pen [SEP]']
[Init] best perm rec loss: 0.6995460987091064 for ['[CLS] pen opener kept middle oh [SEP]']
[Init] best perm rec loss: 0.6993598937988281 for ['[CLS] pen opener oh kept middle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.784 (perp=11.636, rec=0.403, cos=0.053), tot_loss_proj:3.640 [t=0.19s]
prediction: ["[CLS] proof assumed'descendants red [SEP]"]
[ 100/2000] tot_loss=2.266 (perp=9.021, rec=0.406, cos=0.056), tot_loss_proj:2.547 [t=0.19s]
prediction: ['[CLS] certificate assumed and was genuine [SEP]']
[ 150/2000] tot_loss=2.171 (perp=9.688, rec=0.212, cos=0.022), tot_loss_proj:3.039 [t=0.21s]
prediction: ['[CLS] assumed assumed, be innocent [SEP]']
[ 200/2000] tot_loss=1.417 (perp=6.470, rec=0.119, cos=0.005), tot_loss_proj:1.499 [t=0.19s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.381 (perp=6.470, rec=0.086, cos=0.002), tot_loss_proj:1.500 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 300/2000] tot_loss=1.365 (perp=6.470, rec=0.069, cos=0.001), tot_loss_proj:1.501 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.365 (perp=6.470, rec=0.070, cos=0.001), tot_loss_proj:1.496 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.359 (perp=6.470, rec=0.064, cos=0.001), tot_loss_proj:1.499 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 450/2000] tot_loss=1.356 (perp=6.470, rec=0.061, cos=0.001), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.359 (perp=6.470, rec=0.063, cos=0.001), tot_loss_proj:1.498 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.365 (perp=6.470, rec=0.069, cos=0.001), tot_loss_proj:1.492 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 600/2000] tot_loss=1.373 (perp=6.470, rec=0.078, cos=0.001), tot_loss_proj:1.483 [t=0.21s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.348 (perp=6.470, rec=0.053, cos=0.001), tot_loss_proj:1.492 [t=0.19s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.358 (perp=6.470, rec=0.063, cos=0.001), tot_loss_proj:1.487 [t=0.20s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 750/2000] tot_loss=1.359 (perp=6.470, rec=0.063, cos=0.001), tot_loss_proj:1.489 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.354 (perp=6.470, rec=0.059, cos=0.001), tot_loss_proj:1.488 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.359 (perp=6.470, rec=0.063, cos=0.001), tot_loss_proj:1.481 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 900/2000] tot_loss=1.347 (perp=6.470, rec=0.052, cos=0.001), tot_loss_proj:1.479 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.345 (perp=6.470, rec=0.050, cos=0.001), tot_loss_proj:1.481 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.363 (perp=6.470, rec=0.068, cos=0.001), tot_loss_proj:1.475 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1050/2000] tot_loss=1.366 (perp=6.470, rec=0.071, cos=0.001), tot_loss_proj:1.478 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.359 (perp=6.470, rec=0.064, cos=0.001), tot_loss_proj:1.473 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.354 (perp=6.470, rec=0.059, cos=0.001), tot_loss_proj:1.471 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1200/2000] tot_loss=1.356 (perp=6.470, rec=0.061, cos=0.001), tot_loss_proj:1.472 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.346 (perp=6.470, rec=0.051, cos=0.001), tot_loss_proj:1.480 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.356 (perp=6.470, rec=0.061, cos=0.001), tot_loss_proj:1.478 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1350/2000] tot_loss=1.366 (perp=6.470, rec=0.071, cos=0.001), tot_loss_proj:1.478 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.361 (perp=6.470, rec=0.066, cos=0.001), tot_loss_proj:1.474 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.349 (perp=6.470, rec=0.053, cos=0.001), tot_loss_proj:1.482 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1500/2000] tot_loss=1.359 (perp=6.470, rec=0.064, cos=0.001), tot_loss_proj:1.471 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.363 (perp=6.470, rec=0.068, cos=0.001), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.356 (perp=6.470, rec=0.060, cos=0.001), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1650/2000] tot_loss=1.357 (perp=6.470, rec=0.062, cos=0.001), tot_loss_proj:1.472 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.360 (perp=6.470, rec=0.064, cos=0.001), tot_loss_proj:1.482 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.360 (perp=6.470, rec=0.065, cos=0.001), tot_loss_proj:1.473 [t=0.21s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1800/2000] tot_loss=1.340 (perp=6.470, rec=0.045, cos=0.001), tot_loss_proj:1.471 [t=0.23s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.353 (perp=6.470, rec=0.057, cos=0.001), tot_loss_proj:1.455 [t=0.20s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.359 (perp=6.470, rec=0.063, cos=0.001), tot_loss_proj:1.476 [t=0.25s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1950/2000] tot_loss=1.351 (perp=6.470, rec=0.056, cos=0.001), tot_loss_proj:1.484 [t=0.21s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.359 (perp=6.470, rec=0.064, cos=0.001), tot_loss_proj:1.471 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] i assumed to be innocent [SEP]
========================
predicted: 
========================
[CLS] i assumed to be innocent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 77.705 | p: 77.708 | r: 78.058
rouge2     | fm: 37.776 | p: 37.593 | r: 38.093
rougeL     | fm: 67.156 | p: 67.123 | r: 67.436
rougeLsum  | fm: 67.059 | p: 67.038 | r: 67.342
r1fm+r2fm = 115.481

input #70 time: 0:07:30 | total time: 9:47:19


Running input #71 of 100.
reference: 
========================
He could not have been working.
========================
average of cosine similarity 0.9994072032581217
highest_index [0]
highest [0.9994072032581217]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2071, 2025, 2031, 2042, 2551, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he could not have been working. [SEP]']
[Init] best rec loss: 0.9744415879249573 for ['[CLS] winston q officer obedience maize creamkha [SEP]']
[Init] best rec loss: 0.9726535677909851 for ['[CLS] [CLS] holt mls urgent we hey following [SEP]']
[Init] best rec loss: 0.9473275542259216 for ['[CLS] source outside fairias bullet tyson accepted [SEP]']
[Init] best rec loss: 0.9002900719642639 for ['[CLS] production gojn species leaderern led [SEP]']
[Init] best rec loss: 0.8908352255821228 for ['[CLS] sykested abbey rhodesonia ne air [SEP]']
[Init] best rec loss: 0.8839952945709229 for ['[CLS] or led olympic fish pe studiespeed [SEP]']
[Init] best rec loss: 0.880422055721283 for ['[CLS] vincent families ass factoryper inhabited heaven [SEP]']
[Init] best rec loss: 0.8727516531944275 for ['[CLS] helpayaion gun quartersrdatitles [SEP]']
[Init] best rec loss: 0.8656829595565796 for ['[CLS] justice liner contra godizes sin colt [SEP]']
[Init] best rec loss: 0.8539422154426575 for ['[CLS] territory dale sienna yao aggregator see mother [SEP]']
[Init] best perm rec loss: 0.853902280330658 for ['[CLS] see dale aggregator sienna territory mother yao [SEP]']
[Init] best perm rec loss: 0.8496488928794861 for ['[CLS] aggregator see dale sienna mother territory yao [SEP]']
[Init] best perm rec loss: 0.8492418527603149 for ['[CLS] see sienna dale territory yao aggregator mother [SEP]']
[Init] best perm rec loss: 0.8487892150878906 for ['[CLS] see dale territory sienna mother aggregator yao [SEP]']
[Init] best perm rec loss: 0.846971869468689 for ['[CLS] sienna dale mother see yao aggregator territory [SEP]']
[Init] best perm rec loss: 0.8467850089073181 for ['[CLS] see territory dale yao mother aggregator sienna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.336 (perp=8.605, rec=0.616, cos=0.999), tot_loss_proj:3.614 [t=0.17s]
prediction: ['[CLS]? territory.. she among stars [SEP]']
[ 100/2000] tot_loss=2.326 (perp=9.545, rec=0.314, cos=0.103), tot_loss_proj:3.717 [t=0.18s]
prediction: ['[CLS] could working.. he owned working [SEP]']
[ 150/2000] tot_loss=1.877 (perp=8.357, rec=0.176, cos=0.030), tot_loss_proj:3.512 [t=0.22s]
prediction: ['[CLS] could working.. he been working [SEP]']
[ 200/2000] tot_loss=1.833 (perp=8.357, rec=0.145, cos=0.016), tot_loss_proj:3.511 [t=0.21s]
prediction: ['[CLS] could working.. he been working [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.744 (perp=7.758, rec=0.165, cos=0.028), tot_loss_proj:3.489 [t=0.20s]
prediction: ['[CLS] could future ; he been working. [SEP]']
[ 300/2000] tot_loss=1.665 (perp=7.637, rec=0.122, cos=0.016), tot_loss_proj:3.349 [t=0.19s]
prediction: ['[CLS] could new. he been working. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.741 (perp=8.052, rec=0.117, cos=0.014), tot_loss_proj:3.461 [t=0.20s]
prediction: ['[CLS] he could sorry. have working. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.945 (perp=6.790, rec=0.589, cos=0.999), tot_loss_proj:3.432 [t=0.24s]
prediction: ['[CLS] he could have. earlier working. [SEP]']
[ 450/2000] tot_loss=2.778 (perp=6.790, rec=0.424, cos=0.996), tot_loss_proj:3.360 [t=0.18s]
prediction: ['[CLS] he could have. earlier working. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.661 (perp=6.468, rec=0.376, cos=0.992), tot_loss_proj:3.288 [t=0.21s]
prediction: ['[CLS] he could have earlier. working. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.090 (perp=8.820, rec=0.344, cos=0.981), tot_loss_proj:3.635 [t=0.20s]
prediction: ['[CLS] he could have whenever tray working. [SEP]']
[ 600/2000] tot_loss=3.046 (perp=8.820, rec=0.308, cos=0.974), tot_loss_proj:3.633 [t=0.20s]
prediction: ['[CLS] he could have whenever tray working. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.828 (perp=7.803, rec=0.301, cos=0.966), tot_loss_proj:3.478 [t=0.22s]
prediction: ['[CLS] he could have tray earthquake working. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.814 (perp=7.803, rec=0.294, cos=0.959), tot_loss_proj:3.476 [t=0.20s]
prediction: ['[CLS] he could have tray earthquake working. [SEP]']
[ 750/2000] tot_loss=2.793 (perp=7.803, rec=0.280, cos=0.953), tot_loss_proj:3.475 [t=0.19s]
prediction: ['[CLS] he could have tray earthquake working. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.792 (perp=7.803, rec=0.284, cos=0.947), tot_loss_proj:3.474 [t=0.22s]
prediction: ['[CLS] he could have tray earthquake working. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.783 (perp=7.803, rec=0.279, cos=0.943), tot_loss_proj:3.472 [t=0.18s]
prediction: ['[CLS] he could have tray earthquake working. [SEP]']
[ 900/2000] tot_loss=2.866 (perp=8.220, rec=0.282, cos=0.941), tot_loss_proj:3.655 [t=0.17s]
prediction: ['[CLS] he could have graeme earthquake working. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.097 (perp=9.412, rec=0.275, cos=0.940), tot_loss_proj:3.933 [t=0.22s]
prediction: ['[CLS] he could havetma graeme working. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.870 (perp=8.270, rec=0.277, cos=0.939), tot_loss_proj:3.696 [t=0.18s]
prediction: ['[CLS] he could have graeme whenever working. [SEP]']
[1050/2000] tot_loss=2.834 (perp=8.145, rec=0.267, cos=0.937), tot_loss_proj:3.712 [t=0.25s]
prediction: ['[CLS] he could have graeme declared working. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.739 (perp=7.682, rec=0.265, cos=0.937), tot_loss_proj:3.463 [t=0.17s]
prediction: ['[CLS] he could have declared graeme working. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.623 (perp=7.125, rec=0.261, cos=0.937), tot_loss_proj:3.355 [t=0.21s]
prediction: ['[CLS] he could have declared richard working. [SEP]']
[1200/2000] tot_loss=2.619 (perp=7.125, rec=0.257, cos=0.937), tot_loss_proj:3.358 [t=0.18s]
prediction: ['[CLS] he could have declared richard working. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.888 (perp=8.353, rec=0.280, cos=0.937), tot_loss_proj:3.541 [t=0.17s]
prediction: ['[CLS] he could have whenever working richard. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.681 (perp=7.360, rec=0.269, cos=0.940), tot_loss_proj:3.371 [t=0.18s]
prediction: ['[CLS] he could have working whenever richard. [SEP]']
[1350/2000] tot_loss=2.676 (perp=7.360, rec=0.267, cos=0.937), tot_loss_proj:3.375 [t=0.21s]
prediction: ['[CLS] he could have working whenever richard. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.663 (perp=7.360, rec=0.255, cos=0.936), tot_loss_proj:3.373 [t=0.19s]
prediction: ['[CLS] he could have working whenever richard. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.673 (perp=7.360, rec=0.265, cos=0.936), tot_loss_proj:3.373 [t=0.24s]
prediction: ['[CLS] he could have working whenever richard. [SEP]']
[1500/2000] tot_loss=2.806 (perp=8.045, rec=0.261, cos=0.936), tot_loss_proj:3.479 [t=0.18s]
prediction: ['[CLS] he could have working declared richard. [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=2.549 (perp=6.725, rec=0.266, cos=0.938), tot_loss_proj:3.223 [t=0.21s]
prediction: ['[CLS] he could have declared working richard. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.549 (perp=6.725, rec=0.269, cos=0.936), tot_loss_proj:3.223 [t=0.18s]
prediction: ['[CLS] he could have declared working richard. [SEP]']
[1650/2000] tot_loss=2.546 (perp=6.725, rec=0.265, cos=0.936), tot_loss_proj:3.222 [t=0.21s]
prediction: ['[CLS] he could have declared working richard. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.546 (perp=6.725, rec=0.265, cos=0.936), tot_loss_proj:3.227 [t=0.21s]
prediction: ['[CLS] he could have declared working richard. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.546 (perp=6.725, rec=0.265, cos=0.936), tot_loss_proj:3.217 [t=0.22s]
prediction: ['[CLS] he could have declared working richard. [SEP]']
[1800/2000] tot_loss=2.543 (perp=6.725, rec=0.262, cos=0.936), tot_loss_proj:3.219 [t=0.22s]
prediction: ['[CLS] he could have declared working richard. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.542 (perp=6.725, rec=0.261, cos=0.936), tot_loss_proj:3.225 [t=0.21s]
prediction: ['[CLS] he could have declared working richard. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.535 (perp=6.725, rec=0.255, cos=0.936), tot_loss_proj:3.223 [t=0.18s]
prediction: ['[CLS] he could have declared working richard. [SEP]']
[1950/2000] tot_loss=2.543 (perp=6.725, rec=0.262, cos=0.936), tot_loss_proj:3.225 [t=0.18s]
prediction: ['[CLS] he could have declared working richard. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.546 (perp=6.725, rec=0.265, cos=0.936), tot_loss_proj:3.224 [t=0.20s]
prediction: ['[CLS] he could have declared working richard. [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] he could not have been working. [SEP]
========================
predicted: 
========================
[CLS] he could sorry. have working. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 85.714 | r: 75.000
rouge2     | fm: 46.154 | p: 50.000 | r: 42.857
rougeL     | fm: 80.000 | p: 85.714 | r: 75.000
rougeLsum  | fm: 80.000 | p: 85.714 | r: 75.000
r1fm+r2fm = 126.154

[Aggregate metrics]:
rouge1     | fm: 77.737 | p: 77.747 | r: 78.041
rouge2     | fm: 37.855 | p: 37.771 | r: 38.156
rougeL     | fm: 67.329 | p: 67.371 | r: 67.516
rougeLsum  | fm: 67.310 | p: 67.346 | r: 67.473
r1fm+r2fm = 115.592

input #71 time: 0:07:49 | total time: 9:55:09


Running input #72 of 100.
reference: 
========================
He goes.
========================
average of cosine similarity 0.9991964877569265
highest_index [0]
highest [0.9991964877569265]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 2002, 3632, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he goes. [SEP]']
[Init] best rec loss: 0.9233094453811646 for ['[CLS] prior keynes latter [SEP]']
[Init] best rec loss: 0.8991621136665344 for ['[CLS] diver prism theme [SEP]']
[Init] best rec loss: 0.8955864310264587 for ['[CLS] bbc coat coin [SEP]']
[Init] best rec loss: 0.8779672980308533 for ['[CLS] gets handsome fever [SEP]']
[Init] best rec loss: 0.8525456190109253 for ['[CLS]cat soldina [SEP]']
[Init] best rec loss: 0.8413464426994324 for ['[CLS] shouldn might wight [SEP]']
[Init] best perm rec loss: 0.8409014940261841 for ['[CLS] might wight shouldn [SEP]']
[Init] best perm rec loss: 0.8379490971565247 for ['[CLS] shouldn wight might [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.772 (perp=12.190, rec=0.286, cos=0.048), tot_loss_proj:4.301 [t=0.18s]
prediction: ['[CLS] went went might [SEP]']
[ 100/2000] tot_loss=1.170 (perp=5.241, rec=0.110, cos=0.012), tot_loss_proj:1.228 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
[ 150/2000] tot_loss=1.148 (perp=5.241, rec=0.092, cos=0.009), tot_loss_proj:1.238 [t=0.22s]
prediction: ['[CLS] he goes. [SEP]']
[ 200/2000] tot_loss=1.150 (perp=5.241, rec=0.092, cos=0.010), tot_loss_proj:1.233 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.151 (perp=5.241, rec=0.096, cos=0.007), tot_loss_proj:1.219 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
[ 300/2000] tot_loss=1.144 (perp=5.241, rec=0.090, cos=0.006), tot_loss_proj:1.225 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.141 (perp=5.241, rec=0.087, cos=0.006), tot_loss_proj:1.221 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.139 (perp=5.241, rec=0.085, cos=0.006), tot_loss_proj:1.219 [t=0.20s]
prediction: ['[CLS] he goes. [SEP]']
[ 450/2000] tot_loss=1.122 (perp=5.241, rec=0.068, cos=0.006), tot_loss_proj:1.224 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.122 (perp=5.241, rec=0.068, cos=0.006), tot_loss_proj:1.223 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.115 (perp=5.241, rec=0.061, cos=0.006), tot_loss_proj:1.223 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
[ 600/2000] tot_loss=1.125 (perp=5.241, rec=0.071, cos=0.006), tot_loss_proj:1.222 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.135 (perp=5.241, rec=0.080, cos=0.006), tot_loss_proj:1.229 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.127 (perp=5.241, rec=0.073, cos=0.006), tot_loss_proj:1.218 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
[ 750/2000] tot_loss=1.121 (perp=5.241, rec=0.067, cos=0.006), tot_loss_proj:1.215 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.130 (perp=5.241, rec=0.076, cos=0.006), tot_loss_proj:1.227 [t=0.20s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.133 (perp=5.241, rec=0.079, cos=0.006), tot_loss_proj:1.228 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
[ 900/2000] tot_loss=1.130 (perp=5.241, rec=0.075, cos=0.006), tot_loss_proj:1.223 [t=0.20s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.136 (perp=5.241, rec=0.082, cos=0.006), tot_loss_proj:1.233 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.124 (perp=5.241, rec=0.070, cos=0.006), tot_loss_proj:1.228 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
[1050/2000] tot_loss=1.134 (perp=5.241, rec=0.080, cos=0.006), tot_loss_proj:1.233 [t=0.21s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.123 (perp=5.241, rec=0.069, cos=0.006), tot_loss_proj:1.225 [t=0.20s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.131 (perp=5.241, rec=0.077, cos=0.006), tot_loss_proj:1.218 [t=0.21s]
prediction: ['[CLS] he goes. [SEP]']
[1200/2000] tot_loss=1.127 (perp=5.241, rec=0.073, cos=0.006), tot_loss_proj:1.233 [t=0.21s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.132 (perp=5.241, rec=0.078, cos=0.006), tot_loss_proj:1.227 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.132 (perp=5.241, rec=0.078, cos=0.006), tot_loss_proj:1.240 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1350/2000] tot_loss=1.133 (perp=5.241, rec=0.078, cos=0.006), tot_loss_proj:1.230 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.122 (perp=5.241, rec=0.068, cos=0.006), tot_loss_proj:1.231 [t=0.20s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.131 (perp=5.241, rec=0.076, cos=0.006), tot_loss_proj:1.224 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1500/2000] tot_loss=1.135 (perp=5.241, rec=0.081, cos=0.006), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.131 (perp=5.241, rec=0.077, cos=0.006), tot_loss_proj:1.228 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.128 (perp=5.241, rec=0.074, cos=0.006), tot_loss_proj:1.235 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
[1650/2000] tot_loss=1.133 (perp=5.241, rec=0.079, cos=0.006), tot_loss_proj:1.233 [t=0.21s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.129 (perp=5.241, rec=0.075, cos=0.006), tot_loss_proj:1.238 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.131 (perp=5.241, rec=0.077, cos=0.006), tot_loss_proj:1.239 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
[1800/2000] tot_loss=1.118 (perp=5.241, rec=0.064, cos=0.006), tot_loss_proj:1.231 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.130 (perp=5.241, rec=0.076, cos=0.006), tot_loss_proj:1.226 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.131 (perp=5.241, rec=0.076, cos=0.006), tot_loss_proj:1.232 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
[1950/2000] tot_loss=1.138 (perp=5.241, rec=0.083, cos=0.006), tot_loss_proj:1.241 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.127 (perp=5.241, rec=0.073, cos=0.006), tot_loss_proj:1.230 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] he goes. [SEP]
========================
predicted: 
========================
[CLS] he goes. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 78.062 | p: 78.040 | r: 78.321
rouge2     | fm: 38.782 | p: 38.607 | r: 39.016
rougeL     | fm: 67.801 | p: 67.868 | r: 68.010
rougeLsum  | fm: 67.666 | p: 67.753 | r: 67.861
r1fm+r2fm = 116.845

input #72 time: 0:07:30 | total time: 10:02:39


Running input #73 of 100.
reference: 
========================
This machine records well.
========================
average of cosine similarity 0.9994617040871804
highest_index [0]
highest [0.9994617040871804]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2023, 3698, 2636, 2092, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] this machine records well. [SEP]']
[Init] best rec loss: 0.8837974071502686 for ['[CLS] miss violet chord parole tempo [SEP]']
[Init] best rec loss: 0.871936559677124 for ['[CLS]dilly records fortune instituteberry [SEP]']
[Init] best rec loss: 0.8340340852737427 for ['[CLS] guest brushed news pursuing church [SEP]']
[Init] best perm rec loss: 0.8322038054466248 for ['[CLS] brushed news church pursuing guest [SEP]']
[Init] best perm rec loss: 0.8311283588409424 for ['[CLS] brushed news guest pursuing church [SEP]']
[Init] best perm rec loss: 0.8308789730072021 for ['[CLS] brushed news pursuing guest church [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.354 (perp=9.408, rec=0.553, cos=0.920), tot_loss_proj:3.871 [t=0.20s]
prediction: ['[CLS]. which somewhere? debris [SEP]']
[ 100/2000] tot_loss=3.129 (perp=8.688, rec=0.474, cos=0.918), tot_loss_proj:3.773 [t=0.26s]
prediction: ['[CLS]. which quite? records [SEP]']
[ 150/2000] tot_loss=2.871 (perp=7.661, rec=0.440, cos=0.899), tot_loss_proj:3.574 [t=0.19s]
prediction: ['[CLS]. which machine. records [SEP]']
[ 200/2000] tot_loss=3.064 (perp=8.768, rec=0.412, cos=0.899), tot_loss_proj:3.811 [t=0.24s]
prediction: ['[CLS] this which machine. records [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.188 (perp=7.801, rec=0.653, cos=0.975), tot_loss_proj:3.591 [t=0.20s]
prediction: ['[CLS]. records described. records [SEP]']
[ 300/2000] tot_loss=3.174 (perp=8.543, rec=0.512, cos=0.954), tot_loss_proj:3.784 [t=0.23s]
prediction: ['[CLS] of records genus. records [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=3.107 (perp=8.465, rec=0.481, cos=0.933), tot_loss_proj:3.647 [t=0.19s]
prediction: ['[CLS] records this records certainly. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.768 (perp=6.928, rec=0.456, cos=0.926), tot_loss_proj:2.491 [t=0.18s]
prediction: ['[CLS] this machine certainly records. [SEP]']
[ 450/2000] tot_loss=2.731 (perp=6.928, rec=0.428, cos=0.917), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] this machine certainly records. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.585 (perp=6.290, rec=0.421, cos=0.906), tot_loss_proj:2.795 [t=0.17s]
prediction: ['[CLS] this machine certainly.. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.583 (perp=6.386, rec=0.405, cos=0.901), tot_loss_proj:2.960 [t=0.18s]
prediction: ['[CLS] this machine indeed.. [SEP]']
[ 600/2000] tot_loss=2.566 (perp=6.386, rec=0.396, cos=0.892), tot_loss_proj:2.961 [t=0.18s]
prediction: ['[CLS] this machine indeed.. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.566 (perp=6.386, rec=0.395, cos=0.894), tot_loss_proj:2.968 [t=0.19s]
prediction: ['[CLS] this machine indeed.. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.625 (perp=6.749, rec=0.382, cos=0.893), tot_loss_proj:3.404 [t=0.20s]
prediction: ['[CLS] this machine considered.. [SEP]']
[ 750/2000] tot_loss=2.621 (perp=6.749, rec=0.382, cos=0.889), tot_loss_proj:3.395 [t=0.19s]
prediction: ['[CLS] this machine considered.. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.609 (perp=6.749, rec=0.371, cos=0.888), tot_loss_proj:3.401 [t=0.25s]
prediction: ['[CLS] this machine considered.. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.619 (perp=6.749, rec=0.383, cos=0.887), tot_loss_proj:3.400 [t=0.20s]
prediction: ['[CLS] this machine considered.. [SEP]']
[ 900/2000] tot_loss=2.600 (perp=6.749, rec=0.366, cos=0.884), tot_loss_proj:3.401 [t=0.22s]
prediction: ['[CLS] this machine considered.. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.613 (perp=6.749, rec=0.382, cos=0.881), tot_loss_proj:3.405 [t=0.17s]
prediction: ['[CLS] this machine considered.. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.827 (perp=7.824, rec=0.379, cos=0.883), tot_loss_proj:3.580 [t=0.18s]
prediction: ['[CLS] this machine according.. [SEP]']
[1050/2000] tot_loss=2.809 (perp=7.824, rec=0.363, cos=0.881), tot_loss_proj:3.577 [t=0.18s]
prediction: ['[CLS] this machine according.. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.810 (perp=7.824, rec=0.367, cos=0.879), tot_loss_proj:3.580 [t=0.18s]
prediction: ['[CLS] this machine according.. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.812 (perp=7.824, rec=0.368, cos=0.880), tot_loss_proj:3.580 [t=0.18s]
prediction: ['[CLS] this machine according.. [SEP]']
[1200/2000] tot_loss=2.811 (perp=7.824, rec=0.369, cos=0.878), tot_loss_proj:3.576 [t=0.18s]
prediction: ['[CLS] this machine according.. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.809 (perp=7.824, rec=0.367, cos=0.877), tot_loss_proj:3.577 [t=0.18s]
prediction: ['[CLS] this machine according.. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.807 (perp=7.824, rec=0.365, cos=0.877), tot_loss_proj:3.577 [t=0.18s]
prediction: ['[CLS] this machine according.. [SEP]']
[1350/2000] tot_loss=2.802 (perp=7.824, rec=0.362, cos=0.875), tot_loss_proj:3.578 [t=0.18s]
prediction: ['[CLS] this machine according.. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.803 (perp=7.824, rec=0.363, cos=0.875), tot_loss_proj:3.577 [t=0.17s]
prediction: ['[CLS] this machine according.. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.877 (perp=8.222, rec=0.358, cos=0.875), tot_loss_proj:3.728 [t=0.19s]
prediction: ['[CLS] this machinehit.. [SEP]']
[1500/2000] tot_loss=2.876 (perp=8.222, rec=0.357, cos=0.874), tot_loss_proj:3.731 [t=0.20s]
prediction: ['[CLS] this machinehit.. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.872 (perp=8.222, rec=0.353, cos=0.875), tot_loss_proj:3.731 [t=0.17s]
prediction: ['[CLS] this machinehit.. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.877 (perp=8.222, rec=0.360, cos=0.873), tot_loss_proj:3.734 [t=0.27s]
prediction: ['[CLS] this machinehit.. [SEP]']
[1650/2000] tot_loss=2.968 (perp=8.648, rec=0.366, cos=0.873), tot_loss_proj:3.758 [t=0.20s]
prediction: ['[CLS] this machinehit. : [SEP]']
Attempt swap
[1700/2000] tot_loss=2.963 (perp=8.648, rec=0.360, cos=0.873), tot_loss_proj:3.754 [t=0.17s]
prediction: ['[CLS] this machinehit. : [SEP]']
Attempt swap
[1750/2000] tot_loss=2.961 (perp=8.648, rec=0.358, cos=0.873), tot_loss_proj:3.758 [t=0.18s]
prediction: ['[CLS] this machinehit. : [SEP]']
[1800/2000] tot_loss=2.959 (perp=8.648, rec=0.357, cos=0.873), tot_loss_proj:3.757 [t=0.26s]
prediction: ['[CLS] this machinehit. : [SEP]']
Attempt swap
[1850/2000] tot_loss=2.967 (perp=8.648, rec=0.365, cos=0.872), tot_loss_proj:3.757 [t=0.20s]
prediction: ['[CLS] this machinehit. : [SEP]']
Attempt swap
[1900/2000] tot_loss=2.970 (perp=8.648, rec=0.368, cos=0.872), tot_loss_proj:3.755 [t=0.20s]
prediction: ['[CLS] this machinehit. : [SEP]']
[1950/2000] tot_loss=2.969 (perp=8.648, rec=0.367, cos=0.872), tot_loss_proj:3.757 [t=0.17s]
prediction: ['[CLS] this machinehit. : [SEP]']
Attempt swap
[2000/2000] tot_loss=2.963 (perp=8.648, rec=0.362, cos=0.872), tot_loss_proj:3.758 [t=0.20s]
prediction: ['[CLS] this machinehit. : [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] this machine records well. [SEP]
========================
predicted: 
========================
[CLS] this machinehit. : [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 75.000 | r: 50.000
rouge2     | fm: 25.000 | p: 33.333 | r: 20.000
rougeL     | fm: 60.000 | p: 75.000 | r: 50.000
rougeLsum  | fm: 60.000 | p: 75.000 | r: 50.000
r1fm+r2fm = 85.000

[Aggregate metrics]:
rouge1     | fm: 77.879 | p: 78.021 | r: 77.983
rouge2     | fm: 38.532 | p: 38.479 | r: 38.698
rougeL     | fm: 67.729 | p: 68.030 | r: 67.762
rougeLsum  | fm: 67.705 | p: 67.946 | r: 67.741
r1fm+r2fm = 116.411

input #73 time: 0:07:47 | total time: 10:10:26


Running input #74 of 100.
reference: 
========================
Love her though I may, that won't affect the grade.
========================
average of cosine similarity 0.9993168384864588
highest_index [0]
highest [0.9993168384864588]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2293, 2014, 2295, 1045, 2089, 1010, 2008, 2180, 1005, 1056, 7461,
         1996, 3694, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] love her though i may, that won't affect the grade. [SEP]"]
[Init] best rec loss: 1.0024644136428833 for ['[CLS] charm joke classification lemon vhs d （ alzheimer minogueify gunslinger part used club [SEP]']
[Init] best rec loss: 0.9267971515655518 for ['[CLS] blast health charliebase can through letterns door alternatives attenditatedatin competed [SEP]']
[Init] best rec loss: 0.9037371873855591 for ['[CLS] passed eva with two history outward box cai shuffleeritt wonders temple aware [SEP]']
[Init] best rec loss: 0.892467737197876 for ['[CLS] orient conner dresser canada came belly sing sri front jacobdate pharaoh? devon [SEP]']
[Init] best rec loss: 0.875771701335907 for ['[CLS] inflation frowned knew clapped rosalie executed affecteda wild blue keptrcle za rafe [SEP]']
[Init] best rec loss: 0.8655742406845093 for ['[CLS] dot topic strip investigation kg facing chang mani causedond have millie bank divided [SEP]']
[Init] best rec loss: 0.854909360408783 for ['[CLS] par animals gavin hokkaido fisherman gttwined yetrgy sexual thank sophia aim gag [SEP]']
[Init] best perm rec loss: 0.8548519015312195 for ['[CLS] hokkaido gt thank par sophiatwinedrgy aim yet gavin fisherman gag animals sexual [SEP]']
[Init] best perm rec loss: 0.8532049655914307 for ['[CLS] animalsrgy gag aim sophia hokkaido fisherman par thank sexual gt gavin yettwined [SEP]']
[Init] best perm rec loss: 0.8515307903289795 for ['[CLS]rgy gag sophia sexual gavintwined thank fisherman par hokkaido aim animals gt yet [SEP]']
[Init] best perm rec loss: 0.84995037317276 for ['[CLS] parrgy sophiatwined gavin aim thank gt sexual yet fisherman animals hokkaido gag [SEP]']
[Init] best perm rec loss: 0.8490588068962097 for ['[CLS] sexualrgy animals gavin gag fisherman partwined hokkaido aim gt thank yet sophia [SEP]']
[Init] best perm rec loss: 0.8482096195220947 for ['[CLS] aim thank animalstwined par gavin hokkaido yetrgy fisherman gag sexual gt sophia [SEP]']
[Init] best perm rec loss: 0.8481844067573547 for ['[CLS] par gavin hokkaido thank fishermantwined sexual gag aim yet gtrgy sophia animals [SEP]']
[Init] best perm rec loss: 0.845284104347229 for ['[CLS] sexual gagtwined sophia gavin gt thank hokkaido fisherman animals yetrgy par aim [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.502 (perp=9.677, rec=0.439, cos=0.128), tot_loss_proj:3.850 [t=0.21s]
prediction: ['[CLS] ( : less further are hired thomash, through genome − even. [SEP]']
[ 100/2000] tot_loss=2.455 (perp=10.369, rec=0.330, cos=0.051), tot_loss_proj:3.988 [t=0.20s]
prediction: ['[CLS] love : less article cannot thank ihi, a grade. sooner. [SEP]']
[ 150/2000] tot_loss=2.558 (perp=10.633, rec=0.338, cos=0.094), tot_loss_proj:4.010 [t=0.24s]
prediction: ['[CLS] love the census article cannot thank iih. not grade ‚ that contemporary [SEP]']
[ 200/2000] tot_loss=2.463 (perp=11.087, rec=0.220, cos=0.026), tot_loss_proj:4.086 [t=0.22s]
prediction: ['[CLS] love her lay article though thank iih. affect grade ， that. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.364 (perp=10.517, rec=0.224, cos=0.037), tot_loss_proj:3.960 [t=0.25s]
prediction: ['[CLS] love her,r though thank may less would affect grade though that. [SEP]']
[ 300/2000] tot_loss=2.979 (perp=11.736, rec=0.461, cos=0.170), tot_loss_proj:4.238 [t=0.26s]
prediction: ['[CLS] love her.h though quinn ( grow would affect grade nix that. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.503 (perp=10.636, rec=0.306, cos=0.069), tot_loss_proj:4.043 [t=0.18s]
prediction: ['[CLS] love her quinn iron though. said advance cannot change grade... that the [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.232 (perp=9.669, rec=0.255, cos=0.043), tot_loss_proj:3.828 [t=0.17s]
prediction: ['[CLS] love her entertainment said though. bluntgible cannot change grade though that. [SEP]']
[ 450/2000] tot_loss=2.196 (perp=9.684, rec=0.228, cos=0.031), tot_loss_proj:3.832 [t=0.17s]
prediction: ['[CLS] love her entertainment said though.naegible cannot change grade though that. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.164 (perp=8.912, rec=0.292, cos=0.090), tot_loss_proj:3.743 [t=0.22s]
prediction: ['[CLS] her love entertainment saying though. may grade cannot affect grade ‚ that. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.858 (perp=7.876, rec=0.234, cos=0.049), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] her love entertainment saying though. may that cannot affect grade though grade. [SEP]']
[ 600/2000] tot_loss=1.792 (perp=7.745, rec=0.208, cos=0.035), tot_loss_proj:3.476 [t=0.20s]
prediction: ['[CLS] her love entertainment said though. may that cannot affect grade though grade. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.787 (perp=7.796, rec=0.197, cos=0.030), tot_loss_proj:3.490 [t=0.19s]
prediction: ['[CLS] her love entertainment said though. that may will affect grade though grade. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.827 (perp=8.021, rec=0.194, cos=0.029), tot_loss_proj:3.489 [t=0.20s]
prediction: ['[CLS] her love entertainment said though. that may affect cannot grade though grade. [SEP]']
[ 750/2000] tot_loss=1.808 (perp=8.021, rec=0.179, cos=0.025), tot_loss_proj:3.489 [t=0.21s]
prediction: ['[CLS] her love entertainment said though. that may affect cannot grade though grade. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.594 (perp=6.968, rec=0.177, cos=0.024), tot_loss_proj:3.282 [t=0.21s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.590 (perp=6.968, rec=0.175, cos=0.022), tot_loss_proj:3.285 [t=0.21s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
[ 900/2000] tot_loss=1.584 (perp=6.968, rec=0.170, cos=0.021), tot_loss_proj:3.284 [t=0.17s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.574 (perp=6.968, rec=0.161, cos=0.020), tot_loss_proj:3.288 [t=0.18s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.572 (perp=6.968, rec=0.159, cos=0.019), tot_loss_proj:3.288 [t=0.18s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
[1050/2000] tot_loss=1.577 (perp=6.968, rec=0.165, cos=0.018), tot_loss_proj:3.284 [t=0.18s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.799 (perp=8.123, rec=0.156, cos=0.018), tot_loss_proj:3.578 [t=0.19s]
prediction: ['[CLS] will love entertainment i though. that may affect her grade though grade. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.709 (perp=7.206, rec=0.210, cos=0.058), tot_loss_proj:3.413 [t=0.18s]
prediction: ['[CLS] said will love entertainment though. that may affect her grade though grade. [SEP]']
[1200/2000] tot_loss=1.638 (perp=7.206, rec=0.172, cos=0.026), tot_loss_proj:3.409 [t=0.18s]
prediction: ['[CLS] said will love entertainment though. that may affect her grade though grade. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.627 (perp=7.206, rec=0.163, cos=0.023), tot_loss_proj:3.415 [t=0.20s]
prediction: ['[CLS] said will love entertainment though. that may affect her grade though grade. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.569 (perp=6.968, rec=0.154, cos=0.021), tot_loss_proj:3.285 [t=0.18s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
[1350/2000] tot_loss=1.577 (perp=6.968, rec=0.164, cos=0.020), tot_loss_proj:3.289 [t=0.18s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.562 (perp=6.968, rec=0.150, cos=0.019), tot_loss_proj:3.284 [t=0.24s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.569 (perp=6.968, rec=0.157, cos=0.018), tot_loss_proj:3.284 [t=0.18s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
[1500/2000] tot_loss=1.575 (perp=6.968, rec=0.163, cos=0.018), tot_loss_proj:3.284 [t=0.18s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.579 (perp=6.968, rec=0.167, cos=0.017), tot_loss_proj:3.286 [t=0.18s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.571 (perp=6.968, rec=0.160, cos=0.017), tot_loss_proj:3.291 [t=0.17s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
[1650/2000] tot_loss=1.557 (perp=6.968, rec=0.146, cos=0.017), tot_loss_proj:3.282 [t=0.17s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.553 (perp=6.968, rec=0.142, cos=0.017), tot_loss_proj:3.282 [t=0.19s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.562 (perp=6.968, rec=0.151, cos=0.017), tot_loss_proj:3.286 [t=0.18s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
[1800/2000] tot_loss=1.569 (perp=6.968, rec=0.159, cos=0.017), tot_loss_proj:3.281 [t=0.20s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.562 (perp=6.968, rec=0.152, cos=0.016), tot_loss_proj:3.282 [t=0.18s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.555 (perp=6.968, rec=0.145, cos=0.016), tot_loss_proj:3.280 [t=0.20s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
[1950/2000] tot_loss=1.560 (perp=6.968, rec=0.150, cos=0.016), tot_loss_proj:3.283 [t=0.19s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.561 (perp=6.968, rec=0.151, cos=0.016), tot_loss_proj:3.290 [t=0.19s]
prediction: ['[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] love her though i may, that won't affect the grade. [SEP]
========================
predicted: 
========================
[CLS] will love entertainment said though. that may affect her grade though grade. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 64.286 | r: 69.231
rouge2     | fm: 8.000 | p: 7.692 | r: 8.333
rougeL     | fm: 51.852 | p: 50.000 | r: 53.846
rougeLsum  | fm: 51.852 | p: 50.000 | r: 53.846
r1fm+r2fm = 74.667

[Aggregate metrics]:
rouge1     | fm: 77.677 | p: 77.832 | r: 77.831
rouge2     | fm: 38.194 | p: 38.176 | r: 38.370
rougeL     | fm: 67.508 | p: 67.769 | r: 67.559
rougeLsum  | fm: 67.406 | p: 67.658 | r: 67.504
r1fm+r2fm = 115.871

input #74 time: 0:07:42 | total time: 10:18:08


Running input #75 of 100.
reference: 
========================
I have been flying helicopters for years.
========================
average of cosine similarity 0.9993561168596994
highest_index [0]
highest [0.9993561168596994]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1045,  2031,  2042,  3909, 12400,  2005,  2086,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have been flying helicopters for years. [SEP]']
[Init] best rec loss: 0.9605770111083984 for ['[CLS] lindsey exposed gov recreation touch approaching lack troubles [SEP]']
[Init] best rec loss: 0.9479166865348816 for ['[CLS] typical who paul slavery { distinction summit loop [SEP]']
[Init] best rec loss: 0.9144813418388367 for ['[CLS] caineding venture goethe protocolht base great [SEP]']
[Init] best perm rec loss: 0.9137658476829529 for ['[CLS]ding goethe great caine base protocol ventureht [SEP]']
[Init] best perm rec loss: 0.9111108779907227 for ['[CLS] caineding venture goethe baseht great protocol [SEP]']
[Init] best perm rec loss: 0.9083705544471741 for ['[CLS] goethe caine ventureding base protocol greatht [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.893 (perp=11.102, rec=0.688, cos=0.985), tot_loss_proj:4.062 [t=0.20s]
prediction: ['[CLS] rabbi.ta being asia freight. that [SEP]']
[ 100/2000] tot_loss=3.211 (perp=9.789, rec=0.568, cos=0.686), tot_loss_proj:3.832 [t=0.18s]
prediction: ['[CLS] woman. been including helicopter carries.. [SEP]']
[ 150/2000] tot_loss=1.484 (perp=6.063, rec=0.245, cos=0.026), tot_loss_proj:3.272 [t=0.18s]
prediction: ['[CLS] i have been flying helicopters having.. [SEP]']
[ 200/2000] tot_loss=1.396 (perp=6.063, rec=0.170, cos=0.013), tot_loss_proj:3.278 [t=0.18s]
prediction: ['[CLS] i have been flying helicopters having.. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.762 (perp=8.069, rec=0.137, cos=0.011), tot_loss_proj:3.683 [t=0.18s]
prediction: ['[CLS] i years been flying helicopters having.. [SEP]']
[ 300/2000] tot_loss=1.756 (perp=8.069, rec=0.133, cos=0.009), tot_loss_proj:3.683 [t=0.17s]
prediction: ['[CLS] i years been flying helicopters having.. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.513 (perp=6.854, rec=0.134, cos=0.009), tot_loss_proj:3.267 [t=0.18s]
prediction: ['[CLS] i years having been flying helicopters.. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.774 (perp=8.150, rec=0.136, cos=0.009), tot_loss_proj:3.558 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters. years [SEP]']
[ 450/2000] tot_loss=1.761 (perp=8.150, rec=0.124, cos=0.008), tot_loss_proj:3.549 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters. years [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.759 (perp=8.150, rec=0.122, cos=0.007), tot_loss_proj:3.550 [t=0.17s]
prediction: ['[CLS] i having years been flying helicopters. years [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.762 (perp=8.150, rec=0.125, cos=0.007), tot_loss_proj:3.550 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters. years [SEP]']
[ 600/2000] tot_loss=1.756 (perp=8.150, rec=0.119, cos=0.007), tot_loss_proj:3.548 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters. years [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.476 (perp=6.748, rec=0.120, cos=0.007), tot_loss_proj:3.386 [t=0.17s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.479 (perp=6.748, rec=0.123, cos=0.006), tot_loss_proj:3.388 [t=0.17s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
[ 750/2000] tot_loss=1.470 (perp=6.748, rec=0.114, cos=0.006), tot_loss_proj:3.387 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.473 (perp=6.748, rec=0.117, cos=0.006), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.473 (perp=6.748, rec=0.117, cos=0.006), tot_loss_proj:3.385 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
[ 900/2000] tot_loss=1.476 (perp=6.748, rec=0.121, cos=0.006), tot_loss_proj:3.385 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.479 (perp=6.748, rec=0.123, cos=0.006), tot_loss_proj:3.389 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.472 (perp=6.748, rec=0.117, cos=0.006), tot_loss_proj:3.388 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
[1050/2000] tot_loss=1.459 (perp=6.748, rec=0.104, cos=0.006), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.466 (perp=6.748, rec=0.110, cos=0.006), tot_loss_proj:3.388 [t=0.19s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.462 (perp=6.748, rec=0.107, cos=0.006), tot_loss_proj:3.390 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
[1200/2000] tot_loss=1.470 (perp=6.748, rec=0.114, cos=0.006), tot_loss_proj:3.384 [t=0.19s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.479 (perp=6.748, rec=0.123, cos=0.006), tot_loss_proj:3.387 [t=0.23s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.471 (perp=6.748, rec=0.116, cos=0.006), tot_loss_proj:3.392 [t=0.17s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
[1350/2000] tot_loss=1.472 (perp=6.748, rec=0.116, cos=0.006), tot_loss_proj:3.388 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.474 (perp=6.748, rec=0.118, cos=0.006), tot_loss_proj:3.389 [t=0.19s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.474 (perp=6.748, rec=0.119, cos=0.006), tot_loss_proj:3.393 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
[1500/2000] tot_loss=1.466 (perp=6.748, rec=0.110, cos=0.006), tot_loss_proj:3.388 [t=0.17s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.470 (perp=6.748, rec=0.115, cos=0.006), tot_loss_proj:3.388 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.478 (perp=6.748, rec=0.122, cos=0.006), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
[1650/2000] tot_loss=1.469 (perp=6.748, rec=0.113, cos=0.006), tot_loss_proj:3.391 [t=0.19s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.465 (perp=6.748, rec=0.109, cos=0.006), tot_loss_proj:3.389 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.471 (perp=6.748, rec=0.116, cos=0.006), tot_loss_proj:3.389 [t=0.17s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
[1800/2000] tot_loss=1.477 (perp=6.748, rec=0.122, cos=0.006), tot_loss_proj:3.389 [t=0.17s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.468 (perp=6.748, rec=0.113, cos=0.006), tot_loss_proj:3.391 [t=0.19s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.469 (perp=6.748, rec=0.113, cos=0.006), tot_loss_proj:3.392 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
[1950/2000] tot_loss=1.465 (perp=6.748, rec=0.110, cos=0.006), tot_loss_proj:3.389 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.465 (perp=6.748, rec=0.109, cos=0.006), tot_loss_proj:3.392 [t=0.18s]
prediction: ['[CLS] i having years been flying helicopters.. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] i have been flying helicopters for years. [SEP]
========================
predicted: 
========================
[CLS] i having years been flying helicopters.. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 87.500 | r: 77.778
rouge2     | fm: 40.000 | p: 42.857 | r: 37.500
rougeL     | fm: 70.588 | p: 75.000 | r: 66.667
rougeLsum  | fm: 70.588 | p: 75.000 | r: 66.667
r1fm+r2fm = 122.353

[Aggregate metrics]:
rouge1     | fm: 77.815 | p: 78.082 | r: 77.932
rouge2     | fm: 38.047 | p: 38.022 | r: 38.254
rougeL     | fm: 67.403 | p: 67.766 | r: 67.448
rougeLsum  | fm: 67.489 | p: 67.791 | r: 67.470
r1fm+r2fm = 115.861

input #75 time: 0:07:30 | total time: 10:25:39


Running input #76 of 100.
reference: 
========================
the person stand on my foot is heavy.
========================
average of cosine similarity 0.9993156362431244
highest_index [0]
highest [0.9993156362431244]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2711, 3233, 2006, 2026, 3329, 2003, 3082, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the person stand on my foot is heavy. [SEP]']
[Init] best rec loss: 0.8294539451599121 for ['[CLS] yes motorway has entering lin trust d dante without [SEP]']
[Init] best rec loss: 0.8037463426589966 for ['[CLS] concrete supportke police liszt gracelay masjid empress [SEP]']
[Init] best rec loss: 0.798318088054657 for ['[CLS] right atgang connecting naturalistpy half use feud [SEP]']
[Init] best rec loss: 0.7697778344154358 for ['[CLS] speech largest endemicner flow stateism decenttrust [SEP]']
[Init] best rec loss: 0.7677800059318542 for ['[CLS] tag merlin heardhang land anywayimeter anastasia compare [SEP]']
[Init] best rec loss: 0.7535086870193481 for ['[CLS]xt missionary drive draft vancouver camp glory walker un [SEP]']
[Init] best rec loss: 0.7463003396987915 for ['[CLS] faster hope outcome scribe windsor cherry zoe pounder viewing [SEP]']
[Init] best rec loss: 0.6924082636833191 for ['[CLS] landfall day resulted kenton institute kate holland learning recorder [SEP]']
[Init] best rec loss: 0.68180251121521 for ['[CLS] officer laughed reigning taking chronic oldborn coupled meeting [SEP]']
[Init] best perm rec loss: 0.6811312437057495 for ['[CLS] meeting laughed taking old officer chronicborn reigning coupled [SEP]']
[Init] best perm rec loss: 0.6787684559822083 for ['[CLS] reigningborn laughed officer taking meeting coupled old chronic [SEP]']
[Init] best perm rec loss: 0.6758812665939331 for ['[CLS] laughed officer old reigning taking coupled meeting chronicborn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.729 (perp=11.652, rec=0.375, cos=0.024), tot_loss_proj:3.351 [t=0.18s]
prediction: ['[CLS] calls officerf ( stand. hay runner person [SEP]']
[ 100/2000] tot_loss=2.430 (perp=10.605, rec=0.292, cos=0.018), tot_loss_proj:2.813 [t=0.17s]
prediction: ['[CLS] person stand my when stand : foot heavy person [SEP]']
[ 150/2000] tot_loss=2.450 (perp=11.071, rec=0.228, cos=0.008), tot_loss_proj:3.039 [t=0.18s]
prediction: ['[CLS] person stand my when is of foot heavy foot [SEP]']
[ 200/2000] tot_loss=2.280 (perp=10.390, rec=0.196, cos=0.007), tot_loss_proj:2.793 [t=0.18s]
prediction: ['[CLS] person stand my when is. heavy heavy foot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.014 (perp=9.213, rec=0.166, cos=0.005), tot_loss_proj:2.551 [t=0.20s]
prediction: ['[CLS] person my when stand is the heavy heavy foot [SEP]']
[ 300/2000] tot_loss=1.986 (perp=9.213, rec=0.138, cos=0.006), tot_loss_proj:2.557 [t=0.19s]
prediction: ['[CLS] person my when stand is the heavy heavy foot [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.754 (perp=8.094, rec=0.131, cos=0.004), tot_loss_proj:2.168 [t=0.18s]
prediction: ['[CLS]. my person stand is the heavy heavy foot [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.754 (perp=8.199, rec=0.110, cos=0.004), tot_loss_proj:2.434 [t=0.18s]
prediction: ['[CLS]. on stand person is the heavy heavy foot [SEP]']
[ 450/2000] tot_loss=1.748 (perp=8.199, rec=0.104, cos=0.004), tot_loss_proj:2.433 [t=0.18s]
prediction: ['[CLS]. on stand person is the heavy heavy foot [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.810 (perp=8.524, rec=0.101, cos=0.004), tot_loss_proj:2.364 [t=0.17s]
prediction: ['[CLS] heavy on stand person is the heavy my foot [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.695 (perp=7.888, rec=0.112, cos=0.005), tot_loss_proj:2.157 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
[ 600/2000] tot_loss=1.683 (perp=7.888, rec=0.101, cos=0.004), tot_loss_proj:2.157 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.666 (perp=7.888, rec=0.085, cos=0.003), tot_loss_proj:2.157 [t=0.19s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.658 (perp=7.888, rec=0.077, cos=0.003), tot_loss_proj:2.151 [t=0.17s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
[ 750/2000] tot_loss=1.647 (perp=7.888, rec=0.066, cos=0.003), tot_loss_proj:2.163 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.657 (perp=7.888, rec=0.076, cos=0.003), tot_loss_proj:2.159 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.657 (perp=7.888, rec=0.076, cos=0.003), tot_loss_proj:2.155 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
[ 900/2000] tot_loss=1.665 (perp=7.888, rec=0.084, cos=0.003), tot_loss_proj:2.158 [t=0.20s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.654 (perp=7.888, rec=0.073, cos=0.003), tot_loss_proj:2.154 [t=0.19s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1000/2000] tot_loss=1.654 (perp=7.888, rec=0.073, cos=0.003), tot_loss_proj:2.155 [t=0.19s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
[1050/2000] tot_loss=1.661 (perp=7.888, rec=0.080, cos=0.003), tot_loss_proj:2.163 [t=0.21s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1100/2000] tot_loss=1.657 (perp=7.888, rec=0.077, cos=0.003), tot_loss_proj:2.155 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1150/2000] tot_loss=1.657 (perp=7.888, rec=0.076, cos=0.003), tot_loss_proj:2.156 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
[1200/2000] tot_loss=1.655 (perp=7.888, rec=0.074, cos=0.003), tot_loss_proj:2.159 [t=0.20s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1250/2000] tot_loss=1.651 (perp=7.888, rec=0.070, cos=0.003), tot_loss_proj:2.157 [t=0.26s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1300/2000] tot_loss=1.661 (perp=7.888, rec=0.081, cos=0.003), tot_loss_proj:2.163 [t=0.17s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
[1350/2000] tot_loss=1.656 (perp=7.888, rec=0.075, cos=0.003), tot_loss_proj:2.160 [t=0.17s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1400/2000] tot_loss=1.658 (perp=7.888, rec=0.077, cos=0.003), tot_loss_proj:2.153 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1450/2000] tot_loss=1.661 (perp=7.888, rec=0.081, cos=0.003), tot_loss_proj:2.156 [t=0.17s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
[1500/2000] tot_loss=1.652 (perp=7.888, rec=0.071, cos=0.003), tot_loss_proj:2.156 [t=0.17s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1550/2000] tot_loss=1.656 (perp=7.888, rec=0.076, cos=0.003), tot_loss_proj:2.162 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1600/2000] tot_loss=1.654 (perp=7.888, rec=0.073, cos=0.003), tot_loss_proj:2.158 [t=0.19s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
[1650/2000] tot_loss=1.659 (perp=7.888, rec=0.079, cos=0.003), tot_loss_proj:2.164 [t=0.19s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1700/2000] tot_loss=1.641 (perp=7.888, rec=0.060, cos=0.003), tot_loss_proj:2.162 [t=0.17s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1750/2000] tot_loss=1.651 (perp=7.888, rec=0.071, cos=0.003), tot_loss_proj:2.159 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
[1800/2000] tot_loss=1.656 (perp=7.888, rec=0.075, cos=0.003), tot_loss_proj:2.168 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1850/2000] tot_loss=1.655 (perp=7.888, rec=0.075, cos=0.003), tot_loss_proj:2.159 [t=0.17s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[1900/2000] tot_loss=1.655 (perp=7.888, rec=0.074, cos=0.003), tot_loss_proj:2.155 [t=0.18s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
[1950/2000] tot_loss=1.648 (perp=7.888, rec=0.067, cos=0.003), tot_loss_proj:2.161 [t=0.17s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Attempt swap
[2000/2000] tot_loss=1.655 (perp=7.888, rec=0.075, cos=0.003), tot_loss_proj:2.159 [t=0.17s]
prediction: ['[CLS] heavy on stand my person is the heavy foot [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS] the person stand on my foot is heavy. [SEP]
========================
predicted: 
========================
[CLS] heavy on stand my person is the heavy foot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 54.545 | r: 60.000
rougeLsum  | fm: 57.143 | p: 54.545 | r: 60.000
r1fm+r2fm = 95.238

[Aggregate metrics]:
rouge1     | fm: 77.922 | p: 78.065 | r: 78.081
rouge2     | fm: 37.924 | p: 37.902 | r: 37.998
rougeL     | fm: 67.232 | p: 67.627 | r: 67.269
rougeLsum  | fm: 67.343 | p: 67.580 | r: 67.484
r1fm+r2fm = 115.846

input #76 time: 0:07:25 | total time: 10:33:04


Running input #77 of 100.
reference: 
========================
My mother baked a cake for me.
========================
average of cosine similarity 0.999406449863534
highest_index [0]
highest [0.999406449863534]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2026,  2388, 17776,  1037,  9850,  2005,  2033,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] my mother baked a cake for me. [SEP]']
[Init] best rec loss: 1.0671769380569458 for ['[CLS] mysterious statistical its owner soft bodo network posting [SEP]']
[Init] best rec loss: 1.0210918188095093 for ['[CLS] baby jolink & spinal is andre youngest [SEP]']
[Init] best rec loss: 0.978882372379303 for ['[CLS] helmetgating shaking external closed )ations oldest [SEP]']
[Init] best rec loss: 0.977277934551239 for ['[CLS] catch as [UNK] visitraph meet found your [SEP]']
[Init] best rec loss: 0.9744843244552612 for ['[CLS] voice free knuckles citizen dean senior private much [SEP]']
[Init] best perm rec loss: 0.968231201171875 for ['[CLS] voice citizen knuckles dean senior free much private [SEP]']
[Init] best perm rec loss: 0.9661933779716492 for ['[CLS] senior voice citizen much private knuckles dean free [SEP]']
[Init] best perm rec loss: 0.9661873579025269 for ['[CLS] dean citizen senior voice free much private knuckles [SEP]']
[Init] best perm rec loss: 0.9657464623451233 for ['[CLS] private senior voice dean much citizen knuckles free [SEP]']
[Init] best perm rec loss: 0.9645711183547974 for ['[CLS] citizen dean voice knuckles free senior much private [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.205 (perp=9.110, rec=0.332, cos=0.051), tot_loss_proj:3.566 [t=0.18s]
prediction: ['[CLS] baked construction the awarded programme to ritual. [SEP]']
[ 100/2000] tot_loss=1.852 (perp=8.173, rec=0.203, cos=0.014), tot_loss_proj:3.607 [t=0.18s]
prediction: ['[CLS] baked mother a cake aunt baked cake. [SEP]']
[ 150/2000] tot_loss=1.554 (perp=6.986, rec=0.148, cos=0.009), tot_loss_proj:3.233 [t=0.19s]
prediction: ['[CLS] my mother a cake mother baked cake. [SEP]']
[ 200/2000] tot_loss=1.559 (perp=7.194, rec=0.114, cos=0.006), tot_loss_proj:3.496 [t=0.21s]
prediction: ['[CLS] my mother a cake mother baked for. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.428 (perp=6.600, rec=0.102, cos=0.006), tot_loss_proj:3.198 [t=0.18s]
prediction: ['[CLS] my mother cake a mother baked for me [SEP]']
[ 300/2000] tot_loss=1.396 (perp=6.600, rec=0.072, cos=0.004), tot_loss_proj:3.206 [t=0.18s]
prediction: ['[CLS] my mother cake a mother baked for me [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.409 (perp=6.600, rec=0.084, cos=0.004), tot_loss_proj:3.206 [t=0.17s]
prediction: ['[CLS] my mother cake a mother baked for me [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.409 (perp=6.600, rec=0.085, cos=0.004), tot_loss_proj:3.209 [t=0.18s]
prediction: ['[CLS] my mother cake a mother baked for me [SEP]']
[ 450/2000] tot_loss=1.406 (perp=6.600, rec=0.082, cos=0.004), tot_loss_proj:3.204 [t=0.19s]
prediction: ['[CLS] my mother cake a mother baked for me [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.271 (perp=5.730, rec=0.118, cos=0.007), tot_loss_proj:1.672 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.251 (perp=5.730, rec=0.099, cos=0.005), tot_loss_proj:1.662 [t=0.19s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
[ 600/2000] tot_loss=1.255 (perp=5.730, rec=0.104, cos=0.005), tot_loss_proj:1.658 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.245 (perp=5.730, rec=0.094, cos=0.005), tot_loss_proj:1.663 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.237 (perp=5.730, rec=0.087, cos=0.005), tot_loss_proj:1.660 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
[ 750/2000] tot_loss=1.240 (perp=5.730, rec=0.089, cos=0.005), tot_loss_proj:1.668 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.223 (perp=5.730, rec=0.073, cos=0.004), tot_loss_proj:1.663 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.233 (perp=5.730, rec=0.083, cos=0.004), tot_loss_proj:1.670 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
[ 900/2000] tot_loss=1.231 (perp=5.730, rec=0.080, cos=0.004), tot_loss_proj:1.660 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.226 (perp=5.730, rec=0.075, cos=0.004), tot_loss_proj:1.662 [t=0.21s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1000/2000] tot_loss=1.229 (perp=5.730, rec=0.079, cos=0.004), tot_loss_proj:1.663 [t=0.19s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
[1050/2000] tot_loss=1.227 (perp=5.730, rec=0.077, cos=0.004), tot_loss_proj:1.662 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1100/2000] tot_loss=1.223 (perp=5.730, rec=0.073, cos=0.004), tot_loss_proj:1.657 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1150/2000] tot_loss=1.229 (perp=5.730, rec=0.079, cos=0.004), tot_loss_proj:1.670 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
[1200/2000] tot_loss=1.237 (perp=5.730, rec=0.087, cos=0.004), tot_loss_proj:1.662 [t=0.20s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1250/2000] tot_loss=1.233 (perp=5.730, rec=0.083, cos=0.004), tot_loss_proj:1.664 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1300/2000] tot_loss=1.232 (perp=5.730, rec=0.081, cos=0.004), tot_loss_proj:1.658 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
[1350/2000] tot_loss=1.235 (perp=5.730, rec=0.084, cos=0.004), tot_loss_proj:1.671 [t=0.24s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1400/2000] tot_loss=1.235 (perp=5.730, rec=0.084, cos=0.004), tot_loss_proj:1.668 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1450/2000] tot_loss=1.238 (perp=5.730, rec=0.087, cos=0.004), tot_loss_proj:1.656 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
[1500/2000] tot_loss=1.235 (perp=5.730, rec=0.085, cos=0.004), tot_loss_proj:1.669 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1550/2000] tot_loss=1.234 (perp=5.730, rec=0.083, cos=0.004), tot_loss_proj:1.660 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1600/2000] tot_loss=1.236 (perp=5.730, rec=0.086, cos=0.004), tot_loss_proj:1.663 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
[1650/2000] tot_loss=1.229 (perp=5.730, rec=0.078, cos=0.004), tot_loss_proj:1.666 [t=0.18s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1700/2000] tot_loss=1.234 (perp=5.730, rec=0.083, cos=0.004), tot_loss_proj:1.669 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1750/2000] tot_loss=1.231 (perp=5.730, rec=0.081, cos=0.004), tot_loss_proj:1.669 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
[1800/2000] tot_loss=1.238 (perp=5.730, rec=0.088, cos=0.004), tot_loss_proj:1.671 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1850/2000] tot_loss=1.240 (perp=5.730, rec=0.089, cos=0.004), tot_loss_proj:1.662 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[1900/2000] tot_loss=1.237 (perp=5.730, rec=0.087, cos=0.004), tot_loss_proj:1.672 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
[1950/2000] tot_loss=1.220 (perp=5.730, rec=0.069, cos=0.004), tot_loss_proj:1.661 [t=0.17s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Attempt swap
[2000/2000] tot_loss=1.231 (perp=5.730, rec=0.080, cos=0.004), tot_loss_proj:1.660 [t=0.27s]
prediction: ['[CLS] my mother baked a mother cake for me [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] my mother baked a cake for me. [SEP]
========================
predicted: 
========================
[CLS] my mother baked a mother cake for me [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 82.353 | p: 77.778 | r: 87.500
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 177.090

[Aggregate metrics]:
rouge1     | fm: 78.100 | p: 78.240 | r: 78.345
rouge2     | fm: 38.410 | p: 38.362 | r: 38.594
rougeL     | fm: 67.681 | p: 67.932 | r: 67.750
rougeLsum  | fm: 67.679 | p: 67.864 | r: 67.787
r1fm+r2fm = 116.511

input #77 time: 0:07:31 | total time: 10:40:36


Running input #78 of 100.
reference: 
========================
I read some book.
========================
average of cosine similarity 0.9993794737153854
highest_index [0]
highest [0.9993794737153854]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 3191, 2070, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i read some book. [SEP]']
[Init] best rec loss: 0.9242171049118042 for ['[CLS]ys sponsored ni patience courts [SEP]']
[Init] best rec loss: 0.9155153632164001 for ['[CLS] sealing wrestlemania profile sense ar [SEP]']
[Init] best rec loss: 0.813995361328125 for ['[CLS] am iv pregnant lagoon ample [SEP]']
[Init] best rec loss: 0.8045976758003235 for ['[CLS] tour fucking ax him banking [SEP]']
[Init] best rec loss: 0.8032265305519104 for ['[CLS] epidemic deceased accused flames zone [SEP]']
[Init] best rec loss: 0.7923592925071716 for ['[CLS] solitary jumps squeakchev tangled [SEP]']
[Init] best perm rec loss: 0.7846071720123291 for ['[CLS] solitarychev squeak tangled jumps [SEP]']
[Init] best perm rec loss: 0.7840006947517395 for ['[CLS]chev jumps tangled squeak solitary [SEP]']
[Init] best perm rec loss: 0.7813184261322021 for ['[CLS]chev squeak tangled solitary jumps [SEP]']
[Init] best perm rec loss: 0.7804632186889648 for ['[CLS] tangled squeak solitarychev jumps [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.844 (perp=11.289, rec=0.509, cos=0.078), tot_loss_proj:3.898 [t=0.19s]
prediction: ['[CLS] grave movie comic show toured [SEP]']
[ 100/2000] tot_loss=2.870 (perp=12.448, rec=0.341, cos=0.040), tot_loss_proj:3.527 [t=0.19s]
prediction: ['[CLS] ce book book show some [SEP]']
[ 150/2000] tot_loss=2.846 (perp=12.847, rec=0.253, cos=0.024), tot_loss_proj:3.664 [t=0.19s]
prediction: ['[CLS] taught book book some some [SEP]']
[ 200/2000] tot_loss=2.138 (perp=9.610, rec=0.198, cos=0.018), tot_loss_proj:2.921 [t=0.19s]
prediction: ['[CLS] we book read some some [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.515 (perp=10.709, rec=0.330, cos=0.043), tot_loss_proj:3.246 [t=0.20s]
prediction: ['[CLS] received reading. book some [SEP]']
[ 300/2000] tot_loss=2.224 (perp=10.063, rec=0.197, cos=0.015), tot_loss_proj:3.107 [t=0.22s]
prediction: ['[CLS] received book i book some [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.959 (perp=8.875, rec=0.170, cos=0.014), tot_loss_proj:2.803 [t=0.18s]
prediction: ['[CLS] reading i book read some [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.487 (perp=9.251, rec=0.504, cos=0.133), tot_loss_proj:2.926 [t=0.19s]
prediction: ['[CLS] book read read some book [SEP]']
[ 450/2000] tot_loss=2.124 (perp=9.251, rec=0.251, cos=0.022), tot_loss_proj:2.896 [t=0.18s]
prediction: ['[CLS] book read read some book [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.712 (perp=7.548, rec=0.189, cos=0.013), tot_loss_proj:2.569 [t=0.21s]
prediction: ['[CLS] book read some book read [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.516 (perp=6.628, rec=0.177, cos=0.013), tot_loss_proj:2.271 [t=0.17s]
prediction: ['[CLS] book i read some book [SEP]']
[ 600/2000] tot_loss=1.486 (perp=6.628, rec=0.152, cos=0.009), tot_loss_proj:2.268 [t=0.18s]
prediction: ['[CLS] book i read some book [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.550 (perp=7.058, rec=0.131, cos=0.007), tot_loss_proj:2.269 [t=0.18s]
prediction: ['[CLS] reading i read some book [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.542 (perp=7.058, rec=0.124, cos=0.006), tot_loss_proj:2.267 [t=0.18s]
prediction: ['[CLS] reading i read some book [SEP]']
[ 750/2000] tot_loss=1.537 (perp=7.058, rec=0.120, cos=0.006), tot_loss_proj:2.271 [t=0.19s]
prediction: ['[CLS] reading i read some book [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.520 (perp=7.058, rec=0.103, cos=0.006), tot_loss_proj:2.264 [t=0.21s]
prediction: ['[CLS] reading i read some book [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.526 (perp=7.058, rec=0.109, cos=0.006), tot_loss_proj:2.270 [t=0.18s]
prediction: ['[CLS] reading i read some book [SEP]']
[ 900/2000] tot_loss=1.648 (perp=7.653, rec=0.112, cos=0.006), tot_loss_proj:2.416 [t=0.17s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.642 (perp=7.653, rec=0.106, cos=0.006), tot_loss_proj:2.412 [t=0.23s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
[1000/2000] tot_loss=1.646 (perp=7.653, rec=0.110, cos=0.006), tot_loss_proj:2.416 [t=0.20s]
prediction: ['[CLS] read i read some book [SEP]']
[1050/2000] tot_loss=1.644 (perp=7.653, rec=0.108, cos=0.005), tot_loss_proj:2.413 [t=0.21s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
[1100/2000] tot_loss=1.635 (perp=7.653, rec=0.099, cos=0.005), tot_loss_proj:2.416 [t=0.17s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
[1150/2000] tot_loss=1.642 (perp=7.653, rec=0.106, cos=0.005), tot_loss_proj:2.409 [t=0.20s]
prediction: ['[CLS] read i read some book [SEP]']
[1200/2000] tot_loss=1.634 (perp=7.653, rec=0.098, cos=0.005), tot_loss_proj:2.415 [t=0.18s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
[1250/2000] tot_loss=1.635 (perp=7.653, rec=0.099, cos=0.005), tot_loss_proj:2.409 [t=0.17s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
[1300/2000] tot_loss=1.638 (perp=7.653, rec=0.102, cos=0.005), tot_loss_proj:2.413 [t=0.18s]
prediction: ['[CLS] read i read some book [SEP]']
[1350/2000] tot_loss=1.633 (perp=7.653, rec=0.097, cos=0.005), tot_loss_proj:2.409 [t=0.17s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
[1400/2000] tot_loss=1.637 (perp=7.653, rec=0.101, cos=0.005), tot_loss_proj:2.415 [t=0.17s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
[1450/2000] tot_loss=1.635 (perp=7.653, rec=0.099, cos=0.005), tot_loss_proj:2.412 [t=0.20s]
prediction: ['[CLS] read i read some book [SEP]']
[1500/2000] tot_loss=1.637 (perp=7.653, rec=0.101, cos=0.005), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
[1550/2000] tot_loss=1.634 (perp=7.653, rec=0.098, cos=0.005), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
[1600/2000] tot_loss=1.485 (perp=6.912, rec=0.098, cos=0.005), tot_loss_proj:2.785 [t=0.18s]
prediction: ['[CLS] because i read some book [SEP]']
[1650/2000] tot_loss=1.481 (perp=6.912, rec=0.093, cos=0.005), tot_loss_proj:2.788 [t=0.18s]
prediction: ['[CLS] because i read some book [SEP]']
Attempt swap
[1700/2000] tot_loss=1.487 (perp=6.912, rec=0.099, cos=0.005), tot_loss_proj:2.781 [t=0.18s]
prediction: ['[CLS] because i read some book [SEP]']
Attempt swap
[1750/2000] tot_loss=1.492 (perp=6.912, rec=0.104, cos=0.005), tot_loss_proj:2.782 [t=0.20s]
prediction: ['[CLS] because i read some book [SEP]']
[1800/2000] tot_loss=1.482 (perp=6.912, rec=0.095, cos=0.005), tot_loss_proj:2.785 [t=0.19s]
prediction: ['[CLS] because i read some book [SEP]']
Attempt swap
[1850/2000] tot_loss=1.486 (perp=6.912, rec=0.098, cos=0.005), tot_loss_proj:2.778 [t=0.18s]
prediction: ['[CLS] because i read some book [SEP]']
Attempt swap
[1900/2000] tot_loss=1.494 (perp=6.912, rec=0.107, cos=0.005), tot_loss_proj:2.789 [t=0.18s]
prediction: ['[CLS] because i read some book [SEP]']
[1950/2000] tot_loss=1.487 (perp=6.912, rec=0.099, cos=0.005), tot_loss_proj:2.797 [t=0.18s]
prediction: ['[CLS] because i read some book [SEP]']
Attempt swap
[2000/2000] tot_loss=1.479 (perp=6.912, rec=0.092, cos=0.005), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] because i read some book [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] i read some book. [SEP]
========================
predicted: 
========================
[CLS] because i read some book [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 72.727 | p: 66.667 | r: 80.000
rougeL     | fm: 92.308 | p: 85.714 | r: 100.000
rougeLsum  | fm: 92.308 | p: 85.714 | r: 100.000
r1fm+r2fm = 165.035

[Aggregate metrics]:
rouge1     | fm: 78.432 | p: 78.423 | r: 78.744
rouge2     | fm: 38.705 | p: 38.612 | r: 39.008
rougeL     | fm: 67.989 | p: 68.118 | r: 68.210
rougeLsum  | fm: 67.973 | p: 68.075 | r: 68.213
r1fm+r2fm = 117.137

input #78 time: 0:07:38 | total time: 10:48:15


Running input #79 of 100.
reference: 
========================
The umpire called it of.
========================
average of cosine similarity 0.9993217640206553
highest_index [0]
highest [0.9993217640206553]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 20887,  2170,  2009,  1997,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the umpire called it of. [SEP]']
[Init] best rec loss: 0.9944065809249878 for ['[CLS]tlement gi professional julian reaching wingspan [SEP]']
[Init] best rec loss: 0.9885329008102417 for ['[CLS] ′ ears natural developed star quest [SEP]']
[Init] best rec loss: 0.9714334607124329 for ['[CLS] exposure april located cheesequal enough [SEP]']
[Init] best rec loss: 0.9517230987548828 for ['[CLS] consulted ‖ deputy from back alley [SEP]']
[Init] best rec loss: 0.9444591999053955 for ['[CLS] sub nu mode fish calderon? [SEP]']
[Init] best rec loss: 0.9425790905952454 for ['[CLS] investigatoreve sea hell mali otherwise [SEP]']
[Init] best rec loss: 0.9382247924804688 for ['[CLS] immediately... ordinary variouspre extra [SEP]']
[Init] best rec loss: 0.9181168675422668 for ['[CLS]oca named hall would google guard [SEP]']
[Init] best perm rec loss: 0.9179900288581848 for ['[CLS]oca hall would google guard named [SEP]']
[Init] best perm rec loss: 0.9177843928337097 for ['[CLS] guard halloca named google would [SEP]']
[Init] best perm rec loss: 0.9168456792831421 for ['[CLS]oca hall guard would named google [SEP]']
[Init] best perm rec loss: 0.9167401790618896 for ['[CLS] guard named hall would googleoca [SEP]']
[Init] best perm rec loss: 0.9162608981132507 for ['[CLS]oca hall would named google guard [SEP]']
[Init] best perm rec loss: 0.9160237908363342 for ['[CLS]oca would guard google named hall [SEP]']
[Init] best perm rec loss: 0.9141231179237366 for ['[CLS]oca would guard named hall google [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.775 (perp=10.861, rec=0.618, cos=0.985), tot_loss_proj:4.006 [t=0.17s]
prediction: ['[CLS] umpire yearsping cried with. [SEP]']
[ 100/2000] tot_loss=3.696 (perp=11.023, rec=0.518, cos=0.974), tot_loss_proj:4.001 [t=0.17s]
prediction: ['[CLS] umpire is virtually cried regarding each [SEP]']
[ 150/2000] tot_loss=3.736 (perp=11.522, rec=0.451, cos=0.981), tot_loss_proj:4.210 [t=0.17s]
prediction: ['[CLS] umpire the in called ; each [SEP]']
[ 200/2000] tot_loss=3.704 (perp=11.548, rec=0.410, cos=0.984), tot_loss_proj:4.353 [t=0.17s]
prediction: ['[CLS] umpire called called called ;. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.823 (perp=11.894, rec=0.467, cos=0.977), tot_loss_proj:4.300 [t=0.17s]
prediction: ['[CLS] refuge ( umpire called retirement each [SEP]']
[ 300/2000] tot_loss=3.519 (perp=10.721, rec=0.399, cos=0.976), tot_loss_proj:4.153 [t=0.17s]
prediction: ['[CLS]ա called umpire called ;. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.601 (perp=11.053, rec=0.436, cos=0.954), tot_loss_proj:4.143 [t=0.17s]
prediction: ['[CLS]ա called umpire affirmative called. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.647 (perp=11.201, rec=0.445, cos=0.961), tot_loss_proj:4.079 [t=0.17s]
prediction: ['[CLS] termed in umpire calledъ that [SEP]']
[ 450/2000] tot_loss=3.675 (perp=11.551, rec=0.398, cos=0.967), tot_loss_proj:4.147 [t=0.17s]
prediction: ['[CLS] considered called umpire called payment that [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.551 (perp=10.963, rec=0.393, cos=0.966), tot_loss_proj:4.039 [t=0.18s]
prediction: ['[CLS] considered umpire called payment that called [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.536 (perp=10.963, rec=0.377, cos=0.966), tot_loss_proj:4.038 [t=0.17s]
prediction: ['[CLS] considered umpire called payment that called [SEP]']
[ 600/2000] tot_loss=3.680 (perp=11.714, rec=0.370, cos=0.966), tot_loss_proj:4.257 [t=0.17s]
prediction: ['[CLS] considered umpire called [MASK] that called [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.700 (perp=11.812, rec=0.368, cos=0.969), tot_loss_proj:4.353 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.702 (perp=11.812, rec=0.369, cos=0.971), tot_loss_proj:4.354 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
[ 750/2000] tot_loss=3.706 (perp=11.812, rec=0.373, cos=0.971), tot_loss_proj:4.353 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.698 (perp=11.812, rec=0.363, cos=0.972), tot_loss_proj:4.355 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.695 (perp=11.812, rec=0.359, cos=0.973), tot_loss_proj:4.357 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
[ 900/2000] tot_loss=3.689 (perp=11.812, rec=0.353, cos=0.974), tot_loss_proj:4.352 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.695 (perp=11.812, rec=0.358, cos=0.975), tot_loss_proj:4.353 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1000/2000] tot_loss=3.692 (perp=11.812, rec=0.354, cos=0.975), tot_loss_proj:4.354 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
[1050/2000] tot_loss=3.696 (perp=11.812, rec=0.358, cos=0.976), tot_loss_proj:4.355 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1100/2000] tot_loss=3.693 (perp=11.812, rec=0.354, cos=0.976), tot_loss_proj:4.354 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1150/2000] tot_loss=3.685 (perp=11.812, rec=0.346, cos=0.977), tot_loss_proj:4.359 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
[1200/2000] tot_loss=3.691 (perp=11.812, rec=0.351, cos=0.977), tot_loss_proj:4.359 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1250/2000] tot_loss=3.686 (perp=11.812, rec=0.346, cos=0.978), tot_loss_proj:4.353 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1300/2000] tot_loss=3.692 (perp=11.812, rec=0.352, cos=0.978), tot_loss_proj:4.353 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
[1350/2000] tot_loss=3.692 (perp=11.812, rec=0.351, cos=0.978), tot_loss_proj:4.358 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1400/2000] tot_loss=3.690 (perp=11.812, rec=0.349, cos=0.978), tot_loss_proj:4.353 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1450/2000] tot_loss=3.689 (perp=11.812, rec=0.348, cos=0.979), tot_loss_proj:4.355 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
[1500/2000] tot_loss=3.693 (perp=11.812, rec=0.352, cos=0.979), tot_loss_proj:4.356 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1550/2000] tot_loss=3.688 (perp=11.812, rec=0.346, cos=0.979), tot_loss_proj:4.363 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1600/2000] tot_loss=3.693 (perp=11.812, rec=0.352, cos=0.979), tot_loss_proj:4.359 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
[1650/2000] tot_loss=3.693 (perp=11.812, rec=0.351, cos=0.979), tot_loss_proj:4.357 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1700/2000] tot_loss=3.688 (perp=11.812, rec=0.346, cos=0.979), tot_loss_proj:4.355 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1750/2000] tot_loss=3.690 (perp=11.812, rec=0.348, cos=0.979), tot_loss_proj:4.361 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
[1800/2000] tot_loss=3.690 (perp=11.812, rec=0.349, cos=0.979), tot_loss_proj:4.356 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1850/2000] tot_loss=3.690 (perp=11.812, rec=0.348, cos=0.980), tot_loss_proj:4.354 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[1900/2000] tot_loss=3.687 (perp=11.812, rec=0.345, cos=0.980), tot_loss_proj:4.359 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
[1950/2000] tot_loss=3.685 (perp=11.812, rec=0.343, cos=0.980), tot_loss_proj:4.359 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Attempt swap
[2000/2000] tot_loss=3.691 (perp=11.812, rec=0.349, cos=0.980), tot_loss_proj:4.354 [t=0.17s]
prediction: ['[CLS]down umpire called [MASK] that called [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] the umpire called it of. [SEP]
========================
predicted: 
========================
[CLS]down umpire called [MASK] that called [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.333 | p: 50.000 | r: 57.143
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 53.333 | p: 50.000 | r: 57.143
rougeLsum  | fm: 53.333 | p: 50.000 | r: 57.143
r1fm+r2fm = 68.718

[Aggregate metrics]:
rouge1     | fm: 77.967 | p: 77.988 | r: 78.379
rouge2     | fm: 38.380 | p: 38.181 | r: 38.728
rougeL     | fm: 67.785 | p: 67.867 | r: 68.045
rougeLsum  | fm: 67.800 | p: 67.869 | r: 68.052
r1fm+r2fm = 116.346

input #79 time: 0:06:39 | total time: 10:54:54


Running input #80 of 100.
reference: 
========================
The rock placed the sky with the fork.
========================
average of cosine similarity 0.9993117236696569
highest_index [0]
highest [0.9993117236696569]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2600, 2872, 1996, 3712, 2007, 1996, 9292, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the rock placed the sky with the fork. [SEP]']
[Init] best rec loss: 0.9175726175308228 for ['[CLS] female scared marcus humble ramp bracket hybrid marieeur [SEP]']
[Init] best rec loss: 0.891436755657196 for ['[CLS] kind plan loft [MASK]?elin unincorporated beard points [SEP]']
[Init] best rec loss: 0.8769033551216125 for ['[CLS] a bowl documentary position deficiency brand shoulders clinic counties [SEP]']
[Init] best rec loss: 0.8643680214881897 for ['[CLS] between lawrence policiessphere webb hari aria which com [SEP]']
[Init] best rec loss: 0.8254552483558655 for ['[CLS]own volunteers byte carr bold grace interchange chalk our [SEP]']
[Init] best rec loss: 0.7917901277542114 for ['[CLS] rib our ball spelling asleepille oval ash teaching [SEP]']
[Init] best rec loss: 0.7806429266929626 for ["[CLS] cassie guy preneas lake more'rocker jury [SEP]"]
[Init] best rec loss: 0.7527327537536621 for ['[CLS]tos young noah golfer healthy belong notitation modern [SEP]']
[Init] best perm rec loss: 0.752642035484314 for ['[CLS] noah golfer not healthytos belong youngitation modern [SEP]']
[Init] best perm rec loss: 0.7477012276649475 for ['[CLS] moderntositation healthy young not belong golfer noah [SEP]']
[Init] best perm rec loss: 0.747452974319458 for ['[CLS] modern not noah young belongitation healthytos golfer [SEP]']
[Init] best perm rec loss: 0.7451422214508057 for ['[CLS] not healthy youngtos belong modernitation golfer noah [SEP]']
[Init] best perm rec loss: 0.7439910769462585 for ['[CLS]tos not healthy golferitation young belong noah modern [SEP]']
[Init] best perm rec loss: 0.7436251640319824 for ['[CLS]tos noah golfer belong young modern notitation healthy [SEP]']
[Init] best perm rec loss: 0.7427157163619995 for ['[CLS] golfertos healthy belong youngitation not modern noah [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.411 (perp=10.354, rec=0.321, cos=0.020), tot_loss_proj:2.712 [t=0.18s]
prediction: ['[CLS] writing bowl placed many rock because rock so yesterday [SEP]']
[ 100/2000] tot_loss=1.839 (perp=8.184, rec=0.194, cos=0.008), tot_loss_proj:2.005 [t=0.18s]
prediction: ['[CLS] the rock placed the fork. rock with sky [SEP]']
[ 150/2000] tot_loss=1.721 (perp=8.041, rec=0.109, cos=0.004), tot_loss_proj:2.123 [t=0.19s]
prediction: ['[CLS] the rock placed the fork the rock with sky [SEP]']
[ 200/2000] tot_loss=1.706 (perp=8.041, rec=0.094, cos=0.004), tot_loss_proj:2.124 [t=0.18s]
prediction: ['[CLS] the rock placed the fork the rock with sky [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.546 (perp=7.301, rec=0.083, cos=0.003), tot_loss_proj:1.888 [t=0.18s]
prediction: ['[CLS] the rock placed the fork rock with the sky [SEP]']
[ 300/2000] tot_loss=1.551 (perp=7.301, rec=0.088, cos=0.003), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] the rock placed the fork rock with the sky [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.562 (perp=7.335, rec=0.092, cos=0.003), tot_loss_proj:2.052 [t=0.17s]
prediction: ['[CLS] the gravity placed the rock fork with the sky [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.656 (perp=7.889, rec=0.075, cos=0.003), tot_loss_proj:2.166 [t=0.17s]
prediction: ['[CLS] the rock placed the wikipedia fork with the sky [SEP]']
[ 450/2000] tot_loss=1.464 (perp=6.966, rec=0.068, cos=0.003), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.471 (perp=6.966, rec=0.076, cos=0.003), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.476 (perp=6.966, rec=0.080, cos=0.003), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
[ 600/2000] tot_loss=1.471 (perp=6.966, rec=0.076, cos=0.003), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.460 (perp=6.966, rec=0.064, cos=0.003), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.463 (perp=6.966, rec=0.067, cos=0.003), tot_loss_proj:1.731 [t=0.17s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
[ 750/2000] tot_loss=1.467 (perp=6.966, rec=0.071, cos=0.003), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.469 (perp=6.966, rec=0.073, cos=0.003), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.464 (perp=6.966, rec=0.068, cos=0.003), tot_loss_proj:1.734 [t=0.18s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
[ 900/2000] tot_loss=1.459 (perp=6.966, rec=0.063, cos=0.003), tot_loss_proj:1.743 [t=0.19s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.481 (perp=6.966, rec=0.085, cos=0.003), tot_loss_proj:1.748 [t=0.19s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.462 (perp=6.966, rec=0.066, cos=0.003), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] the rock placed the gravity fork with the sky [SEP]']
[1050/2000] tot_loss=1.631 (perp=7.741, rec=0.081, cos=0.003), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS] the rock placed the. fork with the sky [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.561 (perp=7.445, rec=0.070, cos=0.003), tot_loss_proj:2.058 [t=0.17s]
prediction: ['[CLS] the rock placed the fork. with the sky [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.315 (perp=6.181, rec=0.075, cos=0.003), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1200/2000] tot_loss=1.324 (perp=6.181, rec=0.085, cos=0.003), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.307 (perp=6.181, rec=0.068, cos=0.003), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.311 (perp=6.181, rec=0.073, cos=0.003), tot_loss_proj:1.500 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1350/2000] tot_loss=1.310 (perp=6.181, rec=0.071, cos=0.003), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.323 (perp=6.181, rec=0.084, cos=0.003), tot_loss_proj:1.489 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.311 (perp=6.181, rec=0.072, cos=0.003), tot_loss_proj:1.501 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1500/2000] tot_loss=1.307 (perp=6.181, rec=0.068, cos=0.003), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.316 (perp=6.181, rec=0.077, cos=0.003), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.308 (perp=6.181, rec=0.069, cos=0.003), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1650/2000] tot_loss=1.306 (perp=6.181, rec=0.067, cos=0.003), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.321 (perp=6.181, rec=0.082, cos=0.003), tot_loss_proj:1.497 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.311 (perp=6.181, rec=0.072, cos=0.003), tot_loss_proj:1.497 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1800/2000] tot_loss=1.306 (perp=6.181, rec=0.067, cos=0.003), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.312 (perp=6.181, rec=0.073, cos=0.003), tot_loss_proj:1.497 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.315 (perp=6.181, rec=0.076, cos=0.003), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1950/2000] tot_loss=1.317 (perp=6.181, rec=0.078, cos=0.003), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.309 (perp=6.181, rec=0.070, cos=0.003), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] the rock placed the sky with the fork. [SEP]
========================
predicted: 
========================
[CLS] the rock placed the fork gravity with the sky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 73.684 | p: 70.000 | r: 77.778
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 168.922

[Aggregate metrics]:
rouge1     | fm: 78.267 | p: 78.163 | r: 78.638
rouge2     | fm: 38.865 | p: 38.663 | r: 39.223
rougeL     | fm: 67.984 | p: 68.038 | r: 68.360
rougeLsum  | fm: 67.995 | p: 68.010 | r: 68.234
r1fm+r2fm = 117.131

input #80 time: 0:06:45 | total time: 11:01:39


Running input #81 of 100.
reference: 
========================
Tagalog is speaks in the Philippines.
========================
average of cosine similarity 0.9993406957852711
highest_index [0]
highest [0.9993406957852711]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  6415, 23067,  2290,  2003,  8847,  1999,  1996,  5137,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] tagalog is speaks in the philippines. [SEP]']
[Init] best rec loss: 0.8218028545379639 for ['[CLS]lch scotland uhf qualifying claude worse attempt faye costs [SEP]']
[Init] best rec loss: 0.8192242980003357 for ['[CLS] college school hismic nord mate genes transfer heir [SEP]']
[Init] best rec loss: 0.7856317758560181 for ['[CLS] extraburo and committed method pali co guess ir [SEP]']
[Init] best rec loss: 0.7316059470176697 for ['[CLS]ei understand turn infrastructure galley project tracks annual [SEP]']
[Init] best rec loss: 0.7133926153182983 for ['[CLS] opened grtain ft slow lattice season brake miriam [SEP]']
[Init] best rec loss: 0.705670177936554 for ['[CLS] horticultural example overlooking againstside anita hours ; followed [SEP]']
[Init] best rec loss: 0.6805224418640137 for ['[CLS] bigger maxim when interchange for cavity ª before apps [SEP]']
[Init] best perm rec loss: 0.6777098178863525 for ['[CLS] apps bigger when maxim ª cavity interchange for before [SEP]']
[Init] best perm rec loss: 0.6731835007667542 for ['[CLS] maxim apps interchange before when bigger cavity for ª [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.410 (perp=10.278, rec=0.317, cos=0.037), tot_loss_proj:2.736 [t=0.16s]
prediction: ['[CLS] arabic philippine speaks is filipino is science in philippines [SEP]']
[ 100/2000] tot_loss=2.152 (perp=9.531, rec=0.230, cos=0.015), tot_loss_proj:2.696 [t=0.17s]
prediction: ['[CLS] nose philippines is is filipino is speak in philippines [SEP]']
[ 150/2000] tot_loss=2.429 (perp=11.011, rec=0.215, cos=0.012), tot_loss_proj:2.981 [t=0.17s]
prediction: ['[CLS] nose philippines is isalo speaks speak in philippines [SEP]']
[ 200/2000] tot_loss=2.410 (perp=11.170, rec=0.167, cos=0.009), tot_loss_proj:3.026 [t=0.17s]
prediction: ['[CLS] text tag is isalo speaks speaks in philippines [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.252 (perp=9.542, rec=0.315, cos=0.029), tot_loss_proj:2.601 [t=0.17s]
prediction: ['[CLS] cyrillic is is tagalo speaks speaks in philippines [SEP]']
[ 300/2000] tot_loss=2.163 (perp=9.763, rec=0.200, cos=0.011), tot_loss_proj:2.538 [t=0.17s]
prediction: ['[CLS]g is is tagalo speaks speaks in philippines [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.765 (perp=7.800, rec=0.194, cos=0.011), tot_loss_proj:2.360 [t=0.17s]
prediction: ['[CLS] in tagalog is speaks speaks in philippines [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.833 (perp=8.068, rec=0.205, cos=0.014), tot_loss_proj:2.381 [t=0.17s]
prediction: ['[CLS] is speaks in tagaloan speaks in philippines [SEP]']
[ 450/2000] tot_loss=2.040 (perp=9.375, rec=0.157, cos=0.008), tot_loss_proj:2.633 [t=0.17s]
prediction: ['[CLS] is speaks ingaloan speaks in philippines [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.146 (perp=9.911, rec=0.156, cos=0.007), tot_loss_proj:2.684 [t=0.17s]
prediction: ['[CLS] isg speaks ingalo speaks in philippines [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.033 (perp=9.375, rec=0.151, cos=0.007), tot_loss_proj:2.634 [t=0.17s]
prediction: ['[CLS] is speaks ingaloan speaks in philippines [SEP]']
[ 600/2000] tot_loss=2.203 (perp=10.276, rec=0.142, cos=0.006), tot_loss_proj:2.855 [t=0.17s]
prediction: ['[CLS] is speaks ingalo tag speaks in philippines [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.894 (perp=8.760, rec=0.137, cos=0.006), tot_loss_proj:2.540 [t=0.17s]
prediction: ['[CLS] is speaks in taggalo speaks in philippines [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.442 (perp=6.475, rec=0.141, cos=0.005), tot_loss_proj:2.057 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
[ 750/2000] tot_loss=1.433 (perp=6.475, rec=0.133, cos=0.005), tot_loss_proj:2.059 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.438 (perp=6.475, rec=0.138, cos=0.005), tot_loss_proj:2.063 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.426 (perp=6.475, rec=0.126, cos=0.005), tot_loss_proj:2.061 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
[ 900/2000] tot_loss=1.424 (perp=6.475, rec=0.124, cos=0.005), tot_loss_proj:2.058 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.422 (perp=6.475, rec=0.122, cos=0.005), tot_loss_proj:2.057 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[1000/2000] tot_loss=1.422 (perp=6.475, rec=0.122, cos=0.005), tot_loss_proj:2.060 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
[1050/2000] tot_loss=1.434 (perp=6.475, rec=0.134, cos=0.005), tot_loss_proj:2.060 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[1100/2000] tot_loss=1.417 (perp=6.475, rec=0.117, cos=0.005), tot_loss_proj:2.060 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[1150/2000] tot_loss=1.419 (perp=6.475, rec=0.119, cos=0.005), tot_loss_proj:2.059 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
[1200/2000] tot_loss=1.422 (perp=6.475, rec=0.122, cos=0.005), tot_loss_proj:2.063 [t=0.17s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[1250/2000] tot_loss=1.420 (perp=6.475, rec=0.120, cos=0.005), tot_loss_proj:2.060 [t=0.19s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[1300/2000] tot_loss=1.419 (perp=6.475, rec=0.119, cos=0.005), tot_loss_proj:2.058 [t=0.20s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
[1350/2000] tot_loss=1.429 (perp=6.475, rec=0.130, cos=0.005), tot_loss_proj:2.059 [t=0.20s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[1400/2000] tot_loss=1.418 (perp=6.475, rec=0.119, cos=0.004), tot_loss_proj:2.060 [t=0.20s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[1450/2000] tot_loss=1.413 (perp=6.475, rec=0.113, cos=0.004), tot_loss_proj:2.059 [t=0.18s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
[1500/2000] tot_loss=1.414 (perp=6.475, rec=0.115, cos=0.004), tot_loss_proj:2.059 [t=0.18s]
prediction: ['[CLS] is speaks in tagalog speaks in philippines [SEP]']
Attempt swap
[1550/2000] tot_loss=1.407 (perp=6.410, rec=0.121, cos=0.004), tot_loss_proj:1.840 [t=0.19s]
prediction: ['[CLS] is speaks in tagalog spoke in philippines [SEP]']
Attempt swap
[1600/2000] tot_loss=1.412 (perp=6.410, rec=0.126, cos=0.004), tot_loss_proj:1.835 [t=0.19s]
prediction: ['[CLS] is speaks in tagalog spoke in philippines [SEP]']
[1650/2000] tot_loss=1.410 (perp=6.410, rec=0.124, cos=0.004), tot_loss_proj:1.832 [t=0.18s]
prediction: ['[CLS] is speaks in tagalog spoke in philippines [SEP]']
Attempt swap
[1700/2000] tot_loss=1.517 (perp=6.976, rec=0.117, cos=0.004), tot_loss_proj:2.013 [t=0.22s]
prediction: ['[CLS] is speaks the tagalog spoke in philippines [SEP]']
Attempt swap
[1750/2000] tot_loss=1.515 (perp=6.976, rec=0.115, cos=0.004), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] is speaks the tagalog spoke in philippines [SEP]']
[1800/2000] tot_loss=1.517 (perp=6.976, rec=0.117, cos=0.004), tot_loss_proj:2.009 [t=0.20s]
prediction: ['[CLS] is speaks the tagalog spoke in philippines [SEP]']
Attempt swap
[1850/2000] tot_loss=1.513 (perp=6.976, rec=0.114, cos=0.004), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] is speaks the tagalog spoke in philippines [SEP]']
Attempt swap
[1900/2000] tot_loss=1.524 (perp=6.976, rec=0.125, cos=0.004), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] is speaks the tagalog spoke in philippines [SEP]']
[1950/2000] tot_loss=1.513 (perp=6.976, rec=0.113, cos=0.004), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] is speaks the tagalog spoke in philippines [SEP]']
Attempt swap
[2000/2000] tot_loss=1.521 (perp=6.976, rec=0.121, cos=0.004), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] is speaks the tagalog spoke in philippines [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] tagalog is speaks in the philippines. [SEP]
========================
predicted: 
========================
[CLS] is speaks the tagalog spoke in philippines [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 26.667 | p: 25.000 | r: 28.571
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 120.784

[Aggregate metrics]:
rouge1     | fm: 78.453 | p: 78.320 | r: 78.943
rouge2     | fm: 38.634 | p: 38.484 | r: 39.052
rougeL     | fm: 67.988 | p: 68.032 | r: 68.317
rougeLsum  | fm: 67.932 | p: 67.936 | r: 68.303
r1fm+r2fm = 117.087

input #81 time: 0:06:53 | total time: 11:08:32


Running input #82 of 100.
reference: 
========================
He waltzed her across the floor.
========================
average of cosine similarity 0.9995051539996079
highest_index [0]
highest [0.9995051539996079]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2002, 17569,  2098,  2014,  2408,  1996,  2723,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] he waltzed her across the floor. [SEP]']
[Init] best rec loss: 1.0006637573242188 for ['[CLS] beverly womenboat [MASK] greatly waterfold bears [SEP]']
[Init] best rec loss: 1.0003470182418823 for ['[CLS] because star usc but ginger boltontial nat [SEP]']
[Init] best rec loss: 1.0000369548797607 for ['[CLS] bottom especially fed wake ingpy existencerted [SEP]']
[Init] best rec loss: 0.9792600870132446 for ['[CLS]yreang mythopped older jackson cause ɡ [SEP]']
[Init] best rec loss: 0.9738048315048218 for ['[CLS] 50 formed viewing trevorple meeting bundle live [SEP]']
[Init] best rec loss: 0.9515565037727356 for ['[CLS] fraternity concern there times menu stoptford studio [SEP]']
[Init] best rec loss: 0.9510055184364319 for ['[CLS] tor cox flooread maintain km² fledged grupo [SEP]']
[Init] best rec loss: 0.9505051970481873 for ['[CLS] needed brieflyuth doing further here those honour [SEP]']
[Init] best rec loss: 0.9423287510871887 for ['[CLS] exhibited samson mix posing sc issued ernie program [SEP]']
[Init] best perm rec loss: 0.9409102201461792 for ['[CLS] issued ernie exhibited program samson posing mix sc [SEP]']
[Init] best perm rec loss: 0.940762996673584 for ['[CLS] program sc samson issued exhibited mix ernie posing [SEP]']
[Init] best perm rec loss: 0.9402257800102234 for ['[CLS] program ernie exhibited posing sc mix issued samson [SEP]']
[Init] best perm rec loss: 0.9393174648284912 for ['[CLS] program sc issued exhibited ernie posing mix samson [SEP]']
[Init] best perm rec loss: 0.93841952085495 for ['[CLS] ernie sc samson issued program exhibited mix posing [SEP]']
[Init] best perm rec loss: 0.9383668303489685 for ['[CLS] program posing sc samson exhibited ernie issued mix [SEP]']
[Init] best perm rec loss: 0.9381166696548462 for ['[CLS] ernie sc program samson exhibited issued mix posing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.141 (perp=13.426, rec=0.397, cos=0.058), tot_loss_proj:4.668 [t=0.16s]
prediction: ['[CLS] ballet truss jam waltz room grant strolledkal [SEP]']
[ 100/2000] tot_loss=2.099 (perp=8.596, rec=0.334, cos=0.045), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] waltz waltzed waltz floor ha waltz waltz [SEP]']
[ 150/2000] tot_loss=2.205 (perp=9.733, rec=0.242, cos=0.017), tot_loss_proj:3.852 [t=0.17s]
prediction: ['[CLS] he waltzed waltz floor its waltztte [SEP]']
[ 200/2000] tot_loss=2.048 (perp=9.302, rec=0.174, cos=0.014), tot_loss_proj:3.866 [t=0.17s]
prediction: ['[CLS] he waltzed waltz across its waltztte [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.161 (perp=9.804, rec=0.183, cos=0.017), tot_loss_proj:3.891 [t=0.17s]
prediction: ['[CLS] he waltz her across the waltz waltzlling [SEP]']
[ 300/2000] tot_loss=2.032 (perp=9.407, rec=0.140, cos=0.010), tot_loss_proj:3.898 [t=0.17s]
prediction: ['[CLS] he waltz her across the waltz floorlling [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.850 (perp=8.581, rec=0.124, cos=0.009), tot_loss_proj:3.735 [t=0.17s]
prediction: ['[CLS] he waltz her across the waltztte floor [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.841 (perp=8.581, rec=0.116, cos=0.009), tot_loss_proj:3.738 [t=0.17s]
prediction: ['[CLS] he waltz her across the waltztte floor [SEP]']
[ 450/2000] tot_loss=1.465 (perp=6.692, rec=0.117, cos=0.009), tot_loss_proj:3.156 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.465 (perp=6.692, rec=0.118, cos=0.009), tot_loss_proj:3.154 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.467 (perp=6.692, rec=0.120, cos=0.009), tot_loss_proj:3.156 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
[ 600/2000] tot_loss=1.466 (perp=6.692, rec=0.119, cos=0.008), tot_loss_proj:3.162 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.473 (perp=6.692, rec=0.126, cos=0.008), tot_loss_proj:3.160 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.463 (perp=6.692, rec=0.116, cos=0.008), tot_loss_proj:3.156 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
[ 750/2000] tot_loss=1.462 (perp=6.692, rec=0.116, cos=0.008), tot_loss_proj:3.163 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.455 (perp=6.692, rec=0.109, cos=0.008), tot_loss_proj:3.158 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.458 (perp=6.692, rec=0.112, cos=0.007), tot_loss_proj:3.163 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
[ 900/2000] tot_loss=1.463 (perp=6.692, rec=0.118, cos=0.007), tot_loss_proj:3.160 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.453 (perp=6.692, rec=0.107, cos=0.007), tot_loss_proj:3.163 [t=0.19s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[1000/2000] tot_loss=1.454 (perp=6.692, rec=0.109, cos=0.007), tot_loss_proj:3.165 [t=0.19s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
[1050/2000] tot_loss=1.458 (perp=6.692, rec=0.113, cos=0.007), tot_loss_proj:3.165 [t=0.19s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[1100/2000] tot_loss=1.448 (perp=6.692, rec=0.102, cos=0.007), tot_loss_proj:3.165 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[1150/2000] tot_loss=1.456 (perp=6.692, rec=0.110, cos=0.007), tot_loss_proj:3.164 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
[1200/2000] tot_loss=1.455 (perp=6.692, rec=0.110, cos=0.007), tot_loss_proj:3.165 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[1250/2000] tot_loss=1.454 (perp=6.692, rec=0.109, cos=0.007), tot_loss_proj:3.165 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[1300/2000] tot_loss=1.458 (perp=6.692, rec=0.113, cos=0.007), tot_loss_proj:3.164 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
[1350/2000] tot_loss=1.451 (perp=6.692, rec=0.106, cos=0.006), tot_loss_proj:3.160 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltztte floor [SEP]']
Attempt swap
[1400/2000] tot_loss=1.515 (perp=7.017, rec=0.105, cos=0.006), tot_loss_proj:3.348 [t=0.22s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
Attempt swap
[1450/2000] tot_loss=1.515 (perp=7.017, rec=0.105, cos=0.006), tot_loss_proj:3.341 [t=0.20s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
[1500/2000] tot_loss=1.519 (perp=7.017, rec=0.110, cos=0.006), tot_loss_proj:3.343 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
Attempt swap
[1550/2000] tot_loss=1.521 (perp=7.017, rec=0.112, cos=0.006), tot_loss_proj:3.346 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
Attempt swap
[1600/2000] tot_loss=1.521 (perp=7.017, rec=0.112, cos=0.006), tot_loss_proj:3.347 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
[1650/2000] tot_loss=1.523 (perp=7.017, rec=0.113, cos=0.006), tot_loss_proj:3.351 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
Attempt swap
[1700/2000] tot_loss=1.518 (perp=7.017, rec=0.108, cos=0.006), tot_loss_proj:3.346 [t=0.18s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
Attempt swap
[1750/2000] tot_loss=1.522 (perp=7.017, rec=0.113, cos=0.006), tot_loss_proj:3.347 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
[1800/2000] tot_loss=1.524 (perp=7.017, rec=0.114, cos=0.006), tot_loss_proj:3.348 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
Attempt swap
[1850/2000] tot_loss=1.525 (perp=7.017, rec=0.116, cos=0.006), tot_loss_proj:3.350 [t=0.17s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
Attempt swap
[1900/2000] tot_loss=1.507 (perp=7.017, rec=0.098, cos=0.006), tot_loss_proj:3.341 [t=0.18s]
prediction: ['[CLS] he waltzed across the waltz engineering floor [SEP]']
[1950/2000] tot_loss=1.912 (perp=8.996, rec=0.107, cos=0.006), tot_loss_proj:3.805 [t=0.18s]
prediction: ['[CLS] he waltzed across \\ waltz engineering floor [SEP]']
Attempt swap
[2000/2000] tot_loss=1.914 (perp=8.996, rec=0.109, cos=0.006), tot_loss_proj:3.806 [t=0.20s]
prediction: ['[CLS] he waltzed across \\ waltz engineering floor [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] he waltzed her across the floor. [SEP]
========================
predicted: 
========================
[CLS] he waltzed across the waltztte floor [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 144.643

[Aggregate metrics]:
rouge1     | fm: 78.548 | p: 78.393 | r: 79.022
rouge2     | fm: 38.948 | p: 38.773 | r: 39.329
rougeL     | fm: 68.218 | p: 68.231 | r: 68.524
rougeLsum  | fm: 68.145 | p: 68.117 | r: 68.498
r1fm+r2fm = 117.495

input #82 time: 0:06:54 | total time: 11:15:27


Running input #83 of 100.
reference: 
========================
How easy to please John is it?
========================
average of cosine similarity 0.9991972001687284
highest_index [0]
highest [0.9991972001687284]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2129, 3733, 2000, 3531, 2198, 2003, 2009, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] how easy to please john is it? [SEP]']
[Init] best rec loss: 0.9373605251312256 for ['[CLS] blacksmith straight heart comprises works right wa would [SEP]']
[Init] best rec loss: 0.7622125744819641 for ['[CLS] god bay hungarianaround dad pony medal i [SEP]']
[Init] best rec loss: 0.7569143772125244 for ['[CLS] trevorntsgni midway coup eye denied disputed [SEP]']
[Init] best rec loss: 0.7506915330886841 for ['[CLS] lead addressed cruz irish nice motion | father [SEP]']
[Init] best rec loss: 0.7334410548210144 for ['[CLS] motor pacificeni confined near abby holding curled [SEP]']
[Init] best rec loss: 0.7291074395179749 for ['[CLS] buddy city piccoloweed ledger bulb print second [SEP]']
[Init] best rec loss: 0.7228348255157471 for ['[CLS] tonight stupid covering to scores up storm fake [SEP]']
[Init] best rec loss: 0.7001823782920837 for ['[CLS] spent tr paddington kingdoms ryder master jr sides [SEP]']
[Init] best perm rec loss: 0.698954701423645 for ['[CLS] master sides spent ryder kingdoms paddington jr tr [SEP]']
[Init] best perm rec loss: 0.6988367438316345 for ['[CLS] spent master sides paddington ryder jr tr kingdoms [SEP]']
[Init] best perm rec loss: 0.6987406611442566 for ['[CLS] spent paddington ryder master tr kingdoms jr sides [SEP]']
[Init] best perm rec loss: 0.6986838579177856 for ['[CLS] sides master paddington ryder tr spent jr kingdoms [SEP]']
[Init] best perm rec loss: 0.698501467704773 for ['[CLS] sides spent master ryder kingdoms tr jr paddington [SEP]']
[Init] best perm rec loss: 0.6980337500572205 for ['[CLS] jr tr master paddington kingdoms spent ryder sides [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.835 (perp=11.901, rec=0.386, cos=0.068), tot_loss_proj:3.409 [t=0.16s]
prediction: ['[CLS] organisms always is irish easy [MASK] please college [SEP]']
[ 100/2000] tot_loss=2.430 (perp=10.250, rec=0.326, cos=0.054), tot_loss_proj:3.257 [t=0.17s]
prediction: ['[CLS] easy always is how john by please please [SEP]']
[ 150/2000] tot_loss=2.765 (perp=11.215, rec=0.437, cos=0.085), tot_loss_proj:3.153 [t=0.17s]
prediction: ['[CLS] harder neither is free john archives + largely [SEP]']
[ 200/2000] tot_loss=2.525 (perp=10.714, rec=0.331, cos=0.051), tot_loss_proj:3.042 [t=0.17s]
prediction: ['[CLS] easy either is please john archives easy please [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.465 (perp=9.872, rec=0.420, cos=0.071), tot_loss_proj:2.908 [t=0.17s]
prediction: ['[CLS] easy either is please john simple easy structure [SEP]']
[ 300/2000] tot_loss=2.426 (perp=10.459, rec=0.306, cos=0.029), tot_loss_proj:3.250 [t=0.17s]
prediction: ['[CLS] easy how is please john simple easy corps [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.957 (perp=8.403, rec=0.253, cos=0.024), tot_loss_proj:2.958 [t=0.17s]
prediction: ['[CLS] how easy is please it please easy techniques [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.840 (perp=8.096, rec=0.204, cos=0.018), tot_loss_proj:3.076 [t=0.17s]
prediction: ['[CLS] how easy is please it please please lady [SEP]']
[ 450/2000] tot_loss=1.870 (perp=8.401, rec=0.176, cos=0.014), tot_loss_proj:3.269 [t=0.17s]
prediction: ['[CLS] how easy is john it please please lady [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.628 (perp=7.294, rec=0.158, cos=0.012), tot_loss_proj:3.077 [t=0.17s]
prediction: ['[CLS] how easy is please it please john? [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.462 (perp=6.576, rec=0.135, cos=0.012), tot_loss_proj:2.283 [t=0.19s]
prediction: ['[CLS] how easy is it please john please? [SEP]']
[ 600/2000] tot_loss=1.460 (perp=6.576, rec=0.135, cos=0.010), tot_loss_proj:2.283 [t=0.17s]
prediction: ['[CLS] how easy is it please john please? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.454 (perp=6.576, rec=0.129, cos=0.010), tot_loss_proj:2.277 [t=0.17s]
prediction: ['[CLS] how easy is it please john please? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.449 (perp=6.576, rec=0.124, cos=0.010), tot_loss_proj:2.279 [t=0.17s]
prediction: ['[CLS] how easy is it please john please? [SEP]']
[ 750/2000] tot_loss=1.442 (perp=6.576, rec=0.118, cos=0.009), tot_loss_proj:2.275 [t=0.17s]
prediction: ['[CLS] how easy is it please john please? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.432 (perp=6.576, rec=0.108, cos=0.009), tot_loss_proj:2.277 [t=0.17s]
prediction: ['[CLS] how easy is it please john please? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.443 (perp=6.576, rec=0.119, cos=0.008), tot_loss_proj:2.271 [t=0.17s]
prediction: ['[CLS] how easy is it please john please? [SEP]']
[ 900/2000] tot_loss=1.432 (perp=6.576, rec=0.109, cos=0.007), tot_loss_proj:2.271 [t=0.17s]
prediction: ['[CLS] how easy is it please john please? [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.404 (perp=6.429, rec=0.112, cos=0.006), tot_loss_proj:2.358 [t=0.16s]
prediction: ['[CLS] how easy it is please john please? [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.333 (perp=6.083, rec=0.111, cos=0.006), tot_loss_proj:2.225 [t=0.18s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
[1050/2000] tot_loss=1.316 (perp=6.083, rec=0.095, cos=0.005), tot_loss_proj:2.227 [t=0.19s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1100/2000] tot_loss=1.327 (perp=6.083, rec=0.106, cos=0.004), tot_loss_proj:2.234 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1150/2000] tot_loss=1.323 (perp=6.083, rec=0.102, cos=0.004), tot_loss_proj:2.224 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
[1200/2000] tot_loss=1.324 (perp=6.083, rec=0.103, cos=0.004), tot_loss_proj:2.233 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1250/2000] tot_loss=1.319 (perp=6.083, rec=0.098, cos=0.004), tot_loss_proj:2.223 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1300/2000] tot_loss=1.318 (perp=6.083, rec=0.097, cos=0.004), tot_loss_proj:2.228 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
[1350/2000] tot_loss=1.313 (perp=6.083, rec=0.092, cos=0.004), tot_loss_proj:2.235 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1400/2000] tot_loss=1.314 (perp=6.083, rec=0.093, cos=0.004), tot_loss_proj:2.231 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1450/2000] tot_loss=1.318 (perp=6.083, rec=0.097, cos=0.004), tot_loss_proj:2.230 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
[1500/2000] tot_loss=1.320 (perp=6.083, rec=0.099, cos=0.004), tot_loss_proj:2.232 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1550/2000] tot_loss=1.320 (perp=6.083, rec=0.099, cos=0.004), tot_loss_proj:2.227 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1600/2000] tot_loss=1.314 (perp=6.083, rec=0.094, cos=0.004), tot_loss_proj:2.233 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
[1650/2000] tot_loss=1.312 (perp=6.083, rec=0.091, cos=0.004), tot_loss_proj:2.233 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1700/2000] tot_loss=1.320 (perp=6.083, rec=0.099, cos=0.004), tot_loss_proj:2.227 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1750/2000] tot_loss=1.317 (perp=6.083, rec=0.096, cos=0.004), tot_loss_proj:2.229 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
[1800/2000] tot_loss=1.316 (perp=6.083, rec=0.095, cos=0.004), tot_loss_proj:2.235 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1850/2000] tot_loss=1.317 (perp=6.083, rec=0.097, cos=0.004), tot_loss_proj:2.226 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[1900/2000] tot_loss=1.312 (perp=6.083, rec=0.092, cos=0.004), tot_loss_proj:2.228 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
[1950/2000] tot_loss=1.327 (perp=6.083, rec=0.106, cos=0.004), tot_loss_proj:2.234 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Attempt swap
[2000/2000] tot_loss=1.310 (perp=6.083, rec=0.089, cos=0.004), tot_loss_proj:2.228 [t=0.17s]
prediction: ['[CLS] how easy it is please please? john [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] how easy to please john is it? [SEP]
========================
predicted: 
========================
[CLS] how easy it is please please? john [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 126.389

[Aggregate metrics]:
rouge1     | fm: 78.711 | p: 78.555 | r: 79.192
rouge2     | fm: 38.880 | p: 38.697 | r: 39.252
rougeL     | fm: 68.209 | p: 68.172 | r: 68.563
rougeLsum  | fm: 68.152 | p: 68.100 | r: 68.542
r1fm+r2fm = 117.591

input #83 time: 0:06:39 | total time: 11:22:06


Running input #84 of 100.
reference: 
========================
That the king or queen be present is a requirement on all Royal weddings.
========================
average of cosine similarity 0.9993769048273349
highest_index [0]
highest [0.9993769048273349]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2008,  1996,  2332,  2030,  3035,  2022,  2556,  2003,  1037,
          9095,  2006,  2035,  2548, 20429,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]']
[Init] best rec loss: 0.9533893465995789 for ['[CLS] y during udnsorlot shed art closed described power na seriously guild le grinding [SEP]']
[Init] best rec loss: 0.9478017091751099 for ['[CLS] calling time action restrictionhui edge still equality municipality part genieint compelledomp remainder [SEP]']
[Init] best rec loss: 0.9476109743118286 for ['[CLS] mold awful sighs ever shane scottish saetan tu way pin then band paintingssp ridley [SEP]']
[Init] best rec loss: 0.9459329843521118 for ['[CLS] multi class epic average consensus ) international mine heels trim bone erica drama say ren [SEP]']
[Init] best rec loss: 0.9199742078781128 for ['[CLS] metro coulddilly sees command vanessacter zane bend deadly his ledger day 95 poetry [SEP]']
[Init] best rec loss: 0.9192661643028259 for ['[CLS] mid village eastern though sold trafficking royce thanks concerned google member cross humorous climbingtom [SEP]']
[Init] best rec loss: 0.9171982407569885 for ['[CLS] leads reputation amassed as sept education mona t everything questions state ground safety inside kick [SEP]']
[Init] best rec loss: 0.9159625768661499 for ['[CLS] beatmission round truck dissolvedκ wishes residential problems tadestinalinavina imp spirit [SEP]']
[Init] best rec loss: 0.9154359102249146 for ['[CLS] barracks replacedmanful reid avenueorous ads kurt text criminalicing sloane feel brand [SEP]']
[Init] best rec loss: 0.9110174179077148 for ['[CLS]eon way grove church [MASK] style redistribution war better sherry dock traffic bound admission blessing [SEP]']
[Init] best rec loss: 0.9109504222869873 for ['[CLS]bedo legal will pregnant hewitt camera earlier ongoingrralł o mouth would regardedown [SEP]']
[Init] best perm rec loss: 0.9088231325149536 for ['[CLS] pregnant camera ongoingł legalbedo would regarded earlierrral mouth hewitt oown will [SEP]']
[Init] best perm rec loss: 0.9083888530731201 for ['[CLS] regardedown pregnant ongoing earlier mouth legal hewitt would camerałbedo orral will [SEP]']
[Init] best perm rec loss: 0.90836501121521 for ['[CLS] ongoing will pregnantbedo camera legal regarded hewittrral mouth earlierown wouldł o [SEP]']
[Init] best perm rec loss: 0.9055202007293701 for ['[CLS] ongoing regarded camera earlier o pregnantrral will mouthbedoł legal hewitt wouldown [SEP]']
[Init] best perm rec loss: 0.9041357040405273 for ['[CLS] o would regarded mouth camera earlier pregnant ongoing willrralbedoł legalown hewitt [SEP]']
[Init] best perm rec loss: 0.9036893248558044 for ['[CLS] o ongoing earlier willown pregnant regardedł legal mouth hewitt camera wouldbedorral [SEP]']
[Init] best perm rec loss: 0.9027160406112671 for ['[CLS] ongoingł o legalrralownbedo would pregnant camera mouth hewitt will earlier regarded [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.780 (perp=11.818, rec=0.375, cos=0.041), tot_loss_proj:4.229 [t=0.17s]
prediction: ['[CLS]ium being within baroque princess win the royalime mrs john beard,... as [SEP]']
[ 100/2000] tot_loss=2.224 (perp=9.640, rec=0.275, cos=0.020), tot_loss_proj:3.741 [t=0.17s]
prediction: ['[CLS]ium were on weddings princess with the royal allowed mrs on weddings,. as [SEP]']
[ 150/2000] tot_loss=2.181 (perp=9.739, rec=0.220, cos=0.014), tot_loss_proj:3.782 [t=0.17s]
prediction: ['[CLS] non is on weddings queen be the royal requires cannot queen weddings,. as [SEP]']
[ 200/2000] tot_loss=2.138 (perp=9.695, rec=0.190, cos=0.010), tot_loss_proj:3.784 [t=0.17s]
prediction: ['[CLS] required is on weddings queen be the royal requires cannot queen weddings royal. the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.987 (perp=9.003, rec=0.178, cos=0.008), tot_loss_proj:3.646 [t=0.17s]
prediction: ['[CLS] requirement is on be queen weddings the royal requirement cannot queen king royal. the [SEP]']
[ 300/2000] tot_loss=1.836 (perp=8.398, rec=0.151, cos=0.006), tot_loss_proj:3.534 [t=0.17s]
prediction: ['[CLS] requirement is on be queen weddings the royal requirement or queen king royal. the [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.893 (perp=8.735, rec=0.140, cos=0.005), tot_loss_proj:3.568 [t=0.17s]
prediction: ['[CLS] weddings requirement is on present queen that royal requirement or a king royal. or [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.889 (perp=8.592, rec=0.163, cos=0.007), tot_loss_proj:3.639 [t=0.17s]
prediction: ['[CLS] that weddings requirement is on present queen royal requirement or moat king royal. - [SEP]']
[ 450/2000] tot_loss=1.700 (perp=7.817, rec=0.132, cos=0.004), tot_loss_proj:3.401 [t=0.17s]
prediction: ['[CLS] that weddings requirement is on present queen royal any or a king royal. on [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.207 (perp=9.671, rec=0.253, cos=0.020), tot_loss_proj:3.785 [t=0.17s]
prediction: ['[CLS] that weddings requirement is be on queen [SEP] any queen a regent royal. big [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.942 (perp=8.751, rec=0.182, cos=0.010), tot_loss_proj:3.613 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on queen all any queen a regent royaluted. [SEP]']
[ 600/2000] tot_loss=1.905 (perp=8.751, rec=0.148, cos=0.007), tot_loss_proj:3.613 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on queen all any queen a regent royaluted. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.793 (perp=8.256, rec=0.135, cos=0.006), tot_loss_proj:3.591 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any queen a owner king royaluted. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.648 (perp=7.494, rec=0.143, cos=0.006), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any queen owner a king royaluted. [SEP]']
[ 750/2000] tot_loss=1.628 (perp=7.494, rec=0.124, cos=0.005), tot_loss_proj:3.419 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any queen owner a king royaluted. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.625 (perp=7.494, rec=0.121, cos=0.005), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any queen owner a king royaluted. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.618 (perp=7.494, rec=0.114, cos=0.005), tot_loss_proj:3.415 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any queen owner a king royaluted. [SEP]']
[ 900/2000] tot_loss=1.695 (perp=7.820, rec=0.126, cos=0.005), tot_loss_proj:3.430 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any queen owner a king royal than. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.551 (perp=7.130, rec=0.120, cos=0.005), tot_loss_proj:3.305 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any queen owner a king than royal. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.478 (perp=6.803, rec=0.113, cos=0.005), tot_loss_proj:3.244 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner or a king than royal. [SEP]']
[1050/2000] tot_loss=1.482 (perp=6.803, rec=0.117, cos=0.005), tot_loss_proj:3.241 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner or a king than royal. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.410 (perp=6.446, rec=0.116, cos=0.005), tot_loss_proj:3.190 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.410 (perp=6.446, rec=0.116, cos=0.005), tot_loss_proj:3.186 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
[1200/2000] tot_loss=1.408 (perp=6.446, rec=0.114, cos=0.004), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.402 (perp=6.446, rec=0.108, cos=0.004), tot_loss_proj:3.186 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.407 (perp=6.446, rec=0.113, cos=0.004), tot_loss_proj:3.185 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
[1350/2000] tot_loss=1.405 (perp=6.446, rec=0.111, cos=0.004), tot_loss_proj:3.189 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.398 (perp=6.446, rec=0.105, cos=0.004), tot_loss_proj:3.188 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.405 (perp=6.446, rec=0.111, cos=0.004), tot_loss_proj:3.188 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
[1500/2000] tot_loss=1.399 (perp=6.446, rec=0.105, cos=0.004), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.400 (perp=6.446, rec=0.107, cos=0.004), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.403 (perp=6.446, rec=0.109, cos=0.004), tot_loss_proj:3.182 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
[1650/2000] tot_loss=1.395 (perp=6.446, rec=0.102, cos=0.004), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.402 (perp=6.446, rec=0.109, cos=0.004), tot_loss_proj:3.190 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.400 (perp=6.446, rec=0.106, cos=0.004), tot_loss_proj:3.188 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
[1800/2000] tot_loss=1.405 (perp=6.446, rec=0.111, cos=0.004), tot_loss_proj:3.184 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.403 (perp=6.446, rec=0.109, cos=0.004), tot_loss_proj:3.188 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.391 (perp=6.446, rec=0.097, cos=0.004), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
[1950/2000] tot_loss=1.399 (perp=6.446, rec=0.106, cos=0.004), tot_loss_proj:3.186 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.394 (perp=6.446, rec=0.100, cos=0.004), tot_loss_proj:3.186 [t=0.17s]
prediction: ['[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]
========================
predicted: 
========================
[CLS] that weddings requirement is present on all any owner than a king or royal. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.250 | p: 81.250 | r: 81.250
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 43.750 | p: 43.750 | r: 43.750
rougeLsum  | fm: 43.750 | p: 43.750 | r: 43.750
r1fm+r2fm = 101.250

[Aggregate metrics]:
rouge1     | fm: 78.695 | p: 78.575 | r: 79.176
rouge2     | fm: 38.686 | p: 38.501 | r: 39.104
rougeL     | fm: 67.921 | p: 67.919 | r: 68.282
rougeLsum  | fm: 67.902 | p: 67.805 | r: 68.260
r1fm+r2fm = 117.381

input #84 time: 0:06:43 | total time: 11:28:49


Running input #85 of 100.
reference: 
========================
Aphrodite stinks to be omnipotent.
========================
average of cosine similarity 0.9992293766306252
highest_index [0]
highest [0.9992293766306252]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  9706,  8093,  7716,  4221, 27136,  2015,  2000,  2022, 18168,
          3490, 11008,  4765,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] aphrodite stinks to be omnipotent. [SEP]']
[Init] best rec loss: 0.963916003704071 for ['[CLS] grandchildren ghosts course [SEP]et chief view matt single ko pass rural entered [SEP]']
[Init] best rec loss: 0.8446941375732422 for ['[CLS] glancedュ lowell anna bathtana range focus deafules ball look shortened [SEP]']
[Init] best rec loss: 0.8403056263923645 for ['[CLS] bang hd people essential cell [UNK]ckweight wonder origin unique joshua pick [SEP]']
[Init] best rec loss: 0.8182287216186523 for ['[CLS] march mayoralloadsman greatuled coverskieox monuments res bree thomas [SEP]']
[Init] best rec loss: 0.7831145524978638 for ['[CLS] beneath asked string wrath chief premiere general kneltabas expected minute taiwanese careful [SEP]']
[Init] best rec loss: 0.7647914886474609 for ['[CLS] go legged camille song xavier greg corinne most minus fever formation pair se [SEP]']
[Init] best perm rec loss: 0.7635236978530884 for ['[CLS] minus most se legged fever camille xavier go song corinne formation greg pair [SEP]']
[Init] best perm rec loss: 0.7634173631668091 for ['[CLS] pair minus camille greg song corinne formation most xavier se fever legged go [SEP]']
[Init] best perm rec loss: 0.7633981704711914 for ['[CLS] formation song most camille legged greg pair minus se fever xavier go corinne [SEP]']
[Init] best perm rec loss: 0.7631508708000183 for ['[CLS] fever pair go song greg most xavier corinne formation minus camille se legged [SEP]']
[Init] best perm rec loss: 0.762401282787323 for ['[CLS] se go greg formation most song camille fever legged xavier minus pair corinne [SEP]']
[Init] best perm rec loss: 0.7608497738838196 for ['[CLS] most song minus legged greg formation corinne go pair camille fever se xavier [SEP]']
[Init] best perm rec loss: 0.7602949142456055 for ['[CLS] fever go xavier most corinne song legged pair minus camille greg formation se [SEP]']
[Init] best perm rec loss: 0.7601321339607239 for ['[CLS] se minus legged go pair formation xavier greg most camille song corinne fever [SEP]']
[Init] best perm rec loss: 0.7598096132278442 for ['[CLS] camille legged minus corinne fever formation song se most go pair xavier greg [SEP]']
[Init] best perm rec loss: 0.7597153186798096 for ['[CLS] corinne minus camille fever most greg song pair legged formation go xavier se [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.415 (perp=13.960, rec=0.450, cos=0.173), tot_loss_proj:4.149 [t=0.16s]
prediction: ['[CLS] match nominally lecturela demonmen largest red m seoul small penalty teachers [SEP]']
[ 100/2000] tot_loss=3.231 (perp=14.072, rec=0.337, cos=0.080), tot_loss_proj:4.059 [t=0.17s]
prediction: ['[CLS]ite volta stinkaishment nix weak gr topping minute stinkska bugs [SEP]']
[ 150/2000] tot_loss=3.005 (perp=13.455, rec=0.277, cos=0.037), tot_loss_proj:3.915 [t=0.17s]
prediction: ['[CLS]iteite stinkspot ports weak gr toppingpot stinkite bugs [SEP]']
[ 200/2000] tot_loss=2.709 (perp=12.219, rec=0.227, cos=0.039), tot_loss_proj:3.688 [t=0.17s]
prediction: ['[CLS]iteite stink topotent weak redodpot beite eureka [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.421 (perp=10.653, rec=0.228, cos=0.063), tot_loss_proj:3.645 [t=0.17s]
prediction: ['[CLS]iteite stink topotent against f mercury. bepotent [SEP]']
[ 300/2000] tot_loss=2.273 (perp=10.353, rec=0.179, cos=0.024), tot_loss_proj:3.683 [t=0.17s]
prediction: ['[CLS]iteite stink topotent to f mercury. bepotent [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.381 (perp=10.840, rec=0.170, cos=0.044), tot_loss_proj:3.696 [t=0.17s]
prediction: ['[CLS]iteite stink topotents brpotentod. be [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.972 (perp=13.431, rec=0.211, cos=0.074), tot_loss_proj:4.224 [t=0.17s]
prediction: ['[CLS]iteite stinkentpot tos fpotentod - be [SEP]']
[ 450/2000] tot_loss=2.705 (perp=12.671, rec=0.141, cos=0.030), tot_loss_proj:4.000 [t=0.17s]
prediction: ['[CLS]iteite stinkentpot toshrpotentod. be [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.566 (perp=12.045, rec=0.140, cos=0.016), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS]iteite stinkents toodhrpotentod. be [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.626 (perp=12.083, rec=0.185, cos=0.024), tot_loss_proj:3.619 [t=0.17s]
prediction: ['[CLS]iteite stinkents toodnnapotentodite be [SEP]']
[ 600/2000] tot_loss=2.593 (perp=12.218, rec=0.136, cos=0.014), tot_loss_proj:3.560 [t=0.17s]
prediction: ['[CLS]iteite stinkents toodshpotentodite be [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.255 (perp=10.500, rec=0.141, cos=0.014), tot_loss_proj:3.347 [t=0.17s]
prediction: ['[CLS]ite apite stinkss toshpotentodite be [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.156 (perp=9.974, rec=0.143, cos=0.018), tot_loss_proj:3.271 [t=0.16s]
prediction: ['[CLS]ite apites stinks toshpotentodite be [SEP]']
[ 750/2000] tot_loss=2.140 (perp=9.974, rec=0.134, cos=0.012), tot_loss_proj:3.276 [t=0.17s]
prediction: ['[CLS]ite apites stinks toshpotentodite be [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.141 (perp=9.991, rec=0.132, cos=0.011), tot_loss_proj:3.105 [t=0.17s]
prediction: ['[CLS]ite apites stinks tohrpotent beodite [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.066 (perp=9.562, rec=0.143, cos=0.011), tot_loss_proj:2.931 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent behrodod [SEP]']
[ 900/2000] tot_loss=2.044 (perp=9.562, rec=0.122, cos=0.009), tot_loss_proj:2.935 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent behrodod [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.015 (perp=9.406, rec=0.125, cos=0.009), tot_loss_proj:2.981 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
Attempt swap
[1000/2000] tot_loss=2.012 (perp=9.406, rec=0.121, cos=0.009), tot_loss_proj:2.990 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
[1050/2000] tot_loss=2.001 (perp=9.406, rec=0.111, cos=0.009), tot_loss_proj:2.982 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
Attempt swap
[1100/2000] tot_loss=1.999 (perp=9.406, rec=0.109, cos=0.008), tot_loss_proj:2.985 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
Attempt swap
[1150/2000] tot_loss=2.000 (perp=9.406, rec=0.111, cos=0.008), tot_loss_proj:2.978 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
[1200/2000] tot_loss=2.000 (perp=9.406, rec=0.111, cos=0.008), tot_loss_proj:2.977 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
Attempt swap
[1250/2000] tot_loss=2.002 (perp=9.406, rec=0.112, cos=0.008), tot_loss_proj:2.976 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
Attempt swap
[1300/2000] tot_loss=1.997 (perp=9.406, rec=0.108, cos=0.008), tot_loss_proj:2.982 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
[1350/2000] tot_loss=1.994 (perp=9.406, rec=0.105, cos=0.008), tot_loss_proj:2.980 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
Attempt swap
[1400/2000] tot_loss=2.000 (perp=9.406, rec=0.111, cos=0.008), tot_loss_proj:2.982 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
Attempt swap
[1450/2000] tot_loss=1.993 (perp=9.406, rec=0.104, cos=0.008), tot_loss_proj:2.982 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
[1500/2000] tot_loss=1.995 (perp=9.406, rec=0.107, cos=0.007), tot_loss_proj:2.973 [t=0.23s]
prediction: ['[CLS]ite apites stinks topotent beododhr [SEP]']
Attempt swap
[1550/2000] tot_loss=2.028 (perp=9.574, rec=0.105, cos=0.008), tot_loss_proj:3.028 [t=0.20s]
prediction: ['[CLS]ite apites stinks topotent beodhrhr [SEP]']
Attempt swap
[1600/2000] tot_loss=2.177 (perp=10.316, rec=0.107, cos=0.007), tot_loss_proj:3.167 [t=0.20s]
prediction: ['[CLS]ite apites stinks topotent beodhrni [SEP]']
[1650/2000] tot_loss=2.177 (perp=10.316, rec=0.106, cos=0.007), tot_loss_proj:3.165 [t=0.18s]
prediction: ['[CLS]ite apites stinks topotent beodhrni [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.190 (perp=10.404, rec=0.102, cos=0.007), tot_loss_proj:3.172 [t=0.16s]
prediction: ['[CLS]ite apites stinks tohrpotent beodhr [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=2.018 (perp=9.518, rec=0.106, cos=0.008), tot_loss_proj:2.919 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent behrodhr [SEP]']
[1800/2000] tot_loss=2.104 (perp=9.913, rec=0.114, cos=0.008), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beniodhr [SEP]']
Attempt swap
[1850/2000] tot_loss=2.094 (perp=9.913, rec=0.104, cos=0.007), tot_loss_proj:3.063 [t=0.17s]
prediction: ['[CLS]ite apites stinks topotent beniodhr [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.957 (perp=9.218, rec=0.106, cos=0.007), tot_loss_proj:2.899 [t=0.16s]
prediction: ['[CLS]ite apites stinks tonipotent beodhr [SEP]']
[1950/2000] tot_loss=1.951 (perp=9.218, rec=0.100, cos=0.007), tot_loss_proj:2.910 [t=0.17s]
prediction: ['[CLS]ite apites stinks tonipotent beodhr [SEP]']
Attempt swap
[2000/2000] tot_loss=1.976 (perp=9.297, rec=0.109, cos=0.007), tot_loss_proj:3.014 [t=0.17s]
prediction: ['[CLS]ite ap.s stinks tonipotent beodhr [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] aphrodite stinks to be omnipotent. [SEP]
========================
predicted: 
========================
[CLS]ite apites stinks tonipotent beodhr [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 42.857 | p: 42.857 | r: 42.857
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 42.857

[Aggregate metrics]:
rouge1     | fm: 78.324 | p: 78.181 | r: 78.775
rouge2     | fm: 38.251 | p: 38.073 | r: 38.602
rougeL     | fm: 67.594 | p: 67.625 | r: 67.953
rougeLsum  | fm: 67.586 | p: 67.616 | r: 67.929
r1fm+r2fm = 116.575

input #85 time: 0:06:43 | total time: 11:35:32


Running input #86 of 100.
reference: 
========================
I lifted him up the books.
========================
average of cosine similarity 0.9993153968093855
highest_index [0]
highest [0.9993153968093855]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1045, 4196, 2032, 2039, 1996, 2808, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i lifted him up the books. [SEP]']
[Init] best rec loss: 0.8596559762954712 for ['[CLS] associates kill blockade musica [SEP] bees... [SEP]']
[Init] best rec loss: 0.8160300850868225 for ['[CLS] geekping converted order early franchise pressing [SEP]']
[Init] best rec loss: 0.808757483959198 for ['[CLS] schools team legal lateents laird each [SEP]']
[Init] best rec loss: 0.7976799607276917 for ['[CLS] cara jar orchard wolf walking this negative [SEP]']
[Init] best rec loss: 0.7589608430862427 for ['[CLS] interest check indytute watch pitched licence [SEP]']
[Init] best rec loss: 0.739559531211853 for ['[CLS] did chin rearن spray davyologist [SEP]']
[Init] best rec loss: 0.7275917530059814 for ['[CLS]tonic based coveren booth novels infrared [SEP]']
[Init] best rec loss: 0.7006744742393494 for ['[CLS] made par letters imp carrier obviouss [SEP]']
[Init] best rec loss: 0.6927193999290466 for ['[CLS]arus bank groups bare primetime rub reviewer [SEP]']
[Init] best perm rec loss: 0.6910474300384521 for ['[CLS] reviewer rubarus groups bank primetime bare [SEP]']
[Init] best perm rec loss: 0.6876217722892761 for ['[CLS] rubarus bare bank groups reviewer primetime [SEP]']
[Init] best perm rec loss: 0.6860266923904419 for ['[CLS] rub bank primetime groupsarus reviewer bare [SEP]']
[Init] best perm rec loss: 0.6856589317321777 for ['[CLS] rub primetimearus reviewer groups bank bare [SEP]']
[Init] best perm rec loss: 0.6850431561470032 for ['[CLS] rub bank reviewerarus primetime groups bare [SEP]']
[Init] best perm rec loss: 0.6846989393234253 for ['[CLS] reviewer bare groups bank rub primetimearus [SEP]']
[Init] best perm rec loss: 0.6846939921379089 for ['[CLS] primetime bare groups bank rub reviewerarus [SEP]']
[Init] best perm rec loss: 0.6846843361854553 for ['[CLS] bare reviewerarus bank rub primetime groups [SEP]']
[Init] best perm rec loss: 0.683734655380249 for ['[CLS]arus groups reviewer bank bare rub primetime [SEP]']
[Init] best perm rec loss: 0.6832753419876099 for ['[CLS]arus bare primetime reviewer groups bank rub [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.659 (perp=10.397, rec=0.513, cos=0.066), tot_loss_proj:3.096 [t=0.16s]
prediction: ['[CLS] any are charitable two process classes tonight [SEP]']
[ 100/2000] tot_loss=2.832 (perp=11.901, rec=0.416, cos=0.036), tot_loss_proj:3.193 [t=0.17s]
prediction: ['[CLS] lifted particular pushed two groups classes since [SEP]']
[ 150/2000] tot_loss=2.436 (perp=10.533, rec=0.309, cos=0.021), tot_loss_proj:2.975 [t=0.17s]
prediction: ['[CLS] lifted particular up up years books. [SEP]']
[ 200/2000] tot_loss=2.031 (perp=8.979, rec=0.221, cos=0.014), tot_loss_proj:2.560 [t=0.17s]
prediction: ['[CLS] lifted particular up up the books. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.552 (perp=6.976, rec=0.148, cos=0.009), tot_loss_proj:2.197 [t=0.17s]
prediction: ['[CLS] his lifted him up the books. [SEP]']
[ 300/2000] tot_loss=1.529 (perp=6.976, rec=0.125, cos=0.009), tot_loss_proj:2.215 [t=0.17s]
prediction: ['[CLS] his lifted him up the books. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.623 (perp=7.656, rec=0.085, cos=0.007), tot_loss_proj:1.944 [t=0.17s]
prediction: ['[CLS] medical lifted him up the books. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.412 (perp=6.438, rec=0.115, cos=0.010), tot_loss_proj:1.715 [t=0.17s]
prediction: ['[CLS] lifted him up the medical books. [SEP]']
[ 450/2000] tot_loss=1.381 (perp=6.438, rec=0.086, cos=0.006), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] lifted him up the medical books. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.380 (perp=6.438, rec=0.087, cos=0.005), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] lifted him up the medical books. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.430 (perp=6.438, rec=0.134, cos=0.008), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] lifted him up the medical books. [SEP]']
[ 600/2000] tot_loss=1.558 (perp=7.311, rec=0.091, cos=0.005), tot_loss_proj:2.428 [t=0.17s]
prediction: ['[CLS] lifted him up the my books. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.195 (perp=5.534, rec=0.084, cos=0.004), tot_loss_proj:1.551 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.196 (perp=5.534, rec=0.085, cos=0.004), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[ 750/2000] tot_loss=1.199 (perp=5.534, rec=0.089, cos=0.003), tot_loss_proj:1.535 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.186 (perp=5.534, rec=0.076, cos=0.003), tot_loss_proj:1.535 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.191 (perp=5.534, rec=0.081, cos=0.003), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[ 900/2000] tot_loss=1.172 (perp=5.534, rec=0.062, cos=0.003), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.180 (perp=5.534, rec=0.070, cos=0.003), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.177 (perp=5.534, rec=0.067, cos=0.003), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1050/2000] tot_loss=1.187 (perp=5.534, rec=0.077, cos=0.003), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.188 (perp=5.534, rec=0.078, cos=0.003), tot_loss_proj:1.511 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.179 (perp=5.534, rec=0.069, cos=0.003), tot_loss_proj:1.516 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1200/2000] tot_loss=1.191 (perp=5.534, rec=0.081, cos=0.003), tot_loss_proj:1.513 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.176 (perp=5.534, rec=0.066, cos=0.003), tot_loss_proj:1.517 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.173 (perp=5.534, rec=0.063, cos=0.003), tot_loss_proj:1.516 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1350/2000] tot_loss=1.188 (perp=5.534, rec=0.078, cos=0.003), tot_loss_proj:1.514 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.177 (perp=5.534, rec=0.067, cos=0.003), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.174 (perp=5.534, rec=0.064, cos=0.003), tot_loss_proj:1.503 [t=0.18s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1500/2000] tot_loss=1.171 (perp=5.534, rec=0.062, cos=0.003), tot_loss_proj:1.517 [t=0.18s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.182 (perp=5.534, rec=0.072, cos=0.003), tot_loss_proj:1.512 [t=0.18s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.172 (perp=5.534, rec=0.062, cos=0.003), tot_loss_proj:1.506 [t=0.18s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1650/2000] tot_loss=1.177 (perp=5.534, rec=0.067, cos=0.003), tot_loss_proj:1.503 [t=0.18s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.174 (perp=5.534, rec=0.064, cos=0.003), tot_loss_proj:1.507 [t=0.18s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.169 (perp=5.534, rec=0.059, cos=0.003), tot_loss_proj:1.507 [t=0.18s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1800/2000] tot_loss=1.180 (perp=5.534, rec=0.070, cos=0.003), tot_loss_proj:1.503 [t=0.19s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.176 (perp=5.534, rec=0.066, cos=0.003), tot_loss_proj:1.511 [t=0.18s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.186 (perp=5.534, rec=0.076, cos=0.003), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1950/2000] tot_loss=1.176 (perp=5.534, rec=0.066, cos=0.003), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.185 (perp=5.534, rec=0.075, cos=0.003), tot_loss_proj:1.503 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] i lifted him up the books. [SEP]
========================
predicted: 
========================
[CLS] i lifted him up the books. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 78.553 | p: 78.469 | r: 78.965
rouge2     | fm: 38.884 | p: 38.729 | r: 39.196
rougeL     | fm: 67.945 | p: 67.917 | r: 68.336
rougeLsum  | fm: 67.989 | p: 67.948 | r: 68.300
r1fm+r2fm = 117.436

input #86 time: 0:06:44 | total time: 11:42:16


Running input #87 of 100.
reference: 
========================
Heidi thinks that Andy has eaten salmon flavored candy bars.
========================
average of cosine similarity 0.9993324758205361
highest_index [0]
highest [0.9993324758205361]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101, 21372,  6732,  2008,  5557,  2038,  8828, 11840, 14894,  2098,
          9485,  6963,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]']
[Init] best rec loss: 1.0333819389343262 for ['[CLS] flood but! means roe vietnam after partial owe cult novel question [SEP]']
[Init] best rec loss: 0.9575434923171997 for ['[CLS] remained rates made glacier beginning gift pianoril department springsuratie [SEP]']
[Init] best rec loss: 0.9186620116233826 for ['[CLS] moreplppet children bank henri she entertainment expression clipped emotions webber [SEP]']
[Init] best perm rec loss: 0.9178486466407776 for ['[CLS] more expression clippedppet webber emotions entertainmentpl she bank children henri [SEP]']
[Init] best perm rec loss: 0.9169323444366455 for ['[CLS] henri expression entertainment she webber clipped children moreppetpl emotions bank [SEP]']
[Init] best perm rec loss: 0.9160096049308777 for ['[CLS] webber emotions expression childrenppet clipped entertainmentpl more henri bank she [SEP]']
[Init] best perm rec loss: 0.9155099391937256 for ['[CLS] bank webber entertainment expression she henri more clipped children emotionsplppet [SEP]']
[Init] best perm rec loss: 0.9128410816192627 for ['[CLS]plppet emotions clipped entertainment bank children she webber expression more henri [SEP]']
[Init] best perm rec loss: 0.9127443432807922 for ['[CLS] entertainment clippedppet emotions children henri bankpl expression webber she more [SEP]']
[Init] best perm rec loss: 0.911577582359314 for ['[CLS]ppet bank children expression entertainment clipped henri she emotions webber morepl [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.397 (perp=13.925, rec=0.615, cos=0.997), tot_loss_proj:4.614 [t=0.20s]
prediction: ['[CLS] festival compliment children dose bred vodkaivate todd workers rope arctic 2010 [SEP]']
[ 100/2000] tot_loss=2.880 (perp=12.367, rec=0.340, cos=0.066), tot_loss_proj:4.346 [t=0.18s]
prediction: ['[CLS] flavor slogan if question eat andy value todd research tree cheese heard [SEP]']
[ 150/2000] tot_loss=2.699 (perp=12.235, rec=0.232, cos=0.019), tot_loss_proj:4.246 [t=0.18s]
prediction: ['[CLS] flavor cuisine although injury candy heidi. heidi consumed bottle candy heard [SEP]']
[ 200/2000] tot_loss=2.603 (perp=11.971, rec=0.197, cos=0.012), tot_loss_proj:4.204 [t=0.18s]
prediction: ['[CLS] flavor eatenodle alexia candy heidi. heidi eaten candy candy sees [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.351 (perp=10.816, rec=0.176, cos=0.012), tot_loss_proj:4.008 [t=0.18s]
prediction: ['[CLS] heidi eaten that upon eat flavor. andy eaten candy candy think [SEP]']
[ 300/2000] tot_loss=2.394 (perp=11.113, rec=0.161, cos=0.010), tot_loss_proj:4.040 [t=0.18s]
prediction: ['[CLS] heidi eaten that upon eaten flavor. andy eaten candy flavor thinks [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.054 (perp=9.461, rec=0.153, cos=0.010), tot_loss_proj:3.754 [t=0.17s]
prediction: ['[CLS] heidi thinks that already eaten flavor. andy eaten candy flavor eaten [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.175 (perp=10.174, rec=0.131, cos=0.009), tot_loss_proj:3.869 [t=0.17s]
prediction: ['[CLS] heidi thinks that already eaten flavor eaten andy eaten candy flavor eaten [SEP]']
[ 450/2000] tot_loss=2.209 (perp=10.364, rec=0.127, cos=0.009), tot_loss_proj:3.987 [t=0.17s]
prediction: ['[CLS] heidi thinks that alexia eaten flavor eaten andy has candy flavor eaten [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.975 (perp=9.236, rec=0.119, cos=0.009), tot_loss_proj:3.688 [t=0.17s]
prediction: ['[CLS] heidi thinks that which eaten flavor eaten andy has candy flavor eaten [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.976 (perp=9.236, rec=0.120, cos=0.009), tot_loss_proj:3.688 [t=0.17s]
prediction: ['[CLS] heidi thinks that which eaten flavor eaten andy has candy flavor eaten [SEP]']
[ 600/2000] tot_loss=1.976 (perp=9.277, rec=0.113, cos=0.008), tot_loss_proj:3.687 [t=0.17s]
prediction: ['[CLS] heidi thinks that that eaten flavor eaten andy has candy flavor eaten [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.975 (perp=9.277, rec=0.111, cos=0.008), tot_loss_proj:3.686 [t=0.17s]
prediction: ['[CLS] heidi thinks that that eaten flavor eaten andy has candy flavor eaten [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.988 (perp=9.370, rec=0.106, cos=0.008), tot_loss_proj:3.692 [t=0.17s]
prediction: ['[CLS] heidi thinks that that eaten flavor eaten andy has salmon flavor eaten [SEP]']
[ 750/2000] tot_loss=1.990 (perp=9.398, rec=0.102, cos=0.008), tot_loss_proj:3.779 [t=0.17s]
prediction: ['[CLS] heidi thinks that that salmon flavor eaten andy has salmon flavor eaten [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.016 (perp=9.460, rec=0.116, cos=0.008), tot_loss_proj:3.644 [t=0.17s]
prediction: ['[CLS] heidi that thinks that eaten candy eaten andy has salmon flavor eaten [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.089 (perp=9.836, rec=0.113, cos=0.008), tot_loss_proj:3.736 [t=0.17s]
prediction: ['[CLS] heidi that thinks enough eaten salmon eaten andy has candy flavor eaten [SEP]']
[ 900/2000] tot_loss=1.903 (perp=8.940, rec=0.107, cos=0.008), tot_loss_proj:3.548 [t=0.17s]
prediction: ['[CLS] heidi that thinks that eaten salmon eaten andy has candy flavor eaten [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.908 (perp=8.989, rec=0.102, cos=0.008), tot_loss_proj:3.577 [t=0.17s]
prediction: ['[CLS] heidi that thinks that eaten salmon eaten andy has candy flavor bars [SEP]']
Attempt swap
[1000/2000] tot_loss=1.924 (perp=9.094, rec=0.098, cos=0.007), tot_loss_proj:3.639 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon salmon eaten andy has candy flavor bars [SEP]']
[1050/2000] tot_loss=1.930 (perp=9.094, rec=0.104, cos=0.007), tot_loss_proj:3.637 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon salmon eaten andy has candy flavor bars [SEP]']
Attempt swap
[1100/2000] tot_loss=1.933 (perp=9.094, rec=0.106, cos=0.007), tot_loss_proj:3.638 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon salmon eaten andy has candy flavor bars [SEP]']
Attempt swap
[1150/2000] tot_loss=1.936 (perp=9.094, rec=0.110, cos=0.007), tot_loss_proj:3.638 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon salmon eaten andy has candy flavor bars [SEP]']
[1200/2000] tot_loss=1.930 (perp=9.094, rec=0.104, cos=0.007), tot_loss_proj:3.641 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon salmon eaten andy has candy flavor bars [SEP]']
Attempt swap
[1250/2000] tot_loss=1.934 (perp=9.094, rec=0.108, cos=0.007), tot_loss_proj:3.641 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon salmon eaten andy has candy flavor bars [SEP]']
Attempt swap
[1300/2000] tot_loss=1.926 (perp=9.094, rec=0.100, cos=0.007), tot_loss_proj:3.641 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon salmon eaten andy has candy flavor bars [SEP]']
[1350/2000] tot_loss=1.930 (perp=9.094, rec=0.104, cos=0.007), tot_loss_proj:3.639 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon salmon eaten andy has candy flavor bars [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.876 (perp=8.837, rec=0.101, cos=0.007), tot_loss_proj:3.600 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
Attempt swap
[1450/2000] tot_loss=1.876 (perp=8.837, rec=0.101, cos=0.007), tot_loss_proj:3.598 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
[1500/2000] tot_loss=1.879 (perp=8.837, rec=0.105, cos=0.007), tot_loss_proj:3.604 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
Attempt swap
[1550/2000] tot_loss=1.879 (perp=8.837, rec=0.104, cos=0.007), tot_loss_proj:3.598 [t=0.16s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
Attempt swap
[1600/2000] tot_loss=1.872 (perp=8.837, rec=0.097, cos=0.007), tot_loss_proj:3.593 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
[1650/2000] tot_loss=1.866 (perp=8.837, rec=0.092, cos=0.007), tot_loss_proj:3.601 [t=0.21s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
Attempt swap
[1700/2000] tot_loss=1.875 (perp=8.837, rec=0.101, cos=0.007), tot_loss_proj:3.599 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
Attempt swap
[1750/2000] tot_loss=1.867 (perp=8.837, rec=0.093, cos=0.007), tot_loss_proj:3.599 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
[1800/2000] tot_loss=1.866 (perp=8.837, rec=0.091, cos=0.007), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
Attempt swap
[1850/2000] tot_loss=1.872 (perp=8.837, rec=0.098, cos=0.007), tot_loss_proj:3.598 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
Attempt swap
[1900/2000] tot_loss=1.878 (perp=8.837, rec=0.103, cos=0.007), tot_loss_proj:3.601 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
[1950/2000] tot_loss=1.874 (perp=8.837, rec=0.100, cos=0.007), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
Attempt swap
[2000/2000] tot_loss=1.869 (perp=8.837, rec=0.095, cos=0.007), tot_loss_proj:3.599 [t=0.17s]
prediction: ['[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]
========================
predicted: 
========================
[CLS] heidi that thinks that salmon eaten salmon andy has candy flavor bars [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 78.571 | r: 91.667
rouge2     | fm: 41.667 | p: 38.462 | r: 45.455
rougeL     | fm: 69.231 | p: 64.286 | r: 75.000
rougeLsum  | fm: 69.231 | p: 64.286 | r: 75.000
r1fm+r2fm = 126.282

[Aggregate metrics]:
rouge1     | fm: 78.586 | p: 78.427 | r: 79.168
rouge2     | fm: 38.867 | p: 38.621 | r: 39.271
rougeL     | fm: 67.919 | p: 67.832 | r: 68.340
rougeLsum  | fm: 67.933 | p: 67.863 | r: 68.382
r1fm+r2fm = 117.453

input #87 time: 0:06:44 | total time: 11:49:01


Running input #88 of 100.
reference: 
========================
He bought these flowers for Aaron.
========================
average of cosine similarity 0.999392841134532
highest_index [0]
highest [0.999392841134532]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 4149, 2122, 4870, 2005, 7158, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he bought these flowers for aaron. [SEP]']
[Init] best rec loss: 1.034036636352539 for ['[CLS] wi rio xx irving ou obligations tang [SEP]']
[Init] best rec loss: 1.0049952268600464 for ['[CLS]ing rahman medina volume!lyn put [SEP]']
[Init] best rec loss: 0.9832890629768372 for ['[CLS]iateddication media familiar cas re threshold [SEP]']
[Init] best rec loss: 0.9699617624282837 for ['[CLS]card logan bamboo acting phi market query [SEP]']
[Init] best rec loss: 0.9513040781021118 for ['[CLS] drum representative kai edges evolutionary theories abandonment [SEP]']
[Init] best rec loss: 0.9334592223167419 for ['[CLS] americanaur− laughter peedy stock [SEP]']
[Init] best perm rec loss: 0.9307273030281067 for ['[CLS] peedy stock−aur laughter american [SEP]']
[Init] best perm rec loss: 0.9302306175231934 for ['[CLS] american laughter peedy stock−aur [SEP]']
[Init] best perm rec loss: 0.9283412098884583 for ['[CLS] stockdyaur american laughter− pee [SEP]']
[Init] best perm rec loss: 0.9273785352706909 for ['[CLS]dy stock pee laughter−aur american [SEP]']
[Init] best perm rec loss: 0.9272459149360657 for ['[CLS]dy laughter stock pee american−aur [SEP]']
[Init] best perm rec loss: 0.9270510077476501 for ['[CLS] stockdy pee american laughteraur− [SEP]']
[Init] best perm rec loss: 0.9263805747032166 for ['[CLS] pee− laughter stockdy americanaur [SEP]']
[Init] best perm rec loss: 0.9263287782669067 for ['[CLS]aur pee stock laughter−dy american [SEP]']
[Init] best perm rec loss: 0.9248601198196411 for ['[CLS]aur laughter stock peedy− american [SEP]']
[Init] best perm rec loss: 0.9246683120727539 for ['[CLS] laughter stockaur− peedy american [SEP]']
[Init] best perm rec loss: 0.9239789247512817 for ['[CLS] stock laughter− peeaur americandy [SEP]']
[Init] best perm rec loss: 0.9223710298538208 for ['[CLS] laughter− stockdyaur pee american [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.843 (perp=11.626, rec=0.439, cos=0.079), tot_loss_proj:4.355 [t=0.17s]
prediction: ['[CLS] indiana deer experienced pain promotion collections city [SEP]']
[ 100/2000] tot_loss=2.945 (perp=12.998, rec=0.314, cos=0.031), tot_loss_proj:4.439 [t=0.17s]
prediction: ['[CLS] chemical this andcha promotion aaron desert [SEP]']
[ 150/2000] tot_loss=2.283 (perp=10.016, rec=0.261, cos=0.018), tot_loss_proj:3.884 [t=0.17s]
prediction: ['[CLS] aaron bought and flowers flowers aaron. [SEP]']
[ 200/2000] tot_loss=2.416 (perp=10.850, rec=0.229, cos=0.017), tot_loss_proj:4.083 [t=0.17s]
prediction: ['[CLS] aaron these and flowers flowers aaron aaron [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.287 (perp=10.005, rec=0.259, cos=0.027), tot_loss_proj:3.942 [t=0.17s]
prediction: ['[CLS] he bought and aaron flowers promotion yellow [SEP]']
[ 300/2000] tot_loss=2.078 (perp=9.425, rec=0.181, cos=0.012), tot_loss_proj:3.719 [t=0.17s]
prediction: ['[CLS] he bought they aaron flowers for these [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.939 (perp=8.894, rec=0.149, cos=0.010), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] he bought they these flowers for aaron [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.823 (perp=8.530, rec=0.110, cos=0.006), tot_loss_proj:3.498 [t=0.17s]
prediction: ['[CLS] he bought these flowers for these aaron [SEP]']
[ 450/2000] tot_loss=1.804 (perp=8.530, rec=0.093, cos=0.005), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] he bought these flowers for these aaron [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.801 (perp=8.530, rec=0.090, cos=0.005), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] he bought these flowers for these aaron [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.796 (perp=8.530, rec=0.085, cos=0.005), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] he bought these flowers for these aaron [SEP]']
[ 600/2000] tot_loss=1.791 (perp=8.530, rec=0.080, cos=0.005), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] he bought these flowers for these aaron [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.790 (perp=8.530, rec=0.079, cos=0.005), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] he bought these flowers for these aaron [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.797 (perp=8.530, rec=0.086, cos=0.005), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] he bought these flowers for these aaron [SEP]']
[ 750/2000] tot_loss=1.792 (perp=8.530, rec=0.081, cos=0.005), tot_loss_proj:3.508 [t=0.17s]
prediction: ['[CLS] he bought these flowers for these aaron [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.728 (perp=8.216, rec=0.081, cos=0.004), tot_loss_proj:3.457 [t=0.17s]
prediction: ['[CLS] he bought these flowers for. aaron [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.457 (perp=6.841, rec=0.084, cos=0.005), tot_loss_proj:1.515 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[ 900/2000] tot_loss=1.450 (perp=6.841, rec=0.077, cos=0.004), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.455 (perp=6.841, rec=0.082, cos=0.004), tot_loss_proj:1.511 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.449 (perp=6.841, rec=0.076, cos=0.004), tot_loss_proj:1.515 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1050/2000] tot_loss=1.450 (perp=6.841, rec=0.078, cos=0.004), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.447 (perp=6.841, rec=0.074, cos=0.004), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.458 (perp=6.841, rec=0.086, cos=0.004), tot_loss_proj:1.523 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1200/2000] tot_loss=1.452 (perp=6.841, rec=0.080, cos=0.004), tot_loss_proj:1.520 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.451 (perp=6.841, rec=0.079, cos=0.004), tot_loss_proj:1.508 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.446 (perp=6.841, rec=0.073, cos=0.004), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1350/2000] tot_loss=1.454 (perp=6.841, rec=0.082, cos=0.004), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.457 (perp=6.841, rec=0.084, cos=0.004), tot_loss_proj:1.511 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.444 (perp=6.841, rec=0.072, cos=0.004), tot_loss_proj:1.515 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1500/2000] tot_loss=1.453 (perp=6.841, rec=0.081, cos=0.004), tot_loss_proj:1.514 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.448 (perp=6.841, rec=0.076, cos=0.004), tot_loss_proj:1.516 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.448 (perp=6.841, rec=0.075, cos=0.004), tot_loss_proj:1.516 [t=0.18s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1650/2000] tot_loss=1.441 (perp=6.841, rec=0.068, cos=0.004), tot_loss_proj:1.516 [t=0.19s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.451 (perp=6.841, rec=0.079, cos=0.004), tot_loss_proj:1.515 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.441 (perp=6.841, rec=0.068, cos=0.004), tot_loss_proj:1.511 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1800/2000] tot_loss=1.445 (perp=6.841, rec=0.072, cos=0.004), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.457 (perp=6.841, rec=0.084, cos=0.004), tot_loss_proj:1.519 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.452 (perp=6.841, rec=0.080, cos=0.004), tot_loss_proj:1.513 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1950/2000] tot_loss=1.446 (perp=6.841, rec=0.074, cos=0.004), tot_loss_proj:1.514 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.451 (perp=6.841, rec=0.079, cos=0.004), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] he bought these flowers for aaron. [SEP]
========================
predicted: 
========================
[CLS] he bought these flowers for aaron. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 78.855 | p: 78.655 | r: 79.468
rouge2     | fm: 39.697 | p: 39.456 | r: 40.137
rougeL     | fm: 68.316 | p: 68.233 | r: 68.689
rougeLsum  | fm: 68.342 | p: 68.265 | r: 68.730
r1fm+r2fm = 118.552

input #88 time: 0:06:37 | total time: 11:55:39


Running input #89 of 100.
reference: 
========================
Handsome though they told me that Tom is, I still won't date him.
========================
average of cosine similarity 0.9993499747712495
highest_index [0]
highest [0.9993499747712495]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[ 101, 8502, 2295, 2027, 2409, 2033, 2008, 3419, 2003, 1010, 1045, 2145,
         2180, 1005, 1056, 3058, 2032, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] handsome though they told me that tom is, i still won't date him. [SEP]"]
[Init] best rec loss: 0.9502671360969543 for ['[CLS] save jersey myanmar walkedfkthic ˢ wife dealing tomorrow lola e bit ll show ˈ competitions [SEP]']
[Init] best rec loss: 0.9151517748832703 for ['[CLS] listential calling liesnified sesame solution hop failure colonel sign rms wil ever parsons [CLS] punk [SEP]']
[Init] best rec loss: 0.8847743272781372 for ['[CLS] airports in generic root administrative capitol wisconsin blind municipality remainder prasad squirrelswise antioch programricted palmer [SEP]']
[Init] best rec loss: 0.8470215201377869 for ['[CLS] for means dissolved truceuming pere honoured utc richards fl spike shower when quantum gray huge com [SEP]']
[Init] best rec loss: 0.8421288728713989 for ['[CLS] charactersgut 11 flow rocked sigh entitled eurovision termsbridge question rocdictow 3 dj inspired [SEP]']
[Init] best rec loss: 0.8383911848068237 for ['[CLS] mat leader michael gel making underworld problems fast lake wouldn hundred texts couple after de family 1970s [SEP]']
[Init] best rec loss: 0.825195848941803 for ['[CLS] hopes devicesrued iv governor swap that saskatchewan pup under ultimate section drugged voivodeship should morning 500 [SEP]']
[Init] best rec loss: 0.8245096206665039 for ['[CLS] sectionsfest family spacekes upon double oak gas tackplay easy if cryky distinct nautical [SEP]']
[Init] best perm rec loss: 0.8197810053825378 for ['[CLS]play sections familykesfest space distinct easy nautical gas cry ifky upon oak double tack [SEP]']
[Init] best perm rec loss: 0.8192011713981628 for ['[CLS] gas distinct upon oak familykes if tack spacefest easy sectionsplay doubleky nautical cry [SEP]']
[Init] best perm rec loss: 0.819103479385376 for ['[CLS]ky space distinct oak family if upon gas easy tackplay cry double sectionsfest nauticalkes [SEP]']
[Init] best perm rec loss: 0.8139406442642212 for ['[CLS]kes gas distinct iffest oak tack nautical cry easy double space sections familyplayky upon [SEP]']
[Init] best perm rec loss: 0.8118587136268616 for ['[CLS] tack gasplay distinct cry family oakkykes double easyfest sections space nautical if upon [SEP]']
[Init] best perm rec loss: 0.8108945488929749 for ['[CLS]playkykes distinct cry if sections familyfest oak space easy nautical upon double tack gas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.806 (perp=11.031, rec=0.460, cos=0.140), tot_loss_proj:3.741 [t=0.17s]
prediction: ['[CLS] mountain although consonants lord god though true hair was. ( why sea afterwards, be simply [SEP]']
[ 100/2000] tot_loss=2.553 (perp=10.708, rec=0.350, cos=0.061), tot_loss_proj:3.983 [t=0.17s]
prediction: ['[CLS] loves though they handsome christian though their was was, handsome why presidency released, be simply [SEP]']
[ 150/2000] tot_loss=2.399 (perp=10.038, rec=0.283, cos=0.109), tot_loss_proj:3.662 [t=0.17s]
prediction: ['[CLS] indeed though they handsome handsome though matthew is,, handsome why chest that. soonred [SEP]']
[ 200/2000] tot_loss=2.385 (perp=10.306, rec=0.265, cos=0.060), tot_loss_proj:3.832 [t=0.17s]
prediction: ['[CLS]. though they handsome handsome that tom is i. handsome will hudson told, staying i [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.369 (perp=10.367, rec=0.226, cos=0.070), tot_loss_proj:3.943 [t=0.17s]
prediction: ['[CLS] because though they handsome handsome that tom is jake, i will biggest told, imprint i [SEP]']
[ 300/2000] tot_loss=1.991 (perp=8.986, rec=0.166, cos=0.028), tot_loss_proj:3.749 [t=0.17s]
prediction: ['[CLS] certainly though they done handsome that tom is jake, i will upcoming told, date me [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.966 (perp=8.969, rec=0.151, cos=0.021), tot_loss_proj:3.487 [t=0.17s]
prediction: ['[CLS] certainly handsome though they been that tom is jake, i will fastest told not date me [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.982 (perp=9.063, rec=0.142, cos=0.027), tot_loss_proj:3.060 [t=0.17s]
prediction: ['[CLS] ª handsome though they been that tom is jake, i bottle told will. date me [SEP]']
[ 450/2000] tot_loss=2.016 (perp=9.399, rec=0.123, cos=0.013), tot_loss_proj:3.804 [t=0.17s]
prediction: ['[CLS] certainly handsome though they been that tom is alex, i bottle told still him date me [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.841 (perp=8.620, rec=0.104, cos=0.013), tot_loss_proj:3.390 [t=0.17s]
prediction: ['[CLS] certainly handsome though they been that tom is alex, i still bottle told him date me [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.850 (perp=8.620, rec=0.114, cos=0.012), tot_loss_proj:3.392 [t=0.17s]
prediction: ['[CLS] certainly handsome though they been that tom is alex, i still bottle told him date me [SEP]']
[ 600/2000] tot_loss=1.805 (perp=8.476, rec=0.099, cos=0.012), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] still handsome though they been that tom is alex, i still bottle told him date me [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.725 (perp=8.046, rec=0.105, cos=0.011), tot_loss_proj:3.561 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is alex, i still t told him date me [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.714 (perp=8.046, rec=0.095, cos=0.010), tot_loss_proj:3.562 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is alex, i still t told him date me [SEP]']
[ 750/2000] tot_loss=1.714 (perp=8.046, rec=0.096, cos=0.009), tot_loss_proj:3.561 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is alex, i still t told him date me [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.675 (perp=7.844, rec=0.098, cos=0.008), tot_loss_proj:3.492 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is alex, i won t date him told me [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.656 (perp=7.798, rec=0.088, cos=0.008), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
[ 900/2000] tot_loss=1.652 (perp=7.798, rec=0.085, cos=0.007), tot_loss_proj:3.526 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.648 (perp=7.798, rec=0.081, cos=0.007), tot_loss_proj:3.526 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1000/2000] tot_loss=1.646 (perp=7.798, rec=0.079, cos=0.007), tot_loss_proj:3.532 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
[1050/2000] tot_loss=1.644 (perp=7.798, rec=0.077, cos=0.007), tot_loss_proj:3.527 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1100/2000] tot_loss=1.646 (perp=7.798, rec=0.079, cos=0.007), tot_loss_proj:3.532 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1150/2000] tot_loss=1.643 (perp=7.798, rec=0.077, cos=0.007), tot_loss_proj:3.533 [t=0.19s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
[1200/2000] tot_loss=1.647 (perp=7.798, rec=0.080, cos=0.007), tot_loss_proj:3.534 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1250/2000] tot_loss=1.651 (perp=7.798, rec=0.084, cos=0.007), tot_loss_proj:3.535 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1300/2000] tot_loss=1.652 (perp=7.798, rec=0.085, cos=0.007), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
[1350/2000] tot_loss=1.649 (perp=7.798, rec=0.083, cos=0.007), tot_loss_proj:3.531 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1400/2000] tot_loss=1.643 (perp=7.798, rec=0.077, cos=0.007), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1450/2000] tot_loss=1.647 (perp=7.798, rec=0.081, cos=0.007), tot_loss_proj:3.526 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
[1500/2000] tot_loss=1.638 (perp=7.798, rec=0.072, cos=0.007), tot_loss_proj:3.535 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1550/2000] tot_loss=1.638 (perp=7.798, rec=0.072, cos=0.007), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1600/2000] tot_loss=1.651 (perp=7.798, rec=0.085, cos=0.007), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
[1650/2000] tot_loss=1.649 (perp=7.798, rec=0.082, cos=0.007), tot_loss_proj:3.529 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1700/2000] tot_loss=1.654 (perp=7.798, rec=0.087, cos=0.007), tot_loss_proj:3.527 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1750/2000] tot_loss=1.646 (perp=7.798, rec=0.080, cos=0.007), tot_loss_proj:3.532 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
[1800/2000] tot_loss=1.646 (perp=7.798, rec=0.080, cos=0.007), tot_loss_proj:3.526 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1850/2000] tot_loss=1.653 (perp=7.798, rec=0.086, cos=0.007), tot_loss_proj:3.535 [t=0.21s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[1900/2000] tot_loss=1.643 (perp=7.798, rec=0.077, cos=0.007), tot_loss_proj:3.532 [t=0.18s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
[1950/2000] tot_loss=1.646 (perp=7.798, rec=0.080, cos=0.007), tot_loss_proj:3.538 [t=0.18s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Attempt swap
[2000/2000] tot_loss=1.641 (perp=7.798, rec=0.074, cos=0.007), tot_loss_proj:3.536 [t=0.17s]
prediction: ['[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] handsome though they told me that tom is, i still won't date him. [SEP]
========================
predicted: 
========================
[CLS] still handsome though they me that tom is, i won alex t date him told me [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 56.250 | p: 52.941 | r: 60.000
rougeL     | fm: 82.353 | p: 77.778 | r: 87.500
rougeLsum  | fm: 82.353 | p: 77.778 | r: 87.500
r1fm+r2fm = 150.368

[Aggregate metrics]:
rouge1     | fm: 79.024 | p: 78.716 | r: 79.592
rouge2     | fm: 39.759 | p: 39.533 | r: 40.203
rougeL     | fm: 68.535 | p: 68.385 | r: 68.967
rougeLsum  | fm: 68.539 | p: 68.375 | r: 68.948
r1fm+r2fm = 118.783

input #89 time: 0:06:50 | total time: 12:02:29


Running input #90 of 100.
reference: 
========================
Moya's football team loved her
========================
average of cosine similarity 0.9993060410574177
highest_index [0]
highest [0.9993060410574177]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9587, 3148, 1005, 1055, 2374, 2136, 3866, 2014,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] moya's football team loved her [SEP]"]
[Init] best rec loss: 0.8754562735557556 for ['[CLS]rra person gasp shit rex become snow dunn [SEP]']
[Init] best rec loss: 0.8286807537078857 for ['[CLS] company slightly describe eager izzy poetryneyox [SEP]']
[Init] best rec loss: 0.8254004716873169 for ['[CLS] roman oclc consultantjust countrieslic relief kam [SEP]']
[Init] best perm rec loss: 0.8226989507675171 for ['[CLS] oclc roman consultant relief countriesjustlic kam [SEP]']
[Init] best perm rec loss: 0.8145224452018738 for ['[CLS] romanjust consultant oclc countries relief kamlic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.751 (perp=12.426, rec=0.598, cos=0.668), tot_loss_proj:4.336 [t=0.17s]
prediction: ['[CLS] romancetight preferred their = ya america rebuilt [SEP]']
[ 100/2000] tot_loss=3.101 (perp=12.282, rec=0.487, cos=0.158), tot_loss_proj:4.341 [t=0.17s]
prediction: ['[CLS] regina jimmy lovedmaster band purposesya loved [SEP]']
[ 150/2000] tot_loss=2.905 (perp=12.678, rec=0.324, cos=0.046), tot_loss_proj:4.357 [t=0.17s]
prediction: ['[CLS] ho tyson lovedmaster football visitsya loved [SEP]']
[ 200/2000] tot_loss=2.810 (perp=12.443, rec=0.285, cos=0.036), tot_loss_proj:4.398 [t=0.17s]
prediction: ['[CLS] mo her loved her footballweya loved [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.190 (perp=9.083, rec=0.326, cos=0.048), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] mo loved her football moya loved herself [SEP]']
[ 300/2000] tot_loss=2.113 (perp=9.303, rec=0.230, cos=0.022), tot_loss_proj:3.602 [t=0.17s]
prediction: ['[CLS] mo loved her team moya loved her [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.429 (perp=8.422, rec=0.521, cos=0.223), tot_loss_proj:3.419 [t=0.17s]
prediction: ['[CLS] mo moya loved her football loved her [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.034 (perp=8.149, rec=0.340, cos=0.064), tot_loss_proj:3.515 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her football [SEP]']
[ 450/2000] tot_loss=1.995 (perp=8.149, rec=0.303, cos=0.062), tot_loss_proj:3.510 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her football [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.903 (perp=8.149, rec=0.237, cos=0.036), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her football [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.945 (perp=8.149, rec=0.269, cos=0.046), tot_loss_proj:3.517 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her football [SEP]']
[ 600/2000] tot_loss=1.889 (perp=8.149, rec=0.228, cos=0.031), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her football [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.859 (perp=8.149, rec=0.203, cos=0.026), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her football [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.845 (perp=8.149, rec=0.192, cos=0.023), tot_loss_proj:3.497 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her football [SEP]']
[ 750/2000] tot_loss=1.844 (perp=8.149, rec=0.193, cos=0.021), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her football [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.830 (perp=8.149, rec=0.182, cos=0.019), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her football [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.825 (perp=8.149, rec=0.178, cos=0.017), tot_loss_proj:3.495 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her football [SEP]']
[ 900/2000] tot_loss=1.856 (perp=8.349, rec=0.170, cos=0.016), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her team [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.841 (perp=8.349, rec=0.157, cos=0.014), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] mo moya loved her loved her team [SEP]']
Attempt swap
[1000/2000] tot_loss=2.311 (perp=10.707, rec=0.156, cos=0.014), tot_loss_proj:4.018 [t=0.17s]
prediction: ['[CLS] mo moya loved s loved her team [SEP]']
[1050/2000] tot_loss=2.297 (perp=10.707, rec=0.144, cos=0.011), tot_loss_proj:4.016 [t=0.17s]
prediction: ['[CLS] mo moya loved s loved her team [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.463 (perp=10.450, rec=0.291, cos=0.082), tot_loss_proj:3.830 [t=0.17s]
prediction: ['[CLS] mo moya loved s football loved her [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.209 (perp=9.700, rec=0.234, cos=0.036), tot_loss_proj:3.810 [t=0.17s]
prediction: ['[CLS] mo moya loved team loved her s [SEP]']
[1200/2000] tot_loss=2.191 (perp=9.856, rec=0.199, cos=0.021), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS] mo moya loved football loved her s [SEP]']
Attempt swap
[1250/2000] tot_loss=2.176 (perp=9.856, rec=0.188, cos=0.016), tot_loss_proj:3.801 [t=0.18s]
prediction: ['[CLS] mo moya loved football loved her s [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.075 (perp=9.343, rec=0.192, cos=0.014), tot_loss_proj:3.751 [t=0.21s]
prediction: ['[CLS] mo moya loved team s her loved [SEP]']
[1350/2000] tot_loss=2.068 (perp=9.343, rec=0.186, cos=0.013), tot_loss_proj:3.755 [t=0.21s]
prediction: ['[CLS] mo moya loved team s her loved [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.986 (perp=9.016, rec=0.171, cos=0.012), tot_loss_proj:3.658 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
Attempt swap
[1450/2000] tot_loss=1.984 (perp=9.016, rec=0.170, cos=0.011), tot_loss_proj:3.660 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
[1500/2000] tot_loss=1.968 (perp=9.016, rec=0.155, cos=0.010), tot_loss_proj:3.659 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
Attempt swap
[1550/2000] tot_loss=1.974 (perp=9.016, rec=0.161, cos=0.009), tot_loss_proj:3.662 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
Attempt swap
[1600/2000] tot_loss=1.959 (perp=9.016, rec=0.147, cos=0.009), tot_loss_proj:3.660 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
[1650/2000] tot_loss=1.958 (perp=9.016, rec=0.147, cos=0.008), tot_loss_proj:3.656 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
Attempt swap
[1700/2000] tot_loss=1.962 (perp=9.016, rec=0.151, cos=0.008), tot_loss_proj:3.658 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
Attempt swap
[1750/2000] tot_loss=1.953 (perp=9.016, rec=0.143, cos=0.008), tot_loss_proj:3.661 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
[1800/2000] tot_loss=1.965 (perp=9.016, rec=0.155, cos=0.007), tot_loss_proj:3.662 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
Attempt swap
[1850/2000] tot_loss=1.955 (perp=9.016, rec=0.145, cos=0.007), tot_loss_proj:3.660 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
Attempt swap
[1900/2000] tot_loss=1.948 (perp=9.016, rec=0.138, cos=0.007), tot_loss_proj:3.659 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
[1950/2000] tot_loss=1.950 (perp=9.016, rec=0.140, cos=0.007), tot_loss_proj:3.658 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
Attempt swap
[2000/2000] tot_loss=1.957 (perp=9.016, rec=0.147, cos=0.007), tot_loss_proj:3.658 [t=0.17s]
prediction: ['[CLS] mo moya loved s team her loved [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] moya's football team loved her [SEP]
========================
predicted: 
========================
[CLS] mo moya loved s team her loved [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 82.353

[Aggregate metrics]:
rouge1     | fm: 79.127 | p: 78.871 | r: 79.721
rouge2     | fm: 39.300 | p: 39.078 | r: 39.761
rougeL     | fm: 68.510 | p: 68.258 | r: 69.015
rougeLsum  | fm: 68.551 | p: 68.365 | r: 69.066
r1fm+r2fm = 118.428

input #90 time: 0:06:48 | total time: 12:09:18


Running input #91 of 100.
reference: 
========================
They investigated the problem.
========================
average of cosine similarity 0.9994048200497065
highest_index [0]
highest [0.9994048200497065]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2027, 10847,  1996,  3291,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] they investigated the problem. [SEP]']
[Init] best rec loss: 1.0008985996246338 for ['[CLS] non trap brackets opposite mbe [SEP]']
[Init] best rec loss: 0.9636040925979614 for ['[CLS] nope rare chief steveyon [SEP]']
[Init] best rec loss: 0.9533264636993408 for ['[CLS] new award assistant river ce [SEP]']
[Init] best rec loss: 0.946533203125 for ['[CLS] 3 solid property video cane [SEP]']
[Init] best rec loss: 0.9368292093276978 for ['[CLS] communication seat professional delivery lankan [SEP]']
[Init] best rec loss: 0.9343482255935669 for ['[CLS] tongue ways na flush region [SEP]']
[Init] best rec loss: 0.9309041500091553 for ['[CLS] central rosen fashion rounds be [SEP]']
[Init] best rec loss: 0.8867634534835815 for ['[CLS]w czech real mrference [SEP]']
[Init] best rec loss: 0.8775110244750977 for ['[CLS] log hitler heath belgium lynne [SEP]']
[Init] best perm rec loss: 0.8742671608924866 for ['[CLS] lynne log heath belgium hitler [SEP]']
[Init] best perm rec loss: 0.8742567300796509 for ['[CLS] hitler lynne belgium heath log [SEP]']
[Init] best perm rec loss: 0.8719561696052551 for ['[CLS] hitler belgium lynne log heath [SEP]']
[Init] best perm rec loss: 0.8709571361541748 for ['[CLS] hitler log belgium heath lynne [SEP]']
[Init] best perm rec loss: 0.8697481155395508 for ['[CLS] belgium log hitler lynne heath [SEP]']
[Init] best perm rec loss: 0.8682686686515808 for ['[CLS] belgium log heath hitler lynne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.447 (perp=9.822, rec=0.395, cos=0.087), tot_loss_proj:3.946 [t=0.20s]
prediction: ['[CLS].worth episode. their [SEP]']
[ 100/2000] tot_loss=2.553 (perp=11.250, rec=0.267, cos=0.036), tot_loss_proj:4.017 [t=0.20s]
prediction: ['[CLS] they considered problem investigated they [SEP]']
[ 150/2000] tot_loss=2.739 (perp=12.831, rec=0.161, cos=0.012), tot_loss_proj:4.407 [t=0.18s]
prediction: ['[CLS] they grew problem investigated problem [SEP]']
[ 200/2000] tot_loss=2.286 (perp=10.709, rec=0.133, cos=0.011), tot_loss_proj:4.049 [t=0.18s]
prediction: ['[CLS] they consider problem investigated problem [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.013 (perp=9.357, rec=0.130, cos=0.011), tot_loss_proj:3.812 [t=0.21s]
prediction: ['[CLS] they consider problem problem investigated [SEP]']
[ 300/2000] tot_loss=2.097 (perp=9.793, rec=0.129, cos=0.010), tot_loss_proj:3.763 [t=0.18s]
prediction: ['[CLS] they consider problem? investigated [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.174 (perp=10.241, rec=0.115, cos=0.010), tot_loss_proj:3.889 [t=0.20s]
prediction: ['[CLS] they they problem investigated? [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.648 (perp=7.652, rec=0.108, cos=0.009), tot_loss_proj:3.420 [t=0.18s]
prediction: ['[CLS] they the problem investigated. [SEP]']
[ 450/2000] tot_loss=1.637 (perp=7.652, rec=0.098, cos=0.009), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS] they the problem investigated. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.636 (perp=7.652, rec=0.098, cos=0.008), tot_loss_proj:3.426 [t=0.18s]
prediction: ['[CLS] they the problem investigated. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.655 (perp=7.652, rec=0.116, cos=0.008), tot_loss_proj:3.428 [t=0.18s]
prediction: ['[CLS] they the problem investigated. [SEP]']
[ 600/2000] tot_loss=1.638 (perp=7.652, rec=0.101, cos=0.006), tot_loss_proj:3.423 [t=0.18s]
prediction: ['[CLS] they the problem investigated. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.632 (perp=7.652, rec=0.096, cos=0.006), tot_loss_proj:3.417 [t=0.18s]
prediction: ['[CLS] they the problem investigated. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.622 (perp=7.652, rec=0.089, cos=0.002), tot_loss_proj:3.428 [t=0.18s]
prediction: ['[CLS] they the problem investigated. [SEP]']
[ 750/2000] tot_loss=1.601 (perp=7.652, rec=0.069, cos=0.001), tot_loss_proj:3.432 [t=0.18s]
prediction: ['[CLS] they the problem investigated. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=0.997 (perp=4.684, rec=0.059, cos=0.001), tot_loss_proj:1.052 [t=0.20s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.005 (perp=4.684, rec=0.067, cos=0.001), tot_loss_proj:1.055 [t=0.18s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[ 900/2000] tot_loss=1.008 (perp=4.684, rec=0.070, cos=0.001), tot_loss_proj:1.067 [t=0.18s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.006 (perp=4.684, rec=0.068, cos=0.001), tot_loss_proj:1.059 [t=0.18s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.007 (perp=4.684, rec=0.069, cos=0.001), tot_loss_proj:1.050 [t=0.18s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1050/2000] tot_loss=0.998 (perp=4.684, rec=0.060, cos=0.001), tot_loss_proj:1.048 [t=0.18s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.006 (perp=4.684, rec=0.068, cos=0.001), tot_loss_proj:1.062 [t=0.18s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.998 (perp=4.684, rec=0.060, cos=0.001), tot_loss_proj:1.040 [t=0.18s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1200/2000] tot_loss=1.007 (perp=4.684, rec=0.069, cos=0.001), tot_loss_proj:1.048 [t=0.18s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.001 (perp=4.684, rec=0.063, cos=0.001), tot_loss_proj:1.050 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.998 (perp=4.684, rec=0.060, cos=0.001), tot_loss_proj:1.057 [t=0.16s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1350/2000] tot_loss=1.002 (perp=4.684, rec=0.064, cos=0.001), tot_loss_proj:1.053 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.002 (perp=4.684, rec=0.064, cos=0.001), tot_loss_proj:1.049 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.000 (perp=4.684, rec=0.062, cos=0.001), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1500/2000] tot_loss=0.999 (perp=4.684, rec=0.061, cos=0.001), tot_loss_proj:1.049 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.000 (perp=4.684, rec=0.062, cos=0.001), tot_loss_proj:1.052 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.007 (perp=4.684, rec=0.069, cos=0.001), tot_loss_proj:1.049 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1650/2000] tot_loss=1.002 (perp=4.684, rec=0.064, cos=0.001), tot_loss_proj:1.054 [t=0.18s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.995 (perp=4.684, rec=0.057, cos=0.001), tot_loss_proj:1.051 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.993 (perp=4.684, rec=0.055, cos=0.001), tot_loss_proj:1.047 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1800/2000] tot_loss=0.990 (perp=4.684, rec=0.052, cos=0.001), tot_loss_proj:1.053 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.003 (perp=4.684, rec=0.065, cos=0.001), tot_loss_proj:1.051 [t=0.18s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.009 (perp=4.684, rec=0.071, cos=0.001), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1950/2000] tot_loss=1.003 (perp=4.684, rec=0.064, cos=0.001), tot_loss_proj:1.052 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.001 (perp=4.684, rec=0.063, cos=0.001), tot_loss_proj:1.047 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] they investigated the problem. [SEP]
========================
predicted: 
========================
[CLS] they investigated the problem. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 79.313 | p: 79.040 | r: 79.948
rouge2     | fm: 40.033 | p: 39.816 | r: 40.410
rougeL     | fm: 68.939 | p: 68.739 | r: 69.379
rougeLsum  | fm: 68.838 | p: 68.738 | r: 69.353
r1fm+r2fm = 119.346

input #91 time: 0:07:05 | total time: 12:16:23


Running input #92 of 100.
reference: 
========================
Andy promised that we would go.
========================
average of cosine similarity 0.9992554560728404
highest_index [0]
highest [0.9992554560728404]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 5557, 5763, 2008, 2057, 2052, 2175, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] andy promised that we would go. [SEP]']
[Init] best rec loss: 1.0239042043685913 for ['[CLS] church shade features forwardlateral one ⟨ [SEP]']
[Init] best rec loss: 0.998636782169342 for ['[CLS] parental expected chase years fighting ego in [SEP]']
[Init] best rec loss: 0.9670264720916748 for ['[CLS] mateo namely there electronics resort with knows [SEP]']
[Init] best rec loss: 0.9609618782997131 for ['[CLS] municipal over ahead hoping proved energy ui [SEP]']
[Init] best rec loss: 0.9385711550712585 for ['[CLS] internal fulfillinghel church hanging choice heath [SEP]']
[Init] best rec loss: 0.9254687428474426 for ['[CLS] bearerfor game trade suit conference bailey [SEP]']
[Init] best rec loss: 0.9024503231048584 for ['[CLS] deputy clint node ra measured wonders light [SEP]']
[Init] best perm rec loss: 0.9020792841911316 for ['[CLS] clint light deputy ra node wonders measured [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.674 (perp=10.197, rec=0.642, cos=0.992), tot_loss_proj:3.778 [t=0.17s]
prediction: ['[CLS] chevy, as we brett could went [SEP]']
[ 100/2000] tot_loss=3.777 (perp=11.154, rec=0.553, cos=0.993), tot_loss_proj:4.023 [t=0.17s]
prediction: ['[CLS] promised ; spp wehing would would [SEP]']
[ 150/2000] tot_loss=3.580 (perp=10.578, rec=0.468, cos=0.997), tot_loss_proj:3.974 [t=0.17s]
prediction: ['[CLS] promised that ¶ wehing would would [SEP]']
[ 200/2000] tot_loss=3.387 (perp=9.541, rec=0.480, cos=0.999), tot_loss_proj:3.669 [t=0.17s]
prediction: ['[CLS] promised that hms would we would pancakes [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.474 (perp=10.261, rec=0.422, cos=1.000), tot_loss_proj:3.888 [t=0.17s]
prediction: ['[CLS] promised. hd would we wouldved [SEP]']
[ 300/2000] tot_loss=3.484 (perp=10.209, rec=0.449, cos=0.993), tot_loss_proj:3.838 [t=0.17s]
prediction: ['[CLS] promised. hd would we would annabelle [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.439 (perp=10.209, rec=0.397, cos=1.000), tot_loss_proj:3.830 [t=0.17s]
prediction: ['[CLS] promised. hd would we would annabelle [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.561 (perp=10.823, rec=0.396, cos=1.000), tot_loss_proj:3.971 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
[ 450/2000] tot_loss=3.539 (perp=10.823, rec=0.374, cos=1.000), tot_loss_proj:3.975 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.544 (perp=10.823, rec=0.380, cos=0.999), tot_loss_proj:3.969 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.544 (perp=10.823, rec=0.379, cos=1.000), tot_loss_proj:3.971 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
[ 600/2000] tot_loss=3.528 (perp=10.823, rec=0.364, cos=1.000), tot_loss_proj:3.970 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.524 (perp=10.823, rec=0.359, cos=1.000), tot_loss_proj:3.971 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.527 (perp=10.823, rec=0.362, cos=1.000), tot_loss_proj:3.973 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
[ 750/2000] tot_loss=3.526 (perp=10.823, rec=0.361, cos=1.000), tot_loss_proj:3.969 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.526 (perp=10.823, rec=0.361, cos=1.000), tot_loss_proj:3.969 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.517 (perp=10.823, rec=0.352, cos=1.000), tot_loss_proj:3.972 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
[ 900/2000] tot_loss=3.514 (perp=10.823, rec=0.350, cos=1.000), tot_loss_proj:3.971 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.507 (perp=10.823, rec=0.343, cos=1.000), tot_loss_proj:3.970 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
Attempt swap
[1000/2000] tot_loss=3.517 (perp=10.823, rec=0.352, cos=1.000), tot_loss_proj:3.970 [t=0.17s]
prediction: ['[CLS] promised. hd would andy wouldotted [SEP]']
[1050/2000] tot_loss=3.549 (perp=11.016, rec=0.346, cos=1.000), tot_loss_proj:3.953 [t=0.17s]
prediction: ['[CLS] promised.ldon would andy wouldotted [SEP]']
Attempt swap
[1100/2000] tot_loss=3.539 (perp=11.016, rec=0.336, cos=1.000), tot_loss_proj:3.952 [t=0.17s]
prediction: ['[CLS] promised.ldon would andy wouldotted [SEP]']
Attempt swap
[1150/2000] tot_loss=3.326 (perp=9.961, rec=0.334, cos=1.000), tot_loss_proj:3.743 [t=0.17s]
prediction: ['[CLS] promised. we would andy wouldotted [SEP]']
[1200/2000] tot_loss=3.324 (perp=9.961, rec=0.332, cos=1.000), tot_loss_proj:3.750 [t=0.17s]
prediction: ['[CLS] promised. we would andy wouldotted [SEP]']
Attempt swap
[1250/2000] tot_loss=3.406 (perp=10.327, rec=0.340, cos=1.000), tot_loss_proj:3.870 [t=0.17s]
prediction: ['[CLS] promised. v would andy wouldotted [SEP]']
Attempt swap
[1300/2000] tot_loss=3.326 (perp=9.908, rec=0.344, cos=1.000), tot_loss_proj:3.723 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
[1350/2000] tot_loss=3.318 (perp=9.908, rec=0.336, cos=1.000), tot_loss_proj:3.721 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
Attempt swap
[1400/2000] tot_loss=3.324 (perp=9.908, rec=0.343, cos=1.000), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
Attempt swap
[1450/2000] tot_loss=3.315 (perp=9.908, rec=0.334, cos=1.000), tot_loss_proj:3.723 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
[1500/2000] tot_loss=3.312 (perp=9.908, rec=0.331, cos=1.000), tot_loss_proj:3.721 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
Attempt swap
[1550/2000] tot_loss=3.327 (perp=9.908, rec=0.345, cos=1.000), tot_loss_proj:3.724 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
Attempt swap
[1600/2000] tot_loss=3.323 (perp=9.908, rec=0.341, cos=1.000), tot_loss_proj:3.727 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
[1650/2000] tot_loss=3.324 (perp=9.908, rec=0.342, cos=1.000), tot_loss_proj:3.721 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
Attempt swap
[1700/2000] tot_loss=3.323 (perp=9.908, rec=0.341, cos=1.000), tot_loss_proj:3.724 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
Attempt swap
[1750/2000] tot_loss=3.322 (perp=9.908, rec=0.340, cos=1.000), tot_loss_proj:3.723 [t=0.20s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
[1800/2000] tot_loss=3.304 (perp=9.908, rec=0.322, cos=1.000), tot_loss_proj:3.720 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
Attempt swap
[1850/2000] tot_loss=3.309 (perp=9.908, rec=0.327, cos=1.000), tot_loss_proj:3.722 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
Attempt swap
[1900/2000] tot_loss=3.325 (perp=9.908, rec=0.344, cos=1.000), tot_loss_proj:3.727 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
[1950/2000] tot_loss=3.320 (perp=9.908, rec=0.338, cos=1.000), tot_loss_proj:3.722 [t=0.18s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
Attempt swap
[2000/2000] tot_loss=3.315 (perp=9.908, rec=0.333, cos=1.000), tot_loss_proj:3.725 [t=0.17s]
prediction: ['[CLS] promised. v would andy would¦ [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] andy promised that we would go. [SEP]
========================
predicted: 
========================
[CLS] promised. v would andy would¦ [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 71.429 | r: 62.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 53.333 | p: 57.143 | r: 50.000
rougeLsum  | fm: 53.333 | p: 57.143 | r: 50.000
r1fm+r2fm = 66.667

[Aggregate metrics]:
rouge1     | fm: 79.133 | p: 78.921 | r: 79.703
rouge2     | fm: 39.623 | p: 39.408 | r: 40.095
rougeL     | fm: 68.680 | p: 68.527 | r: 69.131
rougeLsum  | fm: 68.716 | p: 68.508 | r: 69.163
r1fm+r2fm = 118.756

input #92 time: 0:06:41 | total time: 12:23:05


Running input #93 of 100.
reference: 
========================
I saw these dancers and those musicians smoking something.
========================
average of cosine similarity 0.9994058377911292
highest_index [0]
highest [0.9994058377911292]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1045,  2387,  2122, 10487,  1998,  2216,  5389,  9422,  2242,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] i saw these dancers and those musicians smoking something. [SEP]']
[Init] best rec loss: 0.9399735331535339 for ['[CLS] choir torque titled uttar 25 tell even hitch encounter choosing [SEP]']
[Init] best rec loss: 0.9395652413368225 for ['[CLS] version ltd blur ringinghs chip astro bandrized federal [SEP]']
[Init] best rec loss: 0.9121893048286438 for ['[CLS] globe ~ titled scoredна japanese lynne they hardly lucas [SEP]']
[Init] best rec loss: 0.9106736779212952 for ['[CLS] existing ten exposurekti understandvirus beyond appear cubs planted [SEP]']
[Init] best rec loss: 0.9029486775398254 for ['[CLS] married formora wrong [CLS] enoughoft unanimouscturing spring [SEP]']
[Init] best rec loss: 0.8923229575157166 for ['[CLS] depending little you criteria remarriedmy within local flame conversion [SEP]']
[Init] best rec loss: 0.8887438774108887 for ['[CLS] sulfate basball shit begin collapse say full matches ems [SEP]']
[Init] best rec loss: 0.8878989219665527 for ['[CLS] applied ze milwaukee sharks though goods taken hour yin apps [SEP]']
[Init] best rec loss: 0.8873622417449951 for ['[CLS] aerospacelore no scheme ground overhead coach clearance under cal [SEP]']
[Init] best perm rec loss: 0.8865259289741516 for ['[CLS] aerospace scheme clearancelore ground overhead no coach cal under [SEP]']
[Init] best perm rec loss: 0.8864747285842896 for ['[CLS] coach clearance no scheme underlore aerospace cal overhead ground [SEP]']
[Init] best perm rec loss: 0.88502037525177 for ['[CLS] cal aerospace scheme overhead ground clearance nolore coach under [SEP]']
[Init] best perm rec loss: 0.8849398493766785 for ['[CLS] overheadlore ground aerospace no cal clearance coach scheme under [SEP]']
[Init] best perm rec loss: 0.8823032379150391 for ['[CLS] ground callore scheme clearance coach no aerospace overhead under [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.718 (perp=10.595, rec=0.603, cos=0.996), tot_loss_proj:3.956 [t=0.16s]
prediction: ['[CLS] its perceivedversion regardless equipment industry, airline : simultaneously [SEP]']
[ 100/2000] tot_loss=3.535 (perp=10.046, rec=0.542, cos=0.984), tot_loss_proj:3.793 [t=0.17s]
prediction: ['[CLS] its experiences dancers those these giant, airline : rhythm [SEP]']
[ 150/2000] tot_loss=3.965 (perp=11.970, rec=0.574, cos=0.997), tot_loss_proj:4.173 [t=0.17s]
prediction: ['[CLS] its these dancers thoseeurseborg and airlineoshi matches [SEP]']
[ 200/2000] tot_loss=3.802 (perp=11.662, rec=0.472, cos=0.998), tot_loss_proj:4.237 [t=0.17s]
prediction: ['[CLS] its diploma dancers those musicians musical nothing airline something something [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.838 (perp=12.007, rec=0.437, cos=0.999), tot_loss_proj:4.252 [t=0.17s]
prediction: ['[CLS] several diploma dancers those musicians musicians nothing attendant something something [SEP]']
[ 300/2000] tot_loss=3.818 (perp=12.007, rec=0.419, cos=0.998), tot_loss_proj:4.250 [t=0.17s]
prediction: ['[CLS] several diploma dancers those musicians musicians nothing attendant something something [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.764 (perp=11.801, rec=0.408, cos=0.995), tot_loss_proj:4.222 [t=0.17s]
prediction: ['[CLS] several diploma dancers those dancers musicians nothing attendant smoking something [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.853 (perp=12.301, rec=0.397, cos=0.996), tot_loss_proj:4.457 [t=0.17s]
prediction: ['[CLS] several diploma dancers those dancers musicians nothing musicians smoking something [SEP]']
[ 450/2000] tot_loss=3.812 (perp=12.160, rec=0.383, cos=0.996), tot_loss_proj:4.222 [t=0.17s]
prediction: ['[CLS] several and dancers those dancers musicians nothing musicians smoking something [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.547 (perp=10.732, rec=0.403, cos=0.998), tot_loss_proj:3.821 [t=0.17s]
prediction: ['[CLS] several nothing dancers those musicians funeral and attendant smoking something [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.504 (perp=10.302, rec=0.445, cos=0.998), tot_loss_proj:3.835 [t=0.17s]
prediction: ['[CLS] several nothing dancers and dancers funeral those contestants smoking something [SEP]']
[ 600/2000] tot_loss=3.444 (perp=10.302, rec=0.387, cos=0.997), tot_loss_proj:3.846 [t=0.17s]
prediction: ['[CLS] several nothing dancers and dancers funeral those contestants smoking something [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.705 (perp=11.684, rec=0.371, cos=0.998), tot_loss_proj:4.197 [t=0.17s]
prediction: ['[CLS] springsteen nothing dancers and dancers funeral those contestants smoking something [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=3.266 (perp=9.342, rec=0.401, cos=0.997), tot_loss_proj:3.665 [t=0.17s]
prediction: ['[CLS] nothing dancers and dancers prove those several musicians smoking something [SEP]']
[ 750/2000] tot_loss=3.243 (perp=9.342, rec=0.378, cos=0.996), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS] nothing dancers and dancers prove those several musicians smoking something [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.235 (perp=9.342, rec=0.370, cos=0.997), tot_loss_proj:3.672 [t=0.17s]
prediction: ['[CLS] nothing dancers and dancers prove those several musicians smoking something [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.345 (perp=9.942, rec=0.360, cos=0.997), tot_loss_proj:3.892 [t=0.17s]
prediction: ['[CLS]eous dancers and dancers prove those springsteen musicians smoking something [SEP]']
[ 900/2000] tot_loss=3.307 (perp=9.776, rec=0.355, cos=0.997), tot_loss_proj:3.852 [t=0.17s]
prediction: ['[CLS]eous dancers and musicians prove those springsteen musicians smoking something [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.311 (perp=9.776, rec=0.359, cos=0.997), tot_loss_proj:3.855 [t=0.17s]
prediction: ['[CLS]eous dancers and musicians prove those springsteen musicians smoking something [SEP]']
Attempt swap
[1000/2000] tot_loss=3.358 (perp=10.062, rec=0.349, cos=0.997), tot_loss_proj:3.855 [t=0.17s]
prediction: ['[CLS]eous dancers and musicians prove thoserained musicians smoking something [SEP]']
[1050/2000] tot_loss=3.361 (perp=10.098, rec=0.344, cos=0.997), tot_loss_proj:3.793 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1100/2000] tot_loss=3.356 (perp=10.098, rec=0.339, cos=0.997), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1150/2000] tot_loss=3.367 (perp=10.098, rec=0.350, cos=0.997), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
[1200/2000] tot_loss=3.363 (perp=10.098, rec=0.346, cos=0.997), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1250/2000] tot_loss=3.368 (perp=10.098, rec=0.351, cos=0.997), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1300/2000] tot_loss=3.357 (perp=10.098, rec=0.340, cos=0.997), tot_loss_proj:3.792 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
[1350/2000] tot_loss=3.362 (perp=10.098, rec=0.345, cos=0.997), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1400/2000] tot_loss=3.359 (perp=10.098, rec=0.342, cos=0.997), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1450/2000] tot_loss=3.353 (perp=10.098, rec=0.336, cos=0.997), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
[1500/2000] tot_loss=3.349 (perp=10.098, rec=0.332, cos=0.997), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1550/2000] tot_loss=3.354 (perp=10.098, rec=0.337, cos=0.997), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] describe dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1600/2000] tot_loss=3.259 (perp=9.614, rec=0.340, cos=0.997), tot_loss_proj:3.793 [t=0.17s]
prediction: ['[CLS] we dancers and musicians prove thoserained musicians smoking something [SEP]']
[1650/2000] tot_loss=3.259 (perp=9.614, rec=0.339, cos=0.997), tot_loss_proj:3.788 [t=0.17s]
prediction: ['[CLS] we dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1700/2000] tot_loss=3.251 (perp=9.614, rec=0.331, cos=0.997), tot_loss_proj:3.793 [t=0.17s]
prediction: ['[CLS] we dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1750/2000] tot_loss=3.261 (perp=9.614, rec=0.341, cos=0.997), tot_loss_proj:3.787 [t=0.18s]
prediction: ['[CLS] we dancers and musicians prove thoserained musicians smoking something [SEP]']
[1800/2000] tot_loss=3.253 (perp=9.614, rec=0.333, cos=0.997), tot_loss_proj:3.788 [t=0.18s]
prediction: ['[CLS] we dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1850/2000] tot_loss=3.265 (perp=9.614, rec=0.345, cos=0.997), tot_loss_proj:3.791 [t=0.18s]
prediction: ['[CLS] we dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[1900/2000] tot_loss=3.251 (perp=9.614, rec=0.331, cos=0.997), tot_loss_proj:3.786 [t=0.18s]
prediction: ['[CLS] we dancers and musicians prove thoserained musicians smoking something [SEP]']
[1950/2000] tot_loss=3.258 (perp=9.614, rec=0.338, cos=0.997), tot_loss_proj:3.788 [t=0.18s]
prediction: ['[CLS] we dancers and musicians prove thoserained musicians smoking something [SEP]']
Attempt swap
[2000/2000] tot_loss=3.253 (perp=9.614, rec=0.333, cos=0.997), tot_loss_proj:3.794 [t=0.18s]
prediction: ['[CLS] we dancers and musicians prove thoserained musicians smoking something [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] i saw these dancers and those musicians smoking something. [SEP]
========================
predicted: 
========================
[CLS] we dancers and musicians prove thoserained musicians smoking something [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.636 | p: 63.636 | r: 63.636
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 103.636

[Aggregate metrics]:
rouge1     | fm: 78.991 | p: 78.758 | r: 79.575
rouge2     | fm: 39.592 | p: 39.334 | r: 39.997
rougeL     | fm: 68.571 | p: 68.516 | r: 69.058
rougeLsum  | fm: 68.590 | p: 68.442 | r: 69.014
r1fm+r2fm = 118.583

input #93 time: 0:06:41 | total time: 12:29:47


Running input #94 of 100.
reference: 
========================
Ayala sent back her cousin the diamond necklace.
========================
average of cosine similarity 0.9992840849473748
highest_index [0]
highest [0.9992840849473748]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  2067,  2014,  5542,  1996,  6323, 13016,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ayala sent back her cousin the diamond necklace. [SEP]']
[Init] best rec loss: 1.0233622789382935 for ['[CLS] universe car flight volume stem? fangs naturally port produced [SEP]']
[Init] best rec loss: 0.810341477394104 for ['[CLS] c2 guysament means tucker indicated corresponding likes instead shifters [SEP]']
[Init] best rec loss: 0.8015455603599548 for ['[CLS] crocodile potter entertainment nearlaw chapel issues dive mohamedistle [SEP]']
[Init] best rec loss: 0.753000020980835 for ['[CLS] nina weights micah economy ladyaciesffled feeling harbor mt [SEP]']
[Init] best rec loss: 0.7525247931480408 for ['[CLS] commander system country ca young orleans facial yhaus boring [SEP]']
[Init] best rec loss: 0.7276646494865417 for ['[CLS] chartered cult4chment boat six cinder bothered eminentacies [SEP]']
[Init] best rec loss: 0.7244107127189636 for ['[CLS] henrytrip rs earlier ranks tr countries collection eye going [SEP]']
[Init] best rec loss: 0.7231367230415344 for ['[CLS] relegation unincorporated q hang separated arrive place settled up drawing [SEP]']
[Init] best rec loss: 0.7114856839179993 for ['[CLS]edge awareness champions being herself h derek label missions fits [SEP]']
[Init] best rec loss: 0.7034398317337036 for ['[CLS] o planned emirates fra conditioned simpsonlund client regulations friendly [SEP]']
[Init] best perm rec loss: 0.7031844854354858 for ['[CLS] simpsonlund conditioned planned emirates fra o client regulations friendly [SEP]']
[Init] best perm rec loss: 0.7023455500602722 for ['[CLS] client planned conditionedlund fra friendly regulations o simpson emirates [SEP]']
[Init] best perm rec loss: 0.7006390690803528 for ['[CLS] clientlund fra planned conditioned o friendly emirates simpson regulations [SEP]']
[Init] best perm rec loss: 0.699734091758728 for ['[CLS] fra emirates o conditioned simpson regulations planned clientlund friendly [SEP]']
[Init] best perm rec loss: 0.6980162858963013 for ['[CLS]lund regulations o client conditioned fra simpson planned emirates friendly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.753 (perp=11.323, rec=0.406, cos=0.083), tot_loss_proj:3.781 [t=0.17s]
prediction: ['[CLS] should sent girls temples her hot diamond body sciences to [SEP]']
[ 100/2000] tot_loss=2.418 (perp=9.949, rec=0.369, cos=0.059), tot_loss_proj:3.224 [t=0.17s]
prediction: ['[CLS] opposite sent body called kinship kiss diamond body diamond. [SEP]']
[ 150/2000] tot_loss=2.830 (perp=10.009, rec=0.659, cos=0.169), tot_loss_proj:3.283 [t=0.17s]
prediction: ['[CLS] liar sent security back grandmother. necklace body vampire. [SEP]']
[ 200/2000] tot_loss=2.439 (perp=9.809, rec=0.409, cos=0.068), tot_loss_proj:3.260 [t=0.17s]
prediction: ['[CLS] daughters sent any back contact. necklace back jewish. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.882 (perp=11.823, rec=0.429, cos=0.088), tot_loss_proj:3.442 [t=0.17s]
prediction: ['[CLS] deluxe sent municipal better latin. his necklace backle [SEP]']
[ 300/2000] tot_loss=3.140 (perp=11.246, rec=0.612, cos=0.279), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] diamond sent municipal better soccer ; empire heartbeat body the [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.973 (perp=11.972, rec=0.446, cos=0.133), tot_loss_proj:3.303 [t=0.17s]
prediction: ['[CLS] diamond sent worse cousin back * municipal diamond disc customs [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.606 (perp=10.684, rec=0.395, cos=0.074), tot_loss_proj:3.050 [t=0.17s]
prediction: ['[CLS] diamond sent back cousin customs * radical diamond front sending [SEP]']
[ 450/2000] tot_loss=2.326 (perp=9.607, rec=0.349, cos=0.055), tot_loss_proj:2.857 [t=0.16s]
prediction: ['[CLS] diamond sent back cousin customs *side diamond jewelry back [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.592 (perp=10.858, rec=0.364, cos=0.057), tot_loss_proj:3.201 [t=0.17s]
prediction: ['[CLS] * diamond sent niece texas customs sick diamond body back [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.422 (perp=10.205, rec=0.332, cos=0.049), tot_loss_proj:3.201 [t=0.17s]
prediction: ['[CLS] * diamond sent aunt cousin girl sick diamond back body [SEP]']
[ 600/2000] tot_loss=2.402 (perp=10.205, rec=0.317, cos=0.044), tot_loss_proj:3.203 [t=0.17s]
prediction: ['[CLS] * diamond sent aunt cousin girl sick diamond back body [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.229 (perp=9.486, rec=0.289, cos=0.043), tot_loss_proj:3.086 [t=0.17s]
prediction: ['[CLS] * diamond sent aunt girl cousin sick diamond back body [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.299 (perp=9.407, rec=0.356, cos=0.061), tot_loss_proj:2.910 [t=0.17s]
prediction: ['[CLS]. diamond sent sick girl cousin aunt diamond back body [SEP]']
[ 750/2000] tot_loss=2.299 (perp=10.042, rec=0.251, cos=0.039), tot_loss_proj:3.091 [t=0.17s]
prediction: ['[CLS] necklace diamond sent sick girl cousin his diamond back body [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.273 (perp=10.146, rec=0.213, cos=0.030), tot_loss_proj:3.435 [t=0.17s]
prediction: ['[CLS] necklaceyala sent sick cousin the diamond back girl necklace [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.117 (perp=9.500, rec=0.191, cos=0.026), tot_loss_proj:2.901 [t=0.17s]
prediction: ['[CLS] necklaceyala sent sick cousin the diamond necklace back girl [SEP]']
[ 900/2000] tot_loss=2.065 (perp=9.361, rec=0.170, cos=0.022), tot_loss_proj:3.074 [t=0.17s]
prediction: ['[CLS] necklaceyala sent sick cousin the diamond necklace back her [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.791 (perp=8.025, rec=0.165, cos=0.021), tot_loss_proj:2.563 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1000/2000] tot_loss=1.791 (perp=8.025, rec=0.167, cos=0.019), tot_loss_proj:2.572 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
[1050/2000] tot_loss=1.777 (perp=8.025, rec=0.154, cos=0.018), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1100/2000] tot_loss=1.775 (perp=8.025, rec=0.153, cos=0.017), tot_loss_proj:2.566 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1150/2000] tot_loss=1.765 (perp=8.025, rec=0.143, cos=0.017), tot_loss_proj:2.568 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
[1200/2000] tot_loss=1.762 (perp=8.025, rec=0.141, cos=0.016), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1250/2000] tot_loss=1.759 (perp=8.025, rec=0.138, cos=0.015), tot_loss_proj:2.562 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1300/2000] tot_loss=1.756 (perp=8.025, rec=0.136, cos=0.015), tot_loss_proj:2.566 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
[1350/2000] tot_loss=1.755 (perp=8.025, rec=0.136, cos=0.015), tot_loss_proj:2.576 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1400/2000] tot_loss=1.759 (perp=8.025, rec=0.139, cos=0.014), tot_loss_proj:2.568 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1450/2000] tot_loss=1.753 (perp=8.025, rec=0.134, cos=0.014), tot_loss_proj:2.566 [t=0.19s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
[1500/2000] tot_loss=1.747 (perp=8.025, rec=0.128, cos=0.014), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1550/2000] tot_loss=1.755 (perp=8.025, rec=0.136, cos=0.014), tot_loss_proj:2.565 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1600/2000] tot_loss=1.756 (perp=8.025, rec=0.138, cos=0.014), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
[1650/2000] tot_loss=1.750 (perp=8.025, rec=0.132, cos=0.013), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1700/2000] tot_loss=1.745 (perp=8.025, rec=0.127, cos=0.013), tot_loss_proj:2.572 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1750/2000] tot_loss=1.752 (perp=8.025, rec=0.134, cos=0.013), tot_loss_proj:2.565 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
[1800/2000] tot_loss=1.747 (perp=8.025, rec=0.129, cos=0.013), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1850/2000] tot_loss=1.743 (perp=8.025, rec=0.125, cos=0.013), tot_loss_proj:2.572 [t=0.18s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[1900/2000] tot_loss=1.747 (perp=8.025, rec=0.129, cos=0.013), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
[1950/2000] tot_loss=1.746 (perp=8.025, rec=0.128, cos=0.013), tot_loss_proj:2.571 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Attempt swap
[2000/2000] tot_loss=1.742 (perp=8.025, rec=0.124, cos=0.013), tot_loss_proj:2.567 [t=0.17s]
prediction: ['[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] ayala sent back her cousin the diamond necklace. [SEP]
========================
predicted: 
========================
[CLS] necklaceyala sent her cousin the diamond necklace back sick [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 42.105 | p: 40.000 | r: 44.444
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 127.820

[Aggregate metrics]:
rouge1     | fm: 79.095 | p: 78.823 | r: 79.730
rouge2     | fm: 39.700 | p: 39.382 | r: 40.152
rougeL     | fm: 68.670 | p: 68.519 | r: 69.161
rougeLsum  | fm: 68.744 | p: 68.586 | r: 69.261
r1fm+r2fm = 118.795

input #94 time: 0:06:40 | total time: 12:36:27


Running input #95 of 100.
reference: 
========================
Brenda met.
========================
average of cosine similarity 0.999258299021157
highest_index [0]
highest [0.999258299021157]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15507,  2777,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] brenda met. [SEP]']
[Init] best rec loss: 0.9856793880462646 for ['[CLS]eptive day less [SEP]']
[Init] best rec loss: 0.931098461151123 for ['[CLS]fall few why [SEP]']
[Init] best rec loss: 0.8573922514915466 for ['[CLS] princess horses domesday [SEP]']
[Init] best rec loss: 0.826335608959198 for ['[CLS]ave recorded head [SEP]']
[Init] best rec loss: 0.753989040851593 for ['[CLS] boss back michigan [SEP]']
[Init] best rec loss: 0.7457810044288635 for ['[CLS] pseudonym mill joyah [SEP]']
[Init] best rec loss: 0.728053867816925 for ['[CLS] mary scott pending [SEP]']
[Init] best perm rec loss: 0.7271443605422974 for ['[CLS] scott mary pending [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.664 (perp=7.451, rec=0.165, cos=0.009), tot_loss_proj:1.586 [t=0.16s]
prediction: ['[CLS] brenda met. [SEP]']
[ 100/2000] tot_loss=1.563 (perp=7.451, rec=0.071, cos=0.002), tot_loss_proj:1.590 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 150/2000] tot_loss=1.561 (perp=7.451, rec=0.069, cos=0.002), tot_loss_proj:1.587 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 200/2000] tot_loss=1.955 (perp=7.451, rec=0.390, cos=0.075), tot_loss_proj:1.645 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.607 (perp=7.451, rec=0.113, cos=0.004), tot_loss_proj:1.580 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 300/2000] tot_loss=1.570 (perp=7.451, rec=0.078, cos=0.002), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.559 (perp=7.451, rec=0.067, cos=0.002), tot_loss_proj:1.585 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.546 (perp=7.451, rec=0.054, cos=0.002), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 450/2000] tot_loss=1.546 (perp=7.451, rec=0.054, cos=0.002), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.547 (perp=7.451, rec=0.055, cos=0.002), tot_loss_proj:1.578 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.557 (perp=7.451, rec=0.065, cos=0.002), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 600/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.002), tot_loss_proj:1.582 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.560 (perp=7.451, rec=0.069, cos=0.001), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.562 (perp=7.451, rec=0.070, cos=0.001), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 750/2000] tot_loss=1.558 (perp=7.451, rec=0.066, cos=0.002), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.554 (perp=7.451, rec=0.062, cos=0.001), tot_loss_proj:1.581 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.549 (perp=7.451, rec=0.057, cos=0.001), tot_loss_proj:1.582 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 900/2000] tot_loss=1.553 (perp=7.451, rec=0.062, cos=0.001), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.549 (perp=7.451, rec=0.057, cos=0.001), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.557 (perp=7.451, rec=0.065, cos=0.001), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1050/2000] tot_loss=1.548 (perp=7.451, rec=0.056, cos=0.001), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.550 (perp=7.451, rec=0.059, cos=0.001), tot_loss_proj:1.577 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.564 (perp=7.451, rec=0.072, cos=0.001), tot_loss_proj:1.577 [t=0.16s]
prediction: ['[CLS] brenda met. [SEP]']
[1200/2000] tot_loss=1.553 (perp=7.451, rec=0.061, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.547 (perp=7.451, rec=0.055, cos=0.001), tot_loss_proj:1.577 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.543 (perp=7.451, rec=0.051, cos=0.001), tot_loss_proj:1.577 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1350/2000] tot_loss=1.548 (perp=7.451, rec=0.057, cos=0.001), tot_loss_proj:1.580 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.552 (perp=7.451, rec=0.060, cos=0.001), tot_loss_proj:1.587 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.552 (perp=7.451, rec=0.061, cos=0.001), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1500/2000] tot_loss=1.552 (perp=7.451, rec=0.060, cos=0.001), tot_loss_proj:1.587 [t=0.16s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.558 (perp=7.451, rec=0.066, cos=0.001), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.560 (perp=7.451, rec=0.068, cos=0.001), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1650/2000] tot_loss=1.560 (perp=7.451, rec=0.068, cos=0.001), tot_loss_proj:1.579 [t=0.16s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.549 (perp=7.451, rec=0.057, cos=0.001), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1800/2000] tot_loss=1.544 (perp=7.451, rec=0.053, cos=0.001), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.544 (perp=7.451, rec=0.052, cos=0.001), tot_loss_proj:1.580 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.553 (perp=7.451, rec=0.061, cos=0.001), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1950/2000] tot_loss=1.557 (perp=7.451, rec=0.065, cos=0.001), tot_loss_proj:1.576 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.550 (perp=7.451, rec=0.058, cos=0.001), tot_loss_proj:1.576 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] brenda met. [SEP]
========================
predicted: 
========================
[CLS] brenda met. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 79.301 | p: 79.026 | r: 79.907
rouge2     | fm: 40.263 | p: 39.983 | r: 40.705
rougeL     | fm: 69.084 | p: 68.874 | r: 69.563
rougeLsum  | fm: 68.972 | p: 68.861 | r: 69.435
r1fm+r2fm = 119.565

input #95 time: 0:06:40 | total time: 12:43:08


Running input #96 of 100.
reference: 
========================
Today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might.
========================
average of cosine similarity 0.9994474553270568
highest_index [0]
highest [0.9994474553270568]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  2651,  2045,  2003,  2210,  2030,  2053,  2880, 16011,  1997,
         11690,  2015,  1998,  5637,  2015,  2011,  1996,  2120,  2231,  1010,
          2348,  8392,  6867,  2453,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]']
[Init] best rec loss: 0.9376290440559387 for ['[CLS] typeilised exiary radha legislative spotlight latter jesse wonder passing opened church charm dropping santa authorities loan youth firm regarding 1930s border kirk [SEP]']
[Init] best rec loss: 0.930988609790802 for ['[CLS] library could quicknco quicklylerrradoum prose biology over spencer dirty? ebony room ltd laugh fiber 」 berlin twinned joe lucas [SEP]']
[Init] best rec loss: 0.9283707141876221 for ['[CLS] including viifactory spot mom avatar terms sikhcentric brandч hilton policemen hiding similarity extension press starring hold by upon were flood duc [SEP]']
[Init] best rec loss: 0.926461398601532 for ['[CLS]ed prepared aloud much directions department kendra wearing imperialism being software idea dyer bet and warner mu 30 bud prem happened operations napoleon silence [SEP]']
[Init] best rec loss: 0.9054527878761292 for ['[CLS] period roster assured disc guess proved au column three kapoor caesar regretphyator sometimes radical patel strait below recognition lori apparatus christiangration [SEP]']
[Init] best rec loss: 0.8999266624450684 for ['[CLS] radio ontogoing ammunition sleep sea invitation or abroad turkey stoneuringuidacious if lexington altar quality plus sum shower license o handy [SEP]']
[Init] best perm rec loss: 0.8994612097740173 for ['[CLS] plusacious if ouid or ammunition stone sleep invitation abroad altar radio license sea sumuring showergoing quality handy onto lexington turkey [SEP]']
[Init] best perm rec loss: 0.8985669016838074 for ['[CLS] sum lexingtonuid stone abroad plusgoing o or turkey invitationacious onto seauring sleep license shower if radio handy altar quality ammunition [SEP]']
[Init] best perm rec loss: 0.898284375667572 for ['[CLS] onto turkey or altar shower invitation abroad lexington qualityuid if stone ammunition ouring seagoingacious handy sleep plus sum license radio [SEP]']
[Init] best perm rec loss: 0.8974266052246094 for ['[CLS]going ontouringuid invitation sleep quality or sea if altar sum radio stone lexington turkey license ammunition o plus shower abroad handyacious [SEP]']
[Init] best perm rec loss: 0.8958510160446167 for ['[CLS] lexingtonuringuidacious stone sleep ammunition ifgoing license invitation radio shower sum onto abroad turkey o altar plus handy quality sea or [SEP]']
[Init] best perm rec loss: 0.8948376178741455 for ['[CLS]uring turkey onto lexington plus qualityuid if license altar sea handy stone ogoing sum or sleep radio abroad invitation shower ammunitionacious [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.959 (perp=12.370, rec=0.395, cos=0.090), tot_loss_proj:4.339 [t=0.17s]
prediction: ['[CLS] tents extinct sources aus any itself print gay bicycle or literature discrimination atoll. flats that population possibly far homosexuality african bottle manwise [SEP]']
[ 100/2000] tot_loss=2.656 (perp=11.571, rec=0.298, cos=0.043), tot_loss_proj:4.178 [t=0.17s]
prediction: ["[CLS] fired online evidencecturing for popularity today gay lesbian rather official spokesperson ′'lgbt the government lesbian government gay gay shower ` struggle [SEP]"]
[ 150/2000] tot_loss=2.694 (perp=11.129, rec=0.371, cos=0.097), tot_loss_proj:4.132 [t=0.17s]
prediction: ['[CLS] metals online realitycturing from popularity today lesbian harassment rather national spokesperson #. lgbt the government lesbian governments lesbian lesbiantablished ` struggle [SEP]']
[ 200/2000] tot_loss=2.258 (perp=9.982, rec=0.236, cos=0.025), tot_loss_proj:3.867 [t=0.17s]
prediction: ['[CLS] fired mommy despite never was influence today lesbian harassment or national spokesperson #, harassment no government lesbian government no gay / ` activities [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.193 (perp=9.695, rec=0.222, cos=0.032), tot_loss_proj:3.842 [t=0.17s]
prediction: ['[CLS] fluids mommy despite neither was ] today gay harassment [ national autonomous level. harassment no government yellow government, lesbian lesbians activities [SEP]']
[ 300/2000] tot_loss=2.135 (perp=9.600, rec=0.194, cos=0.021), tot_loss_proj:3.748 [t=0.17s]
prediction: ['[CLS]mers mommy despite neither was ] today gay harassment or national was level. harassment no governmentpot government the lesbian lesbians activities [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.924 (perp=8.748, rec=0.165, cos=0.010), tot_loss_proj:3.666 [t=0.17s]
prediction: ['[CLS]mers cultural government neither or is today gay harassment or national level. is harassment no government politics government the lesbian lesbians activities [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.866 (perp=8.477, rec=0.162, cos=0.009), tot_loss_proj:3.601 [t=0.17s]
prediction: ['[CLS]mers cultural government little or is today gay harassment or national level.. harassment no government government or government lesbian lesbians might [SEP]']
[ 450/2000] tot_loss=1.989 (perp=8.939, rec=0.181, cos=0.020), tot_loss_proj:3.616 [t=0.19s]
prediction: ['[CLS]mers helped politics little or influence today gay harassment or national level. is harassment no autonomous lesbian the government lesbian lesbians might [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.024 (perp=9.363, rec=0.144, cos=0.007), tot_loss_proj:3.663 [t=0.17s]
prediction: ['[CLS]mers helped politics little or influence today gay harassment or national clinical. lesbian harassment no autonomous lesbian or government is lesbians might [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.967 (perp=9.038, rec=0.149, cos=0.010), tot_loss_proj:3.615 [t=0.17s]
prediction: ['[CLS]mers helped politics little or influence today gay harassment or national clinical could lesbian harassment no autonomous lesbian the government might lesbians. [SEP]']
[ 600/2000] tot_loss=1.913 (perp=8.840, rec=0.139, cos=0.006), tot_loss_proj:3.585 [t=0.17s]
prediction: ['[CLS] how helped politics little or influence today gay harassment or national clinical could lesbian harassment no autonomous lesbian the government might lesbians. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.874 (perp=8.654, rec=0.137, cos=0.006), tot_loss_proj:3.571 [t=0.17s]
prediction: ['[CLS] how might politics little or influence today gay harassment or national under could lesbian harassment although autonomous lesbian the government helped lesbians. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.817 (perp=8.290, rec=0.146, cos=0.013), tot_loss_proj:3.490 [t=0.17s]
prediction: ['[CLS] how. little politics or influence today gay harassment or national official might lesbian harassment although autonomous although although government helped lesbians. [SEP]']
[ 750/2000] tot_loss=1.900 (perp=8.860, rec=0.123, cos=0.005), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] how. little politics or influence today gay harassment by national by might lesbian harassment although autonomous although although government helped lesbians. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.874 (perp=8.755, rec=0.118, cos=0.005), tot_loss_proj:3.620 [t=0.17s]
prediction: ['[CLS] how little. politics or influence today gay harassment by national by might lesbian harassment although autonomous although although government helped lesbians. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.852 (perp=8.609, rec=0.123, cos=0.007), tot_loss_proj:3.527 [t=0.17s]
prediction: ['[CLS]. little castle politics or official today gay harassment by national official might lesbian harassment although autonomous although although government helped lesbians. [SEP]']
[ 900/2000] tot_loss=2.008 (perp=9.423, rec=0.119, cos=0.005), tot_loss_proj:3.704 [t=0.17s]
prediction: ['[CLS]. little how politics or official today gay harassment by national by might lesbian harassment although autonomous although although government helped lesbians. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.992 (perp=9.326, rec=0.122, cos=0.005), tot_loss_proj:3.673 [t=0.17s]
prediction: ['[CLS]. little how reality or official official gay harassment by national today might lesbian harassment although autonomous although although government could lesbians. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.911 (perp=8.951, rec=0.116, cos=0.005), tot_loss_proj:3.669 [t=0.17s]
prediction: ['[CLS]. how little reality or official official gay harassment by national today might lesbian harassment although autonomous although although government could lesbians. [SEP]']
[1050/2000] tot_loss=1.906 (perp=8.951, rec=0.111, cos=0.004), tot_loss_proj:3.664 [t=0.17s]
prediction: ['[CLS]. how little reality or official official gay harassment by national today might lesbian harassment although autonomous although although government could lesbians. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.936 (perp=9.109, rec=0.110, cos=0.004), tot_loss_proj:3.608 [t=0.17s]
prediction: ['[CLS] how little. reality or official official gay harassment by national today might lesbian harassment although autonomous although although government could lesbians, [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.908 (perp=8.910, rec=0.119, cos=0.007), tot_loss_proj:3.603 [t=0.17s]
prediction: ['[CLS] how little. politics or official official gay harassment by national might lesbian harassment today although autonomous although although government could lesbians the [SEP]']
[1200/2000] tot_loss=1.931 (perp=9.110, rec=0.105, cos=0.004), tot_loss_proj:3.638 [t=0.17s]
prediction: ['[CLS] how little. reality or official official gay harassment by national might lesbian harassment today although autonomous although although government could lesbians the [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.888 (perp=8.805, rec=0.123, cos=0.005), tot_loss_proj:3.614 [t=0.17s]
prediction: ['[CLS] how little. reality or official could gay harassment by national might lesbian harassment today although autonomous although although government official lesbians the [SEP]']
Attempt swap
[1300/2000] tot_loss=1.835 (perp=8.600, rec=0.110, cos=0.004), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] how little. reality or official could gay harassment by national might lesbian harassment today although autonomous although the government official lesbians the [SEP]']
[1350/2000] tot_loss=1.879 (perp=8.876, rec=0.100, cos=0.004), tot_loss_proj:3.649 [t=0.17s]
prediction: ['[CLS] how little. reality or official [SEP] gay harassment by national might lesbian harassment today although autonomous although the government official lesbians the [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.940 (perp=9.149, rec=0.106, cos=0.004), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] how little. reality or official [SEP] gay harassment by national might berth harassment today although autonomous although the government official the lesbians [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.885 (perp=8.835, rec=0.114, cos=0.005), tot_loss_proj:3.644 [t=0.17s]
prediction: ['[CLS] how little autonomous reality or official [SEP] gay harassment by national might berth harassment today although. although the government official the lesbians [SEP]']
[1500/2000] tot_loss=1.882 (perp=8.835, rec=0.111, cos=0.004), tot_loss_proj:3.645 [t=0.20s]
prediction: ['[CLS] how little autonomous reality or official [SEP] gay harassment by national might berth harassment today although. although the government official the lesbians [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.828 (perp=8.573, rec=0.109, cos=0.004), tot_loss_proj:3.593 [t=0.20s]
prediction: ['[CLS] how little autonomous reality or official [SEP] gay harassment by national might berth although today harassment. although the government official the lesbians [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.832 (perp=8.560, rec=0.116, cos=0.005), tot_loss_proj:3.547 [t=0.18s]
prediction: ['[CLS] how little harassment reality or official [SEP] gay harassment by national might berth although today autonomous. although the government official the lesbians [SEP]']
[1650/2000] tot_loss=1.832 (perp=8.560, rec=0.116, cos=0.004), tot_loss_proj:3.547 [t=0.17s]
prediction: ['[CLS] how little harassment reality or official [SEP] gay harassment by national might berth although today autonomous. although the government official the lesbians [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.835 (perp=8.508, rec=0.126, cos=0.008), tot_loss_proj:3.540 [t=0.17s]
prediction: ['[CLS] how little harassment reality or official [SEP] gay harassment by national might berth today although autonomous. although the government official the lesbians [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.803 (perp=8.390, rec=0.119, cos=0.007), tot_loss_proj:3.491 [t=0.18s]
prediction: ['[CLS] how little reality or harassment official [SEP] gay harassment by national might berth today although autonomous. although the government official the lesbians [SEP]']
[1800/2000] tot_loss=1.768 (perp=8.195, rec=0.123, cos=0.006), tot_loss_proj:3.461 [t=0.19s]
prediction: ['[CLS] how little reality or harassment official [SEP] gay harassment by national might of today although autonomous. although the government official the lesbians [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.737 (perp=8.105, rec=0.111, cos=0.006), tot_loss_proj:3.483 [t=0.17s]
prediction: ['[CLS] how little reality harassment or official [SEP] gay harassment by national might of today although autonomous. although the government official the lesbians [SEP]']
Attempt swap
[1900/2000] tot_loss=1.743 (perp=8.105, rec=0.117, cos=0.005), tot_loss_proj:3.483 [t=0.17s]
prediction: ['[CLS] how little reality harassment or official [SEP] gay harassment by national might of today although autonomous. although the government official the lesbians [SEP]']
[1950/2000] tot_loss=1.783 (perp=8.378, rec=0.102, cos=0.005), tot_loss_proj:3.588 [t=0.17s]
prediction: ['[CLS] how little reality harassment or official [SEP] gay harassment by national might of today although autonomous. although although government official the lesbians [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.770 (perp=8.234, rec=0.118, cos=0.005), tot_loss_proj:3.554 [t=0.19s]
prediction: ['[CLS] how little reality harassment or official [SEP] gay harassment by national might of today although autonomous. although although the government official lesbians [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]
========================
predicted: 
========================
[CLS] how little harassment reality or official [SEP] gay harassment by national might berth although today autonomous. although the government official the lesbians [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 65.217 | p: 62.500 | r: 68.182
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 43.478 | p: 41.667 | r: 45.455
rougeLsum  | fm: 43.478 | p: 41.667 | r: 45.455
r1fm+r2fm = 65.217

[Aggregate metrics]:
rouge1     | fm: 79.209 | p: 78.920 | r: 79.872
rouge2     | fm: 39.816 | p: 39.559 | r: 40.247
rougeL     | fm: 68.670 | p: 68.535 | r: 69.156
rougeLsum  | fm: 68.833 | p: 68.535 | r: 69.259
r1fm+r2fm = 119.025

input #96 time: 0:06:54 | total time: 12:50:02


Running input #97 of 100.
reference: 
========================
This oven cooks well.
========================
average of cosine similarity 0.9993612893015668
highest_index [0]
highest [0.9993612893015668]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2023, 17428, 26929,  2092,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] this oven cooks well. [SEP]']
[Init] best rec loss: 1.0609800815582275 for ['[CLS] representing savedm ft dynasty [SEP]']
[Init] best rec loss: 1.0057979822158813 for ['[CLS] diagnosed timothy besides jump lab [SEP]']
[Init] best rec loss: 0.9389415383338928 for ['[CLS]gence charity g rain plain [SEP]']
[Init] best rec loss: 0.9305325150489807 for ['[CLS] tre river wil chamberlain donkey [SEP]']
[Init] best rec loss: 0.9199353456497192 for ['[CLS] emotional lara renewed [CLS] ve [SEP]']
[Init] best rec loss: 0.9128320813179016 for ['[CLS] alive sas mass fall why [SEP]']
[Init] best rec loss: 0.8864938020706177 for ['[CLS] led pure simulations lester junior [SEP]']
[Init] best rec loss: 0.8652690052986145 for ['[CLS] gael gearbox deserve enough air [SEP]']
[Init] best perm rec loss: 0.8601428866386414 for ['[CLS] gearbox enough deserve air gael [SEP]']
[Init] best perm rec loss: 0.8588325381278992 for ['[CLS] enough gearbox air gael deserve [SEP]']
[Init] best perm rec loss: 0.8585264682769775 for ['[CLS] enough deserve air gael gearbox [SEP]']
[Init] best perm rec loss: 0.8566455841064453 for ['[CLS] air deserve gael gearbox enough [SEP]']
[Init] best perm rec loss: 0.8556789755821228 for ['[CLS] gael air deserve gearbox enough [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.282 (perp=8.464, rec=0.604, cos=0.985), tot_loss_proj:3.630 [t=0.16s]
prediction: ['[CLS] oven or cliffs ). [SEP]']
[ 100/2000] tot_loss=3.046 (perp=7.726, rec=0.524, cos=0.977), tot_loss_proj:3.498 [t=0.17s]
prediction: ['[CLS] oven short chimneys ). [SEP]']
[ 150/2000] tot_loss=3.964 (perp=12.200, rec=0.556, cos=0.969), tot_loss_proj:4.409 [t=0.17s]
prediction: ['[CLS] oven oven oven cooper enough [SEP]']
[ 200/2000] tot_loss=3.270 (perp=9.313, rec=0.454, cos=0.953), tot_loss_proj:3.913 [t=0.17s]
prediction: ['[CLS] oven oven oven ᵍ. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.770 (perp=11.676, rec=0.516, cos=0.919), tot_loss_proj:4.116 [t=0.17s]
prediction: ['[CLS] oventow these oven ; [SEP]']
[ 300/2000] tot_loss=2.899 (perp=7.735, rec=0.426, cos=0.927), tot_loss_proj:3.546 [t=0.17s]
prediction: ['[CLS] oven oven oven oven. [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.143 (perp=8.991, rec=0.405, cos=0.941), tot_loss_proj:3.807 [t=0.17s]
prediction: ['[CLS] ovenaba oven oven. [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.294 (perp=9.837, rec=0.386, cos=0.940), tot_loss_proj:3.985 [t=0.17s]
prediction: ['[CLS] ovenaba oven cooks. [SEP]']
[ 450/2000] tot_loss=3.270 (perp=9.837, rec=0.376, cos=0.927), tot_loss_proj:3.978 [t=0.17s]
prediction: ['[CLS] ovenaba oven cooks. [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.193 (perp=9.491, rec=0.370, cos=0.925), tot_loss_proj:3.830 [t=0.17s]
prediction: ['[CLS] oven place oven cooks. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.086 (perp=9.026, rec=0.369, cos=0.912), tot_loss_proj:3.742 [t=0.17s]
prediction: ['[CLS] oven keeps oven cooks. [SEP]']
[ 600/2000] tot_loss=3.084 (perp=9.026, rec=0.366, cos=0.912), tot_loss_proj:3.747 [t=0.17s]
prediction: ['[CLS] oven keeps oven cooks. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.058 (perp=9.026, rec=0.350, cos=0.902), tot_loss_proj:3.738 [t=0.17s]
prediction: ['[CLS] oven keeps oven cooks. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.054 (perp=9.026, rec=0.353, cos=0.896), tot_loss_proj:3.737 [t=0.17s]
prediction: ['[CLS] oven keeps oven cooks. [SEP]']
[ 750/2000] tot_loss=3.052 (perp=9.026, rec=0.354, cos=0.893), tot_loss_proj:3.736 [t=0.17s]
prediction: ['[CLS] oven keeps oven cooks. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.034 (perp=9.026, rec=0.333, cos=0.896), tot_loss_proj:3.744 [t=0.17s]
prediction: ['[CLS] oven keeps oven cooks. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.256 (perp=10.112, rec=0.353, cos=0.881), tot_loss_proj:4.099 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
[ 900/2000] tot_loss=3.263 (perp=10.112, rec=0.358, cos=0.882), tot_loss_proj:4.103 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.238 (perp=10.112, rec=0.340, cos=0.876), tot_loss_proj:4.100 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.228 (perp=10.112, rec=0.335, cos=0.871), tot_loss_proj:4.099 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
[1050/2000] tot_loss=3.233 (perp=10.112, rec=0.340, cos=0.870), tot_loss_proj:4.103 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.220 (perp=10.112, rec=0.332, cos=0.866), tot_loss_proj:4.105 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.226 (perp=10.112, rec=0.340, cos=0.864), tot_loss_proj:4.108 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
[1200/2000] tot_loss=3.232 (perp=10.112, rec=0.345, cos=0.865), tot_loss_proj:4.098 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.219 (perp=10.112, rec=0.339, cos=0.858), tot_loss_proj:4.103 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.217 (perp=10.112, rec=0.334, cos=0.861), tot_loss_proj:4.102 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
[1350/2000] tot_loss=3.216 (perp=10.112, rec=0.336, cos=0.858), tot_loss_proj:4.099 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.222 (perp=10.112, rec=0.344, cos=0.856), tot_loss_proj:4.098 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.211 (perp=10.112, rec=0.334, cos=0.855), tot_loss_proj:4.099 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
[1500/2000] tot_loss=3.206 (perp=10.112, rec=0.328, cos=0.856), tot_loss_proj:4.103 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.212 (perp=10.112, rec=0.336, cos=0.854), tot_loss_proj:4.105 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.209 (perp=10.112, rec=0.333, cos=0.854), tot_loss_proj:4.108 [t=0.18s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
[1650/2000] tot_loss=3.214 (perp=10.112, rec=0.338, cos=0.854), tot_loss_proj:4.106 [t=0.18s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.209 (perp=10.112, rec=0.333, cos=0.854), tot_loss_proj:4.105 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.211 (perp=10.112, rec=0.335, cos=0.854), tot_loss_proj:4.101 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
[1800/2000] tot_loss=3.211 (perp=10.112, rec=0.336, cos=0.853), tot_loss_proj:4.103 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.208 (perp=10.112, rec=0.333, cos=0.853), tot_loss_proj:4.104 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.206 (perp=10.112, rec=0.332, cos=0.852), tot_loss_proj:4.101 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
[1950/2000] tot_loss=3.208 (perp=10.112, rec=0.333, cos=0.852), tot_loss_proj:4.101 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.208 (perp=10.112, rec=0.333, cos=0.852), tot_loss_proj:4.098 [t=0.17s]
prediction: ['[CLS] oveneft oven cooks. [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] this oven cooks well. [SEP]
========================
predicted: 
========================
[CLS] oveneft oven cooks. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 80.000 | r: 66.667
rouge2     | fm: 22.222 | p: 25.000 | r: 20.000
rougeL     | fm: 72.727 | p: 80.000 | r: 66.667
rougeLsum  | fm: 72.727 | p: 80.000 | r: 66.667
r1fm+r2fm = 94.949

[Aggregate metrics]:
rouge1     | fm: 79.106 | p: 78.904 | r: 79.651
rouge2     | fm: 39.565 | p: 39.368 | r: 39.974
rougeL     | fm: 68.756 | p: 68.676 | r: 69.206
rougeLsum  | fm: 68.772 | p: 68.683 | r: 69.235
r1fm+r2fm = 118.671

input #97 time: 0:06:36 | total time: 12:56:39


Running input #98 of 100.
reference: 
========================
Sarah devoured the cakes in the kitchen last night.
========================
average of cosine similarity 0.9993452529147651
highest_index [0]
highest [0.9993452529147651]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  4532, 16475, 16777,  1996, 22619,  1999,  1996,  3829,  2197,
          2305,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sarah devoured the cakes in the kitchen last night. [SEP]']
[Init] best rec loss: 0.9987524151802063 for ['[CLS] socialced coordination umbrella louder require paper plank parallel hi dame [SEP]']
[Init] best rec loss: 0.9721340537071228 for ['[CLS]mission instruments overnton _ revenge touch cole palettescent die [SEP]']
[Init] best rec loss: 0.9537109732627869 for ['[CLS] agreed cold indexed clip troops crazy basic methodology low mai burns [SEP]']
[Init] best rec loss: 0.9328851103782654 for ['[CLS] excited hadley coverage theatreere schoolhouse then scored point carpenter nature [SEP]']
[Init] best perm rec loss: 0.932117760181427 for ['[CLS] point schoolhouse theatre scored hadleyere nature excited carpenter then coverage [SEP]']
[Init] best perm rec loss: 0.9296472668647766 for ['[CLS] schoolhouse excited carpenterere hadley theatre coverage nature scored point then [SEP]']
[Init] best perm rec loss: 0.9284753203392029 for ['[CLS]ere excited nature carpenter scored theatre then hadley schoolhouse point coverage [SEP]']
[Init] best perm rec loss: 0.9283377528190613 for ['[CLS] carpenter hadley theatre coverage then excited scored natureere point schoolhouse [SEP]']
[Init] best perm rec loss: 0.9256162047386169 for ['[CLS] nature coverageere excited theatre schoolhouse then hadley scored point carpenter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.433 (perp=13.870, rec=0.471, cos=0.188), tot_loss_proj:4.621 [t=0.18s]
prediction: ['[CLS]yt ahead orleans dark introducing before neighbors codex patient. [ [SEP]']
[ 100/2000] tot_loss=3.074 (perp=12.694, rec=0.380, cos=0.155), tot_loss_proj:4.392 [t=0.18s]
prediction: ['[CLS] sarah laughter say becoming drink dinner sarah soap charles health last [SEP]']
[ 150/2000] tot_loss=3.043 (perp=12.979, rec=0.304, cos=0.144), tot_loss_proj:4.520 [t=0.19s]
prediction: ['[CLS]oured hers mate festival drink night sarah breath sarah kitchen last [SEP]']
[ 200/2000] tot_loss=2.610 (perp=11.611, rec=0.257, cos=0.031), tot_loss_proj:4.374 [t=0.19s]
prediction: ['[CLS]oured cakes intense &oured night sarah breath sarah kitchen last [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.521 (perp=11.574, rec=0.192, cos=0.014), tot_loss_proj:4.326 [t=0.18s]
prediction: ['[CLS]oured cakes replace redoured night sarah breath kitchen kitchen last [SEP]']
[ 300/2000] tot_loss=2.489 (perp=11.504, rec=0.179, cos=0.009), tot_loss_proj:4.321 [t=0.18s]
prediction: ['[CLS]oured cakes replace devoured night sarahzong kitchen kitchen last [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.300 (perp=10.651, rec=0.162, cos=0.008), tot_loss_proj:4.046 [t=0.17s]
prediction: ['[CLS]oured cakes dev devoured night sarah day kitchen kitchen last [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.794 (perp=12.423, rec=0.283, cos=0.026), tot_loss_proj:4.354 [t=0.17s]
prediction: ['[CLS] betweenoured cakesuroured night sarahhetic kitchen kitchen last [SEP]']
[ 450/2000] tot_loss=2.672 (perp=12.306, rec=0.199, cos=0.012), tot_loss_proj:4.303 [t=0.16s]
prediction: ['[CLS] betweenoured cakespoured night sarahhetic kitchen kitchen last [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.730 (perp=12.715, rec=0.178, cos=0.009), tot_loss_proj:4.416 [t=0.17s]
prediction: ['[CLS] betweenoured cakesaroured night sarah kitchen kitchenhetic last [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.631 (perp=12.254, rec=0.172, cos=0.008), tot_loss_proj:4.361 [t=0.17s]
prediction: ['[CLS] betweenoured cakes kitchenoured night sarah kitchenarhetic last [SEP]']
[ 600/2000] tot_loss=2.610 (perp=12.254, rec=0.152, cos=0.007), tot_loss_proj:4.365 [t=0.17s]
prediction: ['[CLS] betweenoured cakes kitchenoured night sarah kitchenarhetic last [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.584 (perp=12.104, rec=0.156, cos=0.007), tot_loss_proj:4.375 [t=0.17s]
prediction: ['[CLS] betweenoured cakes kitchenoured kitchen sarah inarhetic last [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.427 (perp=11.342, rec=0.152, cos=0.007), tot_loss_proj:4.057 [t=0.17s]
prediction: ['[CLS] kitchenoured cakes kitchenoured between sarah inarhetic last [SEP]']
[ 750/2000] tot_loss=2.310 (perp=10.836, rec=0.137, cos=0.006), tot_loss_proj:3.953 [t=0.17s]
prediction: ['[CLS] kitchenoured cakes kitchenoured in sarah inarhetic last [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.195 (perp=10.240, rec=0.141, cos=0.006), tot_loss_proj:3.878 [t=0.17s]
prediction: ['[CLS] kitchenoured cakes in kitchenoured sarah inarhetic last [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.187 (perp=10.210, rec=0.139, cos=0.006), tot_loss_proj:3.806 [t=0.17s]
prediction: ['[CLS] kitchenoured cakes in kitchenoured sarah in devhetic last [SEP]']
[ 900/2000] tot_loss=2.180 (perp=10.210, rec=0.132, cos=0.006), tot_loss_proj:3.811 [t=0.17s]
prediction: ['[CLS] kitchenoured cakes in kitchenoured sarah in devhetic last [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.175 (perp=10.210, rec=0.127, cos=0.006), tot_loss_proj:3.809 [t=0.17s]
prediction: ['[CLS] kitchenoured cakes in kitchenoured sarah in devhetic last [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.911 (perp=8.848, rec=0.134, cos=0.008), tot_loss_proj:3.736 [t=0.17s]
prediction: ['[CLS] kitchen the cakes in kitchen devoured sarah inhetic last [SEP]']
[1050/2000] tot_loss=1.906 (perp=8.848, rec=0.130, cos=0.007), tot_loss_proj:3.732 [t=0.17s]
prediction: ['[CLS] kitchen the cakes in kitchen devoured sarah inhetic last [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.783 (perp=8.247, rec=0.126, cos=0.007), tot_loss_proj:3.662 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah inhetic last [SEP]']
Attempt swap
[1150/2000] tot_loss=1.775 (perp=8.247, rec=0.119, cos=0.007), tot_loss_proj:3.659 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah inhetic last [SEP]']
[1200/2000] tot_loss=1.774 (perp=8.247, rec=0.118, cos=0.007), tot_loss_proj:3.653 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah inhetic last [SEP]']
Attempt swap
[1250/2000] tot_loss=1.771 (perp=8.247, rec=0.115, cos=0.007), tot_loss_proj:3.662 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah inhetic last [SEP]']
Attempt swap
[1300/2000] tot_loss=1.774 (perp=8.247, rec=0.118, cos=0.007), tot_loss_proj:3.656 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah inhetic last [SEP]']
[1350/2000] tot_loss=1.773 (perp=8.247, rec=0.117, cos=0.007), tot_loss_proj:3.654 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah inhetic last [SEP]']
Attempt swap
[1400/2000] tot_loss=1.778 (perp=8.247, rec=0.123, cos=0.007), tot_loss_proj:3.660 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah inhetic last [SEP]']
Attempt swap
[1450/2000] tot_loss=1.778 (perp=8.247, rec=0.122, cos=0.006), tot_loss_proj:3.658 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah inhetic last [SEP]']
[1500/2000] tot_loss=1.766 (perp=8.247, rec=0.111, cos=0.006), tot_loss_proj:3.655 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah inhetic last [SEP]']
Attempt swap
[1550/2000] tot_loss=1.635 (perp=7.621, rec=0.104, cos=0.006), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]']
Attempt swap
[1600/2000] tot_loss=1.648 (perp=7.621, rec=0.117, cos=0.006), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]']
[1650/2000] tot_loss=1.643 (perp=7.621, rec=0.113, cos=0.006), tot_loss_proj:3.380 [t=0.18s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]']
Attempt swap
[1700/2000] tot_loss=1.639 (perp=7.621, rec=0.109, cos=0.006), tot_loss_proj:3.381 [t=0.18s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]']
Attempt swap
[1750/2000] tot_loss=1.636 (perp=7.621, rec=0.105, cos=0.006), tot_loss_proj:3.382 [t=0.18s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]']
[1800/2000] tot_loss=1.646 (perp=7.621, rec=0.115, cos=0.006), tot_loss_proj:3.377 [t=0.18s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]']
Attempt swap
[1850/2000] tot_loss=1.650 (perp=7.621, rec=0.120, cos=0.006), tot_loss_proj:3.379 [t=0.19s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]']
Attempt swap
[1900/2000] tot_loss=1.643 (perp=7.621, rec=0.112, cos=0.006), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]']
[1950/2000] tot_loss=1.640 (perp=7.621, rec=0.110, cos=0.006), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]']
Attempt swap
[2000/2000] tot_loss=1.643 (perp=7.621, rec=0.113, cos=0.006), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] sarah devoured the cakes in the kitchen last night. [SEP]
========================
predicted: 
========================
[CLS] kitchen cakes in the kitchen devoured sarah in " last [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 111.818

[Aggregate metrics]:
rouge1     | fm: 79.153 | p: 78.919 | r: 79.681
rouge2     | fm: 39.715 | p: 39.459 | r: 40.043
rougeL     | fm: 68.729 | p: 68.654 | r: 69.171
rougeLsum  | fm: 68.766 | p: 68.663 | r: 69.233
r1fm+r2fm = 118.867

input #98 time: 0:06:50 | total time: 13:03:29


Running input #99 of 100.
reference: 
========================
The box contains the ball.
========================
average of cosine similarity 0.9994409028712468
highest_index [0]
highest [0.9994409028712468]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 1996, 3482, 3397, 1996, 3608, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the box contains the ball. [SEP]']
[Init] best rec loss: 0.9730719327926636 for ['[CLS] point bono dry position nothing using [SEP]']
[Init] best rec loss: 0.9256172180175781 for ['[CLS] tense childhood port oman mo earl [SEP]']
[Init] best rec loss: 0.9026228785514832 for ['[CLS] storage theatergraphic scholarships africa minorities [SEP]']
[Init] best rec loss: 0.9006547927856445 for ['[CLS] quoien hang town purse savings [SEP]']
[Init] best rec loss: 0.897529661655426 for ['[CLS] especiallylink but merchantywood rapid [SEP]']
[Init] best rec loss: 0.8682069182395935 for ['[CLS] [MASK] tennis reacherェ one note [SEP]']
[Init] best rec loss: 0.8641061186790466 for ['[CLS] returned raphael2 dragon sato deco [SEP]']
[Init] best perm rec loss: 0.8624070286750793 for ['[CLS]2 returned deco sato raphael dragon [SEP]']
[Init] best perm rec loss: 0.8620513677597046 for ['[CLS] deco sato raphael returned2 dragon [SEP]']
[Init] best perm rec loss: 0.8598130345344543 for ['[CLS] returned sato2 deco raphael dragon [SEP]']
[Init] best perm rec loss: 0.8590118885040283 for ['[CLS] sato deco2 returned dragon raphael [SEP]']
[Init] best perm rec loss: 0.8577542901039124 for ['[CLS]2 sato deco returned dragon raphael [SEP]']
[Init] best perm rec loss: 0.8570127487182617 for ['[CLS]2 deco returned dragon raphael sato [SEP]']
[Init] best perm rec loss: 0.8554680347442627 for ['[CLS]2 sato deco dragon returned raphael [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.176 (perp=8.518, rec=0.362, cos=0.111), tot_loss_proj:3.670 [t=0.18s]
prediction: ['[CLS] where box federer box.. [SEP]']
[ 100/2000] tot_loss=1.966 (perp=8.114, rec=0.288, cos=0.055), tot_loss_proj:3.589 [t=0.18s]
prediction: ['[CLS] contains box ball box box. [SEP]']
[ 150/2000] tot_loss=1.724 (perp=7.427, rec=0.206, cos=0.033), tot_loss_proj:3.469 [t=0.18s]
prediction: ['[CLS] contains box ball box ball. [SEP]']
[ 200/2000] tot_loss=1.784 (perp=8.103, rec=0.147, cos=0.017), tot_loss_proj:3.535 [t=0.18s]
prediction: ['[CLS] contains box ball contains ball. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.216 (perp=9.717, rec=0.229, cos=0.043), tot_loss_proj:3.834 [t=0.17s]
prediction: ['[CLS] box contains ball contains the! [SEP]']
[ 300/2000] tot_loss=2.169 (perp=10.036, rec=0.144, cos=0.017), tot_loss_proj:3.993 [t=0.18s]
prediction: ['[CLS] box contains ball box the box [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.631 (perp=7.497, rec=0.115, cos=0.016), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] box the ball box contains box [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.746 (perp=8.025, rec=0.125, cos=0.016), tot_loss_proj:3.029 [t=0.17s]
prediction: ['[CLS] the box ball box contains wines [SEP]']
[ 450/2000] tot_loss=1.735 (perp=8.025, rec=0.116, cos=0.014), tot_loss_proj:3.025 [t=0.17s]
prediction: ['[CLS] the box ball box contains wines [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.593 (perp=7.354, rec=0.109, cos=0.013), tot_loss_proj:3.443 [t=0.17s]
prediction: ['[CLS] the box ball. contains. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.781 (perp=8.294, rec=0.107, cos=0.015), tot_loss_proj:3.606 [t=0.17s]
prediction: ['[CLS] the box ball contains. self [SEP]']
[ 600/2000] tot_loss=1.795 (perp=8.371, rec=0.108, cos=0.013), tot_loss_proj:3.689 [t=0.17s]
prediction: ['[CLS] the box ball contains.½ [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.538 (perp=7.116, rec=0.101, cos=0.014), tot_loss_proj:3.386 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.538 (perp=7.116, rec=0.102, cos=0.013), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
[ 750/2000] tot_loss=1.531 (perp=7.116, rec=0.095, cos=0.012), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.526 (perp=7.116, rec=0.091, cos=0.012), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.533 (perp=7.116, rec=0.098, cos=0.012), tot_loss_proj:3.383 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
[ 900/2000] tot_loss=1.543 (perp=7.116, rec=0.108, cos=0.012), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.535 (perp=7.116, rec=0.100, cos=0.012), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.532 (perp=7.116, rec=0.097, cos=0.012), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
[1050/2000] tot_loss=1.530 (perp=7.116, rec=0.095, cos=0.012), tot_loss_proj:3.377 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.530 (perp=7.116, rec=0.096, cos=0.011), tot_loss_proj:3.382 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.534 (perp=7.116, rec=0.099, cos=0.011), tot_loss_proj:3.382 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
[1200/2000] tot_loss=1.523 (perp=7.116, rec=0.089, cos=0.011), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.533 (perp=7.116, rec=0.099, cos=0.011), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.531 (perp=7.116, rec=0.097, cos=0.011), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
[1350/2000] tot_loss=1.527 (perp=7.116, rec=0.093, cos=0.011), tot_loss_proj:3.373 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.527 (perp=7.116, rec=0.093, cos=0.011), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.531 (perp=7.116, rec=0.097, cos=0.011), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
[1500/2000] tot_loss=1.541 (perp=7.116, rec=0.107, cos=0.011), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.520 (perp=7.116, rec=0.086, cos=0.011), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.532 (perp=7.116, rec=0.097, cos=0.011), tot_loss_proj:3.380 [t=0.23s]
prediction: ['[CLS] the box ball contains½. [SEP]']
[1650/2000] tot_loss=1.529 (perp=7.116, rec=0.095, cos=0.011), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.537 (perp=7.116, rec=0.103, cos=0.011), tot_loss_proj:3.383 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.529 (perp=7.116, rec=0.095, cos=0.011), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
[1800/2000] tot_loss=1.538 (perp=7.116, rec=0.104, cos=0.011), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.537 (perp=7.116, rec=0.103, cos=0.011), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.535 (perp=7.116, rec=0.101, cos=0.011), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
[1950/2000] tot_loss=1.535 (perp=7.116, rec=0.101, cos=0.011), tot_loss_proj:3.380 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.528 (perp=7.116, rec=0.094, cos=0.011), tot_loss_proj:3.377 [t=0.17s]
prediction: ['[CLS] the box ball contains½. [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] the box contains the ball. [SEP]
========================
predicted: 
========================
[CLS] the box ball contains½. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 100.000 | r: 85.714
rouge2     | fm: 36.364 | p: 40.000 | r: 33.333
rougeL     | fm: 76.923 | p: 83.333 | r: 71.429
rougeLsum  | fm: 76.923 | p: 83.333 | r: 71.429
r1fm+r2fm = 128.671

[Aggregate metrics]:
rouge1     | fm: 79.290 | p: 79.120 | r: 79.724
rouge2     | fm: 39.590 | p: 39.419 | r: 39.967
rougeL     | fm: 68.860 | p: 68.850 | r: 69.166
rougeLsum  | fm: 68.885 | p: 68.821 | r: 69.209
r1fm+r2fm = 118.880

input #99 time: 0:06:44 | total time: 13:10:13


Average Cosine Similarity: 0.9993532828782739
Done with all.
