


Command: attack4.py --dataset cola --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola --n_steps 2000 --coeff_pooler_match 0.01 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 1413.33it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
Harriet alternated folk songs and pop songs together.
========================
Sample: 0 1.1914513509471892e-12 0.04816228927718489 0.3176363
average of cosine similarity 0.9884377232308336
highest_index [0]
highest [0.9884377232308336]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 14207,  6585,  2094,  5154,  2774,  1998,  3769,  2774,  2362,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] harriet alternated folk songs and pop songs together. [SEP]']
[Init] best rec loss: 0.9993575811386108 for ['[CLS] study showing exchange victorywall same bryant compulsory cl regiments [SEP]']
[Init] best rec loss: 0.881753146648407 for ['[CLS] report make baglary fell paul max rape younger broken [SEP]']
[Init] best rec loss: 0.8786035180091858 for ['[CLS] ll himself by fines now pleased whole market none cody [SEP]']
[Init] best rec loss: 0.8534309267997742 for ['[CLS] high leonard " fae nightclub awaiting write spillstadyme [SEP]']
[Init] best rec loss: 0.8307695388793945 for ['[CLS] lo hr positionperation trees temperance madonnaguard minutes vs [SEP]']
[Init] best rec loss: 0.8198035359382629 for ['[CLS] ) monitor witch market issue healing stole dia indoor lane [SEP]']
[Init] best perm rec loss: 0.8187926411628723 for ['[CLS] market dia lane issue ) stole monitor witch indoor healing [SEP]']
[Init] best perm rec loss: 0.8181319236755371 for ['[CLS] market healing ) issue witch stole monitor indoor lane dia [SEP]']
[Init] best perm rec loss: 0.8154435753822327 for ['[CLS] witch healing lane ) issue stole indoor monitor market dia [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.266 (perp=12.745, rec=0.494, cos=0.223), tot_loss_proj:4.479 [t=0.17s]
prediction: ['[CLS]不 teaching moth songs twice mixing rm songs arrangements travel [SEP]']
[ 100/2000] tot_loss=3.022 (perp=12.645, rec=0.371, cos=0.122), tot_loss_proj:4.453 [t=0.17s]
prediction: ['[CLS] harriet teaching rock songs already alternate blog songs nancy comedy [SEP]']
[ 150/2000] tot_loss=2.653 (perp=11.293, rec=0.308, cos=0.087), tot_loss_proj:3.978 [t=0.17s]
prediction: ['[CLS] harrietd folk songs alternate alternate lgbt songs harriet folk [SEP]']
[ 200/2000] tot_loss=2.640 (perp=11.293, rec=0.293, cos=0.088), tot_loss_proj:3.988 [t=0.17s]
prediction: ['[CLS] harrietd folk songs alternate alternate lgbt songs harriet folk [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.186 (perp=9.431, rec=0.247, cos=0.053), tot_loss_proj:3.814 [t=0.17s]
prediction: ['[CLS] harriet abs folk songs. alternated " pop folk [SEP]']
[ 300/2000] tot_loss=2.296 (perp=10.215, rec=0.210, cos=0.043), tot_loss_proj:3.975 [t=0.17s]
prediction: ['[CLS] harriet abs folk together when alternated " pop folk [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.503 (perp=9.478, rec=0.433, cos=0.175), tot_loss_proj:3.839 [t=0.17s]
prediction: ['[CLS]\'harriet folk together differences alternateed " harriet. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.395 (perp=10.066, rec=0.307, cos=0.075), tot_loss_proj:3.935 [t=0.17s]
prediction: ['[CLS] abs harriet folk songs differencesed " alternate harriet folk [SEP]']
[ 450/2000] tot_loss=2.528 (perp=11.124, rec=0.257, cos=0.046), tot_loss_proj:4.008 [t=0.17s]
prediction: ['[CLS]ᴺ harriet folk songs anded " alternate [MASK] folk [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.411 (perp=10.748, rec=0.226, cos=0.035), tot_loss_proj:4.050 [t=0.17s]
prediction: ['[CLS] together harriet folked song alternate songs together [MASK] folk [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.261 (perp=10.019, rec=0.218, cos=0.039), tot_loss_proj:3.929 [t=0.17s]
prediction: ['[CLS] together harriet folk song alternated songs together [MASK] folk [SEP]']
[ 600/2000] tot_loss=2.281 (perp=10.019, rec=0.213, cos=0.064), tot_loss_proj:3.934 [t=0.17s]
prediction: ['[CLS] together harriet folk song alternated songs together [MASK] folk [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.069 (perp=9.357, rec=0.168, cos=0.030), tot_loss_proj:3.786 [t=0.17s]
prediction: ['[CLS] together harriet alternated folk songs songs together [MASK] folk [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.386 (perp=8.177, rec=0.491, cos=0.259), tot_loss_proj:3.524 [t=0.17s]
prediction: ['[CLS] alongside harriet alternated folk shit folk songs together. [SEP]']
[ 750/2000] tot_loss=1.985 (perp=7.978, rec=0.298, cos=0.092), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] with harriet alternated folk shit folk songs together. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.781 (perp=7.260, rec=0.253, cos=0.076), tot_loss_proj:3.263 [t=0.17s]
prediction: ['[CLS] harriet alternated folk - with folk songs together. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.751 (perp=7.301, rec=0.226, cos=0.065), tot_loss_proj:3.257 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs together - alongside folk. [SEP]']
[ 900/2000] tot_loss=1.719 (perp=7.301, rec=0.205, cos=0.053), tot_loss_proj:3.257 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs together - alongside folk. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.694 (perp=7.301, rec=0.186, cos=0.048), tot_loss_proj:3.262 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs together - alongside folk. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.680 (perp=7.301, rec=0.176, cos=0.043), tot_loss_proj:3.260 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs together - alongside folk. [SEP]']
[1050/2000] tot_loss=1.703 (perp=7.470, rec=0.169, cos=0.040), tot_loss_proj:3.014 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs together / alongside folk. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.618 (perp=7.063, rec=0.166, cos=0.039), tot_loss_proj:3.146 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs songs together alongside folk. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.350 (perp=5.805, rec=0.150, cos=0.039), tot_loss_proj:2.750 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs alongside folk songs together. [SEP]']
[1200/2000] tot_loss=1.346 (perp=5.805, rec=0.149, cos=0.036), tot_loss_proj:2.746 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs alongside folk songs together. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.227 (perp=5.240, rec=0.145, cos=0.034), tot_loss_proj:2.377 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs with folk songs together. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.222 (perp=5.240, rec=0.142, cos=0.033), tot_loss_proj:2.379 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs with folk songs together. [SEP]']
[1350/2000] tot_loss=1.177 (perp=4.994, rec=0.146, cos=0.032), tot_loss_proj:1.255 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.163 (perp=4.994, rec=0.133, cos=0.031), tot_loss_proj:1.256 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.166 (perp=4.994, rec=0.137, cos=0.030), tot_loss_proj:1.252 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
[1500/2000] tot_loss=1.170 (perp=4.994, rec=0.141, cos=0.030), tot_loss_proj:1.252 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.165 (perp=4.994, rec=0.136, cos=0.030), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.164 (perp=4.994, rec=0.136, cos=0.029), tot_loss_proj:1.246 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
[1650/2000] tot_loss=1.154 (perp=4.994, rec=0.126, cos=0.029), tot_loss_proj:1.248 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.161 (perp=4.994, rec=0.134, cos=0.029), tot_loss_proj:1.252 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.159 (perp=4.994, rec=0.132, cos=0.028), tot_loss_proj:1.259 [t=0.19s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
[1800/2000] tot_loss=1.163 (perp=4.994, rec=0.136, cos=0.028), tot_loss_proj:1.249 [t=0.19s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.151 (perp=4.994, rec=0.124, cos=0.028), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.154 (perp=4.994, rec=0.128, cos=0.028), tot_loss_proj:1.255 [t=0.19s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
[1950/2000] tot_loss=1.160 (perp=4.994, rec=0.133, cos=0.028), tot_loss_proj:1.252 [t=0.18s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.154 (perp=4.994, rec=0.128, cos=0.028), tot_loss_proj:1.251 [t=0.21s]
prediction: ['[CLS] harriet alternated folk songs and folk songs together. [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] harriet alternated folk songs and pop songs together. [SEP]
========================
predicted: 
========================
[CLS] harriet alternated folk songs and folk songs together. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 77.778 | p: 77.778 | r: 77.778
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 167.778

[Aggregate metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 77.778 | p: 77.778 | r: 77.778
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 167.778

input #0 time: 0:07:02 | total time: 0:07:02


Running input #1 of 100.
reference: 
========================
Who do you think that will question Seamus first?
========================
Sample: 0 3.3242934397844367e-13 0.05247265767652943 0.35746136
average of cosine similarity 0.9891673008382202
highest_index [0]
highest [0.9891673008382202]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2040,  2079,  2017,  2228,  2008,  2097,  3160, 24993,  2034,
          1029,   102]], device='cuda:0')
Debug: ref = ['[CLS] who do you think that will question seamus first? [SEP]']
[Init] best rec loss: 0.842589259147644 for ['[CLS] singerии middlesbrough tells certificate numbering century sung nowhere go [SEP]']
[Init] best rec loss: 0.8232784271240234 for ['[CLS] israel work rotational sights warm exclusive neither holding award jet [SEP]']
[Init] best rec loss: 0.7734784483909607 for ['[CLS] can kerr dry jack hood shownnsed powered feet [CLS] [SEP]']
[Init] best rec loss: 0.6931681632995605 for ['[CLS] because richest soc final melbourne gallo building mob might storm [SEP]']
[Init] best rec loss: 0.6918148398399353 for ['[CLS]less millennium billboard ron trial marino empire clerk kai brand [SEP]']
[Init] best rec loss: 0.6907491683959961 for ['[CLS] whitney paid space besides itself freedomud white waist there [SEP]']
[Init] best rec loss: 0.6749796271324158 for ['[CLS]lance spiders roman above selectcarriageoured towardsiness page [SEP]']
[Init] best perm rec loss: 0.6743735074996948 for ['[CLS]iness roman selectcarriage towardsoured abovelance page spiders [SEP]']
[Init] best perm rec loss: 0.6720325946807861 for ['[CLS]lance towards spiders aboveoured romaniness select pagecarriage [SEP]']
[Init] best perm rec loss: 0.6717727780342102 for ['[CLS] page select spidersinesscarriage abovelance romanoured towards [SEP]']
[Init] best perm rec loss: 0.6715611815452576 for ['[CLS] towards page spidersoured selectiness romanlance abovecarriage [SEP]']
[Init] best perm rec loss: 0.6711361408233643 for ['[CLS] abovecarriagelance spidersiness towards pageoured roman select [SEP]']
[Init] best perm rec loss: 0.6707462668418884 for ['[CLS] page above roman spiders selectlanceinesscarriage towardsoured [SEP]']
[Init] best perm rec loss: 0.6705222725868225 for ['[CLS] roman pageinesscarriage select towards above spiderslanceoured [SEP]']
[Init] best perm rec loss: 0.6702622771263123 for ['[CLS]ourediness select page towards roman above spiderslancecarriage [SEP]']
[Init] best perm rec loss: 0.6695494055747986 for ['[CLS]iness page above spiders romancarriageoured towardslance select [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.957 (perp=12.393, rec=0.391, cos=0.087), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] kara fc heavy 2018 which whenathlon bumps seamus transfer [SEP]']
[ 100/2000] tot_loss=2.925 (perp=12.871, rec=0.294, cos=0.056), tot_loss_proj:3.752 [t=0.17s]
prediction: ['[CLS] seamus feellly who that whenathlon follow seamus transfer [SEP]']
[ 150/2000] tot_loss=2.041 (perp=8.725, rec=0.246, cos=0.050), tot_loss_proj:2.661 [t=0.17s]
prediction: ['[CLS] seamus feel? who that would question will seamus? [SEP]']
[ 200/2000] tot_loss=2.216 (perp=10.058, rec=0.177, cos=0.028), tot_loss_proj:3.017 [t=0.17s]
prediction: ['[CLS] seamus think think who that will question will seamus? [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.890 (perp=8.617, rec=0.142, cos=0.025), tot_loss_proj:2.576 [t=0.17s]
prediction: ['[CLS] seamus do think that will always who question seamus? [SEP]']
[ 300/2000] tot_loss=1.849 (perp=8.617, rec=0.104, cos=0.021), tot_loss_proj:2.582 [t=0.17s]
prediction: ['[CLS] seamus do think that will always who question seamus? [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.766 (perp=8.186, rec=0.108, cos=0.021), tot_loss_proj:2.746 [t=0.17s]
prediction: ['[CLS] seamus do think that who will first question seamus? [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.307 (perp=5.992, rec=0.086, cos=0.023), tot_loss_proj:2.790 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[ 450/2000] tot_loss=1.303 (perp=5.992, rec=0.084, cos=0.021), tot_loss_proj:2.754 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.309 (perp=5.992, rec=0.090, cos=0.021), tot_loss_proj:2.744 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.308 (perp=5.992, rec=0.089, cos=0.021), tot_loss_proj:2.741 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[ 600/2000] tot_loss=1.301 (perp=5.992, rec=0.081, cos=0.021), tot_loss_proj:2.738 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.296 (perp=5.992, rec=0.076, cos=0.021), tot_loss_proj:2.737 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.296 (perp=5.992, rec=0.077, cos=0.021), tot_loss_proj:2.737 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[ 750/2000] tot_loss=1.282 (perp=5.992, rec=0.062, cos=0.022), tot_loss_proj:2.734 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.297 (perp=5.992, rec=0.077, cos=0.022), tot_loss_proj:2.730 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.297 (perp=5.992, rec=0.078, cos=0.022), tot_loss_proj:2.726 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[ 900/2000] tot_loss=1.292 (perp=5.992, rec=0.073, cos=0.022), tot_loss_proj:2.727 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.286 (perp=5.992, rec=0.066, cos=0.022), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.289 (perp=5.992, rec=0.069, cos=0.022), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[1050/2000] tot_loss=1.284 (perp=5.992, rec=0.064, cos=0.022), tot_loss_proj:2.721 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.293 (perp=5.992, rec=0.073, cos=0.022), tot_loss_proj:2.721 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.287 (perp=5.992, rec=0.068, cos=0.022), tot_loss_proj:2.721 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[1200/2000] tot_loss=1.282 (perp=5.992, rec=0.062, cos=0.022), tot_loss_proj:2.719 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.281 (perp=5.992, rec=0.061, cos=0.022), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.289 (perp=5.992, rec=0.069, cos=0.022), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[1350/2000] tot_loss=1.294 (perp=5.992, rec=0.075, cos=0.022), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.277 (perp=5.992, rec=0.057, cos=0.022), tot_loss_proj:2.721 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.279 (perp=5.992, rec=0.060, cos=0.022), tot_loss_proj:2.718 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[1500/2000] tot_loss=1.284 (perp=5.992, rec=0.064, cos=0.022), tot_loss_proj:2.721 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.282 (perp=5.992, rec=0.062, cos=0.022), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.293 (perp=5.992, rec=0.073, cos=0.022), tot_loss_proj:2.719 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[1650/2000] tot_loss=1.284 (perp=5.992, rec=0.064, cos=0.022), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.283 (perp=5.992, rec=0.063, cos=0.022), tot_loss_proj:2.724 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.295 (perp=5.992, rec=0.075, cos=0.022), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[1800/2000] tot_loss=1.283 (perp=5.992, rec=0.063, cos=0.022), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.286 (perp=5.992, rec=0.066, cos=0.022), tot_loss_proj:2.726 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.278 (perp=5.992, rec=0.058, cos=0.022), tot_loss_proj:2.721 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
[1950/2000] tot_loss=1.291 (perp=5.992, rec=0.071, cos=0.022), tot_loss_proj:2.721 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.286 (perp=5.992, rec=0.066, cos=0.022), tot_loss_proj:2.720 [t=0.17s]
prediction: ['[CLS] do you think that who will first question seamus? [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] who do you think that will question seamus first? [SEP]
========================
predicted: 
========================
[CLS] do you think that who will first question seamus? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 95.000 | p: 95.000 | r: 95.000
rouge2     | fm: 58.889 | p: 58.889 | r: 58.889
rougeL     | fm: 85.909 | p: 85.909 | r: 85.909
rougeLsum  | fm: 85.909 | p: 85.909 | r: 85.909
r1fm+r2fm = 153.889

input #1 time: 0:06:48 | total time: 0:13:50


Running input #2 of 100.
reference: 
========================
The boy ran.
========================
Sample: 0 3.1693288811942394e-12 0.050566237707134115 0.3542878
average of cosine similarity 0.9897621597882496
highest_index [0]
highest [0.9897621597882496]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 1996, 2879, 2743, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the boy ran. [SEP]']
[Init] best rec loss: 0.9620961546897888 for ['[CLS] animation equal wickets gran [SEP]']
[Init] best rec loss: 0.9495673179626465 for ['[CLS] rose instruction lengths ; [SEP]']
[Init] best rec loss: 0.9206191301345825 for ['[CLS] february bachelor energyets [SEP]']
[Init] best rec loss: 0.8724637627601624 for ['[CLS] directly goes our sang [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.699 (perp=10.795, rec=0.586, cos=0.954), tot_loss_proj:4.254 [t=0.17s]
prediction: ['[CLS] woman ran ran ran [SEP]']
[ 100/2000] tot_loss=2.600 (perp=10.953, rec=0.322, cos=0.088), tot_loss_proj:4.098 [t=0.17s]
prediction: ['[CLS] boy ran ran ran [SEP]']
[ 150/2000] tot_loss=2.442 (perp=11.225, rec=0.156, cos=0.041), tot_loss_proj:4.205 [t=0.17s]
prediction: ['[CLS] boy mask ran ran [SEP]']
[ 200/2000] tot_loss=2.443 (perp=11.309, rec=0.143, cos=0.038), tot_loss_proj:4.189 [t=0.17s]
prediction: ['[CLS] boy the ran ran [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.761 (perp=7.907, rec=0.139, cos=0.041), tot_loss_proj:3.597 [t=0.17s]
prediction: ['[CLS] the ran boy ran [SEP]']
[ 300/2000] tot_loss=2.210 (perp=10.173, rec=0.136, cos=0.039), tot_loss_proj:4.126 [t=0.17s]
prediction: ['[CLS]. ran boy ran [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.461 (perp=11.325, rec=0.155, cos=0.041), tot_loss_proj:4.286 [t=0.19s]
prediction: ['[CLS] - boydown ran [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.587 (perp=7.053, rec=0.138, cos=0.038), tot_loss_proj:2.674 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
[ 450/2000] tot_loss=1.585 (perp=7.053, rec=0.136, cos=0.038), tot_loss_proj:2.664 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.584 (perp=7.053, rec=0.135, cos=0.038), tot_loss_proj:2.667 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.582 (perp=7.053, rec=0.133, cos=0.038), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
[ 600/2000] tot_loss=1.574 (perp=7.053, rec=0.126, cos=0.038), tot_loss_proj:2.662 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.561 (perp=7.053, rec=0.113, cos=0.037), tot_loss_proj:2.662 [t=0.18s]
prediction: ['[CLS].. boy ran [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.579 (perp=7.053, rec=0.131, cos=0.037), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
[ 750/2000] tot_loss=1.575 (perp=7.053, rec=0.127, cos=0.037), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.566 (perp=7.053, rec=0.119, cos=0.037), tot_loss_proj:2.667 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.584 (perp=7.053, rec=0.137, cos=0.036), tot_loss_proj:2.665 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
[ 900/2000] tot_loss=1.581 (perp=7.053, rec=0.134, cos=0.036), tot_loss_proj:2.662 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.574 (perp=7.053, rec=0.127, cos=0.036), tot_loss_proj:2.662 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
Attempt swap
[1000/2000] tot_loss=1.569 (perp=7.053, rec=0.123, cos=0.036), tot_loss_proj:2.668 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
[1050/2000] tot_loss=1.568 (perp=7.053, rec=0.121, cos=0.036), tot_loss_proj:2.662 [t=0.17s]
prediction: ['[CLS].. boy ran [SEP]']
Attempt swap
[1100/2000] tot_loss=2.009 (perp=9.276, rec=0.118, cos=0.036), tot_loss_proj:3.544 [t=0.17s]
prediction: ['[CLS] the. boy ran [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.397 (perp=6.171, rec=0.127, cos=0.036), tot_loss_proj:3.296 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
[1200/2000] tot_loss=1.399 (perp=6.171, rec=0.128, cos=0.036), tot_loss_proj:3.300 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.384 (perp=6.171, rec=0.114, cos=0.036), tot_loss_proj:3.301 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.390 (perp=6.171, rec=0.120, cos=0.036), tot_loss_proj:3.299 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
[1350/2000] tot_loss=1.397 (perp=6.171, rec=0.128, cos=0.036), tot_loss_proj:3.292 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.393 (perp=6.171, rec=0.124, cos=0.036), tot_loss_proj:3.304 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.392 (perp=6.171, rec=0.123, cos=0.036), tot_loss_proj:3.301 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
[1500/2000] tot_loss=1.396 (perp=6.171, rec=0.127, cos=0.036), tot_loss_proj:3.301 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.392 (perp=6.171, rec=0.122, cos=0.036), tot_loss_proj:3.295 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.399 (perp=6.171, rec=0.130, cos=0.036), tot_loss_proj:3.299 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
[1650/2000] tot_loss=1.391 (perp=6.171, rec=0.121, cos=0.035), tot_loss_proj:3.299 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.387 (perp=6.171, rec=0.117, cos=0.035), tot_loss_proj:3.301 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.394 (perp=6.171, rec=0.125, cos=0.035), tot_loss_proj:3.297 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
[1800/2000] tot_loss=1.383 (perp=6.171, rec=0.113, cos=0.035), tot_loss_proj:3.299 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.399 (perp=6.171, rec=0.130, cos=0.035), tot_loss_proj:3.302 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.393 (perp=6.171, rec=0.123, cos=0.035), tot_loss_proj:3.300 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
[1950/2000] tot_loss=1.389 (perp=6.171, rec=0.120, cos=0.035), tot_loss_proj:3.300 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.391 (perp=6.171, rec=0.122, cos=0.035), tot_loss_proj:3.299 [t=0.17s]
prediction: ['[CLS] the ran boy. [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] the boy ran. [SEP]
========================
predicted: 
========================
[CLS] the ran boy. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 96.667 | p: 96.667 | r: 96.667
rouge2     | fm: 47.593 | p: 47.593 | r: 47.593
rougeL     | fm: 83.939 | p: 83.939 | r: 83.939
rougeLsum  | fm: 83.939 | p: 83.939 | r: 83.939
r1fm+r2fm = 144.259

input #2 time: 0:06:57 | total time: 0:20:47


Running input #3 of 100.
reference: 
========================
I wonder who Bill saw and liked Mary.
========================
Sample: 0 5.213419349402922e-12 0.05412712112481605 0.3382717
average of cosine similarity 0.987115321438867
highest_index [0]
highest [0.987115321438867]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1045, 4687, 2040, 3021, 2387, 1998, 4669, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i wonder who bill saw and liked mary. [SEP]']
[Init] best rec loss: 0.8413416743278503 for ['[CLS] term acute turner ren reunion streets strikes still preservation [SEP]']
[Init] best rec loss: 0.8077667951583862 for ['[CLS] safety acting reserve casencies5 walt ready clockwise [SEP]']
[Init] best rec loss: 0.8017082214355469 for ['[CLS] u masters particular prentice payment to councillor cl mls [SEP]']
[Init] best rec loss: 0.7690931558609009 for ['[CLS] talerth cricket favourites semi & reports tier female [SEP]']
[Init] best rec loss: 0.7666354775428772 for ['[CLS] matthew marked studies offensive titular sneak de drama escort [SEP]']
[Init] best rec loss: 0.7478668093681335 for ['[CLS]logist felt sympathetic analogy apr thick dakota origin barracks [SEP]']
[Init] best perm rec loss: 0.7411834597587585 for ['[CLS] felt origin sympathetic thicklogist dakota apr barracks analogy [SEP]']
[Init] best perm rec loss: 0.740568995475769 for ['[CLS]logist analogy barracks dakota thick apr origin sympathetic felt [SEP]']
[Init] best perm rec loss: 0.7380269169807434 for ['[CLS] dakotalogist apr analogy thick sympathetic felt origin barracks [SEP]']
[Init] best perm rec loss: 0.7372322082519531 for ['[CLS] sympathetic dakota thick felt origin analogy apr barrackslogist [SEP]']
[Init] best perm rec loss: 0.7371391654014587 for ['[CLS] apr felt analogy dakota thicklogist origin sympathetic barracks [SEP]']
[Init] best perm rec loss: 0.7346237301826477 for ['[CLS] thick dakota analogy feltlogist barracks apr origin sympathetic [SEP]']
[Init] best perm rec loss: 0.7333685159683228 for ['[CLS] origin dakota sympathetic felt aprlogist analogy thick barracks [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.089 (perp=12.225, rec=0.471, cos=0.172), tot_loss_proj:3.801 [t=0.17s]
prediction: ['[CLS] that deluxetow felt charity! loosely thick dawson [SEP]']
[ 100/2000] tot_loss=2.791 (perp=11.082, rec=0.416, cos=0.159), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] which deluxe deck liked bill! loosely thick. [SEP]']
[ 150/2000] tot_loss=2.549 (perp=10.466, rec=0.359, cos=0.097), tot_loss_proj:3.641 [t=0.17s]
prediction: ['[CLS] who mary deck liked bill mary considered thick. [SEP]']
[ 200/2000] tot_loss=2.453 (perp=10.213, rec=0.313, cos=0.098), tot_loss_proj:3.115 [t=0.17s]
prediction: ['[CLS] who mary deck liked & mary wondered thick, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.078 (perp=8.559, rec=0.278, cos=0.088), tot_loss_proj:3.351 [t=0.17s]
prediction: ['[CLS] who liked died bill and mary wondered thick. [SEP]']
[ 300/2000] tot_loss=2.345 (perp=8.062, rec=0.511, cos=0.221), tot_loss_proj:2.724 [t=0.17s]
prediction: ['[CLS] who liked tom bill and mary wondered.. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.386 (perp=8.911, rec=0.453, cos=0.151), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] who like consult. ; ; mary wonder what [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.103 (perp=8.031, rec=0.391, cos=0.107), tot_loss_proj:2.615 [t=0.17s]
prediction: ['[CLS] who liked mary. bill should. wonder what [SEP]']
[ 450/2000] tot_loss=1.920 (perp=7.680, rec=0.307, cos=0.078), tot_loss_proj:2.379 [t=0.19s]
prediction: ['[CLS] who liked mary. bill ;. wonder what [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.736 (perp=6.960, rec=0.272, cos=0.072), tot_loss_proj:2.436 [t=0.17s]
prediction: ['[CLS] who liked mary.. bill and wonder what [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.670 (perp=6.826, rec=0.238, cos=0.067), tot_loss_proj:2.629 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
[ 600/2000] tot_loss=1.643 (perp=6.826, rec=0.217, cos=0.061), tot_loss_proj:2.623 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.632 (perp=6.826, rec=0.209, cos=0.058), tot_loss_proj:2.629 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.610 (perp=6.826, rec=0.191, cos=0.054), tot_loss_proj:2.629 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
[ 750/2000] tot_loss=1.602 (perp=6.826, rec=0.184, cos=0.053), tot_loss_proj:2.629 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.603 (perp=6.826, rec=0.187, cos=0.052), tot_loss_proj:2.627 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.596 (perp=6.826, rec=0.180, cos=0.051), tot_loss_proj:2.629 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
[ 900/2000] tot_loss=1.579 (perp=6.826, rec=0.164, cos=0.050), tot_loss_proj:2.628 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.594 (perp=6.826, rec=0.180, cos=0.049), tot_loss_proj:2.626 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.574 (perp=6.826, rec=0.160, cos=0.049), tot_loss_proj:2.626 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
[1050/2000] tot_loss=1.571 (perp=6.826, rec=0.158, cos=0.048), tot_loss_proj:2.625 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.577 (perp=6.826, rec=0.164, cos=0.048), tot_loss_proj:2.626 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.562 (perp=6.826, rec=0.149, cos=0.047), tot_loss_proj:2.631 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
[1200/2000] tot_loss=1.567 (perp=6.826, rec=0.155, cos=0.047), tot_loss_proj:2.624 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.574 (perp=6.826, rec=0.162, cos=0.047), tot_loss_proj:2.625 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.578 (perp=6.826, rec=0.166, cos=0.047), tot_loss_proj:2.626 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
[1350/2000] tot_loss=1.556 (perp=6.826, rec=0.144, cos=0.047), tot_loss_proj:2.626 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.564 (perp=6.826, rec=0.153, cos=0.047), tot_loss_proj:2.624 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.572 (perp=6.826, rec=0.161, cos=0.046), tot_loss_proj:2.628 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
[1500/2000] tot_loss=1.571 (perp=6.826, rec=0.159, cos=0.046), tot_loss_proj:2.631 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.559 (perp=6.826, rec=0.148, cos=0.046), tot_loss_proj:2.630 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.577 (perp=6.826, rec=0.166, cos=0.046), tot_loss_proj:2.624 [t=0.17s]
prediction: ['[CLS] who liked mary. what bill and wonder. [SEP]']
[1650/2000] tot_loss=1.446 (perp=6.261, rec=0.147, cos=0.046), tot_loss_proj:2.305 [t=0.17s]
prediction: ['[CLS] who liked mary. to bill and wonder. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.447 (perp=6.261, rec=0.149, cos=0.046), tot_loss_proj:2.312 [t=0.17s]
prediction: ['[CLS] who liked mary. to bill and wonder. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.454 (perp=6.261, rec=0.156, cos=0.046), tot_loss_proj:2.306 [t=0.17s]
prediction: ['[CLS] who liked mary. to bill and wonder. [SEP]']
[1800/2000] tot_loss=1.805 (perp=7.990, rec=0.161, cos=0.046), tot_loss_proj:2.695 [t=0.17s]
prediction: ['[CLS] who liked mary. ben bill and wonder. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.581 (perp=6.858, rec=0.159, cos=0.050), tot_loss_proj:2.620 [t=0.17s]
prediction: ['[CLS] to who liked mary. bill and wonder. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.579 (perp=6.888, rec=0.153, cos=0.048), tot_loss_proj:2.627 [t=0.17s]
prediction: ['[CLS] ben who liked mary. bill and wonder. [SEP]']
[1950/2000] tot_loss=1.576 (perp=6.888, rec=0.150, cos=0.048), tot_loss_proj:2.624 [t=0.17s]
prediction: ['[CLS] ben who liked mary. bill and wonder. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.585 (perp=6.888, rec=0.160, cos=0.047), tot_loss_proj:2.624 [t=0.17s]
prediction: ['[CLS] ben who liked mary. bill and wonder. [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] i wonder who bill saw and liked mary. [SEP]
========================
predicted: 
========================
[CLS] who liked mary. to bill and wonder. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 88.889 | r: 80.000
rouge2     | fm: 11.765 | p: 12.500 | r: 11.111
rougeL     | fm: 52.632 | p: 55.556 | r: 50.000
rougeLsum  | fm: 52.632 | p: 55.556 | r: 50.000
r1fm+r2fm = 95.975

[Aggregate metrics]:
rouge1     | fm: 93.553 | p: 94.722 | r: 92.500
rouge2     | fm: 38.194 | p: 38.194 | r: 38.194
rougeL     | fm: 76.112 | p: 76.843 | r: 75.455
rougeLsum  | fm: 76.112 | p: 76.843 | r: 75.455
r1fm+r2fm = 131.747

input #3 time: 0:06:50 | total time: 0:27:38


Running input #4 of 100.
reference: 
========================
While I might want to, this is the kind of thing that Harris has already suggested.
========================
Sample: 0 5.221707278606271e-13 0.05492842976991461 0.36449203
average of cosine similarity 0.9885797198866375
highest_index [0]
highest [0.9885797198866375]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2096, 1045, 2453, 2215, 2000, 1010, 2023, 2003, 1996, 2785, 1997,
         2518, 2008, 5671, 2038, 2525, 4081, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]']
[Init] best rec loss: 1.0353513956069946 for ['[CLS] june stuffed eponymousdaepathic white bump earth critical security tata fraa area che range soory [SEP]']
[Init] best rec loss: 0.9104655981063843 for ['[CLS] rather againnae henry program seek csi finish et maya alternate drive airport r ke vermont witness 2011 [SEP]']
[Init] best rec loss: 0.9013139009475708 for ['[CLS]enter american howding meial pages navy based talking impact alternative bit frankenstein eating period saidain [SEP]']
[Init] best rec loss: 0.9006959199905396 for ['[CLS] handled off entirely seemedless need elsewhere paper quality trouble presence food anything wood along look tel hot [SEP]']
[Init] best rec loss: 0.8877056837081909 for ['[CLS]rao market object pocket muslim boys columbia producer drawn hostigen flowing media beam vice minutesrion steady [SEP]']
[Init] best perm rec loss: 0.8826872706413269 for ['[CLS] host minutes flowing media producer pocket beam market steady columbia viceraorion drawn boys objectigen muslim [SEP]']
[Init] best perm rec loss: 0.8705316185951233 for ['[CLS] object muslim boys steady vice pocket columbiarao host market producer beamigen media minutesrion drawn flowing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.844 (perp=11.502, rec=0.543, cos=1.000), tot_loss_proj:4.170 [t=0.17s]
prediction: ['[CLS] british record deep backing nearly learned faded maybepooin wantedif ; noah, alone en [SEP] [SEP]']
[ 100/2000] tot_loss=3.696 (perp=11.237, rec=0.453, cos=0.996), tot_loss_proj:4.185 [t=0.18s]
prediction: ["[CLS] and record deep would could experienced knots'uhfin wantedif. harris. had! [SEP] [SEP]"]
[ 150/2000] tot_loss=3.115 (perp=8.505, rec=0.419, cos=0.995), tot_loss_proj:3.700 [t=0.17s]
prediction: ["[CLS] and mentioned. this could presidential knots'harrisə?!. harris. had! [SEP] [SEP]"]
[ 200/2000] tot_loss=3.502 (perp=10.573, rec=0.395, cos=0.992), tot_loss_proj:4.041 [t=0.18s]
prediction: ['[CLS] while already. this could presidential suggested while harrisə therefore! these harris. have! [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.591 (perp=10.550, rec=0.481, cos=1.000), tot_loss_proj:3.974 [t=0.18s]
prediction: ['[CLS] seeing mentioned was this managed mi! while harrisᆫ therefore hence these harris. would. [SEP] [SEP]']
[ 300/2000] tot_loss=3.532 (perp=10.639, rec=0.406, cos=0.998), tot_loss_proj:4.016 [t=0.19s]
prediction: ['[CLS] while harris was harris followed inc! while harrisᆫ therefore hence these harris. thing. : [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.505 (perp=10.634, rec=0.382, cos=0.996), tot_loss_proj:3.938 [t=0.18s]
prediction: ['[CLS] while harris was harris these harassment allegiance while harrisə ) maybe plans harris. thing. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.193 (perp=9.059, rec=0.386, cos=0.995), tot_loss_proj:3.701 [t=0.18s]
prediction: ['[CLS] while harris i harris. harassment allegiance while harrisə? are harris. harris thing! [SEP] [SEP]']
[ 450/2000] tot_loss=3.362 (perp=9.970, rec=0.374, cos=0.994), tot_loss_proj:3.883 [t=0.17s]
prediction: ['[CLS] while harris i harris. sac allegiance while harrisə? are harris. harris thing et [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.145 (perp=8.934, rec=0.367, cos=0.991), tot_loss_proj:3.687 [t=0.18s]
prediction: ['[CLS] while things i harris. presidential ] while harris harris? are harris. harris thing. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.133 (perp=8.826, rec=0.377, cos=0.991), tot_loss_proj:3.681 [t=0.17s]
prediction: ['[CLS] while ] i harris this presidentialbas while harris harris? are harris. harris thing. [SEP] [SEP]']
[ 600/2000] tot_loss=3.109 (perp=8.878, rec=0.343, cos=0.991), tot_loss_proj:3.647 [t=0.17s]
prediction: ['[CLS] while whether i harris. presidentialbas while harris harris? while harris. harris thing. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.890 (perp=7.754, rec=0.349, cos=0.990), tot_loss_proj:3.441 [t=0.18s]
prediction: ['[CLS] while i whether harris. presidential ideas while harris harris? while harris. harris thing. [SEP] [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.971 (perp=8.163, rec=0.349, cos=0.989), tot_loss_proj:3.517 [t=0.17s]
prediction: ['[CLS] while i whether harris. presidential ideas while campbell harris? while harris. harris thing. [SEP] [SEP]']
[ 750/2000] tot_loss=2.959 (perp=8.163, rec=0.339, cos=0.988), tot_loss_proj:3.519 [t=0.17s]
prediction: ['[CLS] while i whether harris. presidential ideas while campbell harris? while harris. harris thing. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.970 (perp=8.179, rec=0.346, cos=0.988), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS] campbell things whether harris. presidential ideas while while harris things while harris. harris thing. [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.074 (perp=8.569, rec=0.374, cos=0.986), tot_loss_proj:3.564 [t=0.17s]
prediction: ['[CLS] campbell things whether did this harris ideas while while harris ) while harris. harris thing. [SEP] [SEP]']
[ 900/2000] tot_loss=2.956 (perp=8.113, rec=0.345, cos=0.988), tot_loss_proj:3.489 [t=0.18s]
prediction: ['[CLS] campbell things whether did this harris ideas while while harris? while harris. harris thing. [SEP] [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.968 (perp=8.174, rec=0.347, cos=0.987), tot_loss_proj:3.515 [t=0.17s]
prediction: ['[CLS] campbell things whether did this harris ideas while while harris things while harris. harris thing. [SEP] [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=3.017 (perp=8.478, rec=0.336, cos=0.985), tot_loss_proj:3.536 [t=0.17s]
prediction: ['[CLS] campbell things whether harris did this ideas while while harris are might harris. harris thing. [SEP] [SEP]']
[1050/2000] tot_loss=2.926 (perp=8.022, rec=0.336, cos=0.986), tot_loss_proj:3.449 [t=0.17s]
prediction: ['[CLS] campbell things whether harris did this ideas while while harris? might harris. harris thing. [SEP] [SEP]']
Attempt swap
[1100/2000] tot_loss=2.950 (perp=8.134, rec=0.336, cos=0.987), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] campbell things whether harris did this ideas while while harris things might harris. harris thing. [SEP] [SEP]']
Attempt swap
[1150/2000] tot_loss=3.294 (perp=9.888, rec=0.330, cos=0.986), tot_loss_proj:3.809 [t=0.17s]
prediction: ['[CLS] campbell things whether harrishad this ideas while while harris things might harris. harris thing suggested [SEP] [SEP]']
[1200/2000] tot_loss=3.291 (perp=9.888, rec=0.327, cos=0.986), tot_loss_proj:3.810 [t=0.17s]
prediction: ['[CLS] campbell things whether harrishad this ideas while while harris things might harris. harris thing suggested [SEP] [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=3.266 (perp=9.760, rec=0.329, cos=0.985), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] campbell things whetherhad harris this ideas while while harris things might harris. harris thing suggested [SEP] [SEP]']
Attempt swap
[1300/2000] tot_loss=3.258 (perp=9.708, rec=0.330, cos=0.986), tot_loss_proj:3.793 [t=0.17s]
prediction: ['[CLS] campbell things whetherhad harris this things while while harris things might harris. harris thing suggested [SEP] [SEP]']
[1350/2000] tot_loss=3.250 (perp=9.708, rec=0.323, cos=0.985), tot_loss_proj:3.790 [t=0.17s]
prediction: ['[CLS] campbell things whetherhad harris this things while while harris things might harris. harris thing suggested [SEP] [SEP]']
Attempt swap
[1400/2000] tot_loss=3.396 (perp=10.394, rec=0.332, cos=0.985), tot_loss_proj:3.908 [t=0.17s]
prediction: ['[CLS] campbell things whetherhad harris. things while while harris depends might harris. harris thing suggested [SEP] [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=3.282 (perp=9.795, rec=0.343, cos=0.980), tot_loss_proj:3.859 [t=0.18s]
prediction: ['[CLS] campbell things whetherhad harris. things might while harris things could harris. harris what suggested [SEP] [SEP]']
[1500/2000] tot_loss=3.229 (perp=9.591, rec=0.327, cos=0.984), tot_loss_proj:3.742 [t=0.18s]
prediction: ['[CLS] campbell things whetherhad harris. things might while harris things could harris. harris thing suggested [SEP] [SEP]']
Attempt swap
[1550/2000] tot_loss=3.230 (perp=9.591, rec=0.327, cos=0.985), tot_loss_proj:3.740 [t=0.17s]
prediction: ['[CLS] campbell things whetherhad harris. things might while harris things could harris. harris thing suggested [SEP] [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=3.395 (perp=10.349, rec=0.338, cos=0.987), tot_loss_proj:3.968 [t=0.17s]
prediction: ['[CLS] campbell things whether thishad harris things might while harris depends could harris. harris what suggested [SEP] [SEP]']
[1650/2000] tot_loss=3.322 (perp=10.044, rec=0.329, cos=0.984), tot_loss_proj:3.889 [t=0.17s]
prediction: ['[CLS] campbell things whether.had harris things might while harris depends could harris. harris what suggested [SEP] [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=3.094 (perp=8.859, rec=0.337, cos=0.984), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] campbell depends whether.had harris things might while harris things could harris. harris thing suggested [SEP] [SEP]']
Attempt swap
[1750/2000] tot_loss=3.085 (perp=8.859, rec=0.329, cos=0.984), tot_loss_proj:3.593 [t=0.18s]
prediction: ['[CLS] campbell depends whether.had harris things might while harris things could harris. harris thing suggested [SEP] [SEP]']
[1800/2000] tot_loss=3.084 (perp=8.859, rec=0.328, cos=0.984), tot_loss_proj:3.593 [t=0.17s]
prediction: ['[CLS] campbell depends whether.had harris things might while harris things could harris. harris thing suggested [SEP] [SEP]']
Attempt swap
[1850/2000] tot_loss=3.136 (perp=9.124, rec=0.325, cos=0.985), tot_loss_proj:3.654 [t=0.18s]
prediction: ['[CLS] campbell things whether.had harris things might while harris things could harris. harris thing suggested [SEP] [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=3.126 (perp=9.068, rec=0.328, cos=0.984), tot_loss_proj:3.652 [t=0.17s]
prediction: ['[CLS] campbell things whether outlined this harris things might while harris things could harris. harris thing suggested [SEP] [SEP]']
[1950/2000] tot_loss=2.965 (perp=8.237, rec=0.333, cos=0.985), tot_loss_proj:3.470 [t=0.17s]
prediction: ['[CLS] campbell things whether outlined. harris things might while harris things could harris. harris thing suggested [SEP] [SEP]']
Attempt swap
[2000/2000] tot_loss=2.958 (perp=8.237, rec=0.326, cos=0.985), tot_loss_proj:3.473 [t=0.18s]
prediction: ['[CLS] campbell things whether outlined. harris things might while harris things could harris. harris thing suggested [SEP] [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]
========================
predicted: 
========================
[CLS] campbell things whetherhad harris. things while while harris depends might harris. harris thing suggested [SEP] [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 41.176 | r: 38.889
rouge2     | fm: 6.061 | p: 6.250 | r: 5.882
rougeL     | fm: 34.286 | p: 35.294 | r: 33.333
rougeLsum  | fm: 34.286 | p: 35.294 | r: 33.333
r1fm+r2fm = 46.061

[Aggregate metrics]:
rouge1     | fm: 84.000 | p: 84.235 | r: 83.778
rouge2     | fm: 31.000 | p: 31.056 | r: 31.000
rougeL     | fm: 68.111 | p: 68.897 | r: 67.394
rougeLsum  | fm: 67.747 | p: 68.534 | r: 67.030
r1fm+r2fm = 115.000

input #4 time: 0:07:01 | total time: 0:34:39


Running input #5 of 100.
reference: 
========================
Who has seen my snorkel?
========================
Sample: 0 3.357168217052137e-12 0.04678120637760178 0.31683913
average of cosine similarity 0.9890397351374642
highest_index [0]
highest [0.9890397351374642]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2040,  2038,  2464,  2026,  1055, 12131, 11705,  1029,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] who has seen my snorkel? [SEP]']
[Init] best rec loss: 1.0512324571609497 for ['[CLS] second lot dimensions absolutelyavia nuclear second century [SEP]']
[Init] best rec loss: 0.9496536254882812 for ['[CLS] softzzled 10 dark ob subscription fury cold [SEP]']
[Init] best rec loss: 0.9399934411048889 for ['[CLS] overall its gallo paintings playing percival crater huge [SEP]']
[Init] best rec loss: 0.8532701134681702 for ['[CLS] driven watering house corner head same advertisements show [SEP]']
[Init] best rec loss: 0.8511939644813538 for ['[CLS] the 10 surprise dear relieve leaf blair its [SEP]']
[Init] best rec loss: 0.8402397632598877 for ['[CLS] mallory loose theta drank thin funk soul = [SEP]']
[Init] best rec loss: 0.8126248121261597 for ['[CLS] nat politicalunk priceeon guess goalstered [SEP]']
[Init] best perm rec loss: 0.8102404475212097 for ['[CLS]eon goal price politicalstered natunk guess [SEP]']
[Init] best perm rec loss: 0.807880699634552 for ['[CLS] nat priceunk guesseon political goalstered [SEP]']
[Init] best perm rec loss: 0.8067676424980164 for ['[CLS] goal political priceeon guessunkstered nat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.057 (perp=12.224, rec=0.443, cos=0.170), tot_loss_proj:4.386 [t=0.17s]
prediction: ['[CLS] sovereign politics australia tourist or. an nathan [SEP]']
[ 100/2000] tot_loss=2.727 (perp=11.445, rec=0.357, cos=0.080), tot_loss_proj:4.243 [t=0.17s]
prediction: ['[CLS] paralympictist australia tourist had. an nathan [SEP]']
[ 150/2000] tot_loss=3.254 (perp=12.678, rec=0.513, cos=0.205), tot_loss_proj:4.471 [t=0.17s]
prediction: ['[CLS] whose spy punk craig originally 1990s katherine kathleen [SEP]']
[ 200/2000] tot_loss=3.024 (perp=12.632, rec=0.387, cos=0.111), tot_loss_proj:4.492 [t=0.17s]
prediction: ['[CLS] who spy death derekki 1960s granny virtue [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.791 (perp=11.958, rec=0.328, cos=0.071), tot_loss_proj:4.271 [t=0.17s]
prediction: ['[CLS] spy who death iki torch indie soo [SEP]']
[ 300/2000] tot_loss=2.690 (perp=11.741, rec=0.284, cos=0.058), tot_loss_proj:4.198 [t=0.17s]
prediction: ['[CLS]? who death iki torch indie soo [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.634 (perp=11.584, rec=0.268, cos=0.049), tot_loss_proj:4.221 [t=0.17s]
prediction: ['[CLS] who death? mykel torch indie soo [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.601 (perp=11.364, rec=0.271, cos=0.058), tot_loss_proj:4.240 [t=0.17s]
prediction: ['[CLS] who just? mykel soo wife must [SEP]']
[ 450/2000] tot_loss=2.455 (perp=10.913, rec=0.227, cos=0.045), tot_loss_proj:4.083 [t=0.17s]
prediction: ['[CLS] whorial? mykel barack wife must [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.404 (perp=10.727, rec=0.215, cos=0.043), tot_loss_proj:4.054 [t=0.17s]
prediction: ['[CLS] whokel? mykel barack must wife [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.058 (perp=9.111, rec=0.194, cos=0.041), tot_loss_proj:3.522 [t=0.17s]
prediction: ['[CLS] who? mynorkelkel haskel [SEP]']
[ 600/2000] tot_loss=2.054 (perp=9.111, rec=0.192, cos=0.040), tot_loss_proj:3.532 [t=0.17s]
prediction: ['[CLS] who? mynorkelkel haskel [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.051 (perp=9.196, rec=0.172, cos=0.040), tot_loss_proj:3.571 [t=0.17s]
prediction: ['[CLS] who? mynorkel haschalkel [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.862 (perp=8.173, rec=0.183, cos=0.044), tot_loss_proj:3.586 [t=0.17s]
prediction: ['[CLS] who mynorkel haschalkel? [SEP]']
[ 750/2000] tot_loss=1.879 (perp=8.308, rec=0.178, cos=0.039), tot_loss_proj:3.626 [t=0.17s]
prediction: ['[CLS] who mynorkel haskelkel? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.598 (perp=6.997, rec=0.160, cos=0.039), tot_loss_proj:3.423 [t=0.17s]
prediction: ['[CLS] who mynorkel hasnorkel? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.593 (perp=6.997, rec=0.156, cos=0.038), tot_loss_proj:3.427 [t=0.17s]
prediction: ['[CLS] who mynorkel hasnorkel? [SEP]']
[ 900/2000] tot_loss=1.592 (perp=6.997, rec=0.156, cos=0.037), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS] who mynorkel hasnorkel? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.588 (perp=6.997, rec=0.153, cos=0.036), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS] who mynorkel hasnorkel? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.583 (perp=6.997, rec=0.149, cos=0.035), tot_loss_proj:3.431 [t=0.17s]
prediction: ['[CLS] who mynorkel hasnorkel? [SEP]']
[1050/2000] tot_loss=1.835 (perp=8.297, rec=0.142, cos=0.033), tot_loss_proj:3.614 [t=0.17s]
prediction: ['[CLS] who mynorkel has haskel? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.822 (perp=8.297, rec=0.130, cos=0.032), tot_loss_proj:3.602 [t=0.17s]
prediction: ['[CLS] who mynorkel has haskel? [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.569 (perp=6.997, rec=0.136, cos=0.034), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS] who mynorkel hasnorkel? [SEP]']
[1200/2000] tot_loss=1.571 (perp=6.997, rec=0.140, cos=0.032), tot_loss_proj:3.430 [t=0.17s]
prediction: ['[CLS] who mynorkel hasnorkel? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.552 (perp=6.997, rec=0.120, cos=0.032), tot_loss_proj:3.430 [t=0.17s]
prediction: ['[CLS] who mynorkel hasnorkel? [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.533 (perp=6.769, rec=0.145, cos=0.034), tot_loss_proj:3.369 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
[1350/2000] tot_loss=1.517 (perp=6.769, rec=0.130, cos=0.033), tot_loss_proj:3.369 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.524 (perp=6.769, rec=0.138, cos=0.032), tot_loss_proj:3.380 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.507 (perp=6.769, rec=0.122, cos=0.032), tot_loss_proj:3.375 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
[1500/2000] tot_loss=1.509 (perp=6.769, rec=0.124, cos=0.031), tot_loss_proj:3.374 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.503 (perp=6.769, rec=0.118, cos=0.031), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.504 (perp=6.769, rec=0.119, cos=0.031), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
[1650/2000] tot_loss=1.507 (perp=6.769, rec=0.122, cos=0.031), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.506 (perp=6.769, rec=0.121, cos=0.031), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.502 (perp=6.769, rec=0.118, cos=0.030), tot_loss_proj:3.375 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
[1800/2000] tot_loss=1.486 (perp=6.769, rec=0.102, cos=0.030), tot_loss_proj:3.374 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.506 (perp=6.769, rec=0.122, cos=0.030), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.498 (perp=6.769, rec=0.114, cos=0.030), tot_loss_proj:3.377 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
[1950/2000] tot_loss=1.504 (perp=6.769, rec=0.120, cos=0.030), tot_loss_proj:3.374 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.494 (perp=6.769, rec=0.111, cos=0.030), tot_loss_proj:3.370 [t=0.17s]
prediction: ['[CLS] who has mynorkelnorkel? [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] who has seen my snorkel? [SEP]
========================
predicted: 
========================
[CLS] who has mynorkelnorkel? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 80.000 | r: 57.143
rouge2     | fm: 40.000 | p: 50.000 | r: 33.333
rougeL     | fm: 66.667 | p: 80.000 | r: 57.143
rougeLsum  | fm: 66.667 | p: 80.000 | r: 57.143
r1fm+r2fm = 106.667

[Aggregate metrics]:
rouge1     | fm: 81.740 | p: 84.826 | r: 79.048
rouge2     | fm: 32.483 | p: 34.213 | r: 31.313
rougeL     | fm: 68.111 | p: 70.748 | r: 65.685
rougeLsum  | fm: 67.845 | p: 70.748 | r: 65.382
r1fm+r2fm = 114.223

input #5 time: 0:06:49 | total time: 0:41:28


Running input #6 of 100.
reference: 
========================
Which goddess helped us?
========================
Sample: 0 9.368832899827124e-13 0.038649124183664944 0.30960712
average of cosine similarity 0.9921777725154611
highest_index [0]
highest [0.9921777725154611]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2029, 7804, 3271, 2149, 1029,  102]], device='cuda:0')
Debug: ref = ['[CLS] which goddess helped us? [SEP]']
[Init] best rec loss: 0.867874264717102 for ['[CLS] naked scoring southeastvyn taliban [SEP]']
[Init] best rec loss: 0.864172101020813 for ['[CLS] heronhesive faye bachelorcom [SEP]']
[Init] best rec loss: 0.8641515374183655 for ['[CLS]bby ve stellathorpe concerns [SEP]']
[Init] best rec loss: 0.8406566381454468 for ['[CLS]nation convenient heal exactly ljubljana [SEP]']
[Init] best perm rec loss: 0.8389413356781006 for ['[CLS] heal exactlynation convenient ljubljana [SEP]']
[Init] best perm rec loss: 0.8358174562454224 for ['[CLS] exactlynation ljubljana convenient heal [SEP]']
[Init] best perm rec loss: 0.8347128033638 for ['[CLS] ljubljana convenientnation exactly heal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.985 (perp=11.644, rec=0.662, cos=0.994), tot_loss_proj:4.321 [t=0.19s]
prediction: ['[CLS] su? guadalupe smartli [SEP]']
[ 100/2000] tot_loss=3.206 (perp=10.696, rec=0.528, cos=0.538), tot_loss_proj:4.123 [t=0.20s]
prediction: ['[CLS] which okay? goddesstus [SEP]']
[ 150/2000] tot_loss=2.311 (perp=9.943, rec=0.242, cos=0.081), tot_loss_proj:3.878 [t=0.19s]
prediction: ['[CLS] which goddess? goddess goddess [SEP]']
[ 200/2000] tot_loss=2.226 (perp=9.917, rec=0.184, cos=0.058), tot_loss_proj:3.885 [t=0.19s]
prediction: ['[CLS] which goddess helped goddess goddess [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.124 (perp=9.478, rec=0.177, cos=0.051), tot_loss_proj:3.812 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped goddess [SEP]']
[ 300/2000] tot_loss=2.088 (perp=9.478, rec=0.152, cos=0.040), tot_loss_proj:3.817 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped goddess [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.132 (perp=9.740, rec=0.146, cos=0.038), tot_loss_proj:4.029 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped we [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.998 (perp=9.136, rec=0.133, cos=0.038), tot_loss_proj:3.299 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped us [SEP]']
[ 450/2000] tot_loss=1.997 (perp=9.136, rec=0.131, cos=0.038), tot_loss_proj:3.300 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped us [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.001 (perp=9.136, rec=0.135, cos=0.038), tot_loss_proj:3.303 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped us [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.001 (perp=9.136, rec=0.135, cos=0.039), tot_loss_proj:3.307 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped us [SEP]']
[ 600/2000] tot_loss=2.000 (perp=9.136, rec=0.133, cos=0.040), tot_loss_proj:3.318 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped us [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.084 (perp=9.588, rec=0.127, cos=0.040), tot_loss_proj:2.887 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped? [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.080 (perp=9.588, rec=0.122, cos=0.040), tot_loss_proj:2.899 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped? [SEP]']
[ 750/2000] tot_loss=2.088 (perp=9.588, rec=0.129, cos=0.041), tot_loss_proj:2.915 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped? [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.075 (perp=9.588, rec=0.117, cos=0.041), tot_loss_proj:2.914 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped? [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.077 (perp=9.588, rec=0.119, cos=0.041), tot_loss_proj:2.926 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped? [SEP]']
[ 900/2000] tot_loss=2.086 (perp=9.588, rec=0.128, cos=0.041), tot_loss_proj:2.922 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped? [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.084 (perp=9.588, rec=0.128, cos=0.039), tot_loss_proj:2.921 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped? [SEP]']
Attempt swap
[1000/2000] tot_loss=2.081 (perp=9.588, rec=0.124, cos=0.040), tot_loss_proj:2.943 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped? [SEP]']
[1050/2000] tot_loss=2.089 (perp=9.588, rec=0.133, cos=0.039), tot_loss_proj:2.929 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped? [SEP]']
Attempt swap
[1100/2000] tot_loss=2.075 (perp=9.588, rec=0.119, cos=0.038), tot_loss_proj:2.942 [t=0.17s]
prediction: ['[CLS] which goddess goddess helped? [SEP]']
Attempt swap
[1150/2000] tot_loss=2.083 (perp=9.682, rec=0.109, cos=0.037), tot_loss_proj:2.413 [t=0.17s]
prediction: ['[CLS] which goddess helped helped? [SEP]']
[1200/2000] tot_loss=2.085 (perp=9.682, rec=0.114, cos=0.034), tot_loss_proj:2.431 [t=0.17s]
prediction: ['[CLS] which goddess helped helped? [SEP]']
Attempt swap
[1250/2000] tot_loss=2.066 (perp=9.682, rec=0.100, cos=0.030), tot_loss_proj:2.422 [t=0.17s]
prediction: ['[CLS] which goddess helped helped? [SEP]']
Attempt swap
[1300/2000] tot_loss=2.031 (perp=9.682, rec=0.077, cos=0.018), tot_loss_proj:2.415 [t=0.17s]
prediction: ['[CLS] which goddess helped helped? [SEP]']
[1350/2000] tot_loss=2.027 (perp=9.682, rec=0.074, cos=0.017), tot_loss_proj:2.402 [t=0.17s]
prediction: ['[CLS] which goddess helped helped? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.924 (perp=9.157, rec=0.076, cos=0.016), tot_loss_proj:3.980 [t=0.17s]
prediction: ['[CLS] which goddess us helped? [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.749 (perp=8.242, rec=0.084, cos=0.016), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1500/2000] tot_loss=1.726 (perp=8.242, rec=0.062, cos=0.016), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.735 (perp=8.242, rec=0.071, cos=0.016), tot_loss_proj:1.795 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.735 (perp=8.242, rec=0.071, cos=0.016), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1650/2000] tot_loss=1.732 (perp=8.242, rec=0.068, cos=0.016), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.744 (perp=8.242, rec=0.080, cos=0.016), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.731 (perp=8.242, rec=0.067, cos=0.016), tot_loss_proj:1.795 [t=0.22s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1800/2000] tot_loss=1.731 (perp=8.242, rec=0.067, cos=0.016), tot_loss_proj:1.798 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.737 (perp=8.242, rec=0.073, cos=0.016), tot_loss_proj:1.790 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.742 (perp=8.242, rec=0.078, cos=0.016), tot_loss_proj:1.790 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1950/2000] tot_loss=1.735 (perp=8.242, rec=0.071, cos=0.016), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.742 (perp=8.242, rec=0.078, cos=0.016), tot_loss_proj:1.801 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] which goddess helped us? [SEP]
========================
predicted: 
========================
[CLS] which goddess helped us? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 84.411 | p: 87.152 | r: 82.290
rouge2     | fm: 41.659 | p: 43.433 | r: 40.682
rougeL     | fm: 72.537 | p: 74.964 | r: 70.544
rougeLsum  | fm: 71.832 | p: 74.667 | r: 70.056
r1fm+r2fm = 126.070

input #6 time: 0:06:54 | total time: 0:48:23


Running input #7 of 100.
reference: 
========================
They have no old.
========================
Sample: 0 3.845751936729604e-12 0.04531937541982254 0.3544846
average of cosine similarity 0.9917941164301534
highest_index [0]
highest [0.9917941164301534]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2027, 2031, 2053, 2214, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] they have no old. [SEP]']
[Init] best rec loss: 0.8596845865249634 for ['[CLS] devices buck 1947 business ji [SEP]']
[Init] best rec loss: 0.7969943284988403 for ['[CLS]emi streamed including same rugby [SEP]']
[Init] best rec loss: 0.745602548122406 for ['[CLS] nopecharged practiced 2011 jersey [SEP]']
[Init] best rec loss: 0.7454397678375244 for ['[CLS] ok programme timetable mae keeping [SEP]']
[Init] best rec loss: 0.7182220816612244 for ['[CLS] necessary nino shin sensory hank [SEP]']
[Init] best rec loss: 0.7062795162200928 for ['[CLS] total mfa km² brock gifford [SEP]']
[Init] best rec loss: 0.694407045841217 for ['[CLS] presents contact managed dontlement [SEP]']
[Init] best rec loss: 0.6856284141540527 for ['[CLS] zhang just plum class bills [SEP]']
[Init] best rec loss: 0.6675581932067871 for ['[CLS] simultaneously campeonato outside - shown [SEP]']
[Init] best perm rec loss: 0.6658273935317993 for ['[CLS] outside shown campeonato - simultaneously [SEP]']
[Init] best perm rec loss: 0.6624957323074341 for ['[CLS] shown campeonato - simultaneously outside [SEP]']
[Init] best perm rec loss: 0.6613995432853699 for ['[CLS] shown simultaneously - campeonato outside [SEP]']
[Init] best perm rec loss: 0.6613324880599976 for ['[CLS] campeonato outside - simultaneously shown [SEP]']
[Init] best perm rec loss: 0.6570094227790833 for ['[CLS] shown - campeonato simultaneously outside [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.361 (perp=14.157, rec=0.644, cos=0.885), tot_loss_proj:4.326 [t=0.19s]
prediction: ['[CLS] my jacques cursedrod giant [SEP]']
[ 100/2000] tot_loss=2.830 (perp=11.859, rec=0.373, cos=0.084), tot_loss_proj:3.277 [t=0.19s]
prediction: ['[CLS] no old my bid with [SEP]']
[ 150/2000] tot_loss=2.387 (perp=10.321, rec=0.271, cos=0.051), tot_loss_proj:2.854 [t=0.19s]
prediction: ['[CLS] no old old had with [SEP]']
[ 200/2000] tot_loss=2.270 (perp=10.147, rec=0.199, cos=0.042), tot_loss_proj:2.844 [t=0.17s]
prediction: ['[CLS] no old old have with [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.698 (perp=7.478, rec=0.171, cos=0.032), tot_loss_proj:2.896 [t=0.17s]
prediction: ['[CLS] old old have no. [SEP]']
[ 300/2000] tot_loss=1.653 (perp=7.478, rec=0.130, cos=0.028), tot_loss_proj:2.908 [t=0.17s]
prediction: ['[CLS] old old have no. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.512 (perp=6.772, rec=0.127, cos=0.031), tot_loss_proj:2.172 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.492 (perp=6.772, rec=0.110, cos=0.028), tot_loss_proj:2.162 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
[ 450/2000] tot_loss=1.495 (perp=6.772, rec=0.112, cos=0.028), tot_loss_proj:2.147 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.488 (perp=6.772, rec=0.107, cos=0.027), tot_loss_proj:2.149 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.490 (perp=6.772, rec=0.110, cos=0.026), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
[ 600/2000] tot_loss=1.482 (perp=6.772, rec=0.102, cos=0.025), tot_loss_proj:2.153 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.477 (perp=6.772, rec=0.098, cos=0.024), tot_loss_proj:2.142 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.486 (perp=6.772, rec=0.108, cos=0.024), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
[ 750/2000] tot_loss=1.484 (perp=6.772, rec=0.107, cos=0.023), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.477 (perp=6.772, rec=0.101, cos=0.022), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.478 (perp=6.772, rec=0.102, cos=0.021), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
[ 900/2000] tot_loss=1.474 (perp=6.772, rec=0.099, cos=0.021), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] old have no old. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.719 (perp=8.007, rec=0.098, cos=0.020), tot_loss_proj:2.842 [t=0.17s]
prediction: ['[CLS] old have no their. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.567 (perp=7.212, rec=0.105, cos=0.020), tot_loss_proj:2.262 [t=0.17s]
prediction: ['[CLS] have no their old. [SEP]']
[1050/2000] tot_loss=1.542 (perp=7.098, rec=0.102, cos=0.020), tot_loss_proj:2.646 [t=0.17s]
prediction: ['[CLS] have no they old. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.280 (perp=5.839, rec=0.093, cos=0.020), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.277 (perp=5.839, rec=0.089, cos=0.020), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
[1200/2000] tot_loss=1.289 (perp=5.839, rec=0.101, cos=0.020), tot_loss_proj:1.581 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.273 (perp=5.839, rec=0.086, cos=0.020), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.280 (perp=5.839, rec=0.093, cos=0.020), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
[1350/2000] tot_loss=1.291 (perp=5.839, rec=0.104, cos=0.020), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.272 (perp=5.839, rec=0.085, cos=0.020), tot_loss_proj:1.577 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.271 (perp=5.839, rec=0.083, cos=0.020), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
[1500/2000] tot_loss=1.282 (perp=5.839, rec=0.094, cos=0.020), tot_loss_proj:1.580 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.284 (perp=5.839, rec=0.097, cos=0.020), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.282 (perp=5.839, rec=0.095, cos=0.020), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
[1650/2000] tot_loss=1.267 (perp=5.839, rec=0.080, cos=0.019), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.272 (perp=5.839, rec=0.085, cos=0.019), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.267 (perp=5.839, rec=0.080, cos=0.019), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
[1800/2000] tot_loss=1.270 (perp=5.839, rec=0.083, cos=0.019), tot_loss_proj:1.575 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.270 (perp=5.839, rec=0.084, cos=0.019), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.269 (perp=5.839, rec=0.082, cos=0.019), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
[1950/2000] tot_loss=1.269 (perp=5.839, rec=0.082, cos=0.019), tot_loss_proj:1.575 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.281 (perp=5.839, rec=0.094, cos=0.019), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] they have no old. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] they have no old. [SEP]
========================
predicted: 
========================
[CLS] they have no old. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.360 | p: 88.758 | r: 84.286
rouge2     | fm: 49.153 | p: 50.599 | r: 48.096
rougeL     | fm: 76.214 | p: 78.093 | r: 74.513
rougeLsum  | fm: 75.686 | p: 78.061 | r: 73.953
r1fm+r2fm = 135.513

input #7 time: 0:06:57 | total time: 0:55:21


Running input #8 of 100.
reference: 
========================
John tries to meet not Mary.
========================
Sample: 0 2.3095519250857666e-12 0.049598564952610454 0.36320284
average of cosine similarity 0.9906319782933353
highest_index [0]
highest [0.9906319782933353]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2198, 5363, 2000, 3113, 2025, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] john tries to meet not mary. [SEP]']
[Init] best rec loss: 0.8751393556594849 for ['[CLS]udeau secretary steinerc pennypeed press [SEP]']
[Init] best rec loss: 0.8258135318756104 for ['[CLS] fresh contact beaten image angle form confederate [SEP]']
[Init] best rec loss: 0.824735701084137 for ['[CLS] catalogue frankie tsar calendar hog case provisional [SEP]']
[Init] best rec loss: 0.7984954714775085 for ['[CLS] key cult accession floating remember oxford suddenly [SEP]']
[Init] best rec loss: 0.7969860434532166 for ['[CLS] warren benny grace boarding saxon nothing " [SEP]']
[Init] best rec loss: 0.7715851664543152 for ['[CLS] further big instance schedule ahead caftium [SEP]']
[Init] best rec loss: 0.7697283029556274 for ['[CLS]culebid driver genome boundary much books [SEP]']
[Init] best rec loss: 0.7694283723831177 for ['[CLS] recession duncanified within youtube michael eventually [SEP]']
[Init] best rec loss: 0.7451742887496948 for ['[CLS] gentleman centre past gradesfies th times [SEP]']
[Init] best perm rec loss: 0.730642557144165 for ['[CLS] centre past gentleman thfies times grades [SEP]']
[Init] best perm rec loss: 0.7257177829742432 for ['[CLS] centre gentleman timesfies past grades th [SEP]']
[Init] best perm rec loss: 0.7234541773796082 for ['[CLS] past centrefies times th gentleman grades [SEP]']
[Init] best perm rec loss: 0.7234346866607666 for ['[CLS] th grades timesfies centre past gentleman [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.090 (perp=8.931, rec=0.280, cos=0.024), tot_loss_proj:3.012 [t=0.17s]
prediction: ['[CLS] also mary? not not met meet [SEP]']
[ 100/2000] tot_loss=2.442 (perp=11.319, rec=0.158, cos=0.021), tot_loss_proj:3.607 [t=0.17s]
prediction: ['[CLS] tries mary harder meet not mary meet [SEP]']
[ 150/2000] tot_loss=2.465 (perp=11.580, rec=0.130, cos=0.019), tot_loss_proj:3.274 [t=0.17s]
prediction: ['[CLS] tries mary trying meet not mary meet [SEP]']
[ 200/2000] tot_loss=2.155 (perp=10.155, rec=0.105, cos=0.019), tot_loss_proj:2.709 [t=0.17s]
prediction: ['[CLS] tries mary trying. not mary meet [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.927 (perp=9.059, rec=0.096, cos=0.019), tot_loss_proj:3.090 [t=0.17s]
prediction: ['[CLS] john mary tries. not meet mary [SEP]']
[ 300/2000] tot_loss=1.913 (perp=9.059, rec=0.082, cos=0.019), tot_loss_proj:3.021 [t=0.17s]
prediction: ['[CLS] john mary tries. not meet mary [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.903 (perp=8.407, rec=0.198, cos=0.023), tot_loss_proj:2.546 [t=0.17s]
prediction: ['[CLS] john to mary tries not meet mary [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.813 (perp=7.913, rec=0.209, cos=0.021), tot_loss_proj:3.088 [t=0.17s]
prediction: ['[CLS] john tries mary, not meet mary [SEP]']
[ 450/2000] tot_loss=1.746 (perp=7.913, rec=0.144, cos=0.019), tot_loss_proj:3.152 [t=0.17s]
prediction: ['[CLS] john tries mary, not meet mary [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.723 (perp=7.913, rec=0.122, cos=0.019), tot_loss_proj:3.145 [t=0.17s]
prediction: ['[CLS] john tries mary, not meet mary [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.715 (perp=7.913, rec=0.114, cos=0.018), tot_loss_proj:3.146 [t=0.17s]
prediction: ['[CLS] john tries mary, not meet mary [SEP]']
[ 600/2000] tot_loss=1.713 (perp=7.913, rec=0.112, cos=0.018), tot_loss_proj:3.137 [t=0.17s]
prediction: ['[CLS] john tries mary, not meet mary [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.712 (perp=7.913, rec=0.111, cos=0.019), tot_loss_proj:3.143 [t=0.17s]
prediction: ['[CLS] john tries mary, not meet mary [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.698 (perp=7.913, rec=0.097, cos=0.019), tot_loss_proj:3.144 [t=0.17s]
prediction: ['[CLS] john tries mary, not meet mary [SEP]']
[ 750/2000] tot_loss=1.590 (perp=7.377, rec=0.096, cos=0.019), tot_loss_proj:3.157 [t=0.17s]
prediction: ['[CLS] john tries mary to not meet mary [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.590 (perp=7.377, rec=0.096, cos=0.019), tot_loss_proj:3.164 [t=0.17s]
prediction: ['[CLS] john tries mary to not meet mary [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.553 (perp=7.168, rec=0.101, cos=0.018), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
[ 900/2000] tot_loss=1.553 (perp=7.168, rec=0.101, cos=0.019), tot_loss_proj:2.793 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.542 (perp=7.168, rec=0.090, cos=0.019), tot_loss_proj:2.792 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
Attempt swap
[1000/2000] tot_loss=1.550 (perp=7.168, rec=0.098, cos=0.018), tot_loss_proj:2.794 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
[1050/2000] tot_loss=1.543 (perp=7.168, rec=0.091, cos=0.018), tot_loss_proj:2.787 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
Attempt swap
[1100/2000] tot_loss=1.547 (perp=7.168, rec=0.095, cos=0.018), tot_loss_proj:2.788 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
Attempt swap
[1150/2000] tot_loss=1.538 (perp=7.168, rec=0.086, cos=0.018), tot_loss_proj:2.791 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
[1200/2000] tot_loss=1.545 (perp=7.168, rec=0.093, cos=0.018), tot_loss_proj:2.795 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
Attempt swap
[1250/2000] tot_loss=1.545 (perp=7.168, rec=0.094, cos=0.018), tot_loss_proj:2.791 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
Attempt swap
[1300/2000] tot_loss=1.544 (perp=7.168, rec=0.093, cos=0.018), tot_loss_proj:2.793 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
[1350/2000] tot_loss=1.539 (perp=7.168, rec=0.087, cos=0.018), tot_loss_proj:2.801 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.588 (perp=7.377, rec=0.094, cos=0.019), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] john tries mary to not meet mary [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.533 (perp=7.168, rec=0.081, cos=0.019), tot_loss_proj:2.802 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
[1500/2000] tot_loss=1.541 (perp=7.168, rec=0.088, cos=0.019), tot_loss_proj:2.805 [t=0.17s]
prediction: ['[CLS] john tries mary not to meet mary [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.013 (perp=9.547, rec=0.086, cos=0.018), tot_loss_proj:3.664 [t=0.17s]
prediction: ['[CLS] john mary tries not. meet mary [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.722 (perp=8.040, rec=0.096, cos=0.018), tot_loss_proj:3.269 [t=0.17s]
prediction: ['[CLS] john mary tries not meet mary. [SEP]']
[1650/2000] tot_loss=1.728 (perp=8.040, rec=0.102, cos=0.018), tot_loss_proj:3.274 [t=0.17s]
prediction: ['[CLS] john mary tries not meet mary. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.713 (perp=8.040, rec=0.087, cos=0.018), tot_loss_proj:3.274 [t=0.17s]
prediction: ['[CLS] john mary tries not meet mary. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.719 (perp=8.040, rec=0.092, cos=0.018), tot_loss_proj:3.278 [t=0.17s]
prediction: ['[CLS] john mary tries not meet mary. [SEP]']
[1800/2000] tot_loss=1.713 (perp=8.040, rec=0.087, cos=0.018), tot_loss_proj:3.280 [t=0.17s]
prediction: ['[CLS] john mary tries not meet mary. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.716 (perp=8.040, rec=0.090, cos=0.018), tot_loss_proj:3.281 [t=0.17s]
prediction: ['[CLS] john mary tries not meet mary. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.708 (perp=8.040, rec=0.082, cos=0.018), tot_loss_proj:3.278 [t=0.17s]
prediction: ['[CLS] john mary tries not meet mary. [SEP]']
[1950/2000] tot_loss=1.711 (perp=8.040, rec=0.085, cos=0.018), tot_loss_proj:3.279 [t=0.17s]
prediction: ['[CLS] john mary tries not meet mary. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.710 (perp=8.040, rec=0.083, cos=0.018), tot_loss_proj:3.281 [t=0.17s]
prediction: ['[CLS] john mary tries not meet mary. [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS] john tries to meet not mary. [SEP]
========================
predicted: 
========================
[CLS] john mary tries not meet mary. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 116.071

[Aggregate metrics]:
rouge1     | fm: 86.121 | p: 88.553 | r: 84.321
rouge2     | fm: 47.070 | p: 48.340 | r: 46.319
rougeL     | fm: 75.877 | p: 77.827 | r: 74.461
rougeLsum  | fm: 76.255 | p: 78.397 | r: 74.549
r1fm+r2fm = 133.190

input #8 time: 0:06:55 | total time: 1:02:16


Running input #9 of 100.
reference: 
========================
The unidentified victim was apparently struck during the early morning hours.
========================
Sample: 0 8.500770349094375e-12 0.05375838307000121 0.34287342
average of cosine similarity 0.9876322813549117
highest_index [0]
highest [0.9876322813549117]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  1996, 20293,  6778,  2001,  4593,  4930,  2076,  1996,  2220,
          2851,  2847,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]']
[Init] best rec loss: 0.9761378169059753 for ['[CLS]re took vie one ioc reading triangle willmour just grantedated [SEP]']
[Init] best rec loss: 0.9484792351722717 for ['[CLS]hearted rendition ho [CLS] factor supreme satinating concentrate baseman cent sin [SEP]']
[Init] best rec loss: 0.9337632060050964 for ['[CLS]ivated guests survivalr academie celebrates ultimately? invoked per substrates based [SEP]']
[Init] best rec loss: 0.9280292391777039 for ['[CLS] hair confederation qualify rid ni interchange semifinals colonel keystone pop equilibrium resting [SEP]']
[Init] best rec loss: 0.9025102853775024 for ['[CLS] located sure studio earlier ceased downpot engineering giles best includingtage [SEP]']
[Init] best perm rec loss: 0.8983306884765625 for ['[CLS]pot including engineering sure studio downtage located earlier best ceased giles [SEP]']
[Init] best perm rec loss: 0.8946741223335266 for ['[CLS] engineering studio including down sure giles best ceased locatedtage earlierpot [SEP]']
[Init] best perm rec loss: 0.893314778804779 for ['[CLS] including down bestpot suretage earlier ceased located giles engineering studio [SEP]']
[Init] best perm rec loss: 0.8884896039962769 for ['[CLS] studio sure engineeringpot giles ceased down best including located earliertage [SEP]']
[Init] best perm rec loss: 0.8874890804290771 for ['[CLS] ceased down engineeringpot sure studiotage including best located earlier giles [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.066 (perp=12.734, rec=0.742, cos=0.777), tot_loss_proj:4.254 [t=0.17s]
prediction: ['[CLS] apparently victim older victims victim during reported died wherein housemates suffered pieter [SEP]']
[ 100/2000] tot_loss=3.815 (perp=11.816, rec=0.493, cos=0.959), tot_loss_proj:4.408 [t=0.17s]
prediction: ['[CLS] unidentified victim older victim victim during struck victim torture variant late suit [SEP]']
[ 150/2000] tot_loss=2.090 (perp=8.979, rec=0.251, cos=0.043), tot_loss_proj:3.817 [t=0.17s]
prediction: ['[CLS] unidentified victim victim victim victim the struck victim the morning during suicide [SEP]']
[ 200/2000] tot_loss=2.352 (perp=10.625, rec=0.196, cos=0.031), tot_loss_proj:3.834 [t=0.17s]
prediction: ['[CLS] apparentlylence unidentified victim victim was struck victim the morning during struck [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.158 (perp=9.732, rec=0.181, cos=0.031), tot_loss_proj:3.688 [t=0.17s]
prediction: ['[CLS] apparently unidentified unidentified victim victim was struck victim the morning struck during [SEP]']
[ 300/2000] tot_loss=2.123 (perp=9.756, rec=0.142, cos=0.030), tot_loss_proj:3.726 [t=0.17s]
prediction: ['[CLS] apparently unidentified unidentified victim victim was struck victim the hours struck during [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.056 (perp=9.527, rec=0.124, cos=0.027), tot_loss_proj:3.811 [t=0.17s]
prediction: ['[CLS] the unidentified unidentified victim victim was struck morning apparently hours struck during [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.877 (perp=8.745, rec=0.101, cos=0.027), tot_loss_proj:3.673 [t=0.17s]
prediction: ['[CLS] the unidentified unidentified victim victim was apparently struck morning hours struck during [SEP]']
[ 450/2000] tot_loss=1.875 (perp=8.745, rec=0.100, cos=0.026), tot_loss_proj:3.673 [t=0.17s]
prediction: ['[CLS] the unidentified unidentified victim victim was apparently struck morning hours struck during [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.715 (perp=7.991, rec=0.091, cos=0.026), tot_loss_proj:3.727 [t=0.17s]
prediction: ['[CLS] the unidentified unidentified victim victim was apparently struck struck during morning hours [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.700 (perp=7.867, rec=0.101, cos=0.026), tot_loss_proj:3.412 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck struck during morning hours [SEP]']
[ 600/2000] tot_loss=1.691 (perp=7.867, rec=0.092, cos=0.026), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck struck during morning hours [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.686 (perp=7.848, rec=0.090, cos=0.026), tot_loss_proj:3.570 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.684 (perp=7.848, rec=0.088, cos=0.026), tot_loss_proj:3.576 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
[ 750/2000] tot_loss=1.675 (perp=7.848, rec=0.080, cos=0.026), tot_loss_proj:3.574 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.681 (perp=7.848, rec=0.086, cos=0.026), tot_loss_proj:3.576 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.679 (perp=7.848, rec=0.084, cos=0.025), tot_loss_proj:3.574 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
[ 900/2000] tot_loss=1.683 (perp=7.848, rec=0.088, cos=0.025), tot_loss_proj:3.573 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.687 (perp=7.848, rec=0.092, cos=0.025), tot_loss_proj:3.576 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1000/2000] tot_loss=1.684 (perp=7.848, rec=0.090, cos=0.025), tot_loss_proj:3.579 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
[1050/2000] tot_loss=1.684 (perp=7.848, rec=0.089, cos=0.025), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1100/2000] tot_loss=1.677 (perp=7.848, rec=0.083, cos=0.025), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1150/2000] tot_loss=1.685 (perp=7.848, rec=0.090, cos=0.025), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
[1200/2000] tot_loss=1.680 (perp=7.848, rec=0.085, cos=0.025), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1250/2000] tot_loss=1.677 (perp=7.848, rec=0.083, cos=0.025), tot_loss_proj:3.578 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1300/2000] tot_loss=1.679 (perp=7.848, rec=0.084, cos=0.025), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
[1350/2000] tot_loss=1.677 (perp=7.848, rec=0.082, cos=0.025), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1400/2000] tot_loss=1.685 (perp=7.848, rec=0.090, cos=0.025), tot_loss_proj:3.579 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1450/2000] tot_loss=1.679 (perp=7.848, rec=0.085, cos=0.025), tot_loss_proj:3.586 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
[1500/2000] tot_loss=1.673 (perp=7.848, rec=0.079, cos=0.025), tot_loss_proj:3.586 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1550/2000] tot_loss=1.684 (perp=7.848, rec=0.089, cos=0.025), tot_loss_proj:3.585 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1600/2000] tot_loss=1.682 (perp=7.848, rec=0.088, cos=0.025), tot_loss_proj:3.576 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
[1650/2000] tot_loss=1.678 (perp=7.848, rec=0.084, cos=0.025), tot_loss_proj:3.581 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1700/2000] tot_loss=1.684 (perp=7.848, rec=0.090, cos=0.025), tot_loss_proj:3.583 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1750/2000] tot_loss=1.686 (perp=7.848, rec=0.091, cos=0.025), tot_loss_proj:3.592 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
[1800/2000] tot_loss=1.675 (perp=7.848, rec=0.080, cos=0.025), tot_loss_proj:3.585 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1850/2000] tot_loss=1.679 (perp=7.848, rec=0.085, cos=0.025), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[1900/2000] tot_loss=1.678 (perp=7.848, rec=0.084, cos=0.025), tot_loss_proj:3.583 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
[1950/2000] tot_loss=1.684 (perp=7.848, rec=0.089, cos=0.025), tot_loss_proj:3.578 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Attempt swap
[2000/2000] tot_loss=1.681 (perp=7.848, rec=0.086, cos=0.025), tot_loss_proj:3.591 [t=0.17s]
prediction: ['[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]
========================
predicted: 
========================
[CLS] the unidentified victim unidentified victim was apparently struck during struck morning hours [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.481 | p: 78.571 | r: 84.615
rouge2     | fm: 72.000 | p: 69.231 | r: 75.000
rougeL     | fm: 81.481 | p: 78.571 | r: 84.615
rougeLsum  | fm: 81.481 | p: 78.571 | r: 84.615
r1fm+r2fm = 153.481

[Aggregate metrics]:
rouge1     | fm: 85.363 | p: 87.233 | r: 84.295
rouge2     | fm: 49.789 | p: 50.617 | r: 49.381
rougeL     | fm: 76.597 | p: 77.966 | r: 75.505
rougeLsum  | fm: 76.533 | p: 78.181 | r: 75.477
r1fm+r2fm = 135.152

input #9 time: 0:06:58 | total time: 1:09:15


Running input #10 of 100.
reference: 
========================
the logs piled the barge high.
========================
Sample: 0 1.9756198002576393e-13 0.050399447231508895 0.35880262
average of cosine similarity 0.9900855650921994
highest_index [0]
highest [0.9900855650921994]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996, 15664, 17835,  1996, 19398,  2152,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the logs piled the barge high. [SEP]']
[Init] best rec loss: 0.8238058090209961 for ['[CLS] my honey queensus suchbble [CLS] [SEP]']
[Init] best rec loss: 0.8123701214790344 for ['[CLS] shots acheron outsider associations seed an using [SEP]']
[Init] best rec loss: 0.8053205609321594 for ['[CLS] papua sorrow arden [MASK] provides sidri [SEP]']
[Init] best rec loss: 0.7905997037887573 for ['[CLS] caps noises imagery amateur recordislaus dismiss [SEP]']
[Init] best rec loss: 0.7373385429382324 for ['[CLS] wonders "elling 1936 recreation ezio outside [SEP]']
[Init] best rec loss: 0.6996959447860718 for ['[CLS] excellence stationary bread otherwise heel least least [SEP]']
[Init] best rec loss: 0.6952798366546631 for ['[CLS] two藤 organizationsworld pot suffered dishes [SEP]']
[Init] best perm rec loss: 0.6888568997383118 for ['[CLS]藤 dishes pot organizationsworld suffered two [SEP]']
[Init] best perm rec loss: 0.6883973479270935 for ['[CLS]藤 dishesworld pot suffered two organizations [SEP]']
[Init] best perm rec loss: 0.6876150369644165 for ['[CLS] organizations dishes potworld two suffered藤 [SEP]']
[Init] best perm rec loss: 0.6853832602500916 for ['[CLS] pot dishes藤world two suffered organizations [SEP]']
[Init] best perm rec loss: 0.6847565174102783 for ['[CLS]藤 dishes organizations potworld two suffered [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.093 (perp=13.589, rec=0.330, cos=0.045), tot_loss_proj:4.626 [t=0.17s]
prediction: ['[CLS] duke dockslalan center networks swedish [SEP]']
[ 100/2000] tot_loss=2.389 (perp=10.482, rec=0.259, cos=0.033), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] logs piled the barges. constructed piled [SEP]']
[ 150/2000] tot_loss=2.250 (perp=10.149, rec=0.191, cos=0.030), tot_loss_proj:3.463 [t=0.17s]
prediction: ['[CLS] logs logs the barge. piled high [SEP]']
[ 200/2000] tot_loss=2.415 (perp=11.223, rec=0.143, cos=0.027), tot_loss_proj:3.749 [t=0.17s]
prediction: ['[CLS] logs logs the barge high piled high [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.007 (perp=9.161, rec=0.146, cos=0.029), tot_loss_proj:3.656 [t=0.19s]
prediction: ['[CLS] high logs the barge logs piled high [SEP]']
[ 300/2000] tot_loss=1.973 (perp=9.161, rec=0.116, cos=0.025), tot_loss_proj:3.662 [t=0.19s]
prediction: ['[CLS] high logs the barge logs piled high [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.063 (perp=9.668, rec=0.106, cos=0.024), tot_loss_proj:3.798 [t=0.20s]
prediction: ['[CLS] barge logs the. logs piled high [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.674 (perp=7.760, rec=0.099, cos=0.023), tot_loss_proj:3.471 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[ 450/2000] tot_loss=1.668 (perp=7.760, rec=0.093, cos=0.023), tot_loss_proj:3.468 [t=0.21s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.670 (perp=7.760, rec=0.096, cos=0.022), tot_loss_proj:3.466 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.669 (perp=7.760, rec=0.094, cos=0.022), tot_loss_proj:3.474 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[ 600/2000] tot_loss=1.677 (perp=7.760, rec=0.103, cos=0.022), tot_loss_proj:3.470 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.659 (perp=7.760, rec=0.085, cos=0.022), tot_loss_proj:3.476 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.655 (perp=7.760, rec=0.081, cos=0.022), tot_loss_proj:3.474 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[ 750/2000] tot_loss=1.661 (perp=7.760, rec=0.087, cos=0.022), tot_loss_proj:3.470 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.668 (perp=7.760, rec=0.094, cos=0.022), tot_loss_proj:3.470 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.656 (perp=7.760, rec=0.082, cos=0.021), tot_loss_proj:3.472 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[ 900/2000] tot_loss=1.661 (perp=7.760, rec=0.088, cos=0.021), tot_loss_proj:3.476 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.671 (perp=7.760, rec=0.097, cos=0.021), tot_loss_proj:3.470 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1000/2000] tot_loss=1.660 (perp=7.760, rec=0.086, cos=0.021), tot_loss_proj:3.474 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[1050/2000] tot_loss=1.672 (perp=7.760, rec=0.099, cos=0.021), tot_loss_proj:3.472 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1100/2000] tot_loss=1.659 (perp=7.760, rec=0.086, cos=0.021), tot_loss_proj:3.478 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1150/2000] tot_loss=1.653 (perp=7.760, rec=0.080, cos=0.021), tot_loss_proj:3.472 [t=0.18s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[1200/2000] tot_loss=1.671 (perp=7.760, rec=0.098, cos=0.021), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1250/2000] tot_loss=1.665 (perp=7.760, rec=0.092, cos=0.021), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1300/2000] tot_loss=1.673 (perp=7.760, rec=0.100, cos=0.021), tot_loss_proj:3.469 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[1350/2000] tot_loss=1.669 (perp=7.760, rec=0.096, cos=0.021), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1400/2000] tot_loss=1.667 (perp=7.760, rec=0.094, cos=0.021), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1450/2000] tot_loss=1.660 (perp=7.760, rec=0.087, cos=0.021), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[1500/2000] tot_loss=1.656 (perp=7.760, rec=0.083, cos=0.021), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1550/2000] tot_loss=1.652 (perp=7.760, rec=0.079, cos=0.021), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1600/2000] tot_loss=1.653 (perp=7.760, rec=0.080, cos=0.021), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[1650/2000] tot_loss=1.658 (perp=7.760, rec=0.085, cos=0.021), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1700/2000] tot_loss=1.659 (perp=7.760, rec=0.086, cos=0.021), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1750/2000] tot_loss=1.657 (perp=7.760, rec=0.084, cos=0.021), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[1800/2000] tot_loss=1.646 (perp=7.760, rec=0.072, cos=0.021), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1850/2000] tot_loss=1.649 (perp=7.760, rec=0.076, cos=0.021), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1900/2000] tot_loss=1.663 (perp=7.760, rec=0.090, cos=0.021), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[1950/2000] tot_loss=1.657 (perp=7.760, rec=0.083, cos=0.021), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[2000/2000] tot_loss=1.657 (perp=7.760, rec=0.084, cos=0.021), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] the logs piled the barge high. [SEP]
========================
predicted: 
========================
[CLS] barge logs. the logs piled high [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 130.357

[Aggregate metrics]:
rouge1     | fm: 85.820 | p: 87.401 | r: 84.673
rouge2     | fm: 48.944 | p: 49.791 | r: 48.460
rougeL     | fm: 76.370 | p: 77.678 | r: 75.484
rougeLsum  | fm: 76.661 | p: 77.827 | r: 75.870
r1fm+r2fm = 134.765

input #10 time: 0:07:17 | total time: 1:16:32


Running input #11 of 100.
reference: 
========================
During the early evening, Saturn can be found in the north, while Jupiter rises in the east.
========================
Sample: 0 1.61784680040617e-13 0.0504334805703033 0.3286486
average of cosine similarity 0.9881553195147004
highest_index [0]
highest [0.9881553195147004]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2076,  1996,  2220,  3944,  1010, 14784,  2064,  2022,  2179,
          1999,  1996,  2167,  1010,  2096, 13035,  9466,  1999,  1996,  2264,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]']
[Init] best rec loss: 0.9603642225265503 for ['[CLS] triedya radcliffe whitney pepper since only ranges beingshibreaker sharedpower kn bn nest o day you detention [SEP]']
[Init] best rec loss: 0.9419578313827515 for ['[CLS] degreess become panted eric like there ⟩nt obeyed gwen supernatural living mexicanard consider launch due griffin block [SEP]']
[Init] best rec loss: 0.9289517998695374 for ['[CLS] poster round around globe magic cameo occupation bash label ever mtv unknownh fund ₹ school famous skillsmat sham [SEP]']
[Init] best rec loss: 0.9151187539100647 for ['[CLS] looks neither sold transportperationum after winning wade laying co licked deep lea bramont mia absentrosis pub [SEP]']
[Init] best rec loss: 0.9120637774467468 for ['[CLS] brands anyway society m founding \\ whichptive dating pop vol days contraction planes moses cooling... scrap warning just [SEP]']
[Init] best rec loss: 0.9037604928016663 for ['[CLS] il [SEP] of ny processes tour madam enchanted woody due hurt free red while studio ever arun beethoven double interval [SEP]']
[Init] best rec loss: 0.900558352470398 for ['[CLS] compared candle sha real cell renacing vigor weight moon chain sweetness amateur strength ad swallow dust northern [SEP] lower [SEP]']
[Init] best rec loss: 0.896977961063385 for ['[CLS] desk nectar parts rpm universallypressed up south davey estimated height advocate heart customary all circular bryson events pan strung [SEP]']
[Init] best rec loss: 0.8925879001617432 for ['[CLS] town performggles ratio property nephew headedta va exilepress executives cleared charm those queen sweat during [SEP] up [SEP]']
[Init] best perm rec loss: 0.8912792801856995 for ['[CLS] charm executivespress town up nephew vaggles property queen exile those during [SEP] perform clearedta headed sweat ratio [SEP]']
[Init] best perm rec loss: 0.890846848487854 for ['[CLS] queen during nephew those exile perform [SEP] va property up ratio executives charm town headedtaggles sweat clearedpress [SEP]']
[Init] best perm rec loss: 0.8906643390655518 for ['[CLS] ratio charmta exile va sweat during those perform headed cleared town nephew queen up propertyggles executives [SEP]press [SEP]']
[Init] best perm rec loss: 0.8884612917900085 for ['[CLS] during sweat town ratio queenggles exile executives those nephew headed performta property charm va uppress cleared [SEP] [SEP]']
[Init] best perm rec loss: 0.8880924582481384 for ['[CLS] [SEP]ta exile ratiopress va charm up nephew property duringggles sweat cleared headed queen those town perform executives [SEP]']
[Init] best perm rec loss: 0.887862503528595 for ['[CLS] charm exile cleared nephewggles during town executives perform queen [SEP] propertypress vata those up sweat headed ratio [SEP]']
[Init] best perm rec loss: 0.8877741694450378 for ['[CLS] headed [SEP] exile property up those charm during cleared perform queen sweatggles nephewta va town ratio executivespress [SEP]']
[Init] best perm rec loss: 0.8856097459793091 for ['[CLS] sweat va [SEP] nephewggles ratio those exile perform up queen executives charm property clearedpress town headedta during [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.694 (perp=10.776, rec=0.540, cos=0.999), tot_loss_proj:4.024 [t=0.18s]
prediction: ['[CLS] yes. is representing located fitzgerald while studio course on meaning next ala. initial max before including river republican [SEP]']
[ 100/2000] tot_loss=3.670 (perp=11.176, rec=0.438, cos=0.997), tot_loss_proj:4.048 [t=0.18s]
prediction: ['[CLS] during. during representing eveningcu while east available include lakes the location. initial cards before owned. jupiter [SEP]']
[ 150/2000] tot_loss=3.481 (perp=10.334, rec=0.419, cos=0.996), tot_loss_proj:3.904 [t=0.18s]
prediction: ['[CLS] during. during east evening saturn while rises earlym east on location a points evening before attacker. jupiter [SEP]']
[ 200/2000] tot_loss=3.887 (perp=12.153, rec=0.463, cos=0.993), tot_loss_proj:4.357 [t=0.18s]
prediction: ['[CLS] during next evening representing evening saturn tho east place lucien east the mood " discovered wax ste in. jupiter [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.730 (perp=11.704, rec=0.396, cos=0.993), tot_loss_proj:4.230 [t=0.18s]
prediction: ['[CLS] during afternoon during ( evening saturn while placed east beyond east < arena " comfortable morning ste overlap. saturn [SEP]']
[ 300/2000] tot_loss=3.674 (perp=11.569, rec=0.369, cos=0.991), tot_loss_proj:4.235 [t=0.18s]
prediction: ['[CLS] during east during ( evening saturn whilst placed east beyond east < achievements " comfortable morning ste£. saturn [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.763 (perp=11.992, rec=0.374, cos=0.991), tot_loss_proj:4.303 [t=0.18s]
prediction: ['[CLS] during east during or evening saturn mama placed east ⟨ saturn < achievements "ught morningce£. schleswig [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.556 (perp=10.745, rec=0.413, cos=0.993), tot_loss_proj:4.022 [t=0.18s]
prediction: ['[CLS] duringce during or evening saturn mama placed east beyond saturn < achievements mentionedught morning east. the schleswig [SEP]']
[ 450/2000] tot_loss=3.339 (perp=10.028, rec=0.347, cos=0.986), tot_loss_proj:3.875 [t=0.18s]
prediction: ['[CLS] duringce during or evening saturn mama placed east beyond saturn. achievements daysught evening east. the decades [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.271 (perp=9.594, rec=0.367, cos=0.985), tot_loss_proj:3.807 [t=0.18s]
prediction: ['[CLS] during both during june evening saturn mama placed east beyond saturn. achievements daysught ( east. the decades [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.466 (perp=10.729, rec=0.340, cos=0.980), tot_loss_proj:4.013 [t=0.18s]
prediction: ['[CLS] during moons during june evening saturn mama placed east beyond saturn.iensis bothught or north. the decades [SEP]']
[ 600/2000] tot_loss=3.428 (perp=10.598, rec=0.331, cos=0.977), tot_loss_proj:4.010 [t=0.18s]
prediction: ['[CLS] during moons during june evening saturn mama placed east beyond saturn.iensis bothught or north. the solar [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.518 (perp=11.108, rec=0.321, cos=0.976), tot_loss_proj:4.156 [t=0.18s]
prediction: ['[CLS] during moons early victory evening saturn mama became east ⟨ saturn ; bothiensisught ( north. the solar [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.361 (perp=10.414, rec=0.312, cos=0.966), tot_loss_proj:4.010 [t=0.18s]
prediction: ['[CLS] during both early victory evening saturn mama became east ⟨ saturn ; jupiteriensisught ( north. the solar [SEP]']
[ 750/2000] tot_loss=3.312 (perp=10.148, rec=0.313, cos=0.970), tot_loss_proj:3.922 [t=0.18s]
prediction: ['[CLS] during both early victory evening saturn mama become east beyond saturn ; jupiteriensisught ( north. the solar [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.280 (perp=10.007, rec=0.314, cos=0.965), tot_loss_proj:3.991 [t=0.18s]
prediction: ['[CLS] during both early victory decades saturn mama became east ⟨ saturn ; jupiteranught ( north. the evening [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.206 (perp=9.676, rec=0.316, cos=0.955), tot_loss_proj:3.905 [t=0.18s]
prediction: ['[CLS] during both early victory decades saturn mama became east ⟨ saturn ;iensisught ( jupiter north. the evening [SEP]']
[ 900/2000] tot_loss=3.440 (perp=10.872, rec=0.305, cos=0.960), tot_loss_proj:4.169 [t=0.18s]
prediction: ['[CLS] during both early victory decades saturn mama became rises⁄₄ saturn ;anught ( jupiter north. the evening [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.390 (perp=10.635, rec=0.308, cos=0.956), tot_loss_proj:4.051 [t=0.18s]
prediction: ['[CLS] during both early victory decades ( mama become rises⁄₄ saturn whileanught saturn universities north. the evening [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.296 (perp=10.181, rec=0.306, cos=0.954), tot_loss_proj:4.021 [t=0.18s]
prediction: ['[CLS] during both early victory decades ( mama become rises⁄₄ saturn while saturnanught jupiter north. the evening [SEP]']
[1050/2000] tot_loss=3.278 (perp=10.138, rec=0.295, cos=0.955), tot_loss_proj:3.994 [t=0.18s]
prediction: ['[CLS] during both early victory decades ( mama become rises ⟨ saturn while saturnanught moons north. the evening [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.236 (perp=9.928, rec=0.296, cos=0.954), tot_loss_proj:3.947 [t=0.18s]
prediction: ['[CLS] during both early victory decades ( mama become rises ⟨ saturn while saturnan moonsught north. the evening [SEP]']
Attempt swap
[1150/2000] tot_loss=3.231 (perp=9.928, rec=0.291, cos=0.954), tot_loss_proj:3.953 [t=0.18s]
prediction: ['[CLS] during both early victory decades ( mama become rises ⟨ saturn while saturnan moonsught north. the evening [SEP]']
[1200/2000] tot_loss=3.253 (perp=10.070, rec=0.286, cos=0.953), tot_loss_proj:3.953 [t=0.18s]
prediction: ['[CLS] during both early victory decades ( mama become rises ⟨ saturn while saturnan moons 、 north. the evening [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.337 (perp=10.431, rec=0.300, cos=0.951), tot_loss_proj:4.013 [t=0.18s]
prediction: ['[CLS] during both early victory decades ( mamaos rises⁄₄ saturn while saturn become universities 、 north. the evening [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=3.369 (perp=10.569, rec=0.303, cos=0.952), tot_loss_proj:3.991 [t=0.18s]
prediction: ['[CLS] during instrument early victory decades ( mamaos rises months saturn while saturn become universities⁄₄ north. the evening [SEP]']
[1350/2000] tot_loss=3.497 (perp=11.233, rec=0.298, cos=0.952), tot_loss_proj:4.099 [t=0.18s]
prediction: ['[CLS] during instrument early victory currency ( mamaos rises months saturn while saturn become universities lucien north. the evening [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=3.421 (perp=10.882, rec=0.294, cos=0.950), tot_loss_proj:4.038 [t=0.18s]
prediction: ['[CLS] during instrument early currency victory ( mamaos rises months saturn while saturn become moons lucien north. the evening [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=3.330 (perp=10.404, rec=0.309, cos=0.940), tot_loss_proj:3.927 [t=0.18s]
prediction: ['[CLS] during early both currency victory ( mamaos rises months saturn while saturn become moons lucien north. the evening [SEP]']
[1500/2000] tot_loss=3.274 (perp=10.153, rec=0.293, cos=0.951), tot_loss_proj:3.863 [t=0.18s]
prediction: ['[CLS] during early both currency victory ( mamaos rises months saturn while saturn become jupiter lucien north. the evening [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=3.255 (perp=10.049, rec=0.292, cos=0.953), tot_loss_proj:3.907 [t=0.18s]
prediction: ['[CLS] during early council currency victory months mamaos rises ( saturn while saturn become jupiter lucien north. the evening [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=3.204 (perp=9.786, rec=0.297, cos=0.950), tot_loss_proj:3.842 [t=0.18s]
prediction: ['[CLS] during early lucien currency victory months mamaos rises ( saturn while saturn become jupiter hades north. the evening [SEP]']
[1650/2000] tot_loss=3.236 (perp=9.956, rec=0.296, cos=0.949), tot_loss_proj:3.864 [t=0.18s]
prediction: ['[CLS] during early lucien currency victory months mamaos rises ( saturn while saturn become jupiter instrument north. the evening [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=3.126 (perp=9.404, rec=0.295, cos=0.950), tot_loss_proj:3.763 [t=0.18s]
prediction: ['[CLS] during early⁄₄ currency victory months mamaos rises while saturn ( saturn become jupiter instrument north. the evening [SEP]']
Attempt swap
[1750/2000] tot_loss=3.053 (perp=9.053, rec=0.294, cos=0.949), tot_loss_proj:3.676 [t=0.18s]
prediction: ['[CLS] during early⁄₄ currency victory months mamaos rises while saturn ( saturn become jupiter both north. the evening [SEP]']
[1800/2000] tot_loss=3.045 (perp=9.020, rec=0.293, cos=0.949), tot_loss_proj:3.660 [t=0.18s]
prediction: ['[CLS] during early⁄₄ currency victory months vantageos rises while saturn ( saturn become jupiter both north. the evening [SEP]']
Attempt swap
[1850/2000] tot_loss=3.041 (perp=9.020, rec=0.286, cos=0.950), tot_loss_proj:3.665 [t=0.18s]
prediction: ['[CLS] during early⁄₄ currency victory months vantageos rises while saturn ( saturn become jupiter both north. the evening [SEP]']
Attempt swap
[1900/2000] tot_loss=3.043 (perp=9.020, rec=0.288, cos=0.951), tot_loss_proj:3.662 [t=0.18s]
prediction: ['[CLS] during early⁄₄ currency victory months vantageos rises while saturn ( saturn become jupiter both north. the evening [SEP]']
[1950/2000] tot_loss=3.146 (perp=9.533, rec=0.289, cos=0.951), tot_loss_proj:3.774 [t=0.18s]
prediction: ['[CLS] during early⁄₄ currency position months vantageos rises while saturn ( saturn become jupiter instrument north. the evening [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=3.098 (perp=9.352, rec=0.279, cos=0.949), tot_loss_proj:3.770 [t=0.18s]
prediction: ['[CLS] during early instrument currency position months vantageos rises while saturn ( saturn become jupiter⁄₄ north. the evening [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]
========================
predicted: 
========================
[CLS] during early⁄₄ currency position months vantageos rises while saturn ( saturn become jupiter instrument north. the evening [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 59.459 | p: 61.111 | r: 57.895
rouge2     | fm: 5.714 | p: 5.882 | r: 5.556
rougeL     | fm: 37.838 | p: 38.889 | r: 36.842
rougeLsum  | fm: 37.838 | p: 38.889 | r: 36.842
r1fm+r2fm = 65.174

[Aggregate metrics]:
rouge1     | fm: 83.446 | p: 84.983 | r: 82.346
rouge2     | fm: 45.268 | p: 46.242 | r: 44.792
rougeL     | fm: 72.918 | p: 74.323 | r: 71.911
rougeLsum  | fm: 73.464 | p: 74.765 | r: 72.622
r1fm+r2fm = 128.714

input #11 time: 0:07:13 | total time: 1:23:46


Running input #12 of 100.
reference: 
========================
He walked up the hill.
========================
Sample: 0 5.873500669403261e-12 0.06149985677474414 0.37100786
average of cosine similarity 0.9861654220288987
highest_index [0]
highest [0.9861654220288987]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2002, 2939, 2039, 1996, 2940, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he walked up the hill. [SEP]']
[Init] best rec loss: 1.0273795127868652 for ['[CLS] stars sans january canvas gdansk beauty [SEP]']
[Init] best rec loss: 0.9705166220664978 for ['[CLS]thevert banks councillors respective puerto [SEP]']
[Init] best rec loss: 0.9683748483657837 for ['[CLS] articles gin keen monster plot baldwin [SEP]']
[Init] best rec loss: 0.9440220594406128 for ['[CLS] probably block tilt cavesree elevation [SEP]']
[Init] best rec loss: 0.9418670535087585 for ['[CLS] careers jewish drain blockade eternity instrument [SEP]']
[Init] best rec loss: 0.9177175164222717 for ['[CLS] untou culture conferencesea display [SEP]']
[Init] best rec loss: 0.9150117039680481 for ['[CLS] progress preyersonctum cable language [SEP]']
[Init] best rec loss: 0.8984030485153198 for ['[CLS] equal successronegizing stock hana [SEP]']
[Init] best perm rec loss: 0.8943411111831665 for ['[CLS]gizing stockrone success hana equal [SEP]']
[Init] best perm rec loss: 0.8935002684593201 for ['[CLS] success stock hanaronegizing equal [SEP]']
[Init] best perm rec loss: 0.8928298950195312 for ['[CLS]ronegizing hana stock success equal [SEP]']
[Init] best perm rec loss: 0.8927457928657532 for ['[CLS] successrone stock hana equalgizing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.495 (perp=9.574, rec=0.623, cos=0.957), tot_loss_proj:3.822 [t=0.17s]
prediction: ['[CLS] sequential rise to vera hill apple [SEP]']
[ 100/2000] tot_loss=2.471 (perp=10.616, rec=0.279, cos=0.068), tot_loss_proj:4.129 [t=0.17s]
prediction: ['[CLS] shri walked. road hill down [SEP]']
[ 150/2000] tot_loss=1.984 (perp=8.715, rec=0.196, cos=0.044), tot_loss_proj:3.660 [t=0.17s]
prediction: ['[CLS] shri walked up hill hill down [SEP]']
[ 200/2000] tot_loss=1.798 (perp=7.959, rec=0.170, cos=0.036), tot_loss_proj:3.574 [t=0.17s]
prediction: ['[CLS]hal walked up hill hill down [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.042 (perp=8.287, rec=0.319, cos=0.065), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS] foyer walked up to up hill [SEP]']
[ 300/2000] tot_loss=1.893 (perp=8.270, rec=0.198, cos=0.040), tot_loss_proj:3.425 [t=0.17s]
prediction: ['[CLS] foyer walked up. up hill [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.960 (perp=8.746, rec=0.171, cos=0.040), tot_loss_proj:3.713 [t=0.17s]
prediction: ['[CLS] mazda walked up up hill to [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.857 (perp=8.265, rec=0.166, cos=0.038), tot_loss_proj:3.465 [t=0.17s]
prediction: ['[CLS] mazda walked up to hill up [SEP]']
[ 450/2000] tot_loss=1.966 (perp=8.918, rec=0.145, cos=0.038), tot_loss_proj:3.684 [t=0.17s]
prediction: ['[CLS] mazda walked up. hill up [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.051 (perp=9.315, rec=0.150, cos=0.038), tot_loss_proj:3.722 [t=0.17s]
prediction: ['[CLS] mazda walked up up hill he [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.936 (perp=8.769, rec=0.144, cos=0.039), tot_loss_proj:3.797 [t=0.17s]
prediction: ['[CLS] he walked up up hilldhi [SEP]']
[ 600/2000] tot_loss=1.903 (perp=8.769, rec=0.113, cos=0.036), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS] he walked up up hilldhi [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.737 (perp=7.925, rec=0.116, cos=0.036), tot_loss_proj:3.562 [t=0.17s]
prediction: ['[CLS] he walked updhi hill up [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.731 (perp=7.925, rec=0.110, cos=0.035), tot_loss_proj:3.570 [t=0.17s]
prediction: ['[CLS] he walked updhi hill up [SEP]']
[ 750/2000] tot_loss=1.729 (perp=7.925, rec=0.109, cos=0.035), tot_loss_proj:3.561 [t=0.17s]
prediction: ['[CLS] he walked updhi hill up [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.920 (perp=8.876, rec=0.110, cos=0.035), tot_loss_proj:3.755 [t=0.17s]
prediction: ['[CLS] he walked up14 hill up [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.818 (perp=8.398, rec=0.104, cos=0.035), tot_loss_proj:3.703 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
[ 900/2000] tot_loss=1.820 (perp=8.398, rec=0.106, cos=0.034), tot_loss_proj:3.711 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.815 (perp=8.398, rec=0.102, cos=0.034), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.834 (perp=8.398, rec=0.120, cos=0.034), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
[1050/2000] tot_loss=1.813 (perp=8.398, rec=0.100, cos=0.034), tot_loss_proj:3.712 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.820 (perp=8.398, rec=0.107, cos=0.034), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.815 (perp=8.398, rec=0.102, cos=0.034), tot_loss_proj:3.712 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
[1200/2000] tot_loss=1.817 (perp=8.398, rec=0.104, cos=0.034), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.815 (perp=8.398, rec=0.102, cos=0.034), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.816 (perp=8.398, rec=0.102, cos=0.034), tot_loss_proj:3.712 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
[1350/2000] tot_loss=1.818 (perp=8.398, rec=0.105, cos=0.034), tot_loss_proj:3.713 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.818 (perp=8.398, rec=0.105, cos=0.034), tot_loss_proj:3.711 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.810 (perp=8.398, rec=0.097, cos=0.034), tot_loss_proj:3.710 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
[1500/2000] tot_loss=1.819 (perp=8.398, rec=0.105, cos=0.033), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.803 (perp=8.398, rec=0.090, cos=0.033), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.818 (perp=8.398, rec=0.105, cos=0.033), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
[1650/2000] tot_loss=1.818 (perp=8.398, rec=0.105, cos=0.033), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.813 (perp=8.398, rec=0.100, cos=0.033), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS] he walked up hill14 up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.867 (perp=8.667, rec=0.100, cos=0.034), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] he walked up hill clair up [SEP]']
[1800/2000] tot_loss=1.867 (perp=8.667, rec=0.100, cos=0.034), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] he walked up hill clair up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.872 (perp=8.667, rec=0.105, cos=0.034), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] he walked up hill clair up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.867 (perp=8.667, rec=0.100, cos=0.034), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] he walked up hill clair up [SEP]']
[1950/2000] tot_loss=1.862 (perp=8.667, rec=0.095, cos=0.034), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] he walked up hill clair up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.858 (perp=8.667, rec=0.092, cos=0.034), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] he walked up hill clair up [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] he walked up the hill. [SEP]
========================
predicted: 
========================
[CLS] he walked up hill clair up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 46.154 | p: 42.857 | r: 50.000
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 126.154

[Aggregate metrics]:
rouge1     | fm: 83.090 | p: 84.313 | r: 82.446
rouge2     | fm: 45.959 | p: 46.329 | r: 45.752
rougeL     | fm: 73.725 | p: 74.287 | r: 73.360
rougeLsum  | fm: 73.843 | p: 74.742 | r: 73.467
r1fm+r2fm = 129.050

input #12 time: 0:06:56 | total time: 1:30:42


Running input #13 of 100.
reference: 
========================
It is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters.
========================
Sample: 0 3.532786491303906e-12 0.05370288332967785 0.36187345
average of cosine similarity 0.9889270656543832
highest_index [0]
highest [0.9889270656543832]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2009,  2003,  2023,  3291,  2008,  1996, 10076,  2017,  9611,
          1996,  2062,  4089,  2017,  1005,  2222, 13225,  1996, 12455,  2039,
          2012,  5971,  4075,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]"]
[Init] best rec loss: 0.9446279406547546 for ['[CLS] id brand fault sciences treated allows american person perceive directions alleyulating pentagonette modern declaration material devoid having participation artistic ricardooration [SEP]']
[Init] best rec loss: 0.8717837929725647 for ['[CLS] independenternussnor beat shelley pattierty better newspapers chanceocation customsdi broke nolanrona tennesseeed drummer worked analog nap [SEP]']
[Init] best rec loss: 0.8676259517669678 for ['[CLS]ge miss west unity homestead usual support starting steady electionseon snoop jamaicagames game bro pen illegal que overland doo new mall [SEP]']
[Init] best perm rec loss: 0.8666638135910034 for ['[CLS] new illegal game miss mall usualgames unity support que jamaica steady pen startingge snoop dooeon homestead bro west elections overland [SEP]']
[Init] best perm rec loss: 0.8617178797721863 for ['[CLS] snoop game support usualge doo homestead quegames steady new illegal west miss unity starting mall bro jamaica overland elections peneon [SEP]']
[Init] best perm rec loss: 0.8612036108970642 for ['[CLS] mall usual illegal que snoop doo electionsge support homestead west unity starting jamaica miss steady new game overland bro pengameseon [SEP]']
[Init] best perm rec loss: 0.8595340251922607 for ['[CLS]games usual miss starting doo homestead bro gamege west steady jamaicaeon illegal support elections new unity que mall snoop overland pen [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.393 (perp=11.522, rec=0.515, cos=0.574), tot_loss_proj:4.263 [t=0.18s]
prediction: ["[CLS] evil th [SEP] railway wednesday obvious thompson the'pga the somali inspector - -kers overwhelming bitch. airline exceeds mountaindie [SEP]"]
[ 100/2000] tot_loss=3.349 (perp=11.475, rec=0.660, cos=0.394), tot_loss_proj:4.231 [t=0.17s]
prediction: ['[CLS] fun fat to poker courses old georgia the i ( theescence2 score wes makes lung is which, exceeds thus poker [SEP]']
[ 150/2000] tot_loss=2.790 (perp=11.887, rec=0.341, cos=0.071), tot_loss_proj:4.337 [t=0.18s]
prediction: ['[CLS] fun fat help waterfront courses old william the i ( theescenceee score big visits blues <. ( scientology big software [SEP]']
[ 200/2000] tot_loss=3.400 (perp=13.022, rec=0.539, cos=0.256), tot_loss_proj:4.558 [t=0.18s]
prediction: ['[CLS] inner阝 understand products programs old jackson the remember ibm theescenceee f neurons ‖ gentlemenulate which2ı wonderful algorithm [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.039 (perp=12.508, rec=0.411, cos=0.127), tot_loss_proj:4.450 [t=0.18s]
prediction: ['[CLS] inner阝 understand products students boys jackson the we cult the second wonderful hill™ < dismissed. which therefore [UNK] contractor problem [SEP]']
[ 300/2000] tot_loss=2.646 (perp=11.312, rec=0.329, cos=0.055), tot_loss_proj:4.209 [t=0.18s]
prediction: ['[CLS] \\阝 understand nautical students boys resources the i cult the first great hill ceo < dismissed. which therefore [UNK] patient problem [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.448 (perp=10.509, rec=0.304, cos=0.042), tot_loss_proj:4.063 [t=0.18s]
prediction: ["[CLS] \\阝 understand nautical students'i resources the ibm the first great hill corporate < continue. which therefore [UNK] patient problem [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.298 (perp=9.952, rec=0.273, cos=0.035), tot_loss_proj:3.947 [t=0.18s]
prediction: ['[CLS] \\阝 understand nautical questions { i resources the ibm the first great hill corporate must erik problem which therefore [UNK] survivors. [SEP]']
[ 450/2000] tot_loss=2.285 (perp=9.941, rec=0.265, cos=0.031), tot_loss_proj:3.931 [t=0.18s]
prediction: ["[CLS] \\阝 solve nautical questions'i resources the ibm the first great hill corporate must erik problem which therefore [UNK] survivors. [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.395 (perp=10.489, rec=0.265, cos=0.032), tot_loss_proj:4.053 [t=0.18s]
prediction: ["[CLS] resources阝 solve nautical replies'i sooner the ibm the first great hill corporate must 我 problem this therefore [UNK] survivors. [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=2.456 (perp=10.597, rec=0.289, cos=0.048), tot_loss_proj:4.052 [t=0.18s]
prediction: ['[CLS]olf [ solve nautical replies { i sooner the subsequently the a great up corporate must problem which 我 therefore [UNK] survivors. [SEP]']
[ 600/2000] tot_loss=2.371 (perp=10.423, rec=0.255, cos=0.032), tot_loss_proj:4.017 [t=0.18s]
prediction: ["[CLS]olf [ solve nautical replies'you sooner the subsequently the a great up corporate must problem this 我 therefore [UNK] survivors. [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=2.317 (perp=10.253, rec=0.237, cos=0.029), tot_loss_proj:3.966 [t=0.18s]
prediction: ["[CLS]olf originally solve nautical replies you sooner'the ibm the a great up corporate must problem this why therefore [UNK] survivors. [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.215 (perp=9.798, rec=0.227, cos=0.028), tot_loss_proj:3.885 [t=0.18s]
prediction: ["[CLS]olf originally solve nautical replies you sooner'the once the survivors great up corporate must problem this why instead [UNK] a. [SEP]"]
[ 750/2000] tot_loss=2.211 (perp=9.798, rec=0.224, cos=0.028), tot_loss_proj:3.889 [t=0.18s]
prediction: ["[CLS]olf originally solve nautical replies you sooner'the once the survivors great up corporate must problem this why instead [UNK] a. [SEP]"]
Attempt swap
[ 800/2000] tot_loss=2.208 (perp=9.798, rec=0.220, cos=0.028), tot_loss_proj:3.886 [t=0.18s]
prediction: ["[CLS]olf originally solve nautical replies you sooner'the once the survivors great up corporate must problem this why instead [UNK] a. [SEP]"]
Attempt swap
[ 850/2000] tot_loss=2.158 (perp=9.576, rec=0.215, cos=0.028), tot_loss_proj:3.844 [t=0.18s]
prediction: ["[CLS] davis originally solve nautical replies you sooner'the once the survivors great up corporate must problem this why instead [UNK] a. [SEP]"]
[ 900/2000] tot_loss=2.195 (perp=9.744, rec=0.218, cos=0.028), tot_loss_proj:3.874 [t=0.18s]
prediction: ["[CLS] davis originally solve nautical results you sooner'the once the folks great up corporate must problem this why instead [UNK] a. [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.362 (perp=10.599, rec=0.213, cos=0.029), tot_loss_proj:4.038 [t=0.18s]
prediction: ["[CLS] 我 originally solve nautical results you sooner'the bored the folks great up corporate cannot problem which resource instead [UNK] a. [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=2.224 (perp=9.889, rec=0.219, cos=0.027), tot_loss_proj:3.914 [t=0.18s]
prediction: ["[CLS] originally solve 我 nautical results you sooner'the bored the folks great up corporate cannot problem that resource instead [UNK] a. [SEP]"]
[1050/2000] tot_loss=2.213 (perp=9.889, rec=0.208, cos=0.027), tot_loss_proj:3.915 [t=0.18s]
prediction: ["[CLS] originally solve 我 nautical results you sooner'the bored the folks great up corporate cannot problem that resource instead [UNK] a. [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=2.231 (perp=9.989, rec=0.207, cos=0.027), tot_loss_proj:3.915 [t=0.18s]
prediction: ["[CLS] originally solve 我 nautical results you sooner'the 1960s the folks up wonderful corporate cannot problem that resource instead 1 a. [SEP]"]
Attempt swap
[1150/2000] tot_loss=2.222 (perp=9.997, rec=0.196, cos=0.026), tot_loss_proj:3.914 [t=0.18s]
prediction: ["[CLS] originally solve 我 nautical results you sooner'the 1960s the folks up wonderful corporate cannot problem that resource instead 1 now. [SEP]"]
[1200/2000] tot_loss=2.273 (perp=10.245, rec=0.198, cos=0.026), tot_loss_proj:3.984 [t=0.18s]
prediction: ["[CLS] originally solve trends nautical sounds you sooner'the sooner the folks up wonderful corporate cannot problem that resource instead 1 now. [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=2.219 (perp=9.940, rec=0.204, cos=0.027), tot_loss_proj:3.932 [t=0.18s]
prediction: ['[CLS] originally solve 我 sounds you nautical sooner this the sooner the folks up wonderful corporate cannot problem that resource instead 1 now. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.192 (perp=9.865, rec=0.193, cos=0.026), tot_loss_proj:3.908 [t=0.18s]
prediction: ['[CLS] you solve trends sounds originally nautical sooner this the sooner the folks up wonderful corporate cannot problem that resource instead 1 now. [SEP]']
[1350/2000] tot_loss=2.196 (perp=9.865, rec=0.197, cos=0.026), tot_loss_proj:3.910 [t=0.18s]
prediction: ['[CLS] you solve trends sounds originally nautical sooner this the sooner the folks up wonderful corporate cannot problem that resource instead 1 now. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.202 (perp=9.932, rec=0.189, cos=0.026), tot_loss_proj:3.915 [t=0.18s]
prediction: ['[CLS] you solve 我 sounds thisestinal sooner originally the sooner the folks up wonderful corporate cannot problem that resource instead 1 now. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.147 (perp=9.634, rec=0.192, cos=0.028), tot_loss_proj:3.858 [t=0.18s]
prediction: ['[CLS] you solve trends this soundsestinal sooner originally the sooner the folks up wonderful corporate cannot problem that resource instead 1 now. [SEP]']
[1500/2000] tot_loss=2.066 (perp=9.274, rec=0.185, cos=0.027), tot_loss_proj:3.816 [t=0.18s]
prediction: ['[CLS] you solve sooner this soundsestinal sooner originally the sooner the folks up great corporate cannot problem that resource instead 1 now. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.046 (perp=9.182, rec=0.183, cos=0.026), tot_loss_proj:3.787 [t=0.18s]
prediction: ['[CLS] you solve sooner this sounds sooner originally theestinal sooner the folks up great corporate cannot problem that resource instead 1 now. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.960 (perp=8.730, rec=0.186, cos=0.028), tot_loss_proj:3.711 [t=0.18s]
prediction: ['[CLS] you solve sooner this sounds sooner originally theestinal sooner the folks up great corporate resource problem that must instead 1 now. [SEP]']
[1650/2000] tot_loss=2.007 (perp=8.975, rec=0.185, cos=0.027), tot_loss_proj:3.750 [t=0.18s]
prediction: ['[CLS] you solve sooner this sounds sooner originally theestinal sooner the folks up great corporate resource problem that cannot instead 1 now. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.954 (perp=8.714, rec=0.184, cos=0.027), tot_loss_proj:3.669 [t=0.18s]
prediction: ['[CLS] you solve sooner this sounds sooner originally the herbs sooner the folks up great corporate resource problem that instead 1 cannot now. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.005 (perp=8.970, rec=0.183, cos=0.028), tot_loss_proj:3.738 [t=0.18s]
prediction: ['[CLS] you solve sooner this sounds sooner originallyestinal the sooner the folks up great corporate resource problem that instead 1 cannot now. [SEP]']
[1800/2000] tot_loss=1.954 (perp=8.699, rec=0.187, cos=0.027), tot_loss_proj:3.689 [t=0.18s]
prediction: ['[CLS] you solve sooner this sounds sooner originally herbs the sooner the folks up great corporate resource problem that instead when cannot now. [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=2.002 (perp=8.929, rec=0.188, cos=0.028), tot_loss_proj:3.725 [t=0.18s]
prediction: ['[CLS] you solve this results sooner originallyestinal sooner the sooner the folks up great corporate resource problem that instead when cannot now. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.940 (perp=8.648, rec=0.184, cos=0.027), tot_loss_proj:3.659 [t=0.18s]
prediction: ['[CLS] you solve this results sooner originally herbs sooner the sooner the folks up great corporate resource problem that instead when cannot now. [SEP]']
[1950/2000] tot_loss=2.020 (perp=9.075, rec=0.178, cos=0.027), tot_loss_proj:3.733 [t=0.18s]
prediction: ['[CLS] you solve this results sooner originally herbs 我 the sooner the folks up great corporate resource problem that instead when cannot now. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.952 (perp=8.747, rec=0.177, cos=0.026), tot_loss_proj:3.666 [t=0.18s]
prediction: ['[CLS] you solve this problem sooner originally herbs 我 the sooner the folks up great corporate resource results that instead when cannot now. [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]
========================
predicted: 
========================
[CLS] you solve this results sooner originally herbs 我 the sooner the folks up great corporate resource problem that instead when cannot now. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.522 | p: 56.522 | r: 56.522
rouge2     | fm: 22.727 | p: 22.727 | r: 22.727
rougeL     | fm: 39.130 | p: 39.130 | r: 39.130
rougeLsum  | fm: 39.130 | p: 39.130 | r: 39.130
r1fm+r2fm = 79.249

[Aggregate metrics]:
rouge1     | fm: 81.145 | p: 82.179 | r: 80.460
rouge2     | fm: 43.848 | p: 44.172 | r: 43.864
rougeL     | fm: 71.182 | p: 71.942 | r: 70.703
rougeLsum  | fm: 71.578 | p: 72.224 | r: 71.214
r1fm+r2fm = 124.993

input #13 time: 0:07:12 | total time: 1:37:54


Running input #14 of 100.
reference: 
========================
Mary has never kissed a man who is taller than John.
========================
Sample: 0 5.573861732463845e-13 0.05275441165216227 0.34857252
average of cosine similarity 0.9884811237670876
highest_index [0]
highest [0.9884811237670876]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2984,  2038,  2196,  4782,  1037,  2158,  2040,  2003, 12283,
          2084,  2198,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mary has never kissed a man who is taller than john. [SEP]']
[Init] best rec loss: 0.9541948437690735 for ['[CLS] isa jude jon force boysraction louise work tip bigger dick sets [SEP]']
[Init] best rec loss: 0.9414898753166199 for ['[CLS]nton integratinglor half inserted al locks cbright family exhibition range [SEP]']
[Init] best rec loss: 0.9376357793807983 for ['[CLS] tar * [SEP] pa jersey efforts partisans miniseries consecrated nominee humans [UNK] [SEP]']
[Init] best rec loss: 0.9275037050247192 for ['[CLS] somewhat high licensed practice story thick septembereira vector bottoms osaka causes [SEP]']
[Init] best rec loss: 0.8851785063743591 for ['[CLS] dimension ser phone visible sv dependent performed unique independence tipped gravity tha [SEP]']
[Init] best rec loss: 0.8732437491416931 for ['[CLS] smart grandderropolis personal drama playback president lest sought producerdened [SEP]']
[Init] best rec loss: 0.8478004932403564 for ['[CLS] claiming dragon hivmerie pace emersonws bandclass how socialist adult [SEP]']
[Init] best perm rec loss: 0.8447031378746033 for ['[CLS] dragon claimingmerie hiv bandclass howws socialist pace adult emerson [SEP]']
[Init] best perm rec loss: 0.836749255657196 for ['[CLS] adult pacemerie dragon hivclass band claiming emerson how socialistws [SEP]']
[Init] best perm rec loss: 0.8359105587005615 for ['[CLS] hiv adult pace dragon band socialistmerieclass how emerson claimingws [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.471 (perp=13.922, rec=0.465, cos=0.221), tot_loss_proj:4.690 [t=0.17s]
prediction: ['[CLS] bahn original john 2003 peers helen must soap john passport afterwards attraction [SEP]']
[ 100/2000] tot_loss=2.620 (perp=10.777, rec=0.374, cos=0.091), tot_loss_proj:4.043 [t=0.17s]
prediction: ['[CLS] ryan his mary kissed pop mary.. mary passport afterwards dvd [SEP]']
[ 150/2000] tot_loss=2.198 (perp=8.973, rec=0.330, cos=0.074), tot_loss_proj:3.729 [t=0.17s]
prediction: ['[CLS] john never mary kissed junior john.. mary passport afterwards never [SEP]']
[ 200/2000] tot_loss=2.241 (perp=9.706, rec=0.251, cos=0.049), tot_loss_proj:3.862 [t=0.17s]
prediction: ['[CLS] john never mary kissed taller john has. mary tournament afterwards never [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.457 (perp=10.986, rec=0.222, cos=0.038), tot_loss_proj:4.077 [t=0.17s]
prediction: ['[CLS] john never mary kissed higher john kissed never. mary tournament exists [SEP]']
[ 300/2000] tot_loss=2.365 (perp=10.725, rec=0.192, cos=0.029), tot_loss_proj:3.987 [t=0.17s]
prediction: ['[CLS] john never mary man higher called kissed never. mary tournament exists [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.185 (perp=9.597, rec=0.228, cos=0.038), tot_loss_proj:3.816 [t=0.17s]
prediction: ['[CLS] john never mary man junior when kissed. unlike mary tournament exists [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.312 (perp=10.538, rec=0.175, cos=0.029), tot_loss_proj:4.030 [t=0.17s]
prediction: ['[CLS] john never mary man taller when kissed mary. unlike tournament varies [SEP]']
[ 450/2000] tot_loss=2.237 (perp=10.219, rec=0.165, cos=0.028), tot_loss_proj:3.931 [t=0.17s]
prediction: ['[CLS] john never mary man taller. kissed mary. unlike taller varies [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.961 (perp=8.823, rec=0.168, cos=0.028), tot_loss_proj:3.620 [t=0.17s]
prediction: ['[CLS] john never mary taller man. kissed john. never taller exists [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.919 (perp=8.598, rec=0.171, cos=0.029), tot_loss_proj:3.566 [t=0.17s]
prediction: ['[CLS] john never taller mary man. kissed john. never taller varies [SEP]']
[ 600/2000] tot_loss=1.809 (perp=8.118, rec=0.158, cos=0.027), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] john never taller mary man. kissed john. never taller exists [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.858 (perp=8.434, rec=0.145, cos=0.026), tot_loss_proj:3.567 [t=0.17s]
prediction: ['[CLS] john never taller. man mary kissed is. never taller exists [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.684 (perp=7.545, rec=0.150, cos=0.026), tot_loss_proj:3.427 [t=0.19s]
prediction: ['[CLS] john never taller. man mary is kissed. never taller exists [SEP]']
[ 750/2000] tot_loss=1.679 (perp=7.545, rec=0.145, cos=0.025), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS] john never taller. man mary is kissed. never taller exists [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.676 (perp=7.545, rec=0.142, cos=0.025), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS] john never taller. man mary is kissed. never taller exists [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.618 (perp=7.013, rec=0.179, cos=0.037), tot_loss_proj:3.286 [t=0.17s]
prediction: ['[CLS] john never taller man mary is kissed. never taller exists. [SEP]']
[ 900/2000] tot_loss=1.584 (perp=7.013, rec=0.153, cos=0.028), tot_loss_proj:3.282 [t=0.17s]
prediction: ['[CLS] john never taller man mary is kissed. never taller exists. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.490 (perp=6.572, rec=0.148, cos=0.027), tot_loss_proj:3.219 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller exists. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.492 (perp=6.572, rec=0.150, cos=0.027), tot_loss_proj:3.215 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller exists. [SEP]']
[1050/2000] tot_loss=1.531 (perp=6.796, rec=0.146, cos=0.027), tot_loss_proj:3.293 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller whatsoever. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.511 (perp=6.670, rec=0.150, cos=0.026), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.501 (perp=6.670, rec=0.141, cos=0.026), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
[1200/2000] tot_loss=1.515 (perp=6.670, rec=0.155, cos=0.026), tot_loss_proj:3.254 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.500 (perp=6.670, rec=0.141, cos=0.026), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.503 (perp=6.670, rec=0.143, cos=0.026), tot_loss_proj:3.255 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
[1350/2000] tot_loss=1.500 (perp=6.670, rec=0.141, cos=0.026), tot_loss_proj:3.255 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.498 (perp=6.670, rec=0.139, cos=0.026), tot_loss_proj:3.250 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.500 (perp=6.670, rec=0.140, cos=0.025), tot_loss_proj:3.256 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
[1500/2000] tot_loss=1.495 (perp=6.670, rec=0.135, cos=0.025), tot_loss_proj:3.256 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.503 (perp=6.670, rec=0.144, cos=0.025), tot_loss_proj:3.258 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.502 (perp=6.670, rec=0.143, cos=0.025), tot_loss_proj:3.253 [t=0.18s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
[1650/2000] tot_loss=1.499 (perp=6.670, rec=0.139, cos=0.025), tot_loss_proj:3.251 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.489 (perp=6.670, rec=0.130, cos=0.025), tot_loss_proj:3.254 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.500 (perp=6.670, rec=0.141, cos=0.025), tot_loss_proj:3.253 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
[1800/2000] tot_loss=1.491 (perp=6.670, rec=0.132, cos=0.025), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.504 (perp=6.670, rec=0.145, cos=0.025), tot_loss_proj:3.255 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.492 (perp=6.670, rec=0.133, cos=0.025), tot_loss_proj:3.255 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
[1950/2000] tot_loss=1.494 (perp=6.670, rec=0.136, cos=0.025), tot_loss_proj:3.254 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.487 (perp=6.670, rec=0.128, cos=0.025), tot_loss_proj:3.251 [t=0.17s]
prediction: ['[CLS] john never taller kissed mary is man. never taller than. [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] mary has never kissed a man who is taller than john. [SEP]
========================
predicted: 
========================
[CLS] john never taller kissed mary is man. never taller than. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 83.333 | r: 76.923
rouge2     | fm: 8.696 | p: 9.091 | r: 8.333
rougeL     | fm: 56.000 | p: 58.333 | r: 53.846
rougeLsum  | fm: 56.000 | p: 58.333 | r: 53.846
r1fm+r2fm = 88.696

[Aggregate metrics]:
rouge1     | fm: 81.180 | p: 82.291 | r: 80.446
rouge2     | fm: 41.393 | p: 41.722 | r: 41.280
rougeL     | fm: 70.076 | p: 70.924 | r: 69.721
rougeLsum  | fm: 70.341 | p: 71.093 | r: 69.756
r1fm+r2fm = 122.573

input #14 time: 0:07:03 | total time: 1:44:58


Running input #15 of 100.
reference: 
========================
After ten soldiers had left, seven more ones came in.
========================
Sample: 0 1.1614462074372251e-11 0.047900472438259685 0.35100156
average of cosine similarity 0.9906445123471554
highest_index [0]
highest [0.9906445123471554]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2044, 2702, 3548, 2018, 2187, 1010, 2698, 2062, 3924, 2234, 1999,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] after ten soldiers had left, seven more ones came in. [SEP]']
[Init] best rec loss: 0.9528211951255798 for ['[CLS] war ne soaking kelly moment another carried ahead fk inches chasing deal [SEP]']
[Init] best rec loss: 0.855108380317688 for ['[CLS] clear love instrument patient commentaryhipversder cowboys progression what tens [SEP]']
[Init] best rec loss: 0.75975501537323 for ['[CLS] trainedpower mere exception meeting spokanemin cash vested large myselffish [SEP]']
[Init] best rec loss: 0.741703987121582 for ['[CLS] cared completely serial attestedbria within averageyriagal /vao job [SEP]']
[Init] best rec loss: 0.7361224889755249 for ['[CLS]d club linked bachelor awfe honored after award wu common ~ [SEP]']
[Init] best perm rec loss: 0.7350735068321228 for ['[CLS]fe award wud ~ linked common aw bachelor club after honored [SEP]']
[Init] best perm rec loss: 0.7331072092056274 for ['[CLS] common bachelor clubfe ~ aw award wud after honored linked [SEP]']
[Init] best perm rec loss: 0.7300412654876709 for ['[CLS]d ~fe bachelor aw award honored wu after club linked common [SEP]']
[Init] best perm rec loss: 0.7290026545524597 for ['[CLS] linked honored wu ~ bachelor club afterfe awd common award [SEP]']
[Init] best perm rec loss: 0.728809654712677 for ['[CLS] aw honored linked wu club award bachelor afterd common ~fe [SEP]']
[Init] best perm rec loss: 0.728542149066925 for ['[CLS] clubd linked honored aw wu afterfe ~ common award bachelor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.248 (perp=9.344, rec=0.323, cos=0.057), tot_loss_proj:3.256 [t=0.17s]
prediction: ['[CLS] four seven ones saving six more earlier one more upon ones in [SEP]']
[ 100/2000] tot_loss=2.292 (perp=9.779, rec=0.293, cos=0.043), tot_loss_proj:3.452 [t=0.17s]
prediction: ['[CLS] seven ten ones had seven came ones one more ones ones in [SEP]']
[ 150/2000] tot_loss=2.200 (perp=9.498, rec=0.239, cos=0.062), tot_loss_proj:3.392 [t=0.17s]
prediction: ['[CLS] seven soldiers had had seven came ones one more ones ones in [SEP]']
[ 200/2000] tot_loss=1.968 (perp=8.716, rec=0.194, cos=0.030), tot_loss_proj:3.200 [t=0.17s]
prediction: ['[CLS] ten soldiers had had seven came after four more ones ones in [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.138 (perp=9.402, rec=0.216, cos=0.042), tot_loss_proj:3.366 [t=0.17s]
prediction: ['[CLS] ten soldiers had had seven came after ghost more ones ones in [SEP]']
[ 300/2000] tot_loss=1.640 (perp=7.144, rec=0.179, cos=0.032), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] ten soldiers had left seven came after three more ones ones. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.803 (perp=8.109, rec=0.152, cos=0.029), tot_loss_proj:2.965 [t=0.17s]
prediction: ['[CLS] ten soldiers had left seven came after three more ones ones in [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.703 (perp=7.617, rec=0.153, cos=0.026), tot_loss_proj:2.971 [t=0.17s]
prediction: ['[CLS] after soldiers had left seven came after three more ones ones in [SEP]']
[ 450/2000] tot_loss=1.590 (perp=6.862, rec=0.178, cos=0.039), tot_loss_proj:2.854 [t=0.17s]
prediction: ['[CLS] after soldiers had left seven came after four more ones ones. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.646 (perp=7.305, rec=0.150, cos=0.035), tot_loss_proj:2.845 [t=0.17s]
prediction: ['[CLS] after soldiers had left four, additional seven more ones ones in [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.955 (perp=8.134, rec=0.277, cos=0.051), tot_loss_proj:2.861 [t=0.17s]
prediction: ['[CLS] ten chariot soldiers had left, after seven more ones ones in [SEP]']
[ 600/2000] tot_loss=1.844 (perp=7.919, rec=0.221, cos=0.039), tot_loss_proj:3.016 [t=0.17s]
prediction: ['[CLS] ten soldiers soldiers had left, after seven more ones ones in [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.584 (perp=6.831, rec=0.184, cos=0.035), tot_loss_proj:2.757 [t=0.17s]
prediction: ['[CLS] after ten soldiers soldiers had left, seven more ones ones came [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.507 (perp=6.368, rec=0.198, cos=0.036), tot_loss_proj:2.561 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones in [SEP]']
[ 750/2000] tot_loss=1.470 (perp=6.368, rec=0.162, cos=0.035), tot_loss_proj:2.559 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones in [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.433 (perp=6.216, rec=0.157, cos=0.033), tot_loss_proj:2.308 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.420 (perp=6.216, rec=0.145, cos=0.032), tot_loss_proj:2.311 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
[ 900/2000] tot_loss=1.419 (perp=6.216, rec=0.145, cos=0.031), tot_loss_proj:2.314 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.417 (perp=6.216, rec=0.143, cos=0.030), tot_loss_proj:2.310 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
Attempt swap
[1000/2000] tot_loss=1.411 (perp=6.216, rec=0.138, cos=0.030), tot_loss_proj:2.314 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
[1050/2000] tot_loss=1.410 (perp=6.216, rec=0.138, cos=0.029), tot_loss_proj:2.318 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
Attempt swap
[1100/2000] tot_loss=1.404 (perp=6.216, rec=0.132, cos=0.029), tot_loss_proj:2.313 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
Attempt swap
[1150/2000] tot_loss=1.396 (perp=6.216, rec=0.124, cos=0.028), tot_loss_proj:2.312 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
[1200/2000] tot_loss=1.397 (perp=6.216, rec=0.125, cos=0.028), tot_loss_proj:2.311 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
Attempt swap
[1250/2000] tot_loss=1.399 (perp=6.216, rec=0.128, cos=0.028), tot_loss_proj:2.317 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
Attempt swap
[1300/2000] tot_loss=1.405 (perp=6.216, rec=0.135, cos=0.027), tot_loss_proj:2.316 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
[1350/2000] tot_loss=1.398 (perp=6.216, rec=0.128, cos=0.027), tot_loss_proj:2.319 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
Attempt swap
[1400/2000] tot_loss=1.396 (perp=6.216, rec=0.126, cos=0.027), tot_loss_proj:2.312 [t=0.17s]
prediction: ['[CLS] after ten soldiers ones had left, seven more soldiers ones came [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.491 (perp=6.637, rec=0.136, cos=0.027), tot_loss_proj:2.265 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
[1500/2000] tot_loss=1.491 (perp=6.637, rec=0.138, cos=0.026), tot_loss_proj:2.273 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
Attempt swap
[1550/2000] tot_loss=1.483 (perp=6.637, rec=0.129, cos=0.026), tot_loss_proj:2.264 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
Attempt swap
[1600/2000] tot_loss=1.479 (perp=6.637, rec=0.125, cos=0.026), tot_loss_proj:2.260 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
[1650/2000] tot_loss=1.474 (perp=6.637, rec=0.120, cos=0.026), tot_loss_proj:2.265 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
Attempt swap
[1700/2000] tot_loss=1.488 (perp=6.637, rec=0.134, cos=0.026), tot_loss_proj:2.263 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
Attempt swap
[1750/2000] tot_loss=1.472 (perp=6.637, rec=0.119, cos=0.026), tot_loss_proj:2.268 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
[1800/2000] tot_loss=1.482 (perp=6.637, rec=0.129, cos=0.026), tot_loss_proj:2.262 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
Attempt swap
[1850/2000] tot_loss=1.476 (perp=6.637, rec=0.122, cos=0.026), tot_loss_proj:2.270 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
Attempt swap
[1900/2000] tot_loss=1.474 (perp=6.637, rec=0.121, cos=0.026), tot_loss_proj:2.266 [t=0.19s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
[1950/2000] tot_loss=1.477 (perp=6.637, rec=0.124, cos=0.026), tot_loss_proj:2.265 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
Attempt swap
[2000/2000] tot_loss=1.469 (perp=6.637, rec=0.116, cos=0.026), tot_loss_proj:2.270 [t=0.17s]
prediction: ['[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] after ten soldiers had left, seven more ones came in. [SEP]
========================
predicted: 
========================
[CLS] after soldiers ones had left, seven more after soldiers ones came [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 76.923 | r: 83.333
rouge2     | fm: 43.478 | p: 41.667 | r: 45.455
rougeL     | fm: 80.000 | p: 76.923 | r: 83.333
rougeLsum  | fm: 80.000 | p: 76.923 | r: 83.333
r1fm+r2fm = 123.478

[Aggregate metrics]:
rouge1     | fm: 80.782 | p: 81.841 | r: 80.485
rouge2     | fm: 41.533 | p: 41.757 | r: 41.550
rougeL     | fm: 70.474 | p: 71.204 | r: 70.134
rougeLsum  | fm: 70.783 | p: 71.404 | r: 70.467
r1fm+r2fm = 122.314

input #15 time: 0:06:54 | total time: 1:51:52


Running input #16 of 100.
reference: 
========================
Willy is taller than that Bill is is generally believed.
========================
Sample: 0 1.6216339661698669e-12 0.05300015441139243 0.35479248
average of cosine similarity 0.9887793864099028
highest_index [0]
highest [0.9887793864099028]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101, 16172,  2003, 12283,  2084,  2008,  3021,  2003,  2003,  3227,
          3373,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] willy is taller than that bill is is generally believed. [SEP]']
[Init] best rec loss: 0.7902119755744934 for ['[CLS] g shared jump inch addition ted poker feel show paul initiative [SEP]']
[Init] best rec loss: 0.739452064037323 for ['[CLS]ette water home campus ceilingblood hillary appeared unfamiliar dead spend [SEP]']
[Init] best rec loss: 0.7369779944419861 for ['[CLS] selection clubs organized us it earl rates colby guardseptive battery [SEP]']
[Init] best rec loss: 0.7346456050872803 for ['[CLS] identified clap ego jurisdiction cop connection term corinne beans probable family [SEP]']
[Init] best rec loss: 0.7262424826622009 for ['[CLS] baysfully occupation volunteers songs andrei punk wheat calls espn erie [SEP]']
[Init] best rec loss: 0.7223520278930664 for ['[CLS] halfway ˢ folkhedblesches trainee itsescor indoor [SEP]']
[Init] best rec loss: 0.7212710976600647 for ['[CLS] behind reconciliation clues eventually indeed genesis king swung西 dec questions [SEP]']
[Init] best rec loss: 0.7075098156929016 for ['[CLS] and molecular beating than driveated become distance baronet mass public [SEP]']
[Init] best rec loss: 0.6890419721603394 for ['[CLS] fashionunt wood freedom finale drake trail incumbent much possibly away [SEP]']
[Init] best perm rec loss: 0.6884592771530151 for ['[CLS] freedomunt possibly wood away much trail incumbent drake fashion finale [SEP]']
[Init] best perm rec loss: 0.6877197623252869 for ['[CLS] possibly freedom trail finale drake fashion much awayunt wood incumbent [SEP]']
[Init] best perm rec loss: 0.6864833831787109 for ['[CLS] freedom possiblyunt wood fashion much incumbent trail away finale drake [SEP]']
[Init] best perm rec loss: 0.6856220960617065 for ['[CLS]unt wood finale fashion incumbent freedom trail away drake much possibly [SEP]']
[Init] best perm rec loss: 0.6856174468994141 for ['[CLS] fashion drake wood much finale possiblyunt trail away freedom incumbent [SEP]']
[Init] best perm rec loss: 0.6853880286216736 for ['[CLS] fashion finale drake away incumbent woodunt trail freedom much possibly [SEP]']
[Init] best perm rec loss: 0.6851638555526733 for ['[CLS] fashion woodunt finale much trail possibly drake incumbent freedom away [SEP]']
[Init] best perm rec loss: 0.6823499798774719 for ['[CLS] trail possibly fashion awayunt wood finale much freedom incumbent drake [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.494 (perp=10.348, rec=0.346, cos=0.078), tot_loss_proj:3.016 [t=0.17s]
prediction: ['[CLS] steve is is is billsity is is £ philip? [SEP]']
[ 100/2000] tot_loss=2.227 (perp=9.616, rec=0.264, cos=0.040), tot_loss_proj:3.128 [t=0.17s]
prediction: ['[CLS] willy is that was taller told is is willy philip? [SEP]']
[ 150/2000] tot_loss=2.402 (perp=10.044, rec=0.315, cos=0.078), tot_loss_proj:2.907 [t=0.17s]
prediction: ['[CLS] willy is than that taller is is is is justin believed [SEP]']
[ 200/2000] tot_loss=2.274 (perp=10.389, rec=0.163, cos=0.033), tot_loss_proj:3.008 [t=0.17s]
prediction: ['[CLS] bill is than that taller bill has is is behaved believed [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.120 (perp=9.675, rec=0.152, cos=0.033), tot_loss_proj:3.345 [t=0.17s]
prediction: ['[CLS] bill is than that taller bill is is behaved is believed [SEP]']
[ 300/2000] tot_loss=2.178 (perp=10.142, rec=0.124, cos=0.026), tot_loss_proj:3.036 [t=0.17s]
prediction: ['[CLS] bill is than that taller bill usually is behaved generally believed [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.804 (perp=8.276, rec=0.123, cos=0.026), tot_loss_proj:2.621 [t=0.17s]
prediction: ['[CLS] bill is believed that taller bill usually is willy generally than [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.766 (perp=8.170, rec=0.108, cos=0.023), tot_loss_proj:2.348 [t=0.17s]
prediction: ['[CLS] bill is believed that taller bill willy is usually generally than [SEP]']
[ 450/2000] tot_loss=1.763 (perp=8.170, rec=0.106, cos=0.023), tot_loss_proj:2.345 [t=0.17s]
prediction: ['[CLS] bill is believed that taller bill willy is usually generally than [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.659 (perp=7.680, rec=0.101, cos=0.023), tot_loss_proj:2.789 [t=0.17s]
prediction: ['[CLS] bill is believed that taller bill than willy is usually generally [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.639 (perp=7.580, rec=0.100, cos=0.023), tot_loss_proj:2.752 [t=0.17s]
prediction: ['[CLS] bill is believed that taller bill than willy is generally usually [SEP]']
[ 600/2000] tot_loss=1.637 (perp=7.580, rec=0.099, cos=0.022), tot_loss_proj:2.753 [t=0.17s]
prediction: ['[CLS] bill is believed that taller bill than willy is generally usually [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.571 (perp=7.290, rec=0.091, cos=0.022), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] bill is believed that taller bill than willy is generally believed [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.490 (perp=6.778, rec=0.109, cos=0.025), tot_loss_proj:2.485 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
[ 750/2000] tot_loss=1.467 (perp=6.778, rec=0.089, cos=0.022), tot_loss_proj:2.470 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.459 (perp=6.778, rec=0.081, cos=0.022), tot_loss_proj:2.474 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.466 (perp=6.778, rec=0.089, cos=0.022), tot_loss_proj:2.471 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
[ 900/2000] tot_loss=1.476 (perp=6.778, rec=0.098, cos=0.022), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.474 (perp=6.778, rec=0.096, cos=0.022), tot_loss_proj:2.470 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
Attempt swap
[1000/2000] tot_loss=1.466 (perp=6.778, rec=0.088, cos=0.022), tot_loss_proj:2.471 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
[1050/2000] tot_loss=1.468 (perp=6.778, rec=0.090, cos=0.022), tot_loss_proj:2.472 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
Attempt swap
[1100/2000] tot_loss=1.455 (perp=6.778, rec=0.077, cos=0.022), tot_loss_proj:2.474 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
Attempt swap
[1150/2000] tot_loss=1.459 (perp=6.778, rec=0.081, cos=0.022), tot_loss_proj:2.477 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
[1200/2000] tot_loss=1.464 (perp=6.778, rec=0.086, cos=0.022), tot_loss_proj:2.471 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
Attempt swap
[1250/2000] tot_loss=1.463 (perp=6.778, rec=0.085, cos=0.022), tot_loss_proj:2.473 [t=0.17s]
prediction: ['[CLS] bill is believed that bill taller than willy is generally believed [SEP]']
Attempt swap
[1300/2000] tot_loss=1.601 (perp=7.466, rec=0.085, cos=0.022), tot_loss_proj:2.560 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally believed [SEP]']
[1350/2000] tot_loss=1.597 (perp=7.466, rec=0.081, cos=0.023), tot_loss_proj:2.557 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally believed [SEP]']
Attempt swap
[1400/2000] tot_loss=1.433 (perp=6.632, rec=0.084, cos=0.023), tot_loss_proj:2.319 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.427 (perp=6.632, rec=0.078, cos=0.023), tot_loss_proj:2.313 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
[1500/2000] tot_loss=1.436 (perp=6.632, rec=0.087, cos=0.023), tot_loss_proj:2.319 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.434 (perp=6.632, rec=0.085, cos=0.023), tot_loss_proj:2.325 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.431 (perp=6.632, rec=0.082, cos=0.023), tot_loss_proj:2.317 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
[1650/2000] tot_loss=1.435 (perp=6.632, rec=0.086, cos=0.023), tot_loss_proj:2.323 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.433 (perp=6.632, rec=0.084, cos=0.023), tot_loss_proj:2.320 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.425 (perp=6.632, rec=0.076, cos=0.023), tot_loss_proj:2.322 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
[1800/2000] tot_loss=1.429 (perp=6.632, rec=0.079, cos=0.023), tot_loss_proj:2.313 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.434 (perp=6.632, rec=0.085, cos=0.023), tot_loss_proj:2.325 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.424 (perp=6.632, rec=0.074, cos=0.023), tot_loss_proj:2.321 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
[1950/2000] tot_loss=1.437 (perp=6.632, rec=0.088, cos=0.023), tot_loss_proj:2.322 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.434 (perp=6.632, rec=0.085, cos=0.023), tot_loss_proj:2.322 [t=0.17s]
prediction: ['[CLS] willy is believed that bill taller than willy is generally. [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] willy is taller than that bill is is generally believed. [SEP]
========================
predicted: 
========================
[CLS] willy is believed that bill taller than willy is generally. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 45.455 | p: 45.455 | r: 45.455
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 137.121

[Aggregate metrics]:
rouge1     | fm: 81.565 | p: 82.447 | r: 81.004
rouge2     | fm: 42.075 | p: 42.265 | r: 42.156
rougeL     | fm: 70.162 | p: 70.804 | r: 70.046
rougeLsum  | fm: 70.085 | p: 70.643 | r: 69.865
r1fm+r2fm = 123.641

input #16 time: 0:06:55 | total time: 1:58:47


Running input #17 of 100.
reference: 
========================
José is eating cabbage, and Holly is too.
========================
Sample: 0 2.36784438024116e-12 0.05559507934489011 0.3545884
average of cosine similarity 0.9876322713714196
highest_index [0]
highest [0.9876322713714196]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  4560,  2003,  5983, 28540,  1010,  1998,  9079,  2003,  2205,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] jose is eating cabbage, and holly is too. [SEP]']
[Init] best rec loss: 0.9251716136932373 for ['[CLS] happenedgil revolution parallelsta right finding flag taiwan bella [SEP]']
[Init] best rec loss: 0.9144431352615356 for ['[CLS] no fleet rep chapter what honor fact double team suite [SEP]']
[Init] best rec loss: 0.9132050275802612 for ['[CLS] horse apartment sureɛ movement falls lordient linear college [SEP]']
[Init] best rec loss: 0.8915717005729675 for ['[CLS] adaptation recurring core ( such jersey each committee minor measures [SEP]']
[Init] best perm rec loss: 0.8897882699966431 for ['[CLS] such minor each jersey committee adaptation ( recurring measures core [SEP]']
[Init] best perm rec loss: 0.8891519904136658 for ['[CLS] committee adaptation such core measures jersey ( each recurring minor [SEP]']
[Init] best perm rec loss: 0.8880159854888916 for ['[CLS] adaptation ( committee measures each recurring jersey such core minor [SEP]']
[Init] best perm rec loss: 0.8873059153556824 for ['[CLS] committee adaptation each recurring minor measures core such jersey ( [SEP]']
[Init] best perm rec loss: 0.8865041136741638 for ['[CLS] jersey minor ( adaptation committee each measures recurring core such [SEP]']
[Init] best perm rec loss: 0.8843079805374146 for ['[CLS] minor jersey recurring each committee such core ( adaptation measures [SEP]']
[Init] best perm rec loss: 0.8835970759391785 for ['[CLS] measures jersey core recurring adaptation ( each such committee minor [SEP]']
[Init] best perm rec loss: 0.8828936815261841 for ['[CLS] jersey measures each adaptation recurring committee ( such core minor [SEP]']
[Init] best perm rec loss: 0.8816406726837158 for ['[CLS] jersey adaptation each ( such minor core committee recurring measures [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.601 (perp=9.844, rec=0.636, cos=0.997), tot_loss_proj:3.861 [t=0.17s]
prediction: ['[CLS]. pagoda too drank immediately. is should but is [SEP]']
[ 100/2000] tot_loss=3.511 (perp=10.198, rec=0.472, cos=0.999), tot_loss_proj:3.857 [t=0.17s]
prediction: ['[CLS] gnu!aya drank. ; is is too is [SEP]']
[ 150/2000] tot_loss=3.309 (perp=9.616, rec=0.387, cos=0.999), tot_loss_proj:3.719 [t=0.17s]
prediction: ['[CLS]rdial eating cabbage herbal is ; is is too. [SEP]']
[ 200/2000] tot_loss=3.184 (perp=9.269, rec=0.331, cos=0.999), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS]rdial eating cabbage herbal. ;folia is too. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.649 (perp=11.420, rec=0.366, cos=0.999), tot_loss_proj:4.057 [t=0.17s]
prediction: ['[CLS] highness cabbage eating herbal. ;folia is too holly [SEP]']
[ 300/2000] tot_loss=3.795 (perp=12.517, rec=0.292, cos=1.000), tot_loss_proj:4.280 [t=0.17s]
prediction: ['[CLS] highness cabbage eating linnaeus and ;folia is too holly [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.080 (perp=8.681, rec=0.345, cos=0.998), tot_loss_proj:3.411 [t=0.17s]
prediction: ['[CLS] got are cabbage eating and holly faber is too. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.337 (perp=10.149, rec=0.309, cos=0.998), tot_loss_proj:3.858 [t=0.17s]
prediction: ['[CLS] representsrrado cabbage and eating holly indeed is too holly [SEP]']
[ 450/2000] tot_loss=3.598 (perp=11.567, rec=0.286, cos=0.999), tot_loss_proj:4.046 [t=0.17s]
prediction: ['[CLS] representsrrado is and eating holly monarchy is too holly [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.210 (perp=9.673, rec=0.277, cos=0.999), tot_loss_proj:3.729 [t=0.17s]
prediction: ['[CLS] represents jacket is eating holly andweed is too holly [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.246 (perp=9.772, rec=0.293, cos=0.999), tot_loss_proj:3.770 [t=0.17s]
prediction: ['[CLS] represents jacket ო is eating holly and is too holly [SEP]']
[ 600/2000] tot_loss=3.215 (perp=9.772, rec=0.261, cos=0.999), tot_loss_proj:3.766 [t=0.17s]
prediction: ['[CLS] represents jacket ო is eating holly and is too holly [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.353 (perp=10.403, rec=0.273, cos=0.999), tot_loss_proj:3.858 [t=0.17s]
prediction: ['[CLS] jacket alzheimer ო is eating holly and is too holly [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.254 (perp=9.914, rec=0.271, cos=1.000), tot_loss_proj:3.754 [t=0.17s]
prediction: ['[CLS] 氵 pens ო is eating holly and is too holly [SEP]']
[ 750/2000] tot_loss=3.249 (perp=9.914, rec=0.267, cos=1.000), tot_loss_proj:3.755 [t=0.17s]
prediction: ['[CLS] 氵 pens ო is eating holly and is too holly [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.342 (perp=10.470, rec=0.248, cos=1.000), tot_loss_proj:3.885 [t=0.17s]
prediction: ['[CLS] alzheimer ო is 氵 eating holly and is too holly [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.239 (perp=9.881, rec=0.263, cos=1.000), tot_loss_proj:3.719 [t=0.17s]
prediction: ['[CLS] ო pens is 氵 eating holly and is too holly [SEP]']
[ 900/2000] tot_loss=3.230 (perp=9.881, rec=0.254, cos=1.000), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] ო pens is 氵 eating holly and is too holly [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=3.193 (perp=9.694, rec=0.254, cos=1.000), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] plants ო is 氵 eating holly and is too holly [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.282 (perp=10.113, rec=0.260, cos=1.000), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS] ო is 氵 eating hollyelial and is too holly [SEP]']
[1050/2000] tot_loss=3.268 (perp=10.113, rec=0.246, cos=1.000), tot_loss_proj:3.797 [t=0.17s]
prediction: ['[CLS] ო is 氵 eating hollyelial and is too holly [SEP]']
Attempt swap
[1100/2000] tot_loss=3.347 (perp=10.534, rec=0.240, cos=1.000), tot_loss_proj:3.914 [t=0.17s]
prediction: ['[CLS] ო is 氵 eating joseelial and is too holly [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=3.349 (perp=10.508, rec=0.247, cos=1.000), tot_loss_proj:3.903 [t=0.17s]
prediction: ['[CLS] ო 氵 is eating jose ⁻ and is too holly [SEP]']
[1200/2000] tot_loss=3.326 (perp=10.413, rec=0.244, cos=1.000), tot_loss_proj:3.903 [t=0.17s]
prediction: ['[CLS]》 氵 is eating jose ⁻ and is too holly [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=3.316 (perp=10.351, rec=0.246, cos=1.000), tot_loss_proj:3.879 [t=0.17s]
prediction: ['[CLS] ო 氵 is ⁻ eating jose and is too holly [SEP]']
Attempt swap
[1300/2000] tot_loss=3.314 (perp=10.351, rec=0.243, cos=1.000), tot_loss_proj:3.876 [t=0.17s]
prediction: ['[CLS] ო 氵 is ⁻ eating jose and is too holly [SEP]']
[1350/2000] tot_loss=3.269 (perp=10.185, rec=0.232, cos=1.000), tot_loss_proj:3.863 [t=0.17s]
prediction: ['[CLS]》 氵 is ⁻ eating jose and is too holly [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=3.223 (perp=9.926, rec=0.238, cos=1.000), tot_loss_proj:3.797 [t=0.17s]
prediction: ['[CLS]》 is ⁻ 氵 eating jose and is too holly [SEP]']
Attempt swap
[1450/2000] tot_loss=3.234 (perp=9.926, rec=0.249, cos=1.000), tot_loss_proj:3.797 [t=0.17s]
prediction: ['[CLS]》 is ⁻ 氵 eating jose and is too holly [SEP]']
[1500/2000] tot_loss=3.225 (perp=9.926, rec=0.240, cos=1.000), tot_loss_proj:3.793 [t=0.17s]
prediction: ['[CLS]》 is ⁻ 氵 eating jose and is too holly [SEP]']
Attempt swap
[1550/2000] tot_loss=3.225 (perp=9.926, rec=0.240, cos=1.000), tot_loss_proj:3.797 [t=0.17s]
prediction: ['[CLS]》 is ⁻ 氵 eating jose and is too holly [SEP]']
Attempt swap
[1600/2000] tot_loss=3.228 (perp=9.926, rec=0.243, cos=1.000), tot_loss_proj:3.793 [t=0.17s]
prediction: ['[CLS]》 is ⁻ 氵 eating jose and is too holly [SEP]']
[1650/2000] tot_loss=3.233 (perp=9.926, rec=0.248, cos=1.000), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS]》 is ⁻ 氵 eating jose and is too holly [SEP]']
Attempt swap
[1700/2000] tot_loss=3.221 (perp=9.926, rec=0.236, cos=1.000), tot_loss_proj:3.798 [t=0.17s]
prediction: ['[CLS]》 is ⁻ 氵 eating jose and is too holly [SEP]']
Attempt swap
[1750/2000] tot_loss=3.228 (perp=9.926, rec=0.243, cos=1.000), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS]》 is ⁻ 氵 eating jose and is too holly [SEP]']
[1800/2000] tot_loss=3.230 (perp=9.926, rec=0.245, cos=1.000), tot_loss_proj:3.791 [t=0.17s]
prediction: ['[CLS]》 is ⁻ 氵 eating jose and is too holly [SEP]']
Attempt swap
[1850/2000] tot_loss=3.189 (perp=9.749, rec=0.240, cos=1.000), tot_loss_proj:3.748 [t=0.17s]
prediction: ['[CLS]》 is enjoyed 氵 eating jose and is too holly [SEP]']
Attempt swap
[1900/2000] tot_loss=3.199 (perp=9.749, rec=0.250, cos=1.000), tot_loss_proj:3.749 [t=0.17s]
prediction: ['[CLS]》 is enjoyed 氵 eating jose and is too holly [SEP]']
[1950/2000] tot_loss=3.189 (perp=9.749, rec=0.239, cos=1.000), tot_loss_proj:3.746 [t=0.17s]
prediction: ['[CLS]》 is enjoyed 氵 eating jose and is too holly [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=3.157 (perp=9.569, rec=0.244, cos=1.000), tot_loss_proj:3.681 [t=0.19s]
prediction: ['[CLS]》 氵 is enjoyed eating jose and is too holly [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] jose is eating cabbage, and holly is too. [SEP]
========================
predicted: 
========================
[CLS]》 is ⁻ 氵 eating jose and is too holly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 100.000 | r: 90.000
rouge2     | fm: 23.529 | p: 25.000 | r: 22.222
rougeL     | fm: 73.684 | p: 77.778 | r: 70.000
rougeLsum  | fm: 73.684 | p: 77.778 | r: 70.000
r1fm+r2fm = 118.266

[Aggregate metrics]:
rouge1     | fm: 82.383 | p: 83.393 | r: 81.708
rouge2     | fm: 40.902 | p: 41.195 | r: 40.841
rougeL     | fm: 70.578 | p: 71.472 | r: 70.187
rougeLsum  | fm: 70.362 | p: 71.198 | r: 69.957
r1fm+r2fm = 123.285

input #17 time: 0:07:06 | total time: 2:05:54


Running input #18 of 100.
reference: 
========================
John demanded that she stop phoning him.
========================
Sample: 0 1.415320779506746e-12 0.049764998210817854 0.36407825
average of cosine similarity 0.9906141635861401
highest_index [0]
highest [0.9906141635861401]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2198,  6303,  2008,  2016,  2644,  6887, 13369,  2032,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] john demanded that she stop phoning him. [SEP]']
[Init] best rec loss: 0.9877802133560181 for ['[CLS] layton fewer consult school lu bounced choose switzerland years [SEP]']
[Init] best rec loss: 0.9811486005783081 for ['[CLS] union contact n sight oldest songs monumentalbal crow [SEP]']
[Init] best rec loss: 0.9715001583099365 for ['[CLS] state oceandd lionner marx sensorycute monthly [SEP]']
[Init] best rec loss: 0.9666527509689331 for ['[CLS] tattooformsmorphic through rogers signed asktaka commons [SEP]']
[Init] best rec loss: 0.9620587825775146 for ['[CLS] sole askʂ waste bull wing imperial were discovered [SEP]']
[Init] best rec loss: 0.9581156969070435 for ['[CLS] suggested possession terri paper [SEP] month ku tar 3000 [SEP]']
[Init] best rec loss: 0.9447695016860962 for ['[CLS] lamp third impact upon navy followed wheel sheila enough [SEP]']
[Init] best perm rec loss: 0.939691960811615 for ['[CLS] followed enough upon impact lamp third sheila navy wheel [SEP]']
[Init] best perm rec loss: 0.9373711347579956 for ['[CLS] impact enough sheila third followed navy lamp wheel upon [SEP]']
[Init] best perm rec loss: 0.9369447827339172 for ['[CLS] navy enough followed upon impact sheila lamp third wheel [SEP]']
[Init] best perm rec loss: 0.9368777275085449 for ['[CLS] lamp enough impact navy followed sheila upon wheel third [SEP]']
[Init] best perm rec loss: 0.9363468885421753 for ['[CLS] impact lamp enough wheel third upon navy followed sheila [SEP]']
[Init] best perm rec loss: 0.9349254965782166 for ['[CLS] wheel sheila enough followed impact upon lamp third navy [SEP]']
[Init] best perm rec loss: 0.9337619543075562 for ['[CLS] lamp enough impact navy followed upon sheila third wheel [SEP]']
[Init] best perm rec loss: 0.9319055080413818 for ['[CLS] enough upon sheila lamp impact followed navy wheel third [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.977 (perp=11.562, rec=0.667, cos=0.998), tot_loss_proj:4.214 [t=0.17s]
prediction: ['[CLS] talks necessity that sanctions, slammingted becomes studied [SEP]']
[ 100/2000] tot_loss=3.952 (perp=12.021, rec=0.555, cos=0.993), tot_loss_proj:4.304 [t=0.17s]
prediction: ['[CLS]oting demanded that kam. demanded demanded circles million [SEP]']
[ 150/2000] tot_loss=3.581 (perp=10.179, rec=0.592, cos=0.954), tot_loss_proj:3.855 [t=0.17s]
prediction: ['[CLS] ¿ asked that fraud, inquired static disappeared, [SEP]']
[ 200/2000] tot_loss=3.317 (perp=9.535, rec=0.501, cos=0.909), tot_loss_proj:3.834 [t=0.17s]
prediction: ['[CLS] demands asked thatoning,oning demanded disappearing. [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.328 (perp=9.467, rec=0.509, cos=0.925), tot_loss_proj:3.920 [t=0.17s]
prediction: ['[CLS] gentle demanded thatoning,oning demandedorestation. [SEP]']
[ 300/2000] tot_loss=3.364 (perp=10.225, rec=0.444, cos=0.875), tot_loss_proj:4.034 [t=0.17s]
prediction: ['[CLS] attempts demanded sheoning,oning demandedorestation. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.470 (perp=10.827, rec=0.469, cos=0.836), tot_loss_proj:4.134 [t=0.17s]
prediction: ['[CLS] everyone demanded thatoning, bacteria demanded tablet transmission [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.249 (perp=10.219, rec=0.441, cos=0.764), tot_loss_proj:3.931 [t=0.17s]
prediction: ['[CLS] clinton demanded sheoning elevatoroning demandedop, [SEP]']
[ 450/2000] tot_loss=3.004 (perp=10.475, rec=0.491, cos=0.418), tot_loss_proj:3.964 [t=0.17s]
prediction: ['[CLS] clinton demanded sheoning elevatoroning demanded tablet, [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=4.246 (perp=12.495, rec=0.756, cos=0.992), tot_loss_proj:4.303 [t=0.17s]
prediction: ['[CLS] someone caused mate divorce vladimironing.oning they [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=4.089 (perp=12.143, rec=0.667, cos=0.994), tot_loss_proj:4.350 [t=0.17s]
prediction: ['[CLS] someone requested mealoning divorce yahoooning states they [SEP]']
[ 600/2000] tot_loss=3.684 (perp=10.463, rec=0.591, cos=1.000), tot_loss_proj:4.149 [t=0.17s]
prediction: ['[CLS] someone demanded mealoning thatgenaseoning. ( [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.295 (perp=8.621, rec=0.573, cos=0.999), tot_loss_proj:3.695 [t=0.17s]
prediction: ['[CLS] they demanded thatoning lunchjordoning.. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.192 (perp=8.237, rec=0.546, cos=0.998), tot_loss_proj:3.523 [t=0.17s]
prediction: ['[CLS] they demanded that lunchoninggenaseoning.. [SEP]']
[ 750/2000] tot_loss=3.243 (perp=8.614, rec=0.528, cos=0.993), tot_loss_proj:3.660 [t=0.17s]
prediction: ['[CLS] they demanded that dinneroninggenaseoning.. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.175 (perp=8.350, rec=0.515, cos=0.990), tot_loss_proj:3.665 [t=0.17s]
prediction: ['[CLS] they demanded that dinneroninggenase.oning. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.153 (perp=8.350, rec=0.496, cos=0.987), tot_loss_proj:3.658 [t=0.17s]
prediction: ['[CLS] they demanded that dinneroninggenase.oning. [SEP]']
[ 900/2000] tot_loss=3.459 (perp=9.938, rec=0.488, cos=0.983), tot_loss_proj:3.968 [t=0.17s]
prediction: ['[CLS] they demanded that dinneroninggenase.oning they [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.501 (perp=9.808, rec=0.569, cos=0.970), tot_loss_proj:3.936 [t=0.17s]
prediction: ['[CLS] someone demanded that dinneroning yahoooning. ( [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.601 (perp=10.421, rec=0.548, cos=0.968), tot_loss_proj:4.026 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreen dinneroningoning. [ [SEP]']
[1050/2000] tot_loss=3.687 (perp=10.983, rec=0.523, cos=0.967), tot_loss_proj:4.136 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreen racehorseoningoning. [ [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.398 (perp=9.654, rec=0.506, cos=0.961), tot_loss_proj:3.882 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning dinneroning. [ [SEP]']
Attempt swap
[1150/2000] tot_loss=3.397 (perp=9.654, rec=0.506, cos=0.960), tot_loss_proj:3.886 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning dinneroning. [ [SEP]']
[1200/2000] tot_loss=3.392 (perp=9.654, rec=0.503, cos=0.958), tot_loss_proj:3.883 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning dinneroning. [ [SEP]']
Attempt swap
[1250/2000] tot_loss=3.382 (perp=9.654, rec=0.494, cos=0.957), tot_loss_proj:3.886 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning dinneroning. [ [SEP]']
Attempt swap
[1300/2000] tot_loss=3.375 (perp=9.654, rec=0.489, cos=0.956), tot_loss_proj:3.882 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning dinneroning. [ [SEP]']
[1350/2000] tot_loss=3.367 (perp=9.654, rec=0.482, cos=0.955), tot_loss_proj:3.884 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning dinneroning. [ [SEP]']
Attempt swap
[1400/2000] tot_loss=3.379 (perp=9.715, rec=0.482, cos=0.953), tot_loss_proj:3.897 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning lunchoning. [ [SEP]']
Attempt swap
[1450/2000] tot_loss=3.377 (perp=9.715, rec=0.482, cos=0.952), tot_loss_proj:3.898 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning lunchoning. [ [SEP]']
[1500/2000] tot_loss=3.370 (perp=9.715, rec=0.475, cos=0.952), tot_loss_proj:3.895 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning lunchoning. [ [SEP]']
Attempt swap
[1550/2000] tot_loss=3.370 (perp=9.715, rec=0.477, cos=0.950), tot_loss_proj:3.894 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning lunchoning. [ [SEP]']
Attempt swap
[1600/2000] tot_loss=3.363 (perp=9.715, rec=0.471, cos=0.949), tot_loss_proj:3.901 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning lunchoning. [ [SEP]']
[1650/2000] tot_loss=3.360 (perp=9.715, rec=0.469, cos=0.949), tot_loss_proj:3.897 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning lunchoning. [ [SEP]']
Attempt swap
[1700/2000] tot_loss=3.332 (perp=9.597, rec=0.464, cos=0.948), tot_loss_proj:3.842 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning lunchoning. they [SEP]']
Attempt swap
[1750/2000] tot_loss=3.538 (perp=10.601, rec=0.470, cos=0.948), tot_loss_proj:4.046 [t=0.17s]
prediction: ['[CLS] complications demanded thatcreenoning lunchoning. they [SEP]']
[1800/2000] tot_loss=3.537 (perp=10.601, rec=0.470, cos=0.947), tot_loss_proj:4.044 [t=0.17s]
prediction: ['[CLS] complications demanded thatcreenoning lunchoning. they [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=3.598 (perp=10.806, rec=0.482, cos=0.955), tot_loss_proj:4.070 [t=0.17s]
prediction: ['[CLS] [ demanded thatcreenoning lunchoning. armand [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=3.371 (perp=9.715, rec=0.477, cos=0.951), tot_loss_proj:3.897 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning lunchoning. [ [SEP]']
[1950/2000] tot_loss=3.359 (perp=9.715, rec=0.469, cos=0.947), tot_loss_proj:3.898 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning lunchoning. [ [SEP]']
Attempt swap
[2000/2000] tot_loss=3.355 (perp=9.715, rec=0.465, cos=0.947), tot_loss_proj:3.896 [t=0.17s]
prediction: ['[CLS] armand demanded thatcreenoning lunchoning. [ [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] john demanded that she stop phoning him. [SEP]
========================
predicted: 
========================
[CLS] clinton demanded sheoning elevatoroning demandedop, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 37.500 | p: 42.857 | r: 33.333
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 37.500 | p: 42.857 | r: 33.333
rougeLsum  | fm: 37.500 | p: 42.857 | r: 33.333
r1fm+r2fm = 37.500

[Aggregate metrics]:
rouge1     | fm: 79.921 | p: 81.175 | r: 79.096
rouge2     | fm: 38.916 | p: 39.181 | r: 38.894
rougeL     | fm: 68.681 | p: 69.815 | r: 68.153
rougeLsum  | fm: 68.637 | p: 69.615 | r: 68.128
r1fm+r2fm = 118.837

input #18 time: 0:06:59 | total time: 2:12:53


Running input #19 of 100.
reference: 
========================
I have six too many marbles.
========================
Sample: 0 1.5231697978996053e-10 0.044106759469395684 0.32018894
average of cosine similarity 0.9904666811481255
highest_index [0]
highest [0.9904666811481255]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 1045, 2031, 2416, 2205, 2116, 7720, 2015, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have six too many marbles. [SEP]']
[Init] best rec loss: 0.9150007367134094 for ['[CLS] endemicston card horsevere kira particular glasses [SEP]']
[Init] best rec loss: 0.9137986302375793 for ['[CLS] they future math note ] chaseanza bore [SEP]']
[Init] best rec loss: 0.8883269429206848 for ['[CLS] basis anythingui cleared looking name began ce [SEP]']
[Init] best rec loss: 0.8865185379981995 for ['[CLS] astronomy bowl records roe processed piano camera stuff [SEP]']
[Init] best rec loss: 0.8345103859901428 for ['[CLS] liability bleak later itpta doinʁ wilde [SEP]']
[Init] best rec loss: 0.7897818088531494 for ['[CLS] rear itself period def chargelth length contract [SEP]']
[Init] best perm rec loss: 0.7894785404205322 for ['[CLS] chargelth itself def contract period length rear [SEP]']
[Init] best perm rec loss: 0.7868735194206238 for ['[CLS] contract length def charge rearlth period itself [SEP]']
[Init] best perm rec loss: 0.786363959312439 for ['[CLS] length period charge itself def contract rearlth [SEP]']
[Init] best perm rec loss: 0.7855151295661926 for ['[CLS] length itself deflth rear contract charge period [SEP]']
[Init] best perm rec loss: 0.7844892740249634 for ['[CLS] def itself lengthlth charge rear contract period [SEP]']
[Init] best perm rec loss: 0.7842040061950684 for ['[CLS] def length itself charge period contract rearlth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.092 (perp=12.128, rec=0.482, cos=0.185), tot_loss_proj:4.306 [t=0.17s]
prediction: ['[CLS] ruin super team nice kawasaki defender japanese china [SEP]']
[ 100/2000] tot_loss=2.974 (perp=12.222, rec=0.403, cos=0.127), tot_loss_proj:4.225 [t=0.17s]
prediction: ['[CLS] excessive super six six first marble short britain [SEP]']
[ 150/2000] tot_loss=2.534 (perp=10.792, rec=0.311, cos=0.065), tot_loss_proj:4.120 [t=0.17s]
prediction: ['[CLS] too. six six first marble player i [SEP]']
[ 200/2000] tot_loss=2.312 (perp=9.638, rec=0.330, cos=0.054), tot_loss_proj:3.897 [t=0.17s]
prediction: ['[CLS] too. five six first marble. i [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.969 (perp=8.548, rec=0.216, cos=0.043), tot_loss_proj:3.736 [t=0.17s]
prediction: ['[CLS] too. six five too marbles i [SEP]']
[ 300/2000] tot_loss=1.952 (perp=8.790, rec=0.163, cos=0.030), tot_loss_proj:3.740 [t=0.17s]
prediction: ['[CLS] too have six five some marbles i [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.780 (perp=8.025, rec=0.148, cos=0.027), tot_loss_proj:3.498 [t=0.17s]
prediction: ['[CLS] i too have six three many marble. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.566 (perp=6.968, rec=0.139, cos=0.033), tot_loss_proj:3.158 [t=0.17s]
prediction: ['[CLS] i three have six too many marble. [SEP]']
[ 450/2000] tot_loss=1.519 (perp=6.968, rec=0.105, cos=0.020), tot_loss_proj:3.312 [t=0.17s]
prediction: ['[CLS] i three have six too many marble. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.285 (perp=5.849, rec=0.096, cos=0.019), tot_loss_proj:2.978 [t=0.17s]
prediction: ['[CLS] i have three six too many marble. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.275 (perp=5.849, rec=0.086, cos=0.019), tot_loss_proj:2.976 [t=0.17s]
prediction: ['[CLS] i have three six too many marble. [SEP]']
[ 600/2000] tot_loss=1.278 (perp=5.849, rec=0.089, cos=0.019), tot_loss_proj:2.976 [t=0.17s]
prediction: ['[CLS] i have three six too many marble. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.270 (perp=5.849, rec=0.081, cos=0.019), tot_loss_proj:2.972 [t=0.17s]
prediction: ['[CLS] i have three six too many marble. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.278 (perp=5.849, rec=0.090, cos=0.019), tot_loss_proj:2.974 [t=0.17s]
prediction: ['[CLS] i have three six too many marble. [SEP]']
[ 750/2000] tot_loss=1.369 (perp=6.315, rec=0.087, cos=0.019), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.358 (perp=6.315, rec=0.076, cos=0.019), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.362 (perp=6.315, rec=0.080, cos=0.019), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
[ 900/2000] tot_loss=1.358 (perp=6.315, rec=0.076, cos=0.019), tot_loss_proj:3.176 [t=0.22s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.356 (perp=6.315, rec=0.074, cos=0.019), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.361 (perp=6.315, rec=0.079, cos=0.019), tot_loss_proj:3.172 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
[1050/2000] tot_loss=1.354 (perp=6.315, rec=0.072, cos=0.019), tot_loss_proj:3.172 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.363 (perp=6.315, rec=0.080, cos=0.019), tot_loss_proj:3.174 [t=0.19s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.351 (perp=6.315, rec=0.069, cos=0.019), tot_loss_proj:3.172 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
[1200/2000] tot_loss=1.362 (perp=6.315, rec=0.080, cos=0.019), tot_loss_proj:3.174 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.358 (perp=6.315, rec=0.076, cos=0.019), tot_loss_proj:3.171 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.355 (perp=6.315, rec=0.073, cos=0.019), tot_loss_proj:3.172 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
[1350/2000] tot_loss=1.358 (perp=6.315, rec=0.076, cos=0.019), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.367 (perp=6.315, rec=0.085, cos=0.019), tot_loss_proj:3.171 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.350 (perp=6.315, rec=0.068, cos=0.019), tot_loss_proj:3.175 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
[1500/2000] tot_loss=1.355 (perp=6.315, rec=0.073, cos=0.019), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.356 (perp=6.315, rec=0.074, cos=0.019), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.354 (perp=6.315, rec=0.072, cos=0.019), tot_loss_proj:3.170 [t=0.18s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
[1650/2000] tot_loss=1.360 (perp=6.315, rec=0.078, cos=0.019), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.362 (perp=6.315, rec=0.080, cos=0.019), tot_loss_proj:3.169 [t=0.19s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.361 (perp=6.315, rec=0.079, cos=0.019), tot_loss_proj:3.170 [t=0.19s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
[1800/2000] tot_loss=1.359 (perp=6.315, rec=0.077, cos=0.019), tot_loss_proj:3.171 [t=0.19s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.358 (perp=6.315, rec=0.076, cos=0.019), tot_loss_proj:3.169 [t=0.19s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.352 (perp=6.315, rec=0.070, cos=0.019), tot_loss_proj:3.172 [t=0.19s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
[1950/2000] tot_loss=1.347 (perp=6.315, rec=0.065, cos=0.019), tot_loss_proj:3.174 [t=0.19s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.355 (perp=6.315, rec=0.073, cos=0.019), tot_loss_proj:3.175 [t=0.19s]
prediction: ['[CLS] i have several six too many marble. [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] i have six too many marbles. [SEP]
========================
predicted: 
========================
[CLS] i have several six too many marble. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 53.333 | p: 50.000 | r: 57.143
rougeL     | fm: 82.353 | p: 77.778 | r: 87.500
rougeLsum  | fm: 82.353 | p: 77.778 | r: 87.500
r1fm+r2fm = 135.686

[Aggregate metrics]:
rouge1     | fm: 80.001 | p: 80.954 | r: 79.379
rouge2     | fm: 39.462 | p: 39.587 | r: 39.564
rougeL     | fm: 69.629 | p: 70.320 | r: 69.275
rougeLsum  | fm: 69.303 | p: 69.996 | r: 69.090
r1fm+r2fm = 119.463

input #19 time: 0:07:05 | total time: 2:19:59


Running input #20 of 100.
reference: 
========================
Mark's single mindedness terrified me.
========================
Sample: 0 2.9578934243264274e-12 0.049625967447536425 0.34667534
average of cosine similarity 0.9897012228086939
highest_index [0]
highest [0.9897012228086939]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2928,  1005,  1055,  2309, 13128,  2791, 10215,  2033,  1012,
           102]], device='cuda:0')
Debug: ref = ["[CLS] mark's single mindedness terrified me. [SEP]"]
[Init] best rec loss: 1.0452334880828857 for ['[CLS] [CLS] asked sirius accessed ling women emphasis disc height [SEP]']
[Init] best rec loss: 0.9451050162315369 for ['[CLS]se guitarfirmed sky 2015 begging box simply agreed [SEP]']
[Init] best rec loss: 0.9352335333824158 for ['[CLS] avery her el practices pius still academic belief power [SEP]']
[Init] best rec loss: 0.9296568036079407 for ['[CLS] silence sounds h derrick serviceks whose begin make [SEP]']
[Init] best perm rec loss: 0.9269508719444275 for ['[CLS] derrick begin whose soundsks h silence make service [SEP]']
[Init] best perm rec loss: 0.9261907935142517 for ['[CLS] derrick make serviceks begin whose silence sounds h [SEP]']
[Init] best perm rec loss: 0.9243326187133789 for ['[CLS] h whose beginks sounds silence service make derrick [SEP]']
[Init] best perm rec loss: 0.9241335988044739 for ['[CLS] make derrickks whose silence sounds begin h service [SEP]']
[Init] best perm rec loss: 0.9237069487571716 for ['[CLS] derrick sounds h make silence whose beginks service [SEP]']
[Init] best perm rec loss: 0.9234338998794556 for ['[CLS] derrick makeks begin silence sounds whose h service [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.590 (perp=11.634, rec=0.583, cos=0.680), tot_loss_proj:4.214 [t=0.19s]
prediction: ['[CLS] luis ed silk review sensed science its clinical? [SEP]']
[ 100/2000] tot_loss=2.507 (perp=10.548, rec=0.335, cos=0.063), tot_loss_proj:4.065 [t=0.19s]
prediction: ['[CLS] marks charles acknowledge mark engineering mark terrified her? [SEP]']
[ 150/2000] tot_loss=2.426 (perp=10.825, rec=0.231, cos=0.030), tot_loss_proj:4.114 [t=0.19s]
prediction: ['[CLS] mark my branded mark minded mark terrified me minded [SEP]']
[ 200/2000] tot_loss=2.371 (perp=10.941, rec=0.156, cos=0.027), tot_loss_proj:4.173 [t=0.19s]
prediction: ['[CLS] mark s minded mark minded mark terrified me minded [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.930 (perp=8.879, rec=0.129, cos=0.025), tot_loss_proj:3.755 [t=0.18s]
prediction: ['[CLS] minded single minded mark s mark terrified me. [SEP]']
[ 300/2000] tot_loss=1.904 (perp=8.879, rec=0.105, cos=0.024), tot_loss_proj:3.758 [t=0.17s]
prediction: ['[CLS] minded single minded mark s mark terrified me. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.842 (perp=8.625, rec=0.093, cos=0.024), tot_loss_proj:3.671 [t=0.17s]
prediction: ['[CLS] s single minded markness mark terrified me. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.689 (perp=7.911, rec=0.084, cos=0.023), tot_loss_proj:3.495 [t=0.17s]
prediction: ['[CLS] s single mindedness mark mark terrified me. [SEP]']
[ 450/2000] tot_loss=1.700 (perp=7.911, rec=0.094, cos=0.023), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] s single mindedness mark mark terrified me. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.678 (perp=7.911, rec=0.073, cos=0.023), tot_loss_proj:3.497 [t=0.17s]
prediction: ['[CLS] s single mindedness mark mark terrified me. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.694 (perp=7.911, rec=0.089, cos=0.023), tot_loss_proj:3.495 [t=0.17s]
prediction: ['[CLS] s single mindedness mark mark terrified me. [SEP]']
[ 600/2000] tot_loss=1.563 (perp=7.269, rec=0.087, cos=0.023), tot_loss_proj:3.540 [t=0.17s]
prediction: ["[CLS] s single mindedness'mark terrified me. [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.562 (perp=7.269, rec=0.085, cos=0.023), tot_loss_proj:3.539 [t=0.17s]
prediction: ["[CLS] s single mindedness'mark terrified me. [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.346 (perp=6.179, rec=0.087, cos=0.024), tot_loss_proj:3.291 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
[ 750/2000] tot_loss=1.332 (perp=6.179, rec=0.074, cos=0.022), tot_loss_proj:3.293 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.337 (perp=6.179, rec=0.079, cos=0.022), tot_loss_proj:3.289 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.344 (perp=6.179, rec=0.086, cos=0.022), tot_loss_proj:3.290 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
[ 900/2000] tot_loss=1.339 (perp=6.179, rec=0.081, cos=0.022), tot_loss_proj:3.289 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.332 (perp=6.179, rec=0.074, cos=0.022), tot_loss_proj:3.294 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.342 (perp=6.179, rec=0.084, cos=0.022), tot_loss_proj:3.288 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
[1050/2000] tot_loss=1.332 (perp=6.179, rec=0.074, cos=0.022), tot_loss_proj:3.292 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.335 (perp=6.179, rec=0.077, cos=0.022), tot_loss_proj:3.291 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.335 (perp=6.179, rec=0.077, cos=0.022), tot_loss_proj:3.293 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
[1200/2000] tot_loss=1.344 (perp=6.179, rec=0.086, cos=0.022), tot_loss_proj:3.293 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.334 (perp=6.179, rec=0.076, cos=0.022), tot_loss_proj:3.291 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.335 (perp=6.179, rec=0.077, cos=0.022), tot_loss_proj:3.296 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
[1350/2000] tot_loss=1.326 (perp=6.179, rec=0.068, cos=0.022), tot_loss_proj:3.292 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.331 (perp=6.179, rec=0.073, cos=0.022), tot_loss_proj:3.295 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.332 (perp=6.179, rec=0.074, cos=0.022), tot_loss_proj:3.288 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
[1500/2000] tot_loss=1.334 (perp=6.179, rec=0.076, cos=0.022), tot_loss_proj:3.291 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.334 (perp=6.179, rec=0.076, cos=0.022), tot_loss_proj:3.295 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.322 (perp=6.179, rec=0.064, cos=0.022), tot_loss_proj:3.292 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
[1650/2000] tot_loss=1.340 (perp=6.179, rec=0.082, cos=0.022), tot_loss_proj:3.299 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.328 (perp=6.179, rec=0.070, cos=0.022), tot_loss_proj:3.296 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.336 (perp=6.179, rec=0.078, cos=0.022), tot_loss_proj:3.291 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
[1800/2000] tot_loss=1.340 (perp=6.179, rec=0.082, cos=0.022), tot_loss_proj:3.300 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.335 (perp=6.179, rec=0.077, cos=0.022), tot_loss_proj:3.291 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.338 (perp=6.179, rec=0.080, cos=0.022), tot_loss_proj:3.291 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
[1950/2000] tot_loss=1.333 (perp=6.179, rec=0.075, cos=0.022), tot_loss_proj:3.287 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.334 (perp=6.179, rec=0.076, cos=0.022), tot_loss_proj:3.291 [t=0.17s]
prediction: ["[CLS] single mindedness's mark terrified me. [SEP]"]
Done with input #20 of 100.
reference: 
========================
[CLS] mark's single mindedness terrified me. [SEP]
========================
predicted: 
========================
[CLS] single mindedness's mark terrified me. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 142.857

[Aggregate metrics]:
rouge1     | fm: 80.862 | p: 81.927 | r: 80.368
rouge2     | fm: 39.713 | p: 39.748 | r: 39.811
rougeL     | fm: 69.865 | p: 70.414 | r: 69.457
rougeLsum  | fm: 69.569 | p: 70.219 | r: 69.229
r1fm+r2fm = 120.575

input #20 time: 0:07:00 | total time: 2:26:59


Running input #21 of 100.
reference: 
========================
Her indiscretions were made light of.
========================
Sample: 0 3.6557675689310175e-12 0.04181809675903677 0.3195539
average of cosine similarity 0.9914003262524657
highest_index [0]
highest [0.9914003262524657]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2014, 27427,  2483, 16748,  9285,  2020,  2081,  2422,  1997,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] her indiscretions were made light of. [SEP]']
[Init] best rec loss: 0.9554566144943237 for ['[CLS] dung help makei de blinds commissioned "z graders [SEP]']
[Init] best rec loss: 0.9515466094017029 for ['[CLS] our regal hadn bollywood parasite pere betapath attack photograph [SEP]']
[Init] best rec loss: 0.9109048247337341 for ['[CLS] paydah silver abigail heart humans " covers lightdder [SEP]']
[Init] best rec loss: 0.9000157117843628 for ['[CLS] this innovation kala these yu sprint experience cas pressure paper [SEP]']
[Init] best rec loss: 0.8907043933868408 for ['[CLS] allie super dwell roadssia come guido swedish magnus named [SEP]']
[Init] best rec loss: 0.8886403441429138 for ['[CLS]hari equals kata id saint cooper listen projects bulgaria guess [SEP]']
[Init] best perm rec loss: 0.8841731548309326 for ['[CLS] bulgaria cooper guess saint id kata listen equals projectshari [SEP]']
[Init] best perm rec loss: 0.8827610015869141 for ['[CLS] id bulgariahari projects kata saint guess cooper equals listen [SEP]']
[Init] best perm rec loss: 0.8818569779396057 for ['[CLS]hari bulgaria id guess listen saint cooper kata equals projects [SEP]']
[Init] best perm rec loss: 0.8816714286804199 for ['[CLS] saint cooper bulgaria equals id projectshari kata listen guess [SEP]']
[Init] best perm rec loss: 0.8802563548088074 for ['[CLS] equals katahari listen cooper bulgaria id saint projects guess [SEP]']
[Init] best perm rec loss: 0.879644513130188 for ['[CLS]hari equals bulgaria listen saint cooper kata guess projects id [SEP]']
[Init] best perm rec loss: 0.8795214891433716 for ['[CLS] bulgaria id saint listen cooper equals projects guess katahari [SEP]']
[Init] best perm rec loss: 0.8789999485015869 for ['[CLS] id listen bulgariahari kata guess saint cooper equals projects [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.476 (perp=9.858, rec=0.524, cos=0.980), tot_loss_proj:3.784 [t=0.17s]
prediction: ['[CLS] welcome. easily.. become metis erupted attendance of [SEP]']
[ 100/2000] tot_loss=2.947 (perp=7.371, rec=0.484, cos=0.988), tot_loss_proj:3.197 [t=0.17s]
prediction: ['[CLS] her. in boat.tions : were attendance. [SEP]']
[ 150/2000] tot_loss=3.370 (perp=9.769, rec=0.436, cos=0.980), tot_loss_proj:3.686 [t=0.17s]
prediction: ['[CLS] her she aboutcre.tions were were amongst. [SEP]']
[ 200/2000] tot_loss=3.239 (perp=9.263, rec=0.409, cos=0.977), tot_loss_proj:3.759 [t=0.17s]
prediction: ['[CLS] hertions incre.tions made of amongst. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.402 (perp=9.803, rec=0.480, cos=0.961), tot_loss_proj:3.789 [t=0.17s]
prediction: ['[CLS] her arise nowehr chest... resough [SEP]']
[ 300/2000] tot_loss=3.608 (perp=11.152, rec=0.418, cos=0.960), tot_loss_proj:4.105 [t=0.17s]
prediction: ['[CLS] her arise nocre whentions.. resough [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.405 (perp=10.285, rec=0.392, cos=0.956), tot_loss_proj:3.822 [t=0.17s]
prediction: ['[CLS] her arise anyway nocretions.. eyesough [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.379 (perp=9.983, rec=0.416, cos=0.967), tot_loss_proj:3.872 [t=0.17s]
prediction: ['[CLS] her dismiss. noviotions anyway. resough [SEP]']
[ 450/2000] tot_loss=3.134 (perp=8.984, rec=0.381, cos=0.956), tot_loss_proj:3.512 [t=0.17s]
prediction: ['[CLS] her arise. nocretions anyway. resough [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.280 (perp=9.721, rec=0.384, cos=0.952), tot_loss_proj:3.674 [t=0.17s]
prediction: ['[CLS] her arise. no seemscretions anyway.ough [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.129 (perp=9.031, rec=0.377, cos=0.946), tot_loss_proj:3.539 [t=0.17s]
prediction: ['[CLS] her arise. nocretions appears anyway.ough [SEP]']
[ 600/2000] tot_loss=3.504 (perp=10.985, rec=0.363, cos=0.944), tot_loss_proj:3.951 [t=0.17s]
prediction: ['[CLS] her arise made nocretions becomeeley.ough [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.321 (perp=10.088, rec=0.362, cos=0.941), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] herheard made nocretions seemseley choir. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.278 (perp=9.923, rec=0.360, cos=0.934), tot_loss_proj:3.771 [t=0.17s]
prediction: ['[CLS] her proved made choircretions seemsionalis. [SEP]']
[ 750/2000] tot_loss=3.495 (perp=11.010, rec=0.358, cos=0.935), tot_loss_proj:4.012 [t=0.17s]
prediction: ['[CLS] her proved madecrecretions seemseleyis. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.399 (perp=10.590, rec=0.349, cos=0.932), tot_loss_proj:3.970 [t=0.17s]
prediction: ['[CLS] her provediscrecretions seemsional made. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.183 (perp=9.485, rec=0.357, cos=0.929), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions seemsnath made. [SEP]']
[ 900/2000] tot_loss=3.175 (perp=9.485, rec=0.355, cos=0.922), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions seemsnath made. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.154 (perp=9.485, rec=0.340, cos=0.918), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions seemsnath made. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.151 (perp=9.485, rec=0.341, cos=0.913), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions seemsnath made. [SEP]']
[1050/2000] tot_loss=3.155 (perp=9.481, rec=0.348, cos=0.910), tot_loss_proj:3.707 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions seems chiefs made. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.201 (perp=9.733, rec=0.348, cos=0.907), tot_loss_proj:4.034 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions byzantine chiefs made. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=3.045 (perp=8.961, rec=0.348, cos=0.905), tot_loss_proj:3.609 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions seems made anyway. [SEP]']
[1200/2000] tot_loss=3.064 (perp=9.068, rec=0.349, cos=0.902), tot_loss_proj:3.862 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions byzantine made anyway. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.060 (perp=9.068, rec=0.346, cos=0.900), tot_loss_proj:3.865 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions byzantine made anyway. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.054 (perp=9.068, rec=0.341, cos=0.899), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions byzantine made anyway. [SEP]']
[1350/2000] tot_loss=3.047 (perp=9.068, rec=0.336, cos=0.898), tot_loss_proj:3.864 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions byzantine made anyway. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.054 (perp=9.068, rec=0.344, cos=0.897), tot_loss_proj:3.867 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions byzantine made anyway. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.040 (perp=9.068, rec=0.331, cos=0.896), tot_loss_proj:3.867 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions byzantine made anyway. [SEP]']
[1500/2000] tot_loss=3.042 (perp=9.068, rec=0.334, cos=0.895), tot_loss_proj:3.864 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions byzantine made anyway. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.040 (perp=9.068, rec=0.332, cos=0.894), tot_loss_proj:3.867 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions byzantine made anyway. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.034 (perp=9.058, rec=0.328, cos=0.894), tot_loss_proj:3.701 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions tribute made anyway. [SEP]']
[1650/2000] tot_loss=3.028 (perp=9.058, rec=0.323, cos=0.893), tot_loss_proj:3.702 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions tribute made anyway. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.042 (perp=9.058, rec=0.338, cos=0.892), tot_loss_proj:3.705 [t=0.18s]
prediction: ['[CLS] hercreis provedcretions tribute made anyway. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.040 (perp=9.058, rec=0.336, cos=0.892), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions tribute made anyway. [SEP]']
[1800/2000] tot_loss=3.029 (perp=9.058, rec=0.326, cos=0.891), tot_loss_proj:3.701 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions tribute made anyway. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.027 (perp=9.058, rec=0.325, cos=0.891), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions tribute made anyway. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.037 (perp=9.058, rec=0.335, cos=0.890), tot_loss_proj:3.703 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions tribute made anyway. [SEP]']
[1950/2000] tot_loss=3.036 (perp=9.058, rec=0.334, cos=0.890), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions tribute made anyway. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.044 (perp=9.058, rec=0.343, cos=0.889), tot_loss_proj:3.702 [t=0.17s]
prediction: ['[CLS] hercreis provedcretions tribute made anyway. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] her indiscretions were made light of. [SEP]
========================
predicted: 
========================
[CLS] hercreis provedcretions tribute made anyway. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 42.857 | r: 37.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 42.857 | r: 37.500
rougeLsum  | fm: 40.000 | p: 42.857 | r: 37.500
r1fm+r2fm = 40.000

[Aggregate metrics]:
rouge1     | fm: 79.087 | p: 80.114 | r: 78.330
rouge2     | fm: 37.924 | p: 37.817 | r: 38.135
rougeL     | fm: 68.496 | p: 69.218 | r: 68.076
rougeLsum  | fm: 68.245 | p: 69.062 | r: 67.800
r1fm+r2fm = 117.011

input #21 time: 0:06:57 | total time: 2:33:57


Running input #22 of 100.
reference: 
========================
Each of the boys fought with the other boys.
========================
Sample: 0 1.7309870174663712e-12 0.048999624406416226 0.34197885
average of cosine similarity 0.9896818041606917
highest_index [0]
highest [0.9896818041606917]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2169, 1997, 1996, 3337, 4061, 2007, 1996, 2060, 3337, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] each of the boys fought with the other boys. [SEP]']
[Init] best rec loss: 1.0515670776367188 for ['[CLS] hers hours woundmund totaling pd hailey stone aftermath tortricidae [SEP]']
[Init] best rec loss: 1.015817642211914 for ['[CLS] library em group come surprise pass varsity moderate must blackness [SEP]']
[Init] best rec loss: 0.9550566077232361 for ['[CLS] broke demolition athens censorship turn blood starts collection unlike sex [SEP]']
[Init] best rec loss: 0.9446551203727722 for ['[CLS] hotterpath started regional chew intention concert bet outsiders labour [SEP]']
[Init] best rec loss: 0.9388949275016785 for ['[CLS] upontra track samurai paste hamlet lots groupto self [SEP]']
[Init] best rec loss: 0.9269140958786011 for ['[CLS] fairy mercury hunt shall never witch pageant aviation add they [SEP]']
[Init] best rec loss: 0.9265666604042053 for ['[CLS] lucky peace [CLS]erationaxvat arrest undo square surface [SEP]']
[Init] best rec loss: 0.9177623391151428 for ['[CLS] own equation belt smoke perceptionful mode quartet crest colin [SEP]']
[Init] best rec loss: 0.9115076065063477 for ['[CLS] massimodo conrad chatham am dean phenomena weapon jam kung [SEP]']
[Init] best perm rec loss: 0.9084622263908386 for ['[CLS] chatham massimo conrad jam phenomenado weapon am kung dean [SEP]']
[Init] best perm rec loss: 0.9081283211708069 for ['[CLS] chatham dean weapon kung jam phenomena massimo conrad amdo [SEP]']
[Init] best perm rec loss: 0.9077945351600647 for ['[CLS] conrad massimo chatham jam kungdo weapon dean phenomena am [SEP]']
[Init] best perm rec loss: 0.906182050704956 for ['[CLS]do kung am weapon massimo conrad phenomena dean chatham jam [SEP]']
[Init] best perm rec loss: 0.9049517512321472 for ['[CLS] massimo conrad kung dean weapon phenomena jamdo chatham am [SEP]']
[Init] best perm rec loss: 0.904506504535675 for ['[CLS] phenomena dean massimo kung am weapon chatham conraddo jam [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.270 (perp=13.363, rec=0.617, cos=0.980), tot_loss_proj:4.504 [t=0.17s]
prediction: ['[CLS] nguyenting clearing fighter affiliate edwin others rivalry in crouch [SEP]']
[ 100/2000] tot_loss=4.122 (perp=12.949, rec=0.547, cos=0.985), tot_loss_proj:4.352 [t=0.17s]
prediction: ['[CLS] nguyenting our fought applied rangers others each. poly [SEP]']
[ 150/2000] tot_loss=3.761 (perp=11.290, rec=0.505, cos=0.998), tot_loss_proj:4.102 [t=0.17s]
prediction: ['[CLS] each east our fought each rangers others each. rope [SEP]']
[ 200/2000] tot_loss=3.493 (perp=10.172, rec=0.459, cos=1.000), tot_loss_proj:3.885 [t=0.17s]
prediction: ['[CLS] eachr from fought boys boy others each. boys [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.362 (perp=9.563, rec=0.449, cos=1.000), tot_loss_proj:3.740 [t=0.17s]
prediction: ['[CLS] each each boys fought from involving others each. boys [SEP]']
[ 300/2000] tot_loss=3.443 (perp=10.113, rec=0.421, cos=0.999), tot_loss_proj:3.841 [t=0.17s]
prediction: ['[CLS] eachrs boys fought our with others each. boys [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.337 (perp=9.617, rec=0.415, cos=0.998), tot_loss_proj:3.828 [t=0.17s]
prediction: ['[CLS] eachdable boys fought gentlemen with those each. boys [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.178 (perp=8.842, rec=0.410, cos=0.999), tot_loss_proj:3.724 [t=0.17s]
prediction: ['[CLS] eachdable boys fought amongst with each of those boys [SEP]']
[ 450/2000] tot_loss=3.117 (perp=8.662, rec=0.387, cos=0.998), tot_loss_proj:3.606 [t=0.17s]
prediction: ['[CLS] eachdable boys fought their with each of those boys [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.075 (perp=8.375, rec=0.401, cos=0.999), tot_loss_proj:3.773 [t=0.17s]
prediction: ['[CLS] eachdable boys fought with with each of those boys [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.058 (perp=8.375, rec=0.384, cos=0.998), tot_loss_proj:3.779 [t=0.17s]
prediction: ['[CLS] eachdable boys fought with with each of those boys [SEP]']
[ 600/2000] tot_loss=3.051 (perp=8.375, rec=0.379, cos=0.997), tot_loss_proj:3.776 [t=0.17s]
prediction: ['[CLS] eachdable boys fought with with each of those boys [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.053 (perp=8.375, rec=0.380, cos=0.998), tot_loss_proj:3.779 [t=0.17s]
prediction: ['[CLS] eachdable boys fought with with each of those boys [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.880 (perp=7.557, rec=0.371, cos=0.998), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] eachacious boys fought with with many of those boys [SEP]']
[ 750/2000] tot_loss=3.017 (perp=8.256, rec=0.368, cos=0.997), tot_loss_proj:3.724 [t=0.17s]
prediction: ['[CLS] eachacious boys fought with with many. those boys [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.010 (perp=8.256, rec=0.361, cos=0.997), tot_loss_proj:3.726 [t=0.17s]
prediction: ['[CLS] eachacious boys fought with with many. those boys [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.971 (perp=8.019, rec=0.369, cos=0.998), tot_loss_proj:3.672 [t=0.17s]
prediction: ['[CLS] eachacious boys fought with with many. both boys [SEP]']
[ 900/2000] tot_loss=3.113 (perp=8.766, rec=0.362, cos=0.998), tot_loss_proj:3.550 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with many. both boys [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.107 (perp=8.766, rec=0.356, cos=0.998), tot_loss_proj:3.547 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with many. both boys [SEP]']
Attempt swap
[1000/2000] tot_loss=3.107 (perp=8.766, rec=0.355, cos=0.999), tot_loss_proj:3.548 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with many. both boys [SEP]']
[1050/2000] tot_loss=3.160 (perp=9.034, rec=0.354, cos=0.999), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with several. both boys [SEP]']
Attempt swap
[1100/2000] tot_loss=3.159 (perp=9.034, rec=0.354, cos=0.999), tot_loss_proj:3.577 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with several. both boys [SEP]']
Attempt swap
[1150/2000] tot_loss=3.156 (perp=9.034, rec=0.350, cos=0.999), tot_loss_proj:3.576 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with several. both boys [SEP]']
[1200/2000] tot_loss=3.261 (perp=9.546, rec=0.353, cos=0.999), tot_loss_proj:3.686 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with your. both boys [SEP]']
Attempt swap
[1250/2000] tot_loss=3.251 (perp=9.546, rec=0.343, cos=0.999), tot_loss_proj:3.683 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with your. both boys [SEP]']
Attempt swap
[1300/2000] tot_loss=3.264 (perp=9.546, rec=0.355, cos=0.999), tot_loss_proj:3.684 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with your. both boys [SEP]']
[1350/2000] tot_loss=3.265 (perp=9.546, rec=0.357, cos=1.000), tot_loss_proj:3.687 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with your. both boys [SEP]']
Attempt swap
[1400/2000] tot_loss=3.254 (perp=9.546, rec=0.345, cos=1.000), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with your. both boys [SEP]']
Attempt swap
[1450/2000] tot_loss=3.261 (perp=9.546, rec=0.352, cos=1.000), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with your. both boys [SEP]']
[1500/2000] tot_loss=3.253 (perp=9.546, rec=0.344, cos=1.000), tot_loss_proj:3.681 [t=0.17s]
prediction: ['[CLS] eachacious boys fought involving with your. both boys [SEP]']
Attempt swap
[1550/2000] tot_loss=3.243 (perp=9.546, rec=0.334, cos=1.000), tot_loss_proj:3.684 [t=0.19s]
prediction: ['[CLS] eachacious boys fought involving with your. both boys [SEP]']
Attempt swap
[1600/2000] tot_loss=3.246 (perp=9.546, rec=0.337, cos=1.000), tot_loss_proj:3.683 [t=0.19s]
prediction: ['[CLS] eachacious boys fought involving with your. both boys [SEP]']
[1650/2000] tot_loss=3.255 (perp=9.546, rec=0.346, cos=1.000), tot_loss_proj:3.684 [t=0.19s]
prediction: ['[CLS] eachacious boys fought involving with your. both boys [SEP]']
Attempt swap
[1700/2000] tot_loss=3.435 (perp=10.472, rec=0.341, cos=1.000), tot_loss_proj:3.921 [t=0.19s]
prediction: ['[CLS] eacheous boys fought involving with offs. both boys [SEP]']
Attempt swap
[1750/2000] tot_loss=3.432 (perp=10.472, rec=0.338, cos=1.000), tot_loss_proj:3.925 [t=0.17s]
prediction: ['[CLS] eacheous boys fought involving with offs. both boys [SEP]']
[1800/2000] tot_loss=3.427 (perp=10.472, rec=0.333, cos=1.000), tot_loss_proj:3.921 [t=0.17s]
prediction: ['[CLS] eacheous boys fought involving with offs. both boys [SEP]']
Attempt swap
[1850/2000] tot_loss=3.432 (perp=10.472, rec=0.337, cos=1.000), tot_loss_proj:3.922 [t=0.17s]
prediction: ['[CLS] eacheous boys fought involving with offs. both boys [SEP]']
Attempt swap
[1900/2000] tot_loss=3.436 (perp=10.472, rec=0.341, cos=1.000), tot_loss_proj:3.923 [t=0.17s]
prediction: ['[CLS] eacheous boys fought involving with offs. both boys [SEP]']
[1950/2000] tot_loss=3.428 (perp=10.472, rec=0.334, cos=1.000), tot_loss_proj:3.919 [t=0.17s]
prediction: ['[CLS] eacheous boys fought involving with offs. both boys [SEP]']
Attempt swap
[2000/2000] tot_loss=3.434 (perp=10.472, rec=0.340, cos=1.000), tot_loss_proj:3.923 [t=0.17s]
prediction: ['[CLS] eacheous boys fought involving with offs. both boys [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] each of the boys fought with the other boys. [SEP]
========================
predicted: 
========================
[CLS] eacheous boys fought involving with offs. both boys [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 60.000 | r: 54.545
rouge2     | fm: 21.053 | p: 22.222 | r: 20.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 78.195

[Aggregate metrics]:
rouge1     | fm: 78.283 | p: 79.351 | r: 77.636
rouge2     | fm: 36.965 | p: 37.168 | r: 37.153
rougeL     | fm: 68.015 | p: 68.805 | r: 67.493
rougeLsum  | fm: 67.823 | p: 68.651 | r: 67.162
r1fm+r2fm = 115.248

input #22 time: 0:07:01 | total time: 2:40:58


Running input #23 of 100.
reference: 
========================
Herman mixed the eggs with the cream.
========================
Sample: 0 7.696654003885897e-13 0.04576828256354869 0.34419063
average of cosine similarity 0.9911195778277173
highest_index [0]
highest [0.9911195778277173]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 11458,  3816,  1996,  6763,  2007,  1996,  6949,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] herman mixed the eggs with the cream. [SEP]']
[Init] best rec loss: 0.9968389868736267 for ['[CLS] digital borrow applied lodging luc reconciliation rhys toe [SEP]']
[Init] best rec loss: 0.9496680498123169 for ['[CLS] slapped seal near ice sick funk operation commodore [SEP]']
[Init] best rec loss: 0.9394097924232483 for ['[CLS]imi thoughlysis extensionous prominently gorgeous else [SEP]']
[Init] best rec loss: 0.9325956702232361 for ['[CLS] nation withinw allen beneath by space moe [SEP]']
[Init] best rec loss: 0.931027352809906 for ['[CLS] thantrom band millsgood scientistend club [SEP]']
[Init] best rec loss: 0.9294249415397644 for ['[CLS] less saga glass study timesvial jamalactive [SEP]']
[Init] best rec loss: 0.9291494488716125 for ['[CLS]run congress sead instead aged althoughbrush [SEP]']
[Init] best rec loss: 0.916151762008667 for ['[CLS] introduction hair stevie system model question russian common [SEP]']
[Init] best perm rec loss: 0.914799690246582 for ['[CLS] introduction model hair stevie russian question system common [SEP]']
[Init] best perm rec loss: 0.9141308665275574 for ['[CLS] introduction stevie hair russian system question model common [SEP]']
[Init] best perm rec loss: 0.91079181432724 for ['[CLS] system model question russian hair introduction common stevie [SEP]']
[Init] best perm rec loss: 0.9083205461502075 for ['[CLS] stevie hair common russian introduction system model question [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.344 (perp=13.598, rec=0.658, cos=0.966), tot_loss_proj:4.483 [t=0.17s]
prediction: ['[CLS] odd mutual down transition mixed nine silk range [SEP]']
[ 100/2000] tot_loss=3.889 (perp=11.361, rec=0.644, cos=0.973), tot_loss_proj:4.096 [t=0.17s]
prediction: ['[CLS] & cold. bring selling combination hamish eggs [SEP]']
[ 150/2000] tot_loss=3.534 (perp=9.957, rec=0.567, cos=0.975), tot_loss_proj:3.907 [t=0.17s]
prediction: ['[CLS] nor cool. bring cream eggs eggs eggs [SEP]']
[ 200/2000] tot_loss=3.684 (perp=10.765, rec=0.553, cos=0.978), tot_loss_proj:4.208 [t=0.17s]
prediction: ['[CLS] hermanburg. bring eggs eggs eggs eggs [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.300 (perp=8.966, rec=0.521, cos=0.986), tot_loss_proj:3.765 [t=0.17s]
prediction: ['[CLS] hermanburg eggs with eggs eggs eggs. [SEP]']
[ 300/2000] tot_loss=3.463 (perp=9.905, rec=0.495, cos=0.987), tot_loss_proj:3.923 [t=0.17s]
prediction: ['[CLS] hermanburg eggs upon eggs eggs eggs. [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.447 (perp=9.905, rec=0.480, cos=0.986), tot_loss_proj:3.925 [t=0.17s]
prediction: ['[CLS] hermanburg eggs upon eggs eggs eggs. [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.439 (perp=9.905, rec=0.463, cos=0.996), tot_loss_proj:3.926 [t=0.17s]
prediction: ['[CLS] hermanburg eggs upon eggs eggs eggs. [SEP]']
[ 450/2000] tot_loss=3.611 (perp=10.830, rec=0.446, cos=0.998), tot_loss_proj:4.200 [t=0.17s]
prediction: ['[CLS] hermanburg eggs mixed eggs eggs eggs. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.233 (perp=8.948, rec=0.445, cos=0.999), tot_loss_proj:3.845 [t=0.17s]
prediction: ['[CLS] herman eggsburg mixed eggs eggs eggs. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.217 (perp=8.948, rec=0.429, cos=0.999), tot_loss_proj:3.834 [t=0.17s]
prediction: ['[CLS] herman eggsburg mixed eggs eggs eggs. [SEP]']
[ 600/2000] tot_loss=3.222 (perp=8.948, rec=0.433, cos=0.999), tot_loss_proj:3.843 [t=0.17s]
prediction: ['[CLS] herman eggsburg mixed eggs eggs eggs. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.223 (perp=8.948, rec=0.433, cos=1.000), tot_loss_proj:3.841 [t=0.17s]
prediction: ['[CLS] herman eggsburg mixed eggs eggs eggs. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.204 (perp=8.948, rec=0.414, cos=1.000), tot_loss_proj:3.839 [t=0.17s]
prediction: ['[CLS] herman eggsburg mixed eggs eggs eggs. [SEP]']
[ 750/2000] tot_loss=3.197 (perp=8.948, rec=0.407, cos=1.000), tot_loss_proj:3.841 [t=0.17s]
prediction: ['[CLS] herman eggsburg mixed eggs eggs eggs. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.209 (perp=8.948, rec=0.420, cos=1.000), tot_loss_proj:3.839 [t=0.17s]
prediction: ['[CLS] herman eggsburg mixed eggs eggs eggs. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.206 (perp=8.948, rec=0.417, cos=1.000), tot_loss_proj:3.836 [t=0.17s]
prediction: ['[CLS] herman eggsburg mixed eggs eggs eggs. [SEP]']
[ 900/2000] tot_loss=3.190 (perp=8.948, rec=0.401, cos=1.000), tot_loss_proj:3.840 [t=0.17s]
prediction: ['[CLS] herman eggsburg mixed eggs eggs eggs. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.197 (perp=8.948, rec=0.407, cos=1.000), tot_loss_proj:3.836 [t=0.17s]
prediction: ['[CLS] herman eggsburg mixed eggs eggs eggs. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.525 (perp=10.616, rec=0.402, cos=1.000), tot_loss_proj:4.133 [t=0.17s]
prediction: ['[CLS] herman eggs je mixed eggs eggs eggs. [SEP]']
[1050/2000] tot_loss=3.523 (perp=10.616, rec=0.400, cos=1.000), tot_loss_proj:4.129 [t=0.17s]
prediction: ['[CLS] herman eggs je mixed eggs eggs eggs. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.476 (perp=10.380, rec=0.400, cos=1.000), tot_loss_proj:4.056 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggs eggs eggs. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.474 (perp=10.380, rec=0.398, cos=1.000), tot_loss_proj:4.055 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggs eggs eggs. [SEP]']
[1200/2000] tot_loss=3.473 (perp=10.380, rec=0.397, cos=1.000), tot_loss_proj:4.054 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggs eggs eggs. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.617 (perp=11.129, rec=0.391, cos=1.000), tot_loss_proj:4.139 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggs eggsscoe. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=3.406 (perp=9.998, rec=0.407, cos=1.000), tot_loss_proj:3.995 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
[1350/2000] tot_loss=3.397 (perp=9.998, rec=0.397, cos=1.000), tot_loss_proj:3.993 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.394 (perp=9.998, rec=0.394, cos=1.000), tot_loss_proj:3.996 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.392 (perp=9.998, rec=0.393, cos=1.000), tot_loss_proj:3.987 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
[1500/2000] tot_loss=3.394 (perp=9.998, rec=0.394, cos=1.000), tot_loss_proj:3.994 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.390 (perp=9.998, rec=0.391, cos=1.000), tot_loss_proj:3.992 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.389 (perp=9.998, rec=0.389, cos=1.000), tot_loss_proj:3.995 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
[1650/2000] tot_loss=3.393 (perp=9.998, rec=0.394, cos=1.000), tot_loss_proj:3.994 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.386 (perp=9.998, rec=0.386, cos=1.000), tot_loss_proj:3.992 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.399 (perp=9.998, rec=0.400, cos=1.000), tot_loss_proj:3.997 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
[1800/2000] tot_loss=3.389 (perp=9.998, rec=0.390, cos=1.000), tot_loss_proj:3.993 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.386 (perp=9.998, rec=0.387, cos=1.000), tot_loss_proj:3.994 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.386 (perp=9.998, rec=0.387, cos=1.000), tot_loss_proj:3.996 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
[1950/2000] tot_loss=3.384 (perp=9.998, rec=0.384, cos=1.000), tot_loss_proj:3.995 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.379 (perp=9.998, rec=0.380, cos=1.000), tot_loss_proj:3.994 [t=0.17s]
prediction: ['[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] herman mixed the eggs with the cream. [SEP]
========================
predicted: 
========================
[CLS] herman eggsdridge mixed eggsscoe eggs. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.500 | p: 71.429 | r: 55.556
rouge2     | fm: 14.286 | p: 16.667 | r: 12.500
rougeL     | fm: 62.500 | p: 71.429 | r: 55.556
rougeLsum  | fm: 62.500 | p: 71.429 | r: 55.556
r1fm+r2fm = 76.786

[Aggregate metrics]:
rouge1     | fm: 77.525 | p: 79.001 | r: 76.480
rouge2     | fm: 36.087 | p: 36.324 | r: 36.027
rougeL     | fm: 67.604 | p: 68.862 | r: 66.747
rougeLsum  | fm: 67.522 | p: 68.687 | r: 66.631
r1fm+r2fm = 113.612

input #23 time: 0:07:00 | total time: 2:47:58


Running input #24 of 100.
reference: 
========================
No John Smiths attended the meeting.
========================
Sample: 0 1.1278507469680454e-11 0.048699607859243675 0.35151783
average of cosine similarity 0.9903567001417337
highest_index [0]
highest [0.9903567001417337]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2053, 2198, 3044, 2015, 3230, 1996, 3116, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] no john smiths attended the meeting. [SEP]']
[Init] best rec loss: 0.9064764976501465 for ['[CLS] performance maybe rae tri / window grace lockheed [SEP]']
[Init] best rec loss: 0.8986294865608215 for ['[CLS] thin southwest laurel body [MASK] minority statue in [SEP]']
[Init] best rec loss: 0.8964348435401917 for ['[CLS] tumors enemy quick tessa moorvere an breath [SEP]']
[Init] best rec loss: 0.8814604878425598 for ['[CLS] commanded belts twilight cameo so mountain 0 radio [SEP]']
[Init] best perm rec loss: 0.8812436461448669 for ['[CLS] belts twilight 0 cameo radio commanded mountain so [SEP]']
[Init] best perm rec loss: 0.8808506727218628 for ['[CLS] belts twilight radio 0 cameo mountain so commanded [SEP]']
[Init] best perm rec loss: 0.8781828284263611 for ['[CLS] so radio cameo belts twilight mountain 0 commanded [SEP]']
[Init] best perm rec loss: 0.875819981098175 for ['[CLS] cameo so commanded belts twilight mountain 0 radio [SEP]']
[Init] best perm rec loss: 0.8754783272743225 for ['[CLS] commanded twilight so belts 0 cameo mountain radio [SEP]']
[Init] best perm rec loss: 0.8746973276138306 for ['[CLS] commanded so twilight 0 belts mountain cameo radio [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.637 (perp=10.286, rec=0.590, cos=0.989), tot_loss_proj:4.027 [t=0.17s]
prediction: ['[CLS] v hara meetings meetings? everybody.? [SEP]']
[ 100/2000] tot_loss=2.571 (perp=10.375, rec=0.394, cos=0.102), tot_loss_proj:3.943 [t=0.17s]
prediction: ['[CLS] doc technique arrived meeting " everybody ;night [SEP]']
[ 150/2000] tot_loss=1.772 (perp=7.064, rec=0.297, cos=0.063), tot_loss_proj:3.354 [t=0.17s]
prediction: ['[CLS]. no attended meetingion meeting ;. [SEP]']
[ 200/2000] tot_loss=1.895 (perp=8.301, rec=0.199, cos=0.036), tot_loss_proj:3.585 [t=0.17s]
prediction: ['[CLS] smith no attended smith smith meeting ;. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.769 (perp=7.895, rec=0.161, cos=0.030), tot_loss_proj:3.614 [t=0.17s]
prediction: ['[CLS] john no smith attended smith meeting.. [SEP]']
[ 300/2000] tot_loss=1.766 (perp=8.127, rec=0.113, cos=0.027), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] john no smith attended smith meeting smith. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.593 (perp=7.229, rec=0.122, cos=0.025), tot_loss_proj:3.388 [t=0.17s]
prediction: ['[CLS] no smith attended john smith meeting smith. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.468 (perp=6.743, rec=0.096, cos=0.023), tot_loss_proj:3.390 [t=0.17s]
prediction: ['[CLS] no smith attended john smith smith meeting. [SEP]']
[ 450/2000] tot_loss=1.537 (perp=7.126, rec=0.090, cos=0.022), tot_loss_proj:3.449 [t=0.17s]
prediction: ['[CLS] nos attended john smith smith meeting. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.451 (perp=6.666, rec=0.096, cos=0.021), tot_loss_proj:2.904 [t=0.17s]
prediction: ['[CLS] no john smiths attended smith meeting. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.443 (perp=6.666, rec=0.088, cos=0.022), tot_loss_proj:2.911 [t=0.17s]
prediction: ['[CLS] no john smiths attended smith meeting. [SEP]']
[ 600/2000] tot_loss=1.438 (perp=6.666, rec=0.082, cos=0.022), tot_loss_proj:2.893 [t=0.17s]
prediction: ['[CLS] no john smiths attended smith meeting. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.437 (perp=6.666, rec=0.082, cos=0.022), tot_loss_proj:2.905 [t=0.17s]
prediction: ['[CLS] no john smiths attended smith meeting. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.400 (perp=6.504, rec=0.078, cos=0.021), tot_loss_proj:2.087 [t=0.17s]
prediction: ['[CLS] no john smiths attended any meeting. [SEP]']
[ 750/2000] tot_loss=1.262 (perp=5.850, rec=0.073, cos=0.020), tot_loss_proj:1.353 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.258 (perp=5.850, rec=0.069, cos=0.019), tot_loss_proj:1.354 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.253 (perp=5.850, rec=0.064, cos=0.019), tot_loss_proj:1.359 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
[ 900/2000] tot_loss=1.258 (perp=5.850, rec=0.069, cos=0.019), tot_loss_proj:1.352 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.250 (perp=5.850, rec=0.061, cos=0.019), tot_loss_proj:1.346 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.251 (perp=5.850, rec=0.063, cos=0.019), tot_loss_proj:1.352 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
[1050/2000] tot_loss=1.255 (perp=5.850, rec=0.067, cos=0.019), tot_loss_proj:1.364 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.252 (perp=5.850, rec=0.063, cos=0.019), tot_loss_proj:1.349 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.257 (perp=5.850, rec=0.069, cos=0.019), tot_loss_proj:1.352 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
[1200/2000] tot_loss=1.246 (perp=5.850, rec=0.057, cos=0.019), tot_loss_proj:1.352 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.255 (perp=5.850, rec=0.066, cos=0.019), tot_loss_proj:1.354 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.253 (perp=5.850, rec=0.064, cos=0.019), tot_loss_proj:1.352 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
[1350/2000] tot_loss=1.251 (perp=5.850, rec=0.062, cos=0.019), tot_loss_proj:1.365 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.247 (perp=5.850, rec=0.058, cos=0.019), tot_loss_proj:1.347 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.245 (perp=5.850, rec=0.056, cos=0.019), tot_loss_proj:1.363 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
[1500/2000] tot_loss=1.254 (perp=5.850, rec=0.065, cos=0.019), tot_loss_proj:1.355 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.256 (perp=5.850, rec=0.067, cos=0.019), tot_loss_proj:1.355 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.242 (perp=5.850, rec=0.054, cos=0.019), tot_loss_proj:1.347 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
[1650/2000] tot_loss=1.252 (perp=5.850, rec=0.063, cos=0.019), tot_loss_proj:1.359 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.244 (perp=5.850, rec=0.055, cos=0.019), tot_loss_proj:1.363 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.247 (perp=5.850, rec=0.058, cos=0.019), tot_loss_proj:1.356 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
[1800/2000] tot_loss=1.251 (perp=5.850, rec=0.062, cos=0.019), tot_loss_proj:1.355 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.257 (perp=5.850, rec=0.068, cos=0.019), tot_loss_proj:1.348 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.242 (perp=5.850, rec=0.053, cos=0.019), tot_loss_proj:1.354 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
[1950/2000] tot_loss=1.249 (perp=5.850, rec=0.060, cos=0.019), tot_loss_proj:1.354 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.256 (perp=5.850, rec=0.067, cos=0.019), tot_loss_proj:1.351 [t=0.17s]
prediction: ['[CLS] no john smiths attended the meeting. [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] no john smiths attended the meeting. [SEP]
========================
predicted: 
========================
[CLS] no john smiths attended the meeting. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 78.464 | p: 79.794 | r: 77.418
rouge2     | fm: 38.673 | p: 38.851 | r: 38.700
rougeL     | fm: 69.035 | p: 70.200 | r: 68.345
rougeLsum  | fm: 68.934 | p: 70.088 | r: 68.159
r1fm+r2fm = 117.137

input #24 time: 0:07:03 | total time: 2:55:02


Running input #25 of 100.
reference: 
========================
I did not, as Bill had thought, go to the store.
========================
Sample: 0 3.2518767898798546e-12 0.05067504920299594 0.3423586
average of cosine similarity 0.9889847651752803
highest_index [0]
highest [0.9889847651752803]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2106, 2025, 1010, 2004, 3021, 2018, 2245, 1010, 2175, 2000,
         1996, 3573, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i did not, as bill had thought, go to the store. [SEP]']
[Init] best rec loss: 0.9354310631752014 for ['[CLS] zu sussex wig son committed koppen youth part sc missile combat carrier licence magazine [SEP]']
[Init] best rec loss: 0.9029408693313599 for ['[CLS] air moisture each van kind pl tribes fulltou nod resolvedhesivevan affair [SEP]']
[Init] best rec loss: 0.8997546434402466 for ['[CLS] roma act roof sperm senior take driven thinking leaguevers coast bettynett nurse [SEP]']
[Init] best rec loss: 0.8800485134124756 for ['[CLS] arrive ana ren thick stared lieutenant political sin skye betule delaware rhea commissioned [SEP]']
[Init] best perm rec loss: 0.8734595775604248 for ['[CLS] arriveule ren political thick lieutenant skye delaware rhea sin bet commissioned ana stared [SEP]']
[Init] best perm rec loss: 0.873327374458313 for ['[CLS] skye ana bet rhea lieutenant sinule stared ren commissioned delaware political arrive thick [SEP]']
[Init] best perm rec loss: 0.8728404641151428 for ['[CLS] bet lieutenant sin anaule commissioned delaware political ren stared skye thick arrive rhea [SEP]']
[Init] best perm rec loss: 0.8718591928482056 for ['[CLS] delaware rhea ren political lieutenant commissioned sinule stared thick bet skye ana arrive [SEP]']
[Init] best perm rec loss: 0.869565486907959 for ['[CLS] rhea lieutenant skye stared commissioned sin delaware ana ren betule political arrive thick [SEP]']
[Init] best perm rec loss: 0.869038999080658 for ['[CLS] rhea thick lieutenant ana bet sin ren commissioned politicalule stared skye delaware arrive [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.003 (perp=12.215, rec=0.454, cos=0.107), tot_loss_proj:4.374 [t=0.17s]
prediction: ['[CLS] ; rand exhibit rock constituent of renamed ku chicago dog religionfield country become [SEP]']
[ 100/2000] tot_loss=2.424 (perp=9.677, rec=0.411, cos=0.078), tot_loss_proj:3.827 [t=0.17s]
prediction: ['[CLS] ; extension did larry parcel, did. did cents bannerfield destination build [SEP]']
[ 150/2000] tot_loss=2.053 (perp=8.478, rec=0.315, cos=0.043), tot_loss_proj:3.651 [t=0.17s]
prediction: ['[CLS], bill did & i, did. did stated banner = boundaries become [SEP]']
[ 200/2000] tot_loss=2.081 (perp=8.725, rec=0.291, cos=0.045), tot_loss_proj:3.665 [t=0.19s]
prediction: ['[CLS] as bill did ( i, did. did statedland - not attend [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.138 (perp=9.144, rec=0.270, cos=0.040), tot_loss_proj:3.731 [t=0.17s]
prediction: ['[CLS] as thought did (, i did. find galaxies banner. cannot went [SEP]']
[ 300/2000] tot_loss=1.755 (perp=7.397, rec=0.230, cos=0.045), tot_loss_proj:3.334 [t=0.17s]
prediction: ['[CLS] as thought bill store, i did. find thought go, could go [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.437 (perp=9.608, rec=0.414, cos=0.102), tot_loss_proj:3.839 [t=0.17s]
prediction: ['[CLS] ; not bill body, i did medvier thought coastback thought into [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.263 (perp=9.021, rec=0.375, cos=0.084), tot_loss_proj:3.652 [t=0.17s]
prediction: ['[CLS] ; not thought body, i did medvier thought coastback bill into [SEP]']
[ 450/2000] tot_loss=2.278 (perp=9.614, rec=0.306, cos=0.050), tot_loss_proj:3.771 [t=0.17s]
prediction: ['[CLS] ; not thought body, my did medvier thought coastback bill into [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.231 (perp=9.543, rec=0.281, cos=0.041), tot_loss_proj:3.782 [t=0.17s]
prediction: ['[CLS] ; not thought where, i didview med thought coastback bill go [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.127 (perp=9.123, rec=0.264, cos=0.038), tot_loss_proj:3.746 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did where med thought coastback bill go [SEP]']
[ 600/2000] tot_loss=2.105 (perp=9.123, rec=0.246, cos=0.034), tot_loss_proj:3.746 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did where med thought coastback bill go [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.040 (perp=8.832, rec=0.242, cos=0.032), tot_loss_proj:3.689 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did where med thought coast go billback [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.030 (perp=8.832, rec=0.232, cos=0.031), tot_loss_proj:3.687 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did where med thought coast go billback [SEP]']
[ 750/2000] tot_loss=1.926 (perp=8.368, rec=0.222, cos=0.031), tot_loss_proj:3.601 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did where the thought coast go billback [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.920 (perp=8.368, rec=0.216, cos=0.030), tot_loss_proj:3.604 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did where the thought coast go billback [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.021 (perp=8.901, rec=0.211, cos=0.030), tot_loss_proj:3.647 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did stores the thought coast go billback [SEP]']
[ 900/2000] tot_loss=2.009 (perp=8.901, rec=0.199, cos=0.030), tot_loss_proj:3.654 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did stores the thought coast go billback [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.938 (perp=8.501, rec=0.209, cos=0.029), tot_loss_proj:3.607 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did stores the go coast thought billback [SEP]']
Attempt swap
[1000/2000] tot_loss=1.929 (perp=8.501, rec=0.200, cos=0.029), tot_loss_proj:3.600 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did stores the go coast thought billback [SEP]']
[1050/2000] tot_loss=1.930 (perp=8.501, rec=0.201, cos=0.029), tot_loss_proj:3.602 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did stores the go coast thought billback [SEP]']
Attempt swap
[1100/2000] tot_loss=1.838 (perp=8.063, rec=0.197, cos=0.028), tot_loss_proj:3.555 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did stores the go coast thought bill ( [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.841 (perp=8.082, rec=0.193, cos=0.031), tot_loss_proj:3.552 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did go stores the store thought bill ( [SEP]']
[1200/2000] tot_loss=1.835 (perp=8.082, rec=0.190, cos=0.029), tot_loss_proj:3.554 [t=0.17s]
prediction: ['[CLS] ; not thoughtview, i did go stores the store thought bill ( [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.788 (perp=7.846, rec=0.191, cos=0.027), tot_loss_proj:3.508 [t=0.17s]
prediction: ['[CLS] ; not thoughtview stores i did go, the store thought bill ( [SEP]']
Attempt swap
[1300/2000] tot_loss=1.785 (perp=7.846, rec=0.189, cos=0.027), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] ; not thoughtview stores i did go, the store thought bill ( [SEP]']
[1350/2000] tot_loss=1.777 (perp=7.846, rec=0.181, cos=0.027), tot_loss_proj:3.510 [t=0.17s]
prediction: ['[CLS] ; not thoughtview stores i did go, the store thought bill ( [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.720 (perp=7.517, rec=0.189, cos=0.028), tot_loss_proj:3.435 [t=0.17s]
prediction: ['[CLS] ; not thought storesview i did go, the store thought bill ( [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.636 (perp=7.101, rec=0.187, cos=0.029), tot_loss_proj:3.315 [t=0.17s]
prediction: ['[CLS] ; not thought storesview i did go, the thought store bill ( [SEP]']
[1500/2000] tot_loss=1.630 (perp=7.101, rec=0.182, cos=0.028), tot_loss_proj:3.314 [t=0.17s]
prediction: ['[CLS] ; not thought storesview i did go, the thought store bill ( [SEP]']
Attempt swap
[1550/2000] tot_loss=1.638 (perp=7.101, rec=0.190, cos=0.028), tot_loss_proj:3.314 [t=0.19s]
prediction: ['[CLS] ; not thought storesview i did go, the thought store bill ( [SEP]']
Attempt swap
[1600/2000] tot_loss=1.628 (perp=7.100, rec=0.181, cos=0.027), tot_loss_proj:3.319 [t=0.17s]
prediction: ['[CLS] ; not thought storeview i did go, the thought store bill ( [SEP]']
[1650/2000] tot_loss=1.623 (perp=7.100, rec=0.176, cos=0.027), tot_loss_proj:3.319 [t=0.17s]
prediction: ['[CLS] ; not thought storeview i did go, the thought store bill ( [SEP]']
Attempt swap
[1700/2000] tot_loss=1.630 (perp=7.100, rec=0.182, cos=0.027), tot_loss_proj:3.323 [t=0.17s]
prediction: ['[CLS] ; not thought storeview i did go, the thought store bill ( [SEP]']
Attempt swap
[1750/2000] tot_loss=1.640 (perp=7.100, rec=0.192, cos=0.027), tot_loss_proj:3.321 [t=0.17s]
prediction: ['[CLS] ; not thought storeview i did go, the thought store bill ( [SEP]']
[1800/2000] tot_loss=1.620 (perp=7.100, rec=0.173, cos=0.027), tot_loss_proj:3.322 [t=0.17s]
prediction: ['[CLS] ; not thought storeview i did go, the thought store bill ( [SEP]']
Attempt swap
[1850/2000] tot_loss=1.628 (perp=7.100, rec=0.181, cos=0.027), tot_loss_proj:3.321 [t=0.17s]
prediction: ['[CLS] ; not thought storeview i did go, the thought store bill ( [SEP]']
Attempt swap
[1900/2000] tot_loss=1.632 (perp=7.100, rec=0.185, cos=0.027), tot_loss_proj:3.325 [t=0.17s]
prediction: ['[CLS] ; not thought storeview i did go, the thought store bill ( [SEP]']
[1950/2000] tot_loss=1.629 (perp=7.100, rec=0.182, cos=0.027), tot_loss_proj:3.317 [t=0.17s]
prediction: ['[CLS] ; not thought storeview i did go, the thought store bill ( [SEP]']
Attempt swap
[2000/2000] tot_loss=1.626 (perp=7.100, rec=0.179, cos=0.027), tot_loss_proj:3.320 [t=0.17s]
prediction: ['[CLS] ; not thought storeview i did go, the thought store bill ( [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] i did not, as bill had thought, go to the store. [SEP]
========================
predicted: 
========================
[CLS] ; not thought storeview i did go, the thought store bill ( [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 83.333 | r: 76.923
rouge2     | fm: 8.696 | p: 9.091 | r: 8.333
rougeL     | fm: 56.000 | p: 58.333 | r: 53.846
rougeLsum  | fm: 56.000 | p: 58.333 | r: 53.846
r1fm+r2fm = 88.696

[Aggregate metrics]:
rouge1     | fm: 78.510 | p: 80.046 | r: 77.505
rouge2     | fm: 37.630 | p: 37.787 | r: 37.630
rougeL     | fm: 68.515 | p: 69.691 | r: 67.642
rougeLsum  | fm: 68.435 | p: 69.609 | r: 67.532
r1fm+r2fm = 116.141

input #25 time: 0:07:04 | total time: 3:02:06


Running input #26 of 100.
reference: 
========================
Who will John ask for information about summer courses?
========================
Sample: 0 7.576464080684049e-12 0.04272546687478926 0.32431722
average of cosine similarity 0.9912843000137117
highest_index [0]
highest [0.9912843000137117]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2040, 2097, 2198, 3198, 2005, 2592, 2055, 2621, 5352, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] who will john ask for information about summer courses? [SEP]']
[Init] best rec loss: 0.923130989074707 for ['[CLS] certified bowedhorn ( lunch dedicated normally played stones nj [SEP]']
[Init] best rec loss: 0.9089930653572083 for ['[CLS] herself xx bat draft song questions pol horde coreoning [SEP]']
[Init] best rec loss: 0.9017698764801025 for ['[CLS] sayserly demon vapor complexvish administration wind prominent remaining [SEP]']
[Init] best rec loss: 0.8877642154693604 for ['[CLS] morgan ， marketingrcleamy credit x respective local rufus [SEP]']
[Init] best rec loss: 0.8666320443153381 for ['[CLS] wa fashionon ordinary size ou nice carrier carnegie blankets [SEP]']
[Init] best rec loss: 0.8615206480026245 for ['[CLS] significant brooke stellar motion familiar several cast tigersx student [SEP]']
[Init] best rec loss: 0.8474037051200867 for ['[CLS] pga mill known shannon om lord exercise band no around [SEP]']
[Init] best rec loss: 0.8357264399528503 for ['[CLS] louisiana societe origin suicide attached 680 athletics swallow choicethest [SEP]']
[Init] best perm rec loss: 0.8355830907821655 for ['[CLS]thest suicide swallow louisiana origin attached choice societe 680 athletics [SEP]']
[Init] best perm rec loss: 0.8355064988136292 for ['[CLS] choice louisiana origin swallowthest suicide attached societe 680 athletics [SEP]']
[Init] best perm rec loss: 0.8345492482185364 for ['[CLS] suicide swallow attached origin societe louisiana 680 athletics choicethest [SEP]']
[Init] best perm rec loss: 0.8326054215431213 for ['[CLS] louisiana societe choice origin attached athletics swallow suicide 680thest [SEP]']
[Init] best perm rec loss: 0.8323923349380493 for ['[CLS] 680 choice attached originthest suicide swallow societe louisiana athletics [SEP]']
[Init] best perm rec loss: 0.8307003378868103 for ['[CLS] societe louisiana attached origin choice 680 swallow suicidethest athletics [SEP]']
[Init] best perm rec loss: 0.8306877613067627 for ['[CLS] louisiana attachedthest choice swallow origin societe suicide 680 athletics [SEP]']
[Init] best perm rec loss: 0.8306139707565308 for ['[CLS] 680 attached societe origin athletics choice louisiana swallow suicidethest [SEP]']
[Init] best perm rec loss: 0.8287435173988342 for ['[CLS]thest swallow louisiana societe choice attached suicide origin athletics 680 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.688 (perp=10.133, rec=0.482, cos=0.180), tot_loss_proj:3.895 [t=0.17s]
prediction: ['[CLS] match.mism ranked other sabha plays matches? while [SEP]']
[ 100/2000] tot_loss=2.605 (perp=10.515, rec=0.407, cos=0.095), tot_loss_proj:3.947 [t=0.17s]
prediction: ['[CLS] include? what ranked survived would plays games? while [SEP]']
[ 150/2000] tot_loss=2.391 (perp=9.949, rec=0.351, cos=0.050), tot_loss_proj:3.904 [t=0.17s]
prediction: ['[CLS] include? whatnbc survived would seek information? while [SEP]']
[ 200/2000] tot_loss=2.298 (perp=9.854, rec=0.287, cos=0.040), tot_loss_proj:3.886 [t=0.17s]
prediction: ['[CLS] include? who excuse will will asking information? with [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.326 (perp=9.457, rec=0.361, cos=0.074), tot_loss_proj:3.681 [t=0.17s]
prediction: ['[CLS] my? who willtom will ask information? describing [SEP]']
[ 300/2000] tot_loss=2.441 (perp=9.262, rec=0.351, cos=0.238), tot_loss_proj:3.738 [t=0.17s]
prediction: ['[CLS] tax? who will excuse will ask information? horizontal [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.807 (perp=7.583, rec=0.254, cos=0.037), tot_loss_proj:3.437 [t=0.17s]
prediction: ['[CLS] of study? who will paid will ask information? [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.837 (perp=7.677, rec=0.260, cos=0.041), tot_loss_proj:3.388 [t=0.17s]
prediction: ['[CLS] to exam tuition who will? will ask information? [SEP]']
[ 450/2000] tot_loss=2.110 (perp=9.334, rec=0.214, cos=0.029), tot_loss_proj:3.731 [t=0.17s]
prediction: ['[CLS] to courses tuition who john? will ask information? [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.843 (perp=8.001, rec=0.218, cos=0.024), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] of courses who john tuition? will ask information? [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.113 (perp=9.357, rec=0.218, cos=0.024), tot_loss_proj:3.823 [t=0.17s]
prediction: ['[CLS] who courses of john tuition will will ask information? [SEP]']
[ 600/2000] tot_loss=2.090 (perp=9.357, rec=0.197, cos=0.021), tot_loss_proj:3.823 [t=0.17s]
prediction: ['[CLS] who courses of john tuition will will ask information? [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.878 (perp=8.320, rec=0.193, cos=0.021), tot_loss_proj:3.598 [t=0.17s]
prediction: ['[CLS] who will of john tuition courses will ask information? [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.797 (perp=7.953, rec=0.185, cos=0.021), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] who will tuition john of courses will ask information? [SEP]']
[ 750/2000] tot_loss=1.926 (perp=8.624, rec=0.182, cos=0.019), tot_loss_proj:3.639 [t=0.17s]
prediction: ['[CLS] who will tuition john of summer will ask information? [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.836 (perp=8.224, rec=0.172, cos=0.019), tot_loss_proj:3.603 [t=0.17s]
prediction: ['[CLS] who will john of summer tuition will ask information? [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.853 (perp=8.358, rec=0.162, cos=0.019), tot_loss_proj:3.531 [t=0.17s]
prediction: ['[CLS] who will summer to john tuition will ask information? [SEP]']
[ 900/2000] tot_loss=1.835 (perp=8.358, rec=0.145, cos=0.019), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] who will summer to john tuition will ask information? [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.826 (perp=8.318, rec=0.144, cos=0.019), tot_loss_proj:3.615 [t=0.17s]
prediction: ['[CLS] who will john to summer tuition will ask information? [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.732 (perp=7.835, rec=0.146, cos=0.019), tot_loss_proj:3.438 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask tuition? [SEP]']
[1050/2000] tot_loss=1.705 (perp=7.835, rec=0.119, cos=0.019), tot_loss_proj:3.431 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask tuition? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.712 (perp=7.835, rec=0.126, cos=0.018), tot_loss_proj:3.437 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask tuition? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.713 (perp=7.835, rec=0.128, cos=0.018), tot_loss_proj:3.434 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask tuition? [SEP]']
[1200/2000] tot_loss=1.720 (perp=7.835, rec=0.135, cos=0.018), tot_loss_proj:3.431 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask tuition? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.694 (perp=7.725, rec=0.131, cos=0.018), tot_loss_proj:3.380 [t=0.18s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.680 (perp=7.725, rec=0.117, cos=0.018), tot_loss_proj:3.380 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
[1350/2000] tot_loss=1.685 (perp=7.725, rec=0.122, cos=0.018), tot_loss_proj:3.380 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.681 (perp=7.725, rec=0.119, cos=0.018), tot_loss_proj:3.386 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.681 (perp=7.725, rec=0.119, cos=0.018), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
[1500/2000] tot_loss=1.687 (perp=7.725, rec=0.124, cos=0.018), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.674 (perp=7.725, rec=0.111, cos=0.017), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.681 (perp=7.725, rec=0.118, cos=0.017), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
[1650/2000] tot_loss=1.674 (perp=7.725, rec=0.112, cos=0.017), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.675 (perp=7.725, rec=0.113, cos=0.017), tot_loss_proj:3.380 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.680 (perp=7.725, rec=0.118, cos=0.017), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
[1800/2000] tot_loss=1.678 (perp=7.725, rec=0.116, cos=0.017), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.678 (perp=7.725, rec=0.115, cos=0.017), tot_loss_proj:3.380 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.677 (perp=7.725, rec=0.115, cos=0.017), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
[1950/2000] tot_loss=1.678 (perp=7.725, rec=0.116, cos=0.017), tot_loss_proj:3.382 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.674 (perp=7.725, rec=0.112, cos=0.017), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] who will john to summer information will ask courses? [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] who will john ask for information about summer courses? [SEP]
========================
predicted: 
========================
[CLS] who will john to summer information will ask courses? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 121.818

[Aggregate metrics]:
rouge1     | fm: 78.690 | p: 80.092 | r: 77.707
rouge2     | fm: 37.734 | p: 38.002 | r: 37.762
rougeL     | fm: 68.293 | p: 69.559 | r: 67.425
rougeLsum  | fm: 68.125 | p: 69.332 | r: 67.250
r1fm+r2fm = 116.424

input #26 time: 0:07:08 | total time: 3:09:15


Running input #27 of 100.
reference: 
========================
Ron wanted to wear a tuxedo to the party, but Caspar couldn't decide whether to.
========================
Sample: 0 5.4863595142054834e-12 0.0427272008369945 0.32658345
average of cosine similarity 0.9914047058977643
highest_index [0]
highest [0.9914047058977643]
Debug: ids_shape = 24, pads = [24]
Debug: input ids = tensor([[  101,  6902,  2359,  2000,  4929,  1037, 10722, 19068,  2080,  2000,
          1996,  2283,  1010,  2021, 25222, 19362,  2481,  1005,  1056,  5630,
          3251,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]"]
[Init] best rec loss: 0.9158304333686829 for ['[CLS]ig operated already block sad pac further armenians songs, fund book waters line buy willis relief strike collaborative tack violet bring [SEP]']
[Init] best rec loss: 0.9106042981147766 for ['[CLS] glory money divided paidckenging pressedent magneticance baptist tasteroving [SEP] echo jeremy cipher warrant 』 option measures shot [SEP]']
[Init] best rec loss: 0.897331953048706 for ['[CLS] hay swedish scholars similarities passing sounds bruno anyway accountcy accounts quantum zelity excellence summer diego hepburn documentation buried would league [SEP]']
[Init] best rec loss: 0.8913874626159668 for ['[CLS] perhaps whateveriff implement suit jam silk recruits county reidcted japan smellbed campus needs strolledlem minimum values legs monty [SEP]']
[Init] best rec loss: 0.8904507160186768 for ['[CLS]mum medley basis school started primaries 500ization terrific available boundgies film ninebered constellation edcule gan switch week waters [SEP]']
[Init] best rec loss: 0.8834986686706543 for ['[CLS] devote simulator filled kidd contrast orientucherctive nba ll past ticked rhysbad impgle stereo ferries possibility shooterphone dad [SEP]']
[Init] best rec loss: 0.8819141983985901 for ['[CLS] thesefold ant integration seconds news only advantage epithetpants governed s number agents published every guard bulgarian particular flying dental evening [SEP]']
[Init] best rec loss: 0.8795796036720276 for ['[CLS]vet levelgam findings what deployment weeks claimed rivers lights incumbent always shot callum recordldongesttle regional tank mat university [SEP]']
[Init] best perm rec loss: 0.8790776133537292 for ['[CLS] level shot university matges lights incumbent deployment weeks claimed tank riversgam regional always callum recordldon findingsttlevet what [SEP]']
[Init] best perm rec loss: 0.8726145625114441 for ['[CLS] deployment claimed riversttlevet weeks what findings university levelgam lights mat record callum alwaysgesldon regional shot tank incumbent [SEP]']
[Init] best perm rec loss: 0.8725971579551697 for ['[CLS]ldon universityvet shotgam callumges rivers what recordttle always lights tank level incumbent regional weeks deployment claimed findings mat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.144 (perp=12.531, rec=0.669, cos=0.969), tot_loss_proj:4.354 [t=0.18s]
prediction: ['[CLS] raf santa von information doorway conservatory to switchrrado how materials as [SEP] -.cturing than premier tennistaking ， est [SEP]']
[ 100/2000] tot_loss=3.211 (perp=13.849, rec=0.363, cos=0.079), tot_loss_proj:4.689 [t=0.18s]
prediction: ['[CLS] negative governor wild technology doorway nedra to ton paddington at prime act coalition william couldnpar refused behalf wedding poems chateau antigen [SEP]']
[ 150/2000] tot_loss=2.618 (perp=11.753, rec=0.239, cos=0.029), tot_loss_proj:4.202 [t=0.18s]
prediction: ['[CLS] ron governor yourure originally. to wheel jacket at to, somehow ron couldnpar decided whether wedding poems chateaupar [SEP]']
[ 200/2000] tot_loss=2.582 (perp=11.830, rec=0.189, cos=0.027), tot_loss_proj:4.134 [t=0.18s]
prediction: ['[CLS] ron party yourure wanted to to opportunity jacket to to, but ron couldnpar decide whether wear stemmed chateaupar [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.612 (perp=12.028, rec=0.182, cos=0.024), tot_loss_proj:4.250 [t=0.18s]
prediction: ['[CLS] chick party yourure wanted to to fours jacket to to, cas ron couldnpar decide whether wear ron chosepar [SEP]']
[ 300/2000] tot_loss=2.197 (perp=10.116, rec=0.148, cos=0.025), tot_loss_proj:3.821 [t=0.18s]
prediction: ['[CLS] chick party the birthday wanted to to big. not to and cas ron couldnpar decide whether wear ron ;par [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.484 (perp=10.987, rec=0.243, cos=0.044), tot_loss_proj:4.043 [t=0.18s]
prediction: ['[CLS] scent party pet akeeping wanted gotta ton. to a bacteria but ron couldnpar decide whether party let.par [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.421 (perp=11.030, rec=0.184, cos=0.031), tot_loss_proj:4.084 [t=0.18s]
prediction: ['[CLS] cas party pet.keeping wanted gotta ton. to a might but ron couldnpar whether whetherwy or party, [SEP]']
[ 450/2000] tot_loss=2.391 (perp=11.030, rec=0.160, cos=0.026), tot_loss_proj:4.077 [t=0.18s]
prediction: ['[CLS] cas party pet.keeping wanted gotta ton. to a might but ron couldnpar whether whetherwy or party, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.262 (perp=10.384, rec=0.161, cos=0.024), tot_loss_proj:3.959 [t=0.18s]
prediction: ['[CLS]. party pet.keeping wanted gotta ton cas to a might but ron couldnpar whether whetherwy or party. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.279 (perp=10.496, rec=0.156, cos=0.024), tot_loss_proj:3.975 [t=0.18s]
prediction: ['[CLS]. party. clothing wanted gotta pet ton cas to a might but ron couldnpar whetherxed ⁻ or wear. [SEP]']
[ 600/2000] tot_loss=2.410 (perp=11.211, rec=0.145, cos=0.022), tot_loss_proj:4.102 [t=0.18s]
prediction: ['[CLS]. party. clothing wanted gotta pet ton cas cas, might but ron couldnpar whetherxed ⁻ yet wear. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.179 (perp=10.068, rec=0.144, cos=0.022), tot_loss_proj:3.904 [t=0.18s]
prediction: ['[CLS].. party clothing wanted gotta pet ton cas cas, might but ron couldnpar whetherxed. or wear. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.113 (perp=9.774, rec=0.137, cos=0.021), tot_loss_proj:3.828 [t=0.18s]
prediction: ['[CLS].. party clothing wanted gotta pet tonxed cas, might but ron couldnpar whether cas. or wear. [SEP]']
[ 750/2000] tot_loss=2.065 (perp=9.595, rec=0.125, cos=0.021), tot_loss_proj:3.788 [t=0.18s]
prediction: ['[CLS].. party clothing wanted gotta pet tonxed cas, might but ron couldnpar whether cas did or wear. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.133 (perp=9.881, rec=0.133, cos=0.024), tot_loss_proj:3.846 [t=0.18s]
prediction: ['[CLS]. : party clothing wanted gotta pet ton, cas tu might but ron couldnpar whether cas did to wear. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.055 (perp=9.517, rec=0.129, cos=0.022), tot_loss_proj:3.784 [t=0.18s]
prediction: ['[CLS]. : party clothing wanted gotta pet cas, ton tu might but ron couldnpar whether cas to or wear. [SEP]']
[ 900/2000] tot_loss=2.084 (perp=9.723, rec=0.118, cos=0.021), tot_loss_proj:3.823 [t=0.18s]
prediction: ['[CLS]. : party clothing wanted gotta s cas, ton tu might but ron couldnpar whether cas to or wear. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.035 (perp=9.456, rec=0.123, cos=0.020), tot_loss_proj:3.759 [t=0.18s]
prediction: ['[CLS] the. partykeeping wanted. s cas, ton tu might but ron couldnpar whether cas to or wear. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.932 (perp=8.939, rec=0.124, cos=0.020), tot_loss_proj:3.646 [t=0.18s]
prediction: ['[CLS]keeping. party the wanted. s cas, tonxed might but ron couldnpar whether cas to or wear. [SEP]']
[1050/2000] tot_loss=1.918 (perp=8.939, rec=0.111, cos=0.020), tot_loss_proj:3.646 [t=0.18s]
prediction: ['[CLS]keeping. party the wanted. s cas, tonxed might but ron couldnpar whether cas to or wear. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.936 (perp=9.017, rec=0.113, cos=0.020), tot_loss_proj:3.689 [t=0.18s]
prediction: ['[CLS]keeping. party the wanted. ton cas, sxed chew but ron couldnpar whether cas to or wear. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.846 (perp=8.545, rec=0.117, cos=0.020), tot_loss_proj:3.582 [t=0.18s]
prediction: ['[CLS]keeping. party the wanted. ton cas, sxed might but ron couldnpar whether cas to wear or. [SEP]']
[1200/2000] tot_loss=1.905 (perp=8.808, rec=0.123, cos=0.019), tot_loss_proj:3.635 [t=0.18s]
prediction: ['[CLS]彳. party the wanted. ton cas, sxed might but ron couldnpar whether cas to wear or. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.847 (perp=8.545, rec=0.118, cos=0.020), tot_loss_proj:3.585 [t=0.18s]
prediction: ['[CLS]彳. the party wanted. ton cas, sxed might but ron couldnpar whether cas to wear or. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.808 (perp=8.286, rec=0.131, cos=0.020), tot_loss_proj:3.567 [t=0.18s]
prediction: ['[CLS]彳.. the party wanted ton cas, sxed might but ron couldnpar whether cas to wear or. [SEP]']
[1350/2000] tot_loss=1.784 (perp=8.286, rec=0.108, cos=0.020), tot_loss_proj:3.562 [t=0.18s]
prediction: ['[CLS]彳.. the party wanted ton cas, sxed might but ron couldnpar whether cas to wear or. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.762 (perp=8.171, rec=0.109, cos=0.019), tot_loss_proj:3.547 [t=0.18s]
prediction: ['[CLS].. the party wanted ton cas,彳 sxed might but ron couldnpar whether cas to wear or. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.829 (perp=8.524, rec=0.105, cos=0.019), tot_loss_proj:3.610 [t=0.18s]
prediction: ['[CLS].. the party wantedde cas, or sxed might but ron couldnpar whether cas to wear彳. [SEP]']
[1500/2000] tot_loss=1.827 (perp=8.524, rec=0.104, cos=0.019), tot_loss_proj:3.613 [t=0.18s]
prediction: ['[CLS].. the party wantedde cas, or sxed might but ron couldnpar whether cas to wear彳. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.596 (perp=7.322, rec=0.112, cos=0.020), tot_loss_proj:3.383 [t=0.18s]
prediction: ['[CLS].. the party wanted cas, or sxed might but ronde couldnpar whether cas to wear clothing. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.604 (perp=7.322, rec=0.120, cos=0.020), tot_loss_proj:3.380 [t=0.18s]
prediction: ['[CLS].. the party wanted cas, or sxed might but ronde couldnpar whether cas to wear clothing. [SEP]']
[1650/2000] tot_loss=1.600 (perp=7.322, rec=0.116, cos=0.020), tot_loss_proj:3.387 [t=0.18s]
prediction: ['[CLS].. the party wanted cas, or sxed might but ronde couldnpar whether cas to wear clothing. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.598 (perp=7.322, rec=0.115, cos=0.019), tot_loss_proj:3.387 [t=0.18s]
prediction: ['[CLS].. the party wanted cas, or sxed might but ronde couldnpar whether cas to wear clothing. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.604 (perp=7.322, rec=0.120, cos=0.019), tot_loss_proj:3.381 [t=0.18s]
prediction: ['[CLS].. the party wanted cas, or sxed might but ronde couldnpar whether cas to wear clothing. [SEP]']
[1800/2000] tot_loss=1.639 (perp=7.553, rec=0.109, cos=0.019), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS].. the party wanted cas, to sxed might but ronde couldnpar whether cas to wear clothing. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.602 (perp=7.336, rec=0.116, cos=0.019), tot_loss_proj:3.381 [t=0.18s]
prediction: ['[CLS].. the party wanted cas, or sxed but might ronde couldnpar whether cas to wear clothing. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.634 (perp=7.553, rec=0.104, cos=0.019), tot_loss_proj:3.426 [t=0.18s]
prediction: ['[CLS].. the party wanted cas, to sxed might but ronde couldnpar whether cas to wear clothing. [SEP]']
[1950/2000] tot_loss=1.636 (perp=7.553, rec=0.106, cos=0.019), tot_loss_proj:3.422 [t=0.18s]
prediction: ['[CLS].. the party wanted cas, to sxed might but ronde couldnpar whether cas to wear clothing. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.634 (perp=7.553, rec=0.104, cos=0.019), tot_loss_proj:3.431 [t=0.18s]
prediction: ['[CLS].. the party wanted cas, to sxed might but ronde couldnpar whether cas to wear clothing. [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]
========================
predicted: 
========================
[CLS].. the party wanted cas, or sxed might but ronde couldnpar whether cas to wear clothing. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 51.429 | p: 52.941 | r: 50.000
rouge2     | fm: 12.121 | p: 12.500 | r: 11.765
rougeL     | fm: 40.000 | p: 41.176 | r: 38.889
rougeLsum  | fm: 40.000 | p: 41.176 | r: 38.889
r1fm+r2fm = 63.550

[Aggregate metrics]:
rouge1     | fm: 77.531 | p: 78.983 | r: 76.647
rouge2     | fm: 36.667 | p: 36.867 | r: 36.794
rougeL     | fm: 67.428 | p: 68.607 | r: 66.540
rougeLsum  | fm: 67.125 | p: 68.336 | r: 66.275
r1fm+r2fm = 114.198

input #27 time: 0:07:26 | total time: 3:16:41


Running input #28 of 100.
reference: 
========================
Bill gave Sue the book.
========================
Sample: 0 3.665816137516211e-12 0.05367637703239208 0.37147304
average of cosine similarity 0.9895053384011018
highest_index [0]
highest [0.9895053384011018]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 3021, 2435, 9790, 1996, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bill gave sue the book. [SEP]']
[Init] best rec loss: 0.9755856394767761 for ['[CLS] martin links ponder _ borntist [SEP]']
[Init] best rec loss: 0.9694833755493164 for ['[CLS] grain farm processing fielding following pierced [SEP]']
[Init] best rec loss: 0.9555665254592896 for ['[CLS] whoever mphaghan live manor patrol [SEP]']
[Init] best rec loss: 0.9311076998710632 for ['[CLS]cked nicknamed me hardware colour boil [SEP]']
[Init] best rec loss: 0.8972436189651489 for ['[CLS] anniversary deposit ethan baroque barnet recently [SEP]']
[Init] best perm rec loss: 0.8948907256126404 for ['[CLS] recently anniversary baroque ethan barnet deposit [SEP]']
[Init] best perm rec loss: 0.8926964402198792 for ['[CLS] ethan baroque barnet recently deposit anniversary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.031 (perp=11.961, rec=0.658, cos=0.982), tot_loss_proj:4.229 [t=0.17s]
prediction: ['[CLS] getting backed particularly short annabellession [SEP]']
[ 100/2000] tot_loss=4.134 (perp=12.825, rec=0.595, cos=0.974), tot_loss_proj:4.467 [t=0.17s]
prediction: ['[CLS] giving yeah bill filmed billssion [SEP]']
[ 150/2000] tot_loss=3.975 (perp=12.723, rec=0.516, cos=0.914), tot_loss_proj:4.476 [t=0.17s]
prediction: ['[CLS] giving stanton bill je bill legislation [SEP]']
[ 200/2000] tot_loss=4.116 (perp=13.310, rec=0.543, cos=0.912), tot_loss_proj:4.443 [t=0.17s]
prediction: ['[CLS] givingbbing billudence bill spent [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.707 (perp=11.773, rec=0.487, cos=0.866), tot_loss_proj:4.274 [t=0.17s]
prediction: ['[CLS] giving bill johnnie impressed bill programs [SEP]']
[ 300/2000] tot_loss=3.586 (perp=11.424, rec=0.442, cos=0.859), tot_loss_proj:4.257 [t=0.17s]
prediction: ['[CLS] gave bill suebbing bill dollars [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.527 (perp=11.424, rec=0.427, cos=0.816), tot_loss_proj:4.261 [t=0.17s]
prediction: ['[CLS] gave bill suebbing bill dollars [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.453 (perp=11.424, rec=0.421, cos=0.748), tot_loss_proj:4.254 [t=0.17s]
prediction: ['[CLS] gave bill suebbing bill dollars [SEP]']
[ 450/2000] tot_loss=3.562 (perp=11.828, rec=0.432, cos=0.764), tot_loss_proj:4.247 [t=0.17s]
prediction: ['[CLS] gave bill sue sue bill dollars [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.363 (perp=11.601, rec=0.416, cos=0.627), tot_loss_proj:4.239 [t=0.17s]
prediction: ['[CLS] gave johnnie bill sue bill trophy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.972 (perp=10.960, rec=0.429, cos=0.351), tot_loss_proj:4.002 [t=0.17s]
prediction: ['[CLS] bill nomination gave sue bill sheet [SEP]']
[ 600/2000] tot_loss=2.552 (perp=11.451, rec=0.218, cos=0.044), tot_loss_proj:4.207 [t=0.17s]
prediction: ['[CLS] bill sue gave sue sue which [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.423 (perp=11.119, rec=0.167, cos=0.032), tot_loss_proj:4.076 [t=0.17s]
prediction: ['[CLS] sue the gave bill sue book [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.088 (perp=9.474, rec=0.163, cos=0.030), tot_loss_proj:3.755 [t=0.17s]
prediction: ['[CLS] sue bill gave the sue book [SEP]']
[ 750/2000] tot_loss=2.044 (perp=9.474, rec=0.123, cos=0.027), tot_loss_proj:3.758 [t=0.17s]
prediction: ['[CLS] sue bill gave the sue book [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.940 (perp=9.028, rec=0.108, cos=0.026), tot_loss_proj:3.703 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.945 (perp=9.028, rec=0.114, cos=0.025), tot_loss_proj:3.703 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[ 900/2000] tot_loss=1.933 (perp=9.028, rec=0.103, cos=0.025), tot_loss_proj:3.701 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.918 (perp=9.028, rec=0.088, cos=0.024), tot_loss_proj:3.701 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1000/2000] tot_loss=1.929 (perp=9.028, rec=0.099, cos=0.024), tot_loss_proj:3.707 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[1050/2000] tot_loss=1.929 (perp=9.028, rec=0.100, cos=0.024), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1100/2000] tot_loss=1.935 (perp=9.028, rec=0.105, cos=0.024), tot_loss_proj:3.702 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1150/2000] tot_loss=1.919 (perp=9.028, rec=0.090, cos=0.024), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[1200/2000] tot_loss=1.920 (perp=9.028, rec=0.091, cos=0.024), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1250/2000] tot_loss=1.932 (perp=9.028, rec=0.103, cos=0.024), tot_loss_proj:3.699 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1300/2000] tot_loss=1.930 (perp=9.028, rec=0.101, cos=0.024), tot_loss_proj:3.694 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[1350/2000] tot_loss=1.932 (perp=9.028, rec=0.103, cos=0.024), tot_loss_proj:3.695 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1400/2000] tot_loss=1.916 (perp=9.028, rec=0.087, cos=0.024), tot_loss_proj:3.696 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1450/2000] tot_loss=1.917 (perp=9.028, rec=0.088, cos=0.024), tot_loss_proj:3.712 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[1500/2000] tot_loss=1.919 (perp=9.028, rec=0.089, cos=0.024), tot_loss_proj:3.699 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1550/2000] tot_loss=1.922 (perp=9.028, rec=0.093, cos=0.023), tot_loss_proj:3.690 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1600/2000] tot_loss=1.926 (perp=9.028, rec=0.097, cos=0.024), tot_loss_proj:3.701 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[1650/2000] tot_loss=1.917 (perp=9.028, rec=0.088, cos=0.024), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1700/2000] tot_loss=1.930 (perp=9.028, rec=0.101, cos=0.023), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1750/2000] tot_loss=1.928 (perp=9.028, rec=0.099, cos=0.023), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[1800/2000] tot_loss=1.917 (perp=9.028, rec=0.088, cos=0.023), tot_loss_proj:3.704 [t=0.26s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1850/2000] tot_loss=1.925 (perp=9.028, rec=0.096, cos=0.023), tot_loss_proj:3.704 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[1900/2000] tot_loss=1.921 (perp=9.028, rec=0.092, cos=0.023), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
[1950/2000] tot_loss=1.911 (perp=9.028, rec=0.082, cos=0.023), tot_loss_proj:3.702 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Attempt swap
[2000/2000] tot_loss=1.915 (perp=9.028, rec=0.086, cos=0.023), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] sue bill gave sue the book [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] bill gave sue the book. [SEP]
========================
predicted: 
========================
[CLS] sue bill gave sue the book [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 78.130 | p: 79.263 | r: 77.337
rouge2     | fm: 38.147 | p: 38.201 | r: 38.404
rougeL     | fm: 68.277 | p: 69.116 | r: 67.690
rougeLsum  | fm: 67.928 | p: 68.989 | r: 67.383
r1fm+r2fm = 116.277

input #28 time: 0:06:58 | total time: 3:23:40


Running input #29 of 100.
reference: 
========================
The bread was chewed by Martha.
========================
Sample: 0 1.0822166446818419e-11 0.047381710733494356 0.34812495
average of cosine similarity 0.9906943709755613
highest_index [0]
highest [0.9906943709755613]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996,  7852,  2001, 18362,  2011,  9246,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the bread was chewed by martha. [SEP]']
[Init] best rec loss: 1.033448576927185 for ['[CLS] squeezed pace bonnie know plantsoic bishop [SEP]']
[Init] best rec loss: 0.9979770183563232 for ['[CLS] party morrison #ramet animated fluent [SEP]']
[Init] best rec loss: 0.9941338300704956 for ['[CLS] chewed attack turing science sport tontist [SEP]']
[Init] best rec loss: 0.9654293060302734 for ['[CLS] rose worth cowboys aresror affair links [SEP]']
[Init] best rec loss: 0.9611841440200806 for ['[CLS] initially begingram als mothscode loan [SEP]']
[Init] best rec loss: 0.9402060508728027 for ['[CLS] guardian blocked printed, entry important household [SEP]']
[Init] best perm rec loss: 0.9361010789871216 for ['[CLS] guardian important printed entry, blocked household [SEP]']
[Init] best perm rec loss: 0.9354170560836792 for ['[CLS] important entry household, printed guardian blocked [SEP]']
[Init] best perm rec loss: 0.9348337054252625 for ['[CLS], printed blocked entry important guardian household [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.733 (perp=11.453, rec=0.373, cos=0.069), tot_loss_proj:4.072 [t=0.17s]
prediction: ['[CLS] meat bread was cream glorious chewed by [SEP]']
[ 100/2000] tot_loss=2.331 (perp=10.507, rec=0.194, cos=0.036), tot_loss_proj:3.820 [t=0.17s]
prediction: ['[CLS] bread bread was martha chewed chewed by [SEP]']
[ 150/2000] tot_loss=2.238 (perp=10.507, rec=0.110, cos=0.026), tot_loss_proj:3.815 [t=0.17s]
prediction: ['[CLS] bread bread was martha chewed chewed by [SEP]']
[ 200/2000] tot_loss=2.209 (perp=10.507, rec=0.083, cos=0.025), tot_loss_proj:3.817 [t=0.17s]
prediction: ['[CLS] bread bread was martha chewed chewed by [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.869 (perp=8.326, rec=0.169, cos=0.035), tot_loss_proj:3.513 [t=0.17s]
prediction: ['[CLS]. bread was the chewed by martha [SEP]']
[ 300/2000] tot_loss=1.826 (perp=8.476, rec=0.107, cos=0.025), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] bread bread was the chewed by martha [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.505 (perp=6.955, rec=0.090, cos=0.024), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] the bread was bread chewed by martha [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.555 (perp=7.188, rec=0.093, cos=0.024), tot_loss_proj:3.576 [t=0.17s]
prediction: ['[CLS] the bread was chewed. by martha [SEP]']
[ 450/2000] tot_loss=1.536 (perp=7.188, rec=0.075, cos=0.024), tot_loss_proj:3.575 [t=0.17s]
prediction: ['[CLS] the bread was chewed. by martha [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.480 (perp=6.951, rec=0.066, cos=0.024), tot_loss_proj:3.352 [t=0.17s]
prediction: ['[CLS] the bread was chewed by. martha [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.483 (perp=6.951, rec=0.069, cos=0.023), tot_loss_proj:3.347 [t=0.17s]
prediction: ['[CLS] the bread was chewed by. martha [SEP]']
[ 600/2000] tot_loss=1.499 (perp=6.951, rec=0.086, cos=0.023), tot_loss_proj:3.353 [t=0.17s]
prediction: ['[CLS] the bread was chewed by. martha [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.336 (perp=6.120, rec=0.088, cos=0.023), tot_loss_proj:1.374 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.319 (perp=6.120, rec=0.072, cos=0.023), tot_loss_proj:1.367 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 750/2000] tot_loss=1.327 (perp=6.120, rec=0.080, cos=0.023), tot_loss_proj:1.351 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.320 (perp=6.120, rec=0.074, cos=0.023), tot_loss_proj:1.362 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.327 (perp=6.120, rec=0.080, cos=0.023), tot_loss_proj:1.366 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 900/2000] tot_loss=1.324 (perp=6.120, rec=0.078, cos=0.022), tot_loss_proj:1.364 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.322 (perp=6.120, rec=0.075, cos=0.023), tot_loss_proj:1.361 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.327 (perp=6.120, rec=0.080, cos=0.022), tot_loss_proj:1.362 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1050/2000] tot_loss=1.321 (perp=6.120, rec=0.075, cos=0.022), tot_loss_proj:1.359 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.317 (perp=6.120, rec=0.071, cos=0.022), tot_loss_proj:1.358 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.319 (perp=6.120, rec=0.072, cos=0.022), tot_loss_proj:1.358 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1200/2000] tot_loss=1.314 (perp=6.120, rec=0.068, cos=0.022), tot_loss_proj:1.352 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.328 (perp=6.120, rec=0.082, cos=0.022), tot_loss_proj:1.363 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.314 (perp=6.120, rec=0.068, cos=0.022), tot_loss_proj:1.358 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1350/2000] tot_loss=1.323 (perp=6.120, rec=0.077, cos=0.022), tot_loss_proj:1.361 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.321 (perp=6.120, rec=0.075, cos=0.022), tot_loss_proj:1.345 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.302 (perp=6.120, rec=0.060, cos=0.018), tot_loss_proj:1.350 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1500/2000] tot_loss=1.309 (perp=6.120, rec=0.067, cos=0.018), tot_loss_proj:1.368 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.306 (perp=6.120, rec=0.064, cos=0.018), tot_loss_proj:1.356 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.300 (perp=6.120, rec=0.057, cos=0.018), tot_loss_proj:1.355 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1650/2000] tot_loss=1.312 (perp=6.120, rec=0.069, cos=0.018), tot_loss_proj:1.355 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.305 (perp=6.120, rec=0.062, cos=0.018), tot_loss_proj:1.366 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.294 (perp=6.120, rec=0.051, cos=0.018), tot_loss_proj:1.360 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1800/2000] tot_loss=1.307 (perp=6.120, rec=0.064, cos=0.018), tot_loss_proj:1.362 [t=0.21s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.302 (perp=6.120, rec=0.060, cos=0.018), tot_loss_proj:1.368 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.308 (perp=6.120, rec=0.066, cos=0.018), tot_loss_proj:1.360 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1950/2000] tot_loss=1.299 (perp=6.120, rec=0.057, cos=0.018), tot_loss_proj:1.351 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.300 (perp=6.120, rec=0.058, cos=0.018), tot_loss_proj:1.359 [t=0.17s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] the bread was chewed by martha. [SEP]
========================
predicted: 
========================
[CLS] the bread was chewed by martha. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 78.798 | p: 79.973 | r: 78.135
rouge2     | fm: 40.367 | p: 40.404 | r: 40.593
rougeL     | fm: 69.291 | p: 70.235 | r: 68.752
rougeLsum  | fm: 69.145 | p: 70.041 | r: 68.674
r1fm+r2fm = 119.166

input #29 time: 0:06:59 | total time: 3:30:40


Running input #30 of 100.
reference: 
========================
Read Fred's story, I also want to.
========================
Sample: 0 3.5055815975401076e-12 0.05699342845774908 0.3759358
average of cosine similarity 0.9884412798748556
highest_index [0]
highest [0.9884412798748556]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 3191, 5965, 1005, 1055, 2466, 1010, 1045, 2036, 2215, 2000, 1012,
          102]], device='cuda:0')
Debug: ref = ["[CLS] read fred's story, i also want to. [SEP]"]
[Init] best rec loss: 0.9123356938362122 for ['[CLS] design tourea chargessionkan voicesitatingrak freedom mild [SEP]']
[Init] best rec loss: 0.8970316648483276 for ['[CLS] oil thornton sc platoon scouts reserves town perennial mounted fundamental of [SEP]']
[Init] best rec loss: 0.881742537021637 for ['[CLS] withdrawnnesia lucas planned coloursix oak amin cooper morgan houses [SEP]']
[Init] best rec loss: 0.8782221674919128 for ['[CLS] attempted roadpherizan watches looked mercy wedding momect husbands [SEP]']
[Init] best rec loss: 0.8723532557487488 for ['[CLS] spread happening meant advisory sniff record scheduled justice baltimore straightopa [SEP]']
[Init] best rec loss: 0.865502655506134 for ['[CLS] conference waiting divided twin sweat ponye criminal universe family window [SEP]']
[Init] best rec loss: 0.8589546084403992 for ['[CLS] athleticffled tallinn dial commonly gallery acc relation ruby speakingski [SEP]']
[Init] best rec loss: 0.8508736491203308 for ['[CLS] oldest mon station video moi reserve conference non coming combatathlon [SEP]']
[Init] best perm rec loss: 0.8473225235939026 for ['[CLS]athlon combat coming oldest video moi reserve conference mon non station [SEP]']
[Init] best perm rec loss: 0.8470238447189331 for ['[CLS]athlon station combat reserve moi mon coming video conference non oldest [SEP]']
[Init] best perm rec loss: 0.8467389345169067 for ['[CLS]athlon oldest conference video coming reserve mon moi station non combat [SEP]']
[Init] best perm rec loss: 0.8465926051139832 for ['[CLS] moi oldest video station conference combat nonathlon reserve coming mon [SEP]']
[Init] best perm rec loss: 0.8462216258049011 for ['[CLS] reserve video station comingathlon combat non conference moi mon oldest [SEP]']
[Init] best perm rec loss: 0.8446699976921082 for ['[CLS] nonathlon mon station oldest combat video reserve moi coming conference [SEP]']
[Init] best perm rec loss: 0.8441019058227539 for ['[CLS] conference station reserveathlon oldest coming video combat mon non moi [SEP]']
[Init] best perm rec loss: 0.8434234261512756 for ['[CLS] combatathlon station video coming conference moi mon reserve non oldest [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.075 (perp=12.416, rec=0.603, cos=0.989), tot_loss_proj:4.246 [t=0.17s]
prediction: ['[CLS] assassination chapter, read civil kappa done treatise grenade payment most [SEP]']
[ 100/2000] tot_loss=3.586 (perp=10.138, rec=0.581, cos=0.978), tot_loss_proj:3.767 [t=0.17s]
prediction: ['[CLS] pictured story, read acts / want podcast reprinted amounts most [SEP]']
[ 150/2000] tot_loss=3.283 (perp=9.239, rec=0.447, cos=0.988), tot_loss_proj:3.663 [t=0.24s]
prediction: ['[CLS] the story, read they / want want ª privilege area [SEP]']
[ 200/2000] tot_loss=3.305 (perp=9.724, rec=0.390, cos=0.971), tot_loss_proj:3.761 [t=0.19s]
prediction: ['[CLS] the story, read theywski nonetheless want http become area [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.681 (perp=10.657, rec=0.556, cos=0.993), tot_loss_proj:3.964 [t=0.20s]
prediction: ['[CLS] his story, readneas none want precinct dimensional array ( [SEP]']
[ 300/2000] tot_loss=3.536 (perp=10.776, rec=0.397, cos=0.984), tot_loss_proj:3.983 [t=0.19s]
prediction: ['[CLS] its story, readdra want want lesbian dimensional deal ( [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.652 (perp=11.548, rec=0.360, cos=0.982), tot_loss_proj:4.055 [t=0.17s]
prediction: ['[CLS] fred story, read they want wantestinal domain dimensional ( [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.279 (perp=9.489, rec=0.406, cos=0.975), tot_loss_proj:3.725 [t=0.17s]
prediction: ['[CLS] dimensional story, read we wanna wantestinal domain fred and [SEP]']
[ 450/2000] tot_loss=3.225 (perp=9.562, rec=0.337, cos=0.976), tot_loss_proj:3.718 [t=0.17s]
prediction: ['[CLS] dimensional story, read they also wantestinal domain fred and [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.223 (perp=9.562, rec=0.334, cos=0.976), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] dimensional story, read they also wantestinal domain fred and [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.190 (perp=9.439, rec=0.326, cos=0.976), tot_loss_proj:3.737 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also wantestinal phrase fred and [SEP]']
[ 600/2000] tot_loss=2.988 (perp=8.482, rec=0.318, cos=0.973), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also wantreate phrase fred. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.041 (perp=8.787, rec=0.313, cos=0.971), tot_loss_proj:3.610 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also wantestinal phrase fred. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.285 (perp=9.976, rec=0.321, cos=0.969), tot_loss_proj:3.826 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also wantestinal phrase fred stations [SEP]']
[ 750/2000] tot_loss=3.277 (perp=9.976, rec=0.312, cos=0.969), tot_loss_proj:3.827 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also wantestinal phrase fred stations [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.335 (perp=10.345, rec=0.298, cos=0.968), tot_loss_proj:3.914 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want filmfare phrase fred stations [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.262 (perp=9.974, rec=0.300, cos=0.968), tot_loss_proj:3.830 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want⊕ phrase fred stations [SEP]']
[ 900/2000] tot_loss=3.311 (perp=10.210, rec=0.301, cos=0.968), tot_loss_proj:3.900 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer phrase fredrting [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.308 (perp=10.210, rec=0.296, cos=0.969), tot_loss_proj:3.901 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer phrase fredrting [SEP]']
Attempt swap
[1000/2000] tot_loss=3.317 (perp=10.210, rec=0.307, cos=0.968), tot_loss_proj:3.904 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer phrase fredrting [SEP]']
[1050/2000] tot_loss=3.309 (perp=10.210, rec=0.298, cos=0.969), tot_loss_proj:3.901 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer phrase fredrting [SEP]']
Attempt swap
[1100/2000] tot_loss=3.080 (perp=9.061, rec=0.299, cos=0.969), tot_loss_proj:3.637 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1150/2000] tot_loss=3.085 (perp=9.061, rec=0.304, cos=0.969), tot_loss_proj:3.640 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
[1200/2000] tot_loss=3.073 (perp=9.061, rec=0.292, cos=0.970), tot_loss_proj:3.637 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1250/2000] tot_loss=3.068 (perp=9.061, rec=0.286, cos=0.969), tot_loss_proj:3.633 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1300/2000] tot_loss=3.068 (perp=9.061, rec=0.286, cos=0.970), tot_loss_proj:3.639 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
[1350/2000] tot_loss=3.078 (perp=9.061, rec=0.296, cos=0.970), tot_loss_proj:3.641 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1400/2000] tot_loss=3.079 (perp=9.061, rec=0.297, cos=0.970), tot_loss_proj:3.640 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1450/2000] tot_loss=3.077 (perp=9.061, rec=0.294, cos=0.970), tot_loss_proj:3.640 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
[1500/2000] tot_loss=3.074 (perp=9.061, rec=0.292, cos=0.970), tot_loss_proj:3.638 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1550/2000] tot_loss=3.081 (perp=9.061, rec=0.299, cos=0.970), tot_loss_proj:3.639 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1600/2000] tot_loss=3.080 (perp=9.061, rec=0.297, cos=0.970), tot_loss_proj:3.637 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
[1650/2000] tot_loss=3.074 (perp=9.061, rec=0.292, cos=0.970), tot_loss_proj:3.637 [t=0.17s]
prediction: ['[CLS] dimensional story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1700/2000] tot_loss=3.064 (perp=8.992, rec=0.295, cos=0.971), tot_loss_proj:3.653 [t=0.17s]
prediction: ['[CLS] want story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1750/2000] tot_loss=3.067 (perp=8.992, rec=0.298, cos=0.971), tot_loss_proj:3.649 [t=0.17s]
prediction: ['[CLS] want story, read we also want drawer! fredrting [SEP]']
[1800/2000] tot_loss=3.063 (perp=8.992, rec=0.294, cos=0.971), tot_loss_proj:3.647 [t=0.17s]
prediction: ['[CLS] want story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1850/2000] tot_loss=3.051 (perp=8.992, rec=0.282, cos=0.971), tot_loss_proj:3.645 [t=0.17s]
prediction: ['[CLS] want story, read we also want drawer! fredrting [SEP]']
Attempt swap
[1900/2000] tot_loss=3.058 (perp=8.992, rec=0.288, cos=0.971), tot_loss_proj:3.648 [t=0.17s]
prediction: ['[CLS] want story, read we also want drawer! fredrting [SEP]']
[1950/2000] tot_loss=3.062 (perp=8.992, rec=0.293, cos=0.971), tot_loss_proj:3.650 [t=0.17s]
prediction: ['[CLS] want story, read we also want drawer! fredrting [SEP]']
Attempt swap
[2000/2000] tot_loss=3.052 (perp=8.992, rec=0.283, cos=0.971), tot_loss_proj:3.647 [t=0.17s]
prediction: ['[CLS] want story, read we also want drawer! fredrting [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] read fred's story, i also want to. [SEP]
========================
predicted: 
========================
[CLS] dimensional story, read we also want drawer! fredrting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 71.111

[Aggregate metrics]:
rouge1     | fm: 78.253 | p: 79.335 | r: 77.593
rouge2     | fm: 39.271 | p: 39.303 | r: 39.438
rougeL     | fm: 68.662 | p: 69.445 | r: 68.120
rougeLsum  | fm: 68.577 | p: 69.494 | r: 68.105
r1fm+r2fm = 117.524

input #30 time: 0:07:02 | total time: 3:37:42


Running input #31 of 100.
reference: 
========================
Some of the water from melted snow also goes into the ground for plants.
========================
Sample: 0 8.794256807811237e-12 0.05235780140612458 0.3643594
average of cosine similarity 0.9896215312835297
highest_index [0]
highest [0.9896215312835297]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2070,  1997,  1996,  2300,  2013, 12501,  4586,  2036,  3632,
          2046,  1996,  2598,  2005,  4264,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]']
[Init] best rec loss: 0.9458415508270264 for ["[CLS] girlfriend set faculty clay angeles boom cross bandonus sh 'tical mistake inn ballard [SEP]"]
[Init] best rec loss: 0.922178328037262 for ['[CLS] ace brady declared temples eight simply { doi clapped content unit foot npr chargedtro [SEP]']
[Init] best rec loss: 0.912794828414917 for ['[CLS] spaceship mercy loanbil spoken continued gun quentin merit closed abrl asked chemistry states [SEP]']
[Init] best rec loss: 0.9126591086387634 for ['[CLS] modern currently joey press trent bed reaching main herzegovina mahmoud recent may prescription cover french [SEP]']
[Init] best rec loss: 0.9065945744514465 for ['[CLS] carolina wonder calendar macy rocktill students power search under length laketia greg lowest [SEP]']
[Init] best rec loss: 0.8944409489631653 for ['[CLS] colt vampires well apartheid general viscount skate lend absolutely and tension dramatic diner chief level [SEP]']
[Init] best rec loss: 0.8925084471702576 for ['[CLS]agi independentnished spruce campus best george any crawford ft goals poetry mushroom unaoulos [SEP]']
[Init] best perm rec loss: 0.8879450559616089 for ['[CLS]nished spruce campus any mushroom unaoulos ft georgeagi independent best poetry goals crawford [SEP]']
[Init] best perm rec loss: 0.8877514600753784 for ['[CLS]oulos independent campus anyagi spruce best george poetry ft mushroom crawfordnished goals una [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.181 (perp=13.370, rec=0.530, cos=0.978), tot_loss_proj:4.519 [t=0.19s]
prediction: ['[CLS] acids cars brand other bunker eventuallytric originally melted hittereo bronze from cyclone eva [SEP]']
[ 100/2000] tot_loss=3.674 (perp=12.518, rec=0.461, cos=0.710), tot_loss_proj:4.349 [t=0.19s]
prediction: ['[CLS] acidske + previous can continues for the melted needle theological snow from throughout through [SEP]']
[ 150/2000] tot_loss=2.342 (perp=9.925, rec=0.310, cos=0.048), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS] acidstes. additional amounts goes for some. land landed melted ( water around [SEP]']
[ 200/2000] tot_loss=2.301 (perp=9.755, rec=0.293, cos=0.058), tot_loss_proj:3.875 [t=0.17s]
prediction: ['[CLS] water still. additional trees goes for old melted roof material melted ( water off [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.666 (perp=6.793, rec=0.265, cos=0.043), tot_loss_proj:3.288 [t=0.17s]
prediction: ['[CLS] water from the additional plants goes for other melted snow plants for snow water and [SEP]']
[ 300/2000] tot_loss=1.637 (perp=6.962, rec=0.213, cos=0.032), tot_loss_proj:3.321 [t=0.17s]
prediction: ['[CLS] water from the additional plants goes for some melted snow water - snow water and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.703 (perp=7.361, rec=0.200, cos=0.031), tot_loss_proj:3.388 [t=0.18s]
prediction: ['[CLS] water from the also plants goes for some melted snow water - snow water and [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.604 (perp=6.901, rec=0.194, cos=0.030), tot_loss_proj:3.272 [t=0.17s]
prediction: ['[CLS] water from the also plants goes for some snow - snow melted snow water and [SEP]']
[ 450/2000] tot_loss=1.583 (perp=6.901, rec=0.175, cos=0.028), tot_loss_proj:3.272 [t=0.17s]
prediction: ['[CLS] water from the also plants goes for some snow - snow melted snow water and [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.457 (perp=6.331, rec=0.165, cos=0.026), tot_loss_proj:3.155 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow. snow melted snow water and [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.517 (perp=6.304, rec=0.213, cos=0.043), tot_loss_proj:3.168 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow and snow melted snow water - [SEP]']
[ 600/2000] tot_loss=1.454 (perp=6.304, rec=0.166, cos=0.027), tot_loss_proj:3.154 [t=0.18s]
prediction: ['[CLS] also from the water plants goes for some snow and snow melted snow water - [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.384 (perp=6.059, rec=0.146, cos=0.026), tot_loss_proj:3.079 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow and melted snow water snow - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.363 (perp=5.974, rec=0.143, cos=0.026), tot_loss_proj:3.031 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water snow - [SEP]']
[ 750/2000] tot_loss=1.482 (perp=6.599, rec=0.138, cos=0.025), tot_loss_proj:3.194 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted ground water snow - [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.421 (perp=6.307, rec=0.135, cos=0.025), tot_loss_proj:3.144 [t=0.18s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.418 (perp=6.307, rec=0.132, cos=0.024), tot_loss_proj:3.142 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground - [SEP]']
[ 900/2000] tot_loss=1.408 (perp=6.307, rec=0.122, cos=0.024), tot_loss_proj:3.145 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.409 (perp=6.307, rec=0.123, cos=0.025), tot_loss_proj:3.138 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.404 (perp=6.307, rec=0.118, cos=0.025), tot_loss_proj:3.137 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground - [SEP]']
[1050/2000] tot_loss=1.403 (perp=6.307, rec=0.117, cos=0.025), tot_loss_proj:3.144 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.405 (perp=6.307, rec=0.119, cos=0.025), tot_loss_proj:3.143 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.398 (perp=6.307, rec=0.112, cos=0.024), tot_loss_proj:3.145 [t=0.18s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground - [SEP]']
[1200/2000] tot_loss=1.279 (perp=5.728, rec=0.109, cos=0.024), tot_loss_proj:3.023 [t=0.18s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.278 (perp=5.728, rec=0.108, cos=0.025), tot_loss_proj:3.028 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.281 (perp=5.728, rec=0.111, cos=0.025), tot_loss_proj:3.023 [t=0.19s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
[1350/2000] tot_loss=1.283 (perp=5.728, rec=0.113, cos=0.025), tot_loss_proj:3.023 [t=0.19s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.276 (perp=5.728, rec=0.107, cos=0.024), tot_loss_proj:3.024 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.272 (perp=5.728, rec=0.102, cos=0.024), tot_loss_proj:3.024 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
[1500/2000] tot_loss=1.278 (perp=5.728, rec=0.108, cos=0.025), tot_loss_proj:3.023 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.276 (perp=5.728, rec=0.106, cos=0.025), tot_loss_proj:3.024 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.270 (perp=5.728, rec=0.100, cos=0.025), tot_loss_proj:3.029 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
[1650/2000] tot_loss=1.278 (perp=5.728, rec=0.108, cos=0.025), tot_loss_proj:3.024 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.268 (perp=5.728, rec=0.098, cos=0.025), tot_loss_proj:3.023 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.282 (perp=5.728, rec=0.112, cos=0.025), tot_loss_proj:3.024 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
[1800/2000] tot_loss=1.276 (perp=5.728, rec=0.105, cos=0.025), tot_loss_proj:3.020 [t=0.19s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.268 (perp=5.728, rec=0.098, cos=0.025), tot_loss_proj:3.022 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.276 (perp=5.728, rec=0.106, cos=0.025), tot_loss_proj:3.017 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
[1950/2000] tot_loss=1.266 (perp=5.728, rec=0.096, cos=0.025), tot_loss_proj:3.024 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.269 (perp=5.728, rec=0.099, cos=0.025), tot_loss_proj:3.020 [t=0.17s]
prediction: ['[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]
========================
predicted: 
========================
[CLS] also from the water plants goes for some snow from melted snow water ground. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.250 | p: 81.250 | r: 81.250
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 101.250

[Aggregate metrics]:
rouge1     | fm: 78.276 | p: 79.410 | r: 77.645
rouge2     | fm: 38.787 | p: 38.781 | r: 38.894
rougeL     | fm: 67.960 | p: 68.865 | r: 67.473
rougeLsum  | fm: 67.993 | p: 68.822 | r: 67.454
r1fm+r2fm = 117.062

input #31 time: 0:07:13 | total time: 3:44:56


Running input #32 of 100.
reference: 
========================
Bob is very serious about Mary, but less so than Paul.
========================
Sample: 0 3.0933471631193946e-12 0.05082565738318495 0.35393968
average of cosine similarity 0.989635793267188
highest_index [0]
highest [0.989635793267188]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[ 101, 3960, 2003, 2200, 3809, 2055, 2984, 1010, 2021, 2625, 2061, 2084,
         2703, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bob is very serious about mary, but less so than paul. [SEP]']
[Init] best rec loss: 0.9588392376899719 for ['[CLS] archery dual„ pam an arrows kings beyond if rev up place behind [SEP]']
[Init] best rec loss: 0.9246671795845032 for ['[CLS] minnesota greeceignantach supplied process + after atletico memorialpee degrees blur [SEP]']
[Init] best rec loss: 0.9175419211387634 for ['[CLS] transitium through comeedd im slaughtered sympathy opening as directorcu hint [SEP]']
[Init] best rec loss: 0.9033082127571106 for ['[CLS] records copy middle sr ( partly challenged skin dowager must warner with pick [SEP]']
[Init] best rec loss: 0.900634765625 for ['[CLS] spikeen august but collaboration golf age howlage giro inflation etched form [SEP]']
[Init] best rec loss: 0.8903785347938538 for ['[CLS] inactive chip wantedwaterville career twenties shear reign janeiroable shame floor [SEP]']
[Init] best rec loss: 0.8777366280555725 for ['[CLS] arts hardly labor hi nosestage it what short balloonab champion nightmares [SEP]']
[Init] best rec loss: 0.876878559589386 for ['[CLS] missed ev talon hope thinking white g producerator practice well overly it [SEP]']
[Init] best perm rec loss: 0.876000702381134 for ['[CLS] missed producer practice thinking white hope g wellator it overly ev talon [SEP]']
[Init] best perm rec loss: 0.874030590057373 for ['[CLS] producer talon overlyator it g practice well hope white ev thinking missed [SEP]']
[Init] best perm rec loss: 0.873460054397583 for ['[CLS] g hope missed white overly talon practiceator ev thinking it well producer [SEP]']
[Init] best perm rec loss: 0.8725891709327698 for ['[CLS] well whiteator thinking talon hope missed practice overly g it ev producer [SEP]']
[Init] best perm rec loss: 0.8714865446090698 for ['[CLS] overlyator it ev thinking producer hope missed g talon practice well white [SEP]']
[Init] best perm rec loss: 0.8703650236129761 for ['[CLS] practice producer missed overly thinking ev talon whiteator hope g it well [SEP]']
[Init] best perm rec loss: 0.8692450523376465 for ['[CLS] missed producer overly evator practice talon hope well white g thinking it [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.825 (perp=9.729, rec=0.532, cos=0.347), tot_loss_proj:3.894 [t=0.17s]
prediction: ['[CLS]. didn. god solidarity rules commonly spell besides. aids.. [SEP]']
[ 100/2000] tot_loss=2.011 (perp=8.416, rec=0.292, cos=0.036), tot_loss_proj:3.581 [t=0.17s]
prediction: ['[CLS]. paul. pretty paul mary is paul besides more third.. [SEP]']
[ 150/2000] tot_loss=1.917 (perp=8.395, rec=0.210, cos=0.027), tot_loss_proj:3.577 [t=0.17s]
prediction: ['[CLS]. bob. serious about mary is paul than serious so is, [SEP]']
[ 200/2000] tot_loss=1.934 (perp=8.790, rec=0.155, cos=0.021), tot_loss_proj:3.615 [t=0.17s]
prediction: ['[CLS] but bob. serious about mary is paul than so so is, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.706 (perp=7.635, rec=0.153, cos=0.026), tot_loss_proj:3.436 [t=0.17s]
prediction: ['[CLS] but bob fully serious about mary is so than paul so is. [SEP]']
[ 300/2000] tot_loss=1.636 (perp=7.479, rec=0.115, cos=0.025), tot_loss_proj:3.397 [t=0.17s]
prediction: ['[CLS] but bob. serious about mary is so than paul so is. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.504 (perp=6.760, rec=0.128, cos=0.024), tot_loss_proj:3.256 [t=0.17s]
prediction: ['[CLS] but bob is serious about mary is so than paul so so. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.437 (perp=6.545, rec=0.104, cos=0.023), tot_loss_proj:3.229 [t=0.17s]
prediction: ['[CLS] but bob is serious about mary is less than paul so. so [SEP]']
[ 450/2000] tot_loss=1.439 (perp=6.545, rec=0.107, cos=0.023), tot_loss_proj:3.227 [t=0.17s]
prediction: ['[CLS] but bob is serious about mary is less than paul so. so [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.497 (perp=6.795, rec=0.115, cos=0.023), tot_loss_proj:3.272 [t=0.17s]
prediction: ['[CLS] but bob is serious about mary very very less than paul so. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.489 (perp=6.795, rec=0.107, cos=0.023), tot_loss_proj:3.270 [t=0.17s]
prediction: ['[CLS] but bob is serious about mary very very less than paul so. [SEP]']
[ 600/2000] tot_loss=1.405 (perp=6.399, rec=0.102, cos=0.023), tot_loss_proj:3.251 [t=0.17s]
prediction: ['[CLS] but bob is serious about mary. very less than paul so. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.416 (perp=6.399, rec=0.113, cos=0.023), tot_loss_proj:3.250 [t=0.17s]
prediction: ['[CLS] but bob is serious about mary. very less than paul so. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.366 (perp=6.127, rec=0.116, cos=0.024), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
[ 750/2000] tot_loss=1.363 (perp=6.127, rec=0.114, cos=0.023), tot_loss_proj:2.581 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.359 (perp=6.127, rec=0.111, cos=0.023), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.348 (perp=6.127, rec=0.100, cos=0.023), tot_loss_proj:2.595 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
[ 900/2000] tot_loss=1.363 (perp=6.127, rec=0.115, cos=0.023), tot_loss_proj:2.591 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.356 (perp=6.127, rec=0.109, cos=0.022), tot_loss_proj:2.594 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.352 (perp=6.127, rec=0.104, cos=0.022), tot_loss_proj:2.586 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
[1050/2000] tot_loss=1.351 (perp=6.127, rec=0.103, cos=0.022), tot_loss_proj:2.590 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.346 (perp=6.127, rec=0.099, cos=0.022), tot_loss_proj:2.588 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.348 (perp=6.127, rec=0.100, cos=0.022), tot_loss_proj:2.598 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
[1200/2000] tot_loss=1.341 (perp=6.127, rec=0.093, cos=0.022), tot_loss_proj:2.586 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.350 (perp=6.127, rec=0.103, cos=0.022), tot_loss_proj:2.591 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.351 (perp=6.127, rec=0.104, cos=0.022), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
[1350/2000] tot_loss=1.353 (perp=6.127, rec=0.106, cos=0.022), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.592 (perp=7.360, rec=0.098, cos=0.022), tot_loss_proj:3.418 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than so less [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.527 (perp=6.968, rec=0.109, cos=0.024), tot_loss_proj:2.910 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than less so [SEP]']
[1500/2000] tot_loss=1.521 (perp=6.968, rec=0.104, cos=0.023), tot_loss_proj:2.908 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than less so [SEP]']
Attempt swap
[1550/2000] tot_loss=1.516 (perp=6.968, rec=0.100, cos=0.023), tot_loss_proj:2.913 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than less so [SEP]']
Attempt swap
[1600/2000] tot_loss=1.525 (perp=6.968, rec=0.109, cos=0.023), tot_loss_proj:2.908 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than less so [SEP]']
[1650/2000] tot_loss=1.511 (perp=6.968, rec=0.095, cos=0.023), tot_loss_proj:2.903 [t=0.19s]
prediction: ['[CLS] but bob paul is serious about mary. very less than less so [SEP]']
Attempt swap
[1700/2000] tot_loss=1.516 (perp=6.968, rec=0.100, cos=0.022), tot_loss_proj:2.912 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary. very less than less so [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.471 (perp=6.702, rec=0.108, cos=0.024), tot_loss_proj:3.168 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary very less than less so. [SEP]']
[1800/2000] tot_loss=1.464 (perp=6.702, rec=0.101, cos=0.023), tot_loss_proj:3.168 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary very less than less so. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.470 (perp=6.702, rec=0.107, cos=0.023), tot_loss_proj:3.171 [t=0.17s]
prediction: ['[CLS] but bob paul is serious about mary very less than less so. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.373 (perp=6.116, rec=0.124, cos=0.026), tot_loss_proj:3.148 [t=0.17s]
prediction: ['[CLS] but bob paul is less serious about mary very than less so. [SEP]']
[1950/2000] tot_loss=1.353 (perp=6.116, rec=0.106, cos=0.024), tot_loss_proj:3.143 [t=0.17s]
prediction: ['[CLS] but bob paul is less serious about mary very than less so. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.355 (perp=6.116, rec=0.108, cos=0.024), tot_loss_proj:3.145 [t=0.17s]
prediction: ['[CLS] but bob paul is less serious about mary very than less so. [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] bob is very serious about mary, but less so than paul. [SEP]
========================
predicted: 
========================
[CLS] but bob paul is serious about mary. very less than so. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 69.231 | p: 69.231 | r: 69.231
rougeLsum  | fm: 69.231 | p: 69.231 | r: 69.231
r1fm+r2fm = 116.667

[Aggregate metrics]:
rouge1     | fm: 78.982 | p: 80.047 | r: 78.267
rouge2     | fm: 38.311 | p: 38.393 | r: 38.433
rougeL     | fm: 68.209 | p: 68.983 | r: 67.753
rougeLsum  | fm: 68.043 | p: 68.911 | r: 67.645
r1fm+r2fm = 117.293

input #32 time: 0:07:00 | total time: 3:51:56


Running input #33 of 100.
reference: 
========================
Ayala sent the diamond necklace back.
========================
Sample: 0 1.2913890694781483e-11 0.05009862584472335 0.35218638
average of cosine similarity 0.9898306565571107
highest_index [0]
highest [0.9898306565571107]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  1996,  6323, 13016,  2067,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] ayala sent the diamond necklace back. [SEP]']
[Init] best rec loss: 1.0263526439666748 for ['[CLS] terms primary contribution an soil all competition dug [SEP]']
[Init] best rec loss: 0.9502540230751038 for ['[CLS] militiaiom slim lei daryl dip bay well [SEP]']
[Init] best rec loss: 0.9274391531944275 for ['[CLS] langley 9 shoe soon tray originally ha inclined [SEP]']
[Init] best rec loss: 0.9139430522918701 for ['[CLS] strikingenberg online poland silver through proper comfort [SEP]']
[Init] best rec loss: 0.913354754447937 for ['[CLS] dante railroad stage headeddictz prostate abby [SEP]']
[Init] best perm rec loss: 0.912300705909729 for ['[CLS] railroad headedzdict abby dante stage prostate [SEP]']
[Init] best perm rec loss: 0.9117847084999084 for ['[CLS] railroadz abby dante headed prostate stagedict [SEP]']
[Init] best perm rec loss: 0.9092954993247986 for ['[CLS] dantez prostatedict railroad headed stage abby [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.696 (perp=9.317, rec=0.502, cos=0.331), tot_loss_proj:3.919 [t=0.17s]
prediction: ['[CLS] : noticed enough command. number ayala [SEP]']
[ 100/2000] tot_loss=2.372 (perp=10.228, rec=0.271, cos=0.056), tot_loss_proj:4.127 [t=0.17s]
prediction: ['[CLS] : sentyala diamond. sent ayala [SEP]']
[ 150/2000] tot_loss=2.134 (perp=9.678, rec=0.166, cos=0.032), tot_loss_proj:3.886 [t=0.17s]
prediction: ['[CLS] : sentyala diamond necklace back ayala [SEP]']
[ 200/2000] tot_loss=2.029 (perp=9.463, rec=0.108, cos=0.029), tot_loss_proj:3.813 [t=0.17s]
prediction: ['[CLS]. sentyala diamond necklace back ayala [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.574 (perp=7.271, rec=0.094, cos=0.027), tot_loss_proj:3.408 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[ 300/2000] tot_loss=1.573 (perp=7.271, rec=0.093, cos=0.026), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.578 (perp=7.271, rec=0.098, cos=0.025), tot_loss_proj:3.406 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.686 (perp=7.819, rec=0.097, cos=0.025), tot_loss_proj:3.535 [t=0.17s]
prediction: ['[CLS]. sent this diamond necklace back ayala [SEP]']
[ 450/2000] tot_loss=1.563 (perp=7.271, rec=0.083, cos=0.025), tot_loss_proj:3.406 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.574 (perp=7.271, rec=0.094, cos=0.025), tot_loss_proj:3.401 [t=0.20s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.567 (perp=7.271, rec=0.087, cos=0.025), tot_loss_proj:3.400 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[ 600/2000] tot_loss=1.569 (perp=7.271, rec=0.089, cos=0.026), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.572 (perp=7.271, rec=0.092, cos=0.025), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.571 (perp=7.271, rec=0.092, cos=0.025), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[ 750/2000] tot_loss=1.562 (perp=7.271, rec=0.083, cos=0.025), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.576 (perp=7.271, rec=0.096, cos=0.025), tot_loss_proj:3.401 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.567 (perp=7.271, rec=0.088, cos=0.025), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[ 900/2000] tot_loss=1.567 (perp=7.271, rec=0.088, cos=0.025), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.570 (perp=7.271, rec=0.091, cos=0.025), tot_loss_proj:3.400 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1000/2000] tot_loss=1.567 (perp=7.271, rec=0.088, cos=0.025), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[1050/2000] tot_loss=1.569 (perp=7.271, rec=0.090, cos=0.025), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1100/2000] tot_loss=1.556 (perp=7.271, rec=0.077, cos=0.025), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1150/2000] tot_loss=1.568 (perp=7.271, rec=0.089, cos=0.025), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[1200/2000] tot_loss=1.561 (perp=7.271, rec=0.082, cos=0.025), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1250/2000] tot_loss=1.566 (perp=7.271, rec=0.087, cos=0.025), tot_loss_proj:3.394 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1300/2000] tot_loss=1.567 (perp=7.271, rec=0.088, cos=0.025), tot_loss_proj:3.397 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[1350/2000] tot_loss=1.569 (perp=7.271, rec=0.090, cos=0.025), tot_loss_proj:3.397 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1400/2000] tot_loss=1.567 (perp=7.271, rec=0.088, cos=0.025), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1450/2000] tot_loss=1.561 (perp=7.271, rec=0.083, cos=0.025), tot_loss_proj:3.401 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[1500/2000] tot_loss=1.557 (perp=7.271, rec=0.078, cos=0.025), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1550/2000] tot_loss=1.557 (perp=7.271, rec=0.078, cos=0.025), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1600/2000] tot_loss=1.568 (perp=7.271, rec=0.089, cos=0.025), tot_loss_proj:3.397 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[1650/2000] tot_loss=1.555 (perp=7.271, rec=0.076, cos=0.025), tot_loss_proj:3.397 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1700/2000] tot_loss=1.559 (perp=7.271, rec=0.080, cos=0.025), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1750/2000] tot_loss=1.562 (perp=7.271, rec=0.083, cos=0.025), tot_loss_proj:3.393 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[1800/2000] tot_loss=1.559 (perp=7.271, rec=0.080, cos=0.025), tot_loss_proj:3.395 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1850/2000] tot_loss=1.566 (perp=7.271, rec=0.087, cos=0.025), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[1900/2000] tot_loss=1.561 (perp=7.271, rec=0.082, cos=0.025), tot_loss_proj:3.395 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
[1950/2000] tot_loss=1.566 (perp=7.271, rec=0.087, cos=0.025), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Attempt swap
[2000/2000] tot_loss=1.564 (perp=7.271, rec=0.085, cos=0.025), tot_loss_proj:3.401 [t=0.17s]
prediction: ['[CLS]. sent the diamond necklace back ayala [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] ayala sent the diamond necklace back. [SEP]
========================
predicted: 
========================
[CLS]. sent the diamond necklace back ayala [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 79.501 | p: 80.418 | r: 78.963
rouge2     | fm: 38.808 | p: 38.857 | r: 38.962
rougeL     | fm: 68.535 | p: 69.413 | r: 68.108
rougeLsum  | fm: 68.846 | p: 69.615 | r: 68.344
r1fm+r2fm = 118.310

input #33 time: 0:07:00 | total time: 3:58:57


Running input #34 of 100.
reference: 
========================
Jessica sprayed paint under the table.
========================
Sample: 0 4.0424569430543e-09 0.05109640139737424 0.32941005
average of cosine similarity 0.9878964033062757
highest_index [0]
highest [0.9878964033062757]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  8201, 25401,  6773,  2104,  1996,  2795,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] jessica sprayed paint under the table. [SEP]']
[Init] best rec loss: 0.9414330720901489 for ['[CLS] solvent pure sitting returns open penelope gerais [SEP]']
[Init] best rec loss: 0.9049432277679443 for ['[CLS]vision best te sided ms lowest elected [SEP]']
[Init] best rec loss: 0.899651825428009 for ['[CLS]iating achievement tablet navy raaf commissionvet [SEP]']
[Init] best rec loss: 0.8826460838317871 for ['[CLS]ter & since cureraßeeratednes [SEP]']
[Init] best perm rec loss: 0.8818284273147583 for ['[CLS]nes cure &terraßeerated since [SEP]']
[Init] best perm rec loss: 0.8814307451248169 for ['[CLS] sinceerated cureraßeter &nes [SEP]']
[Init] best perm rec loss: 0.8780422210693359 for ['[CLS]eratedterraße & curenes since [SEP]']
[Init] best perm rec loss: 0.8755910396575928 for ['[CLS]tererated &nes cure sinceraße [SEP]']
[Init] best perm rec loss: 0.8677996397018433 for ['[CLS]raßeter &nes cureerated since [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.970 (perp=11.627, rec=0.669, cos=0.975), tot_loss_proj:4.070 [t=0.17s]
prediction: ['[CLS] dancetness & appearances. wife tablet [SEP]']
[ 100/2000] tot_loss=2.799 (perp=11.863, rec=0.327, cos=0.100), tot_loss_proj:4.231 [t=0.17s]
prediction: ['[CLS] paintox marketed ;. jessica sounded [SEP]']
[ 150/2000] tot_loss=2.684 (perp=12.322, rec=0.182, cos=0.037), tot_loss_proj:4.306 [t=0.17s]
prediction: ['[CLS] paint sprayed sprayed table. jessica looked [SEP]']
[ 200/2000] tot_loss=2.390 (perp=11.114, rec=0.139, cos=0.028), tot_loss_proj:4.084 [t=0.17s]
prediction: ['[CLS] paint under sprayed table. jessica table [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.785 (perp=10.745, rec=0.468, cos=0.168), tot_loss_proj:4.121 [t=0.17s]
prediction: ['[CLS] paint sprayed under table. jessica table [SEP]']
[ 300/2000] tot_loss=2.577 (perp=10.745, rec=0.325, cos=0.102), tot_loss_proj:4.153 [t=0.17s]
prediction: ['[CLS] paint sprayed under table. jessica table [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.282 (perp=9.557, rec=0.296, cos=0.074), tot_loss_proj:3.829 [t=0.17s]
prediction: ['[CLS] sprayed under table. jessica paint table [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.114 (perp=8.902, rec=0.264, cos=0.069), tot_loss_proj:3.569 [t=0.17s]
prediction: ['[CLS] sprayed under table jessica paint table. [SEP]']
[ 450/2000] tot_loss=2.076 (perp=8.902, rec=0.241, cos=0.055), tot_loss_proj:3.557 [t=0.17s]
prediction: ['[CLS] sprayed under table jessica paint table. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.034 (perp=8.902, rec=0.205, cos=0.048), tot_loss_proj:3.556 [t=0.17s]
prediction: ['[CLS] sprayed under table jessica paint table. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.029 (perp=8.902, rec=0.204, cos=0.044), tot_loss_proj:3.554 [t=0.17s]
prediction: ['[CLS] sprayed under table jessica paint table. [SEP]']
[ 600/2000] tot_loss=2.002 (perp=8.902, rec=0.181, cos=0.041), tot_loss_proj:3.551 [t=0.17s]
prediction: ['[CLS] sprayed under table jessica paint table. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.992 (perp=8.902, rec=0.173, cos=0.038), tot_loss_proj:3.552 [t=0.17s]
prediction: ['[CLS] sprayed under table jessica paint table. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.889 (perp=8.366, rec=0.175, cos=0.041), tot_loss_proj:3.483 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
[ 750/2000] tot_loss=1.888 (perp=8.366, rec=0.179, cos=0.036), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.867 (perp=8.366, rec=0.160, cos=0.034), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.858 (perp=8.366, rec=0.151, cos=0.033), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
[ 900/2000] tot_loss=1.852 (perp=8.366, rec=0.146, cos=0.033), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.840 (perp=8.366, rec=0.135, cos=0.032), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.836 (perp=8.366, rec=0.131, cos=0.032), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
[1050/2000] tot_loss=1.846 (perp=8.366, rec=0.141, cos=0.031), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.832 (perp=8.366, rec=0.127, cos=0.031), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.845 (perp=8.366, rec=0.141, cos=0.031), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
[1200/2000] tot_loss=1.835 (perp=8.366, rec=0.132, cos=0.030), tot_loss_proj:3.481 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.837 (perp=8.366, rec=0.134, cos=0.030), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.832 (perp=8.366, rec=0.129, cos=0.030), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
[1350/2000] tot_loss=1.832 (perp=8.366, rec=0.129, cos=0.030), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.834 (perp=8.366, rec=0.131, cos=0.030), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.840 (perp=8.366, rec=0.137, cos=0.030), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
[1500/2000] tot_loss=1.837 (perp=8.366, rec=0.134, cos=0.030), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.832 (perp=8.366, rec=0.129, cos=0.030), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.825 (perp=8.366, rec=0.122, cos=0.029), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
[1650/2000] tot_loss=1.835 (perp=8.366, rec=0.133, cos=0.029), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.820 (perp=8.366, rec=0.118, cos=0.029), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.828 (perp=8.366, rec=0.126, cos=0.029), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
[1800/2000] tot_loss=1.830 (perp=8.366, rec=0.127, cos=0.029), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.827 (perp=8.366, rec=0.125, cos=0.029), tot_loss_proj:3.474 [t=0.19s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.830 (perp=8.366, rec=0.127, cos=0.029), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
[1950/2000] tot_loss=1.829 (perp=8.366, rec=0.126, cos=0.029), tot_loss_proj:3.481 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.817 (perp=8.366, rec=0.115, cos=0.029), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] table under sprayed jessica paint table. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] jessica sprayed paint under the table. [SEP]
========================
predicted: 
========================
[CLS] paint under sprayed table. jessica table [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 116.071

[Aggregate metrics]:
rouge1     | fm: 79.748 | p: 80.677 | r: 79.198
rouge2     | fm: 38.417 | p: 38.547 | r: 38.629
rougeL     | fm: 68.648 | p: 69.363 | r: 68.192
rougeLsum  | fm: 68.582 | p: 69.341 | r: 68.168
r1fm+r2fm = 118.165

input #34 time: 0:06:51 | total time: 4:05:48


Running input #35 of 100.
reference: 
========================
John is refused.
========================
Sample: 0 1.5579866713777242e-12 0.050770396666533726 0.3531675
average of cosine similarity 0.9896130189165462
highest_index [0]
highest [0.9896130189165462]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2198, 2003, 4188, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is refused. [SEP]']
[Init] best rec loss: 0.9893831610679626 for ['[CLS] hugo cruise than seconds [SEP]']
[Init] best rec loss: 0.9861062169075012 for ['[CLS] painful friendly reputation popularity [SEP]']
[Init] best rec loss: 0.8789446949958801 for ['[CLS] wings property warned wish [SEP]']
[Init] best rec loss: 0.8721048831939697 for ['[CLS] community evenly development appealed [SEP]']
[Init] best rec loss: 0.8641420006752014 for ['[CLS]estinal atanger toilet [SEP]']
[Init] best perm rec loss: 0.8629884719848633 for ['[CLS] toiletanger atestinal [SEP]']
[Init] best perm rec loss: 0.8620949983596802 for ['[CLS] toiletestinalanger at [SEP]']
[Init] best perm rec loss: 0.861962616443634 for ['[CLS]estinalanger toilet at [SEP]']
[Init] best perm rec loss: 0.8614445924758911 for ['[CLS] atestinalanger toilet [SEP]']
[Init] best perm rec loss: 0.8610238432884216 for ['[CLS] atanger toiletestinal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.456 (perp=10.760, rec=0.603, cos=0.702), tot_loss_proj:4.063 [t=0.17s]
prediction: ['[CLS]. pan are commanded [SEP]']
[ 100/2000] tot_loss=2.326 (perp=8.865, rec=0.415, cos=0.138), tot_loss_proj:3.583 [t=0.17s]
prediction: ['[CLS]. refused is refused [SEP]']
[ 150/2000] tot_loss=2.387 (perp=10.392, rec=0.257, cos=0.052), tot_loss_proj:3.949 [t=0.17s]
prediction: ['[CLS] refused john is refused [SEP]']
[ 200/2000] tot_loss=2.235 (perp=10.392, rec=0.131, cos=0.027), tot_loss_proj:3.948 [t=0.17s]
prediction: ['[CLS] refused john is refused [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.900 (perp=6.834, rec=0.399, cos=0.134), tot_loss_proj:1.815 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[ 300/2000] tot_loss=1.636 (perp=6.834, rec=0.232, cos=0.036), tot_loss_proj:1.554 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.573 (perp=6.834, rec=0.176, cos=0.030), tot_loss_proj:1.547 [t=0.20s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.546 (perp=6.834, rec=0.151, cos=0.028), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[ 450/2000] tot_loss=1.525 (perp=6.834, rec=0.132, cos=0.027), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.522 (perp=6.834, rec=0.129, cos=0.026), tot_loss_proj:1.547 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.516 (perp=6.834, rec=0.125, cos=0.025), tot_loss_proj:1.535 [t=0.18s]
prediction: ['[CLS] john is refused. [SEP]']
[ 600/2000] tot_loss=1.512 (perp=6.834, rec=0.121, cos=0.024), tot_loss_proj:1.541 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.497 (perp=6.834, rec=0.106, cos=0.024), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.487 (perp=6.834, rec=0.097, cos=0.023), tot_loss_proj:1.533 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[ 750/2000] tot_loss=1.486 (perp=6.834, rec=0.097, cos=0.023), tot_loss_proj:1.548 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.485 (perp=6.834, rec=0.095, cos=0.023), tot_loss_proj:1.541 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.481 (perp=6.834, rec=0.092, cos=0.023), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[ 900/2000] tot_loss=1.472 (perp=6.834, rec=0.083, cos=0.022), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.479 (perp=6.834, rec=0.090, cos=0.022), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.481 (perp=6.834, rec=0.091, cos=0.023), tot_loss_proj:1.544 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[1050/2000] tot_loss=1.471 (perp=6.834, rec=0.082, cos=0.022), tot_loss_proj:1.534 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.476 (perp=6.834, rec=0.087, cos=0.023), tot_loss_proj:1.540 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.478 (perp=6.834, rec=0.089, cos=0.022), tot_loss_proj:1.544 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[1200/2000] tot_loss=1.473 (perp=6.834, rec=0.084, cos=0.022), tot_loss_proj:1.543 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.473 (perp=6.834, rec=0.084, cos=0.022), tot_loss_proj:1.530 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.489 (perp=6.834, rec=0.100, cos=0.022), tot_loss_proj:1.541 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[1350/2000] tot_loss=1.473 (perp=6.834, rec=0.084, cos=0.022), tot_loss_proj:1.534 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.480 (perp=6.834, rec=0.091, cos=0.022), tot_loss_proj:1.540 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.471 (perp=6.834, rec=0.082, cos=0.022), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[1500/2000] tot_loss=1.476 (perp=6.834, rec=0.087, cos=0.022), tot_loss_proj:1.541 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.480 (perp=6.834, rec=0.091, cos=0.022), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.469 (perp=6.834, rec=0.080, cos=0.022), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[1650/2000] tot_loss=1.477 (perp=6.834, rec=0.089, cos=0.022), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.463 (perp=6.834, rec=0.074, cos=0.022), tot_loss_proj:1.532 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.477 (perp=6.834, rec=0.088, cos=0.022), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[1800/2000] tot_loss=1.471 (perp=6.834, rec=0.082, cos=0.022), tot_loss_proj:1.542 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.472 (perp=6.834, rec=0.083, cos=0.022), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.476 (perp=6.834, rec=0.087, cos=0.022), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[1950/2000] tot_loss=1.469 (perp=6.834, rec=0.081, cos=0.022), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.462 (perp=6.834, rec=0.073, cos=0.022), tot_loss_proj:1.548 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] john is refused. [SEP]
========================
predicted: 
========================
[CLS] john is refused. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 80.175 | p: 81.242 | r: 79.604
rouge2     | fm: 40.308 | p: 40.247 | r: 40.503
rougeL     | fm: 69.362 | p: 70.021 | r: 68.861
rougeLsum  | fm: 69.397 | p: 70.167 | r: 68.978
r1fm+r2fm = 120.482

input #35 time: 0:07:01 | total time: 4:12:50


Running input #36 of 100.
reference: 
========================
This information could have been released by Gorbachev, but he chose not to.
========================
Sample: 0 1.1828740893927968e-12 0.04420914886043928 0.32759836
average of cosine similarity 0.9908525312826211
highest_index [0]
highest [0.9908525312826211]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[  101,  2023,  2592,  2071,  2031,  2042,  2207,  2011,  2175, 28483,
         16179,  1010,  2021,  2002,  4900,  2025,  2000,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]']
[Init] best rec loss: 0.9475834369659424 for ['[CLS] actually joseph sofia sas colt late sketch sensefixed skate shaved clerical period huis powers news [SEP]']
[Init] best rec loss: 0.9407480359077454 for ['[CLS] gottfried cause credit family manufacturing assent active peek what conscious [ jurisdiction ch high porter tomashein [SEP]']
[Init] best rec loss: 0.9353086352348328 for ['[CLS] whenpressed pain must battled spyvu kilometres 10 term & enough bell each bandwidthdly design [SEP]']
[Init] best rec loss: 0.8846843242645264 for ['[CLS] penny quartersrim however reliefly supreme grant which departure mortar oak black touch apex golden ruling [SEP]']
[Init] best perm rec loss: 0.8831620812416077 for ['[CLS] departure which supreme touch grantrim apex relief penny mortar golden oak blackly ruling however quarters [SEP]']
[Init] best perm rec loss: 0.8824912905693054 for ['[CLS] mortar grant goldenrim which touch black ruling apexly oak supreme however quarters penny relief departure [SEP]']
[Init] best perm rec loss: 0.8821429014205933 for ['[CLS] grant which penny however apex departure oak touch black ruling mortar goldenrim quarters relief supremely [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.979 (perp=11.948, rec=0.589, cos=1.000), tot_loss_proj:4.272 [t=0.17s]
prediction: ['[CLS] request of amount & amendments got interrupt rapid hit but /. bed lotbling giovanni freak [SEP]']
[ 100/2000] tot_loss=4.420 (perp=14.532, rec=0.519, cos=0.995), tot_loss_proj:4.678 [t=0.17s]
prediction: ['[CLS] ordered sesamechev mule cigarette got judicial came was but, ، bouquet drove receiving giovanni bradley [SEP]']
[ 150/2000] tot_loss=3.991 (perp=12.581, rec=0.482, cos=0.993), tot_loss_proj:4.295 [t=0.17s]
prediction: ['[CLS] protest ;chev could wr getting archive came been decided on ، like days receives giovanni bradley [SEP]']
[ 200/2000] tot_loss=3.842 (perp=12.001, rec=0.448, cos=0.994), tot_loss_proj:4.245 [t=0.17s]
prediction: ['[CLS] blurted "chev did acquired dollars procession this was oneself, fauna like just receives giovanni http [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=4.018 (perp=12.649, rec=0.495, cos=0.993), tot_loss_proj:4.320 [t=0.17s]
prediction: ['[CLS] pronounschev including were example decades outbreak this well cannot,. big just receives broadly retrieved [SEP]']
[ 300/2000] tot_loss=3.913 (perp=12.454, rec=0.429, cos=0.994), tot_loss_proj:4.281 [t=0.17s]
prediction: ['[CLS] informationchev intentions thoughtburg decades outbreak this well chose,. big body receives giovanni retrieved [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.808 (perp=12.066, rec=0.399, cos=0.995), tot_loss_proj:4.201 [t=0.17s]
prediction: ['[CLS] informationchev intentionskie chart decades decades could well chose phrase. big not receives thesis, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.570 (perp=10.952, rec=0.384, cos=0.996), tot_loss_proj:4.030 [t=0.17s]
prediction: ['[CLS] information notions bribes chart decades decades could well chose phrase. bigchev receivesnessy, [SEP]']
[ 450/2000] tot_loss=3.488 (perp=10.608, rec=0.370, cos=0.996), tot_loss_proj:3.922 [t=0.17s]
prediction: ['[CLS] information not released bribes chart decades decades could well chose phrase. goldenchev interactionnessy, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.863 (perp=12.495, rec=0.367, cos=0.996), tot_loss_proj:4.289 [t=0.17s]
prediction: ['[CLS] information not releasedceaeburgsight grandfather could well exposed phrase. morechev chosechiorba [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.982 (perp=11.672, rec=0.661, cos=0.986), tot_loss_proj:4.179 [t=0.18s]
prediction: ['[CLS] information not ॥ his couldsight.ti no stephen pardon. wouldchev chose depthrba [SEP]']
[ 600/2000] tot_loss=3.842 (perp=11.815, rec=0.487, cos=0.991), tot_loss_proj:4.166 [t=0.17s]
prediction: ['[CLS] information notworks his could advisory.ti do stephen pardon, thenchev chose thingsrba [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.505 (perp=10.359, rec=0.441, cos=0.992), tot_loss_proj:3.872 [t=0.17s]
prediction: ['[CLS] information simply betray histi advisory. could do receives pardon, thenchev chose things has [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.585 (perp=10.850, rec=0.422, cos=0.993), tot_loss_proj:3.949 [t=0.17s]
prediction: ['[CLS] information simply peggy his pardon information. could do breuningti, thenchev chose domenico has [SEP]']
[ 750/2000] tot_loss=3.653 (perp=11.262, rec=0.408, cos=0.992), tot_loss_proj:4.013 [t=0.18s]
prediction: ['[CLS] information just peggy his pardonnsor. could do breuningti, thenchev chose domenico has [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.337 (perp=9.706, rec=0.402, cos=0.993), tot_loss_proj:3.686 [t=0.17s]
prediction: ['[CLS] has not released his pardonnsor. could do breuning offer, thenchev chose domenico information [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.311 (perp=9.601, rec=0.396, cos=0.994), tot_loss_proj:3.772 [t=0.18s]
prediction: ['[CLS] has not released his pardonnsor information could donging offer, thenchev chose domenico. [SEP]']
[ 900/2000] tot_loss=3.298 (perp=9.601, rec=0.384, cos=0.994), tot_loss_proj:3.771 [t=0.18s]
prediction: ['[CLS] has not released his pardonnsor information could donging offer, thenchev chose domenico. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.259 (perp=9.363, rec=0.393, cos=0.994), tot_loss_proj:3.711 [t=0.18s]
prediction: ['[CLS] has not released his pardon could informationnsor donging decision, thenchev chose becca. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.243 (perp=9.363, rec=0.376, cos=0.995), tot_loss_proj:3.711 [t=0.17s]
prediction: ['[CLS] has not released his pardon could informationnsor donging decision, thenchev chose becca. [SEP]']
[1050/2000] tot_loss=3.247 (perp=9.363, rec=0.380, cos=0.995), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] has not released his pardon could informationnsor donging decision, thenchev chose becca. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.217 (perp=9.259, rec=0.370, cos=0.995), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] has not released his pardon could information donsornging decision, thenchev chose becca. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.216 (perp=9.259, rec=0.369, cos=0.995), tot_loss_proj:3.701 [t=0.18s]
prediction: ['[CLS] has not released his pardon could information donsornging decision, thenchev chose becca. [SEP]']
[1200/2000] tot_loss=3.217 (perp=9.259, rec=0.370, cos=0.995), tot_loss_proj:3.702 [t=0.17s]
prediction: ['[CLS] has not released his pardon could information donsornging decision, thenchev chose becca. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.218 (perp=9.259, rec=0.372, cos=0.995), tot_loss_proj:3.701 [t=0.17s]
prediction: ['[CLS] has not released his pardon could information donsornging decision, thenchev chose becca. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.217 (perp=9.259, rec=0.370, cos=0.995), tot_loss_proj:3.697 [t=0.17s]
prediction: ['[CLS] has not released his pardon could information donsornging decision, thenchev chose becca. [SEP]']
[1350/2000] tot_loss=3.168 (perp=9.052, rec=0.363, cos=0.995), tot_loss_proj:3.628 [t=0.17s]
prediction: ['[CLS] has not released his pardon could information donsorheard decision, thenchev chose becca. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.168 (perp=9.052, rec=0.362, cos=0.995), tot_loss_proj:3.628 [t=0.17s]
prediction: ['[CLS] has not released his pardon could information donsorheard decision, thenchev chose becca. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.184 (perp=9.052, rec=0.378, cos=0.995), tot_loss_proj:3.628 [t=0.18s]
prediction: ['[CLS] has not released his pardon could information donsorheard decision, thenchev chose becca. [SEP]']
[1500/2000] tot_loss=3.170 (perp=9.052, rec=0.364, cos=0.995), tot_loss_proj:3.627 [t=0.18s]
prediction: ['[CLS] has not released his pardon could information donsorheard decision, thenchev chose becca. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.169 (perp=9.052, rec=0.363, cos=0.995), tot_loss_proj:3.629 [t=0.17s]
prediction: ['[CLS] has not released his pardon could information donsorheard decision, thenchev chose becca. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.167 (perp=9.052, rec=0.361, cos=0.995), tot_loss_proj:3.627 [t=0.17s]
prediction: ['[CLS] has not released his pardon could information donsorheard decision, thenchev chose becca. [SEP]']
[1650/2000] tot_loss=3.157 (perp=9.052, rec=0.351, cos=0.995), tot_loss_proj:3.628 [t=0.18s]
prediction: ['[CLS] has not released his pardon could information donsorheard decision, thenchev chose becca. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=3.147 (perp=8.918, rec=0.368, cos=0.995), tot_loss_proj:3.604 [t=0.18s]
prediction: ['[CLS] has not released his pardon information could donsorheard decision, thenchev chose becca. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.143 (perp=8.918, rec=0.364, cos=0.995), tot_loss_proj:3.605 [t=0.17s]
prediction: ['[CLS] has not released his pardon information could donsorheard decision, thenchev chose becca. [SEP]']
[1800/2000] tot_loss=3.142 (perp=8.918, rec=0.363, cos=0.995), tot_loss_proj:3.603 [t=0.17s]
prediction: ['[CLS] has not released his pardon information could donsorheard decision, thenchev chose becca. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.140 (perp=8.918, rec=0.361, cos=0.995), tot_loss_proj:3.601 [t=0.17s]
prediction: ['[CLS] has not released his pardon information could donsorheard decision, thenchev chose becca. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.136 (perp=8.918, rec=0.357, cos=0.995), tot_loss_proj:3.606 [t=0.17s]
prediction: ['[CLS] has not released his pardon information could donsorheard decision, thenchev chose becca. [SEP]']
[1950/2000] tot_loss=3.144 (perp=8.918, rec=0.365, cos=0.995), tot_loss_proj:3.605 [t=0.17s]
prediction: ['[CLS] has not released his pardon information could donsorheard decision, thenchev chose becca. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.141 (perp=8.918, rec=0.362, cos=0.995), tot_loss_proj:3.605 [t=0.17s]
prediction: ['[CLS] has not released his pardon information could donsorheard decision, thenchev chose becca. [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]
========================
predicted: 
========================
[CLS] has not released his pardon information could donsorheard decision, thenchev chose becca. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.276 | p: 50.000 | r: 46.667
rouge2     | fm: 7.407 | p: 7.692 | r: 7.143
rougeL     | fm: 34.483 | p: 35.714 | r: 33.333
rougeLsum  | fm: 34.483 | p: 35.714 | r: 33.333
r1fm+r2fm = 55.683

[Aggregate metrics]:
rouge1     | fm: 79.499 | p: 80.467 | r: 78.901
rouge2     | fm: 39.297 | p: 39.262 | r: 39.495
rougeL     | fm: 68.591 | p: 69.280 | r: 68.189
rougeLsum  | fm: 68.541 | p: 69.295 | r: 68.128
r1fm+r2fm = 118.796

input #36 time: 0:07:00 | total time: 4:19:50


Running input #37 of 100.
reference: 
========================
Kevin ate spaghetti with a spoon and Geordie did so too.
========================
Sample: 0 8.200695206166865e-11 0.044736533838878996 0.30852264
average of cosine similarity 0.9894313001231408
highest_index [0]
highest [0.9894313001231408]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  4901,  8823, 26666,  2007,  1037, 15642,  1998, 20248, 17080,
          2063,  2106,  2061,  2205,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]']
[Init] best rec loss: 0.9316594004631042 for ['[CLS] grace extent first over maritime walked aria intake axis catcher dickinson twice tires serve [SEP]']
[Init] best rec loss: 0.9283725023269653 for ['[CLS] firingih bark programme powell colt angeles iangina warrant intention natural torontokind [SEP]']
[Init] best rec loss: 0.9265769124031067 for ['[CLS] chip culture airndafa phrase abandoned dissatisfied team musicbula page trulybahn [SEP]']
[Init] best rec loss: 0.9028146862983704 for ['[CLS] gone don sqaur [SEP] labels ivory fair crew across folded lamar plates roses [SEP]']
[Init] best perm rec loss: 0.9003402590751648 for ['[CLS] goneaur sq across folded crew don [SEP] lamar roses fair ivory labels plates [SEP]']
[Init] best perm rec loss: 0.8979520201683044 for ['[CLS] don lamar gone rosesaur folded labels across crew plates sq [SEP] fair ivory [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.066 (perp=12.483, rec=0.569, cos=1.000), tot_loss_proj:4.294 [t=0.17s]
prediction: ['[CLS] falkland eugen, casefrdi expense showed lucky ; burned geo hopeless storms [SEP]']
[ 100/2000] tot_loss=4.046 (perp=12.872, rec=0.473, cos=0.999), tot_loss_proj:4.609 [t=0.18s]
prediction: ['[CLS] everyone annabelle, downrdirdi did ate jessie ; ate geo geordi [SEP]']
[ 150/2000] tot_loss=4.121 (perp=12.531, rec=0.623, cos=0.992), tot_loss_proj:4.441 [t=0.19s]
prediction: ['[CLS] retirement peerage. wasrdirdi giggles oh mrs ; burned benrdi [SEP]']
[ 200/2000] tot_loss=3.801 (perp=11.812, rec=0.446, cos=0.993), tot_loss_proj:4.238 [t=0.17s]
prediction: ['[CLS] lana peerage. leastrdirdi ( did kevin ; burned geonrdi [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.789 (perp=11.615, rec=0.476, cos=0.989), tot_loss_proj:4.254 [t=0.17s]
prediction: ['[CLS] lana peerage. leastrdi ( did kevin ; saidlynnrdi geordi [SEP]']
[ 300/2000] tot_loss=3.751 (perp=11.754, rec=0.409, cos=0.991), tot_loss_proj:4.219 [t=0.17s]
prediction: ['[CLS] lana peerage. candacerdi ( did kevin while saidlynnrdi geordi [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.559 (perp=10.631, rec=0.445, cos=0.988), tot_loss_proj:4.074 [t=0.17s]
prediction: ['[CLS] namely did critics, similarlyrdi書 kevin ; smokeerdi geordi [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.748 (perp=11.743, rec=0.409, cos=0.990), tot_loss_proj:4.217 [t=0.17s]
prediction: ['[CLS] namely didrdi, ate peerage ( kevin while smokeoiserdi geordi [SEP]']
[ 450/2000] tot_loss=3.742 (perp=11.825, rec=0.385, cos=0.992), tot_loss_proj:4.246 [t=0.17s]
prediction: ['[CLS] namely didrdi, ate peerage ( kevin while ateoiserdi geordi [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.498 (perp=10.674, rec=0.371, cos=0.992), tot_loss_proj:3.986 [t=0.17s]
prediction: ['[CLS] analysis didrdi kevin, ate peerage ( while ate agendardi geordi [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.504 (perp=10.723, rec=0.368, cos=0.991), tot_loss_proj:3.992 [t=0.17s]
prediction: ['[CLS] analysis didrdi kevin died peerage, ( and ate agendardi geordi [SEP]']
[ 600/2000] tot_loss=3.707 (perp=11.852, rec=0.347, cos=0.990), tot_loss_proj:4.215 [t=0.17s]
prediction: ['[CLS] analysis didrdi kevin beside peerage, _ and ate agendardi geordi [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.861 (perp=12.658, rec=0.340, cos=0.989), tot_loss_proj:4.364 [t=0.17s]
prediction: ['[CLS] analysis didrdi kevin beside ( peerage, and ate racialrdi geordi [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.734 (perp=12.023, rec=0.341, cos=0.988), tot_loss_proj:4.241 [t=0.17s]
prediction: ['[CLS] rather didrdi kevin beside ( ion, and ate racial peerage geordi [SEP]']
[ 750/2000] tot_loss=3.729 (perp=12.029, rec=0.334, cos=0.989), tot_loss_proj:4.236 [t=0.17s]
prediction: ['[CLS] rather didrdi kevin beside ( ion, and ate sasha latin geordi [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.748 (perp=12.142, rec=0.330, cos=0.990), tot_loss_proj:4.252 [t=0.17s]
prediction: ['[CLS] rather didrdi spaghetti beside ( ion. and ate sasha kevin geordi [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.719 (perp=11.951, rec=0.341, cos=0.988), tot_loss_proj:4.202 [t=0.17s]
prediction: ['[CLS] rather didrdi spaghetti beside ( ion. and racial ate kevin geordi [SEP]']
[ 900/2000] tot_loss=3.578 (perp=11.334, rec=0.320, cos=0.991), tot_loss_proj:4.119 [t=0.17s]
prediction: ['[CLS] rather didrdi spaghetti beside ( ion. and sasha ate kevin geordi [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.480 (perp=10.803, rec=0.328, cos=0.991), tot_loss_proj:4.024 [t=0.18s]
prediction: ['[CLS] rather didrdi. beside ( ion spaghetti and sasha ate kevin geordi [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.406 (perp=10.427, rec=0.330, cos=0.990), tot_loss_proj:3.903 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( ion spaghetti beside and sasha ate kevin geordi [SEP]']
[1050/2000] tot_loss=3.393 (perp=10.427, rec=0.317, cos=0.991), tot_loss_proj:3.907 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( ion spaghetti beside and sasha ate kevin geordi [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.374 (perp=10.338, rec=0.316, cos=0.990), tot_loss_proj:3.935 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( beside ion spaghetti and sasha ate kevin geordi [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=3.352 (perp=10.161, rec=0.328, cos=0.992), tot_loss_proj:3.948 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( beside ion and spaghetti sasha ate kevin geordi [SEP]']
[1200/2000] tot_loss=3.338 (perp=10.161, rec=0.315, cos=0.991), tot_loss_proj:3.954 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( beside ion and spaghetti sasha ate kevin geordi [SEP]']
Attempt swap
[1250/2000] tot_loss=3.335 (perp=10.161, rec=0.311, cos=0.991), tot_loss_proj:3.948 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( beside ion and spaghetti sasha ate kevin geordi [SEP]']
Attempt swap
[1300/2000] tot_loss=3.362 (perp=10.272, rec=0.316, cos=0.991), tot_loss_proj:3.927 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( gavepile and spaghetti sasha ate kevin geordi [SEP]']
[1350/2000] tot_loss=3.351 (perp=10.272, rec=0.306, cos=0.991), tot_loss_proj:3.934 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( gavepile and spaghetti sasha ate kevin geordi [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=3.392 (perp=10.468, rec=0.307, cos=0.992), tot_loss_proj:3.978 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( gave kevin and spaghettionus atepile geordi [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=3.360 (perp=10.279, rec=0.312, cos=0.992), tot_loss_proj:3.900 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( gave spaghetti and kevin sasha atepile geordi [SEP]']
[1500/2000] tot_loss=3.352 (perp=10.279, rec=0.305, cos=0.992), tot_loss_proj:3.900 [t=0.17s]
prediction: ['[CLS] rather didrdi. ( gave spaghetti and kevin sasha atepile geordi [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=3.230 (perp=9.658, rec=0.307, cos=0.992), tot_loss_proj:3.788 [t=0.17s]
prediction: ['[CLS] ratherrdi did. ( gave spaghetti and kevin sasha atepile geordi [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=3.164 (perp=9.255, rec=0.321, cos=0.992), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] ratherrdi did. ( gave spaghetti sasha kevin and atepile geordi [SEP]']
[1650/2000] tot_loss=3.158 (perp=9.255, rec=0.316, cos=0.992), tot_loss_proj:3.711 [t=0.17s]
prediction: ['[CLS] ratherrdi did. ( gave spaghetti sasha kevin and atepile geordi [SEP]']
Attempt swap
[1700/2000] tot_loss=3.146 (perp=9.255, rec=0.303, cos=0.992), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] ratherrdi did. ( gave spaghetti sasha kevin and atepile geordi [SEP]']
Attempt swap
[1750/2000] tot_loss=3.148 (perp=9.255, rec=0.305, cos=0.992), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] ratherrdi did. ( gave spaghetti sasha kevin and atepile geordi [SEP]']
[1800/2000] tot_loss=3.150 (perp=9.255, rec=0.307, cos=0.992), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] ratherrdi did. ( gave spaghetti sasha kevin and atepile geordi [SEP]']
Attempt swap
[1850/2000] tot_loss=3.138 (perp=9.255, rec=0.295, cos=0.992), tot_loss_proj:3.717 [t=0.18s]
prediction: ['[CLS] ratherrdi did. ( gave spaghetti sasha kevin and atepile geordi [SEP]']
Attempt swap
[1900/2000] tot_loss=3.146 (perp=9.255, rec=0.303, cos=0.992), tot_loss_proj:3.716 [t=0.21s]
prediction: ['[CLS] ratherrdi did. ( gave spaghetti sasha kevin and atepile geordi [SEP]']
[1950/2000] tot_loss=3.155 (perp=9.255, rec=0.312, cos=0.992), tot_loss_proj:3.715 [t=0.20s]
prediction: ['[CLS] ratherrdi did. ( gave spaghetti sasha kevin and atepile geordi [SEP]']
Attempt swap
[2000/2000] tot_loss=3.142 (perp=9.255, rec=0.299, cos=0.992), tot_loss_proj:3.719 [t=0.19s]
prediction: ['[CLS] ratherrdi did. ( gave spaghetti sasha kevin and atepile geordi [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]
========================
predicted: 
========================
[CLS] ratherrdi did. ( gave spaghetti sasha kevin and atepile geordi [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 54.545 | r: 46.154
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 33.333 | p: 36.364 | r: 30.769
rougeLsum  | fm: 33.333 | p: 36.364 | r: 30.769
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 78.587 | p: 79.652 | r: 77.938
rouge2     | fm: 38.398 | p: 38.430 | r: 38.453
rougeL     | fm: 67.646 | p: 68.389 | r: 67.152
rougeLsum  | fm: 67.655 | p: 68.493 | r: 67.136
r1fm+r2fm = 116.984

input #37 time: 0:07:01 | total time: 4:26:52


Running input #38 of 100.
reference: 
========================
John is the kind of fool that I told you about.
========================
Sample: 0 2.528064683912059e-11 0.0486004103673312 0.34904584
average of cosine similarity 0.9902589652823317
highest_index [0]
highest [0.9902589652823317]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2198, 2003, 1996, 2785, 1997, 7966, 2008, 1045, 2409, 2017, 2055,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is the kind of fool that i told you about. [SEP]']
[Init] best rec loss: 0.9675338268280029 for ['[CLS] medicine horns clear john splash treaties samson com credited birthplace ago managing [SEP]']
[Init] best rec loss: 0.9361371397972107 for ['[CLS]vance jace texas silk mid will ongative to important sweat prize [SEP]']
[Init] best rec loss: 0.9326436519622803 for ['[CLS] nina won allied issues after stride growing joo kevin gabriel skiermonium [SEP]']
[Init] best rec loss: 0.9324679970741272 for ['[CLS] off bumpheint same mustlding sydney young movie something odd [SEP]']
[Init] best rec loss: 0.9286861419677734 for ['[CLS] jr massachusetts [SEP] refrigerator inch paradox jury all provided somewhere galaxy francis [SEP]']
[Init] best rec loss: 0.9026694297790527 for ['[CLS] label sea safety zeronessfixed builder med scrub fairound amateur [SEP]']
[Init] best perm rec loss: 0.9024163484573364 for ['[CLS] seaound zeroness safety medfixed scrub label builder fair amateur [SEP]']
[Init] best perm rec loss: 0.9023182392120361 for ['[CLS]fixed med amateur zeroound label seaness builder fair scrub safety [SEP]']
[Init] best perm rec loss: 0.9020756483078003 for ['[CLS]ness amateuround sea labelfixed med scrub zero fair builder safety [SEP]']
[Init] best perm rec loss: 0.9013963341712952 for ['[CLS]ness zero safetyfixed scrub builder label sea fair amateuround med [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.635 (perp=8.846, rec=0.503, cos=0.363), tot_loss_proj:3.789 [t=0.17s]
prediction: ['[CLS] really.??ward raymond your. his? fool. [SEP]']
[ 100/2000] tot_loss=2.351 (perp=10.012, rec=0.304, cos=0.044), tot_loss_proj:3.833 [t=0.17s]
prediction: ['[CLS] seriously fool.? i a you. kind gave foollaise [SEP]']
[ 150/2000] tot_loss=2.198 (perp=9.651, rec=0.232, cos=0.036), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] seriously fool john is that the you of kind john type rory [SEP]']
[ 200/2000] tot_loss=2.017 (perp=8.979, rec=0.190, cos=0.031), tot_loss_proj:3.692 [t=0.17s]
prediction: ['[CLS] seriously fool john is that the you of kind john type, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.651 (perp=7.173, rec=0.182, cos=0.035), tot_loss_proj:3.220 [t=0.17s]
prediction: ['[CLS] if fool john is that the sort of kind john you, [SEP]']
[ 300/2000] tot_loss=1.597 (perp=7.094, rec=0.152, cos=0.026), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS]? fool john is that the sort of kind john you, [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.749 (perp=7.692, rec=0.180, cos=0.030), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS]? fool john is that john the sort of kind you... [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.795 (perp=8.077, rec=0.153, cos=0.027), tot_loss_proj:3.465 [t=0.17s]
prediction: ['[CLS]? fool john is that john you told of kind the... [SEP]']
[ 450/2000] tot_loss=1.726 (perp=7.801, rec=0.141, cos=0.025), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS]! fool john is that john you told of kind the. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.817 (perp=7.943, rec=0.193, cos=0.036), tot_loss_proj:3.431 [t=0.17s]
prediction: ['[CLS] ே fool john is that john you kind of guys the. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.639 (perp=7.249, rec=0.160, cos=0.030), tot_loss_proj:3.243 [t=0.17s]
prediction: ['[CLS] ே fool john is that john you kind of the guys. [SEP]']
[ 600/2000] tot_loss=1.733 (perp=7.810, rec=0.143, cos=0.029), tot_loss_proj:3.391 [t=0.17s]
prediction: ['[CLS] ே fool john is that john you kind of the we. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.692 (perp=7.619, rec=0.140, cos=0.028), tot_loss_proj:3.335 [t=0.17s]
prediction: ['[CLS] ே fool john is that the you kind of john we. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.695 (perp=7.619, rec=0.144, cos=0.027), tot_loss_proj:3.332 [t=0.17s]
prediction: ['[CLS] ே fool john is that the you kind of john we. [SEP]']
[ 750/2000] tot_loss=1.677 (perp=7.619, rec=0.126, cos=0.027), tot_loss_proj:3.331 [t=0.17s]
prediction: ['[CLS] ே fool john is that the you kind of john we. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.680 (perp=7.619, rec=0.130, cos=0.027), tot_loss_proj:3.332 [t=0.17s]
prediction: ['[CLS] ே fool john is that the you kind of john we. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.707 (perp=7.735, rec=0.132, cos=0.027), tot_loss_proj:3.330 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
[ 900/2000] tot_loss=1.704 (perp=7.735, rec=0.130, cos=0.027), tot_loss_proj:3.325 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.695 (perp=7.735, rec=0.122, cos=0.026), tot_loss_proj:3.328 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.690 (perp=7.735, rec=0.117, cos=0.026), tot_loss_proj:3.329 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
[1050/2000] tot_loss=1.693 (perp=7.735, rec=0.120, cos=0.026), tot_loss_proj:3.324 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.687 (perp=7.735, rec=0.114, cos=0.026), tot_loss_proj:3.326 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.695 (perp=7.735, rec=0.123, cos=0.025), tot_loss_proj:3.326 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
[1200/2000] tot_loss=1.688 (perp=7.735, rec=0.116, cos=0.025), tot_loss_proj:3.327 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.692 (perp=7.735, rec=0.120, cos=0.025), tot_loss_proj:3.325 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.689 (perp=7.735, rec=0.116, cos=0.025), tot_loss_proj:3.331 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
[1350/2000] tot_loss=1.683 (perp=7.735, rec=0.111, cos=0.025), tot_loss_proj:3.325 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.679 (perp=7.735, rec=0.107, cos=0.025), tot_loss_proj:3.329 [t=0.17s]
prediction: ['[CLS] ே fool john is you that the kind about john told. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.642 (perp=7.448, rec=0.127, cos=0.026), tot_loss_proj:3.279 [t=0.17s]
prediction: ['[CLS] john fool ே is you that the kind about john told. [SEP]']
[1500/2000] tot_loss=1.623 (perp=7.448, rec=0.108, cos=0.026), tot_loss_proj:3.276 [t=0.17s]
prediction: ['[CLS] john fool ே is you that the kind about john told. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.605 (perp=7.278, rec=0.125, cos=0.025), tot_loss_proj:3.245 [t=0.17s]
prediction: ['[CLS] the fool ே is you that john kind about john told. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.593 (perp=7.278, rec=0.112, cos=0.025), tot_loss_proj:3.246 [t=0.17s]
prediction: ['[CLS] the fool ே is you that john kind about john told. [SEP]']
[1650/2000] tot_loss=1.598 (perp=7.278, rec=0.117, cos=0.025), tot_loss_proj:3.247 [t=0.17s]
prediction: ['[CLS] the fool ே is you that john kind about john told. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.592 (perp=7.278, rec=0.111, cos=0.025), tot_loss_proj:3.248 [t=0.17s]
prediction: ['[CLS] the fool ே is you that john kind about john told. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.587 (perp=7.278, rec=0.106, cos=0.025), tot_loss_proj:3.246 [t=0.17s]
prediction: ['[CLS] the fool ே is you that john kind about john told. [SEP]']
[1800/2000] tot_loss=1.591 (perp=7.278, rec=0.111, cos=0.025), tot_loss_proj:3.246 [t=0.17s]
prediction: ['[CLS] the fool ே is you that john kind about john told. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.543 (perp=6.989, rec=0.120, cos=0.025), tot_loss_proj:3.245 [t=0.17s]
prediction: ['[CLS] the fool ே is you that john kind told about john. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.541 (perp=6.989, rec=0.119, cos=0.025), tot_loss_proj:3.244 [t=0.17s]
prediction: ['[CLS] the fool ே is you that john kind told about john. [SEP]']
[1950/2000] tot_loss=1.531 (perp=6.989, rec=0.108, cos=0.025), tot_loss_proj:3.243 [t=0.19s]
prediction: ['[CLS] the fool ே is you that john kind told about john. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.544 (perp=6.989, rec=0.121, cos=0.025), tot_loss_proj:3.248 [t=0.17s]
prediction: ['[CLS] the fool ே is you that john kind told about john. [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] john is the kind of fool that i told you about. [SEP]
========================
predicted: 
========================
[CLS] the fool ே is you that john kind about john told. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 91.667 | r: 84.615
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 48.000 | p: 50.000 | r: 46.154
rougeLsum  | fm: 48.000 | p: 50.000 | r: 46.154
r1fm+r2fm = 88.000

[Aggregate metrics]:
rouge1     | fm: 78.972 | p: 80.066 | r: 78.111
rouge2     | fm: 37.166 | p: 37.226 | r: 37.395
rougeL     | fm: 67.147 | p: 67.965 | r: 66.615
rougeLsum  | fm: 67.045 | p: 67.962 | r: 66.453
r1fm+r2fm = 116.138

input #38 time: 0:06:55 | total time: 4:33:47


Running input #39 of 100.
reference: 
========================
I doubt if you can help me in understanding this.
========================
Sample: 0 1.5188378314757766e-08 0.051884722422132726 0.36481202
average of cosine similarity 0.989834689370328
highest_index [0]
highest [0.989834689370328]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 1045, 4797, 2065, 2017, 2064, 2393, 2033, 1999, 4824, 2023, 1012,
          102]], device='cuda:0')
Debug: ref = ['[CLS] i doubt if you can help me in understanding this. [SEP]']
[Init] best rec loss: 0.9692432880401611 for ['[CLS] probably issue jade aren circumstances day old mayohum asian belonging [SEP]']
[Init] best rec loss: 0.9366908073425293 for ['[CLS] complications destiny com sex asteroids location outline shock focus impact highest [SEP]']
[Init] best rec loss: 0.9288410544395447 for ['[CLS] being reserved treat layer regulation model nose niche paddle picked think [SEP]']
[Init] best rec loss: 0.9272903800010681 for ['[CLS] exchange connect piano confirmed planted class mean company critically d men [SEP]']
[Init] best rec loss: 0.9174222946166992 for ['[CLS] legislature exploits mit alice didn tubes true mountvity lane animal [SEP]']
[Init] best rec loss: 0.9120254516601562 for ['[CLS] evangelist across shared fingernails rhythm machine following competition minute member babylon [SEP]']
[Init] best rec loss: 0.9110709428787231 for ['[CLS] composergist squared dee directedigraphy payingunds caseative half [SEP]']
[Init] best perm rec loss: 0.9087654948234558 for ['[CLS] payinggistunds squared caseigraphy half dee composer directedative [SEP]']
[Init] best perm rec loss: 0.9077205657958984 for ['[CLS] directed half payinggistative dee case composerunds squaredigraphy [SEP]']
[Init] best perm rec loss: 0.9066043496131897 for ['[CLS]undsative paying half squaredigraphy directed case composergist dee [SEP]']
[Init] best perm rec loss: 0.9061527252197266 for ['[CLS] composerative payingigraphy directed half squared deegist caseunds [SEP]']
[Init] best perm rec loss: 0.9044231176376343 for ['[CLS] caseunds directedative squaredigraphy dee composergist half paying [SEP]']
[Init] best perm rec loss: 0.9036428928375244 for ['[CLS] directedative half composergist caseunds paying squaredigraphy dee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.495 (perp=9.567, rec=0.612, cos=0.970), tot_loss_proj:3.655 [t=0.17s]
prediction: ['[CLS] thereby smiled think. can you is better experience transmission on [SEP]']
[ 100/2000] tot_loss=3.520 (perp=10.205, rec=0.591, cos=0.888), tot_loss_proj:3.819 [t=0.17s]
prediction: ['[CLS]? if it region could you is if reserves transmission this [SEP]']
[ 150/2000] tot_loss=2.043 (perp=8.557, rec=0.280, cos=0.052), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] i doubt you can could you while helping understanding forth this [SEP]']
[ 200/2000] tot_loss=1.930 (perp=8.448, rec=0.208, cos=0.033), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] i doubt you ( can you while help understanding forth this [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.972 (perp=8.553, rec=0.222, cos=0.039), tot_loss_proj:3.451 [t=0.17s]
prediction: ['[CLS] i doubt you learning can you help in understandingathic this [SEP]']
[ 300/2000] tot_loss=1.836 (perp=8.224, rec=0.159, cos=0.033), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS] i doubt if learning can me help in understandingathic this [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.444 (perp=6.361, rec=0.140, cos=0.032), tot_loss_proj:3.328 [t=0.17s]
prediction: ['[CLS] i doubt if learning can help me in understanding outcome this [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.301 (perp=5.663, rec=0.137, cos=0.032), tot_loss_proj:1.837 [t=0.17s]
prediction: ['[CLS] i doubt if reading can help me in understanding this outcome [SEP]']
[ 450/2000] tot_loss=1.295 (perp=5.663, rec=0.131, cos=0.032), tot_loss_proj:1.834 [t=0.17s]
prediction: ['[CLS] i doubt if reading can help me in understanding this outcome [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.299 (perp=5.663, rec=0.135, cos=0.031), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] i doubt if reading can help me in understanding this outcome [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.291 (perp=5.663, rec=0.128, cos=0.031), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] i doubt if reading can help me in understanding this outcome [SEP]']
[ 600/2000] tot_loss=1.134 (perp=4.927, rec=0.118, cos=0.031), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] i doubt if this can help me in understanding this outcome [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.143 (perp=4.927, rec=0.128, cos=0.030), tot_loss_proj:1.534 [t=0.17s]
prediction: ['[CLS] i doubt if this can help me in understanding this outcome [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.132 (perp=4.927, rec=0.116, cos=0.030), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] i doubt if this can help me in understanding this outcome [SEP]']
[ 750/2000] tot_loss=1.137 (perp=4.927, rec=0.122, cos=0.030), tot_loss_proj:1.534 [t=0.17s]
prediction: ['[CLS] i doubt if this can help me in understanding this outcome [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.138 (perp=4.927, rec=0.123, cos=0.030), tot_loss_proj:1.530 [t=0.18s]
prediction: ['[CLS] i doubt if this can help me in understanding this outcome [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.243 (perp=5.462, rec=0.121, cos=0.029), tot_loss_proj:3.207 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this outcome [SEP]']
[ 900/2000] tot_loss=1.248 (perp=5.462, rec=0.127, cos=0.029), tot_loss_proj:3.207 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this outcome [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.233 (perp=5.462, rec=0.112, cos=0.029), tot_loss_proj:3.206 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this outcome [SEP]']
Attempt swap
[1000/2000] tot_loss=1.233 (perp=5.462, rec=0.112, cos=0.029), tot_loss_proj:3.202 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this outcome [SEP]']
[1050/2000] tot_loss=1.231 (perp=5.462, rec=0.109, cos=0.029), tot_loss_proj:3.206 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this outcome [SEP]']
Attempt swap
[1100/2000] tot_loss=1.216 (perp=5.366, rec=0.114, cos=0.029), tot_loss_proj:3.168 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1150/2000] tot_loss=1.223 (perp=5.366, rec=0.121, cos=0.029), tot_loss_proj:3.172 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
[1200/2000] tot_loss=1.221 (perp=5.366, rec=0.119, cos=0.029), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1250/2000] tot_loss=1.219 (perp=5.366, rec=0.116, cos=0.029), tot_loss_proj:3.175 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1300/2000] tot_loss=1.224 (perp=5.366, rec=0.122, cos=0.029), tot_loss_proj:3.175 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
[1350/2000] tot_loss=1.219 (perp=5.366, rec=0.117, cos=0.029), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1400/2000] tot_loss=1.212 (perp=5.366, rec=0.110, cos=0.029), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1450/2000] tot_loss=1.218 (perp=5.366, rec=0.116, cos=0.029), tot_loss_proj:3.167 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
[1500/2000] tot_loss=1.218 (perp=5.366, rec=0.116, cos=0.029), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1550/2000] tot_loss=1.220 (perp=5.366, rec=0.118, cos=0.029), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1600/2000] tot_loss=1.219 (perp=5.366, rec=0.117, cos=0.029), tot_loss_proj:3.171 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
[1650/2000] tot_loss=1.218 (perp=5.366, rec=0.116, cos=0.029), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1700/2000] tot_loss=1.229 (perp=5.366, rec=0.127, cos=0.029), tot_loss_proj:3.172 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1750/2000] tot_loss=1.230 (perp=5.366, rec=0.128, cos=0.029), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
[1800/2000] tot_loss=1.219 (perp=5.366, rec=0.117, cos=0.029), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1850/2000] tot_loss=1.223 (perp=5.366, rec=0.121, cos=0.029), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[1900/2000] tot_loss=1.216 (perp=5.366, rec=0.114, cos=0.029), tot_loss_proj:3.171 [t=0.19s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
[1950/2000] tot_loss=1.220 (perp=5.366, rec=0.118, cos=0.029), tot_loss_proj:3.171 [t=0.19s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Attempt swap
[2000/2000] tot_loss=1.212 (perp=5.366, rec=0.110, cos=0.029), tot_loss_proj:3.169 [t=0.20s]
prediction: ['[CLS] i doubt if so can help me in understanding this because [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] i doubt if you can help me in understanding this. [SEP]
========================
predicted: 
========================
[CLS] i doubt if so can help me in understanding this because [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 69.565 | p: 66.667 | r: 72.727
rougeL     | fm: 88.000 | p: 84.615 | r: 91.667
rougeLsum  | fm: 88.000 | p: 84.615 | r: 91.667
r1fm+r2fm = 157.565

[Aggregate metrics]:
rouge1     | fm: 79.143 | p: 80.108 | r: 78.444
rouge2     | fm: 38.242 | p: 38.239 | r: 38.426
rougeL     | fm: 67.585 | p: 68.338 | r: 67.160
rougeLsum  | fm: 67.573 | p: 68.298 | r: 67.135
r1fm+r2fm = 117.385

input #39 time: 0:06:56 | total time: 4:40:44


Running input #40 of 100.
reference: 
========================
Was the child running to the car?
========================
Sample: 0 2.79212896490244e-09 0.05074100890549388 0.34731463
average of cosine similarity 0.9892705712897679
highest_index [0]
highest [0.9892705712897679]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2001, 1996, 2775, 2770, 2000, 1996, 2482, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] was the child running to the car? [SEP]']
[Init] best rec loss: 0.9621278047561646 for ['[CLS]chfield only loan mast lust nape " nearly [SEP]']
[Init] best rec loss: 0.9481551051139832 for ['[CLS]typic races investigation singular haven boreay libby [SEP]']
[Init] best rec loss: 0.9173352122306824 for ['[CLS] standing colonyhers angry isn [SEP] women waste [SEP]']
[Init] best rec loss: 0.9018546938896179 for ['[CLS] rhapsody edna german award hamburg once horn govt [SEP]']
[Init] best rec loss: 0.8998432159423828 for ['[CLS] o junior grinning appear stitchfy with they [SEP]']
[Init] best rec loss: 0.895498514175415 for ['[CLS] arrived door bat simon unwillinghorthaling syn [SEP]']
[Init] best rec loss: 0.8836095929145813 for ['[CLS]lene novi following [SEP] circumstances business practice l [SEP]']
[Init] best rec loss: 0.8725322484970093 for ['[CLS]ning archbishop whomont andreasization parents rest [SEP]']
[Init] best rec loss: 0.8687050938606262 for ['[CLS] ethnic product czech feed diego problems construction methods [SEP]']
[Init] best perm rec loss: 0.8622528910636902 for ['[CLS] diego feed methods product construction czech problems ethnic [SEP]']
[Init] best perm rec loss: 0.8621556758880615 for ['[CLS] construction diego methods feed czech ethnic problems product [SEP]']
[Init] best perm rec loss: 0.8614377975463867 for ['[CLS] czech ethnic construction methods feed problems product diego [SEP]']
[Init] best perm rec loss: 0.8572033643722534 for ['[CLS] feed diego product construction ethnic czech problems methods [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.912 (perp=10.974, rec=0.741, cos=0.977), tot_loss_proj:4.009 [t=0.17s]
prediction: ['[CLS] prospect for killed kills ethnic. had department [SEP]']
[ 100/2000] tot_loss=3.952 (perp=11.739, rec=0.607, cos=0.997), tot_loss_proj:4.234 [t=0.17s]
prediction: ['[CLS] pastrs just is ethnic including and department [SEP]']
[ 150/2000] tot_loss=3.453 (perp=9.502, rec=0.554, cos=0.999), tot_loss_proj:3.820 [t=0.17s]
prediction: ['[CLS] especially lights just is leading also, department [SEP]']
[ 200/2000] tot_loss=3.976 (perp=12.275, rec=0.526, cos=0.995), tot_loss_proj:4.291 [t=0.17s]
prediction: ['[CLS] especially lights child yoko featuring hiding, department [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.595 (perp=10.542, rec=0.494, cos=0.993), tot_loss_proj:4.005 [t=0.17s]
prediction: ['[CLS] entering lights child is featuring car, membership [SEP]']
[ 300/2000] tot_loss=3.571 (perp=9.695, rec=0.632, cos=1.000), tot_loss_proj:3.815 [t=0.17s]
prediction: ['[CLS] ion ح.. featuring hiding for hers [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=4.233 (perp=13.381, rec=0.563, cos=0.994), tot_loss_proj:4.535 [t=0.17s]
prediction: ['[CLS]!. whorls official ion hidingba hers [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.603 (perp=10.380, rec=0.535, cos=0.991), tot_loss_proj:3.967 [t=0.17s]
prediction: ['[CLS] brief? official ion when wallet of hers [SEP]']
[ 450/2000] tot_loss=3.479 (perp=9.981, rec=0.498, cos=0.985), tot_loss_proj:3.838 [t=0.17s]
prediction: ['[CLS] :? official into when wallet of daughter [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.489 (perp=10.079, rec=0.494, cos=0.979), tot_loss_proj:3.980 [t=0.17s]
prediction: ['[CLS] :? officialn of arrived when ms [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.629 (perp=10.737, rec=0.494, cos=0.987), tot_loss_proj:4.102 [t=0.17s]
prediction: ['[CLS] ms? officialn execution arrived when brief [SEP]']
[ 600/2000] tot_loss=3.501 (perp=10.252, rec=0.469, cos=0.981), tot_loss_proj:4.037 [t=0.17s]
prediction: ['[CLS] ms? officialn execution arrived when! [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.234 (perp=8.987, rec=0.458, cos=0.979), tot_loss_proj:3.855 [t=0.17s]
prediction: ['[CLS] ms?n official execution arrived when! [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.191 (perp=8.843, rec=0.449, cos=0.974), tot_loss_proj:3.783 [t=0.17s]
prediction: ['[CLS]? msn official execution arrived when brief [SEP]']
[ 750/2000] tot_loss=3.136 (perp=8.565, rec=0.450, cos=0.973), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS]? msn official execution arrived when found [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.140 (perp=8.635, rec=0.444, cos=0.970), tot_loss_proj:3.787 [t=0.17s]
prediction: ['[CLS]??n official execution car when found [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.977 (perp=7.844, rec=0.443, cos=0.965), tot_loss_proj:3.524 [t=0.17s]
prediction: ['[CLS]? child? official car car car found [SEP]']
[ 900/2000] tot_loss=3.104 (perp=8.562, rec=0.429, cos=0.963), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS]? child? official execution car car found [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.332 (perp=9.742, rec=0.424, cos=0.959), tot_loss_proj:3.897 [t=0.17s]
prediction: ['[CLS]? child? official behind car car found [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.121 (perp=8.571, rec=0.445, cos=0.961), tot_loss_proj:3.652 [t=0.17s]
prediction: ['[CLS]? child car official bus car? found [SEP]']
[1050/2000] tot_loss=3.043 (perp=8.315, rec=0.427, cos=0.954), tot_loss_proj:3.561 [t=0.17s]
prediction: ['[CLS]? child car official behind car? found [SEP]']
Attempt swap
[1100/2000] tot_loss=3.067 (perp=8.459, rec=0.424, cos=0.951), tot_loss_proj:3.570 [t=0.17s]
prediction: ['[CLS]? child car the behind car? found [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.248 (perp=9.340, rec=0.429, cos=0.951), tot_loss_proj:3.768 [t=0.17s]
prediction: ['[CLS]? child car execution the car? found [SEP]']
[1200/2000] tot_loss=2.831 (perp=7.336, rec=0.416, cos=0.947), tot_loss_proj:3.450 [t=0.17s]
prediction: ['[CLS]? child car behind the car? found [SEP]']
Attempt swap
[1250/2000] tot_loss=2.993 (perp=8.183, rec=0.412, cos=0.944), tot_loss_proj:3.589 [t=0.17s]
prediction: ['[CLS]? child car bus the car? found [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=3.024 (perp=8.317, rec=0.421, cos=0.940), tot_loss_proj:3.586 [t=0.17s]
prediction: ['[CLS]? child car bus the car found car [SEP]']
[1350/2000] tot_loss=2.856 (perp=7.474, rec=0.421, cos=0.940), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
Attempt swap
[1400/2000] tot_loss=2.839 (perp=7.474, rec=0.407, cos=0.938), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
Attempt swap
[1450/2000] tot_loss=2.835 (perp=7.474, rec=0.405, cos=0.936), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
[1500/2000] tot_loss=2.837 (perp=7.474, rec=0.408, cos=0.933), tot_loss_proj:3.387 [t=0.17s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
Attempt swap
[1550/2000] tot_loss=2.827 (perp=7.474, rec=0.401, cos=0.931), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
Attempt swap
[1600/2000] tot_loss=2.831 (perp=7.474, rec=0.406, cos=0.930), tot_loss_proj:3.389 [t=0.17s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
[1650/2000] tot_loss=2.827 (perp=7.474, rec=0.404, cos=0.928), tot_loss_proj:3.387 [t=0.17s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
Attempt swap
[1700/2000] tot_loss=2.819 (perp=7.474, rec=0.397, cos=0.927), tot_loss_proj:3.387 [t=0.17s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
Attempt swap
[1750/2000] tot_loss=2.823 (perp=7.474, rec=0.402, cos=0.926), tot_loss_proj:3.384 [t=0.18s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
[1800/2000] tot_loss=2.814 (perp=7.474, rec=0.394, cos=0.925), tot_loss_proj:3.387 [t=0.19s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
Attempt swap
[1850/2000] tot_loss=2.817 (perp=7.474, rec=0.398, cos=0.924), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
Attempt swap
[1900/2000] tot_loss=2.817 (perp=7.474, rec=0.399, cos=0.923), tot_loss_proj:3.385 [t=0.20s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
[1950/2000] tot_loss=2.819 (perp=7.474, rec=0.402, cos=0.922), tot_loss_proj:3.385 [t=0.19s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
Attempt swap
[2000/2000] tot_loss=2.811 (perp=7.474, rec=0.395, cos=0.921), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS]? child car bus the car found? [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] was the child running to the car? [SEP]
========================
predicted: 
========================
[CLS]? child car bus the car found? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.824 | p: 62.500 | r: 55.556
rouge2     | fm: 13.333 | p: 14.286 | r: 12.500
rougeL     | fm: 58.824 | p: 62.500 | r: 55.556
rougeLsum  | fm: 58.824 | p: 62.500 | r: 55.556
r1fm+r2fm = 72.157

[Aggregate metrics]:
rouge1     | fm: 78.655 | p: 79.730 | r: 77.911
rouge2     | fm: 37.549 | p: 37.530 | r: 37.778
rougeL     | fm: 67.334 | p: 68.099 | r: 66.853
rougeLsum  | fm: 67.508 | p: 68.261 | r: 66.986
r1fm+r2fm = 116.203

input #40 time: 0:06:55 | total time: 4:47:39


Running input #41 of 100.
reference: 
========================
Mary is shorter than five feet.
========================
Sample: 0 8.173737192272735e-13 0.044201111586254976 0.32230958
average of cosine similarity 0.9905518455563211
highest_index [0]
highest [0.9905518455563211]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2984, 2003, 7820, 2084, 2274, 2519, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] mary is shorter than five feet. [SEP]']
[Init] best rec loss: 0.9804759621620178 for ['[CLS] try formerly doneicz gmina away originals [SEP]']
[Init] best rec loss: 0.9635863304138184 for ['[CLS] whilst cards loud jacksonon ladies bounded [SEP]']
[Init] best rec loss: 0.9399990439414978 for ['[CLS] she motto nerve five patsy unable deeper [SEP]']
[Init] best rec loss: 0.9262915849685669 for ['[CLS]ticalntonvious subjects hotelceae trains [SEP]']
[Init] best rec loss: 0.9226271510124207 for ['[CLS] [sei mixed sung assuming bag night [SEP]']
[Init] best rec loss: 0.9194919466972351 for ['[CLS]ading investigate closet lily mad page cover [SEP]']
[Init] best rec loss: 0.9147651195526123 for ['[CLS] younger xiarableuded respect miss flight [SEP]']
[Init] best rec loss: 0.9046170115470886 for ['[CLS] [UNK]micises background mechanism forces important [SEP]']
[Init] best rec loss: 0.9044715166091919 for ['[CLS] while they much cannotmal bedside death [SEP]']
[Init] best rec loss: 0.897434651851654 for ['[CLS] optionicated wherehausen fact reflection feel [SEP]']
[Init] best rec loss: 0.877751886844635 for ['[CLS] non completing 0 string page families space [SEP]']
[Init] best perm rec loss: 0.8773093223571777 for ['[CLS] page families non space completing string 0 [SEP]']
[Init] best perm rec loss: 0.8756932616233826 for ['[CLS] completing string non 0 page space families [SEP]']
[Init] best perm rec loss: 0.875471830368042 for ['[CLS] string families non page completing 0 space [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.737 (perp=10.717, rec=0.603, cos=0.991), tot_loss_proj:4.103 [t=0.17s]
prediction: ['[CLS] orders at :ards cyril st assessment [SEP]']
[ 100/2000] tot_loss=3.480 (perp=10.125, rec=0.488, cos=0.966), tot_loss_proj:3.975 [t=0.17s]
prediction: ['[CLS] plants.. shorter allie shorter metre [SEP]']
[ 150/2000] tot_loss=3.786 (perp=11.759, rec=0.477, cos=0.957), tot_loss_proj:4.131 [t=0.17s]
prediction: ['[CLS] aloud is. despite skyscraper shorter defence [SEP]']
[ 200/2000] tot_loss=3.992 (perp=12.754, rec=0.476, cos=0.965), tot_loss_proj:4.359 [t=0.17s]
prediction: ['[CLS] aloud is. shorter cannot shorter deck [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.346 (perp=9.806, rec=0.424, cos=0.960), tot_loss_proj:3.743 [t=0.17s]
prediction: ['[CLS] francis is shorter shorter aloud shorter ; [SEP]']
[ 300/2000] tot_loss=3.404 (perp=10.363, rec=0.383, cos=0.949), tot_loss_proj:3.852 [t=0.17s]
prediction: ['[CLS] mary is shorter shorter answered feet ; [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.843 (perp=12.296, rec=0.431, cos=0.953), tot_loss_proj:4.270 [t=0.17s]
prediction: ['[CLS] species was shorter feet marissa delilahᵤ [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.986 (perp=13.154, rec=0.411, cos=0.945), tot_loss_proj:4.521 [t=0.17s]
prediction: ['[CLS] species mary shorter feet visibility bum delilah [SEP]']
[ 450/2000] tot_loss=3.739 (perp=12.164, rec=0.364, cos=0.941), tot_loss_proj:4.383 [t=0.17s]
prediction: ['[CLS] species mary shorter feet! shillings delilah [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.600 (perp=11.545, rec=0.351, cos=0.940), tot_loss_proj:4.209 [t=0.17s]
prediction: ['[CLS] species mary shorter feet shillings delilah! [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.326 (perp=10.190, rec=0.353, cos=0.935), tot_loss_proj:4.014 [t=0.17s]
prediction: ['[CLS] m mary shorter delilah feet shorter sideways [SEP]']
[ 600/2000] tot_loss=3.045 (perp=8.880, rec=0.345, cos=0.923), tot_loss_proj:3.755 [t=0.17s]
prediction: ['[CLS] m mary shorter ashley feet shorter! [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.024 (perp=8.880, rec=0.332, cos=0.916), tot_loss_proj:3.753 [t=0.17s]
prediction: ['[CLS] m mary shorter ashley feet shorter! [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.013 (perp=8.880, rec=0.331, cos=0.907), tot_loss_proj:3.748 [t=0.17s]
prediction: ['[CLS] m mary shorter ashley feet shorter! [SEP]']
[ 750/2000] tot_loss=2.811 (perp=7.958, rec=0.328, cos=0.892), tot_loss_proj:3.462 [t=0.17s]
prediction: ['[CLS] m mary shorter ashley feet shorter. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.787 (perp=7.958, rec=0.322, cos=0.873), tot_loss_proj:3.461 [t=0.17s]
prediction: ['[CLS] m mary shorter ashley feet shorter. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.972 (perp=9.069, rec=0.319, cos=0.839), tot_loss_proj:3.624 [t=0.17s]
prediction: ['[CLS] mans mary shorter ashley feet shorter. [SEP]']
[ 900/2000] tot_loss=2.929 (perp=9.069, rec=0.319, cos=0.796), tot_loss_proj:3.626 [t=0.17s]
prediction: ['[CLS] mans mary shorter ashley feet shorter. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.891 (perp=9.069, rec=0.312, cos=0.765), tot_loss_proj:3.623 [t=0.17s]
prediction: ['[CLS] mans mary shorter ashley feet shorter. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.863 (perp=9.069, rec=0.315, cos=0.735), tot_loss_proj:3.621 [t=0.17s]
prediction: ['[CLS] mans mary shorter ashley feet shorter. [SEP]']
[1050/2000] tot_loss=2.829 (perp=9.069, rec=0.308, cos=0.707), tot_loss_proj:3.620 [t=0.17s]
prediction: ['[CLS] mans mary shorter ashley feet shorter. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.797 (perp=9.069, rec=0.307, cos=0.676), tot_loss_proj:3.619 [t=0.17s]
prediction: ['[CLS] mans mary shorter ashley feet shorter. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.771 (perp=9.069, rec=0.313, cos=0.644), tot_loss_proj:3.622 [t=0.17s]
prediction: ['[CLS] mans mary shorter ashley feet shorter. [SEP]']
[1200/2000] tot_loss=2.737 (perp=9.069, rec=0.317, cos=0.606), tot_loss_proj:3.622 [t=0.17s]
prediction: ['[CLS] mans mary shorter ashley feet shorter. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.681 (perp=9.069, rec=0.311, cos=0.556), tot_loss_proj:3.620 [t=0.17s]
prediction: ['[CLS] mans mary shorter ashley feet shorter. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.512 (perp=9.127, rec=0.295, cos=0.392), tot_loss_proj:3.647 [t=0.17s]
prediction: ['[CLS] j mary shorter ashley feet shorter. [SEP]']
[1350/2000] tot_loss=2.194 (perp=9.801, rec=0.183, cos=0.051), tot_loss_proj:3.791 [t=0.17s]
prediction: ['[CLS] j mary shorter jenkins feet are. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.170 (perp=9.756, rec=0.175, cos=0.044), tot_loss_proj:3.785 [t=0.17s]
prediction: ['[CLS] j mary shorter pair are feet. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.030 (perp=9.057, rec=0.174, cos=0.044), tot_loss_proj:3.575 [t=0.17s]
prediction: ['[CLS] j mary shorter is pair feet. [SEP]']
[1500/2000] tot_loss=2.030 (perp=9.057, rec=0.179, cos=0.040), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] j mary shorter is pair feet. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.945 (perp=8.678, rec=0.169, cos=0.040), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] mary j shorter is pair feet. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.942 (perp=8.678, rec=0.168, cos=0.038), tot_loss_proj:3.542 [t=0.17s]
prediction: ['[CLS] mary j shorter is pair feet. [SEP]']
[1650/2000] tot_loss=1.929 (perp=8.678, rec=0.156, cos=0.037), tot_loss_proj:3.538 [t=0.17s]
prediction: ['[CLS] mary j shorter is pair feet. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.931 (perp=8.678, rec=0.159, cos=0.037), tot_loss_proj:3.539 [t=0.17s]
prediction: ['[CLS] mary j shorter is pair feet. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.934 (perp=8.678, rec=0.162, cos=0.036), tot_loss_proj:3.544 [t=0.17s]
prediction: ['[CLS] mary j shorter is pair feet. [SEP]']
[1800/2000] tot_loss=1.932 (perp=8.678, rec=0.161, cos=0.036), tot_loss_proj:3.544 [t=0.17s]
prediction: ['[CLS] mary j shorter is pair feet. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.928 (perp=8.678, rec=0.158, cos=0.035), tot_loss_proj:3.536 [t=0.17s]
prediction: ['[CLS] mary j shorter is pair feet. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.725 (perp=7.664, rec=0.156, cos=0.036), tot_loss_proj:3.313 [t=0.17s]
prediction: ['[CLS] mary is shorter 5 pair feet. [SEP]']
[1950/2000] tot_loss=1.728 (perp=7.664, rec=0.160, cos=0.035), tot_loss_proj:3.310 [t=0.17s]
prediction: ['[CLS] mary is shorter 5 pair feet. [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.680 (perp=7.432, rec=0.158, cos=0.036), tot_loss_proj:3.243 [t=0.17s]
prediction: ['[CLS] pair mary is shorter 5 feet. [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] mary is shorter than five feet. [SEP]
========================
predicted: 
========================
[CLS] mary j shorter is pair feet. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 103.571

[Aggregate metrics]:
rouge1     | fm: 78.652 | p: 79.640 | r: 77.886
rouge2     | fm: 37.395 | p: 37.365 | r: 37.543
rougeL     | fm: 67.282 | p: 68.084 | r: 66.764
rougeLsum  | fm: 67.373 | p: 68.109 | r: 66.836
r1fm+r2fm = 116.047

input #41 time: 0:06:54 | total time: 4:54:34


Running input #42 of 100.
reference: 
========================
She has enough of a problem as it is.
========================
Sample: 0 3.1682564596026554e-12 0.05502587790593059 0.3697859
average of cosine similarity 0.9888666240526898
highest_index [0]
highest [0.9888666240526898]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2016, 2038, 2438, 1997, 1037, 3291, 2004, 2009, 2003, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] she has enough of a problem as it is. [SEP]']
[Init] best rec loss: 0.9195099472999573 for ['[CLS] only shooter /press como solid togetherando ‑堂 [SEP]']
[Init] best rec loss: 0.9177475571632385 for ['[CLS] reflex cross tres silk families part ●wind translated like [SEP]']
[Init] best rec loss: 0.9160884022712708 for ['[CLS] violence trees closed much multimament mall freedoms separated squeezed [SEP]']
[Init] best rec loss: 0.9051212668418884 for ['[CLS] screenings former would headarty methyl saint bennett glenn ki [SEP]']
[Init] best rec loss: 0.8916860222816467 for ['[CLS] flock claimed jon domestic intelligence climax everywhere coal still census [SEP]']
[Init] best rec loss: 0.8842885494232178 for ['[CLS] boys # troy bel welcome honey sui application opera lark [SEP]']
[Init] best rec loss: 0.880082368850708 for ['[CLS] south historic maya hayden宀 clerkion coverage former tuesday [SEP]']
[Init] best rec loss: 0.8406323790550232 for ['[CLS] mine time minor deep fort clues erwin son leader troubled [SEP]']
[Init] best rec loss: 0.8227308392524719 for ['[CLS] into movement responsible huh belief hall safe representativepose fellow [SEP]']
[Init] best perm rec loss: 0.8197659254074097 for ['[CLS] representative into huh responsible safe hall belief movement fellowpose [SEP]']
[Init] best perm rec loss: 0.8181493878364563 for ['[CLS] movement responsiblepose safe belief fellow hall representative huh into [SEP]']
[Init] best perm rec loss: 0.8146902918815613 for ['[CLS] fellow representative belief responsible hall movementpose into huh safe [SEP]']
[Init] best perm rec loss: 0.8133512139320374 for ['[CLS] huh representative movement belief fellow into hall responsiblepose safe [SEP]']
[Init] best perm rec loss: 0.8132941126823425 for ['[CLS] safe responsible fellow into hallpose belief movement representative huh [SEP]']
[Init] best perm rec loss: 0.8127557039260864 for ['[CLS] hall belief representative into responsible movement safe huh fellowpose [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.784 (perp=11.077, rec=0.437, cos=0.131), tot_loss_proj:4.133 [t=0.17s]
prediction: ['[CLS] particular / minority five until was representative statutoryex, [SEP]']
[ 100/2000] tot_loss=2.467 (perp=10.431, rec=0.334, cos=0.047), tot_loss_proj:4.118 [t=0.17s]
prediction: ['[CLS] parish a system she have is representative is problem as [SEP]']
[ 150/2000] tot_loss=2.041 (perp=8.622, rec=0.273, cos=0.044), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS] ) as problem she think has enough of problem as [SEP]']
[ 200/2000] tot_loss=1.850 (perp=7.813, rec=0.237, cos=0.049), tot_loss_proj:3.622 [t=0.17s]
prediction: ['[CLS] as having problem she has has enough a problem as [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.945 (perp=8.080, rec=0.263, cos=0.065), tot_loss_proj:3.673 [t=0.17s]
prediction: ['[CLS] is at problem has she has enough of problem as [SEP]']
[ 300/2000] tot_loss=1.795 (perp=8.043, rec=0.152, cos=0.034), tot_loss_proj:3.632 [t=0.17s]
prediction: ['[CLS] is or problem has she has enough of problem as [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.979 (perp=8.460, rec=0.239, cos=0.048), tot_loss_proj:3.573 [t=0.17s]
prediction: ['[CLS] is enough of problem goddamn, has she has as [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.686 (perp=7.471, rec=0.153, cos=0.039), tot_loss_proj:3.437 [t=0.17s]
prediction: ['[CLS] is enough of problem of, as she has has [SEP]']
[ 450/2000] tot_loss=1.740 (perp=7.837, rec=0.136, cos=0.037), tot_loss_proj:3.515 [t=0.17s]
prediction: ['[CLS] is enough of problem of. as she has has [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.707 (perp=7.664, rec=0.139, cos=0.034), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] enough is of problem of. as she has has [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.701 (perp=7.664, rec=0.136, cos=0.033), tot_loss_proj:3.382 [t=0.17s]
prediction: ['[CLS] enough is of problem of. as she has has [SEP]']
[ 600/2000] tot_loss=1.691 (perp=7.664, rec=0.127, cos=0.032), tot_loss_proj:3.375 [t=0.17s]
prediction: ['[CLS] enough is of problem of. as she has has [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.862 (perp=8.543, rec=0.123, cos=0.031), tot_loss_proj:3.665 [t=0.17s]
prediction: ['[CLS] enough of is of problem a as she has has [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.526 (perp=6.884, rec=0.119, cos=0.031), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] enough of is of a problem as she has problem [SEP]']
[ 750/2000] tot_loss=1.519 (perp=6.884, rec=0.111, cos=0.031), tot_loss_proj:3.377 [t=0.17s]
prediction: ['[CLS] enough of is of a problem as she has problem [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.403 (perp=6.286, rec=0.115, cos=0.031), tot_loss_proj:3.201 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has has [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.391 (perp=6.286, rec=0.103, cos=0.031), tot_loss_proj:3.207 [t=0.20s]
prediction: ['[CLS] of is enough of a problem as she has has [SEP]']
[ 900/2000] tot_loss=1.407 (perp=6.286, rec=0.120, cos=0.031), tot_loss_proj:3.201 [t=0.21s]
prediction: ['[CLS] of is enough of a problem as she has has [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.374 (perp=6.174, rec=0.109, cos=0.031), tot_loss_proj:3.188 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1000/2000] tot_loss=1.377 (perp=6.174, rec=0.112, cos=0.031), tot_loss_proj:3.185 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
[1050/2000] tot_loss=1.372 (perp=6.174, rec=0.107, cos=0.030), tot_loss_proj:3.191 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1100/2000] tot_loss=1.360 (perp=6.174, rec=0.094, cos=0.030), tot_loss_proj:3.189 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1150/2000] tot_loss=1.375 (perp=6.174, rec=0.110, cos=0.030), tot_loss_proj:3.189 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
[1200/2000] tot_loss=1.361 (perp=6.174, rec=0.095, cos=0.030), tot_loss_proj:3.190 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1250/2000] tot_loss=1.355 (perp=6.174, rec=0.090, cos=0.030), tot_loss_proj:3.189 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1300/2000] tot_loss=1.366 (perp=6.174, rec=0.101, cos=0.030), tot_loss_proj:3.188 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
[1350/2000] tot_loss=1.373 (perp=6.174, rec=0.107, cos=0.030), tot_loss_proj:3.190 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1400/2000] tot_loss=1.366 (perp=6.174, rec=0.101, cos=0.030), tot_loss_proj:3.191 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1450/2000] tot_loss=1.371 (perp=6.174, rec=0.106, cos=0.030), tot_loss_proj:3.190 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
[1500/2000] tot_loss=1.363 (perp=6.174, rec=0.097, cos=0.030), tot_loss_proj:3.189 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1550/2000] tot_loss=1.369 (perp=6.174, rec=0.103, cos=0.030), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1600/2000] tot_loss=1.367 (perp=6.174, rec=0.102, cos=0.030), tot_loss_proj:3.186 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
[1650/2000] tot_loss=1.359 (perp=6.174, rec=0.094, cos=0.030), tot_loss_proj:3.186 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1700/2000] tot_loss=1.355 (perp=6.174, rec=0.090, cos=0.030), tot_loss_proj:3.186 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1750/2000] tot_loss=1.354 (perp=6.174, rec=0.088, cos=0.030), tot_loss_proj:3.191 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
[1800/2000] tot_loss=1.367 (perp=6.174, rec=0.102, cos=0.030), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1850/2000] tot_loss=1.368 (perp=6.174, rec=0.102, cos=0.030), tot_loss_proj:3.188 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[1900/2000] tot_loss=1.360 (perp=6.174, rec=0.095, cos=0.030), tot_loss_proj:3.189 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
[1950/2000] tot_loss=1.350 (perp=6.174, rec=0.085, cos=0.030), tot_loss_proj:3.184 [t=0.17s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Attempt swap
[2000/2000] tot_loss=1.354 (perp=6.174, rec=0.089, cos=0.030), tot_loss_proj:3.184 [t=0.20s]
prediction: ['[CLS] of is enough of a problem as she has problem [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] she has enough of a problem as it is. [SEP]
========================
predicted: 
========================
[CLS] of is enough of a problem as she has problem [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 47.619 | p: 45.455 | r: 50.000
rougeL     | fm: 60.870 | p: 58.333 | r: 63.636
rougeLsum  | fm: 60.870 | p: 58.333 | r: 63.636
r1fm+r2fm = 134.576

[Aggregate metrics]:
rouge1     | fm: 78.753 | p: 79.706 | r: 78.165
rouge2     | fm: 37.516 | p: 37.478 | r: 37.770
rougeL     | fm: 67.187 | p: 67.842 | r: 66.736
rougeLsum  | fm: 67.205 | p: 67.874 | r: 66.795
r1fm+r2fm = 116.269

input #42 time: 0:07:05 | total time: 5:01:39


Running input #43 of 100.
reference: 
========================
Every student has to come up with three arguments that show that some condition proposed by Bill is wrong.
========================
Sample: 0 4.101798560240494e-10 0.054252445089160065 0.3741632
average of cosine similarity 0.9894320711149427
highest_index [0]
highest [0.9894320711149427]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[ 101, 2296, 3076, 2038, 2000, 2272, 2039, 2007, 2093, 9918, 2008, 2265,
         2008, 2070, 4650, 3818, 2011, 3021, 2003, 3308, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]']
[Init] best rec loss: 0.941371500492096 for ['[CLS] unaffected peter interval sporting campaign singular relieved start shooting club helleche date operative either meredith occupied lamagee metals [SEP]']
[Init] best rec loss: 0.9361624121665955 for ['[CLS]work beginning refugees accurate ever livesि thesis skirt gran language kingsley scrub regis opera al kin tri all bearing [SEP]']
[Init] best rec loss: 0.9320390224456787 for ['[CLS]nium truck register heart paper whitney subdivision pseudonym dog leapsner reply photon intense border nk blown sri artillery sad [SEP]']
[Init] best rec loss: 0.9182119369506836 for ['[CLS] rule blind third sheen a xu snarl brainific storm median head you gathering mono operational hard patti nba coach [SEP]']
[Init] best rec loss: 0.9167119264602661 for ['[CLS] army duck abolished [MASK]kyumons spokeverse how und purchase joined midstiard beijing breakfastcter after reserve promise [SEP]']
[Init] best rec loss: 0.9060932993888855 for ['[CLS]room tango plumageote along turn smashwords living bill always energy machines threaten glacier formed t patent proik pick [SEP]']
[Init] best rec loss: 0.9036861062049866 for ['[CLS] surprise santa nell games circumstances may enclosed pilot late surf graduation not tuneau date payne oceanrogate big fellow [SEP]']
[Init] best rec loss: 0.8932493925094604 for ['[CLS] awesome entertainment below electricity sage dreamerpressing colliery harvest share color bed titanic rapid were before features titular baymura [SEP]']
[Init] best perm rec loss: 0.8914357423782349 for ['[CLS]pressing colliery titanic were before titularmura color share features entertainment below dreamer awesome bay rapid sage bed electricity harvest [SEP]']
[Init] best perm rec loss: 0.8903899192810059 for ['[CLS] sage entertainmentpressing colliery titanic harvest color awesomemura titular before features bed dreamer electricity below were rapid share bay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.884 (perp=11.963, rec=0.423, cos=0.068), tot_loss_proj:4.241 [t=0.17s]
prediction: ['[CLS] david music serena protest reply islamic its " their rtual greatest most conduct influenced a comedy proposed different treatment [SEP]']
[ 100/2000] tot_loss=2.426 (perp=10.681, rec=0.260, cos=0.029), tot_loss_proj:4.075 [t=0.17s]
prediction: ['[CLS] eric music catfish decisive argument arguments every " every skillual < have bill influenced a plan proposed three issue [SEP]']
[ 150/2000] tot_loss=2.526 (perp=11.321, rec=0.241, cos=0.021), tot_loss_proj:4.178 [t=0.17s]
prediction: ['[CLS] eric music billpromising arguments arguments every up every allual proposed that bill influenced group plan proposed three student [SEP]']
[ 200/2000] tot_loss=2.315 (perp=10.374, rec=0.215, cos=0.026), tot_loss_proj:3.907 [t=0.18s]
prediction: ['[CLS] bill music billpromising arguments condition every up if argument that proposed that student influenced some plan proposed three student [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.242 (perp=10.179, rec=0.184, cos=0.023), tot_loss_proj:3.874 [t=0.18s]
prediction: ['[CLS] billpromising music bill arguments condition every up if argument that proposed that student have some plan some three student [SEP]']
[ 300/2000] tot_loss=2.233 (perp=9.837, rec=0.225, cos=0.040), tot_loss_proj:3.789 [t=0.18s]
prediction: ['[CLS] billpromising music bill arguments condition every up if all that proposed that student by some plan some three student [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.245 (perp=10.239, rec=0.169, cos=0.028), tot_loss_proj:3.925 [t=0.17s]
prediction: ['[CLS] bill wrong music bill every condition arguments up if all that showed that student majority some plan some three student [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.050 (perp=9.415, rec=0.143, cos=0.024), tot_loss_proj:3.750 [t=0.17s]
prediction: ['[CLS] bill arguments music bill every condition wrong up if argument that show that condition by some plan some three student [SEP]']
[ 450/2000] tot_loss=2.064 (perp=9.425, rec=0.153, cos=0.026), tot_loss_proj:3.761 [t=0.17s]
prediction: ['[CLS] bill arguments music bill every condition wrong up or argument that show that condition by some plan some three student [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.926 (perp=8.818, rec=0.140, cos=0.023), tot_loss_proj:3.662 [t=0.17s]
prediction: ['[CLS] bill arguments where bill every condition wrong up. having that show condition has by some plan some three student [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.919 (perp=8.851, rec=0.127, cos=0.022), tot_loss_proj:3.637 [t=0.18s]
prediction: ['[CLS] bill arguments where bill every condition wrong up. must that show condition has by some plan some three student [SEP]']
[ 600/2000] tot_loss=1.972 (perp=9.079, rec=0.133, cos=0.024), tot_loss_proj:3.707 [t=0.18s]
prediction: ['[CLS] bill arguments where bill every condition wrong up. has that show condition has by some plan some three student [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.878 (perp=8.694, rec=0.117, cos=0.022), tot_loss_proj:3.609 [t=0.17s]
prediction: ['[CLS] bill arguments where bill has condition wrong up. every that show condition has by some proposal some three student [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.937 (perp=9.001, rec=0.115, cos=0.021), tot_loss_proj:3.661 [t=0.17s]
prediction: ['[CLS] bill arguments where bill has condition wrong up. every that show condition has by by proposal some three student [SEP]']
[ 750/2000] tot_loss=1.974 (perp=9.212, rec=0.110, cos=0.022), tot_loss_proj:3.713 [t=0.18s]
prediction: ['[CLS] bill arguments where bill has condition wrong up. every that show condition has by by proposed some three student [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.212 (perp=9.796, rec=0.220, cos=0.033), tot_loss_proj:3.781 [t=0.18s]
prediction: ['[CLS] bill arguments music bill has condition wrong up. every that show condition of by proposed by some three student [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.066 (perp=9.191, rec=0.198, cos=0.030), tot_loss_proj:3.612 [t=0.17s]
prediction: ['[CLS] that arguments music bill has condition wrong up. every bill show condition of by proposed by some three student [SEP]']
[ 900/2000] tot_loss=2.038 (perp=9.220, rec=0.166, cos=0.028), tot_loss_proj:3.632 [t=0.17s]
prediction: ['[CLS] that arguments much bill has condition wrong up. every bill show condition of by proposed by some three student [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.243 (perp=10.273, rec=0.161, cos=0.027), tot_loss_proj:3.849 [t=0.18s]
prediction: ['[CLS] thatlish arguments bill has condition wrong up intended every bill show condition of by proposed by some three student [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.110 (perp=9.671, rec=0.149, cos=0.027), tot_loss_proj:3.757 [t=0.18s]
prediction: ['[CLS] thatlish arguments bill has condition wrong up intended every bill show by of condition proposed by some three student [SEP]']
[1050/2000] tot_loss=2.106 (perp=9.671, rec=0.145, cos=0.026), tot_loss_proj:3.757 [t=0.18s]
prediction: ['[CLS] thatlish arguments bill has condition wrong up intended every bill show by of condition proposed by some three student [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.022 (perp=9.291, rec=0.139, cos=0.025), tot_loss_proj:3.692 [t=0.18s]
prediction: ['[CLS] thatlish arguments bill has condition wrong up intended by every bill show of condition proposed by some three student [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.977 (perp=9.026, rec=0.147, cos=0.025), tot_loss_proj:3.689 [t=0.18s]
prediction: ['[CLS] thatlish wrong bill has condition arguments up intended by every bill show of condition proposed by some three student [SEP]']
[1200/2000] tot_loss=1.976 (perp=9.026, rec=0.146, cos=0.025), tot_loss_proj:3.693 [t=0.18s]
prediction: ['[CLS] thatlish wrong bill has condition arguments up intended by every bill show of condition proposed by some three student [SEP]']
Attempt swap
[1250/2000] tot_loss=1.962 (perp=9.026, rec=0.132, cos=0.025), tot_loss_proj:3.689 [t=0.18s]
prediction: ['[CLS] thatlish wrong bill has condition arguments up intended by every bill show of condition proposed by some three student [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.951 (perp=8.926, rec=0.141, cos=0.025), tot_loss_proj:3.619 [t=0.17s]
prediction: ['[CLS] that condition wrong bill haslish arguments up intended by every bill show of condition proposed by some three student [SEP]']
[1350/2000] tot_loss=1.945 (perp=8.926, rec=0.135, cos=0.025), tot_loss_proj:3.611 [t=0.17s]
prediction: ['[CLS] that condition wrong bill haslish arguments up intended by every bill show of condition proposed by some three student [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.869 (perp=8.526, rec=0.140, cos=0.024), tot_loss_proj:3.592 [t=0.18s]
prediction: ['[CLS] that some wrong bill haslish arguments up intended by every bill show of condition proposed by condition three student [SEP]']
Attempt swap
[1450/2000] tot_loss=1.872 (perp=8.526, rec=0.142, cos=0.024), tot_loss_proj:3.595 [t=0.18s]
prediction: ['[CLS] that some wrong bill haslish arguments up intended by every bill show of condition proposed by condition three student [SEP]']
[1500/2000] tot_loss=1.868 (perp=8.526, rec=0.139, cos=0.024), tot_loss_proj:3.593 [t=0.18s]
prediction: ['[CLS] that some wrong bill haslish arguments up intended by every bill show of condition proposed by condition three student [SEP]']
Attempt swap
[1550/2000] tot_loss=1.924 (perp=8.826, rec=0.134, cos=0.024), tot_loss_proj:3.635 [t=0.18s]
prediction: ['[CLS] that some wrong bill haslish arguments up without by every bill show of condition proposed by condition three student [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.854 (perp=8.463, rec=0.136, cos=0.025), tot_loss_proj:3.569 [t=0.18s]
prediction: ['[CLS] that some wrong bill has without arguments uplish by every bill show of condition proposed by condition three student [SEP]']
[1650/2000] tot_loss=1.843 (perp=8.463, rec=0.126, cos=0.024), tot_loss_proj:3.569 [t=0.17s]
prediction: ['[CLS] that some wrong bill has without arguments uplish by every bill show of condition proposed by condition three student [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.742 (perp=7.898, rec=0.139, cos=0.024), tot_loss_proj:3.497 [t=0.18s]
prediction: ['[CLS] that some wrong bill has. arguments uplish by show every bill of condition proposed by condition three student [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.731 (perp=7.840, rec=0.138, cos=0.025), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] that some wrong bill has. arguments uplish show by every bill of condition proposed by condition three student [SEP]']
[1800/2000] tot_loss=1.773 (perp=8.080, rec=0.133, cos=0.024), tot_loss_proj:3.509 [t=0.19s]
prediction: ['[CLS] that some wrong bill has without arguments uplish show by every bill of condition proposed by condition three student [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.770 (perp=8.080, rec=0.129, cos=0.025), tot_loss_proj:3.513 [t=0.19s]
prediction: ['[CLS] that some wrong bill has without arguments uplish show by every bill of condition proposed by condition three student [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.740 (perp=7.889, rec=0.137, cos=0.025), tot_loss_proj:3.462 [t=0.19s]
prediction: ['[CLS] that some wrong bill has without arguments uplish show by every bill of condition proposed by three condition student [SEP]']
[1950/2000] tot_loss=1.735 (perp=7.889, rec=0.133, cos=0.024), tot_loss_proj:3.465 [t=0.19s]
prediction: ['[CLS] that some wrong bill has without arguments uplish show by every bill of condition proposed by three condition student [SEP]']
Attempt swap
[2000/2000] tot_loss=1.727 (perp=7.889, rec=0.125, cos=0.024), tot_loss_proj:3.462 [t=0.18s]
prediction: ['[CLS] that some wrong bill has without arguments uplish show by every bill of condition proposed by three condition student [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]
========================
predicted: 
========================
[CLS] bill arguments where bill has condition wrong up. every that show condition has by by proposed some three student [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 76.190 | r: 76.190
rouge2     | fm: 5.000 | p: 5.000 | r: 5.000
rougeL     | fm: 38.095 | p: 38.095 | r: 38.095
rougeLsum  | fm: 38.095 | p: 38.095 | r: 38.095
r1fm+r2fm = 81.190

[Aggregate metrics]:
rouge1     | fm: 78.667 | p: 79.630 | r: 77.995
rouge2     | fm: 36.930 | p: 36.844 | r: 37.153
rougeL     | fm: 66.368 | p: 67.062 | r: 65.954
rougeLsum  | fm: 66.556 | p: 67.194 | r: 66.139
r1fm+r2fm = 115.597

input #43 time: 0:07:14 | total time: 5:08:53


Running input #44 of 100.
reference: 
========================
Kim alienates cats and beat his dog.
========================
Sample: 0 3.498895157671097e-12 0.053727770688652886 0.36076158
average of cosine similarity 0.988847961923894
highest_index [0]
highest [0.988847961923894]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 5035, 7344, 8520, 8870, 1998, 3786, 2010, 3899, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] kim alienates cats and beat his dog. [SEP]']
[Init] best rec loss: 1.0216113328933716 for ['[CLS] vineyard sterling michigan bat hot boltedpati cannot matter [SEP]']
[Init] best rec loss: 0.9771472215652466 for ['[CLS] jihad much complex marshall deadline [SEP] terminus volume japan [SEP]']
[Init] best rec loss: 0.9380818605422974 for ['[CLS] attempt ll foreign suck off spy gain app promoted [SEP]']
[Init] best rec loss: 0.9156078100204468 for ['[CLS] glacial examlip eat condition von wonder channel junk [SEP]']
[Init] best rec loss: 0.915208637714386 for ['[CLS] cooled best teams stellaxide staffed qualified will roll [SEP]']
[Init] best rec loss: 0.9150818586349487 for ['[CLS] cigarette harvey givensso nurse una rash beautiful inquired [SEP]']
[Init] best rec loss: 0.9134103655815125 for ['[CLS] sir glimpse license faun frame scars principleess [SEP]']
[Init] best rec loss: 0.9127835631370544 for ['[CLS]torewives corps answer bombs organization federation fine bronze [SEP]']
[Init] best rec loss: 0.8829893469810486 for ['[CLS]⁄ lance assigns edmund missouri other. started dan [SEP]']
[Init] best perm rec loss: 0.8820619583129883 for ['[CLS] missouri started edmund dan other lance⁄. assigns [SEP]']
[Init] best perm rec loss: 0.8815537095069885 for ['[CLS] lance dan assigns. other started⁄ edmund missouri [SEP]']
[Init] best perm rec loss: 0.8798965811729431 for ['[CLS] lance started edmund.⁄ other missouri assigns dan [SEP]']
[Init] best perm rec loss: 0.8791020512580872 for ['[CLS]⁄ lance edmund. assigns other started missouri dan [SEP]']
[Init] best perm rec loss: 0.8787437081336975 for ['[CLS] other lance. started missouri assigns edmund⁄ dan [SEP]']
[Init] best perm rec loss: 0.8781583905220032 for ['[CLS] dan lance edmund missouri other started. assigns⁄ [SEP]']
[Init] best perm rec loss: 0.8779261112213135 for ['[CLS] assigns lance. started⁄ other dan edmund missouri [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.015 (perp=12.175, rec=0.632, cos=0.948), tot_loss_proj:4.383 [t=0.17s]
prediction: ['[CLS] ; bad seen come mac天 beat alice smoking [SEP]']
[ 100/2000] tot_loss=3.906 (perp=12.130, rec=0.525, cos=0.955), tot_loss_proj:4.422 [t=0.17s]
prediction: ['[CLS] especially dog. uncleistles cyclone beat jess beat [SEP]']
[ 150/2000] tot_loss=3.757 (perp=11.816, rec=0.457, cos=0.936), tot_loss_proj:4.321 [t=0.17s]
prediction: ['[CLS] although dog. uncleistles cyclone beat kim beat [SEP]']
[ 200/2000] tot_loss=4.049 (perp=13.427, rec=0.430, cos=0.933), tot_loss_proj:4.657 [t=0.17s]
prediction: ['[CLS]jit dog.rence cats cyclone beat kim beat [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.919 (perp=12.463, rec=0.491, cos=0.935), tot_loss_proj:4.444 [t=0.17s]
prediction: ['[CLS] ª dog theoremausen.ɴ beat mom beat [SEP]']
[ 300/2000] tot_loss=3.760 (perp=12.048, rec=0.418, cos=0.932), tot_loss_proj:4.374 [t=0.17s]
prediction: ['[CLS] acronym dog dogphate. churches beat kim beat [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=3.751 (perp=12.006, rec=0.420, cos=0.930), tot_loss_proj:4.363 [t=0.17s]
prediction: ['[CLS] instruments beat kim beat ¬ dog dogishlyenham [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.264 (perp=9.704, rec=0.403, cos=0.920), tot_loss_proj:3.878 [t=0.17s]
prediction: ['[CLS] kim beat instruments beat sevens dog dogishly. [SEP]']
[ 450/2000] tot_loss=3.674 (perp=11.898, rec=0.377, cos=0.918), tot_loss_proj:4.347 [t=0.17s]
prediction: ['[CLS] kim beat instruments beatlynn dog objectsishly. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.453 (perp=10.820, rec=0.374, cos=0.915), tot_loss_proj:4.095 [t=0.17s]
prediction: ['[CLS] kim beat instruments beatː dograined objects. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.415 (perp=10.635, rec=0.378, cos=0.911), tot_loss_proj:4.028 [t=0.17s]
prediction: ['[CLS] kim beat instruments beat dogːrained objects. [SEP]']
[ 600/2000] tot_loss=3.389 (perp=10.635, rec=0.353, cos=0.909), tot_loss_proj:4.026 [t=0.17s]
prediction: ['[CLS] kim beat instruments beat dogːrained objects. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.264 (perp=10.059, rec=0.349, cos=0.903), tot_loss_proj:3.977 [t=0.17s]
prediction: ['[CLS] kimː instruments beat dog beatrained objects. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.192 (perp=9.708, rec=0.349, cos=0.902), tot_loss_proj:3.894 [t=0.17s]
prediction: ['[CLS] kim spaceship instruments beat dog beatrained objects. [SEP]']
[ 750/2000] tot_loss=3.135 (perp=9.427, rec=0.348, cos=0.902), tot_loss_proj:3.860 [t=0.17s]
prediction: ['[CLS] kim spaceship updates beat dog beatrained objects. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.339 (perp=10.497, rec=0.341, cos=0.898), tot_loss_proj:4.051 [t=0.17s]
prediction: ['[CLS] kim spaceship updates beat dog beatrainedizes. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.358 (perp=10.482, rec=0.358, cos=0.903), tot_loss_proj:4.065 [t=0.17s]
prediction: ['[CLS] kimি things beat dog beat insectizes. [SEP]']
[ 900/2000] tot_loss=3.331 (perp=10.482, rec=0.337, cos=0.897), tot_loss_proj:4.062 [t=0.17s]
prediction: ['[CLS] kimি things beat dog beat insectizes. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.177 (perp=9.760, rec=0.328, cos=0.896), tot_loss_proj:3.895 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog beat insect things. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.185 (perp=9.760, rec=0.336, cos=0.897), tot_loss_proj:3.891 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog beat insect things. [SEP]']
[1050/2000] tot_loss=3.247 (perp=10.088, rec=0.333, cos=0.896), tot_loss_proj:3.959 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog beat insect anything. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.468 (perp=11.203, rec=0.331, cos=0.896), tot_loss_proj:4.179 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog beat updates insect. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.642 (perp=12.048, rec=0.340, cos=0.893), tot_loss_proj:4.397 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog beat blouse insect updates [SEP]']
[1200/2000] tot_loss=3.543 (perp=11.608, rec=0.329, cos=0.893), tot_loss_proj:4.265 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog beatorted insect updates [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=3.645 (perp=12.139, rec=0.325, cos=0.892), tot_loss_proj:4.404 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog blouse beat insect anything [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=3.530 (perp=11.540, rec=0.334, cos=0.888), tot_loss_proj:4.224 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog blouse beat anything insect [SEP]']
[1350/2000] tot_loss=3.284 (perp=10.294, rec=0.333, cos=0.893), tot_loss_proj:3.989 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog. beat anything insect [SEP]']
Attempt swap
[1400/2000] tot_loss=3.529 (perp=11.543, rec=0.328, cos=0.892), tot_loss_proj:4.219 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog.ates anything insect [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=3.727 (perp=12.517, rec=0.335, cos=0.889), tot_loss_proj:4.422 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog insectates anythingcle [SEP]']
[1500/2000] tot_loss=3.727 (perp=12.517, rec=0.334, cos=0.889), tot_loss_proj:4.421 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog insectates anythingcle [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=3.648 (perp=12.151, rec=0.328, cos=0.890), tot_loss_proj:4.352 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog blouse insectates anything [SEP]']
Attempt swap
[1600/2000] tot_loss=3.438 (perp=11.152, rec=0.320, cos=0.888), tot_loss_proj:4.146 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog. insectates anything [SEP]']
[1650/2000] tot_loss=3.444 (perp=11.152, rec=0.326, cos=0.888), tot_loss_proj:4.147 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog. insectates anything [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=3.346 (perp=10.672, rec=0.323, cos=0.889), tot_loss_proj:4.064 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog. anything insectates [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=3.257 (perp=10.224, rec=0.327, cos=0.885), tot_loss_proj:3.952 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog anything insectates. [SEP]']
[1800/2000] tot_loss=3.251 (perp=10.224, rec=0.322, cos=0.885), tot_loss_proj:3.952 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog anything insectates. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.245 (perp=10.224, rec=0.315, cos=0.885), tot_loss_proj:3.952 [t=0.17s]
prediction: ['[CLS] kimিizes beat dog anything insectates. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=3.249 (perp=10.153, rec=0.328, cos=0.890), tot_loss_proj:3.966 [t=0.17s]
prediction: ['[CLS] kimিizes beat anything dog insectates. [SEP]']
[1950/2000] tot_loss=3.243 (perp=10.153, rec=0.323, cos=0.889), tot_loss_proj:3.969 [t=0.17s]
prediction: ['[CLS] kimিizes beat anything dog insectates. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.252 (perp=10.153, rec=0.333, cos=0.889), tot_loss_proj:3.965 [t=0.17s]
prediction: ['[CLS] kimিizes beat anything dog insectates. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] kim alienates cats and beat his dog. [SEP]
========================
predicted: 
========================
[CLS] kimিizes beat dog.ates anything insect [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.556 | p: 55.556 | r: 55.556
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 68.056

[Aggregate metrics]:
rouge1     | fm: 78.186 | p: 79.001 | r: 77.666
rouge2     | fm: 36.237 | p: 36.216 | r: 36.482
rougeL     | fm: 66.184 | p: 66.840 | r: 65.875
rougeLsum  | fm: 66.269 | p: 66.824 | r: 65.890
r1fm+r2fm = 114.424

input #44 time: 0:07:00 | total time: 5:15:54


Running input #45 of 100.
reference: 
========================
John's I stole bike.
========================
Sample: 0 1.0530487425456805e-12 0.04681299116707997 0.35503352
average of cosine similarity 0.9912689873533194
highest_index [0]
highest [0.9912689873533194]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2198,  1005,  1055,  1045, 10312,  7997,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] john's i stole bike. [SEP]"]
[Init] best rec loss: 0.9623914957046509 for ['[CLS] outskirts came too yourtered occupy tradition [SEP]']
[Init] best rec loss: 0.890116274356842 for ['[CLS] and general driving weak [SEP]akcede [SEP]']
[Init] best rec loss: 0.7756944298744202 for ['[CLS] video date prime tall lifeless grape person [SEP]']
[Init] best rec loss: 0.7738812565803528 for ['[CLS] orbit editor ring spread using jones yugoslav [SEP]']
[Init] best rec loss: 0.7658082246780396 for ['[CLS] expecting special scaleslock mhz wish ser [SEP]']
[Init] best rec loss: 0.7612343430519104 for ['[CLS] evening lose high design bankrupt caucus landscape [SEP]']
[Init] best rec loss: 0.7316742539405823 for ['[CLS] hadn quite about sit exit rugby mc [SEP]']
[Init] best perm rec loss: 0.7308976054191589 for ['[CLS] rugby mc about sit hadn quite exit [SEP]']
[Init] best perm rec loss: 0.7300025820732117 for ['[CLS] exit hadn rugby sit quite about mc [SEP]']
[Init] best perm rec loss: 0.7252820134162903 for ['[CLS] quite hadn about rugby exit mc sit [SEP]']
[Init] best perm rec loss: 0.722222626209259 for ['[CLS] exit about quite mc sit hadn rugby [SEP]']
[Init] best perm rec loss: 0.7214416265487671 for ['[CLS] sit rugby exit hadn quite about mc [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.347 (perp=10.088, rec=0.304, cos=0.026), tot_loss_proj:3.289 [t=0.17s]
prediction: ['[CLS] was father snakes bike killed bike. [SEP]']
[ 100/2000] tot_loss=2.157 (perp=9.559, rec=0.223, cos=0.022), tot_loss_proj:2.492 [t=0.17s]
prediction: ['[CLS] i patrick s bike stole bike. [SEP]']
[ 150/2000] tot_loss=2.025 (perp=8.992, rec=0.205, cos=0.021), tot_loss_proj:2.757 [t=0.17s]
prediction: ['[CLS] i john s bike stole bike. [SEP]']
[ 200/2000] tot_loss=2.140 (perp=8.992, rec=0.318, cos=0.023), tot_loss_proj:2.964 [t=0.17s]
prediction: ['[CLS] i john s bike stole bike. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.811 (perp=8.009, rec=0.188, cos=0.021), tot_loss_proj:2.413 [t=0.17s]
prediction: ['[CLS] john i s john stole bike. [SEP]']
[ 300/2000] tot_loss=1.764 (perp=8.009, rec=0.142, cos=0.020), tot_loss_proj:2.562 [t=0.17s]
prediction: ['[CLS] john i s john stole bike. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.738 (perp=8.009, rec=0.117, cos=0.020), tot_loss_proj:2.578 [t=0.17s]
prediction: ['[CLS] john i s john stole bike. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.724 (perp=8.009, rec=0.103, cos=0.019), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] john i s john stole bike. [SEP]']
[ 450/2000] tot_loss=1.823 (perp=8.009, rec=0.200, cos=0.021), tot_loss_proj:2.555 [t=0.17s]
prediction: ['[CLS] john i s john stole bike. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.735 (perp=8.009, rec=0.113, cos=0.020), tot_loss_proj:2.538 [t=0.17s]
prediction: ['[CLS] john i s john stole bike. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.746 (perp=8.009, rec=0.126, cos=0.018), tot_loss_proj:2.562 [t=0.17s]
prediction: ['[CLS] john i s john stole bike. [SEP]']
[ 600/2000] tot_loss=1.714 (perp=8.009, rec=0.094, cos=0.019), tot_loss_proj:2.599 [t=0.17s]
prediction: ['[CLS] john i s john stole bike. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.714 (perp=8.009, rec=0.092, cos=0.020), tot_loss_proj:2.612 [t=0.17s]
prediction: ['[CLS] john i s john stole bike. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.529 (perp=6.819, rec=0.146, cos=0.019), tot_loss_proj:2.449 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
[ 750/2000] tot_loss=1.472 (perp=6.819, rec=0.089, cos=0.020), tot_loss_proj:2.479 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.468 (perp=6.819, rec=0.085, cos=0.019), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.470 (perp=6.819, rec=0.087, cos=0.019), tot_loss_proj:2.479 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
[ 900/2000] tot_loss=1.480 (perp=6.819, rec=0.096, cos=0.020), tot_loss_proj:2.453 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.465 (perp=6.819, rec=0.082, cos=0.019), tot_loss_proj:2.460 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.467 (perp=6.819, rec=0.084, cos=0.019), tot_loss_proj:2.466 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
[1050/2000] tot_loss=1.471 (perp=6.819, rec=0.088, cos=0.019), tot_loss_proj:2.463 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.458 (perp=6.819, rec=0.075, cos=0.019), tot_loss_proj:2.459 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.459 (perp=6.819, rec=0.076, cos=0.019), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
[1200/2000] tot_loss=1.470 (perp=6.819, rec=0.088, cos=0.019), tot_loss_proj:2.462 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.452 (perp=6.819, rec=0.069, cos=0.019), tot_loss_proj:2.466 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.455 (perp=6.819, rec=0.072, cos=0.019), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
[1350/2000] tot_loss=1.457 (perp=6.819, rec=0.075, cos=0.019), tot_loss_proj:2.462 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.460 (perp=6.819, rec=0.078, cos=0.019), tot_loss_proj:2.459 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.455 (perp=6.819, rec=0.072, cos=0.019), tot_loss_proj:2.453 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
[1500/2000] tot_loss=1.462 (perp=6.819, rec=0.079, cos=0.019), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.459 (perp=6.819, rec=0.076, cos=0.019), tot_loss_proj:2.453 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.460 (perp=6.819, rec=0.077, cos=0.019), tot_loss_proj:2.453 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
[1650/2000] tot_loss=1.451 (perp=6.819, rec=0.068, cos=0.019), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.453 (perp=6.819, rec=0.070, cos=0.019), tot_loss_proj:2.457 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.459 (perp=6.819, rec=0.076, cos=0.019), tot_loss_proj:2.454 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
[1800/2000] tot_loss=1.467 (perp=6.819, rec=0.084, cos=0.019), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.456 (perp=6.819, rec=0.074, cos=0.019), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.457 (perp=6.819, rec=0.074, cos=0.019), tot_loss_proj:2.448 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
[1950/2000] tot_loss=1.457 (perp=6.819, rec=0.075, cos=0.019), tot_loss_proj:2.454 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.453 (perp=6.819, rec=0.070, cos=0.019), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS] i s john i stole bike. [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] john's i stole bike. [SEP]
========================
predicted: 
========================
[CLS] i s john i stole bike. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 46.154 | p: 42.857 | r: 50.000
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 139.487

[Aggregate metrics]:
rouge1     | fm: 78.411 | p: 79.196 | r: 78.099
rouge2     | fm: 36.506 | p: 36.296 | r: 36.844
rougeL     | fm: 66.644 | p: 67.107 | r: 66.361
rougeLsum  | fm: 66.671 | p: 67.122 | r: 66.412
r1fm+r2fm = 114.917

input #45 time: 0:06:58 | total time: 5:22:53


Running input #46 of 100.
reference: 
========================
The witch went into the forest by vanishing.
========================
Sample: 0 1.5027161397941455e-12 0.04750979540623304 0.3417578
average of cosine similarity 0.9902901420636567
highest_index [0]
highest [0.9902901420636567]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1996,  6965,  2253,  2046,  1996,  3224,  2011, 24866,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] the witch went into the forest by vanishing. [SEP]']
[Init] best rec loss: 0.7126263380050659 for ['[CLS] tripume mackenzie enterprise crunch threshold engine free down [SEP]']
[Init] best rec loss: 0.7099688053131104 for ['[CLS] terms masters nightingale appeared calling tropical has brant returns [SEP]']
[Init] best rec loss: 0.7057819366455078 for ['[CLS] gear rest roninpment s members university evenly matthew [SEP]']
[Init] best rec loss: 0.7033528685569763 for ['[CLS] hell advent shared moderatenton drivendity kennedyided [SEP]']
[Init] best rec loss: 0.698776125907898 for ['[CLS] suffix joe clay just crewmun warn cycle flows [SEP]']
[Init] best rec loss: 0.6938488483428955 for ['[CLS]led feed noah hung baydding blog house gate [SEP]']
[Init] best rec loss: 0.6714576482772827 for ['[CLS] ink loss yet volvo remaining fine manor sa glacier [SEP]']
[Init] best perm rec loss: 0.6680058240890503 for ['[CLS] ink volvo manor yet glacier fine remaining loss sa [SEP]']
[Init] best perm rec loss: 0.667153000831604 for ['[CLS] glacier yet remaining loss volvo ink sa manor fine [SEP]']
[Init] best perm rec loss: 0.6671254634857178 for ['[CLS] manor remaining fine loss ink yet sa volvo glacier [SEP]']
[Init] best perm rec loss: 0.6665775179862976 for ['[CLS] fine loss manor ink sa glacier remaining volvo yet [SEP]']
[Init] best perm rec loss: 0.6625388860702515 for ['[CLS] glacier remaining ink fine manor loss sa volvo yet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.128 (perp=12.739, rec=0.469, cos=0.111), tot_loss_proj:3.560 [t=0.17s]
prediction: ['[CLS] healer jews association use isn. killed working bankruptcy [SEP]']
[ 100/2000] tot_loss=2.723 (perp=12.137, rec=0.244, cos=0.052), tot_loss_proj:3.527 [t=0.17s]
prediction: ['[CLS] healer witchness off the by by vanishing vanishing [SEP]']
[ 150/2000] tot_loss=2.425 (perp=11.109, rec=0.167, cos=0.037), tot_loss_proj:3.216 [t=0.17s]
prediction: ['[CLS] forest witch forest visited the by by vanishing vanishing [SEP]']
[ 200/2000] tot_loss=2.454 (perp=11.451, rec=0.136, cos=0.028), tot_loss_proj:3.107 [t=0.17s]
prediction: ['[CLS] forest witch witch went the by by vanishing vanishing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.092 (perp=9.762, rec=0.109, cos=0.031), tot_loss_proj:2.606 [t=0.17s]
prediction: ['[CLS] the witch witch went forest by by vanishing vanishing [SEP]']
[ 300/2000] tot_loss=2.080 (perp=9.762, rec=0.100, cos=0.028), tot_loss_proj:2.595 [t=0.17s]
prediction: ['[CLS] the witch witch went forest by by vanishing vanishing [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.056 (perp=9.626, rec=0.106, cos=0.026), tot_loss_proj:2.538 [t=0.17s]
prediction: ['[CLS] the the witch went forest by by vanishing vanishing [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.062 (perp=8.613, rec=0.252, cos=0.087), tot_loss_proj:2.414 [t=0.20s]
prediction: ['[CLS] the the witch went forest by vanishing by vanishing [SEP]']
[ 450/2000] tot_loss=1.889 (perp=8.613, rec=0.132, cos=0.034), tot_loss_proj:2.892 [t=0.19s]
prediction: ['[CLS] the the witch went forest by vanishing by vanishing [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.814 (perp=8.326, rec=0.117, cos=0.031), tot_loss_proj:2.939 [t=0.17s]
prediction: ['[CLS] the forest the witch went by vanishing by vanishing [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.796 (perp=8.242, rec=0.119, cos=0.028), tot_loss_proj:2.603 [t=0.17s]
prediction: ['[CLS] the forest by the witch went vanishing by vanishing [SEP]']
[ 600/2000] tot_loss=1.772 (perp=8.242, rec=0.096, cos=0.028), tot_loss_proj:2.592 [t=0.17s]
prediction: ['[CLS] the forest by the witch went vanishing by vanishing [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.134 (perp=10.109, rec=0.085, cos=0.027), tot_loss_proj:3.018 [t=0.17s]
prediction: ['[CLS] the forest by into witch went vanishing by vanishing [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.886 (perp=8.803, rec=0.099, cos=0.027), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS] the forest went by into witch vanishing by vanishing [SEP]']
[ 750/2000] tot_loss=1.885 (perp=8.803, rec=0.099, cos=0.025), tot_loss_proj:2.454 [t=0.17s]
prediction: ['[CLS] the forest went by into witch vanishing by vanishing [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.807 (perp=8.408, rec=0.101, cos=0.025), tot_loss_proj:2.297 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.798 (perp=8.408, rec=0.092, cos=0.024), tot_loss_proj:2.295 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
[ 900/2000] tot_loss=1.806 (perp=8.408, rec=0.101, cos=0.024), tot_loss_proj:2.300 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.789 (perp=8.408, rec=0.083, cos=0.024), tot_loss_proj:2.297 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1000/2000] tot_loss=1.793 (perp=8.408, rec=0.088, cos=0.024), tot_loss_proj:2.300 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
[1050/2000] tot_loss=1.794 (perp=8.408, rec=0.088, cos=0.024), tot_loss_proj:2.306 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1100/2000] tot_loss=1.795 (perp=8.408, rec=0.090, cos=0.023), tot_loss_proj:2.300 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1150/2000] tot_loss=1.787 (perp=8.408, rec=0.082, cos=0.023), tot_loss_proj:2.295 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
[1200/2000] tot_loss=1.789 (perp=8.408, rec=0.084, cos=0.023), tot_loss_proj:2.306 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1250/2000] tot_loss=1.796 (perp=8.408, rec=0.092, cos=0.023), tot_loss_proj:2.298 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1300/2000] tot_loss=1.804 (perp=8.408, rec=0.099, cos=0.023), tot_loss_proj:2.298 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
[1350/2000] tot_loss=1.796 (perp=8.408, rec=0.092, cos=0.023), tot_loss_proj:2.300 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1400/2000] tot_loss=1.786 (perp=8.408, rec=0.082, cos=0.023), tot_loss_proj:2.292 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1450/2000] tot_loss=1.784 (perp=8.408, rec=0.079, cos=0.023), tot_loss_proj:2.296 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
[1500/2000] tot_loss=1.785 (perp=8.408, rec=0.080, cos=0.023), tot_loss_proj:2.297 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1550/2000] tot_loss=1.775 (perp=8.408, rec=0.071, cos=0.023), tot_loss_proj:2.289 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1600/2000] tot_loss=1.790 (perp=8.408, rec=0.086, cos=0.023), tot_loss_proj:2.301 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
[1650/2000] tot_loss=1.785 (perp=8.408, rec=0.081, cos=0.023), tot_loss_proj:2.292 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1700/2000] tot_loss=1.793 (perp=8.408, rec=0.089, cos=0.023), tot_loss_proj:2.298 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1750/2000] tot_loss=1.783 (perp=8.408, rec=0.078, cos=0.023), tot_loss_proj:2.288 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
[1800/2000] tot_loss=1.788 (perp=8.408, rec=0.084, cos=0.023), tot_loss_proj:2.304 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1850/2000] tot_loss=1.781 (perp=8.408, rec=0.077, cos=0.023), tot_loss_proj:2.289 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[1900/2000] tot_loss=1.777 (perp=8.408, rec=0.073, cos=0.023), tot_loss_proj:2.287 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
[1950/2000] tot_loss=1.783 (perp=8.408, rec=0.078, cos=0.023), tot_loss_proj:2.298 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Attempt swap
[2000/2000] tot_loss=1.777 (perp=8.408, rec=0.073, cos=0.023), tot_loss_proj:2.295 [t=0.17s]
prediction: ['[CLS] the forest went into witch by vanishing by vanishing [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] the witch went into the forest by vanishing. [SEP]
========================
predicted: 
========================
[CLS] the forest went into witch by vanishing by vanishing [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 52.632 | p: 50.000 | r: 55.556
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 138.346

[Aggregate metrics]:
rouge1     | fm: 78.762 | p: 79.345 | r: 78.478
rouge2     | fm: 36.967 | p: 36.669 | r: 37.290
rougeL     | fm: 66.508 | p: 66.963 | r: 66.290
rougeLsum  | fm: 66.590 | p: 67.025 | r: 66.460
r1fm+r2fm = 115.730

input #46 time: 0:06:57 | total time: 5:29:50


Running input #47 of 100.
reference: 
========================
Mary noticed John's excessive appreciation of himself.
========================
Sample: 0 2.0911676619380496e-12 0.052809693472476535 0.34555757
average of cosine similarity 0.9882533164750726
highest_index [0]
highest [0.9882533164750726]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2984,  4384,  2198,  1005,  1055, 11664, 12284,  1997,  2370,
          1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] mary noticed john's excessive appreciation of himself. [SEP]"]
[Init] best rec loss: 0.9377633929252625 for ['[CLS] negotiationsris deemedtment prohibition wine holdingyn divorced within [SEP]']
[Init] best rec loss: 0.9331151247024536 for ['[CLS] apart nearly twinotho point onceient overcome beck hong [SEP]']
[Init] best rec loss: 0.924275815486908 for ['[CLS] less pain enters silk mktiv doesn thighs replde [SEP]']
[Init] best rec loss: 0.8977593183517456 for ['[CLS] accompanying moss advent visitedsit corbin pas grade convictedbacks [SEP]']
[Init] best rec loss: 0.8822109699249268 for ['[CLS] december hit leisure journey none sinclair ras chaos whereby burke [SEP]']
[Init] best rec loss: 0.8803945779800415 for ['[CLS]care di sarperson zach original participantsllis " direct [SEP]']
[Init] best rec loss: 0.8778656721115112 for ['[CLS] po 2006 contention sort nameorestation were say dressed caps [SEP]']
[Init] best rec loss: 0.8622311353683472 for ['[CLS] general letting springs engineer large especially together cost tracing framework [SEP]']
[Init] best perm rec loss: 0.856625497341156 for ['[CLS] engineer together letting large general tracing springs framework especially cost [SEP]']
[Init] best perm rec loss: 0.8556800484657288 for ['[CLS] framework together large tracing springs general especially engineer letting cost [SEP]']
[Init] best perm rec loss: 0.8556457161903381 for ['[CLS] tracing large framework cost general together springs especially letting engineer [SEP]']
[Init] best perm rec loss: 0.854211688041687 for ['[CLS] engineer cost framework large general especially together tracing letting springs [SEP]']
[Init] best perm rec loss: 0.8541837334632874 for ['[CLS] engineer springs together especially tracing large general framework cost letting [SEP]']
[Init] best perm rec loss: 0.8541443347930908 for ['[CLS] engineer large tracing springs cost especially letting framework together general [SEP]']
[Init] best perm rec loss: 0.850818932056427 for ['[CLS] springs cost tracing together large especially engineer letting general framework [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.870 (perp=11.573, rec=0.560, cos=0.996), tot_loss_proj:4.253 [t=0.17s]
prediction: ['[CLS]., education capped says operative levi noticed hintsـ [SEP]']
[ 100/2000] tot_loss=3.888 (perp=12.055, rec=0.484, cos=0.993), tot_loss_proj:4.321 [t=0.17s]
prediction: ["[CLS].'islamic organizationaleering excessive appreciation noticed laying bubble [SEP]"]
[ 150/2000] tot_loss=3.942 (perp=12.483, rec=0.453, cos=0.993), tot_loss_proj:4.415 [t=0.17s]
prediction: ['[CLS]. & treatment buttons ebook excessive appreciation noticed leather centimetres [SEP]']
[ 200/2000] tot_loss=3.791 (perp=11.824, rec=0.436, cos=0.990), tot_loss_proj:4.293 [t=0.17s]
prediction: ['[CLS]. mary lifestyle buttons his excessive appreciation noticed storage renaissance [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=4.362 (perp=14.754, rec=0.429, cos=0.982), tot_loss_proj:4.817 [t=0.17s]
prediction: ['[CLS] endemic mary islamic.nction excessive appreciation noticed storagelike [SEP]']
[ 300/2000] tot_loss=3.416 (perp=10.097, rec=0.414, cos=0.982), tot_loss_proj:3.921 [t=0.17s]
prediction: ['[CLS]ᆫ mary lifestyle. his excessive appreciation noticed storage. [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.642 (perp=11.340, rec=0.397, cos=0.977), tot_loss_proj:4.114 [t=0.17s]
prediction: ['[CLS]ᆫ mary lifestyle.cter excessive appreciation noticed greatly. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.916 (perp=12.716, rec=0.402, cos=0.971), tot_loss_proj:4.475 [t=0.17s]
prediction: ['[CLS]ᆫ marycter. lifestyle excessive appreciation noticed storage appreciation [SEP]']
[ 450/2000] tot_loss=3.808 (perp=12.305, rec=0.382, cos=0.965), tot_loss_proj:4.325 [t=0.17s]
prediction: ['[CLS] excessive marycter. manuscript excessive appreciation noticed jess appreciation [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.569 (perp=11.156, rec=0.378, cos=0.960), tot_loss_proj:4.154 [t=0.17s]
prediction: ['[CLS] jess marycter.ø excessive appreciation noticed excessive appreciation [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.854 (perp=12.604, rec=0.374, cos=0.959), tot_loss_proj:4.372 [t=0.17s]
prediction: ['[CLS] many marycter.ø excessive appreciation noticed excessive appreciation [SEP]']
[ 600/2000] tot_loss=3.847 (perp=12.604, rec=0.368, cos=0.958), tot_loss_proj:4.373 [t=0.17s]
prediction: ['[CLS] many marycter.ø excessive appreciation noticed excessive appreciation [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.664 (perp=11.656, rec=0.415, cos=0.917), tot_loss_proj:4.221 [t=0.17s]
prediction: ['[CLS]cter mary delilah. affection excessive appreciation noticed excessive appreciation [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.509 (perp=11.029, rec=0.394, cos=0.909), tot_loss_proj:4.118 [t=0.17s]
prediction: ['[CLS]cter mary affection delilah ; excessive appreciation noticed excessive appreciation [SEP]']
[ 750/2000] tot_loss=3.493 (perp=11.029, rec=0.375, cos=0.912), tot_loss_proj:4.122 [t=0.17s]
prediction: ['[CLS]cter mary affection delilah ; excessive appreciation noticed excessive appreciation [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.485 (perp=11.029, rec=0.368, cos=0.911), tot_loss_proj:4.125 [t=0.17s]
prediction: ['[CLS]cter mary affection delilah ; excessive appreciation noticed excessive appreciation [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.557 (perp=11.425, rec=0.362, cos=0.909), tot_loss_proj:4.098 [t=0.17s]
prediction: ['[CLS]cter mary certainly delilah of excessive appreciation noticed excessive appreciation [SEP]']
[ 900/2000] tot_loss=3.622 (perp=11.730, rec=0.369, cos=0.908), tot_loss_proj:4.214 [t=0.17s]
prediction: ['[CLS]cter mary certainly jess of excessive appreciation noticed excessive appreciation [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=3.660 (perp=11.989, rec=0.360, cos=0.902), tot_loss_proj:4.277 [t=0.17s]
prediction: ['[CLS]cter mary jess of certainly excessive appreciation noticed hector appreciation [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.586 (perp=11.622, rec=0.361, cos=0.901), tot_loss_proj:4.229 [t=0.17s]
prediction: ['[CLS]cter mary jess of certainly excessive appreciation hector noticed appreciation [SEP]']
[1050/2000] tot_loss=3.573 (perp=11.622, rec=0.355, cos=0.893), tot_loss_proj:4.228 [t=0.17s]
prediction: ['[CLS]cter mary jess of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1100/2000] tot_loss=3.567 (perp=11.622, rec=0.354, cos=0.889), tot_loss_proj:4.233 [t=0.17s]
prediction: ['[CLS]cter mary jess of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1150/2000] tot_loss=3.567 (perp=11.622, rec=0.358, cos=0.884), tot_loss_proj:4.226 [t=0.17s]
prediction: ['[CLS]cter mary jess of certainly excessive appreciation hector noticed appreciation [SEP]']
[1200/2000] tot_loss=3.443 (perp=11.084, rec=0.347, cos=0.879), tot_loss_proj:4.092 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1250/2000] tot_loss=3.441 (perp=11.084, rec=0.351, cos=0.874), tot_loss_proj:4.091 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1300/2000] tot_loss=3.443 (perp=11.084, rec=0.357, cos=0.869), tot_loss_proj:4.096 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
[1350/2000] tot_loss=3.426 (perp=11.084, rec=0.345, cos=0.865), tot_loss_proj:4.093 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1400/2000] tot_loss=3.424 (perp=11.084, rec=0.348, cos=0.859), tot_loss_proj:4.089 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1450/2000] tot_loss=3.411 (perp=11.084, rec=0.339, cos=0.855), tot_loss_proj:4.096 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
[1500/2000] tot_loss=3.405 (perp=11.084, rec=0.338, cos=0.850), tot_loss_proj:4.090 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1550/2000] tot_loss=3.403 (perp=11.084, rec=0.341, cos=0.845), tot_loss_proj:4.092 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1600/2000] tot_loss=3.400 (perp=11.084, rec=0.342, cos=0.841), tot_loss_proj:4.097 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
[1650/2000] tot_loss=3.402 (perp=11.084, rec=0.349, cos=0.835), tot_loss_proj:4.091 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1700/2000] tot_loss=3.392 (perp=11.084, rec=0.344, cos=0.832), tot_loss_proj:4.097 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1750/2000] tot_loss=3.381 (perp=11.084, rec=0.337, cos=0.827), tot_loss_proj:4.087 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
[1800/2000] tot_loss=3.381 (perp=11.084, rec=0.342, cos=0.822), tot_loss_proj:4.091 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1850/2000] tot_loss=3.383 (perp=11.084, rec=0.348, cos=0.818), tot_loss_proj:4.098 [t=0.17s]
prediction: ['[CLS] loudly mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[1900/2000] tot_loss=3.518 (perp=11.805, rec=0.344, cos=0.813), tot_loss_proj:4.273 [t=0.17s]
prediction: ['[CLS]rned mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
[1950/2000] tot_loss=3.514 (perp=11.805, rec=0.343, cos=0.809), tot_loss_proj:4.275 [t=0.17s]
prediction: ['[CLS]rned mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Attempt swap
[2000/2000] tot_loss=3.509 (perp=11.805, rec=0.343, cos=0.805), tot_loss_proj:4.271 [t=0.17s]
prediction: ['[CLS]rned mary martha of certainly excessive appreciation hector noticed appreciation [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] mary noticed john's excessive appreciation of himself. [SEP]
========================
predicted: 
========================
[CLS]rned mary martha of certainly excessive appreciation hector noticed appreciation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.636 | p: 58.333 | r: 70.000
rouge2     | fm: 10.000 | p: 9.091 | r: 11.111
rougeL     | fm: 45.455 | p: 41.667 | r: 50.000
rougeLsum  | fm: 45.455 | p: 41.667 | r: 50.000
r1fm+r2fm = 73.636

[Aggregate metrics]:
rouge1     | fm: 78.296 | p: 78.768 | r: 78.142
rouge2     | fm: 36.289 | p: 36.062 | r: 36.659
rougeL     | fm: 66.081 | p: 66.446 | r: 65.939
rougeLsum  | fm: 66.166 | p: 66.571 | r: 66.050
r1fm+r2fm = 114.586

input #47 time: 0:06:55 | total time: 5:36:46


Running input #48 of 100.
reference: 
========================
John tagged Lewis with a regulation baseball on Tuesday.
========================
Sample: 0 1.2262200909446048e-11 0.051985932312923894 0.341237
average of cosine similarity 0.9883273450394022
highest_index [0]
highest [0.9883273450394022]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198, 26610,  4572,  2007,  1037,  7816,  3598,  2006,  9857,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]']
[Init] best rec loss: 1.0071521997451782 for ['[CLS]... spit opening tolerant lie officer 3rd wiener true li [SEP]']
[Init] best rec loss: 0.9635554552078247 for ['[CLS] stunt exclusively since bear toss temple calings whispers claimed [SEP]']
[Init] best rec loss: 0.9312321543693542 for ['[CLS]tative fc matched thorough kay responsible backward pali vera its [SEP]']
[Init] best rec loss: 0.9218538403511047 for ['[CLS] pride grams base telling ramstters shame olive stonerah [SEP]']
[Init] best rec loss: 0.9126393795013428 for ['[CLS] fine screened reference [SEP] industry brick liver fleetwr south [SEP]']
[Init] best perm rec loss: 0.9066827297210693 for ['[CLS]wr screened south fleet brick liver fine reference industry [SEP] [SEP]']
[Init] best perm rec loss: 0.9059775471687317 for ['[CLS] liver south fleet [SEP] fine brick reference screened industrywr [SEP]']
[Init] best perm rec loss: 0.9045016765594482 for ['[CLS] fine fleet [SEP] industry screened brick reference liver southwr [SEP]']
[Init] best perm rec loss: 0.903518557548523 for ['[CLS] screened industry south reference fine liver fleet [SEP]wr brick [SEP]']
[Init] best perm rec loss: 0.9033243656158447 for ['[CLS] south reference [SEP] fleet fine brick industry screened liverwr [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.753 (perp=14.265, rec=0.570, cos=0.330), tot_loss_proj:4.764 [t=0.17s]
prediction: ['[CLS] [SEP] popped genus comic geese entering angie reported thirdful [SEP]']
[ 100/2000] tot_loss=2.916 (perp=12.424, rec=0.353, cos=0.078), tot_loss_proj:4.376 [t=0.17s]
prediction: ['[CLS] [SEP] hokkaido hiding soccer baseball college malcolm labeled football baseball [SEP]']
[ 150/2000] tot_loss=2.756 (perp=11.974, rec=0.306, cos=0.055), tot_loss_proj:4.329 [t=0.17s]
prediction: ['[CLS] [SEP] hokkaido nate baseball baseball lankan lewis tagged grape baseball [SEP]']
[ 200/2000] tot_loss=2.181 (perp=9.454, rec=0.253, cos=0.037), tot_loss_proj:3.848 [t=0.17s]
prediction: ['[CLS] [SEP] tagged lewis baseball baseball tagged lewis with tuesday baseball [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.242 (perp=9.741, rec=0.249, cos=0.046), tot_loss_proj:3.905 [t=0.17s]
prediction: ['[CLS] [SEP] lewis tagged baseball ！ tagged lewis with tuesday baseball [SEP]']
[ 300/2000] tot_loss=2.454 (perp=11.176, rec=0.181, cos=0.038), tot_loss_proj:4.240 [t=0.17s]
prediction: ['[CLS] [SEP] john tagged friday tagged tagged lewis with tuesday baseball [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.389 (perp=10.409, rec=0.250, cos=0.056), tot_loss_proj:4.046 [t=0.17s]
prediction: ['[CLS] [SEP] john lewis tagged friday eddie tagged with tuesday baseball [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.260 (perp=10.116, rec=0.201, cos=0.036), tot_loss_proj:4.042 [t=0.17s]
prediction: ['[CLS] [SEP] friday john lewis tagged tagged tagged with tuesday baseball [SEP]']
[ 450/2000] tot_loss=2.292 (perp=10.116, rec=0.219, cos=0.050), tot_loss_proj:4.034 [t=0.17s]
prediction: ['[CLS] [SEP] friday john lewis tagged tagged tagged with tuesday baseball [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.257 (perp=10.286, rec=0.166, cos=0.033), tot_loss_proj:3.986 [t=0.17s]
prediction: ['[CLS] [SEP] tagged friday john lewis dollars tagged with tuesday baseball [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.137 (perp=9.734, rec=0.157, cos=0.034), tot_loss_proj:3.939 [t=0.17s]
prediction: ['[CLS] [SEP] tagged tuesday john lewis tagged regulation with friday baseball [SEP]']
[ 600/2000] tot_loss=2.129 (perp=9.734, rec=0.152, cos=0.030), tot_loss_proj:3.939 [t=0.17s]
prediction: ['[CLS] [SEP] tagged tuesday john lewis tagged regulation with friday baseball [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.080 (perp=9.501, rec=0.150, cos=0.030), tot_loss_proj:3.842 [t=0.17s]
prediction: ['[CLS] [SEP] tagged tuesday john lewis tagged with friday regulation baseball [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.024 (perp=9.277, rec=0.138, cos=0.030), tot_loss_proj:3.833 [t=0.17s]
prediction: ['[CLS] [SEP] tagged tuesday john lewis with tagged friday regulation baseball [SEP]']
[ 750/2000] tot_loss=2.014 (perp=9.277, rec=0.130, cos=0.029), tot_loss_proj:3.830 [t=0.17s]
prediction: ['[CLS] [SEP] tagged tuesday john lewis with tagged friday regulation baseball [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.171 (perp=9.987, rec=0.145, cos=0.029), tot_loss_proj:3.921 [t=0.17s]
prediction: ['[CLS] [SEP] tagged tuesday john lewis with. friday regulation baseball [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.969 (perp=8.851, rec=0.162, cos=0.037), tot_loss_proj:3.442 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. friday regulation baseball [SEP]']
[ 900/2000] tot_loss=1.939 (perp=8.851, rec=0.141, cos=0.028), tot_loss_proj:3.440 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. friday regulation baseball [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.931 (perp=8.851, rec=0.133, cos=0.028), tot_loss_proj:3.436 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. friday regulation baseball [SEP]']
Attempt swap
[1000/2000] tot_loss=1.912 (perp=8.851, rec=0.116, cos=0.027), tot_loss_proj:3.441 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. friday regulation baseball [SEP]']
[1050/2000] tot_loss=1.912 (perp=8.851, rec=0.116, cos=0.026), tot_loss_proj:3.437 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. friday regulation baseball [SEP]']
Attempt swap
[1100/2000] tot_loss=1.913 (perp=8.851, rec=0.117, cos=0.026), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. friday regulation baseball [SEP]']
Attempt swap
[1150/2000] tot_loss=1.910 (perp=8.851, rec=0.114, cos=0.026), tot_loss_proj:3.443 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. friday regulation baseball [SEP]']
[1200/2000] tot_loss=1.918 (perp=8.851, rec=0.123, cos=0.026), tot_loss_proj:3.439 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. friday regulation baseball [SEP]']
Attempt swap
[1250/2000] tot_loss=1.907 (perp=8.851, rec=0.111, cos=0.026), tot_loss_proj:3.439 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. friday regulation baseball [SEP]']
Attempt swap
[1300/2000] tot_loss=1.927 (perp=8.935, rec=0.115, cos=0.025), tot_loss_proj:3.495 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
[1350/2000] tot_loss=1.923 (perp=8.935, rec=0.110, cos=0.026), tot_loss_proj:3.492 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
Attempt swap
[1400/2000] tot_loss=1.932 (perp=8.935, rec=0.119, cos=0.026), tot_loss_proj:3.498 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
Attempt swap
[1450/2000] tot_loss=1.915 (perp=8.935, rec=0.103, cos=0.025), tot_loss_proj:3.491 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
[1500/2000] tot_loss=1.921 (perp=8.935, rec=0.109, cos=0.026), tot_loss_proj:3.491 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
Attempt swap
[1550/2000] tot_loss=1.916 (perp=8.935, rec=0.103, cos=0.026), tot_loss_proj:3.497 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
Attempt swap
[1600/2000] tot_loss=1.922 (perp=8.935, rec=0.109, cos=0.026), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
[1650/2000] tot_loss=1.914 (perp=8.935, rec=0.101, cos=0.026), tot_loss_proj:3.489 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
Attempt swap
[1700/2000] tot_loss=1.919 (perp=8.935, rec=0.107, cos=0.026), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
Attempt swap
[1750/2000] tot_loss=1.916 (perp=8.935, rec=0.104, cos=0.025), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
[1800/2000] tot_loss=1.915 (perp=8.935, rec=0.103, cos=0.025), tot_loss_proj:3.492 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
Attempt swap
[1850/2000] tot_loss=1.916 (perp=8.935, rec=0.104, cos=0.025), tot_loss_proj:3.495 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
Attempt swap
[1900/2000] tot_loss=1.915 (perp=8.935, rec=0.103, cos=0.025), tot_loss_proj:3.492 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
[1950/2000] tot_loss=1.907 (perp=8.935, rec=0.094, cos=0.025), tot_loss_proj:3.493 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
Attempt swap
[2000/2000] tot_loss=1.914 (perp=8.935, rec=0.102, cos=0.025), tot_loss_proj:3.497 [t=0.17s]
prediction: ['[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]
========================
predicted: 
========================
[CLS] [SEP] tagged with john lewis tuesday. tuesday regulation baseball [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 10.000 | p: 10.000 | r: 10.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 91.818

[Aggregate metrics]:
rouge1     | fm: 78.403 | p: 78.859 | r: 78.249
rouge2     | fm: 35.901 | p: 35.721 | r: 36.258
rougeL     | fm: 65.894 | p: 66.269 | r: 65.786
rougeLsum  | fm: 65.940 | p: 66.381 | r: 65.849
r1fm+r2fm = 114.304

input #48 time: 0:06:59 | total time: 5:43:45


Running input #49 of 100.
reference: 
========================
We all thought him to be unhappy
========================
Sample: 0 2.5837886182697143e-12 0.0426695922275113 0.31218532
average of cosine similarity 0.9906151944512263
highest_index [0]
highest [0.9906151944512263]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2057,  2035,  2245,  2032,  2000,  2022, 12511,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] we all thought him to be unhappy [SEP]']
[Init] best rec loss: 0.9411858320236206 for ['[CLS] mattermei visibly port brandenburgmissive le [SEP]']
[Init] best rec loss: 0.9296923875808716 for ['[CLS] smoke starary pmid feather consider line [SEP]']
[Init] best rec loss: 0.9013326168060303 for ['[CLS] studies brig numbered logan tour percent rex [SEP]']
[Init] best rec loss: 0.8935877680778503 for ['[CLS]vy threatened fragments straight long piper sign [SEP]']
[Init] best rec loss: 0.8891277313232422 for ['[CLS] cominglett than carrier holiday exposed long [SEP]']
[Init] best rec loss: 0.8783950805664062 for ['[CLS] added guinea gretchen nine cast patent closed [SEP]']
[Init] best rec loss: 0.8762047290802002 for ['[CLS] steppedine band yeshiva / mansion investment [SEP]']
[Init] best rec loss: 0.8750602602958679 for ['[CLS] turf rib hutually driven celine richards [SEP]']
[Init] best rec loss: 0.8677970170974731 for ['[CLS] kennedy drive hold ro steering sindhuising [SEP]']
[Init] best rec loss: 0.8665210604667664 for ['[CLS] rolandylus que phelps books haste yourselves [SEP]']
[Init] best perm rec loss: 0.8652602434158325 for ['[CLS] rolandylus books que phelps yourselves haste [SEP]']
[Init] best perm rec loss: 0.8644270896911621 for ['[CLS]ylus phelps que yourselves haste roland books [SEP]']
[Init] best perm rec loss: 0.8641104102134705 for ['[CLS] yourselves phelpsylus roland que books haste [SEP]']
[Init] best perm rec loss: 0.8639255166053772 for ['[CLS] yourselves roland books haste queylus phelps [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.158 (perp=12.367, rec=0.487, cos=0.198), tot_loss_proj:4.393 [t=0.17s]
prediction: ['[CLS] 978 dishes therefore. ke boys bolt [SEP]']
[ 100/2000] tot_loss=2.888 (perp=12.014, rec=0.394, cos=0.091), tot_loss_proj:4.341 [t=0.17s]
prediction: ['[CLS] 978 shops always think never deputy mca [SEP]']
[ 150/2000] tot_loss=2.520 (perp=10.339, rec=0.380, cos=0.073), tot_loss_proj:3.980 [t=0.17s]
prediction: ['[CLS] lucy ions we think that boyfriend mca [SEP]']
[ 200/2000] tot_loss=2.643 (perp=11.599, rec=0.292, cos=0.032), tot_loss_proj:4.252 [t=0.17s]
prediction: ['[CLS] lucy editorial we think none du unhappy [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.530 (perp=11.255, rec=0.247, cos=0.031), tot_loss_proj:4.106 [t=0.17s]
prediction: ['[CLS] lucy access all think none du him [SEP]']
[ 300/2000] tot_loss=2.249 (perp=9.778, rec=0.243, cos=0.050), tot_loss_proj:3.839 [t=0.17s]
prediction: ['[CLS] lucy to all thought unhappy du him [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.187 (perp=9.193, rec=0.297, cos=0.051), tot_loss_proj:3.754 [t=0.17s]
prediction: ['[CLS] nobody john we thought you to him [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.288 (perp=9.998, rec=0.251, cos=0.037), tot_loss_proj:3.938 [t=0.17s]
prediction: ['[CLS]heim thought we unhappy you to him [SEP]']
[ 450/2000] tot_loss=2.228 (perp=9.998, rec=0.199, cos=0.030), tot_loss_proj:3.938 [t=0.17s]
prediction: ['[CLS]heim thought we unhappy you to him [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.001 (perp=9.094, rec=0.157, cos=0.025), tot_loss_proj:3.729 [t=0.17s]
prediction: ['[CLS]ties thought all unhappy you to him [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.782 (perp=8.112, rec=0.137, cos=0.023), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] be thought all you unhappy to him [SEP]']
[ 600/2000] tot_loss=1.771 (perp=8.112, rec=0.126, cos=0.023), tot_loss_proj:3.530 [t=0.17s]
prediction: ['[CLS] be thought all you unhappy to him [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.889 (perp=8.277, rec=0.199, cos=0.034), tot_loss_proj:3.530 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.828 (perp=8.277, rec=0.149, cos=0.024), tot_loss_proj:3.523 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
[ 750/2000] tot_loss=1.815 (perp=8.277, rec=0.136, cos=0.023), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.796 (perp=8.252, rec=0.123, cos=0.023), tot_loss_proj:3.531 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.807 (perp=8.277, rec=0.129, cos=0.023), tot_loss_proj:3.526 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
[ 900/2000] tot_loss=1.812 (perp=8.277, rec=0.134, cos=0.023), tot_loss_proj:3.524 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.789 (perp=8.252, rec=0.116, cos=0.022), tot_loss_proj:3.539 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
[1000/2000] tot_loss=1.795 (perp=8.252, rec=0.122, cos=0.022), tot_loss_proj:3.537 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
[1050/2000] tot_loss=1.789 (perp=8.252, rec=0.116, cos=0.022), tot_loss_proj:3.535 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
[1100/2000] tot_loss=1.796 (perp=8.252, rec=0.124, cos=0.022), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
[1150/2000] tot_loss=1.798 (perp=8.252, rec=0.125, cos=0.022), tot_loss_proj:3.537 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
[1200/2000] tot_loss=1.788 (perp=8.252, rec=0.116, cos=0.022), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
[1250/2000] tot_loss=1.790 (perp=8.252, rec=0.117, cos=0.022), tot_loss_proj:3.537 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
[1300/2000] tot_loss=1.779 (perp=8.252, rec=0.107, cos=0.022), tot_loss_proj:3.538 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
[1350/2000] tot_loss=1.788 (perp=8.252, rec=0.116, cos=0.022), tot_loss_proj:3.535 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
[1400/2000] tot_loss=1.779 (perp=8.252, rec=0.106, cos=0.022), tot_loss_proj:3.536 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.795 (perp=8.277, rec=0.117, cos=0.023), tot_loss_proj:3.527 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
[1500/2000] tot_loss=1.795 (perp=8.277, rec=0.117, cos=0.023), tot_loss_proj:3.524 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
Attempt swap
[1550/2000] tot_loss=1.794 (perp=8.277, rec=0.117, cos=0.022), tot_loss_proj:3.523 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.783 (perp=8.252, rec=0.111, cos=0.022), tot_loss_proj:3.542 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
[1650/2000] tot_loss=1.782 (perp=8.252, rec=0.109, cos=0.022), tot_loss_proj:3.543 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
[1700/2000] tot_loss=1.778 (perp=8.252, rec=0.106, cos=0.022), tot_loss_proj:3.536 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
[1750/2000] tot_loss=1.787 (perp=8.252, rec=0.114, cos=0.022), tot_loss_proj:3.534 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
[1800/2000] tot_loss=1.784 (perp=8.252, rec=0.112, cos=0.022), tot_loss_proj:3.538 [t=0.17s]
prediction: ['[CLS] you thought all unhappy double to him [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.792 (perp=8.277, rec=0.114, cos=0.023), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
Attempt swap
[1900/2000] tot_loss=1.785 (perp=8.277, rec=0.108, cos=0.022), tot_loss_proj:3.527 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
[1950/2000] tot_loss=1.794 (perp=8.277, rec=0.116, cos=0.022), tot_loss_proj:3.525 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
Attempt swap
[2000/2000] tot_loss=1.794 (perp=8.277, rec=0.116, cos=0.022), tot_loss_proj:3.524 [t=0.17s]
prediction: ['[CLS] you thought all double unhappy to him [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] we all thought him to be unhappy [SEP]
========================
predicted: 
========================
[CLS] you thought all double unhappy to him [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 77.778

[Aggregate metrics]:
rouge1     | fm: 78.426 | p: 78.863 | r: 78.307
rouge2     | fm: 35.307 | p: 35.033 | r: 35.700
rougeL     | fm: 65.558 | p: 65.950 | r: 65.455
rougeLsum  | fm: 65.496 | p: 65.893 | r: 65.448
r1fm+r2fm = 113.732

input #49 time: 0:06:55 | total time: 5:50:40


Running input #50 of 100.
reference: 
========================
Book is available in most countries.
========================
Sample: 0 1.5155620353135454e-10 0.044889143231747274 0.35766673
average of cosine similarity 0.9920928806457971
highest_index [0]
highest [0.9920928806457971]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2338, 2003, 2800, 1999, 2087, 3032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] book is available in most countries. [SEP]']
[Init] best rec loss: 0.7874211072921753 for ['[CLS] keyxy neither jenksuka chow administration [SEP]']
[Init] best rec loss: 0.7831349968910217 for ['[CLS] rev vaughn debut inspiration theme mind wonder [SEP]']
[Init] best rec loss: 0.7579970955848694 for ['[CLS] tapes [SEP] stronger u part radio tropical [SEP]']
[Init] best rec loss: 0.7362892627716064 for ['[CLS]ers quality thereafter small conversations gaius sven [SEP]']
[Init] best rec loss: 0.7306573987007141 for ['[CLS] po gustav room governors roger underpathic [SEP]']
[Init] best rec loss: 0.730445146560669 for ['[CLS]ping casualties election creditsiestitiafactory [SEP]']
[Init] best rec loss: 0.7263517379760742 for ['[CLS] reconnaissancefieldsffen switzerland humor spells scenario [SEP]']
[Init] best perm rec loss: 0.7249794006347656 for ['[CLS]ffen scenario spells switzerland humorfields reconnaissance [SEP]']
[Init] best perm rec loss: 0.7248560786247253 for ['[CLS] switzerlandffenfields reconnaissance humor scenario spells [SEP]']
[Init] best perm rec loss: 0.7243238091468811 for ['[CLS] switzerlandffen reconnaissance scenariofields humor spells [SEP]']
[Init] best perm rec loss: 0.7224777936935425 for ['[CLS] switzerland scenariofields humor reconnaissance spellsffen [SEP]']
[Init] best perm rec loss: 0.7222394943237305 for ['[CLS] spells reconnaissance scenariofieldsffen humor switzerland [SEP]']
[Init] best perm rec loss: 0.7190003991127014 for ['[CLS] scenariofieldsffen switzerland humor spells reconnaissance [SEP]']
[Init] best perm rec loss: 0.7169519662857056 for ['[CLS] switzerlandfields scenarioffen spells reconnaissance humor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.885 (perp=12.505, rec=0.328, cos=0.057), tot_loss_proj:3.985 [t=0.17s]
prediction: ['[CLS] model magna vanilla jack counterpart nano book [SEP]']
[ 100/2000] tot_loss=2.578 (perp=11.535, rec=0.233, cos=0.038), tot_loss_proj:3.321 [t=0.17s]
prediction: ['[CLS] book magna available available is spaces book [SEP]']
[ 150/2000] tot_loss=1.845 (perp=8.183, rec=0.180, cos=0.028), tot_loss_proj:2.571 [t=0.17s]
prediction: ['[CLS] book makes available available is available book [SEP]']
[ 200/2000] tot_loss=1.855 (perp=8.332, rec=0.161, cos=0.028), tot_loss_proj:2.757 [t=0.17s]
prediction: ['[CLS] most is available available is available book [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.646 (perp=7.402, rec=0.144, cos=0.022), tot_loss_proj:2.582 [t=0.17s]
prediction: ['[CLS] most is available book is available available [SEP]']
[ 300/2000] tot_loss=1.656 (perp=7.523, rec=0.131, cos=0.020), tot_loss_proj:2.533 [t=0.17s]
prediction: ['[CLS] most in countries book is available available [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.323 (perp=5.926, rec=0.114, cos=0.023), tot_loss_proj:2.107 [t=0.17s]
prediction: ['[CLS] in most countries book is available available [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.312 (perp=5.926, rec=0.108, cos=0.020), tot_loss_proj:2.088 [t=0.17s]
prediction: ['[CLS] in most countries book is available available [SEP]']
[ 450/2000] tot_loss=1.293 (perp=5.926, rec=0.089, cos=0.019), tot_loss_proj:2.082 [t=0.17s]
prediction: ['[CLS] in most countries book is available available [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.201 (perp=5.428, rec=0.096, cos=0.019), tot_loss_proj:1.531 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.181 (perp=5.428, rec=0.077, cos=0.018), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
[ 600/2000] tot_loss=1.185 (perp=5.428, rec=0.081, cos=0.018), tot_loss_proj:1.543 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.182 (perp=5.428, rec=0.078, cos=0.018), tot_loss_proj:1.530 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.174 (perp=5.428, rec=0.070, cos=0.018), tot_loss_proj:1.524 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
[ 750/2000] tot_loss=1.182 (perp=5.428, rec=0.078, cos=0.018), tot_loss_proj:1.532 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.181 (perp=5.428, rec=0.077, cos=0.018), tot_loss_proj:1.543 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.182 (perp=5.428, rec=0.078, cos=0.018), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
[ 900/2000] tot_loss=1.183 (perp=5.428, rec=0.080, cos=0.018), tot_loss_proj:1.531 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.182 (perp=5.428, rec=0.078, cos=0.018), tot_loss_proj:1.533 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1000/2000] tot_loss=1.177 (perp=5.428, rec=0.073, cos=0.018), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
[1050/2000] tot_loss=1.181 (perp=5.428, rec=0.078, cos=0.018), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1100/2000] tot_loss=1.182 (perp=5.428, rec=0.079, cos=0.018), tot_loss_proj:1.537 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1150/2000] tot_loss=1.178 (perp=5.428, rec=0.074, cos=0.018), tot_loss_proj:1.542 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
[1200/2000] tot_loss=1.184 (perp=5.428, rec=0.081, cos=0.018), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1250/2000] tot_loss=1.183 (perp=5.428, rec=0.080, cos=0.018), tot_loss_proj:1.534 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1300/2000] tot_loss=1.183 (perp=5.428, rec=0.080, cos=0.018), tot_loss_proj:1.542 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
[1350/2000] tot_loss=1.176 (perp=5.428, rec=0.073, cos=0.018), tot_loss_proj:1.540 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1400/2000] tot_loss=1.169 (perp=5.428, rec=0.065, cos=0.018), tot_loss_proj:1.549 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1450/2000] tot_loss=1.175 (perp=5.428, rec=0.071, cos=0.018), tot_loss_proj:1.535 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
[1500/2000] tot_loss=1.169 (perp=5.428, rec=0.065, cos=0.018), tot_loss_proj:1.540 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1550/2000] tot_loss=1.189 (perp=5.428, rec=0.086, cos=0.018), tot_loss_proj:1.547 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1600/2000] tot_loss=1.170 (perp=5.428, rec=0.067, cos=0.018), tot_loss_proj:1.540 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
[1650/2000] tot_loss=1.158 (perp=5.428, rec=0.055, cos=0.018), tot_loss_proj:1.541 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1700/2000] tot_loss=1.184 (perp=5.428, rec=0.081, cos=0.018), tot_loss_proj:1.537 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1750/2000] tot_loss=1.178 (perp=5.428, rec=0.075, cos=0.018), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
[1800/2000] tot_loss=1.171 (perp=5.428, rec=0.068, cos=0.018), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1850/2000] tot_loss=1.174 (perp=5.428, rec=0.071, cos=0.018), tot_loss_proj:1.543 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[1900/2000] tot_loss=1.174 (perp=5.428, rec=0.071, cos=0.018), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
[1950/2000] tot_loss=1.185 (perp=5.428, rec=0.082, cos=0.018), tot_loss_proj:1.544 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Attempt swap
[2000/2000] tot_loss=1.162 (perp=5.428, rec=0.058, cos=0.018), tot_loss_proj:1.535 [t=0.17s]
prediction: ['[CLS] book is available in most countries available [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] book is available in most countries. [SEP]
========================
predicted: 
========================
[CLS] book is available in most countries available [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 80.000 | p: 75.000 | r: 85.714
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 174.118

[Aggregate metrics]:
rouge1     | fm: 78.633 | p: 78.941 | r: 78.592
rouge2     | fm: 35.876 | p: 35.669 | r: 36.404
rougeL     | fm: 66.061 | p: 66.277 | r: 66.040
rougeLsum  | fm: 66.211 | p: 66.438 | r: 66.231
r1fm+r2fm = 114.509

input #50 time: 0:06:55 | total time: 5:57:36


Running input #51 of 100.
reference: 
========================
I could have little known that more trouble was just around the corner.
========================
Sample: 0 4.236865717032573e-11 0.04085310745215602 0.29938722
average of cosine similarity 0.9906461645276705
highest_index [0]
highest [0.9906461645276705]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2071, 2031, 2210, 2124, 2008, 2062, 4390, 2001, 2074, 2105,
         1996, 3420, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i could have little known that more trouble was just around the corner. [SEP]']
[Init] best rec loss: 0.958308219909668 for ['[CLS] missing coincidence ten ideas gas need status singleton silver considered demolished tale convert grumbled [SEP]']
[Init] best rec loss: 0.9319798350334167 for ['[CLS] clshfalls chicago walled steps turn photos tell covers yet letter xx table [SEP]']
[Init] best rec loss: 0.8892698287963867 for ['[CLS] reason strength trains chance dawsonwyl milk diplomatic tie chance parked honey summer associated [SEP]']
[Init] best rec loss: 0.8843215703964233 for ['[CLS]ponecope calm social solemn milesling moodeersi demon position negativeif [SEP]']
[Init] best rec loss: 0.8748561143875122 for ['[CLS] theirform prevented throughoutnight younger ham near should mustizationite split individual [SEP]']
[Init] best rec loss: 0.860314667224884 for ['[CLS] temperatures ruth krishna metre cultural samurai acceleration visual oscar premiere hitter priest jo ps [SEP]']
[Init] best perm rec loss: 0.8551190495491028 for ['[CLS] ps temperatures samurai metre priest cultural premiere jo krishna oscar visual ruth hitter acceleration [SEP]']
[Init] best perm rec loss: 0.8518536686897278 for ['[CLS] temperatures metre krishna premiere cultural ps samurai ruth acceleration jo priest hitter visual oscar [SEP]']
[Init] best perm rec loss: 0.8513066172599792 for ['[CLS] cultural acceleration ruth metre temperatures oscar samurai krishna premiere jo visual ps priest hitter [SEP]']
[Init] best perm rec loss: 0.8505657911300659 for ['[CLS] premiere visual priest krishna oscar samurai metre acceleration temperatures cultural ps jo ruth hitter [SEP]']
[Init] best perm rec loss: 0.8491230607032776 for ['[CLS] oscar samurai priest temperatures hitter visual acceleration ruth premiere krishna jo cultural ps metre [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.776 (perp=11.297, rec=0.531, cos=0.986), tot_loss_proj:4.191 [t=0.18s]
prediction: ['[CLS] 7 : jim rca corps,firmed. settlershort brigade pressure carrying walkover [SEP]']
[ 100/2000] tot_loss=3.468 (perp=10.120, rec=0.467, cos=0.978), tot_loss_proj:3.897 [t=0.19s]
prediction: ['[CLS] especially the ezio further. was ᶜ. me although bastards bulk maintenance walkover [SEP]']
[ 150/2000] tot_loss=3.808 (perp=11.228, rec=0.567, cos=0.996), tot_loss_proj:4.111 [t=0.20s]
prediction: ['[CLS] was. fame zealand ) looked help.ard publicity. bulk measured walkover [SEP]']
[ 200/2000] tot_loss=3.703 (perp=11.236, rec=0.468, cos=0.987), tot_loss_proj:4.151 [t=0.21s]
prediction: ['[CLS] considered. which zealandif yeah easily.ard annabelle. initial over used [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.464 (perp=10.261, rec=0.433, cos=0.979), tot_loss_proj:3.958 [t=0.17s]
prediction: ['[CLS] harry could which smiled myself knew not. ifław. initial > w [SEP]']
[ 300/2000] tot_loss=3.466 (perp=10.499, rec=0.394, cos=0.972), tot_loss_proj:4.074 [t=0.17s]
prediction: ['[CLS] moore had little knew considered knew more. ifław. smaller > where [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.717 (perp=10.797, rec=0.572, cos=0.986), tot_loss_proj:4.019 [t=0.17s]
prediction: ['[CLS] boundary, little apart up is h by at erebidae. is respect [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.573 (perp=10.383, rec=0.528, cos=0.968), tot_loss_proj:3.931 [t=0.17s]
prediction: ['[CLS] track probably little. including knew h for in nigel. heavily respect [CLS] [SEP]']
[ 450/2000] tot_loss=3.504 (perp=10.390, rec=0.470, cos=0.956), tot_loss_proj:3.937 [t=0.18s]
prediction: ['[CLS] track but little. including knew the for behind nigel. heavily respect [CLS] [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.759 (perp=11.872, rec=0.444, cos=0.940), tot_loss_proj:4.225 [t=0.17s]
prediction: ['[CLS] track less little. lives knew cold commission for nigel.walk trouble [CLS] [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=3.458 (perp=10.428, rec=0.437, cos=0.936), tot_loss_proj:3.961 [t=0.19s]
prediction: ['[CLS] track less little. lives knew coldtead. trouble commission for trouble [CLS] [SEP]']
[ 600/2000] tot_loss=3.470 (perp=10.676, rec=0.414, cos=0.921), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] included less little. tea knew coldtead. trouble behind for trouble when [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.111 (perp=9.001, rec=0.391, cos=0.919), tot_loss_proj:3.665 [t=0.17s]
prediction: ['[CLS] included knew little. tea less coldtead. was behind for trouble [CLS] [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.000 (perp=8.514, rec=0.384, cos=0.913), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] included knew little. teatead the less. was get for trouble when [SEP]']
[ 750/2000] tot_loss=3.022 (perp=8.788, rec=0.369, cos=0.895), tot_loss_proj:3.658 [t=0.17s]
prediction: ['[CLS] included knew little. teaback the less. was olive for trouble when [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.995 (perp=8.762, rec=0.360, cos=0.882), tot_loss_proj:3.628 [t=0.19s]
prediction: ['[CLS] included known little that teaback the became. was olive about trouble. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.992 (perp=8.862, rec=0.358, cos=0.862), tot_loss_proj:3.630 [t=0.17s]
prediction: ['[CLS] included known little that teaback became attention. was olive about trouble. [SEP]']
[ 900/2000] tot_loss=2.959 (perp=8.862, rec=0.341, cos=0.846), tot_loss_proj:3.632 [t=0.17s]
prediction: ['[CLS] included known little that teaback became attention. was olive about trouble. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.943 (perp=8.779, rec=0.348, cos=0.839), tot_loss_proj:3.663 [t=0.17s]
prediction: ['[CLS] included known little known teaback became attention. olive was about trouble. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.916 (perp=8.779, rec=0.333, cos=0.827), tot_loss_proj:3.660 [t=0.18s]
prediction: ['[CLS] included known little known teaback became attention. olive was about trouble. [SEP]']
[1050/2000] tot_loss=2.908 (perp=8.779, rec=0.335, cos=0.817), tot_loss_proj:3.664 [t=0.17s]
prediction: ['[CLS] included known little known teaback became attention. olive was about trouble. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.931 (perp=8.976, rec=0.325, cos=0.810), tot_loss_proj:3.707 [t=0.17s]
prediction: ['[CLS] included known little known teaback became they. olive was about trouble. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.844 (perp=8.504, rec=0.328, cos=0.816), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] included known little known tea condition they became. olive was about trouble. [SEP]']
[1200/2000] tot_loss=2.822 (perp=8.504, rec=0.319, cos=0.802), tot_loss_proj:3.600 [t=0.17s]
prediction: ['[CLS] included known little known tea condition they became. olive was about trouble. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.819 (perp=8.504, rec=0.323, cos=0.795), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] included known little known tea condition they became. olive was about trouble. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.667 (perp=7.804, rec=0.316, cos=0.790), tot_loss_proj:3.449 [t=0.19s]
prediction: ['[CLS] included known little known about condition they became. olive was about trouble. [SEP]']
[1350/2000] tot_loss=2.704 (perp=8.019, rec=0.314, cos=0.787), tot_loss_proj:3.473 [t=0.19s]
prediction: ['[CLS] included known little known about condition the became. olive was about trouble. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.844 (perp=8.682, rec=0.316, cos=0.792), tot_loss_proj:3.559 [t=0.17s]
prediction: ['[CLS] included known little known about they distance became. olive was about trouble. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.815 (perp=8.479, rec=0.320, cos=0.800), tot_loss_proj:3.599 [t=0.17s]
prediction: ['[CLS] included known little known about distance the became. olive was about trouble. [SEP]']
[1500/2000] tot_loss=2.794 (perp=8.479, rec=0.311, cos=0.787), tot_loss_proj:3.604 [t=0.17s]
prediction: ['[CLS] included known little known about distance the became. olive was about trouble. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.671 (perp=7.786, rec=0.318, cos=0.796), tot_loss_proj:3.428 [t=0.17s]
prediction: ['[CLS] included known little known about became the distance. olive was about trouble. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.851 (perp=8.682, rec=0.319, cos=0.796), tot_loss_proj:3.559 [t=0.19s]
prediction: ['[CLS] included known little known about they distance became. olive was about trouble. [SEP]']
[1650/2000] tot_loss=2.842 (perp=8.682, rec=0.315, cos=0.790), tot_loss_proj:3.556 [t=0.17s]
prediction: ['[CLS] included known little known about they distance became. olive was about trouble. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.693 (perp=7.977, rec=0.310, cos=0.787), tot_loss_proj:3.440 [t=0.17s]
prediction: ['[CLS] included known little known about they became distance. olive was about trouble. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.808 (perp=8.479, rec=0.317, cos=0.795), tot_loss_proj:3.600 [t=0.17s]
prediction: ['[CLS] included known little known about distance the became. olive was about trouble. [SEP]']
[1800/2000] tot_loss=2.795 (perp=8.479, rec=0.317, cos=0.783), tot_loss_proj:3.601 [t=0.17s]
prediction: ['[CLS] included known little known about distance the became. olive was about trouble. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.868 (perp=8.734, rec=0.322, cos=0.799), tot_loss_proj:3.612 [t=0.17s]
prediction: ['[CLS] included known little known about distance became. olive was they about trouble. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.698 (perp=7.965, rec=0.315, cos=0.790), tot_loss_proj:3.462 [t=0.17s]
prediction: ['[CLS] included known little known about distance became olive. was they about trouble. [SEP]']
[1950/2000] tot_loss=2.738 (perp=8.180, rec=0.314, cos=0.788), tot_loss_proj:3.511 [t=0.17s]
prediction: ['[CLS] included known little known about distance became olive. was the about trouble. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.739 (perp=8.156, rec=0.315, cos=0.794), tot_loss_proj:3.516 [t=0.17s]
prediction: ['[CLS] included known little known about distance became olive. they was about trouble. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] i could have little known that more trouble was just around the corner. [SEP]
========================
predicted: 
========================
[CLS] included known little known about distance the became. olive was about trouble. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.276 | p: 50.000 | r: 46.667
rouge2     | fm: 7.407 | p: 7.692 | r: 7.143
rougeL     | fm: 34.483 | p: 35.714 | r: 33.333
rougeLsum  | fm: 34.483 | p: 35.714 | r: 33.333
r1fm+r2fm = 55.683

[Aggregate metrics]:
rouge1     | fm: 78.123 | p: 78.503 | r: 77.992
rouge2     | fm: 35.520 | p: 35.259 | r: 36.042
rougeL     | fm: 65.394 | p: 65.757 | r: 65.404
rougeLsum  | fm: 65.478 | p: 65.762 | r: 65.474
r1fm+r2fm = 113.643

input #51 time: 0:07:02 | total time: 6:04:39


Running input #52 of 100.
reference: 
========================
John gave the books to Mary at Christmas, and the records to Sue for her birthday.
========================
Sample: 0 1.3264832123985696e-09 0.0488014187997924 0.34998003
average of cosine similarity 0.9902304136776361
highest_index [0]
highest [0.9902304136776361]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2198, 2435, 1996, 2808, 2000, 2984, 2012, 4234, 1010, 1998, 1996,
         2636, 2000, 9790, 2005, 2014, 5798, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]']
[Init] best rec loss: 0.9534174799919128 for ['[CLS] drama establishments wicket vocal willem presence arm australia dashed guineaturn hand converse sparrow mastof hueymined [SEP]']
[Init] best rec loss: 0.9517337083816528 for ['[CLS] thorn double opera y learnedmist maxi bow [SEP] hove flowering as gwen rug hiding style gold ku [SEP]']
[Init] best rec loss: 0.9427309036254883 for ['[CLS] miller balancelined crawl net ramsay frost platform moved eachcial report lay reflecting # gray army contributed [SEP]']
[Init] best rec loss: 0.9308578372001648 for ['[CLS] semi disks chartersnesia glasses hearth while farm motto jack from enoughyr chamber "grass already steven [SEP]']
[Init] best rec loss: 0.9264649152755737 for ['[CLS] titled gesture sc isaac musical officers afghanistan mineral squarekra chip inducted leaving who jon journal ethan ruse [SEP]']
[Init] best rec loss: 0.8957587480545044 for ['[CLS] widowed pat age tack collaroresuk : we finally characteristic [MASK] workingneyawa printingigraphy intelligence [SEP]']
[Init] best perm rec loss: 0.8955612182617188 for ['[CLS] printing working [MASK]awa pat characteristic finallyney tackores widowedigraphy ageuk collar : intelligence we [SEP]']
[Init] best perm rec loss: 0.8945481181144714 for ['[CLS] intelligenceney characteristic finallyawa we pat widowed printing tackigraphyores collar [MASK]uk age working : [SEP]']
[Init] best perm rec loss: 0.8907304406166077 for ['[CLS] age printingukoresigraphy finally intelligence we : widowed collar [MASK]neyawa pat working characteristic tack [SEP]']
[Init] best perm rec loss: 0.887945294380188 for ['[CLS] : [MASK] workingney characteristic weoresigraphy pat finallyawa tack age intelligenceuk widowed collar printing [SEP]']
[Init] best perm rec loss: 0.8872994780540466 for ['[CLS] :igraphyney working characteristic finally collar age printing tackores [MASK]awa pat intelligenceuk widowed we [SEP]']
[Init] best perm rec loss: 0.8868954181671143 for ['[CLS] : working weney pat finallyores [MASK] printingukawa intelligence characteristic collar tack age widowedigraphy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.908 (perp=11.717, rec=0.428, cos=0.136), tot_loss_proj:4.280 [t=0.17s]
prediction: ['[CLS] ( the exhibition one christmas slanggraphsbook pickupache published glad consulting games archbishop minus - mix [SEP]']
[ 100/2000] tot_loss=2.555 (perp=10.905, rec=0.315, cos=0.060), tot_loss_proj:4.025 [t=0.17s]
prediction: ['[CLS] ; the mary books gave sue carriebook pickup would published his the books sue tooth the sessions [SEP]']
[ 150/2000] tot_loss=2.248 (perp=9.836, rec=0.249, cos=0.032), tot_loss_proj:3.784 [t=0.17s]
prediction: ['[CLS] ; for mary books gave sue carrie 1998 series wanted published the the books sue. the sessions [SEP]']
[ 200/2000] tot_loss=2.372 (perp=10.014, rec=0.311, cos=0.058), tot_loss_proj:3.841 [t=0.17s]
prediction: ['[CLS] ; for mary books gave mary records membrane series wanted jean a the books sue to records? [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.060 (perp=9.035, rec=0.221, cos=0.032), tot_loss_proj:3.644 [t=0.17s]
prediction: ['[CLS] during for mary books gave mary supperbook, sue christmas a to books for to the. [SEP]']
[ 300/2000] tot_loss=1.904 (perp=8.404, rec=0.196, cos=0.027), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] during to mary books gave mary at she. sue christmas to to records for to the christmas [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.690 (perp=9.222, rec=0.845, cos=1.000), tot_loss_proj:3.671 [t=0.17s]
prediction: ['[CLS] events to mary books gave maryscribecard, sue and torted records mourning to the christmas [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.364 (perp=9.668, rec=0.559, cos=0.871), tot_loss_proj:3.715 [t=0.17s]
prediction: ['[CLS] corporation to mary books gave maryscriberial sue and against, captured presents temeraire to the christmas [SEP]']
[ 450/2000] tot_loss=3.073 (perp=9.668, rec=0.541, cos=0.599), tot_loss_proj:3.712 [t=0.18s]
prediction: ['[CLS] corporation to mary books gave maryscriberial sue and against, captured presents temeraire to the christmas [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.629 (perp=10.285, rec=0.408, cos=0.164), tot_loss_proj:3.926 [t=0.17s]
prediction: ['[CLS] mary to mary books gave corporationscriberial sue and to, captured santa topical off records christmas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.314 (perp=9.781, rec=0.294, cos=0.064), tot_loss_proj:3.767 [t=0.17s]
prediction: ['[CLS] mary to mary books gave spa carrierial sue and to, captured santa chew records to sue [SEP]']
[ 600/2000] tot_loss=2.149 (perp=9.297, rec=0.247, cos=0.043), tot_loss_proj:3.679 [t=0.17s]
prediction: ['[CLS] mary to mary books gave. carrierial sue and its, captured santa chew records to sue [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.067 (perp=8.941, rec=0.243, cos=0.036), tot_loss_proj:3.585 [t=0.17s]
prediction: ['[CLS] mary to john booksrial. christmas gave sue and its, for santa chew records to sue [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.067 (perp=9.026, rec=0.229, cos=0.033), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] mary to john books for began christmas gave sue and the,rial birthday chew records to sue [SEP]']
[ 750/2000] tot_loss=2.047 (perp=9.026, rec=0.215, cos=0.027), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] mary to john books for began christmas gave sue and the,rial birthday chew records to sue [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.018 (perp=8.907, rec=0.209, cos=0.027), tot_loss_proj:3.690 [t=0.18s]
prediction: ['[CLS] mary at john books for began christmas gave sue, and therial birthday chew records to sue [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.953 (perp=8.570, rec=0.211, cos=0.028), tot_loss_proj:3.618 [t=0.17s]
prediction: ['[CLS] mary at christmas books its began john gave sue, and therial birthday chew records to sue [SEP]']
[ 900/2000] tot_loss=1.955 (perp=8.691, rec=0.191, cos=0.025), tot_loss_proj:3.644 [t=0.17s]
prediction: ['[CLS] mary at christmas books its began john gave sue, and thebell birthday chew records to sue [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.960 (perp=8.744, rec=0.186, cos=0.025), tot_loss_proj:3.684 [t=0.18s]
prediction: ['[CLS] mary at christmas records its began john gave sue, and the chewpress birthday records to sue [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.936 (perp=8.622, rec=0.186, cos=0.025), tot_loss_proj:3.625 [t=0.17s]
prediction: ['[CLS] mary at christmas records began its john gave sue, and the chewpress birthday records to sue [SEP]']
[1050/2000] tot_loss=1.926 (perp=8.622, rec=0.178, cos=0.023), tot_loss_proj:3.626 [t=0.17s]
prediction: ['[CLS] mary at christmas records began its john gave sue, and the chewpress birthday records to sue [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.850 (perp=8.264, rec=0.174, cos=0.023), tot_loss_proj:3.518 [t=0.17s]
prediction: ['[CLS] mary at christmas records began, john gave sue its and the chewpress birthday records to sue [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.839 (perp=8.219, rec=0.171, cos=0.024), tot_loss_proj:3.512 [t=0.17s]
prediction: ['[CLS] mary at christmas records gave, john gave sue and its the chewpress birthday records to sue [SEP]']
[1200/2000] tot_loss=1.836 (perp=8.219, rec=0.169, cos=0.023), tot_loss_proj:3.511 [t=0.17s]
prediction: ['[CLS] mary at christmas records gave, john gave sue and its the chewpress birthday records to sue [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.789 (perp=7.997, rec=0.167, cos=0.023), tot_loss_proj:3.483 [t=0.17s]
prediction: ['[CLS] mary at christmas records gave, john gave sue and the its chewpress birthday records to sue [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.769 (perp=7.933, rec=0.160, cos=0.022), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] mary at christmas records gave, john gave sue and the itspress chew birthday records to sue [SEP]']
[1350/2000] tot_loss=1.756 (perp=7.933, rec=0.147, cos=0.022), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] mary at christmas records gave, john gave sue and the itspress chew birthday records to sue [SEP]']
Attempt swap
[1400/2000] tot_loss=1.770 (perp=7.933, rec=0.161, cos=0.022), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] mary at christmas records gave, john gave sue and the itspress chew birthday records to sue [SEP]']
Attempt swap
[1450/2000] tot_loss=1.765 (perp=7.933, rec=0.156, cos=0.022), tot_loss_proj:3.506 [t=0.18s]
prediction: ['[CLS] mary at christmas records gave, john gave sue and the itspress chew birthday records to sue [SEP]']
[1500/2000] tot_loss=1.761 (perp=7.933, rec=0.152, cos=0.022), tot_loss_proj:3.508 [t=0.17s]
prediction: ['[CLS] mary at christmas records gave, john gave sue and the itspress chew birthday records to sue [SEP]']
Attempt swap
[1550/2000] tot_loss=1.764 (perp=7.933, rec=0.155, cos=0.022), tot_loss_proj:3.511 [t=0.18s]
prediction: ['[CLS] mary at christmas records gave, john gave sue and the itspress chew birthday records to sue [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.696 (perp=7.580, rec=0.158, cos=0.022), tot_loss_proj:3.448 [t=0.17s]
prediction: ['[CLS] at christmas mary records gave, john gave sue and the itspress chew birthday records to sue [SEP]']
[1650/2000] tot_loss=1.684 (perp=7.580, rec=0.147, cos=0.022), tot_loss_proj:3.448 [t=0.17s]
prediction: ['[CLS] at christmas mary records gave, john gave sue and the itspress chew birthday records to sue [SEP]']
Attempt swap
[1700/2000] tot_loss=1.681 (perp=7.580, rec=0.143, cos=0.022), tot_loss_proj:3.443 [t=0.17s]
prediction: ['[CLS] at christmas mary records gave, john gave sue and the itspress chew birthday records to sue [SEP]']
Attempt swap
[1750/2000] tot_loss=1.726 (perp=7.800, rec=0.145, cos=0.022), tot_loss_proj:3.512 [t=0.17s]
prediction: ['[CLS] at christmas mary records gave, john gave sue and the itspress chew birthday books to sue [SEP]']
[1800/2000] tot_loss=1.727 (perp=7.800, rec=0.146, cos=0.022), tot_loss_proj:3.509 [t=0.17s]
prediction: ['[CLS] at christmas mary records gave, john gave sue and the itspress chew birthday books to sue [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.740 (perp=7.804, rec=0.157, cos=0.022), tot_loss_proj:3.492 [t=0.17s]
prediction: ['[CLS] at christmas mary records gave, john gave sue and the its chewpress birthday books to sue [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.719 (perp=7.694, rec=0.156, cos=0.024), tot_loss_proj:3.383 [t=0.17s]
prediction: ['[CLS] at christmas mary records gave, john gave sue and thepress chew its birthday books to sue [SEP]']
[1950/2000] tot_loss=1.709 (perp=7.694, rec=0.148, cos=0.022), tot_loss_proj:3.389 [t=0.17s]
prediction: ['[CLS] at christmas mary records gave, john gave sue and thepress chew its birthday books to sue [SEP]']
Attempt swap
[2000/2000] tot_loss=1.714 (perp=7.694, rec=0.154, cos=0.022), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS] at christmas mary records gave, john gave sue and thepress chew its birthday books to sue [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]
========================
predicted: 
========================
[CLS] at christmas mary records gave, john gave sue and the its chewpress birthday books to sue [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 29.412 | p: 29.412 | r: 29.412
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 107.190

[Aggregate metrics]:
rouge1     | fm: 78.090 | p: 78.428 | r: 78.038
rouge2     | fm: 35.399 | p: 35.216 | r: 35.898
rougeL     | fm: 64.977 | p: 65.227 | r: 64.998
rougeLsum  | fm: 65.203 | p: 65.454 | r: 65.195
r1fm+r2fm = 113.489

input #52 time: 0:07:07 | total time: 6:11:46


Running input #53 of 100.
reference: 
========================
He said that himself was hungry.
========================
Sample: 0 5.452173651807291e-11 0.04846728483955673 0.357744
average of cosine similarity 0.9907800475688989
highest_index [0]
highest [0.9907800475688989]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2056, 2008, 2370, 2001, 7501, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he said that himself was hungry. [SEP]']
[Init] best rec loss: 0.9756957292556763 for ['[CLS] syncoc youth also returning jaguar flower [SEP]']
[Init] best rec loss: 0.9171878695487976 for ['[CLS] terms expireditanupt racing everuating [SEP]']
[Init] best rec loss: 0.8175871968269348 for ['[CLS] these once ofents intensive course vu [SEP]']
[Init] best rec loss: 0.8068182468414307 for ['[CLS] over breed [CLS] mentioned pitched genus memories [SEP]']
[Init] best rec loss: 0.7839474081993103 for ['[CLS] house chi browningchia himalayan audience appeal [SEP]']
[Init] best rec loss: 0.7613614201545715 for ['[CLS] " head rifle hate moved course youth [SEP]']
[Init] best rec loss: 0.7518348693847656 for ['[CLS] gravel shooter promotion rios press eve voyage [SEP]']
[Init] best rec loss: 0.738399863243103 for ['[CLS] 2002 faso tone averaged category wave doubt [SEP]']
[Init] best rec loss: 0.7359643578529358 for ['[CLS] sorry multi care by sherlock relief google [SEP]']
[Init] best perm rec loss: 0.7308405041694641 for ['[CLS] google multi sorry sherlock relief care by [SEP]']
[Init] best perm rec loss: 0.7285928726196289 for ['[CLS] care sorry by sherlock multi relief google [SEP]']
[Init] best perm rec loss: 0.7279585003852844 for ['[CLS] multi by sorry care google relief sherlock [SEP]']
[Init] best perm rec loss: 0.7274588346481323 for ['[CLS] multi care by sherlock sorry relief google [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.391 (perp=10.428, rec=0.281, cos=0.024), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] helped. by themville until hungry [SEP]']
[ 100/2000] tot_loss=1.823 (perp=8.044, rec=0.190, cos=0.025), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] himself said him himself was that hungry [SEP]']
[ 150/2000] tot_loss=1.512 (perp=6.918, rec=0.104, cos=0.024), tot_loss_proj:2.198 [t=0.17s]
prediction: ['[CLS] himself said he himself was that hungry [SEP]']
[ 200/2000] tot_loss=1.494 (perp=6.918, rec=0.088, cos=0.023), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] himself said he himself was that hungry [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.709 (perp=7.883, rec=0.109, cos=0.023), tot_loss_proj:2.991 [t=0.17s]
prediction: ['[CLS] that said he himself wasgingly hungry [SEP]']
[ 300/2000] tot_loss=1.515 (perp=7.044, rec=0.084, cos=0.023), tot_loss_proj:2.697 [t=0.17s]
prediction: ['[CLS] that said he himself was. hungry [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.155 (perp=5.257, rec=0.082, cos=0.022), tot_loss_proj:2.298 [t=0.17s]
prediction: ['[CLS] that said he himself was hungry. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.039 (perp=4.646, rec=0.087, cos=0.023), tot_loss_proj:1.131 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 450/2000] tot_loss=1.034 (perp=4.646, rec=0.083, cos=0.022), tot_loss_proj:1.138 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.037 (perp=4.646, rec=0.086, cos=0.021), tot_loss_proj:1.123 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.032 (perp=4.646, rec=0.082, cos=0.021), tot_loss_proj:1.121 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 600/2000] tot_loss=1.031 (perp=4.646, rec=0.080, cos=0.022), tot_loss_proj:1.130 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.025 (perp=4.646, rec=0.074, cos=0.021), tot_loss_proj:1.127 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.016 (perp=4.646, rec=0.065, cos=0.021), tot_loss_proj:1.123 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 750/2000] tot_loss=1.024 (perp=4.646, rec=0.073, cos=0.021), tot_loss_proj:1.129 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.014 (perp=4.646, rec=0.064, cos=0.021), tot_loss_proj:1.125 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.021 (perp=4.646, rec=0.071, cos=0.021), tot_loss_proj:1.123 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 900/2000] tot_loss=1.028 (perp=4.646, rec=0.077, cos=0.021), tot_loss_proj:1.128 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.027 (perp=4.646, rec=0.076, cos=0.022), tot_loss_proj:1.126 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.026 (perp=4.646, rec=0.075, cos=0.022), tot_loss_proj:1.118 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1050/2000] tot_loss=1.019 (perp=4.646, rec=0.068, cos=0.022), tot_loss_proj:1.125 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.027 (perp=4.646, rec=0.077, cos=0.022), tot_loss_proj:1.118 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.014 (perp=4.646, rec=0.064, cos=0.022), tot_loss_proj:1.124 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1200/2000] tot_loss=1.026 (perp=4.646, rec=0.075, cos=0.022), tot_loss_proj:1.128 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.025 (perp=4.646, rec=0.074, cos=0.022), tot_loss_proj:1.118 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.014 (perp=4.646, rec=0.063, cos=0.022), tot_loss_proj:1.125 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1350/2000] tot_loss=1.023 (perp=4.646, rec=0.073, cos=0.022), tot_loss_proj:1.127 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.009 (perp=4.646, rec=0.059, cos=0.022), tot_loss_proj:1.126 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.020 (perp=4.646, rec=0.070, cos=0.022), tot_loss_proj:1.117 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1500/2000] tot_loss=1.020 (perp=4.646, rec=0.069, cos=0.022), tot_loss_proj:1.134 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.025 (perp=4.646, rec=0.074, cos=0.022), tot_loss_proj:1.118 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.020 (perp=4.646, rec=0.069, cos=0.022), tot_loss_proj:1.117 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1650/2000] tot_loss=1.033 (perp=4.646, rec=0.082, cos=0.022), tot_loss_proj:1.122 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.021 (perp=4.646, rec=0.071, cos=0.022), tot_loss_proj:1.117 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.013 (perp=4.646, rec=0.062, cos=0.022), tot_loss_proj:1.119 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1800/2000] tot_loss=1.023 (perp=4.646, rec=0.073, cos=0.022), tot_loss_proj:1.119 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.024 (perp=4.646, rec=0.074, cos=0.022), tot_loss_proj:1.119 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.012 (perp=4.646, rec=0.061, cos=0.022), tot_loss_proj:1.109 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1950/2000] tot_loss=1.027 (perp=4.646, rec=0.076, cos=0.022), tot_loss_proj:1.137 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.021 (perp=4.646, rec=0.070, cos=0.022), tot_loss_proj:1.124 [t=0.17s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] he said that himself was hungry. [SEP]
========================
predicted: 
========================
[CLS] he said that himself was hungry. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 78.437 | p: 78.826 | r: 78.410
rouge2     | fm: 36.429 | p: 36.140 | r: 36.852
rougeL     | fm: 65.731 | p: 65.895 | r: 65.712
rougeLsum  | fm: 65.691 | p: 66.019 | r: 65.738
r1fm+r2fm = 114.867

input #53 time: 0:06:52 | total time: 6:18:38


Running input #54 of 100.
reference: 
========================
After reading the pamphlet, Judy threw them into the garbage can.
========================
Sample: 0 1.2494981412203098e-10 0.048988266295717155 0.343227
average of cosine similarity 0.9897618784209152
highest_index [0]
highest [0.9897618784209152]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  2044,  3752,  1996, 19899,  1010, 12120,  4711,  2068,  2046,
          1996, 13044,  2064,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]']
[Init] best rec loss: 1.0086065530776978 for ['[CLS]position unavailable reporter wink zero do leaning double declared temple swift 2012 fine [SEP]']
[Init] best rec loss: 0.9829070568084717 for ['[CLS] crop jagger occurred badly oil alike destination [ session show sunrisehita you [SEP]']
[Init] best rec loss: 0.9422270059585571 for ['[CLS] electvic push warehouse humor aboutpiece lock eponymousgrant prison measure even [SEP]']
[Init] best rec loss: 0.9266153573989868 for ['[CLS] edward gwen daily ever consideredards erminafar quad river given why [SEP]']
[Init] best rec loss: 0.9201857447624207 for ['[CLS] eve battalion minutes strike twinned trip bond candidatesiarangleib lame macedonia [SEP]']
[Init] best rec loss: 0.9138299226760864 for ['[CLS]chi £ our melbourne back [MASK] damtec isn jake hangbution a [SEP]']
[Init] best rec loss: 0.9105693697929382 for ['[CLS]abyrase fin self beers graphic concentration rise odd coolerus sex flying [SEP]']
[Init] best perm rec loss: 0.9102561473846436 for ['[CLS] sex self graphic odd fin rise coolaby flying beersraseerus concentration [SEP]']
[Init] best perm rec loss: 0.9093592762947083 for ['[CLS] flying concentration odd fin graphicerus coolaby self sex beers riserase [SEP]']
[Init] best perm rec loss: 0.9088178873062134 for ['[CLS] rise beers odd self fin flyingrase graphic sexerusaby cool concentration [SEP]']
[Init] best perm rec loss: 0.9084143042564392 for ['[CLS] concentration coolaby self odd riseerus fin sexrase beers flying graphic [SEP]']
[Init] best perm rec loss: 0.9079568982124329 for ['[CLS] concentration riseerus fin graphicaby self oddrase sex flying beers cool [SEP]']
[Init] best perm rec loss: 0.9070364832878113 for ['[CLS]raseerus graphic cool fin selfaby beers flying sex concentration odd rise [SEP]']
[Init] best perm rec loss: 0.9065402150154114 for ['[CLS] graphic rise odd selfrase flying sex fin cool beersaby concentrationerus [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.878 (perp=11.759, rec=0.602, cos=0.925), tot_loss_proj:4.250 [t=0.17s]
prediction: ['[CLS]. book candle effectiveness loudly inquired describe beating,inginging freestyleginal [SEP]']
[ 100/2000] tot_loss=2.698 (perp=11.656, rec=0.300, cos=0.067), tot_loss_proj:4.238 [t=0.17s]
prediction: ['[CLS] included reading pamphlet activists photo threw them throwrish into? in katharine [SEP]']
[ 150/2000] tot_loss=2.507 (perp=11.353, rec=0.198, cos=0.038), tot_loss_proj:4.192 [t=0.17s]
prediction: ['[CLS] included reading pamphletʔ judy pamphlet them threw. into into. katharine [SEP]']
[ 200/2000] tot_loss=2.324 (perp=10.722, rec=0.152, cos=0.027), tot_loss_proj:4.056 [t=0.17s]
prediction: ['[CLS] after reading pamphlet subsequent judy reading them threw. into into. garbage [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.778 (perp=11.379, rec=0.399, cos=0.103), tot_loss_proj:4.198 [t=0.17s]
prediction: ['[CLS]rs reading pamphletbroken judy reading them threw →ers landed - black [SEP]']
[ 300/2000] tot_loss=2.469 (perp=10.800, rec=0.267, cos=0.042), tot_loss_proj:4.076 [t=0.17s]
prediction: ['[CLS]fide the pamphlet defeated judy reading them threw window debris into - black [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.106 (perp=9.318, rec=0.210, cos=0.033), tot_loss_proj:3.801 [t=0.19s]
prediction: ['[CLS] when the pamphlet window judy reading them threw vocal debris into - black [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.951 (perp=8.695, rec=0.182, cos=0.030), tot_loss_proj:3.650 [t=0.19s]
prediction: ['[CLS] when the pamphlet window black reading them threw vocal garbage into - judy [SEP]']
[ 450/2000] tot_loss=1.929 (perp=8.694, rec=0.162, cos=0.028), tot_loss_proj:3.641 [t=0.19s]
prediction: ['[CLS] after the pamphlet window black reading them threw vocal garbage into - judy [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.062 (perp=9.398, rec=0.155, cos=0.027), tot_loss_proj:3.764 [t=0.19s]
prediction: ['[CLS] after the pamphlet window black reading them threw during into into - judy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.965 (perp=8.938, rec=0.153, cos=0.024), tot_loss_proj:3.667 [t=0.19s]
prediction: ['[CLS] after the pamphlet furnace a reading them threw after black into - judy [SEP]']
[ 600/2000] tot_loss=1.967 (perp=8.923, rec=0.158, cos=0.025), tot_loss_proj:3.656 [t=0.19s]
prediction: ['[CLS] after the pamphlet furnace into reading them threw onto black into - judy [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.055 (perp=9.384, rec=0.153, cos=0.025), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] after the pamphletworth into reading threw afterward them l into - judy [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.988 (perp=9.106, rec=0.143, cos=0.024), tot_loss_proj:3.734 [t=0.17s]
prediction: ['[CLS] after the pamphlet garbage into reading them afterward threw l into garbage judy [SEP]']
[ 750/2000] tot_loss=2.005 (perp=9.214, rec=0.139, cos=0.023), tot_loss_proj:3.729 [t=0.17s]
prediction: ['[CLS] after the pamphlet garbage into reading them onto threw l into garbage judy [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.917 (perp=8.810, rec=0.130, cos=0.024), tot_loss_proj:3.635 [t=0.17s]
prediction: ['[CLS] after the pamphlet threw into reading them onto garbage l into garbage judy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.980 (perp=9.135, rec=0.129, cos=0.024), tot_loss_proj:3.713 [t=0.17s]
prediction: ['[CLS] after the pamphlet threw into reading them afterward garbage l into garbage judy [SEP]']
[ 900/2000] tot_loss=1.981 (perp=9.135, rec=0.130, cos=0.024), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] after the pamphlet threw into reading them afterward garbage l into garbage judy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.978 (perp=9.135, rec=0.127, cos=0.024), tot_loss_proj:3.716 [t=0.17s]
prediction: ['[CLS] after the pamphlet threw into reading them afterward garbage l into garbage judy [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.906 (perp=8.776, rec=0.126, cos=0.025), tot_loss_proj:3.679 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward garbage threw into garbage judy [SEP]']
[1050/2000] tot_loss=1.903 (perp=8.776, rec=0.123, cos=0.024), tot_loss_proj:3.684 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward garbage threw into garbage judy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.903 (perp=8.776, rec=0.124, cos=0.024), tot_loss_proj:3.683 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward garbage threw into garbage judy [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.880 (perp=8.694, rec=0.117, cos=0.024), tot_loss_proj:3.677 [t=0.18s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
[1200/2000] tot_loss=1.894 (perp=8.694, rec=0.132, cos=0.024), tot_loss_proj:3.679 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.882 (perp=8.694, rec=0.120, cos=0.024), tot_loss_proj:3.683 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.884 (perp=8.694, rec=0.121, cos=0.024), tot_loss_proj:3.688 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
[1350/2000] tot_loss=1.873 (perp=8.694, rec=0.111, cos=0.024), tot_loss_proj:3.687 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.886 (perp=8.694, rec=0.123, cos=0.024), tot_loss_proj:3.681 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.882 (perp=8.694, rec=0.119, cos=0.024), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
[1500/2000] tot_loss=1.887 (perp=8.694, rec=0.124, cos=0.024), tot_loss_proj:3.677 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.880 (perp=8.694, rec=0.117, cos=0.024), tot_loss_proj:3.679 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.879 (perp=8.694, rec=0.116, cos=0.024), tot_loss_proj:3.685 [t=0.19s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
[1650/2000] tot_loss=1.873 (perp=8.694, rec=0.110, cos=0.024), tot_loss_proj:3.682 [t=0.19s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.872 (perp=8.694, rec=0.109, cos=0.024), tot_loss_proj:3.681 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.877 (perp=8.694, rec=0.114, cos=0.024), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
[1800/2000] tot_loss=1.873 (perp=8.694, rec=0.111, cos=0.024), tot_loss_proj:3.686 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.877 (perp=8.694, rec=0.115, cos=0.024), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.879 (perp=8.694, rec=0.116, cos=0.024), tot_loss_proj:3.685 [t=0.19s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
[1950/2000] tot_loss=1.890 (perp=8.694, rec=0.128, cos=0.024), tot_loss_proj:3.683 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.874 (perp=8.694, rec=0.111, cos=0.024), tot_loss_proj:3.683 [t=0.17s]
prediction: ['[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]
========================
predicted: 
========================
[CLS] after the pamphlet l into reading them afterward threw garbage into garbage judy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 73.333 | r: 84.615
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 57.143 | p: 53.333 | r: 61.538
rougeLsum  | fm: 57.143 | p: 53.333 | r: 61.538
r1fm+r2fm = 93.956

[Aggregate metrics]:
rouge1     | fm: 78.507 | p: 78.748 | r: 78.559
rouge2     | fm: 36.253 | p: 35.954 | r: 36.607
rougeL     | fm: 65.375 | p: 65.516 | r: 65.525
rougeLsum  | fm: 65.524 | p: 65.738 | r: 65.554
r1fm+r2fm = 114.760

input #54 time: 0:07:10 | total time: 6:25:49


Running input #55 of 100.
reference: 
========================
Collapsed Harry.
========================
Sample: 0 1.3597862061582066e-12 0.04859554137372386 0.35645807
average of cosine similarity 0.9906636330936966
highest_index [0]
highest [0.9906636330936966]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 7798, 4302, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] collapsed harry. [SEP]']
[Init] best rec loss: 0.9055206179618835 for ['[CLS] taken dana once [SEP]']
[Init] best rec loss: 0.8123528957366943 for ['[CLS] information op respect [SEP]']
[Init] best rec loss: 0.7759804129600525 for ['[CLS] lorieyer marrow [SEP]']
[Init] best rec loss: 0.723248302936554 for ['[CLS] class atlantic martins [SEP]']
[Init] best rec loss: 0.718425452709198 for ['[CLS] these how conditioning [SEP]']
[Init] best rec loss: 0.7074264287948608 for ['[CLS] coup pace lila [SEP]']
[Init] best rec loss: 0.6903390884399414 for ['[CLS] mage sharing roman [SEP]']
[Init] best perm rec loss: 0.6879101395606995 for ['[CLS] mage roman sharing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.176 (perp=13.044, rec=0.485, cos=0.082), tot_loss_proj:3.444 [t=0.17s]
prediction: ['[CLS] strength collapsed clyde [SEP]']
[ 100/2000] tot_loss=3.084 (perp=13.094, rec=0.279, cos=0.186), tot_loss_proj:3.487 [t=0.17s]
prediction: ['[CLS]tension collapsed harry [SEP]']
[ 150/2000] tot_loss=2.630 (perp=12.184, rec=0.152, cos=0.042), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] harry collapsed harry [SEP]']
[ 200/2000] tot_loss=2.616 (perp=12.184, rec=0.138, cos=0.041), tot_loss_proj:3.386 [t=0.17s]
prediction: ['[CLS] harry collapsed harry [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.316 (perp=10.807, rec=0.124, cos=0.030), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] harry harry collapsed [SEP]']
[ 300/2000] tot_loss=2.427 (perp=10.807, rec=0.220, cos=0.045), tot_loss_proj:3.349 [t=0.17s]
prediction: ['[CLS] harry harry collapsed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.299 (perp=10.807, rec=0.110, cos=0.027), tot_loss_proj:3.217 [t=0.17s]
prediction: ['[CLS] harry harry collapsed [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=2.439 (perp=10.982, rec=0.178, cos=0.064), tot_loss_proj:3.377 [t=0.17s]
prediction: ['[CLS] collapsed harry harry [SEP]']
[ 450/2000] tot_loss=2.338 (perp=10.982, rec=0.114, cos=0.028), tot_loss_proj:3.442 [t=0.17s]
prediction: ['[CLS] collapsed harry harry [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.310 (perp=10.982, rec=0.090, cos=0.024), tot_loss_proj:3.425 [t=0.17s]
prediction: ['[CLS] collapsed harry harry [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.306 (perp=10.982, rec=0.088, cos=0.022), tot_loss_proj:3.419 [t=0.17s]
prediction: ['[CLS] collapsed harry harry [SEP]']
[ 600/2000] tot_loss=2.000 (perp=9.472, rec=0.086, cos=0.020), tot_loss_proj:3.910 [t=0.17s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.269 (perp=9.208, rec=0.328, cos=0.100), tot_loss_proj:3.004 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.168 (perp=9.208, rec=0.258, cos=0.069), tot_loss_proj:3.011 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
[ 750/2000] tot_loss=2.122 (perp=9.208, rec=0.231, cos=0.049), tot_loss_proj:3.026 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.078 (perp=9.208, rec=0.197, cos=0.039), tot_loss_proj:3.018 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.075 (perp=9.208, rec=0.199, cos=0.034), tot_loss_proj:3.012 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
[ 900/2000] tot_loss=2.046 (perp=9.208, rec=0.173, cos=0.031), tot_loss_proj:3.011 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.044 (perp=9.208, rec=0.174, cos=0.028), tot_loss_proj:3.017 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.032 (perp=9.208, rec=0.164, cos=0.027), tot_loss_proj:3.008 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1050/2000] tot_loss=2.032 (perp=9.208, rec=0.164, cos=0.026), tot_loss_proj:3.007 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.034 (perp=9.208, rec=0.167, cos=0.026), tot_loss_proj:3.007 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.028 (perp=9.208, rec=0.162, cos=0.025), tot_loss_proj:3.003 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1200/2000] tot_loss=2.025 (perp=9.208, rec=0.158, cos=0.025), tot_loss_proj:3.013 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.021 (perp=9.208, rec=0.155, cos=0.024), tot_loss_proj:3.000 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.022 (perp=9.208, rec=0.156, cos=0.024), tot_loss_proj:3.001 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1350/2000] tot_loss=2.010 (perp=9.208, rec=0.145, cos=0.024), tot_loss_proj:3.019 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.004 (perp=9.208, rec=0.139, cos=0.024), tot_loss_proj:3.012 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.020 (perp=9.208, rec=0.155, cos=0.024), tot_loss_proj:3.009 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1500/2000] tot_loss=2.007 (perp=9.208, rec=0.142, cos=0.024), tot_loss_proj:3.004 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.011 (perp=9.208, rec=0.146, cos=0.023), tot_loss_proj:3.000 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.009 (perp=9.208, rec=0.144, cos=0.023), tot_loss_proj:3.011 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1650/2000] tot_loss=2.018 (perp=9.208, rec=0.153, cos=0.023), tot_loss_proj:3.014 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.005 (perp=9.208, rec=0.141, cos=0.023), tot_loss_proj:3.007 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.011 (perp=9.208, rec=0.146, cos=0.023), tot_loss_proj:3.006 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1800/2000] tot_loss=2.010 (perp=9.208, rec=0.145, cos=0.023), tot_loss_proj:2.998 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.993 (perp=9.208, rec=0.128, cos=0.023), tot_loss_proj:3.013 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.996 (perp=9.208, rec=0.132, cos=0.023), tot_loss_proj:3.014 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
[1950/2000] tot_loss=1.999 (perp=9.208, rec=0.135, cos=0.023), tot_loss_proj:3.002 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.013 (perp=9.208, rec=0.149, cos=0.022), tot_loss_proj:3.013 [t=0.17s]
prediction: ['[CLS] collapsed harry. [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] collapsed harry. [SEP]
========================
predicted: 
========================
[CLS] collapsed. harry [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 78.904 | p: 79.167 | r: 78.915
rouge2     | fm: 37.279 | p: 37.033 | r: 37.726
rougeL     | fm: 66.067 | p: 66.323 | r: 66.189
rougeLsum  | fm: 66.148 | p: 66.344 | r: 66.250
r1fm+r2fm = 116.183

input #55 time: 0:06:47 | total time: 6:32:37


Running input #56 of 100.
reference: 
========================
John was seeing his children.
========================
Sample: 0 1.0411335070143175e-11 0.05830258309838134 0.355649
average of cosine similarity 0.9864714873860576
highest_index [0]
highest [0.9864714873860576]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2198, 2001, 3773, 2010, 2336, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john was seeing his children. [SEP]']
[Init] best rec loss: 0.9693037271499634 for ['[CLS] vampire artists at like edge into [SEP]']
[Init] best rec loss: 0.9084345102310181 for ['[CLS] banned scout fadeper residence nursery [SEP]']
[Init] best perm rec loss: 0.9078051447868347 for ['[CLS] banned residence fade scoutper nursery [SEP]']
[Init] best perm rec loss: 0.9077329635620117 for ['[CLS] scout nursery residence bannedper fade [SEP]']
[Init] best perm rec loss: 0.9056980013847351 for ['[CLS] residence fade nurseryper banned scout [SEP]']
[Init] best perm rec loss: 0.9053595662117004 for ['[CLS] residence fade bannedper scout nursery [SEP]']
[Init] best perm rec loss: 0.9046943187713623 for ['[CLS] banned residence fade scout nurseryper [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.916 (perp=11.487, rec=0.632, cos=0.986), tot_loss_proj:4.088 [t=0.17s]
prediction: ['[CLS] mind so?ney son jerk [SEP]']
[ 100/2000] tot_loss=2.077 (perp=8.177, rec=0.355, cos=0.087), tot_loss_proj:3.547 [t=0.17s]
prediction: ['[CLS] see john thinking john is. [SEP]']
[ 150/2000] tot_loss=2.125 (perp=9.229, rec=0.235, cos=0.044), tot_loss_proj:3.607 [t=0.17s]
prediction: ['[CLS] seeing john was john children was [SEP]']
[ 200/2000] tot_loss=2.034 (perp=9.333, rec=0.133, cos=0.035), tot_loss_proj:3.620 [t=0.17s]
prediction: ['[CLS] seeing john was william children is [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.892 (perp=8.639, rec=0.130, cos=0.034), tot_loss_proj:3.491 [t=0.17s]
prediction: ['[CLS] seeing john was children william is [SEP]']
[ 300/2000] tot_loss=1.962 (perp=9.049, rec=0.119, cos=0.034), tot_loss_proj:3.554 [t=0.17s]
prediction: ['[CLS] seeing john was children william of [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.644 (perp=7.432, rec=0.123, cos=0.034), tot_loss_proj:3.240 [t=0.17s]
prediction: ['[CLS] seeing john was children of william [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.678 (perp=7.678, rec=0.108, cos=0.034), tot_loss_proj:3.318 [t=0.17s]
prediction: ['[CLS] seeing was children ; john william [SEP]']
[ 450/2000] tot_loss=1.662 (perp=7.591, rec=0.110, cos=0.033), tot_loss_proj:3.272 [t=0.17s]
prediction: ['[CLS] seeing was children. john william [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.645 (perp=7.591, rec=0.094, cos=0.033), tot_loss_proj:3.269 [t=0.17s]
prediction: ['[CLS] seeing was children. john william [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.654 (perp=7.591, rec=0.104, cos=0.033), tot_loss_proj:3.267 [t=0.17s]
prediction: ['[CLS] seeing was children. john william [SEP]']
[ 600/2000] tot_loss=1.656 (perp=7.591, rec=0.105, cos=0.033), tot_loss_proj:3.265 [t=0.17s]
prediction: ['[CLS] seeing was children. john william [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.643 (perp=7.591, rec=0.092, cos=0.033), tot_loss_proj:3.271 [t=0.17s]
prediction: ['[CLS] seeing was children. john william [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.637 (perp=7.591, rec=0.086, cos=0.033), tot_loss_proj:3.264 [t=0.17s]
prediction: ['[CLS] seeing was children. john william [SEP]']
[ 750/2000] tot_loss=1.874 (perp=8.708, rec=0.100, cos=0.033), tot_loss_proj:3.437 [t=0.17s]
prediction: ['[CLS] seeing was children. john his [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.835 (perp=8.543, rec=0.098, cos=0.028), tot_loss_proj:3.426 [t=0.17s]
prediction: ['[CLS] seeing was william children. john [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.400 (perp=6.410, rec=0.089, cos=0.028), tot_loss_proj:3.058 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
[ 900/2000] tot_loss=1.393 (perp=6.410, rec=0.082, cos=0.029), tot_loss_proj:3.058 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.405 (perp=6.410, rec=0.095, cos=0.029), tot_loss_proj:3.058 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.390 (perp=6.410, rec=0.080, cos=0.028), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
[1050/2000] tot_loss=1.391 (perp=6.410, rec=0.081, cos=0.028), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.390 (perp=6.410, rec=0.080, cos=0.027), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.383 (perp=6.410, rec=0.074, cos=0.027), tot_loss_proj:3.060 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
[1200/2000] tot_loss=1.388 (perp=6.410, rec=0.079, cos=0.027), tot_loss_proj:3.056 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.396 (perp=6.410, rec=0.088, cos=0.027), tot_loss_proj:3.065 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.381 (perp=6.410, rec=0.072, cos=0.026), tot_loss_proj:3.058 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
[1350/2000] tot_loss=1.376 (perp=6.410, rec=0.067, cos=0.026), tot_loss_proj:3.060 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.381 (perp=6.410, rec=0.073, cos=0.026), tot_loss_proj:3.066 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.395 (perp=6.410, rec=0.087, cos=0.026), tot_loss_proj:3.061 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
[1500/2000] tot_loss=1.373 (perp=6.410, rec=0.065, cos=0.026), tot_loss_proj:3.060 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.380 (perp=6.410, rec=0.072, cos=0.026), tot_loss_proj:3.061 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.386 (perp=6.410, rec=0.078, cos=0.026), tot_loss_proj:3.063 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
[1650/2000] tot_loss=1.382 (perp=6.410, rec=0.074, cos=0.026), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.384 (perp=6.410, rec=0.076, cos=0.026), tot_loss_proj:3.056 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.374 (perp=6.410, rec=0.066, cos=0.026), tot_loss_proj:3.063 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
[1800/2000] tot_loss=1.374 (perp=6.410, rec=0.066, cos=0.026), tot_loss_proj:3.058 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.378 (perp=6.410, rec=0.070, cos=0.026), tot_loss_proj:3.061 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.381 (perp=6.410, rec=0.073, cos=0.026), tot_loss_proj:3.063 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
[1950/2000] tot_loss=1.381 (perp=6.410, rec=0.073, cos=0.026), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.371 (perp=6.410, rec=0.063, cos=0.026), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS] seeing was his children john. [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] john was seeing his children. [SEP]
========================
predicted: 
========================
[CLS] seeing was his children john. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 116.667

[Aggregate metrics]:
rouge1     | fm: 79.263 | p: 79.529 | r: 79.300
rouge2     | fm: 36.853 | p: 36.568 | r: 37.325
rougeL     | fm: 66.053 | p: 66.221 | r: 66.109
rougeLsum  | fm: 66.307 | p: 66.499 | r: 66.410
r1fm+r2fm = 116.116

input #56 time: 0:07:00 | total time: 6:39:37


Running input #57 of 100.
reference: 
========================
Carla mopped the floor under the furniture.
========================
Sample: 0 4.996129428275298e-13 0.043131749126379175 0.32397497
average of cosine similarity 0.9910981878092575
highest_index [0]
highest [0.9910981878092575]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 17081,  9587, 11469,  1996,  2723,  2104,  1996,  7390,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] carla mopped the floor under the furniture. [SEP]']
[Init] best rec loss: 0.9423267245292664 for ['[CLS]ne gathering do their health retirement go enforce things [SEP]']
[Init] best rec loss: 0.9340547919273376 for ['[CLS]kes second loose late west allied creation utility evelyn [SEP]']
[Init] best rec loss: 0.9054117202758789 for ['[CLS]quent quadrant material seat inclusion kn difference vincent stubborn [SEP]']
[Init] best rec loss: 0.8925279974937439 for ['[CLS] mari guy identity episode use formsorescence nm fit [SEP]']
[Init] best rec loss: 0.8883852958679199 for ['[CLS] jack itself cheers elevation back sharing volunteeredthan solid [SEP]']
[Init] best perm rec loss: 0.8876361846923828 for ['[CLS] itself elevation back jack sharing solid volunteeredthan cheers [SEP]']
[Init] best perm rec loss: 0.8854588270187378 for ['[CLS] jack elevation back solid sharing cheers itself volunteeredthan [SEP]']
[Init] best perm rec loss: 0.8849825859069824 for ['[CLS] sharing jackthan cheers volunteered solid itself back elevation [SEP]']
[Init] best perm rec loss: 0.8849116563796997 for ['[CLS] back solid cheers jack elevation itselfthan volunteered sharing [SEP]']
[Init] best perm rec loss: 0.8840395212173462 for ['[CLS] itselfthan jack volunteered cheers solid sharing elevation back [SEP]']
[Init] best perm rec loss: 0.8835548162460327 for ['[CLS] solid cheers back elevation itself sharingthan jack volunteered [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.223 (perp=11.800, rec=0.553, cos=0.310), tot_loss_proj:4.228 [t=0.17s]
prediction: ['[CLS] cut jaw players almost coach dating player via finance [SEP]']
[ 100/2000] tot_loss=3.561 (perp=14.531, rec=0.480, cos=0.175), tot_loss_proj:4.763 [t=0.17s]
prediction: ['[CLS] throwing let victor mock carla played playerchi gravel [SEP]']
[ 150/2000] tot_loss=3.199 (perp=13.979, rec=0.340, cos=0.063), tot_loss_proj:4.625 [t=0.17s]
prediction: ['[CLS] sacked let victorrangle carlapped football carla floor [SEP]']
[ 200/2000] tot_loss=2.725 (perp=12.084, rec=0.270, cos=0.038), tot_loss_proj:4.302 [t=0.17s]
prediction: ['[CLS] spaces importantly carla mo carlapped floor carla floor [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.810 (perp=12.093, rec=0.322, cos=0.069), tot_loss_proj:4.296 [t=0.17s]
prediction: ['[CLS] let carla mo carlapped floor carla yards ground [SEP]']
[ 300/2000] tot_loss=2.841 (perp=12.363, rec=0.292, cos=0.077), tot_loss_proj:4.293 [t=0.17s]
prediction: ['[CLS] let carla mo carlapped floor carla beside under [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.694 (perp=12.131, rec=0.231, cos=0.036), tot_loss_proj:4.279 [t=0.17s]
prediction: ['[CLS] let carla mo carlapped floor beneath carla under [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.434 (perp=10.882, rec=0.222, cos=0.036), tot_loss_proj:4.030 [t=0.17s]
prediction: ['[CLS] carla letting carla mopped floor under carla under [SEP]']
[ 450/2000] tot_loss=2.424 (perp=10.882, rec=0.211, cos=0.037), tot_loss_proj:4.028 [t=0.17s]
prediction: ['[CLS] carla letting carla mopped floor under carla under [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.331 (perp=10.515, rec=0.198, cos=0.030), tot_loss_proj:3.965 [t=0.17s]
prediction: ['[CLS] carla letting carla mopped carla under floor foundation [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.256 (perp=10.239, rec=0.179, cos=0.029), tot_loss_proj:3.928 [t=0.17s]
prediction: ['[CLS] carla letting carla mopped carla under foundation floor [SEP]']
[ 600/2000] tot_loss=2.403 (perp=10.999, rec=0.176, cos=0.028), tot_loss_proj:4.088 [t=0.17s]
prediction: ['[CLS] carla letting carla mopped carla under taft floor [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.329 (perp=10.699, rec=0.162, cos=0.027), tot_loss_proj:4.018 [t=0.17s]
prediction: ['[CLS] carla letting carla mopped carla under floor taft [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.542 (perp=11.484, rec=0.202, cos=0.043), tot_loss_proj:4.170 [t=0.17s]
prediction: ['[CLS] overall carla carla mopped carla under floor taft [SEP]']
[ 750/2000] tot_loss=2.497 (perp=11.508, rec=0.166, cos=0.030), tot_loss_proj:4.185 [t=0.17s]
prediction: ['[CLS] overall carla carla mopped carla under floor reserve [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.406 (perp=11.026, rec=0.168, cos=0.032), tot_loss_proj:4.072 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped carla under floor reserve [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.307 (perp=10.633, rec=0.150, cos=0.030), tot_loss_proj:3.985 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped carla under reserve floor [SEP]']
[ 900/2000] tot_loss=2.308 (perp=10.633, rec=0.154, cos=0.028), tot_loss_proj:3.988 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped carla under reserve floor [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.289 (perp=10.591, rec=0.143, cos=0.027), tot_loss_proj:3.962 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped. under reserve floor [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.465 (perp=11.352, rec=0.161, cos=0.034), tot_loss_proj:4.175 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor carla [SEP]']
[1050/2000] tot_loss=2.444 (perp=11.352, rec=0.144, cos=0.029), tot_loss_proj:4.174 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor carla [SEP]']
Attempt swap
[1100/2000] tot_loss=2.193 (perp=10.117, rec=0.141, cos=0.028), tot_loss_proj:3.935 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.192 (perp=10.117, rec=0.141, cos=0.027), tot_loss_proj:3.941 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
[1200/2000] tot_loss=2.192 (perp=10.117, rec=0.141, cos=0.027), tot_loss_proj:3.938 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.191 (perp=10.117, rec=0.141, cos=0.027), tot_loss_proj:3.938 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.174 (perp=10.117, rec=0.123, cos=0.027), tot_loss_proj:3.936 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
[1350/2000] tot_loss=2.192 (perp=10.117, rec=0.141, cos=0.027), tot_loss_proj:3.941 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.186 (perp=10.117, rec=0.136, cos=0.027), tot_loss_proj:3.938 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.180 (perp=10.117, rec=0.130, cos=0.027), tot_loss_proj:3.943 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
[1500/2000] tot_loss=2.178 (perp=10.117, rec=0.128, cos=0.026), tot_loss_proj:3.938 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.178 (perp=10.117, rec=0.128, cos=0.026), tot_loss_proj:3.941 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.183 (perp=10.117, rec=0.133, cos=0.026), tot_loss_proj:3.939 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
[1650/2000] tot_loss=2.186 (perp=10.117, rec=0.137, cos=0.026), tot_loss_proj:3.941 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.190 (perp=10.117, rec=0.140, cos=0.026), tot_loss_proj:3.939 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.183 (perp=10.117, rec=0.133, cos=0.026), tot_loss_proj:3.938 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
[1800/2000] tot_loss=2.180 (perp=10.117, rec=0.131, cos=0.026), tot_loss_proj:3.934 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.182 (perp=10.117, rec=0.133, cos=0.026), tot_loss_proj:3.940 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.181 (perp=10.117, rec=0.131, cos=0.026), tot_loss_proj:3.943 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
[1950/2000] tot_loss=2.181 (perp=10.117, rec=0.131, cos=0.026), tot_loss_proj:3.937 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.171 (perp=10.117, rec=0.122, cos=0.026), tot_loss_proj:3.939 [t=0.17s]
prediction: ['[CLS] carla carla overall mopped under reserve floor. [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] carla mopped the floor under the furniture. [SEP]
========================
predicted: 
========================
[CLS] carla carla overall mopped under reserve floor. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 79.167

[Aggregate metrics]:
rouge1     | fm: 79.063 | p: 79.364 | r: 79.100
rouge2     | fm: 36.642 | p: 36.354 | r: 37.058
rougeL     | fm: 65.920 | p: 66.161 | r: 66.004
rougeLsum  | fm: 66.042 | p: 66.191 | r: 66.235
r1fm+r2fm = 115.704

input #57 time: 0:07:02 | total time: 6:46:40


Running input #58 of 100.
reference: 
========================
They expected us to should leave him.
========================
Sample: 0 3.996439554858808e-13 0.04815553460507343 0.34536454
average of cosine similarity 0.9902313997289791
highest_index [0]
highest [0.9902313997289791]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2027, 3517, 2149, 2000, 2323, 2681, 2032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] they expected us to should leave him. [SEP]']
[Init] best rec loss: 1.01006019115448 for ['[CLS] like cal hazard far indiangence pair rolled [SEP]']
[Init] best rec loss: 0.9678995013237 for ['[CLS] suit agent special small crack still try cases [SEP]']
[Init] best rec loss: 0.7499859929084778 for ['[CLS] michellevable moved lottery fold °f ask collectively [SEP]']
[Init] best rec loss: 0.7345256805419922 for ['[CLS] fore primary pcs publishing source pu ra germany [SEP]']
[Init] best rec loss: 0.7178595662117004 for ['[CLS] cartoon bastionional pulitzer implant camp assistance away [SEP]']
[Init] best rec loss: 0.7141168117523193 for ['[CLS] satellite cum deserves specialized saw shoteral town [SEP]']
[Init] best perm rec loss: 0.7126652598381042 for ['[CLS] deserves shot town saw specialized satellite cumeral [SEP]']
[Init] best perm rec loss: 0.7116402387619019 for ['[CLS] cum town satellite deserves shot saweral specialized [SEP]']
[Init] best perm rec loss: 0.7094566226005554 for ['[CLS] shot cum deserves saweral town specialized satellite [SEP]']
[Init] best perm rec loss: 0.7093368172645569 for ['[CLS] specialized saw satellite cum shot town deserveseral [SEP]']
[Init] best perm rec loss: 0.7073099613189697 for ['[CLS] satellite shot deserves specialized cumeral town saw [SEP]']
[Init] best perm rec loss: 0.7069427371025085 for ['[CLS] deserves satellite town shot cumeral specialized saw [SEP]']
[Init] best perm rec loss: 0.7052599787712097 for ['[CLS] cum deserves shot towneral specialized satellite saw [SEP]']
[Init] best perm rec loss: 0.70352703332901 for ['[CLS] cum shot town satellite deserves saw specializederal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.522 (perp=10.634, rec=0.333, cos=0.062), tot_loss_proj:3.238 [t=0.17s]
prediction: ['[CLS] self shouldons pressure should shouldked. [SEP]']
[ 100/2000] tot_loss=2.448 (perp=8.563, rec=0.492, cos=0.243), tot_loss_proj:3.077 [t=0.17s]
prediction: ['[CLS] icelandic. immediately would should should upset. [SEP]']
[ 150/2000] tot_loss=1.810 (perp=7.416, rec=0.266, cos=0.060), tot_loss_proj:2.329 [t=0.17s]
prediction: ['[CLS] had they they would should should leave. [SEP]']
[ 200/2000] tot_loss=1.795 (perp=7.652, rec=0.218, cos=0.047), tot_loss_proj:2.626 [t=0.17s]
prediction: ['[CLS] had they to would should should leave. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.186 (perp=8.467, rec=0.393, cos=0.100), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] does they hormones to should should leave. [SEP]']
[ 300/2000] tot_loss=1.548 (perp=6.053, rec=0.280, cos=0.057), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] should they expected to should should leave. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.583 (perp=6.616, rec=0.213, cos=0.046), tot_loss_proj:2.411 [t=0.17s]
prediction: ['[CLS] to they expected to should should leave. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.435 (perp=5.967, rec=0.196, cos=0.045), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] should they expected to should to leave. [SEP]']
[ 450/2000] tot_loss=1.406 (perp=5.967, rec=0.170, cos=0.043), tot_loss_proj:2.182 [t=0.17s]
prediction: ['[CLS] should they expected to should to leave. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.377 (perp=5.967, rec=0.143, cos=0.041), tot_loss_proj:2.181 [t=0.17s]
prediction: ['[CLS] should they expected to should to leave. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.343 (perp=5.823, rec=0.143, cos=0.035), tot_loss_proj:1.907 [t=0.17s]
prediction: ['[CLS] should they expected to should leave us. [SEP]']
[ 600/2000] tot_loss=1.305 (perp=5.823, rec=0.110, cos=0.030), tot_loss_proj:1.910 [t=0.17s]
prediction: ['[CLS] should they expected to should leave us. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.314 (perp=5.823, rec=0.121, cos=0.029), tot_loss_proj:1.908 [t=0.17s]
prediction: ['[CLS] should they expected to should leave us. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.303 (perp=5.823, rec=0.110, cos=0.028), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] should they expected to should leave us. [SEP]']
[ 750/2000] tot_loss=1.299 (perp=5.823, rec=0.106, cos=0.028), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] should they expected to should leave us. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.294 (perp=5.823, rec=0.101, cos=0.028), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] should they expected to should leave us. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.280 (perp=5.699, rec=0.108, cos=0.033), tot_loss_proj:2.201 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
[ 900/2000] tot_loss=1.270 (perp=5.699, rec=0.102, cos=0.028), tot_loss_proj:2.193 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.272 (perp=5.699, rec=0.105, cos=0.028), tot_loss_proj:2.178 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.267 (perp=5.699, rec=0.100, cos=0.028), tot_loss_proj:2.189 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
[1050/2000] tot_loss=1.266 (perp=5.699, rec=0.099, cos=0.028), tot_loss_proj:2.189 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.264 (perp=5.699, rec=0.097, cos=0.027), tot_loss_proj:2.185 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.265 (perp=5.699, rec=0.098, cos=0.027), tot_loss_proj:2.182 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
[1200/2000] tot_loss=1.262 (perp=5.699, rec=0.095, cos=0.027), tot_loss_proj:2.187 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.266 (perp=5.699, rec=0.099, cos=0.027), tot_loss_proj:2.190 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.267 (perp=5.699, rec=0.100, cos=0.027), tot_loss_proj:2.181 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
[1350/2000] tot_loss=1.261 (perp=5.699, rec=0.094, cos=0.027), tot_loss_proj:2.187 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.262 (perp=5.699, rec=0.095, cos=0.027), tot_loss_proj:2.183 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.252 (perp=5.699, rec=0.085, cos=0.027), tot_loss_proj:2.187 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
[1500/2000] tot_loss=1.262 (perp=5.699, rec=0.095, cos=0.027), tot_loss_proj:2.185 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.262 (perp=5.699, rec=0.095, cos=0.027), tot_loss_proj:2.186 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.260 (perp=5.699, rec=0.093, cos=0.027), tot_loss_proj:2.192 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
[1650/2000] tot_loss=1.262 (perp=5.699, rec=0.095, cos=0.027), tot_loss_proj:2.189 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.260 (perp=5.699, rec=0.093, cos=0.027), tot_loss_proj:2.190 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.262 (perp=5.699, rec=0.095, cos=0.027), tot_loss_proj:2.193 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
[1800/2000] tot_loss=1.264 (perp=5.699, rec=0.097, cos=0.027), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.261 (perp=5.699, rec=0.095, cos=0.027), tot_loss_proj:2.191 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.262 (perp=5.699, rec=0.096, cos=0.027), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
[1950/2000] tot_loss=1.257 (perp=5.699, rec=0.090, cos=0.027), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.267 (perp=5.699, rec=0.100, cos=0.027), tot_loss_proj:2.191 [t=0.17s]
prediction: ['[CLS] should they expected us to should leave. [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] they expected us to should leave him. [SEP]
========================
predicted: 
========================
[CLS] should they expected us to should leave. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 151.389

[Aggregate metrics]:
rouge1     | fm: 79.306 | p: 79.500 | r: 79.368
rouge2     | fm: 37.119 | p: 36.843 | r: 37.495
rougeL     | fm: 66.322 | p: 66.438 | r: 66.415
rougeLsum  | fm: 66.527 | p: 66.732 | r: 66.657
r1fm+r2fm = 116.425

input #58 time: 0:06:51 | total time: 6:53:31


Running input #59 of 100.
reference: 
========================
Mr Woodhouse sat in an armchair.
========================
Sample: 0 6.180647973988944e-13 0.04759936473433145 0.29337433
average of cosine similarity 0.9867500356121262
highest_index [0]
highest [0.9867500356121262]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2720,  3536,  4580,  2938,  1999,  2019, 29372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[Init] best rec loss: 1.0133568048477173 for ['[CLS] zero treasurer kennedy vet when le bronze plans [SEP]']
[Init] best rec loss: 0.9783481359481812 for ['[CLS] greenbis wa ant chamber disks distinguishednine [SEP]']
[Init] best rec loss: 0.9641304016113281 for ['[CLS] geraldine draft side everythingion lack hamlet react [SEP]']
[Init] best rec loss: 0.9588362574577332 for ['[CLS] poll citizen heads chapter nor giants alec cinder [SEP]']
[Init] best rec loss: 0.9540868997573853 for ['[CLS] survivors tend bounce visitors guessed nomination miles independence [SEP]']
[Init] best rec loss: 0.9535396099090576 for ['[CLS] jaw sega indians no dug columbia tribe throughout [SEP]']
[Init] best perm rec loss: 0.9530171751976013 for ['[CLS] tribe throughout jaw sega dug columbia indians no [SEP]']
[Init] best perm rec loss: 0.9528425931930542 for ['[CLS] jaw tribe throughout sega columbia indians no dug [SEP]']
[Init] best perm rec loss: 0.9518237709999084 for ['[CLS] dug indians sega jaw columbia throughout tribe no [SEP]']
[Init] best perm rec loss: 0.9487836956977844 for ['[CLS] sega indians tribe dug jaw columbia no throughout [SEP]']
[Init] best perm rec loss: 0.9484539031982422 for ['[CLS] jaw dug throughout indians columbia no tribe sega [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.811 (perp=10.589, rec=0.497, cos=0.196), tot_loss_proj:3.953 [t=0.17s]
prediction: ['[CLS] 000 poor men party mitchell order deal earlier [SEP]']
[ 100/2000] tot_loss=2.425 (perp=10.308, rec=0.302, cos=0.061), tot_loss_proj:3.881 [t=0.17s]
prediction: ['[CLS] mr portuguese at party jacket sat deal pri [SEP]']
[ 150/2000] tot_loss=2.443 (perp=11.066, rec=0.193, cos=0.037), tot_loss_proj:4.125 [t=0.17s]
prediction: ['[CLS] mr indian at partyhouse sat deal an [SEP]']
[ 200/2000] tot_loss=2.421 (perp=11.106, rec=0.166, cos=0.034), tot_loss_proj:4.058 [t=0.17s]
prediction: ['[CLS] mr indian horseback armchairhouse sat deal an [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.083 (perp=9.605, rec=0.133, cos=0.030), tot_loss_proj:3.790 [t=0.17s]
prediction: ['[CLS] mr indian in armchairhouse deal sat an [SEP]']
[ 300/2000] tot_loss=1.766 (perp=8.089, rec=0.120, cos=0.029), tot_loss_proj:3.453 [t=0.17s]
prediction: ['[CLS] mr wood in armchairhouse deal sat. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.734 (perp=7.987, rec=0.108, cos=0.028), tot_loss_proj:3.513 [t=0.17s]
prediction: ['[CLS] mr wood in armchair sat dealhouse. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.709 (perp=7.987, rec=0.084, cos=0.028), tot_loss_proj:3.511 [t=0.17s]
prediction: ['[CLS] mr wood in armchair sat dealhouse. [SEP]']
[ 450/2000] tot_loss=1.710 (perp=7.987, rec=0.085, cos=0.027), tot_loss_proj:3.517 [t=0.17s]
prediction: ['[CLS] mr wood in armchair sat dealhouse. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.716 (perp=7.987, rec=0.091, cos=0.027), tot_loss_proj:3.514 [t=0.17s]
prediction: ['[CLS] mr wood in armchair sat dealhouse. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.710 (perp=7.987, rec=0.086, cos=0.027), tot_loss_proj:3.519 [t=0.17s]
prediction: ['[CLS] mr wood in armchair sat dealhouse. [SEP]']
[ 600/2000] tot_loss=1.713 (perp=7.987, rec=0.088, cos=0.027), tot_loss_proj:3.519 [t=0.17s]
prediction: ['[CLS] mr wood in armchair sat dealhouse. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.708 (perp=7.987, rec=0.083, cos=0.027), tot_loss_proj:3.514 [t=0.17s]
prediction: ['[CLS] mr wood in armchair sat dealhouse. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.723 (perp=7.987, rec=0.098, cos=0.027), tot_loss_proj:3.513 [t=0.17s]
prediction: ['[CLS] mr wood in armchair sat dealhouse. [SEP]']
[ 750/2000] tot_loss=1.702 (perp=7.987, rec=0.077, cos=0.027), tot_loss_proj:3.514 [t=0.17s]
prediction: ['[CLS] mr wood in armchair sat dealhouse. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.712 (perp=7.987, rec=0.088, cos=0.027), tot_loss_proj:3.523 [t=0.17s]
prediction: ['[CLS] mr wood in armchair sat dealhouse. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.719 (perp=8.028, rec=0.086, cos=0.028), tot_loss_proj:3.566 [t=0.17s]
prediction: ['[CLS] mr wood armchair sat in upperhouse. [SEP]']
[ 900/2000] tot_loss=1.726 (perp=8.028, rec=0.093, cos=0.028), tot_loss_proj:3.572 [t=0.17s]
prediction: ['[CLS] mr wood armchair sat in upperhouse. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.428 (perp=6.580, rec=0.084, cos=0.028), tot_loss_proj:3.108 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.439 (perp=6.580, rec=0.095, cos=0.027), tot_loss_proj:3.116 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
[1050/2000] tot_loss=1.425 (perp=6.580, rec=0.081, cos=0.027), tot_loss_proj:3.116 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.419 (perp=6.580, rec=0.075, cos=0.027), tot_loss_proj:3.107 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.416 (perp=6.580, rec=0.073, cos=0.027), tot_loss_proj:3.119 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
[1200/2000] tot_loss=1.417 (perp=6.580, rec=0.074, cos=0.027), tot_loss_proj:3.110 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.420 (perp=6.580, rec=0.077, cos=0.027), tot_loss_proj:3.115 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.418 (perp=6.580, rec=0.075, cos=0.027), tot_loss_proj:3.108 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
[1350/2000] tot_loss=1.420 (perp=6.580, rec=0.077, cos=0.027), tot_loss_proj:3.116 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.432 (perp=6.580, rec=0.089, cos=0.027), tot_loss_proj:3.113 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.415 (perp=6.580, rec=0.072, cos=0.027), tot_loss_proj:3.109 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
[1500/2000] tot_loss=1.410 (perp=6.580, rec=0.067, cos=0.027), tot_loss_proj:3.109 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.422 (perp=6.580, rec=0.078, cos=0.027), tot_loss_proj:3.111 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.420 (perp=6.580, rec=0.077, cos=0.027), tot_loss_proj:3.116 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
[1650/2000] tot_loss=1.417 (perp=6.580, rec=0.074, cos=0.027), tot_loss_proj:3.115 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.428 (perp=6.580, rec=0.085, cos=0.027), tot_loss_proj:3.113 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.421 (perp=6.580, rec=0.078, cos=0.027), tot_loss_proj:3.107 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in upper armchair. [SEP]']
[1800/2000] tot_loss=1.178 (perp=5.368, rec=0.077, cos=0.027), tot_loss_proj:1.346 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.176 (perp=5.368, rec=0.075, cos=0.027), tot_loss_proj:1.341 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.181 (perp=5.368, rec=0.080, cos=0.027), tot_loss_proj:1.330 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[1950/2000] tot_loss=1.180 (perp=5.368, rec=0.079, cos=0.027), tot_loss_proj:1.345 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.181 (perp=5.368, rec=0.080, cos=0.027), tot_loss_proj:1.330 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] mr woodhouse sat in an armchair. [SEP]
========================
predicted: 
========================
[CLS] mr woodhouse sat in an armchair. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 79.591 | p: 79.815 | r: 79.623
rouge2     | fm: 38.099 | p: 37.777 | r: 38.512
rougeL     | fm: 66.832 | p: 67.049 | r: 66.904
rougeLsum  | fm: 67.024 | p: 67.184 | r: 67.096
r1fm+r2fm = 117.690

input #59 time: 0:06:47 | total time: 7:00:19


Running input #60 of 100.
reference: 
========================
It is likely that Jean left.
========================
Sample: 0 2.1902134690720915e-12 0.04982698914018009 0.35318676
average of cosine similarity 0.9899984836602869
highest_index [0]
highest [0.9899984836602869]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2009, 2003, 3497, 2008, 3744, 2187, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] it is likely that jean left. [SEP]']
[Init] best rec loss: 1.0610324144363403 for ['[CLS]ach called vision sea age include wren [SEP]']
[Init] best rec loss: 0.9535291790962219 for ['[CLS] blue returnedisen within zur immediateores [SEP]']
[Init] best rec loss: 0.9524242281913757 for ['[CLS] threw presley dependent state safetyending hood [SEP]']
[Init] best rec loss: 0.9489620923995972 for ['[CLS] hazardous least thumbs politically play w contrast [SEP]']
[Init] best rec loss: 0.9254016876220703 for ['[CLS] knight cass labor force cap inspiration time [SEP]']
[Init] best perm rec loss: 0.9237791299819946 for ['[CLS] time cap labor inspiration knight cass force [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.735 (perp=9.398, rec=0.567, cos=0.289), tot_loss_proj:3.652 [t=0.17s]
prediction: ['[CLS] jean, playing victim that ) because [SEP]']
[ 100/2000] tot_loss=2.119 (perp=8.837, rec=0.306, cos=0.046), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] jean. happened either probably even that [SEP]']
[ 150/2000] tot_loss=2.309 (perp=10.381, rec=0.201, cos=0.031), tot_loss_proj:3.858 [t=0.17s]
prediction: ['[CLS] jean. left likely likely left that [SEP]']
[ 200/2000] tot_loss=1.991 (perp=9.171, rec=0.132, cos=0.025), tot_loss_proj:3.591 [t=0.17s]
prediction: ['[CLS] jean. left likely likely. that [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.385 (perp=9.857, rec=0.348, cos=0.066), tot_loss_proj:3.767 [t=0.17s]
prediction: ['[CLS] jean. left that likely likely humans [SEP]']
[ 300/2000] tot_loss=2.265 (perp=9.775, rec=0.264, cos=0.046), tot_loss_proj:3.785 [t=0.17s]
prediction: ['[CLS] jean probably left that it likely rachel [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.250 (perp=10.193, rec=0.182, cos=0.029), tot_loss_proj:3.807 [t=0.17s]
prediction: ['[CLS] jean probably likely that is left intention [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.794 (perp=7.966, rec=0.173, cos=0.028), tot_loss_proj:3.354 [t=0.17s]
prediction: ['[CLS] jean probably is likely that left jean [SEP]']
[ 450/2000] tot_loss=1.765 (perp=7.966, rec=0.144, cos=0.028), tot_loss_proj:3.351 [t=0.17s]
prediction: ['[CLS] jean probably is likely that left jean [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.688 (perp=7.598, rec=0.141, cos=0.027), tot_loss_proj:3.262 [t=0.17s]
prediction: ['[CLS] jean is probably likely that left jean [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.653 (perp=7.422, rec=0.142, cos=0.026), tot_loss_proj:3.669 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
[ 600/2000] tot_loss=1.642 (perp=7.422, rec=0.132, cos=0.026), tot_loss_proj:3.672 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.637 (perp=7.422, rec=0.127, cos=0.026), tot_loss_proj:3.674 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.628 (perp=7.422, rec=0.118, cos=0.026), tot_loss_proj:3.669 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
[ 750/2000] tot_loss=1.642 (perp=7.422, rec=0.132, cos=0.025), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.629 (perp=7.422, rec=0.120, cos=0.025), tot_loss_proj:3.672 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.629 (perp=7.422, rec=0.119, cos=0.025), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
[ 900/2000] tot_loss=1.620 (perp=7.422, rec=0.111, cos=0.025), tot_loss_proj:3.680 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.632 (perp=7.422, rec=0.122, cos=0.025), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1000/2000] tot_loss=1.622 (perp=7.422, rec=0.113, cos=0.025), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
[1050/2000] tot_loss=1.622 (perp=7.422, rec=0.112, cos=0.025), tot_loss_proj:3.671 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1100/2000] tot_loss=1.621 (perp=7.422, rec=0.111, cos=0.025), tot_loss_proj:3.677 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1150/2000] tot_loss=1.611 (perp=7.422, rec=0.101, cos=0.025), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
[1200/2000] tot_loss=1.627 (perp=7.422, rec=0.117, cos=0.025), tot_loss_proj:3.667 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1250/2000] tot_loss=1.604 (perp=7.422, rec=0.094, cos=0.025), tot_loss_proj:3.668 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1300/2000] tot_loss=1.617 (perp=7.422, rec=0.108, cos=0.025), tot_loss_proj:3.672 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
[1350/2000] tot_loss=1.618 (perp=7.422, rec=0.108, cos=0.025), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1400/2000] tot_loss=1.616 (perp=7.422, rec=0.106, cos=0.025), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1450/2000] tot_loss=1.610 (perp=7.422, rec=0.101, cos=0.025), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
[1500/2000] tot_loss=1.615 (perp=7.422, rec=0.105, cos=0.025), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1550/2000] tot_loss=1.614 (perp=7.422, rec=0.104, cos=0.025), tot_loss_proj:3.673 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1600/2000] tot_loss=1.623 (perp=7.422, rec=0.114, cos=0.026), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
[1650/2000] tot_loss=1.613 (perp=7.422, rec=0.103, cos=0.026), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1700/2000] tot_loss=1.617 (perp=7.422, rec=0.107, cos=0.026), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1750/2000] tot_loss=1.625 (perp=7.422, rec=0.115, cos=0.026), tot_loss_proj:3.668 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
[1800/2000] tot_loss=1.611 (perp=7.422, rec=0.101, cos=0.026), tot_loss_proj:3.673 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1850/2000] tot_loss=1.611 (perp=7.422, rec=0.101, cos=0.026), tot_loss_proj:3.674 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[1900/2000] tot_loss=1.616 (perp=7.422, rec=0.106, cos=0.026), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
[1950/2000] tot_loss=1.620 (perp=7.422, rec=0.110, cos=0.026), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Attempt swap
[2000/2000] tot_loss=1.616 (perp=7.422, rec=0.106, cos=0.026), tot_loss_proj:3.665 [t=0.17s]
prediction: ['[CLS] jean is probably likely that jean left [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] it is likely that jean left. [SEP]
========================
predicted: 
========================
[CLS] jean is probably likely that jean left [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 53.333 | p: 50.000 | r: 57.143
rougeL     | fm: 82.353 | p: 77.778 | r: 87.500
rougeLsum  | fm: 82.353 | p: 77.778 | r: 87.500
r1fm+r2fm = 135.686

[Aggregate metrics]:
rouge1     | fm: 79.512 | p: 79.799 | r: 79.648
rouge2     | fm: 38.132 | p: 37.759 | r: 38.684
rougeL     | fm: 67.087 | p: 67.190 | r: 67.281
rougeLsum  | fm: 67.222 | p: 67.355 | r: 67.421
r1fm+r2fm = 117.644

input #60 time: 0:06:53 | total time: 7:07:12


Running input #61 of 100.
reference: 
========================
Physicists like yourself are a godsend.
========================
Sample: 0 8.278762057770847e-12 0.05241860108615287 0.34948853
average of cosine similarity 0.9886880429835991
highest_index [0]
highest [0.9886880429835991]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 13702,  2015,  2066,  4426,  2024,  1037,  5932, 10497,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] physicists like yourself are a godsend. [SEP]']
[Init] best rec loss: 0.9368430376052856 for ['[CLS]serromatic rescue object morning which viable for seeking [SEP]']
[Init] best rec loss: 0.9271156191825867 for ['[CLS] realmsᵇ group mac en whoever " administrator canvas [SEP]']
[Init] best rec loss: 0.9082102179527283 for ['[CLS] bombardment symptoms ul memorial were worked gray haiti know [SEP]']
[Init] best rec loss: 0.9022470712661743 for ['[CLS] fixed commissioner manual church off stem pickup lips austin [SEP]']
[Init] best rec loss: 0.8885534405708313 for ['[CLS] first parental bill julius orthodox thank orson what knock [SEP]']
[Init] best perm rec loss: 0.8879454731941223 for ['[CLS] orson knock first thank julius bill parental what orthodox [SEP]']
[Init] best perm rec loss: 0.8876521587371826 for ['[CLS] parental what julius knock bill orthodox first thank orson [SEP]']
[Init] best perm rec loss: 0.8857608437538147 for ['[CLS] knock bill thank parental julius orthodox orson first what [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.737 (perp=11.386, rec=0.570, cos=0.890), tot_loss_proj:4.176 [t=0.17s]
prediction: ['[CLS] nouns. we like lexie vegas lucivar herself themselves [SEP]']
[ 100/2000] tot_loss=4.212 (perp=13.273, rec=0.635, cos=0.923), tot_loss_proj:4.649 [t=0.17s]
prediction: ['[CLS] kimballssee vampires like bold emeritus goddamn yourself themselves [SEP]']
[ 150/2000] tot_loss=4.322 (perp=14.221, rec=0.559, cos=0.919), tot_loss_proj:4.772 [t=0.17s]
prediction: ['[CLS] mussolini! physicist like attendance am charging yourselfbution [SEP]']
[ 200/2000] tot_loss=3.883 (perp=12.868, rec=0.431, cos=0.879), tot_loss_proj:4.530 [t=0.17s]
prediction: ['[CLS]ₙ. physicist like brow am rental yourselfbution [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.696 (perp=12.136, rec=0.475, cos=0.794), tot_loss_proj:4.338 [t=0.17s]
prediction: ['[CLS] milfordbution physicist like aregible doug yourself. [SEP]']
[ 300/2000] tot_loss=3.666 (perp=12.711, rec=0.533, cos=0.591), tot_loss_proj:4.471 [t=0.17s]
prediction: ['[CLS] milford 龸 physicist like brow behalf doug yourself. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.972 (perp=12.648, rec=0.315, cos=0.128), tot_loss_proj:4.457 [t=0.17s]
prediction: ['[CLS] terminology ী physicist likeoteric namely... yourself. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.367 (perp=10.013, rec=0.281, cos=0.084), tot_loss_proj:3.913 [t=0.17s]
prediction: ['[CLS] myself happens are creatures... physicist like yourself. [SEP]']
[ 450/2000] tot_loss=2.227 (perp=9.819, rec=0.217, cos=0.047), tot_loss_proj:3.875 [t=0.17s]
prediction: ['[CLS] himself coincidence arehaven. physicist like yourself. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.404 (perp=10.764, rec=0.205, cos=0.046), tot_loss_proj:4.082 [t=0.17s]
prediction: ['[CLS] himselfoteric physicisthaven are physicist like yourself. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.149 (perp=8.605, rec=0.311, cos=0.116), tot_loss_proj:3.621 [t=0.17s]
prediction: ['[CLS] myselfoteric physicist physicist are physicist like yourself. [SEP]']
[ 600/2000] tot_loss=2.096 (perp=9.156, rec=0.214, cos=0.050), tot_loss_proj:3.726 [t=0.17s]
prediction: ['[CLS] myselfoteric physicist physicist are physicist like yourself ; [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.870 (perp=8.231, rec=0.180, cos=0.043), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] myselfoteric physicist physicist physicist are like yourself. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.876 (perp=8.231, rec=0.190, cos=0.039), tot_loss_proj:3.543 [t=0.17s]
prediction: ['[CLS] myselfoteric physicist physicist physicist are like yourself. [SEP]']
[ 750/2000] tot_loss=1.859 (perp=8.231, rec=0.176, cos=0.037), tot_loss_proj:3.546 [t=0.17s]
prediction: ['[CLS] myselfoteric physicist physicist physicist are like yourself. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.200 (perp=9.944, rec=0.176, cos=0.035), tot_loss_proj:3.893 [t=0.17s]
prediction: ['[CLS] yourselfotericfolk physicist physicist are like yourself. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.045 (perp=8.963, rec=0.193, cos=0.059), tot_loss_proj:3.690 [t=0.17s]
prediction: ['[CLS] yourself physicist physicist physicistfolk are like yourself. [SEP]']
[ 900/2000] tot_loss=1.914 (perp=8.564, rec=0.165, cos=0.036), tot_loss_proj:3.642 [t=0.17s]
prediction: ['[CLS] myself physicist physicist physicistfolk are like yourself. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.916 (perp=8.564, rec=0.167, cos=0.036), tot_loss_proj:3.645 [t=0.17s]
prediction: ['[CLS] myself physicist physicist physicistfolk are like yourself. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.905 (perp=8.564, rec=0.158, cos=0.034), tot_loss_proj:3.643 [t=0.17s]
prediction: ['[CLS] myself physicist physicist physicistfolk are like yourself. [SEP]']
[1050/2000] tot_loss=1.991 (perp=8.963, rec=0.165, cos=0.033), tot_loss_proj:3.691 [t=0.17s]
prediction: ['[CLS] yourself physicist physicist physicistfolk are like yourself. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.990 (perp=8.963, rec=0.165, cos=0.032), tot_loss_proj:3.695 [t=0.17s]
prediction: ['[CLS] yourself physicist physicist physicistfolk are like yourself. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.796 (perp=8.038, rec=0.155, cos=0.034), tot_loss_proj:3.470 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
[1200/2000] tot_loss=1.812 (perp=8.038, rec=0.173, cos=0.032), tot_loss_proj:3.466 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.782 (perp=8.038, rec=0.143, cos=0.031), tot_loss_proj:3.463 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.800 (perp=8.038, rec=0.160, cos=0.032), tot_loss_proj:3.466 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
[1350/2000] tot_loss=1.799 (perp=8.038, rec=0.161, cos=0.031), tot_loss_proj:3.466 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.801 (perp=8.038, rec=0.163, cos=0.030), tot_loss_proj:3.468 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.806 (perp=8.038, rec=0.169, cos=0.030), tot_loss_proj:3.466 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
[1500/2000] tot_loss=1.792 (perp=8.038, rec=0.155, cos=0.030), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.795 (perp=8.038, rec=0.158, cos=0.030), tot_loss_proj:3.470 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.791 (perp=8.038, rec=0.154, cos=0.030), tot_loss_proj:3.467 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
[1650/2000] tot_loss=1.788 (perp=8.038, rec=0.151, cos=0.029), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.786 (perp=8.038, rec=0.149, cos=0.029), tot_loss_proj:3.470 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.789 (perp=8.038, rec=0.152, cos=0.029), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
[1800/2000] tot_loss=1.782 (perp=8.038, rec=0.146, cos=0.029), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.793 (perp=8.038, rec=0.156, cos=0.029), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.791 (perp=8.038, rec=0.154, cos=0.030), tot_loss_proj:3.468 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
[1950/2000] tot_loss=1.782 (perp=8.038, rec=0.145, cos=0.029), tot_loss_proj:3.470 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.780 (perp=8.038, rec=0.143, cos=0.029), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS] physicists like yourself are a godsend. [SEP]
========================
predicted: 
========================
[CLS] like physicist physicist physicistfolk are yourself yourself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.824 | p: 55.556 | r: 62.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.059 | p: 44.444 | r: 50.000
rougeLsum  | fm: 47.059 | p: 44.444 | r: 50.000
r1fm+r2fm = 58.824

[Aggregate metrics]:
rouge1     | fm: 79.312 | p: 79.423 | r: 79.558
rouge2     | fm: 37.725 | p: 37.439 | r: 38.264
rougeL     | fm: 66.743 | p: 66.737 | r: 66.965
rougeLsum  | fm: 67.006 | p: 67.013 | r: 67.200
r1fm+r2fm = 117.037

input #61 time: 0:06:46 | total time: 7:13:59


Running input #62 of 100.
reference: 
========================
Any pilot could be flying this plane.
========================
Sample: 0 1.6369583512265902e-11 0.040914055601817025 0.3244081
average of cosine similarity 0.9920150184507704
highest_index [0]
highest [0.9920150184507704]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2151, 4405, 2071, 2022, 3909, 2023, 4946, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] any pilot could be flying this plane. [SEP]']
[Init] best rec loss: 0.9977968335151672 for ['[CLS] events heat names cole issue. 505 regina [SEP]']
[Init] best rec loss: 0.9175378084182739 for ['[CLS] from actress le testament sooner pit confederacy oct [SEP]']
[Init] best rec loss: 0.8922759890556335 for ['[CLS]liest into holding complained discovery sutherland coast fork [SEP]']
[Init] best rec loss: 0.8342140913009644 for ['[CLS] reader leagues english our place guestfire mad [SEP]']
[Init] best perm rec loss: 0.8291640281677246 for ['[CLS] mad place englishfire our guest leagues reader [SEP]']
[Init] best perm rec loss: 0.8275080919265747 for ['[CLS] guest reader english place mad leagues ourfire [SEP]']
[Init] best perm rec loss: 0.824095606803894 for ['[CLS]fire guest english leagues mad our reader place [SEP]']
[Init] best perm rec loss: 0.823464035987854 for ['[CLS] mad guestfire leagues reader our english place [SEP]']
[Init] best perm rec loss: 0.8207629323005676 for ['[CLS] our readerfire mad guest leagues place english [SEP]']
[Init] best perm rec loss: 0.8206089735031128 for ['[CLS]fire guest mad our reader leagues place english [SEP]']
[Init] best perm rec loss: 0.8204890489578247 for ['[CLS] reader guest english leaguesfire our place mad [SEP]']
[Init] best perm rec loss: 0.8204536437988281 for ['[CLS] reader leagues english guest our place madfire [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.225 (perp=12.100, rec=0.524, cos=0.281), tot_loss_proj:4.379 [t=0.17s]
prediction: ['[CLS]jack wanted magic rock saw wonderful step fancy [SEP]']
[ 100/2000] tot_loss=2.943 (perp=12.029, rec=0.398, cos=0.139), tot_loss_proj:4.256 [t=0.17s]
prediction: ['[CLS] 男 wanted magic spirit saw wonderful man fancy [SEP]']
[ 150/2000] tot_loss=2.563 (perp=10.537, rec=0.352, cos=0.103), tot_loss_proj:3.946 [t=0.17s]
prediction: ['[CLS] them wanted jersey art saw wonderful every. [SEP]']
[ 200/2000] tot_loss=2.608 (perp=11.135, rec=0.303, cos=0.078), tot_loss_proj:4.079 [t=0.17s]
prediction: ['[CLS] them wanted flying voice instantly wonderful every. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.382 (perp=9.504, rec=0.352, cos=0.129), tot_loss_proj:3.816 [t=0.17s]
prediction: ['[CLS] wanted them flying call model really a. [SEP]']
[ 300/2000] tot_loss=2.394 (perp=10.071, rec=0.288, cos=0.092), tot_loss_proj:3.910 [t=0.17s]
prediction: ['[CLS] could them flying call human really this. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.032 (perp=8.663, rec=0.242, cos=0.057), tot_loss_proj:3.690 [t=0.17s]
prediction: ['[CLS] could them really call human flying this. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.100 (perp=8.029, rec=0.351, cos=0.143), tot_loss_proj:3.164 [t=0.17s]
prediction: ['[CLS] could anyone really shout this flying brain. [SEP]']
[ 450/2000] tot_loss=2.010 (perp=8.546, rec=0.246, cos=0.056), tot_loss_proj:3.720 [t=0.17s]
prediction: ['[CLS] could any really shout this flying precision. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.928 (perp=8.362, rec=0.214, cos=0.041), tot_loss_proj:3.692 [t=0.17s]
prediction: ['[CLS] any could really soundtrack this flying pilot. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.558 (perp=6.665, rec=0.189, cos=0.036), tot_loss_proj:3.312 [t=0.17s]
prediction: ['[CLS] any could really carry this flying pilot. [SEP]']
[ 600/2000] tot_loss=1.657 (perp=7.245, rec=0.174, cos=0.034), tot_loss_proj:3.457 [t=0.17s]
prediction: ['[CLS] any could really pilot this flying pilot. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.648 (perp=7.245, rec=0.166, cos=0.033), tot_loss_proj:3.454 [t=0.17s]
prediction: ['[CLS] any could really pilot this flying pilot. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.753 (perp=7.791, rec=0.163, cos=0.032), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] any could flying pilot this flying pilot. [SEP]']
[ 750/2000] tot_loss=1.740 (perp=7.791, rec=0.151, cos=0.031), tot_loss_proj:3.509 [t=0.17s]
prediction: ['[CLS] any could flying pilot this flying pilot. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.507 (perp=6.681, rec=0.139, cos=0.031), tot_loss_proj:2.890 [t=0.17s]
prediction: ['[CLS] any pilot could really pilot this flying. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.504 (perp=6.681, rec=0.138, cos=0.030), tot_loss_proj:2.900 [t=0.17s]
prediction: ['[CLS] any pilot could really pilot this flying. [SEP]']
[ 900/2000] tot_loss=1.591 (perp=7.115, rec=0.139, cos=0.029), tot_loss_proj:3.358 [t=0.17s]
prediction: ['[CLS] any pilot could flying pilot this flying. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.533 (perp=6.876, rec=0.130, cos=0.028), tot_loss_proj:3.346 [t=0.17s]
prediction: ['[CLS] any pilot flying could flying this flying. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.522 (perp=6.744, rec=0.145, cos=0.028), tot_loss_proj:3.327 [t=0.17s]
prediction: ['[CLS] any flying pilot could flying this flying. [SEP]']
[1050/2000] tot_loss=1.247 (perp=5.457, rec=0.128, cos=0.028), tot_loss_proj:3.065 [t=0.17s]
prediction: ['[CLS] any flying pilot could flying this plane. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.518 (perp=6.832, rec=0.124, cos=0.027), tot_loss_proj:3.279 [t=0.17s]
prediction: ['[CLS] any be pilot could flying this plane. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.372 (perp=6.024, rec=0.137, cos=0.030), tot_loss_proj:3.199 [t=0.17s]
prediction: ['[CLS] any pilot could flying flying this plane. [SEP]']
[1200/2000] tot_loss=1.125 (perp=4.831, rec=0.131, cos=0.028), tot_loss_proj:1.134 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.120 (perp=4.831, rec=0.126, cos=0.027), tot_loss_proj:1.142 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.108 (perp=4.831, rec=0.114, cos=0.027), tot_loss_proj:1.140 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
[1350/2000] tot_loss=1.119 (perp=4.831, rec=0.126, cos=0.027), tot_loss_proj:1.136 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.125 (perp=4.831, rec=0.132, cos=0.027), tot_loss_proj:1.128 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.110 (perp=4.831, rec=0.117, cos=0.027), tot_loss_proj:1.138 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
[1500/2000] tot_loss=1.115 (perp=4.831, rec=0.122, cos=0.027), tot_loss_proj:1.134 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.118 (perp=4.831, rec=0.124, cos=0.027), tot_loss_proj:1.137 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.112 (perp=4.831, rec=0.119, cos=0.027), tot_loss_proj:1.137 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
[1650/2000] tot_loss=1.111 (perp=4.831, rec=0.118, cos=0.027), tot_loss_proj:1.129 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.102 (perp=4.831, rec=0.109, cos=0.027), tot_loss_proj:1.129 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.106 (perp=4.831, rec=0.113, cos=0.027), tot_loss_proj:1.137 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
[1800/2000] tot_loss=1.107 (perp=4.831, rec=0.115, cos=0.027), tot_loss_proj:1.129 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.114 (perp=4.831, rec=0.121, cos=0.027), tot_loss_proj:1.131 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.100 (perp=4.831, rec=0.107, cos=0.027), tot_loss_proj:1.137 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
[1950/2000] tot_loss=1.112 (perp=4.831, rec=0.119, cos=0.027), tot_loss_proj:1.146 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.111 (perp=4.831, rec=0.119, cos=0.027), tot_loss_proj:1.145 [t=0.17s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] any pilot could be flying this plane. [SEP]
========================
predicted: 
========================
[CLS] any pilot could be flying this plane. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 79.650 | p: 79.656 | r: 79.856
rouge2     | fm: 38.564 | p: 38.269 | r: 39.111
rougeL     | fm: 67.204 | p: 67.261 | r: 67.501
rougeLsum  | fm: 67.446 | p: 67.470 | r: 67.634
r1fm+r2fm = 118.214

input #62 time: 0:06:45 | total time: 7:20:45


Running input #63 of 100.
reference: 
========================
We wonder if Bill left.
========================
Sample: 0 1.2722608522969456e-12 0.051843745188180294 0.33660987
average of cosine similarity 0.9880681716086526
highest_index [0]
highest [0.9880681716086526]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2057, 4687, 2065, 3021, 2187, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] we wonder if bill left. [SEP]']
[Init] best rec loss: 0.9412387609481812 for ['[CLS] affected maine effect streets studies its [SEP]']
[Init] best rec loss: 0.9324620366096497 for ['[CLS]creen past effortwn can pier [SEP]']
[Init] best rec loss: 0.9266335964202881 for ['[CLS]ining strata won suitedtis near [SEP]']
[Init] best rec loss: 0.8718317747116089 for ['[CLS] threatsης roman randy loganicative [SEP]']
[Init] best rec loss: 0.8663002848625183 for ['[CLS] fis project of somecoming elf [SEP]']
[Init] best perm rec loss: 0.8493537902832031 for ['[CLS] elf project somecoming of fis [SEP]']
[Init] best perm rec loss: 0.848770797252655 for ['[CLS] of some elf projectcoming fis [SEP]']
[Init] best perm rec loss: 0.8487182259559631 for ['[CLS] elfcoming some project of fis [SEP]']
[Init] best perm rec loss: 0.8484838008880615 for ['[CLS] elf some fis of projectcoming [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.335 (perp=13.119, rec=0.469, cos=0.242), tot_loss_proj:4.548 [t=0.17s]
prediction: ['[CLS] julia mr nice private roll pba [SEP]']
[ 100/2000] tot_loss=2.860 (perp=11.613, rec=0.403, cos=0.134), tot_loss_proj:4.130 [t=0.17s]
prediction: ['[CLS] avery mister. private bill wonder [SEP]']
[ 150/2000] tot_loss=2.310 (perp=9.152, rec=0.371, cos=0.108), tot_loss_proj:3.692 [t=0.17s]
prediction: ['[CLS] bill win. bill bill wonder [SEP]']
[ 200/2000] tot_loss=2.096 (perp=8.209, rec=0.371, cos=0.083), tot_loss_proj:3.571 [t=0.17s]
prediction: ['[CLS] bill wonder. bill bill wonder [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.030 (perp=8.209, rec=0.321, cos=0.068), tot_loss_proj:3.572 [t=0.17s]
prediction: ['[CLS] bill wonder. bill bill wonder [SEP]']
[ 300/2000] tot_loss=1.997 (perp=8.119, rec=0.309, cos=0.064), tot_loss_proj:3.470 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.996 (perp=8.119, rec=0.318, cos=0.054), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.970 (perp=8.119, rec=0.289, cos=0.058), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
[ 450/2000] tot_loss=1.948 (perp=8.119, rec=0.273, cos=0.051), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.926 (perp=8.119, rec=0.260, cos=0.042), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.950 (perp=8.119, rec=0.278, cos=0.047), tot_loss_proj:3.469 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
[ 600/2000] tot_loss=1.914 (perp=8.119, rec=0.248, cos=0.042), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.896 (perp=8.119, rec=0.231, cos=0.041), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.892 (perp=8.119, rec=0.228, cos=0.041), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
[ 750/2000] tot_loss=1.922 (perp=8.119, rec=0.258, cos=0.040), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.873 (perp=8.119, rec=0.212, cos=0.037), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] bill if. bill bill wonder [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.736 (perp=7.279, rec=0.228, cos=0.052), tot_loss_proj:3.397 [t=0.17s]
prediction: ['[CLS] we wonder if. bill bill [SEP]']
[ 900/2000] tot_loss=1.668 (perp=7.279, rec=0.175, cos=0.037), tot_loss_proj:3.393 [t=0.17s]
prediction: ['[CLS] we wonder if. bill bill [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.518 (perp=6.630, rec=0.158, cos=0.035), tot_loss_proj:3.317 [t=0.17s]
prediction: ['[CLS] we wonder if bill. bill [SEP]']
Attempt swap
[1000/2000] tot_loss=1.511 (perp=6.630, rec=0.152, cos=0.033), tot_loss_proj:3.319 [t=0.17s]
prediction: ['[CLS] we wonder if bill. bill [SEP]']
[1050/2000] tot_loss=1.783 (perp=8.059, rec=0.139, cos=0.032), tot_loss_proj:2.171 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1100/2000] tot_loss=1.777 (perp=8.059, rec=0.135, cos=0.031), tot_loss_proj:2.164 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1150/2000] tot_loss=1.777 (perp=8.059, rec=0.135, cos=0.030), tot_loss_proj:2.168 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1200/2000] tot_loss=1.774 (perp=8.059, rec=0.132, cos=0.030), tot_loss_proj:2.168 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1250/2000] tot_loss=1.764 (perp=8.059, rec=0.122, cos=0.030), tot_loss_proj:2.165 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1300/2000] tot_loss=1.760 (perp=8.059, rec=0.118, cos=0.030), tot_loss_proj:2.168 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1350/2000] tot_loss=1.757 (perp=8.059, rec=0.116, cos=0.030), tot_loss_proj:2.159 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1400/2000] tot_loss=1.769 (perp=8.059, rec=0.128, cos=0.030), tot_loss_proj:2.168 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1450/2000] tot_loss=1.751 (perp=8.059, rec=0.109, cos=0.030), tot_loss_proj:2.167 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1500/2000] tot_loss=1.749 (perp=8.059, rec=0.107, cos=0.030), tot_loss_proj:2.168 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1550/2000] tot_loss=1.751 (perp=8.059, rec=0.109, cos=0.030), tot_loss_proj:2.167 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1600/2000] tot_loss=1.755 (perp=8.059, rec=0.114, cos=0.030), tot_loss_proj:2.164 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1650/2000] tot_loss=1.765 (perp=8.059, rec=0.123, cos=0.030), tot_loss_proj:2.160 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1700/2000] tot_loss=1.747 (perp=8.059, rec=0.106, cos=0.029), tot_loss_proj:2.159 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1750/2000] tot_loss=1.738 (perp=8.059, rec=0.097, cos=0.029), tot_loss_proj:2.166 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1800/2000] tot_loss=1.744 (perp=8.059, rec=0.103, cos=0.029), tot_loss_proj:2.170 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1850/2000] tot_loss=1.759 (perp=8.059, rec=0.118, cos=0.029), tot_loss_proj:2.171 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[1900/2000] tot_loss=1.741 (perp=8.059, rec=0.100, cos=0.029), tot_loss_proj:2.163 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
[1950/2000] tot_loss=1.751 (perp=8.059, rec=0.110, cos=0.029), tot_loss_proj:2.169 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Attempt swap
[2000/2000] tot_loss=1.758 (perp=8.059, rec=0.117, cos=0.029), tot_loss_proj:2.159 [t=0.17s]
prediction: ['[CLS] we wonder if bill left bill [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] we wonder if bill left. [SEP]
========================
predicted: 
========================
[CLS] we wonder if bill left bill [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 79.846 | p: 79.877 | r: 80.132
rouge2     | fm: 38.988 | p: 38.607 | r: 39.583
rougeL     | fm: 67.647 | p: 67.562 | r: 67.963
rougeLsum  | fm: 67.795 | p: 67.705 | r: 68.144
r1fm+r2fm = 118.834

input #63 time: 0:06:51 | total time: 7:27:36


Running input #64 of 100.
reference: 
========================
Ellen talked with Helen about the problem.
========================
Sample: 0 2.7623910852028016e-12 0.053356468175096414 0.36099547
average of cosine similarity 0.9890167507686103
highest_index [0]
highest [0.9890167507686103]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9155, 5720, 2007, 6330, 2055, 1996, 3291, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] ellen talked with helen about the problem. [SEP]']
[Init] best rec loss: 1.0532675981521606 for ['[CLS] states gmina auction monument worthy than kennedy urban [SEP]']
[Init] best rec loss: 0.9713220000267029 for ['[CLS] dc partmona identity writer mary prime pool [SEP]']
[Init] best rec loss: 0.9620294570922852 for ['[CLS] me rough water diagnosed lanka numbered approved treatment [SEP]']
[Init] best rec loss: 0.955909788608551 for ['[CLS] king supporting sex dropping step emotional ave nodded [SEP]']
[Init] best rec loss: 0.9527767896652222 for ['[CLS] yards hospitals insteadware luis council evervc [SEP]']
[Init] best rec loss: 0.9495007991790771 for ['[CLS] caution h riding established science along usual julia [SEP]']
[Init] best rec loss: 0.9492765069007874 for ['[CLS] pistolsfc for german null express his aloud [SEP]']
[Init] best rec loss: 0.9482495784759521 for ['[CLS]yevenity cook viscount simon statpate lap [SEP]']
[Init] best rec loss: 0.9479407072067261 for ['[CLS] to valerietake hot gwen my cricketumen [SEP]']
[Init] best rec loss: 0.9380924105644226 for ['[CLS]ested static accounts credit anonymousey afternoon massachusetts [SEP]']
[Init] best perm rec loss: 0.9359466433525085 for ['[CLS] accounts staticested afternooney massachusetts anonymous credit [SEP]']
[Init] best perm rec loss: 0.9322394132614136 for ['[CLS]ey static afternoon anonymous creditested massachusetts accounts [SEP]']
[Init] best perm rec loss: 0.9310908913612366 for ['[CLS] static anonymous accountsested afternoon massachusettsey credit [SEP]']
[Init] best perm rec loss: 0.9301943778991699 for ['[CLS]ested afternoon static anonymousey accounts massachusetts credit [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.074 (perp=13.699, rec=0.597, cos=0.737), tot_loss_proj:4.541 [t=0.17s]
prediction: ['[CLS] leaned becausenostic plantationi pest she orders [SEP]']
[ 100/2000] tot_loss=2.760 (perp=11.964, rec=0.307, cos=0.060), tot_loss_proj:4.240 [t=0.17s]
prediction: ['[CLS] frowned breast ellen ellen ellen que ellen another [SEP]']
[ 150/2000] tot_loss=2.337 (perp=10.474, rec=0.209, cos=0.033), tot_loss_proj:3.867 [t=0.17s]
prediction: ['[CLS] frowned breast ellen ellen ellen by talked about [SEP]']
[ 200/2000] tot_loss=2.684 (perp=12.473, rec=0.165, cos=0.025), tot_loss_proj:4.413 [t=0.17s]
prediction: ['[CLS] frowned with helen ellen helen problem talked about [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.646 (perp=12.173, rec=0.182, cos=0.029), tot_loss_proj:4.220 [t=0.17s]
prediction: ['[CLS] pulled already helen ellen problem grandfather talked about [SEP]']
[ 300/2000] tot_loss=2.488 (perp=11.611, rec=0.140, cos=0.026), tot_loss_proj:4.232 [t=0.17s]
prediction: ['[CLS] pulled. helen ellen problem program talked about [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.369 (perp=10.971, rec=0.146, cos=0.029), tot_loss_proj:4.013 [t=0.17s]
prediction: ['[CLS] pulled your helen ellen talked about problem program [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.467 (perp=11.541, rec=0.131, cos=0.028), tot_loss_proj:4.078 [t=0.17s]
prediction: ['[CLS] pulled your helen ellen talked with problem program [SEP]']
[ 450/2000] tot_loss=2.273 (perp=10.557, rec=0.133, cos=0.028), tot_loss_proj:3.957 [t=0.17s]
prediction: ['[CLS] problem your helen ellen talked with problem program [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.204 (perp=10.247, rec=0.127, cos=0.027), tot_loss_proj:3.870 [t=0.17s]
prediction: ['[CLS] problem your helen ellen talked with problem report [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.205 (perp=10.247, rec=0.128, cos=0.027), tot_loss_proj:3.873 [t=0.17s]
prediction: ['[CLS] problem your helen ellen talked with problem report [SEP]']
[ 600/2000] tot_loss=2.195 (perp=10.247, rec=0.119, cos=0.027), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS] problem your helen ellen talked with problem report [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.193 (perp=10.247, rec=0.117, cos=0.026), tot_loss_proj:3.869 [t=0.17s]
prediction: ['[CLS] problem your helen ellen talked with problem report [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.134 (perp=9.912, rec=0.125, cos=0.026), tot_loss_proj:3.839 [t=0.17s]
prediction: ['[CLS] problem the helen ellen talked with problem report [SEP]']
[ 750/2000] tot_loss=2.131 (perp=9.912, rec=0.122, cos=0.026), tot_loss_proj:3.836 [t=0.17s]
prediction: ['[CLS] problem the helen ellen talked with problem report [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.631 (perp=12.332, rec=0.135, cos=0.030), tot_loss_proj:4.488 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problemrangle [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.242 (perp=10.436, rec=0.127, cos=0.028), tot_loss_proj:4.029 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
[ 900/2000] tot_loss=2.250 (perp=10.436, rec=0.134, cos=0.028), tot_loss_proj:4.029 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.247 (perp=10.436, rec=0.132, cos=0.028), tot_loss_proj:4.026 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
[1000/2000] tot_loss=2.243 (perp=10.436, rec=0.128, cos=0.028), tot_loss_proj:4.027 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
[1050/2000] tot_loss=2.236 (perp=10.436, rec=0.121, cos=0.028), tot_loss_proj:4.028 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
[1100/2000] tot_loss=2.239 (perp=10.436, rec=0.124, cos=0.027), tot_loss_proj:4.028 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
[1150/2000] tot_loss=2.240 (perp=10.436, rec=0.126, cos=0.027), tot_loss_proj:4.028 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
[1200/2000] tot_loss=2.247 (perp=10.436, rec=0.132, cos=0.027), tot_loss_proj:4.029 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.231 (perp=10.436, rec=0.116, cos=0.027), tot_loss_proj:4.008 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.241 (perp=10.436, rec=0.127, cos=0.027), tot_loss_proj:4.030 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
[1350/2000] tot_loss=2.237 (perp=10.436, rec=0.123, cos=0.027), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
[1400/2000] tot_loss=2.234 (perp=10.436, rec=0.120, cos=0.027), tot_loss_proj:4.030 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
[1450/2000] tot_loss=2.231 (perp=10.436, rec=0.117, cos=0.027), tot_loss_proj:4.027 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
[1500/2000] tot_loss=2.233 (perp=10.436, rec=0.119, cos=0.027), tot_loss_proj:4.032 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
[1550/2000] tot_loss=2.234 (perp=10.436, rec=0.120, cos=0.027), tot_loss_proj:4.027 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
[1600/2000] tot_loss=2.236 (perp=10.436, rec=0.122, cos=0.027), tot_loss_proj:4.032 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
[1650/2000] tot_loss=2.237 (perp=10.436, rec=0.123, cos=0.027), tot_loss_proj:4.027 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.238 (perp=10.436, rec=0.124, cos=0.027), tot_loss_proj:4.006 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
[1750/2000] tot_loss=2.234 (perp=10.436, rec=0.120, cos=0.027), tot_loss_proj:4.006 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
[1800/2000] tot_loss=2.236 (perp=10.436, rec=0.122, cos=0.027), tot_loss_proj:4.004 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
[1850/2000] tot_loss=2.235 (perp=10.436, rec=0.121, cos=0.027), tot_loss_proj:4.005 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.238 (perp=10.436, rec=0.124, cos=0.027), tot_loss_proj:4.032 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
[1950/2000] tot_loss=2.231 (perp=10.436, rec=0.117, cos=0.027), tot_loss_proj:4.026 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.233 (perp=10.436, rec=0.119, cos=0.027), tot_loss_proj:4.003 [t=0.17s]
prediction: ['[CLS] problem problem helen ellen talked with problem report [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] ellen talked with helen about the problem. [SEP]
========================
predicted: 
========================
[CLS] problem problem helen ellen talked with problem report [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 70.000 | r: 77.778
rouge2     | fm: 23.529 | p: 22.222 | r: 25.000
rougeL     | fm: 63.158 | p: 60.000 | r: 66.667
rougeLsum  | fm: 63.158 | p: 60.000 | r: 66.667
r1fm+r2fm = 97.214

[Aggregate metrics]:
rouge1     | fm: 79.899 | p: 79.827 | r: 80.267
rouge2     | fm: 38.672 | p: 38.270 | r: 39.309
rougeL     | fm: 67.780 | p: 67.684 | r: 68.085
rougeLsum  | fm: 67.572 | p: 67.533 | r: 67.937
r1fm+r2fm = 118.570

input #64 time: 0:06:47 | total time: 7:34:24


Running input #65 of 100.
reference: 
========================
Mag Wildwood came to introduce the bartender but I came precisely not to.
========================
Sample: 0 1.812175852638556e-12 0.05146666122575833 0.33753812
average of cosine similarity 0.9883070082674728
highest_index [0]
highest [0.9883070082674728]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101, 23848,  3748,  3702,  2234,  2000,  8970,  1996, 15812,  2021,
          1045,  2234, 10785,  2025,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]']
[Init] best rec loss: 0.9090550541877747 for ['[CLS] old shaw mcgill standminated chapter publication legal non penny cheekatics contemporary story fleet [SEP]']
[Init] best rec loss: 0.8861916661262512 for ['[CLS] mail shooting legends capture gen attention cpud graders democratic but lips suspicious suppressed out [SEP]']
[Init] best rec loss: 0.8844349980354309 for ['[CLS] groom ownership hd mellon field house of [SEP]zed lisa iranbreaker bypass short [SEP]']
[Init] best rec loss: 0.8687723278999329 for ['[CLS]ines organ salesmanisen sectionoise people ideal succession single humanunt shown monk black [SEP]']
[Init] best rec loss: 0.8403171896934509 for ['[CLS] question ibn calledevich gulfcting due instead mist end banks half mef butch [SEP]']
[Init] best perm rec loss: 0.8378674983978271 for ['[CLS]f mecting called ibn butch half banks end due instead gulfevich question mist [SEP]']
[Init] best perm rec loss: 0.8377445936203003 for ['[CLS] gulf butch me banks due mist insteadevich halff questioncting end called ibn [SEP]']
[Init] best perm rec loss: 0.8348801732063293 for ['[CLS] question banks me due half gulfevich mistcting called end butch ibn insteadf [SEP]']
[Init] best perm rec loss: 0.8347507119178772 for ['[CLS]cting end half banks mist instead dueevich me question called gulff ibn butch [SEP]']
[Init] best perm rec loss: 0.8344051837921143 for ['[CLS]f question end instead banks mecting gulfevich due ibn mist half called butch [SEP]']
[Init] best perm rec loss: 0.8343683481216431 for ['[CLS] ibn me called questionevich instead mist due banks half butchfcting gulf end [SEP]']
[Init] best perm rec loss: 0.8341259360313416 for ['[CLS] banks insteadevich ibn me end mistcting gulff called question due half butch [SEP]']
[Init] best perm rec loss: 0.8338921666145325 for ['[CLS] called me banks due instead halffevich ibncting question gulf end butch mist [SEP]']
[Init] best perm rec loss: 0.8312921524047852 for ['[CLS] called butch ibn me end question banksevich mist due instead gulfcting halff [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.217 (perp=11.479, rec=0.569, cos=0.352), tot_loss_proj:4.168 [t=0.17s]
prediction: ['[CLS] not costume « = panel theme sarcasm ª dr parody comes beckyal twilight. [SEP]']
[ 100/2000] tot_loss=3.370 (perp=13.686, rec=0.463, cos=0.170), tot_loss_proj:4.603 [t=0.17s]
prediction: ['[CLS] cab [SEP] pokemon = display theme bribe liked steve parody comes beckyal dave. [SEP]']
[ 150/2000] tot_loss=3.054 (perp=12.500, rec=0.433, cos=0.121), tot_loss_proj:4.366 [t=0.17s]
prediction: ['[CLS] fletcherflower sired = display theme bribe liked really parody comes beckyal dave. [SEP]']
[ 200/2000] tot_loss=3.105 (perp=12.173, rec=0.450, cos=0.220), tot_loss_proj:4.288 [t=0.17s]
prediction: ['[CLS] cabflower sired solid lease episode bribe liked really drink comes beckyal dave. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.731 (perp=11.547, rec=0.356, cos=0.066), tot_loss_proj:4.181 [t=0.17s]
prediction: ['[CLS] cabflower werewolf solid is y exactly liked really auctional becky comes servant. [SEP]']
[ 300/2000] tot_loss=2.834 (perp=12.129, rec=0.345, cos=0.063), tot_loss_proj:4.285 [t=0.17s]
prediction: ['[CLS] quiflower bartender = is y exactly liked really raisesela becky comes servant. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.737 (perp=11.826, rec=0.322, cos=0.050), tot_loss_proj:4.243 [t=0.17s]
prediction: ['[CLS] notflower bartender off is exactly liked y really raisesela tray comes servant. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.845 (perp=12.175, rec=0.348, cos=0.062), tot_loss_proj:4.307 [t=0.17s]
prediction: ['[CLS]ipflower bartender & is exactly ya introduced really raises liked tray comes servant. [SEP]']
[ 450/2000] tot_loss=2.648 (perp=11.456, rec=0.312, cos=0.045), tot_loss_proj:4.167 [t=0.17s]
prediction: ['[CLS] notflower bartender down is exactly precisely introduced really campaign liked tray comes servant. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.610 (perp=11.335, rec=0.302, cos=0.041), tot_loss_proj:4.124 [t=0.17s]
prediction: ['[CLS] yflower bartender down campaign exactly precisely introduced really is liked tray comes matched. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.845 (perp=12.386, rec=0.317, cos=0.051), tot_loss_proj:4.339 [t=0.17s]
prediction: ['[CLS] esq bartenderflower down exclusively exactly precisely introduced really brought liked tray comes matched. [SEP]']
[ 600/2000] tot_loss=2.728 (perp=11.987, rec=0.292, cos=0.038), tot_loss_proj:4.287 [t=0.17s]
prediction: ['[CLS] y bartenderflower down exclusively exactly precisely introduced exactly brought liked tray comes matched. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.720 (perp=11.971, rec=0.289, cos=0.036), tot_loss_proj:4.266 [t=0.17s]
prediction: ['[CLS] dupont bartender substitute down exclusively exactly precisely introduced exactly introduced comes tray comesflower. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.552 (perp=11.113, rec=0.288, cos=0.042), tot_loss_proj:4.074 [t=0.17s]
prediction: ['[CLS] not bartender down exclusively matched precisely precisely introduced exactly introduced comes tray comesflower. [SEP]']
[ 750/2000] tot_loss=2.714 (perp=12.011, rec=0.279, cos=0.033), tot_loss_proj:4.262 [t=0.17s]
prediction: ['[CLS] dupont bartender down off matched precisely precisely introduce exactly introduced comes tray comes replied. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.482 (perp=10.842, rec=0.281, cos=0.033), tot_loss_proj:4.020 [t=0.17s]
prediction: ['[CLS] dupont bartender down off matched precisely precisely introduce tray offered comes exactly comes replied. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.509 (perp=11.025, rec=0.273, cos=0.031), tot_loss_proj:4.081 [t=0.17s]
prediction: ['[CLS] dupont bartender down off matched precisely precisely introduce tray offered comes exactly came replied. [SEP]']
[ 900/2000] tot_loss=2.471 (perp=10.863, rec=0.266, cos=0.033), tot_loss_proj:4.043 [t=0.17s]
prediction: ['[CLS] esq bartender down off matched precisely precisely introduce tray offered comes exactly came replied. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.690 (perp=11.919, rec=0.276, cos=0.030), tot_loss_proj:4.260 [t=0.17s]
prediction: ['[CLS]mia bartender down off substitute precisely precisely introduce tray introduced comes exactly came replied. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.610 (perp=11.388, rec=0.293, cos=0.040), tot_loss_proj:4.177 [t=0.17s]
prediction: ['[CLS] esq comes down off matched precisely precisely introduce tray offered bartender exactly came replied. [SEP]']
[1050/2000] tot_loss=2.532 (perp=11.136, rec=0.271, cos=0.033), tot_loss_proj:4.123 [t=0.17s]
prediction: ['[CLS] esq comes down off matched precisely precisely introduce i offered bartender exactly came replied. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.398 (perp=10.490, rec=0.268, cos=0.032), tot_loss_proj:3.965 [t=0.17s]
prediction: ['[CLS] esq matched down off comes precisely precisely introduce i offered bartender exactly came replied. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.363 (perp=10.338, rec=0.262, cos=0.033), tot_loss_proj:3.932 [t=0.17s]
prediction: ['[CLS] esq substitute comes off down precisely precisely introduce i offered bartender exactly came replied. [SEP]']
[1200/2000] tot_loss=2.375 (perp=10.413, rec=0.261, cos=0.031), tot_loss_proj:3.939 [t=0.17s]
prediction: ['[CLS] esq substitute comes off precisely precisely precisely introduce i offered bartender exactly came replied. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.363 (perp=10.319, rec=0.265, cos=0.034), tot_loss_proj:3.952 [t=0.17s]
prediction: ['[CLS] esq substitute comes off precisely precisely precisely introduce exactly introduced bartender i came replied. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.491 (perp=10.962, rec=0.263, cos=0.036), tot_loss_proj:4.088 [t=0.17s]
prediction: ['[CLS] substitute esq comes off precisely precisely precisely introduce exactly introduced bartender i came replied. [SEP]']
[1350/2000] tot_loss=2.484 (perp=10.962, rec=0.258, cos=0.034), tot_loss_proj:4.089 [t=0.17s]
prediction: ['[CLS] substitute esq comes off precisely precisely precisely introduce exactly introduced bartender i came replied. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.405 (perp=10.561, rec=0.261, cos=0.032), tot_loss_proj:3.977 [t=0.17s]
prediction: ['[CLS] mag substitute comes off & precisely precisely introduce exactly introduced bartender i came replied. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.429 (perp=10.683, rec=0.259, cos=0.033), tot_loss_proj:3.988 [t=0.17s]
prediction: ['[CLS] mag spoken comes quite precisely precisely & introduce exactly introduced bartender i came replied. [SEP]']
[1500/2000] tot_loss=2.348 (perp=10.350, rec=0.245, cos=0.033), tot_loss_proj:3.893 [t=0.17s]
prediction: ['[CLS] mag spoken comes quite precisely precisely & introduce exactly introduced bartender i came mag. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.205 (perp=9.584, rec=0.256, cos=0.032), tot_loss_proj:3.756 [t=0.17s]
prediction: ['[CLS] mag comes spoken quite precisely precisely & introduce exactly introduced bartender i came mag. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.282 (perp=9.995, rec=0.252, cos=0.031), tot_loss_proj:3.837 [t=0.17s]
prediction: ['[CLS] mag spoken comes off precisely precisely & introduce exactly introduced bartender i came mag. [SEP]']
[1650/2000] tot_loss=2.279 (perp=9.995, rec=0.249, cos=0.030), tot_loss_proj:3.834 [t=0.17s]
prediction: ['[CLS] mag spoken comes off precisely precisely & introduce exactly introduced bartender i came mag. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.267 (perp=9.995, rec=0.238, cos=0.030), tot_loss_proj:3.839 [t=0.17s]
prediction: ['[CLS] mag spoken comes off precisely precisely & introduce exactly introduced bartender i came mag. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.236 (perp=9.799, rec=0.243, cos=0.033), tot_loss_proj:3.819 [t=0.17s]
prediction: ['[CLS] spoken mag comes off precisely precisely precisely introduce exactly introduced bartender i came mag. [SEP]']
[1800/2000] tot_loss=2.233 (perp=9.799, rec=0.242, cos=0.032), tot_loss_proj:3.815 [t=0.19s]
prediction: ['[CLS] spoken mag comes off precisely precisely precisely introduce exactly introduced bartender i came mag. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.230 (perp=9.799, rec=0.239, cos=0.031), tot_loss_proj:3.817 [t=0.17s]
prediction: ['[CLS] spoken mag comes off precisely precisely precisely introduce exactly introduced bartender i came mag. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.239 (perp=9.799, rec=0.248, cos=0.031), tot_loss_proj:3.814 [t=0.17s]
prediction: ['[CLS] spoken mag comes off precisely precisely precisely introduce exactly introduced bartender i came mag. [SEP]']
[1950/2000] tot_loss=2.235 (perp=9.799, rec=0.245, cos=0.031), tot_loss_proj:3.818 [t=0.17s]
prediction: ['[CLS] spoken mag comes off precisely precisely precisely introduce exactly introduced bartender i came mag. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.181 (perp=9.540, rec=0.242, cos=0.031), tot_loss_proj:3.748 [t=0.17s]
prediction: ['[CLS] spoken mag comes off precisely precisely but introduce exactly introduced bartender i came mag. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]
========================
predicted: 
========================
[CLS] spoken mag comes off precisely precisely precisely introduce exactly introduced bartender i came mag. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 51.613 | p: 50.000 | r: 53.333
rouge2     | fm: 6.897 | p: 6.667 | r: 7.143
rougeL     | fm: 45.161 | p: 43.750 | r: 46.667
rougeLsum  | fm: 45.161 | p: 43.750 | r: 46.667
r1fm+r2fm = 58.509

[Aggregate metrics]:
rouge1     | fm: 79.367 | p: 79.328 | r: 79.796
rouge2     | fm: 38.278 | p: 37.816 | r: 38.812
rougeL     | fm: 67.341 | p: 67.264 | r: 67.729
rougeLsum  | fm: 67.168 | p: 67.090 | r: 67.608
r1fm+r2fm = 117.645

input #65 time: 0:06:56 | total time: 7:41:20


Running input #66 of 100.
reference: 
========================
There tried to be riots in Seoul.
========================
Sample: 0 1.2878575916783752e-12 0.04641558466650461 0.35016412
average of cosine similarity 0.9911757968917323
highest_index [0]
highest [0.9911757968917323]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2045,  2699,  2000,  2022, 12925,  1999, 10884,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] there tried to be riots in seoul. [SEP]']
[Init] best rec loss: 0.8370904326438904 for ['[CLS] mcdonnell mount activities death today game medal ng [SEP]']
[Init] best rec loss: 0.7445188164710999 for ['[CLS] vamp kada devil kent lizard home angels [SEP]']
[Init] best rec loss: 0.7357205748558044 for ['[CLS] general maryland head learners balancemm experience vehicles [SEP]']
[Init] best rec loss: 0.6963397860527039 for ['[CLS] kirk line may anniversary bee combined ladder doubtful [SEP]']
[Init] best rec loss: 0.6802833676338196 for ['[CLS] mainger soil music means numbers this left [SEP]']
[Init] best rec loss: 0.6790328025817871 for ['[CLS] duel paradise birdsfireshane express knows archives [SEP]']
[Init] best perm rec loss: 0.6775854825973511 for ['[CLS]hane express paradise birds archives knowsfires duel [SEP]']
[Init] best perm rec loss: 0.6764670610427856 for ['[CLS] express birds paradisehane duel knowsfires archives [SEP]']
[Init] best perm rec loss: 0.6757842898368835 for ['[CLS]fires paradisehane knows birds archives express duel [SEP]']
[Init] best perm rec loss: 0.6753475069999695 for ['[CLS] paradise duel express birds knows archivesfireshane [SEP]']
[Init] best perm rec loss: 0.6744402647018433 for ['[CLS] paradise archivesfires birdshane knows express duel [SEP]']
[Init] best perm rec loss: 0.6731578707695007 for ['[CLS] express duel paradisehane archives knows birdsfires [SEP]']
[Init] best perm rec loss: 0.6708163022994995 for ['[CLS] paradise knows duelhane express birds archivesfires [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.912 (perp=12.367, rec=0.377, cos=0.062), tot_loss_proj:3.439 [t=0.17s]
prediction: ['[CLS]how track playstation behausened rice was [SEP]']
[ 100/2000] tot_loss=2.794 (perp=12.357, rec=0.284, cos=0.038), tot_loss_proj:3.150 [t=0.17s]
prediction: ['[CLS] tried tried korean behausened riots was [SEP]']
[ 150/2000] tot_loss=3.474 (perp=13.928, rec=0.349, cos=0.340), tot_loss_proj:3.418 [t=0.17s]
prediction: ['[CLS] there tried seoul be connectscr riots be [SEP]']
[ 200/2000] tot_loss=2.661 (perp=12.455, rec=0.143, cos=0.027), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] there tried seoul be riotsband riots be [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.230 (perp=10.403, rec=0.125, cos=0.025), tot_loss_proj:2.631 [t=0.17s]
prediction: ['[CLS] there tried be riots of seoul riots be [SEP]']
[ 300/2000] tot_loss=2.146 (perp=10.155, rec=0.093, cos=0.023), tot_loss_proj:2.819 [t=0.17s]
prediction: ['[CLS] there tried to riots of seoul riots be [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.809 (perp=8.543, rec=0.079, cos=0.021), tot_loss_proj:2.314 [t=0.17s]
prediction: ['[CLS] there tried to be of seoul riots in [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.408 (perp=6.567, rec=0.075, cos=0.020), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] there tried to be seoul in riots. [SEP]']
[ 450/2000] tot_loss=1.414 (perp=6.567, rec=0.082, cos=0.019), tot_loss_proj:2.109 [t=0.17s]
prediction: ['[CLS] there tried to be seoul in riots. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.172 (perp=5.431, rec=0.067, cos=0.019), tot_loss_proj:1.240 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.182 (perp=5.431, rec=0.077, cos=0.019), tot_loss_proj:1.247 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
[ 600/2000] tot_loss=1.181 (perp=5.431, rec=0.076, cos=0.019), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.168 (perp=5.431, rec=0.063, cos=0.019), tot_loss_proj:1.241 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.171 (perp=5.431, rec=0.066, cos=0.019), tot_loss_proj:1.238 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
[ 750/2000] tot_loss=1.162 (perp=5.431, rec=0.057, cos=0.019), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.167 (perp=5.431, rec=0.062, cos=0.019), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.168 (perp=5.431, rec=0.064, cos=0.019), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
[ 900/2000] tot_loss=1.174 (perp=5.431, rec=0.069, cos=0.019), tot_loss_proj:1.240 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.161 (perp=5.431, rec=0.056, cos=0.019), tot_loss_proj:1.237 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.166 (perp=5.431, rec=0.061, cos=0.019), tot_loss_proj:1.242 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
[1050/2000] tot_loss=1.171 (perp=5.431, rec=0.066, cos=0.019), tot_loss_proj:1.244 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.168 (perp=5.431, rec=0.064, cos=0.019), tot_loss_proj:1.247 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.173 (perp=5.431, rec=0.068, cos=0.019), tot_loss_proj:1.239 [t=0.19s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
[1200/2000] tot_loss=1.172 (perp=5.431, rec=0.067, cos=0.019), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.172 (perp=5.431, rec=0.067, cos=0.019), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.177 (perp=5.431, rec=0.072, cos=0.019), tot_loss_proj:1.246 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
[1350/2000] tot_loss=1.165 (perp=5.431, rec=0.060, cos=0.019), tot_loss_proj:1.242 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.171 (perp=5.431, rec=0.066, cos=0.019), tot_loss_proj:1.238 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.177 (perp=5.431, rec=0.072, cos=0.019), tot_loss_proj:1.240 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
[1500/2000] tot_loss=1.166 (perp=5.431, rec=0.062, cos=0.019), tot_loss_proj:1.240 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.169 (perp=5.431, rec=0.064, cos=0.019), tot_loss_proj:1.234 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.163 (perp=5.431, rec=0.058, cos=0.019), tot_loss_proj:1.234 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
[1650/2000] tot_loss=1.184 (perp=5.431, rec=0.079, cos=0.019), tot_loss_proj:1.244 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.171 (perp=5.431, rec=0.066, cos=0.019), tot_loss_proj:1.243 [t=0.18s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.170 (perp=5.431, rec=0.065, cos=0.019), tot_loss_proj:1.247 [t=0.18s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
[1800/2000] tot_loss=1.179 (perp=5.431, rec=0.074, cos=0.019), tot_loss_proj:1.233 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.165 (perp=5.431, rec=0.060, cos=0.019), tot_loss_proj:1.242 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.166 (perp=5.431, rec=0.061, cos=0.019), tot_loss_proj:1.237 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
[1950/2000] tot_loss=1.171 (perp=5.431, rec=0.066, cos=0.019), tot_loss_proj:1.237 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.162 (perp=5.431, rec=0.057, cos=0.019), tot_loss_proj:1.247 [t=0.17s]
prediction: ['[CLS] there tried to be riots in seoul. [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] there tried to be riots in seoul. [SEP]
========================
predicted: 
========================
[CLS] there tried to be riots in seoul. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 79.621 | p: 79.557 | r: 80.010
rouge2     | fm: 39.220 | p: 38.828 | r: 39.854
rougeL     | fm: 67.847 | p: 67.815 | r: 68.216
rougeLsum  | fm: 67.746 | p: 67.618 | r: 68.109
r1fm+r2fm = 118.841

input #66 time: 0:06:50 | total time: 7:48:10


Running input #67 of 100.
reference: 
========================
Fido is the smarter dog than Spot.
========================
Sample: 0 4.026396892097135e-12 0.05868423881717337 0.37675238
average of cosine similarity 0.9877943970911222
highest_index [0]
highest [0.9877943970911222]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 10882,  3527,  2003,  1996, 25670,  3899,  2084,  3962,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] fido is the smarter dog than spot. [SEP]']
[Init] best rec loss: 1.016399621963501 for ['[CLS] spec legend currently boarding reasons chapel assistance accomplish through [SEP]']
[Init] best rec loss: 0.9444090723991394 for ['[CLS] bi ride driveway° student " life representative bomb [SEP]']
[Init] best rec loss: 0.9167268872261047 for ['[CLS] silkrting relating break cigarette bail finger charts do [SEP]']
[Init] best rec loss: 0.8861123323440552 for ['[CLS] word cab healthychenifying ruled mills flat prison [SEP]']
[Init] best rec loss: 0.8842894434928894 for ['[CLS]vert prompt train circle being ableaco horror ada [SEP]']
[Init] best rec loss: 0.8251447081565857 for ['[CLS] canberra mountain terms first transit ladder rats running naval [SEP]']
[Init] best rec loss: 0.8203999996185303 for ['[CLS] date disease expert monkey ich determination only oncelow [SEP]']
[Init] best rec loss: 0.8164994716644287 for ['[CLS] ] house christ box swore rex marina limit replacement [SEP]']
[Init] best perm rec loss: 0.8159659504890442 for ['[CLS] house limit box ] marina christ rex replacement swore [SEP]']
[Init] best perm rec loss: 0.8144137263298035 for ['[CLS] limit replacement house rex box marina swore christ ] [SEP]']
[Init] best perm rec loss: 0.8091739416122437 for ['[CLS] box house replacement rex christ swore limit marina ] [SEP]']
[Init] best perm rec loss: 0.808587908744812 for ['[CLS] ] house box replacement marina christ rex limit swore [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.283 (perp=12.952, rec=0.500, cos=0.193), tot_loss_proj:4.236 [t=0.17s]
prediction: ['[CLS] tournamentlo spot companion hunters fifa after although hates [SEP]']
[ 100/2000] tot_loss=2.912 (perp=11.681, rec=0.444, cos=0.132), tot_loss_proj:3.924 [t=0.17s]
prediction: ['[CLS] ]plex roar tribe dog done dog as uhf [SEP]']
[ 150/2000] tot_loss=3.193 (perp=9.185, rec=0.794, cos=0.563), tot_loss_proj:3.631 [t=0.17s]
prediction: ['[CLS] is spot smarter quiz smarter than dog as smarter [SEP]']
[ 200/2000] tot_loss=2.311 (perp=9.122, rec=0.380, cos=0.106), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS]ens is smarter dog dog than dog to spot [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.218 (perp=8.268, rec=0.424, cos=0.141), tot_loss_proj:3.372 [t=0.17s]
prediction: ['[CLS] is ( smarter than dog being dog they makes [SEP]']
[ 300/2000] tot_loss=2.270 (perp=9.474, rec=0.314, cos=0.061), tot_loss_proj:3.546 [t=0.17s]
prediction: ['[CLS] is ( smarter than dog being dog spot copy [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.081 (perp=8.965, rec=0.231, cos=0.057), tot_loss_proj:3.452 [t=0.17s]
prediction: ['[CLS] is smarter than smarter is dog spot copy ( [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.115 (perp=8.863, rec=0.240, cos=0.102), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS] is smarter than smarter is dog copy spot ( [SEP]']
[ 450/2000] tot_loss=1.865 (perp=8.272, rec=0.163, cos=0.048), tot_loss_proj:3.263 [t=0.17s]
prediction: ['[CLS] spot smarter than smarter is dog! spot ( [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.751 (perp=7.605, rec=0.179, cos=0.051), tot_loss_proj:3.211 [t=0.17s]
prediction: ['[CLS] is smarter than spot smarter is dog! ( [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.583 (perp=6.854, rec=0.172, cos=0.040), tot_loss_proj:2.961 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog! ( [SEP]']
[ 600/2000] tot_loss=1.756 (perp=7.860, rec=0.146, cos=0.038), tot_loss_proj:3.111 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.749 (perp=7.860, rec=0.142, cos=0.035), tot_loss_proj:3.121 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.730 (perp=7.860, rec=0.124, cos=0.033), tot_loss_proj:3.116 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
[ 750/2000] tot_loss=1.743 (perp=7.860, rec=0.139, cos=0.032), tot_loss_proj:3.117 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.714 (perp=7.860, rec=0.110, cos=0.032), tot_loss_proj:3.115 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.716 (perp=7.860, rec=0.113, cos=0.031), tot_loss_proj:3.118 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
[ 900/2000] tot_loss=1.712 (perp=7.860, rec=0.109, cos=0.031), tot_loss_proj:3.113 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.721 (perp=7.860, rec=0.118, cos=0.031), tot_loss_proj:3.120 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[1000/2000] tot_loss=1.716 (perp=7.860, rec=0.113, cos=0.030), tot_loss_proj:3.115 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
[1050/2000] tot_loss=2.125 (perp=9.891, rec=0.116, cos=0.030), tot_loss_proj:3.604 [t=0.17s]
prediction: ['[CLS]do smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.770 (perp=7.860, rec=0.147, cos=0.051), tot_loss_proj:3.111 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[1150/2000] tot_loss=1.735 (perp=7.860, rec=0.123, cos=0.040), tot_loss_proj:3.107 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
[1200/2000] tot_loss=1.729 (perp=7.860, rec=0.119, cos=0.037), tot_loss_proj:3.107 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[1250/2000] tot_loss=1.715 (perp=7.860, rec=0.107, cos=0.036), tot_loss_proj:3.109 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[1300/2000] tot_loss=1.723 (perp=7.860, rec=0.116, cos=0.035), tot_loss_proj:3.103 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
[1350/2000] tot_loss=1.710 (perp=7.860, rec=0.103, cos=0.035), tot_loss_proj:3.104 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[1400/2000] tot_loss=1.978 (perp=9.150, rec=0.113, cos=0.034), tot_loss_proj:3.362 [t=0.17s]
prediction: ['[CLS] fi smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.722 (perp=7.860, rec=0.113, cos=0.038), tot_loss_proj:3.097 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
[1500/2000] tot_loss=1.723 (perp=7.860, rec=0.118, cos=0.033), tot_loss_proj:3.096 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
[1550/2000] tot_loss=1.702 (perp=7.860, rec=0.097, cos=0.033), tot_loss_proj:3.095 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog spot ( [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.695 (perp=7.741, rec=0.107, cos=0.040), tot_loss_proj:3.174 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog ( fi [SEP]']
[1650/2000] tot_loss=1.694 (perp=7.741, rec=0.112, cos=0.033), tot_loss_proj:3.180 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog ( fi [SEP]']
Attempt swap
[1700/2000] tot_loss=1.681 (perp=7.741, rec=0.099, cos=0.033), tot_loss_proj:3.175 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog ( fi [SEP]']
Attempt swap
[1750/2000] tot_loss=1.692 (perp=7.741, rec=0.112, cos=0.033), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog ( fi [SEP]']
[1800/2000] tot_loss=1.695 (perp=7.741, rec=0.114, cos=0.033), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog ( fi [SEP]']
Attempt swap
[1850/2000] tot_loss=1.693 (perp=7.741, rec=0.113, cos=0.032), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog ( fi [SEP]']
Attempt swap
[1900/2000] tot_loss=1.690 (perp=7.741, rec=0.109, cos=0.032), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog ( fi [SEP]']
[1950/2000] tot_loss=1.692 (perp=7.741, rec=0.111, cos=0.032), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog ( fi [SEP]']
Attempt swap
[2000/2000] tot_loss=1.677 (perp=7.741, rec=0.097, cos=0.032), tot_loss_proj:3.180 [t=0.17s]
prediction: ['[CLS] spot smarter than spot smarter is dog ( fi [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] fido is the smarter dog than spot. [SEP]
========================
predicted: 
========================
[CLS] spot smarter than spot smarter is dog ( fi [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 70.000 | r: 77.778
rouge2     | fm: 11.765 | p: 11.111 | r: 12.500
rougeL     | fm: 52.632 | p: 50.000 | r: 55.556
rougeLsum  | fm: 52.632 | p: 50.000 | r: 55.556
r1fm+r2fm = 85.449

[Aggregate metrics]:
rouge1     | fm: 79.702 | p: 79.532 | r: 80.039
rouge2     | fm: 38.785 | p: 38.356 | r: 39.341
rougeL     | fm: 67.606 | p: 67.490 | r: 67.975
rougeLsum  | fm: 67.600 | p: 67.406 | r: 67.986
r1fm+r2fm = 118.487

input #67 time: 0:06:49 | total time: 7:54:59


Running input #68 of 100.
reference: 
========================
John convinced the rice to be cooked by Bill.
========================
Sample: 0 9.256583844536869e-13 0.04683045205149594 0.34312814
average of cosine similarity 0.9906427079338287
highest_index [0]
highest [0.9906427079338287]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198,  6427,  1996,  5785,  2000,  2022, 12984,  2011,  3021,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john convinced the rice to be cooked by bill. [SEP]']
[Init] best rec loss: 0.7907953262329102 for ['[CLS] rich plant ticket has an boat favorite malaysia showing procedures [SEP]']
[Init] best rec loss: 0.7299020886421204 for ['[CLS] ago participants bo charlie across formula alone fisheries core constantine [SEP]']
[Init] best rec loss: 0.7223528027534485 for ['[CLS] maintenance fr respectively sports alive turnoured acquisition barrow body [SEP]']
[Init] best rec loss: 0.7169906497001648 for ['[CLS] clouditedpath 23rch lying staff students waiting supreme [SEP]']
[Init] best rec loss: 0.7140128016471863 for ['[CLS] protested rob child truss privileged rise efforts saber [MASK] goat [SEP]']
[Init] best rec loss: 0.7135128378868103 for ['[CLS] buy miles figureider okay hit springs loving todd contract [SEP]']
[Init] best rec loss: 0.70791095495224 for ['[CLS] shipped pali elevation stacy mississippi spectacle [SEP] completely physical airlines [SEP]']
[Init] best rec loss: 0.6938566565513611 for ['[CLS] bail tallest moth twenty plate maybe verse story growing > [SEP]']
[Init] best perm rec loss: 0.6931449770927429 for ['[CLS] > bail plate moth verse twenty growing tallest maybe story [SEP]']
[Init] best perm rec loss: 0.6930882334709167 for ['[CLS] story maybe bail tallest verse twenty moth > plate growing [SEP]']
[Init] best perm rec loss: 0.6856919527053833 for ['[CLS] growing maybe story verse twenty > plate tallest moth bail [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.019 (perp=13.365, rec=0.293, cos=0.052), tot_loss_proj:3.740 [t=0.17s]
prediction: ['[CLS] convinced yes gary x mind chicken rice everyone convinced infantry [SEP]']
[ 100/2000] tot_loss=2.143 (perp=9.613, rec=0.192, cos=0.029), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] the again rice the. to rice to convinced rice [SEP]']
[ 150/2000] tot_loss=2.557 (perp=10.860, rec=0.315, cos=0.071), tot_loss_proj:3.277 [t=0.17s]
prediction: ['[CLS] the [SEP] john structure ) rice rice being convinced the [SEP]']
[ 200/2000] tot_loss=3.128 (perp=12.812, rec=0.431, cos=0.135), tot_loss_proj:3.523 [t=0.17s]
prediction: ['[CLS] the [SEP] juan [SEP] [SEP] championshipsdt to convinced the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.604 (perp=10.849, rec=0.341, cos=0.094), tot_loss_proj:3.084 [t=0.17s]
prediction: ['[CLS] the to juan [SEP] [SEP] championships area [SEP] convinced the [SEP]']
[ 300/2000] tot_loss=2.529 (perp=10.675, rec=0.308, cos=0.086), tot_loss_proj:3.096 [t=0.17s]
prediction: ['[CLS] the to bennett 15 [SEP] championships rice [SEP] convinced the [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.415 (perp=10.235, rec=0.286, cos=0.082), tot_loss_proj:3.060 [t=0.17s]
prediction: ['[CLS] the to bennett 15 [SEP] coffee championships [SEP] convinced the [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.346 (perp=10.013, rec=0.263, cos=0.080), tot_loss_proj:3.160 [t=0.17s]
prediction: ['[CLS] to the bennett 15 [SEP] coffee championships [SEP] convinced the [SEP]']
[ 450/2000] tot_loss=2.343 (perp=10.058, rec=0.257, cos=0.074), tot_loss_proj:2.980 [t=0.17s]
prediction: ['[CLS] to the mohammad 15 [SEP] rice championships [SEP] convinced the [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.200 (perp=9.401, rec=0.253, cos=0.067), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] to the 15 [SEP] rice championships [SEP] convinced the mohammad [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=2.151 (perp=9.224, rec=0.236, cos=0.070), tot_loss_proj:2.770 [t=0.17s]
prediction: ['[CLS] 15 [SEP] rice cuisine [SEP] convinced the mohammad to the [SEP]']
[ 600/2000] tot_loss=2.291 (perp=10.070, rec=0.219, cos=0.058), tot_loss_proj:2.896 [t=0.17s]
prediction: ['[CLS] 15 [SEP] rice cuisine [SEP] convinced the postage to the [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.250 (perp=9.867, rec=0.219, cos=0.058), tot_loss_proj:2.865 [t=0.17s]
prediction: ['[CLS] 15 [SEP] rice [SEP] convinced the postage to the cuisine [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.164 (perp=9.496, rec=0.214, cos=0.051), tot_loss_proj:2.760 [t=0.17s]
prediction: ['[CLS] 15 [SEP] rice [SEP] convinced the cuisine to the postage [SEP]']
[ 750/2000] tot_loss=2.150 (perp=9.496, rec=0.200, cos=0.051), tot_loss_proj:2.758 [t=0.17s]
prediction: ['[CLS] 15 [SEP] rice [SEP] convinced the cuisine to the postage [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.142 (perp=9.415, rec=0.208, cos=0.051), tot_loss_proj:2.707 [t=0.17s]
prediction: ['[CLS] that [SEP] cuisine [SEP] convinced the rice to the postage [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.061 (perp=9.041, rec=0.204, cos=0.049), tot_loss_proj:2.657 [t=0.17s]
prediction: ['[CLS] [SEP] that cuisine [SEP] convinced the rice to the postage [SEP]']
[ 900/2000] tot_loss=2.052 (perp=9.041, rec=0.196, cos=0.048), tot_loss_proj:2.652 [t=0.17s]
prediction: ['[CLS] [SEP] that cuisine [SEP] convinced the rice to the postage [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.016 (perp=8.917, rec=0.185, cos=0.047), tot_loss_proj:2.616 [t=0.17s]
prediction: ['[CLS] [SEP] that [SEP] cuisine convinced the rice to the postage [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.996 (perp=8.803, rec=0.191, cos=0.045), tot_loss_proj:3.067 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
[1050/2000] tot_loss=1.986 (perp=8.803, rec=0.180, cos=0.045), tot_loss_proj:3.060 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
Attempt swap
[1100/2000] tot_loss=1.985 (perp=8.803, rec=0.181, cos=0.044), tot_loss_proj:3.056 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
Attempt swap
Put prefix at the end
[1150/2000] tot_loss=2.157 (perp=9.674, rec=0.180, cos=0.042), tot_loss_proj:3.201 [t=0.17s]
prediction: ['[CLS] that the cuisine convinced the rice to [SEP] postage [SEP] [SEP]']
[1200/2000] tot_loss=2.169 (perp=9.674, rec=0.191, cos=0.043), tot_loss_proj:3.197 [t=0.17s]
prediction: ['[CLS] that the cuisine convinced the rice to [SEP] postage [SEP] [SEP]']
Attempt swap
Put prefix at the end
[1250/2000] tot_loss=1.983 (perp=8.803, rec=0.180, cos=0.043), tot_loss_proj:3.058 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
Attempt swap
[1300/2000] tot_loss=1.995 (perp=8.803, rec=0.189, cos=0.045), tot_loss_proj:3.053 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
[1350/2000] tot_loss=1.999 (perp=8.803, rec=0.194, cos=0.045), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
Attempt swap
[1400/2000] tot_loss=1.986 (perp=8.803, rec=0.181, cos=0.045), tot_loss_proj:3.051 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
Attempt swap
[1450/2000] tot_loss=1.983 (perp=8.803, rec=0.178, cos=0.045), tot_loss_proj:3.054 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
[1500/2000] tot_loss=1.984 (perp=8.803, rec=0.178, cos=0.044), tot_loss_proj:3.050 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.986 (perp=8.803, rec=0.181, cos=0.044), tot_loss_proj:2.951 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
Attempt swap
[1600/2000] tot_loss=1.976 (perp=8.803, rec=0.171, cos=0.044), tot_loss_proj:2.949 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
[1650/2000] tot_loss=1.977 (perp=8.803, rec=0.172, cos=0.044), tot_loss_proj:2.948 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] postage [SEP]']
Attempt swap
[1700/2000] tot_loss=1.936 (perp=8.605, rec=0.171, cos=0.044), tot_loss_proj:2.658 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] john [SEP]']
Attempt swap
[1750/2000] tot_loss=1.937 (perp=8.605, rec=0.173, cos=0.044), tot_loss_proj:2.663 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] john [SEP]']
[1800/2000] tot_loss=1.942 (perp=8.605, rec=0.178, cos=0.043), tot_loss_proj:2.659 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] john [SEP]']
Attempt swap
[1850/2000] tot_loss=1.935 (perp=8.605, rec=0.170, cos=0.043), tot_loss_proj:2.657 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] john [SEP]']
Attempt swap
[1900/2000] tot_loss=1.930 (perp=8.605, rec=0.165, cos=0.043), tot_loss_proj:2.661 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] john [SEP]']
[1950/2000] tot_loss=1.937 (perp=8.605, rec=0.173, cos=0.043), tot_loss_proj:2.668 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] john [SEP]']
Attempt swap
[2000/2000] tot_loss=1.938 (perp=8.605, rec=0.174, cos=0.043), tot_loss_proj:2.661 [t=0.17s]
prediction: ['[CLS] [SEP] that the cuisine convinced the rice to [SEP] john [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] john convinced the rice to be cooked by bill. [SEP]
========================
predicted: 
========================
[CLS] [SEP] that the cuisine convinced the rice to [SEP] john [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.870 | p: 58.333 | r: 63.636
rouge2     | fm: 28.571 | p: 27.273 | r: 30.000
rougeL     | fm: 52.174 | p: 50.000 | r: 54.545
rougeLsum  | fm: 52.174 | p: 50.000 | r: 54.545
r1fm+r2fm = 89.441

[Aggregate metrics]:
rouge1     | fm: 79.284 | p: 79.126 | r: 79.773
rouge2     | fm: 38.578 | p: 38.205 | r: 39.170
rougeL     | fm: 67.496 | p: 67.308 | r: 67.836
rougeLsum  | fm: 67.292 | p: 67.155 | r: 67.721
r1fm+r2fm = 117.863

input #68 time: 0:06:47 | total time: 8:01:47


Running input #69 of 100.
reference: 
========================
The squirrel ran straight quickly.
========================
Sample: 0 1.520630452037191e-10 0.04970365243326032 0.358498
average of cosine similarity 0.9903422215251041
highest_index [0]
highest [0.9903422215251041]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 18197,  2743,  3442,  2855,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the squirrel ran straight quickly. [SEP]']
[Init] best rec loss: 0.7449679970741272 for ['[CLS] theme skin alive won reach one [SEP]']
[Init] best rec loss: 0.7045864462852478 for ['[CLS] action ou defenceiom unto violence [SEP]']
[Init] best rec loss: 0.6891953349113464 for ['[CLS] pry material lay steadywled surveyor [SEP]']
[Init] best rec loss: 0.684439480304718 for ['[CLS]ango pieces wal ar upon bound [SEP]']
[Init] best rec loss: 0.6838079690933228 for ['[CLS] on years magazine belong eugen wah [SEP]']
[Init] best rec loss: 0.6556761860847473 for ['[CLS] brief forgetlyhawks husbandch [SEP]']
[Init] best perm rec loss: 0.6538225412368774 for ['[CLS] brieftlyhawks husband forgech [SEP]']
[Init] best perm rec loss: 0.6537908911705017 for ['[CLS]chtly briefhawks forge husband [SEP]']
[Init] best perm rec loss: 0.6512235999107361 for ['[CLS] briefhawks husband forgetlych [SEP]']
[Init] best perm rec loss: 0.6494418382644653 for ['[CLS] brieftly forgehawks husbandch [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.431 (perp=10.007, rec=0.335, cos=0.095), tot_loss_proj:2.965 [t=0.17s]
prediction: ['[CLS] brought straight during guard had straight [SEP]']
[ 100/2000] tot_loss=2.465 (perp=9.917, rec=0.352, cos=0.130), tot_loss_proj:3.734 [t=0.17s]
prediction: ['[CLS] run quickly. straight jr straight [SEP]']
[ 150/2000] tot_loss=2.449 (perp=10.989, rec=0.209, cos=0.042), tot_loss_proj:3.121 [t=0.17s]
prediction: ['[CLS] run quickly. straight squirrel straight [SEP]']
[ 200/2000] tot_loss=2.550 (perp=11.860, rec=0.151, cos=0.027), tot_loss_proj:3.085 [t=0.17s]
prediction: ['[CLS] ran quickly. straight squirrel straight [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.172 (perp=9.258, rec=0.248, cos=0.072), tot_loss_proj:3.138 [t=0.17s]
prediction: ['[CLS] ran quickly ran straight squirrel. [SEP]']
[ 300/2000] tot_loss=1.889 (perp=8.606, rec=0.134, cos=0.033), tot_loss_proj:2.894 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.876 (perp=8.606, rec=0.128, cos=0.026), tot_loss_proj:2.868 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.868 (perp=8.606, rec=0.124, cos=0.023), tot_loss_proj:2.863 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
[ 450/2000] tot_loss=1.847 (perp=8.606, rec=0.104, cos=0.022), tot_loss_proj:2.862 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.857 (perp=8.606, rec=0.114, cos=0.021), tot_loss_proj:2.862 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.849 (perp=8.606, rec=0.107, cos=0.021), tot_loss_proj:2.867 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
[ 600/2000] tot_loss=1.833 (perp=8.606, rec=0.092, cos=0.020), tot_loss_proj:2.864 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.842 (perp=8.606, rec=0.101, cos=0.020), tot_loss_proj:2.860 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.832 (perp=8.606, rec=0.091, cos=0.020), tot_loss_proj:2.856 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
[ 750/2000] tot_loss=1.834 (perp=8.606, rec=0.093, cos=0.021), tot_loss_proj:2.866 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.824 (perp=8.606, rec=0.082, cos=0.021), tot_loss_proj:2.857 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.831 (perp=8.606, rec=0.089, cos=0.020), tot_loss_proj:2.863 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
[ 900/2000] tot_loss=1.838 (perp=8.606, rec=0.096, cos=0.020), tot_loss_proj:2.868 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.835 (perp=8.606, rec=0.093, cos=0.020), tot_loss_proj:2.860 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.824 (perp=8.606, rec=0.083, cos=0.020), tot_loss_proj:2.858 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
[1050/2000] tot_loss=1.823 (perp=8.606, rec=0.081, cos=0.020), tot_loss_proj:2.863 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.820 (perp=8.606, rec=0.079, cos=0.020), tot_loss_proj:2.862 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight squirrel. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.614 (perp=7.558, rec=0.082, cos=0.020), tot_loss_proj:2.310 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
[1200/2000] tot_loss=1.623 (perp=7.558, rec=0.091, cos=0.020), tot_loss_proj:2.311 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.613 (perp=7.558, rec=0.081, cos=0.020), tot_loss_proj:2.313 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.618 (perp=7.558, rec=0.086, cos=0.020), tot_loss_proj:2.306 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
[1350/2000] tot_loss=1.614 (perp=7.558, rec=0.083, cos=0.020), tot_loss_proj:2.309 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.603 (perp=7.558, rec=0.071, cos=0.020), tot_loss_proj:2.308 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.610 (perp=7.558, rec=0.079, cos=0.020), tot_loss_proj:2.316 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
[1500/2000] tot_loss=1.610 (perp=7.558, rec=0.078, cos=0.020), tot_loss_proj:2.310 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.606 (perp=7.558, rec=0.075, cos=0.020), tot_loss_proj:2.302 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.613 (perp=7.558, rec=0.081, cos=0.020), tot_loss_proj:2.312 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
[1650/2000] tot_loss=1.611 (perp=7.558, rec=0.079, cos=0.020), tot_loss_proj:2.307 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.621 (perp=7.558, rec=0.089, cos=0.020), tot_loss_proj:2.307 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.616 (perp=7.558, rec=0.085, cos=0.020), tot_loss_proj:2.305 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
[1800/2000] tot_loss=1.614 (perp=7.558, rec=0.082, cos=0.020), tot_loss_proj:2.313 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.616 (perp=7.558, rec=0.085, cos=0.020), tot_loss_proj:2.309 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.616 (perp=7.558, rec=0.084, cos=0.020), tot_loss_proj:2.305 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
[1950/2000] tot_loss=1.617 (perp=7.558, rec=0.085, cos=0.020), tot_loss_proj:2.311 [t=0.18s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.609 (perp=7.558, rec=0.077, cos=0.020), tot_loss_proj:2.310 [t=0.17s]
prediction: ['[CLS] the quickly ran straight squirrel. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] the squirrel ran straight quickly. [SEP]
========================
predicted: 
========================
[CLS] the quickly ran straight squirrel. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 79.626 | p: 79.494 | r: 80.108
rouge2     | fm: 38.534 | p: 38.096 | r: 39.065
rougeL     | fm: 67.444 | p: 67.374 | r: 67.823
rougeLsum  | fm: 67.355 | p: 67.186 | r: 67.737
r1fm+r2fm = 118.160

input #69 time: 0:06:46 | total time: 8:08:33


Running input #70 of 100.
reference: 
========================
I assumed to be innocent
========================
Sample: 0 7.681698238507886e-13 0.052903979787665326 0.3515218
average of cosine similarity 0.9886099812715186
highest_index [0]
highest [0.9886099812715186]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 5071, 2000, 2022, 7036,  102]], device='cuda:0')
Debug: ref = ['[CLS] i assumed to be innocent [SEP]']
[Init] best rec loss: 0.7952191829681396 for ['[CLS] down op epithet medicine sick [SEP]']
[Init] best rec loss: 0.7703707814216614 for ['[CLS] small beings equation flightfall [SEP]']
[Init] best rec loss: 0.7321346402168274 for ['[CLS] allied breath road revelation airport [SEP]']
[Init] best rec loss: 0.728435754776001 for ['[CLS] [ across not inside stuff [SEP]']
[Init] best rec loss: 0.7198368906974792 for ['[CLS] breeding overseas signature activated points [SEP]']
[Init] best rec loss: 0.7161601781845093 for ['[CLS] honors protocolgne trackshis [SEP]']
[Init] best rec loss: 0.7038858532905579 for ['[CLS] oh kept middle pen opener [SEP]']
[Init] best perm rec loss: 0.7016999125480652 for ['[CLS] middle oh kept opener pen [SEP]']
[Init] best perm rec loss: 0.6995460987091064 for ['[CLS] pen opener kept middle oh [SEP]']
[Init] best perm rec loss: 0.6993598937988281 for ['[CLS] pen opener oh kept middle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.917 (perp=12.386, rec=0.383, cos=0.056), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS]able keeps " owned bo [SEP]']
[ 100/2000] tot_loss=2.547 (perp=11.134, rec=0.276, cos=0.044), tot_loss_proj:2.999 [t=0.17s]
prediction: ['[CLS] above assumed we being innocent [SEP]']
[ 150/2000] tot_loss=2.795 (perp=9.830, rec=0.651, cos=0.179), tot_loss_proj:2.710 [t=0.17s]
prediction: ['[CLS] i assumed been be innocent [SEP]']
[ 200/2000] tot_loss=2.661 (perp=10.691, rec=0.435, cos=0.088), tot_loss_proj:3.127 [t=0.17s]
prediction: ['[CLS] getting assumed seemed to brain [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.505 (perp=10.339, rec=0.372, cos=0.065), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] assumed seemed assumed to brain [SEP]']
[ 300/2000] tot_loss=2.349 (perp=9.815, rec=0.331, cos=0.055), tot_loss_proj:2.929 [t=0.17s]
prediction: ['[CLS] assumed be assumed to innocent [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.836 (perp=7.442, rec=0.296, cos=0.051), tot_loss_proj:2.410 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.816 (perp=7.442, rec=0.281, cos=0.047), tot_loss_proj:2.407 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[ 450/2000] tot_loss=1.789 (perp=7.442, rec=0.255, cos=0.046), tot_loss_proj:2.408 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.764 (perp=7.442, rec=0.232, cos=0.044), tot_loss_proj:2.408 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.725 (perp=7.442, rec=0.198, cos=0.039), tot_loss_proj:2.409 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[ 600/2000] tot_loss=1.706 (perp=7.442, rec=0.179, cos=0.038), tot_loss_proj:2.406 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.684 (perp=7.442, rec=0.158, cos=0.038), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.669 (perp=7.442, rec=0.143, cos=0.038), tot_loss_proj:2.408 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[ 750/2000] tot_loss=1.675 (perp=7.442, rec=0.149, cos=0.037), tot_loss_proj:2.415 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.666 (perp=7.442, rec=0.141, cos=0.037), tot_loss_proj:2.415 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.664 (perp=7.442, rec=0.138, cos=0.037), tot_loss_proj:2.416 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[ 900/2000] tot_loss=1.655 (perp=7.442, rec=0.129, cos=0.037), tot_loss_proj:2.418 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.657 (perp=7.442, rec=0.131, cos=0.037), tot_loss_proj:2.413 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.654 (perp=7.442, rec=0.128, cos=0.038), tot_loss_proj:2.420 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[1050/2000] tot_loss=1.661 (perp=7.442, rec=0.135, cos=0.038), tot_loss_proj:2.425 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.655 (perp=7.442, rec=0.129, cos=0.038), tot_loss_proj:2.424 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.648 (perp=7.442, rec=0.121, cos=0.038), tot_loss_proj:2.423 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[1200/2000] tot_loss=1.649 (perp=7.442, rec=0.122, cos=0.039), tot_loss_proj:2.427 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.647 (perp=7.442, rec=0.120, cos=0.039), tot_loss_proj:2.429 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.648 (perp=7.442, rec=0.121, cos=0.039), tot_loss_proj:2.434 [t=0.19s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[1350/2000] tot_loss=1.644 (perp=7.442, rec=0.117, cos=0.039), tot_loss_proj:2.432 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.644 (perp=7.442, rec=0.117, cos=0.039), tot_loss_proj:2.430 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.647 (perp=7.442, rec=0.120, cos=0.039), tot_loss_proj:2.431 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[1500/2000] tot_loss=1.647 (perp=7.442, rec=0.119, cos=0.039), tot_loss_proj:2.430 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.637 (perp=7.442, rec=0.110, cos=0.039), tot_loss_proj:2.435 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.644 (perp=7.442, rec=0.117, cos=0.039), tot_loss_proj:2.429 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[1650/2000] tot_loss=1.642 (perp=7.442, rec=0.115, cos=0.039), tot_loss_proj:2.440 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.650 (perp=7.442, rec=0.122, cos=0.039), tot_loss_proj:2.430 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.647 (perp=7.442, rec=0.120, cos=0.039), tot_loss_proj:2.438 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[1800/2000] tot_loss=1.651 (perp=7.442, rec=0.124, cos=0.039), tot_loss_proj:2.436 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.651 (perp=7.442, rec=0.124, cos=0.039), tot_loss_proj:2.439 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.651 (perp=7.442, rec=0.124, cos=0.039), tot_loss_proj:2.438 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
[1950/2000] tot_loss=1.641 (perp=7.442, rec=0.113, cos=0.039), tot_loss_proj:2.439 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.649 (perp=7.442, rec=0.122, cos=0.039), tot_loss_proj:2.436 [t=0.17s]
prediction: ['[CLS] assumed assumed to be innocent [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] i assumed to be innocent [SEP]
========================
predicted: 
========================
[CLS] assumed assumed to be innocent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 152.381

[Aggregate metrics]:
rouge1     | fm: 79.705 | p: 79.595 | r: 80.191
rouge2     | fm: 39.014 | p: 38.544 | r: 39.557
rougeL     | fm: 67.808 | p: 67.671 | r: 68.163
rougeLsum  | fm: 67.609 | p: 67.496 | r: 68.038
r1fm+r2fm = 118.719

input #70 time: 0:06:48 | total time: 8:15:21


Running input #71 of 100.
reference: 
========================
He could not have been working.
========================
Sample: 0 2.2022929279911505e-11 0.03867752569232572 0.27745122
average of cosine similarity 0.9902357066399525
highest_index [0]
highest [0.9902357066399525]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2071, 2025, 2031, 2042, 2551, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he could not have been working. [SEP]']
[Init] best rec loss: 0.9744415879249573 for ['[CLS] winston q officer obedience maize creamkha [SEP]']
[Init] best rec loss: 0.9726535677909851 for ['[CLS] [CLS] holt mls urgent we hey following [SEP]']
[Init] best rec loss: 0.9473275542259216 for ['[CLS] source outside fairias bullet tyson accepted [SEP]']
[Init] best rec loss: 0.9002900719642639 for ['[CLS] production gojn species leaderern led [SEP]']
[Init] best rec loss: 0.8908352255821228 for ['[CLS] sykested abbey rhodesonia ne air [SEP]']
[Init] best rec loss: 0.8839952945709229 for ['[CLS] or led olympic fish pe studiespeed [SEP]']
[Init] best rec loss: 0.880422055721283 for ['[CLS] vincent families ass factoryper inhabited heaven [SEP]']
[Init] best rec loss: 0.8727516531944275 for ['[CLS] helpayaion gun quartersrdatitles [SEP]']
[Init] best rec loss: 0.8656829595565796 for ['[CLS] justice liner contra godizes sin colt [SEP]']
[Init] best rec loss: 0.8539422154426575 for ['[CLS] territory dale sienna yao aggregator see mother [SEP]']
[Init] best perm rec loss: 0.853902280330658 for ['[CLS] see dale aggregator sienna territory mother yao [SEP]']
[Init] best perm rec loss: 0.8496488928794861 for ['[CLS] aggregator see dale sienna mother territory yao [SEP]']
[Init] best perm rec loss: 0.8492418527603149 for ['[CLS] see sienna dale territory yao aggregator mother [SEP]']
[Init] best perm rec loss: 0.8487892150878906 for ['[CLS] see dale territory sienna mother aggregator yao [SEP]']
[Init] best perm rec loss: 0.846971869468689 for ['[CLS] sienna dale mother see yao aggregator territory [SEP]']
[Init] best perm rec loss: 0.8467850089073181 for ['[CLS] see territory dale yao mother aggregator sienna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.418 (perp=9.334, rec=0.551, cos=1.000), tot_loss_proj:3.828 [t=0.17s]
prediction: ['[CLS] disney territory.. her capture thoughts [SEP]']
[ 100/2000] tot_loss=1.777 (perp=6.916, rec=0.304, cos=0.090), tot_loss_proj:3.299 [t=0.17s]
prediction: ['[CLS] not might... worked anyway [SEP]']
[ 150/2000] tot_loss=1.735 (perp=7.513, rec=0.195, cos=0.037), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS] not working.. could working he [SEP]']
[ 200/2000] tot_loss=2.024 (perp=9.242, rec=0.145, cos=0.030), tot_loss_proj:3.732 [t=0.17s]
prediction: ['[CLS] could working.. have working he [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.769 (perp=8.102, rec=0.123, cos=0.027), tot_loss_proj:3.634 [t=0.17s]
prediction: ['[CLS] could he.. have working working [SEP]']
[ 300/2000] tot_loss=1.816 (perp=8.400, rec=0.113, cos=0.023), tot_loss_proj:3.546 [t=0.17s]
prediction: ['[CLS] could he not. have working working [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.573 (perp=7.284, rec=0.094, cos=0.022), tot_loss_proj:3.326 [t=0.17s]
prediction: ['[CLS] he could not. have working working [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.501 (perp=6.915, rec=0.098, cos=0.020), tot_loss_proj:3.407 [t=0.17s]
prediction: ['[CLS] he could not. have working been [SEP]']
[ 450/2000] tot_loss=1.493 (perp=6.915, rec=0.090, cos=0.020), tot_loss_proj:3.407 [t=0.17s]
prediction: ['[CLS] he could not. have working been [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.255 (perp=5.748, rec=0.084, cos=0.021), tot_loss_proj:1.994 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.282 (perp=5.642, rec=0.126, cos=0.028), tot_loss_proj:2.867 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
[ 600/2000] tot_loss=1.254 (perp=5.642, rec=0.102, cos=0.023), tot_loss_proj:2.949 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.240 (perp=5.642, rec=0.089, cos=0.023), tot_loss_proj:2.951 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.238 (perp=5.642, rec=0.087, cos=0.023), tot_loss_proj:2.948 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
[ 750/2000] tot_loss=1.235 (perp=5.642, rec=0.084, cos=0.023), tot_loss_proj:2.949 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.237 (perp=5.642, rec=0.086, cos=0.023), tot_loss_proj:2.945 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.230 (perp=5.642, rec=0.080, cos=0.022), tot_loss_proj:2.950 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
[ 900/2000] tot_loss=1.238 (perp=5.642, rec=0.087, cos=0.022), tot_loss_proj:2.949 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.243 (perp=5.642, rec=0.092, cos=0.022), tot_loss_proj:2.948 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.233 (perp=5.642, rec=0.083, cos=0.022), tot_loss_proj:2.957 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
[1050/2000] tot_loss=1.235 (perp=5.642, rec=0.084, cos=0.022), tot_loss_proj:2.954 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.225 (perp=5.642, rec=0.074, cos=0.022), tot_loss_proj:2.953 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.230 (perp=5.642, rec=0.080, cos=0.022), tot_loss_proj:2.951 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
[1200/2000] tot_loss=1.229 (perp=5.642, rec=0.079, cos=0.022), tot_loss_proj:2.955 [t=0.17s]
prediction: ['[CLS] he could anyway have been working. [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.071 (perp=4.780, rec=0.092, cos=0.023), tot_loss_proj:1.659 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.058 (perp=4.780, rec=0.080, cos=0.022), tot_loss_proj:1.661 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
[1350/2000] tot_loss=1.063 (perp=4.780, rec=0.085, cos=0.022), tot_loss_proj:1.659 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.066 (perp=4.780, rec=0.088, cos=0.022), tot_loss_proj:1.656 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.058 (perp=4.780, rec=0.080, cos=0.022), tot_loss_proj:1.660 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
[1500/2000] tot_loss=1.055 (perp=4.780, rec=0.077, cos=0.022), tot_loss_proj:1.658 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.066 (perp=4.780, rec=0.088, cos=0.022), tot_loss_proj:1.656 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.047 (perp=4.780, rec=0.069, cos=0.022), tot_loss_proj:1.657 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
[1650/2000] tot_loss=1.064 (perp=4.780, rec=0.086, cos=0.022), tot_loss_proj:1.655 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.055 (perp=4.780, rec=0.078, cos=0.022), tot_loss_proj:1.658 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.063 (perp=4.780, rec=0.085, cos=0.022), tot_loss_proj:1.660 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
[1800/2000] tot_loss=1.058 (perp=4.780, rec=0.080, cos=0.022), tot_loss_proj:1.652 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.055 (perp=4.780, rec=0.077, cos=0.022), tot_loss_proj:1.654 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.055 (perp=4.780, rec=0.077, cos=0.022), tot_loss_proj:1.665 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
[1950/2000] tot_loss=1.053 (perp=4.780, rec=0.075, cos=0.022), tot_loss_proj:1.658 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.056 (perp=4.780, rec=0.079, cos=0.022), tot_loss_proj:1.649 [t=0.17s]
prediction: ['[CLS] he could have been working anyway. [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] he could not have been working. [SEP]
========================
predicted: 
========================
[CLS] he could not. have been working [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 80.020 | p: 79.918 | r: 80.490
rouge2     | fm: 39.731 | p: 39.342 | r: 40.330
rougeL     | fm: 68.224 | p: 68.048 | r: 68.550
rougeLsum  | fm: 68.045 | p: 67.873 | r: 68.445
r1fm+r2fm = 119.751

input #71 time: 0:06:54 | total time: 8:22:16


Running input #72 of 100.
reference: 
========================
He goes.
========================
Sample: 0 1.2968214753390664e-10 0.06068168695341905 0.36702558
average of cosine similarity 0.986237721228304
highest_index [0]
highest [0.986237721228304]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 2002, 3632, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he goes. [SEP]']
[Init] best rec loss: 0.9233094453811646 for ['[CLS] prior keynes latter [SEP]']
[Init] best rec loss: 0.8991621136665344 for ['[CLS] diver prism theme [SEP]']
[Init] best rec loss: 0.8955864310264587 for ['[CLS] bbc coat coin [SEP]']
[Init] best rec loss: 0.8779672980308533 for ['[CLS] gets handsome fever [SEP]']
[Init] best rec loss: 0.8525456190109253 for ['[CLS]cat soldina [SEP]']
[Init] best rec loss: 0.8413464426994324 for ['[CLS] shouldn might wight [SEP]']
[Init] best perm rec loss: 0.8409014940261841 for ['[CLS] might wight shouldn [SEP]']
[Init] best perm rec loss: 0.8379490971565247 for ['[CLS] shouldn wight might [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.360 (perp=9.655, rec=0.337, cos=0.092), tot_loss_proj:3.904 [t=0.17s]
prediction: ['[CLS] went. here [SEP]']
[ 100/2000] tot_loss=1.891 (perp=8.624, rec=0.130, cos=0.036), tot_loss_proj:3.662 [t=0.17s]
prediction: ['[CLS] he goes actually [SEP]']
[ 150/2000] tot_loss=1.195 (perp=5.241, rec=0.112, cos=0.034), tot_loss_proj:1.257 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 200/2000] tot_loss=1.201 (perp=5.241, rec=0.119, cos=0.034), tot_loss_proj:1.263 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.194 (perp=5.241, rec=0.111, cos=0.035), tot_loss_proj:1.257 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 300/2000] tot_loss=1.185 (perp=5.241, rec=0.104, cos=0.034), tot_loss_proj:1.248 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.194 (perp=5.241, rec=0.113, cos=0.033), tot_loss_proj:1.252 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.182 (perp=5.241, rec=0.097, cos=0.037), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 450/2000] tot_loss=1.173 (perp=5.241, rec=0.092, cos=0.033), tot_loss_proj:1.245 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.179 (perp=5.241, rec=0.098, cos=0.033), tot_loss_proj:1.255 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.164 (perp=5.241, rec=0.084, cos=0.032), tot_loss_proj:1.246 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 600/2000] tot_loss=1.156 (perp=5.241, rec=0.076, cos=0.032), tot_loss_proj:1.249 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.151 (perp=5.241, rec=0.072, cos=0.032), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.164 (perp=5.241, rec=0.085, cos=0.031), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 750/2000] tot_loss=1.167 (perp=5.241, rec=0.088, cos=0.032), tot_loss_proj:1.247 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.161 (perp=5.241, rec=0.082, cos=0.032), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.141 (perp=5.241, rec=0.061, cos=0.032), tot_loss_proj:1.246 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 900/2000] tot_loss=1.150 (perp=5.241, rec=0.070, cos=0.032), tot_loss_proj:1.245 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.160 (perp=5.241, rec=0.081, cos=0.032), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.152 (perp=5.241, rec=0.072, cos=0.031), tot_loss_proj:1.248 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1050/2000] tot_loss=1.155 (perp=5.241, rec=0.075, cos=0.032), tot_loss_proj:1.262 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.145 (perp=5.241, rec=0.066, cos=0.032), tot_loss_proj:1.249 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.155 (perp=5.241, rec=0.075, cos=0.032), tot_loss_proj:1.245 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1200/2000] tot_loss=1.151 (perp=5.241, rec=0.071, cos=0.032), tot_loss_proj:1.259 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.151 (perp=5.241, rec=0.071, cos=0.032), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.146 (perp=5.241, rec=0.066, cos=0.032), tot_loss_proj:1.251 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1350/2000] tot_loss=1.139 (perp=5.241, rec=0.059, cos=0.032), tot_loss_proj:1.259 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.164 (perp=5.241, rec=0.084, cos=0.032), tot_loss_proj:1.256 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.156 (perp=5.241, rec=0.077, cos=0.032), tot_loss_proj:1.257 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1500/2000] tot_loss=1.152 (perp=5.241, rec=0.072, cos=0.032), tot_loss_proj:1.259 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.156 (perp=5.241, rec=0.077, cos=0.032), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.150 (perp=5.241, rec=0.071, cos=0.032), tot_loss_proj:1.257 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1650/2000] tot_loss=1.152 (perp=5.241, rec=0.072, cos=0.032), tot_loss_proj:1.246 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.151 (perp=5.241, rec=0.071, cos=0.032), tot_loss_proj:1.261 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.148 (perp=5.241, rec=0.068, cos=0.032), tot_loss_proj:1.243 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1800/2000] tot_loss=1.153 (perp=5.241, rec=0.073, cos=0.032), tot_loss_proj:1.260 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.149 (perp=5.241, rec=0.069, cos=0.032), tot_loss_proj:1.258 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.158 (perp=5.241, rec=0.078, cos=0.032), tot_loss_proj:1.247 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1950/2000] tot_loss=1.156 (perp=5.241, rec=0.076, cos=0.032), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.155 (perp=5.241, rec=0.076, cos=0.032), tot_loss_proj:1.268 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] he goes. [SEP]
========================
predicted: 
========================
[CLS] he goes. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 80.333 | p: 80.178 | r: 80.725
rouge2     | fm: 40.554 | p: 40.175 | r: 41.106
rougeL     | fm: 68.615 | p: 68.492 | r: 68.932
rougeLsum  | fm: 68.465 | p: 68.316 | r: 68.847
r1fm+r2fm = 120.886

input #72 time: 0:06:43 | total time: 8:29:00


Running input #73 of 100.
reference: 
========================
This machine records well.
========================
Sample: 0 5.982537632719626e-12 0.04269555961999706 0.3368797
average of cosine similarity 0.991936182224942
highest_index [0]
highest [0.991936182224942]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2023, 3698, 2636, 2092, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] this machine records well. [SEP]']
[Init] best rec loss: 0.8837974071502686 for ['[CLS] miss violet chord parole tempo [SEP]']
[Init] best rec loss: 0.871936559677124 for ['[CLS]dilly records fortune instituteberry [SEP]']
[Init] best rec loss: 0.8340340852737427 for ['[CLS] guest brushed news pursuing church [SEP]']
[Init] best perm rec loss: 0.8322038054466248 for ['[CLS] brushed news church pursuing guest [SEP]']
[Init] best perm rec loss: 0.8311283588409424 for ['[CLS] brushed news guest pursuing church [SEP]']
[Init] best perm rec loss: 0.8308789730072021 for ['[CLS] brushed news pursuing guest church [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.352 (perp=9.725, rec=0.589, cos=0.818), tot_loss_proj:3.910 [t=0.17s]
prediction: ['[CLS]. which william, synthesis [SEP]']
[ 100/2000] tot_loss=2.860 (perp=8.765, rec=0.514, cos=0.593), tot_loss_proj:3.746 [t=0.17s]
prediction: ['[CLS]. which things. machine [SEP]']
[ 150/2000] tot_loss=2.736 (perp=7.899, rec=0.508, cos=0.648), tot_loss_proj:3.377 [t=0.17s]
prediction: ['[CLS]. timing machines. machine [SEP]']
[ 200/2000] tot_loss=2.931 (perp=10.834, rec=0.517, cos=0.247), tot_loss_proj:3.659 [t=0.17s]
prediction: ['[CLS]... early machines ; records [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.406 (perp=10.058, rec=0.320, cos=0.075), tot_loss_proj:3.886 [t=0.17s]
prediction: ['[CLS]... machines ; ] records [SEP]']
[ 300/2000] tot_loss=3.806 (perp=9.590, rec=0.926, cos=0.962), tot_loss_proj:3.878 [t=0.17s]
prediction: ['[CLS] this machine records myself records [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.408 (perp=9.021, rec=0.647, cos=0.957), tot_loss_proj:3.130 [t=0.17s]
prediction: ['[CLS]. machine tools records records [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.384 (perp=9.307, rec=0.577, cos=0.946), tot_loss_proj:3.868 [t=0.17s]
prediction: ['[CLS]. personally machine records records [SEP]']
[ 450/2000] tot_loss=3.577 (perp=10.502, rec=0.530, cos=0.946), tot_loss_proj:3.879 [t=0.17s]
prediction: ['[CLS].nen machine records records [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.453 (perp=10.047, rec=0.520, cos=0.924), tot_loss_proj:3.315 [t=0.17s]
prediction: ['[CLS] genes. machine records records [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=3.335 (perp=9.088, rec=0.574, cos=0.944), tot_loss_proj:3.855 [t=0.17s]
prediction: ['[CLS] machine ( records genes. [SEP]']
[ 600/2000] tot_loss=2.953 (perp=7.606, rec=0.498, cos=0.934), tot_loss_proj:3.322 [t=0.17s]
prediction: ['[CLS] machine records records genes. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.991 (perp=7.877, rec=0.478, cos=0.938), tot_loss_proj:3.524 [t=0.17s]
prediction: ['[CLS] machine records records pac. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.981 (perp=7.877, rec=0.466, cos=0.940), tot_loss_proj:3.522 [t=0.17s]
prediction: ['[CLS] machine records records pac. [SEP]']
[ 750/2000] tot_loss=2.973 (perp=7.877, rec=0.455, cos=0.942), tot_loss_proj:3.527 [t=0.17s]
prediction: ['[CLS] machine records records pac. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.970 (perp=7.877, rec=0.453, cos=0.942), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] machine records records pac. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.967 (perp=7.877, rec=0.450, cos=0.941), tot_loss_proj:3.526 [t=0.17s]
prediction: ['[CLS] machine records records pac. [SEP]']
[ 900/2000] tot_loss=2.950 (perp=7.877, rec=0.434, cos=0.940), tot_loss_proj:3.530 [t=0.17s]
prediction: ['[CLS] machine records records pac. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.782 (perp=7.014, rec=0.440, cos=0.940), tot_loss_proj:3.409 [t=0.17s]
prediction: ['[CLS] machine records records machine. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.779 (perp=7.014, rec=0.438, cos=0.938), tot_loss_proj:3.415 [t=0.17s]
prediction: ['[CLS] machine records records machine. [SEP]']
[1050/2000] tot_loss=2.774 (perp=7.014, rec=0.432, cos=0.938), tot_loss_proj:3.414 [t=0.17s]
prediction: ['[CLS] machine records records machine. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.774 (perp=7.014, rec=0.434, cos=0.938), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS] machine records records machine. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.760 (perp=7.014, rec=0.420, cos=0.937), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS] machine records records machine. [SEP]']
[1200/2000] tot_loss=2.766 (perp=7.014, rec=0.427, cos=0.936), tot_loss_proj:3.412 [t=0.17s]
prediction: ['[CLS] machine records records machine. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.765 (perp=7.014, rec=0.426, cos=0.936), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS] machine records records machine. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.766 (perp=7.014, rec=0.428, cos=0.936), tot_loss_proj:3.414 [t=0.17s]
prediction: ['[CLS] machine records records machine. [SEP]']
[1350/2000] tot_loss=2.731 (perp=6.875, rec=0.420, cos=0.935), tot_loss_proj:3.415 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.729 (perp=6.875, rec=0.419, cos=0.934), tot_loss_proj:3.410 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.723 (perp=6.875, rec=0.414, cos=0.934), tot_loss_proj:3.408 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
[1500/2000] tot_loss=2.723 (perp=6.875, rec=0.414, cos=0.934), tot_loss_proj:3.412 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
Attempt swap
[1550/2000] tot_loss=2.728 (perp=6.875, rec=0.419, cos=0.934), tot_loss_proj:3.411 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.728 (perp=6.875, rec=0.420, cos=0.933), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
[1650/2000] tot_loss=2.716 (perp=6.875, rec=0.408, cos=0.933), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.720 (perp=6.875, rec=0.412, cos=0.933), tot_loss_proj:3.412 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.713 (perp=6.875, rec=0.405, cos=0.933), tot_loss_proj:3.409 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
[1800/2000] tot_loss=2.715 (perp=6.875, rec=0.407, cos=0.932), tot_loss_proj:3.411 [t=0.19s]
prediction: ['[CLS] machine records records originally. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.720 (perp=6.875, rec=0.413, cos=0.932), tot_loss_proj:3.410 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.721 (perp=6.875, rec=0.415, cos=0.932), tot_loss_proj:3.414 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
[1950/2000] tot_loss=2.719 (perp=6.875, rec=0.412, cos=0.932), tot_loss_proj:3.409 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.719 (perp=6.875, rec=0.412, cos=0.931), tot_loss_proj:3.409 [t=0.17s]
prediction: ['[CLS] machine records records originally. [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] this machine records well. [SEP]
========================
predicted: 
========================
[CLS] this machine records enough records [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 54.545 | p: 50.000 | r: 60.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 131.469

[Aggregate metrics]:
rouge1     | fm: 80.193 | p: 80.035 | r: 80.745
rouge2     | fm: 40.843 | p: 40.404 | r: 41.514
rougeL     | fm: 68.745 | p: 68.554 | r: 69.226
rougeLsum  | fm: 68.595 | p: 68.279 | r: 69.139
r1fm+r2fm = 121.037

input #73 time: 0:06:46 | total time: 8:35:46


Running input #74 of 100.
reference: 
========================
Love her though I may, that won't affect the grade.
========================
Sample: 0 5.744379687675696e-13 0.04757583871675091 0.30800343
average of cosine similarity 0.9879982258518754
highest_index [0]
highest [0.9879982258518754]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2293, 2014, 2295, 1045, 2089, 1010, 2008, 2180, 1005, 1056, 7461,
         1996, 3694, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] love her though i may, that won't affect the grade. [SEP]"]
[Init] best rec loss: 1.0024644136428833 for ['[CLS] charm joke classification lemon vhs d （ alzheimer minogueify gunslinger part used club [SEP]']
[Init] best rec loss: 0.9267971515655518 for ['[CLS] blast health charliebase can through letterns door alternatives attenditatedatin competed [SEP]']
[Init] best rec loss: 0.9037371873855591 for ['[CLS] passed eva with two history outward box cai shuffleeritt wonders temple aware [SEP]']
[Init] best rec loss: 0.892467737197876 for ['[CLS] orient conner dresser canada came belly sing sri front jacobdate pharaoh? devon [SEP]']
[Init] best rec loss: 0.875771701335907 for ['[CLS] inflation frowned knew clapped rosalie executed affecteda wild blue keptrcle za rafe [SEP]']
[Init] best rec loss: 0.8655742406845093 for ['[CLS] dot topic strip investigation kg facing chang mani causedond have millie bank divided [SEP]']
[Init] best rec loss: 0.854909360408783 for ['[CLS] par animals gavin hokkaido fisherman gttwined yetrgy sexual thank sophia aim gag [SEP]']
[Init] best perm rec loss: 0.8548519015312195 for ['[CLS] hokkaido gt thank par sophiatwinedrgy aim yet gavin fisherman gag animals sexual [SEP]']
[Init] best perm rec loss: 0.8532049655914307 for ['[CLS] animalsrgy gag aim sophia hokkaido fisherman par thank sexual gt gavin yettwined [SEP]']
[Init] best perm rec loss: 0.8515307903289795 for ['[CLS]rgy gag sophia sexual gavintwined thank fisherman par hokkaido aim animals gt yet [SEP]']
[Init] best perm rec loss: 0.84995037317276 for ['[CLS] parrgy sophiatwined gavin aim thank gt sexual yet fisherman animals hokkaido gag [SEP]']
[Init] best perm rec loss: 0.8490588068962097 for ['[CLS] sexualrgy animals gavin gag fisherman partwined hokkaido aim gt thank yet sophia [SEP]']
[Init] best perm rec loss: 0.8482096195220947 for ['[CLS] aim thank animalstwined par gavin hokkaido yetrgy fisherman gag sexual gt sophia [SEP]']
[Init] best perm rec loss: 0.8481844067573547 for ['[CLS] par gavin hokkaido thank fishermantwined sexual gag aim yet gtrgy sophia animals [SEP]']
[Init] best perm rec loss: 0.845284104347229 for ['[CLS] sexual gagtwined sophia gavin gt thank hokkaido fisherman animals yetrgy par aim [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.778 (perp=11.228, rec=0.418, cos=0.115), tot_loss_proj:4.204 [t=0.17s]
prediction: ['[CLS] because : spur bush who hate cellular meantime, turning depression love az historical [SEP]']
[ 100/2000] tot_loss=2.915 (perp=11.718, rec=0.430, cos=0.141), tot_loss_proj:4.254 [t=0.17s]
prediction: ['[CLS] love roller girl never. almost bench flower " love ( preach in ; [SEP]']
[ 150/2000] tot_loss=3.139 (perp=12.078, rec=0.499, cos=0.224), tot_loss_proj:4.316 [t=0.17s]
prediction: ['[CLS] love sponge pity neverou never becausele. love her malley studying ; [SEP]']
[ 200/2000] tot_loss=2.397 (perp=10.236, rec=0.285, cos=0.065), tot_loss_proj:3.982 [t=0.17s]
prediction: ['[CLS] feel sponge pity never. never hate eventually. love her ، grade. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.282 (perp=9.616, rec=0.289, cos=0.070), tot_loss_proj:3.812 [t=0.17s]
prediction: ['[CLS] feel her but never ( never obviously tooth. love three whether grade. [SEP]']
[ 300/2000] tot_loss=2.110 (perp=9.114, rec=0.244, cos=0.043), tot_loss_proj:3.713 [t=0.17s]
prediction: ['[CLS] feel her but never. never obviously tooth. love angry without grade. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.929 (perp=8.334, rec=0.226, cos=0.036), tot_loss_proj:3.572 [t=0.17s]
prediction: ['[CLS] ; her but never. never if angry. love tooth though grade. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.849 (perp=7.944, rec=0.223, cos=0.038), tot_loss_proj:3.485 [t=0.17s]
prediction: ['[CLS] her ; but never. never if angry. love hearted though grade. [SEP]']
[ 450/2000] tot_loss=1.812 (perp=7.698, rec=0.230, cos=0.043), tot_loss_proj:3.448 [t=0.17s]
prediction: ['[CLS] her ; but never. never because honest. love sided though grade. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.966 (perp=8.687, rec=0.195, cos=0.033), tot_loss_proj:3.619 [t=0.17s]
prediction: ['[CLS] her though but grade. never because honest. love sided though never. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.950 (perp=11.556, rec=0.465, cos=0.174), tot_loss_proj:4.211 [t=0.17s]
prediction: ['[CLS] not her blake grade but society though your. love ended represents藤 affect [SEP]']
[ 600/2000] tot_loss=2.622 (perp=11.016, rec=0.345, cos=0.073), tot_loss_proj:4.076 [t=0.17s]
prediction: ['[CLS] wrote her pity grade, society though site. love ended represents藤 affect [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.628 (perp=11.291, rec=0.304, cos=0.065), tot_loss_proj:4.163 [t=0.17s]
prediction: ['[CLS] love her my grade, never though #. love ended represents affect decker [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.245 (perp=9.557, rec=0.280, cos=0.054), tot_loss_proj:3.834 [t=0.17s]
prediction: ['[CLS] love her please grade, never though love ended would affect decker #. [SEP]']
[ 750/2000] tot_loss=2.268 (perp=9.867, rec=0.252, cos=0.043), tot_loss_proj:3.838 [t=0.17s]
prediction: ['[CLS] love her her grade, never though love ended would affect prostate #. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.069 (perp=8.618, rec=0.287, cos=0.059), tot_loss_proj:3.626 [t=0.17s]
prediction: ['[CLS] love her grade but never though love hearted would affect my fortune /. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.887 (perp=7.958, rec=0.251, cos=0.045), tot_loss_proj:3.512 [t=0.17s]
prediction: ['[CLS] her love grade, never though love consolation would affect my fortune #. [SEP]']
[ 900/2000] tot_loss=1.854 (perp=7.868, rec=0.239, cos=0.042), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] her love grade, never though love would would affect my luck #. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.805 (perp=7.704, rec=0.224, cos=0.040), tot_loss_proj:3.430 [t=0.17s]
prediction: ['[CLS] her love grade, never though love would affect my luck # would. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.862 (perp=7.975, rec=0.229, cos=0.037), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] her love brewing, never though love would affect my grade # would. [SEP]']
[1050/2000] tot_loss=1.788 (perp=7.666, rec=0.218, cos=0.036), tot_loss_proj:3.457 [t=0.17s]
prediction: ['[CLS] her love healing, never though love would affect my grade his would. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.817 (perp=7.828, rec=0.215, cos=0.036), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS] her love healing, that though love would affect my grade his would. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.813 (perp=7.828, rec=0.212, cos=0.036), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] her love healing, that though love would affect my grade his would. [SEP]']
[1200/2000] tot_loss=1.808 (perp=7.828, rec=0.207, cos=0.035), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] her love healing, that though love would affect my grade his would. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.795 (perp=7.828, rec=0.195, cos=0.035), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] her love healing, that though love would affect my grade his would. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.804 (perp=7.828, rec=0.204, cos=0.035), tot_loss_proj:3.495 [t=0.17s]
prediction: ['[CLS] her love healing, that though love would affect my grade his would. [SEP]']
[1350/2000] tot_loss=1.791 (perp=7.828, rec=0.191, cos=0.034), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS] her love healing, that though love would affect my grade his would. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.760 (perp=7.677, rec=0.190, cos=0.035), tot_loss_proj:3.465 [t=0.17s]
prediction: ['[CLS] her love healing, that though would would affect my grade his love. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.705 (perp=7.398, rec=0.188, cos=0.036), tot_loss_proj:3.405 [t=0.17s]
prediction: ['[CLS] her love that healing, though would would affect my grade his love. [SEP]']
[1500/2000] tot_loss=1.704 (perp=7.398, rec=0.190, cos=0.034), tot_loss_proj:3.411 [t=0.17s]
prediction: ['[CLS] her love that healing, though would would affect my grade his love. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.702 (perp=7.398, rec=0.189, cos=0.034), tot_loss_proj:3.409 [t=0.17s]
prediction: ['[CLS] her love that healing, though would would affect my grade his love. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.635 (perp=7.064, rec=0.188, cos=0.034), tot_loss_proj:3.338 [t=0.20s]
prediction: ['[CLS] her love that healing, though would would affect his grade my love. [SEP]']
[1650/2000] tot_loss=1.633 (perp=7.064, rec=0.186, cos=0.034), tot_loss_proj:3.331 [t=0.19s]
prediction: ['[CLS] her love that healing, though would would affect his grade my love. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.626 (perp=7.064, rec=0.179, cos=0.034), tot_loss_proj:3.330 [t=0.17s]
prediction: ['[CLS] her love that healing, though would would affect his grade my love. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.618 (perp=7.064, rec=0.172, cos=0.033), tot_loss_proj:3.331 [t=0.17s]
prediction: ['[CLS] her love that healing, though would would affect his grade my love. [SEP]']
[1800/2000] tot_loss=1.645 (perp=7.209, rec=0.170, cos=0.033), tot_loss_proj:3.339 [t=0.17s]
prediction: ['[CLS] her love that healing, though would will affect his grade my love. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.651 (perp=7.209, rec=0.176, cos=0.033), tot_loss_proj:3.340 [t=0.17s]
prediction: ['[CLS] her love that healing, though would will affect his grade my love. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.659 (perp=7.209, rec=0.184, cos=0.033), tot_loss_proj:3.337 [t=0.17s]
prediction: ['[CLS] her love that healing, though would will affect his grade my love. [SEP]']
[1950/2000] tot_loss=1.657 (perp=7.209, rec=0.183, cos=0.033), tot_loss_proj:3.336 [t=0.17s]
prediction: ['[CLS] her love that healing, though would will affect his grade my love. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.651 (perp=7.209, rec=0.176, cos=0.033), tot_loss_proj:3.337 [t=0.17s]
prediction: ['[CLS] her love that healing, though would will affect his grade my love. [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] love her though i may, that won't affect the grade. [SEP]
========================
predicted: 
========================
[CLS] her love that healing, though would will affect his grade my love. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 59.259 | p: 57.143 | r: 61.538
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 42.857 | r: 46.154
rougeLsum  | fm: 44.444 | p: 42.857 | r: 46.154
r1fm+r2fm = 59.259

[Aggregate metrics]:
rouge1     | fm: 80.027 | p: 79.726 | r: 80.531
rouge2     | fm: 40.380 | p: 39.972 | r: 40.941
rougeL     | fm: 68.378 | p: 68.155 | r: 68.929
rougeLsum  | fm: 68.236 | p: 67.978 | r: 68.771
r1fm+r2fm = 120.406

input #74 time: 0:06:59 | total time: 8:42:46


Running input #75 of 100.
reference: 
========================
I have been flying helicopters for years.
========================
Sample: 0 9.437708130565875e-12 0.05485609728793578 0.37021896
average of cosine similarity 0.9889615398579872
highest_index [0]
highest [0.9889615398579872]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1045,  2031,  2042,  3909, 12400,  2005,  2086,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have been flying helicopters for years. [SEP]']
[Init] best rec loss: 0.9605770111083984 for ['[CLS] lindsey exposed gov recreation touch approaching lack troubles [SEP]']
[Init] best rec loss: 0.9479166865348816 for ['[CLS] typical who paul slavery { distinction summit loop [SEP]']
[Init] best rec loss: 0.9144813418388367 for ['[CLS] caineding venture goethe protocolht base great [SEP]']
[Init] best perm rec loss: 0.9137658476829529 for ['[CLS]ding goethe great caine base protocol ventureht [SEP]']
[Init] best perm rec loss: 0.9111108779907227 for ['[CLS] caineding venture goethe baseht great protocol [SEP]']
[Init] best perm rec loss: 0.9083705544471741 for ['[CLS] goethe caine ventureding base protocol greatht [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.851 (perp=11.173, rec=0.701, cos=0.916), tot_loss_proj:4.022 [t=0.17s]
prediction: ['[CLS] c toward as getting fiber. = sold [SEP]']
[ 100/2000] tot_loss=3.418 (perp=9.170, rec=0.584, cos=1.000), tot_loss_proj:3.642 [t=0.17s]
prediction: ['[CLS] i engines had flying helicopter. famine. [SEP]']
[ 150/2000] tot_loss=3.850 (perp=11.050, rec=0.643, cos=0.997), tot_loss_proj:3.975 [t=0.17s]
prediction: ['[CLS] without after had flying helicopter. reign that [SEP]']
[ 200/2000] tot_loss=2.672 (perp=11.536, rec=0.308, cos=0.057), tot_loss_proj:4.191 [t=0.17s]
prediction: ['[CLS] psi. been flying helicopter. snort helicopters [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.485 (perp=10.964, rec=0.250, cos=0.042), tot_loss_proj:4.004 [t=0.17s]
prediction: ['[CLS] gi because fromently been flying helicopters i [SEP]']
[ 300/2000] tot_loss=2.131 (perp=9.689, rec=0.165, cos=0.028), tot_loss_proj:3.768 [t=0.17s]
prediction: ['[CLS] spirit have have years been flying helicopters i [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.890 (perp=8.566, rec=0.149, cos=0.028), tot_loss_proj:3.575 [t=0.17s]
prediction: ['[CLS] spirit have i have years been flying helicopters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.565 (perp=7.054, rec=0.127, cos=0.028), tot_loss_proj:3.307 [t=0.17s]
prediction: ['[CLS] because have i have years been flying helicopters [SEP]']
[ 450/2000] tot_loss=1.567 (perp=7.054, rec=0.129, cos=0.027), tot_loss_proj:3.304 [t=0.17s]
prediction: ['[CLS] because have i have years been flying helicopters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.784 (perp=8.210, rec=0.115, cos=0.027), tot_loss_proj:3.615 [t=0.17s]
prediction: ['[CLS] because have i. years been flying helicopters [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.662 (perp=7.566, rec=0.122, cos=0.027), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] because i have. years been flying helicopters [SEP]']
[ 600/2000] tot_loss=1.657 (perp=7.566, rec=0.118, cos=0.026), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] because i have. years been flying helicopters [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.667 (perp=7.348, rec=0.169, cos=0.028), tot_loss_proj:3.569 [t=0.17s]
prediction: ['[CLS]. i have years been flying helicopters have [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.896 (perp=8.582, rec=0.150, cos=0.029), tot_loss_proj:3.762 [t=0.17s]
prediction: ['[CLS] i have years been flying combination helicopters have [SEP]']
[ 750/2000] tot_loss=1.876 (perp=8.582, rec=0.132, cos=0.028), tot_loss_proj:3.749 [t=0.17s]
prediction: ['[CLS] i have years been flying combination helicopters have [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.455 (perp=6.502, rec=0.127, cos=0.028), tot_loss_proj:1.663 [t=0.17s]
prediction: ['[CLS] i have been flying combination helicopters for years [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.382 (perp=6.143, rec=0.126, cos=0.028), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
[ 900/2000] tot_loss=1.378 (perp=6.143, rec=0.123, cos=0.027), tot_loss_proj:3.174 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.377 (perp=6.143, rec=0.121, cos=0.027), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1000/2000] tot_loss=1.372 (perp=6.143, rec=0.117, cos=0.027), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
[1050/2000] tot_loss=1.373 (perp=6.143, rec=0.118, cos=0.026), tot_loss_proj:3.178 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1100/2000] tot_loss=1.366 (perp=6.143, rec=0.111, cos=0.026), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1150/2000] tot_loss=1.360 (perp=6.143, rec=0.106, cos=0.026), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
[1200/2000] tot_loss=1.371 (perp=6.143, rec=0.117, cos=0.026), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1250/2000] tot_loss=1.363 (perp=6.143, rec=0.109, cos=0.026), tot_loss_proj:3.178 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1300/2000] tot_loss=1.358 (perp=6.143, rec=0.103, cos=0.026), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
[1350/2000] tot_loss=1.354 (perp=6.143, rec=0.100, cos=0.025), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1400/2000] tot_loss=1.355 (perp=6.143, rec=0.101, cos=0.025), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1450/2000] tot_loss=1.349 (perp=6.143, rec=0.095, cos=0.025), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
[1500/2000] tot_loss=1.357 (perp=6.143, rec=0.103, cos=0.025), tot_loss_proj:3.175 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1550/2000] tot_loss=1.347 (perp=6.143, rec=0.094, cos=0.025), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1600/2000] tot_loss=1.354 (perp=6.143, rec=0.100, cos=0.025), tot_loss_proj:3.181 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
[1650/2000] tot_loss=1.355 (perp=6.143, rec=0.101, cos=0.025), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1700/2000] tot_loss=1.352 (perp=6.143, rec=0.099, cos=0.025), tot_loss_proj:3.178 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1750/2000] tot_loss=1.355 (perp=6.143, rec=0.102, cos=0.025), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
[1800/2000] tot_loss=1.352 (perp=6.143, rec=0.099, cos=0.025), tot_loss_proj:3.175 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1850/2000] tot_loss=1.357 (perp=6.143, rec=0.104, cos=0.025), tot_loss_proj:3.178 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[1900/2000] tot_loss=1.353 (perp=6.143, rec=0.100, cos=0.025), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
[1950/2000] tot_loss=1.355 (perp=6.143, rec=0.102, cos=0.025), tot_loss_proj:3.178 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Attempt swap
[2000/2000] tot_loss=1.352 (perp=6.143, rec=0.099, cos=0.025), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS] combination i have been flying helicopters for years [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] i have been flying helicopters for years. [SEP]
========================
predicted: 
========================
[CLS] combination i have been flying helicopters for years [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 82.353 | p: 77.778 | r: 87.500
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 177.090

[Aggregate metrics]:
rouge1     | fm: 80.211 | p: 79.924 | r: 80.790
rouge2     | fm: 40.717 | p: 40.253 | r: 41.437
rougeL     | fm: 68.793 | p: 68.491 | r: 69.258
rougeLsum  | fm: 68.686 | p: 68.396 | r: 69.278
r1fm+r2fm = 120.928

input #75 time: 0:06:52 | total time: 8:49:39


Running input #76 of 100.
reference: 
========================
the person stand on my foot is heavy.
========================
Sample: 0 6.255252329912438e-13 0.04756341703721848 0.3631259
average of cosine similarity 0.991384639125785
highest_index [0]
highest [0.991384639125785]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2711, 3233, 2006, 2026, 3329, 2003, 3082, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the person stand on my foot is heavy. [SEP]']
[Init] best rec loss: 0.8294539451599121 for ['[CLS] yes motorway has entering lin trust d dante without [SEP]']
[Init] best rec loss: 0.8037463426589966 for ['[CLS] concrete supportke police liszt gracelay masjid empress [SEP]']
[Init] best rec loss: 0.798318088054657 for ['[CLS] right atgang connecting naturalistpy half use feud [SEP]']
[Init] best rec loss: 0.7697778344154358 for ['[CLS] speech largest endemicner flow stateism decenttrust [SEP]']
[Init] best rec loss: 0.7677800059318542 for ['[CLS] tag merlin heardhang land anywayimeter anastasia compare [SEP]']
[Init] best rec loss: 0.7535086870193481 for ['[CLS]xt missionary drive draft vancouver camp glory walker un [SEP]']
[Init] best rec loss: 0.7463003396987915 for ['[CLS] faster hope outcome scribe windsor cherry zoe pounder viewing [SEP]']
[Init] best rec loss: 0.6924082636833191 for ['[CLS] landfall day resulted kenton institute kate holland learning recorder [SEP]']
[Init] best rec loss: 0.68180251121521 for ['[CLS] officer laughed reigning taking chronic oldborn coupled meeting [SEP]']
[Init] best perm rec loss: 0.6811312437057495 for ['[CLS] meeting laughed taking old officer chronicborn reigning coupled [SEP]']
[Init] best perm rec loss: 0.6787684559822083 for ['[CLS] reigningborn laughed officer taking meeting coupled old chronic [SEP]']
[Init] best perm rec loss: 0.6758812665939331 for ['[CLS] laughed officer old reigning taking coupled meeting chronicborn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.307 (perp=9.595, rec=0.358, cos=0.031), tot_loss_proj:2.854 [t=0.17s]
prediction: ['[CLS] one personw from taking is discus runner person [SEP]']
[ 100/2000] tot_loss=2.725 (perp=12.021, rec=0.296, cos=0.025), tot_loss_proj:3.437 [t=0.17s]
prediction: ['[CLS] person personw heavy stand on boots foot person [SEP]']
[ 150/2000] tot_loss=2.390 (perp=10.562, rec=0.252, cos=0.026), tot_loss_proj:3.185 [t=0.17s]
prediction: ['[CLS] person person heavy heavy stand on heavy foot person [SEP]']
[ 200/2000] tot_loss=2.381 (perp=10.562, rec=0.235, cos=0.034), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] person person heavy heavy stand on heavy foot person [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.196 (perp=9.474, rec=0.274, cos=0.028), tot_loss_proj:2.539 [t=0.17s]
prediction: ['[CLS] the heavy was person stand on heavy foot person [SEP]']
[ 300/2000] tot_loss=2.136 (perp=9.739, rec=0.166, cos=0.022), tot_loss_proj:2.690 [t=0.17s]
prediction: ['[CLS] the my is person stand on heavy foot person [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.752 (perp=7.928, rec=0.145, cos=0.021), tot_loss_proj:3.052 [t=0.17s]
prediction: ['[CLS] the person is my stand on heavy foot person [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.751 (perp=7.832, rec=0.162, cos=0.023), tot_loss_proj:2.587 [t=0.17s]
prediction: ['[CLS] the person is my foot stand on foot person [SEP]']
[ 450/2000] tot_loss=1.709 (perp=7.832, rec=0.121, cos=0.022), tot_loss_proj:2.563 [t=0.17s]
prediction: ['[CLS] the person is my foot stand on foot person [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.573 (perp=7.169, rec=0.118, cos=0.021), tot_loss_proj:2.152 [t=0.17s]
prediction: ['[CLS] the person foot is my stand on foot person [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.696 (perp=7.768, rec=0.122, cos=0.021), tot_loss_proj:2.590 [t=0.17s]
prediction: ['[CLS] the person heavy is my stand on foot person [SEP]']
[ 600/2000] tot_loss=1.684 (perp=7.768, rec=0.109, cos=0.021), tot_loss_proj:2.594 [t=0.17s]
prediction: ['[CLS] the person heavy is my stand on foot person [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.684 (perp=7.768, rec=0.109, cos=0.021), tot_loss_proj:2.597 [t=0.17s]
prediction: ['[CLS] the person heavy is my stand on foot person [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.670 (perp=7.768, rec=0.096, cos=0.021), tot_loss_proj:2.592 [t=0.17s]
prediction: ['[CLS] the person heavy is my stand on foot person [SEP]']
[ 750/2000] tot_loss=1.680 (perp=7.768, rec=0.106, cos=0.021), tot_loss_proj:2.599 [t=0.17s]
prediction: ['[CLS] the person heavy is my stand on foot person [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.674 (perp=7.768, rec=0.099, cos=0.021), tot_loss_proj:2.591 [t=0.17s]
prediction: ['[CLS] the person heavy is my stand on foot person [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.680 (perp=7.768, rec=0.106, cos=0.021), tot_loss_proj:2.594 [t=0.17s]
prediction: ['[CLS] the person heavy is my stand on foot person [SEP]']
[ 900/2000] tot_loss=1.681 (perp=7.768, rec=0.107, cos=0.020), tot_loss_proj:2.602 [t=0.17s]
prediction: ['[CLS] the person heavy is my stand on foot person [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.669 (perp=7.750, rec=0.099, cos=0.021), tot_loss_proj:1.984 [t=0.17s]
prediction: ['[CLS] the person stand is my heavy on foot person [SEP]']
Attempt swap
[1000/2000] tot_loss=1.653 (perp=7.750, rec=0.083, cos=0.020), tot_loss_proj:1.984 [t=0.17s]
prediction: ['[CLS] the person stand is my heavy on foot person [SEP]']
[1050/2000] tot_loss=1.661 (perp=7.750, rec=0.091, cos=0.020), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS] the person stand is my heavy on foot person [SEP]']
Attempt swap
[1100/2000] tot_loss=1.662 (perp=7.750, rec=0.092, cos=0.020), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] the person stand is my heavy on foot person [SEP]']
Attempt swap
[1150/2000] tot_loss=1.666 (perp=7.750, rec=0.096, cos=0.020), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] the person stand is my heavy on foot person [SEP]']
[1200/2000] tot_loss=1.660 (perp=7.750, rec=0.091, cos=0.020), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] the person stand is my heavy on foot person [SEP]']
Attempt swap
[1250/2000] tot_loss=1.659 (perp=7.750, rec=0.089, cos=0.020), tot_loss_proj:1.981 [t=0.20s]
prediction: ['[CLS] the person stand is my heavy on foot person [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.609 (perp=7.400, rec=0.109, cos=0.021), tot_loss_proj:1.913 [t=0.17s]
prediction: ['[CLS] the person stand is my heavy person on foot [SEP]']
[1350/2000] tot_loss=1.589 (perp=7.400, rec=0.090, cos=0.020), tot_loss_proj:1.910 [t=0.17s]
prediction: ['[CLS] the person stand is my heavy person on foot [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.579 (perp=7.347, rec=0.090, cos=0.019), tot_loss_proj:1.950 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
Attempt swap
[1450/2000] tot_loss=1.578 (perp=7.347, rec=0.089, cos=0.019), tot_loss_proj:1.945 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
[1500/2000] tot_loss=1.580 (perp=7.347, rec=0.091, cos=0.019), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
Attempt swap
[1550/2000] tot_loss=1.581 (perp=7.347, rec=0.092, cos=0.019), tot_loss_proj:1.945 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
Attempt swap
[1600/2000] tot_loss=1.571 (perp=7.347, rec=0.082, cos=0.019), tot_loss_proj:1.952 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
[1650/2000] tot_loss=1.579 (perp=7.347, rec=0.091, cos=0.019), tot_loss_proj:1.946 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
Attempt swap
[1700/2000] tot_loss=1.573 (perp=7.347, rec=0.085, cos=0.019), tot_loss_proj:1.952 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
Attempt swap
[1750/2000] tot_loss=1.565 (perp=7.347, rec=0.077, cos=0.019), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
[1800/2000] tot_loss=1.571 (perp=7.347, rec=0.083, cos=0.019), tot_loss_proj:1.951 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
Attempt swap
[1850/2000] tot_loss=1.577 (perp=7.347, rec=0.088, cos=0.019), tot_loss_proj:1.946 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
Attempt swap
[1900/2000] tot_loss=1.567 (perp=7.347, rec=0.079, cos=0.019), tot_loss_proj:1.939 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
[1950/2000] tot_loss=1.573 (perp=7.347, rec=0.085, cos=0.019), tot_loss_proj:1.950 [t=0.19s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
Attempt swap
[2000/2000] tot_loss=1.570 (perp=7.347, rec=0.082, cos=0.019), tot_loss_proj:1.946 [t=0.17s]
prediction: ['[CLS] the person stand is my person heavy on foot [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS] the person stand on my foot is heavy. [SEP]
========================
predicted: 
========================
[CLS] the person stand is my person heavy on foot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 31.579 | p: 30.000 | r: 33.333
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 126.817

[Aggregate metrics]:
rouge1     | fm: 80.396 | p: 80.070 | r: 81.026
rouge2     | fm: 40.753 | p: 40.208 | r: 41.430
rougeL     | fm: 68.687 | p: 68.390 | r: 69.335
rougeLsum  | fm: 68.618 | p: 68.216 | r: 69.218
r1fm+r2fm = 121.148

input #76 time: 0:06:52 | total time: 8:56:31


Running input #77 of 100.
reference: 
========================
My mother baked a cake for me.
========================
Sample: 0 5.61456726910697e-13 0.05123028055278625 0.36143658
average of cosine similarity 0.9899038273142409
highest_index [0]
highest [0.9899038273142409]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2026,  2388, 17776,  1037,  9850,  2005,  2033,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] my mother baked a cake for me. [SEP]']
[Init] best rec loss: 1.0671769380569458 for ['[CLS] mysterious statistical its owner soft bodo network posting [SEP]']
[Init] best rec loss: 1.0210918188095093 for ['[CLS] baby jolink & spinal is andre youngest [SEP]']
[Init] best rec loss: 0.978882372379303 for ['[CLS] helmetgating shaking external closed )ations oldest [SEP]']
[Init] best rec loss: 0.977277934551239 for ['[CLS] catch as [UNK] visitraph meet found your [SEP]']
[Init] best rec loss: 0.9744843244552612 for ['[CLS] voice free knuckles citizen dean senior private much [SEP]']
[Init] best perm rec loss: 0.968231201171875 for ['[CLS] voice citizen knuckles dean senior free much private [SEP]']
[Init] best perm rec loss: 0.9661933779716492 for ['[CLS] senior voice citizen much private knuckles dean free [SEP]']
[Init] best perm rec loss: 0.9661873579025269 for ['[CLS] dean citizen senior voice free much private knuckles [SEP]']
[Init] best perm rec loss: 0.9657464623451233 for ['[CLS] private senior voice dean much citizen knuckles free [SEP]']
[Init] best perm rec loss: 0.9645711183547974 for ['[CLS] citizen dean voice knuckles free senior much private [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.695 (perp=11.425, rec=0.357, cos=0.053), tot_loss_proj:4.116 [t=0.17s]
prediction: ['[CLS] ( bells a missiles baird [SEP]. tray [SEP]']
[ 100/2000] tot_loss=2.535 (perp=11.391, rec=0.225, cos=0.032), tot_loss_proj:4.053 [t=0.17s]
prediction: ['[CLS] vital mother a talk alone baked cake rothschild [SEP]']
[ 150/2000] tot_loss=2.200 (perp=10.003, rec=0.174, cos=0.026), tot_loss_proj:3.952 [t=0.17s]
prediction: ['[CLS] my mother a talk my baked cake my [SEP]']
[ 200/2000] tot_loss=1.896 (perp=8.723, rec=0.128, cos=0.024), tot_loss_proj:3.548 [t=0.17s]
prediction: ['[CLS] my mother a cake me baked cake my [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.667 (perp=7.568, rec=0.130, cos=0.023), tot_loss_proj:3.333 [t=0.17s]
prediction: ['[CLS] my mother a cake me baked my cake [SEP]']
[ 300/2000] tot_loss=1.851 (perp=8.592, rec=0.110, cos=0.022), tot_loss_proj:3.527 [t=0.17s]
prediction: ['[CLS] for mother a cake me baked my cake [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.667 (perp=7.788, rec=0.087, cos=0.022), tot_loss_proj:3.351 [t=0.17s]
prediction: ['[CLS] for mother me a cake baked my cake [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.608 (perp=7.472, rec=0.091, cos=0.023), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[ 450/2000] tot_loss=1.609 (perp=7.472, rec=0.092, cos=0.022), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.598 (perp=7.472, rec=0.082, cos=0.022), tot_loss_proj:3.364 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.596 (perp=7.472, rec=0.080, cos=0.022), tot_loss_proj:3.369 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[ 600/2000] tot_loss=1.596 (perp=7.472, rec=0.081, cos=0.022), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.603 (perp=7.472, rec=0.087, cos=0.022), tot_loss_proj:3.369 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.601 (perp=7.472, rec=0.085, cos=0.022), tot_loss_proj:3.370 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[ 750/2000] tot_loss=1.602 (perp=7.472, rec=0.087, cos=0.022), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.597 (perp=7.472, rec=0.082, cos=0.022), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.598 (perp=7.472, rec=0.082, cos=0.021), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[ 900/2000] tot_loss=1.589 (perp=7.472, rec=0.073, cos=0.021), tot_loss_proj:3.372 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.601 (perp=7.472, rec=0.085, cos=0.021), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1000/2000] tot_loss=1.593 (perp=7.472, rec=0.077, cos=0.021), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[1050/2000] tot_loss=1.602 (perp=7.472, rec=0.087, cos=0.021), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1100/2000] tot_loss=1.599 (perp=7.472, rec=0.083, cos=0.021), tot_loss_proj:3.369 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1150/2000] tot_loss=1.592 (perp=7.472, rec=0.076, cos=0.021), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[1200/2000] tot_loss=1.602 (perp=7.472, rec=0.086, cos=0.021), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1250/2000] tot_loss=1.591 (perp=7.472, rec=0.075, cos=0.021), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1300/2000] tot_loss=1.597 (perp=7.472, rec=0.081, cos=0.021), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[1350/2000] tot_loss=1.595 (perp=7.472, rec=0.080, cos=0.021), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1400/2000] tot_loss=1.602 (perp=7.472, rec=0.086, cos=0.021), tot_loss_proj:3.362 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1450/2000] tot_loss=1.602 (perp=7.472, rec=0.086, cos=0.021), tot_loss_proj:3.366 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[1500/2000] tot_loss=1.598 (perp=7.472, rec=0.083, cos=0.021), tot_loss_proj:3.370 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1550/2000] tot_loss=1.596 (perp=7.472, rec=0.081, cos=0.021), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1600/2000] tot_loss=1.587 (perp=7.472, rec=0.071, cos=0.021), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[1650/2000] tot_loss=1.599 (perp=7.472, rec=0.083, cos=0.021), tot_loss_proj:3.366 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1700/2000] tot_loss=1.606 (perp=7.472, rec=0.090, cos=0.021), tot_loss_proj:3.362 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1750/2000] tot_loss=1.588 (perp=7.472, rec=0.072, cos=0.021), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[1800/2000] tot_loss=1.590 (perp=7.472, rec=0.075, cos=0.021), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1850/2000] tot_loss=1.597 (perp=7.472, rec=0.081, cos=0.021), tot_loss_proj:3.366 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[1900/2000] tot_loss=1.596 (perp=7.472, rec=0.080, cos=0.021), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
[1950/2000] tot_loss=1.604 (perp=7.472, rec=0.089, cos=0.021), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Attempt swap
[2000/2000] tot_loss=1.600 (perp=7.472, rec=0.084, cos=0.021), tot_loss_proj:3.364 [t=0.17s]
prediction: ['[CLS] for mother me a cake my cake baked [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] my mother baked a cake for me. [SEP]
========================
predicted: 
========================
[CLS] for mother me a cake my cake baked [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 11.765 | p: 11.111 | r: 12.500
rougeL     | fm: 52.632 | p: 50.000 | r: 55.556
rougeLsum  | fm: 52.632 | p: 50.000 | r: 55.556
r1fm+r2fm = 106.502

[Aggregate metrics]:
rouge1     | fm: 80.542 | p: 80.182 | r: 81.273
rouge2     | fm: 40.395 | p: 39.876 | r: 41.128
rougeL     | fm: 68.506 | p: 68.164 | r: 69.137
rougeLsum  | fm: 68.409 | p: 68.095 | r: 69.072
r1fm+r2fm = 120.936

input #77 time: 0:06:59 | total time: 9:03:31


Running input #78 of 100.
reference: 
========================
I read some book.
========================
Sample: 0 6.265835340417827e-13 0.04166184684804132 0.33434358
average of cosine similarity 0.9922060730619653
highest_index [0]
highest [0.9922060730619653]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 3191, 2070, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i read some book. [SEP]']
[Init] best rec loss: 0.9242171049118042 for ['[CLS]ys sponsored ni patience courts [SEP]']
[Init] best rec loss: 0.9155153632164001 for ['[CLS] sealing wrestlemania profile sense ar [SEP]']
[Init] best rec loss: 0.813995361328125 for ['[CLS] am iv pregnant lagoon ample [SEP]']
[Init] best rec loss: 0.8045976758003235 for ['[CLS] tour fucking ax him banking [SEP]']
[Init] best rec loss: 0.8032265305519104 for ['[CLS] epidemic deceased accused flames zone [SEP]']
[Init] best rec loss: 0.7923592925071716 for ['[CLS] solitary jumps squeakchev tangled [SEP]']
[Init] best perm rec loss: 0.7846071720123291 for ['[CLS] solitarychev squeak tangled jumps [SEP]']
[Init] best perm rec loss: 0.7840006947517395 for ['[CLS]chev jumps tangled squeak solitary [SEP]']
[Init] best perm rec loss: 0.7813184261322021 for ['[CLS]chev squeak tangled solitary jumps [SEP]']
[Init] best perm rec loss: 0.7804632186889648 for ['[CLS] tangled squeak solitarychev jumps [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.403 (perp=9.730, rec=0.402, cos=0.055), tot_loss_proj:3.035 [t=0.17s]
prediction: ['[CLS] some book type followed get [SEP]']
[ 100/2000] tot_loss=2.303 (perp=9.886, rec=0.284, cos=0.042), tot_loss_proj:3.800 [t=0.17s]
prediction: ['[CLS] some book book music some [SEP]']
[ 150/2000] tot_loss=2.002 (perp=8.913, rec=0.190, cos=0.029), tot_loss_proj:2.951 [t=0.17s]
prediction: ['[CLS] we book read. some [SEP]']
[ 200/2000] tot_loss=2.381 (perp=8.883, rec=0.513, cos=0.092), tot_loss_proj:2.829 [t=0.17s]
prediction: ['[CLS] she book bought. some [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.920 (perp=6.862, rec=0.478, cos=0.069), tot_loss_proj:2.439 [t=0.17s]
prediction: ['[CLS] we book some loan. [SEP]']
[ 300/2000] tot_loss=1.659 (perp=6.522, rec=0.311, cos=0.043), tot_loss_proj:2.736 [t=0.17s]
prediction: ['[CLS] we book some plot. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.712 (perp=7.268, rec=0.231, cos=0.028), tot_loss_proj:2.478 [t=0.17s]
prediction: ['[CLS] we book some read. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.353 (perp=5.592, rec=0.203, cos=0.031), tot_loss_proj:2.217 [t=0.17s]
prediction: ['[CLS] we read some book. [SEP]']
[ 450/2000] tot_loss=1.306 (perp=5.592, rec=0.162, cos=0.025), tot_loss_proj:2.191 [t=0.17s]
prediction: ['[CLS] we read some book. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.215 (perp=5.181, rec=0.155, cos=0.024), tot_loss_proj:1.928 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.204 (perp=5.181, rec=0.144, cos=0.023), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
[ 600/2000] tot_loss=1.700 (perp=5.181, rec=0.493, cos=0.171), tot_loss_proj:2.206 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.306 (perp=5.181, rec=0.233, cos=0.037), tot_loss_proj:2.224 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.254 (perp=5.181, rec=0.185, cos=0.033), tot_loss_proj:2.042 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
[ 750/2000] tot_loss=1.239 (perp=5.181, rec=0.171, cos=0.031), tot_loss_proj:1.858 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.231 (perp=5.181, rec=0.165, cos=0.030), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.218 (perp=5.181, rec=0.153, cos=0.029), tot_loss_proj:1.672 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
[ 900/2000] tot_loss=1.225 (perp=5.181, rec=0.160, cos=0.029), tot_loss_proj:1.638 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.213 (perp=5.181, rec=0.149, cos=0.028), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.219 (perp=5.181, rec=0.155, cos=0.028), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
[1050/2000] tot_loss=1.210 (perp=5.181, rec=0.146, cos=0.028), tot_loss_proj:1.585 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.217 (perp=5.181, rec=0.153, cos=0.028), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.213 (perp=5.181, rec=0.149, cos=0.027), tot_loss_proj:1.571 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
[1200/2000] tot_loss=1.196 (perp=5.181, rec=0.133, cos=0.027), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.203 (perp=5.181, rec=0.140, cos=0.027), tot_loss_proj:1.551 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.206 (perp=5.181, rec=0.143, cos=0.027), tot_loss_proj:1.544 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
[1350/2000] tot_loss=1.193 (perp=5.181, rec=0.131, cos=0.026), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.201 (perp=5.181, rec=0.139, cos=0.026), tot_loss_proj:1.533 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.192 (perp=5.181, rec=0.130, cos=0.026), tot_loss_proj:1.523 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
[1500/2000] tot_loss=1.192 (perp=5.181, rec=0.131, cos=0.026), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.203 (perp=5.181, rec=0.141, cos=0.025), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.211 (perp=5.181, rec=0.149, cos=0.025), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
[1650/2000] tot_loss=1.185 (perp=5.181, rec=0.123, cos=0.025), tot_loss_proj:1.517 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.202 (perp=5.181, rec=0.141, cos=0.025), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.187 (perp=5.181, rec=0.126, cos=0.025), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
[1800/2000] tot_loss=1.185 (perp=5.181, rec=0.124, cos=0.025), tot_loss_proj:1.494 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.191 (perp=5.181, rec=0.130, cos=0.025), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.191 (perp=5.181, rec=0.130, cos=0.025), tot_loss_proj:1.490 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
[1950/2000] tot_loss=1.190 (perp=5.181, rec=0.129, cos=0.025), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.191 (perp=5.181, rec=0.130, cos=0.024), tot_loss_proj:1.482 [t=0.17s]
prediction: ['[CLS] i read some book. [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] i read some book. [SEP]
========================
predicted: 
========================
[CLS] i read some book. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 80.810 | p: 80.408 | r: 81.540
rouge2     | fm: 41.045 | p: 40.472 | r: 41.712
rougeL     | fm: 68.930 | p: 68.547 | r: 69.563
rougeLsum  | fm: 68.800 | p: 68.461 | r: 69.483
r1fm+r2fm = 121.855

input #78 time: 0:06:50 | total time: 9:10:21


Running input #79 of 100.
reference: 
========================
The umpire called it of.
========================
Sample: 0 6.643322729490149e-11 0.05081553378037325 0.36073637
average of cosine similarity 0.9900286766616314
highest_index [0]
highest [0.9900286766616314]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 20887,  2170,  2009,  1997,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the umpire called it of. [SEP]']
[Init] best rec loss: 0.9944065809249878 for ['[CLS]tlement gi professional julian reaching wingspan [SEP]']
[Init] best rec loss: 0.9885329008102417 for ['[CLS] ′ ears natural developed star quest [SEP]']
[Init] best rec loss: 0.9714334607124329 for ['[CLS] exposure april located cheesequal enough [SEP]']
[Init] best rec loss: 0.9517230987548828 for ['[CLS] consulted ‖ deputy from back alley [SEP]']
[Init] best rec loss: 0.9444591999053955 for ['[CLS] sub nu mode fish calderon? [SEP]']
[Init] best rec loss: 0.9425790905952454 for ['[CLS] investigatoreve sea hell mali otherwise [SEP]']
[Init] best rec loss: 0.9382247924804688 for ['[CLS] immediately... ordinary variouspre extra [SEP]']
[Init] best rec loss: 0.9181168675422668 for ['[CLS]oca named hall would google guard [SEP]']
[Init] best perm rec loss: 0.9179900288581848 for ['[CLS]oca hall would google guard named [SEP]']
[Init] best perm rec loss: 0.9177843928337097 for ['[CLS] guard halloca named google would [SEP]']
[Init] best perm rec loss: 0.9168456792831421 for ['[CLS]oca hall guard would named google [SEP]']
[Init] best perm rec loss: 0.9167401790618896 for ['[CLS] guard named hall would googleoca [SEP]']
[Init] best perm rec loss: 0.9162608981132507 for ['[CLS]oca hall would named google guard [SEP]']
[Init] best perm rec loss: 0.9160237908363342 for ['[CLS]oca would guard google named hall [SEP]']
[Init] best perm rec loss: 0.9141231179237366 for ['[CLS]oca would guard named hall google [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.851 (perp=11.031, rec=0.647, cos=0.998), tot_loss_proj:4.019 [t=0.17s]
prediction: ['[CLS] lo isball named taxes, [SEP]']
[ 100/2000] tot_loss=3.456 (perp=9.566, rec=0.550, cos=0.993), tot_loss_proj:3.928 [t=0.17s]
prediction: ['[CLS] umpire isberger named ;. [SEP]']
[ 150/2000] tot_loss=3.376 (perp=9.461, rec=0.492, cos=0.992), tot_loss_proj:3.845 [t=0.17s]
prediction: ['[CLS] umpire umpire umpire ¿.. [SEP]']
[ 200/2000] tot_loss=3.281 (perp=9.315, rec=0.432, cos=0.986), tot_loss_proj:3.773 [t=0.17s]
prediction: ['[CLS] umpire umpire umpire called at. [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.263 (perp=9.359, rec=0.405, cos=0.986), tot_loss_proj:3.752 [t=0.18s]
prediction: ['[CLS] umpire its jones called at. [SEP]']
[ 300/2000] tot_loss=3.377 (perp=9.913, rec=0.406, cos=0.988), tot_loss_proj:3.909 [t=0.17s]
prediction: ['[CLS] umpire οgnon called at. [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.359 (perp=9.913, rec=0.393, cos=0.983), tot_loss_proj:3.914 [t=0.18s]
prediction: ['[CLS] umpire οgnon called at. [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.409 (perp=10.199, rec=0.387, cos=0.982), tot_loss_proj:3.862 [t=0.18s]
prediction: ['[CLS] umpire calledgnon called at. [SEP]']
[ 450/2000] tot_loss=3.396 (perp=10.199, rec=0.373, cos=0.984), tot_loss_proj:3.862 [t=0.18s]
prediction: ['[CLS] umpire calledgnon called at. [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.617 (perp=11.251, rec=0.381, cos=0.986), tot_loss_proj:4.178 [t=0.18s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.589 (perp=11.251, rec=0.358, cos=0.981), tot_loss_proj:4.177 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
[ 600/2000] tot_loss=3.596 (perp=11.251, rec=0.364, cos=0.981), tot_loss_proj:4.176 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.598 (perp=11.251, rec=0.365, cos=0.982), tot_loss_proj:4.181 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.591 (perp=11.251, rec=0.360, cos=0.982), tot_loss_proj:4.181 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
[ 750/2000] tot_loss=3.595 (perp=11.251, rec=0.364, cos=0.980), tot_loss_proj:4.178 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.583 (perp=11.251, rec=0.354, cos=0.979), tot_loss_proj:4.181 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.589 (perp=11.251, rec=0.359, cos=0.980), tot_loss_proj:4.178 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
[ 900/2000] tot_loss=3.582 (perp=11.251, rec=0.352, cos=0.980), tot_loss_proj:4.179 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.591 (perp=11.251, rec=0.360, cos=0.981), tot_loss_proj:4.182 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.587 (perp=11.251, rec=0.356, cos=0.981), tot_loss_proj:4.177 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
[1050/2000] tot_loss=3.579 (perp=11.251, rec=0.349, cos=0.980), tot_loss_proj:4.181 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.580 (perp=11.251, rec=0.349, cos=0.981), tot_loss_proj:4.178 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.578 (perp=11.251, rec=0.347, cos=0.981), tot_loss_proj:4.176 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
[1200/2000] tot_loss=3.579 (perp=11.251, rec=0.348, cos=0.981), tot_loss_proj:4.174 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.594 (perp=11.251, rec=0.363, cos=0.981), tot_loss_proj:4.182 [t=0.21s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.583 (perp=11.251, rec=0.352, cos=0.981), tot_loss_proj:4.180 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
[1350/2000] tot_loss=3.583 (perp=11.251, rec=0.352, cos=0.981), tot_loss_proj:4.182 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.585 (perp=11.251, rec=0.354, cos=0.981), tot_loss_proj:4.179 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.576 (perp=11.251, rec=0.345, cos=0.981), tot_loss_proj:4.179 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
[1500/2000] tot_loss=3.587 (perp=11.251, rec=0.355, cos=0.981), tot_loss_proj:4.178 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.587 (perp=11.251, rec=0.356, cos=0.981), tot_loss_proj:4.181 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.585 (perp=11.251, rec=0.354, cos=0.981), tot_loss_proj:4.178 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
[1650/2000] tot_loss=3.577 (perp=11.251, rec=0.345, cos=0.981), tot_loss_proj:4.183 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.571 (perp=11.251, rec=0.340, cos=0.981), tot_loss_proj:4.178 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.588 (perp=11.251, rec=0.356, cos=0.981), tot_loss_proj:4.180 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
[1800/2000] tot_loss=3.578 (perp=11.251, rec=0.347, cos=0.981), tot_loss_proj:4.176 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.580 (perp=11.251, rec=0.349, cos=0.981), tot_loss_proj:4.178 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.576 (perp=11.251, rec=0.345, cos=0.981), tot_loss_proj:4.179 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
[1950/2000] tot_loss=3.572 (perp=11.251, rec=0.341, cos=0.981), tot_loss_proj:4.180 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.584 (perp=11.251, rec=0.352, cos=0.981), tot_loss_proj:4.176 [t=0.17s]
prediction: ['[CLS] umpire called termed called at. [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] the umpire called it of. [SEP]
========================
predicted: 
========================
[CLS] umpire called termed called at. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 57.143 | r: 57.143
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 73.810

[Aggregate metrics]:
rouge1     | fm: 80.462 | p: 80.092 | r: 81.174
rouge2     | fm: 40.771 | p: 40.280 | r: 41.418
rougeL     | fm: 68.777 | p: 68.452 | r: 69.412
rougeLsum  | fm: 68.559 | p: 68.271 | r: 69.197
r1fm+r2fm = 121.232

input #79 time: 0:06:55 | total time: 9:17:16


Running input #80 of 100.
reference: 
========================
The rock placed the sky with the fork.
========================
Sample: 0 8.717431290080408e-11 0.048977553334484114 0.3540735
average of cosine similarity 0.9903867818653396
highest_index [0]
highest [0.9903867818653396]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2600, 2872, 1996, 3712, 2007, 1996, 9292, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the rock placed the sky with the fork. [SEP]']
[Init] best rec loss: 0.9175726175308228 for ['[CLS] female scared marcus humble ramp bracket hybrid marieeur [SEP]']
[Init] best rec loss: 0.891436755657196 for ['[CLS] kind plan loft [MASK]?elin unincorporated beard points [SEP]']
[Init] best rec loss: 0.8769033551216125 for ['[CLS] a bowl documentary position deficiency brand shoulders clinic counties [SEP]']
[Init] best rec loss: 0.8643680214881897 for ['[CLS] between lawrence policiessphere webb hari aria which com [SEP]']
[Init] best rec loss: 0.8254552483558655 for ['[CLS]own volunteers byte carr bold grace interchange chalk our [SEP]']
[Init] best rec loss: 0.7917901277542114 for ['[CLS] rib our ball spelling asleepille oval ash teaching [SEP]']
[Init] best rec loss: 0.7806429266929626 for ["[CLS] cassie guy preneas lake more'rocker jury [SEP]"]
[Init] best rec loss: 0.7527327537536621 for ['[CLS]tos young noah golfer healthy belong notitation modern [SEP]']
[Init] best perm rec loss: 0.752642035484314 for ['[CLS] noah golfer not healthytos belong youngitation modern [SEP]']
[Init] best perm rec loss: 0.7477012276649475 for ['[CLS] moderntositation healthy young not belong golfer noah [SEP]']
[Init] best perm rec loss: 0.747452974319458 for ['[CLS] modern not noah young belongitation healthytos golfer [SEP]']
[Init] best perm rec loss: 0.7451422214508057 for ['[CLS] not healthy youngtos belong modernitation golfer noah [SEP]']
[Init] best perm rec loss: 0.7439910769462585 for ['[CLS]tos not healthy golferitation young belong noah modern [SEP]']
[Init] best perm rec loss: 0.7436251640319824 for ['[CLS]tos noah golfer belong young modern notitation healthy [SEP]']
[Init] best perm rec loss: 0.7427157163619995 for ['[CLS] golfertos healthy belong youngitation not modern noah [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.487 (perp=10.808, rec=0.296, cos=0.029), tot_loss_proj:2.849 [t=0.17s]
prediction: ['[CLS] painting bowl placed everyone rock for rock token year [SEP]']
[ 100/2000] tot_loss=1.998 (perp=8.896, rec=0.191, cos=0.028), tot_loss_proj:2.453 [t=0.17s]
prediction: ['[CLS] folding rock placed the fork with rock with sky [SEP]']
[ 150/2000] tot_loss=1.930 (perp=8.639, rec=0.174, cos=0.028), tot_loss_proj:2.209 [t=0.17s]
prediction: ['[CLS] the rock placed the fork sky rock with sky [SEP]']
[ 200/2000] tot_loss=1.877 (perp=8.639, rec=0.127, cos=0.022), tot_loss_proj:2.219 [t=0.17s]
prediction: ['[CLS] the rock placed the fork sky rock with sky [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.091 (perp=9.460, rec=0.172, cos=0.027), tot_loss_proj:2.557 [t=0.17s]
prediction: ['[CLS] the icon placed the rock sky fork with sky [SEP]']
[ 300/2000] tot_loss=2.031 (perp=9.460, rec=0.117, cos=0.022), tot_loss_proj:2.559 [t=0.17s]
prediction: ['[CLS] the icon placed the rock sky fork with sky [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.882 (perp=8.856, rec=0.089, cos=0.021), tot_loss_proj:2.419 [t=0.17s]
prediction: ['[CLS] the rock placed the icon sky fork with sky [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.864 (perp=8.754, rec=0.091, cos=0.022), tot_loss_proj:2.203 [t=0.17s]
prediction: ['[CLS] the rock placed the sky merely fork with sky [SEP]']
[ 450/2000] tot_loss=1.859 (perp=8.754, rec=0.087, cos=0.021), tot_loss_proj:2.201 [t=0.17s]
prediction: ['[CLS] the rock placed the sky merely fork with sky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.851 (perp=8.754, rec=0.079, cos=0.021), tot_loss_proj:2.213 [t=0.17s]
prediction: ['[CLS] the rock placed the sky merely fork with sky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.848 (perp=8.754, rec=0.077, cos=0.021), tot_loss_proj:2.197 [t=0.17s]
prediction: ['[CLS] the rock placed the sky merely fork with sky [SEP]']
[ 600/2000] tot_loss=1.854 (perp=8.754, rec=0.083, cos=0.020), tot_loss_proj:2.195 [t=0.17s]
prediction: ['[CLS] the rock placed the sky merely fork with sky [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.803 (perp=8.527, rec=0.076, cos=0.021), tot_loss_proj:2.151 [t=0.17s]
prediction: ['[CLS] the rock placed the sky fork merely with sky [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.562 (perp=7.277, rec=0.086, cos=0.021), tot_loss_proj:1.821 [t=0.17s]
prediction: ['[CLS] the rock placed the sky fork with the sky [SEP]']
[ 750/2000] tot_loss=1.552 (perp=7.277, rec=0.076, cos=0.021), tot_loss_proj:1.824 [t=0.17s]
prediction: ['[CLS] the rock placed the sky fork with the sky [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.760 (perp=8.342, rec=0.071, cos=0.021), tot_loss_proj:2.085 [t=0.19s]
prediction: ['[CLS] the rock placed the sky fork sky with the [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.433 (perp=6.745, rec=0.064, cos=0.021), tot_loss_proj:1.532 [t=0.19s]
prediction: ['[CLS] the rock placed the sky with the fork. [SEP]']
[ 900/2000] tot_loss=1.443 (perp=6.745, rec=0.074, cos=0.020), tot_loss_proj:1.534 [t=0.17s]
prediction: ['[CLS] the rock placed the sky with the fork. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.322 (perp=6.181, rec=0.065, cos=0.021), tot_loss_proj:1.500 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.331 (perp=6.181, rec=0.075, cos=0.020), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1050/2000] tot_loss=1.336 (perp=6.181, rec=0.080, cos=0.020), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.332 (perp=6.181, rec=0.075, cos=0.020), tot_loss_proj:1.511 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.329 (perp=6.181, rec=0.073, cos=0.020), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1200/2000] tot_loss=1.334 (perp=6.181, rec=0.077, cos=0.020), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.328 (perp=6.181, rec=0.072, cos=0.020), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.340 (perp=6.181, rec=0.083, cos=0.020), tot_loss_proj:1.493 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1350/2000] tot_loss=1.329 (perp=6.181, rec=0.072, cos=0.020), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.314 (perp=6.181, rec=0.058, cos=0.020), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.334 (perp=6.181, rec=0.077, cos=0.021), tot_loss_proj:1.494 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1500/2000] tot_loss=1.342 (perp=6.181, rec=0.085, cos=0.021), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.325 (perp=6.181, rec=0.069, cos=0.020), tot_loss_proj:1.497 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.334 (perp=6.181, rec=0.077, cos=0.020), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1650/2000] tot_loss=1.336 (perp=6.181, rec=0.080, cos=0.020), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.330 (perp=6.181, rec=0.073, cos=0.020), tot_loss_proj:1.500 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.329 (perp=6.181, rec=0.073, cos=0.020), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1800/2000] tot_loss=1.335 (perp=6.181, rec=0.078, cos=0.020), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.340 (perp=6.181, rec=0.084, cos=0.020), tot_loss_proj:1.505 [t=0.19s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.331 (perp=6.181, rec=0.074, cos=0.021), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
[1950/2000] tot_loss=1.327 (perp=6.181, rec=0.071, cos=0.021), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.330 (perp=6.181, rec=0.074, cos=0.020), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] the rock placed the fork with the sky. [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] the rock placed the sky with the fork. [SEP]
========================
predicted: 
========================
[CLS] the rock placed the fork with the sky. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 77.778 | p: 77.778 | r: 77.778
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 177.778

[Aggregate metrics]:
rouge1     | fm: 80.709 | p: 80.373 | r: 81.419
rouge2     | fm: 41.287 | p: 40.791 | r: 41.910
rougeL     | fm: 68.908 | p: 68.548 | r: 69.538
rougeLsum  | fm: 68.758 | p: 68.334 | r: 69.346
r1fm+r2fm = 121.996

input #80 time: 0:07:13 | total time: 9:24:29


Running input #81 of 100.
reference: 
========================
Tagalog is speaks in the Philippines.
========================
Sample: 0 2.6243251287782706e-12 0.04590048732136968 0.34106126
average of cosine similarity 0.9909025301769578
highest_index [0]
highest [0.9909025301769578]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  6415, 23067,  2290,  2003,  8847,  1999,  1996,  5137,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] tagalog is speaks in the philippines. [SEP]']
[Init] best rec loss: 0.8218028545379639 for ['[CLS]lch scotland uhf qualifying claude worse attempt faye costs [SEP]']
[Init] best rec loss: 0.8192242980003357 for ['[CLS] college school hismic nord mate genes transfer heir [SEP]']
[Init] best rec loss: 0.7856317758560181 for ['[CLS] extraburo and committed method pali co guess ir [SEP]']
[Init] best rec loss: 0.7316059470176697 for ['[CLS]ei understand turn infrastructure galley project tracks annual [SEP]']
[Init] best rec loss: 0.7133926153182983 for ['[CLS] opened grtain ft slow lattice season brake miriam [SEP]']
[Init] best rec loss: 0.705670177936554 for ['[CLS] horticultural example overlooking againstside anita hours ; followed [SEP]']
[Init] best rec loss: 0.6805224418640137 for ['[CLS] bigger maxim when interchange for cavity ª before apps [SEP]']
[Init] best perm rec loss: 0.6777098178863525 for ['[CLS] apps bigger when maxim ª cavity interchange for before [SEP]']
[Init] best perm rec loss: 0.6731835007667542 for ['[CLS] maxim apps interchange before when bigger cavity for ª [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.741 (perp=11.859, rec=0.318, cos=0.052), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] philippine tiger speaks is filipino ran pinyin is worlds [SEP]']
[ 100/2000] tot_loss=2.755 (perp=12.398, rec=0.242, cos=0.034), tot_loss_proj:3.457 [t=0.17s]
prediction: ['[CLS] philippines philippines is isalo tag philippines is speaks [SEP]']
[ 150/2000] tot_loss=2.828 (perp=12.862, rec=0.225, cos=0.030), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS] philippines philippines is isalo tag philippines speaks speaks [SEP]']
[ 200/2000] tot_loss=2.794 (perp=12.802, rec=0.208, cos=0.026), tot_loss_proj:3.488 [t=0.17s]
prediction: ['[CLS] philippines philippines is isalo tagg speaks philippines [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.237 (perp=9.842, rec=0.235, cos=0.034), tot_loss_proj:2.767 [t=0.17s]
prediction: ['[CLS] philippines philippines is is tagalog speaks philippines [SEP]']
[ 300/2000] tot_loss=2.178 (perp=9.842, rec=0.187, cos=0.022), tot_loss_proj:2.761 [t=0.17s]
prediction: ['[CLS] philippines philippines is is tagalog speaks philippines [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.330 (perp=10.747, rec=0.156, cos=0.025), tot_loss_proj:3.051 [t=0.17s]
prediction: ['[CLS] philippines is philippines is philippinesalog speaks philippines [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.801 (perp=8.057, rec=0.166, cos=0.024), tot_loss_proj:2.359 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog speaks in [SEP]']
[ 450/2000] tot_loss=1.774 (perp=8.057, rec=0.140, cos=0.023), tot_loss_proj:2.352 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog speaks in [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.758 (perp=8.057, rec=0.124, cos=0.023), tot_loss_proj:2.349 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog speaks in [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.758 (perp=8.057, rec=0.124, cos=0.023), tot_loss_proj:2.353 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog speaks in [SEP]']
[ 600/2000] tot_loss=1.753 (perp=8.057, rec=0.119, cos=0.023), tot_loss_proj:2.348 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog speaks in [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.751 (perp=8.057, rec=0.118, cos=0.022), tot_loss_proj:2.349 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog speaks in [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.667 (perp=7.556, rec=0.133, cos=0.023), tot_loss_proj:2.268 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
[ 750/2000] tot_loss=1.654 (perp=7.556, rec=0.120, cos=0.022), tot_loss_proj:2.259 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.643 (perp=7.556, rec=0.110, cos=0.022), tot_loss_proj:2.269 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.647 (perp=7.556, rec=0.113, cos=0.022), tot_loss_proj:2.267 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
[ 900/2000] tot_loss=1.642 (perp=7.556, rec=0.108, cos=0.022), tot_loss_proj:2.262 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.645 (perp=7.556, rec=0.111, cos=0.022), tot_loss_proj:2.264 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1000/2000] tot_loss=1.643 (perp=7.556, rec=0.109, cos=0.022), tot_loss_proj:2.262 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
[1050/2000] tot_loss=1.632 (perp=7.556, rec=0.098, cos=0.022), tot_loss_proj:2.260 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1100/2000] tot_loss=1.643 (perp=7.556, rec=0.109, cos=0.022), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1150/2000] tot_loss=1.637 (perp=7.556, rec=0.103, cos=0.022), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
[1200/2000] tot_loss=1.637 (perp=7.556, rec=0.103, cos=0.023), tot_loss_proj:2.264 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1250/2000] tot_loss=1.635 (perp=7.556, rec=0.101, cos=0.022), tot_loss_proj:2.257 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1300/2000] tot_loss=1.640 (perp=7.556, rec=0.106, cos=0.023), tot_loss_proj:2.264 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
[1350/2000] tot_loss=1.638 (perp=7.556, rec=0.104, cos=0.023), tot_loss_proj:2.265 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1400/2000] tot_loss=1.640 (perp=7.556, rec=0.106, cos=0.023), tot_loss_proj:2.268 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1450/2000] tot_loss=1.633 (perp=7.556, rec=0.099, cos=0.023), tot_loss_proj:2.263 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
[1500/2000] tot_loss=1.644 (perp=7.556, rec=0.110, cos=0.023), tot_loss_proj:2.263 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1550/2000] tot_loss=1.637 (perp=7.556, rec=0.103, cos=0.023), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1600/2000] tot_loss=1.642 (perp=7.556, rec=0.108, cos=0.023), tot_loss_proj:2.260 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
[1650/2000] tot_loss=1.634 (perp=7.556, rec=0.100, cos=0.023), tot_loss_proj:2.260 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1700/2000] tot_loss=1.641 (perp=7.556, rec=0.107, cos=0.023), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1750/2000] tot_loss=1.634 (perp=7.556, rec=0.100, cos=0.023), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
[1800/2000] tot_loss=1.643 (perp=7.556, rec=0.109, cos=0.023), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1850/2000] tot_loss=1.641 (perp=7.556, rec=0.108, cos=0.023), tot_loss_proj:2.262 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[1900/2000] tot_loss=1.632 (perp=7.556, rec=0.098, cos=0.023), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
[1950/2000] tot_loss=1.638 (perp=7.556, rec=0.104, cos=0.023), tot_loss_proj:2.263 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Attempt swap
[2000/2000] tot_loss=1.631 (perp=7.556, rec=0.097, cos=0.023), tot_loss_proj:2.255 [t=0.17s]
prediction: ['[CLS] philippines is philippines is tagalog in speaks [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] tagalog is speaks in the philippines. [SEP]
========================
predicted: 
========================
[CLS] philippines is philippines is tagalog in speaks [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.059 | p: 44.444 | r: 50.000
rougeLsum  | fm: 47.059 | p: 44.444 | r: 50.000
r1fm+r2fm = 82.353

[Aggregate metrics]:
rouge1     | fm: 80.851 | p: 80.450 | r: 81.634
rouge2     | fm: 40.673 | p: 40.144 | r: 41.328
rougeL     | fm: 68.659 | p: 68.338 | r: 69.337
rougeLsum  | fm: 68.471 | p: 68.075 | r: 69.153
r1fm+r2fm = 121.524

input #81 time: 0:07:05 | total time: 9:31:35


Running input #82 of 100.
reference: 
========================
He waltzed her across the floor.
========================
Sample: 0 3.866755947872136e-12 0.046926977391397964 0.32780167
average of cosine similarity 0.989700063198101
highest_index [0]
highest [0.989700063198101]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2002, 17569,  2098,  2014,  2408,  1996,  2723,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] he waltzed her across the floor. [SEP]']
[Init] best rec loss: 1.0006637573242188 for ['[CLS] beverly womenboat [MASK] greatly waterfold bears [SEP]']
[Init] best rec loss: 1.0003470182418823 for ['[CLS] because star usc but ginger boltontial nat [SEP]']
[Init] best rec loss: 1.0000369548797607 for ['[CLS] bottom especially fed wake ingpy existencerted [SEP]']
[Init] best rec loss: 0.9792600870132446 for ['[CLS]yreang mythopped older jackson cause ɡ [SEP]']
[Init] best rec loss: 0.9738048315048218 for ['[CLS] 50 formed viewing trevorple meeting bundle live [SEP]']
[Init] best rec loss: 0.9515565037727356 for ['[CLS] fraternity concern there times menu stoptford studio [SEP]']
[Init] best rec loss: 0.9510055184364319 for ['[CLS] tor cox flooread maintain km² fledged grupo [SEP]']
[Init] best rec loss: 0.9505051970481873 for ['[CLS] needed brieflyuth doing further here those honour [SEP]']
[Init] best rec loss: 0.9423287510871887 for ['[CLS] exhibited samson mix posing sc issued ernie program [SEP]']
[Init] best perm rec loss: 0.9409102201461792 for ['[CLS] issued ernie exhibited program samson posing mix sc [SEP]']
[Init] best perm rec loss: 0.940762996673584 for ['[CLS] program sc samson issued exhibited mix ernie posing [SEP]']
[Init] best perm rec loss: 0.9402257800102234 for ['[CLS] program ernie exhibited posing sc mix issued samson [SEP]']
[Init] best perm rec loss: 0.9393174648284912 for ['[CLS] program sc issued exhibited ernie posing mix samson [SEP]']
[Init] best perm rec loss: 0.93841952085495 for ['[CLS] ernie sc samson issued program exhibited mix posing [SEP]']
[Init] best perm rec loss: 0.9383668303489685 for ['[CLS] program posing sc samson exhibited ernie issued mix [SEP]']
[Init] best perm rec loss: 0.9381166696548462 for ['[CLS] ernie sc program samson exhibited issued mix posing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.366 (perp=13.068, rec=0.760, cos=0.993), tot_loss_proj:4.544 [t=0.17s]
prediction: ['[CLS] song preacher on driven alongsidetation dev fare [SEP]']
[ 100/2000] tot_loss=3.681 (perp=10.947, rec=0.660, cos=0.832), tot_loss_proj:4.150 [t=0.17s]
prediction: ['[CLS] viewers waltz billboardday song pas broadway fare [SEP]']
[ 150/2000] tot_loss=3.693 (perp=12.276, rec=0.587, cos=0.651), tot_loss_proj:4.464 [t=0.17s]
prediction: ['[CLS] danced waltz talent peacekeeping song ↑ paced shouting [SEP]']
[ 200/2000] tot_loss=2.868 (perp=11.989, rec=0.387, cos=0.083), tot_loss_proj:4.298 [t=0.17s]
prediction: ['[CLS] danced waltz longitude her waltz within sally shouting [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.255 (perp=9.468, rec=0.307, cos=0.054), tot_loss_proj:3.790 [t=0.17s]
prediction: ['[CLS] waltz waltz across her floor waltz floor shouting [SEP]']
[ 300/2000] tot_loss=2.166 (perp=9.468, rec=0.242, cos=0.030), tot_loss_proj:3.790 [t=0.17s]
prediction: ['[CLS] waltz waltz across her floor waltz floor shouting [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.535 (perp=11.655, rec=0.175, cos=0.029), tot_loss_proj:4.275 [t=0.17s]
prediction: ['[CLS] waltz her across heized waltz floor spoken [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.106 (perp=9.548, rec=0.167, cos=0.030), tot_loss_proj:3.788 [t=0.17s]
prediction: ['[CLS] he her across waltzed waltz floor spoken [SEP]']
[ 450/2000] tot_loss=2.078 (perp=9.548, rec=0.142, cos=0.027), tot_loss_proj:3.787 [t=0.17s]
prediction: ['[CLS] he her across waltzed waltz floor spoken [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.957 (perp=9.039, rec=0.122, cos=0.027), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS] he across her waltzed waltz floor spoken [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.155 (perp=9.978, rec=0.130, cos=0.030), tot_loss_proj:3.864 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed ף floor across [SEP]']
[ 600/2000] tot_loss=2.185 (perp=10.298, rec=0.101, cos=0.025), tot_loss_proj:3.909 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed obvious floor across [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.909 (perp=8.965, rec=0.091, cos=0.024), tot_loss_proj:3.627 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed across floor obvious [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.872 (perp=8.808, rec=0.086, cos=0.025), tot_loss_proj:3.596 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed across obvious floor [SEP]']
[ 750/2000] tot_loss=1.877 (perp=8.808, rec=0.092, cos=0.024), tot_loss_proj:3.600 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed across obvious floor [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.869 (perp=8.808, rec=0.084, cos=0.024), tot_loss_proj:3.593 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed across obvious floor [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.874 (perp=8.808, rec=0.089, cos=0.024), tot_loss_proj:3.596 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed across obvious floor [SEP]']
[ 900/2000] tot_loss=1.879 (perp=8.808, rec=0.093, cos=0.024), tot_loss_proj:3.599 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed across obvious floor [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.883 (perp=8.808, rec=0.098, cos=0.024), tot_loss_proj:3.596 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed across obvious floor [SEP]']
Attempt swap
[1000/2000] tot_loss=1.870 (perp=8.808, rec=0.085, cos=0.024), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed across obvious floor [SEP]']
[1050/2000] tot_loss=1.875 (perp=8.808, rec=0.090, cos=0.024), tot_loss_proj:3.597 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed across obvious floor [SEP]']
Attempt swap
[1100/2000] tot_loss=1.878 (perp=8.856, rec=0.083, cos=0.024), tot_loss_proj:3.616 [t=0.17s]
prediction: ['[CLS] he spoken her waltzed across because floor [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.691 (perp=7.866, rec=0.094, cos=0.024), tot_loss_proj:3.455 [t=0.17s]
prediction: ['[CLS] he spoken because waltzed across her floor [SEP]']
[1200/2000] tot_loss=1.689 (perp=7.866, rec=0.093, cos=0.023), tot_loss_proj:3.454 [t=0.17s]
prediction: ['[CLS] he spoken because waltzed across her floor [SEP]']
Attempt swap
[1250/2000] tot_loss=1.686 (perp=7.866, rec=0.090, cos=0.024), tot_loss_proj:3.453 [t=0.17s]
prediction: ['[CLS] he spoken because waltzed across her floor [SEP]']
Attempt swap
[1300/2000] tot_loss=1.682 (perp=7.866, rec=0.085, cos=0.024), tot_loss_proj:3.454 [t=0.17s]
prediction: ['[CLS] he spoken because waltzed across her floor [SEP]']
[1350/2000] tot_loss=1.673 (perp=7.866, rec=0.076, cos=0.024), tot_loss_proj:3.454 [t=0.17s]
prediction: ['[CLS] he spoken because waltzed across her floor [SEP]']
Attempt swap
[1400/2000] tot_loss=1.683 (perp=7.866, rec=0.086, cos=0.024), tot_loss_proj:3.451 [t=0.18s]
prediction: ['[CLS] he spoken because waltzed across her floor [SEP]']
Attempt swap
[1450/2000] tot_loss=1.691 (perp=7.866, rec=0.094, cos=0.024), tot_loss_proj:3.459 [t=0.18s]
prediction: ['[CLS] he spoken because waltzed across her floor [SEP]']
[1500/2000] tot_loss=1.713 (perp=7.985, rec=0.092, cos=0.024), tot_loss_proj:3.611 [t=0.19s]
prediction: ['[CLS] he. because waltzed across her floor [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.643 (perp=7.655, rec=0.088, cos=0.024), tot_loss_proj:3.531 [t=0.17s]
prediction: ['[CLS] he because. waltzed across her floor [SEP]']
Attempt swap
[1600/2000] tot_loss=1.644 (perp=7.655, rec=0.089, cos=0.023), tot_loss_proj:3.531 [t=0.19s]
prediction: ['[CLS] he because. waltzed across her floor [SEP]']
[1650/2000] tot_loss=1.647 (perp=7.655, rec=0.092, cos=0.023), tot_loss_proj:3.532 [t=0.19s]
prediction: ['[CLS] he because. waltzed across her floor [SEP]']
Attempt swap
[1700/2000] tot_loss=1.637 (perp=7.655, rec=0.083, cos=0.023), tot_loss_proj:3.531 [t=0.17s]
prediction: ['[CLS] he because. waltzed across her floor [SEP]']
Attempt swap
[1750/2000] tot_loss=1.650 (perp=7.655, rec=0.096, cos=0.023), tot_loss_proj:3.530 [t=0.17s]
prediction: ['[CLS] he because. waltzed across her floor [SEP]']
[1800/2000] tot_loss=1.643 (perp=7.655, rec=0.089, cos=0.023), tot_loss_proj:3.531 [t=0.19s]
prediction: ['[CLS] he because. waltzed across her floor [SEP]']
Attempt swap
[1850/2000] tot_loss=1.635 (perp=7.655, rec=0.081, cos=0.023), tot_loss_proj:3.532 [t=0.17s]
prediction: ['[CLS] he because. waltzed across her floor [SEP]']
Attempt swap
[1900/2000] tot_loss=1.642 (perp=7.655, rec=0.088, cos=0.023), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] he because. waltzed across her floor [SEP]']
[1950/2000] tot_loss=1.637 (perp=7.655, rec=0.083, cos=0.023), tot_loss_proj:3.532 [t=0.17s]
prediction: ['[CLS] he because. waltzed across her floor [SEP]']
Attempt swap
[2000/2000] tot_loss=1.641 (perp=7.655, rec=0.087, cos=0.023), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] he because. waltzed across her floor [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] he waltzed her across the floor. [SEP]
========================
predicted: 
========================
[CLS] he because. waltzed across her floor [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 116.071

[Aggregate metrics]:
rouge1     | fm: 80.875 | p: 80.456 | r: 81.602
rouge2     | fm: 40.610 | p: 40.063 | r: 41.243
rougeL     | fm: 68.849 | p: 68.477 | r: 69.459
rougeLsum  | fm: 68.575 | p: 68.132 | r: 69.158
r1fm+r2fm = 121.485

input #82 time: 0:07:08 | total time: 9:38:43


Running input #83 of 100.
reference: 
========================
How easy to please John is it?
========================
Sample: 0 9.848383638375558e-13 0.05912532137051233 0.3618427
average of cosine similarity 0.9865598008151544
highest_index [0]
highest [0.9865598008151544]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2129, 3733, 2000, 3531, 2198, 2003, 2009, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] how easy to please john is it? [SEP]']
[Init] best rec loss: 0.9373605251312256 for ['[CLS] blacksmith straight heart comprises works right wa would [SEP]']
[Init] best rec loss: 0.7622125744819641 for ['[CLS] god bay hungarianaround dad pony medal i [SEP]']
[Init] best rec loss: 0.7569143772125244 for ['[CLS] trevorntsgni midway coup eye denied disputed [SEP]']
[Init] best rec loss: 0.7506915330886841 for ['[CLS] lead addressed cruz irish nice motion | father [SEP]']
[Init] best rec loss: 0.7334410548210144 for ['[CLS] motor pacificeni confined near abby holding curled [SEP]']
[Init] best rec loss: 0.7291074395179749 for ['[CLS] buddy city piccoloweed ledger bulb print second [SEP]']
[Init] best rec loss: 0.7228348255157471 for ['[CLS] tonight stupid covering to scores up storm fake [SEP]']
[Init] best rec loss: 0.7001823782920837 for ['[CLS] spent tr paddington kingdoms ryder master jr sides [SEP]']
[Init] best perm rec loss: 0.698954701423645 for ['[CLS] master sides spent ryder kingdoms paddington jr tr [SEP]']
[Init] best perm rec loss: 0.6988367438316345 for ['[CLS] spent master sides paddington ryder jr tr kingdoms [SEP]']
[Init] best perm rec loss: 0.6987406611442566 for ['[CLS] spent paddington ryder master tr kingdoms jr sides [SEP]']
[Init] best perm rec loss: 0.6986838579177856 for ['[CLS] sides master paddington ryder tr spent jr kingdoms [SEP]']
[Init] best perm rec loss: 0.698501467704773 for ['[CLS] sides spent master ryder kingdoms tr jr paddington [SEP]']
[Init] best perm rec loss: 0.6980337500572205 for ['[CLS] jr tr master paddington kingdoms spent ryder sides [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.749 (perp=11.151, rec=0.409, cos=0.110), tot_loss_proj:3.334 [t=0.17s]
prediction: ['[CLS] involves ron which elder temple tribes please please [SEP]']
[ 100/2000] tot_loss=2.601 (perp=10.900, rec=0.343, cos=0.078), tot_loss_proj:3.437 [t=0.17s]
prediction: ['[CLS] extremely began which easy please non please please [SEP]']
[ 150/2000] tot_loss=1.955 (perp=7.906, rec=0.313, cos=0.061), tot_loss_proj:2.618 [t=0.17s]
prediction: ['[CLS] how within how easy please to please please [SEP]']
[ 200/2000] tot_loss=2.181 (perp=7.856, rec=0.347, cos=0.263), tot_loss_proj:2.974 [t=0.17s]
prediction: ['[CLS] how was how please john to please please [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.866 (perp=7.573, rec=0.298, cos=0.054), tot_loss_proj:2.759 [t=0.17s]
prediction: ['[CLS] how was is to please john please please [SEP]']
[ 300/2000] tot_loss=1.814 (perp=7.573, rec=0.257, cos=0.042), tot_loss_proj:2.753 [t=0.17s]
prediction: ['[CLS] how was is to please john please please [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.011 (perp=8.732, rec=0.224, cos=0.040), tot_loss_proj:3.033 [t=0.17s]
prediction: ['[CLS] how is is to easy john please please [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.411 (perp=10.447, rec=0.269, cos=0.052), tot_loss_proj:3.005 [t=0.17s]
prediction: ['[CLS] how is is please easy john non please [SEP]']
[ 450/2000] tot_loss=1.818 (perp=7.834, rec=0.210, cos=0.042), tot_loss_proj:2.766 [t=0.17s]
prediction: ['[CLS] how is is please please john, please [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.936 (perp=8.512, rec=0.196, cos=0.038), tot_loss_proj:2.814 [t=0.17s]
prediction: ['[CLS] how is is please easy john, please [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.136 (perp=8.746, rec=0.319, cos=0.068), tot_loss_proj:2.379 [t=0.17s]
prediction: ['[CLS] how easy is it is john non please [SEP]']
[ 600/2000] tot_loss=1.623 (perp=7.013, rec=0.176, cos=0.044), tot_loss_proj:2.306 [t=0.17s]
prediction: ['[CLS] how easy is it is john to please [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.380 (perp=5.971, rec=0.146, cos=0.040), tot_loss_proj:3.117 [t=0.17s]
prediction: ['[CLS] how easy is it? to please john [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.333 (perp=5.777, rec=0.144, cos=0.034), tot_loss_proj:2.659 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
[ 750/2000] tot_loss=1.306 (perp=5.777, rec=0.121, cos=0.029), tot_loss_proj:2.659 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.308 (perp=5.777, rec=0.124, cos=0.028), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.292 (perp=5.777, rec=0.109, cos=0.027), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
[ 900/2000] tot_loss=1.297 (perp=5.777, rec=0.114, cos=0.027), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.284 (perp=5.777, rec=0.102, cos=0.027), tot_loss_proj:2.655 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1000/2000] tot_loss=1.289 (perp=5.777, rec=0.106, cos=0.027), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
[1050/2000] tot_loss=1.297 (perp=5.777, rec=0.115, cos=0.027), tot_loss_proj:2.659 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1100/2000] tot_loss=1.281 (perp=5.777, rec=0.099, cos=0.027), tot_loss_proj:2.657 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1150/2000] tot_loss=1.290 (perp=5.777, rec=0.108, cos=0.027), tot_loss_proj:2.658 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
[1200/2000] tot_loss=1.281 (perp=5.777, rec=0.099, cos=0.027), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1250/2000] tot_loss=1.286 (perp=5.777, rec=0.103, cos=0.027), tot_loss_proj:2.657 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1300/2000] tot_loss=1.270 (perp=5.777, rec=0.087, cos=0.028), tot_loss_proj:2.656 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
[1350/2000] tot_loss=1.262 (perp=5.777, rec=0.079, cos=0.027), tot_loss_proj:2.653 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1400/2000] tot_loss=1.267 (perp=5.777, rec=0.085, cos=0.027), tot_loss_proj:2.650 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1450/2000] tot_loss=1.252 (perp=5.777, rec=0.070, cos=0.027), tot_loss_proj:2.657 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
[1500/2000] tot_loss=1.255 (perp=5.777, rec=0.073, cos=0.027), tot_loss_proj:2.658 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1550/2000] tot_loss=1.267 (perp=5.777, rec=0.085, cos=0.027), tot_loss_proj:2.655 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1600/2000] tot_loss=1.259 (perp=5.777, rec=0.077, cos=0.027), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
[1650/2000] tot_loss=1.259 (perp=5.777, rec=0.077, cos=0.027), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1700/2000] tot_loss=1.259 (perp=5.777, rec=0.077, cos=0.027), tot_loss_proj:2.659 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1750/2000] tot_loss=1.258 (perp=5.777, rec=0.076, cos=0.027), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
[1800/2000] tot_loss=1.263 (perp=5.777, rec=0.081, cos=0.026), tot_loss_proj:2.658 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1850/2000] tot_loss=1.260 (perp=5.777, rec=0.078, cos=0.026), tot_loss_proj:2.653 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[1900/2000] tot_loss=1.258 (perp=5.777, rec=0.076, cos=0.026), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
[1950/2000] tot_loss=1.252 (perp=5.777, rec=0.070, cos=0.026), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Attempt swap
[2000/2000] tot_loss=1.264 (perp=5.777, rec=0.082, cos=0.026), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS] how easy is to please it? john [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] how easy to please john is it? [SEP]
========================
predicted: 
========================
[CLS] how easy is to please it? john [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 81.087 | p: 80.699 | r: 81.850
rouge2     | fm: 40.534 | p: 40.033 | r: 41.163
rougeL     | fm: 68.785 | p: 68.429 | r: 69.413
rougeLsum  | fm: 68.725 | p: 68.338 | r: 69.310
r1fm+r2fm = 121.621

input #83 time: 0:06:57 | total time: 9:45:40


Running input #84 of 100.
reference: 
========================
That the king or queen be present is a requirement on all Royal weddings.
========================
Sample: 0 6.365158387927056e-11 0.05767445415112552 0.3741325
average of cosine similarity 0.9880466211921768
highest_index [0]
highest [0.9880466211921768]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2008,  1996,  2332,  2030,  3035,  2022,  2556,  2003,  1037,
          9095,  2006,  2035,  2548, 20429,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]']
[Init] best rec loss: 0.9533893465995789 for ['[CLS] y during udnsorlot shed art closed described power na seriously guild le grinding [SEP]']
[Init] best rec loss: 0.9478017091751099 for ['[CLS] calling time action restrictionhui edge still equality municipality part genieint compelledomp remainder [SEP]']
[Init] best rec loss: 0.9476109743118286 for ['[CLS] mold awful sighs ever shane scottish saetan tu way pin then band paintingssp ridley [SEP]']
[Init] best rec loss: 0.9459329843521118 for ['[CLS] multi class epic average consensus ) international mine heels trim bone erica drama say ren [SEP]']
[Init] best rec loss: 0.9199742078781128 for ['[CLS] metro coulddilly sees command vanessacter zane bend deadly his ledger day 95 poetry [SEP]']
[Init] best rec loss: 0.9192661643028259 for ['[CLS] mid village eastern though sold trafficking royce thanks concerned google member cross humorous climbingtom [SEP]']
[Init] best rec loss: 0.9171982407569885 for ['[CLS] leads reputation amassed as sept education mona t everything questions state ground safety inside kick [SEP]']
[Init] best rec loss: 0.9159625768661499 for ['[CLS] beatmission round truck dissolvedκ wishes residential problems tadestinalinavina imp spirit [SEP]']
[Init] best rec loss: 0.9154359102249146 for ['[CLS] barracks replacedmanful reid avenueorous ads kurt text criminalicing sloane feel brand [SEP]']
[Init] best rec loss: 0.9110174179077148 for ['[CLS]eon way grove church [MASK] style redistribution war better sherry dock traffic bound admission blessing [SEP]']
[Init] best rec loss: 0.9109504222869873 for ['[CLS]bedo legal will pregnant hewitt camera earlier ongoingrralł o mouth would regardedown [SEP]']
[Init] best perm rec loss: 0.9088231325149536 for ['[CLS] pregnant camera ongoingł legalbedo would regarded earlierrral mouth hewitt oown will [SEP]']
[Init] best perm rec loss: 0.9083888530731201 for ['[CLS] regardedown pregnant ongoing earlier mouth legal hewitt would camerałbedo orral will [SEP]']
[Init] best perm rec loss: 0.90836501121521 for ['[CLS] ongoing will pregnantbedo camera legal regarded hewittrral mouth earlierown wouldł o [SEP]']
[Init] best perm rec loss: 0.9055202007293701 for ['[CLS] ongoing regarded camera earlier o pregnantrral will mouthbedoł legal hewitt wouldown [SEP]']
[Init] best perm rec loss: 0.9041357040405273 for ['[CLS] o would regarded mouth camera earlier pregnant ongoing willrralbedoł legalown hewitt [SEP]']
[Init] best perm rec loss: 0.9036893248558044 for ['[CLS] o ongoing earlier willown pregnant regardedł legal mouth hewitt camera wouldbedorral [SEP]']
[Init] best perm rec loss: 0.9027160406112671 for ['[CLS] ongoingł o legalrralownbedo would pregnant camera mouth hewitt will earlier regarded [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.852 (perp=12.125, rec=0.368, cos=0.059), tot_loss_proj:4.367 [t=0.17s]
prediction: ['[CLS] alexander considered. weddings aidan win the fime mrsand beard,... as [SEP]']
[ 100/2000] tot_loss=2.155 (perp=9.101, rec=0.295, cos=0.040), tot_loss_proj:3.716 [t=0.17s]
prediction: ['[CLS] all one on weddings royal win the royal requires weddings on consensus,. as [SEP]']
[ 150/2000] tot_loss=2.503 (perp=11.173, rec=0.232, cos=0.036), tot_loss_proj:4.134 [t=0.17s]
prediction: ['[CLS] reece one on weddings my be a royal requires weddings livingstone consensus royal. the [SEP]']
[ 200/2000] tot_loss=2.001 (perp=8.696, rec=0.226, cos=0.035), tot_loss_proj:3.618 [t=0.17s]
prediction: ['[CLS] provided as on weddings royal queen a royal allows weddings upon present royal. the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.939 (perp=8.561, rec=0.197, cos=0.030), tot_loss_proj:3.586 [t=0.17s]
prediction: ['[CLS] as requirement on weddings royal queen a royal allows weddings upon present royal. the [SEP]']
[ 300/2000] tot_loss=1.863 (perp=8.349, rec=0.167, cos=0.026), tot_loss_proj:3.628 [t=0.17s]
prediction: ['[CLS] requirement requirement on weddings royal present a royal allows weddings that present royal. the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.843 (perp=8.217, rec=0.174, cos=0.026), tot_loss_proj:3.526 [t=0.17s]
prediction: ['[CLS] royal requirement on weddings royal present a requirement is or that present king. royal [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.641 (perp=7.395, rec=0.138, cos=0.024), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] royal requirement on weddings. present is a requirement or that present king. royal [SEP]']
[ 450/2000] tot_loss=1.632 (perp=7.395, rec=0.129, cos=0.024), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] royal requirement on weddings. present is a requirement or that present king. royal [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.596 (perp=7.207, rec=0.132, cos=0.023), tot_loss_proj:3.333 [t=0.17s]
prediction: ['[CLS] requirement on royal weddings. present is a requirement or that present king. royal [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.696 (perp=7.479, rec=0.170, cos=0.030), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] requirement on royal weddings royal present is a requirement or present that king. royal [SEP]']
[ 600/2000] tot_loss=1.733 (perp=7.884, rec=0.130, cos=0.026), tot_loss_proj:3.434 [t=0.17s]
prediction: ['[CLS] requirement on royal weddings queen present is a requirement or present that king. royal [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.606 (perp=7.306, rec=0.121, cos=0.024), tot_loss_proj:3.307 [t=0.17s]
prediction: ['[CLS] requirement on royal weddings be queen is a requirement or present that king. royal [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.578 (perp=7.169, rec=0.120, cos=0.024), tot_loss_proj:3.309 [t=0.17s]
prediction: ['[CLS] requirement that royal weddings be queen is a requirement or present on king. royal [SEP]']
[ 750/2000] tot_loss=1.669 (perp=7.669, rec=0.111, cos=0.024), tot_loss_proj:3.407 [t=0.18s]
prediction: ['[CLS] requirement that royal weddings be queen is a requirement or present on king all royal [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.557 (perp=7.132, rec=0.107, cos=0.024), tot_loss_proj:3.315 [t=0.19s]
prediction: ['[CLS] requirement that royal weddings or be queen is a requirement present on king all royal [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.537 (perp=7.031, rec=0.106, cos=0.025), tot_loss_proj:3.274 [t=0.21s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
[ 900/2000] tot_loss=1.538 (perp=7.031, rec=0.108, cos=0.024), tot_loss_proj:3.272 [t=0.19s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.531 (perp=7.031, rec=0.101, cos=0.024), tot_loss_proj:3.271 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
Attempt swap
[1000/2000] tot_loss=1.532 (perp=7.031, rec=0.102, cos=0.024), tot_loss_proj:3.271 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
[1050/2000] tot_loss=1.517 (perp=7.031, rec=0.087, cos=0.024), tot_loss_proj:3.274 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
Attempt swap
[1100/2000] tot_loss=1.525 (perp=7.031, rec=0.096, cos=0.024), tot_loss_proj:3.273 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
Attempt swap
[1150/2000] tot_loss=1.521 (perp=7.031, rec=0.091, cos=0.024), tot_loss_proj:3.275 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
[1200/2000] tot_loss=1.527 (perp=7.031, rec=0.097, cos=0.024), tot_loss_proj:3.272 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
Attempt swap
[1250/2000] tot_loss=1.517 (perp=7.031, rec=0.087, cos=0.024), tot_loss_proj:3.277 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
Attempt swap
[1300/2000] tot_loss=1.509 (perp=7.031, rec=0.079, cos=0.024), tot_loss_proj:3.273 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
[1350/2000] tot_loss=1.525 (perp=7.031, rec=0.095, cos=0.024), tot_loss_proj:3.274 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.523 (perp=7.031, rec=0.093, cos=0.024), tot_loss_proj:3.261 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.461 (perp=6.734, rec=0.090, cos=0.024), tot_loss_proj:3.192 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
[1500/2000] tot_loss=1.452 (perp=6.734, rec=0.081, cos=0.024), tot_loss_proj:3.192 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
Attempt swap
[1550/2000] tot_loss=1.457 (perp=6.734, rec=0.086, cos=0.024), tot_loss_proj:3.193 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
Attempt swap
[1600/2000] tot_loss=1.461 (perp=6.734, rec=0.091, cos=0.024), tot_loss_proj:3.190 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
[1650/2000] tot_loss=1.459 (perp=6.734, rec=0.088, cos=0.024), tot_loss_proj:3.189 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
Attempt swap
[1700/2000] tot_loss=1.455 (perp=6.734, rec=0.084, cos=0.024), tot_loss_proj:3.192 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
Attempt swap
[1750/2000] tot_loss=1.466 (perp=6.734, rec=0.095, cos=0.024), tot_loss_proj:3.192 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
[1800/2000] tot_loss=1.458 (perp=6.734, rec=0.087, cos=0.024), tot_loss_proj:3.191 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
Attempt swap
[1850/2000] tot_loss=1.459 (perp=6.734, rec=0.089, cos=0.024), tot_loss_proj:3.190 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
Attempt swap
[1900/2000] tot_loss=1.455 (perp=6.734, rec=0.085, cos=0.024), tot_loss_proj:3.194 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
[1950/2000] tot_loss=1.458 (perp=6.734, rec=0.088, cos=0.024), tot_loss_proj:3.193 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
Attempt swap
[2000/2000] tot_loss=1.458 (perp=6.734, rec=0.087, cos=0.024), tot_loss_proj:3.190 [t=0.17s]
prediction: ['[CLS] royal that royal weddings or be queen is a requirement present on all king requirement [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]
========================
predicted: 
========================
[CLS] royal that royal weddings or be queen is a requirement present on king all requirement [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 88.235 | r: 93.750
rouge2     | fm: 19.355 | p: 18.750 | r: 20.000
rougeL     | fm: 60.606 | p: 58.824 | r: 62.500
rougeLsum  | fm: 60.606 | p: 58.824 | r: 62.500
r1fm+r2fm = 110.264

[Aggregate metrics]:
rouge1     | fm: 81.218 | p: 80.791 | r: 81.899
rouge2     | fm: 40.349 | p: 39.833 | r: 41.003
rougeL     | fm: 68.744 | p: 68.380 | r: 69.369
rougeLsum  | fm: 68.644 | p: 68.181 | r: 69.268
r1fm+r2fm = 121.566

input #84 time: 0:07:06 | total time: 9:52:47


Running input #85 of 100.
reference: 
========================
Aphrodite stinks to be omnipotent.
========================
Sample: 0 1.3283579409564741e-11 0.061123414985022766 0.37155718
average of cosine similarity 0.9863760439189806
highest_index [0]
highest [0.9863760439189806]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  9706,  8093,  7716,  4221, 27136,  2015,  2000,  2022, 18168,
          3490, 11008,  4765,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] aphrodite stinks to be omnipotent. [SEP]']
[Init] best rec loss: 0.963916003704071 for ['[CLS] grandchildren ghosts course [SEP]et chief view matt single ko pass rural entered [SEP]']
[Init] best rec loss: 0.8446941375732422 for ['[CLS] glancedュ lowell anna bathtana range focus deafules ball look shortened [SEP]']
[Init] best rec loss: 0.8403056263923645 for ['[CLS] bang hd people essential cell [UNK]ckweight wonder origin unique joshua pick [SEP]']
[Init] best rec loss: 0.8182287216186523 for ['[CLS] march mayoralloadsman greatuled coverskieox monuments res bree thomas [SEP]']
[Init] best rec loss: 0.7831145524978638 for ['[CLS] beneath asked string wrath chief premiere general kneltabas expected minute taiwanese careful [SEP]']
[Init] best rec loss: 0.7647914886474609 for ['[CLS] go legged camille song xavier greg corinne most minus fever formation pair se [SEP]']
[Init] best perm rec loss: 0.7635236978530884 for ['[CLS] minus most se legged fever camille xavier go song corinne formation greg pair [SEP]']
[Init] best perm rec loss: 0.7634173631668091 for ['[CLS] pair minus camille greg song corinne formation most xavier se fever legged go [SEP]']
[Init] best perm rec loss: 0.7633981704711914 for ['[CLS] formation song most camille legged greg pair minus se fever xavier go corinne [SEP]']
[Init] best perm rec loss: 0.7631508708000183 for ['[CLS] fever pair go song greg most xavier corinne formation minus camille se legged [SEP]']
[Init] best perm rec loss: 0.762401282787323 for ['[CLS] se go greg formation most song camille fever legged xavier minus pair corinne [SEP]']
[Init] best perm rec loss: 0.7608497738838196 for ['[CLS] most song minus legged greg formation corinne go pair camille fever se xavier [SEP]']
[Init] best perm rec loss: 0.7602949142456055 for ['[CLS] fever go xavier most corinne song legged pair minus camille greg formation se [SEP]']
[Init] best perm rec loss: 0.7601321339607239 for ['[CLS] se minus legged go pair formation xavier greg most camille song corinne fever [SEP]']
[Init] best perm rec loss: 0.7598096132278442 for ['[CLS] camille legged minus corinne fever formation song se most go pair xavier greg [SEP]']
[Init] best perm rec loss: 0.7597153186798096 for ['[CLS] corinne minus camille fever most greg song pair legged formation go xavier se [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.203 (perp=13.107, rec=0.432, cos=0.150), tot_loss_proj:3.910 [t=0.17s]
prediction: ['[CLS] householdedance dish fever demon absent largestddling m cuisine champion penalty ″ [SEP]']
[ 100/2000] tot_loss=3.100 (perp=13.417, rec=0.335, cos=0.082), tot_loss_proj:4.215 [t=0.17s]
prediction: ['[CLS] household smells pete fever事sk leader herport cuisine championpot stink [SEP]']
[ 150/2000] tot_loss=2.973 (perp=13.201, rec=0.285, cos=0.048), tot_loss_proj:4.104 [t=0.17s]
prediction: ['[CLS]ite stink know beodite leaders herod stink rulerpot stink [SEP]']
[ 200/2000] tot_loss=2.807 (perp=12.549, rec=0.251, cos=0.046), tot_loss_proj:3.816 [t=0.17s]
prediction: ['[CLS]ite stink be beodite by eachod stink rulerpot stink [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.483 (perp=11.050, rec=0.226, cos=0.047), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS]ite stink to beodite terms apod stink beingpot stink [SEP]']
[ 300/2000] tot_loss=2.595 (perp=11.719, rec=0.200, cos=0.052), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS]ite stink to beodite terms everyodpot beingpot stink [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.745 (perp=12.673, rec=0.166, cos=0.044), tot_loss_proj:3.744 [t=0.17s]
prediction: ['[CLS]ite stink to beodite terms any spot appot stink [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.715 (perp=12.550, rec=0.157, cos=0.048), tot_loss_proj:3.996 [t=0.17s]
prediction: ['[CLS]ite stink to beoditeent fpotent ap ruler stink [SEP]']
[ 450/2000] tot_loss=2.699 (perp=12.550, rec=0.150, cos=0.039), tot_loss_proj:4.000 [t=0.17s]
prediction: ['[CLS]ite stink to beoditeent fpotent ap ruler stink [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.417 (perp=11.146, rec=0.150, cos=0.038), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] ap stink to beoditeent fpotentite ruler stink [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.277 (perp=10.290, rec=0.168, cos=0.051), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] apoditeent appotent stink to beite s stink [SEP]']
[ 600/2000] tot_loss=2.232 (perp=10.273, rec=0.140, cos=0.037), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] apoditeent appotent stink to beite highly stink [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.345 (perp=10.880, rec=0.135, cos=0.035), tot_loss_proj:3.539 [t=0.17s]
prediction: ['[CLS] apodite rearentpotent stink to beite s stink [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.385 (perp=11.048, rec=0.138, cos=0.038), tot_loss_proj:3.517 [t=0.17s]
prediction: ['[CLS] apodite rearent stink to bepotentite poll stink [SEP]']
[ 750/2000] tot_loss=2.235 (perp=10.442, rec=0.116, cos=0.031), tot_loss_proj:3.452 [t=0.18s]
prediction: ['[CLS] apodite apent stink to bepotentite poll stink [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.203 (perp=10.314, rec=0.110, cos=0.030), tot_loss_proj:3.887 [t=0.17s]
prediction: ['[CLS] apoditepotent stink to be rearentite when stink [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.987 (perp=9.273, rec=0.103, cos=0.030), tot_loss_proj:3.408 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite when stink [SEP]']
[ 900/2000] tot_loss=1.989 (perp=9.273, rec=0.105, cos=0.030), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite when stink [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.988 (perp=9.273, rec=0.104, cos=0.030), tot_loss_proj:3.404 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite when stink [SEP]']
Attempt swap
[1000/2000] tot_loss=1.986 (perp=9.273, rec=0.102, cos=0.030), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite when stink [SEP]']
[1050/2000] tot_loss=1.980 (perp=9.273, rec=0.096, cos=0.030), tot_loss_proj:3.406 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite when stink [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.107 (perp=9.877, rec=0.101, cos=0.030), tot_loss_proj:3.421 [t=0.17s]
prediction: ['[CLS] apoditepotents to be stinkentite when gi [SEP]']
Attempt swap
[1150/2000] tot_loss=2.102 (perp=9.877, rec=0.096, cos=0.030), tot_loss_proj:3.421 [t=0.17s]
prediction: ['[CLS] apoditepotents to be stinkentite when gi [SEP]']
[1200/2000] tot_loss=2.098 (perp=9.877, rec=0.092, cos=0.030), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] apoditepotents to be stinkentite when gi [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.059 (perp=9.612, rec=0.105, cos=0.031), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] apoditepotents to be gientite when stink [SEP]']
Attempt swap
[1300/2000] tot_loss=2.053 (perp=9.612, rec=0.100, cos=0.030), tot_loss_proj:3.540 [t=0.17s]
prediction: ['[CLS] apoditepotents to be gientite when stink [SEP]']
[1350/2000] tot_loss=1.990 (perp=9.349, rec=0.091, cos=0.030), tot_loss_proj:3.244 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
Attempt swap
[1400/2000] tot_loss=1.996 (perp=9.349, rec=0.096, cos=0.030), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
Attempt swap
[1450/2000] tot_loss=1.997 (perp=9.349, rec=0.098, cos=0.030), tot_loss_proj:3.241 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
[1500/2000] tot_loss=1.998 (perp=9.349, rec=0.099, cos=0.030), tot_loss_proj:3.247 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
Attempt swap
[1550/2000] tot_loss=1.996 (perp=9.349, rec=0.097, cos=0.030), tot_loss_proj:3.237 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
Attempt swap
[1600/2000] tot_loss=1.994 (perp=9.349, rec=0.095, cos=0.030), tot_loss_proj:3.239 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
[1650/2000] tot_loss=1.999 (perp=9.349, rec=0.099, cos=0.030), tot_loss_proj:3.240 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
Attempt swap
[1700/2000] tot_loss=1.994 (perp=9.349, rec=0.095, cos=0.029), tot_loss_proj:3.240 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
Attempt swap
[1750/2000] tot_loss=1.998 (perp=9.349, rec=0.099, cos=0.029), tot_loss_proj:3.246 [t=0.19s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
[1800/2000] tot_loss=2.006 (perp=9.349, rec=0.107, cos=0.029), tot_loss_proj:3.239 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
Attempt swap
[1850/2000] tot_loss=1.997 (perp=9.349, rec=0.098, cos=0.029), tot_loss_proj:3.246 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
Attempt swap
[1900/2000] tot_loss=1.991 (perp=9.349, rec=0.092, cos=0.029), tot_loss_proj:3.236 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
[1950/2000] tot_loss=1.998 (perp=9.349, rec=0.099, cos=0.029), tot_loss_proj:3.238 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
Attempt swap
[2000/2000] tot_loss=1.992 (perp=9.349, rec=0.093, cos=0.029), tot_loss_proj:3.242 [t=0.17s]
prediction: ['[CLS] apoditepotents to be fentite om stink [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] aphrodite stinks to be omnipotent. [SEP]
========================
predicted: 
========================
[CLS] apoditepotents to be fentite om stink [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.333 | p: 50.000 | r: 57.143
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 53.333 | p: 50.000 | r: 57.143
rougeLsum  | fm: 53.333 | p: 50.000 | r: 57.143
r1fm+r2fm = 68.718

[Aggregate metrics]:
rouge1     | fm: 80.824 | p: 80.395 | r: 81.588
rouge2     | fm: 40.063 | p: 39.657 | r: 40.758
rougeL     | fm: 68.519 | p: 68.183 | r: 69.246
rougeLsum  | fm: 68.349 | p: 67.968 | r: 69.057
r1fm+r2fm = 120.887

input #85 time: 0:06:58 | total time: 9:59:46


Running input #86 of 100.
reference: 
========================
I lifted him up the books.
========================
Sample: 0 1.2097755901380335e-12 0.043956891657792756 0.35296324
average of cosine similarity 0.9922149769502308
highest_index [0]
highest [0.9922149769502308]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1045, 4196, 2032, 2039, 1996, 2808, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i lifted him up the books. [SEP]']
[Init] best rec loss: 0.8596559762954712 for ['[CLS] associates kill blockade musica [SEP] bees... [SEP]']
[Init] best rec loss: 0.8160300850868225 for ['[CLS] geekping converted order early franchise pressing [SEP]']
[Init] best rec loss: 0.808757483959198 for ['[CLS] schools team legal lateents laird each [SEP]']
[Init] best rec loss: 0.7976799607276917 for ['[CLS] cara jar orchard wolf walking this negative [SEP]']
[Init] best rec loss: 0.7589608430862427 for ['[CLS] interest check indytute watch pitched licence [SEP]']
[Init] best rec loss: 0.739559531211853 for ['[CLS] did chin rearن spray davyologist [SEP]']
[Init] best rec loss: 0.7275917530059814 for ['[CLS]tonic based coveren booth novels infrared [SEP]']
[Init] best rec loss: 0.7006744742393494 for ['[CLS] made par letters imp carrier obviouss [SEP]']
[Init] best rec loss: 0.6927193999290466 for ['[CLS]arus bank groups bare primetime rub reviewer [SEP]']
[Init] best perm rec loss: 0.6910474300384521 for ['[CLS] reviewer rubarus groups bank primetime bare [SEP]']
[Init] best perm rec loss: 0.6876217722892761 for ['[CLS] rubarus bare bank groups reviewer primetime [SEP]']
[Init] best perm rec loss: 0.6860266923904419 for ['[CLS] rub bank primetime groupsarus reviewer bare [SEP]']
[Init] best perm rec loss: 0.6856589317321777 for ['[CLS] rub primetimearus reviewer groups bank bare [SEP]']
[Init] best perm rec loss: 0.6850431561470032 for ['[CLS] rub bank reviewerarus primetime groups bare [SEP]']
[Init] best perm rec loss: 0.6846989393234253 for ['[CLS] reviewer bare groups bank rub primetimearus [SEP]']
[Init] best perm rec loss: 0.6846939921379089 for ['[CLS] primetime bare groups bank rub reviewerarus [SEP]']
[Init] best perm rec loss: 0.6846843361854553 for ['[CLS] bare reviewerarus bank rub primetime groups [SEP]']
[Init] best perm rec loss: 0.683734655380249 for ['[CLS]arus groups reviewer bank bare rub primetime [SEP]']
[Init] best perm rec loss: 0.6832753419876099 for ['[CLS]arus bare primetime reviewer groups bank rub [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.801 (perp=11.077, rec=0.516, cos=0.069), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] my november flexible two process systems electronic [SEP]']
[ 100/2000] tot_loss=2.722 (perp=11.602, rec=0.365, cos=0.037), tot_loss_proj:3.094 [t=0.17s]
prediction: ['[CLS] my tunic up an process classes even [SEP]']
[ 150/2000] tot_loss=2.119 (perp=9.107, rec=0.270, cos=0.028), tot_loss_proj:2.621 [t=0.17s]
prediction: ['[CLS] lifted tunic up the their books, [SEP]']
[ 200/2000] tot_loss=1.922 (perp=8.419, rec=0.209, cos=0.030), tot_loss_proj:2.460 [t=0.17s]
prediction: ['[CLS] lifted frequencies up the books books. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.791 (perp=7.857, rec=0.189, cos=0.031), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS] lifted up the her kernel books. [SEP]']
[ 300/2000] tot_loss=1.841 (perp=8.421, rec=0.133, cos=0.024), tot_loss_proj:2.553 [t=0.17s]
prediction: ['[CLS] lifted up the her sanctioned books. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.644 (perp=7.471, rec=0.129, cos=0.022), tot_loss_proj:2.343 [t=0.17s]
prediction: ['[CLS] lifted up the increased him books. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.712 (perp=7.662, rec=0.155, cos=0.025), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] lifted him up the royal books, [SEP]']
[ 450/2000] tot_loss=1.659 (perp=7.662, rec=0.105, cos=0.021), tot_loss_proj:2.048 [t=0.17s]
prediction: ['[CLS] lifted him up the royal books, [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.619 (perp=7.469, rec=0.103, cos=0.022), tot_loss_proj:2.024 [t=0.17s]
prediction: ['[CLS] royal lifted him up the books, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.274 (perp=5.815, rec=0.093, cos=0.018), tot_loss_proj:1.642 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
[ 600/2000] tot_loss=1.269 (perp=5.815, rec=0.090, cos=0.016), tot_loss_proj:1.637 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.260 (perp=5.815, rec=0.080, cos=0.017), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.264 (perp=5.815, rec=0.084, cos=0.016), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
[ 750/2000] tot_loss=1.264 (perp=5.815, rec=0.084, cos=0.016), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.260 (perp=5.815, rec=0.081, cos=0.016), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.254 (perp=5.815, rec=0.075, cos=0.016), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
[ 900/2000] tot_loss=1.247 (perp=5.815, rec=0.067, cos=0.016), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.250 (perp=5.815, rec=0.071, cos=0.016), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.250 (perp=5.815, rec=0.070, cos=0.016), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
[1050/2000] tot_loss=1.271 (perp=5.815, rec=0.091, cos=0.016), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.254 (perp=5.815, rec=0.074, cos=0.016), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.262 (perp=5.815, rec=0.082, cos=0.016), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
[1200/2000] tot_loss=1.239 (perp=5.815, rec=0.060, cos=0.016), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.251 (perp=5.815, rec=0.071, cos=0.016), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.254 (perp=5.815, rec=0.074, cos=0.017), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
[1350/2000] tot_loss=1.254 (perp=5.815, rec=0.075, cos=0.016), tot_loss_proj:1.594 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.263 (perp=5.815, rec=0.084, cos=0.016), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.252 (perp=5.815, rec=0.073, cos=0.016), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
[1500/2000] tot_loss=1.251 (perp=5.815, rec=0.072, cos=0.017), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.246 (perp=5.815, rec=0.066, cos=0.017), tot_loss_proj:1.594 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.248 (perp=5.815, rec=0.069, cos=0.017), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
[1650/2000] tot_loss=1.248 (perp=5.815, rec=0.069, cos=0.017), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.242 (perp=5.815, rec=0.063, cos=0.016), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.257 (perp=5.815, rec=0.077, cos=0.017), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
[1800/2000] tot_loss=1.257 (perp=5.815, rec=0.078, cos=0.016), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.253 (perp=5.815, rec=0.073, cos=0.017), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.247 (perp=5.815, rec=0.068, cos=0.017), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
[1950/2000] tot_loss=1.252 (perp=5.815, rec=0.073, cos=0.017), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.249 (perp=5.815, rec=0.070, cos=0.017), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] i lifted him up the books, [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] i lifted him up the books. [SEP]
========================
predicted: 
========================
[CLS] i lifted him up the books, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.128 | p: 80.700 | r: 81.860
rouge2     | fm: 40.695 | p: 40.153 | r: 41.351
rougeL     | fm: 68.895 | p: 68.502 | r: 69.614
rougeLsum  | fm: 68.812 | p: 68.388 | r: 69.500
r1fm+r2fm = 121.823

input #86 time: 0:07:03 | total time: 10:06:49


Running input #87 of 100.
reference: 
========================
Heidi thinks that Andy has eaten salmon flavored candy bars.
========================
Sample: 0 9.894280108499597e-13 0.05116418875871953 0.34610575
average of cosine similarity 0.989013042836532
highest_index [0]
highest [0.989013042836532]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101, 21372,  6732,  2008,  5557,  2038,  8828, 11840, 14894,  2098,
          9485,  6963,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]']
[Init] best rec loss: 1.0333819389343262 for ['[CLS] flood but! means roe vietnam after partial owe cult novel question [SEP]']
[Init] best rec loss: 0.9575434923171997 for ['[CLS] remained rates made glacier beginning gift pianoril department springsuratie [SEP]']
[Init] best rec loss: 0.9186620116233826 for ['[CLS] moreplppet children bank henri she entertainment expression clipped emotions webber [SEP]']
[Init] best perm rec loss: 0.9178486466407776 for ['[CLS] more expression clippedppet webber emotions entertainmentpl she bank children henri [SEP]']
[Init] best perm rec loss: 0.9169323444366455 for ['[CLS] henri expression entertainment she webber clipped children moreppetpl emotions bank [SEP]']
[Init] best perm rec loss: 0.9160096049308777 for ['[CLS] webber emotions expression childrenppet clipped entertainmentpl more henri bank she [SEP]']
[Init] best perm rec loss: 0.9155099391937256 for ['[CLS] bank webber entertainment expression she henri more clipped children emotionsplppet [SEP]']
[Init] best perm rec loss: 0.9128410816192627 for ['[CLS]plppet emotions clipped entertainment bank children she webber expression more henri [SEP]']
[Init] best perm rec loss: 0.9127443432807922 for ['[CLS] entertainment clippedppet emotions children henri bankpl expression webber she more [SEP]']
[Init] best perm rec loss: 0.911577582359314 for ['[CLS]ppet bank children expression entertainment clipped henri she emotions webber morepl [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.390 (perp=14.081, rec=0.598, cos=0.976), tot_loss_proj:4.630 [t=0.17s]
prediction: ['[CLS] festival compliment book dose jason vodkaivate todd employees rope giving lost [SEP]']
[ 100/2000] tot_loss=2.601 (perp=11.258, rec=0.295, cos=0.054), tot_loss_proj:4.122 [t=0.17s]
prediction: ['[CLS]pping ！ heidi. jason kylie ordered heidi reported steak giving dismiss [SEP]']
[ 150/2000] tot_loss=2.542 (perp=11.453, rec=0.224, cos=0.028), tot_loss_proj:4.186 [t=0.17s]
prediction: ['[CLS] heidi ་ heidi thou eat flavor. heidi thinks candy candy andy [SEP]']
[ 200/2000] tot_loss=2.554 (perp=11.721, rec=0.181, cos=0.029), tot_loss_proj:4.174 [t=0.17s]
prediction: ['[CLS] heidi eaten andy thou eaten flavor. heidi thinks candy candy andy [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.246 (perp=10.292, rec=0.160, cos=0.027), tot_loss_proj:3.959 [t=0.17s]
prediction: ['[CLS] heidi eaten andy has eaten flavor. heidi thinks candy candy admits [SEP]']
[ 300/2000] tot_loss=2.122 (perp=9.773, rec=0.142, cos=0.026), tot_loss_proj:3.852 [t=0.17s]
prediction: ['[CLS] heidi eaten andy has eaten flavor. heidi thinks candy candy has [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.844 (perp=12.861, rec=0.231, cos=0.041), tot_loss_proj:4.363 [t=0.17s]
prediction: ['[CLS] eating eaten andy been william taste. heidi thinks candy侍 candy [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.554 (perp=11.670, rec=0.186, cos=0.035), tot_loss_proj:4.179 [t=0.17s]
prediction: ['[CLS] eating侍 andy been andy flavor. heidi thinks candy eaten candy [SEP]']
[ 450/2000] tot_loss=2.482 (perp=11.393, rec=0.172, cos=0.031), tot_loss_proj:4.179 [t=0.17s]
prediction: ['[CLS] eating whose andy having andy flavor. heidi thinks candy eaten candy [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.439 (perp=10.991, rec=0.201, cos=0.039), tot_loss_proj:4.095 [t=0.17s]
prediction: ['[CLS] eating hairy candy of andy flavor traditional heidi thinks andy eaten candy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.485 (perp=11.344, rec=0.183, cos=0.033), tot_loss_proj:4.135 [t=0.17s]
prediction: ['[CLS] eating hairy candy andy andy flavor. heidi thinks been eaten candy [SEP]']
[ 600/2000] tot_loss=2.381 (perp=10.888, rec=0.171, cos=0.031), tot_loss_proj:4.016 [t=0.17s]
prediction: ['[CLS] eating has candy andy andy flavor. heidi thinks been eaten candy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.089 (perp=9.506, rec=0.156, cos=0.032), tot_loss_proj:3.866 [t=0.17s]
prediction: ['[CLS] eating has candy having andy flavor. heidi thinks andy eaten candy [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.039 (perp=9.284, rec=0.151, cos=0.031), tot_loss_proj:3.750 [t=0.17s]
prediction: ['[CLS] eating has flavor having andy salmon. heidi thinks andy eaten candy [SEP]']
[ 750/2000] tot_loss=2.138 (perp=9.793, rec=0.149, cos=0.030), tot_loss_proj:3.857 [t=0.17s]
prediction: ['[CLS] billy has flavor having andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.136 (perp=9.793, rec=0.147, cos=0.030), tot_loss_proj:3.858 [t=0.17s]
prediction: ['[CLS] billy has flavor having andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.125 (perp=9.728, rec=0.150, cos=0.029), tot_loss_proj:3.953 [t=0.17s]
prediction: ['[CLS] billy has flavor. andy salmon taste heidi thinks andy eaten candy [SEP]']
[ 900/2000] tot_loss=2.112 (perp=9.645, rec=0.153, cos=0.030), tot_loss_proj:4.078 [t=0.17s]
prediction: ['[CLS] billy has flavor. andy salmon flavor heidi thinks andy eaten candy [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.099 (perp=9.645, rec=0.140, cos=0.029), tot_loss_proj:4.086 [t=0.17s]
prediction: ['[CLS] billy has flavor. andy salmon flavor heidi thinks andy eaten candy [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.098 (perp=9.648, rec=0.138, cos=0.031), tot_loss_proj:3.818 [t=0.17s]
prediction: ['[CLS] ᅳ has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
[1050/2000] tot_loss=2.096 (perp=9.648, rec=0.137, cos=0.030), tot_loss_proj:3.816 [t=0.17s]
prediction: ['[CLS] ᅳ has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1100/2000] tot_loss=2.093 (perp=9.648, rec=0.134, cos=0.029), tot_loss_proj:3.818 [t=0.17s]
prediction: ['[CLS] ᅳ has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1150/2000] tot_loss=2.096 (perp=9.648, rec=0.137, cos=0.029), tot_loss_proj:3.818 [t=0.17s]
prediction: ['[CLS] ᅳ has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
[1200/2000] tot_loss=1.982 (perp=9.090, rec=0.135, cos=0.029), tot_loss_proj:3.727 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.980 (perp=9.090, rec=0.133, cos=0.029), tot_loss_proj:3.727 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.973 (perp=9.090, rec=0.126, cos=0.029), tot_loss_proj:3.724 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
[1350/2000] tot_loss=1.986 (perp=9.090, rec=0.139, cos=0.029), tot_loss_proj:3.725 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.972 (perp=9.090, rec=0.125, cos=0.029), tot_loss_proj:3.729 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.978 (perp=9.090, rec=0.131, cos=0.029), tot_loss_proj:3.726 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
[1500/2000] tot_loss=1.984 (perp=9.090, rec=0.137, cos=0.029), tot_loss_proj:3.724 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.974 (perp=9.090, rec=0.127, cos=0.029), tot_loss_proj:3.724 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.976 (perp=9.090, rec=0.129, cos=0.029), tot_loss_proj:3.726 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
[1650/2000] tot_loss=1.972 (perp=9.090, rec=0.126, cos=0.029), tot_loss_proj:3.725 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.974 (perp=9.090, rec=0.127, cos=0.029), tot_loss_proj:3.720 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.972 (perp=9.090, rec=0.126, cos=0.029), tot_loss_proj:3.724 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
[1800/2000] tot_loss=1.976 (perp=9.090, rec=0.129, cos=0.029), tot_loss_proj:3.723 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.975 (perp=9.090, rec=0.128, cos=0.029), tot_loss_proj:3.724 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.969 (perp=9.090, rec=0.123, cos=0.029), tot_loss_proj:3.728 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
[1950/2000] tot_loss=1.972 (perp=9.090, rec=0.125, cos=0.029), tot_loss_proj:3.726 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.978 (perp=9.090, rec=0.131, cos=0.029), tot_loss_proj:3.725 [t=0.17s]
prediction: ['[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]
========================
predicted: 
========================
[CLS] candy has flavor flavor andy salmon. heidi thinks andy eaten candy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.000 | p: 69.231 | r: 75.000
rouge2     | fm: 8.696 | p: 8.333 | r: 9.091
rougeL     | fm: 56.000 | p: 53.846 | r: 58.333
rougeLsum  | fm: 56.000 | p: 53.846 | r: 58.333
r1fm+r2fm = 80.696

[Aggregate metrics]:
rouge1     | fm: 81.055 | p: 80.572 | r: 81.821
rouge2     | fm: 40.381 | p: 39.861 | r: 40.913
rougeL     | fm: 68.806 | p: 68.416 | r: 69.425
rougeLsum  | fm: 68.656 | p: 68.261 | r: 69.333
r1fm+r2fm = 121.436

input #87 time: 0:07:16 | total time: 10:14:06


Running input #88 of 100.
reference: 
========================
He bought these flowers for Aaron.
========================
Sample: 0 7.0443768306767545e-12 0.05356477902669037 0.38151124
average of cosine similarity 0.9900946184700621
highest_index [0]
highest [0.9900946184700621]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 4149, 2122, 4870, 2005, 7158, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he bought these flowers for aaron. [SEP]']
[Init] best rec loss: 1.034036636352539 for ['[CLS] wi rio xx irving ou obligations tang [SEP]']
[Init] best rec loss: 1.0049952268600464 for ['[CLS]ing rahman medina volume!lyn put [SEP]']
[Init] best rec loss: 0.9832890629768372 for ['[CLS]iateddication media familiar cas re threshold [SEP]']
[Init] best rec loss: 0.9699617624282837 for ['[CLS]card logan bamboo acting phi market query [SEP]']
[Init] best rec loss: 0.9513040781021118 for ['[CLS] drum representative kai edges evolutionary theories abandonment [SEP]']
[Init] best rec loss: 0.9334592223167419 for ['[CLS] americanaur− laughter peedy stock [SEP]']
[Init] best perm rec loss: 0.9307273030281067 for ['[CLS] peedy stock−aur laughter american [SEP]']
[Init] best perm rec loss: 0.9302306175231934 for ['[CLS] american laughter peedy stock−aur [SEP]']
[Init] best perm rec loss: 0.9283412098884583 for ['[CLS] stockdyaur american laughter− pee [SEP]']
[Init] best perm rec loss: 0.9273785352706909 for ['[CLS]dy stock pee laughter−aur american [SEP]']
[Init] best perm rec loss: 0.9272459149360657 for ['[CLS]dy laughter stock pee american−aur [SEP]']
[Init] best perm rec loss: 0.9270510077476501 for ['[CLS] stockdy pee american laughteraur− [SEP]']
[Init] best perm rec loss: 0.9263805747032166 for ['[CLS] pee− laughter stockdy americanaur [SEP]']
[Init] best perm rec loss: 0.9263287782669067 for ['[CLS]aur pee stock laughter−dy american [SEP]']
[Init] best perm rec loss: 0.9248601198196411 for ['[CLS]aur laughter stock peedy− american [SEP]']
[Init] best perm rec loss: 0.9246683120727539 for ['[CLS] laughter stockaur− peedy american [SEP]']
[Init] best perm rec loss: 0.9239789247512817 for ['[CLS] stock laughter− peeaur americandy [SEP]']
[Init] best perm rec loss: 0.9223710298538208 for ['[CLS] laughter− stockdyaur pee american [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.561 (perp=9.954, rec=0.460, cos=0.111), tot_loss_proj:3.899 [t=0.17s]
prediction: ['[CLS] purchase feelings. grief promotion received relief [SEP]']
[ 100/2000] tot_loss=2.680 (perp=11.464, rec=0.336, cos=0.051), tot_loss_proj:4.214 [t=0.17s]
prediction: ['[CLS] bought spots and belonging flowers aaron desert [SEP]']
[ 150/2000] tot_loss=2.769 (perp=12.301, rec=0.270, cos=0.038), tot_loss_proj:4.386 [t=0.17s]
prediction: ['[CLS] bought bought and flowers flowers aaronfied [SEP]']
[ 200/2000] tot_loss=2.639 (perp=11.883, rec=0.230, cos=0.032), tot_loss_proj:4.195 [t=0.17s]
prediction: ['[CLS] bought bought and flowers flowers aaron for [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.012 (perp=8.978, rec=0.184, cos=0.033), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] bought flowers and bought flowers aaron for [SEP]']
[ 300/2000] tot_loss=2.067 (perp=9.387, rec=0.161, cos=0.030), tot_loss_proj:3.827 [t=0.17s]
prediction: ['[CLS] bought flowers and these flowers aaron for [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.924 (perp=8.817, rec=0.133, cos=0.027), tot_loss_proj:3.877 [t=0.17s]
prediction: ['[CLS] bought flowers and these flowers for aaron [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.637 (perp=6.841, rec=0.240, cos=0.029), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[ 450/2000] tot_loss=1.543 (perp=6.841, rec=0.152, cos=0.023), tot_loss_proj:1.540 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.505 (perp=6.841, rec=0.115, cos=0.022), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.492 (perp=6.841, rec=0.103, cos=0.021), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[ 600/2000] tot_loss=1.483 (perp=6.841, rec=0.094, cos=0.020), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.478 (perp=6.841, rec=0.089, cos=0.020), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.472 (perp=6.841, rec=0.083, cos=0.020), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[ 750/2000] tot_loss=1.468 (perp=6.841, rec=0.080, cos=0.020), tot_loss_proj:1.516 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.474 (perp=6.841, rec=0.086, cos=0.020), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.466 (perp=6.841, rec=0.078, cos=0.020), tot_loss_proj:1.516 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[ 900/2000] tot_loss=1.470 (perp=6.841, rec=0.082, cos=0.020), tot_loss_proj:1.529 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.460 (perp=6.841, rec=0.072, cos=0.020), tot_loss_proj:1.524 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.459 (perp=6.841, rec=0.071, cos=0.020), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1050/2000] tot_loss=1.470 (perp=6.841, rec=0.082, cos=0.020), tot_loss_proj:1.520 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.462 (perp=6.841, rec=0.074, cos=0.020), tot_loss_proj:1.525 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.468 (perp=6.841, rec=0.081, cos=0.020), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1200/2000] tot_loss=1.464 (perp=6.841, rec=0.076, cos=0.020), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.464 (perp=6.841, rec=0.076, cos=0.020), tot_loss_proj:1.525 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.465 (perp=6.841, rec=0.077, cos=0.020), tot_loss_proj:1.529 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1350/2000] tot_loss=1.466 (perp=6.841, rec=0.079, cos=0.020), tot_loss_proj:1.515 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.459 (perp=6.841, rec=0.072, cos=0.020), tot_loss_proj:1.523 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.465 (perp=6.841, rec=0.077, cos=0.020), tot_loss_proj:1.514 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1500/2000] tot_loss=1.463 (perp=6.841, rec=0.075, cos=0.020), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.458 (perp=6.841, rec=0.070, cos=0.020), tot_loss_proj:1.523 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.454 (perp=6.841, rec=0.066, cos=0.020), tot_loss_proj:1.517 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1650/2000] tot_loss=1.452 (perp=6.841, rec=0.064, cos=0.020), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.455 (perp=6.841, rec=0.067, cos=0.020), tot_loss_proj:1.523 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.462 (perp=6.841, rec=0.074, cos=0.020), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1800/2000] tot_loss=1.461 (perp=6.841, rec=0.073, cos=0.020), tot_loss_proj:1.516 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.463 (perp=6.841, rec=0.075, cos=0.020), tot_loss_proj:1.522 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.459 (perp=6.841, rec=0.071, cos=0.020), tot_loss_proj:1.525 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
[1950/2000] tot_loss=1.459 (perp=6.841, rec=0.071, cos=0.020), tot_loss_proj:1.516 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.468 (perp=6.841, rec=0.081, cos=0.020), tot_loss_proj:1.520 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron. [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] he bought these flowers for aaron. [SEP]
========================
predicted: 
========================
[CLS] he bought these flowers for aaron. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.251 | p: 80.741 | r: 82.022
rouge2     | fm: 40.787 | p: 40.335 | r: 41.511
rougeL     | fm: 69.048 | p: 68.624 | r: 69.724
rougeLsum  | fm: 69.006 | p: 68.553 | r: 69.737
r1fm+r2fm = 122.038

input #88 time: 0:06:57 | total time: 10:21:04


Running input #89 of 100.
reference: 
========================
Handsome though they told me that Tom is, I still won't date him.
========================
Sample: 0 1.26170033492509e-11 0.05475815507520681 0.36249536
average of cosine similarity 0.9885247824621017
highest_index [0]
highest [0.9885247824621017]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[ 101, 8502, 2295, 2027, 2409, 2033, 2008, 3419, 2003, 1010, 1045, 2145,
         2180, 1005, 1056, 3058, 2032, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] handsome though they told me that tom is, i still won't date him. [SEP]"]
[Init] best rec loss: 0.9502671360969543 for ['[CLS] save jersey myanmar walkedfkthic ˢ wife dealing tomorrow lola e bit ll show ˈ competitions [SEP]']
[Init] best rec loss: 0.9151517748832703 for ['[CLS] listential calling liesnified sesame solution hop failure colonel sign rms wil ever parsons [CLS] punk [SEP]']
[Init] best rec loss: 0.8847743272781372 for ['[CLS] airports in generic root administrative capitol wisconsin blind municipality remainder prasad squirrelswise antioch programricted palmer [SEP]']
[Init] best rec loss: 0.8470215201377869 for ['[CLS] for means dissolved truceuming pere honoured utc richards fl spike shower when quantum gray huge com [SEP]']
[Init] best rec loss: 0.8421288728713989 for ['[CLS] charactersgut 11 flow rocked sigh entitled eurovision termsbridge question rocdictow 3 dj inspired [SEP]']
[Init] best rec loss: 0.8383911848068237 for ['[CLS] mat leader michael gel making underworld problems fast lake wouldn hundred texts couple after de family 1970s [SEP]']
[Init] best rec loss: 0.825195848941803 for ['[CLS] hopes devicesrued iv governor swap that saskatchewan pup under ultimate section drugged voivodeship should morning 500 [SEP]']
[Init] best rec loss: 0.8245096206665039 for ['[CLS] sectionsfest family spacekes upon double oak gas tackplay easy if cryky distinct nautical [SEP]']
[Init] best perm rec loss: 0.8197810053825378 for ['[CLS]play sections familykesfest space distinct easy nautical gas cry ifky upon oak double tack [SEP]']
[Init] best perm rec loss: 0.8192011713981628 for ['[CLS] gas distinct upon oak familykes if tack spacefest easy sectionsplay doubleky nautical cry [SEP]']
[Init] best perm rec loss: 0.819103479385376 for ['[CLS]ky space distinct oak family if upon gas easy tackplay cry double sectionsfest nauticalkes [SEP]']
[Init] best perm rec loss: 0.8139406442642212 for ['[CLS]kes gas distinct iffest oak tack nautical cry easy double space sections familyplayky upon [SEP]']
[Init] best perm rec loss: 0.8118587136268616 for ['[CLS] tack gasplay distinct cry family oakkykes double easyfest sections space nautical if upon [SEP]']
[Init] best perm rec loss: 0.8108945488929749 for ['[CLS]playkykes distinct cry if sections familyfest oak space easy nautical upon double tack gas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.727 (perp=10.931, rec=0.431, cos=0.110), tot_loss_proj:3.895 [t=0.17s]
prediction: ['[CLS] win though consonants liu body though its character their was nothing hit sea enclosed, be i [SEP]']
[ 100/2000] tot_loss=2.838 (perp=10.109, rec=0.404, cos=0.412), tot_loss_proj:3.864 [t=0.17s]
prediction: ['[CLS] handsome though because liu christian though tom is they i nothing remember handsome did, than i [SEP]']
[ 150/2000] tot_loss=2.793 (perp=11.148, rec=0.447, cos=0.117), tot_loss_proj:4.142 [t=0.17s]
prediction: ['[CLS] board though they towards man though tom is ) iham probably handsome angrily trains blame much [SEP]']
[ 200/2000] tot_loss=2.638 (perp=11.348, rec=0.307, cos=0.062), tot_loss_proj:3.827 [t=0.17s]
prediction: ['[CLS] tom though her masovian man though tom is ) iham probably handsome conditions fa not und [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.565 (perp=11.243, rec=0.267, cos=0.049), tot_loss_proj:3.881 [t=0.17s]
prediction: ['[CLS] tom though her though handsome though tom is ) i probablyham handsome conditions date never und [SEP]']
[ 300/2000] tot_loss=2.509 (perp=11.165, rec=0.228, cos=0.048), tot_loss_proj:4.026 [t=0.18s]
prediction: ['[CLS] tom though her though handsome though handsome is they i probablyham handsome immediately date never und [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.265 (perp=10.079, rec=0.202, cos=0.046), tot_loss_proj:3.841 [t=0.17s]
prediction: ['[CLS] tom though that handsome though though handsome is told i probablyity handsome them date still und [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.020 (perp=8.796, rec=0.210, cos=0.051), tot_loss_proj:3.592 [t=0.18s]
prediction: ['[CLS] tom though that handsome usually though handsome isham i probably told handsome them date never. [SEP]']
[ 450/2000] tot_loss=1.995 (perp=8.855, rec=0.182, cos=0.042), tot_loss_proj:3.652 [t=0.17s]
prediction: ['[CLS] tom though that handsome usually though handsome isham i probably told handsome them date still. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.900 (perp=8.317, rec=0.167, cos=0.070), tot_loss_proj:3.574 [t=0.17s]
prediction: ['[CLS] still though that handsome usually though handsome isham i probably told tom them date tom. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.926 (perp=8.466, rec=0.180, cos=0.053), tot_loss_proj:3.261 [t=0.17s]
prediction: ['[CLS] still though that handsome though always handsome is smooth i probably told tom them date tom ( [SEP]']
[ 600/2000] tot_loss=1.868 (perp=8.390, rec=0.153, cos=0.036), tot_loss_proj:3.278 [t=0.17s]
prediction: ['[CLS] still though that handsome though always handsome is sleek i probably told tom them date tom ( [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.854 (perp=8.330, rec=0.154, cos=0.034), tot_loss_proj:3.136 [t=0.17s]
prediction: ["[CLS] still though that handsome though always handsome is sleek i probably told them date tom tom'[SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.844 (perp=8.330, rec=0.145, cos=0.033), tot_loss_proj:3.139 [t=0.17s]
prediction: ["[CLS] still though that handsome though always handsome is sleek i probably told them date tom tom'[SEP]"]
[ 750/2000] tot_loss=1.848 (perp=8.330, rec=0.150, cos=0.033), tot_loss_proj:3.132 [t=0.17s]
prediction: ["[CLS] still though that handsome though always handsome is sleek i probably told them date tom tom'[SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.832 (perp=8.330, rec=0.134, cos=0.032), tot_loss_proj:3.140 [t=0.18s]
prediction: ["[CLS] still though that handsome though always handsome is sleek i probably told them date tom tom'[SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.680 (perp=7.603, rec=0.127, cos=0.032), tot_loss_proj:2.979 [t=0.18s]
prediction: ['[CLS] though still that handsome though always handsome is sleek i probably told them date tom tom, [SEP]']
[ 900/2000] tot_loss=1.874 (perp=8.568, rec=0.129, cos=0.032), tot_loss_proj:3.644 [t=0.18s]
prediction: ['[CLS] though still that handsome though exactly handsome is sleek i probably they them date tom tom, [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.863 (perp=8.518, rec=0.125, cos=0.035), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] told still that handsome though exactly handsome is sleek, probably date them they tom tom, [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.787 (perp=8.139, rec=0.126, cos=0.033), tot_loss_proj:3.369 [t=0.18s]
prediction: ['[CLS] still told that handsome though exactly handsome is sleek, still date them they tom tom, [SEP]']
[1050/2000] tot_loss=1.783 (perp=8.139, rec=0.123, cos=0.032), tot_loss_proj:3.369 [t=0.17s]
prediction: ['[CLS] still told that handsome though exactly handsome is sleek, still date them they tom tom, [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.638 (perp=7.336, rec=0.139, cos=0.032), tot_loss_proj:3.212 [t=0.18s]
prediction: ['[CLS] still told that handsome though exactly handsome is sleek, they date them still tom tom, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.618 (perp=7.336, rec=0.119, cos=0.032), tot_loss_proj:3.209 [t=0.18s]
prediction: ['[CLS] still told that handsome though exactly handsome is sleek, they date them still tom tom, [SEP]']
[1200/2000] tot_loss=1.617 (perp=7.353, rec=0.116, cos=0.031), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] still told that handsome though her handsome is sleek, they date them still tom tom, [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.642 (perp=7.492, rec=0.114, cos=0.030), tot_loss_proj:3.265 [t=0.17s]
prediction: ['[CLS] still told exactly that handsome though handsome is sleek, they date them still tom tom, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.574 (perp=7.126, rec=0.118, cos=0.030), tot_loss_proj:2.928 [t=0.17s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
[1350/2000] tot_loss=1.574 (perp=7.126, rec=0.119, cos=0.030), tot_loss_proj:2.921 [t=0.17s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.573 (perp=7.126, rec=0.117, cos=0.030), tot_loss_proj:2.923 [t=0.17s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.567 (perp=7.126, rec=0.112, cos=0.030), tot_loss_proj:2.922 [t=0.18s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
[1500/2000] tot_loss=1.568 (perp=7.126, rec=0.112, cos=0.030), tot_loss_proj:2.919 [t=0.17s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.569 (perp=7.126, rec=0.114, cos=0.030), tot_loss_proj:2.923 [t=0.17s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.565 (perp=7.126, rec=0.110, cos=0.030), tot_loss_proj:2.919 [t=0.17s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
[1650/2000] tot_loss=1.565 (perp=7.126, rec=0.110, cos=0.030), tot_loss_proj:2.926 [t=0.17s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.566 (perp=7.126, rec=0.111, cos=0.030), tot_loss_proj:2.920 [t=0.17s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.570 (perp=7.126, rec=0.115, cos=0.030), tot_loss_proj:2.924 [t=0.17s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
[1800/2000] tot_loss=1.559 (perp=7.126, rec=0.104, cos=0.030), tot_loss_proj:2.926 [t=0.18s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they date them still tom tom, [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.527 (perp=6.981, rec=0.100, cos=0.031), tot_loss_proj:2.777 [t=0.18s]
prediction: ['[CLS] still told him that handsome though handsome is sleek, they still date them tom tom, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.522 (perp=6.902, rec=0.111, cos=0.030), tot_loss_proj:2.762 [t=0.17s]
prediction: ['[CLS] still told me that handsome though handsome is sleek, they still date them tom tom, [SEP]']
[1950/2000] tot_loss=1.516 (perp=6.902, rec=0.105, cos=0.030), tot_loss_proj:2.766 [t=0.17s]
prediction: ['[CLS] still told me that handsome though handsome is sleek, they still date them tom tom, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.510 (perp=6.902, rec=0.100, cos=0.030), tot_loss_proj:2.766 [t=0.17s]
prediction: ['[CLS] still told me that handsome though handsome is sleek, they still date them tom tom, [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] handsome though they told me that tom is, i still won't date him. [SEP]
========================
predicted: 
========================
[CLS] still told me that handsome though handsome is sleek, they still date them tom tom, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 70.588 | r: 75.000
rouge2     | fm: 19.355 | p: 18.750 | r: 20.000
rougeL     | fm: 48.485 | p: 47.059 | r: 50.000
rougeLsum  | fm: 48.485 | p: 47.059 | r: 50.000
r1fm+r2fm = 92.082

[Aggregate metrics]:
rouge1     | fm: 81.142 | p: 80.629 | r: 81.971
rouge2     | fm: 40.762 | p: 40.261 | r: 41.424
rougeL     | fm: 68.843 | p: 68.387 | r: 69.563
rougeLsum  | fm: 68.785 | p: 68.336 | r: 69.512
r1fm+r2fm = 121.904

input #89 time: 0:07:16 | total time: 10:28:20


Running input #90 of 100.
reference: 
========================
Moya's football team loved her
========================
Sample: 0 6.290024215171874e-13 0.055220675569194834 0.34747103
average of cosine similarity 0.9872912214447092
highest_index [0]
highest [0.9872912214447092]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9587, 3148, 1005, 1055, 2374, 2136, 3866, 2014,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] moya's football team loved her [SEP]"]
[Init] best rec loss: 0.8754562735557556 for ['[CLS]rra person gasp shit rex become snow dunn [SEP]']
[Init] best rec loss: 0.8286807537078857 for ['[CLS] company slightly describe eager izzy poetryneyox [SEP]']
[Init] best rec loss: 0.8254004716873169 for ['[CLS] roman oclc consultantjust countrieslic relief kam [SEP]']
[Init] best perm rec loss: 0.8226989507675171 for ['[CLS] oclc roman consultant relief countriesjustlic kam [SEP]']
[Init] best perm rec loss: 0.8145224452018738 for ['[CLS] romanjust consultant oclc countries relief kamlic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.639 (perp=12.814, rec=0.623, cos=0.454), tot_loss_proj:4.453 [t=0.17s]
prediction: ['[CLS] wishtight nailed cotton therefore boostle siren [SEP]']
[ 100/2000] tot_loss=3.109 (perp=12.236, rec=0.480, cos=0.182), tot_loss_proj:4.323 [t=0.19s]
prediction: ['[CLS] 6 continue loved publication8 hostelma siren [SEP]']
[ 150/2000] tot_loss=2.825 (perp=12.179, rec=0.330, cos=0.059), tot_loss_proj:4.297 [t=0.17s]
prediction: ['[CLS] 6 family loved baseball never hostelya danielle [SEP]']
[ 200/2000] tot_loss=2.645 (perp=10.886, rec=0.378, cos=0.090), tot_loss_proj:4.036 [t=0.17s]
prediction: ['[CLS] " break loved football - evenyaya [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.938 (perp=12.449, rec=0.367, cos=0.082), tot_loss_proj:4.388 [t=0.17s]
prediction: ['[CLS] break loved football european - moya quickly [SEP]']
[ 300/2000] tot_loss=2.477 (perp=10.765, rec=0.280, cos=0.044), tot_loss_proj:4.040 [t=0.19s]
prediction: ["[CLS] ro loved football european'moya her [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.196 (perp=9.644, rec=0.231, cos=0.036), tot_loss_proj:3.471 [t=0.17s]
prediction: ["[CLS] ro loved her european'moya football [SEP]"]
Attempt swap
[ 400/2000] tot_loss=2.157 (perp=9.644, rec=0.195, cos=0.034), tot_loss_proj:3.467 [t=0.17s]
prediction: ["[CLS] ro loved her european'moya football [SEP]"]
[ 450/2000] tot_loss=2.006 (perp=8.978, rec=0.179, cos=0.031), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] ro loved her " football moya football [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.976 (perp=8.978, rec=0.152, cos=0.029), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] ro loved her " football moya football [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.184 (perp=9.686, rec=0.196, cos=0.050), tot_loss_proj:3.850 [t=0.17s]
prediction: ['[CLS] ro loved her marie football moya football [SEP]']
[ 600/2000] tot_loss=2.156 (perp=9.879, rec=0.151, cos=0.029), tot_loss_proj:3.804 [t=0.17s]
prediction: ['[CLS] ro loved her marie football moya team [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.034 (perp=9.292, rec=0.145, cos=0.030), tot_loss_proj:3.580 [t=0.17s]
prediction: ["[CLS] ro loved her moya marie'team [SEP]"]
Attempt swap
[ 700/2000] tot_loss=2.014 (perp=9.292, rec=0.128, cos=0.028), tot_loss_proj:3.582 [t=0.17s]
prediction: ["[CLS] ro loved her moya marie'team [SEP]"]
[ 750/2000] tot_loss=2.153 (perp=10.021, rec=0.122, cos=0.027), tot_loss_proj:3.890 [t=0.17s]
prediction: ['[CLS] ro loved her moya marie s team [SEP]']
Attempt swap
Put prefix at the end
[ 800/2000] tot_loss=1.996 (perp=9.222, rec=0.120, cos=0.031), tot_loss_proj:3.671 [t=0.17s]
prediction: ['[CLS] s team ro loved her moya marie [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.983 (perp=9.222, rec=0.110, cos=0.029), tot_loss_proj:3.668 [t=0.17s]
prediction: ['[CLS] s team ro loved her moya marie [SEP]']
[ 900/2000] tot_loss=1.974 (perp=9.165, rec=0.113, cos=0.028), tot_loss_proj:3.714 [t=0.17s]
prediction: ["[CLS] s team'loved her moya marie [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.817 (perp=8.434, rec=0.104, cos=0.026), tot_loss_proj:3.525 [t=0.17s]
prediction: ["[CLS] s team loved her'moya marie [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.816 (perp=8.434, rec=0.103, cos=0.026), tot_loss_proj:3.533 [t=0.17s]
prediction: ["[CLS] s team loved her'moya marie [SEP]"]
[1050/2000] tot_loss=1.813 (perp=8.434, rec=0.101, cos=0.026), tot_loss_proj:3.528 [t=0.17s]
prediction: ["[CLS] s team loved her'moya marie [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.809 (perp=8.434, rec=0.096, cos=0.026), tot_loss_proj:3.534 [t=0.17s]
prediction: ["[CLS] s team loved her'moya marie [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.812 (perp=8.434, rec=0.099, cos=0.026), tot_loss_proj:3.531 [t=0.17s]
prediction: ["[CLS] s team loved her'moya marie [SEP]"]
[1200/2000] tot_loss=1.813 (perp=8.434, rec=0.100, cos=0.026), tot_loss_proj:3.532 [t=0.17s]
prediction: ["[CLS] s team loved her'moya marie [SEP]"]
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.785 (perp=8.306, rec=0.098, cos=0.026), tot_loss_proj:3.495 [t=0.17s]
prediction: ["[CLS]'s team loved her moya marie [SEP]"]
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.640 (perp=6.936, rec=0.192, cos=0.061), tot_loss_proj:3.160 [t=0.17s]
prediction: ["[CLS] moya's team loved her marie [SEP]"]
[1350/2000] tot_loss=1.526 (perp=6.936, rec=0.108, cos=0.030), tot_loss_proj:3.163 [t=0.17s]
prediction: ["[CLS] moya's team loved her marie [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.515 (perp=6.936, rec=0.100, cos=0.028), tot_loss_proj:3.160 [t=0.17s]
prediction: ["[CLS] moya's team loved her marie [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.515 (perp=6.936, rec=0.101, cos=0.027), tot_loss_proj:3.164 [t=0.17s]
prediction: ["[CLS] moya's team loved her marie [SEP]"]
[1500/2000] tot_loss=1.518 (perp=6.936, rec=0.104, cos=0.027), tot_loss_proj:3.163 [t=0.17s]
prediction: ["[CLS] moya's team loved her marie [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.490 (perp=6.844, rec=0.094, cos=0.027), tot_loss_proj:2.822 [t=0.21s]
prediction: ["[CLS] moya's team loved her his [SEP]"]
Attempt swap
Moved token
[1600/2000] tot_loss=1.476 (perp=6.765, rec=0.097, cos=0.026), tot_loss_proj:2.551 [t=0.17s]
prediction: ["[CLS] moya's team loved his her [SEP]"]
[1650/2000] tot_loss=1.478 (perp=6.765, rec=0.099, cos=0.026), tot_loss_proj:2.559 [t=0.17s]
prediction: ["[CLS] moya's team loved his her [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.473 (perp=6.765, rec=0.094, cos=0.026), tot_loss_proj:2.570 [t=0.17s]
prediction: ["[CLS] moya's team loved his her [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.467 (perp=6.765, rec=0.088, cos=0.026), tot_loss_proj:2.569 [t=0.17s]
prediction: ["[CLS] moya's team loved his her [SEP]"]
[1800/2000] tot_loss=1.471 (perp=6.765, rec=0.092, cos=0.026), tot_loss_proj:2.579 [t=0.17s]
prediction: ["[CLS] moya's team loved his her [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.475 (perp=6.765, rec=0.096, cos=0.026), tot_loss_proj:2.592 [t=0.17s]
prediction: ["[CLS] moya's team loved his her [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.473 (perp=6.765, rec=0.094, cos=0.026), tot_loss_proj:2.593 [t=0.17s]
prediction: ["[CLS] moya's team loved his her [SEP]"]
[1950/2000] tot_loss=1.468 (perp=6.765, rec=0.090, cos=0.026), tot_loss_proj:2.588 [t=0.17s]
prediction: ["[CLS] moya's team loved his her [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.477 (perp=6.765, rec=0.098, cos=0.026), tot_loss_proj:2.591 [t=0.17s]
prediction: ["[CLS] moya's team loved his her [SEP]"]
Done with input #90 of 100.
reference: 
========================
[CLS] moya's football team loved her [SEP]
========================
predicted: 
========================
[CLS] moya's team loved his her [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 144.643

[Aggregate metrics]:
rouge1     | fm: 81.159 | p: 80.680 | r: 81.931
rouge2     | fm: 40.864 | p: 40.393 | r: 41.454
rougeL     | fm: 69.053 | p: 68.624 | r: 69.703
rougeLsum  | fm: 68.954 | p: 68.509 | r: 69.624
r1fm+r2fm = 122.024

input #90 time: 0:07:13 | total time: 10:35:34


Running input #91 of 100.
reference: 
========================
They investigated the problem.
========================
Sample: 0 5.7063668668971204e-11 0.04577055298170726 0.34557846
average of cosine similarity 0.9911901482069322
highest_index [0]
highest [0.9911901482069322]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2027, 10847,  1996,  3291,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] they investigated the problem. [SEP]']
[Init] best rec loss: 1.0008985996246338 for ['[CLS] non trap brackets opposite mbe [SEP]']
[Init] best rec loss: 0.9636040925979614 for ['[CLS] nope rare chief steveyon [SEP]']
[Init] best rec loss: 0.9533264636993408 for ['[CLS] new award assistant river ce [SEP]']
[Init] best rec loss: 0.946533203125 for ['[CLS] 3 solid property video cane [SEP]']
[Init] best rec loss: 0.9368292093276978 for ['[CLS] communication seat professional delivery lankan [SEP]']
[Init] best rec loss: 0.9343482255935669 for ['[CLS] tongue ways na flush region [SEP]']
[Init] best rec loss: 0.9309041500091553 for ['[CLS] central rosen fashion rounds be [SEP]']
[Init] best rec loss: 0.8867634534835815 for ['[CLS]w czech real mrference [SEP]']
[Init] best rec loss: 0.8775110244750977 for ['[CLS] log hitler heath belgium lynne [SEP]']
[Init] best perm rec loss: 0.8742671608924866 for ['[CLS] lynne log heath belgium hitler [SEP]']
[Init] best perm rec loss: 0.8742567300796509 for ['[CLS] hitler lynne belgium heath log [SEP]']
[Init] best perm rec loss: 0.8719561696052551 for ['[CLS] hitler belgium lynne log heath [SEP]']
[Init] best perm rec loss: 0.8709571361541748 for ['[CLS] hitler log belgium heath lynne [SEP]']
[Init] best perm rec loss: 0.8697481155395508 for ['[CLS] belgium log hitler lynne heath [SEP]']
[Init] best perm rec loss: 0.8682686686515808 for ['[CLS] belgium log heath hitler lynne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.905 (perp=11.401, rec=0.465, cos=0.160), tot_loss_proj:4.198 [t=0.17s]
prediction: ['[CLS] alex forever symmetry. lash [SEP]']
[ 100/2000] tot_loss=2.757 (perp=11.766, rec=0.335, cos=0.069), tot_loss_proj:4.096 [t=0.17s]
prediction: ['[CLS] wesley examined investigate. problem [SEP]']
[ 150/2000] tot_loss=2.372 (perp=10.273, rec=0.267, cos=0.051), tot_loss_proj:3.842 [t=0.17s]
prediction: ['[CLS] they investigated investigated they problem [SEP]']
[ 200/2000] tot_loss=2.312 (perp=10.631, rec=0.160, cos=0.026), tot_loss_proj:3.895 [t=0.17s]
prediction: ['[CLS] they investigated investigated problem problem [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.682 (perp=7.756, rec=0.106, cos=0.025), tot_loss_proj:2.207 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[ 300/2000] tot_loss=1.678 (perp=7.756, rec=0.101, cos=0.025), tot_loss_proj:2.190 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.678 (perp=7.756, rec=0.102, cos=0.024), tot_loss_proj:2.178 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.667 (perp=7.756, rec=0.092, cos=0.024), tot_loss_proj:2.167 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[ 450/2000] tot_loss=1.682 (perp=7.756, rec=0.106, cos=0.024), tot_loss_proj:2.161 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.669 (perp=7.756, rec=0.094, cos=0.024), tot_loss_proj:2.155 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.656 (perp=7.756, rec=0.081, cos=0.024), tot_loss_proj:2.152 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[ 600/2000] tot_loss=1.664 (perp=7.756, rec=0.089, cos=0.023), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.668 (perp=7.756, rec=0.094, cos=0.024), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.652 (perp=7.756, rec=0.078, cos=0.023), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[ 750/2000] tot_loss=1.673 (perp=7.756, rec=0.099, cos=0.023), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.663 (perp=7.756, rec=0.089, cos=0.023), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.659 (perp=7.756, rec=0.085, cos=0.023), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[ 900/2000] tot_loss=1.661 (perp=7.756, rec=0.087, cos=0.023), tot_loss_proj:2.125 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.654 (perp=7.756, rec=0.080, cos=0.023), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1000/2000] tot_loss=1.657 (perp=7.756, rec=0.083, cos=0.023), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[1050/2000] tot_loss=1.667 (perp=7.756, rec=0.093, cos=0.023), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1100/2000] tot_loss=1.665 (perp=7.756, rec=0.091, cos=0.023), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1150/2000] tot_loss=1.665 (perp=7.756, rec=0.091, cos=0.023), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[1200/2000] tot_loss=1.660 (perp=7.756, rec=0.086, cos=0.023), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1250/2000] tot_loss=1.655 (perp=7.756, rec=0.081, cos=0.023), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1300/2000] tot_loss=1.657 (perp=7.756, rec=0.083, cos=0.023), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[1350/2000] tot_loss=1.662 (perp=7.756, rec=0.088, cos=0.023), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1400/2000] tot_loss=1.657 (perp=7.756, rec=0.083, cos=0.023), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1450/2000] tot_loss=1.657 (perp=7.756, rec=0.083, cos=0.023), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[1500/2000] tot_loss=1.658 (perp=7.756, rec=0.084, cos=0.023), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1550/2000] tot_loss=1.665 (perp=7.756, rec=0.091, cos=0.023), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1600/2000] tot_loss=1.655 (perp=7.756, rec=0.081, cos=0.023), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[1650/2000] tot_loss=1.658 (perp=7.756, rec=0.084, cos=0.023), tot_loss_proj:2.108 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1700/2000] tot_loss=1.655 (perp=7.756, rec=0.081, cos=0.023), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1750/2000] tot_loss=1.660 (perp=7.756, rec=0.086, cos=0.023), tot_loss_proj:2.109 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[1800/2000] tot_loss=1.668 (perp=7.756, rec=0.094, cos=0.023), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1850/2000] tot_loss=1.651 (perp=7.756, rec=0.077, cos=0.023), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[1900/2000] tot_loss=1.665 (perp=7.756, rec=0.091, cos=0.023), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
[1950/2000] tot_loss=1.664 (perp=7.756, rec=0.090, cos=0.023), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Attempt swap
[2000/2000] tot_loss=1.652 (perp=7.756, rec=0.078, cos=0.023), tot_loss_proj:2.107 [t=0.17s]
prediction: ['[CLS] they investigated the problem problem [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] they investigated the problem. [SEP]
========================
predicted: 
========================
[CLS] they investigated the problem problem [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 90.909 | p: 83.333 | r: 100.000
rougeL     | fm: 92.308 | p: 85.714 | r: 100.000
rougeLsum  | fm: 92.308 | p: 85.714 | r: 100.000
r1fm+r2fm = 183.217

[Aggregate metrics]:
rouge1     | fm: 81.283 | p: 80.766 | r: 82.192
rouge2     | fm: 41.418 | p: 40.914 | r: 42.127
rougeL     | fm: 69.355 | p: 68.878 | r: 70.077
rougeLsum  | fm: 69.288 | p: 68.769 | r: 70.032
r1fm+r2fm = 122.701

input #91 time: 0:06:46 | total time: 10:42:20


Running input #92 of 100.
reference: 
========================
Andy promised that we would go.
========================
Sample: 0 2.019171329845838e-12 0.05945844719821877 0.3703882
average of cosine similarity 0.9870309412477755
highest_index [0]
highest [0.9870309412477755]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 5557, 5763, 2008, 2057, 2052, 2175, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] andy promised that we would go. [SEP]']
[Init] best rec loss: 1.0239042043685913 for ['[CLS] church shade features forwardlateral one ⟨ [SEP]']
[Init] best rec loss: 0.998636782169342 for ['[CLS] parental expected chase years fighting ego in [SEP]']
[Init] best rec loss: 0.9670264720916748 for ['[CLS] mateo namely there electronics resort with knows [SEP]']
[Init] best rec loss: 0.9609618782997131 for ['[CLS] municipal over ahead hoping proved energy ui [SEP]']
[Init] best rec loss: 0.9385711550712585 for ['[CLS] internal fulfillinghel church hanging choice heath [SEP]']
[Init] best rec loss: 0.9254687428474426 for ['[CLS] bearerfor game trade suit conference bailey [SEP]']
[Init] best rec loss: 0.9024503231048584 for ['[CLS] deputy clint node ra measured wonders light [SEP]']
[Init] best perm rec loss: 0.9020792841911316 for ['[CLS] clint light deputy ra node wonders measured [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.321 (perp=13.535, rec=0.620, cos=0.994), tot_loss_proj:4.492 [t=0.17s]
prediction: ['[CLS] didn. could demanded ongoing guru how [SEP]']
[ 100/2000] tot_loss=3.864 (perp=11.698, rec=0.528, cos=0.997), tot_loss_proj:4.161 [t=0.17s]
prediction: ['[CLS] would. promised promised announced anywhere went [SEP]']
[ 150/2000] tot_loss=3.795 (perp=11.550, rec=0.486, cos=0.998), tot_loss_proj:4.111 [t=0.17s]
prediction: ['[CLS] would. promised promised upcoming anywhere went [SEP]']
[ 200/2000] tot_loss=4.059 (perp=12.860, rec=0.492, cos=0.996), tot_loss_proj:4.358 [t=0.17s]
prediction: ['[CLS]rked andy promised promised upcoming anywhere looked [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.880 (perp=12.109, rec=0.459, cos=1.000), tot_loss_proj:4.208 [t=0.17s]
prediction: ['[CLS]. would promised promised unpleasant anywhere into [SEP]']
[ 300/2000] tot_loss=3.786 (perp=11.843, rec=0.418, cos=0.999), tot_loss_proj:4.196 [t=0.17s]
prediction: ['[CLS]. would promised promised unpleasant button fucked [SEP]']
Attempt swap
[ 350/2000] tot_loss=4.153 (perp=13.691, rec=0.417, cos=0.998), tot_loss_proj:4.560 [t=0.17s]
prediction: ['[CLS] andy would promised promised unpleasantorough fucked [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.873 (perp=12.124, rec=0.448, cos=1.000), tot_loss_proj:4.458 [t=0.17s]
prediction: ['[CLS] andy priority promised promised charlie would ⺩ [SEP]']
[ 450/2000] tot_loss=4.061 (perp=13.269, rec=0.407, cos=1.000), tot_loss_proj:4.471 [t=0.17s]
prediction: ['[CLS] andy priority promised promised validity would₂ [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.835 (perp=12.240, rec=0.387, cos=1.000), tot_loss_proj:4.263 [t=0.17s]
prediction: ['[CLS] andy ® promised promised ⁱ would cartridge [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.672 (perp=11.419, rec=0.388, cos=0.999), tot_loss_proj:4.085 [t=0.17s]
prediction: ['[CLS] andy folder promised promised ⁱ would ® [SEP]']
[ 600/2000] tot_loss=3.740 (perp=11.775, rec=0.386, cos=0.999), tot_loss_proj:4.166 [t=0.17s]
prediction: ['[CLS] andy folder promised promised ⁱ would₂ [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.731 (perp=11.775, rec=0.376, cos=0.999), tot_loss_proj:4.165 [t=0.17s]
prediction: ['[CLS] andy folder promised promised ⁱ would₂ [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.718 (perp=11.676, rec=0.383, cos=0.999), tot_loss_proj:4.350 [t=0.17s]
prediction: ['[CLS] andy folder promised promised ⁱ would ⺩ [SEP]']
[ 750/2000] tot_loss=3.746 (perp=11.894, rec=0.368, cos=0.999), tot_loss_proj:4.371 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would ⺩ [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.700 (perp=11.632, rec=0.374, cos=0.999), tot_loss_proj:4.225 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ wouldा [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.695 (perp=11.632, rec=0.369, cos=1.000), tot_loss_proj:4.222 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ wouldा [SEP]']
[ 900/2000] tot_loss=3.691 (perp=11.632, rec=0.365, cos=0.999), tot_loss_proj:4.219 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ wouldा [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.742 (perp=11.894, rec=0.364, cos=0.999), tot_loss_proj:4.373 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would ⺩ [SEP]']
Attempt swap
[1000/2000] tot_loss=3.734 (perp=11.894, rec=0.356, cos=0.999), tot_loss_proj:4.372 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would ⺩ [SEP]']
[1050/2000] tot_loss=3.742 (perp=11.894, rec=0.363, cos=1.000), tot_loss_proj:4.371 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would ⺩ [SEP]']
Attempt swap
[1100/2000] tot_loss=3.730 (perp=11.797, rec=0.371, cos=1.000), tot_loss_proj:4.289 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would 比 [SEP]']
Attempt swap
[1150/2000] tot_loss=3.726 (perp=11.797, rec=0.367, cos=1.000), tot_loss_proj:4.288 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would 比 [SEP]']
[1200/2000] tot_loss=3.721 (perp=11.797, rec=0.362, cos=0.999), tot_loss_proj:4.290 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would 比 [SEP]']
Attempt swap
[1250/2000] tot_loss=3.717 (perp=11.797, rec=0.358, cos=0.999), tot_loss_proj:4.291 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would 比 [SEP]']
Attempt swap
[1300/2000] tot_loss=3.719 (perp=11.797, rec=0.361, cos=0.999), tot_loss_proj:4.285 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would 比 [SEP]']
[1350/2000] tot_loss=3.725 (perp=11.797, rec=0.366, cos=1.000), tot_loss_proj:4.285 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would 比 [SEP]']
Attempt swap
[1400/2000] tot_loss=3.715 (perp=11.797, rec=0.356, cos=1.000), tot_loss_proj:4.288 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promised ⁱ would 比 [SEP]']
Attempt swap
[1450/2000] tot_loss=3.776 (perp=12.094, rec=0.357, cos=0.999), tot_loss_proj:4.478 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
[1500/2000] tot_loss=3.769 (perp=12.094, rec=0.351, cos=1.000), tot_loss_proj:4.473 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
Attempt swap
[1550/2000] tot_loss=3.775 (perp=12.094, rec=0.357, cos=0.999), tot_loss_proj:4.475 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
Attempt swap
[1600/2000] tot_loss=3.774 (perp=12.094, rec=0.356, cos=0.999), tot_loss_proj:4.470 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
[1650/2000] tot_loss=3.774 (perp=12.094, rec=0.356, cos=0.999), tot_loss_proj:4.479 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
Attempt swap
[1700/2000] tot_loss=3.776 (perp=12.094, rec=0.358, cos=0.999), tot_loss_proj:4.468 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
Attempt swap
[1750/2000] tot_loss=3.772 (perp=12.094, rec=0.354, cos=0.999), tot_loss_proj:4.473 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
[1800/2000] tot_loss=3.769 (perp=12.094, rec=0.350, cos=0.999), tot_loss_proj:4.475 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
Attempt swap
[1850/2000] tot_loss=3.777 (perp=12.094, rec=0.359, cos=0.999), tot_loss_proj:4.471 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
Attempt swap
[1900/2000] tot_loss=3.774 (perp=12.094, rec=0.356, cos=0.999), tot_loss_proj:4.468 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
[1950/2000] tot_loss=3.776 (perp=12.094, rec=0.358, cos=0.999), tot_loss_proj:4.473 [t=0.17s]
prediction: ['[CLS] andy cartridge promised promisedndo would 比 [SEP]']
Attempt swap
[2000/2000] tot_loss=3.823 (perp=12.366, rec=0.351, cos=0.999), tot_loss_proj:4.452 [t=0.17s]
prediction: ['[CLS] andyudence promised promisedndo would 比 [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] andy promised that we would go. [SEP]
========================
predicted: 
========================
[CLS] andy cartridge promised promisedndo would 比 [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 71.429 | r: 62.500
rouge2     | fm: 15.385 | p: 16.667 | r: 14.286
rougeL     | fm: 66.667 | p: 71.429 | r: 62.500
rougeLsum  | fm: 66.667 | p: 71.429 | r: 62.500
r1fm+r2fm = 82.051

[Aggregate metrics]:
rouge1     | fm: 81.162 | p: 80.644 | r: 81.992
rouge2     | fm: 41.118 | p: 40.638 | r: 41.798
rougeL     | fm: 69.340 | p: 68.882 | r: 70.060
rougeLsum  | fm: 69.205 | p: 68.754 | r: 69.893
r1fm+r2fm = 122.279

input #92 time: 0:06:56 | total time: 10:49:16


Running input #93 of 100.
reference: 
========================
I saw these dancers and those musicians smoking something.
========================
Sample: 0 1.0155784246828767e-12 0.04924288603522979 0.353082
average of cosine similarity 0.9902269086860778
highest_index [0]
highest [0.9902269086860778]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1045,  2387,  2122, 10487,  1998,  2216,  5389,  9422,  2242,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] i saw these dancers and those musicians smoking something. [SEP]']
[Init] best rec loss: 0.9399735331535339 for ['[CLS] choir torque titled uttar 25 tell even hitch encounter choosing [SEP]']
[Init] best rec loss: 0.9395652413368225 for ['[CLS] version ltd blur ringinghs chip astro bandrized federal [SEP]']
[Init] best rec loss: 0.9121893048286438 for ['[CLS] globe ~ titled scoredна japanese lynne they hardly lucas [SEP]']
[Init] best rec loss: 0.9106736779212952 for ['[CLS] existing ten exposurekti understandvirus beyond appear cubs planted [SEP]']
[Init] best rec loss: 0.9029486775398254 for ['[CLS] married formora wrong [CLS] enoughoft unanimouscturing spring [SEP]']
[Init] best rec loss: 0.8923229575157166 for ['[CLS] depending little you criteria remarriedmy within local flame conversion [SEP]']
[Init] best rec loss: 0.8887438774108887 for ['[CLS] sulfate basball shit begin collapse say full matches ems [SEP]']
[Init] best rec loss: 0.8878989219665527 for ['[CLS] applied ze milwaukee sharks though goods taken hour yin apps [SEP]']
[Init] best rec loss: 0.8873622417449951 for ['[CLS] aerospacelore no scheme ground overhead coach clearance under cal [SEP]']
[Init] best perm rec loss: 0.8865259289741516 for ['[CLS] aerospace scheme clearancelore ground overhead no coach cal under [SEP]']
[Init] best perm rec loss: 0.8864747285842896 for ['[CLS] coach clearance no scheme underlore aerospace cal overhead ground [SEP]']
[Init] best perm rec loss: 0.88502037525177 for ['[CLS] cal aerospace scheme overhead ground clearance nolore coach under [SEP]']
[Init] best perm rec loss: 0.8849398493766785 for ['[CLS] overheadlore ground aerospace no cal clearance coach scheme under [SEP]']
[Init] best perm rec loss: 0.8823032379150391 for ['[CLS] ground callore scheme clearance coach no aerospace overhead under [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.084 (perp=12.450, rec=0.598, cos=0.995), tot_loss_proj:4.205 [t=0.17s]
prediction: ['[CLS] roads organization engage ; theirst production aerospace kept soon [SEP]']
[ 100/2000] tot_loss=4.021 (perp=12.547, rec=0.513, cos=0.998), tot_loss_proj:4.251 [t=0.17s]
prediction: ['[CLS] notes organizations musicians those these that groups orchestra smoking event [SEP]']
[ 150/2000] tot_loss=3.851 (perp=11.845, rec=0.483, cos=0.999), tot_loss_proj:4.136 [t=0.17s]
prediction: ['[CLS] notes saw dancers those these those performing orchestra smoking acquired [SEP]']
[ 200/2000] tot_loss=3.809 (perp=11.812, rec=0.448, cos=0.999), tot_loss_proj:4.108 [t=0.17s]
prediction: ['[CLS] man these dancers those those those smoking orchestra smoking acquired [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=4.069 (perp=12.977, rec=0.474, cos=0.999), tot_loss_proj:4.366 [t=0.17s]
prediction: ['[CLS] consonant these dancers those thoseential orchestra something smoking had [SEP]']
[ 300/2000] tot_loss=3.976 (perp=12.767, rec=0.423, cos=1.000), tot_loss_proj:4.325 [t=0.17s]
prediction: ['[CLS] consonant these dancers those thoseiful musicians something smoking acquired [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.465 (perp=10.300, rec=0.406, cos=1.000), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] these verdict dancers those thoseiful musicians something smoking. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.264 (perp=9.177, rec=0.429, cos=1.000), tot_loss_proj:3.690 [t=0.17s]
prediction: ['[CLS] these been dancers those those dancers smoking polgara smoking. [SEP]']
[ 450/2000] tot_loss=3.156 (perp=8.812, rec=0.393, cos=1.000), tot_loss_proj:3.575 [t=0.17s]
prediction: ['[CLS] these been dancers those those musicians something those smoking. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.488 (perp=10.298, rec=0.429, cos=0.999), tot_loss_proj:3.848 [t=0.17s]
prediction: ['[CLS] these been dancers those those something polgara dancers smoking : [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.272 (perp=9.357, rec=0.402, cos=0.999), tot_loss_proj:3.695 [t=0.17s]
prediction: ['[CLS] these been dancers those those dancers something polgara smoking. [SEP]']
[ 600/2000] tot_loss=3.165 (perp=8.940, rec=0.378, cos=0.999), tot_loss_proj:3.622 [t=0.17s]
prediction: ['[CLS] these been dancers those those musicians something these smoking. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.224 (perp=9.231, rec=0.379, cos=0.999), tot_loss_proj:3.650 [t=0.17s]
prediction: ['[CLS] these dancers been those those musicians something polgara smoking. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.196 (perp=9.096, rec=0.379, cos=0.998), tot_loss_proj:3.623 [t=0.17s]
prediction: ['[CLS] these dancers been those those musicians outta something smoking. [SEP]']
[ 750/2000] tot_loss=3.182 (perp=9.096, rec=0.364, cos=0.998), tot_loss_proj:3.625 [t=0.17s]
prediction: ['[CLS] these dancers been those those musicians outta something smoking. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.168 (perp=9.066, rec=0.356, cos=0.998), tot_loss_proj:3.615 [t=0.17s]
prediction: ['[CLS] seeing dancers been those those musicians outta smoking something. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.165 (perp=9.066, rec=0.354, cos=0.998), tot_loss_proj:3.613 [t=0.17s]
prediction: ['[CLS] seeing dancers been those those musicians outta smoking something. [SEP]']
[ 900/2000] tot_loss=3.169 (perp=9.066, rec=0.359, cos=0.997), tot_loss_proj:3.616 [t=0.17s]
prediction: ['[CLS] seeing dancers been those those musicians outta smoking something. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.165 (perp=9.066, rec=0.353, cos=0.998), tot_loss_proj:3.614 [t=0.17s]
prediction: ['[CLS] seeing dancers been those those musicians outta smoking something. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.161 (perp=9.066, rec=0.350, cos=0.998), tot_loss_proj:3.615 [t=0.17s]
prediction: ['[CLS] seeing dancers been those those musicians outta smoking something. [SEP]']
[1050/2000] tot_loss=3.156 (perp=9.066, rec=0.345, cos=0.998), tot_loss_proj:3.614 [t=0.17s]
prediction: ['[CLS] seeing dancers been those those musicians outta smoking something. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.155 (perp=9.066, rec=0.344, cos=0.997), tot_loss_proj:3.612 [t=0.17s]
prediction: ['[CLS] seeing dancers been those those musicians outta smoking something. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.314 (perp=9.739, rec=0.368, cos=0.997), tot_loss_proj:3.744 [t=0.17s]
prediction: ['[CLS] wanda dancers seeing those those musicians outta smoking something. [SEP]']
[1200/2000] tot_loss=3.290 (perp=9.739, rec=0.345, cos=0.998), tot_loss_proj:3.745 [t=0.17s]
prediction: ['[CLS] wanda dancers seeing those those musicians outta smoking something. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.286 (perp=9.739, rec=0.341, cos=0.998), tot_loss_proj:3.745 [t=0.17s]
prediction: ['[CLS] wanda dancers seeing those those musicians outta smoking something. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.284 (perp=9.739, rec=0.338, cos=0.998), tot_loss_proj:3.743 [t=0.17s]
prediction: ['[CLS] wanda dancers seeing those those musicians outta smoking something. [SEP]']
[1350/2000] tot_loss=3.366 (perp=10.135, rec=0.342, cos=0.998), tot_loss_proj:3.835 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians outta smoking something. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=3.191 (perp=9.287, rec=0.336, cos=0.998), tot_loss_proj:3.737 [t=0.17s]
prediction: ['[CLS] been dancers seeing those those musicians smoking outta something. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.302 (perp=9.852, rec=0.334, cos=0.998), tot_loss_proj:3.804 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
[1500/2000] tot_loss=3.304 (perp=9.852, rec=0.336, cos=0.998), tot_loss_proj:3.803 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.299 (perp=9.852, rec=0.331, cos=0.998), tot_loss_proj:3.807 [t=0.19s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.297 (perp=9.852, rec=0.329, cos=0.998), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
[1650/2000] tot_loss=3.291 (perp=9.852, rec=0.322, cos=0.998), tot_loss_proj:3.801 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.295 (perp=9.852, rec=0.327, cos=0.998), tot_loss_proj:3.808 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.299 (perp=9.852, rec=0.330, cos=0.998), tot_loss_proj:3.803 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
[1800/2000] tot_loss=3.300 (perp=9.852, rec=0.332, cos=0.998), tot_loss_proj:3.804 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.292 (perp=9.852, rec=0.324, cos=0.998), tot_loss_proj:3.802 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.302 (perp=9.852, rec=0.334, cos=0.998), tot_loss_proj:3.807 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
[1950/2000] tot_loss=3.292 (perp=9.852, rec=0.324, cos=0.998), tot_loss_proj:3.812 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.296 (perp=9.852, rec=0.328, cos=0.998), tot_loss_proj:3.807 [t=0.17s]
prediction: ['[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] i saw these dancers and those musicians smoking something. [SEP]
========================
predicted: 
========================
[CLS]ha dancers seeing those those musicians smoking outta something. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.636 | p: 63.636 | r: 63.636
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 93.636

[Aggregate metrics]:
rouge1     | fm: 80.986 | p: 80.480 | r: 81.784
rouge2     | fm: 41.045 | p: 40.548 | r: 41.721
rougeL     | fm: 69.213 | p: 68.769 | r: 69.876
rougeLsum  | fm: 69.116 | p: 68.666 | r: 69.839
r1fm+r2fm = 122.031

input #93 time: 0:06:57 | total time: 10:56:13


Running input #94 of 100.
reference: 
========================
Ayala sent back her cousin the diamond necklace.
========================
Sample: 0 2.559382717902067e-12 0.04938000190829382 0.36020124
average of cosine similarity 0.9905585626753779
highest_index [0]
highest [0.9905585626753779]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  2067,  2014,  5542,  1996,  6323, 13016,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ayala sent back her cousin the diamond necklace. [SEP]']
[Init] best rec loss: 1.0233622789382935 for ['[CLS] universe car flight volume stem? fangs naturally port produced [SEP]']
[Init] best rec loss: 0.810341477394104 for ['[CLS] c2 guysament means tucker indicated corresponding likes instead shifters [SEP]']
[Init] best rec loss: 0.8015455603599548 for ['[CLS] crocodile potter entertainment nearlaw chapel issues dive mohamedistle [SEP]']
[Init] best rec loss: 0.753000020980835 for ['[CLS] nina weights micah economy ladyaciesffled feeling harbor mt [SEP]']
[Init] best rec loss: 0.7525247931480408 for ['[CLS] commander system country ca young orleans facial yhaus boring [SEP]']
[Init] best rec loss: 0.7276646494865417 for ['[CLS] chartered cult4chment boat six cinder bothered eminentacies [SEP]']
[Init] best rec loss: 0.7244107127189636 for ['[CLS] henrytrip rs earlier ranks tr countries collection eye going [SEP]']
[Init] best rec loss: 0.7231367230415344 for ['[CLS] relegation unincorporated q hang separated arrive place settled up drawing [SEP]']
[Init] best rec loss: 0.7114856839179993 for ['[CLS]edge awareness champions being herself h derek label missions fits [SEP]']
[Init] best rec loss: 0.7034398317337036 for ['[CLS] o planned emirates fra conditioned simpsonlund client regulations friendly [SEP]']
[Init] best perm rec loss: 0.7031844854354858 for ['[CLS] simpsonlund conditioned planned emirates fra o client regulations friendly [SEP]']
[Init] best perm rec loss: 0.7023455500602722 for ['[CLS] client planned conditionedlund fra friendly regulations o simpson emirates [SEP]']
[Init] best perm rec loss: 0.7006390690803528 for ['[CLS] clientlund fra planned conditioned o friendly emirates simpson regulations [SEP]']
[Init] best perm rec loss: 0.699734091758728 for ['[CLS] fra emirates o conditioned simpson regulations planned clientlund friendly [SEP]']
[Init] best perm rec loss: 0.6980162858963013 for ['[CLS]lund regulations o client conditioned fra simpson planned emirates friendly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.996 (perp=12.260, rec=0.436, cos=0.108), tot_loss_proj:3.641 [t=0.17s]
prediction: ["[CLS] your states medal employees her little ringo strengthrrard'[SEP]"]
[ 100/2000] tot_loss=2.568 (perp=10.919, rec=0.328, cos=0.056), tot_loss_proj:3.269 [t=0.17s]
prediction: ['[CLS] his back medal god her back necklace her hindu her [SEP]']
[ 150/2000] tot_loss=2.623 (perp=9.775, rec=0.524, cos=0.144), tot_loss_proj:3.000 [t=0.17s]
prediction: ['[CLS] regard back brother legendary sent back alonso the diamond. [SEP]']
[ 200/2000] tot_loss=2.503 (perp=10.450, rec=0.350, cos=0.063), tot_loss_proj:2.980 [t=0.17s]
prediction: ['[CLS] sent back debt legendary sent backyala. womantaking [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.375 (perp=10.217, rec=0.281, cos=0.051), tot_loss_proj:3.259 [t=0.17s]
prediction: ['[CLS] sent back debt woman sent backyala the artifacts necklace [SEP]']
[ 300/2000] tot_loss=2.335 (perp=10.513, rec=0.197, cos=0.036), tot_loss_proj:3.677 [t=0.17s]
prediction: ['[CLS] his back debt secondary sent backyala the the necklace [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.973 (perp=8.926, rec=0.158, cos=0.029), tot_loss_proj:3.214 [t=0.17s]
prediction: ['[CLS] her back cousin necklace sent back theyala the necklace [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.872 (perp=8.487, rec=0.144, cos=0.030), tot_loss_proj:3.001 [t=0.17s]
prediction: ['[CLS] her back necklace cousin sent back theyala the necklace [SEP]']
[ 450/2000] tot_loss=1.852 (perp=8.487, rec=0.127, cos=0.027), tot_loss_proj:3.001 [t=0.17s]
prediction: ['[CLS] her back necklace cousin sent back theyala the necklace [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.123 (perp=9.728, rec=0.146, cos=0.031), tot_loss_proj:2.621 [t=0.17s]
prediction: ['[CLS] her back secondary cousin sent cousin the necklace theyala [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.050 (perp=9.468, rec=0.127, cos=0.030), tot_loss_proj:3.085 [t=0.17s]
prediction: ['[CLS] her cousin secondary back sent cousin the necklace theyala [SEP]']
[ 600/2000] tot_loss=2.039 (perp=9.468, rec=0.118, cos=0.027), tot_loss_proj:3.082 [t=0.17s]
prediction: ['[CLS] her cousin secondary back sent cousin the necklace theyala [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.988 (perp=9.211, rec=0.120, cos=0.026), tot_loss_proj:2.868 [t=0.17s]
prediction: ['[CLS] her secondary cousin back sent cousin the necklace theyala [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.970 (perp=9.211, rec=0.103, cos=0.025), tot_loss_proj:2.868 [t=0.17s]
prediction: ['[CLS] her secondary cousin back sent cousin the necklace theyala [SEP]']
[ 750/2000] tot_loss=2.016 (perp=9.426, rec=0.106, cos=0.025), tot_loss_proj:3.222 [t=0.17s]
prediction: ['[CLS] her secondary cousin back sent necklace the necklace theyala [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.883 (perp=8.795, rec=0.100, cos=0.024), tot_loss_proj:2.992 [t=0.17s]
prediction: ['[CLS] her secondary cousin sent back necklace the necklace theyala [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.836 (perp=8.480, rec=0.113, cos=0.027), tot_loss_proj:2.356 [t=0.17s]
prediction: ['[CLS] her secondary cousin sent back the necklace necklace theyala [SEP]']
[ 900/2000] tot_loss=1.821 (perp=8.480, rec=0.100, cos=0.025), tot_loss_proj:2.362 [t=0.17s]
prediction: ['[CLS] her secondary cousin sent back the necklace necklace theyala [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.754 (perp=8.141, rec=0.102, cos=0.024), tot_loss_proj:2.743 [t=0.17s]
prediction: ['[CLS] her secondary cousin sent back the necklace the necklaceyala [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.669 (perp=7.733, rec=0.099, cos=0.023), tot_loss_proj:2.605 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the secondary necklaceyala [SEP]']
[1050/2000] tot_loss=1.519 (perp=6.996, rec=0.098, cos=0.022), tot_loss_proj:2.293 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1100/2000] tot_loss=1.523 (perp=6.996, rec=0.102, cos=0.022), tot_loss_proj:2.296 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1150/2000] tot_loss=1.511 (perp=6.996, rec=0.090, cos=0.022), tot_loss_proj:2.306 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
[1200/2000] tot_loss=1.514 (perp=6.996, rec=0.093, cos=0.022), tot_loss_proj:2.293 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1250/2000] tot_loss=1.519 (perp=6.996, rec=0.099, cos=0.022), tot_loss_proj:2.296 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1300/2000] tot_loss=1.508 (perp=6.996, rec=0.088, cos=0.022), tot_loss_proj:2.299 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
[1350/2000] tot_loss=1.506 (perp=6.996, rec=0.086, cos=0.022), tot_loss_proj:2.292 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1400/2000] tot_loss=1.513 (perp=6.996, rec=0.093, cos=0.021), tot_loss_proj:2.300 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1450/2000] tot_loss=1.512 (perp=6.996, rec=0.091, cos=0.021), tot_loss_proj:2.299 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
[1500/2000] tot_loss=1.508 (perp=6.996, rec=0.088, cos=0.021), tot_loss_proj:2.300 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1550/2000] tot_loss=1.504 (perp=6.996, rec=0.083, cos=0.021), tot_loss_proj:2.292 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1600/2000] tot_loss=1.513 (perp=6.996, rec=0.092, cos=0.021), tot_loss_proj:2.299 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
[1650/2000] tot_loss=1.512 (perp=6.996, rec=0.091, cos=0.021), tot_loss_proj:2.292 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1700/2000] tot_loss=1.500 (perp=6.996, rec=0.079, cos=0.021), tot_loss_proj:2.295 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1750/2000] tot_loss=1.508 (perp=6.996, rec=0.087, cos=0.021), tot_loss_proj:2.293 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
[1800/2000] tot_loss=1.507 (perp=6.996, rec=0.086, cos=0.021), tot_loss_proj:2.299 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1850/2000] tot_loss=1.513 (perp=6.996, rec=0.093, cos=0.021), tot_loss_proj:2.291 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[1900/2000] tot_loss=1.503 (perp=6.996, rec=0.083, cos=0.021), tot_loss_proj:2.296 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
[1950/2000] tot_loss=1.503 (perp=6.996, rec=0.083, cos=0.021), tot_loss_proj:2.294 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Attempt swap
[2000/2000] tot_loss=1.519 (perp=6.996, rec=0.098, cos=0.021), tot_loss_proj:2.298 [t=0.17s]
prediction: ['[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] ayala sent back her cousin the diamond necklace. [SEP]
========================
predicted: 
========================
[CLS] her cousin sent back the necklace the diamond necklaceyala [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 31.579 | p: 30.000 | r: 33.333
rougeL     | fm: 57.143 | p: 54.545 | r: 60.000
rougeLsum  | fm: 57.143 | p: 54.545 | r: 60.000
r1fm+r2fm = 117.293

[Aggregate metrics]:
rouge1     | fm: 81.078 | p: 80.437 | r: 81.897
rouge2     | fm: 40.999 | p: 40.409 | r: 41.621
rougeL     | fm: 69.066 | p: 68.596 | r: 69.798
rougeLsum  | fm: 69.058 | p: 68.558 | r: 69.720
r1fm+r2fm = 122.076

input #94 time: 0:06:56 | total time: 11:03:09


Running input #95 of 100.
reference: 
========================
Brenda met.
========================
Sample: 0 2.989647551328729e-12 0.05180644760883647 0.36008123
average of cosine similarity 0.9895959247602386
highest_index [0]
highest [0.9895959247602386]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15507,  2777,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] brenda met. [SEP]']
[Init] best rec loss: 0.9856793880462646 for ['[CLS]eptive day less [SEP]']
[Init] best rec loss: 0.931098461151123 for ['[CLS]fall few why [SEP]']
[Init] best rec loss: 0.8573922514915466 for ['[CLS] princess horses domesday [SEP]']
[Init] best rec loss: 0.826335608959198 for ['[CLS]ave recorded head [SEP]']
[Init] best rec loss: 0.753989040851593 for ['[CLS] boss back michigan [SEP]']
[Init] best rec loss: 0.7457810044288635 for ['[CLS] pseudonym mill joyah [SEP]']
[Init] best rec loss: 0.728053867816925 for ['[CLS] mary scott pending [SEP]']
[Init] best perm rec loss: 0.7271443605422974 for ['[CLS] scott mary pending [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.359 (perp=9.713, rec=0.370, cos=0.046), tot_loss_proj:2.772 [t=0.17s]
prediction: ['[CLS] met had. [SEP]']
[ 100/2000] tot_loss=1.691 (perp=7.451, rec=0.174, cos=0.027), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 150/2000] tot_loss=1.620 (perp=7.451, rec=0.108, cos=0.022), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 200/2000] tot_loss=1.602 (perp=7.451, rec=0.091, cos=0.021), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.593 (perp=7.451, rec=0.082, cos=0.021), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 300/2000] tot_loss=1.580 (perp=7.451, rec=0.070, cos=0.020), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.573 (perp=7.451, rec=0.062, cos=0.020), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.574 (perp=7.451, rec=0.064, cos=0.020), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 450/2000] tot_loss=1.573 (perp=7.451, rec=0.062, cos=0.020), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.573 (perp=7.451, rec=0.063, cos=0.020), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.579 (perp=7.451, rec=0.068, cos=0.020), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 600/2000] tot_loss=1.576 (perp=7.451, rec=0.065, cos=0.020), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.582 (perp=7.451, rec=0.071, cos=0.020), tot_loss_proj:1.606 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.572 (perp=7.451, rec=0.061, cos=0.021), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 750/2000] tot_loss=1.574 (perp=7.451, rec=0.063, cos=0.021), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.579 (perp=7.451, rec=0.068, cos=0.021), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.567 (perp=7.451, rec=0.056, cos=0.021), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 900/2000] tot_loss=1.577 (perp=7.451, rec=0.066, cos=0.021), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.569 (perp=7.451, rec=0.059, cos=0.021), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.565 (perp=7.451, rec=0.054, cos=0.021), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1050/2000] tot_loss=1.570 (perp=7.451, rec=0.059, cos=0.021), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.578 (perp=7.451, rec=0.067, cos=0.021), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.575 (perp=7.451, rec=0.064, cos=0.021), tot_loss_proj:1.606 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1200/2000] tot_loss=1.567 (perp=7.451, rec=0.056, cos=0.021), tot_loss_proj:1.606 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.571 (perp=7.451, rec=0.060, cos=0.021), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.566 (perp=7.451, rec=0.055, cos=0.021), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1350/2000] tot_loss=1.569 (perp=7.451, rec=0.058, cos=0.021), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.568 (perp=7.451, rec=0.058, cos=0.021), tot_loss_proj:1.606 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.570 (perp=7.451, rec=0.059, cos=0.021), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1500/2000] tot_loss=1.563 (perp=7.451, rec=0.052, cos=0.021), tot_loss_proj:1.602 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.580 (perp=7.451, rec=0.070, cos=0.021), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.558 (perp=7.451, rec=0.047, cos=0.021), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1650/2000] tot_loss=1.570 (perp=7.451, rec=0.060, cos=0.021), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.562 (perp=7.451, rec=0.051, cos=0.021), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.571 (perp=7.451, rec=0.060, cos=0.021), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1800/2000] tot_loss=1.569 (perp=7.451, rec=0.058, cos=0.021), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.574 (perp=7.451, rec=0.063, cos=0.021), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.572 (perp=7.451, rec=0.061, cos=0.021), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1950/2000] tot_loss=1.572 (perp=7.451, rec=0.062, cos=0.021), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.574 (perp=7.451, rec=0.064, cos=0.021), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] brenda met. [SEP]
========================
predicted: 
========================
[CLS] brenda met. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.298 | p: 80.745 | r: 82.139
rouge2     | fm: 41.617 | p: 41.026 | r: 42.281
rougeL     | fm: 69.440 | p: 68.979 | r: 70.147
rougeLsum  | fm: 69.342 | p: 68.907 | r: 70.030
r1fm+r2fm = 122.915

input #95 time: 0:06:44 | total time: 11:09:54


Running input #96 of 100.
reference: 
========================
Today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might.
========================
Sample: 0 2.303266201677062e-12 0.052969411625028634 0.35916322
average of cosine similarity 0.9890650469469622
highest_index [0]
highest [0.9890650469469622]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  2651,  2045,  2003,  2210,  2030,  2053,  2880, 16011,  1997,
         11690,  2015,  1998,  5637,  2015,  2011,  1996,  2120,  2231,  1010,
          2348,  8392,  6867,  2453,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]']
[Init] best rec loss: 0.9376290440559387 for ['[CLS] typeilised exiary radha legislative spotlight latter jesse wonder passing opened church charm dropping santa authorities loan youth firm regarding 1930s border kirk [SEP]']
[Init] best rec loss: 0.930988609790802 for ['[CLS] library could quicknco quicklylerrradoum prose biology over spencer dirty? ebony room ltd laugh fiber 」 berlin twinned joe lucas [SEP]']
[Init] best rec loss: 0.9283707141876221 for ['[CLS] including viifactory spot mom avatar terms sikhcentric brandч hilton policemen hiding similarity extension press starring hold by upon were flood duc [SEP]']
[Init] best rec loss: 0.926461398601532 for ['[CLS]ed prepared aloud much directions department kendra wearing imperialism being software idea dyer bet and warner mu 30 bud prem happened operations napoleon silence [SEP]']
[Init] best rec loss: 0.9054527878761292 for ['[CLS] period roster assured disc guess proved au column three kapoor caesar regretphyator sometimes radical patel strait below recognition lori apparatus christiangration [SEP]']
[Init] best rec loss: 0.8999266624450684 for ['[CLS] radio ontogoing ammunition sleep sea invitation or abroad turkey stoneuringuidacious if lexington altar quality plus sum shower license o handy [SEP]']
[Init] best perm rec loss: 0.8994612097740173 for ['[CLS] plusacious if ouid or ammunition stone sleep invitation abroad altar radio license sea sumuring showergoing quality handy onto lexington turkey [SEP]']
[Init] best perm rec loss: 0.8985669016838074 for ['[CLS] sum lexingtonuid stone abroad plusgoing o or turkey invitationacious onto seauring sleep license shower if radio handy altar quality ammunition [SEP]']
[Init] best perm rec loss: 0.898284375667572 for ['[CLS] onto turkey or altar shower invitation abroad lexington qualityuid if stone ammunition ouring seagoingacious handy sleep plus sum license radio [SEP]']
[Init] best perm rec loss: 0.8974266052246094 for ['[CLS]going ontouringuid invitation sleep quality or sea if altar sum radio stone lexington turkey license ammunition o plus shower abroad handyacious [SEP]']
[Init] best perm rec loss: 0.8958510160446167 for ['[CLS] lexingtonuringuidacious stone sleep ammunition ifgoing license invitation radio shower sum onto abroad turkey o altar plus handy quality sea or [SEP]']
[Init] best perm rec loss: 0.8948376178741455 for ['[CLS]uring turkey onto lexington plus qualityuid if license altar sea handy stone ogoing sum or sleep radio abroad invitation shower ammunitionacious [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.126 (perp=12.091, rec=0.565, cos=0.142), tot_loss_proj:4.321 [t=0.17s]
prediction: ['[CLS]men ↓ follow al abolished homosexuality today named witches or national via have.breakers sum armyological welfare broadcast culture must off gardens [SEP]']
[ 100/2000] tot_loss=3.066 (perp=13.031, rec=0.380, cos=0.080), tot_loss_proj:4.474 [t=0.18s]
prediction: ['[CLS]men swimming want al information homosexuality today gay homosexuality a national tomorrow poem turkic harassment typically royal as galleryp cultural fine protect die [SEP]']
[ 150/2000] tot_loss=2.499 (perp=10.926, rec=0.275, cos=0.039), tot_loss_proj:4.066 [t=0.17s]
prediction: ['[CLS] mine swimming. al understand gay today gay lesbian or national today poem powerful harassment excess government national governmentp )ing protecting china [SEP]']
[ 200/2000] tot_loss=2.436 (perp=10.872, rec=0.234, cos=0.028), tot_loss_proj:4.002 [t=0.17s]
prediction: ['[CLS] tourists interview thinks no exhaust lesbian today gay lesbian or national today policy powerful harassment excess autonomous national governmentp )s protective government [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.452 (perp=11.033, rec=0.219, cos=0.026), tot_loss_proj:4.067 [t=0.17s]
prediction: ['[CLS]ckle interview need no gay lesbian although lesbian today or national today policy definitely harassment occasionally autonomous national governmentbs entertainments defense government [SEP]']
[ 300/2000] tot_loss=2.338 (perp=10.646, rec=0.184, cos=0.024), tot_loss_proj:3.928 [t=0.18s]
prediction: ['[CLS]rily there harassment no gay lesbian although lesbian today or national today nu definitely harassment crosses autonomous national governmentbs officialsanian government [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.168 (perp=9.675, rec=0.201, cos=0.032), tot_loss_proj:3.752 [t=0.18s]
prediction: ['[CLS]rily there harassment no gay lesbian although definitely today or national today why lesbian harassment crosses autonomous national government. officialsanian government [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.031 (perp=9.243, rec=0.160, cos=0.023), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS]rily there harassment no lesbian although official gay today or national today why lesbian harassment crosses autonomous national government. officials [SEP] government [SEP]']
[ 450/2000] tot_loss=1.891 (perp=8.578, rec=0.153, cos=0.022), tot_loss_proj:3.557 [t=0.17s]
prediction: ['[CLS]rily there harassment no lesbian although official gay today or national today why lesbian harassment crosses autonomous national government. officials and government [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.855 (perp=8.430, rec=0.148, cos=0.021), tot_loss_proj:3.537 [t=0.17s]
prediction: ['[CLS] harassment thererily no lesbian although official gay today or national today why lesbian harassment crosses autonomous national government. officials and government [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.596 (perp=8.600, rec=0.661, cos=0.215), tot_loss_proj:3.640 [t=0.17s]
prediction: ['[CLS] harassment thererily no lesbian although official female today or national today explicitly lesbian harassment occasionally autonomous national governmentp officials,. [SEP]']
[ 600/2000] tot_loss=2.459 (perp=10.293, rec=0.333, cos=0.067), tot_loss_proj:3.867 [t=0.18s]
prediction: ['[CLS] harassment theretage little lesbian prevent official female today intobound today hence lesbian representatives occasionally autonomous national governmentp officials,. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.317 (perp=9.894, rec=0.290, cos=0.048), tot_loss_proj:3.834 [t=0.18s]
prediction: ['[CLS] harassment theretage little today prevent official female lesbian intobound today hence lesbian representatives occasionally autonomous national governmentious officials and. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.241 (perp=9.742, rec=0.257, cos=0.036), tot_loss_proj:3.778 [t=0.17s]
prediction: ['[CLS] harassment theretage little today prevent underbound lesbian into lesbian today hence lesbian representatives occasionally autonomous national governmentious officials and. [SEP]']
[ 750/2000] tot_loss=2.265 (perp=10.004, rec=0.232, cos=0.032), tot_loss_proj:3.822 [t=0.18s]
prediction: ['[CLS] harassment theretage little today prevent underbound lesbian into lesbian today presumably lesbian representatives occasionally autonomous national governmentious officials and. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.228 (perp=9.879, rec=0.223, cos=0.030), tot_loss_proj:3.810 [t=0.17s]
prediction: ['[CLS] harassment theretage little today prevent underbound lesbian into lesbian hence lesbian representatives today occasionally autonomous national governmentious officials and. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.079 (perp=9.083, rec=0.230, cos=0.033), tot_loss_proj:3.679 [t=0.17s]
prediction: ['[CLS] harassment theretage little today of underbound lesbian into lesbian. lesbian governments today occasionally autonomous national governmentious officials and hence [SEP]']
[ 900/2000] tot_loss=2.058 (perp=9.083, rec=0.214, cos=0.027), tot_loss_proj:3.678 [t=0.18s]
prediction: ['[CLS] harassment theretage little today of underbound lesbian into lesbian. lesbian governments today occasionally autonomous national governmentious officials and hence [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.032 (perp=9.004, rec=0.205, cos=0.026), tot_loss_proj:3.638 [t=0.18s]
prediction: ['[CLS] governments theretage little today of underbound lesbian into lesbian. lesbian harassment today occasionally autonomous national governmentious officials and hence [SEP]']
Attempt swap
[1000/2000] tot_loss=2.018 (perp=9.004, rec=0.191, cos=0.026), tot_loss_proj:3.638 [t=0.18s]
prediction: ['[CLS] governments theretage little today of underbound lesbian into lesbian. lesbian harassment today occasionally autonomous national governmentious officials and hence [SEP]']
[1050/2000] tot_loss=2.015 (perp=9.004, rec=0.189, cos=0.025), tot_loss_proj:3.641 [t=0.17s]
prediction: ['[CLS] governments theretage little today of underbound lesbian into lesbian. lesbian harassment today occasionally autonomous national governmentious officials and hence [SEP]']
Attempt swap
[1100/2000] tot_loss=2.033 (perp=9.078, rec=0.193, cos=0.025), tot_loss_proj:3.657 [t=0.18s]
prediction: ['[CLS] governments theretage little today of officialbound lesbian into lesbian. lesbian harassment today occasionally autonomous national governmentious officials and hence [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.091 (perp=9.418, rec=0.183, cos=0.025), tot_loss_proj:3.734 [t=0.17s]
prediction: ['[CLS] governments theretage little today of officialbound lesbian into lesbian. lesbian harassmentwar occasionally autonomous national government officials andious hence [SEP]']
[1200/2000] tot_loss=2.093 (perp=9.418, rec=0.185, cos=0.024), tot_loss_proj:3.734 [t=0.18s]
prediction: ['[CLS] governments theretage little today of officialbound lesbian into lesbian. lesbian harassmentwar occasionally autonomous national government officials andious hence [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.057 (perp=9.244, rec=0.185, cos=0.023), tot_loss_proj:3.703 [t=0.17s]
prediction: ['[CLS] governments theretage little today of officialbound lesbian into lesbian. lesbian harassmentwar occasionally autonomous national government officials and henceious [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.006 (perp=8.983, rec=0.186, cos=0.024), tot_loss_proj:3.652 [t=0.18s]
prediction: ['[CLS] governments theretage little today of official lesbianbound into lesbian. lesbian harassmentwar occasionally autonomous national government officials and henceious [SEP]']
[1350/2000] tot_loss=2.044 (perp=9.206, rec=0.180, cos=0.023), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] governments theretage little today of official lesbianbound within lesbian. lesbian harassmentwar occasionally autonomous national government officials and henceious [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.017 (perp=9.051, rec=0.183, cos=0.024), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] governments theretage little today of official lesbianbound within lesbian. lesbianwar harassment occasionally autonomous national government officials and henceious [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.986 (perp=8.906, rec=0.179, cos=0.026), tot_loss_proj:3.590 [t=0.18s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
[1500/2000] tot_loss=1.976 (perp=8.906, rec=0.170, cos=0.025), tot_loss_proj:3.596 [t=0.18s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
Attempt swap
[1550/2000] tot_loss=1.973 (perp=8.906, rec=0.167, cos=0.024), tot_loss_proj:3.587 [t=0.17s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
Attempt swap
[1600/2000] tot_loss=1.981 (perp=8.906, rec=0.176, cos=0.024), tot_loss_proj:3.593 [t=0.17s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
[1650/2000] tot_loss=1.981 (perp=8.906, rec=0.177, cos=0.023), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
Attempt swap
[1700/2000] tot_loss=1.979 (perp=8.906, rec=0.175, cos=0.023), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
Attempt swap
[1750/2000] tot_loss=1.973 (perp=8.906, rec=0.169, cos=0.023), tot_loss_proj:3.590 [t=0.18s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
[1800/2000] tot_loss=1.979 (perp=8.906, rec=0.174, cos=0.023), tot_loss_proj:3.593 [t=0.17s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
Attempt swap
[1850/2000] tot_loss=1.974 (perp=8.906, rec=0.170, cos=0.023), tot_loss_proj:3.595 [t=0.18s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
Attempt swap
[1900/2000] tot_loss=1.974 (perp=8.906, rec=0.170, cos=0.023), tot_loss_proj:3.592 [t=0.18s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
[1950/2000] tot_loss=1.984 (perp=8.906, rec=0.180, cos=0.023), tot_loss_proj:3.588 [t=0.17s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
Attempt swap
[2000/2000] tot_loss=1.974 (perp=8.906, rec=0.170, cos=0.023), tot_loss_proj:3.591 [t=0.17s]
prediction: ['[CLS] governments theretage little today nothing official lesbian harassment within lesbian. lesbianwarbound occasionally autonomous national government officials and henceious [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]
========================
predicted: 
========================
[CLS] harassment thererily no lesbian although official gay today or national today why lesbian harassment crosses autonomous national government. officials and government [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.333 | p: 52.174 | r: 54.545
rouge2     | fm: 4.651 | p: 4.545 | r: 4.762
rougeL     | fm: 31.111 | p: 30.435 | r: 31.818
rougeLsum  | fm: 31.111 | p: 30.435 | r: 31.818
r1fm+r2fm = 57.984

[Aggregate metrics]:
rouge1     | fm: 81.002 | p: 80.485 | r: 81.879
rouge2     | fm: 41.208 | p: 40.633 | r: 41.858
rougeL     | fm: 69.042 | p: 68.584 | r: 69.689
rougeLsum  | fm: 68.917 | p: 68.468 | r: 69.670
r1fm+r2fm = 122.209

input #96 time: 0:07:16 | total time: 11:17:11


Running input #97 of 100.
reference: 
========================
This oven cooks well.
========================
Sample: 0 3.1618753061681913e-12 0.04745953587409392 0.3642931
average of cosine similarity 0.9914774623430151
highest_index [0]
highest [0.9914774623430151]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2023, 17428, 26929,  2092,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] this oven cooks well. [SEP]']
[Init] best rec loss: 1.0609800815582275 for ['[CLS] representing savedm ft dynasty [SEP]']
[Init] best rec loss: 1.0057979822158813 for ['[CLS] diagnosed timothy besides jump lab [SEP]']
[Init] best rec loss: 0.9389415383338928 for ['[CLS]gence charity g rain plain [SEP]']
[Init] best rec loss: 0.9305325150489807 for ['[CLS] tre river wil chamberlain donkey [SEP]']
[Init] best rec loss: 0.9199353456497192 for ['[CLS] emotional lara renewed [CLS] ve [SEP]']
[Init] best rec loss: 0.9128320813179016 for ['[CLS] alive sas mass fall why [SEP]']
[Init] best rec loss: 0.8864938020706177 for ['[CLS] led pure simulations lester junior [SEP]']
[Init] best rec loss: 0.8652690052986145 for ['[CLS] gael gearbox deserve enough air [SEP]']
[Init] best perm rec loss: 0.8601428866386414 for ['[CLS] gearbox enough deserve air gael [SEP]']
[Init] best perm rec loss: 0.8588325381278992 for ['[CLS] enough gearbox air gael deserve [SEP]']
[Init] best perm rec loss: 0.8585264682769775 for ['[CLS] enough deserve air gael gearbox [SEP]']
[Init] best perm rec loss: 0.8566455841064453 for ['[CLS] air deserve gael gearbox enough [SEP]']
[Init] best perm rec loss: 0.8556789755821228 for ['[CLS] gael air deserve gearbox enough [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.589 (perp=14.564, rec=0.686, cos=0.991), tot_loss_proj:4.767 [t=0.17s]
prediction: ['[CLS]my australian looks ) stems [SEP]']
[ 100/2000] tot_loss=3.172 (perp=8.358, rec=0.522, cos=0.978), tot_loss_proj:3.608 [t=0.17s]
prediction: ['[CLS] oven oven looks ). [SEP]']
[ 150/2000] tot_loss=2.901 (perp=7.372, rec=0.482, cos=0.945), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] oven oven oven ). [SEP]']
[ 200/2000] tot_loss=3.175 (perp=8.959, rec=0.444, cos=0.939), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] oven oven oven greasy. [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.884 (perp=7.521, rec=0.438, cos=0.942), tot_loss_proj:3.522 [t=0.17s]
prediction: ['[CLS] oven oven oven.. [SEP]']
[ 300/2000] tot_loss=2.948 (perp=7.902, rec=0.427, cos=0.941), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] cooks oven oven.. [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.969 (perp=8.099, rec=0.405, cos=0.945), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] cooks oven cooked.. [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.379 (perp=10.598, rec=0.376, cos=0.884), tot_loss_proj:3.920 [t=0.17s]
prediction: ['[CLS] cooks oven cooked. justice [SEP]']
[ 450/2000] tot_loss=3.420 (perp=10.598, rec=0.392, cos=0.909), tot_loss_proj:3.924 [t=0.17s]
prediction: ['[CLS] cooks oven cooked. justice [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.430 (perp=10.946, rec=0.377, cos=0.863), tot_loss_proj:4.000 [t=0.17s]
prediction: ['[CLS] cooks oven comes. justice [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.426 (perp=10.946, rec=0.369, cos=0.868), tot_loss_proj:3.994 [t=0.17s]
prediction: ['[CLS] cooks oven comes. justice [SEP]']
[ 600/2000] tot_loss=3.536 (perp=11.553, rec=0.376, cos=0.850), tot_loss_proj:4.057 [t=0.17s]
prediction: ['[CLS] cooks oven comes.xide [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.507 (perp=11.553, rec=0.361, cos=0.836), tot_loss_proj:4.056 [t=0.17s]
prediction: ['[CLS] cooks oven comes.xide [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.502 (perp=11.553, rec=0.363, cos=0.828), tot_loss_proj:4.056 [t=0.17s]
prediction: ['[CLS] cooks oven comes.xide [SEP]']
[ 750/2000] tot_loss=3.400 (perp=11.128, rec=0.350, cos=0.825), tot_loss_proj:4.000 [t=0.17s]
prediction: ['[CLS] cooks oven comes. easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.400 (perp=11.128, rec=0.351, cos=0.823), tot_loss_proj:4.002 [t=0.17s]
prediction: ['[CLS] cooks oven comes. easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.441 (perp=11.415, rec=0.344, cos=0.814), tot_loss_proj:4.098 [t=0.17s]
prediction: ['[CLS] cooks oven nowadays. easily [SEP]']
[ 900/2000] tot_loss=3.483 (perp=11.415, rec=0.362, cos=0.838), tot_loss_proj:4.091 [t=0.17s]
prediction: ['[CLS] cooks oven nowadays. easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.301 (perp=10.718, rec=0.356, cos=0.802), tot_loss_proj:3.917 [t=0.17s]
prediction: ['[CLS] cooks oven well. easily [SEP]']
Attempt swap
[1000/2000] tot_loss=3.299 (perp=10.718, rec=0.363, cos=0.793), tot_loss_proj:3.925 [t=0.17s]
prediction: ['[CLS] cooks oven well. easily [SEP]']
[1050/2000] tot_loss=3.278 (perp=10.718, rec=0.349, cos=0.786), tot_loss_proj:3.923 [t=0.17s]
prediction: ['[CLS] cooks oven well. easily [SEP]']
Attempt swap
[1100/2000] tot_loss=3.342 (perp=11.040, rec=0.350, cos=0.784), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
Attempt swap
[1150/2000] tot_loss=3.334 (perp=11.040, rec=0.354, cos=0.772), tot_loss_proj:4.037 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
[1200/2000] tot_loss=3.317 (perp=11.040, rec=0.345, cos=0.764), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
Attempt swap
[1250/2000] tot_loss=3.313 (perp=11.040, rec=0.346, cos=0.759), tot_loss_proj:4.036 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
Attempt swap
[1300/2000] tot_loss=3.303 (perp=11.040, rec=0.344, cos=0.752), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
[1350/2000] tot_loss=3.302 (perp=11.040, rec=0.349, cos=0.745), tot_loss_proj:4.033 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
Attempt swap
[1400/2000] tot_loss=3.301 (perp=11.040, rec=0.352, cos=0.742), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
Attempt swap
[1450/2000] tot_loss=3.289 (perp=11.040, rec=0.344, cos=0.736), tot_loss_proj:4.034 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
[1500/2000] tot_loss=3.291 (perp=11.040, rec=0.351, cos=0.732), tot_loss_proj:4.035 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
Attempt swap
[1550/2000] tot_loss=3.273 (perp=11.040, rec=0.339, cos=0.727), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
Attempt swap
[1600/2000] tot_loss=3.275 (perp=11.040, rec=0.344, cos=0.723), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] cooks oven well.oint [SEP]']
[1650/2000] tot_loss=3.358 (perp=11.473, rec=0.345, cos=0.719), tot_loss_proj:4.146 [t=0.17s]
prediction: ['[CLS] cooks oven wellreoint [SEP]']
Attempt swap
[1700/2000] tot_loss=3.350 (perp=11.473, rec=0.341, cos=0.715), tot_loss_proj:4.149 [t=0.17s]
prediction: ['[CLS] cooks oven wellreoint [SEP]']
Attempt swap
[1750/2000] tot_loss=3.355 (perp=11.473, rec=0.350, cos=0.711), tot_loss_proj:4.148 [t=0.17s]
prediction: ['[CLS] cooks oven wellreoint [SEP]']
[1800/2000] tot_loss=3.351 (perp=11.473, rec=0.350, cos=0.707), tot_loss_proj:4.147 [t=0.17s]
prediction: ['[CLS] cooks oven wellreoint [SEP]']
Attempt swap
[1850/2000] tot_loss=3.342 (perp=11.473, rec=0.344, cos=0.703), tot_loss_proj:4.143 [t=0.17s]
prediction: ['[CLS] cooks oven wellreoint [SEP]']
Attempt swap
[1900/2000] tot_loss=3.338 (perp=11.473, rec=0.345, cos=0.699), tot_loss_proj:4.147 [t=0.17s]
prediction: ['[CLS] cooks oven wellreoint [SEP]']
[1950/2000] tot_loss=3.343 (perp=11.473, rec=0.351, cos=0.698), tot_loss_proj:4.147 [t=0.17s]
prediction: ['[CLS] cooks oven wellreoint [SEP]']
Attempt swap
[2000/2000] tot_loss=3.327 (perp=11.473, rec=0.338, cos=0.695), tot_loss_proj:4.147 [t=0.17s]
prediction: ['[CLS] cooks oven wellreoint [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] this oven cooks well. [SEP]
========================
predicted: 
========================
[CLS] cooks oven well.oint [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 83.333

[Aggregate metrics]:
rouge1     | fm: 80.972 | p: 80.434 | r: 81.791
rouge2     | fm: 40.668 | p: 40.164 | r: 41.298
rougeL     | fm: 68.990 | p: 68.552 | r: 69.690
rougeLsum  | fm: 68.916 | p: 68.510 | r: 69.588
r1fm+r2fm = 121.640

input #97 time: 0:06:59 | total time: 11:24:10


Running input #98 of 100.
reference: 
========================
Sarah devoured the cakes in the kitchen last night.
========================
Sample: 0 2.987125958451841e-12 0.04551204378365032 0.33133113
average of cosine similarity 0.9905210080048596
highest_index [0]
highest [0.9905210080048596]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  4532, 16475, 16777,  1996, 22619,  1999,  1996,  3829,  2197,
          2305,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sarah devoured the cakes in the kitchen last night. [SEP]']
[Init] best rec loss: 0.9987524151802063 for ['[CLS] socialced coordination umbrella louder require paper plank parallel hi dame [SEP]']
[Init] best rec loss: 0.9721340537071228 for ['[CLS]mission instruments overnton _ revenge touch cole palettescent die [SEP]']
[Init] best rec loss: 0.9537109732627869 for ['[CLS] agreed cold indexed clip troops crazy basic methodology low mai burns [SEP]']
[Init] best rec loss: 0.9328851103782654 for ['[CLS] excited hadley coverage theatreere schoolhouse then scored point carpenter nature [SEP]']
[Init] best perm rec loss: 0.932117760181427 for ['[CLS] point schoolhouse theatre scored hadleyere nature excited carpenter then coverage [SEP]']
[Init] best perm rec loss: 0.9296472668647766 for ['[CLS] schoolhouse excited carpenterere hadley theatre coverage nature scored point then [SEP]']
[Init] best perm rec loss: 0.9284753203392029 for ['[CLS]ere excited nature carpenter scored theatre then hadley schoolhouse point coverage [SEP]']
[Init] best perm rec loss: 0.9283377528190613 for ['[CLS] carpenter hadley theatre coverage then excited scored natureere point schoolhouse [SEP]']
[Init] best perm rec loss: 0.9256162047386169 for ['[CLS] nature coverageere excited theatre schoolhouse then hadley scored point carpenter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.468 (perp=10.033, rec=0.392, cos=0.069), tot_loss_proj:3.790 [t=0.17s]
prediction: ['[CLS] now ago definitely killed the social sarah return really stella then [SEP]']
[ 100/2000] tot_loss=2.556 (perp=11.689, rec=0.187, cos=0.031), tot_loss_proj:4.185 [t=0.17s]
prediction: ['[CLS]! sarah thoroughlyoured cakes kitchen sarah tomorrow in cakes last [SEP]']
[ 150/2000] tot_loss=2.241 (perp=10.396, rec=0.136, cos=0.027), tot_loss_proj:3.923 [t=0.17s]
prediction: ['[CLS]! sarah devoured cakes kitchen sarah last in cakes last [SEP]']
[ 200/2000] tot_loss=2.202 (perp=10.345, rec=0.108, cos=0.025), tot_loss_proj:4.021 [t=0.17s]
prediction: ['[CLS]! sarah devoured cakes kitchen sarah night in cakes last [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.188 (perp=9.938, rec=0.171, cos=0.030), tot_loss_proj:3.755 [t=0.17s]
prediction: ['[CLS] weeks devoured cakes kitchen. sarahergy in night last [SEP]']
[ 300/2000] tot_loss=1.963 (perp=9.182, rec=0.104, cos=0.023), tot_loss_proj:3.586 [t=0.17s]
prediction: ['[CLS] now devoured cakes kitchen. sarah smell in night last [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.851 (perp=8.602, rec=0.108, cos=0.022), tot_loss_proj:3.457 [t=0.17s]
prediction: ['[CLS] now devoured cakes kitchen last sarah mind in night. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.651 (perp=7.619, rec=0.107, cos=0.021), tot_loss_proj:3.279 [t=0.17s]
prediction: ['[CLS] now devoured cakes kitchen in sarah close last night. [SEP]']
[ 450/2000] tot_loss=1.678 (perp=7.818, rec=0.094, cos=0.020), tot_loss_proj:3.317 [t=0.17s]
prediction: ['[CLS] now devoured cakes kitchen in sarah mind last night. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.615 (perp=7.538, rec=0.087, cos=0.020), tot_loss_proj:3.279 [t=0.17s]
prediction: ['[CLS] now devoured cakes kitchen in door sarah last night. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.511 (perp=7.034, rec=0.084, cos=0.020), tot_loss_proj:3.157 [t=0.17s]
prediction: ['[CLS] now devoured cakes in kitchen door sarah last night. [SEP]']
[ 600/2000] tot_loss=1.508 (perp=7.034, rec=0.081, cos=0.020), tot_loss_proj:3.157 [t=0.17s]
prediction: ['[CLS] now devoured cakes in kitchen door sarah last night. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.560 (perp=7.301, rec=0.081, cos=0.020), tot_loss_proj:3.307 [t=0.17s]
prediction: ['[CLS], devoured cakes in kitchen door sarah last night. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.463 (perp=6.793, rec=0.085, cos=0.020), tot_loss_proj:3.227 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
[ 750/2000] tot_loss=1.465 (perp=6.793, rec=0.087, cos=0.019), tot_loss_proj:3.226 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.452 (perp=6.793, rec=0.074, cos=0.019), tot_loss_proj:3.224 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.461 (perp=6.793, rec=0.083, cos=0.019), tot_loss_proj:3.219 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
[ 900/2000] tot_loss=1.454 (perp=6.793, rec=0.076, cos=0.019), tot_loss_proj:3.223 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.463 (perp=6.793, rec=0.085, cos=0.019), tot_loss_proj:3.221 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.455 (perp=6.793, rec=0.077, cos=0.019), tot_loss_proj:3.226 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
[1050/2000] tot_loss=1.459 (perp=6.793, rec=0.081, cos=0.019), tot_loss_proj:3.223 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.459 (perp=6.793, rec=0.081, cos=0.019), tot_loss_proj:3.221 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.449 (perp=6.793, rec=0.071, cos=0.019), tot_loss_proj:3.221 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
[1200/2000] tot_loss=1.459 (perp=6.793, rec=0.081, cos=0.019), tot_loss_proj:3.222 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.449 (perp=6.793, rec=0.071, cos=0.019), tot_loss_proj:3.223 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.461 (perp=6.793, rec=0.083, cos=0.019), tot_loss_proj:3.222 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
[1350/2000] tot_loss=1.468 (perp=6.793, rec=0.090, cos=0.019), tot_loss_proj:3.221 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.463 (perp=6.793, rec=0.086, cos=0.019), tot_loss_proj:3.219 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.460 (perp=6.793, rec=0.083, cos=0.019), tot_loss_proj:3.220 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
[1500/2000] tot_loss=1.454 (perp=6.793, rec=0.077, cos=0.019), tot_loss_proj:3.222 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.461 (perp=6.793, rec=0.083, cos=0.019), tot_loss_proj:3.216 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.465 (perp=6.793, rec=0.087, cos=0.019), tot_loss_proj:3.221 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
[1650/2000] tot_loss=1.462 (perp=6.793, rec=0.084, cos=0.019), tot_loss_proj:3.222 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.456 (perp=6.793, rec=0.078, cos=0.019), tot_loss_proj:3.221 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.456 (perp=6.793, rec=0.078, cos=0.019), tot_loss_proj:3.216 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
[1800/2000] tot_loss=1.458 (perp=6.793, rec=0.080, cos=0.019), tot_loss_proj:3.218 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.458 (perp=6.793, rec=0.080, cos=0.019), tot_loss_proj:3.217 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.460 (perp=6.793, rec=0.082, cos=0.019), tot_loss_proj:3.222 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
[1950/2000] tot_loss=1.458 (perp=6.793, rec=0.080, cos=0.019), tot_loss_proj:3.220 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.467 (perp=6.793, rec=0.090, cos=0.019), tot_loss_proj:3.220 [t=0.17s]
prediction: ['[CLS] door, devoured cakes in kitchen sarah last night. [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] sarah devoured the cakes in the kitchen last night. [SEP]
========================
predicted: 
========================
[CLS] door, devoured cakes in kitchen sarah last night. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 90.000 | r: 81.818
rouge2     | fm: 31.579 | p: 33.333 | r: 30.000
rougeL     | fm: 76.190 | p: 80.000 | r: 72.727
rougeLsum  | fm: 76.190 | p: 80.000 | r: 72.727
r1fm+r2fm = 117.293

[Aggregate metrics]:
rouge1     | fm: 81.064 | p: 80.582 | r: 81.791
rouge2     | fm: 40.655 | p: 40.155 | r: 41.306
rougeL     | fm: 69.100 | p: 68.713 | r: 69.734
rougeLsum  | fm: 69.016 | p: 68.581 | r: 69.649
r1fm+r2fm = 121.719

input #98 time: 0:06:58 | total time: 11:31:09


Running input #99 of 100.
reference: 
========================
The box contains the ball.
========================
Sample: 0 1.2547540680955125e-12 0.04862834661919888 0.33270139
average of cosine similarity 0.9892606866430219
highest_index [0]
highest [0.9892606866430219]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 1996, 3482, 3397, 1996, 3608, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the box contains the ball. [SEP]']
[Init] best rec loss: 0.9730719327926636 for ['[CLS] point bono dry position nothing using [SEP]']
[Init] best rec loss: 0.9256172180175781 for ['[CLS] tense childhood port oman mo earl [SEP]']
[Init] best rec loss: 0.9026228785514832 for ['[CLS] storage theatergraphic scholarships africa minorities [SEP]']
[Init] best rec loss: 0.9006547927856445 for ['[CLS] quoien hang town purse savings [SEP]']
[Init] best rec loss: 0.897529661655426 for ['[CLS] especiallylink but merchantywood rapid [SEP]']
[Init] best rec loss: 0.8682069182395935 for ['[CLS] [MASK] tennis reacherェ one note [SEP]']
[Init] best rec loss: 0.8641061186790466 for ['[CLS] returned raphael2 dragon sato deco [SEP]']
[Init] best perm rec loss: 0.8624070286750793 for ['[CLS]2 returned deco sato raphael dragon [SEP]']
[Init] best perm rec loss: 0.8620513677597046 for ['[CLS] deco sato raphael returned2 dragon [SEP]']
[Init] best perm rec loss: 0.8598130345344543 for ['[CLS] returned sato2 deco raphael dragon [SEP]']
[Init] best perm rec loss: 0.8590118885040283 for ['[CLS] sato deco2 returned dragon raphael [SEP]']
[Init] best perm rec loss: 0.8577542901039124 for ['[CLS]2 sato deco returned dragon raphael [SEP]']
[Init] best perm rec loss: 0.8570127487182617 for ['[CLS]2 deco returned dragon raphael sato [SEP]']
[Init] best perm rec loss: 0.8554680347442627 for ['[CLS]2 sato deco dragon returned raphael [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.073 (perp=8.026, rec=0.363, cos=0.105), tot_loss_proj:3.605 [t=0.17s]
prediction: ['[CLS] where box ball box.. [SEP]']
[ 100/2000] tot_loss=1.838 (perp=7.427, rec=0.274, cos=0.078), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] contains box ball box ball. [SEP]']
[ 150/2000] tot_loss=1.766 (perp=7.427, rec=0.225, cos=0.056), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] contains box ball box ball. [SEP]']
[ 200/2000] tot_loss=1.951 (perp=8.987, rec=0.120, cos=0.034), tot_loss_proj:3.810 [t=0.17s]
prediction: ['[CLS] contains box ball box the. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.824 (perp=8.404, rec=0.112, cos=0.032), tot_loss_proj:3.631 [t=0.17s]
prediction: ['[CLS] box box ball contains the. [SEP]']
[ 300/2000] tot_loss=1.817 (perp=8.404, rec=0.107, cos=0.029), tot_loss_proj:3.637 [t=0.17s]
prediction: ['[CLS] box box ball contains the. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.603 (perp=7.365, rec=0.101, cos=0.029), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] box box contains the ball. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.461 (perp=6.599, rec=0.109, cos=0.032), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[ 450/2000] tot_loss=1.450 (perp=6.599, rec=0.101, cos=0.029), tot_loss_proj:3.411 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.448 (perp=6.599, rec=0.098, cos=0.030), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.447 (perp=6.599, rec=0.099, cos=0.028), tot_loss_proj:3.408 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[ 600/2000] tot_loss=1.451 (perp=6.599, rec=0.102, cos=0.028), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.441 (perp=6.599, rec=0.093, cos=0.029), tot_loss_proj:3.405 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.449 (perp=6.599, rec=0.099, cos=0.029), tot_loss_proj:3.397 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[ 750/2000] tot_loss=1.437 (perp=6.599, rec=0.088, cos=0.029), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.440 (perp=6.599, rec=0.091, cos=0.029), tot_loss_proj:3.393 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.437 (perp=6.599, rec=0.089, cos=0.028), tot_loss_proj:3.390 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[ 900/2000] tot_loss=1.448 (perp=6.599, rec=0.100, cos=0.028), tot_loss_proj:3.388 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.439 (perp=6.599, rec=0.092, cos=0.028), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.439 (perp=6.599, rec=0.091, cos=0.028), tot_loss_proj:3.382 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[1050/2000] tot_loss=1.439 (perp=6.599, rec=0.092, cos=0.028), tot_loss_proj:3.375 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.440 (perp=6.599, rec=0.092, cos=0.027), tot_loss_proj:3.383 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.445 (perp=6.599, rec=0.098, cos=0.027), tot_loss_proj:3.377 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[1200/2000] tot_loss=1.433 (perp=6.599, rec=0.086, cos=0.027), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.440 (perp=6.599, rec=0.093, cos=0.027), tot_loss_proj:3.372 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.428 (perp=6.599, rec=0.082, cos=0.027), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[1350/2000] tot_loss=1.432 (perp=6.599, rec=0.085, cos=0.027), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.435 (perp=6.599, rec=0.089, cos=0.027), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.445 (perp=6.599, rec=0.099, cos=0.027), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[1500/2000] tot_loss=1.434 (perp=6.599, rec=0.088, cos=0.027), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.442 (perp=6.599, rec=0.096, cos=0.027), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.428 (perp=6.599, rec=0.081, cos=0.026), tot_loss_proj:3.366 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[1650/2000] tot_loss=1.434 (perp=6.599, rec=0.088, cos=0.026), tot_loss_proj:3.369 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.431 (perp=6.599, rec=0.085, cos=0.026), tot_loss_proj:3.364 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.426 (perp=6.599, rec=0.080, cos=0.026), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[1800/2000] tot_loss=1.436 (perp=6.599, rec=0.090, cos=0.026), tot_loss_proj:3.375 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.436 (perp=6.599, rec=0.090, cos=0.026), tot_loss_proj:3.364 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.435 (perp=6.599, rec=0.089, cos=0.026), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
[1950/2000] tot_loss=1.431 (perp=6.599, rec=0.085, cos=0.026), tot_loss_proj:3.364 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.442 (perp=6.599, rec=0.096, cos=0.026), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] box contains the box ball. [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] the box contains the ball. [SEP]
========================
predicted: 
========================
[CLS] box contains the box ball. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 152.381

[Aggregate metrics]:
rouge1     | fm: 81.078 | p: 80.582 | r: 81.827
rouge2     | fm: 40.918 | p: 40.450 | r: 41.530
rougeL     | fm: 69.228 | p: 68.844 | r: 69.897
rougeLsum  | fm: 69.214 | p: 68.792 | r: 69.849
r1fm+r2fm = 121.996

input #99 time: 0:07:08 | total time: 11:38:17


Average Cosine Similarity: 0.9895987743380812
Done with all.
