


Command: attack4.py --dataset cola --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola --n_steps 2000 --coeff_pooler_match 0.05 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 772.81it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
Harriet alternated folk songs and pop songs together.
========================
average of cosine similarity 0.9993562480586127
highest_index [0]
highest [0.9993562480586127]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 14207,  6585,  2094,  5154,  2774,  1998,  3769,  2774,  2362,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] harriet alternated folk songs and pop songs together. [SEP]']
[Init] best rec loss: 0.9993575811386108 for ['[CLS] study showing exchange victorywall same bryant compulsory cl regiments [SEP]']
[Init] best rec loss: 0.881753146648407 for ['[CLS] report make baglary fell paul max rape younger broken [SEP]']
[Init] best rec loss: 0.8786035180091858 for ['[CLS] ll himself by fines now pleased whole market none cody [SEP]']
[Init] best rec loss: 0.8534309267997742 for ['[CLS] high leonard " fae nightclub awaiting write spillstadyme [SEP]']
[Init] best rec loss: 0.8307695388793945 for ['[CLS] lo hr positionperation trees temperance madonnaguard minutes vs [SEP]']
[Init] best rec loss: 0.8198035359382629 for ['[CLS] ) monitor witch market issue healing stole dia indoor lane [SEP]']
[Init] best perm rec loss: 0.8187926411628723 for ['[CLS] market dia lane issue ) stole monitor witch indoor healing [SEP]']
[Init] best perm rec loss: 0.8181319236755371 for ['[CLS] market healing ) issue witch stole monitor indoor lane dia [SEP]']
[Init] best perm rec loss: 0.8154435753822327 for ['[CLS] witch healing lane ) issue stole indoor monitor market dia [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.083 (perp=13.024, rec=0.400, cos=0.078), tot_loss_proj:4.350 [t=1.41s]
prediction: ['[CLS] whitman learning cr videos twice 1945 ′ combat spots title [SEP]']
[ 100/2000] tot_loss=2.795 (perp=11.679, rec=0.373, cos=0.086), tot_loss_proj:4.204 [t=0.18s]
prediction: ['[CLS] harriet alternate married songs,den alternate rugby harriet therefore [SEP]']
[ 150/2000] tot_loss=2.286 (perp=10.182, rec=0.236, cos=0.014), tot_loss_proj:4.021 [t=0.18s]
prediction: ['[CLS] harriet alternated songs togetherden alternate pop harriet sessions [SEP]']
[ 200/2000] tot_loss=2.806 (perp=10.709, rec=0.464, cos=0.200), tot_loss_proj:3.939 [t=0.18s]
prediction: ['[CLS] harriet alternate pop songs together harriet alternate pop harriet simultaneously [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.550 (perp=11.243, rec=0.275, cos=0.026), tot_loss_proj:4.230 [t=0.19s]
prediction: ['[CLS] harriet alternate popden alternate pop songs together harriet simultaneously [SEP]']
[ 300/2000] tot_loss=2.273 (perp=9.903, rec=0.258, cos=0.034), tot_loss_proj:3.733 [t=0.18s]
prediction: ['[CLS] harriet alternate pop harriet alternate folk songs together harriet together [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.726 (perp=7.641, rec=0.188, cos=0.010), tot_loss_proj:3.491 [t=0.18s]
prediction: ['[CLS] harriet alternate pop harriet alternate folk songs together together. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.717 (perp=7.641, rec=0.176, cos=0.012), tot_loss_proj:3.494 [t=0.18s]
prediction: ['[CLS] harriet alternate pop harriet alternate folk songs together together. [SEP]']
[ 450/2000] tot_loss=1.696 (perp=7.640, rec=0.162, cos=0.007), tot_loss_proj:3.504 [t=0.18s]
prediction: ['[CLS] harriet alternate pop. alternate folk songs together together. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.787 (perp=7.873, rec=0.197, cos=0.015), tot_loss_proj:3.178 [t=0.18s]
prediction: ['[CLS] harriet helped alternate pop alternate folk songs together together. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.657 (perp=7.357, rec=0.172, cos=0.013), tot_loss_proj:2.304 [t=0.18s]
prediction: ['[CLS] harriet helped alternate alternate pop folk songs together together. [SEP]']
[ 600/2000] tot_loss=1.900 (perp=8.654, rec=0.161, cos=0.008), tot_loss_proj:3.596 [t=0.18s]
prediction: ['[CLS] harriet harriet alternate alternate pop folk songs together together. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.828 (perp=8.186, rec=0.176, cos=0.014), tot_loss_proj:3.528 [t=0.18s]
prediction: ['[CLS] harriet harriet alternate folk folk songs together alternate together. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.777 (perp=8.089, rec=0.151, cos=0.008), tot_loss_proj:3.541 [t=0.17s]
prediction: ['[CLS] harriet harriet alternate folk folk songs alternate together together. [SEP]']
[ 750/2000] tot_loss=1.779 (perp=8.089, rec=0.154, cos=0.007), tot_loss_proj:3.542 [t=0.18s]
prediction: ['[CLS] harriet harriet alternate folk folk songs alternate together together. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.762 (perp=7.969, rec=0.162, cos=0.007), tot_loss_proj:3.478 [t=0.18s]
prediction: ['[CLS] harriet harriet alternate folk songs alternate folk together together. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.746 (perp=7.969, rec=0.146, cos=0.006), tot_loss_proj:3.487 [t=0.18s]
prediction: ['[CLS] harriet harriet alternate folk songs alternate folk together together. [SEP]']
[ 900/2000] tot_loss=1.742 (perp=7.969, rec=0.142, cos=0.006), tot_loss_proj:3.485 [t=0.18s]
prediction: ['[CLS] harriet harriet alternate folk songs alternate folk together together. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.846 (perp=8.399, rec=0.155, cos=0.011), tot_loss_proj:3.653 [t=0.18s]
prediction: ['[CLS] harrietteacher alternate folk songs together alternate folk together. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.809 (perp=8.224, rec=0.157, cos=0.007), tot_loss_proj:3.453 [t=0.18s]
prediction: ['[CLS]teacher harriet alternate folk songs together alternate folk together. [SEP]']
[1050/2000] tot_loss=1.801 (perp=8.224, rec=0.151, cos=0.006), tot_loss_proj:3.460 [t=0.18s]
prediction: ['[CLS]teacher harriet alternate folk songs together alternate folk together. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.885 (perp=8.710, rec=0.137, cos=0.005), tot_loss_proj:3.583 [t=0.18s]
prediction: ['[CLS] harriet harriet alternate pop songs together alternate folk together. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.998 (perp=9.278, rec=0.137, cos=0.006), tot_loss_proj:3.725 [t=0.18s]
prediction: ['[CLS] together harriet alternate pop songsteacher alternate folk together. [SEP]']
[1200/2000] tot_loss=1.989 (perp=9.278, rec=0.128, cos=0.005), tot_loss_proj:3.723 [t=0.18s]
prediction: ['[CLS] together harriet alternate pop songsteacher alternate folk together. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.816 (perp=8.356, rec=0.139, cos=0.006), tot_loss_proj:3.565 [t=0.18s]
prediction: ['[CLS] together alternate pop harriet songsteacher alternate folk together. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.836 (perp=8.505, rec=0.130, cos=0.005), tot_loss_proj:3.648 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songsteacher alternate folk together. [SEP]']
[1350/2000] tot_loss=1.842 (perp=8.505, rec=0.136, cos=0.005), tot_loss_proj:3.642 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songsteacher alternate folk together. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.639 (perp=7.529, rec=0.128, cos=0.005), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.633 (perp=7.529, rec=0.123, cos=0.005), tot_loss_proj:3.421 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
[1500/2000] tot_loss=1.629 (perp=7.529, rec=0.118, cos=0.005), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.639 (perp=7.529, rec=0.129, cos=0.005), tot_loss_proj:3.424 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.630 (perp=7.529, rec=0.120, cos=0.005), tot_loss_proj:3.419 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
[1650/2000] tot_loss=1.636 (perp=7.529, rec=0.126, cos=0.005), tot_loss_proj:3.420 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.630 (perp=7.529, rec=0.119, cos=0.004), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.628 (perp=7.529, rec=0.117, cos=0.004), tot_loss_proj:3.417 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
[1800/2000] tot_loss=1.634 (perp=7.529, rec=0.124, cos=0.004), tot_loss_proj:3.422 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.623 (perp=7.529, rec=0.112, cos=0.004), tot_loss_proj:3.421 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.633 (perp=7.529, rec=0.123, cos=0.004), tot_loss_proj:3.422 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
[1950/2000] tot_loss=1.626 (perp=7.529, rec=0.116, cos=0.004), tot_loss_proj:3.420 [t=0.18s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.625 (perp=7.529, rec=0.114, cos=0.004), tot_loss_proj:3.419 [t=0.27s]
prediction: ['[CLS] together alternate and harriet songs. alternate folk together. [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] harriet alternated folk songs and pop songs together. [SEP]
========================
predicted: 
========================
[CLS] together alternate and harriet songs. alternate folk together. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.000 | p: 70.000 | r: 70.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 81.111

[Aggregate metrics]:
rouge1     | fm: 70.000 | p: 70.000 | r: 70.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 81.111

input #0 time: 0:07:22 | total time: 0:07:22


Running input #1 of 100.
reference: 
========================
Who do you think that will question Seamus first?
========================
average of cosine similarity 0.9991835207453212
highest_index [0]
highest [0.9991835207453212]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2040,  2079,  2017,  2228,  2008,  2097,  3160, 24993,  2034,
          1029,   102]], device='cuda:0')
Debug: ref = ['[CLS] who do you think that will question seamus first? [SEP]']
[Init] best rec loss: 0.842589259147644 for ['[CLS] singerии middlesbrough tells certificate numbering century sung nowhere go [SEP]']
[Init] best rec loss: 0.8232784271240234 for ['[CLS] israel work rotational sights warm exclusive neither holding award jet [SEP]']
[Init] best rec loss: 0.7734784483909607 for ['[CLS] can kerr dry jack hood shownnsed powered feet [CLS] [SEP]']
[Init] best rec loss: 0.6931681632995605 for ['[CLS] because richest soc final melbourne gallo building mob might storm [SEP]']
[Init] best rec loss: 0.6918148398399353 for ['[CLS]less millennium billboard ron trial marino empire clerk kai brand [SEP]']
[Init] best rec loss: 0.6907491683959961 for ['[CLS] whitney paid space besides itself freedomud white waist there [SEP]']
[Init] best rec loss: 0.6749796271324158 for ['[CLS]lance spiders roman above selectcarriageoured towardsiness page [SEP]']
[Init] best perm rec loss: 0.6743735074996948 for ['[CLS]iness roman selectcarriage towardsoured abovelance page spiders [SEP]']
[Init] best perm rec loss: 0.6720325946807861 for ['[CLS]lance towards spiders aboveoured romaniness select pagecarriage [SEP]']
[Init] best perm rec loss: 0.6717727780342102 for ['[CLS] page select spidersinesscarriage abovelance romanoured towards [SEP]']
[Init] best perm rec loss: 0.6715611815452576 for ['[CLS] towards page spidersoured selectiness romanlance abovecarriage [SEP]']
[Init] best perm rec loss: 0.6711361408233643 for ['[CLS] abovecarriagelance spidersiness towards pageoured roman select [SEP]']
[Init] best perm rec loss: 0.6707462668418884 for ['[CLS] page above roman spiders selectlanceinesscarriage towardsoured [SEP]']
[Init] best perm rec loss: 0.6705222725868225 for ['[CLS] roman pageinesscarriage select towards above spiderslanceoured [SEP]']
[Init] best perm rec loss: 0.6702622771263123 for ['[CLS]ourediness select page towards roman above spiderslancecarriage [SEP]']
[Init] best perm rec loss: 0.6695494055747986 for ['[CLS]iness page above spiders romancarriageoured towardslance select [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.777 (perp=11.673, rec=0.395, cos=0.047), tot_loss_proj:3.343 [t=0.21s]
prediction: ['[CLS] offered vote maori originates from council decided papers ma estate [SEP]']
[ 100/2000] tot_loss=2.445 (perp=10.754, rec=0.278, cos=0.016), tot_loss_proj:3.219 [t=0.18s]
prediction: ['[CLS] would think say who that must weekly seamus ma estate [SEP]']
[ 150/2000] tot_loss=2.292 (perp=9.824, rec=0.295, cos=0.031), tot_loss_proj:2.767 [t=0.18s]
prediction: ['[CLS] would think and who that prison? seamus seamus registry [SEP]']
[ 200/2000] tot_loss=2.060 (perp=9.255, rec=0.194, cos=0.014), tot_loss_proj:2.968 [t=0.18s]
prediction: ['[CLS] would think that who that will? seamus seamus quarter [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.749 (perp=7.775, rec=0.184, cos=0.011), tot_loss_proj:2.922 [t=0.18s]
prediction: ['[CLS] will you who think that will? seamus seamus seamus [SEP]']
[ 300/2000] tot_loss=1.930 (perp=8.907, rec=0.142, cos=0.006), tot_loss_proj:2.542 [t=0.18s]
prediction: ['[CLS] will do who think that will? seamus seamus question [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.793 (perp=8.289, rec=0.131, cos=0.005), tot_loss_proj:2.447 [t=0.18s]
prediction: ['[CLS] who will do think that will? seamus seamus question [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.584 (perp=7.311, rec=0.116, cos=0.006), tot_loss_proj:2.088 [t=0.18s]
prediction: ['[CLS] who will do think that will first seamus seamus? [SEP]']
[ 450/2000] tot_loss=1.416 (perp=6.589, rec=0.094, cos=0.004), tot_loss_proj:2.228 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.428 (perp=6.589, rec=0.107, cos=0.004), tot_loss_proj:2.225 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.414 (perp=6.589, rec=0.092, cos=0.004), tot_loss_proj:2.233 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
[ 600/2000] tot_loss=1.412 (perp=6.589, rec=0.091, cos=0.003), tot_loss_proj:2.228 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.414 (perp=6.589, rec=0.093, cos=0.003), tot_loss_proj:2.226 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.394 (perp=6.589, rec=0.073, cos=0.003), tot_loss_proj:2.223 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
[ 750/2000] tot_loss=1.398 (perp=6.589, rec=0.078, cos=0.002), tot_loss_proj:2.228 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.400 (perp=6.589, rec=0.080, cos=0.002), tot_loss_proj:2.218 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.392 (perp=6.589, rec=0.072, cos=0.003), tot_loss_proj:2.215 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
[ 900/2000] tot_loss=1.392 (perp=6.589, rec=0.072, cos=0.003), tot_loss_proj:2.220 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.402 (perp=6.589, rec=0.082, cos=0.003), tot_loss_proj:2.220 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.401 (perp=6.589, rec=0.081, cos=0.003), tot_loss_proj:2.224 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
[1050/2000] tot_loss=1.396 (perp=6.589, rec=0.075, cos=0.003), tot_loss_proj:2.217 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.388 (perp=6.589, rec=0.068, cos=0.003), tot_loss_proj:2.219 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.394 (perp=6.589, rec=0.074, cos=0.003), tot_loss_proj:2.219 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
[1200/2000] tot_loss=1.397 (perp=6.589, rec=0.077, cos=0.003), tot_loss_proj:2.217 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.392 (perp=6.589, rec=0.071, cos=0.003), tot_loss_proj:2.217 [t=0.18s]
prediction: ['[CLS] who will do think that will first question seamus? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.399 (perp=6.564, rec=0.084, cos=0.003), tot_loss_proj:2.748 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
[1350/2000] tot_loss=1.394 (perp=6.564, rec=0.078, cos=0.003), tot_loss_proj:2.748 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.399 (perp=6.564, rec=0.083, cos=0.003), tot_loss_proj:2.750 [t=0.17s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.379 (perp=6.564, rec=0.064, cos=0.003), tot_loss_proj:2.747 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
[1500/2000] tot_loss=1.393 (perp=6.564, rec=0.078, cos=0.003), tot_loss_proj:2.746 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.386 (perp=6.564, rec=0.071, cos=0.003), tot_loss_proj:2.748 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.388 (perp=6.564, rec=0.073, cos=0.003), tot_loss_proj:2.741 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
[1650/2000] tot_loss=1.385 (perp=6.564, rec=0.070, cos=0.003), tot_loss_proj:2.740 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.392 (perp=6.564, rec=0.077, cos=0.003), tot_loss_proj:2.744 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.399 (perp=6.564, rec=0.084, cos=0.003), tot_loss_proj:2.745 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
[1800/2000] tot_loss=1.393 (perp=6.564, rec=0.078, cos=0.003), tot_loss_proj:2.744 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.384 (perp=6.564, rec=0.069, cos=0.003), tot_loss_proj:2.743 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.378 (perp=6.564, rec=0.063, cos=0.003), tot_loss_proj:2.746 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
[1950/2000] tot_loss=1.388 (perp=6.564, rec=0.073, cos=0.003), tot_loss_proj:2.747 [t=0.18s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.383 (perp=6.564, rec=0.068, cos=0.003), tot_loss_proj:2.748 [t=0.17s]
prediction: ['[CLS] who will do think that you first question seamus? [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] who do you think that will question seamus first? [SEP]
========================
predicted: 
========================
[CLS] who will do think that you first question seamus? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 85.000 | p: 85.000 | r: 85.000
rouge2     | fm: 20.556 | p: 20.556 | r: 20.556
rougeL     | fm: 61.364 | p: 61.364 | r: 61.364
rougeLsum  | fm: 61.364 | p: 61.364 | r: 61.364
r1fm+r2fm = 105.556

input #1 time: 0:07:35 | total time: 0:14:58


Running input #2 of 100.
reference: 
========================
The boy ran.
========================
average of cosine similarity 0.999382605741486
highest_index [0]
highest [0.999382605741486]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 1996, 2879, 2743, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the boy ran. [SEP]']
[Init] best rec loss: 0.9620961546897888 for ['[CLS] animation equal wickets gran [SEP]']
[Init] best rec loss: 0.9495673179626465 for ['[CLS] rose instruction lengths ; [SEP]']
[Init] best rec loss: 0.9206191301345825 for ['[CLS] february bachelor energyets [SEP]']
[Init] best rec loss: 0.8724637627601624 for ['[CLS] directly goes our sang [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.461 (perp=10.642, rec=0.591, cos=0.741), tot_loss_proj:4.104 [t=0.17s]
prediction: ['[CLS] woman ran belly ran [SEP]']
[ 100/2000] tot_loss=1.898 (perp=8.425, rec=0.198, cos=0.015), tot_loss_proj:3.728 [t=0.17s]
prediction: ['[CLS] boy ran boy ran [SEP]']
[ 150/2000] tot_loss=1.835 (perp=8.425, rec=0.139, cos=0.012), tot_loss_proj:3.728 [t=0.17s]
prediction: ['[CLS] boy ran boy ran [SEP]']
[ 200/2000] tot_loss=2.318 (perp=10.873, rec=0.133, cos=0.011), tot_loss_proj:4.128 [t=0.17s]
prediction: ['[CLS] boy an boy ran [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.216 (perp=10.298, rec=0.146, cos=0.011), tot_loss_proj:4.156 [t=0.17s]
prediction: ['[CLS] boy boy boy ran [SEP]']
[ 300/2000] tot_loss=1.750 (perp=8.053, rec=0.130, cos=0.010), tot_loss_proj:3.703 [t=0.17s]
prediction: ['[CLS] the boy boy ran [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.251 (perp=10.592, rec=0.124, cos=0.009), tot_loss_proj:4.047 [t=0.17s]
prediction: ['[CLS] ; boy boy ran [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.838 (perp=8.543, rec=0.121, cos=0.008), tot_loss_proj:3.583 [t=0.17s]
prediction: ['[CLS] the boy ran boy [SEP]']
[ 450/2000] tot_loss=1.818 (perp=8.543, rec=0.103, cos=0.006), tot_loss_proj:3.578 [t=0.17s]
prediction: ['[CLS] the boy ran boy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.817 (perp=8.543, rec=0.102, cos=0.006), tot_loss_proj:3.583 [t=0.17s]
prediction: ['[CLS] the boy ran boy [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.730 (perp=8.053, rec=0.112, cos=0.007), tot_loss_proj:3.687 [t=0.17s]
prediction: ['[CLS] the boy boy ran [SEP]']
[ 600/2000] tot_loss=1.707 (perp=8.053, rec=0.091, cos=0.006), tot_loss_proj:3.686 [t=0.17s]
prediction: ['[CLS] the boy boy ran [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.715 (perp=8.053, rec=0.098, cos=0.006), tot_loss_proj:3.692 [t=0.17s]
prediction: ['[CLS] the boy boy ran [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.709 (perp=8.053, rec=0.092, cos=0.006), tot_loss_proj:3.692 [t=0.17s]
prediction: ['[CLS] the boy boy ran [SEP]']
[ 750/2000] tot_loss=1.719 (perp=8.053, rec=0.102, cos=0.006), tot_loss_proj:3.693 [t=0.17s]
prediction: ['[CLS] the boy boy ran [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.476 (perp=6.905, rec=0.089, cos=0.006), tot_loss_proj:2.837 [t=0.17s]
prediction: ['[CLS] the boy. ran [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.316 (perp=6.128, rec=0.084, cos=0.006), tot_loss_proj:1.346 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
[ 900/2000] tot_loss=1.317 (perp=6.128, rec=0.085, cos=0.006), tot_loss_proj:1.349 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.320 (perp=6.128, rec=0.088, cos=0.006), tot_loss_proj:1.353 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.327 (perp=6.128, rec=0.095, cos=0.006), tot_loss_proj:1.341 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
[1050/2000] tot_loss=1.315 (perp=6.128, rec=0.084, cos=0.006), tot_loss_proj:1.353 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.320 (perp=6.128, rec=0.088, cos=0.006), tot_loss_proj:1.357 [t=0.21s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.322 (perp=6.128, rec=0.090, cos=0.006), tot_loss_proj:1.344 [t=0.19s]
prediction: ['[CLS] the boy ran. [SEP]']
[1200/2000] tot_loss=1.318 (perp=6.128, rec=0.087, cos=0.006), tot_loss_proj:1.350 [t=0.19s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.311 (perp=6.128, rec=0.080, cos=0.006), tot_loss_proj:1.357 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.320 (perp=6.128, rec=0.088, cos=0.006), tot_loss_proj:1.343 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[1350/2000] tot_loss=1.323 (perp=6.128, rec=0.091, cos=0.006), tot_loss_proj:1.346 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.319 (perp=6.128, rec=0.088, cos=0.006), tot_loss_proj:1.351 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.329 (perp=6.128, rec=0.097, cos=0.006), tot_loss_proj:1.352 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[1500/2000] tot_loss=1.319 (perp=6.128, rec=0.087, cos=0.006), tot_loss_proj:1.349 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.314 (perp=6.128, rec=0.082, cos=0.006), tot_loss_proj:1.351 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.309 (perp=6.128, rec=0.077, cos=0.006), tot_loss_proj:1.354 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
[1650/2000] tot_loss=1.310 (perp=6.128, rec=0.079, cos=0.006), tot_loss_proj:1.353 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.312 (perp=6.128, rec=0.081, cos=0.006), tot_loss_proj:1.342 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.315 (perp=6.128, rec=0.084, cos=0.006), tot_loss_proj:1.344 [t=0.17s]
prediction: ['[CLS] the boy ran. [SEP]']
[1800/2000] tot_loss=1.311 (perp=6.128, rec=0.079, cos=0.006), tot_loss_proj:1.343 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.322 (perp=6.128, rec=0.090, cos=0.006), tot_loss_proj:1.350 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.318 (perp=6.128, rec=0.086, cos=0.006), tot_loss_proj:1.349 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[1950/2000] tot_loss=1.327 (perp=6.128, rec=0.096, cos=0.006), tot_loss_proj:1.347 [t=0.19s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.320 (perp=6.128, rec=0.089, cos=0.006), tot_loss_proj:1.359 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] the boy ran. [SEP]
========================
predicted: 
========================
[CLS] the boy ran. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 47.037 | p: 47.037 | r: 47.037
rougeL     | fm: 74.242 | p: 74.242 | r: 74.242
rougeLsum  | fm: 74.242 | p: 74.242 | r: 74.242
r1fm+r2fm = 137.037

input #2 time: 0:07:06 | total time: 0:22:04


Running input #3 of 100.
reference: 
========================
I wonder who Bill saw and liked Mary.
========================
average of cosine similarity 0.9993519691025421
highest_index [0]
highest [0.9993519691025421]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1045, 4687, 2040, 3021, 2387, 1998, 4669, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i wonder who bill saw and liked mary. [SEP]']
[Init] best rec loss: 0.8413416743278503 for ['[CLS] term acute turner ren reunion streets strikes still preservation [SEP]']
[Init] best rec loss: 0.8077667951583862 for ['[CLS] safety acting reserve casencies5 walt ready clockwise [SEP]']
[Init] best rec loss: 0.8017082214355469 for ['[CLS] u masters particular prentice payment to councillor cl mls [SEP]']
[Init] best rec loss: 0.7690931558609009 for ['[CLS] talerth cricket favourites semi & reports tier female [SEP]']
[Init] best rec loss: 0.7666354775428772 for ['[CLS] matthew marked studies offensive titular sneak de drama escort [SEP]']
[Init] best rec loss: 0.7478668093681335 for ['[CLS]logist felt sympathetic analogy apr thick dakota origin barracks [SEP]']
[Init] best perm rec loss: 0.7411834597587585 for ['[CLS] felt origin sympathetic thicklogist dakota apr barracks analogy [SEP]']
[Init] best perm rec loss: 0.740568995475769 for ['[CLS]logist analogy barracks dakota thick apr origin sympathetic felt [SEP]']
[Init] best perm rec loss: 0.7380269169807434 for ['[CLS] dakotalogist apr analogy thick sympathetic felt origin barracks [SEP]']
[Init] best perm rec loss: 0.7372322082519531 for ['[CLS] sympathetic dakota thick felt origin analogy apr barrackslogist [SEP]']
[Init] best perm rec loss: 0.7371391654014587 for ['[CLS] apr felt analogy dakota thicklogist origin sympathetic barracks [SEP]']
[Init] best perm rec loss: 0.7346237301826477 for ['[CLS] thick dakota analogy feltlogist barracks apr origin sympathetic [SEP]']
[Init] best perm rec loss: 0.7333685159683228 for ['[CLS] origin dakota sympathetic felt aprlogist analogy thick barracks [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.766 (perp=11.072, rec=0.457, cos=0.094), tot_loss_proj:4.012 [t=0.17s]
prediction: ['[CLS] which cars lighthouse felt camille ; to thicktangle [SEP]']
[ 100/2000] tot_loss=2.833 (perp=11.336, rec=0.412, cos=0.153), tot_loss_proj:3.945 [t=0.18s]
prediction: ['[CLS] which liked traveler liked australian ; to thick dawson [SEP]']
[ 150/2000] tot_loss=2.256 (perp=9.375, rec=0.348, cos=0.033), tot_loss_proj:3.457 [t=0.18s]
prediction: ['[CLS] which mary whom liked bill. considered thick. [SEP]']
[ 200/2000] tot_loss=3.046 (perp=11.142, rec=0.415, cos=0.403), tot_loss_proj:3.750 [t=0.17s]
prediction: ['[CLS] wonder maryriation liked bill and considered thick. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.405 (perp=10.319, rec=0.306, cos=0.035), tot_loss_proj:3.854 [t=0.18s]
prediction: ['[CLS] wonder whom liked bill mary and liked liked. [SEP]']
[ 300/2000] tot_loss=2.780 (perp=11.262, rec=0.426, cos=0.102), tot_loss_proj:3.554 [t=0.18s]
prediction: ['[CLS] wonder beetle who western bill as. ; cameron [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.621 (perp=10.833, rec=0.383, cos=0.072), tot_loss_proj:3.401 [t=0.18s]
prediction: ['[CLS] wonder edward who mary bill as. ; cameron [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.963 (perp=8.065, rec=0.316, cos=0.033), tot_loss_proj:2.888 [t=0.18s]
prediction: ['[CLS] wonder edward who. bill and mary ; cameron [SEP]']
[ 450/2000] tot_loss=1.955 (perp=8.065, rec=0.309, cos=0.033), tot_loss_proj:2.893 [t=0.18s]
prediction: ['[CLS] wonder edward who. bill and mary ; cameron [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.782 (perp=7.480, rec=0.263, cos=0.024), tot_loss_proj:2.752 [t=0.18s]
prediction: ['[CLS] edward wonder who. bill and mary ; cameron [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.763 (perp=7.480, rec=0.248, cos=0.020), tot_loss_proj:2.756 [t=0.18s]
prediction: ['[CLS] edward wonder who. bill and mary ; cameron [SEP]']
[ 600/2000] tot_loss=1.889 (perp=8.180, rec=0.236, cos=0.018), tot_loss_proj:2.613 [t=0.18s]
prediction: ['[CLS] edward wonder who! bill and mary. cameron [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.877 (perp=8.180, rec=0.225, cos=0.016), tot_loss_proj:2.613 [t=0.18s]
prediction: ['[CLS] edward wonder who! bill and mary. cameron [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.929 (perp=8.345, rec=0.239, cos=0.022), tot_loss_proj:2.916 [t=0.18s]
prediction: ['[CLS] edward wonder who... bill and mary cameron. [SEP]']
[ 750/2000] tot_loss=1.907 (perp=8.345, rec=0.220, cos=0.017), tot_loss_proj:2.922 [t=0.19s]
prediction: ['[CLS] edward wonder who... bill and mary cameron. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.730 (perp=7.523, rec=0.209, cos=0.017), tot_loss_proj:2.510 [t=0.18s]
prediction: ['[CLS] charles wonder who! bill and mary cameron. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.729 (perp=7.523, rec=0.209, cos=0.016), tot_loss_proj:2.508 [t=0.18s]
prediction: ['[CLS] charles wonder who! bill and mary cameron. [SEP]']
[ 900/2000] tot_loss=1.725 (perp=7.523, rec=0.205, cos=0.016), tot_loss_proj:2.510 [t=0.18s]
prediction: ['[CLS] charles wonder who! bill and mary cameron. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.723 (perp=7.523, rec=0.203, cos=0.015), tot_loss_proj:2.512 [t=0.18s]
prediction: ['[CLS] charles wonder who! bill and mary cameron. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.856 (perp=8.239, rec=0.193, cos=0.015), tot_loss_proj:3.326 [t=0.18s]
prediction: ['[CLS] charles wonder who! bill and liked cameron. [SEP]']
[1050/2000] tot_loss=1.854 (perp=8.239, rec=0.191, cos=0.015), tot_loss_proj:3.329 [t=0.18s]
prediction: ['[CLS] charles wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.878 (perp=8.393, rec=0.184, cos=0.015), tot_loss_proj:3.277 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.891 (perp=8.393, rec=0.198, cos=0.014), tot_loss_proj:3.272 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
[1200/2000] tot_loss=1.879 (perp=8.393, rec=0.187, cos=0.014), tot_loss_proj:3.269 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.879 (perp=8.393, rec=0.187, cos=0.013), tot_loss_proj:3.270 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.871 (perp=8.393, rec=0.180, cos=0.012), tot_loss_proj:3.277 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
[1350/2000] tot_loss=1.874 (perp=8.393, rec=0.183, cos=0.012), tot_loss_proj:3.270 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.867 (perp=8.393, rec=0.176, cos=0.012), tot_loss_proj:3.276 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.858 (perp=8.393, rec=0.167, cos=0.012), tot_loss_proj:3.272 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
[1500/2000] tot_loss=1.864 (perp=8.393, rec=0.173, cos=0.012), tot_loss_proj:3.276 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.848 (perp=8.393, rec=0.157, cos=0.012), tot_loss_proj:3.277 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.852 (perp=8.393, rec=0.162, cos=0.011), tot_loss_proj:3.272 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
[1650/2000] tot_loss=1.860 (perp=8.393, rec=0.170, cos=0.011), tot_loss_proj:3.272 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.853 (perp=8.393, rec=0.163, cos=0.011), tot_loss_proj:3.270 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.854 (perp=8.393, rec=0.164, cos=0.011), tot_loss_proj:3.275 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
[1800/2000] tot_loss=1.860 (perp=8.393, rec=0.171, cos=0.011), tot_loss_proj:3.274 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.843 (perp=8.393, rec=0.154, cos=0.011), tot_loss_proj:3.272 [t=0.18s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.848 (perp=8.393, rec=0.158, cos=0.011), tot_loss_proj:3.265 [t=0.20s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
[1950/2000] tot_loss=1.844 (perp=8.393, rec=0.155, cos=0.010), tot_loss_proj:3.277 [t=0.21s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.852 (perp=8.393, rec=0.163, cos=0.010), tot_loss_proj:3.271 [t=0.19s]
prediction: ['[CLS] mary wonder who! bill and liked cameron. [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] i wonder who bill saw and liked mary. [SEP]
========================
predicted: 
========================
[CLS] mary wonder who! bill and liked cameron. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 88.889 | r: 80.000
rouge2     | fm: 35.294 | p: 37.500 | r: 33.333
rougeL     | fm: 73.684 | p: 77.778 | r: 70.000
rougeLsum  | fm: 73.684 | p: 77.778 | r: 70.000
r1fm+r2fm = 119.505

[Aggregate metrics]:
rouge1     | fm: 88.553 | p: 89.722 | r: 87.500
rouge2     | fm: 44.101 | p: 44.653 | r: 43.611
rougeL     | fm: 74.103 | p: 75.126 | r: 73.182
rougeLsum  | fm: 74.103 | p: 75.126 | r: 73.182
r1fm+r2fm = 132.654

input #3 time: 0:07:23 | total time: 0:29:28


Running input #4 of 100.
reference: 
========================
While I might want to, this is the kind of thing that Harris has already suggested.
========================
average of cosine similarity 0.9993692677558084
highest_index [0]
highest [0.9993692677558084]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2096, 1045, 2453, 2215, 2000, 1010, 2023, 2003, 1996, 2785, 1997,
         2518, 2008, 5671, 2038, 2525, 4081, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]']
[Init] best rec loss: 1.0353513956069946 for ['[CLS] june stuffed eponymousdaepathic white bump earth critical security tata fraa area che range soory [SEP]']
[Init] best rec loss: 0.9104655981063843 for ['[CLS] rather againnae henry program seek csi finish et maya alternate drive airport r ke vermont witness 2011 [SEP]']
[Init] best rec loss: 0.9013139009475708 for ['[CLS]enter american howding meial pages navy based talking impact alternative bit frankenstein eating period saidain [SEP]']
[Init] best rec loss: 0.9006959199905396 for ['[CLS] handled off entirely seemedless need elsewhere paper quality trouble presence food anything wood along look tel hot [SEP]']
[Init] best rec loss: 0.8877056837081909 for ['[CLS]rao market object pocket muslim boys columbia producer drawn hostigen flowing media beam vice minutesrion steady [SEP]']
[Init] best perm rec loss: 0.8826872706413269 for ['[CLS] host minutes flowing media producer pocket beam market steady columbia viceraorion drawn boys objectigen muslim [SEP]']
[Init] best perm rec loss: 0.8705316185951233 for ['[CLS] object muslim boys steady vice pocket columbiarao host market producer beamigen media minutesrion drawn flowing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.953 (perp=12.135, rec=0.527, cos=0.999), tot_loss_proj:4.314 [t=0.19s]
prediction: ['[CLS] and raf as upon went over reflect forfer picking locationif delaware when europa preferred boundarywee [SEP]']
[ 100/2000] tot_loss=3.775 (perp=11.527, rec=0.470, cos=1.000), tot_loss_proj:4.236 [t=0.21s]
prediction: ['[CLS] and mentioned as upon zach. congestion for the merely wantedif racer each harris suggested airs brings [SEP]']
[ 150/2000] tot_loss=3.495 (perp=10.399, rec=0.416, cos=0.999), tot_loss_proj:3.934 [t=0.20s]
prediction: ['[CLS] and mentioned while two would. distributed ofby print have prefer racer should harris suggested airs. [SEP]']
[ 200/2000] tot_loss=3.854 (perp=11.290, rec=0.601, cos=0.994), tot_loss_proj:4.130 [t=0.22s]
prediction: ['[CLS] and ll robin into were in julian wintertra archie possibly. whom legendary harris.. has [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.670 (perp=10.747, rec=0.522, cos=0.998), tot_loss_proj:4.000 [t=0.20s]
prediction: ['[CLS] ll. the had as across whenever andtra constructed possibly. of has harris gives request has [SEP]']
[ 300/2000] tot_loss=3.497 (perp=10.166, rec=0.464, cos=1.000), tot_loss_proj:3.851 [t=0.21s]
prediction: ['[CLS] witch. the has could across whenever and also harris actually. of situated harris gives request has [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.804 (perp=11.640, rec=0.476, cos=1.000), tot_loss_proj:4.221 [t=0.18s]
prediction: ['[CLS] ll moment mythology harris went perhaps whenever but also are its.er residence harris parts priced in [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.459 (perp=10.116, rec=0.438, cos=0.998), tot_loss_proj:3.875 [t=0.18s]
prediction: ['[CLS] usingv rather harris in perhaps whenever while harris is its.er residence the parts etc has [SEP]']
[ 450/2000] tot_loss=3.569 (perp=10.870, rec=0.405, cos=0.990), tot_loss_proj:4.044 [t=0.18s]
prediction: ['[CLS] usingvor mind harris in perhaps whenever while harris is its.er residence the parts etc has [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.571 (perp=11.098, rec=0.394, cos=0.958), tot_loss_proj:4.081 [t=0.18s]
prediction: ['[CLS] differently parts principles harris in ecole whenever while harris is its. which breakfast thevor etc has [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.630 (perp=10.917, rec=0.454, cos=0.992), tot_loss_proj:4.061 [t=0.18s]
prediction: ['[CLS] spelled whenever affection harris would trailed award while harris is its. which breakfast thevor etc has [SEP]']
[ 600/2000] tot_loss=3.366 (perp=10.035, rec=0.396, cos=0.963), tot_loss_proj:3.876 [t=0.18s]
prediction: ['[CLS] using whenever affection harris have trailed award while harris is its. which residence thevor. has [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.784 (perp=9.379, rec=0.403, cos=0.505), tot_loss_proj:3.801 [t=0.18s]
prediction: ['[CLS] harris tornadoes mind harris have trailed award while harris has its. which breakfast thevor has. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.641 (perp=10.557, rec=0.396, cos=0.134), tot_loss_proj:3.979 [t=0.18s]
prediction: ['[CLS] using tornadoes considered interrupted harris exist award while harris suggested its. which residence the shall has. [SEP]']
[ 750/2000] tot_loss=2.368 (perp=10.252, rec=0.292, cos=0.026), tot_loss_proj:3.971 [t=0.18s]
prediction: ['[CLS] harris tornadoes considered interrupted harris robes award while harris suggested its. which residence the suppose has. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.302 (perp=10.096, rec=0.262, cos=0.021), tot_loss_proj:3.904 [t=0.18s]
prediction: ['[CLS] harris considered koppen interrupted harris have thing while harris suggested its. which years the suppose has. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.201 (perp=9.604, rec=0.257, cos=0.023), tot_loss_proj:3.830 [t=0.18s]
prediction: ['[CLS] using considered koppen interrupted harris thing while harris suggested its. which breakfast thev would have if [SEP]']
[ 900/2000] tot_loss=2.211 (perp=9.745, rec=0.243, cos=0.018), tot_loss_proj:3.842 [t=0.18s]
prediction: ['[CLS] spelled considered digits didn harris thing while harris suggests its. which years thev would have. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.134 (perp=9.409, rec=0.235, cos=0.017), tot_loss_proj:3.755 [t=0.18s]
prediction: ['[CLS] i digits didn harris thing considered while harris suggests its. which years thev would have. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.302 (perp=10.284, rec=0.231, cos=0.014), tot_loss_proj:3.914 [t=0.18s]
prediction: ['[CLS] spelled didn harris thing considered while harris suggests sort. which years the digitsv can would. [SEP]']
[1050/2000] tot_loss=1.964 (perp=8.599, rec=0.231, cos=0.013), tot_loss_proj:3.578 [t=0.18s]
prediction: ['[CLS] i would harris thing considered while harris suggests sort. which years the digitsv can have. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.826 (perp=7.966, rec=0.220, cos=0.012), tot_loss_proj:3.459 [t=0.18s]
prediction: ['[CLS] i would harris thing considered while harris has sort. the years which digitsv can have. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.819 (perp=7.966, rec=0.215, cos=0.011), tot_loss_proj:3.461 [t=0.18s]
prediction: ['[CLS] i would harris thing considered while harris has sort. the years which digitsv can have. [SEP]']
[1200/2000] tot_loss=1.851 (perp=8.116, rec=0.217, cos=0.010), tot_loss_proj:3.474 [t=0.18s]
prediction: ['[CLS] i would harris thing considered while harris has sort. the years which digits while can have. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.859 (perp=8.161, rec=0.216, cos=0.011), tot_loss_proj:3.494 [t=0.18s]
prediction: ['[CLS] during would harris thing might while harris has perhaps. the years which digits i can while. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.885 (perp=8.320, rec=0.210, cos=0.010), tot_loss_proj:3.520 [t=0.18s]
prediction: ['[CLS] during would harris thing might while harris has perhaps. the years which digits i while told. [SEP]']
[1350/2000] tot_loss=1.813 (perp=8.001, rec=0.203, cos=0.010), tot_loss_proj:3.463 [t=0.18s]
prediction: ['[CLS] during would harris thing could while harris has perhaps. the years which digits i have told. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.788 (perp=7.877, rec=0.203, cos=0.010), tot_loss_proj:3.413 [t=0.18s]
prediction: ['[CLS] during which would harris thing could while harris has sometimes. the years digits i have told. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.755 (perp=7.693, rec=0.207, cos=0.010), tot_loss_proj:3.396 [t=0.18s]
prediction: ['[CLS] during which would thing harris could while harris has perhaps. the years digits i have told. [SEP]']
[1500/2000] tot_loss=1.752 (perp=7.693, rec=0.204, cos=0.009), tot_loss_proj:3.390 [t=0.18s]
prediction: ['[CLS] during which would thing harris could while harris has perhaps. the years digits i have told. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.864 (perp=8.261, rec=0.203, cos=0.009), tot_loss_proj:3.502 [t=0.18s]
prediction: ['[CLS] during even would thing harris could while harris has perhaps. the years digits i have told. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.816 (perp=7.997, rec=0.208, cos=0.008), tot_loss_proj:3.445 [t=0.18s]
prediction: ['[CLS] during thing even would harris could while harris has perhaps. the years digits i have told. [SEP]']
[1650/2000] tot_loss=1.830 (perp=8.088, rec=0.204, cos=0.008), tot_loss_proj:3.480 [t=0.18s]
prediction: ['[CLS] while thing even would harris could while harris has perhaps. the years digits i have told. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.812 (perp=8.057, rec=0.193, cos=0.008), tot_loss_proj:3.466 [t=0.18s]
prediction: ['[CLS] during even thing would harris could while harris has perhaps. the years digits i have told. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.818 (perp=8.088, rec=0.193, cos=0.008), tot_loss_proj:3.481 [t=0.18s]
prediction: ['[CLS] while thing even would harris could while harris has perhaps. the years digits i have told. [SEP]']
[1800/2000] tot_loss=1.814 (perp=8.088, rec=0.189, cos=0.008), tot_loss_proj:3.479 [t=0.18s]
prediction: ['[CLS] while thing even would harris could while harris has perhaps. the years digits i have told. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.819 (perp=8.059, rec=0.200, cos=0.007), tot_loss_proj:3.485 [t=0.18s]
prediction: ['[CLS] while even thing would harris could while harris has perhaps. the yearslton i have told. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.711 (perp=7.508, rec=0.199, cos=0.010), tot_loss_proj:3.399 [t=0.21s]
prediction: ['[CLS] while even thing i harris could while harris has perhaps. the yearslton would have told. [SEP]']
[1950/2000] tot_loss=1.702 (perp=7.508, rec=0.193, cos=0.007), tot_loss_proj:3.397 [t=0.18s]
prediction: ['[CLS] while even thing i harris could while harris has perhaps. the yearslton would have told. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.658 (perp=7.276, rec=0.195, cos=0.007), tot_loss_proj:3.336 [t=0.19s]
prediction: ['[CLS] while even thing i could harris while harris has perhaps. the yearslton would have told. [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]
========================
predicted: 
========================
[CLS] while even thing would harris could while harris has perhaps. the yearslton i have told. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 45.714 | p: 47.059 | r: 44.444
rouge2     | fm: 12.121 | p: 12.500 | r: 11.765
rougeL     | fm: 34.286 | p: 35.294 | r: 33.333
rougeLsum  | fm: 34.286 | p: 35.294 | r: 33.333
r1fm+r2fm = 57.835

[Aggregate metrics]:
rouge1     | fm: 81.684 | p: 82.745 | r: 80.000
rouge2     | fm: 37.705 | p: 38.222 | r: 37.242
rougeL     | fm: 66.139 | p: 67.160 | r: 65.212
rougeLsum  | fm: 66.139 | p: 67.160 | r: 65.212
r1fm+r2fm = 119.389

input #4 time: 0:08:01 | total time: 0:37:29


Running input #5 of 100.
reference: 
========================
Who has seen my snorkel?
========================
average of cosine similarity 0.9994131902913327
highest_index [0]
highest [0.9994131902913327]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2040,  2038,  2464,  2026,  1055, 12131, 11705,  1029,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] who has seen my snorkel? [SEP]']
[Init] best rec loss: 1.0512324571609497 for ['[CLS] second lot dimensions absolutelyavia nuclear second century [SEP]']
[Init] best rec loss: 0.9496536254882812 for ['[CLS] softzzled 10 dark ob subscription fury cold [SEP]']
[Init] best rec loss: 0.9399934411048889 for ['[CLS] overall its gallo paintings playing percival crater huge [SEP]']
[Init] best rec loss: 0.8532701134681702 for ['[CLS] driven watering house corner head same advertisements show [SEP]']
[Init] best rec loss: 0.8511939644813538 for ['[CLS] the 10 surprise dear relieve leaf blair its [SEP]']
[Init] best rec loss: 0.8402397632598877 for ['[CLS] mallory loose theta drank thin funk soul = [SEP]']
[Init] best rec loss: 0.8126248121261597 for ['[CLS] nat politicalunk priceeon guess goalstered [SEP]']
[Init] best perm rec loss: 0.8102404475212097 for ['[CLS]eon goal price politicalstered natunk guess [SEP]']
[Init] best perm rec loss: 0.807880699634552 for ['[CLS] nat priceunk guesseon political goalstered [SEP]']
[Init] best perm rec loss: 0.8067676424980164 for ['[CLS] goal political priceeon guessunkstered nat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.262 (perp=12.990, rec=0.480, cos=0.183), tot_loss_proj:4.539 [t=0.17s]
prediction: ['[CLS] reynolds love death helped todayinkles island ⟨ [SEP]']
[ 100/2000] tot_loss=2.239 (perp=9.319, rec=0.342, cos=0.034), tot_loss_proj:3.789 [t=0.18s]
prediction: ['[CLS] my was! carly? youtube anna brandon [SEP]']
[ 150/2000] tot_loss=2.282 (perp=9.996, rec=0.255, cos=0.027), tot_loss_proj:3.956 [t=0.18s]
prediction: ['[CLS] mywater whokel? youtube? brandon [SEP]']
[ 200/2000] tot_loss=2.368 (perp=10.758, rec=0.203, cos=0.014), tot_loss_proj:4.127 [t=0.20s]
prediction: ['[CLS] my is whokel? youtube nightmaresnor [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.439 (perp=10.060, rec=0.348, cos=0.079), tot_loss_proj:3.962 [t=0.18s]
prediction: ['[CLS] who knows mykel?ist cock wife [SEP]']
[ 300/2000] tot_loss=2.427 (perp=10.756, rec=0.247, cos=0.028), tot_loss_proj:4.075 [t=0.18s]
prediction: ['[CLS] who read mykel?ist cock wife [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.423 (perp=10.900, rec=0.221, cos=0.022), tot_loss_proj:4.176 [t=0.18s]
prediction: ['[CLS] who read mynor?ist cockkel [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.084 (perp=9.394, rec=0.190, cos=0.016), tot_loss_proj:3.791 [t=0.18s]
prediction: ['[CLS] who seen my cock? apparentnorkel [SEP]']
[ 450/2000] tot_loss=2.065 (perp=9.394, rec=0.173, cos=0.013), tot_loss_proj:3.794 [t=0.18s]
prediction: ['[CLS] who seen my cock? apparentnorkel [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.981 (perp=9.046, rec=0.160, cos=0.012), tot_loss_proj:3.515 [t=0.18s]
prediction: ['[CLS] who seen my cock? formernorkel [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.962 (perp=9.046, rec=0.142, cos=0.011), tot_loss_proj:3.515 [t=0.18s]
prediction: ['[CLS] who seen my cock? formernorkel [SEP]']
[ 600/2000] tot_loss=1.967 (perp=9.046, rec=0.148, cos=0.010), tot_loss_proj:3.516 [t=0.18s]
prediction: ['[CLS] who seen my cock? formernorkel [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.111 (perp=9.773, rec=0.147, cos=0.009), tot_loss_proj:3.972 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.100 (perp=9.773, rec=0.136, cos=0.009), tot_loss_proj:3.975 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
[ 750/2000] tot_loss=2.093 (perp=9.773, rec=0.130, cos=0.009), tot_loss_proj:3.976 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.088 (perp=9.773, rec=0.125, cos=0.008), tot_loss_proj:3.978 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.088 (perp=9.773, rec=0.125, cos=0.008), tot_loss_proj:3.974 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
[ 900/2000] tot_loss=2.083 (perp=9.773, rec=0.120, cos=0.008), tot_loss_proj:3.970 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.075 (perp=9.773, rec=0.113, cos=0.008), tot_loss_proj:3.975 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1000/2000] tot_loss=2.074 (perp=9.773, rec=0.112, cos=0.007), tot_loss_proj:3.971 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
[1050/2000] tot_loss=2.076 (perp=9.773, rec=0.114, cos=0.007), tot_loss_proj:3.979 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1100/2000] tot_loss=2.070 (perp=9.773, rec=0.108, cos=0.007), tot_loss_proj:3.972 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1150/2000] tot_loss=2.077 (perp=9.773, rec=0.115, cos=0.007), tot_loss_proj:3.974 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
[1200/2000] tot_loss=2.084 (perp=9.773, rec=0.123, cos=0.007), tot_loss_proj:3.978 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1250/2000] tot_loss=2.066 (perp=9.773, rec=0.104, cos=0.007), tot_loss_proj:3.975 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1300/2000] tot_loss=2.080 (perp=9.773, rec=0.119, cos=0.007), tot_loss_proj:3.978 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
[1350/2000] tot_loss=2.075 (perp=9.773, rec=0.114, cos=0.007), tot_loss_proj:3.976 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1400/2000] tot_loss=2.072 (perp=9.773, rec=0.110, cos=0.006), tot_loss_proj:3.972 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1450/2000] tot_loss=2.069 (perp=9.773, rec=0.108, cos=0.006), tot_loss_proj:3.973 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
[1500/2000] tot_loss=2.071 (perp=9.773, rec=0.110, cos=0.006), tot_loss_proj:3.977 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1550/2000] tot_loss=2.066 (perp=9.773, rec=0.105, cos=0.006), tot_loss_proj:3.974 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1600/2000] tot_loss=2.068 (perp=9.773, rec=0.107, cos=0.006), tot_loss_proj:3.975 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
[1650/2000] tot_loss=2.079 (perp=9.773, rec=0.118, cos=0.006), tot_loss_proj:3.976 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1700/2000] tot_loss=2.066 (perp=9.773, rec=0.105, cos=0.006), tot_loss_proj:3.974 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1750/2000] tot_loss=2.066 (perp=9.773, rec=0.105, cos=0.006), tot_loss_proj:3.976 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
[1800/2000] tot_loss=2.074 (perp=9.773, rec=0.113, cos=0.006), tot_loss_proj:3.971 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1850/2000] tot_loss=2.067 (perp=9.773, rec=0.106, cos=0.006), tot_loss_proj:3.973 [t=0.19s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[1900/2000] tot_loss=2.073 (perp=9.773, rec=0.112, cos=0.006), tot_loss_proj:3.979 [t=0.22s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
[1950/2000] tot_loss=2.082 (perp=9.773, rec=0.121, cos=0.006), tot_loss_proj:3.972 [t=0.18s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Attempt swap
[2000/2000] tot_loss=2.078 (perp=9.773, rec=0.117, cos=0.006), tot_loss_proj:3.969 [t=0.21s]
prediction: ['[CLS] who seen my disk?kelnorkel [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] who has seen my snorkel? [SEP]
========================
predicted: 
========================
[CLS] who seen my disk?kelnorkel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 104.762

[Aggregate metrics]:
rouge1     | fm: 79.856 | p: 80.501 | r: 78.333
rouge2     | fm: 36.818 | p: 37.130 | r: 36.481
rougeL     | fm: 66.910 | p: 67.871 | r: 66.248
rougeLsum  | fm: 67.180 | p: 68.088 | r: 66.270
r1fm+r2fm = 116.674

input #5 time: 0:07:21 | total time: 0:44:51


Running input #6 of 100.
reference: 
========================
Which goddess helped us?
========================
average of cosine similarity 0.999551417969332
highest_index [0]
highest [0.999551417969332]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2029, 7804, 3271, 2149, 1029,  102]], device='cuda:0')
Debug: ref = ['[CLS] which goddess helped us? [SEP]']
[Init] best rec loss: 0.867874264717102 for ['[CLS] naked scoring southeastvyn taliban [SEP]']
[Init] best rec loss: 0.864172101020813 for ['[CLS] heronhesive faye bachelorcom [SEP]']
[Init] best rec loss: 0.8641515374183655 for ['[CLS]bby ve stellathorpe concerns [SEP]']
[Init] best rec loss: 0.8406566381454468 for ['[CLS]nation convenient heal exactly ljubljana [SEP]']
[Init] best perm rec loss: 0.8389413356781006 for ['[CLS] heal exactlynation convenient ljubljana [SEP]']
[Init] best perm rec loss: 0.8358174562454224 for ['[CLS] exactlynation ljubljana convenient heal [SEP]']
[Init] best perm rec loss: 0.8347128033638 for ['[CLS] ljubljana convenientnation exactly heal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.984 (perp=11.736, rec=0.651, cos=0.986), tot_loss_proj:4.367 [t=0.18s]
prediction: ['[CLS] me viewers (? shifters [SEP]']
[ 100/2000] tot_loss=2.617 (perp=10.771, rec=0.370, cos=0.092), tot_loss_proj:4.128 [t=0.18s]
prediction: ['[CLS] which helping helped goddess? [SEP]']
[ 150/2000] tot_loss=2.191 (perp=9.917, rec=0.182, cos=0.026), tot_loss_proj:3.900 [t=0.18s]
prediction: ['[CLS] which goddess helped goddess goddess [SEP]']
[ 200/2000] tot_loss=2.130 (perp=10.083, rec=0.110, cos=0.004), tot_loss_proj:4.020 [t=0.17s]
prediction: ['[CLS] which? helped goddess we [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.986 (perp=9.545, rec=0.076, cos=0.001), tot_loss_proj:3.961 [t=0.18s]
prediction: ['[CLS] which? helped us goddess [SEP]']
[ 300/2000] tot_loss=1.990 (perp=9.545, rec=0.080, cos=0.001), tot_loss_proj:3.965 [t=0.18s]
prediction: ['[CLS] which? helped us goddess [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.723 (perp=8.242, rec=0.074, cos=0.001), tot_loss_proj:1.782 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.707 (perp=8.242, rec=0.058, cos=0.001), tot_loss_proj:1.773 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[ 450/2000] tot_loss=1.706 (perp=8.242, rec=0.057, cos=0.001), tot_loss_proj:1.784 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.719 (perp=8.242, rec=0.070, cos=0.001), tot_loss_proj:1.792 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.714 (perp=8.242, rec=0.065, cos=0.001), tot_loss_proj:1.775 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[ 600/2000] tot_loss=1.705 (perp=8.242, rec=0.056, cos=0.001), tot_loss_proj:1.782 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.709 (perp=8.242, rec=0.060, cos=0.001), tot_loss_proj:1.785 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.701 (perp=8.242, rec=0.052, cos=0.001), tot_loss_proj:1.785 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[ 750/2000] tot_loss=1.708 (perp=8.242, rec=0.059, cos=0.001), tot_loss_proj:1.779 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.712 (perp=8.242, rec=0.063, cos=0.001), tot_loss_proj:1.781 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.707 (perp=8.242, rec=0.058, cos=0.001), tot_loss_proj:1.788 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[ 900/2000] tot_loss=1.720 (perp=8.242, rec=0.070, cos=0.001), tot_loss_proj:1.778 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.711 (perp=8.242, rec=0.062, cos=0.001), tot_loss_proj:1.793 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.714 (perp=8.242, rec=0.064, cos=0.001), tot_loss_proj:1.777 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1050/2000] tot_loss=1.705 (perp=8.242, rec=0.055, cos=0.001), tot_loss_proj:1.775 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.703 (perp=8.242, rec=0.054, cos=0.001), tot_loss_proj:1.783 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.706 (perp=8.242, rec=0.056, cos=0.001), tot_loss_proj:1.773 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1200/2000] tot_loss=1.716 (perp=8.242, rec=0.066, cos=0.001), tot_loss_proj:1.780 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.714 (perp=8.242, rec=0.065, cos=0.001), tot_loss_proj:1.790 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.701 (perp=8.242, rec=0.051, cos=0.001), tot_loss_proj:1.772 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1350/2000] tot_loss=1.711 (perp=8.242, rec=0.062, cos=0.001), tot_loss_proj:1.785 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.708 (perp=8.242, rec=0.059, cos=0.001), tot_loss_proj:1.780 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.708 (perp=8.242, rec=0.059, cos=0.001), tot_loss_proj:1.786 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1500/2000] tot_loss=1.718 (perp=8.242, rec=0.069, cos=0.001), tot_loss_proj:1.786 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.710 (perp=8.242, rec=0.061, cos=0.001), tot_loss_proj:1.781 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.712 (perp=8.242, rec=0.063, cos=0.001), tot_loss_proj:1.775 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1650/2000] tot_loss=1.703 (perp=8.242, rec=0.054, cos=0.001), tot_loss_proj:1.787 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.714 (perp=8.242, rec=0.064, cos=0.001), tot_loss_proj:1.776 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.710 (perp=8.242, rec=0.061, cos=0.001), tot_loss_proj:1.774 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1800/2000] tot_loss=1.713 (perp=8.242, rec=0.063, cos=0.001), tot_loss_proj:1.785 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.701 (perp=8.242, rec=0.051, cos=0.001), tot_loss_proj:1.774 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.715 (perp=8.242, rec=0.065, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] which goddess helped us? [SEP]']
[1950/2000] tot_loss=1.707 (perp=8.242, rec=0.058, cos=0.001), tot_loss_proj:1.781 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.712 (perp=8.242, rec=0.062, cos=0.001), tot_loss_proj:1.780 [t=0.18s]
prediction: ['[CLS] which goddess helped us? [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] which goddess helped us? [SEP]
========================
predicted: 
========================
[CLS] which goddess helped us? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.234 | p: 83.287 | r: 81.270
rouge2     | fm: 45.844 | p: 46.151 | r: 45.649
rougeL     | fm: 71.732 | p: 72.461 | r: 70.977
rougeLsum  | fm: 71.410 | p: 72.348 | r: 70.625
r1fm+r2fm = 128.078

input #6 time: 0:07:04 | total time: 0:51:56


Running input #7 of 100.
reference: 
========================
They have no old.
========================
average of cosine similarity 0.9993867448742303
highest_index [0]
highest [0.9993867448742303]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2027, 2031, 2053, 2214, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] they have no old. [SEP]']
[Init] best rec loss: 0.8596845865249634 for ['[CLS] devices buck 1947 business ji [SEP]']
[Init] best rec loss: 0.7969943284988403 for ['[CLS]emi streamed including same rugby [SEP]']
[Init] best rec loss: 0.745602548122406 for ['[CLS] nopecharged practiced 2011 jersey [SEP]']
[Init] best rec loss: 0.7454397678375244 for ['[CLS] ok programme timetable mae keeping [SEP]']
[Init] best rec loss: 0.7182220816612244 for ['[CLS] necessary nino shin sensory hank [SEP]']
[Init] best rec loss: 0.7062795162200928 for ['[CLS] total mfa km² brock gifford [SEP]']
[Init] best rec loss: 0.694407045841217 for ['[CLS] presents contact managed dontlement [SEP]']
[Init] best rec loss: 0.6856284141540527 for ['[CLS] zhang just plum class bills [SEP]']
[Init] best rec loss: 0.6675581932067871 for ['[CLS] simultaneously campeonato outside - shown [SEP]']
[Init] best perm rec loss: 0.6658273935317993 for ['[CLS] outside shown campeonato - simultaneously [SEP]']
[Init] best perm rec loss: 0.6624957323074341 for ['[CLS] shown campeonato - simultaneously outside [SEP]']
[Init] best perm rec loss: 0.6613995432853699 for ['[CLS] shown simultaneously - campeonato outside [SEP]']
[Init] best perm rec loss: 0.6613324880599976 for ['[CLS] campeonato outside - simultaneously shown [SEP]']
[Init] best perm rec loss: 0.6570094227790833 for ['[CLS] shown - campeonato simultaneously outside [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.025 (perp=11.919, rec=0.715, cos=0.926), tot_loss_proj:3.465 [t=0.19s]
prediction: ['[CLS] her lucien cursed twin founding [SEP]']
[ 100/2000] tot_loss=2.765 (perp=11.478, rec=0.398, cos=0.072), tot_loss_proj:3.214 [t=0.19s]
prediction: ['[CLS] no old my fixed with [SEP]']
[ 150/2000] tot_loss=2.509 (perp=10.976, rec=0.277, cos=0.037), tot_loss_proj:3.225 [t=0.19s]
prediction: ['[CLS] no old boydock old [SEP]']
[ 200/2000] tot_loss=2.031 (perp=8.996, rec=0.206, cos=0.026), tot_loss_proj:2.958 [t=0.19s]
prediction: ['[CLS] no old boy because old [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.932 (perp=8.618, rec=0.189, cos=0.020), tot_loss_proj:3.141 [t=0.19s]
prediction: ['[CLS] have no old boy old [SEP]']
[ 300/2000] tot_loss=1.895 (perp=8.618, rec=0.158, cos=0.014), tot_loss_proj:3.144 [t=0.19s]
prediction: ['[CLS] have no old boy old [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.881 (perp=8.618, rec=0.145, cos=0.012), tot_loss_proj:3.134 [t=0.18s]
prediction: ['[CLS] have no old boy old [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.883 (perp=8.618, rec=0.148, cos=0.011), tot_loss_proj:3.132 [t=0.17s]
prediction: ['[CLS] have no old boy old [SEP]']
[ 450/2000] tot_loss=2.045 (perp=9.554, rec=0.125, cos=0.009), tot_loss_proj:3.019 [t=0.17s]
prediction: ['[CLS] have no. boy old [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.451 (perp=6.622, rec=0.119, cos=0.008), tot_loss_proj:3.209 [t=0.17s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.456 (perp=6.622, rec=0.125, cos=0.007), tot_loss_proj:3.205 [t=0.17s]
prediction: ['[CLS] have no old brother. [SEP]']
[ 600/2000] tot_loss=1.445 (perp=6.622, rec=0.115, cos=0.006), tot_loss_proj:3.208 [t=0.17s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.438 (perp=6.622, rec=0.109, cos=0.005), tot_loss_proj:3.214 [t=0.17s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.431 (perp=6.622, rec=0.101, cos=0.005), tot_loss_proj:3.208 [t=0.17s]
prediction: ['[CLS] have no old brother. [SEP]']
[ 750/2000] tot_loss=1.434 (perp=6.622, rec=0.104, cos=0.005), tot_loss_proj:3.214 [t=0.17s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.443 (perp=6.622, rec=0.113, cos=0.005), tot_loss_proj:3.210 [t=0.18s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.430 (perp=6.622, rec=0.100, cos=0.005), tot_loss_proj:3.206 [t=0.17s]
prediction: ['[CLS] have no old brother. [SEP]']
[ 900/2000] tot_loss=1.430 (perp=6.622, rec=0.100, cos=0.005), tot_loss_proj:3.210 [t=0.18s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.436 (perp=6.622, rec=0.106, cos=0.005), tot_loss_proj:3.212 [t=0.18s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.433 (perp=6.622, rec=0.104, cos=0.005), tot_loss_proj:3.213 [t=0.18s]
prediction: ['[CLS] have no old brother. [SEP]']
[1050/2000] tot_loss=1.429 (perp=6.622, rec=0.100, cos=0.005), tot_loss_proj:3.213 [t=0.18s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.436 (perp=6.622, rec=0.107, cos=0.005), tot_loss_proj:3.212 [t=0.17s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.428 (perp=6.622, rec=0.098, cos=0.005), tot_loss_proj:3.211 [t=0.18s]
prediction: ['[CLS] have no old brother. [SEP]']
[1200/2000] tot_loss=1.429 (perp=6.622, rec=0.099, cos=0.005), tot_loss_proj:3.212 [t=0.18s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.429 (perp=6.622, rec=0.099, cos=0.005), tot_loss_proj:3.215 [t=0.18s]
prediction: ['[CLS] have no old brother. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.350 (perp=6.233, rec=0.099, cos=0.005), tot_loss_proj:2.659 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
[1350/2000] tot_loss=1.348 (perp=6.233, rec=0.097, cos=0.005), tot_loss_proj:2.660 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.354 (perp=6.233, rec=0.102, cos=0.005), tot_loss_proj:2.657 [t=0.17s]
prediction: ['[CLS] have no old.. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.358 (perp=6.233, rec=0.107, cos=0.005), tot_loss_proj:2.666 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
[1500/2000] tot_loss=1.348 (perp=6.233, rec=0.096, cos=0.005), tot_loss_proj:2.667 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.351 (perp=6.233, rec=0.100, cos=0.005), tot_loss_proj:2.664 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.342 (perp=6.233, rec=0.091, cos=0.005), tot_loss_proj:2.667 [t=0.17s]
prediction: ['[CLS] have no old.. [SEP]']
[1650/2000] tot_loss=1.354 (perp=6.233, rec=0.102, cos=0.005), tot_loss_proj:2.666 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.342 (perp=6.233, rec=0.090, cos=0.005), tot_loss_proj:2.665 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.348 (perp=6.233, rec=0.097, cos=0.005), tot_loss_proj:2.663 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
[1800/2000] tot_loss=1.354 (perp=6.233, rec=0.103, cos=0.005), tot_loss_proj:2.667 [t=0.17s]
prediction: ['[CLS] have no old.. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.351 (perp=6.233, rec=0.099, cos=0.005), tot_loss_proj:2.669 [t=0.17s]
prediction: ['[CLS] have no old.. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.352 (perp=6.233, rec=0.101, cos=0.005), tot_loss_proj:2.669 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
[1950/2000] tot_loss=1.352 (perp=6.233, rec=0.101, cos=0.005), tot_loss_proj:2.670 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.347 (perp=6.233, rec=0.095, cos=0.005), tot_loss_proj:2.668 [t=0.18s]
prediction: ['[CLS] have no old.. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] they have no old. [SEP]
========================
predicted: 
========================
[CLS] have no old.. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 100.000 | r: 83.333
rouge2     | fm: 66.667 | p: 75.000 | r: 60.000
rougeL     | fm: 90.909 | p: 100.000 | r: 83.333
rougeLsum  | fm: 90.909 | p: 100.000 | r: 83.333
r1fm+r2fm = 157.576

[Aggregate metrics]:
rouge1     | fm: 83.554 | p: 85.466 | r: 81.796
rouge2     | fm: 48.021 | p: 49.514 | r: 46.916
rougeL     | fm: 74.225 | p: 76.066 | r: 72.603
rougeLsum  | fm: 74.076 | p: 75.903 | r: 72.440
r1fm+r2fm = 131.575

input #7 time: 0:07:14 | total time: 0:59:11


Running input #8 of 100.
reference: 
========================
John tries to meet not Mary.
========================
average of cosine similarity 0.9992857817396013
highest_index [0]
highest [0.9992857817396013]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2198, 5363, 2000, 3113, 2025, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] john tries to meet not mary. [SEP]']
[Init] best rec loss: 0.8751393556594849 for ['[CLS]udeau secretary steinerc pennypeed press [SEP]']
[Init] best rec loss: 0.8258135318756104 for ['[CLS] fresh contact beaten image angle form confederate [SEP]']
[Init] best rec loss: 0.824735701084137 for ['[CLS] catalogue frankie tsar calendar hog case provisional [SEP]']
[Init] best rec loss: 0.7984954714775085 for ['[CLS] key cult accession floating remember oxford suddenly [SEP]']
[Init] best rec loss: 0.7969860434532166 for ['[CLS] warren benny grace boarding saxon nothing " [SEP]']
[Init] best rec loss: 0.7715851664543152 for ['[CLS] further big instance schedule ahead caftium [SEP]']
[Init] best rec loss: 0.7697283029556274 for ['[CLS]culebid driver genome boundary much books [SEP]']
[Init] best rec loss: 0.7694283723831177 for ['[CLS] recession duncanified within youtube michael eventually [SEP]']
[Init] best rec loss: 0.7451742887496948 for ['[CLS] gentleman centre past gradesfies th times [SEP]']
[Init] best perm rec loss: 0.730642557144165 for ['[CLS] centre past gentleman thfies times grades [SEP]']
[Init] best perm rec loss: 0.7257177829742432 for ['[CLS] centre gentleman timesfies past grades th [SEP]']
[Init] best perm rec loss: 0.7234541773796082 for ['[CLS] past centrefies times th gentleman grades [SEP]']
[Init] best perm rec loss: 0.7234346866607666 for ['[CLS] th grades timesfies centre past gentleman [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.204 (perp=9.525, rec=0.289, cos=0.010), tot_loss_proj:3.308 [t=0.19s]
prediction: ['[CLS] mary mary? not nothi meet [SEP]']
[ 100/2000] tot_loss=1.979 (perp=9.012, rec=0.169, cos=0.007), tot_loss_proj:2.451 [t=0.19s]
prediction: ['[CLS] tries mary how to not meet meet [SEP]']
[ 150/2000] tot_loss=2.018 (perp=9.472, rec=0.121, cos=0.003), tot_loss_proj:3.217 [t=0.17s]
prediction: ['[CLS] tries mary. to not mary meet [SEP]']
[ 200/2000] tot_loss=1.872 (perp=8.723, rec=0.124, cos=0.003), tot_loss_proj:2.737 [t=0.19s]
prediction: ['[CLS] tries mary.. not mary meet [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.715 (perp=8.052, rec=0.102, cos=0.002), tot_loss_proj:2.983 [t=0.17s]
prediction: ['[CLS] tries mary.. not meet john [SEP]']
[ 300/2000] tot_loss=1.696 (perp=8.052, rec=0.083, cos=0.002), tot_loss_proj:2.969 [t=0.18s]
prediction: ['[CLS] tries mary.. not meet john [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.704 (perp=7.805, rec=0.139, cos=0.003), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS] mary tries.. not meet john [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.606 (perp=7.542, rec=0.095, cos=0.002), tot_loss_proj:3.075 [t=0.17s]
prediction: ['[CLS] mary tries. not meet mary, [SEP]']
[ 450/2000] tot_loss=1.600 (perp=7.542, rec=0.090, cos=0.002), tot_loss_proj:3.070 [t=0.17s]
prediction: ['[CLS] mary tries. not meet mary, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.600 (perp=7.542, rec=0.090, cos=0.002), tot_loss_proj:3.069 [t=0.17s]
prediction: ['[CLS] mary tries. not meet mary, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.330 (perp=5.633, rec=0.197, cos=0.006), tot_loss_proj:3.068 [t=0.18s]
prediction: ['[CLS] mary tries to not meet mary. [SEP]']
[ 600/2000] tot_loss=1.259 (perp=5.633, rec=0.129, cos=0.003), tot_loss_proj:3.000 [t=0.17s]
prediction: ['[CLS] mary tries to not meet mary. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.237 (perp=5.633, rec=0.107, cos=0.003), tot_loss_proj:2.996 [t=0.17s]
prediction: ['[CLS] mary tries to not meet mary. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.238 (perp=5.633, rec=0.109, cos=0.002), tot_loss_proj:2.990 [t=0.17s]
prediction: ['[CLS] mary tries to not meet mary. [SEP]']
[ 750/2000] tot_loss=1.228 (perp=5.633, rec=0.100, cos=0.002), tot_loss_proj:2.999 [t=0.17s]
prediction: ['[CLS] mary tries to not meet mary. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.212 (perp=5.633, rec=0.084, cos=0.002), tot_loss_proj:2.995 [t=0.17s]
prediction: ['[CLS] mary tries to not meet mary. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.299 (perp=6.036, rec=0.090, cos=0.002), tot_loss_proj:2.938 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
[ 900/2000] tot_loss=1.286 (perp=6.036, rec=0.077, cos=0.002), tot_loss_proj:2.936 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.296 (perp=6.036, rec=0.087, cos=0.002), tot_loss_proj:2.938 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.297 (perp=6.036, rec=0.088, cos=0.002), tot_loss_proj:2.925 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
[1050/2000] tot_loss=1.293 (perp=6.036, rec=0.084, cos=0.002), tot_loss_proj:2.931 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.301 (perp=6.036, rec=0.092, cos=0.002), tot_loss_proj:2.932 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.290 (perp=6.036, rec=0.081, cos=0.002), tot_loss_proj:2.935 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
[1200/2000] tot_loss=1.291 (perp=6.036, rec=0.082, cos=0.002), tot_loss_proj:2.931 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.288 (perp=6.036, rec=0.079, cos=0.002), tot_loss_proj:2.938 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.299 (perp=6.036, rec=0.090, cos=0.002), tot_loss_proj:2.943 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
[1350/2000] tot_loss=1.282 (perp=6.036, rec=0.073, cos=0.002), tot_loss_proj:2.931 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.286 (perp=6.036, rec=0.077, cos=0.002), tot_loss_proj:2.932 [t=0.21s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.289 (perp=6.036, rec=0.080, cos=0.002), tot_loss_proj:2.937 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
[1500/2000] tot_loss=1.286 (perp=6.036, rec=0.077, cos=0.002), tot_loss_proj:2.937 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.292 (perp=6.036, rec=0.083, cos=0.002), tot_loss_proj:2.934 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.270 (perp=6.036, rec=0.061, cos=0.002), tot_loss_proj:2.935 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
[1650/2000] tot_loss=1.288 (perp=6.036, rec=0.079, cos=0.002), tot_loss_proj:2.935 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.293 (perp=6.036, rec=0.084, cos=0.002), tot_loss_proj:2.940 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.281 (perp=6.036, rec=0.072, cos=0.002), tot_loss_proj:2.940 [t=0.22s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
[1800/2000] tot_loss=1.290 (perp=6.036, rec=0.081, cos=0.002), tot_loss_proj:2.934 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.278 (perp=6.036, rec=0.070, cos=0.002), tot_loss_proj:2.938 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.288 (perp=6.036, rec=0.079, cos=0.002), tot_loss_proj:2.934 [t=0.18s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
[1950/2000] tot_loss=1.295 (perp=6.036, rec=0.086, cos=0.002), tot_loss_proj:2.941 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.282 (perp=6.036, rec=0.073, cos=0.002), tot_loss_proj:2.939 [t=0.17s]
prediction: ['[CLS] mary tries to not meet john. [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS] john tries to meet not mary. [SEP]
========================
predicted: 
========================
[CLS] mary tries to not meet john. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 114.286

[Aggregate metrics]:
rouge1     | fm: 85.230 | p: 86.984 | r: 83.536
rouge2     | fm: 44.186 | p: 45.646 | r: 43.010
rougeL     | fm: 73.088 | p: 74.557 | r: 71.686
rougeLsum  | fm: 73.185 | p: 75.000 | r: 71.805
r1fm+r2fm = 129.416

input #8 time: 0:07:07 | total time: 1:06:19


Running input #9 of 100.
reference: 
========================
The unidentified victim was apparently struck during the early morning hours.
========================
average of cosine similarity 0.9994535457719615
highest_index [0]
highest [0.9994535457719615]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  1996, 20293,  6778,  2001,  4593,  4930,  2076,  1996,  2220,
          2851,  2847,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]']
[Init] best rec loss: 0.9761378169059753 for ['[CLS]re took vie one ioc reading triangle willmour just grantedated [SEP]']
[Init] best rec loss: 0.9484792351722717 for ['[CLS]hearted rendition ho [CLS] factor supreme satinating concentrate baseman cent sin [SEP]']
[Init] best rec loss: 0.9337632060050964 for ['[CLS]ivated guests survivalr academie celebrates ultimately? invoked per substrates based [SEP]']
[Init] best rec loss: 0.9280292391777039 for ['[CLS] hair confederation qualify rid ni interchange semifinals colonel keystone pop equilibrium resting [SEP]']
[Init] best rec loss: 0.9025102853775024 for ['[CLS] located sure studio earlier ceased downpot engineering giles best includingtage [SEP]']
[Init] best perm rec loss: 0.8983306884765625 for ['[CLS]pot including engineering sure studio downtage located earlier best ceased giles [SEP]']
[Init] best perm rec loss: 0.8946741223335266 for ['[CLS] engineering studio including down sure giles best ceased locatedtage earlierpot [SEP]']
[Init] best perm rec loss: 0.893314778804779 for ['[CLS] including down bestpot suretage earlier ceased located giles engineering studio [SEP]']
[Init] best perm rec loss: 0.8884896039962769 for ['[CLS] studio sure engineeringpot giles ceased down best including located earliertage [SEP]']
[Init] best perm rec loss: 0.8874890804290771 for ['[CLS] ceased down engineeringpot sure studiotage including best located earlier giles [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.007 (perp=13.378, rec=0.574, cos=0.757), tot_loss_proj:4.476 [t=0.17s]
prediction: ['[CLS] apparentlyjiangerty eachpowered apparently hour bitch during lock during victim [SEP]']
[ 100/2000] tot_loss=4.021 (perp=13.416, rec=0.540, cos=0.798), tot_loss_proj:4.577 [t=0.17s]
prediction: ['[CLS] struck unidentified victim victim rubbing victim hours struck during sparrow during intervened [SEP]']
[ 150/2000] tot_loss=4.043 (perp=13.453, rec=0.435, cos=0.917), tot_loss_proj:4.491 [t=0.17s]
prediction: ['[CLS] struck unidentified victim victim during victim during struck during sparrow untilgie [SEP]']
[ 200/2000] tot_loss=2.474 (perp=11.173, rec=0.224, cos=0.016), tot_loss_proj:4.005 [t=0.17s]
prediction: ['[CLS] apparently unidentified victim victim during victim shortly struck during apparently. was [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.372 (perp=10.899, rec=0.180, cos=0.012), tot_loss_proj:3.944 [t=0.17s]
prediction: ['[CLS] apparently unidentified victim victim at victim during struck during apparently during the [SEP]']
[ 300/2000] tot_loss=2.070 (perp=9.682, rec=0.127, cos=0.007), tot_loss_proj:3.741 [t=0.17s]
prediction: ['[CLS] apparently unidentified victim was at victim during struck during morning during the [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.797 (perp=8.397, rec=0.112, cos=0.005), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] apparently unidentified victim was at the victim during struck hours hours during [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.869 (perp=8.790, rec=0.106, cos=0.005), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] the unidentified victim was during apparently victim during struck morning hours during [SEP]']
[ 450/2000] tot_loss=1.799 (perp=8.495, rec=0.096, cos=0.004), tot_loss_proj:3.492 [t=0.17s]
prediction: ['[CLS] the unidentified victim was. apparently victim during struck morning hours morning [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.841 (perp=8.650, rec=0.106, cos=0.006), tot_loss_proj:3.636 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently victim during struck morning hours morning responsibility [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.787 (perp=8.452, rec=0.093, cos=0.004), tot_loss_proj:3.602 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently victim during struck morning morning hours responsibility [SEP]']
[ 600/2000] tot_loss=1.798 (perp=8.452, rec=0.104, cos=0.004), tot_loss_proj:3.601 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently victim during struck morning morning hours responsibility [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.741 (perp=8.259, rec=0.086, cos=0.004), tot_loss_proj:2.932 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently victim struck during morning morning hours responsibility [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.634 (perp=7.707, rec=0.088, cos=0.004), tot_loss_proj:3.631 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck victim during morning morning hours responsibility [SEP]']
[ 750/2000] tot_loss=1.634 (perp=7.707, rec=0.089, cos=0.004), tot_loss_proj:3.638 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck victim during morning morning hours responsibility [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.588 (perp=7.527, rec=0.079, cos=0.004), tot_loss_proj:3.664 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours responsibility victim [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.599 (perp=7.527, rec=0.090, cos=0.004), tot_loss_proj:3.661 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours responsibility victim [SEP]']
[ 900/2000] tot_loss=1.605 (perp=7.527, rec=0.096, cos=0.004), tot_loss_proj:3.666 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours responsibility victim [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.588 (perp=7.527, rec=0.079, cos=0.003), tot_loss_proj:3.659 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours responsibility victim [SEP]']
Attempt swap
[1000/2000] tot_loss=1.586 (perp=7.527, rec=0.077, cos=0.003), tot_loss_proj:3.658 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours responsibility victim [SEP]']
[1050/2000] tot_loss=1.697 (perp=8.047, rec=0.085, cos=0.003), tot_loss_proj:3.838 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hoursng victim [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.648 (perp=7.743, rec=0.095, cos=0.003), tot_loss_proj:3.517 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.638 (perp=7.743, rec=0.086, cos=0.004), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
[1200/2000] tot_loss=1.642 (perp=7.743, rec=0.090, cos=0.003), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[1250/2000] tot_loss=1.644 (perp=7.743, rec=0.092, cos=0.003), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[1300/2000] tot_loss=1.627 (perp=7.743, rec=0.075, cos=0.003), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
[1350/2000] tot_loss=1.639 (perp=7.743, rec=0.087, cos=0.003), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[1400/2000] tot_loss=1.634 (perp=7.743, rec=0.082, cos=0.003), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[1450/2000] tot_loss=1.633 (perp=7.743, rec=0.081, cos=0.003), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
[1500/2000] tot_loss=1.640 (perp=7.743, rec=0.088, cos=0.003), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[1550/2000] tot_loss=1.634 (perp=7.743, rec=0.082, cos=0.003), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[1600/2000] tot_loss=1.625 (perp=7.743, rec=0.073, cos=0.003), tot_loss_proj:3.512 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
[1650/2000] tot_loss=1.629 (perp=7.743, rec=0.077, cos=0.003), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[1700/2000] tot_loss=1.632 (perp=7.743, rec=0.080, cos=0.003), tot_loss_proj:3.511 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[1750/2000] tot_loss=1.635 (perp=7.743, rec=0.083, cos=0.003), tot_loss_proj:3.508 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
[1800/2000] tot_loss=1.638 (perp=7.743, rec=0.086, cos=0.003), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[1850/2000] tot_loss=1.631 (perp=7.743, rec=0.079, cos=0.003), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[1900/2000] tot_loss=1.630 (perp=7.743, rec=0.078, cos=0.003), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
[1950/2000] tot_loss=1.642 (perp=7.743, rec=0.090, cos=0.003), tot_loss_proj:3.511 [t=0.17s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Attempt swap
[2000/2000] tot_loss=1.633 (perp=7.743, rec=0.081, cos=0.003), tot_loss_proj:3.503 [t=0.19s]
prediction: ['[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]
========================
predicted: 
========================
[CLS] the unidentified victim was apparently struck during morning morning hours victimng [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 84.615 | r: 84.615
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 84.615 | p: 84.615 | r: 84.615
rougeLsum  | fm: 84.615 | p: 84.615 | r: 84.615
r1fm+r2fm = 151.282

[Aggregate metrics]:
rouge1     | fm: 85.158 | p: 86.627 | r: 83.747
rouge2     | fm: 46.509 | p: 47.395 | r: 45.462
rougeL     | fm: 74.173 | p: 75.508 | r: 72.990
rougeLsum  | fm: 74.546 | p: 76.059 | r: 73.339
r1fm+r2fm = 131.667

input #9 time: 0:07:04 | total time: 1:13:23


Running input #10 of 100.
reference: 
========================
the logs piled the barge high.
========================
average of cosine similarity 0.9992999377037376
highest_index [0]
highest [0.9992999377037376]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996, 15664, 17835,  1996, 19398,  2152,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the logs piled the barge high. [SEP]']
[Init] best rec loss: 0.8238058090209961 for ['[CLS] my honey queensus suchbble [CLS] [SEP]']
[Init] best rec loss: 0.8123701214790344 for ['[CLS] shots acheron outsider associations seed an using [SEP]']
[Init] best rec loss: 0.8053205609321594 for ['[CLS] papua sorrow arden [MASK] provides sidri [SEP]']
[Init] best rec loss: 0.7905997037887573 for ['[CLS] caps noises imagery amateur recordislaus dismiss [SEP]']
[Init] best rec loss: 0.7373385429382324 for ['[CLS] wonders "elling 1936 recreation ezio outside [SEP]']
[Init] best rec loss: 0.6996959447860718 for ['[CLS] excellence stationary bread otherwise heel least least [SEP]']
[Init] best rec loss: 0.6952798366546631 for ['[CLS] two藤 organizationsworld pot suffered dishes [SEP]']
[Init] best perm rec loss: 0.6888568997383118 for ['[CLS]藤 dishes pot organizationsworld suffered two [SEP]']
[Init] best perm rec loss: 0.6883973479270935 for ['[CLS]藤 dishesworld pot suffered two organizations [SEP]']
[Init] best perm rec loss: 0.6876150369644165 for ['[CLS] organizations dishes potworld two suffered藤 [SEP]']
[Init] best perm rec loss: 0.6853832602500916 for ['[CLS] pot dishes藤world two suffered organizations [SEP]']
[Init] best perm rec loss: 0.6847565174102783 for ['[CLS]藤 dishes organizations potworld two suffered [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.753 (perp=12.029, rec=0.326, cos=0.021), tot_loss_proj:3.465 [t=0.22s]
prediction: ['[CLS] duke gear john railway. participated swedish [SEP]']
[ 100/2000] tot_loss=2.806 (perp=12.691, rec=0.258, cos=0.011), tot_loss_proj:3.856 [t=0.17s]
prediction: ['[CLS] logs piled arizona hu. piled heavy [SEP]']
[ 150/2000] tot_loss=2.470 (perp=11.328, rec=0.197, cos=0.008), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS] logs logs the barge. piled piled [SEP]']
[ 200/2000] tot_loss=2.398 (perp=11.223, rec=0.148, cos=0.005), tot_loss_proj:3.740 [t=0.17s]
prediction: ['[CLS] logs logs the barge high piled high [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.011 (perp=9.161, rec=0.170, cos=0.009), tot_loss_proj:3.677 [t=0.17s]
prediction: ['[CLS] high logs the barge logs piled high [SEP]']
[ 300/2000] tot_loss=1.963 (perp=9.217, rec=0.116, cos=0.004), tot_loss_proj:3.735 [t=0.17s]
prediction: ['[CLS]. logs the barge logs piled high [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.076 (perp=9.789, rec=0.114, cos=0.004), tot_loss_proj:3.825 [t=0.17s]
prediction: ['[CLS] logs high the barge logs piled high [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.932 (perp=9.161, rec=0.097, cos=0.004), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] high logs the barge logs piled high [SEP]']
[ 450/2000] tot_loss=1.942 (perp=9.217, rec=0.096, cos=0.003), tot_loss_proj:3.730 [t=0.19s]
prediction: ['[CLS]. logs the barge logs piled high [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.860 (perp=8.795, rec=0.097, cos=0.003), tot_loss_proj:3.685 [t=0.18s]
prediction: ['[CLS] logs. the barge logs piled high [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.690 (perp=7.760, rec=0.133, cos=0.005), tot_loss_proj:3.475 [t=0.18s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[ 600/2000] tot_loss=1.658 (perp=7.760, rec=0.103, cos=0.003), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.647 (perp=7.760, rec=0.092, cos=0.003), tot_loss_proj:3.469 [t=0.18s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.648 (perp=7.760, rec=0.094, cos=0.003), tot_loss_proj:3.473 [t=0.18s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[ 750/2000] tot_loss=1.644 (perp=7.760, rec=0.089, cos=0.003), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.650 (perp=7.760, rec=0.095, cos=0.003), tot_loss_proj:3.475 [t=0.19s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.649 (perp=7.760, rec=0.094, cos=0.002), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[ 900/2000] tot_loss=1.640 (perp=7.760, rec=0.085, cos=0.002), tot_loss_proj:3.477 [t=0.18s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.648 (perp=7.760, rec=0.093, cos=0.002), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1000/2000] tot_loss=1.654 (perp=7.760, rec=0.100, cos=0.002), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
[1050/2000] tot_loss=1.638 (perp=7.760, rec=0.084, cos=0.002), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1100/2000] tot_loss=1.635 (perp=7.760, rec=0.080, cos=0.002), tot_loss_proj:3.476 [t=0.21s]
prediction: ['[CLS] barge logs. the logs piled high [SEP]']
Attempt swap
[1150/2000] tot_loss=1.888 (perp=8.948, rec=0.097, cos=0.002), tot_loss_proj:3.775 [t=0.17s]
prediction: ['[CLS] barge logs. the cookie piled high [SEP]']
[1200/2000] tot_loss=1.897 (perp=8.948, rec=0.105, cos=0.002), tot_loss_proj:3.771 [t=0.17s]
prediction: ['[CLS] barge logs. the cookie piled high [SEP]']
Attempt swap
[1250/2000] tot_loss=1.878 (perp=8.948, rec=0.086, cos=0.002), tot_loss_proj:3.768 [t=0.17s]
prediction: ['[CLS] barge logs. the cookie piled high [SEP]']
Attempt swap
[1300/2000] tot_loss=1.880 (perp=8.948, rec=0.088, cos=0.002), tot_loss_proj:3.775 [t=0.17s]
prediction: ['[CLS] barge logs. the cookie piled high [SEP]']
[1350/2000] tot_loss=1.884 (perp=8.948, rec=0.092, cos=0.002), tot_loss_proj:3.772 [t=0.17s]
prediction: ['[CLS] barge logs. the cookie piled high [SEP]']
Attempt swap
[1400/2000] tot_loss=1.887 (perp=8.948, rec=0.095, cos=0.002), tot_loss_proj:3.774 [t=0.17s]
prediction: ['[CLS] barge logs. the cookie piled high [SEP]']
Attempt swap
[1450/2000] tot_loss=1.914 (perp=9.112, rec=0.089, cos=0.002), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] barge logs. the. piled high [SEP]']
[1500/2000] tot_loss=1.919 (perp=9.112, rec=0.095, cos=0.002), tot_loss_proj:3.524 [t=0.17s]
prediction: ['[CLS] barge logs. the. piled high [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.720 (perp=8.107, rec=0.096, cos=0.002), tot_loss_proj:3.423 [t=0.17s]
prediction: ['[CLS] barge logs.. the piled high [SEP]']
Attempt swap
[1600/2000] tot_loss=1.720 (perp=8.107, rec=0.096, cos=0.002), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS] barge logs.. the piled high [SEP]']
[1650/2000] tot_loss=1.709 (perp=8.107, rec=0.086, cos=0.002), tot_loss_proj:3.421 [t=0.17s]
prediction: ['[CLS] barge logs.. the piled high [SEP]']
Attempt swap
[1700/2000] tot_loss=1.704 (perp=8.107, rec=0.080, cos=0.002), tot_loss_proj:3.425 [t=0.17s]
prediction: ['[CLS] barge logs.. the piled high [SEP]']
Attempt swap
[1750/2000] tot_loss=1.702 (perp=8.107, rec=0.078, cos=0.002), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] barge logs.. the piled high [SEP]']
[1800/2000] tot_loss=1.706 (perp=8.107, rec=0.083, cos=0.002), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS] barge logs.. the piled high [SEP]']
Attempt swap
[1850/2000] tot_loss=1.692 (perp=8.107, rec=0.068, cos=0.002), tot_loss_proj:3.421 [t=0.17s]
prediction: ['[CLS] barge logs.. the piled high [SEP]']
Attempt swap
[1900/2000] tot_loss=1.707 (perp=8.107, rec=0.083, cos=0.002), tot_loss_proj:3.420 [t=0.17s]
prediction: ['[CLS] barge logs.. the piled high [SEP]']
[1950/2000] tot_loss=1.713 (perp=8.107, rec=0.089, cos=0.002), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] barge logs.. the piled high [SEP]']
Attempt swap
[2000/2000] tot_loss=1.702 (perp=8.107, rec=0.078, cos=0.002), tot_loss_proj:3.426 [t=0.17s]
prediction: ['[CLS] barge logs.. the piled high [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] the logs piled the barge high. [SEP]
========================
predicted: 
========================
[CLS] barge logs.. the piled high [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 100.000 | r: 87.500
rouge2     | fm: 15.385 | p: 16.667 | r: 14.286
rougeL     | fm: 66.667 | p: 71.429 | r: 62.500
rougeLsum  | fm: 66.667 | p: 71.429 | r: 62.500
r1fm+r2fm = 108.718

[Aggregate metrics]:
rouge1     | fm: 85.694 | p: 87.647 | r: 83.943
rouge2     | fm: 43.428 | p: 44.322 | r: 42.482
rougeL     | fm: 73.748 | p: 75.488 | r: 72.053
rougeLsum  | fm: 73.728 | p: 75.490 | r: 72.244
r1fm+r2fm = 129.122

input #10 time: 0:07:05 | total time: 1:20:29


Running input #11 of 100.
reference: 
========================
During the early evening, Saturn can be found in the north, while Jupiter rises in the east.
========================
average of cosine similarity 0.9993928571086103
highest_index [0]
highest [0.9993928571086103]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2076,  1996,  2220,  3944,  1010, 14784,  2064,  2022,  2179,
          1999,  1996,  2167,  1010,  2096, 13035,  9466,  1999,  1996,  2264,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]']
[Init] best rec loss: 0.9603642225265503 for ['[CLS] triedya radcliffe whitney pepper since only ranges beingshibreaker sharedpower kn bn nest o day you detention [SEP]']
[Init] best rec loss: 0.9419578313827515 for ['[CLS] degreess become panted eric like there ⟩nt obeyed gwen supernatural living mexicanard consider launch due griffin block [SEP]']
[Init] best rec loss: 0.9289517998695374 for ['[CLS] poster round around globe magic cameo occupation bash label ever mtv unknownh fund ₹ school famous skillsmat sham [SEP]']
[Init] best rec loss: 0.9151187539100647 for ['[CLS] looks neither sold transportperationum after winning wade laying co licked deep lea bramont mia absentrosis pub [SEP]']
[Init] best rec loss: 0.9120637774467468 for ['[CLS] brands anyway society m founding \\ whichptive dating pop vol days contraction planes moses cooling... scrap warning just [SEP]']
[Init] best rec loss: 0.9037604928016663 for ['[CLS] il [SEP] of ny processes tour madam enchanted woody due hurt free red while studio ever arun beethoven double interval [SEP]']
[Init] best rec loss: 0.900558352470398 for ['[CLS] compared candle sha real cell renacing vigor weight moon chain sweetness amateur strength ad swallow dust northern [SEP] lower [SEP]']
[Init] best rec loss: 0.896977961063385 for ['[CLS] desk nectar parts rpm universallypressed up south davey estimated height advocate heart customary all circular bryson events pan strung [SEP]']
[Init] best rec loss: 0.8925879001617432 for ['[CLS] town performggles ratio property nephew headedta va exilepress executives cleared charm those queen sweat during [SEP] up [SEP]']
[Init] best perm rec loss: 0.8912792801856995 for ['[CLS] charm executivespress town up nephew vaggles property queen exile those during [SEP] perform clearedta headed sweat ratio [SEP]']
[Init] best perm rec loss: 0.890846848487854 for ['[CLS] queen during nephew those exile perform [SEP] va property up ratio executives charm town headedtaggles sweat clearedpress [SEP]']
[Init] best perm rec loss: 0.8906643390655518 for ['[CLS] ratio charmta exile va sweat during those perform headed cleared town nephew queen up propertyggles executives [SEP]press [SEP]']
[Init] best perm rec loss: 0.8884612917900085 for ['[CLS] during sweat town ratio queenggles exile executives those nephew headed performta property charm va uppress cleared [SEP] [SEP]']
[Init] best perm rec loss: 0.8880924582481384 for ['[CLS] [SEP]ta exile ratiopress va charm up nephew property duringggles sweat cleared headed queen those town perform executives [SEP]']
[Init] best perm rec loss: 0.887862503528595 for ['[CLS] charm exile cleared nephewggles during town executives perform queen [SEP] propertypress vata those up sweat headed ratio [SEP]']
[Init] best perm rec loss: 0.8877741694450378 for ['[CLS] headed [SEP] exile property up those charm during cleared perform queen sweatggles nephewta va town ratio executivespress [SEP]']
[Init] best perm rec loss: 0.8856097459793091 for ['[CLS] sweat va [SEP] nephewggles ratio those exile perform up queen executives charm property clearedpress town headedta during [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.703 (perp=10.660, rec=0.571, cos=1.000), tot_loss_proj:3.936 [t=0.17s]
prediction: ['[CLS] on i colony in locals get about easternscreen party largest ) thus " initial affect organisations including river fumble [SEP]']
[ 100/2000] tot_loss=3.418 (perp=9.764, rec=0.465, cos=1.000), tot_loss_proj:3.753 [t=0.18s]
prediction: ['[CLS] during help evening during arrival get while eastscreen prize is ) east. morning., major river before [SEP]']
[ 150/2000] tot_loss=3.584 (perp=10.688, rec=0.447, cos=0.999), tot_loss_proj:3.937 [t=0.18s]
prediction: ['[CLS] during jupiter evening in spent growing while east enjoy cluster or ) east the morning. considered. saturn ancient [SEP]']
[ 200/2000] tot_loss=3.346 (perp=9.773, rec=0.393, cos=0.999), tot_loss_proj:3.794 [t=0.19s]
prediction: ['[CLS] during saturn evening during spent growing while east jupiter cluster or ) east the morning ( considered. saturn jupiter [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.697 (perp=11.392, rec=0.419, cos=1.000), tot_loss_proj:4.145 [t=0.18s]
prediction: ['[CLS] during saturn evening during thus headquarters while east jupiter or ) east the morning ( considered charity lucky saturn jupiter [SEP]']
[ 300/2000] tot_loss=3.287 (perp=9.626, rec=0.365, cos=0.997), tot_loss_proj:3.791 [t=0.18s]
prediction: ['[CLS] during saturn evening the thus headquarters while east jupiter rises ) east the morning (, charity. evening jupiter [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.328 (perp=9.883, rec=0.357, cos=0.994), tot_loss_proj:3.841 [t=0.18s]
prediction: ['[CLS] during the evening the arrival headquarters while east jupiter than ) jupiter saturn evening (, charity. evening jupiter [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.112 (perp=8.917, rec=0.352, cos=0.976), tot_loss_proj:3.747 [t=0.18s]
prediction: ['[CLS] during the evening the arrival jupiter while east jupiter rises ) headquarters saturn evening (, doublehetic evening jupiter [SEP]']
[ 450/2000] tot_loss=3.107 (perp=9.341, rec=0.332, cos=0.907), tot_loss_proj:3.736 [t=0.18s]
prediction: ['[CLS] during the evening the arrival jupiter while east jupiter than. headquarters saturn evening (, doublehetic evening jupiter [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.544 (perp=11.177, rec=0.266, cos=0.043), tot_loss_proj:4.105 [t=0.21s]
prediction: ['[CLS] during the evening the simone jupiter when systems jupiter than ) published saturn evening morningnessyhetic, evening jupiter [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.111 (perp=9.471, rec=0.202, cos=0.015), tot_loss_proj:3.777 [t=0.19s]
prediction: ['[CLS] during the evening the saturn jupiter when systems jupiter while while published, evening morningnessy. saturn evening jupiter [SEP]']
[ 600/2000] tot_loss=1.890 (perp=8.497, rec=0.180, cos=0.011), tot_loss_proj:3.558 [t=0.19s]
prediction: ['[CLS] during the evening the saturn jupiter when north appears while while published, evening morning early. saturn evening jupiter [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.720 (perp=7.726, rec=0.166, cos=0.009), tot_loss_proj:3.424 [t=0.18s]
prediction: ['[CLS] during the evening the saturn jupiter when north appears while while published early, early morning. saturn evening jupiter [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.757 (perp=7.907, rec=0.166, cos=0.009), tot_loss_proj:3.449 [t=0.18s]
prediction: ['[CLS] during the evening the saturn jupiter while north appeared while while published early, early. morning saturn evening jupiter [SEP]']
[ 750/2000] tot_loss=1.858 (perp=8.501, rec=0.151, cos=0.008), tot_loss_proj:3.534 [t=0.18s]
prediction: ['[CLS] during the rises the saturn jupiter while north appeared while while published just, early. morning saturn evening jupiter [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.725 (perp=7.757, rec=0.167, cos=0.007), tot_loss_proj:3.350 [t=0.18s]
prediction: ['[CLS] during the rises the saturn north while north appeared while while published just, early jupiter when saturn evening. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.666 (perp=7.489, rec=0.160, cos=0.009), tot_loss_proj:3.289 [t=0.18s]
prediction: ['[CLS] during the rises the saturn jupiter while north appeared, while published just while early jupiter when saturn evening. [SEP]']
[ 900/2000] tot_loss=1.608 (perp=7.263, rec=0.148, cos=0.007), tot_loss_proj:3.254 [t=0.18s]
prediction: ['[CLS] during the rises the saturn north when north appeared, while published just while early jupiter. saturn evening. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.541 (perp=6.926, rec=0.150, cos=0.006), tot_loss_proj:3.192 [t=0.18s]
prediction: ['[CLS] during the rises the north saturn, north appeared, while published just while early jupiter. saturn evening. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.513 (perp=6.804, rec=0.147, cos=0.005), tot_loss_proj:3.179 [t=0.18s]
prediction: ['[CLS] during the rises the north, saturn north appeared, while published just while early jupiter. saturn evening. [SEP]']
[1050/2000] tot_loss=1.503 (perp=6.804, rec=0.137, cos=0.005), tot_loss_proj:3.176 [t=0.18s]
prediction: ['[CLS] during the rises the north, saturn north appeared, while published just while early jupiter. saturn evening. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.482 (perp=6.690, rec=0.139, cos=0.005), tot_loss_proj:3.161 [t=0.18s]
prediction: ['[CLS] during the rises the north, north saturn appeared, while published just while early jupiter. saturn evening. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.467 (perp=6.555, rec=0.149, cos=0.006), tot_loss_proj:3.171 [t=0.18s]
prediction: ['[CLS] during the rises the north, north while saturn appeared, published just while early jupiter. saturn evening. [SEP]']
[1200/2000] tot_loss=1.453 (perp=6.555, rec=0.137, cos=0.005), tot_loss_proj:3.176 [t=0.18s]
prediction: ['[CLS] during the rises the north, north while saturn appeared, published just while early jupiter. saturn evening. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.046, rec=0.136, cos=0.005), tot_loss_proj:3.231 [t=0.18s]
prediction: ['[CLS] during the rises the north, north while saturn found, published just while early jupiter. saturn evening. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.503 (perp=6.816, rec=0.134, cos=0.005), tot_loss_proj:3.192 [t=0.18s]
prediction: ['[CLS] during the rises the north, while north saturn found, published just while early jupiter. saturn evening. [SEP]']
[1350/2000] tot_loss=1.500 (perp=6.816, rec=0.132, cos=0.005), tot_loss_proj:3.188 [t=0.18s]
prediction: ['[CLS] during the rises the north, while north saturn found, published just while early jupiter. saturn evening. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.475 (perp=6.687, rec=0.133, cos=0.005), tot_loss_proj:3.161 [t=0.18s]
prediction: ['[CLS] during the rises the north, while found saturn north, published just while early jupiter. saturn evening. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.437 (perp=6.501, rec=0.133, cos=0.004), tot_loss_proj:3.185 [t=0.18s]
prediction: ['[CLS] during the rises the north, while north found saturn, published just while early jupiter. saturn evening. [SEP]']
[1500/2000] tot_loss=1.443 (perp=6.501, rec=0.139, cos=0.004), tot_loss_proj:3.190 [t=0.18s]
prediction: ['[CLS] during the rises the north, while north found saturn, published just while early jupiter. saturn evening. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.415 (perp=6.381, rec=0.135, cos=0.004), tot_loss_proj:3.182 [t=0.18s]
prediction: ['[CLS] during the rises the north, while north found saturn, published just while early evening. saturn jupiter. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.397 (perp=6.381, rec=0.116, cos=0.004), tot_loss_proj:3.176 [t=0.18s]
prediction: ['[CLS] during the rises the north, while north found saturn, published just while early evening. saturn jupiter. [SEP]']
[1650/2000] tot_loss=1.414 (perp=6.381, rec=0.134, cos=0.004), tot_loss_proj:3.179 [t=0.18s]
prediction: ['[CLS] during the rises the north, while north found saturn, published just while early evening. saturn jupiter. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.408 (perp=6.381, rec=0.127, cos=0.004), tot_loss_proj:3.178 [t=0.18s]
prediction: ['[CLS] during the rises the north, while north found saturn, published just while early evening. saturn jupiter. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.406 (perp=6.381, rec=0.126, cos=0.004), tot_loss_proj:3.182 [t=0.18s]
prediction: ['[CLS] during the rises the north, while north found saturn, published just while early evening. saturn jupiter. [SEP]']
[1800/2000] tot_loss=1.409 (perp=6.381, rec=0.129, cos=0.004), tot_loss_proj:3.178 [t=0.18s]
prediction: ['[CLS] during the rises the north, while north found saturn, published just while early evening. saturn jupiter. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.420 (perp=6.495, rec=0.117, cos=0.004), tot_loss_proj:3.203 [t=0.18s]
prediction: ['[CLS] during the rises the east, while north found saturn, published just while early evening. saturn jupiter. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.431 (perp=6.473, rec=0.132, cos=0.005), tot_loss_proj:3.203 [t=0.18s]
prediction: ['[CLS] during the rises the east, while jupiter found saturn, published just while early evening. saturn north. [SEP]']
[1950/2000] tot_loss=1.431 (perp=6.473, rec=0.132, cos=0.004), tot_loss_proj:3.196 [t=0.18s]
prediction: ['[CLS] during the rises the east, while jupiter found saturn, published just while early evening. saturn north. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.429 (perp=6.473, rec=0.131, cos=0.004), tot_loss_proj:3.195 [t=0.18s]
prediction: ['[CLS] during the rises the east, while jupiter found saturn, published just while early evening. saturn north. [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]
========================
predicted: 
========================
[CLS] during the rises the east, while jupiter found saturn, published just while early evening. saturn north. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.676 | p: 77.778 | r: 73.684
rouge2     | fm: 34.286 | p: 35.294 | r: 33.333
rougeL     | fm: 43.243 | p: 44.444 | r: 42.105
rougeLsum  | fm: 43.243 | p: 44.444 | r: 42.105
r1fm+r2fm = 109.961

[Aggregate metrics]:
rouge1     | fm: 85.086 | p: 86.990 | r: 83.383
rouge2     | fm: 43.070 | p: 44.019 | r: 42.004
rougeL     | fm: 70.839 | p: 72.655 | r: 69.396
rougeLsum  | fm: 70.978 | p: 72.643 | r: 69.629
r1fm+r2fm = 128.156

input #11 time: 0:07:15 | total time: 1:27:44


Running input #12 of 100.
reference: 
========================
He walked up the hill.
========================
average of cosine similarity 0.9993584436723262
highest_index [0]
highest [0.9993584436723262]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2002, 2939, 2039, 1996, 2940, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he walked up the hill. [SEP]']
[Init] best rec loss: 1.0273795127868652 for ['[CLS] stars sans january canvas gdansk beauty [SEP]']
[Init] best rec loss: 0.9705166220664978 for ['[CLS]thevert banks councillors respective puerto [SEP]']
[Init] best rec loss: 0.9683748483657837 for ['[CLS] articles gin keen monster plot baldwin [SEP]']
[Init] best rec loss: 0.9440220594406128 for ['[CLS] probably block tilt cavesree elevation [SEP]']
[Init] best rec loss: 0.9418670535087585 for ['[CLS] careers jewish drain blockade eternity instrument [SEP]']
[Init] best rec loss: 0.9177175164222717 for ['[CLS] untou culture conferencesea display [SEP]']
[Init] best rec loss: 0.9150117039680481 for ['[CLS] progress preyersonctum cable language [SEP]']
[Init] best rec loss: 0.8984030485153198 for ['[CLS] equal successronegizing stock hana [SEP]']
[Init] best perm rec loss: 0.8943411111831665 for ['[CLS]gizing stockrone success hana equal [SEP]']
[Init] best perm rec loss: 0.8935002684593201 for ['[CLS] success stock hanaronegizing equal [SEP]']
[Init] best perm rec loss: 0.8928298950195312 for ['[CLS]ronegizing hana stock success equal [SEP]']
[Init] best perm rec loss: 0.8927457928657532 for ['[CLS] successrone stock hana equalgizing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.985 (perp=12.465, rec=0.634, cos=0.858), tot_loss_proj:4.384 [t=0.17s]
prediction: ['[CLS]fell walked a jalan aerialhang [SEP]']
[ 100/2000] tot_loss=3.170 (perp=8.526, rec=0.548, cos=0.917), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] thee walked a hill she keep [SEP]']
[ 150/2000] tot_loss=1.828 (perp=8.095, rec=0.192, cos=0.018), tot_loss_proj:3.332 [t=0.17s]
prediction: ['[CLS] me walked the hill he hill [SEP]']
[ 200/2000] tot_loss=1.807 (perp=8.300, rec=0.138, cos=0.009), tot_loss_proj:3.431 [t=0.17s]
prediction: ['[CLS] up walked the hill he hill [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.686 (perp=7.756, rec=0.128, cos=0.007), tot_loss_proj:3.496 [t=0.17s]
prediction: ['[CLS] up he walked up hill keep [SEP]']
[ 300/2000] tot_loss=1.305 (perp=5.879, rec=0.123, cos=0.006), tot_loss_proj:2.615 [t=0.17s]
prediction: ['[CLS]. he walked up hill. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.283 (perp=5.879, rec=0.102, cos=0.005), tot_loss_proj:2.630 [t=0.17s]
prediction: ['[CLS]. he walked up hill. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.282 (perp=5.879, rec=0.101, cos=0.005), tot_loss_proj:2.644 [t=0.17s]
prediction: ['[CLS]. he walked up hill. [SEP]']
[ 450/2000] tot_loss=1.282 (perp=5.879, rec=0.102, cos=0.005), tot_loss_proj:2.656 [t=0.17s]
prediction: ['[CLS]. he walked up hill. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.286 (perp=5.879, rec=0.105, cos=0.004), tot_loss_proj:2.682 [t=0.17s]
prediction: ['[CLS]. he walked up hill. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.275 (perp=5.879, rec=0.095, cos=0.004), tot_loss_proj:2.697 [t=0.17s]
prediction: ['[CLS]. he walked up hill. [SEP]']
[ 600/2000] tot_loss=1.274 (perp=5.879, rec=0.094, cos=0.004), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS]. he walked up hill. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.274 (perp=5.879, rec=0.094, cos=0.004), tot_loss_proj:2.748 [t=0.17s]
prediction: ['[CLS]. he walked up hill. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.275 (perp=5.879, rec=0.095, cos=0.004), tot_loss_proj:2.765 [t=0.17s]
prediction: ['[CLS]. he walked up hill. [SEP]']
[ 750/2000] tot_loss=1.273 (perp=5.879, rec=0.093, cos=0.004), tot_loss_proj:2.775 [t=0.17s]
prediction: ['[CLS]. he walked up hill. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.235 (perp=5.687, rec=0.094, cos=0.004), tot_loss_proj:2.843 [t=0.18s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.244 (perp=5.687, rec=0.103, cos=0.004), tot_loss_proj:2.838 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
[ 900/2000] tot_loss=1.225 (perp=5.687, rec=0.084, cos=0.004), tot_loss_proj:2.836 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.231 (perp=5.687, rec=0.090, cos=0.004), tot_loss_proj:2.833 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.234 (perp=5.687, rec=0.093, cos=0.004), tot_loss_proj:2.834 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
[1050/2000] tot_loss=1.236 (perp=5.687, rec=0.095, cos=0.004), tot_loss_proj:2.835 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.238 (perp=5.687, rec=0.097, cos=0.004), tot_loss_proj:2.829 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.240 (perp=5.687, rec=0.098, cos=0.004), tot_loss_proj:2.833 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
[1200/2000] tot_loss=1.228 (perp=5.687, rec=0.087, cos=0.004), tot_loss_proj:2.829 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.221 (perp=5.687, rec=0.080, cos=0.004), tot_loss_proj:2.831 [t=0.18s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.235 (perp=5.687, rec=0.094, cos=0.004), tot_loss_proj:2.825 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
[1350/2000] tot_loss=1.232 (perp=5.687, rec=0.091, cos=0.004), tot_loss_proj:2.825 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.230 (perp=5.687, rec=0.089, cos=0.004), tot_loss_proj:2.830 [t=0.18s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.227 (perp=5.687, rec=0.086, cos=0.004), tot_loss_proj:2.826 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
[1500/2000] tot_loss=1.221 (perp=5.687, rec=0.080, cos=0.004), tot_loss_proj:2.824 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.231 (perp=5.687, rec=0.090, cos=0.004), tot_loss_proj:2.820 [t=0.21s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.231 (perp=5.687, rec=0.090, cos=0.004), tot_loss_proj:2.818 [t=0.19s]
prediction: ['[CLS] the he walked up hill. [SEP]']
[1650/2000] tot_loss=1.229 (perp=5.687, rec=0.088, cos=0.004), tot_loss_proj:2.822 [t=0.19s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.236 (perp=5.687, rec=0.095, cos=0.004), tot_loss_proj:2.819 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.224 (perp=5.687, rec=0.083, cos=0.004), tot_loss_proj:2.823 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
[1800/2000] tot_loss=1.225 (perp=5.687, rec=0.084, cos=0.004), tot_loss_proj:2.820 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.234 (perp=5.687, rec=0.094, cos=0.004), tot_loss_proj:2.825 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.229 (perp=5.687, rec=0.088, cos=0.004), tot_loss_proj:2.821 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
[1950/2000] tot_loss=1.226 (perp=5.687, rec=0.085, cos=0.004), tot_loss_proj:2.822 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.232 (perp=5.687, rec=0.091, cos=0.004), tot_loss_proj:2.823 [t=0.17s]
prediction: ['[CLS] the he walked up hill. [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] he walked up the hill. [SEP]
========================
predicted: 
========================
[CLS] the he walked up hill. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 86.225 | p: 88.148 | r: 84.512
rouge2     | fm: 43.409 | p: 44.355 | r: 42.454
rougeL     | fm: 72.084 | p: 73.858 | r: 70.643
rougeLsum  | fm: 72.203 | p: 73.757 | r: 70.879
r1fm+r2fm = 129.634

input #12 time: 0:07:16 | total time: 1:35:01


Running input #13 of 100.
reference: 
========================
It is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters.
========================
average of cosine similarity 0.9993068673747104
highest_index [0]
highest [0.9993068673747104]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2009,  2003,  2023,  3291,  2008,  1996, 10076,  2017,  9611,
          1996,  2062,  4089,  2017,  1005,  2222, 13225,  1996, 12455,  2039,
          2012,  5971,  4075,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]"]
[Init] best rec loss: 0.9446279406547546 for ['[CLS] id brand fault sciences treated allows american person perceive directions alleyulating pentagonette modern declaration material devoid having participation artistic ricardooration [SEP]']
[Init] best rec loss: 0.8717837929725647 for ['[CLS] independenternussnor beat shelley pattierty better newspapers chanceocation customsdi broke nolanrona tennesseeed drummer worked analog nap [SEP]']
[Init] best rec loss: 0.8676259517669678 for ['[CLS]ge miss west unity homestead usual support starting steady electionseon snoop jamaicagames game bro pen illegal que overland doo new mall [SEP]']
[Init] best perm rec loss: 0.8666638135910034 for ['[CLS] new illegal game miss mall usualgames unity support que jamaica steady pen startingge snoop dooeon homestead bro west elections overland [SEP]']
[Init] best perm rec loss: 0.8617178797721863 for ['[CLS] snoop game support usualge doo homestead quegames steady new illegal west miss unity starting mall bro jamaica overland elections peneon [SEP]']
[Init] best perm rec loss: 0.8612036108970642 for ['[CLS] mall usual illegal que snoop doo electionsge support homestead west unity starting jamaica miss steady new game overland bro pengameseon [SEP]']
[Init] best perm rec loss: 0.8595340251922607 for ['[CLS]games usual miss starting doo homestead bro gamege west steady jamaicaeon illegal support elections new unity que mall snoop overland pen [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.861 (perp=13.308, rec=0.622, cos=0.577), tot_loss_proj:4.612 [t=0.18s]
prediction: ['[CLS] station original want seminary reviews nakanies me intro mini a damon sympathetic program exchangeduced fangs gets your louisiana € la ranger [SEP]']
[ 100/2000] tot_loss=2.564 (perp=10.926, rec=0.334, cos=0.044), tot_loss_proj:4.137 [t=0.18s]
prediction: ['[CLS] bureau future play weekend reviews trouble you wait. requirement a guaranteed： program officer we shortlyshi your personal. corporate [CLS] [SEP]']
[ 150/2000] tot_loss=2.423 (perp=10.578, rec=0.285, cos=0.023), tot_loss_proj:4.043 [t=0.18s]
prediction: ['[CLS] bureau local play situation facilitate trouble you wait. required a guaranteed： problem corporate we fergus dammit your this. corporate. [SEP]']
[ 200/2000] tot_loss=2.272 (perp=10.124, rec=0.239, cos=0.009), tot_loss_proj:3.940 [t=0.18s]
prediction: ['[CLS] problem certain play problem solve trouble you operates. sooner a guaranteeddson problem corporate we meanwhile dammit your vested. corporate. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.168 (perp=9.694, rec=0.220, cos=0.009), tot_loss_proj:3.847 [t=0.18s]
prediction: ['[CLS] problem guys corporate problem solve larger you solve. sooner this youdson problem corporate we eventually dammit your vested. play. [SEP]']
[ 300/2000] tot_loss=2.128 (perp=9.470, rec=0.224, cos=0.010), tot_loss_proj:3.823 [t=0.18s]
prediction: ['[CLS] problem guys corporate problem satisfy is you solve. sooner this immediately on problem folks we would dammit you 戦. eat. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.134 (perp=9.645, rec=0.196, cos=0.009), tot_loss_proj:3.826 [t=0.18s]
prediction: ['[CLS] problem nyc corporate problem. is you solve. sooner this there upon problem folks the easily up on this satisfy eat. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.754 (perp=7.839, rec=0.179, cos=0.007), tot_loss_proj:3.482 [t=0.19s]
prediction: ['[CLS] problem folks corporate problem. is you solve. sooner this there on problem folks the eat up on this satisfy easily. [SEP]']
[ 450/2000] tot_loss=3.515 (perp=9.814, rec=0.654, cos=0.898), tot_loss_proj:3.957 [t=0.18s]
prediction: ['[CLS] problem. corporate problems ( [SEP] you solve. sooner the we next championship team the. exact. this satisfy just [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.973 (perp=9.535, rec=0.537, cos=0.529), tot_loss_proj:3.850 [t=0.18s]
prediction: ['[CLS] problem. corporate problems ( [SEP] you solve. sooner the we captured production team the until exact. this encourages blue animation [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.346 (perp=9.634, rec=0.355, cos=0.065), tot_loss_proj:3.882 [t=0.20s]
prediction: ['[CLS] problem. [SEP] corporatebots ( you solve. sooner the we easy production team the until gene. this encourages 2nd [SEP] [SEP]']
[ 600/2000] tot_loss=2.184 (perp=9.267, rec=0.303, cos=0.027), tot_loss_proj:3.799 [t=0.19s]
prediction: ['[CLS] problem counterpart [SEP] corporate headquarters ( you solve. sooner this we easy problem team the until alright. this encourages 2nd, [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.168 (perp=9.273, rec=0.296, cos=0.018), tot_loss_proj:3.799 [t=0.19s]
prediction: ['[CLS] problem counterpart [SEP] corporate headquarters this ( you solve. sooner we easy problem you the sooner larry. this satisfy 2nd, [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.151 (perp=9.169, rec=0.297, cos=0.020), tot_loss_proj:3.826 [t=0.18s]
prediction: ['[CLS] ( counterpart [SEP] corporate headquarters this problem you solve. sooner your easy problem you the sooner alright. this satisfymorphism, [SEP]']
[ 750/2000] tot_loss=2.112 (perp=9.169, rec=0.266, cos=0.012), tot_loss_proj:3.825 [t=0.18s]
prediction: ['[CLS] ( counterpart [SEP] corporate headquarters this problem you solve. sooner your easy problem you the sooner alright. this satisfymorphism, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.974 (perp=8.542, rec=0.255, cos=0.011), tot_loss_proj:3.660 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate headquarters this problem you solve. you your easy problem sooner the soonerʲ. this satisfymorphism, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.915 (perp=8.290, rec=0.245, cos=0.011), tot_loss_proj:3.606 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate headquarters this problem you solve. you your easy problem sooner the soonerʲ, this satisfymorphism. [SEP]']
[ 900/2000] tot_loss=1.919 (perp=8.303, rec=0.249, cos=0.010), tot_loss_proj:3.594 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate headquarters this problem you solve. you your easy problem sooner the sooner ª, this satisfymorphism. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.937 (perp=8.426, rec=0.242, cos=0.009), tot_loss_proj:3.605 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate headquarters this problem you solve. you your easy problem sooner the sooner ª, satisfy thishered. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.898 (perp=8.225, rec=0.242, cos=0.010), tot_loss_proj:3.561 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate headquarters this problem you solve. this your easy problem sooner the sooner allmusic, satisfy youhered. [SEP]']
[1050/2000] tot_loss=2.020 (perp=8.875, rec=0.236, cos=0.009), tot_loss_proj:3.703 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate folks this problem you solve. this your easy problem sooner the sooner allmusic, satisfy youhered. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.921 (perp=8.359, rec=0.240, cos=0.009), tot_loss_proj:3.616 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate, this problem you solve. this your easy problem sooner the sooner allmusic folks satisfy youhered. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.907 (perp=8.359, rec=0.226, cos=0.009), tot_loss_proj:3.621 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate, this problem you solve. this your easy problem sooner the sooner allmusic folks satisfy youhered. [SEP]']
[1200/2000] tot_loss=1.899 (perp=8.359, rec=0.219, cos=0.008), tot_loss_proj:3.621 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate, this problem you solve. this your easy problem sooner the sooner allmusic folks satisfy youhered. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.899 (perp=8.359, rec=0.220, cos=0.008), tot_loss_proj:3.623 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate, this problem you solve. this your easy problem sooner the sooner allmusic folks satisfy youhered. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.907 (perp=8.359, rec=0.228, cos=0.008), tot_loss_proj:3.621 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate, this problem you solve. this your easy problem sooner the sooner allmusic folks satisfy youhered. [SEP]']
[1350/2000] tot_loss=1.901 (perp=8.359, rec=0.222, cos=0.007), tot_loss_proj:3.618 [t=0.18s]
prediction: ['[CLS] that counterpart [SEP] corporate, this problem you solve. this your easy problem sooner the sooner allmusic folks satisfy youhered. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.876 (perp=8.222, rec=0.224, cos=0.008), tot_loss_proj:3.596 [t=0.18s]
prediction: ['[CLS] that corporate [SEP] counterpart, this problem you solve. this your easy problem sooner the sooner allmusic folks satisfy youhered. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.857 (perp=8.179, rec=0.213, cos=0.008), tot_loss_proj:3.593 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks satisfy youhered. [SEP]']
[1500/2000] tot_loss=1.852 (perp=8.179, rec=0.209, cos=0.007), tot_loss_proj:3.590 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks satisfy youhered. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.843 (perp=8.086, rec=0.219, cos=0.007), tot_loss_proj:3.549 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks you satisfyhered. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.831 (perp=8.028, rec=0.218, cos=0.007), tot_loss_proj:3.543 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks you satisfy ⟨. [SEP]']
[1650/2000] tot_loss=1.824 (perp=8.028, rec=0.211, cos=0.007), tot_loss_proj:3.544 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks you satisfy ⟨. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.814 (perp=8.028, rec=0.201, cos=0.007), tot_loss_proj:3.541 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks you satisfy ⟨. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.823 (perp=8.028, rec=0.211, cos=0.007), tot_loss_proj:3.540 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks you satisfy ⟨. [SEP]']
[1800/2000] tot_loss=1.817 (perp=8.028, rec=0.205, cos=0.007), tot_loss_proj:3.544 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks you satisfy ⟨. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.817 (perp=8.028, rec=0.204, cos=0.007), tot_loss_proj:3.539 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks you satisfy ⟨. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.814 (perp=8.028, rec=0.202, cos=0.007), tot_loss_proj:3.544 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks you satisfy ⟨. [SEP]']
[1950/2000] tot_loss=1.816 (perp=8.028, rec=0.204, cos=0.007), tot_loss_proj:3.540 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks you satisfy ⟨. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.823 (perp=8.028, rec=0.210, cos=0.007), tot_loss_proj:3.543 [t=0.18s]
prediction: ['[CLS] that corporate counterpart [SEP], this problem you solve. this your easy problem sooner the sooner allmusic folks you satisfy ⟨. [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]
========================
predicted: 
========================
[CLS] problem folks corporate problem. is you solve. sooner this there upon problem folks the eat up on this satisfy easily. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.222 | p: 63.636 | r: 60.870
rouge2     | fm: 4.651 | p: 4.762 | r: 4.545
rougeL     | fm: 31.111 | p: 31.818 | r: 30.435
rougeLsum  | fm: 31.111 | p: 31.818 | r: 30.435
r1fm+r2fm = 66.873

[Aggregate metrics]:
rouge1     | fm: 84.307 | p: 86.054 | r: 82.755
rouge2     | fm: 40.374 | p: 41.288 | r: 39.577
rougeL     | fm: 69.210 | p: 70.685 | r: 67.890
rougeLsum  | fm: 69.688 | p: 71.177 | r: 68.358
r1fm+r2fm = 124.682

input #13 time: 0:07:18 | total time: 1:42:19


Running input #14 of 100.
reference: 
========================
Mary has never kissed a man who is taller than John.
========================
average of cosine similarity 0.9993000739577431
highest_index [0]
highest [0.9993000739577431]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2984,  2038,  2196,  4782,  1037,  2158,  2040,  2003, 12283,
          2084,  2198,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mary has never kissed a man who is taller than john. [SEP]']
[Init] best rec loss: 0.9541948437690735 for ['[CLS] isa jude jon force boysraction louise work tip bigger dick sets [SEP]']
[Init] best rec loss: 0.9414898753166199 for ['[CLS]nton integratinglor half inserted al locks cbright family exhibition range [SEP]']
[Init] best rec loss: 0.9376357793807983 for ['[CLS] tar * [SEP] pa jersey efforts partisans miniseries consecrated nominee humans [UNK] [SEP]']
[Init] best rec loss: 0.9275037050247192 for ['[CLS] somewhat high licensed practice story thick septembereira vector bottoms osaka causes [SEP]']
[Init] best rec loss: 0.8851785063743591 for ['[CLS] dimension ser phone visible sv dependent performed unique independence tipped gravity tha [SEP]']
[Init] best rec loss: 0.8732437491416931 for ['[CLS] smart grandderropolis personal drama playback president lest sought producerdened [SEP]']
[Init] best rec loss: 0.8478004932403564 for ['[CLS] claiming dragon hivmerie pace emersonws bandclass how socialist adult [SEP]']
[Init] best perm rec loss: 0.8447031378746033 for ['[CLS] dragon claimingmerie hiv bandclass howws socialist pace adult emerson [SEP]']
[Init] best perm rec loss: 0.836749255657196 for ['[CLS] adult pacemerie dragon hivclass band claiming emerson how socialistws [SEP]']
[Init] best perm rec loss: 0.8359105587005615 for ['[CLS] hiv adult pace dragon band socialistmerieclass how emerson claimingws [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.306 (perp=13.702, rec=0.459, cos=0.107), tot_loss_proj:4.604 [t=0.19s]
prediction: ['[CLS] ryan off brother husbandsef helen stiffened viewers this singhts attraction [SEP]']
[ 100/2000] tot_loss=2.561 (perp=10.843, rec=0.352, cos=0.041), tot_loss_proj:4.057 [t=0.19s]
prediction: ['[CLS] mary orthodox john husband draft helen. ; longest singhnish attraction [SEP]']
[ 150/2000] tot_loss=2.509 (perp=10.740, rec=0.328, cos=0.033), tot_loss_proj:4.017 [t=0.19s]
prediction: ['[CLS] mary doubles john kissed gentleman john. ; been isore attraction [SEP]']
[ 200/2000] tot_loss=2.103 (perp=9.081, rec=0.262, cos=0.025), tot_loss_proj:3.750 [t=0.19s]
prediction: ['[CLS] mary has john kissed gentleman john.. never looked whatsoever understand [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.083 (perp=9.060, rec=0.247, cos=0.025), tot_loss_proj:3.686 [t=0.17s]
prediction: ['[CLS] mary has john kissed kissed john.. never looked whatsoever understand [SEP]']
[ 300/2000] tot_loss=2.067 (perp=9.140, rec=0.220, cos=0.020), tot_loss_proj:3.744 [t=0.19s]
prediction: ['[CLS] mary has john kissed man john.. never kissed has understand [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.046 (perp=9.135, rec=0.204, cos=0.016), tot_loss_proj:3.640 [t=0.17s]
prediction: ['[CLS] mary has john kissed man john.. never kissed hasrell [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.856 (perp=8.037, rec=0.229, cos=0.020), tot_loss_proj:3.581 [t=0.17s]
prediction: ['[CLS] mary has john never looked john.. never man hasrell [SEP]']
[ 450/2000] tot_loss=1.650 (perp=7.277, rec=0.183, cos=0.012), tot_loss_proj:3.421 [t=0.17s]
prediction: ['[CLS] mary has john never kissed john.. never man hasrell [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.759 (perp=7.907, rec=0.168, cos=0.010), tot_loss_proj:3.477 [t=0.27s]
prediction: ['[CLS] mary has john never kissed john.. has man hasrell [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.961 (perp=8.530, rec=0.234, cos=0.021), tot_loss_proj:3.479 [t=0.20s]
prediction: ['[CLS] mary has john never kissed john kissed. someone has much taller [SEP]']
[ 600/2000] tot_loss=1.952 (perp=8.793, rec=0.183, cos=0.011), tot_loss_proj:3.630 [t=0.17s]
prediction: ['[CLS] mary has john never kissed. kissed ; man has much taller [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.837 (perp=8.318, rec=0.164, cos=0.009), tot_loss_proj:3.565 [t=0.17s]
prediction: ['[CLS] mary has john. never kissed kissed ; man has much taller [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.777 (perp=8.026, rec=0.163, cos=0.009), tot_loss_proj:3.492 [t=0.17s]
prediction: ['[CLS] mary has john ; never kissed. man has kissed much taller [SEP]']
[ 750/2000] tot_loss=1.769 (perp=8.026, rec=0.155, cos=0.008), tot_loss_proj:3.492 [t=0.17s]
prediction: ['[CLS] mary has john ; never kissed. man has kissed much taller [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.619 (perp=7.344, rec=0.143, cos=0.008), tot_loss_proj:3.337 [t=0.17s]
prediction: ['[CLS] mary has never kissed. john. man has kissed much taller [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.574 (perp=7.115, rec=0.143, cos=0.008), tot_loss_proj:3.089 [t=0.18s]
prediction: ['[CLS] mary has never kissed.. man john has kissed much taller [SEP]']
[ 900/2000] tot_loss=1.568 (perp=7.115, rec=0.138, cos=0.007), tot_loss_proj:3.090 [t=0.18s]
prediction: ['[CLS] mary has never kissed.. man john has kissed much taller [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.526 (perp=6.894, rec=0.140, cos=0.007), tot_loss_proj:3.147 [t=0.17s]
prediction: ['[CLS] mary has never kissed.. man has kissed john much taller [SEP]']
Attempt swap
[1000/2000] tot_loss=1.519 (perp=6.894, rec=0.134, cos=0.007), tot_loss_proj:3.153 [t=0.17s]
prediction: ['[CLS] mary has never kissed.. man has kissed john much taller [SEP]']
[1050/2000] tot_loss=1.509 (perp=6.894, rec=0.123, cos=0.006), tot_loss_proj:3.150 [t=0.18s]
prediction: ['[CLS] mary has never kissed.. man has kissed john much taller [SEP]']
Attempt swap
[1100/2000] tot_loss=1.518 (perp=6.894, rec=0.133, cos=0.006), tot_loss_proj:3.145 [t=0.23s]
prediction: ['[CLS] mary has never kissed.. man has kissed john much taller [SEP]']
Attempt swap
[1150/2000] tot_loss=1.515 (perp=6.894, rec=0.130, cos=0.006), tot_loss_proj:3.145 [t=0.19s]
prediction: ['[CLS] mary has never kissed.. man has kissed john much taller [SEP]']
[1200/2000] tot_loss=1.513 (perp=6.894, rec=0.128, cos=0.006), tot_loss_proj:3.147 [t=0.19s]
prediction: ['[CLS] mary has never kissed.. man has kissed john much taller [SEP]']
Attempt swap
[1250/2000] tot_loss=1.507 (perp=6.894, rec=0.123, cos=0.006), tot_loss_proj:3.150 [t=0.19s]
prediction: ['[CLS] mary has never kissed.. man has kissed john much taller [SEP]']
Attempt swap
[1300/2000] tot_loss=1.513 (perp=6.894, rec=0.128, cos=0.006), tot_loss_proj:3.152 [t=0.19s]
prediction: ['[CLS] mary has never kissed.. man has kissed john much taller [SEP]']
[1350/2000] tot_loss=1.727 (perp=7.966, rec=0.128, cos=0.006), tot_loss_proj:3.526 [t=0.19s]
prediction: ['[CLS] mary has never kissed than. man has kissed john much taller [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.678 (perp=7.749, rec=0.123, cos=0.006), tot_loss_proj:3.516 [t=0.19s]
prediction: ['[CLS] mary has never kissed man. than has kissed john much taller [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.574 (perp=7.126, rec=0.139, cos=0.010), tot_loss_proj:2.761 [t=0.19s]
prediction: ['[CLS] mary has never kissed man. has kissed john much taller than [SEP]']
[1500/2000] tot_loss=1.493 (perp=6.783, rec=0.130, cos=0.006), tot_loss_proj:2.768 [t=0.19s]
prediction: ['[CLS] mary has never kissed man. has kissed john much taller. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.447 (perp=6.511, rec=0.138, cos=0.006), tot_loss_proj:3.244 [t=0.19s]
prediction: ['[CLS] mary has never kissed. man has. john much taller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.433 (perp=6.511, rec=0.125, cos=0.006), tot_loss_proj:3.245 [t=0.19s]
prediction: ['[CLS] mary has never kissed. man has. john much taller. [SEP]']
[1650/2000] tot_loss=1.424 (perp=6.511, rec=0.116, cos=0.006), tot_loss_proj:3.241 [t=0.19s]
prediction: ['[CLS] mary has never kissed. man has. john much taller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.433 (perp=6.511, rec=0.125, cos=0.006), tot_loss_proj:3.242 [t=0.19s]
prediction: ['[CLS] mary has never kissed. man has. john much taller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.437 (perp=6.511, rec=0.128, cos=0.006), tot_loss_proj:3.247 [t=0.17s]
prediction: ['[CLS] mary has never kissed. man has. john much taller. [SEP]']
[1800/2000] tot_loss=1.431 (perp=6.511, rec=0.123, cos=0.006), tot_loss_proj:3.247 [t=0.18s]
prediction: ['[CLS] mary has never kissed. man has. john much taller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.433 (perp=6.511, rec=0.125, cos=0.006), tot_loss_proj:3.248 [t=0.17s]
prediction: ['[CLS] mary has never kissed. man has. john much taller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.442 (perp=6.511, rec=0.134, cos=0.006), tot_loss_proj:3.247 [t=0.20s]
prediction: ['[CLS] mary has never kissed. man has. john much taller. [SEP]']
[1950/2000] tot_loss=1.435 (perp=6.511, rec=0.127, cos=0.006), tot_loss_proj:3.243 [t=0.19s]
prediction: ['[CLS] mary has never kissed. man has. john much taller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.430 (perp=6.511, rec=0.122, cos=0.006), tot_loss_proj:3.243 [t=0.19s]
prediction: ['[CLS] mary has never kissed. man has. john much taller. [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] mary has never kissed a man who is taller than john. [SEP]
========================
predicted: 
========================
[CLS] mary has never kissed than. man has kissed john much taller [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 76.923 | r: 76.923
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 61.538 | p: 61.538 | r: 61.538
rougeLsum  | fm: 61.538 | p: 61.538 | r: 61.538
r1fm+r2fm = 110.256

[Aggregate metrics]:
rouge1     | fm: 83.747 | p: 85.590 | r: 82.307
rouge2     | fm: 40.007 | p: 40.946 | r: 39.236
rougeL     | fm: 68.595 | p: 69.936 | r: 67.529
rougeLsum  | fm: 68.911 | p: 70.270 | r: 67.688
r1fm+r2fm = 123.754

input #14 time: 0:07:43 | total time: 1:50:03


Running input #15 of 100.
reference: 
========================
After ten soldiers had left, seven more ones came in.
========================
average of cosine similarity 0.9993145518230557
highest_index [0]
highest [0.9993145518230557]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2044, 2702, 3548, 2018, 2187, 1010, 2698, 2062, 3924, 2234, 1999,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] after ten soldiers had left, seven more ones came in. [SEP]']
[Init] best rec loss: 0.9528211951255798 for ['[CLS] war ne soaking kelly moment another carried ahead fk inches chasing deal [SEP]']
[Init] best rec loss: 0.855108380317688 for ['[CLS] clear love instrument patient commentaryhipversder cowboys progression what tens [SEP]']
[Init] best rec loss: 0.75975501537323 for ['[CLS] trainedpower mere exception meeting spokanemin cash vested large myselffish [SEP]']
[Init] best rec loss: 0.741703987121582 for ['[CLS] cared completely serial attestedbria within averageyriagal /vao job [SEP]']
[Init] best rec loss: 0.7361224889755249 for ['[CLS]d club linked bachelor awfe honored after award wu common ~ [SEP]']
[Init] best perm rec loss: 0.7350735068321228 for ['[CLS]fe award wud ~ linked common aw bachelor club after honored [SEP]']
[Init] best perm rec loss: 0.7331072092056274 for ['[CLS] common bachelor clubfe ~ aw award wud after honored linked [SEP]']
[Init] best perm rec loss: 0.7300412654876709 for ['[CLS]d ~fe bachelor aw award honored wu after club linked common [SEP]']
[Init] best perm rec loss: 0.7290026545524597 for ['[CLS] linked honored wu ~ bachelor club afterfe awd common award [SEP]']
[Init] best perm rec loss: 0.728809654712677 for ['[CLS] aw honored linked wu club award bachelor afterd common ~fe [SEP]']
[Init] best perm rec loss: 0.728542149066925 for ['[CLS] clubd linked honored aw wu afterfe ~ common award bachelor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.326 (perp=9.804, rec=0.333, cos=0.032), tot_loss_proj:3.220 [t=0.17s]
prediction: ['[CLS] three four ones saving six more worker four whole softly ones. [SEP]']
[ 100/2000] tot_loss=2.051 (perp=8.897, rec=0.253, cos=0.018), tot_loss_proj:2.900 [t=0.17s]
prediction: ['[CLS] seven ones ones after seven more ones other seven ones ones in [SEP]']
[ 150/2000] tot_loss=1.835 (perp=7.829, rec=0.252, cos=0.017), tot_loss_proj:2.987 [t=0.17s]
prediction: ['[CLS] seven ones in after seven, ones other more ones ones. [SEP]']
[ 200/2000] tot_loss=1.856 (perp=8.240, rec=0.195, cos=0.012), tot_loss_proj:2.725 [t=0.18s]
prediction: ['[CLS] ten ones in after seven, ones soldiers more ones ones. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.283 (perp=9.532, rec=0.339, cos=0.038), tot_loss_proj:2.970 [t=0.17s]
prediction: ['[CLS] ten ones in after seven building, soldiers more ones ones國 [SEP]']
[ 300/2000] tot_loss=1.966 (perp=8.470, rec=0.247, cos=0.025), tot_loss_proj:2.946 [t=0.17s]
prediction: ['[CLS] ten ones in had seven building, four more ones ones ~ [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.684 (perp=7.185, rec=0.225, cos=0.022), tot_loss_proj:2.150 [t=0.18s]
prediction: ['[CLS] ten had seven soldiers in settlement, three more five ones ; [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.844 (perp=7.252, rec=0.351, cos=0.042), tot_loss_proj:2.189 [t=0.18s]
prediction: ['[CLS] ten had seven soldiers in accounts, soldiers more ones five. [SEP]']
[ 450/2000] tot_loss=1.691 (perp=7.010, rec=0.266, cos=0.023), tot_loss_proj:2.183 [t=0.17s]
prediction: ['[CLS] ten had seven soldiers in ones, soldiers more ones seven. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.517 (perp=6.370, rec=0.228, cos=0.015), tot_loss_proj:2.300 [t=0.18s]
prediction: ['[CLS] ten had seven soldiers in ones, seven more ones soldiers. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.464 (perp=6.176, rec=0.217, cos=0.012), tot_loss_proj:2.175 [t=0.17s]
prediction: ['[CLS] ten had seven soldiers in ones, seven more soldiers ones. [SEP]']
[ 600/2000] tot_loss=1.522 (perp=6.594, rec=0.192, cos=0.011), tot_loss_proj:2.431 [t=0.18s]
prediction: ['[CLS] ten had seven soldiers in ones, seven more ones ones. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.501 (perp=6.594, rec=0.172, cos=0.010), tot_loss_proj:2.423 [t=0.17s]
prediction: ['[CLS] ten had seven soldiers in ones, seven more ones ones. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.495 (perp=6.594, rec=0.166, cos=0.010), tot_loss_proj:2.432 [t=0.17s]
prediction: ['[CLS] ten had seven soldiers in ones, seven more ones ones. [SEP]']
[ 750/2000] tot_loss=1.488 (perp=6.594, rec=0.160, cos=0.009), tot_loss_proj:2.430 [t=0.17s]
prediction: ['[CLS] ten had seven soldiers in ones, seven more ones ones. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.504 (perp=6.718, rec=0.151, cos=0.009), tot_loss_proj:2.274 [t=0.17s]
prediction: ['[CLS] ten had soldiers in seven ones, seven more came ones. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.451 (perp=6.421, rec=0.158, cos=0.009), tot_loss_proj:2.457 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more came ones. [SEP]']
[ 900/2000] tot_loss=1.677 (perp=7.589, rec=0.151, cos=0.008), tot_loss_proj:2.888 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more came ones left [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.579 (perp=7.163, rec=0.138, cos=0.008), tot_loss_proj:2.412 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1000/2000] tot_loss=1.573 (perp=7.163, rec=0.133, cos=0.008), tot_loss_proj:2.414 [t=0.17s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
[1050/2000] tot_loss=1.583 (perp=7.163, rec=0.143, cos=0.007), tot_loss_proj:2.411 [t=0.17s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1100/2000] tot_loss=1.571 (perp=7.163, rec=0.132, cos=0.007), tot_loss_proj:2.411 [t=0.17s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1150/2000] tot_loss=1.569 (perp=7.163, rec=0.130, cos=0.007), tot_loss_proj:2.411 [t=0.17s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
[1200/2000] tot_loss=1.563 (perp=7.163, rec=0.124, cos=0.007), tot_loss_proj:2.408 [t=0.17s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1250/2000] tot_loss=1.561 (perp=7.163, rec=0.122, cos=0.007), tot_loss_proj:2.406 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1300/2000] tot_loss=1.564 (perp=7.163, rec=0.125, cos=0.006), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
[1350/2000] tot_loss=1.564 (perp=7.163, rec=0.126, cos=0.006), tot_loss_proj:2.408 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1400/2000] tot_loss=1.561 (perp=7.163, rec=0.122, cos=0.006), tot_loss_proj:2.413 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1450/2000] tot_loss=1.551 (perp=7.163, rec=0.112, cos=0.006), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
[1500/2000] tot_loss=1.562 (perp=7.163, rec=0.124, cos=0.006), tot_loss_proj:2.404 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1550/2000] tot_loss=1.556 (perp=7.163, rec=0.118, cos=0.006), tot_loss_proj:2.408 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1600/2000] tot_loss=1.558 (perp=7.163, rec=0.120, cos=0.006), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
[1650/2000] tot_loss=1.549 (perp=7.163, rec=0.111, cos=0.006), tot_loss_proj:2.403 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1700/2000] tot_loss=1.556 (perp=7.163, rec=0.118, cos=0.005), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1750/2000] tot_loss=1.560 (perp=7.163, rec=0.122, cos=0.005), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
[1800/2000] tot_loss=1.550 (perp=7.163, rec=0.112, cos=0.005), tot_loss_proj:2.404 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1850/2000] tot_loss=1.547 (perp=7.163, rec=0.109, cos=0.005), tot_loss_proj:2.407 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
[1900/2000] tot_loss=1.552 (perp=7.163, rec=0.115, cos=0.005), tot_loss_proj:2.411 [t=0.18s]
prediction: ['[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]']
[1950/2000] tot_loss=1.727 (perp=8.065, rec=0.109, cos=0.005), tot_loss_proj:2.937 [t=0.18s]
prediction: ['[CLS] had after soldiers in seven ones, seven more ones came left [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.554 (perp=7.144, rec=0.121, cos=0.005), tot_loss_proj:2.674 [t=0.18s]
prediction: ['[CLS] after soldiers had in seven ones, seven more ones came left [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] after ten soldiers had left, seven more ones came in. [SEP]
========================
predicted: 
========================
[CLS] had ten soldiers in seven ones, seven more ones came left [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 34.783 | p: 33.333 | r: 36.364
rougeL     | fm: 64.000 | p: 61.538 | r: 66.667
rougeLsum  | fm: 64.000 | p: 61.538 | r: 66.667
r1fm+r2fm = 122.783

[Aggregate metrics]:
rouge1     | fm: 84.249 | p: 85.509 | r: 83.056
rouge2     | fm: 39.727 | p: 40.448 | r: 39.069
rougeL     | fm: 68.284 | p: 69.416 | r: 67.384
rougeLsum  | fm: 68.507 | p: 69.780 | r: 67.533
r1fm+r2fm = 123.976

input #15 time: 0:07:07 | total time: 1:57:10


Running input #16 of 100.
reference: 
========================
Willy is taller than that Bill is is generally believed.
========================
average of cosine similarity 0.9992796327127058
highest_index [0]
highest [0.9992796327127058]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101, 16172,  2003, 12283,  2084,  2008,  3021,  2003,  2003,  3227,
          3373,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] willy is taller than that bill is is generally believed. [SEP]']
[Init] best rec loss: 0.7902119755744934 for ['[CLS] g shared jump inch addition ted poker feel show paul initiative [SEP]']
[Init] best rec loss: 0.739452064037323 for ['[CLS]ette water home campus ceilingblood hillary appeared unfamiliar dead spend [SEP]']
[Init] best rec loss: 0.7369779944419861 for ['[CLS] selection clubs organized us it earl rates colby guardseptive battery [SEP]']
[Init] best rec loss: 0.7346456050872803 for ['[CLS] identified clap ego jurisdiction cop connection term corinne beans probable family [SEP]']
[Init] best rec loss: 0.7262424826622009 for ['[CLS] baysfully occupation volunteers songs andrei punk wheat calls espn erie [SEP]']
[Init] best rec loss: 0.7223520278930664 for ['[CLS] halfway ˢ folkhedblesches trainee itsescor indoor [SEP]']
[Init] best rec loss: 0.7212710976600647 for ['[CLS] behind reconciliation clues eventually indeed genesis king swung西 dec questions [SEP]']
[Init] best rec loss: 0.7075098156929016 for ['[CLS] and molecular beating than driveated become distance baronet mass public [SEP]']
[Init] best rec loss: 0.6890419721603394 for ['[CLS] fashionunt wood freedom finale drake trail incumbent much possibly away [SEP]']
[Init] best perm rec loss: 0.6884592771530151 for ['[CLS] freedomunt possibly wood away much trail incumbent drake fashion finale [SEP]']
[Init] best perm rec loss: 0.6877197623252869 for ['[CLS] possibly freedom trail finale drake fashion much awayunt wood incumbent [SEP]']
[Init] best perm rec loss: 0.6864833831787109 for ['[CLS] freedom possiblyunt wood fashion much incumbent trail away finale drake [SEP]']
[Init] best perm rec loss: 0.6856220960617065 for ['[CLS]unt wood finale fashion incumbent freedom trail away drake much possibly [SEP]']
[Init] best perm rec loss: 0.6856174468994141 for ['[CLS] fashion drake wood much finale possiblyunt trail away freedom incumbent [SEP]']
[Init] best perm rec loss: 0.6853880286216736 for ['[CLS] fashion finale drake away incumbent woodunt trail freedom much possibly [SEP]']
[Init] best perm rec loss: 0.6851638555526733 for ['[CLS] fashion woodunt finale much trail possibly drake incumbent freedom away [SEP]']
[Init] best perm rec loss: 0.6823499798774719 for ['[CLS] trail possibly fashion awayunt wood finale much freedom incumbent drake [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.760 (perp=11.876, rec=0.351, cos=0.034), tot_loss_proj:3.181 [t=0.17s]
prediction: ['[CLS] willy than is is estimated alright or is tim billmeister [SEP]']
[ 100/2000] tot_loss=2.668 (perp=11.927, rec=0.267, cos=0.015), tot_loss_proj:3.320 [t=0.17s]
prediction: ['[CLS] willy than is is vancouver taller is is bill bill is [SEP]']
[ 150/2000] tot_loss=2.365 (perp=10.640, rec=0.225, cos=0.012), tot_loss_proj:3.162 [t=0.17s]
prediction: ['[CLS] willy than is is taller believed is is bill bill. [SEP]']
[ 200/2000] tot_loss=2.138 (perp=9.807, rec=0.165, cos=0.011), tot_loss_proj:3.020 [t=0.17s]
prediction: ['[CLS] willy than that is taller believed is is bill bill. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.925 (perp=8.880, rec=0.142, cos=0.007), tot_loss_proj:2.579 [t=0.17s]
prediction: ['[CLS] willy is taller believed midland than that is bill bill. [SEP]']
[ 300/2000] tot_loss=1.843 (perp=8.670, rec=0.105, cos=0.004), tot_loss_proj:2.662 [t=0.17s]
prediction: ['[CLS] bill is taller believed or than that is generally willy. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.463 (perp=6.758, rec=0.106, cos=0.004), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] bill is taller than believed or that is generally willy. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.439 (perp=6.712, rec=0.094, cos=0.003), tot_loss_proj:2.165 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that or is generally willy. [SEP]']
[ 450/2000] tot_loss=1.429 (perp=6.712, rec=0.084, cos=0.003), tot_loss_proj:2.160 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that or is generally willy. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.519 (perp=7.157, rec=0.085, cos=0.003), tot_loss_proj:2.127 [t=0.19s]
prediction: ['[CLS] bill is taller than believed that " is generally willy. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.415 (perp=6.583, rec=0.095, cos=0.003), tot_loss_proj:2.497 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
[ 600/2000] tot_loss=1.402 (perp=6.583, rec=0.083, cos=0.003), tot_loss_proj:2.475 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.408 (perp=6.583, rec=0.089, cos=0.003), tot_loss_proj:2.473 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.399 (perp=6.583, rec=0.080, cos=0.002), tot_loss_proj:2.468 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
[ 750/2000] tot_loss=1.397 (perp=6.583, rec=0.078, cos=0.002), tot_loss_proj:2.471 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.391 (perp=6.583, rec=0.073, cos=0.002), tot_loss_proj:2.465 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.390 (perp=6.583, rec=0.071, cos=0.002), tot_loss_proj:2.473 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
[ 900/2000] tot_loss=1.399 (perp=6.583, rec=0.080, cos=0.002), tot_loss_proj:2.471 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.397 (perp=6.583, rec=0.078, cos=0.002), tot_loss_proj:2.465 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.402 (perp=6.583, rec=0.084, cos=0.002), tot_loss_proj:2.466 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
[1050/2000] tot_loss=1.394 (perp=6.583, rec=0.075, cos=0.002), tot_loss_proj:2.470 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.396 (perp=6.583, rec=0.077, cos=0.002), tot_loss_proj:2.464 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.393 (perp=6.583, rec=0.075, cos=0.002), tot_loss_proj:2.469 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
[1200/2000] tot_loss=1.397 (perp=6.583, rec=0.078, cos=0.002), tot_loss_proj:2.465 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.393 (perp=6.583, rec=0.074, cos=0.002), tot_loss_proj:2.466 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.394 (perp=6.583, rec=0.075, cos=0.002), tot_loss_proj:2.466 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
[1350/2000] tot_loss=1.390 (perp=6.583, rec=0.072, cos=0.002), tot_loss_proj:2.464 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.393 (perp=6.583, rec=0.075, cos=0.002), tot_loss_proj:2.462 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.402 (perp=6.583, rec=0.084, cos=0.002), tot_loss_proj:2.462 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
[1500/2000] tot_loss=1.404 (perp=6.583, rec=0.085, cos=0.002), tot_loss_proj:2.465 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.394 (perp=6.583, rec=0.075, cos=0.002), tot_loss_proj:2.464 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.392 (perp=6.583, rec=0.073, cos=0.002), tot_loss_proj:2.467 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
[1650/2000] tot_loss=1.394 (perp=6.583, rec=0.075, cos=0.002), tot_loss_proj:2.464 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.382 (perp=6.583, rec=0.063, cos=0.002), tot_loss_proj:2.463 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.385 (perp=6.583, rec=0.067, cos=0.002), tot_loss_proj:2.464 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
[1800/2000] tot_loss=1.392 (perp=6.583, rec=0.073, cos=0.002), tot_loss_proj:2.468 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.394 (perp=6.583, rec=0.075, cos=0.002), tot_loss_proj:2.472 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.387 (perp=6.583, rec=0.069, cos=0.002), tot_loss_proj:2.467 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
[1950/2000] tot_loss=1.397 (perp=6.583, rec=0.078, cos=0.002), tot_loss_proj:2.466 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.399 (perp=6.583, rec=0.080, cos=0.002), tot_loss_proj:2.470 [t=0.17s]
prediction: ['[CLS] bill is taller than believed that willy is generally.. [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] willy is taller than that bill is is generally believed. [SEP]
========================
predicted: 
========================
[CLS] bill is taller than believed that willy is generally.. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 100.000 | r: 91.667
rouge2     | fm: 47.619 | p: 50.000 | r: 45.455
rougeL     | fm: 69.565 | p: 72.727 | r: 66.667
rougeLsum  | fm: 69.565 | p: 72.727 | r: 66.667
r1fm+r2fm = 143.271

[Aggregate metrics]:
rouge1     | fm: 84.586 | p: 86.168 | r: 83.218
rouge2     | fm: 40.257 | p: 41.211 | r: 39.555
rougeL     | fm: 68.414 | p: 69.677 | r: 67.304
rougeLsum  | fm: 68.302 | p: 69.640 | r: 67.150
r1fm+r2fm = 124.844

input #16 time: 0:06:58 | total time: 2:04:09


Running input #17 of 100.
reference: 
========================
José is eating cabbage, and Holly is too.
========================
average of cosine similarity 0.9992581872479298
highest_index [0]
highest [0.9992581872479298]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  4560,  2003,  5983, 28540,  1010,  1998,  9079,  2003,  2205,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] jose is eating cabbage, and holly is too. [SEP]']
[Init] best rec loss: 0.9251716136932373 for ['[CLS] happenedgil revolution parallelsta right finding flag taiwan bella [SEP]']
[Init] best rec loss: 0.9144431352615356 for ['[CLS] no fleet rep chapter what honor fact double team suite [SEP]']
[Init] best rec loss: 0.9132050275802612 for ['[CLS] horse apartment sureɛ movement falls lordient linear college [SEP]']
[Init] best rec loss: 0.8915717005729675 for ['[CLS] adaptation recurring core ( such jersey each committee minor measures [SEP]']
[Init] best perm rec loss: 0.8897882699966431 for ['[CLS] such minor each jersey committee adaptation ( recurring measures core [SEP]']
[Init] best perm rec loss: 0.8891519904136658 for ['[CLS] committee adaptation such core measures jersey ( each recurring minor [SEP]']
[Init] best perm rec loss: 0.8880159854888916 for ['[CLS] adaptation ( committee measures each recurring jersey such core minor [SEP]']
[Init] best perm rec loss: 0.8873059153556824 for ['[CLS] committee adaptation each recurring minor measures core such jersey ( [SEP]']
[Init] best perm rec loss: 0.8865041136741638 for ['[CLS] jersey minor ( adaptation committee each measures recurring core such [SEP]']
[Init] best perm rec loss: 0.8843079805374146 for ['[CLS] minor jersey recurring each committee such core ( adaptation measures [SEP]']
[Init] best perm rec loss: 0.8835970759391785 for ['[CLS] measures jersey core recurring adaptation ( each such committee minor [SEP]']
[Init] best perm rec loss: 0.8828936815261841 for ['[CLS] jersey measures each adaptation recurring committee ( such core minor [SEP]']
[Init] best perm rec loss: 0.8816406726837158 for ['[CLS] jersey adaptation each ( such minor core committee recurring measures [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.925 (perp=11.751, rec=0.577, cos=0.998), tot_loss_proj:4.102 [t=0.17s]
prediction: ['[CLS] missing beans corresponds sees giants. alt was as thanks [SEP]']
[ 100/2000] tot_loss=4.059 (perp=12.506, rec=0.558, cos=1.000), tot_loss_proj:4.228 [t=0.17s]
prediction: ['[CLS] genus emerged per legislature jim nearly is too is sweetie [SEP]']
[ 150/2000] tot_loss=3.660 (perp=11.040, rec=0.455, cos=0.997), tot_loss_proj:3.918 [t=0.17s]
prediction: ['[CLS] if holly per. eating airs is too too sweetie [SEP]']
[ 200/2000] tot_loss=3.430 (perp=10.157, rec=0.401, cos=0.998), tot_loss_proj:3.772 [t=0.17s]
prediction: ['[CLS] worker hollyosition. holly dick is too is too [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.283 (perp=9.393, rec=0.409, cos=0.995), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS]. craig is tooা, holly bastard is ~ [SEP]']
[ 300/2000] tot_loss=3.636 (perp=11.544, rec=0.333, cos=0.994), tot_loss_proj:4.205 [t=0.17s]
prediction: ['[CLS]. holly holly too bitch. holly whisky isː [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.305 (perp=9.949, rec=0.320, cos=0.995), tot_loss_proj:3.880 [t=0.17s]
prediction: ['[CLS] holly. holly too pmid. holly whisky isː [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.178 (perp=9.241, rec=0.336, cos=0.993), tot_loss_proj:3.794 [t=0.18s]
prediction: ['[CLS] holly. holly nasal. holly whisky too isː [SEP]']
[ 450/2000] tot_loss=3.267 (perp=9.877, rec=0.296, cos=0.995), tot_loss_proj:3.803 [t=0.17s]
prediction: ['[CLS] holly. holly icao. holly whisky too isː [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.068 (perp=8.861, rec=0.300, cos=0.995), tot_loss_proj:3.632 [t=0.17s]
prediction: ['[CLS] holly. holly. holly pmid whisky too isː [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.575 (perp=11.039, rec=0.373, cos=0.994), tot_loss_proj:3.976 [t=0.17s]
prediction: ['[CLS] holly areᵃ. and pmid is toordialː [SEP]']
[ 600/2000] tot_loss=3.584 (perp=11.361, rec=0.317, cos=0.995), tot_loss_proj:4.014 [t=0.17s]
prediction: ['[CLS] holly are killings. and °c is too vantage beverages [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.216 (perp=9.585, rec=0.304, cos=0.995), tot_loss_proj:3.651 [t=0.17s]
prediction: ['[CLS] holly are drinking beverages and °c is too vantage, [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.407 (perp=10.608, rec=0.291, cos=0.995), tot_loss_proj:3.845 [t=0.17s]
prediction: ['[CLS] holly are eating. and °c is too vantage beverages [SEP]']
[ 750/2000] tot_loss=3.419 (perp=10.718, rec=0.280, cos=0.995), tot_loss_proj:3.915 [t=0.17s]
prediction: ['[CLS] holly are eating. and °c is too vantageː [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.286 (perp=10.062, rec=0.278, cos=0.996), tot_loss_proj:3.789 [t=0.17s]
prediction: ['[CLS] holly are eating. and °c is tooː vantage [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.283 (perp=10.062, rec=0.275, cos=0.996), tot_loss_proj:3.787 [t=0.17s]
prediction: ['[CLS] holly are eating. and °c is tooː vantage [SEP]']
[ 900/2000] tot_loss=3.254 (perp=9.961, rec=0.266, cos=0.996), tot_loss_proj:3.740 [t=0.17s]
prediction: ['[CLS] holly are eating. and °c is too grassy vantage [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=3.088 (perp=9.153, rec=0.262, cos=0.996), tot_loss_proj:3.633 [t=0.17s]
prediction: ['[CLS]. eating holly. andա is too grassy vantage [SEP]']
Attempt swap
[1000/2000] tot_loss=3.094 (perp=9.153, rec=0.267, cos=0.996), tot_loss_proj:3.633 [t=0.17s]
prediction: ['[CLS]. eating holly. andա is too grassy vantage [SEP]']
[1050/2000] tot_loss=3.143 (perp=9.428, rec=0.262, cos=0.996), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS]. eating holly. andա is too bleeding vantage [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.096 (perp=9.155, rec=0.269, cos=0.996), tot_loss_proj:3.596 [t=0.17s]
prediction: ['[CLS] and eating holly.. dangling is too grassy vantage [SEP]']
Attempt swap
[1150/2000] tot_loss=2.968 (perp=8.528, rec=0.267, cos=0.996), tot_loss_proj:3.534 [t=0.18s]
prediction: ['[CLS] and eating holly..ա is too grassy vantage [SEP]']
[1200/2000] tot_loss=3.200 (perp=9.657, rec=0.273, cos=0.996), tot_loss_proj:3.706 [t=0.18s]
prediction: ['[CLS] and eating holly..market is too cabbage vantage [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.064 (perp=8.970, rec=0.275, cos=0.994), tot_loss_proj:3.574 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.market is too grassy, [SEP]']
Attempt swap
[1300/2000] tot_loss=3.051 (perp=8.970, rec=0.261, cos=0.995), tot_loss_proj:3.572 [t=0.18s]
prediction: ['[CLS] and eating holly vantage.market is too grassy, [SEP]']
[1350/2000] tot_loss=3.058 (perp=9.024, rec=0.257, cos=0.996), tot_loss_proj:3.548 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.market is too cabbage. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.078 (perp=9.024, rec=0.277, cos=0.996), tot_loss_proj:3.550 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.market is too cabbage. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.051 (perp=9.024, rec=0.250, cos=0.996), tot_loss_proj:3.546 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.market is too cabbage. [SEP]']
[1500/2000] tot_loss=3.057 (perp=9.024, rec=0.256, cos=0.996), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.market is too cabbage. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.066 (perp=9.024, rec=0.264, cos=0.996), tot_loss_proj:3.548 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.market is too cabbage. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.058 (perp=9.024, rec=0.257, cos=0.996), tot_loss_proj:3.547 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.market is too cabbage. [SEP]']
[1650/2000] tot_loss=3.063 (perp=9.024, rec=0.262, cos=0.997), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.market is too cabbage. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.983 (perp=8.639, rec=0.259, cos=0.997), tot_loss_proj:3.487 [t=0.18s]
prediction: ['[CLS] and eating holly vantage.ա is too cabbage. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.950 (perp=8.486, rec=0.255, cos=0.997), tot_loss_proj:3.473 [t=0.18s]
prediction: ['[CLS] and eating holly vantage.ա is cabbage too. [SEP]']
[1800/2000] tot_loss=2.952 (perp=8.486, rec=0.258, cos=0.997), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.ա is cabbage too. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.952 (perp=8.486, rec=0.258, cos=0.997), tot_loss_proj:3.481 [t=0.18s]
prediction: ['[CLS] and eating holly vantage.ա is cabbage too. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.952 (perp=8.486, rec=0.258, cos=0.997), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.ա is cabbage too. [SEP]']
[1950/2000] tot_loss=2.952 (perp=8.486, rec=0.258, cos=0.997), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] and eating holly vantage.ա is cabbage too. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.944 (perp=8.486, rec=0.250, cos=0.997), tot_loss_proj:3.474 [t=0.18s]
prediction: ['[CLS] and eating holly vantage.ա is cabbage too. [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] jose is eating cabbage, and holly is too. [SEP]
========================
predicted: 
========================
[CLS] and eating holly vantage.ա is too cabbage. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 88.889 | r: 80.000
rouge2     | fm: 11.765 | p: 12.500 | r: 11.111
rougeL     | fm: 63.158 | p: 66.667 | r: 60.000
rougeLsum  | fm: 63.158 | p: 66.667 | r: 60.000
r1fm+r2fm = 95.975

[Aggregate metrics]:
rouge1     | fm: 84.702 | p: 86.510 | r: 83.188
rouge2     | fm: 38.971 | p: 39.813 | r: 38.316
rougeL     | fm: 68.121 | p: 69.559 | r: 67.142
rougeLsum  | fm: 67.899 | p: 69.362 | r: 66.590
r1fm+r2fm = 123.673

input #17 time: 0:07:02 | total time: 2:11:12


Running input #18 of 100.
reference: 
========================
John demanded that she stop phoning him.
========================
average of cosine similarity 0.9994126222039297
highest_index [0]
highest [0.9994126222039297]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2198,  6303,  2008,  2016,  2644,  6887, 13369,  2032,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] john demanded that she stop phoning him. [SEP]']
[Init] best rec loss: 0.9877802133560181 for ['[CLS] layton fewer consult school lu bounced choose switzerland years [SEP]']
[Init] best rec loss: 0.9811486005783081 for ['[CLS] union contact n sight oldest songs monumentalbal crow [SEP]']
[Init] best rec loss: 0.9715001583099365 for ['[CLS] state oceandd lionner marx sensorycute monthly [SEP]']
[Init] best rec loss: 0.9666527509689331 for ['[CLS] tattooformsmorphic through rogers signed asktaka commons [SEP]']
[Init] best rec loss: 0.9620587825775146 for ['[CLS] sole askʂ waste bull wing imperial were discovered [SEP]']
[Init] best rec loss: 0.9581156969070435 for ['[CLS] suggested possession terri paper [SEP] month ku tar 3000 [SEP]']
[Init] best rec loss: 0.9447695016860962 for ['[CLS] lamp third impact upon navy followed wheel sheila enough [SEP]']
[Init] best perm rec loss: 0.939691960811615 for ['[CLS] followed enough upon impact lamp third sheila navy wheel [SEP]']
[Init] best perm rec loss: 0.9373711347579956 for ['[CLS] impact enough sheila third followed navy lamp wheel upon [SEP]']
[Init] best perm rec loss: 0.9369447827339172 for ['[CLS] navy enough followed upon impact sheila lamp third wheel [SEP]']
[Init] best perm rec loss: 0.9368777275085449 for ['[CLS] lamp enough impact navy followed sheila upon wheel third [SEP]']
[Init] best perm rec loss: 0.9363468885421753 for ['[CLS] impact lamp enough wheel third upon navy followed sheila [SEP]']
[Init] best perm rec loss: 0.9349254965782166 for ['[CLS] wheel sheila enough followed impact upon lamp third navy [SEP]']
[Init] best perm rec loss: 0.9337619543075562 for ['[CLS] lamp enough impact navy followed upon sheila third wheel [SEP]']
[Init] best perm rec loss: 0.9319055080413818 for ['[CLS] enough upon sheila lamp impact followed navy wheel third [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.555 (perp=10.451, rec=0.616, cos=0.849), tot_loss_proj:3.885 [t=0.17s]
prediction: ['[CLS] friend asked that cells. entered luciandrop. [SEP]']
[ 100/2000] tot_loss=3.344 (perp=10.084, rec=0.535, cos=0.792), tot_loss_proj:4.059 [t=0.17s]
prediction: ['[CLS] tribal demanded thatoning. demanded aleccup. [SEP]']
[ 150/2000] tot_loss=3.159 (perp=10.033, rec=0.490, cos=0.663), tot_loss_proj:3.854 [t=0.17s]
prediction: ['[CLS] reversed demanded thatoning.oningð disappear. [SEP]']
[ 200/2000] tot_loss=3.963 (perp=11.059, rec=0.753, cos=0.998), tot_loss_proj:4.043 [t=0.17s]
prediction: ['[CLS] ones demanded paper computers hell let sleeping sylvester. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.977 (perp=11.688, rec=0.640, cos=1.000), tot_loss_proj:4.134 [t=0.17s]
prediction: ['[CLS] herb demanded money matters hell let prevention sylvester. [SEP]']
[ 300/2000] tot_loss=3.548 (perp=9.990, rec=0.563, cos=0.987), tot_loss_proj:3.783 [t=0.17s]
prediction: ['[CLS] krishna demanded money matters hell let these ltd. [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.481 (perp=9.990, rec=0.530, cos=0.953), tot_loss_proj:3.787 [t=0.17s]
prediction: ['[CLS] krishna demanded money matters hell let these ltd. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.494 (perp=10.759, rec=0.540, cos=0.801), tot_loss_proj:3.969 [t=0.17s]
prediction: ['[CLS]ivated hell demanded match matters let hisonus. [SEP]']
[ 450/2000] tot_loss=2.600 (perp=10.936, rec=0.349, cos=0.064), tot_loss_proj:3.972 [t=0.17s]
prediction: ['[CLS] hitler hell demanded paper she used santa disclosure. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.138 (perp=9.076, rec=0.294, cos=0.029), tot_loss_proj:3.607 [t=0.17s]
prediction: ['[CLS] krishna demanded hell paper she wanted his worse. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.968 (perp=8.316, rec=0.279, cos=0.026), tot_loss_proj:3.613 [t=0.17s]
prediction: ['[CLS] she demanded helloning john wanted his worse. [SEP]']
[ 600/2000] tot_loss=1.937 (perp=8.316, rec=0.256, cos=0.018), tot_loss_proj:3.608 [t=0.17s]
prediction: ['[CLS] she demanded helloning john wanted his worse. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.147 (perp=9.480, rec=0.237, cos=0.014), tot_loss_proj:3.841 [t=0.17s]
prediction: ['[CLS] she demanded whyoning johnoning his worse. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.138 (perp=9.480, rec=0.231, cos=0.012), tot_loss_proj:3.837 [t=0.17s]
prediction: ['[CLS] she demanded whyoning johnoning his worse. [SEP]']
[ 750/2000] tot_loss=2.130 (perp=9.480, rec=0.224, cos=0.010), tot_loss_proj:3.843 [t=0.17s]
prediction: ['[CLS] she demanded whyoning johnoning his worse. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.118 (perp=9.480, rec=0.212, cos=0.009), tot_loss_proj:3.841 [t=0.17s]
prediction: ['[CLS] she demanded whyoning johnoning his worse. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.113 (perp=9.480, rec=0.209, cos=0.009), tot_loss_proj:3.840 [t=0.17s]
prediction: ['[CLS] she demanded whyoning johnoning his worse. [SEP]']
[ 900/2000] tot_loss=1.999 (perp=8.952, rec=0.200, cos=0.008), tot_loss_proj:3.716 [t=0.17s]
prediction: ['[CLS] she demanded johnoning johnoning his worse. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.992 (perp=8.952, rec=0.194, cos=0.007), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] she demanded johnoning johnoning his worse. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.939 (perp=8.725, rec=0.187, cos=0.007), tot_loss_proj:3.654 [t=0.17s]
prediction: ['[CLS] she demanded johnoning johnoning his woman. [SEP]']
[1050/2000] tot_loss=1.933 (perp=8.725, rec=0.181, cos=0.007), tot_loss_proj:3.652 [t=0.17s]
prediction: ['[CLS] she demanded johnoning johnoning his woman. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.851 (perp=8.276, rec=0.188, cos=0.007), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.838 (perp=8.276, rec=0.177, cos=0.006), tot_loss_proj:3.710 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
[1200/2000] tot_loss=1.835 (perp=8.276, rec=0.174, cos=0.006), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.840 (perp=8.276, rec=0.179, cos=0.006), tot_loss_proj:3.707 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.841 (perp=8.276, rec=0.180, cos=0.006), tot_loss_proj:3.704 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
[1350/2000] tot_loss=1.833 (perp=8.276, rec=0.171, cos=0.006), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.831 (perp=8.276, rec=0.170, cos=0.006), tot_loss_proj:3.710 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.827 (perp=8.276, rec=0.167, cos=0.006), tot_loss_proj:3.709 [t=0.19s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
[1500/2000] tot_loss=1.834 (perp=8.276, rec=0.174, cos=0.006), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.821 (perp=8.276, rec=0.160, cos=0.005), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.819 (perp=8.276, rec=0.159, cos=0.005), tot_loss_proj:3.707 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
[1650/2000] tot_loss=1.831 (perp=8.276, rec=0.171, cos=0.005), tot_loss_proj:3.707 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.822 (perp=8.276, rec=0.162, cos=0.005), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.825 (perp=8.276, rec=0.165, cos=0.005), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
[1800/2000] tot_loss=1.816 (perp=8.276, rec=0.156, cos=0.005), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.817 (perp=8.276, rec=0.156, cos=0.005), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his johnoning woman. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.719 (perp=7.764, rec=0.161, cos=0.005), tot_loss_proj:3.538 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his phoning woman. [SEP]']
[1950/2000] tot_loss=1.713 (perp=7.764, rec=0.155, cos=0.005), tot_loss_proj:3.536 [t=0.17s]
prediction: ['[CLS] she demanded johnoning his phoning woman. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.692 (perp=7.570, rec=0.173, cos=0.005), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] sheoning john demanded his phoning woman. [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] john demanded that she stop phoning him. [SEP]
========================
predicted: 
========================
[CLS] she demanded johnoning his johnoning woman. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 47.059 | p: 50.000 | r: 44.444
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 35.294 | p: 37.500 | r: 33.333
rougeLsum  | fm: 35.294 | p: 37.500 | r: 33.333
r1fm+r2fm = 47.059

[Aggregate metrics]:
rouge1     | fm: 82.846 | p: 84.545 | r: 81.224
rouge2     | fm: 36.864 | p: 37.734 | r: 36.232
rougeL     | fm: 66.520 | p: 68.018 | r: 65.246
rougeLsum  | fm: 66.426 | p: 67.893 | r: 65.092
r1fm+r2fm = 119.710

input #18 time: 0:06:58 | total time: 2:18:10


Running input #19 of 100.
reference: 
========================
I have six too many marbles.
========================
average of cosine similarity 0.999305888550308
highest_index [0]
highest [0.999305888550308]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 1045, 2031, 2416, 2205, 2116, 7720, 2015, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have six too many marbles. [SEP]']
[Init] best rec loss: 0.9150007367134094 for ['[CLS] endemicston card horsevere kira particular glasses [SEP]']
[Init] best rec loss: 0.9137986302375793 for ['[CLS] they future math note ] chaseanza bore [SEP]']
[Init] best rec loss: 0.8883269429206848 for ['[CLS] basis anythingui cleared looking name began ce [SEP]']
[Init] best rec loss: 0.8865185379981995 for ['[CLS] astronomy bowl records roe processed piano camera stuff [SEP]']
[Init] best rec loss: 0.8345103859901428 for ['[CLS] liability bleak later itpta doinʁ wilde [SEP]']
[Init] best rec loss: 0.7897818088531494 for ['[CLS] rear itself period def chargelth length contract [SEP]']
[Init] best perm rec loss: 0.7894785404205322 for ['[CLS] chargelth itself def contract period length rear [SEP]']
[Init] best perm rec loss: 0.7868735194206238 for ['[CLS] contract length def charge rearlth period itself [SEP]']
[Init] best perm rec loss: 0.786363959312439 for ['[CLS] length period charge itself def contract rearlth [SEP]']
[Init] best perm rec loss: 0.7855151295661926 for ['[CLS] length itself deflth rear contract charge period [SEP]']
[Init] best perm rec loss: 0.7844892740249634 for ['[CLS] def itself lengthlth charge rear contract period [SEP]']
[Init] best perm rec loss: 0.7842040061950684 for ['[CLS] def length itself charge period contract rearlth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.319 (perp=13.674, rec=0.462, cos=0.122), tot_loss_proj:4.689 [t=0.17s]
prediction: ['[CLS] stupid several team everyza midfielder roundedging [SEP]']
[ 100/2000] tot_loss=2.981 (perp=12.687, rec=0.379, cos=0.065), tot_loss_proj:4.506 [t=0.17s]
prediction: ['[CLS] most several team sixza marble video south [SEP]']
[ 150/2000] tot_loss=2.734 (perp=11.948, rec=0.302, cos=0.043), tot_loss_proj:4.341 [t=0.17s]
prediction: ['[CLS] too four team sixza marble spanish south [SEP]']
[ 200/2000] tot_loss=1.980 (perp=8.395, rec=0.262, cos=0.039), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS] too. have six scott marbles i [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.630 (perp=11.596, rec=0.264, cos=0.047), tot_loss_proj:4.277 [t=0.17s]
prediction: ['[CLS] too i six many marble many football have [SEP]']
[ 300/2000] tot_loss=2.535 (perp=11.596, rec=0.196, cos=0.019), tot_loss_proj:4.249 [t=0.17s]
prediction: ['[CLS] too i six many marble many football have [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.224 (perp=9.942, rec=0.213, cos=0.022), tot_loss_proj:3.982 [t=0.17s]
prediction: ['[CLS] too i should. marble many i six [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.807 (perp=7.923, rec=0.198, cos=0.024), tot_loss_proj:3.589 [t=0.17s]
prediction: ['[CLS] too i have many. marble i six [SEP]']
[ 450/2000] tot_loss=1.743 (perp=7.923, rec=0.146, cos=0.012), tot_loss_proj:3.583 [t=0.17s]
prediction: ['[CLS] too i have many. marble i six [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.726 (perp=7.912, rec=0.133, cos=0.011), tot_loss_proj:3.579 [t=0.17s]
prediction: ['[CLS] too i have many six marble fame. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.578 (perp=6.942, rec=0.168, cos=0.021), tot_loss_proj:3.412 [t=0.17s]
prediction: ['[CLS] i have too many six marble fame. [SEP]']
[ 600/2000] tot_loss=1.669 (perp=7.664, rec=0.125, cos=0.011), tot_loss_proj:3.481 [t=0.17s]
prediction: ['[CLS] i have too many six marblenga. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.590 (perp=7.299, rec=0.121, cos=0.009), tot_loss_proj:3.071 [t=0.17s]
prediction: ['[CLS] i have six too many marblenga. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.583 (perp=7.299, rec=0.115, cos=0.008), tot_loss_proj:3.073 [t=0.17s]
prediction: ['[CLS] i have six too many marblenga. [SEP]']
[ 750/2000] tot_loss=1.441 (perp=6.626, rec=0.108, cos=0.008), tot_loss_proj:3.112 [t=0.17s]
prediction: ['[CLS] i have six too many marble y. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.439 (perp=6.626, rec=0.107, cos=0.007), tot_loss_proj:3.122 [t=0.18s]
prediction: ['[CLS] i have six too many marble y. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.438 (perp=6.626, rec=0.106, cos=0.006), tot_loss_proj:3.117 [t=0.18s]
prediction: ['[CLS] i have six too many marble y. [SEP]']
[ 900/2000] tot_loss=1.278 (perp=5.825, rec=0.107, cos=0.006), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.266 (perp=5.825, rec=0.095, cos=0.006), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.265 (perp=5.825, rec=0.095, cos=0.006), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
[1050/2000] tot_loss=1.266 (perp=5.825, rec=0.095, cos=0.005), tot_loss_proj:2.779 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.275 (perp=5.825, rec=0.105, cos=0.005), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.265 (perp=5.825, rec=0.094, cos=0.005), tot_loss_proj:2.777 [t=0.18s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
[1200/2000] tot_loss=1.263 (perp=5.825, rec=0.092, cos=0.005), tot_loss_proj:2.778 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.257 (perp=5.825, rec=0.087, cos=0.005), tot_loss_proj:2.777 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.267 (perp=5.825, rec=0.098, cos=0.005), tot_loss_proj:2.778 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
[1350/2000] tot_loss=1.253 (perp=5.825, rec=0.083, cos=0.005), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.253 (perp=5.825, rec=0.084, cos=0.005), tot_loss_proj:2.779 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.261 (perp=5.825, rec=0.092, cos=0.005), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
[1500/2000] tot_loss=1.258 (perp=5.825, rec=0.088, cos=0.004), tot_loss_proj:2.779 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.256 (perp=5.825, rec=0.086, cos=0.004), tot_loss_proj:2.781 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.255 (perp=5.825, rec=0.086, cos=0.004), tot_loss_proj:2.778 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
[1650/2000] tot_loss=1.257 (perp=5.825, rec=0.088, cos=0.004), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.252 (perp=5.825, rec=0.082, cos=0.004), tot_loss_proj:2.779 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.262 (perp=5.825, rec=0.093, cos=0.004), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
[1800/2000] tot_loss=1.343 (perp=6.251, rec=0.089, cos=0.004), tot_loss_proj:2.968 [t=0.17s]
prediction: ['[CLS] i have six too many marble!. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.271 (perp=5.825, rec=0.100, cos=0.006), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.270 (perp=5.825, rec=0.100, cos=0.005), tot_loss_proj:2.779 [t=0.19s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
[1950/2000] tot_loss=1.261 (perp=5.825, rec=0.091, cos=0.005), tot_loss_proj:2.784 [t=0.19s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.260 (perp=5.825, rec=0.090, cos=0.005), tot_loss_proj:2.786 [t=0.19s]
prediction: ['[CLS] i have six too many marble.. [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] i have six too many marbles. [SEP]
========================
predicted: 
========================
[CLS] i have six too many marble.. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 71.429 | p: 71.429 | r: 71.429
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 158.929

[Aggregate metrics]:
rouge1     | fm: 82.958 | p: 84.679 | r: 81.479
rouge2     | fm: 38.735 | p: 39.499 | r: 38.025
rougeL     | fm: 67.504 | p: 68.874 | r: 66.365
rougeLsum  | fm: 67.300 | p: 68.614 | r: 66.180
r1fm+r2fm = 121.693

input #19 time: 0:07:11 | total time: 2:25:22


Running input #20 of 100.
reference: 
========================
Mark's single mindedness terrified me.
========================
average of cosine similarity 0.9994279625663224
highest_index [0]
highest [0.9994279625663224]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2928,  1005,  1055,  2309, 13128,  2791, 10215,  2033,  1012,
           102]], device='cuda:0')
Debug: ref = ["[CLS] mark's single mindedness terrified me. [SEP]"]
[Init] best rec loss: 1.0452334880828857 for ['[CLS] [CLS] asked sirius accessed ling women emphasis disc height [SEP]']
[Init] best rec loss: 0.9451050162315369 for ['[CLS]se guitarfirmed sky 2015 begging box simply agreed [SEP]']
[Init] best rec loss: 0.9352335333824158 for ['[CLS] avery her el practices pius still academic belief power [SEP]']
[Init] best rec loss: 0.9296568036079407 for ['[CLS] silence sounds h derrick serviceks whose begin make [SEP]']
[Init] best perm rec loss: 0.9269508719444275 for ['[CLS] derrick begin whose soundsks h silence make service [SEP]']
[Init] best perm rec loss: 0.9261907935142517 for ['[CLS] derrick make serviceks begin whose silence sounds h [SEP]']
[Init] best perm rec loss: 0.9243326187133789 for ['[CLS] h whose beginks sounds silence service make derrick [SEP]']
[Init] best perm rec loss: 0.9241335988044739 for ['[CLS] make derrickks whose silence sounds begin h service [SEP]']
[Init] best perm rec loss: 0.9237069487571716 for ['[CLS] derrick sounds h make silence whose beginks service [SEP]']
[Init] best perm rec loss: 0.9234338998794556 for ['[CLS] derrick makeks begin silence sounds whose h service [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.729 (perp=11.977, rec=0.627, cos=0.707), tot_loss_proj:4.272 [t=0.18s]
prediction: ['[CLS] fiction leon highwayively is jan went my. [SEP]']
[ 100/2000] tot_loss=2.432 (perp=10.950, rec=0.225, cos=0.017), tot_loss_proj:4.084 [t=0.19s]
prediction: ['[CLS] mark billy / least s mark terrified me bullshit [SEP]']
[ 150/2000] tot_loss=2.343 (perp=10.957, rec=0.146, cos=0.006), tot_loss_proj:4.126 [t=0.19s]
prediction: ["[CLS] mark'/ minded s mark terrified meness [SEP]"]
[ 200/2000] tot_loss=2.308 (perp=10.957, rec=0.112, cos=0.005), tot_loss_proj:4.125 [t=0.17s]
prediction: ["[CLS] mark'/ minded s mark terrified meness [SEP]"]
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.598 (perp=12.225, rec=0.147, cos=0.006), tot_loss_proj:4.352 [t=0.17s]
prediction: ['[CLS]ovich ; minded baptist s mark terrified meness [SEP]']
[ 300/2000] tot_loss=2.285 (perp=10.844, rec=0.112, cos=0.005), tot_loss_proj:4.086 [t=0.17s]
prediction: ['[CLS]. ; minded baptist s mark terrified meness [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.157 (perp=10.213, rec=0.110, cos=0.004), tot_loss_proj:4.032 [t=0.17s]
prediction: ['[CLS] s single minded baptist. mark terrified meness [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.998 (perp=9.434, rec=0.107, cos=0.005), tot_loss_proj:3.960 [t=0.17s]
prediction: ['[CLS] s single minded baptistness mark terrified me. [SEP]']
[ 450/2000] tot_loss=1.988 (perp=9.434, rec=0.098, cos=0.004), tot_loss_proj:3.962 [t=0.17s]
prediction: ['[CLS] s single minded baptistness mark terrified me. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.870 (perp=8.872, rec=0.091, cos=0.004), tot_loss_proj:3.774 [t=0.18s]
prediction: ['[CLS] guy s single mindedness mark terrified me. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.856 (perp=8.872, rec=0.078, cos=0.004), tot_loss_proj:3.767 [t=0.17s]
prediction: ['[CLS] guy s single mindedness mark terrified me. [SEP]']
[ 600/2000] tot_loss=1.859 (perp=8.872, rec=0.081, cos=0.004), tot_loss_proj:3.771 [t=0.17s]
prediction: ['[CLS] guy s single mindedness mark terrified me. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.813 (perp=8.631, rec=0.083, cos=0.004), tot_loss_proj:3.796 [t=0.20s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.812 (perp=8.631, rec=0.082, cos=0.004), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
[ 750/2000] tot_loss=1.815 (perp=8.631, rec=0.085, cos=0.003), tot_loss_proj:3.798 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.816 (perp=8.631, rec=0.087, cos=0.003), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.811 (perp=8.631, rec=0.082, cos=0.003), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
[ 900/2000] tot_loss=1.812 (perp=8.631, rec=0.082, cos=0.003), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.808 (perp=8.631, rec=0.078, cos=0.003), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.814 (perp=8.631, rec=0.084, cos=0.003), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
[1050/2000] tot_loss=1.812 (perp=8.631, rec=0.082, cos=0.003), tot_loss_proj:3.797 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.810 (perp=8.631, rec=0.080, cos=0.003), tot_loss_proj:3.802 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.813 (perp=8.631, rec=0.084, cos=0.003), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
[1200/2000] tot_loss=1.808 (perp=8.631, rec=0.079, cos=0.003), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.796 (perp=8.631, rec=0.067, cos=0.003), tot_loss_proj:3.798 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.807 (perp=8.631, rec=0.078, cos=0.003), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
[1350/2000] tot_loss=1.803 (perp=8.631, rec=0.074, cos=0.003), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.806 (perp=8.631, rec=0.076, cos=0.003), tot_loss_proj:3.801 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.807 (perp=8.631, rec=0.078, cos=0.003), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
[1500/2000] tot_loss=1.807 (perp=8.631, rec=0.078, cos=0.003), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.802 (perp=8.631, rec=0.073, cos=0.003), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.798 (perp=8.631, rec=0.069, cos=0.003), tot_loss_proj:3.798 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
[1650/2000] tot_loss=1.797 (perp=8.631, rec=0.068, cos=0.003), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.793 (perp=8.631, rec=0.064, cos=0.003), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.803 (perp=8.631, rec=0.074, cos=0.003), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
[1800/2000] tot_loss=1.804 (perp=8.631, rec=0.075, cos=0.003), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.811 (perp=8.631, rec=0.082, cos=0.003), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.810 (perp=8.631, rec=0.081, cos=0.003), tot_loss_proj:3.794 [t=0.21s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
[1950/2000] tot_loss=1.801 (perp=8.631, rec=0.071, cos=0.003), tot_loss_proj:3.793 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.802 (perp=8.631, rec=0.073, cos=0.003), tot_loss_proj:3.796 [t=0.17s]
prediction: ['[CLS] mark s single mindedness guy terrified me. [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] mark's single mindedness terrified me. [SEP]
========================
predicted: 
========================
[CLS] mark s single mindedness guy terrified me. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 80.000 | p: 75.000 | r: 85.714
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 174.118

[Aggregate metrics]:
rouge1     | fm: 83.391 | p: 84.763 | r: 82.225
rouge2     | fm: 40.250 | p: 40.783 | r: 39.971
rougeL     | fm: 68.720 | p: 69.945 | r: 67.924
rougeLsum  | fm: 68.376 | p: 69.532 | r: 67.470
r1fm+r2fm = 123.641

input #20 time: 0:07:04 | total time: 2:32:26


Running input #21 of 100.
reference: 
========================
Her indiscretions were made light of.
========================
average of cosine similarity 0.9994566039006179
highest_index [0]
highest [0.9994566039006179]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2014, 27427,  2483, 16748,  9285,  2020,  2081,  2422,  1997,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] her indiscretions were made light of. [SEP]']
[Init] best rec loss: 0.9554566144943237 for ['[CLS] dung help makei de blinds commissioned "z graders [SEP]']
[Init] best rec loss: 0.9515466094017029 for ['[CLS] our regal hadn bollywood parasite pere betapath attack photograph [SEP]']
[Init] best rec loss: 0.9109048247337341 for ['[CLS] paydah silver abigail heart humans " covers lightdder [SEP]']
[Init] best rec loss: 0.9000157117843628 for ['[CLS] this innovation kala these yu sprint experience cas pressure paper [SEP]']
[Init] best rec loss: 0.8907043933868408 for ['[CLS] allie super dwell roadssia come guido swedish magnus named [SEP]']
[Init] best rec loss: 0.8886403441429138 for ['[CLS]hari equals kata id saint cooper listen projects bulgaria guess [SEP]']
[Init] best perm rec loss: 0.8841731548309326 for ['[CLS] bulgaria cooper guess saint id kata listen equals projectshari [SEP]']
[Init] best perm rec loss: 0.8827610015869141 for ['[CLS] id bulgariahari projects kata saint guess cooper equals listen [SEP]']
[Init] best perm rec loss: 0.8818569779396057 for ['[CLS]hari bulgaria id guess listen saint cooper kata equals projects [SEP]']
[Init] best perm rec loss: 0.8816714286804199 for ['[CLS] saint cooper bulgaria equals id projectshari kata listen guess [SEP]']
[Init] best perm rec loss: 0.8802563548088074 for ['[CLS] equals katahari listen cooper bulgaria id saint projects guess [SEP]']
[Init] best perm rec loss: 0.879644513130188 for ['[CLS]hari equals bulgaria listen saint cooper kata guess projects id [SEP]']
[Init] best perm rec loss: 0.8795214891433716 for ['[CLS] bulgaria id saint listen cooper equals projects guess katahari [SEP]']
[Init] best perm rec loss: 0.8789999485015869 for ['[CLS] id listen bulgariahari kata guess saint cooper equals projects [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.064 (perp=12.285, rec=0.608, cos=0.999), tot_loss_proj:4.247 [t=0.17s]
prediction: ['[CLS] princess. christensen decree pierce got stirred recognitionroud foreign [SEP]']
[ 100/2000] tot_loss=4.032 (perp=12.211, rec=0.596, cos=0.994), tot_loss_proj:4.359 [t=0.17s]
prediction: ['[CLS] her. christensen act entitledtled balaaciesefined foreign [SEP]']
[ 150/2000] tot_loss=3.846 (perp=12.346, rec=0.444, cos=0.933), tot_loss_proj:4.198 [t=0.17s]
prediction: ['[CLS] her.ca overthrow involved been detailstionshered significant [SEP]']
[ 200/2000] tot_loss=3.757 (perp=12.656, rec=0.440, cos=0.786), tot_loss_proj:4.403 [t=0.17s]
prediction: ['[CLS] her.cre reforms included been detailstionshered choral [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.554 (perp=11.439, rec=0.448, cos=0.819), tot_loss_proj:4.030 [t=0.17s]
prediction: ['[CLS] her. of won included solution detailstions amongst apartments [SEP]']
[ 300/2000] tot_loss=2.411 (perp=10.088, rec=0.327, cos=0.067), tot_loss_proj:3.743 [t=0.17s]
prediction: ['[CLS] her. of been named solution detailstions keynes. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.218 (perp=9.693, rec=0.255, cos=0.025), tot_loss_proj:3.665 [t=0.17s]
prediction: ['[CLS].tions her appeared namedtion details in light. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.206 (perp=9.787, rec=0.235, cos=0.014), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS]. details her appeared namedtionstions in light. [SEP]']
[ 450/2000] tot_loss=2.353 (perp=10.673, rec=0.209, cos=0.009), tot_loss_proj:3.878 [t=0.17s]
prediction: ['[CLS]cre details her were namedtionstions light light. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.270 (perp=10.340, rec=0.193, cos=0.009), tot_loss_proj:3.834 [t=0.17s]
prediction: ['[CLS]cretions details her wereitariantions light made. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.941 (perp=8.810, rec=0.168, cos=0.011), tot_loss_proj:3.555 [t=0.17s]
prediction: ['[CLS]cretionsted her astions were light made. [SEP]']
[ 600/2000] tot_loss=1.923 (perp=8.810, rec=0.153, cos=0.008), tot_loss_proj:3.555 [t=0.17s]
prediction: ['[CLS]cretionsted her astions were light made. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.788 (perp=8.261, rec=0.128, cos=0.007), tot_loss_proj:3.457 [t=0.17s]
prediction: ['[CLS]cretionsted as hertions were light made. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.614 (perp=7.386, rec=0.132, cos=0.006), tot_loss_proj:3.297 [t=0.22s]
prediction: ['[CLS] impcretions as hertions were light made. [SEP]']
[ 750/2000] tot_loss=1.732 (perp=8.113, rec=0.104, cos=0.005), tot_loss_proj:3.524 [t=0.18s]
prediction: ['[CLS] impcretions as hertions were light made of [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.729 (perp=8.113, rec=0.101, cos=0.005), tot_loss_proj:3.521 [t=0.17s]
prediction: ['[CLS] impcretions as hertions were light made of [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.668 (perp=7.736, rec=0.115, cos=0.006), tot_loss_proj:3.572 [t=0.17s]
prediction: ['[CLS] impcretions as hertions were made light of [SEP]']
[ 900/2000] tot_loss=1.656 (perp=7.736, rec=0.103, cos=0.005), tot_loss_proj:3.570 [t=0.17s]
prediction: ['[CLS] impcretions as hertions were made light of [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.649 (perp=7.736, rec=0.097, cos=0.005), tot_loss_proj:3.572 [t=0.17s]
prediction: ['[CLS] impcretions as hertions were made light of [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.812 (perp=8.496, rec=0.107, cos=0.006), tot_loss_proj:3.734 [t=0.17s]
prediction: ['[CLS] imp hereit ascretions were made light of [SEP]']
[1050/2000] tot_loss=1.813 (perp=8.562, rec=0.095, cos=0.006), tot_loss_proj:3.839 [t=0.18s]
prediction: ['[CLS]is hereit.cretions were made light of [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.580 (perp=7.418, rec=0.091, cos=0.006), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS]. hereitiscretions were made light of [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.423 (perp=6.526, rec=0.112, cos=0.006), tot_loss_proj:2.946 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
[1200/2000] tot_loss=1.409 (perp=6.526, rec=0.098, cos=0.006), tot_loss_proj:2.956 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.402 (perp=6.526, rec=0.091, cos=0.006), tot_loss_proj:2.947 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.401 (perp=6.526, rec=0.090, cos=0.006), tot_loss_proj:2.953 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
[1350/2000] tot_loss=1.403 (perp=6.526, rec=0.092, cos=0.006), tot_loss_proj:2.949 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.406 (perp=6.526, rec=0.095, cos=0.006), tot_loss_proj:2.949 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.411 (perp=6.526, rec=0.100, cos=0.006), tot_loss_proj:2.955 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
[1500/2000] tot_loss=1.403 (perp=6.526, rec=0.092, cos=0.006), tot_loss_proj:2.952 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.406 (perp=6.526, rec=0.095, cos=0.006), tot_loss_proj:2.955 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.403 (perp=6.526, rec=0.092, cos=0.006), tot_loss_proj:2.948 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
[1650/2000] tot_loss=1.398 (perp=6.526, rec=0.087, cos=0.006), tot_loss_proj:2.955 [t=0.18s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.398 (perp=6.526, rec=0.087, cos=0.006), tot_loss_proj:2.952 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.390 (perp=6.526, rec=0.079, cos=0.006), tot_loss_proj:2.946 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
[1800/2000] tot_loss=1.401 (perp=6.526, rec=0.090, cos=0.006), tot_loss_proj:2.945 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.403 (perp=6.526, rec=0.092, cos=0.006), tot_loss_proj:2.959 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.405 (perp=6.526, rec=0.095, cos=0.006), tot_loss_proj:2.948 [t=0.18s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
[1950/2000] tot_loss=1.400 (perp=6.526, rec=0.089, cos=0.006), tot_loss_proj:2.950 [t=0.19s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.396 (perp=6.526, rec=0.085, cos=0.006), tot_loss_proj:2.952 [t=0.17s]
prediction: ['[CLS] hereitiscretions were made light of. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] her indiscretions were made light of. [SEP]
========================
predicted: 
========================
[CLS] hereitiscretions were made light of. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 85.714 | r: 75.000
rouge2     | fm: 61.538 | p: 66.667 | r: 57.143
rougeL     | fm: 80.000 | p: 85.714 | r: 75.000
rougeLsum  | fm: 80.000 | p: 85.714 | r: 75.000
r1fm+r2fm = 141.538

[Aggregate metrics]:
rouge1     | fm: 83.362 | p: 84.877 | r: 82.023
rouge2     | fm: 41.196 | p: 42.055 | r: 40.748
rougeL     | fm: 69.425 | p: 70.753 | r: 68.434
rougeLsum  | fm: 69.087 | p: 70.370 | r: 67.897
r1fm+r2fm = 124.558

input #21 time: 0:07:02 | total time: 2:39:29


Running input #22 of 100.
reference: 
========================
Each of the boys fought with the other boys.
========================
average of cosine similarity 0.9994588680226513
highest_index [0]
highest [0.9994588680226513]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2169, 1997, 1996, 3337, 4061, 2007, 1996, 2060, 3337, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] each of the boys fought with the other boys. [SEP]']
[Init] best rec loss: 1.0515670776367188 for ['[CLS] hers hours woundmund totaling pd hailey stone aftermath tortricidae [SEP]']
[Init] best rec loss: 1.015817642211914 for ['[CLS] library em group come surprise pass varsity moderate must blackness [SEP]']
[Init] best rec loss: 0.9550566077232361 for ['[CLS] broke demolition athens censorship turn blood starts collection unlike sex [SEP]']
[Init] best rec loss: 0.9446551203727722 for ['[CLS] hotterpath started regional chew intention concert bet outsiders labour [SEP]']
[Init] best rec loss: 0.9388949275016785 for ['[CLS] upontra track samurai paste hamlet lots groupto self [SEP]']
[Init] best rec loss: 0.9269140958786011 for ['[CLS] fairy mercury hunt shall never witch pageant aviation add they [SEP]']
[Init] best rec loss: 0.9265666604042053 for ['[CLS] lucky peace [CLS]erationaxvat arrest undo square surface [SEP]']
[Init] best rec loss: 0.9177623391151428 for ['[CLS] own equation belt smoke perceptionful mode quartet crest colin [SEP]']
[Init] best rec loss: 0.9115076065063477 for ['[CLS] massimodo conrad chatham am dean phenomena weapon jam kung [SEP]']
[Init] best perm rec loss: 0.9084622263908386 for ['[CLS] chatham massimo conrad jam phenomenado weapon am kung dean [SEP]']
[Init] best perm rec loss: 0.9081283211708069 for ['[CLS] chatham dean weapon kung jam phenomena massimo conrad amdo [SEP]']
[Init] best perm rec loss: 0.9077945351600647 for ['[CLS] conrad massimo chatham jam kungdo weapon dean phenomena am [SEP]']
[Init] best perm rec loss: 0.906182050704956 for ['[CLS]do kung am weapon massimo conrad phenomena dean chatham jam [SEP]']
[Init] best perm rec loss: 0.9049517512321472 for ['[CLS] massimo conrad kung dean weapon phenomena jamdo chatham am [SEP]']
[Init] best perm rec loss: 0.904506504535675 for ['[CLS] phenomena dean massimo kung am weapon chatham conraddo jam [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.812 (perp=11.334, rec=0.638, cos=0.907), tot_loss_proj:4.029 [t=0.17s]
prediction: ['[CLS] compared destroyed woman battle lasted dirty and routine per equipment [SEP]']
[ 100/2000] tot_loss=3.497 (perp=10.258, rec=0.550, cos=0.896), tot_loss_proj:3.866 [t=0.17s]
prediction: ['[CLS] each fought of fought boys altogether with the places females [SEP]']
[ 150/2000] tot_loss=2.991 (perp=9.252, rec=0.500, cos=0.641), tot_loss_proj:3.675 [t=0.22s]
prediction: ['[CLS] each fought with fought boys altogether with the each females [SEP]']
[ 200/2000] tot_loss=3.858 (perp=9.910, rec=0.939, cos=0.937), tot_loss_proj:3.550 [t=0.17s]
prediction: ['[CLS] the participants boys fought each versus daughter although boys girls [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=4.169 (perp=12.124, rec=0.749, cos=0.995), tot_loss_proj:4.454 [t=0.17s]
prediction: ['[CLS] participants boys fought eachulously frs although marek girls girls [SEP]']
[ 300/2000] tot_loss=4.213 (perp=12.845, rec=0.645, cos=0.998), tot_loss_proj:4.446 [t=0.17s]
prediction: ['[CLS] participants boys fought eachulously frs divided yuri girls girls [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=4.201 (perp=12.968, rec=0.609, cos=0.999), tot_loss_proj:4.551 [t=0.17s]
prediction: ['[CLS] participants boys fought soldiersulously divided yuriern girls boys [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=4.231 (perp=13.111, rec=0.608, cos=1.000), tot_loss_proj:4.483 [t=0.17s]
prediction: ['[CLS] boys boys fought soldiersulouslytnessskayaern girls participants [SEP]']
[ 450/2000] tot_loss=4.473 (perp=14.613, rec=0.557, cos=0.994), tot_loss_proj:4.747 [t=0.19s]
prediction: ['[CLS] boys couple each soldiersulouslytness shortlyern boys participants [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.924 (perp=11.983, rec=0.551, cos=0.977), tot_loss_proj:4.184 [t=0.17s]
prediction: ['[CLS] boys soldiersulously couple eachtness shortly of boys participants [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=4.425 (perp=12.358, rec=0.970, cos=0.984), tot_loss_proj:4.260 [t=0.17s]
prediction: ['[CLS] boys fought the child eachtness others boys eugen from [SEP]']
[ 600/2000] tot_loss=3.793 (perp=10.755, rec=0.642, cos=1.000), tot_loss_proj:3.990 [t=0.17s]
prediction: ['[CLS] immediately fought the child each outsider others boys of from [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.418 (perp=9.150, rec=0.589, cos=1.000), tot_loss_proj:3.674 [t=0.17s]
prediction: ['[CLS] immediately fought the child each women from boys of some [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.550 (perp=9.911, rec=0.568, cos=1.000), tot_loss_proj:3.896 [t=0.17s]
prediction: ['[CLS] afterwards fought the each child women from boysadia some [SEP]']
[ 750/2000] tot_loss=3.649 (perp=10.506, rec=0.549, cos=1.000), tot_loss_proj:3.912 [t=0.17s]
prediction: ['[CLS] afterwards fought the each child joyah from boysadia some [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.604 (perp=10.327, rec=0.539, cos=0.999), tot_loss_proj:3.833 [t=0.20s]
prediction: ['[CLS] fought afterwards the each child joyah from boysadia some [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.750 (perp=11.160, rec=0.519, cos=0.999), tot_loss_proj:3.985 [t=0.17s]
prediction: ['[CLS] fought afterwards the each themselves joyah from boysadia some [SEP]']
[ 900/2000] tot_loss=3.737 (perp=11.129, rec=0.512, cos=0.999), tot_loss_proj:4.013 [t=0.17s]
prediction: ['[CLS] fought so the each themselves joyah from boysadia some [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.520 (perp=10.085, rec=0.504, cos=0.999), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] fought so the themselves each joyah to boys of some [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.425 (perp=9.584, rec=0.510, cos=0.998), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS] fought so the themselves each joyah to some boys each [SEP]']
[1050/2000] tot_loss=3.468 (perp=9.828, rec=0.505, cos=0.998), tot_loss_proj:3.722 [t=0.17s]
prediction: ['[CLS] fought so the themselves each females to some boys each [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.645 (perp=10.775, rec=0.492, cos=0.998), tot_loss_proj:3.926 [t=0.17s]
prediction: ['[CLS] fought so the joyah themselves each boys some boys each [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=3.756 (perp=11.211, rec=0.516, cos=0.998), tot_loss_proj:4.240 [t=0.17s]
prediction: ['[CLS] afterwards the joyah themselves each fought onset some boys each [SEP]']
[1200/2000] tot_loss=3.456 (perp=9.829, rec=0.493, cos=0.998), tot_loss_proj:3.891 [t=0.17s]
prediction: ['[CLS] so the joyah boys each fought onset some boys each [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.241 (perp=8.752, rec=0.493, cos=0.998), tot_loss_proj:3.772 [t=0.17s]
prediction: ['[CLS] so the joyah boys each boys fought some boys each [SEP]']
Attempt swap
[1300/2000] tot_loss=3.236 (perp=8.752, rec=0.487, cos=0.998), tot_loss_proj:3.769 [t=0.17s]
prediction: ['[CLS] so the joyah boys each boys fought some boys each [SEP]']
[1350/2000] tot_loss=3.237 (perp=8.752, rec=0.489, cos=0.998), tot_loss_proj:3.769 [t=0.17s]
prediction: ['[CLS] so the joyah boys each boys fought some boys each [SEP]']
Attempt swap
[1400/2000] tot_loss=3.228 (perp=8.752, rec=0.480, cos=0.998), tot_loss_proj:3.776 [t=0.17s]
prediction: ['[CLS] so the joyah boys each boys fought some boys each [SEP]']
Attempt swap
[1450/2000] tot_loss=3.225 (perp=8.752, rec=0.478, cos=0.998), tot_loss_proj:3.773 [t=0.17s]
prediction: ['[CLS] so the joyah boys each boys fought some boys each [SEP]']
[1500/2000] tot_loss=3.226 (perp=8.752, rec=0.478, cos=0.997), tot_loss_proj:3.776 [t=0.17s]
prediction: ['[CLS] so the joyah boys each boys fought some boys each [SEP]']
Attempt swap
[1550/2000] tot_loss=3.220 (perp=8.752, rec=0.472, cos=0.997), tot_loss_proj:3.770 [t=0.17s]
prediction: ['[CLS] so the joyah boys each boys fought some boys each [SEP]']
Attempt swap
[1600/2000] tot_loss=3.215 (perp=8.752, rec=0.468, cos=0.997), tot_loss_proj:3.772 [t=0.19s]
prediction: ['[CLS] so the joyah boys each boys fought some boys each [SEP]']
[1650/2000] tot_loss=3.222 (perp=8.752, rec=0.474, cos=0.997), tot_loss_proj:3.776 [t=0.19s]
prediction: ['[CLS] so the joyah boys each boys fought some boys each [SEP]']
Attempt swap
[1700/2000] tot_loss=3.216 (perp=8.752, rec=0.468, cos=0.997), tot_loss_proj:3.773 [t=0.17s]
prediction: ['[CLS] so the joyah boys each boys fought some boys each [SEP]']
Attempt swap
[1750/2000] tot_loss=3.281 (perp=9.099, rec=0.464, cos=0.997), tot_loss_proj:3.806 [t=0.17s]
prediction: ['[CLS] so thetypical boys each boys fought some boys each [SEP]']
[1800/2000] tot_loss=3.284 (perp=9.099, rec=0.467, cos=0.997), tot_loss_proj:3.809 [t=0.17s]
prediction: ['[CLS] so thetypical boys each boys fought some boys each [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=3.222 (perp=8.766, rec=0.472, cos=0.997), tot_loss_proj:3.815 [t=0.17s]
prediction: ['[CLS] so thetypical boys boys each fought some boys each [SEP]']
Attempt swap
[1900/2000] tot_loss=3.617 (perp=10.794, rec=0.462, cos=0.997), tot_loss_proj:4.080 [t=0.18s]
prediction: ['[CLS] quarrel thetypical boys boys each fought some boys each [SEP]']
[1950/2000] tot_loss=3.212 (perp=8.766, rec=0.463, cos=0.997), tot_loss_proj:3.814 [t=0.18s]
prediction: ['[CLS] so thetypical boys boys each fought some boys each [SEP]']
Attempt swap
[2000/2000] tot_loss=3.212 (perp=8.766, rec=0.462, cos=0.996), tot_loss_proj:3.809 [t=0.17s]
prediction: ['[CLS] so thetypical boys boys each fought some boys each [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] each of the boys fought with the other boys. [SEP]
========================
predicted: 
========================
[CLS] each fought from fought boys altogether with the each females [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.870 | p: 58.333 | r: 63.636
rouge2     | fm: 19.048 | p: 18.182 | r: 20.000
rougeL     | fm: 52.174 | p: 50.000 | r: 54.545
rougeLsum  | fm: 52.174 | p: 50.000 | r: 54.545
r1fm+r2fm = 79.917

[Aggregate metrics]:
rouge1     | fm: 82.388 | p: 83.889 | r: 81.288
rouge2     | fm: 40.598 | p: 41.253 | r: 40.115
rougeL     | fm: 68.700 | p: 69.784 | r: 67.847
rougeLsum  | fm: 68.190 | p: 69.308 | r: 67.400
r1fm+r2fm = 122.986

input #22 time: 0:07:15 | total time: 2:46:44


Running input #23 of 100.
reference: 
========================
Herman mixed the eggs with the cream.
========================
average of cosine similarity 0.999419669419539
highest_index [0]
highest [0.999419669419539]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 11458,  3816,  1996,  6763,  2007,  1996,  6949,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] herman mixed the eggs with the cream. [SEP]']
[Init] best rec loss: 0.9968389868736267 for ['[CLS] digital borrow applied lodging luc reconciliation rhys toe [SEP]']
[Init] best rec loss: 0.9496680498123169 for ['[CLS] slapped seal near ice sick funk operation commodore [SEP]']
[Init] best rec loss: 0.9394097924232483 for ['[CLS]imi thoughlysis extensionous prominently gorgeous else [SEP]']
[Init] best rec loss: 0.9325956702232361 for ['[CLS] nation withinw allen beneath by space moe [SEP]']
[Init] best rec loss: 0.931027352809906 for ['[CLS] thantrom band millsgood scientistend club [SEP]']
[Init] best rec loss: 0.9294249415397644 for ['[CLS] less saga glass study timesvial jamalactive [SEP]']
[Init] best rec loss: 0.9291494488716125 for ['[CLS]run congress sead instead aged althoughbrush [SEP]']
[Init] best rec loss: 0.916151762008667 for ['[CLS] introduction hair stevie system model question russian common [SEP]']
[Init] best perm rec loss: 0.914799690246582 for ['[CLS] introduction model hair stevie russian question system common [SEP]']
[Init] best perm rec loss: 0.9141308665275574 for ['[CLS] introduction stevie hair russian system question model common [SEP]']
[Init] best perm rec loss: 0.91079181432724 for ['[CLS] system model question russian hair introduction common stevie [SEP]']
[Init] best perm rec loss: 0.9083205461502075 for ['[CLS] stevie hair common russian introduction system model question [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.899 (perp=12.176, rec=0.730, cos=0.734), tot_loss_proj:4.233 [t=0.17s]
prediction: ['[CLS] swami unique down. including : thouhun [SEP]']
[ 100/2000] tot_loss=3.934 (perp=13.203, rec=0.641, cos=0.652), tot_loss_proj:4.502 [t=0.18s]
prediction: ['[CLS] scaresggles whorls cream accompanied : hitter genus [SEP]']
[ 150/2000] tot_loss=3.780 (perp=12.678, rec=0.600, cos=0.644), tot_loss_proj:4.435 [t=0.18s]
prediction: ['[CLS] herman mutual whorls eggs eggs : cream trojan [SEP]']
[ 200/2000] tot_loss=3.588 (perp=10.336, rec=0.724, cos=0.797), tot_loss_proj:3.939 [t=0.18s]
prediction: ['[CLS] gnu mutual gastropod eggs using the eggs steak [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.443 (perp=10.894, rec=0.605, cos=0.659), tot_loss_proj:3.988 [t=0.18s]
prediction: ['[CLS] tor freestyle voice throughout eggs using : eggs [SEP]']
[ 300/2000] tot_loss=3.314 (perp=12.160, rec=0.543, cos=0.339), tot_loss_proj:4.307 [t=0.21s]
prediction: ['[CLS] tor reggaeni throughout eggs eggs : eggs [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.712 (perp=9.839, rec=0.526, cos=0.219), tot_loss_proj:3.933 [t=0.17s]
prediction: ['[CLS] tor eggs frank using eggs dollars : eggs [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.203 (perp=12.867, rec=0.507, cos=0.123), tot_loss_proj:4.508 [t=0.18s]
prediction: ['[CLS] tor mohan initially stemmed eggs dollars squadron eggs [SEP]']
[ 450/2000] tot_loss=3.479 (perp=13.429, rec=0.534, cos=0.259), tot_loss_proj:4.621 [t=0.17s]
prediction: ['[CLS] tor mohan initially stemmed eggs dollars louie eggs [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.121 (perp=12.907, rec=0.495, cos=0.045), tot_loss_proj:4.396 [t=0.17s]
prediction: ['[CLS] tor manifestation initially stemmed eggs louie dollars eggs [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.232 (perp=13.581, rec=0.478, cos=0.038), tot_loss_proj:4.591 [t=0.17s]
prediction: ['[CLS] tor louie initially stemmed eggschrome dollars eggs [SEP]']
[ 600/2000] tot_loss=3.134 (perp=13.238, rec=0.470, cos=0.016), tot_loss_proj:4.438 [t=0.18s]
prediction: ['[CLS] tor louie initially stemmed eggsmaid dollars eggs [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.146 (perp=13.334, rec=0.466, cos=0.013), tot_loss_proj:4.448 [t=0.18s]
prediction: ['[CLS] toroso stemmed initially eggsmaid dollars eggs [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.115 (perp=13.099, rec=0.461, cos=0.034), tot_loss_proj:4.546 [t=0.17s]
prediction: ['[CLS] toroso stemmed eggs eggspathic dollars subsequently [SEP]']
[ 750/2000] tot_loss=3.123 (perp=13.099, rec=0.447, cos=0.056), tot_loss_proj:4.546 [t=0.18s]
prediction: ['[CLS] toroso stemmed eggs eggspathic dollars subsequently [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.191 (perp=13.567, rec=0.453, cos=0.024), tot_loss_proj:4.519 [t=0.17s]
prediction: ['[CLS] torosopathic eggs eggs stemmed cookie subsequently [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.980 (perp=12.537, rec=0.446, cos=0.027), tot_loss_proj:4.362 [t=0.19s]
prediction: ['[CLS] torosopathic eggs eggs subsequently cookie stemmed [SEP]']
[ 900/2000] tot_loss=3.225 (perp=13.741, rec=0.448, cos=0.029), tot_loss_proj:4.760 [t=0.17s]
prediction: ['[CLS] torosopathic eggs eggs frank cookie stemmed [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.149 (perp=13.454, rec=0.446, cos=0.013), tot_loss_proj:4.450 [t=0.17s]
prediction: ['[CLS] subsequentlyosopathic eggs eggs tor cookie stemmed [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.996 (perp=12.492, rec=0.453, cos=0.045), tot_loss_proj:4.456 [t=0.17s]
prediction: ['[CLS] subsequentlyosopathic eggs tor cookie reef eggs [SEP]']
[1050/2000] tot_loss=2.953 (perp=12.492, rec=0.445, cos=0.009), tot_loss_proj:4.455 [t=0.17s]
prediction: ['[CLS] subsequentlyosopathic eggs tor cookie reef eggs [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.974 (perp=12.555, rec=0.450, cos=0.014), tot_loss_proj:4.415 [t=0.17s]
prediction: ['[CLS] torosopathic eggs frank cookieoulos eggs [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.040 (perp=12.804, rec=0.445, cos=0.034), tot_loss_proj:4.628 [t=0.17s]
prediction: ['[CLS] toroso annabelle eggs subsequently h₂opathic eggs [SEP]']
[1200/2000] tot_loss=2.735 (perp=11.412, rec=0.442, cos=0.011), tot_loss_proj:4.326 [t=0.17s]
prediction: ['[CLS] toroso annabelle eggs subsequently cookiepathic eggs [SEP]']
Attempt swap
[1250/2000] tot_loss=2.738 (perp=11.467, rec=0.436, cos=0.009), tot_loss_proj:4.359 [t=0.17s]
prediction: ['[CLS] toroso annabelle eggs frank cookiepathic eggs [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.842 (perp=11.878, rec=0.445, cos=0.021), tot_loss_proj:4.285 [t=0.17s]
prediction: ['[CLS] subsequentlyoso annabelle eggs tor cookiepathic eggs [SEP]']
[1350/2000] tot_loss=2.817 (perp=11.878, rec=0.434, cos=0.008), tot_loss_proj:4.284 [t=0.17s]
prediction: ['[CLS] subsequentlyoso annabelle eggs tor cookiepathic eggs [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.730 (perp=11.412, rec=0.440, cos=0.008), tot_loss_proj:4.321 [t=0.17s]
prediction: ['[CLS] toroso annabelle eggs subsequently cookiepathic eggs [SEP]']
Attempt swap
[1450/2000] tot_loss=2.775 (perp=11.633, rec=0.441, cos=0.007), tot_loss_proj:4.131 [t=0.17s]
prediction: ['[CLS] toroso annabelle eggs subsequently cookie mixed eggs [SEP]']
[1500/2000] tot_loss=2.692 (perp=11.259, rec=0.433, cos=0.007), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] torrk annabelle eggs subsequently cookie mixed eggs [SEP]']
Attempt swap
[1550/2000] tot_loss=2.691 (perp=11.259, rec=0.432, cos=0.007), tot_loss_proj:4.034 [t=0.17s]
prediction: ['[CLS] torrk annabelle eggs subsequently cookie mixed eggs [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.704 (perp=11.210, rec=0.440, cos=0.022), tot_loss_proj:4.149 [t=0.17s]
prediction: ['[CLS] torrk eggs subsequently annabelle cookie mixed eggs [SEP]']
[1650/2000] tot_loss=2.659 (perp=11.103, rec=0.432, cos=0.006), tot_loss_proj:4.277 [t=0.17s]
prediction: ['[CLS] torrk eggs frank annabelle cookie mixed eggs [SEP]']
Attempt swap
[1700/2000] tot_loss=2.659 (perp=11.103, rec=0.431, cos=0.007), tot_loss_proj:4.273 [t=0.17s]
prediction: ['[CLS] torrk eggs frank annabelle cookie mixed eggs [SEP]']
Attempt swap
[1750/2000] tot_loss=2.662 (perp=11.103, rec=0.436, cos=0.005), tot_loss_proj:4.272 [t=0.17s]
prediction: ['[CLS] torrk eggs frank annabelle cookie mixed eggs [SEP]']
[1800/2000] tot_loss=2.660 (perp=11.103, rec=0.434, cos=0.005), tot_loss_proj:4.277 [t=0.17s]
prediction: ['[CLS] torrk eggs frank annabelle cookie mixed eggs [SEP]']
Attempt swap
[1850/2000] tot_loss=2.814 (perp=11.912, rec=0.425, cos=0.006), tot_loss_proj:4.461 [t=0.19s]
prediction: ['[CLS] torrk eggs herman annabelle cookie mixed eggs [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.827 (perp=11.861, rec=0.433, cos=0.022), tot_loss_proj:4.337 [t=0.20s]
prediction: ['[CLS] torrk eggs annabelle frank cookie mixed eggs [SEP]']
[1950/2000] tot_loss=2.792 (perp=11.754, rec=0.435, cos=0.006), tot_loss_proj:4.330 [t=0.17s]
prediction: ['[CLS] torrk eggs annabelle herman cookie mixed eggs [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.887 (perp=12.184, rec=0.438, cos=0.012), tot_loss_proj:4.492 [t=0.18s]
prediction: ['[CLS] torrk eggs annabelle cookie frank mixed eggs [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] herman mixed the eggs with the cream. [SEP]
========================
predicted: 
========================
[CLS] torrk eggs frank annabelle cookie mixed eggs [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 44.444 | p: 44.444 | r: 44.444
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 44.444

[Aggregate metrics]:
rouge1     | fm: 80.780 | p: 82.131 | r: 79.799
rouge2     | fm: 39.115 | p: 39.691 | r: 38.616
rougeL     | fm: 67.762 | p: 68.767 | r: 66.822
rougeLsum  | fm: 67.324 | p: 68.347 | r: 66.464
r1fm+r2fm = 119.896

input #23 time: 0:07:03 | total time: 2:53:47


Running input #24 of 100.
reference: 
========================
No John Smiths attended the meeting.
========================
average of cosine similarity 0.9993669078291529
highest_index [0]
highest [0.9993669078291529]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2053, 2198, 3044, 2015, 3230, 1996, 3116, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] no john smiths attended the meeting. [SEP]']
[Init] best rec loss: 0.9064764976501465 for ['[CLS] performance maybe rae tri / window grace lockheed [SEP]']
[Init] best rec loss: 0.8986294865608215 for ['[CLS] thin southwest laurel body [MASK] minority statue in [SEP]']
[Init] best rec loss: 0.8964348435401917 for ['[CLS] tumors enemy quick tessa moorvere an breath [SEP]']
[Init] best rec loss: 0.8814604878425598 for ['[CLS] commanded belts twilight cameo so mountain 0 radio [SEP]']
[Init] best perm rec loss: 0.8812436461448669 for ['[CLS] belts twilight 0 cameo radio commanded mountain so [SEP]']
[Init] best perm rec loss: 0.8808506727218628 for ['[CLS] belts twilight radio 0 cameo mountain so commanded [SEP]']
[Init] best perm rec loss: 0.8781828284263611 for ['[CLS] so radio cameo belts twilight mountain 0 commanded [SEP]']
[Init] best perm rec loss: 0.875819981098175 for ['[CLS] cameo so commanded belts twilight mountain 0 radio [SEP]']
[Init] best perm rec loss: 0.8754783272743225 for ['[CLS] commanded twilight so belts 0 cameo mountain radio [SEP]']
[Init] best perm rec loss: 0.8746973276138306 for ['[CLS] commanded so twilight 0 belts mountain cameo radio [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.004 (perp=12.003, rec=0.611, cos=0.992), tot_loss_proj:4.423 [t=0.17s]
prediction: ['[CLS] - house meetings meetings necessarily need sipped $ [SEP]']
[ 100/2000] tot_loss=3.830 (perp=11.553, rec=0.589, cos=0.930), tot_loss_proj:4.295 [t=0.17s]
prediction: ['[CLS] a young meetings buildings congress picket wouldn [SEP]']
[ 150/2000] tot_loss=2.078 (perp=8.021, rec=0.401, cos=0.073), tot_loss_proj:3.550 [t=0.17s]
prediction: ['[CLS] the aboriginalites meeting in meeting or. [SEP]']
[ 200/2000] tot_loss=1.729 (perp=7.111, rec=0.277, cos=0.030), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] the john smiths attended meeting or. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.511 (perp=6.330, rec=0.225, cos=0.021), tot_loss_proj:3.167 [t=0.17s]
prediction: ['[CLS] the john smiths meeting attended smith. [SEP]']
[ 300/2000] tot_loss=1.474 (perp=6.330, rec=0.192, cos=0.016), tot_loss_proj:3.163 [t=0.18s]
prediction: ['[CLS] the john smiths meeting attended smith. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.306 (perp=9.541, rec=0.334, cos=0.064), tot_loss_proj:3.895 [t=0.18s]
prediction: ['[CLS]. john smiths attended guards meeting ன [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.985 (perp=8.587, rec=0.240, cos=0.028), tot_loss_proj:3.810 [t=0.18s]
prediction: ['[CLS]. john smiths attended smith meeting ன [SEP]']
[ 450/2000] tot_loss=2.221 (perp=9.945, rec=0.213, cos=0.019), tot_loss_proj:3.838 [t=0.17s]
prediction: ['[CLS]. john smiths attended attended meeting ன [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.194 (perp=9.945, rec=0.190, cos=0.015), tot_loss_proj:3.827 [t=0.18s]
prediction: ['[CLS]. john smiths attended attended meeting ன [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.308 (perp=10.643, rec=0.165, cos=0.014), tot_loss_proj:4.059 [t=0.17s]
prediction: ['[CLS] no john smiths attended attended meeting ς [SEP]']
[ 600/2000] tot_loss=1.918 (perp=8.837, rec=0.137, cos=0.014), tot_loss_proj:3.670 [t=0.18s]
prediction: ['[CLS] no john smiths attended no meeting ς [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.912 (perp=8.837, rec=0.132, cos=0.012), tot_loss_proj:3.660 [t=0.17s]
prediction: ['[CLS] no john smiths attended no meeting ς [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.897 (perp=8.837, rec=0.119, cos=0.011), tot_loss_proj:3.669 [t=0.18s]
prediction: ['[CLS] no john smiths attended no meeting ς [SEP]']
[ 750/2000] tot_loss=1.896 (perp=8.837, rec=0.118, cos=0.010), tot_loss_proj:3.666 [t=0.18s]
prediction: ['[CLS] no john smiths attended no meeting ς [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.888 (perp=8.837, rec=0.111, cos=0.010), tot_loss_proj:3.663 [t=0.17s]
prediction: ['[CLS] no john smiths attended no meeting ς [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.781 (perp=8.296, rec=0.111, cos=0.011), tot_loss_proj:3.611 [t=0.17s]
prediction: ['[CLS] no john smiths ς attended no meeting [SEP]']
[ 900/2000] tot_loss=1.769 (perp=8.296, rec=0.101, cos=0.009), tot_loss_proj:3.610 [t=0.18s]
prediction: ['[CLS] no john smiths ς attended no meeting [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.771 (perp=8.271, rec=0.108, cos=0.008), tot_loss_proj:3.654 [t=0.19s]
prediction: ['[CLS] no john smith ςs attended no meeting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.774 (perp=8.271, rec=0.111, cos=0.008), tot_loss_proj:3.654 [t=0.17s]
prediction: ['[CLS] no john smith ςs attended no meeting [SEP]']
[1050/2000] tot_loss=1.761 (perp=8.271, rec=0.099, cos=0.008), tot_loss_proj:3.658 [t=0.17s]
prediction: ['[CLS] no john smith ςs attended no meeting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.761 (perp=8.271, rec=0.099, cos=0.008), tot_loss_proj:3.654 [t=0.17s]
prediction: ['[CLS] no john smith ςs attended no meeting [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.772 (perp=8.296, rec=0.106, cos=0.008), tot_loss_proj:3.608 [t=0.17s]
prediction: ['[CLS] no john smiths ς attended no meeting [SEP]']
[1200/2000] tot_loss=1.768 (perp=8.296, rec=0.102, cos=0.007), tot_loss_proj:3.607 [t=0.17s]
prediction: ['[CLS] no john smiths ς attended no meeting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.759 (perp=8.296, rec=0.092, cos=0.007), tot_loss_proj:3.606 [t=0.17s]
prediction: ['[CLS] no john smiths ς attended no meeting [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.786 (perp=8.341, rec=0.110, cos=0.008), tot_loss_proj:3.647 [t=0.17s]
prediction: ['[CLS]. ς john smiths attended no meeting [SEP]']
[1350/2000] tot_loss=1.777 (perp=8.341, rec=0.102, cos=0.007), tot_loss_proj:3.649 [t=0.17s]
prediction: ['[CLS]. ς john smiths attended no meeting [SEP]']
Attempt swap
Put prefix at the end
[1400/2000] tot_loss=1.510 (perp=6.962, rec=0.106, cos=0.012), tot_loss_proj:3.326 [t=0.17s]
prediction: ['[CLS] ς john smiths attended no meeting. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.515 (perp=6.962, rec=0.112, cos=0.010), tot_loss_proj:3.321 [t=0.17s]
prediction: ['[CLS] ς john smiths attended no meeting. [SEP]']
[1500/2000] tot_loss=1.500 (perp=6.962, rec=0.098, cos=0.010), tot_loss_proj:3.322 [t=0.17s]
prediction: ['[CLS] ς john smiths attended no meeting. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.502 (perp=6.962, rec=0.100, cos=0.009), tot_loss_proj:3.321 [t=0.17s]
prediction: ['[CLS] ς john smiths attended no meeting. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.516 (perp=7.059, rec=0.095, cos=0.009), tot_loss_proj:3.423 [t=0.17s]
prediction: ['[CLS] 比 john smiths attended no meeting. [SEP]']
[1650/2000] tot_loss=1.517 (perp=7.059, rec=0.097, cos=0.009), tot_loss_proj:3.421 [t=0.17s]
prediction: ['[CLS] 比 john smiths attended no meeting. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.515 (perp=7.059, rec=0.094, cos=0.009), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS] 比 john smiths attended no meeting. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.515 (perp=7.059, rec=0.094, cos=0.009), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS] 比 john smiths attended no meeting. [SEP]']
[1800/2000] tot_loss=1.507 (perp=7.059, rec=0.087, cos=0.009), tot_loss_proj:3.414 [t=0.17s]
prediction: ['[CLS] 比 john smiths attended no meeting. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.513 (perp=7.059, rec=0.093, cos=0.008), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] 比 john smiths attended no meeting. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.513 (perp=7.059, rec=0.093, cos=0.008), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS] 比 john smiths attended no meeting. [SEP]']
[1950/2000] tot_loss=1.517 (perp=7.059, rec=0.097, cos=0.008), tot_loss_proj:3.414 [t=0.17s]
prediction: ['[CLS] 比 john smiths attended no meeting. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.514 (perp=7.059, rec=0.094, cos=0.008), tot_loss_proj:3.411 [t=0.17s]
prediction: ['[CLS] 比 john smiths attended no meeting. [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] no john smiths attended the meeting. [SEP]
========================
predicted: 
========================
[CLS] 比 john smiths attended no meeting. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 100.000 | r: 87.500
rouge2     | fm: 46.154 | p: 50.000 | r: 42.857
rougeL     | fm: 80.000 | p: 85.714 | r: 75.000
rougeLsum  | fm: 80.000 | p: 85.714 | r: 75.000
r1fm+r2fm = 139.487

[Aggregate metrics]:
rouge1     | fm: 81.322 | p: 82.881 | r: 80.217
rouge2     | fm: 39.311 | p: 40.095 | r: 38.664
rougeL     | fm: 68.083 | p: 69.357 | r: 67.004
rougeLsum  | fm: 67.727 | p: 69.050 | r: 66.671
r1fm+r2fm = 120.634

input #24 time: 0:07:03 | total time: 3:00:51


Running input #25 of 100.
reference: 
========================
I did not, as Bill had thought, go to the store.
========================
average of cosine similarity 0.9993283700816344
highest_index [0]
highest [0.9993283700816344]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2106, 2025, 1010, 2004, 3021, 2018, 2245, 1010, 2175, 2000,
         1996, 3573, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i did not, as bill had thought, go to the store. [SEP]']
[Init] best rec loss: 0.9354310631752014 for ['[CLS] zu sussex wig son committed koppen youth part sc missile combat carrier licence magazine [SEP]']
[Init] best rec loss: 0.9029408693313599 for ['[CLS] air moisture each van kind pl tribes fulltou nod resolvedhesivevan affair [SEP]']
[Init] best rec loss: 0.8997546434402466 for ['[CLS] roma act roof sperm senior take driven thinking leaguevers coast bettynett nurse [SEP]']
[Init] best rec loss: 0.8800485134124756 for ['[CLS] arrive ana ren thick stared lieutenant political sin skye betule delaware rhea commissioned [SEP]']
[Init] best perm rec loss: 0.8734595775604248 for ['[CLS] arriveule ren political thick lieutenant skye delaware rhea sin bet commissioned ana stared [SEP]']
[Init] best perm rec loss: 0.873327374458313 for ['[CLS] skye ana bet rhea lieutenant sinule stared ren commissioned delaware political arrive thick [SEP]']
[Init] best perm rec loss: 0.8728404641151428 for ['[CLS] bet lieutenant sin anaule commissioned delaware political ren stared skye thick arrive rhea [SEP]']
[Init] best perm rec loss: 0.8718591928482056 for ['[CLS] delaware rhea ren political lieutenant commissioned sinule stared thick bet skye ana arrive [SEP]']
[Init] best perm rec loss: 0.869565486907959 for ['[CLS] rhea lieutenant skye stared commissioned sin delaware ana ren betule political arrive thick [SEP]']
[Init] best perm rec loss: 0.869038999080658 for ['[CLS] rhea thick lieutenant ana bet sin ren commissioned politicalule stared skye delaware arrive [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.584 (perp=10.391, rec=0.450, cos=0.056), tot_loss_proj:4.013 [t=0.17s]
prediction: ['[CLS] ; responsibility farm. interred ; would - love dog order theology. established [SEP]']
[ 100/2000] tot_loss=2.385 (perp=9.926, rec=0.378, cos=0.022), tot_loss_proj:3.923 [t=0.17s]
prediction: ['[CLS] would bill farm ; congratulations ; would, the pilgrimage title exploration southern established [SEP]']
[ 150/2000] tot_loss=2.086 (perp=8.787, rec=0.315, cos=0.013), tot_loss_proj:3.641 [t=0.17s]
prediction: ['[CLS] would bill mother ; congratulations : did, the thought any exploration. of [SEP]']
[ 200/2000] tot_loss=2.029 (perp=7.810, rec=0.396, cos=0.071), tot_loss_proj:3.429 [t=0.17s]
prediction: ['[CLS] i bill mother ; not : did, and thought any go. was [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.488 (perp=10.479, rec=0.364, cos=0.027), tot_loss_proj:4.011 [t=0.17s]
prediction: ['[CLS] i bill never fairy not loved,ʔ (master success did go de [SEP]']
[ 300/2000] tot_loss=2.232 (perp=9.635, rec=0.293, cos=0.013), tot_loss_proj:3.844 [t=0.17s]
prediction: ['[CLS] i bill not fairy not loved,ʔ ( a success did go de [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.066 (perp=8.903, rec=0.271, cos=0.014), tot_loss_proj:3.665 [t=0.17s]
prediction: ['[CLS] i. not scanned not bill,ʔ ( the thought did go had [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.017 (perp=8.862, rec=0.233, cos=0.011), tot_loss_proj:3.661 [t=0.19s]
prediction: ['[CLS] i. notir not billʔ,, the thought did go had [SEP]']
[ 450/2000] tot_loss=1.709 (perp=7.477, rec=0.205, cos=0.009), tot_loss_proj:3.346 [t=0.19s]
prediction: ['[CLS] i. not thought not bill denied, as the thought did go had [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.597 (perp=7.044, rec=0.180, cos=0.008), tot_loss_proj:3.233 [t=0.17s]
prediction: ['[CLS] i. not thought not bill milk, as the thought did go had [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.558 (perp=7.018, rec=0.147, cos=0.007), tot_loss_proj:3.254 [t=0.17s]
prediction: ['[CLS] i., store not bill milk, as the thought did go had [SEP]']
[ 600/2000] tot_loss=1.539 (perp=7.018, rec=0.130, cos=0.006), tot_loss_proj:3.254 [t=0.17s]
prediction: ['[CLS] i., store not bill milk, as the thought did go had [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.535 (perp=7.018, rec=0.126, cos=0.005), tot_loss_proj:3.253 [t=0.17s]
prediction: ['[CLS] i., store not bill milk, as the thought did go had [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.523 (perp=7.018, rec=0.115, cos=0.005), tot_loss_proj:3.253 [t=0.17s]
prediction: ['[CLS] i., store not bill milk, as the thought did go had [SEP]']
[ 750/2000] tot_loss=1.518 (perp=7.018, rec=0.109, cos=0.005), tot_loss_proj:3.255 [t=0.17s]
prediction: ['[CLS] i., store not bill milk, as the thought did go had [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.509 (perp=7.018, rec=0.100, cos=0.005), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] i., store not bill milk, as the thought did go had [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.507 (perp=7.018, rec=0.099, cos=0.004), tot_loss_proj:3.251 [t=0.17s]
prediction: ['[CLS] i., store not bill milk, as the thought did go had [SEP]']
[ 900/2000] tot_loss=1.505 (perp=7.018, rec=0.097, cos=0.004), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] i., store not bill milk, as the thought did go had [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.417 (perp=6.534, rec=0.106, cos=0.005), tot_loss_proj:3.148 [t=0.17s]
prediction: ['[CLS] i had, store not bill milk, as the thought did go to [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.400 (perp=6.445, rec=0.107, cos=0.004), tot_loss_proj:3.144 [t=0.17s]
prediction: ['[CLS] i had, store not bill milk, as the thought to go did [SEP]']
[1050/2000] tot_loss=1.385 (perp=6.445, rec=0.092, cos=0.004), tot_loss_proj:3.141 [t=0.17s]
prediction: ['[CLS] i had, store not bill milk, as the thought to go did [SEP]']
Attempt swap
[1100/2000] tot_loss=1.388 (perp=6.445, rec=0.095, cos=0.004), tot_loss_proj:3.142 [t=0.17s]
prediction: ['[CLS] i had, store not bill milk, as the thought to go did [SEP]']
Attempt swap
[1150/2000] tot_loss=1.391 (perp=6.445, rec=0.098, cos=0.004), tot_loss_proj:3.142 [t=0.17s]
prediction: ['[CLS] i had, store not bill milk, as the thought to go did [SEP]']
[1200/2000] tot_loss=1.393 (perp=6.445, rec=0.100, cos=0.004), tot_loss_proj:3.140 [t=0.17s]
prediction: ['[CLS] i had, store not bill milk, as the thought to go did [SEP]']
Attempt swap
[1250/2000] tot_loss=1.382 (perp=6.445, rec=0.089, cos=0.004), tot_loss_proj:3.143 [t=0.17s]
prediction: ['[CLS] i had, store not bill milk, as the thought to go did [SEP]']
Attempt swap
[1300/2000] tot_loss=1.386 (perp=6.445, rec=0.093, cos=0.004), tot_loss_proj:3.141 [t=0.17s]
prediction: ['[CLS] i had, store not bill milk, as the thought to go did [SEP]']
[1350/2000] tot_loss=1.385 (perp=6.445, rec=0.092, cos=0.004), tot_loss_proj:3.139 [t=0.17s]
prediction: ['[CLS] i had, store not bill milk, as the thought to go did [SEP]']
Attempt swap
[1400/2000] tot_loss=1.385 (perp=6.445, rec=0.093, cos=0.004), tot_loss_proj:3.139 [t=0.17s]
prediction: ['[CLS] i had, store not bill milk, as the thought to go did [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.419 (perp=6.605, rec=0.093, cos=0.005), tot_loss_proj:3.189 [t=0.17s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
[1500/2000] tot_loss=1.419 (perp=6.605, rec=0.094, cos=0.004), tot_loss_proj:3.191 [t=0.19s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
Attempt swap
[1550/2000] tot_loss=1.416 (perp=6.605, rec=0.091, cos=0.004), tot_loss_proj:3.185 [t=0.17s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
Attempt swap
[1600/2000] tot_loss=1.421 (perp=6.605, rec=0.096, cos=0.004), tot_loss_proj:3.185 [t=0.17s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
[1650/2000] tot_loss=1.415 (perp=6.605, rec=0.090, cos=0.004), tot_loss_proj:3.186 [t=0.17s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
Attempt swap
[1700/2000] tot_loss=1.414 (perp=6.605, rec=0.089, cos=0.004), tot_loss_proj:3.186 [t=0.17s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
Attempt swap
[1750/2000] tot_loss=1.404 (perp=6.605, rec=0.080, cos=0.004), tot_loss_proj:3.182 [t=0.17s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
[1800/2000] tot_loss=1.412 (perp=6.605, rec=0.087, cos=0.004), tot_loss_proj:3.185 [t=0.18s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
Attempt swap
[1850/2000] tot_loss=1.410 (perp=6.605, rec=0.085, cos=0.004), tot_loss_proj:3.189 [t=0.17s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
Attempt swap
[1900/2000] tot_loss=1.407 (perp=6.605, rec=0.082, cos=0.004), tot_loss_proj:3.184 [t=0.17s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
[1950/2000] tot_loss=1.409 (perp=6.605, rec=0.084, cos=0.004), tot_loss_proj:3.188 [t=0.17s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
Attempt swap
[2000/2000] tot_loss=1.417 (perp=6.605, rec=0.093, cos=0.004), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] i had store, not billfar, as the thought to go did [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] i did not, as bill had thought, go to the store. [SEP]
========================
predicted: 
========================
[CLS] i had store, not billfar, as the thought to go did [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 8.333 | p: 8.333 | r: 8.333
rougeL     | fm: 53.846 | p: 53.846 | r: 53.846
rougeLsum  | fm: 53.846 | p: 53.846 | r: 53.846
r1fm+r2fm = 100.641

[Aggregate metrics]:
rouge1     | fm: 81.766 | p: 83.235 | r: 80.589
rouge2     | fm: 38.233 | p: 38.831 | r: 37.652
rougeL     | fm: 67.548 | p: 68.808 | r: 66.642
rougeLsum  | fm: 67.250 | p: 68.452 | r: 66.282
r1fm+r2fm = 119.998

input #25 time: 0:07:02 | total time: 3:07:53


Running input #26 of 100.
reference: 
========================
Who will John ask for information about summer courses?
========================
average of cosine similarity 0.9994149465253206
highest_index [0]
highest [0.9994149465253206]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2040, 2097, 2198, 3198, 2005, 2592, 2055, 2621, 5352, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] who will john ask for information about summer courses? [SEP]']
[Init] best rec loss: 0.923130989074707 for ['[CLS] certified bowedhorn ( lunch dedicated normally played stones nj [SEP]']
[Init] best rec loss: 0.9089930653572083 for ['[CLS] herself xx bat draft song questions pol horde coreoning [SEP]']
[Init] best rec loss: 0.9017698764801025 for ['[CLS] sayserly demon vapor complexvish administration wind prominent remaining [SEP]']
[Init] best rec loss: 0.8877642154693604 for ['[CLS] morgan ， marketingrcleamy credit x respective local rufus [SEP]']
[Init] best rec loss: 0.8666320443153381 for ['[CLS] wa fashionon ordinary size ou nice carrier carnegie blankets [SEP]']
[Init] best rec loss: 0.8615206480026245 for ['[CLS] significant brooke stellar motion familiar several cast tigersx student [SEP]']
[Init] best rec loss: 0.8474037051200867 for ['[CLS] pga mill known shannon om lord exercise band no around [SEP]']
[Init] best rec loss: 0.8357264399528503 for ['[CLS] louisiana societe origin suicide attached 680 athletics swallow choicethest [SEP]']
[Init] best perm rec loss: 0.8355830907821655 for ['[CLS]thest suicide swallow louisiana origin attached choice societe 680 athletics [SEP]']
[Init] best perm rec loss: 0.8355064988136292 for ['[CLS] choice louisiana origin swallowthest suicide attached societe 680 athletics [SEP]']
[Init] best perm rec loss: 0.8345492482185364 for ['[CLS] suicide swallow attached origin societe louisiana 680 athletics choicethest [SEP]']
[Init] best perm rec loss: 0.8326054215431213 for ['[CLS] louisiana societe choice origin attached athletics swallow suicide 680thest [SEP]']
[Init] best perm rec loss: 0.8323923349380493 for ['[CLS] 680 choice attached originthest suicide swallow societe louisiana athletics [SEP]']
[Init] best perm rec loss: 0.8307003378868103 for ['[CLS] societe louisiana attached origin choice 680 swallow suicidethest athletics [SEP]']
[Init] best perm rec loss: 0.8306877613067627 for ['[CLS] louisiana attachedthest choice swallow origin societe suicide 680 athletics [SEP]']
[Init] best perm rec loss: 0.8306139707565308 for ['[CLS] 680 attached societe origin athletics choice louisiana swallow suicidethest [SEP]']
[Init] best perm rec loss: 0.8287435173988342 for ['[CLS]thest swallow louisiana societe choice attached suicide origin athletics 680 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.152 (perp=12.945, rec=0.485, cos=0.078), tot_loss_proj:4.510 [t=0.17s]
prediction: ['[CLS] postal barrister students called navigation indian condition statistics encouragedfia [SEP]']
[ 100/2000] tot_loss=2.803 (perp=11.511, rec=0.425, cos=0.075), tot_loss_proj:4.129 [t=0.17s]
prediction: ['[CLS] among how students with finalist indian would information excluded tennis [SEP]']
[ 150/2000] tot_loss=2.962 (perp=12.815, rec=0.370, cos=0.028), tot_loss_proj:4.408 [t=0.17s]
prediction: ['[CLS] rightful what students who finalist indian ll information information tennis [SEP]']
[ 200/2000] tot_loss=2.471 (perp=10.600, rec=0.329, cos=0.022), tot_loss_proj:4.041 [t=0.17s]
prediction: ['[CLS] consist who will who offers indian ll information? advice [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.418 (perp=10.507, rec=0.298, cos=0.019), tot_loss_proj:3.970 [t=0.17s]
prediction: ['[CLS] consist will will who offers he ll? information matters [SEP]']
[ 300/2000] tot_loss=2.078 (perp=9.223, rec=0.222, cos=0.012), tot_loss_proj:3.765 [t=0.17s]
prediction: ['[CLS]? will john who ask john vacuum? information matters [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.988 (perp=8.567, rec=0.253, cos=0.022), tot_loss_proj:3.622 [t=0.17s]
prediction: ['[CLS]? will john europe ask who for? information reading [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.840 (perp=8.225, rec=0.185, cos=0.010), tot_loss_proj:3.590 [t=0.17s]
prediction: ['[CLS]? will john europe ask who? for information reading [SEP]']
[ 450/2000] tot_loss=1.813 (perp=8.357, rec=0.136, cos=0.005), tot_loss_proj:3.483 [t=0.19s]
prediction: ['[CLS]? will john europe ask who? for information program [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.697 (perp=7.784, rec=0.137, cos=0.004), tot_loss_proj:3.476 [t=0.19s]
prediction: ['[CLS]? will john - ask who? while for information [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.660 (perp=7.506, rec=0.150, cos=0.009), tot_loss_proj:3.346 [t=0.19s]
prediction: ['[CLS]? will john - ask who summer for information? [SEP]']
[ 600/2000] tot_loss=1.847 (perp=8.674, rec=0.109, cos=0.003), tot_loss_proj:3.616 [t=0.19s]
prediction: ['[CLS]? will john - ask who summer for information information [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.682 (perp=7.870, rec=0.105, cos=0.003), tot_loss_proj:3.420 [t=0.19s]
prediction: ['[CLS] for will john - ask who summer? information information [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.682 (perp=7.870, rec=0.106, cos=0.002), tot_loss_proj:3.422 [t=0.19s]
prediction: ['[CLS] for will john - ask who summer? information information [SEP]']
[ 750/2000] tot_loss=1.673 (perp=7.870, rec=0.097, cos=0.002), tot_loss_proj:3.423 [t=0.19s]
prediction: ['[CLS] for will john - ask who summer? information information [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.640 (perp=7.669, rec=0.104, cos=0.002), tot_loss_proj:3.316 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.628 (perp=7.669, rec=0.092, cos=0.002), tot_loss_proj:3.315 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
[ 900/2000] tot_loss=1.633 (perp=7.669, rec=0.098, cos=0.002), tot_loss_proj:3.315 [t=0.20s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.618 (perp=7.669, rec=0.082, cos=0.002), tot_loss_proj:3.317 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1000/2000] tot_loss=1.626 (perp=7.669, rec=0.090, cos=0.002), tot_loss_proj:3.318 [t=0.20s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
[1050/2000] tot_loss=1.624 (perp=7.669, rec=0.088, cos=0.002), tot_loss_proj:3.316 [t=0.19s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1100/2000] tot_loss=1.631 (perp=7.669, rec=0.096, cos=0.002), tot_loss_proj:3.317 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.623 (perp=7.669, rec=0.087, cos=0.002), tot_loss_proj:3.315 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
[1200/2000] tot_loss=1.627 (perp=7.669, rec=0.091, cos=0.002), tot_loss_proj:3.314 [t=0.18s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1250/2000] tot_loss=1.626 (perp=7.669, rec=0.091, cos=0.002), tot_loss_proj:3.313 [t=0.18s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1300/2000] tot_loss=1.623 (perp=7.669, rec=0.088, cos=0.002), tot_loss_proj:3.315 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
[1350/2000] tot_loss=1.627 (perp=7.669, rec=0.092, cos=0.002), tot_loss_proj:3.317 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1400/2000] tot_loss=1.618 (perp=7.669, rec=0.083, cos=0.002), tot_loss_proj:3.315 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1450/2000] tot_loss=1.617 (perp=7.669, rec=0.082, cos=0.002), tot_loss_proj:3.317 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
[1500/2000] tot_loss=1.623 (perp=7.669, rec=0.088, cos=0.002), tot_loss_proj:3.315 [t=0.18s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1550/2000] tot_loss=1.629 (perp=7.669, rec=0.093, cos=0.002), tot_loss_proj:3.315 [t=0.18s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1600/2000] tot_loss=1.616 (perp=7.669, rec=0.081, cos=0.002), tot_loss_proj:3.317 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
[1650/2000] tot_loss=1.617 (perp=7.669, rec=0.082, cos=0.002), tot_loss_proj:3.316 [t=0.18s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1700/2000] tot_loss=1.622 (perp=7.669, rec=0.086, cos=0.002), tot_loss_proj:3.315 [t=0.18s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1750/2000] tot_loss=1.621 (perp=7.669, rec=0.086, cos=0.002), tot_loss_proj:3.316 [t=0.18s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
[1800/2000] tot_loss=1.614 (perp=7.669, rec=0.079, cos=0.002), tot_loss_proj:3.314 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1850/2000] tot_loss=1.604 (perp=7.669, rec=0.069, cos=0.002), tot_loss_proj:3.313 [t=0.17s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[1900/2000] tot_loss=1.627 (perp=7.669, rec=0.092, cos=0.002), tot_loss_proj:3.316 [t=0.18s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
[1950/2000] tot_loss=1.624 (perp=7.669, rec=0.089, cos=0.002), tot_loss_proj:3.317 [t=0.19s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Attempt swap
[2000/2000] tot_loss=1.624 (perp=7.669, rec=0.089, cos=0.002), tot_loss_proj:3.318 [t=0.19s]
prediction: ['[CLS] for will john and ask who summer? information information [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] who will john ask for information about summer courses? [SEP]
========================
predicted: 
========================
[CLS] for will john and ask who summer? information information [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 10.000 | p: 10.000 | r: 10.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 91.818

[Aggregate metrics]:
rouge1     | fm: 81.782 | p: 83.242 | r: 80.609
rouge2     | fm: 36.935 | p: 37.700 | r: 36.512
rougeL     | fm: 67.149 | p: 68.341 | r: 66.151
rougeLsum  | fm: 66.820 | p: 68.045 | r: 65.803
r1fm+r2fm = 118.716

input #26 time: 0:07:25 | total time: 3:15:19


Running input #27 of 100.
reference: 
========================
Ron wanted to wear a tuxedo to the party, but Caspar couldn't decide whether to.
========================
average of cosine similarity 0.9993526850364247
highest_index [0]
highest [0.9993526850364247]
Debug: ids_shape = 24, pads = [24]
Debug: input ids = tensor([[  101,  6902,  2359,  2000,  4929,  1037, 10722, 19068,  2080,  2000,
          1996,  2283,  1010,  2021, 25222, 19362,  2481,  1005,  1056,  5630,
          3251,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]"]
[Init] best rec loss: 0.9158304333686829 for ['[CLS]ig operated already block sad pac further armenians songs, fund book waters line buy willis relief strike collaborative tack violet bring [SEP]']
[Init] best rec loss: 0.9106042981147766 for ['[CLS] glory money divided paidckenging pressedent magneticance baptist tasteroving [SEP] echo jeremy cipher warrant 』 option measures shot [SEP]']
[Init] best rec loss: 0.897331953048706 for ['[CLS] hay swedish scholars similarities passing sounds bruno anyway accountcy accounts quantum zelity excellence summer diego hepburn documentation buried would league [SEP]']
[Init] best rec loss: 0.8913874626159668 for ['[CLS] perhaps whateveriff implement suit jam silk recruits county reidcted japan smellbed campus needs strolledlem minimum values legs monty [SEP]']
[Init] best rec loss: 0.8904507160186768 for ['[CLS]mum medley basis school started primaries 500ization terrific available boundgies film ninebered constellation edcule gan switch week waters [SEP]']
[Init] best rec loss: 0.8834986686706543 for ['[CLS] devote simulator filled kidd contrast orientucherctive nba ll past ticked rhysbad impgle stereo ferries possibility shooterphone dad [SEP]']
[Init] best rec loss: 0.8819141983985901 for ['[CLS] thesefold ant integration seconds news only advantage epithetpants governed s number agents published every guard bulgarian particular flying dental evening [SEP]']
[Init] best rec loss: 0.8795796036720276 for ['[CLS]vet levelgam findings what deployment weeks claimed rivers lights incumbent always shot callum recordldongesttle regional tank mat university [SEP]']
[Init] best perm rec loss: 0.8790776133537292 for ['[CLS] level shot university matges lights incumbent deployment weeks claimed tank riversgam regional always callum recordldon findingsttlevet what [SEP]']
[Init] best perm rec loss: 0.8726145625114441 for ['[CLS] deployment claimed riversttlevet weeks what findings university levelgam lights mat record callum alwaysgesldon regional shot tank incumbent [SEP]']
[Init] best perm rec loss: 0.8725971579551697 for ['[CLS]ldon universityvet shotgam callumges rivers what recordttle always lights tank level incumbent regional weeks deployment claimed findings mat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.208 (perp=13.715, rec=0.690, cos=0.774), tot_loss_proj:4.595 [t=0.18s]
prediction: ['[CLS] ron nicky tim announced has gloria by bram erebidae an than ares applications and championships nations melt liszt interests factionstered talk [SEP]']
[ 100/2000] tot_loss=2.903 (perp=12.787, rec=0.322, cos=0.024), tot_loss_proj:4.451 [t=0.18s]
prediction: ['[CLS] ron ronradfest agreed pants. price achieved an has review pub & competitions...pt tropical couldn albionsteredutnant [SEP]']
[ 150/2000] tot_loss=2.912 (perp=12.029, rec=0.412, cos=0.094), tot_loss_proj:4.258 [t=0.18s]
prediction: ['[CLS] ron ron fife coffee wanted withctle when, examination massnus de seem. nova maria didn patience fuja [SEP]']
[ 200/2000] tot_loss=2.810 (perp=12.559, rec=0.278, cos=0.020), tot_loss_proj:4.376 [t=0.18s]
prediction: ['[CLS] ron brotherpar wants wanted class toolsted whether, examination mess2ς approach, mu baron didn nobel ranchja [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.017 (perp=13.776, rec=0.249, cos=0.013), tot_loss_proj:4.686 [t=0.18s]
prediction: ['[CLS] ronparparpar wanted class toolsted out, whether mass5 { seem. mu baron couldn nobel ranchja [SEP]']
[ 300/2000] tot_loss=3.008 (perp=13.937, rec=0.210, cos=0.011), tot_loss_proj:4.692 [t=0.18s]
prediction: ['[CLS] ronparparpar wanted class ated out, whether ensemblex enemy seem veil mu baron couldn nobel ranchzen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.946 (perp=13.721, rec=0.193, cos=0.009), tot_loss_proj:4.648 [t=0.18s]
prediction: ['[CLS] ron /parpar wanted class toted out to whether gax faso seem wearpar baron couldn nobel geekzen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.938 (perp=13.690, rec=0.192, cos=0.008), tot_loss_proj:4.661 [t=0.18s]
prediction: ['[CLS] class /parpar wanted ron toted out to whether partyx bwv interact wearpar baron couldn nobel geekzen [SEP]']
[ 450/2000] tot_loss=2.816 (perp=13.137, rec=0.182, cos=0.006), tot_loss_proj:4.541 [t=0.18s]
prediction: ['[CLS] class /parpar wanted ron toted out to whether partyx faso interact wearpar baron couldn nobel geekzen [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.690 (perp=12.565, rec=0.170, cos=0.007), tot_loss_proj:4.406 [t=0.18s]
prediction: ['[CLS] class selectparpar wanted ron toted out to whether partyx smashwords interact wearpar couldn baron nobel didn. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.697 (perp=12.086, rec=0.246, cos=0.034), tot_loss_proj:4.290 [t=0.18s]
prediction: ['[CLS] with / comepar wanted ron tole out to whether party5 janeiro matterparpar couldn ladystatic didn if [SEP]']
[ 600/2000] tot_loss=2.370 (perp=10.825, rec=0.195, cos=0.011), tot_loss_proj:4.044 [t=0.18s]
prediction: ['[CLS] with /.par wanted ron tole out to whether partyx janeiro matter caspar couldn ladystatic didn. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.215 (perp=10.118, rec=0.183, cos=0.008), tot_loss_proj:3.923 [t=0.18s]
prediction: ['[CLS] with /. wear wanted ron to an out to whether partyx 000par caspar couldn baronstatic thighs. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.109 (perp=9.639, rec=0.173, cos=0.008), tot_loss_proj:3.749 [t=0.18s]
prediction: ['[CLS] with a wanted wear. ron to an out to whether partyx 000par caspar couldn baronstatic thighs. [SEP]']
[ 750/2000] tot_loss=2.146 (perp=9.847, rec=0.170, cos=0.007), tot_loss_proj:3.813 [t=0.18s]
prediction: ['[CLS] with a wanted wear. ron to an out to whether partyx 000par caspar couldn baron label thighs. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.439 (perp=10.847, rec=0.243, cos=0.027), tot_loss_proj:3.998 [t=0.18s]
prediction: ["[CLS] let'wanted scott wear ron. a which to whether partyx influencedpar caspar'couldn annie didn. [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.252 (perp=10.106, rec=0.214, cos=0.016), tot_loss_proj:3.892 [t=0.18s]
prediction: ["[CLS] whether'wanted scott wear ron. a which to let partyx influencedpar caspar'couldn annie didn. [SEP]"]
[ 900/2000] tot_loss=2.413 (perp=11.063, rec=0.188, cos=0.012), tot_loss_proj:4.048 [t=0.18s]
prediction: ["[CLS] whether'wanted scott wearing ron. a to to let partyx betweenpar caspar'couldn puppy didn. [SEP]"]
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.285 (perp=10.427, rec=0.188, cos=0.012), tot_loss_proj:3.906 [t=0.18s]
prediction: ["[CLS] whetheri wanted scott wearing ron. to speech party the tox followedpar caspar'couldn picnic didn. [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.125 (perp=9.717, rec=0.171, cos=0.011), tot_loss_proj:3.750 [t=0.18s]
prediction: ['[CLS] whetheri wanted scott wearing ron. to speech " the tox partypar caspar\'couldn picnic didn. [SEP]']
[1050/2000] tot_loss=2.120 (perp=9.717, rec=0.168, cos=0.009), tot_loss_proj:3.743 [t=0.18s]
prediction: ['[CLS] whetheri wanted scott wearing ron. to speech " the tox partypar caspar\'couldn picnic didn. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.314 (perp=10.692, rec=0.167, cos=0.008), tot_loss_proj:3.976 [t=0.20s]
prediction: ['[CLS] whetheri wanted scott wearing ron. to party " the (x speechpar caspar\'couldn picnic didn. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.183 (perp=10.030, rec=0.167, cos=0.010), tot_loss_proj:3.805 [t=0.18s]
prediction: ['[CLS] whetheri wanted scott wearing ron. to to party " thex speechpar caspar\'couldn picnic didn. [SEP]']
[1200/2000] tot_loss=2.136 (perp=9.858, rec=0.156, cos=0.008), tot_loss_proj:3.782 [t=0.18s]
prediction: ['[CLS] whether a wanted d wear ron. to to party " thex speechpar caspar\'couldn picnic didn. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.029 (perp=9.325, rec=0.157, cos=0.008), tot_loss_proj:3.687 [t=0.18s]
prediction: ['[CLS] whether a wanted d to wear ron. to party " thex speechpar caspar\'couldn picnic didn. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.287 (perp=10.559, rec=0.167, cos=0.008), tot_loss_proj:3.958 [t=0.18s]
prediction: ["[CLS] whetheri wanted ( wear ron. to party subsequently the bx speechpar caspar'couldn picnic didn. [SEP]"]
[1350/2000] tot_loss=2.124 (perp=9.803, rec=0.156, cos=0.007), tot_loss_proj:3.781 [t=0.18s]
prediction: ["[CLS] whether a wanted, wear ron. to party subsequently the bx speechpar caspar'couldn picnic didn. [SEP]"]
Attempt swap
Moved sequence
[1400/2000] tot_loss=2.127 (perp=9.774, rec=0.164, cos=0.008), tot_loss_proj:3.784 [t=0.18s]
prediction: ["[CLS] whether wanted,i wear ron. to party subsequently the dx speechpar caspar'couldn picnic didn. [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.038 (perp=9.371, rec=0.156, cos=0.008), tot_loss_proj:3.712 [t=0.18s]
prediction: ["[CLS] whether wanted,i wear ron. the party subsequently to dx speechpar caspar'couldn picnic didn. [SEP]"]
[1500/2000] tot_loss=2.045 (perp=9.422, rec=0.153, cos=0.007), tot_loss_proj:3.749 [t=0.18s]
prediction: ['[CLS] whether wanted toi wear ron. the party " to dx speechpar caspar\'couldn picnic didn. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.976 (perp=9.057, rec=0.158, cos=0.007), tot_loss_proj:3.634 [t=0.18s]
prediction: ['[CLS] whether wanted,i ron. wear the party " to dx speechpar caspar\'couldn picnic didn. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.920 (perp=8.740, rec=0.165, cos=0.007), tot_loss_proj:3.577 [t=0.18s]
prediction: ['[CLS] whether wanted, a ron. wear the party " to dx speechpar caspar\'picnic couldn didn. [SEP]']
[1650/2000] tot_loss=1.917 (perp=8.740, rec=0.162, cos=0.007), tot_loss_proj:3.580 [t=0.18s]
prediction: ['[CLS] whether wanted, a ron. wear the party " to dx speechpar caspar\'picnic couldn didn. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.973 (perp=9.104, rec=0.145, cos=0.006), tot_loss_proj:3.653 [t=0.18s]
prediction: ['[CLS] whether wanted, picnic ron. wear the party " to dx speechpar caspar \'i couldn didn. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.922 (perp=8.803, rec=0.155, cos=0.006), tot_loss_proj:3.575 [t=0.18s]
prediction: ['[CLS] whether wanted, picnic ron. wear the party " to dx speechpar caspari\'couldn didn. [SEP]']
[1800/2000] tot_loss=1.843 (perp=8.426, rec=0.151, cos=0.006), tot_loss_proj:3.517 [t=0.18s]
prediction: ['[CLS] whether wanted, picnic ron. wear the party " to dx speechpar caspar a\'couldn didn. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.846 (perp=8.426, rec=0.155, cos=0.006), tot_loss_proj:3.521 [t=0.18s]
prediction: ['[CLS] whether wanted, picnic ron. wear the party " to dx speechpar caspar a\'couldn didn. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.853 (perp=8.483, rec=0.150, cos=0.006), tot_loss_proj:3.551 [t=0.18s]
prediction: ['[CLS] whether wanted to picnic ron to wear the party ". dx speechpar caspar a\'couldn didn. [SEP]']
[1950/2000] tot_loss=1.853 (perp=8.483, rec=0.150, cos=0.006), tot_loss_proj:3.550 [t=0.18s]
prediction: ['[CLS] whether wanted to picnic ron to wear the party ". dx speechpar caspar a\'couldn didn. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.766 (perp=8.029, rec=0.154, cos=0.006), tot_loss_proj:3.445 [t=0.18s]
prediction: ['[CLS] whether wanted to " ron to wear the party picnic. dx speechpar caspar a\'couldn didn. [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]
========================
predicted: 
========================
[CLS] whether wanted, picnic ron. wear the party " to dx speechpar caspar a'couldn didn. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 75.000 | r: 66.667
rouge2     | fm: 6.250 | p: 6.667 | r: 5.882
rougeL     | fm: 47.059 | p: 50.000 | r: 44.444
rougeLsum  | fm: 47.059 | p: 50.000 | r: 44.444
r1fm+r2fm = 76.838

[Aggregate metrics]:
rouge1     | fm: 81.325 | p: 82.849 | r: 80.014
rouge2     | fm: 35.776 | p: 36.461 | r: 35.292
rougeL     | fm: 66.419 | p: 67.687 | r: 65.375
rougeLsum  | fm: 66.135 | p: 67.413 | r: 65.070
r1fm+r2fm = 117.102

input #27 time: 0:07:29 | total time: 3:22:48


Running input #28 of 100.
reference: 
========================
Bill gave Sue the book.
========================
average of cosine similarity 0.9992527833287079
highest_index [0]
highest [0.9992527833287079]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 3021, 2435, 9790, 1996, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bill gave sue the book. [SEP]']
[Init] best rec loss: 0.9755856394767761 for ['[CLS] martin links ponder _ borntist [SEP]']
[Init] best rec loss: 0.9694833755493164 for ['[CLS] grain farm processing fielding following pierced [SEP]']
[Init] best rec loss: 0.9555665254592896 for ['[CLS] whoever mphaghan live manor patrol [SEP]']
[Init] best rec loss: 0.9311076998710632 for ['[CLS]cked nicknamed me hardware colour boil [SEP]']
[Init] best rec loss: 0.8972436189651489 for ['[CLS] anniversary deposit ethan baroque barnet recently [SEP]']
[Init] best perm rec loss: 0.8948907256126404 for ['[CLS] recently anniversary baroque ethan barnet deposit [SEP]']
[Init] best perm rec loss: 0.8926964402198792 for ['[CLS] ethan baroque barnet recently deposit anniversary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.283 (perp=13.410, rec=0.665, cos=0.936), tot_loss_proj:4.527 [t=0.19s]
prediction: ['[CLS] never andre hanging hungry department languages [SEP]']
[ 100/2000] tot_loss=2.931 (perp=12.179, rec=0.396, cos=0.099), tot_loss_proj:4.257 [t=0.19s]
prediction: ['[CLS] never helped many sue sue would [SEP]']
[ 150/2000] tot_loss=2.883 (perp=13.023, rec=0.260, cos=0.018), tot_loss_proj:4.444 [t=0.19s]
prediction: ['[CLS] johnson gave gave sue sue gave [SEP]']
[ 200/2000] tot_loss=2.767 (perp=12.743, rec=0.206, cos=0.013), tot_loss_proj:4.284 [t=0.19s]
prediction: ['[CLS] johnson gave book sue sue gave [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.457 (perp=11.236, rec=0.196, cos=0.013), tot_loss_proj:4.033 [t=0.20s]
prediction: ['[CLS] sue gave book sue bill it [SEP]']
[ 300/2000] tot_loss=2.452 (perp=11.443, rec=0.156, cos=0.007), tot_loss_proj:4.072 [t=0.20s]
prediction: ['[CLS] bill gave book sue bill book [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.790 (perp=11.659, rec=0.383, cos=0.076), tot_loss_proj:4.098 [t=0.19s]
prediction: ['[CLS] bill given gave sue warning book [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.316 (perp=9.881, rec=0.300, cos=0.040), tot_loss_proj:3.840 [t=0.20s]
prediction: ['[CLS] sue given book gave sue warning [SEP]']
[ 450/2000] tot_loss=2.389 (perp=10.638, rec=0.238, cos=0.023), tot_loss_proj:4.000 [t=0.21s]
prediction: ['[CLS] bill given book gave sue warning [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.346 (perp=10.655, rec=0.199, cos=0.016), tot_loss_proj:3.928 [t=0.17s]
prediction: ['[CLS] bill book release book gave sue [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.061 (perp=9.175, rec=0.209, cos=0.017), tot_loss_proj:3.547 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
[ 600/2000] tot_loss=2.019 (perp=9.175, rec=0.173, cos=0.011), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.016 (perp=9.175, rec=0.171, cos=0.010), tot_loss_proj:3.540 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.017 (perp=9.175, rec=0.173, cos=0.009), tot_loss_proj:3.540 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
[ 750/2000] tot_loss=2.004 (perp=9.175, rec=0.160, cos=0.009), tot_loss_proj:3.539 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.009 (perp=9.175, rec=0.165, cos=0.009), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.994 (perp=9.175, rec=0.150, cos=0.009), tot_loss_proj:3.485 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
[ 900/2000] tot_loss=1.988 (perp=9.175, rec=0.145, cos=0.008), tot_loss_proj:3.480 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.982 (perp=9.175, rec=0.139, cos=0.008), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1000/2000] tot_loss=1.987 (perp=9.175, rec=0.144, cos=0.008), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
[1050/2000] tot_loss=1.990 (perp=9.175, rec=0.147, cos=0.008), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1100/2000] tot_loss=1.984 (perp=9.175, rec=0.142, cos=0.007), tot_loss_proj:3.472 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1150/2000] tot_loss=1.982 (perp=9.175, rec=0.140, cos=0.007), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
[1200/2000] tot_loss=1.984 (perp=9.175, rec=0.141, cos=0.007), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1250/2000] tot_loss=1.981 (perp=9.175, rec=0.139, cos=0.007), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1300/2000] tot_loss=1.980 (perp=9.175, rec=0.138, cos=0.007), tot_loss_proj:3.470 [t=0.20s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
[1350/2000] tot_loss=1.979 (perp=9.175, rec=0.137, cos=0.007), tot_loss_proj:3.472 [t=0.20s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1400/2000] tot_loss=1.984 (perp=9.175, rec=0.142, cos=0.007), tot_loss_proj:3.471 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1450/2000] tot_loss=1.980 (perp=9.175, rec=0.139, cos=0.007), tot_loss_proj:3.472 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
[1500/2000] tot_loss=1.979 (perp=9.175, rec=0.137, cos=0.007), tot_loss_proj:3.468 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1550/2000] tot_loss=1.963 (perp=9.175, rec=0.121, cos=0.007), tot_loss_proj:3.473 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1600/2000] tot_loss=1.970 (perp=9.175, rec=0.128, cos=0.007), tot_loss_proj:3.473 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
[1650/2000] tot_loss=1.976 (perp=9.175, rec=0.134, cos=0.007), tot_loss_proj:3.471 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1700/2000] tot_loss=1.979 (perp=9.175, rec=0.137, cos=0.007), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1750/2000] tot_loss=1.969 (perp=9.175, rec=0.128, cos=0.007), tot_loss_proj:3.465 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
[1800/2000] tot_loss=1.976 (perp=9.175, rec=0.135, cos=0.007), tot_loss_proj:3.471 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1850/2000] tot_loss=1.975 (perp=9.175, rec=0.134, cos=0.007), tot_loss_proj:3.475 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[1900/2000] tot_loss=1.961 (perp=9.175, rec=0.119, cos=0.007), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
[1950/2000] tot_loss=1.963 (perp=9.175, rec=0.122, cos=0.007), tot_loss_proj:3.473 [t=0.18s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Attempt swap
[2000/2000] tot_loss=1.965 (perp=9.175, rec=0.124, cos=0.007), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] book book release bill gave sue [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] bill gave sue the book. [SEP]
========================
predicted: 
========================
[CLS] book book release bill gave sue [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 30.769 | p: 28.571 | r: 33.333
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 110.769

[Aggregate metrics]:
rouge1     | fm: 81.303 | p: 82.673 | r: 80.243
rouge2     | fm: 35.708 | p: 36.280 | r: 35.311
rougeL     | fm: 66.291 | p: 67.427 | r: 65.466
rougeLsum  | fm: 66.174 | p: 67.232 | r: 65.376
r1fm+r2fm = 117.011

input #28 time: 0:07:19 | total time: 3:30:08


Running input #29 of 100.
reference: 
========================
The bread was chewed by Martha.
========================
average of cosine similarity 0.9994577127920362
highest_index [0]
highest [0.9994577127920362]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996,  7852,  2001, 18362,  2011,  9246,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the bread was chewed by martha. [SEP]']
[Init] best rec loss: 1.033448576927185 for ['[CLS] squeezed pace bonnie know plantsoic bishop [SEP]']
[Init] best rec loss: 0.9979770183563232 for ['[CLS] party morrison #ramet animated fluent [SEP]']
[Init] best rec loss: 0.9941338300704956 for ['[CLS] chewed attack turing science sport tontist [SEP]']
[Init] best rec loss: 0.9654293060302734 for ['[CLS] rose worth cowboys aresror affair links [SEP]']
[Init] best rec loss: 0.9611841440200806 for ['[CLS] initially begingram als mothscode loan [SEP]']
[Init] best rec loss: 0.9402060508728027 for ['[CLS] guardian blocked printed, entry important household [SEP]']
[Init] best perm rec loss: 0.9361010789871216 for ['[CLS] guardian important printed entry, blocked household [SEP]']
[Init] best perm rec loss: 0.9354170560836792 for ['[CLS] important entry household, printed guardian blocked [SEP]']
[Init] best perm rec loss: 0.9348337054252625 for ['[CLS], printed blocked entry important guardian household [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.337 (perp=9.592, rec=0.370, cos=0.048), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS],. seized eating bread bread bread [SEP]']
[ 100/2000] tot_loss=2.403 (perp=10.732, rec=0.242, cos=0.015), tot_loss_proj:3.899 [t=0.17s]
prediction: ['[CLS] by martha chewed chewed chewed bread bread [SEP]']
[ 150/2000] tot_loss=2.312 (perp=10.732, rec=0.151, cos=0.014), tot_loss_proj:3.898 [t=0.17s]
prediction: ['[CLS] by martha chewed chewed chewed bread bread [SEP]']
[ 200/2000] tot_loss=1.983 (perp=9.362, rec=0.105, cos=0.006), tot_loss_proj:3.557 [t=0.17s]
prediction: ['[CLS] by martha was chewed chewed by bread [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.971 (perp=9.362, rec=0.093, cos=0.006), tot_loss_proj:3.554 [t=0.18s]
prediction: ['[CLS] by martha was chewed chewed by bread [SEP]']
[ 300/2000] tot_loss=1.968 (perp=9.362, rec=0.091, cos=0.005), tot_loss_proj:3.551 [t=0.18s]
prediction: ['[CLS] by martha was chewed chewed by bread [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.325 (perp=11.150, rec=0.091, cos=0.004), tot_loss_proj:3.887 [t=0.18s]
prediction: ['[CLS] by martha was chewed chewedatable bread [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.314 (perp=11.150, rec=0.080, cos=0.004), tot_loss_proj:3.883 [t=0.18s]
prediction: ['[CLS] by martha was chewed chewedatable bread [SEP]']
[ 450/2000] tot_loss=2.468 (perp=11.379, rec=0.173, cos=0.019), tot_loss_proj:3.986 [t=0.18s]
prediction: ['[CLS] by martha was chewed chewedently bread [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.885 (perp=8.923, rec=0.095, cos=0.005), tot_loss_proj:3.510 [t=0.18s]
prediction: ['[CLS] the martha was chewed chewed by bread [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.837 (perp=8.725, rec=0.087, cos=0.005), tot_loss_proj:3.528 [t=0.18s]
prediction: ['[CLS] the martha was chewed by chewed bread [SEP]']
[ 600/2000] tot_loss=1.836 (perp=8.725, rec=0.087, cos=0.004), tot_loss_proj:3.532 [t=0.18s]
prediction: ['[CLS] the martha was chewed by chewed bread [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.723 (perp=8.173, rec=0.084, cos=0.005), tot_loss_proj:3.860 [t=0.18s]
prediction: ['[CLS] the martha chewed bread was chewed by [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.528 (perp=7.131, rec=0.095, cos=0.007), tot_loss_proj:1.763 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
[ 750/2000] tot_loss=1.524 (perp=7.131, rec=0.093, cos=0.004), tot_loss_proj:1.766 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.515 (perp=7.131, rec=0.085, cos=0.004), tot_loss_proj:1.772 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.508 (perp=7.131, rec=0.077, cos=0.004), tot_loss_proj:1.762 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
[ 900/2000] tot_loss=1.513 (perp=7.131, rec=0.083, cos=0.004), tot_loss_proj:1.768 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.508 (perp=7.131, rec=0.078, cos=0.004), tot_loss_proj:1.773 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1000/2000] tot_loss=1.508 (perp=7.131, rec=0.078, cos=0.004), tot_loss_proj:1.771 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
[1050/2000] tot_loss=1.499 (perp=7.131, rec=0.069, cos=0.004), tot_loss_proj:1.773 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1100/2000] tot_loss=1.507 (perp=7.131, rec=0.077, cos=0.004), tot_loss_proj:1.773 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1150/2000] tot_loss=1.508 (perp=7.131, rec=0.078, cos=0.004), tot_loss_proj:1.773 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
[1200/2000] tot_loss=1.512 (perp=7.131, rec=0.082, cos=0.004), tot_loss_proj:1.772 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1250/2000] tot_loss=1.519 (perp=7.131, rec=0.089, cos=0.004), tot_loss_proj:1.768 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1300/2000] tot_loss=1.517 (perp=7.131, rec=0.087, cos=0.004), tot_loss_proj:1.765 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
[1350/2000] tot_loss=1.507 (perp=7.131, rec=0.077, cos=0.004), tot_loss_proj:1.769 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1400/2000] tot_loss=1.524 (perp=7.131, rec=0.094, cos=0.004), tot_loss_proj:1.768 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1450/2000] tot_loss=1.512 (perp=7.131, rec=0.082, cos=0.004), tot_loss_proj:1.767 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
[1500/2000] tot_loss=1.509 (perp=7.131, rec=0.079, cos=0.004), tot_loss_proj:1.768 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1550/2000] tot_loss=1.515 (perp=7.131, rec=0.085, cos=0.004), tot_loss_proj:1.763 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1600/2000] tot_loss=1.521 (perp=7.131, rec=0.091, cos=0.004), tot_loss_proj:1.768 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
[1650/2000] tot_loss=1.505 (perp=7.131, rec=0.075, cos=0.004), tot_loss_proj:1.765 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1700/2000] tot_loss=1.502 (perp=7.131, rec=0.072, cos=0.004), tot_loss_proj:1.763 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1750/2000] tot_loss=1.521 (perp=7.131, rec=0.091, cos=0.004), tot_loss_proj:1.771 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
[1800/2000] tot_loss=1.510 (perp=7.131, rec=0.080, cos=0.004), tot_loss_proj:1.773 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1850/2000] tot_loss=1.521 (perp=7.131, rec=0.091, cos=0.004), tot_loss_proj:1.770 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[1900/2000] tot_loss=1.507 (perp=7.131, rec=0.077, cos=0.004), tot_loss_proj:1.769 [t=0.17s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
[1950/2000] tot_loss=1.509 (perp=7.131, rec=0.079, cos=0.004), tot_loss_proj:1.772 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Attempt swap
[2000/2000] tot_loss=1.509 (perp=7.131, rec=0.079, cos=0.004), tot_loss_proj:1.779 [t=0.18s]
prediction: ['[CLS] the chewed bread was chewed by martha [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] the bread was chewed by martha. [SEP]
========================
predicted: 
========================
[CLS] the chewed bread was chewed by martha [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 80.000 | p: 75.000 | r: 85.714
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 174.118

[Aggregate metrics]:
rouge1     | fm: 81.785 | p: 82.846 | r: 80.887
rouge2     | fm: 36.941 | p: 37.394 | r: 36.699
rougeL     | fm: 67.308 | p: 68.142 | r: 66.661
rougeLsum  | fm: 66.964 | p: 67.815 | r: 66.497
r1fm+r2fm = 118.726

input #29 time: 0:07:11 | total time: 3:37:19


Running input #30 of 100.
reference: 
========================
Read Fred's story, I also want to.
========================
average of cosine similarity 0.9993327887556609
highest_index [0]
highest [0.9993327887556609]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 3191, 5965, 1005, 1055, 2466, 1010, 1045, 2036, 2215, 2000, 1012,
          102]], device='cuda:0')
Debug: ref = ["[CLS] read fred's story, i also want to. [SEP]"]
[Init] best rec loss: 0.9123356938362122 for ['[CLS] design tourea chargessionkan voicesitatingrak freedom mild [SEP]']
[Init] best rec loss: 0.8970316648483276 for ['[CLS] oil thornton sc platoon scouts reserves town perennial mounted fundamental of [SEP]']
[Init] best rec loss: 0.881742537021637 for ['[CLS] withdrawnnesia lucas planned coloursix oak amin cooper morgan houses [SEP]']
[Init] best rec loss: 0.8782221674919128 for ['[CLS] attempted roadpherizan watches looked mercy wedding momect husbands [SEP]']
[Init] best rec loss: 0.8723532557487488 for ['[CLS] spread happening meant advisory sniff record scheduled justice baltimore straightopa [SEP]']
[Init] best rec loss: 0.865502655506134 for ['[CLS] conference waiting divided twin sweat ponye criminal universe family window [SEP]']
[Init] best rec loss: 0.8589546084403992 for ['[CLS] athleticffled tallinn dial commonly gallery acc relation ruby speakingski [SEP]']
[Init] best rec loss: 0.8508736491203308 for ['[CLS] oldest mon station video moi reserve conference non coming combatathlon [SEP]']
[Init] best perm rec loss: 0.8473225235939026 for ['[CLS]athlon combat coming oldest video moi reserve conference mon non station [SEP]']
[Init] best perm rec loss: 0.8470238447189331 for ['[CLS]athlon station combat reserve moi mon coming video conference non oldest [SEP]']
[Init] best perm rec loss: 0.8467389345169067 for ['[CLS]athlon oldest conference video coming reserve mon moi station non combat [SEP]']
[Init] best perm rec loss: 0.8465926051139832 for ['[CLS] moi oldest video station conference combat nonathlon reserve coming mon [SEP]']
[Init] best perm rec loss: 0.8462216258049011 for ['[CLS] reserve video station comingathlon combat non conference moi mon oldest [SEP]']
[Init] best perm rec loss: 0.8446699976921082 for ['[CLS] nonathlon mon station oldest combat video reserve moi coming conference [SEP]']
[Init] best perm rec loss: 0.8441019058227539 for ['[CLS] conference station reserveathlon oldest coming video combat mon non moi [SEP]']
[Init] best perm rec loss: 0.8434234261512756 for ['[CLS] combatathlon station video coming conference moi mon reserve non oldest [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.985 (perp=11.437, rec=0.728, cos=0.970), tot_loss_proj:4.041 [t=0.17s]
prediction: ['[CLS] infantry wrote in is various gene son saying grenade payment most [SEP]']
[ 100/2000] tot_loss=3.829 (perp=11.270, rec=0.580, cos=0.995), tot_loss_proj:4.029 [t=0.17s]
prediction: ['[CLS] read read, read various damn because saying constable bridge most [SEP]']
[ 150/2000] tot_loss=3.708 (perp=10.978, rec=0.525, cos=0.987), tot_loss_proj:3.969 [t=0.17s]
prediction: ['[CLS] read read. read various stupid because wanna stanley positions most [SEP]']
[ 200/2000] tot_loss=3.657 (perp=11.102, rec=0.445, cos=0.991), tot_loss_proj:3.978 [t=0.19s]
prediction: ['[CLS] read story, read aisles cartridge because wanna stanley letting most [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.550 (perp=10.102, rec=0.546, cos=0.983), tot_loss_proj:3.891 [t=0.20s]
prediction: ['[CLS] read story, read..., surviving want rearview relationship however [SEP]']
[ 300/2000] tot_loss=3.544 (perp=10.811, rec=0.415, cos=0.968), tot_loss_proj:3.992 [t=0.19s]
prediction: ['[CLS] read story, read although already surviving want http woman < [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.347 (perp=10.031, rec=0.404, cos=0.937), tot_loss_proj:3.847 [t=0.23s]
prediction: ['[CLS] read story, read davies also his want http although < [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.681 (perp=12.023, rec=0.393, cos=0.884), tot_loss_proj:4.181 [t=0.18s]
prediction: ['[CLS] read story, cartridge davies also his want httpflies ⟨ [SEP]']
[ 450/2000] tot_loss=3.306 (perp=10.732, rec=0.483, cos=0.676), tot_loss_proj:3.951 [t=0.17s]
prediction: ['[CLS] read story, although sofa because his wantrued executive ⟨ [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.357 (perp=9.299, rec=0.408, cos=0.088), tot_loss_proj:3.763 [t=0.18s]
prediction: ['[CLS] read stories, your because, wantleader, → della [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.074 (perp=8.806, rec=0.285, cos=0.028), tot_loss_proj:3.749 [t=0.18s]
prediction: ['[CLS] read your story,., wantleader stories ( actually [SEP]']
[ 600/2000] tot_loss=2.036 (perp=8.894, rec=0.240, cos=0.018), tot_loss_proj:3.646 [t=0.17s]
prediction: ['[CLS] read your story, also sick wantleader poems ( actually [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.070 (perp=9.167, rec=0.220, cos=0.016), tot_loss_proj:3.708 [t=0.18s]
prediction: ['[CLS] also read his story, evil want cousin poems ( privilege [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.885 (perp=8.276, rec=0.216, cos=0.014), tot_loss_proj:3.549 [t=0.18s]
prediction: ['[CLS] also read his story, want his, poems ( smashwords [SEP]']
[ 750/2000] tot_loss=1.825 (perp=8.048, rec=0.204, cos=0.012), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] also read his story, want his in poems ( smashwords [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.959 (perp=8.789, rec=0.190, cos=0.011), tot_loss_proj:3.576 [t=0.18s]
prediction: ['[CLS] also read his story, want in his politics fred smashwords [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.600 (perp=7.018, rec=0.185, cos=0.012), tot_loss_proj:3.356 [t=0.18s]
prediction: ['[CLS] to read his story, his want., fred actually [SEP]']
[ 900/2000] tot_loss=1.587 (perp=7.018, rec=0.173, cos=0.010), tot_loss_proj:3.354 [t=0.18s]
prediction: ['[CLS] to read his story, his want., fred actually [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.541 (perp=6.844, rec=0.162, cos=0.010), tot_loss_proj:3.325 [t=0.18s]
prediction: ['[CLS] to read his story, his want - fred. actually [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.456 (perp=6.440, rec=0.157, cos=0.011), tot_loss_proj:3.117 [t=0.19s]
prediction: ['[CLS] to read his story, his want actually fred. - [SEP]']
[1050/2000] tot_loss=1.463 (perp=6.440, rec=0.166, cos=0.009), tot_loss_proj:3.121 [t=0.18s]
prediction: ['[CLS] to read his story, his want actually fred. - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.460 (perp=6.467, rec=0.158, cos=0.009), tot_loss_proj:3.152 [t=0.18s]
prediction: ['[CLS] to read his story, his want also fred. - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.452 (perp=6.467, rec=0.150, cos=0.009), tot_loss_proj:3.156 [t=0.17s]
prediction: ['[CLS] to read his story, his want also fred. - [SEP]']
[1200/2000] tot_loss=1.725 (perp=7.831, rec=0.150, cos=0.009), tot_loss_proj:3.316 [t=0.17s]
prediction: ['[CLS] to read fred story, his want also fred. - [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.625 (perp=7.321, rec=0.151, cos=0.010), tot_loss_proj:3.261 [t=0.17s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.622 (perp=7.321, rec=0.148, cos=0.009), tot_loss_proj:3.256 [t=0.17s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
[1350/2000] tot_loss=1.616 (perp=7.321, rec=0.143, cos=0.009), tot_loss_proj:3.259 [t=0.17s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.620 (perp=7.321, rec=0.147, cos=0.009), tot_loss_proj:3.259 [t=0.18s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.623 (perp=7.321, rec=0.149, cos=0.009), tot_loss_proj:3.258 [t=0.18s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
[1500/2000] tot_loss=1.627 (perp=7.321, rec=0.154, cos=0.009), tot_loss_proj:3.258 [t=0.18s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.611 (perp=7.321, rec=0.138, cos=0.009), tot_loss_proj:3.254 [t=0.18s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.612 (perp=7.321, rec=0.139, cos=0.009), tot_loss_proj:3.257 [t=0.18s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
[1650/2000] tot_loss=1.614 (perp=7.321, rec=0.141, cos=0.009), tot_loss_proj:3.257 [t=0.17s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.624 (perp=7.321, rec=0.151, cos=0.009), tot_loss_proj:3.257 [t=0.17s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.610 (perp=7.321, rec=0.137, cos=0.009), tot_loss_proj:3.254 [t=0.17s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
[1800/2000] tot_loss=1.600 (perp=7.321, rec=0.128, cos=0.009), tot_loss_proj:3.258 [t=0.17s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.611 (perp=7.321, rec=0.138, cos=0.009), tot_loss_proj:3.257 [t=0.17s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.607 (perp=7.321, rec=0.134, cos=0.009), tot_loss_proj:3.256 [t=0.17s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
[1950/2000] tot_loss=1.609 (perp=7.321, rec=0.136, cos=0.009), tot_loss_proj:3.258 [t=0.18s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.609 (perp=7.321, rec=0.137, cos=0.009), tot_loss_proj:3.259 [t=0.17s]
prediction: ['[CLS] to read fred story his want, also fred. - [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] read fred's story, i also want to. [SEP]
========================
predicted: 
========================
[CLS] to read fred story his want, also fred. - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 91.111

[Aggregate metrics]:
rouge1     | fm: 81.697 | p: 82.791 | r: 80.881
rouge2     | fm: 36.155 | p: 36.451 | r: 36.042
rougeL     | fm: 67.240 | p: 67.985 | r: 66.593
rougeLsum  | fm: 67.015 | p: 67.840 | r: 66.423
r1fm+r2fm = 117.853

input #30 time: 0:07:16 | total time: 3:44:35


Running input #31 of 100.
reference: 
========================
Some of the water from melted snow also goes into the ground for plants.
========================
average of cosine similarity 0.9992295707454686
highest_index [0]
highest [0.9992295707454686]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2070,  1997,  1996,  2300,  2013, 12501,  4586,  2036,  3632,
          2046,  1996,  2598,  2005,  4264,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]']
[Init] best rec loss: 0.9458415508270264 for ["[CLS] girlfriend set faculty clay angeles boom cross bandonus sh 'tical mistake inn ballard [SEP]"]
[Init] best rec loss: 0.922178328037262 for ['[CLS] ace brady declared temples eight simply { doi clapped content unit foot npr chargedtro [SEP]']
[Init] best rec loss: 0.912794828414917 for ['[CLS] spaceship mercy loanbil spoken continued gun quentin merit closed abrl asked chemistry states [SEP]']
[Init] best rec loss: 0.9126591086387634 for ['[CLS] modern currently joey press trent bed reaching main herzegovina mahmoud recent may prescription cover french [SEP]']
[Init] best rec loss: 0.9065945744514465 for ['[CLS] carolina wonder calendar macy rocktill students power search under length laketia greg lowest [SEP]']
[Init] best rec loss: 0.8944409489631653 for ['[CLS] colt vampires well apartheid general viscount skate lend absolutely and tension dramatic diner chief level [SEP]']
[Init] best rec loss: 0.8925084471702576 for ['[CLS]agi independentnished spruce campus best george any crawford ft goals poetry mushroom unaoulos [SEP]']
[Init] best perm rec loss: 0.8879450559616089 for ['[CLS]nished spruce campus any mushroom unaoulos ft georgeagi independent best poetry goals crawford [SEP]']
[Init] best perm rec loss: 0.8877514600753784 for ['[CLS]oulos independent campus anyagi spruce best george poetry ft mushroom crawfordnished goals una [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.715 (perp=12.241, rec=0.819, cos=0.448), tot_loss_proj:4.284 [t=0.18s]
prediction: ['[CLS]forth ki parts more material uses brakes save several. telescope military until thermal melting [SEP]']
[ 100/2000] tot_loss=2.798 (perp=12.043, rec=0.352, cos=0.038), tot_loss_proj:4.296 [t=0.18s]
prediction: ['[CLS] milk tracks - still water uses snow synthetic many battles healing military world crash reduction [SEP]']
[ 150/2000] tot_loss=2.508 (perp=10.637, rec=0.342, cos=0.039), tot_loss_proj:4.025 [t=0.18s]
prediction: ['[CLS] cold lake - more water uses snow his other battles ash military world hit stories [SEP]']
[ 200/2000] tot_loss=2.366 (perp=10.306, rec=0.286, cos=0.019), tot_loss_proj:3.939 [t=0.18s]
prediction: ['[CLS] cold lake of more water goes snow his other plant water accident world stops stories [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.222 (perp=9.740, rec=0.256, cos=0.018), tot_loss_proj:3.806 [t=0.18s]
prediction: ['[CLS] his lake of some water goes snow cold other plants water accident asian into stories [SEP]']
[ 300/2000] tot_loss=2.198 (perp=9.460, rec=0.276, cos=0.031), tot_loss_proj:3.718 [t=0.18s]
prediction: ['[CLS] his lake of some snow goes snow cold the plants water partially asian into water [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.912 (perp=8.344, rec=0.232, cos=0.012), tot_loss_proj:3.478 [t=0.18s]
prediction: ['[CLS] off lake of some plants goes snow snow the snow water mountain asian for water [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.841 (perp=8.066, rec=0.217, cos=0.011), tot_loss_proj:3.464 [t=0.18s]
prediction: ['[CLS] from lake of some plants goes plants snow the snow water for melted mountain water [SEP]']
[ 450/2000] tot_loss=1.827 (perp=8.123, rec=0.193, cos=0.009), tot_loss_proj:3.477 [t=0.18s]
prediction: ['[CLS] from water of some plants goes plants snow the snow water for melted melted water [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.861 (perp=8.328, rec=0.187, cos=0.008), tot_loss_proj:3.544 [t=0.18s]
prediction: ['[CLS] from water of some for goes northern plants the snow water for melted melted water [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.829 (perp=8.179, rec=0.185, cos=0.008), tot_loss_proj:3.505 [t=0.18s]
prediction: ['[CLS] from water of some for goes northern plants the snow for melted water melted water [SEP]']
[ 600/2000] tot_loss=1.816 (perp=8.179, rec=0.173, cos=0.007), tot_loss_proj:3.501 [t=0.18s]
prediction: ['[CLS] from water of some for goes northern plants the snow for melted water melted water [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.769 (perp=7.922, rec=0.176, cos=0.009), tot_loss_proj:3.462 [t=0.18s]
prediction: ['[CLS] from water for some of goes northern plants the snow for melted water melted water [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.737 (perp=7.832, rec=0.164, cos=0.007), tot_loss_proj:3.437 [t=0.18s]
prediction: ['[CLS] from water for some goes of northern plants the snow for melted water melted water [SEP]']
[ 750/2000] tot_loss=1.659 (perp=7.466, rec=0.159, cos=0.006), tot_loss_proj:3.379 [t=0.18s]
prediction: ['[CLS] from water for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.650 (perp=7.466, rec=0.151, cos=0.006), tot_loss_proj:3.381 [t=0.18s]
prediction: ['[CLS] from water for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.657 (perp=7.466, rec=0.159, cos=0.005), tot_loss_proj:3.382 [t=0.18s]
prediction: ['[CLS] from water for some goes of melted plants the snow for melted water melted water [SEP]']
[ 900/2000] tot_loss=1.650 (perp=7.466, rec=0.151, cos=0.006), tot_loss_proj:3.383 [t=0.18s]
prediction: ['[CLS] from water for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.653 (perp=7.466, rec=0.154, cos=0.005), tot_loss_proj:3.380 [t=0.18s]
prediction: ['[CLS] from water for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1000/2000] tot_loss=1.704 (perp=7.764, rec=0.146, cos=0.005), tot_loss_proj:3.439 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
[1050/2000] tot_loss=1.708 (perp=7.764, rec=0.150, cos=0.005), tot_loss_proj:3.438 [t=0.17s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1100/2000] tot_loss=1.696 (perp=7.764, rec=0.138, cos=0.005), tot_loss_proj:3.437 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1150/2000] tot_loss=1.705 (perp=7.764, rec=0.147, cos=0.005), tot_loss_proj:3.436 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
[1200/2000] tot_loss=1.700 (perp=7.764, rec=0.143, cos=0.005), tot_loss_proj:3.444 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1250/2000] tot_loss=1.696 (perp=7.764, rec=0.138, cos=0.005), tot_loss_proj:3.434 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1300/2000] tot_loss=1.698 (perp=7.764, rec=0.140, cos=0.005), tot_loss_proj:3.435 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
[1350/2000] tot_loss=1.697 (perp=7.764, rec=0.140, cos=0.004), tot_loss_proj:3.437 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1400/2000] tot_loss=1.690 (perp=7.764, rec=0.132, cos=0.005), tot_loss_proj:3.438 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1450/2000] tot_loss=1.695 (perp=7.764, rec=0.138, cos=0.004), tot_loss_proj:3.439 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
[1500/2000] tot_loss=1.684 (perp=7.764, rec=0.126, cos=0.004), tot_loss_proj:3.439 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1550/2000] tot_loss=1.692 (perp=7.764, rec=0.135, cos=0.004), tot_loss_proj:3.436 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1600/2000] tot_loss=1.687 (perp=7.764, rec=0.130, cos=0.004), tot_loss_proj:3.438 [t=0.19s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
[1650/2000] tot_loss=1.696 (perp=7.764, rec=0.138, cos=0.004), tot_loss_proj:3.440 [t=0.20s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1700/2000] tot_loss=1.687 (perp=7.764, rec=0.130, cos=0.004), tot_loss_proj:3.437 [t=0.19s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1750/2000] tot_loss=1.694 (perp=7.764, rec=0.137, cos=0.004), tot_loss_proj:3.437 [t=0.17s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
[1800/2000] tot_loss=1.691 (perp=7.764, rec=0.133, cos=0.004), tot_loss_proj:3.440 [t=0.17s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1850/2000] tot_loss=1.691 (perp=7.764, rec=0.133, cos=0.004), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]']
Attempt swap
[1900/2000] tot_loss=1.744 (perp=8.061, rec=0.128, cos=0.004), tot_loss_proj:3.500 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted ground melted water [SEP]']
[1950/2000] tot_loss=1.747 (perp=8.061, rec=0.130, cos=0.004), tot_loss_proj:3.502 [t=0.18s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted ground melted water [SEP]']
Attempt swap
[2000/2000] tot_loss=1.743 (perp=8.061, rec=0.127, cos=0.004), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] from ground for some goes of melted plants the snow for melted ground melted water [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]
========================
predicted: 
========================
[CLS] from ground for some goes of melted plants the snow for melted water melted water [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.788 | p: 76.471 | r: 81.250
rouge2     | fm: 6.452 | p: 6.250 | r: 6.667
rougeL     | fm: 42.424 | p: 41.176 | r: 43.750
rougeLsum  | fm: 42.424 | p: 41.176 | r: 43.750
r1fm+r2fm = 85.239

[Aggregate metrics]:
rouge1     | fm: 81.596 | p: 82.532 | r: 80.928
rouge2     | fm: 35.192 | p: 35.583 | r: 34.963
rougeL     | fm: 66.386 | p: 67.113 | r: 65.927
rougeLsum  | fm: 66.021 | p: 66.797 | r: 65.472
r1fm+r2fm = 116.788

input #31 time: 0:07:29 | total time: 3:52:05


Running input #32 of 100.
reference: 
========================
Bob is very serious about Mary, but less so than Paul.
========================
average of cosine similarity 0.9993563156377977
highest_index [0]
highest [0.9993563156377977]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[ 101, 3960, 2003, 2200, 3809, 2055, 2984, 1010, 2021, 2625, 2061, 2084,
         2703, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bob is very serious about mary, but less so than paul. [SEP]']
[Init] best rec loss: 0.9588392376899719 for ['[CLS] archery dual„ pam an arrows kings beyond if rev up place behind [SEP]']
[Init] best rec loss: 0.9246671795845032 for ['[CLS] minnesota greeceignantach supplied process + after atletico memorialpee degrees blur [SEP]']
[Init] best rec loss: 0.9175419211387634 for ['[CLS] transitium through comeedd im slaughtered sympathy opening as directorcu hint [SEP]']
[Init] best rec loss: 0.9033082127571106 for ['[CLS] records copy middle sr ( partly challenged skin dowager must warner with pick [SEP]']
[Init] best rec loss: 0.900634765625 for ['[CLS] spikeen august but collaboration golf age howlage giro inflation etched form [SEP]']
[Init] best rec loss: 0.8903785347938538 for ['[CLS] inactive chip wantedwaterville career twenties shear reign janeiroable shame floor [SEP]']
[Init] best rec loss: 0.8777366280555725 for ['[CLS] arts hardly labor hi nosestage it what short balloonab champion nightmares [SEP]']
[Init] best rec loss: 0.876878559589386 for ['[CLS] missed ev talon hope thinking white g producerator practice well overly it [SEP]']
[Init] best perm rec loss: 0.876000702381134 for ['[CLS] missed producer practice thinking white hope g wellator it overly ev talon [SEP]']
[Init] best perm rec loss: 0.874030590057373 for ['[CLS] producer talon overlyator it g practice well hope white ev thinking missed [SEP]']
[Init] best perm rec loss: 0.873460054397583 for ['[CLS] g hope missed white overly talon practiceator ev thinking it well producer [SEP]']
[Init] best perm rec loss: 0.8725891709327698 for ['[CLS] well whiteator thinking talon hope missed practice overly g it ev producer [SEP]']
[Init] best perm rec loss: 0.8714865446090698 for ['[CLS] overlyator it ev thinking producer hope missed g talon practice well white [SEP]']
[Init] best perm rec loss: 0.8703650236129761 for ['[CLS] practice producer missed overly thinking ev talon whiteator hope g it well [SEP]']
[Init] best perm rec loss: 0.8692450523376465 for ['[CLS] missed producer overly evator practice talon hope well white g thinking it [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.078 (perp=11.090, rec=0.539, cos=0.321), tot_loss_proj:4.029 [t=0.19s]
prediction: ['[CLS]. not slip serious leash levelsingly spread beneath ambulance :. him [SEP]']
[ 100/2000] tot_loss=2.457 (perp=10.723, rec=0.298, cos=0.015), tot_loss_proj:4.035 [t=0.19s]
prediction: ['[CLS] paul not paul serious bob mary commonly jesus is serious indeed. without [SEP]']
[ 150/2000] tot_loss=2.190 (perp=9.563, rec=0.264, cos=0.013), tot_loss_proj:3.817 [t=0.19s]
prediction: ['[CLS] paul not paul serious bob mary for mary is serious very. serious [SEP]']
[ 200/2000] tot_loss=1.993 (perp=8.750, rec=0.232, cos=0.011), tot_loss_proj:3.603 [t=0.19s]
prediction: ['[CLS] paul when paul serious really mary for mary is serious very. serious [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.768 (perp=7.775, rec=0.207, cos=0.006), tot_loss_proj:3.413 [t=0.21s]
prediction: ['[CLS] paul when paul serious really mary for mary is serious very serious. [SEP]']
[ 300/2000] tot_loss=2.153 (perp=9.677, rec=0.209, cos=0.009), tot_loss_proj:3.763 [t=0.19s]
prediction: ['[CLS] bob when paul serious serious mary for mary is serious very less. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.398 (perp=10.568, rec=0.267, cos=0.017), tot_loss_proj:3.977 [t=0.19s]
prediction: ['[CLS] bob oh paul serious almost mary than mary less serious is serious. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.038 (perp=8.947, rec=0.233, cos=0.016), tot_loss_proj:3.589 [t=0.19s]
prediction: ['[CLS] less because bob but very about than mary bob serious is serious. [SEP]']
[ 450/2000] tot_loss=1.977 (perp=8.947, rec=0.179, cos=0.009), tot_loss_proj:3.587 [t=0.19s]
prediction: ['[CLS] less because bob but very about than mary bob serious is serious. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.774 (perp=7.979, rec=0.170, cos=0.008), tot_loss_proj:3.440 [t=0.17s]
prediction: ['[CLS] less than paul but very about because mary bob more is serious. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.663 (perp=7.501, rec=0.155, cos=0.008), tot_loss_proj:3.278 [t=0.19s]
prediction: ['[CLS] less than paul but mary about because very bob less is serious. [SEP]']
[ 600/2000] tot_loss=1.649 (perp=7.501, rec=0.144, cos=0.005), tot_loss_proj:3.281 [t=0.23s]
prediction: ['[CLS] less than paul but mary about because very bob less is serious. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.854 (perp=8.606, rec=0.129, cos=0.004), tot_loss_proj:3.567 [t=0.18s]
prediction: ['[CLS] than than paul but mary about. very bob less is serious. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.803 (perp=8.329, rec=0.132, cos=0.006), tot_loss_proj:3.480 [t=0.19s]
prediction: ['[CLS] than is paul but mary about than very bob less than serious. [SEP]']
[ 750/2000] tot_loss=1.666 (perp=7.695, rec=0.123, cos=0.004), tot_loss_proj:3.378 [t=0.19s]
prediction: ['[CLS] than is paul but mary about. very bob less than serious. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.530 (perp=7.058, rec=0.115, cos=0.003), tot_loss_proj:3.301 [t=0.19s]
prediction: ['[CLS] than is paul but mary about. very serious less than bob. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.523 (perp=7.058, rec=0.109, cos=0.003), tot_loss_proj:3.301 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. very serious less than bob. [SEP]']
[ 900/2000] tot_loss=1.516 (perp=7.058, rec=0.102, cos=0.003), tot_loss_proj:3.301 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. very serious less than bob. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.519 (perp=7.058, rec=0.104, cos=0.003), tot_loss_proj:3.298 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. very serious less than bob. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.519 (perp=7.058, rec=0.105, cos=0.003), tot_loss_proj:3.299 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. very serious less than bob. [SEP]']
[1050/2000] tot_loss=1.515 (perp=7.058, rec=0.101, cos=0.002), tot_loss_proj:3.294 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. very serious less than bob. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.515 (perp=7.058, rec=0.101, cos=0.002), tot_loss_proj:3.298 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. very serious less than bob. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.410 (perp=6.508, rec=0.105, cos=0.004), tot_loss_proj:3.226 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
[1200/2000] tot_loss=1.399 (perp=6.508, rec=0.095, cos=0.003), tot_loss_proj:3.225 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.401 (perp=6.508, rec=0.097, cos=0.002), tot_loss_proj:3.224 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.403 (perp=6.508, rec=0.099, cos=0.002), tot_loss_proj:3.227 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
[1350/2000] tot_loss=1.393 (perp=6.508, rec=0.089, cos=0.002), tot_loss_proj:3.224 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.396 (perp=6.508, rec=0.093, cos=0.002), tot_loss_proj:3.226 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.398 (perp=6.508, rec=0.095, cos=0.002), tot_loss_proj:3.227 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
[1500/2000] tot_loss=1.403 (perp=6.508, rec=0.099, cos=0.002), tot_loss_proj:3.229 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.405 (perp=6.508, rec=0.102, cos=0.002), tot_loss_proj:3.225 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.394 (perp=6.508, rec=0.091, cos=0.002), tot_loss_proj:3.229 [t=0.22s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
[1650/2000] tot_loss=1.406 (perp=6.508, rec=0.102, cos=0.002), tot_loss_proj:3.226 [t=0.20s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.395 (perp=6.508, rec=0.092, cos=0.002), tot_loss_proj:3.223 [t=0.19s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.401 (perp=6.508, rec=0.097, cos=0.002), tot_loss_proj:3.225 [t=0.19s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
[1800/2000] tot_loss=1.400 (perp=6.508, rec=0.096, cos=0.002), tot_loss_proj:3.227 [t=0.22s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.393 (perp=6.508, rec=0.089, cos=0.002), tot_loss_proj:3.229 [t=0.18s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.394 (perp=6.508, rec=0.091, cos=0.002), tot_loss_proj:3.227 [t=0.19s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
[1950/2000] tot_loss=1.395 (perp=6.508, rec=0.092, cos=0.002), tot_loss_proj:3.228 [t=0.19s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.394 (perp=6.508, rec=0.091, cos=0.002), tot_loss_proj:3.229 [t=0.17s]
prediction: ['[CLS] than is paul but mary about. less very serious than bob. [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] bob is very serious about mary, but less so than paul. [SEP]
========================
predicted: 
========================
[CLS] than is paul but mary about. less very serious than bob. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 8.333 | p: 8.333 | r: 8.333
rougeL     | fm: 46.154 | p: 46.154 | r: 46.154
rougeLsum  | fm: 46.154 | p: 46.154 | r: 46.154
r1fm+r2fm = 100.641

[Aggregate metrics]:
rouge1     | fm: 81.928 | p: 82.882 | r: 81.268
rouge2     | fm: 34.744 | p: 35.084 | r: 34.615
rougeL     | fm: 65.672 | p: 66.356 | r: 65.172
rougeLsum  | fm: 65.776 | p: 66.499 | r: 65.250
r1fm+r2fm = 116.671

input #32 time: 0:07:24 | total time: 3:59:29


Running input #33 of 100.
reference: 
========================
Ayala sent the diamond necklace back.
========================
average of cosine similarity 0.9993190743310341
highest_index [0]
highest [0.9993190743310341]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  1996,  6323, 13016,  2067,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] ayala sent the diamond necklace back. [SEP]']
[Init] best rec loss: 1.0263526439666748 for ['[CLS] terms primary contribution an soil all competition dug [SEP]']
[Init] best rec loss: 0.9502540230751038 for ['[CLS] militiaiom slim lei daryl dip bay well [SEP]']
[Init] best rec loss: 0.9274391531944275 for ['[CLS] langley 9 shoe soon tray originally ha inclined [SEP]']
[Init] best rec loss: 0.9139430522918701 for ['[CLS] strikingenberg online poland silver through proper comfort [SEP]']
[Init] best rec loss: 0.913354754447937 for ['[CLS] dante railroad stage headeddictz prostate abby [SEP]']
[Init] best perm rec loss: 0.912300705909729 for ['[CLS] railroad headedzdict abby dante stage prostate [SEP]']
[Init] best perm rec loss: 0.9117847084999084 for ['[CLS] railroadz abby dante headed prostate stagedict [SEP]']
[Init] best perm rec loss: 0.9092954993247986 for ['[CLS] dantez prostatedict railroad headed stage abby [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.492 (perp=10.370, rec=0.371, cos=0.046), tot_loss_proj:3.993 [t=0.19s]
prediction: ['[CLS] instead necklace.yalayce sent ayala [SEP]']
[ 100/2000] tot_loss=1.968 (perp=8.779, rec=0.198, cos=0.014), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] with necklace ayalayala sent ayala [SEP]']
[ 150/2000] tot_loss=2.053 (perp=9.495, rec=0.147, cos=0.007), tot_loss_proj:3.968 [t=0.17s]
prediction: ['[CLS] back necklace ayalayala sent ayala [SEP]']
[ 200/2000] tot_loss=2.123 (perp=9.983, rec=0.121, cos=0.005), tot_loss_proj:3.962 [t=0.17s]
prediction: ['[CLS] back necklace.yala necklace sent ayala [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.024 (perp=9.578, rec=0.104, cos=0.005), tot_loss_proj:3.919 [t=0.17s]
prediction: ['[CLS] necklace back theyala necklace sent ayala [SEP]']
[ 300/2000] tot_loss=1.884 (perp=8.955, rec=0.089, cos=0.004), tot_loss_proj:3.738 [t=0.17s]
prediction: ['[CLS] necklace back the diamond diamond sent ayala [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.651 (perp=7.738, rec=0.098, cos=0.006), tot_loss_proj:3.483 [t=0.17s]
prediction: ['[CLS] diamond necklace back the diamond sent ayala [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.632 (perp=6.618, rec=0.271, cos=0.037), tot_loss_proj:3.272 [t=0.17s]
prediction: ['[CLS] diamond sent back the diamond necklace ayala [SEP]']
[ 450/2000] tot_loss=1.727 (perp=7.887, rec=0.142, cos=0.007), tot_loss_proj:3.562 [t=0.17s]
prediction: ['[CLS]zziness sent back the diamond necklace ayala [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.643 (perp=7.625, rec=0.113, cos=0.006), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.621 (perp=7.625, rec=0.091, cos=0.006), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
[ 600/2000] tot_loss=1.620 (perp=7.625, rec=0.089, cos=0.006), tot_loss_proj:3.696 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.611 (perp=7.625, rec=0.081, cos=0.006), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.612 (perp=7.625, rec=0.081, cos=0.005), tot_loss_proj:3.697 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
[ 750/2000] tot_loss=1.612 (perp=7.625, rec=0.082, cos=0.005), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.611 (perp=7.625, rec=0.081, cos=0.005), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.621 (perp=7.625, rec=0.091, cos=0.005), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
[ 900/2000] tot_loss=1.612 (perp=7.625, rec=0.082, cos=0.005), tot_loss_proj:3.700 [t=0.19s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.608 (perp=7.625, rec=0.078, cos=0.005), tot_loss_proj:3.699 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1000/2000] tot_loss=1.608 (perp=7.625, rec=0.078, cos=0.005), tot_loss_proj:3.696 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
[1050/2000] tot_loss=1.610 (perp=7.625, rec=0.080, cos=0.005), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1100/2000] tot_loss=1.606 (perp=7.625, rec=0.076, cos=0.005), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1150/2000] tot_loss=1.598 (perp=7.625, rec=0.068, cos=0.005), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
[1200/2000] tot_loss=1.609 (perp=7.625, rec=0.079, cos=0.005), tot_loss_proj:3.707 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1250/2000] tot_loss=1.612 (perp=7.625, rec=0.082, cos=0.005), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1300/2000] tot_loss=1.607 (perp=7.625, rec=0.076, cos=0.005), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
[1350/2000] tot_loss=1.616 (perp=7.625, rec=0.086, cos=0.005), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1400/2000] tot_loss=1.609 (perp=7.625, rec=0.079, cos=0.005), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1450/2000] tot_loss=1.606 (perp=7.625, rec=0.076, cos=0.005), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
[1500/2000] tot_loss=1.611 (perp=7.625, rec=0.081, cos=0.005), tot_loss_proj:3.708 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1550/2000] tot_loss=1.611 (perp=7.625, rec=0.081, cos=0.005), tot_loss_proj:3.701 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1600/2000] tot_loss=1.611 (perp=7.625, rec=0.081, cos=0.005), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
[1650/2000] tot_loss=1.607 (perp=7.625, rec=0.077, cos=0.005), tot_loss_proj:3.710 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1700/2000] tot_loss=1.607 (perp=7.625, rec=0.077, cos=0.005), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1750/2000] tot_loss=1.607 (perp=7.625, rec=0.077, cos=0.005), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
[1800/2000] tot_loss=1.610 (perp=7.625, rec=0.080, cos=0.005), tot_loss_proj:3.702 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1850/2000] tot_loss=1.602 (perp=7.625, rec=0.072, cos=0.005), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[1900/2000] tot_loss=1.610 (perp=7.625, rec=0.080, cos=0.005), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
[1950/2000] tot_loss=1.611 (perp=7.625, rec=0.081, cos=0.005), tot_loss_proj:3.699 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Attempt swap
[2000/2000] tot_loss=1.612 (perp=7.625, rec=0.082, cos=0.005), tot_loss_proj:3.699 [t=0.17s]
prediction: ['[CLS] a sent back the diamond necklace ayala [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] ayala sent the diamond necklace back. [SEP]
========================
predicted: 
========================
[CLS] a sent back the diamond necklace ayala [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 26.667 | p: 25.000 | r: 28.571
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 120.784

[Aggregate metrics]:
rouge1     | fm: 82.199 | p: 82.950 | r: 81.787
rouge2     | fm: 34.382 | p: 34.621 | r: 34.389
rougeL     | fm: 65.860 | p: 66.427 | r: 65.525
rougeLsum  | fm: 65.785 | p: 66.452 | r: 65.444
r1fm+r2fm = 116.580

input #33 time: 0:06:55 | total time: 4:06:24


Running input #34 of 100.
reference: 
========================
Jessica sprayed paint under the table.
========================
average of cosine similarity 0.9993079982050087
highest_index [0]
highest [0.9993079982050087]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  8201, 25401,  6773,  2104,  1996,  2795,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] jessica sprayed paint under the table. [SEP]']
[Init] best rec loss: 0.9414330720901489 for ['[CLS] solvent pure sitting returns open penelope gerais [SEP]']
[Init] best rec loss: 0.9049432277679443 for ['[CLS]vision best te sided ms lowest elected [SEP]']
[Init] best rec loss: 0.899651825428009 for ['[CLS]iating achievement tablet navy raaf commissionvet [SEP]']
[Init] best rec loss: 0.8826460838317871 for ['[CLS]ter & since cureraßeeratednes [SEP]']
[Init] best perm rec loss: 0.8818284273147583 for ['[CLS]nes cure &terraßeerated since [SEP]']
[Init] best perm rec loss: 0.8814307451248169 for ['[CLS] sinceerated cureraßeter &nes [SEP]']
[Init] best perm rec loss: 0.8780422210693359 for ['[CLS]eratedterraße & curenes since [SEP]']
[Init] best perm rec loss: 0.8755910396575928 for ['[CLS]tererated &nes cure sinceraße [SEP]']
[Init] best perm rec loss: 0.8677996397018433 for ['[CLS]raßeter &nes cureerated since [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.778 (perp=11.247, rec=0.695, cos=0.833), tot_loss_proj:4.110 [t=0.17s]
prediction: ['[CLS] help hit & defeat tyne wife modeled [SEP]']
[ 100/2000] tot_loss=3.613 (perp=10.380, rec=0.564, cos=0.973), tot_loss_proj:3.975 [t=0.17s]
prediction: ['[CLS] lipstick off & produced ; jessicaisance [SEP]']
[ 150/2000] tot_loss=2.751 (perp=11.113, rec=0.406, cos=0.123), tot_loss_proj:4.230 [t=0.19s]
prediction: ['[CLS] jessica blow & renee examiner jessica jessica [SEP]']
[ 200/2000] tot_loss=2.457 (perp=11.227, rec=0.198, cos=0.014), tot_loss_proj:4.307 [t=0.17s]
prediction: ['[CLS] paint blow. sprayed paint jessica jessica [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.603 (perp=11.701, rec=0.238, cos=0.025), tot_loss_proj:4.324 [t=0.17s]
prediction: ['[CLS] paint off jessica sprayed paint table jessica [SEP]']
[ 300/2000] tot_loss=2.499 (perp=11.701, rec=0.150, cos=0.009), tot_loss_proj:4.251 [t=0.17s]
prediction: ['[CLS] paint off jessica sprayed paint table jessica [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.325 (perp=10.954, rec=0.127, cos=0.007), tot_loss_proj:4.145 [t=0.17s]
prediction: ['[CLS] paint table jessica sprayed paint under jessica [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.234 (perp=10.422, rec=0.140, cos=0.009), tot_loss_proj:3.982 [t=0.17s]
prediction: ['[CLS] paint jessica sprayed table paint under missiles [SEP]']
[ 450/2000] tot_loss=2.210 (perp=10.422, rec=0.121, cos=0.005), tot_loss_proj:4.076 [t=0.17s]
prediction: ['[CLS] paint jessica sprayed table paint under missiles [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.772 (perp=8.232, rec=0.120, cos=0.005), tot_loss_proj:3.369 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint table paint under. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.652 (perp=7.712, rec=0.104, cos=0.005), tot_loss_proj:2.204 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
[ 600/2000] tot_loss=1.641 (perp=7.712, rec=0.094, cos=0.005), tot_loss_proj:2.165 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.639 (perp=7.712, rec=0.092, cos=0.005), tot_loss_proj:2.150 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.637 (perp=7.712, rec=0.090, cos=0.004), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
[ 750/2000] tot_loss=1.648 (perp=7.712, rec=0.102, cos=0.004), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.641 (perp=7.712, rec=0.094, cos=0.005), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.630 (perp=7.712, rec=0.084, cos=0.004), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
[ 900/2000] tot_loss=1.628 (perp=7.712, rec=0.082, cos=0.004), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.633 (perp=7.712, rec=0.087, cos=0.004), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.635 (perp=7.712, rec=0.088, cos=0.004), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
[1050/2000] tot_loss=1.635 (perp=7.712, rec=0.088, cos=0.004), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.644 (perp=7.712, rec=0.098, cos=0.004), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.632 (perp=7.712, rec=0.084, cos=0.006), tot_loss_proj:2.109 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
[1200/2000] tot_loss=1.633 (perp=7.712, rec=0.086, cos=0.004), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.638 (perp=7.712, rec=0.092, cos=0.004), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.621 (perp=7.712, rec=0.075, cos=0.004), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
[1350/2000] tot_loss=1.629 (perp=7.712, rec=0.082, cos=0.004), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.619 (perp=7.712, rec=0.073, cos=0.004), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.619 (perp=7.712, rec=0.073, cos=0.004), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
[1500/2000] tot_loss=1.620 (perp=7.712, rec=0.074, cos=0.004), tot_loss_proj:2.094 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.631 (perp=7.712, rec=0.085, cos=0.004), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.624 (perp=7.712, rec=0.078, cos=0.004), tot_loss_proj:2.099 [t=0.19s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
[1650/2000] tot_loss=1.641 (perp=7.712, rec=0.095, cos=0.004), tot_loss_proj:2.098 [t=0.19s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.623 (perp=7.712, rec=0.077, cos=0.004), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.626 (perp=7.712, rec=0.080, cos=0.004), tot_loss_proj:2.089 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
[1800/2000] tot_loss=1.630 (perp=7.712, rec=0.084, cos=0.004), tot_loss_proj:2.089 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.628 (perp=7.712, rec=0.082, cos=0.004), tot_loss_proj:2.093 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.630 (perp=7.712, rec=0.084, cos=0.004), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
[1950/2000] tot_loss=1.627 (perp=7.712, rec=0.082, cos=0.004), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.613 (perp=7.712, rec=0.068, cos=0.004), tot_loss_proj:2.094 [t=0.17s]
prediction: ['[CLS] jessica sprayed paint under table paint. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] jessica sprayed paint under the table. [SEP]
========================
predicted: 
========================
[CLS] jessica sprayed paint under table paint. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 144.643

[Aggregate metrics]:
rouge1     | fm: 82.311 | p: 83.064 | r: 81.865
rouge2     | fm: 34.969 | p: 35.326 | r: 34.904
rougeL     | fm: 66.444 | p: 66.952 | r: 66.053
rougeLsum  | fm: 66.620 | p: 67.152 | r: 66.189
r1fm+r2fm = 117.280

input #34 time: 0:06:59 | total time: 4:13:24


Running input #35 of 100.
reference: 
========================
John is refused.
========================
average of cosine similarity 0.9992893523444286
highest_index [0]
highest [0.9992893523444286]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2198, 2003, 4188, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is refused. [SEP]']
[Init] best rec loss: 0.9893831610679626 for ['[CLS] hugo cruise than seconds [SEP]']
[Init] best rec loss: 0.9861062169075012 for ['[CLS] painful friendly reputation popularity [SEP]']
[Init] best rec loss: 0.8789446949958801 for ['[CLS] wings property warned wish [SEP]']
[Init] best rec loss: 0.8721048831939697 for ['[CLS] community evenly development appealed [SEP]']
[Init] best rec loss: 0.8641420006752014 for ['[CLS]estinal atanger toilet [SEP]']
[Init] best perm rec loss: 0.8629884719848633 for ['[CLS] toiletanger atestinal [SEP]']
[Init] best perm rec loss: 0.8620949983596802 for ['[CLS] toiletestinalanger at [SEP]']
[Init] best perm rec loss: 0.861962616443634 for ['[CLS]estinalanger toilet at [SEP]']
[Init] best perm rec loss: 0.8614445924758911 for ['[CLS] atestinalanger toilet [SEP]']
[Init] best perm rec loss: 0.8610238432884216 for ['[CLS] atanger toiletestinal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.110 (perp=10.332, rec=0.568, cos=0.475), tot_loss_proj:3.965 [t=0.17s]
prediction: ['[CLS] became santa were refused [SEP]']
[ 100/2000] tot_loss=2.390 (perp=10.200, rec=0.312, cos=0.038), tot_loss_proj:3.888 [t=0.18s]
prediction: ['[CLS].ni are refused [SEP]']
[ 150/2000] tot_loss=2.480 (perp=9.954, rec=0.386, cos=0.103), tot_loss_proj:3.897 [t=0.18s]
prediction: ['[CLS] is john are refused [SEP]']
[ 200/2000] tot_loss=2.198 (perp=9.954, rec=0.192, cos=0.016), tot_loss_proj:3.908 [t=0.17s]
prediction: ['[CLS] is john are refused [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.447 (perp=9.370, rec=0.447, cos=0.126), tot_loss_proj:3.744 [t=0.17s]
prediction: ['[CLS] john is is refused [SEP]']
[ 300/2000] tot_loss=2.230 (perp=9.370, rec=0.319, cos=0.037), tot_loss_proj:3.844 [t=0.17s]
prediction: ['[CLS] john is is refused [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.017 (perp=8.804, rec=0.237, cos=0.019), tot_loss_proj:3.523 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.964 (perp=8.804, rec=0.190, cos=0.013), tot_loss_proj:3.520 [t=0.18s]
prediction: ['[CLS] john is refused is [SEP]']
[ 450/2000] tot_loss=1.928 (perp=8.804, rec=0.156, cos=0.011), tot_loss_proj:3.508 [t=0.18s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.910 (perp=8.804, rec=0.140, cos=0.010), tot_loss_proj:3.495 [t=0.18s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.891 (perp=8.804, rec=0.121, cos=0.009), tot_loss_proj:3.500 [t=0.19s]
prediction: ['[CLS] john is refused is [SEP]']
[ 600/2000] tot_loss=1.888 (perp=8.804, rec=0.118, cos=0.009), tot_loss_proj:3.486 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.884 (perp=8.804, rec=0.114, cos=0.009), tot_loss_proj:3.490 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.878 (perp=8.804, rec=0.108, cos=0.009), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
[ 750/2000] tot_loss=1.874 (perp=8.804, rec=0.104, cos=0.008), tot_loss_proj:3.489 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.873 (perp=8.804, rec=0.104, cos=0.008), tot_loss_proj:3.491 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.865 (perp=8.804, rec=0.096, cos=0.008), tot_loss_proj:3.493 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
[ 900/2000] tot_loss=1.867 (perp=8.804, rec=0.098, cos=0.008), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.868 (perp=8.804, rec=0.099, cos=0.008), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.865 (perp=8.804, rec=0.096, cos=0.008), tot_loss_proj:3.503 [t=0.18s]
prediction: ['[CLS] john is refused is [SEP]']
[1050/2000] tot_loss=1.862 (perp=8.804, rec=0.093, cos=0.008), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.870 (perp=8.804, rec=0.101, cos=0.008), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.862 (perp=8.804, rec=0.094, cos=0.008), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
[1200/2000] tot_loss=1.868 (perp=8.804, rec=0.100, cos=0.008), tot_loss_proj:3.508 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.857 (perp=8.804, rec=0.089, cos=0.008), tot_loss_proj:3.511 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.865 (perp=8.804, rec=0.096, cos=0.008), tot_loss_proj:3.510 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
[1350/2000] tot_loss=1.867 (perp=8.804, rec=0.098, cos=0.008), tot_loss_proj:3.509 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.869 (perp=8.804, rec=0.101, cos=0.008), tot_loss_proj:3.510 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.868 (perp=8.804, rec=0.100, cos=0.008), tot_loss_proj:3.515 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
[1500/2000] tot_loss=1.864 (perp=8.804, rec=0.096, cos=0.008), tot_loss_proj:3.517 [t=0.18s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.859 (perp=8.804, rec=0.091, cos=0.007), tot_loss_proj:3.520 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.869 (perp=8.804, rec=0.101, cos=0.007), tot_loss_proj:3.516 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
[1650/2000] tot_loss=1.863 (perp=8.804, rec=0.095, cos=0.007), tot_loss_proj:3.515 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.857 (perp=8.804, rec=0.089, cos=0.007), tot_loss_proj:3.512 [t=0.20s]
prediction: ['[CLS] john is refused is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.863 (perp=8.804, rec=0.095, cos=0.007), tot_loss_proj:3.512 [t=0.17s]
prediction: ['[CLS] john is refused is [SEP]']
[1800/2000] tot_loss=1.469 (perp=6.834, rec=0.095, cos=0.007), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.477 (perp=6.834, rec=0.103, cos=0.007), tot_loss_proj:1.503 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.466 (perp=6.834, rec=0.092, cos=0.007), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
[1950/2000] tot_loss=1.480 (perp=6.834, rec=0.106, cos=0.007), tot_loss_proj:1.501 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.468 (perp=6.834, rec=0.094, cos=0.007), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] john is refused. [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] john is refused. [SEP]
========================
predicted: 
========================
[CLS] john is refused. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.815 | p: 83.556 | r: 82.365
rouge2     | fm: 37.024 | p: 37.307 | r: 36.886
rougeL     | fm: 67.391 | p: 67.889 | r: 67.017
rougeLsum  | fm: 67.416 | p: 68.022 | r: 67.110
r1fm+r2fm = 119.839

input #35 time: 0:07:11 | total time: 4:20:36


Running input #36 of 100.
reference: 
========================
This information could have been released by Gorbachev, but he chose not to.
========================
average of cosine similarity 0.999461896585002
highest_index [0]
highest [0.999461896585002]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[  101,  2023,  2592,  2071,  2031,  2042,  2207,  2011,  2175, 28483,
         16179,  1010,  2021,  2002,  4900,  2025,  2000,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]']
[Init] best rec loss: 0.9475834369659424 for ['[CLS] actually joseph sofia sas colt late sketch sensefixed skate shaved clerical period huis powers news [SEP]']
[Init] best rec loss: 0.9407480359077454 for ['[CLS] gottfried cause credit family manufacturing assent active peek what conscious [ jurisdiction ch high porter tomashein [SEP]']
[Init] best rec loss: 0.9353086352348328 for ['[CLS] whenpressed pain must battled spyvu kilometres 10 term & enough bell each bandwidthdly design [SEP]']
[Init] best rec loss: 0.8846843242645264 for ['[CLS] penny quartersrim however reliefly supreme grant which departure mortar oak black touch apex golden ruling [SEP]']
[Init] best perm rec loss: 0.8831620812416077 for ['[CLS] departure which supreme touch grantrim apex relief penny mortar golden oak blackly ruling however quarters [SEP]']
[Init] best perm rec loss: 0.8824912905693054 for ['[CLS] mortar grant goldenrim which touch black ruling apexly oak supreme however quarters penny relief departure [SEP]']
[Init] best perm rec loss: 0.8821429014205933 for ['[CLS] grant which penny however apex departure oak touch black ruling mortar goldenrim quarters relief supremely [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.386 (perp=14.006, rec=0.585, cos=0.999), tot_loss_proj:4.734 [t=0.17s]
prediction: ['[CLS] hat ice distancetus minister di educational book! facedpa ; did became res you aviation [SEP]']
[ 100/2000] tot_loss=2.691 (perp=11.809, rec=0.308, cos=0.021), tot_loss_proj:4.166 [t=0.18s]
prediction: ['[CLS] somehowchev information thismaster co information waiting? assumedchev ; led never res judgmentchev [SEP]']
[ 150/2000] tot_loss=2.546 (perp=11.496, rec=0.237, cos=0.010), tot_loss_proj:4.080 [t=0.18s]
prediction: ['[CLS]naichev information this secretly were information a! assumedchev released were chose ex himchev [SEP]']
[ 200/2000] tot_loss=2.713 (perp=12.498, rec=0.203, cos=0.010), tot_loss_proj:4.269 [t=0.18s]
prediction: ['[CLS]nechev information this sideways were could arba assumedchev ;rba chose did himchev [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.736 (perp=12.163, rec=0.273, cos=0.031), tot_loss_proj:4.250 [t=0.17s]
prediction: ['[CLS]nichev information this sideways already could wereflictchev reasons byrba chosers himchev [SEP]']
[ 300/2000] tot_loss=2.590 (perp=11.753, rec=0.223, cos=0.016), tot_loss_proj:4.214 [t=0.17s]
prediction: ['[CLS].chev information thised blu could release releasedchev anyway byrba chosers judicialchev [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.560 (perp=11.760, rec=0.197, cos=0.012), tot_loss_proj:4.249 [t=0.17s]
prediction: ['[CLS].chev information this [SEP]rba could release releasedchev anyway by chosersdisrbachev [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.688 (perp=12.251, rec=0.223, cos=0.014), tot_loss_proj:4.426 [t=0.18s]
prediction: ['[CLS].chev information this [SEP]rbarba released release released anyway by chosersdisrbarba [SEP]']
[ 450/2000] tot_loss=2.673 (perp=12.329, rec=0.197, cos=0.010), tot_loss_proj:4.330 [t=0.18s]
prediction: ['[CLS].chev information this [SEP]rbarba released release could anyway by chosersdisrbarba [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.458 (perp=11.374, rec=0.175, cos=0.009), tot_loss_proj:4.129 [t=0.18s]
prediction: ['[CLS].chev information this [SEP]rbadis released release could anyway by chose couldrbarbarba [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.402 (perp=10.322, rec=0.296, cos=0.042), tot_loss_proj:3.852 [t=0.18s]
prediction: ['[CLS]rbachev information this of went - released ( if anyway by choseestedrbarba. [SEP]']
[ 600/2000] tot_loss=2.552 (perp=11.659, rec=0.205, cos=0.015), tot_loss_proj:4.089 [t=0.18s]
prediction: ['[CLS]rbachev information this [SEP] wenta released ( easily must could chose endsrba himself. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.137 (perp=9.661, rec=0.195, cos=0.010), tot_loss_proj:3.756 [t=0.18s]
prediction: ['[CLS]rbachev information this he wenta could ( possibly must released chose arerba himself. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.191 (perp=9.999, rec=0.182, cos=0.009), tot_loss_proj:3.789 [t=0.18s]
prediction: ['[CLS]rbachev information this he wenta could easily must released ( chose endsrbarba. [SEP]']
[ 750/2000] tot_loss=2.070 (perp=9.421, rec=0.178, cos=0.008), tot_loss_proj:3.700 [t=0.18s]
prediction: ['[CLS]rbachev information this he wenta could released and released ( chose wouldrbarba. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.900 (perp=8.563, rec=0.180, cos=0.007), tot_loss_proj:3.506 [t=0.18s]
prediction: ['[CLS]rbachev information this he went coulda released and released by chose wouldrbarba. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.045 (perp=9.365, rec=0.163, cos=0.008), tot_loss_proj:3.613 [t=0.18s]
prediction: ['[CLS]rbachev information this he went coulda released chose have released by couldrbarba. [SEP]']
[ 900/2000] tot_loss=2.045 (perp=9.365, rec=0.165, cos=0.007), tot_loss_proj:3.611 [t=0.18s]
prediction: ['[CLS]rbachev information this he went coulda released chose have released by couldrbarba. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.926 (perp=8.775, rec=0.164, cos=0.007), tot_loss_proj:3.519 [t=0.18s]
prediction: ['[CLS]rbachev information this he went coulda released not have released by choserbarba. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.877 (perp=8.529, rec=0.163, cos=0.008), tot_loss_proj:3.435 [t=0.18s]
prediction: ['[CLS]rbachev information this he went could have released nota released by choserbarba. [SEP]']
[1050/2000] tot_loss=1.871 (perp=8.529, rec=0.158, cos=0.007), tot_loss_proj:3.434 [t=0.18s]
prediction: ['[CLS]rbachev information this he went could have released nota released by choserbarba. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.784 (perp=8.145, rec=0.149, cos=0.006), tot_loss_proj:3.523 [t=0.19s]
prediction: ['[CLS]rbachev information this he could have released went nota released by choserbarba. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.966 (perp=9.023, rec=0.155, cos=0.007), tot_loss_proj:3.567 [t=0.19s]
prediction: ['[CLS]rbachev information this he could immediately released things went not released by choserbarba. [SEP]']
[1200/2000] tot_loss=1.814 (perp=8.319, rec=0.145, cos=0.006), tot_loss_proj:3.450 [t=0.19s]
prediction: ['[CLS]rbachev information this he could have released things went not released by choserbarba. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.757 (perp=8.018, rec=0.147, cos=0.006), tot_loss_proj:3.443 [t=0.20s]
prediction: ['[CLS]rbachev information this he could have released chose things went not released byrbarba. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.760 (perp=8.018, rec=0.151, cos=0.005), tot_loss_proj:3.445 [t=0.20s]
prediction: ['[CLS]rbachev information this he could have released chose things went not released byrbarba. [SEP]']
[1350/2000] tot_loss=1.754 (perp=8.018, rec=0.145, cos=0.005), tot_loss_proj:3.443 [t=0.20s]
prediction: ['[CLS]rbachev information this he could have released chose things went not released byrbarba. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.750 (perp=8.018, rec=0.142, cos=0.005), tot_loss_proj:3.448 [t=0.20s]
prediction: ['[CLS]rbachev information this he could have released chose things went not released byrbarba. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.730 (perp=7.918, rec=0.141, cos=0.006), tot_loss_proj:3.481 [t=0.19s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
[1500/2000] tot_loss=1.734 (perp=7.918, rec=0.145, cos=0.005), tot_loss_proj:3.482 [t=0.21s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.722 (perp=7.918, rec=0.133, cos=0.005), tot_loss_proj:3.479 [t=0.19s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.726 (perp=7.918, rec=0.138, cos=0.005), tot_loss_proj:3.481 [t=0.20s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
[1650/2000] tot_loss=1.729 (perp=7.918, rec=0.141, cos=0.005), tot_loss_proj:3.482 [t=0.19s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.730 (perp=7.918, rec=0.142, cos=0.005), tot_loss_proj:3.483 [t=0.20s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.722 (perp=7.918, rec=0.133, cos=0.005), tot_loss_proj:3.478 [t=0.18s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
[1800/2000] tot_loss=1.723 (perp=7.918, rec=0.135, cos=0.005), tot_loss_proj:3.482 [t=0.21s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.720 (perp=7.918, rec=0.132, cos=0.005), tot_loss_proj:3.480 [t=0.18s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.728 (perp=7.918, rec=0.139, cos=0.005), tot_loss_proj:3.480 [t=0.18s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
[1950/2000] tot_loss=1.732 (perp=7.918, rec=0.144, cos=0.005), tot_loss_proj:3.481 [t=0.18s]
prediction: ['[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.715 (perp=7.883, rec=0.133, cos=0.005), tot_loss_proj:3.365 [t=0.18s]
prediction: ['[CLS] wentchev information this he could have released chose things not released byrbarbarba. [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]
========================
predicted: 
========================
[CLS]rbachev information this he could have released chose things not released by wentrbarba. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.333 | p: 73.333 | r: 73.333
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 53.333 | p: 53.333 | r: 53.333
rougeLsum  | fm: 53.333 | p: 53.333 | r: 53.333
r1fm+r2fm = 87.619

[Aggregate metrics]:
rouge1     | fm: 82.595 | p: 83.280 | r: 82.156
rouge2     | fm: 36.418 | p: 36.652 | r: 36.429
rougeL     | fm: 67.021 | p: 67.550 | r: 66.726
rougeLsum  | fm: 67.190 | p: 67.713 | r: 66.889
r1fm+r2fm = 119.013

input #36 time: 0:07:36 | total time: 4:28:12


Running input #37 of 100.
reference: 
========================
Kevin ate spaghetti with a spoon and Geordie did so too.
========================
average of cosine similarity 0.9993304804986536
highest_index [0]
highest [0.9993304804986536]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  4901,  8823, 26666,  2007,  1037, 15642,  1998, 20248, 17080,
          2063,  2106,  2061,  2205,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]']
[Init] best rec loss: 0.9316594004631042 for ['[CLS] grace extent first over maritime walked aria intake axis catcher dickinson twice tires serve [SEP]']
[Init] best rec loss: 0.9283725023269653 for ['[CLS] firingih bark programme powell colt angeles iangina warrant intention natural torontokind [SEP]']
[Init] best rec loss: 0.9265769124031067 for ['[CLS] chip culture airndafa phrase abandoned dissatisfied team musicbula page trulybahn [SEP]']
[Init] best rec loss: 0.9028146862983704 for ['[CLS] gone don sqaur [SEP] labels ivory fair crew across folded lamar plates roses [SEP]']
[Init] best perm rec loss: 0.9003402590751648 for ['[CLS] goneaur sq across folded crew don [SEP] lamar roses fair ivory labels plates [SEP]']
[Init] best perm rec loss: 0.8979520201683044 for ['[CLS] don lamar gone rosesaur folded labels across crew plates sq [SEP] fair ivory [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.168 (perp=12.278, rec=0.721, cos=0.992), tot_loss_proj:4.259 [t=0.17s]
prediction: ['[CLS] jesus leave [SEP] forgive seaman scholar hospital scarlett lilly. pneumonia. approval suddenly [SEP]']
[ 100/2000] tot_loss=2.900 (perp=12.175, rec=0.397, cos=0.068), tot_loss_proj:4.251 [t=0.17s]
prediction: ['[CLS] trace too, given contact towardsmerie althoughnni mexican looked. council quickly [SEP]']
[ 150/2000] tot_loss=2.967 (perp=13.275, rec=0.284, cos=0.029), tot_loss_proj:4.483 [t=0.17s]
prediction: ['[CLS] mark too, somali contact aterdi practicalrdi clarksone, maggie came [SEP]']
[ 200/2000] tot_loss=2.503 (perp=11.330, rec=0.221, cos=0.015), tot_loss_proj:4.089 [t=0.17s]
prediction: ['[CLS] mark too, kevin contact geordi behindrdi geoe and geo did [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.799 (perp=11.603, rec=0.392, cos=0.086), tot_loss_proj:4.218 [t=0.17s]
prediction: ['[CLS] kevin smiled? kevin if geo unity fish bye & geordi [SEP]']
[ 300/2000] tot_loss=2.465 (perp=10.739, rec=0.293, cos=0.024), tot_loss_proj:4.050 [t=0.17s]
prediction: ['[CLS] kevin ate? kevin did geo wereity cheese usinge and geordi [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.347 (perp=10.407, rec=0.253, cos=0.013), tot_loss_proj:3.956 [t=0.17s]
prediction: ['[CLS] kevin ate? kevin did geordiso food usinge and geo un [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.418 (perp=10.878, rec=0.228, cos=0.015), tot_loss_proj:4.073 [t=0.17s]
prediction: ['[CLS] kevin ate? kevin spaghetti geordioce with cheese andrdi rec [SEP]']
[ 450/2000] tot_loss=2.408 (perp=10.979, rec=0.204, cos=0.008), tot_loss_proj:4.141 [t=0.17s]
prediction: ['[CLS] kevin ate? kevin spaghetti geordioce with eat andrdi un [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.346 (perp=10.751, rec=0.189, cos=0.007), tot_loss_proj:4.051 [t=0.17s]
prediction: ['[CLS] did kevin did kevin spaghetti geordioce with eat andrdi un [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.399 (perp=10.743, rec=0.216, cos=0.034), tot_loss_proj:3.991 [t=0.17s]
prediction: ['[CLS] dinner kevin did kevin spaghetti geordioce with did andrdi un [SEP]']
[ 600/2000] tot_loss=2.338 (perp=10.743, rec=0.180, cos=0.009), tot_loss_proj:3.994 [t=0.17s]
prediction: ['[CLS] dinner kevin did kevin spaghetti geordioce with did andrdi un [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.242 (perp=10.368, rec=0.160, cos=0.008), tot_loss_proj:3.907 [t=0.17s]
prediction: ['[CLS] dinner kevin un kevin spaghetti geordioce with did andrdi did [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.108 (perp=9.705, rec=0.161, cos=0.007), tot_loss_proj:3.821 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordioce did with andrdi did [SEP]']
[ 750/2000] tot_loss=2.101 (perp=9.705, rec=0.154, cos=0.006), tot_loss_proj:3.821 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordioce did with andrdi did [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.091 (perp=9.705, rec=0.144, cos=0.005), tot_loss_proj:3.820 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordioce did with andrdi did [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.050 (perp=9.520, rec=0.141, cos=0.005), tot_loss_proj:3.802 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordieoc did with andrdi did [SEP]']
[ 900/2000] tot_loss=2.064 (perp=9.520, rec=0.155, cos=0.005), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordieoc did with andrdi did [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.052 (perp=9.520, rec=0.144, cos=0.005), tot_loss_proj:3.803 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordieoc did with andrdi did [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.025 (perp=9.436, rec=0.133, cos=0.005), tot_loss_proj:3.772 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordie did withoc andrdi did [SEP]']
[1050/2000] tot_loss=2.027 (perp=9.436, rec=0.135, cos=0.004), tot_loss_proj:3.768 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordie did withoc andrdi did [SEP]']
Attempt swap
[1100/2000] tot_loss=2.021 (perp=9.436, rec=0.129, cos=0.004), tot_loss_proj:3.767 [t=0.21s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordie did withoc andrdi did [SEP]']
Attempt swap
[1150/2000] tot_loss=2.030 (perp=9.436, rec=0.139, cos=0.004), tot_loss_proj:3.776 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordie did withoc andrdi did [SEP]']
[1200/2000] tot_loss=2.081 (perp=9.735, rec=0.130, cos=0.004), tot_loss_proj:3.891 [t=0.19s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordie did withoc andrdi too [SEP]']
Attempt swap
[1250/2000] tot_loss=2.079 (perp=9.735, rec=0.128, cos=0.004), tot_loss_proj:3.888 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordie did withoc andrdi too [SEP]']
Attempt swap
[1300/2000] tot_loss=2.069 (perp=9.735, rec=0.118, cos=0.004), tot_loss_proj:3.891 [t=0.17s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordie did withoc andrdi too [SEP]']
[1350/2000] tot_loss=2.080 (perp=9.735, rec=0.129, cos=0.004), tot_loss_proj:3.885 [t=0.19s]
prediction: ['[CLS] eat kevin un kevin spaghetti geordie did withoc andrdi too [SEP]']
Attempt swap
[1400/2000] tot_loss=2.115 (perp=9.914, rec=0.128, cos=0.004), tot_loss_proj:3.838 [t=0.18s]
prediction: ['[CLS] eat kevin did kevin spaghetti geordie did withoc andrdi too [SEP]']
Attempt swap
[1450/2000] tot_loss=2.110 (perp=9.914, rec=0.124, cos=0.004), tot_loss_proj:3.840 [t=0.18s]
prediction: ['[CLS] eat kevin did kevin spaghetti geordie did withoc andrdi too [SEP]']
[1500/2000] tot_loss=2.147 (perp=10.080, rec=0.127, cos=0.004), tot_loss_proj:3.936 [t=0.17s]
prediction: ['[CLS] eat kevin tha kevin spaghetti geordie did withoc andrdi too [SEP]']
Attempt swap
[1550/2000] tot_loss=2.143 (perp=10.080, rec=0.124, cos=0.004), tot_loss_proj:3.937 [t=0.17s]
prediction: ['[CLS] eat kevin tha kevin spaghetti geordie did withoc andrdi too [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.120 (perp=9.985, rec=0.119, cos=0.004), tot_loss_proj:3.959 [t=0.18s]
prediction: ['[CLS] eat kevin thaoc spaghetti geordie did with kevin andrdi too [SEP]']
[1650/2000] tot_loss=2.167 (perp=10.231, rec=0.117, cos=0.004), tot_loss_proj:4.004 [t=0.18s]
prediction: ['[CLS] eat kevin spoonoc spaghetti geordie did with kevin andrdi too [SEP]']
Attempt swap
[1700/2000] tot_loss=2.173 (perp=10.231, rec=0.123, cos=0.004), tot_loss_proj:4.007 [t=0.18s]
prediction: ['[CLS] eat kevin spoonoc spaghetti geordie did with kevin andrdi too [SEP]']
Attempt swap
[1750/2000] tot_loss=2.273 (perp=10.759, rec=0.118, cos=0.004), tot_loss_proj:4.062 [t=0.18s]
prediction: ['[CLS] ate kevin spoonoc spaghetti geordie did with kevin andrdi too [SEP]']
[1800/2000] tot_loss=2.282 (perp=10.759, rec=0.127, cos=0.004), tot_loss_proj:4.057 [t=0.18s]
prediction: ['[CLS] ate kevin spoonoc spaghetti geordie did with kevin andrdi too [SEP]']
Attempt swap
[1850/2000] tot_loss=2.278 (perp=10.759, rec=0.122, cos=0.004), tot_loss_proj:4.063 [t=0.18s]
prediction: ['[CLS] ate kevin spoonoc spaghetti geordie did with kevin andrdi too [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.225 (perp=10.493, rec=0.122, cos=0.005), tot_loss_proj:3.937 [t=0.18s]
prediction: ['[CLS] ate kevin spoonoc spaghetti did geordie with kevin andrdi too [SEP]']
[1950/2000] tot_loss=2.221 (perp=10.493, rec=0.118, cos=0.004), tot_loss_proj:3.940 [t=0.18s]
prediction: ['[CLS] ate kevin spoonoc spaghetti did geordie with kevin andrdi too [SEP]']
Attempt swap
[2000/2000] tot_loss=2.225 (perp=10.493, rec=0.122, cos=0.004), tot_loss_proj:3.936 [t=0.18s]
prediction: ['[CLS] ate kevin spoonoc spaghetti did geordie with kevin andrdi too [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]
========================
predicted: 
========================
[CLS] ate kevin spoonoc spaghetti geordie did with kevin andrdi too [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.000 | p: 75.000 | r: 69.231
rouge2     | fm: 17.391 | p: 18.182 | r: 16.667
rougeL     | fm: 56.000 | p: 58.333 | r: 53.846
rougeLsum  | fm: 56.000 | p: 58.333 | r: 53.846
r1fm+r2fm = 89.391

[Aggregate metrics]:
rouge1     | fm: 82.264 | p: 83.058 | r: 81.768
rouge2     | fm: 35.952 | p: 36.222 | r: 35.841
rougeL     | fm: 66.692 | p: 67.343 | r: 66.274
rougeLsum  | fm: 66.803 | p: 67.344 | r: 66.395
r1fm+r2fm = 118.216

input #37 time: 0:07:07 | total time: 4:35:20


Running input #38 of 100.
reference: 
========================
John is the kind of fool that I told you about.
========================
average of cosine similarity 0.9995113299775283
highest_index [0]
highest [0.9995113299775283]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2198, 2003, 1996, 2785, 1997, 7966, 2008, 1045, 2409, 2017, 2055,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is the kind of fool that i told you about. [SEP]']
[Init] best rec loss: 0.9675338268280029 for ['[CLS] medicine horns clear john splash treaties samson com credited birthplace ago managing [SEP]']
[Init] best rec loss: 0.9361371397972107 for ['[CLS]vance jace texas silk mid will ongative to important sweat prize [SEP]']
[Init] best rec loss: 0.9326436519622803 for ['[CLS] nina won allied issues after stride growing joo kevin gabriel skiermonium [SEP]']
[Init] best rec loss: 0.9324679970741272 for ['[CLS] off bumpheint same mustlding sydney young movie something odd [SEP]']
[Init] best rec loss: 0.9286861419677734 for ['[CLS] jr massachusetts [SEP] refrigerator inch paradox jury all provided somewhere galaxy francis [SEP]']
[Init] best rec loss: 0.9026694297790527 for ['[CLS] label sea safety zeronessfixed builder med scrub fairound amateur [SEP]']
[Init] best perm rec loss: 0.9024163484573364 for ['[CLS] seaound zeroness safety medfixed scrub label builder fair amateur [SEP]']
[Init] best perm rec loss: 0.9023182392120361 for ['[CLS]fixed med amateur zeroound label seaness builder fair scrub safety [SEP]']
[Init] best perm rec loss: 0.9020756483078003 for ['[CLS]ness amateuround sea labelfixed med scrub zero fair builder safety [SEP]']
[Init] best perm rec loss: 0.9013963341712952 for ['[CLS]ness zero safetyfixed scrub builder label sea fair amateuround med [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.901 (perp=10.776, rec=0.753, cos=0.993), tot_loss_proj:3.958 [t=0.19s]
prediction: ['[CLS] [SEP] talking. of who pilot who ki six guy raymond [CLS] [SEP]']
[ 100/2000] tot_loss=3.796 (perp=11.125, rec=0.574, cos=0.997), tot_loss_proj:4.167 [t=0.19s]
prediction: ['[CLS] [SEP] ham. discount who rpg who ki about gandhi frank dr [SEP]']
[ 150/2000] tot_loss=3.623 (perp=10.629, rec=0.530, cos=0.968), tot_loss_proj:3.903 [t=0.19s]
prediction: ['[CLS] [SEP] ham. discount being rpg of asked woman fool minded the [SEP]']
[ 200/2000] tot_loss=4.042 (perp=12.293, rec=0.590, cos=0.994), tot_loss_proj:4.159 [t=0.17s]
prediction: ['[CLS] [SEP] started released tempted who rpg of. percy fool ed the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.568 (perp=10.315, rec=0.572, cos=0.933), tot_loss_proj:3.842 [t=0.17s]
prediction: ['[CLS] [SEP] scanned ; scanned system magic of called the fool frank moines [SEP]']
[ 300/2000] tot_loss=3.488 (perp=11.191, rec=0.686, cos=0.564), tot_loss_proj:4.038 [t=0.17s]
prediction: ['[CLS] [SEP] scanned ; involves daughter missile of called the fool frank moines [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.512 (perp=9.784, rec=0.457, cos=0.098), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS] [SEP] thomas conner involves about of. the fool missile frank ralph [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.267 (perp=9.358, rec=0.359, cos=0.036), tot_loss_proj:3.652 [t=0.17s]
prediction: ['[CLS] [SEP] thomas conner involves fool of. the fool told frank rachel [SEP]']
[ 450/2000] tot_loss=2.363 (perp=10.088, rec=0.323, cos=0.023), tot_loss_proj:3.877 [t=0.17s]
prediction: ['[CLS] [SEP] thomas. involves fool of fool the fool told johnny nicholas [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.202 (perp=9.392, rec=0.305, cos=0.019), tot_loss_proj:3.737 [t=0.17s]
prediction: ['[CLS] [SEP] thomas. involves fool of nicholas the fool told johnny fool [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.238 (perp=9.691, rec=0.284, cos=0.016), tot_loss_proj:3.756 [t=0.17s]
prediction: ['[CLS] [SEP]ffled. involves fool nicholas of the fool told johnny fool [SEP]']
[ 600/2000] tot_loss=2.059 (perp=8.834, rec=0.279, cos=0.013), tot_loss_proj:3.632 [t=0.17s]
prediction: ['[CLS] [SEP] your. is fool nicholas of the fool told john fool [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.810 (perp=7.683, rec=0.262, cos=0.012), tot_loss_proj:3.331 [t=0.17s]
prediction: ['[CLS] [SEP] your nicholas is fool. of the fool told john fool [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.775 (perp=7.582, rec=0.248, cos=0.011), tot_loss_proj:3.333 [t=0.17s]
prediction: ['[CLS] [SEP] your nicholas is kind. of the fool told john fool [SEP]']
[ 750/2000] tot_loss=1.827 (perp=7.922, rec=0.232, cos=0.011), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS] [SEP] you nicholas is kind. of the fool told john fool [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.687 (perp=7.235, rec=0.230, cos=0.010), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] [SEP] you nicholas is kind of the fool. told john fool [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.658 (perp=7.235, rec=0.202, cos=0.009), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] [SEP] you nicholas is kind of the fool. told john fool [SEP]']
[ 900/2000] tot_loss=1.777 (perp=7.891, rec=0.190, cos=0.009), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS] [SEP] you nicholas is kind of about fool. told john fool [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.866 (perp=8.270, rec=0.204, cos=0.009), tot_loss_proj:3.483 [t=0.17s]
prediction: ['[CLS] [SEP] you nicholas is kind of fool about fool told john fool [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.709 (perp=7.519, rec=0.195, cos=0.010), tot_loss_proj:3.334 [t=0.17s]
prediction: ['[CLS] [SEP] you is kind of fool about nicholas. told john fool [SEP]']
[1050/2000] tot_loss=1.741 (perp=7.791, rec=0.174, cos=0.008), tot_loss_proj:3.366 [t=0.18s]
prediction: ['[CLS] [SEP] you is kind of fool about nicholas fool told john fool [SEP]']
Attempt swap
[1100/2000] tot_loss=1.686 (perp=7.519, rec=0.175, cos=0.008), tot_loss_proj:3.331 [t=0.17s]
prediction: ['[CLS] [SEP] you is kind of fool about nicholas. told john fool [SEP]']
Attempt swap
[1150/2000] tot_loss=1.684 (perp=7.519, rec=0.172, cos=0.008), tot_loss_proj:3.332 [t=0.17s]
prediction: ['[CLS] [SEP] you is kind of fool about nicholas. told john fool [SEP]']
[1200/2000] tot_loss=1.679 (perp=7.519, rec=0.168, cos=0.007), tot_loss_proj:3.332 [t=0.17s]
prediction: ['[CLS] [SEP] you is kind of fool about nicholas. told john fool [SEP]']
Attempt swap
[1250/2000] tot_loss=1.681 (perp=7.519, rec=0.170, cos=0.007), tot_loss_proj:3.333 [t=0.17s]
prediction: ['[CLS] [SEP] you is kind of fool about nicholas. told john fool [SEP]']
Attempt swap
[1300/2000] tot_loss=1.672 (perp=7.519, rec=0.161, cos=0.007), tot_loss_proj:3.335 [t=0.17s]
prediction: ['[CLS] [SEP] you is kind of fool about nicholas. told john fool [SEP]']
[1350/2000] tot_loss=1.872 (perp=8.490, rec=0.167, cos=0.007), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] [SEP] you is kind that fool about nicholas. told john fool [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.834 (perp=8.303, rec=0.167, cos=0.007), tot_loss_proj:3.465 [t=0.17s]
prediction: ['[CLS] [SEP] you is kind that fool about. nicholas told john fool [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.708 (perp=7.630, rec=0.174, cos=0.008), tot_loss_proj:3.423 [t=0.17s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
[1500/2000] tot_loss=1.697 (perp=7.630, rec=0.164, cos=0.007), tot_loss_proj:3.428 [t=0.17s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
Attempt swap
[1550/2000] tot_loss=1.697 (perp=7.630, rec=0.164, cos=0.007), tot_loss_proj:3.422 [t=0.19s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
Attempt swap
[1600/2000] tot_loss=1.686 (perp=7.630, rec=0.154, cos=0.006), tot_loss_proj:3.428 [t=0.17s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
[1650/2000] tot_loss=1.693 (perp=7.630, rec=0.160, cos=0.006), tot_loss_proj:3.425 [t=0.17s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
Attempt swap
[1700/2000] tot_loss=1.695 (perp=7.630, rec=0.162, cos=0.006), tot_loss_proj:3.428 [t=0.18s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
Attempt swap
[1750/2000] tot_loss=1.685 (perp=7.630, rec=0.153, cos=0.006), tot_loss_proj:3.429 [t=0.17s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
[1800/2000] tot_loss=1.685 (perp=7.630, rec=0.153, cos=0.006), tot_loss_proj:3.426 [t=0.18s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
Attempt swap
[1850/2000] tot_loss=1.684 (perp=7.630, rec=0.152, cos=0.006), tot_loss_proj:3.434 [t=0.18s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
Attempt swap
[1900/2000] tot_loss=1.695 (perp=7.630, rec=0.163, cos=0.006), tot_loss_proj:3.427 [t=0.17s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
[1950/2000] tot_loss=1.686 (perp=7.630, rec=0.154, cos=0.006), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
Attempt swap
[2000/2000] tot_loss=1.685 (perp=7.630, rec=0.153, cos=0.006), tot_loss_proj:3.429 [t=0.18s]
prediction: ['[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] john is the kind of fool that i told you about. [SEP]
========================
predicted: 
========================
[CLS] [SEP] is kind that you fool about. nicholas told john fool [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 76.923 | r: 76.923
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 53.846 | p: 53.846 | r: 53.846
rougeLsum  | fm: 53.846 | p: 53.846 | r: 53.846
r1fm+r2fm = 76.923

[Aggregate metrics]:
rouge1     | fm: 82.079 | p: 82.906 | r: 81.599
rouge2     | fm: 34.899 | p: 35.215 | r: 34.830
rougeL     | fm: 66.282 | p: 66.928 | r: 65.869
rougeLsum  | fm: 66.414 | p: 67.069 | r: 66.109
r1fm+r2fm = 116.978

input #38 time: 0:07:07 | total time: 4:42:27


Running input #39 of 100.
reference: 
========================
I doubt if you can help me in understanding this.
========================
average of cosine similarity 0.99941311323763
highest_index [0]
highest [0.99941311323763]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 1045, 4797, 2065, 2017, 2064, 2393, 2033, 1999, 4824, 2023, 1012,
          102]], device='cuda:0')
Debug: ref = ['[CLS] i doubt if you can help me in understanding this. [SEP]']
[Init] best rec loss: 0.9692432880401611 for ['[CLS] probably issue jade aren circumstances day old mayohum asian belonging [SEP]']
[Init] best rec loss: 0.9366908073425293 for ['[CLS] complications destiny com sex asteroids location outline shock focus impact highest [SEP]']
[Init] best rec loss: 0.9288410544395447 for ['[CLS] being reserved treat layer regulation model nose niche paddle picked think [SEP]']
[Init] best rec loss: 0.9272903800010681 for ['[CLS] exchange connect piano confirmed planted class mean company critically d men [SEP]']
[Init] best rec loss: 0.9174222946166992 for ['[CLS] legislature exploits mit alice didn tubes true mountvity lane animal [SEP]']
[Init] best rec loss: 0.9120254516601562 for ['[CLS] evangelist across shared fingernails rhythm machine following competition minute member babylon [SEP]']
[Init] best rec loss: 0.9110709428787231 for ['[CLS] composergist squared dee directedigraphy payingunds caseative half [SEP]']
[Init] best perm rec loss: 0.9087654948234558 for ['[CLS] payinggistunds squared caseigraphy half dee composer directedative [SEP]']
[Init] best perm rec loss: 0.9077205657958984 for ['[CLS] directed half payinggistative dee case composerunds squaredigraphy [SEP]']
[Init] best perm rec loss: 0.9066043496131897 for ['[CLS]undsative paying half squaredigraphy directed case composergist dee [SEP]']
[Init] best perm rec loss: 0.9061527252197266 for ['[CLS] composerative payingigraphy directed half squared deegist caseunds [SEP]']
[Init] best perm rec loss: 0.9044231176376343 for ['[CLS] caseunds directedative squaredigraphy dee composergist half paying [SEP]']
[Init] best perm rec loss: 0.9036428928375244 for ['[CLS] directedative half composergist caseunds paying squaredigraphy dee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.189 (perp=8.269, rec=0.572, cos=0.963), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] thereby might think these we about papers if having you. [SEP]']
[ 100/2000] tot_loss=3.540 (perp=10.399, rec=0.607, cos=0.853), tot_loss_proj:3.798 [t=0.17s]
prediction: ['[CLS] " howizing master can prints does deserves they such. [SEP]']
[ 150/2000] tot_loss=3.225 (perp=8.622, rec=0.501, cos=1.000), tot_loss_proj:3.549 [t=0.17s]
prediction: ['[CLS] " howian round can doubt. doubt they such. [SEP]']
[ 200/2000] tot_loss=1.971 (perp=8.061, rec=0.326, cos=0.033), tot_loss_proj:3.393 [t=0.17s]
prediction: ['[CLS] " how if round can doubt. doubt any you. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.262 (perp=8.916, rec=0.415, cos=0.064), tot_loss_proj:3.529 [t=0.17s]
prediction: ['[CLS] iordin production has not. thinking these on this [SEP]']
[ 300/2000] tot_loss=2.031 (perp=8.478, rec=0.315, cos=0.020), tot_loss_proj:3.485 [t=0.17s]
prediction: ['[CLS] you if my you has not. thinking understanding this isbn [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.954 (perp=8.268, rec=0.286, cos=0.014), tot_loss_proj:3.548 [t=0.17s]
prediction: ['[CLS] you doubt not if you has. thinking understanding this playstation [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.844 (perp=7.933, rec=0.246, cos=0.011), tot_loss_proj:3.300 [t=0.17s]
prediction: ['[CLS] you doubt not if you thinking. we understanding this playstation [SEP]']
[ 450/2000] tot_loss=1.989 (perp=8.741, rec=0.229, cos=0.011), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS] you doubt not my you understanding. we understanding this playstation [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.902 (perp=8.332, rec=0.224, cos=0.012), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] you doubt not my understanding you. we understanding this playstation [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.805 (perp=7.984, rec=0.196, cos=0.012), tot_loss_proj:3.289 [t=0.17s]
prediction: ['[CLS] if doubt in my understanding you. we understanding this playstation [SEP]']
[ 600/2000] tot_loss=1.715 (perp=7.504, rec=0.203, cos=0.011), tot_loss_proj:3.195 [t=0.17s]
prediction: ['[CLS] if doubt in my understanding you. we understanding this you [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.776 (perp=7.879, rec=0.188, cos=0.012), tot_loss_proj:3.345 [t=0.17s]
prediction: ['[CLS] if doubt in help understanding you you my understanding this. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.545 (perp=6.739, rec=0.186, cos=0.012), tot_loss_proj:3.155 [t=0.17s]
prediction: ['[CLS] if doubt you help understanding in you my understanding this. [SEP]']
[ 750/2000] tot_loss=1.539 (perp=6.754, rec=0.178, cos=0.011), tot_loss_proj:3.100 [t=0.17s]
prediction: ['[CLS] if doubt you help help in you my understanding this. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.487 (perp=6.506, rec=0.175, cos=0.011), tot_loss_proj:3.059 [t=0.17s]
prediction: ['[CLS] if doubt you help you help in i understanding this. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.370 (perp=5.945, rec=0.170, cos=0.011), tot_loss_proj:2.973 [t=0.17s]
prediction: ['[CLS] if doubt you help you help i in understanding this. [SEP]']
[ 900/2000] tot_loss=1.360 (perp=5.945, rec=0.161, cos=0.010), tot_loss_proj:2.976 [t=0.17s]
prediction: ['[CLS] if doubt you help you help i in understanding this. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.241 (perp=5.366, rec=0.158, cos=0.010), tot_loss_proj:3.039 [t=0.18s]
prediction: ['[CLS] if doubt i help you help you in understanding this. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.490 (perp=6.580, rec=0.164, cos=0.010), tot_loss_proj:3.197 [t=0.18s]
prediction: ['[CLS] if doubt i help you help you in understanding this if [SEP]']
[1050/2000] tot_loss=1.475 (perp=6.580, rec=0.150, cos=0.010), tot_loss_proj:3.202 [t=0.18s]
prediction: ['[CLS] if doubt i help you help you in understanding this if [SEP]']
Attempt swap
[1100/2000] tot_loss=1.475 (perp=6.580, rec=0.149, cos=0.010), tot_loss_proj:3.200 [t=0.17s]
prediction: ['[CLS] if doubt i help you help you in understanding this if [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.401 (perp=6.085, rec=0.173, cos=0.011), tot_loss_proj:3.116 [t=0.18s]
prediction: ['[CLS] if doubt i help if you help you in understanding this [SEP]']
[1200/2000] tot_loss=1.387 (perp=6.085, rec=0.159, cos=0.010), tot_loss_proj:3.115 [t=0.18s]
prediction: ['[CLS] if doubt i help if you help you in understanding this [SEP]']
Attempt swap
[1250/2000] tot_loss=1.511 (perp=6.725, rec=0.155, cos=0.010), tot_loss_proj:3.147 [t=0.18s]
prediction: ['[CLS] if doubt i me if you help you in understanding this [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.418 (perp=6.260, rec=0.156, cos=0.010), tot_loss_proj:3.044 [t=0.18s]
prediction: ['[CLS] if doubt you me if i help you in understanding this [SEP]']
[1350/2000] tot_loss=1.409 (perp=6.260, rec=0.147, cos=0.010), tot_loss_proj:3.041 [t=0.17s]
prediction: ['[CLS] if doubt you me if i help you in understanding this [SEP]']
Attempt swap
[1400/2000] tot_loss=1.402 (perp=6.260, rec=0.140, cos=0.010), tot_loss_proj:3.044 [t=0.17s]
prediction: ['[CLS] if doubt you me if i help you in understanding this [SEP]']
Attempt swap
[1450/2000] tot_loss=1.408 (perp=6.260, rec=0.146, cos=0.010), tot_loss_proj:3.047 [t=0.17s]
prediction: ['[CLS] if doubt you me if i help you in understanding this [SEP]']
[1500/2000] tot_loss=1.407 (perp=6.260, rec=0.146, cos=0.010), tot_loss_proj:3.040 [t=0.18s]
prediction: ['[CLS] if doubt you me if i help you in understanding this [SEP]']
Attempt swap
[1550/2000] tot_loss=1.405 (perp=6.260, rec=0.143, cos=0.010), tot_loss_proj:3.044 [t=0.17s]
prediction: ['[CLS] if doubt you me if i help you in understanding this [SEP]']
Attempt swap
[1600/2000] tot_loss=1.394 (perp=6.260, rec=0.133, cos=0.010), tot_loss_proj:3.044 [t=0.17s]
prediction: ['[CLS] if doubt you me if i help you in understanding this [SEP]']
[1650/2000] tot_loss=1.397 (perp=6.260, rec=0.136, cos=0.009), tot_loss_proj:3.046 [t=0.17s]
prediction: ['[CLS] if doubt you me if i help you in understanding this [SEP]']
Attempt swap
[1700/2000] tot_loss=1.392 (perp=6.260, rec=0.131, cos=0.009), tot_loss_proj:3.045 [t=0.18s]
prediction: ['[CLS] if doubt you me if i help you in understanding this [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.226 (perp=5.347, rec=0.146, cos=0.011), tot_loss_proj:2.871 [t=0.18s]
prediction: ['[CLS] if you doubt me if i help you in understanding this [SEP]']
[1800/2000] tot_loss=1.227 (perp=5.347, rec=0.148, cos=0.010), tot_loss_proj:2.872 [t=0.23s]
prediction: ['[CLS] if you doubt me if i help you in understanding this [SEP]']
Attempt swap
[1850/2000] tot_loss=1.214 (perp=5.347, rec=0.135, cos=0.010), tot_loss_proj:2.871 [t=0.18s]
prediction: ['[CLS] if you doubt me if i help you in understanding this [SEP]']
Attempt swap
[1900/2000] tot_loss=1.214 (perp=5.347, rec=0.135, cos=0.010), tot_loss_proj:2.874 [t=0.18s]
prediction: ['[CLS] if you doubt me if i help you in understanding this [SEP]']
[1950/2000] tot_loss=1.217 (perp=5.347, rec=0.138, cos=0.009), tot_loss_proj:2.876 [t=0.18s]
prediction: ['[CLS] if you doubt me if i help you in understanding this [SEP]']
Attempt swap
[2000/2000] tot_loss=1.202 (perp=5.347, rec=0.123, cos=0.009), tot_loss_proj:2.869 [t=0.18s]
prediction: ['[CLS] if you doubt me if i help you in understanding this [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] i doubt if you can help me in understanding this. [SEP]
========================
predicted: 
========================
[CLS] if you doubt me if i help you in understanding this [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 34.783 | p: 33.333 | r: 36.364
rougeL     | fm: 64.000 | p: 61.538 | r: 66.667
rougeLsum  | fm: 64.000 | p: 61.538 | r: 66.667
r1fm+r2fm = 122.783

[Aggregate metrics]:
rouge1     | fm: 82.258 | p: 82.851 | r: 81.909
rouge2     | fm: 34.867 | p: 34.996 | r: 34.836
rougeL     | fm: 66.262 | p: 66.698 | r: 66.078
rougeLsum  | fm: 66.458 | p: 66.938 | r: 66.126
r1fm+r2fm = 117.125

input #39 time: 0:06:59 | total time: 4:49:27


Running input #40 of 100.
reference: 
========================
Was the child running to the car?
========================
average of cosine similarity 0.9994376310826198
highest_index [0]
highest [0.9994376310826198]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2001, 1996, 2775, 2770, 2000, 1996, 2482, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] was the child running to the car? [SEP]']
[Init] best rec loss: 0.9621278047561646 for ['[CLS]chfield only loan mast lust nape " nearly [SEP]']
[Init] best rec loss: 0.9481551051139832 for ['[CLS]typic races investigation singular haven boreay libby [SEP]']
[Init] best rec loss: 0.9173352122306824 for ['[CLS] standing colonyhers angry isn [SEP] women waste [SEP]']
[Init] best rec loss: 0.9018546938896179 for ['[CLS] rhapsody edna german award hamburg once horn govt [SEP]']
[Init] best rec loss: 0.8998432159423828 for ['[CLS] o junior grinning appear stitchfy with they [SEP]']
[Init] best rec loss: 0.895498514175415 for ['[CLS] arrived door bat simon unwillinghorthaling syn [SEP]']
[Init] best rec loss: 0.8836095929145813 for ['[CLS]lene novi following [SEP] circumstances business practice l [SEP]']
[Init] best rec loss: 0.8725322484970093 for ['[CLS]ning archbishop whomont andreasization parents rest [SEP]']
[Init] best rec loss: 0.8687050938606262 for ['[CLS] ethnic product czech feed diego problems construction methods [SEP]']
[Init] best perm rec loss: 0.8622528910636902 for ['[CLS] diego feed methods product construction czech problems ethnic [SEP]']
[Init] best perm rec loss: 0.8621556758880615 for ['[CLS] construction diego methods feed czech ethnic problems product [SEP]']
[Init] best perm rec loss: 0.8614377975463867 for ['[CLS] czech ethnic construction methods feed problems product diego [SEP]']
[Init] best perm rec loss: 0.8572033643722534 for ['[CLS] feed diego product construction ethnic czech problems methods [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.642 (perp=10.819, rec=0.712, cos=0.766), tot_loss_proj:4.017 [t=0.21s]
prediction: ['[CLS] tells every and as zevera popular? [SEP]']
[ 100/2000] tot_loss=3.485 (perp=10.100, rec=0.655, cos=0.810), tot_loss_proj:3.888 [t=0.19s]
prediction: ['[CLS] tells whom or as ursula princess woke? [SEP]']
[ 150/2000] tot_loss=3.502 (perp=10.266, rec=0.631, cos=0.818), tot_loss_proj:4.121 [t=0.19s]
prediction: ['[CLS] give runs or a hilda animal television? [SEP]']
[ 200/2000] tot_loss=3.558 (perp=11.334, rec=0.544, cos=0.747), tot_loss_proj:4.125 [t=0.19s]
prediction: ['[CLS] gave whom or to included nut television? [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.257 (perp=10.238, rec=0.535, cos=0.675), tot_loss_proj:3.915 [t=0.18s]
prediction: ['[CLS] gave whom the thehip childrening? [SEP]']
[ 300/2000] tot_loss=2.872 (perp=9.599, rec=0.511, cos=0.441), tot_loss_proj:3.782 [t=0.18s]
prediction: ['[CLS] gave whom being thehip consciousness for? [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.794 (perp=9.549, rec=0.501, cos=0.383), tot_loss_proj:3.934 [t=0.18s]
prediction: ['[CLS] was the totead? card whom? [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.168 (perp=9.895, rec=0.535, cos=0.654), tot_loss_proj:4.023 [t=0.17s]
prediction: ['[CLS] was thecarriagetead card? whom? [SEP]']
[ 450/2000] tot_loss=2.531 (perp=9.521, rec=0.477, cos=0.150), tot_loss_proj:3.745 [t=0.17s]
prediction: ['[CLS] was the fiabasket card? whom? [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.461 (perp=9.139, rec=0.480, cos=0.153), tot_loss_proj:3.851 [t=0.17s]
prediction: ['[CLS] thecarriage astor card was? whom? [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.375 (perp=9.188, rec=0.466, cos=0.071), tot_loss_proj:3.712 [t=0.17s]
prediction: ['[CLS] the to card astor was lad whom? [SEP]']
[ 600/2000] tot_loss=2.457 (perp=9.884, rec=0.450, cos=0.029), tot_loss_proj:3.859 [t=0.17s]
prediction: ['[CLS] the to card astor car lad smug? [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.143 (perp=8.558, rec=0.573, cos=0.858), tot_loss_proj:3.656 [t=0.17s]
prediction: ['[CLS] the card raf was theirblood to? [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.889 (perp=8.037, rec=0.547, cos=0.734), tot_loss_proj:3.558 [t=0.17s]
prediction: ['[CLS] the raf card was their reactor to? [SEP]']
[ 750/2000] tot_loss=2.672 (perp=10.206, rec=0.469, cos=0.161), tot_loss_proj:3.930 [t=0.17s]
prediction: ['[CLS] the zane card was giving ref to? [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.192 (perp=9.045, rec=0.323, cos=0.060), tot_loss_proj:3.747 [t=0.17s]
prediction: ['[CLS] the beetles was giving left to zane? [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.677 (perp=6.758, rec=0.289, cos=0.036), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] the animal was left giving to david? [SEP]']
[ 900/2000] tot_loss=1.642 (perp=6.758, rec=0.263, cos=0.027), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] the animal was left giving to david? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.626 (perp=6.797, rec=0.245, cos=0.022), tot_loss_proj:3.129 [t=0.17s]
prediction: ['[CLS] the animal was left running to david? [SEP]']
Attempt swap
[1000/2000] tot_loss=2.061 (perp=9.022, rec=0.236, cos=0.020), tot_loss_proj:3.697 [t=0.17s]
prediction: ['[CLS] children animal was left running to david? [SEP]']
[1050/2000] tot_loss=2.050 (perp=9.022, rec=0.227, cos=0.019), tot_loss_proj:3.696 [t=0.17s]
prediction: ['[CLS] children animal was left running to david? [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.064 (perp=9.032, rec=0.237, cos=0.020), tot_loss_proj:3.710 [t=0.17s]
prediction: ['[CLS] children running screen was left to david? [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.975 (perp=8.650, rec=0.227, cos=0.019), tot_loss_proj:3.561 [t=0.17s]
prediction: ['[CLS] children running david was left to animal? [SEP]']
[1200/2000] tot_loss=1.960 (perp=8.650, rec=0.214, cos=0.016), tot_loss_proj:3.564 [t=0.17s]
prediction: ['[CLS] children running david was left to animal? [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.932 (perp=8.567, rec=0.202, cos=0.016), tot_loss_proj:3.556 [t=0.19s]
prediction: ['[CLS] children running was left to david animal? [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.012 (perp=8.993, rec=0.198, cos=0.016), tot_loss_proj:3.695 [t=0.19s]
prediction: ['[CLS] child running screen was left to david? [SEP]']
[1350/2000] tot_loss=2.017 (perp=8.993, rec=0.204, cos=0.014), tot_loss_proj:3.694 [t=0.20s]
prediction: ['[CLS] child running screen was left to david? [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.906 (perp=8.445, rec=0.203, cos=0.014), tot_loss_proj:3.686 [t=0.21s]
prediction: ['[CLS] child running was left to david? screen [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.830 (perp=8.088, rec=0.198, cos=0.014), tot_loss_proj:3.553 [t=0.17s]
prediction: ['[CLS] child running was left to david screen? [SEP]']
[1500/2000] tot_loss=1.826 (perp=8.088, rec=0.196, cos=0.013), tot_loss_proj:3.549 [t=0.17s]
prediction: ['[CLS] child running was left to david screen? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.801 (perp=8.019, rec=0.184, cos=0.013), tot_loss_proj:3.469 [t=0.17s]
prediction: ['[CLS] child running was left to david animal? [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.894 (perp=8.418, rec=0.197, cos=0.014), tot_loss_proj:3.544 [t=0.17s]
prediction: ['[CLS] child running was animal car to david? [SEP]']
[1650/2000] tot_loss=1.885 (perp=8.418, rec=0.189, cos=0.013), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] child running was animal car to david? [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.764 (perp=7.752, rec=0.201, cos=0.013), tot_loss_proj:3.457 [t=0.17s]
prediction: ['[CLS] child was running animal car to david? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.749 (perp=7.752, rec=0.185, cos=0.013), tot_loss_proj:3.455 [t=0.17s]
prediction: ['[CLS] child was running animal car to david? [SEP]']
[1800/2000] tot_loss=1.756 (perp=7.752, rec=0.193, cos=0.013), tot_loss_proj:3.460 [t=0.17s]
prediction: ['[CLS] child was running animal car to david? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.753 (perp=7.752, rec=0.190, cos=0.013), tot_loss_proj:3.458 [t=0.17s]
prediction: ['[CLS] child was running animal car to david? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.751 (perp=7.752, rec=0.189, cos=0.012), tot_loss_proj:3.460 [t=0.17s]
prediction: ['[CLS] child was running animal car to david? [SEP]']
[1950/2000] tot_loss=1.739 (perp=7.752, rec=0.177, cos=0.012), tot_loss_proj:3.459 [t=0.17s]
prediction: ['[CLS] child was running animal car to david? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.747 (perp=7.752, rec=0.185, cos=0.012), tot_loss_proj:3.455 [t=0.17s]
prediction: ['[CLS] child was running animal car to david? [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] was the child running to the car? [SEP]
========================
predicted: 
========================
[CLS] child was running animal car to david? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 77.778

[Aggregate metrics]:
rouge1     | fm: 82.186 | p: 82.796 | r: 81.750
rouge2     | fm: 33.900 | p: 34.173 | r: 33.923
rougeL     | fm: 66.106 | p: 66.530 | r: 65.798
rougeLsum  | fm: 66.212 | p: 66.651 | r: 65.917
r1fm+r2fm = 116.086

input #40 time: 0:07:24 | total time: 4:56:51


Running input #41 of 100.
reference: 
========================
Mary is shorter than five feet.
========================
average of cosine similarity 0.9993780592173414
highest_index [0]
highest [0.9993780592173414]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2984, 2003, 7820, 2084, 2274, 2519, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] mary is shorter than five feet. [SEP]']
[Init] best rec loss: 0.9804759621620178 for ['[CLS] try formerly doneicz gmina away originals [SEP]']
[Init] best rec loss: 0.9635863304138184 for ['[CLS] whilst cards loud jacksonon ladies bounded [SEP]']
[Init] best rec loss: 0.9399990439414978 for ['[CLS] she motto nerve five patsy unable deeper [SEP]']
[Init] best rec loss: 0.9262915849685669 for ['[CLS]ticalntonvious subjects hotelceae trains [SEP]']
[Init] best rec loss: 0.9226271510124207 for ['[CLS] [sei mixed sung assuming bag night [SEP]']
[Init] best rec loss: 0.9194919466972351 for ['[CLS]ading investigate closet lily mad page cover [SEP]']
[Init] best rec loss: 0.9147651195526123 for ['[CLS] younger xiarableuded respect miss flight [SEP]']
[Init] best rec loss: 0.9046170115470886 for ['[CLS] [UNK]micises background mechanism forces important [SEP]']
[Init] best rec loss: 0.9044715166091919 for ['[CLS] while they much cannotmal bedside death [SEP]']
[Init] best rec loss: 0.897434651851654 for ['[CLS] optionicated wherehausen fact reflection feel [SEP]']
[Init] best rec loss: 0.877751886844635 for ['[CLS] non completing 0 string page families space [SEP]']
[Init] best perm rec loss: 0.8773093223571777 for ['[CLS] page families non space completing string 0 [SEP]']
[Init] best perm rec loss: 0.8756932616233826 for ['[CLS] completing string non 0 page space families [SEP]']
[Init] best perm rec loss: 0.875471830368042 for ['[CLS] string families non page completing 0 space [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.520 (perp=9.631, rec=0.602, cos=0.992), tot_loss_proj:3.779 [t=0.17s]
prediction: ['[CLS] signals bull. greatest meritorious of. [SEP]']
[ 100/2000] tot_loss=2.993 (perp=7.386, rec=0.522, cos=0.994), tot_loss_proj:3.380 [t=0.17s]
prediction: ['[CLS] mary was. most mary feet. [SEP]']
[ 150/2000] tot_loss=3.830 (perp=11.071, rec=0.635, cos=0.981), tot_loss_proj:3.993 [t=0.17s]
prediction: ['[CLS] mary hired. spent mary actress percent [SEP]']
[ 200/2000] tot_loss=3.787 (perp=11.742, rec=0.459, cos=0.980), tot_loss_proj:4.196 [t=0.17s]
prediction: ['[CLS] mary was studies waist mary inch than [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.877 (perp=10.803, rec=0.758, cos=0.958), tot_loss_proj:4.056 [t=0.17s]
prediction: ['[CLS] mary waist ottoman. mary meters percent [SEP]']
[ 300/2000] tot_loss=3.585 (perp=10.122, rec=0.634, cos=0.927), tot_loss_proj:3.938 [t=0.17s]
prediction: ['[CLS] mary. ottoman. millimetres towers percent [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.264 (perp=9.493, rec=0.586, cos=0.780), tot_loss_proj:3.791 [t=0.17s]
prediction: ['[CLS] mary. ottoman shannon height percent. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.814 (perp=9.977, rec=0.536, cos=0.283), tot_loss_proj:3.847 [t=0.17s]
prediction: ['[CLS] ottoman mary. mary height teeth reminded [SEP]']
[ 450/2000] tot_loss=2.700 (perp=11.246, rec=0.373, cos=0.078), tot_loss_proj:4.125 [t=0.17s]
prediction: ['[CLS] protein mary. mary genus eyes reminded [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.321 (perp=9.704, rec=0.329, cos=0.051), tot_loss_proj:3.860 [t=0.17s]
prediction: ['[CLS] protein reminded mary. mary height feet [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.234 (perp=9.423, rec=0.313, cos=0.037), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] mary reminded protein. mary height feet [SEP]']
[ 600/2000] tot_loss=1.959 (perp=8.232, rec=0.284, cos=0.029), tot_loss_proj:3.516 [t=0.17s]
prediction: ['[CLS] mary reminded protein. mary is feet [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.000 (perp=8.497, rec=0.275, cos=0.025), tot_loss_proj:3.518 [t=0.17s]
prediction: ['[CLS] mary reminded shorter. mary is feet [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.783 (perp=7.379, rec=0.282, cos=0.025), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] mary reminded. mary is feet shorter [SEP]']
[ 750/2000] tot_loss=1.752 (perp=7.379, rec=0.255, cos=0.021), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] mary reminded. mary is feet shorter [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.658 (perp=6.983, rec=0.239, cos=0.022), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.652 (perp=6.983, rec=0.235, cos=0.021), tot_loss_proj:3.393 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
[ 900/2000] tot_loss=1.640 (perp=6.983, rec=0.223, cos=0.020), tot_loss_proj:3.392 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.640 (perp=6.983, rec=0.224, cos=0.019), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
Attempt swap
[1000/2000] tot_loss=1.636 (perp=6.983, rec=0.221, cos=0.019), tot_loss_proj:3.401 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
[1050/2000] tot_loss=1.631 (perp=6.983, rec=0.217, cos=0.018), tot_loss_proj:3.400 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
Attempt swap
[1100/2000] tot_loss=1.618 (perp=6.983, rec=0.204, cos=0.017), tot_loss_proj:3.401 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
Attempt swap
[1150/2000] tot_loss=1.618 (perp=6.983, rec=0.204, cos=0.017), tot_loss_proj:3.395 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
[1200/2000] tot_loss=1.614 (perp=6.983, rec=0.201, cos=0.017), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
Attempt swap
[1250/2000] tot_loss=1.614 (perp=6.983, rec=0.200, cos=0.017), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
Attempt swap
[1300/2000] tot_loss=1.615 (perp=6.983, rec=0.202, cos=0.017), tot_loss_proj:3.395 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
[1350/2000] tot_loss=1.607 (perp=6.983, rec=0.194, cos=0.017), tot_loss_proj:3.393 [t=0.17s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
Attempt swap
[1400/2000] tot_loss=1.614 (perp=6.983, rec=0.201, cos=0.017), tot_loss_proj:3.401 [t=0.18s]
prediction: ['[CLS] reminded mary. mary is feet shorter [SEP]']
Attempt swap
[1450/2000] tot_loss=1.889 (perp=8.412, rec=0.190, cos=0.016), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] reminded mary than mary is feet shorter [SEP]']
[1500/2000] tot_loss=1.895 (perp=8.412, rec=0.196, cos=0.016), tot_loss_proj:3.498 [t=0.18s]
prediction: ['[CLS] reminded mary than mary is feet shorter [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.699 (perp=7.248, rec=0.225, cos=0.025), tot_loss_proj:3.254 [t=0.17s]
prediction: ['[CLS] reminded mary mary is feet shorter. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.593 (perp=6.766, rec=0.217, cos=0.023), tot_loss_proj:3.208 [t=0.17s]
prediction: ['[CLS] mary reminded mary is feet shorter. [SEP]']
[1650/2000] tot_loss=1.588 (perp=6.766, rec=0.214, cos=0.021), tot_loss_proj:3.205 [t=0.17s]
prediction: ['[CLS] mary reminded mary is feet shorter. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.576 (perp=6.766, rec=0.202, cos=0.020), tot_loss_proj:3.204 [t=0.17s]
prediction: ['[CLS] mary reminded mary is feet shorter. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.583 (perp=6.766, rec=0.210, cos=0.020), tot_loss_proj:3.200 [t=0.18s]
prediction: ['[CLS] mary reminded mary is feet shorter. [SEP]']
[1800/2000] tot_loss=1.578 (perp=6.766, rec=0.205, cos=0.019), tot_loss_proj:3.203 [t=0.17s]
prediction: ['[CLS] mary reminded mary is feet shorter. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.578 (perp=6.766, rec=0.206, cos=0.019), tot_loss_proj:3.202 [t=0.17s]
prediction: ['[CLS] mary reminded mary is feet shorter. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.572 (perp=6.766, rec=0.200, cos=0.018), tot_loss_proj:3.204 [t=0.17s]
prediction: ['[CLS] mary reminded mary is feet shorter. [SEP]']
[1950/2000] tot_loss=1.577 (perp=6.766, rec=0.206, cos=0.018), tot_loss_proj:3.202 [t=0.17s]
prediction: ['[CLS] mary reminded mary is feet shorter. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.570 (perp=6.766, rec=0.199, cos=0.018), tot_loss_proj:3.205 [t=0.17s]
prediction: ['[CLS] mary reminded mary is feet shorter. [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] mary is shorter than five feet. [SEP]
========================
predicted: 
========================
[CLS] reminded mary than mary is feet shorter [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 13.333 | p: 12.500 | r: 14.286
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 95.686

[Aggregate metrics]:
rouge1     | fm: 82.194 | p: 82.734 | r: 81.900
rouge2     | fm: 33.683 | p: 33.931 | r: 33.609
rougeL     | fm: 65.851 | p: 66.355 | r: 65.612
rougeLsum  | fm: 66.119 | p: 66.491 | r: 65.792
r1fm+r2fm = 115.878

input #41 time: 0:07:16 | total time: 5:04:08


Running input #42 of 100.
reference: 
========================
She has enough of a problem as it is.
========================
average of cosine similarity 0.9992277228604687
highest_index [0]
highest [0.9992277228604687]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2016, 2038, 2438, 1997, 1037, 3291, 2004, 2009, 2003, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] she has enough of a problem as it is. [SEP]']
[Init] best rec loss: 0.9195099472999573 for ['[CLS] only shooter /press como solid togetherando ‑堂 [SEP]']
[Init] best rec loss: 0.9177475571632385 for ['[CLS] reflex cross tres silk families part ●wind translated like [SEP]']
[Init] best rec loss: 0.9160884022712708 for ['[CLS] violence trees closed much multimament mall freedoms separated squeezed [SEP]']
[Init] best rec loss: 0.9051212668418884 for ['[CLS] screenings former would headarty methyl saint bennett glenn ki [SEP]']
[Init] best rec loss: 0.8916860222816467 for ['[CLS] flock claimed jon domestic intelligence climax everywhere coal still census [SEP]']
[Init] best rec loss: 0.8842885494232178 for ['[CLS] boys # troy bel welcome honey sui application opera lark [SEP]']
[Init] best rec loss: 0.880082368850708 for ['[CLS] south historic maya hayden宀 clerkion coverage former tuesday [SEP]']
[Init] best rec loss: 0.8406323790550232 for ['[CLS] mine time minor deep fort clues erwin son leader troubled [SEP]']
[Init] best rec loss: 0.8227308392524719 for ['[CLS] into movement responsible huh belief hall safe representativepose fellow [SEP]']
[Init] best perm rec loss: 0.8197659254074097 for ['[CLS] representative into huh responsible safe hall belief movement fellowpose [SEP]']
[Init] best perm rec loss: 0.8181493878364563 for ['[CLS] movement responsiblepose safe belief fellow hall representative huh into [SEP]']
[Init] best perm rec loss: 0.8146902918815613 for ['[CLS] fellow representative belief responsible hall movementpose into huh safe [SEP]']
[Init] best perm rec loss: 0.8133512139320374 for ['[CLS] huh representative movement belief fellow into hall responsiblepose safe [SEP]']
[Init] best perm rec loss: 0.8132941126823425 for ['[CLS] safe responsible fellow into hallpose belief movement representative huh [SEP]']
[Init] best perm rec loss: 0.8127557039260864 for ['[CLS] hall belief representative into responsible movement safe huh fellowpose [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.685 (perp=11.110, rec=0.420, cos=0.042), tot_loss_proj:4.206 [t=0.17s]
prediction: ['[CLS] ladies quite study grade leone enough program as needs, [SEP]']
[ 100/2000] tot_loss=2.396 (perp=10.167, rec=0.343, cos=0.020), tot_loss_proj:4.060 [t=0.17s]
prediction: ['[CLS] additional quite study enough of enough system as problem, [SEP]']
[ 150/2000] tot_loss=2.211 (perp=9.628, rec=0.265, cos=0.021), tot_loss_proj:3.956 [t=0.17s]
prediction: ['[CLS] additional has she she as enough is is problem, [SEP]']
[ 200/2000] tot_loss=2.467 (perp=10.582, rec=0.317, cos=0.034), tot_loss_proj:4.131 [t=0.17s]
prediction: ['[CLS]dable has problem she as enough is of problem is [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.881 (perp=8.413, rec=0.185, cos=0.013), tot_loss_proj:3.570 [t=0.17s]
prediction: ['[CLS] single problem she has as enough is of problem, [SEP]']
[ 300/2000] tot_loss=1.789 (perp=8.096, rec=0.162, cos=0.008), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS]. problem she has as enough is of problem, [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.854 (perp=8.466, rec=0.150, cos=0.011), tot_loss_proj:3.561 [t=0.17s]
prediction: ['[CLS] 止 she has as enough problem is of problem. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.536 (perp=6.779, rec=0.169, cos=0.011), tot_loss_proj:3.345 [t=0.17s]
prediction: ['[CLS] enough she has as whole problem is of problem. [SEP]']
[ 450/2000] tot_loss=1.512 (perp=6.779, rec=0.147, cos=0.010), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] enough she has as whole problem is of problem. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.486 (perp=6.779, rec=0.121, cos=0.009), tot_loss_proj:3.361 [t=0.17s]
prediction: ['[CLS] enough she has as whole problem is of problem. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.546 (perp=7.026, rec=0.132, cos=0.009), tot_loss_proj:3.240 [t=0.17s]
prediction: ['[CLS] enough she has as running problem is of problem. [SEP]']
[ 600/2000] tot_loss=1.569 (perp=7.270, rec=0.106, cos=0.009), tot_loss_proj:3.351 [t=0.17s]
prediction: ['[CLS] enough she has as chance a is of problem. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.458 (perp=6.677, rec=0.114, cos=0.009), tot_loss_proj:3.264 [t=0.17s]
prediction: ['[CLS] enough she has as long a is of problem. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.398 (perp=6.454, rec=0.098, cos=0.009), tot_loss_proj:3.097 [t=0.17s]
prediction: ['[CLS] enough she has as a big is of problem. [SEP]']
[ 750/2000] tot_loss=1.662 (perp=7.739, rec=0.107, cos=0.007), tot_loss_proj:3.490 [t=0.17s]
prediction: ['[CLS] enough she has as a big is of problem it [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.435 (perp=6.630, rec=0.102, cos=0.007), tot_loss_proj:3.055 [t=0.17s]
prediction: ['[CLS] enough she has as a big problem is of it [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.426 (perp=6.630, rec=0.094, cos=0.006), tot_loss_proj:3.052 [t=0.17s]
prediction: ['[CLS] enough she has as a big problem is of it [SEP]']
[ 900/2000] tot_loss=1.421 (perp=6.630, rec=0.089, cos=0.006), tot_loss_proj:3.051 [t=0.17s]
prediction: ['[CLS] enough she has as a big problem is of it [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.697 (perp=7.985, rec=0.094, cos=0.006), tot_loss_proj:3.496 [t=0.17s]
prediction: ['[CLS] enough she has as a chance problem is of it [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.613 (perp=7.612, rec=0.084, cos=0.006), tot_loss_proj:3.427 [t=0.17s]
prediction: ['[CLS] enough she has as a chance is problem of it [SEP]']
[1050/2000] tot_loss=1.492 (perp=6.969, rec=0.092, cos=0.006), tot_loss_proj:3.275 [t=0.17s]
prediction: ['[CLS] enough she has as a big is problem of it [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.576 (perp=7.474, rec=0.075, cos=0.006), tot_loss_proj:3.369 [t=0.18s]
prediction: ['[CLS] enough she has as a chance problem of it is [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.421 (perp=6.615, rec=0.091, cos=0.007), tot_loss_proj:3.065 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of long it is [SEP]']
[1200/2000] tot_loss=1.412 (perp=6.615, rec=0.083, cos=0.006), tot_loss_proj:3.066 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of long it is [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.372 (perp=6.326, rec=0.101, cos=0.006), tot_loss_proj:3.149 [t=0.18s]
prediction: ['[CLS] enough she has as a problem of it is running [SEP]']
Attempt swap
[1300/2000] tot_loss=1.350 (perp=6.326, rec=0.079, cos=0.006), tot_loss_proj:3.152 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of it is running [SEP]']
[1350/2000] tot_loss=1.345 (perp=6.326, rec=0.074, cos=0.006), tot_loss_proj:3.153 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of it is running [SEP]']
Attempt swap
[1400/2000] tot_loss=1.344 (perp=6.326, rec=0.073, cos=0.006), tot_loss_proj:3.151 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of it is running [SEP]']
Attempt swap
[1450/2000] tot_loss=1.389 (perp=6.518, rec=0.080, cos=0.006), tot_loss_proj:3.122 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of it is chance [SEP]']
[1500/2000] tot_loss=1.387 (perp=6.518, rec=0.078, cos=0.006), tot_loss_proj:3.122 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of it is chance [SEP]']
Attempt swap
[1550/2000] tot_loss=1.395 (perp=6.518, rec=0.085, cos=0.006), tot_loss_proj:3.122 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of it is chance [SEP]']
Attempt swap
[1600/2000] tot_loss=1.382 (perp=6.518, rec=0.073, cos=0.006), tot_loss_proj:3.123 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of it is chance [SEP]']
[1650/2000] tot_loss=1.387 (perp=6.518, rec=0.078, cos=0.006), tot_loss_proj:3.122 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of it is chance [SEP]']
Attempt swap
[1700/2000] tot_loss=1.391 (perp=6.518, rec=0.082, cos=0.005), tot_loss_proj:3.119 [t=0.17s]
prediction: ['[CLS] enough she has as a problem of it is chance [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.363 (perp=6.350, rec=0.087, cos=0.006), tot_loss_proj:3.077 [t=0.17s]
prediction: ['[CLS] enough as she has a problem of it is chance [SEP]']
[1800/2000] tot_loss=1.356 (perp=6.350, rec=0.080, cos=0.006), tot_loss_proj:3.076 [t=0.17s]
prediction: ['[CLS] enough as she has a problem of it is chance [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.282 (perp=5.974, rec=0.081, cos=0.006), tot_loss_proj:3.214 [t=0.17s]
prediction: ['[CLS] enough of she has a problem as it is chance [SEP]']
Attempt swap
[1900/2000] tot_loss=1.281 (perp=5.974, rec=0.081, cos=0.006), tot_loss_proj:3.213 [t=0.17s]
prediction: ['[CLS] enough of she has a problem as it is chance [SEP]']
[1950/2000] tot_loss=1.280 (perp=5.974, rec=0.080, cos=0.005), tot_loss_proj:3.216 [t=0.17s]
prediction: ['[CLS] enough of she has a problem as it is chance [SEP]']
Attempt swap
[2000/2000] tot_loss=1.286 (perp=5.974, rec=0.086, cos=0.005), tot_loss_proj:3.217 [t=0.17s]
prediction: ['[CLS] enough of she has a problem as it is chance [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] she has enough of a problem as it is. [SEP]
========================
predicted: 
========================
[CLS] enough of she has a problem as it is chance [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 57.143 | p: 54.545 | r: 60.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 152.795

[Aggregate metrics]:
rouge1     | fm: 82.441 | p: 82.790 | r: 82.292
rouge2     | fm: 34.166 | p: 34.295 | r: 34.188
rougeL     | fm: 65.983 | p: 66.375 | r: 65.850
rougeLsum  | fm: 66.237 | p: 66.630 | r: 66.209
r1fm+r2fm = 116.607

input #42 time: 0:07:08 | total time: 5:11:16


Running input #43 of 100.
reference: 
========================
Every student has to come up with three arguments that show that some condition proposed by Bill is wrong.
========================
average of cosine similarity 0.9993892958061774
highest_index [0]
highest [0.9993892958061774]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[ 101, 2296, 3076, 2038, 2000, 2272, 2039, 2007, 2093, 9918, 2008, 2265,
         2008, 2070, 4650, 3818, 2011, 3021, 2003, 3308, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]']
[Init] best rec loss: 0.941371500492096 for ['[CLS] unaffected peter interval sporting campaign singular relieved start shooting club helleche date operative either meredith occupied lamagee metals [SEP]']
[Init] best rec loss: 0.9361624121665955 for ['[CLS]work beginning refugees accurate ever livesि thesis skirt gran language kingsley scrub regis opera al kin tri all bearing [SEP]']
[Init] best rec loss: 0.9320390224456787 for ['[CLS]nium truck register heart paper whitney subdivision pseudonym dog leapsner reply photon intense border nk blown sri artillery sad [SEP]']
[Init] best rec loss: 0.9182119369506836 for ['[CLS] rule blind third sheen a xu snarl brainific storm median head you gathering mono operational hard patti nba coach [SEP]']
[Init] best rec loss: 0.9167119264602661 for ['[CLS] army duck abolished [MASK]kyumons spokeverse how und purchase joined midstiard beijing breakfastcter after reserve promise [SEP]']
[Init] best rec loss: 0.9060932993888855 for ['[CLS]room tango plumageote along turn smashwords living bill always energy machines threaten glacier formed t patent proik pick [SEP]']
[Init] best rec loss: 0.9036861062049866 for ['[CLS] surprise santa nell games circumstances may enclosed pilot late surf graduation not tuneau date payne oceanrogate big fellow [SEP]']
[Init] best rec loss: 0.8932493925094604 for ['[CLS] awesome entertainment below electricity sage dreamerpressing colliery harvest share color bed titanic rapid were before features titular baymura [SEP]']
[Init] best perm rec loss: 0.8914357423782349 for ['[CLS]pressing colliery titanic were before titularmura color share features entertainment below dreamer awesome bay rapid sage bed electricity harvest [SEP]']
[Init] best perm rec loss: 0.8903899192810059 for ['[CLS] sage entertainmentpressing colliery titanic harvest color awesomemura titular before features bed dreamer electricity below were rapid share bay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.948 (perp=12.621, rec=0.385, cos=0.039), tot_loss_proj:4.407 [t=0.18s]
prediction: ['[CLS] predicting music reactors valid type produce racial as machine movie pattern ink per parliamentary wrong het program parallel a creature [SEP]']
[ 100/2000] tot_loss=2.778 (perp=12.408, rec=0.281, cos=0.015), tot_loss_proj:4.295 [t=0.18s]
prediction: ['[CLS] predicting show studentvable plan produce arguments theseface that because published per contrary wrong gospel project clearly three bill [SEP]']
[ 150/2000] tot_loss=2.380 (perp=10.821, rec=0.208, cos=0.008), tot_loss_proj:4.020 [t=0.18s]
prediction: ['[CLS] mark show student every argument include arguments arguments noise that because published this wrong wrong student project show three bill [SEP]']
[ 200/2000] tot_loss=2.403 (perp=11.125, rec=0.172, cos=0.007), tot_loss_proj:4.088 [t=0.18s]
prediction: ['[CLS] bill, student every must includes arguments argumentsface that because by that condition student strange bill show three bill [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.053 (perp=9.449, rec=0.156, cos=0.008), tot_loss_proj:3.725 [t=0.18s]
prediction: ['[CLS] bill, student arguments has with every argumentssume that - by this condition student condition bill show three bill [SEP]']
[ 300/2000] tot_loss=2.263 (perp=10.589, rec=0.139, cos=0.006), tot_loss_proj:3.938 [t=0.18s]
prediction: ['[CLS] bill, student arguments has up every arguments halfway that like by that condition condition condition bill show three bill [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.993 (perp=9.246, rec=0.138, cos=0.006), tot_loss_proj:3.692 [t=0.18s]
prediction: ['[CLS] bill, every student arguments has up arguments up that. by that condition condition condition bill show three bill [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.088 (perp=9.723, rec=0.139, cos=0.004), tot_loss_proj:3.772 [t=0.18s]
prediction: ['[CLS] condition to every student arguments has up arguments up that like has any bill condition condition bill show three bill [SEP]']
[ 450/2000] tot_loss=2.188 (perp=10.248, rec=0.135, cos=0.004), tot_loss_proj:3.863 [t=0.18s]
prediction: ['[CLS] condition to every student arguments has up arguments up that like has that bill condition condition bill show three bill [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.008 (perp=9.377, rec=0.130, cos=0.003), tot_loss_proj:3.688 [t=0.18s]
prediction: ['[CLS] condition to every student arguments has up some up that like has that bill condition bill show three condition bill [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.982 (perp=9.286, rec=0.122, cos=0.003), tot_loss_proj:3.651 [t=0.18s]
prediction: ['[CLS] condition to every student arguments has up some up that like bill that has condition bill show three condition bill [SEP]']
[ 600/2000] tot_loss=1.970 (perp=9.286, rec=0.110, cos=0.002), tot_loss_proj:3.652 [t=0.18s]
prediction: ['[CLS] condition to every student arguments has up some up that like bill that has condition bill show three condition bill [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.945 (perp=9.134, rec=0.116, cos=0.002), tot_loss_proj:3.635 [t=0.18s]
prediction: ['[CLS] condition to every student arguments has up some up that like that bill has condition bill show three condition bill [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.939 (perp=9.134, rec=0.110, cos=0.002), tot_loss_proj:3.634 [t=0.18s]
prediction: ['[CLS] condition to every student arguments has up some up that like that bill has condition bill show three condition bill [SEP]']
[ 750/2000] tot_loss=1.971 (perp=9.247, rec=0.119, cos=0.002), tot_loss_proj:3.649 [t=0.18s]
prediction: ['[CLS] condition to every student arguments has up some up that - some bill has condition bill show three condition bill [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.961 (perp=9.252, rec=0.108, cos=0.002), tot_loss_proj:3.666 [t=0.18s]
prediction: ['[CLS] condition to every student arguments has up some up that - some bill has condition proposed show three condition bill [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.922 (perp=9.024, rec=0.115, cos=0.003), tot_loss_proj:3.623 [t=0.18s]
prediction: ['[CLS] wrong to every student arguments has up some up that - some bill has condition proposed show three condition bill [SEP]']
[ 900/2000] tot_loss=1.919 (perp=9.024, rec=0.112, cos=0.002), tot_loss_proj:3.626 [t=0.18s]
prediction: ['[CLS] wrong to every student arguments has up some up that - some bill has condition proposed show three condition bill [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.915 (perp=9.024, rec=0.108, cos=0.002), tot_loss_proj:3.622 [t=0.18s]
prediction: ['[CLS] wrong to every student arguments has up some up that - some bill has condition proposed show three condition bill [SEP]']
Attempt swap
[1000/2000] tot_loss=1.913 (perp=9.024, rec=0.106, cos=0.002), tot_loss_proj:3.625 [t=0.18s]
prediction: ['[CLS] wrong to every student arguments has up some up that - some bill has condition proposed show three condition bill [SEP]']
[1050/2000] tot_loss=1.938 (perp=9.106, rec=0.115, cos=0.002), tot_loss_proj:3.625 [t=0.18s]
prediction: ['[CLS] wrong to every student arguments has up some up that. some bill has condition proposed show three condition bill [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.929 (perp=9.107, rec=0.104, cos=0.003), tot_loss_proj:3.662 [t=0.18s]
prediction: ['[CLS] wrong to every student arguments has up has up that - some bill some condition proposed show three condition bill [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.900 (perp=8.924, rec=0.112, cos=0.002), tot_loss_proj:3.645 [t=0.20s]
prediction: ['[CLS] wrong to every student arguments has up has up that of some bill some proposed condition show three condition bill [SEP]']
[1200/2000] tot_loss=2.049 (perp=9.693, rec=0.109, cos=0.002), tot_loss_proj:3.785 [t=0.20s]
prediction: ['[CLS] wrong come every student arguments has up has up that, some bill some proposed condition show three condition bill [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.998 (perp=9.462, rec=0.103, cos=0.002), tot_loss_proj:3.757 [t=0.18s]
prediction: ['[CLS] wrong come every student arguments has up has up that, some condition bill some proposed show three condition bill [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.949 (perp=9.203, rec=0.106, cos=0.003), tot_loss_proj:3.693 [t=0.18s]
prediction: ['[CLS] wrong come every student arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
[1350/2000] tot_loss=1.946 (perp=9.203, rec=0.103, cos=0.002), tot_loss_proj:3.693 [t=0.18s]
prediction: ['[CLS] wrong come every student arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.927 (perp=9.131, rec=0.099, cos=0.002), tot_loss_proj:3.683 [t=0.18s]
prediction: ['[CLS] wrong arguments every student come has up has up that, some show condition bill some proposed three condition bill [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.919 (perp=9.073, rec=0.102, cos=0.002), tot_loss_proj:3.683 [t=0.18s]
prediction: ['[CLS] wrong arguments every come student has up has up that, some show condition bill some proposed three condition bill [SEP]']
[1500/2000] tot_loss=1.924 (perp=9.073, rec=0.107, cos=0.002), tot_loss_proj:3.685 [t=0.18s]
prediction: ['[CLS] wrong arguments every come student has up has up that, some show condition bill some proposed three condition bill [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.923 (perp=9.073, rec=0.106, cos=0.002), tot_loss_proj:3.685 [t=0.18s]
prediction: ['[CLS] wrong arguments every come student has up has up that, some show condition bill some proposed three condition bill [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.903 (perp=9.014, rec=0.098, cos=0.002), tot_loss_proj:3.656 [t=0.18s]
prediction: ['[CLS] wrong student every come arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
[1650/2000] tot_loss=1.903 (perp=9.014, rec=0.098, cos=0.002), tot_loss_proj:3.654 [t=0.18s]
prediction: ['[CLS] wrong student every come arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
Attempt swap
[1700/2000] tot_loss=1.908 (perp=9.014, rec=0.103, cos=0.002), tot_loss_proj:3.653 [t=0.18s]
prediction: ['[CLS] wrong student every come arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
Attempt swap
[1750/2000] tot_loss=1.905 (perp=9.014, rec=0.100, cos=0.002), tot_loss_proj:3.653 [t=0.18s]
prediction: ['[CLS] wrong student every come arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
[1800/2000] tot_loss=1.899 (perp=9.014, rec=0.094, cos=0.002), tot_loss_proj:3.657 [t=0.18s]
prediction: ['[CLS] wrong student every come arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
Attempt swap
[1850/2000] tot_loss=1.906 (perp=9.014, rec=0.101, cos=0.002), tot_loss_proj:3.653 [t=0.18s]
prediction: ['[CLS] wrong student every come arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
Attempt swap
[1900/2000] tot_loss=1.908 (perp=9.014, rec=0.103, cos=0.002), tot_loss_proj:3.654 [t=0.18s]
prediction: ['[CLS] wrong student every come arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
[1950/2000] tot_loss=1.909 (perp=9.014, rec=0.105, cos=0.002), tot_loss_proj:3.654 [t=0.18s]
prediction: ['[CLS] wrong student every come arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
Attempt swap
[2000/2000] tot_loss=1.906 (perp=9.014, rec=0.101, cos=0.002), tot_loss_proj:3.656 [t=0.18s]
prediction: ['[CLS] wrong student every come arguments has up has up that, some show condition bill some proposed three condition bill [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]
========================
predicted: 
========================
[CLS] wrong student every come arguments has up has up that, some show condition bill some proposed three condition bill [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 76.190 | r: 76.190
rouge2     | fm: 5.000 | p: 5.000 | r: 5.000
rougeL     | fm: 47.619 | p: 47.619 | r: 47.619
rougeLsum  | fm: 47.619 | p: 47.619 | r: 47.619
r1fm+r2fm = 81.190

[Aggregate metrics]:
rouge1     | fm: 82.306 | p: 82.765 | r: 82.156
rouge2     | fm: 33.582 | p: 33.774 | r: 33.661
rougeL     | fm: 65.685 | p: 66.000 | r: 65.588
rougeLsum  | fm: 65.773 | p: 66.028 | r: 65.790
r1fm+r2fm = 115.888

input #43 time: 0:07:16 | total time: 5:18:33


Running input #44 of 100.
reference: 
========================
Kim alienates cats and beat his dog.
========================
average of cosine similarity 0.9993126822858673
highest_index [0]
highest [0.9993126822858673]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 5035, 7344, 8520, 8870, 1998, 3786, 2010, 3899, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] kim alienates cats and beat his dog. [SEP]']
[Init] best rec loss: 1.0216113328933716 for ['[CLS] vineyard sterling michigan bat hot boltedpati cannot matter [SEP]']
[Init] best rec loss: 0.9771472215652466 for ['[CLS] jihad much complex marshall deadline [SEP] terminus volume japan [SEP]']
[Init] best rec loss: 0.9380818605422974 for ['[CLS] attempt ll foreign suck off spy gain app promoted [SEP]']
[Init] best rec loss: 0.9156078100204468 for ['[CLS] glacial examlip eat condition von wonder channel junk [SEP]']
[Init] best rec loss: 0.915208637714386 for ['[CLS] cooled best teams stellaxide staffed qualified will roll [SEP]']
[Init] best rec loss: 0.9150818586349487 for ['[CLS] cigarette harvey givensso nurse una rash beautiful inquired [SEP]']
[Init] best rec loss: 0.9134103655815125 for ['[CLS] sir glimpse license faun frame scars principleess [SEP]']
[Init] best rec loss: 0.9127835631370544 for ['[CLS]torewives corps answer bombs organization federation fine bronze [SEP]']
[Init] best rec loss: 0.8829893469810486 for ['[CLS]⁄ lance assigns edmund missouri other. started dan [SEP]']
[Init] best perm rec loss: 0.8820619583129883 for ['[CLS] missouri started edmund dan other lance⁄. assigns [SEP]']
[Init] best perm rec loss: 0.8815537095069885 for ['[CLS] lance dan assigns. other started⁄ edmund missouri [SEP]']
[Init] best perm rec loss: 0.8798965811729431 for ['[CLS] lance started edmund.⁄ other missouri assigns dan [SEP]']
[Init] best perm rec loss: 0.8791020512580872 for ['[CLS]⁄ lance edmund. assigns other started missouri dan [SEP]']
[Init] best perm rec loss: 0.8787437081336975 for ['[CLS] other lance. started missouri assigns edmund⁄ dan [SEP]']
[Init] best perm rec loss: 0.8781583905220032 for ['[CLS] dan lance edmund missouri other started. assigns⁄ [SEP]']
[Init] best perm rec loss: 0.8779261112213135 for ['[CLS] assigns lance. started⁄ other dan edmund missouri [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.870 (perp=11.423, rec=0.629, cos=0.956), tot_loss_proj:4.193 [t=0.17s]
prediction: ['[CLS] sounded worse upon yes barack injuries had our angry [SEP]']
[ 100/2000] tot_loss=3.503 (perp=10.197, rec=0.562, cos=0.902), tot_loss_proj:3.945 [t=0.17s]
prediction: ['[CLS]. worse off tomorrow tempo injuries had dave dog [SEP]']
[ 150/2000] tot_loss=3.963 (perp=11.843, rec=0.745, cos=0.849), tot_loss_proj:4.296 [t=0.17s]
prediction: ['[CLS]. worse despite ‚ beat hunter had y dog [SEP]']
[ 200/2000] tot_loss=3.607 (perp=10.726, rec=0.817, cos=0.645), tot_loss_proj:4.163 [t=0.17s]
prediction: ['[CLS] ( wise beat how beat nouns hadelle beat [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.687 (perp=11.025, rec=0.418, cos=0.064), tot_loss_proj:4.185 [t=0.17s]
prediction: ['[CLS] firing barack beatations shot kaitlyn has cats played [SEP]']
[ 300/2000] tot_loss=2.520 (perp=10.690, rec=0.350, cos=0.032), tot_loss_proj:4.121 [t=0.17s]
prediction: ['[CLS] wrong dog beat beat beat kim had cats beat [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.364 (perp=10.163, rec=0.309, cos=0.023), tot_loss_proj:4.000 [t=0.17s]
prediction: ['[CLS] kim beat dog beat beat beat had cats beat [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.093 (perp=8.990, rec=0.273, cos=0.022), tot_loss_proj:3.802 [t=0.17s]
prediction: ['[CLS] kim kim cat beat beat beat had cats beat [SEP]']
[ 450/2000] tot_loss=2.178 (perp=9.633, rec=0.237, cos=0.015), tot_loss_proj:3.872 [t=0.17s]
prediction: ['[CLS] ignoring kim dog beat his beat and cats beat [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.999 (perp=8.866, rec=0.214, cos=0.011), tot_loss_proj:3.691 [t=0.17s]
prediction: ['[CLS] kim ignoring dog beat his beat and cats beat [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.896 (perp=8.401, rec=0.206, cos=0.011), tot_loss_proj:3.639 [t=0.18s]
prediction: ['[CLS] kim ignoring his beat dog beat and cats beat [SEP]']
[ 600/2000] tot_loss=2.020 (perp=9.121, rec=0.187, cos=0.009), tot_loss_proj:3.762 [t=0.19s]
prediction: ['[CLS] kim alien his beat dog beat and cats beat [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.827 (perp=8.201, rec=0.180, cos=0.008), tot_loss_proj:3.619 [t=0.19s]
prediction: ['[CLS] kim alien beat his dog beat and cats beat [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.822 (perp=8.201, rec=0.175, cos=0.007), tot_loss_proj:3.626 [t=0.19s]
prediction: ['[CLS] kim alien beat his dog beat and cats beat [SEP]']
[ 750/2000] tot_loss=1.804 (perp=8.201, rec=0.158, cos=0.006), tot_loss_proj:3.623 [t=0.19s]
prediction: ['[CLS] kim alien beat his dog beat and cats beat [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.797 (perp=8.201, rec=0.151, cos=0.006), tot_loss_proj:3.626 [t=0.19s]
prediction: ['[CLS] kim alien beat his dog beat and cats beat [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.797 (perp=8.201, rec=0.151, cos=0.006), tot_loss_proj:3.625 [t=0.19s]
prediction: ['[CLS] kim alien beat his dog beat and cats beat [SEP]']
[ 900/2000] tot_loss=1.790 (perp=8.201, rec=0.143, cos=0.006), tot_loss_proj:3.621 [t=0.19s]
prediction: ['[CLS] kim alien beat his dog beat and cats beat [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.794 (perp=8.282, rec=0.132, cos=0.006), tot_loss_proj:3.627 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1000/2000] tot_loss=1.786 (perp=8.282, rec=0.124, cos=0.005), tot_loss_proj:3.628 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
[1050/2000] tot_loss=1.780 (perp=8.282, rec=0.118, cos=0.005), tot_loss_proj:3.627 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1100/2000] tot_loss=1.768 (perp=8.282, rec=0.107, cos=0.005), tot_loss_proj:3.624 [t=0.19s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1150/2000] tot_loss=1.773 (perp=8.282, rec=0.112, cos=0.005), tot_loss_proj:3.626 [t=0.24s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
[1200/2000] tot_loss=1.776 (perp=8.282, rec=0.116, cos=0.004), tot_loss_proj:3.625 [t=0.19s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1250/2000] tot_loss=1.770 (perp=8.282, rec=0.109, cos=0.004), tot_loss_proj:3.626 [t=0.18s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1300/2000] tot_loss=1.770 (perp=8.282, rec=0.110, cos=0.004), tot_loss_proj:3.627 [t=0.18s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
[1350/2000] tot_loss=1.767 (perp=8.282, rec=0.107, cos=0.004), tot_loss_proj:3.630 [t=0.18s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1400/2000] tot_loss=1.758 (perp=8.282, rec=0.098, cos=0.004), tot_loss_proj:3.625 [t=0.18s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1450/2000] tot_loss=1.755 (perp=8.282, rec=0.094, cos=0.004), tot_loss_proj:3.628 [t=0.18s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
[1500/2000] tot_loss=1.756 (perp=8.282, rec=0.096, cos=0.004), tot_loss_proj:3.628 [t=0.18s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1550/2000] tot_loss=1.761 (perp=8.282, rec=0.100, cos=0.004), tot_loss_proj:3.626 [t=0.18s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1600/2000] tot_loss=1.752 (perp=8.282, rec=0.092, cos=0.004), tot_loss_proj:3.626 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
[1650/2000] tot_loss=1.761 (perp=8.282, rec=0.101, cos=0.004), tot_loss_proj:3.629 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1700/2000] tot_loss=1.765 (perp=8.282, rec=0.105, cos=0.004), tot_loss_proj:3.623 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1750/2000] tot_loss=1.754 (perp=8.282, rec=0.094, cos=0.004), tot_loss_proj:3.624 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
[1800/2000] tot_loss=1.749 (perp=8.282, rec=0.089, cos=0.004), tot_loss_proj:3.625 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1850/2000] tot_loss=1.770 (perp=8.282, rec=0.110, cos=0.004), tot_loss_proj:3.628 [t=0.18s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[1900/2000] tot_loss=1.760 (perp=8.282, rec=0.100, cos=0.004), tot_loss_proj:3.623 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
[1950/2000] tot_loss=1.754 (perp=8.282, rec=0.094, cos=0.004), tot_loss_proj:3.628 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Attempt swap
[2000/2000] tot_loss=1.760 (perp=8.282, rec=0.100, cos=0.004), tot_loss_proj:3.627 [t=0.17s]
prediction: ['[CLS] kim alienates his dog beat and cats beat [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] kim alienates cats and beat his dog. [SEP]
========================
predicted: 
========================
[CLS] kim alienates his dog beat and cats beat [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 35.294 | p: 33.333 | r: 37.500
rougeL     | fm: 63.158 | p: 60.000 | r: 66.667
rougeLsum  | fm: 63.158 | p: 60.000 | r: 66.667
r1fm+r2fm = 130.031

[Aggregate metrics]:
rouge1     | fm: 82.643 | p: 82.931 | r: 82.650
rouge2     | fm: 33.300 | p: 33.356 | r: 33.445
rougeL     | fm: 65.545 | p: 65.862 | r: 65.553
rougeLsum  | fm: 65.724 | p: 65.942 | r: 65.700
r1fm+r2fm = 115.943

input #44 time: 0:07:18 | total time: 5:25:51


Running input #45 of 100.
reference: 
========================
John's I stole bike.
========================
average of cosine similarity 0.999353611080195
highest_index [0]
highest [0.999353611080195]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2198,  1005,  1055,  1045, 10312,  7997,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] john's i stole bike. [SEP]"]
[Init] best rec loss: 0.9623914957046509 for ['[CLS] outskirts came too yourtered occupy tradition [SEP]']
[Init] best rec loss: 0.890116274356842 for ['[CLS] and general driving weak [SEP]akcede [SEP]']
[Init] best rec loss: 0.7756944298744202 for ['[CLS] video date prime tall lifeless grape person [SEP]']
[Init] best rec loss: 0.7738812565803528 for ['[CLS] orbit editor ring spread using jones yugoslav [SEP]']
[Init] best rec loss: 0.7658082246780396 for ['[CLS] expecting special scaleslock mhz wish ser [SEP]']
[Init] best rec loss: 0.7612343430519104 for ['[CLS] evening lose high design bankrupt caucus landscape [SEP]']
[Init] best rec loss: 0.7316742539405823 for ['[CLS] hadn quite about sit exit rugby mc [SEP]']
[Init] best perm rec loss: 0.7308976054191589 for ['[CLS] rugby mc about sit hadn quite exit [SEP]']
[Init] best perm rec loss: 0.7300025820732117 for ['[CLS] exit hadn rugby sit quite about mc [SEP]']
[Init] best perm rec loss: 0.7252820134162903 for ['[CLS] quite hadn about rugby exit mc sit [SEP]']
[Init] best perm rec loss: 0.722222626209259 for ['[CLS] exit about quite mc sit hadn rugby [SEP]']
[Init] best perm rec loss: 0.7214416265487671 for ['[CLS] sit rugby exit hadn quite about mc [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.462 (perp=10.729, rec=0.306, cos=0.010), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] was father lanka bike killed bike. [SEP]']
[ 100/2000] tot_loss=1.972 (perp=8.434, rec=0.274, cos=0.011), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS] i joseph s bike stole bike. [SEP]']
[ 150/2000] tot_loss=1.966 (perp=8.992, rec=0.161, cos=0.006), tot_loss_proj:2.788 [t=0.17s]
prediction: ['[CLS] i john s bike stole bike. [SEP]']
[ 200/2000] tot_loss=1.925 (perp=8.992, rec=0.122, cos=0.005), tot_loss_proj:2.785 [t=0.17s]
prediction: ['[CLS] i john s bike stole bike. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.809 (perp=8.396, rec=0.125, cos=0.005), tot_loss_proj:2.244 [t=0.17s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[ 300/2000] tot_loss=1.792 (perp=8.396, rec=0.109, cos=0.004), tot_loss_proj:2.247 [t=0.17s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.787 (perp=8.396, rec=0.104, cos=0.004), tot_loss_proj:2.242 [t=0.19s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.778 (perp=8.396, rec=0.095, cos=0.004), tot_loss_proj:2.240 [t=0.17s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[ 450/2000] tot_loss=1.784 (perp=8.396, rec=0.101, cos=0.004), tot_loss_proj:2.245 [t=0.17s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.777 (perp=8.396, rec=0.095, cos=0.004), tot_loss_proj:2.243 [t=0.21s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.777 (perp=8.396, rec=0.094, cos=0.003), tot_loss_proj:2.249 [t=0.17s]
prediction: ['[CLS] john i s bike stole bike. [SEP]']
[ 600/2000] tot_loss=1.869 (perp=8.863, rec=0.094, cos=0.003), tot_loss_proj:2.429 [t=0.17s]
prediction: ['[CLS] john i s bike stole keeps. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.084 (perp=9.952, rec=0.091, cos=0.003), tot_loss_proj:2.641 [t=0.17s]
prediction: ['[CLS] john i s bike stoleker. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.868 (perp=8.896, rec=0.086, cos=0.003), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] john i s bike stole release. [SEP]']
[ 750/2000] tot_loss=1.986 (perp=9.411, rec=0.101, cos=0.003), tot_loss_proj:2.867 [t=0.17s]
prediction: ['[CLS] john i s bike stolesea. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.862 (perp=8.830, rec=0.093, cos=0.003), tot_loss_proj:3.052 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.866 (perp=8.830, rec=0.097, cos=0.003), tot_loss_proj:3.051 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
[ 900/2000] tot_loss=1.855 (perp=8.830, rec=0.086, cos=0.003), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.860 (perp=8.830, rec=0.091, cos=0.003), tot_loss_proj:3.050 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.851 (perp=8.830, rec=0.082, cos=0.003), tot_loss_proj:3.047 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
[1050/2000] tot_loss=1.852 (perp=8.830, rec=0.084, cos=0.003), tot_loss_proj:3.054 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.855 (perp=8.830, rec=0.086, cos=0.003), tot_loss_proj:3.049 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.856 (perp=8.830, rec=0.087, cos=0.003), tot_loss_proj:3.054 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
[1200/2000] tot_loss=1.856 (perp=8.830, rec=0.088, cos=0.003), tot_loss_proj:3.052 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.854 (perp=8.830, rec=0.086, cos=0.003), tot_loss_proj:3.052 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.858 (perp=8.830, rec=0.090, cos=0.003), tot_loss_proj:3.052 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
[1350/2000] tot_loss=1.855 (perp=8.830, rec=0.087, cos=0.003), tot_loss_proj:3.051 [t=0.17s]
prediction: ['[CLS] john i s stole bikesea. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.069 (perp=9.909, rec=0.085, cos=0.003), tot_loss_proj:3.135 [t=0.18s]
prediction: ['[CLS] john i s stole bikepu. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.783 (perp=8.281, rec=0.122, cos=0.005), tot_loss_proj:2.263 [t=0.18s]
prediction: ['[CLS] john i s plato stole bike. [SEP]']
[1500/2000] tot_loss=1.829 (perp=8.681, rec=0.090, cos=0.003), tot_loss_proj:2.936 [t=0.18s]
prediction: ['[CLS] john i spu stole bike. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.741 (perp=8.281, rec=0.082, cos=0.002), tot_loss_proj:2.276 [t=0.17s]
prediction: ['[CLS] john i s plato stole bike. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.788 (perp=8.509, rec=0.084, cos=0.002), tot_loss_proj:2.951 [t=0.17s]
prediction: ['[CLS] john i sgent stole bike. [SEP]']
[1650/2000] tot_loss=1.789 (perp=8.509, rec=0.085, cos=0.002), tot_loss_proj:2.949 [t=0.17s]
prediction: ['[CLS] john i sgent stole bike. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.951 (perp=9.135, rec=0.121, cos=0.003), tot_loss_proj:3.228 [t=0.17s]
prediction: ['[CLS] john i s ago stole bike. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.915 (perp=9.135, rec=0.086, cos=0.003), tot_loss_proj:3.231 [t=0.17s]
prediction: ['[CLS] john i s ago stole bike. [SEP]']
[1800/2000] tot_loss=1.913 (perp=9.135, rec=0.084, cos=0.002), tot_loss_proj:3.231 [t=0.17s]
prediction: ['[CLS] john i s ago stole bike. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.913 (perp=9.135, rec=0.084, cos=0.002), tot_loss_proj:3.232 [t=0.17s]
prediction: ['[CLS] john i s ago stole bike. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.910 (perp=9.135, rec=0.080, cos=0.002), tot_loss_proj:3.230 [t=0.17s]
prediction: ['[CLS] john i s ago stole bike. [SEP]']
[1950/2000] tot_loss=1.901 (perp=9.135, rec=0.072, cos=0.002), tot_loss_proj:3.228 [t=0.17s]
prediction: ['[CLS] john i s ago stole bike. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.905 (perp=9.135, rec=0.076, cos=0.002), tot_loss_proj:3.229 [t=0.18s]
prediction: ['[CLS] john i s ago stole bike. [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] john's i stole bike. [SEP]
========================
predicted: 
========================
[CLS] john i s ago stole bike. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 46.154 | p: 42.857 | r: 50.000
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 139.487

[Aggregate metrics]:
rouge1     | fm: 82.848 | p: 82.980 | r: 82.956
rouge2     | fm: 33.806 | p: 33.820 | r: 33.995
rougeL     | fm: 65.916 | p: 65.954 | r: 65.970
rougeLsum  | fm: 66.119 | p: 66.307 | r: 66.153
r1fm+r2fm = 116.655

input #45 time: 0:07:11 | total time: 5:33:03


Running input #46 of 100.
reference: 
========================
The witch went into the forest by vanishing.
========================
average of cosine similarity 0.9993622173126959
highest_index [0]
highest [0.9993622173126959]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1996,  6965,  2253,  2046,  1996,  3224,  2011, 24866,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] the witch went into the forest by vanishing. [SEP]']
[Init] best rec loss: 0.7126263380050659 for ['[CLS] tripume mackenzie enterprise crunch threshold engine free down [SEP]']
[Init] best rec loss: 0.7099688053131104 for ['[CLS] terms masters nightingale appeared calling tropical has brant returns [SEP]']
[Init] best rec loss: 0.7057819366455078 for ['[CLS] gear rest roninpment s members university evenly matthew [SEP]']
[Init] best rec loss: 0.7033528685569763 for ['[CLS] hell advent shared moderatenton drivendity kennedyided [SEP]']
[Init] best rec loss: 0.698776125907898 for ['[CLS] suffix joe clay just crewmun warn cycle flows [SEP]']
[Init] best rec loss: 0.6938488483428955 for ['[CLS]led feed noah hung baydding blog house gate [SEP]']
[Init] best rec loss: 0.6714576482772827 for ['[CLS] ink loss yet volvo remaining fine manor sa glacier [SEP]']
[Init] best perm rec loss: 0.6680058240890503 for ['[CLS] ink volvo manor yet glacier fine remaining loss sa [SEP]']
[Init] best perm rec loss: 0.667153000831604 for ['[CLS] glacier yet remaining loss volvo ink sa manor fine [SEP]']
[Init] best perm rec loss: 0.6671254634857178 for ['[CLS] manor remaining fine loss ink yet sa volvo glacier [SEP]']
[Init] best perm rec loss: 0.6665775179862976 for ['[CLS] fine loss manor ink sa glacier remaining volvo yet [SEP]']
[Init] best perm rec loss: 0.6625388860702515 for ['[CLS] glacier remaining ink fine manor loss sa volvo yet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.419 (perp=10.591, rec=0.264, cos=0.037), tot_loss_proj:3.092 [t=0.17s]
prediction: ['[CLS] revolutionary abroad association works into disappeared by becoming vanishing [SEP]']
[ 100/2000] tot_loss=2.154 (perp=10.069, rec=0.131, cos=0.009), tot_loss_proj:2.457 [t=0.17s]
prediction: ['[CLS] witch demon owners went into forest by vanishing vanishing [SEP]']
[ 150/2000] tot_loss=2.055 (perp=9.756, rec=0.098, cos=0.006), tot_loss_proj:2.448 [t=0.17s]
prediction: ['[CLS] witch witch witch went into forest by vanishing vanishing [SEP]']
[ 200/2000] tot_loss=2.076 (perp=9.945, rec=0.082, cos=0.005), tot_loss_proj:2.678 [t=0.17s]
prediction: ['[CLS] witch witch the went into forest by vanishing vanishing [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.766 (perp=8.409, rec=0.078, cos=0.006), tot_loss_proj:2.271 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing vanishing [SEP]']
[ 300/2000] tot_loss=1.769 (perp=8.409, rec=0.083, cos=0.005), tot_loss_proj:2.303 [t=0.21s]
prediction: ['[CLS] witch the witch went into forest by vanishing vanishing [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.760 (perp=8.409, rec=0.073, cos=0.004), tot_loss_proj:2.311 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing vanishing [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.762 (perp=8.409, rec=0.076, cos=0.004), tot_loss_proj:2.297 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing vanishing [SEP]']
[ 450/2000] tot_loss=1.754 (perp=8.409, rec=0.068, cos=0.004), tot_loss_proj:2.304 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing vanishing [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.758 (perp=8.409, rec=0.072, cos=0.004), tot_loss_proj:2.299 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing vanishing [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.745 (perp=8.409, rec=0.059, cos=0.004), tot_loss_proj:2.299 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing vanishing [SEP]']
[ 600/2000] tot_loss=1.758 (perp=8.409, rec=0.071, cos=0.004), tot_loss_proj:2.300 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing vanishing [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.443 (perp=6.805, rec=0.078, cos=0.004), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.432 (perp=6.805, rec=0.067, cos=0.003), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[ 750/2000] tot_loss=1.443 (perp=6.805, rec=0.079, cos=0.003), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.439 (perp=6.805, rec=0.075, cos=0.003), tot_loss_proj:1.971 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.430 (perp=6.805, rec=0.066, cos=0.003), tot_loss_proj:1.969 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[ 900/2000] tot_loss=1.438 (perp=6.805, rec=0.075, cos=0.003), tot_loss_proj:1.959 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.441 (perp=6.805, rec=0.077, cos=0.003), tot_loss_proj:1.976 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.431 (perp=6.805, rec=0.067, cos=0.003), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1050/2000] tot_loss=1.446 (perp=6.805, rec=0.082, cos=0.003), tot_loss_proj:1.980 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.434 (perp=6.805, rec=0.070, cos=0.003), tot_loss_proj:1.969 [t=0.20s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.442 (perp=6.805, rec=0.078, cos=0.003), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1200/2000] tot_loss=1.441 (perp=6.805, rec=0.077, cos=0.003), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.419 (perp=6.805, rec=0.056, cos=0.003), tot_loss_proj:1.977 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.439 (perp=6.805, rec=0.075, cos=0.003), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1350/2000] tot_loss=1.425 (perp=6.805, rec=0.062, cos=0.003), tot_loss_proj:1.975 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.424 (perp=6.805, rec=0.060, cos=0.003), tot_loss_proj:1.980 [t=0.18s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.434 (perp=6.805, rec=0.071, cos=0.003), tot_loss_proj:1.971 [t=0.19s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1500/2000] tot_loss=1.429 (perp=6.805, rec=0.066, cos=0.003), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.432 (perp=6.805, rec=0.069, cos=0.003), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.441 (perp=6.805, rec=0.078, cos=0.003), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1650/2000] tot_loss=1.438 (perp=6.805, rec=0.075, cos=0.003), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.437 (perp=6.805, rec=0.073, cos=0.003), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.440 (perp=6.805, rec=0.077, cos=0.003), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1800/2000] tot_loss=1.440 (perp=6.805, rec=0.077, cos=0.003), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.435 (perp=6.805, rec=0.071, cos=0.003), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.437 (perp=6.805, rec=0.073, cos=0.003), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
[1950/2000] tot_loss=1.440 (perp=6.805, rec=0.077, cos=0.003), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.438 (perp=6.805, rec=0.074, cos=0.003), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] witch the witch went into forest by vanishing. [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] the witch went into the forest by vanishing. [SEP]
========================
predicted: 
========================
[CLS] witch the witch went into forest by vanishing. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 90.000 | p: 90.000 | r: 90.000
rougeLsum  | fm: 90.000 | p: 90.000 | r: 90.000
r1fm+r2fm = 156.667

[Aggregate metrics]:
rouge1     | fm: 82.988 | p: 83.198 | r: 83.124
rouge2     | fm: 34.521 | p: 34.506 | r: 34.665
rougeL     | fm: 66.386 | p: 66.514 | r: 66.502
rougeLsum  | fm: 66.654 | p: 66.774 | r: 66.807
r1fm+r2fm = 117.509

input #46 time: 0:07:09 | total time: 5:40:12


Running input #47 of 100.
reference: 
========================
Mary noticed John's excessive appreciation of himself.
========================
average of cosine similarity 0.9992399581895643
highest_index [0]
highest [0.9992399581895643]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2984,  4384,  2198,  1005,  1055, 11664, 12284,  1997,  2370,
          1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] mary noticed john's excessive appreciation of himself. [SEP]"]
[Init] best rec loss: 0.9377633929252625 for ['[CLS] negotiationsris deemedtment prohibition wine holdingyn divorced within [SEP]']
[Init] best rec loss: 0.9331151247024536 for ['[CLS] apart nearly twinotho point onceient overcome beck hong [SEP]']
[Init] best rec loss: 0.924275815486908 for ['[CLS] less pain enters silk mktiv doesn thighs replde [SEP]']
[Init] best rec loss: 0.8977593183517456 for ['[CLS] accompanying moss advent visitedsit corbin pas grade convictedbacks [SEP]']
[Init] best rec loss: 0.8822109699249268 for ['[CLS] december hit leisure journey none sinclair ras chaos whereby burke [SEP]']
[Init] best rec loss: 0.8803945779800415 for ['[CLS]care di sarperson zach original participantsllis " direct [SEP]']
[Init] best rec loss: 0.8778656721115112 for ['[CLS] po 2006 contention sort nameorestation were say dressed caps [SEP]']
[Init] best rec loss: 0.8622311353683472 for ['[CLS] general letting springs engineer large especially together cost tracing framework [SEP]']
[Init] best perm rec loss: 0.856625497341156 for ['[CLS] engineer together letting large general tracing springs framework especially cost [SEP]']
[Init] best perm rec loss: 0.8556800484657288 for ['[CLS] framework together large tracing springs general especially engineer letting cost [SEP]']
[Init] best perm rec loss: 0.8556457161903381 for ['[CLS] tracing large framework cost general together springs especially letting engineer [SEP]']
[Init] best perm rec loss: 0.854211688041687 for ['[CLS] engineer cost framework large general especially together tracing letting springs [SEP]']
[Init] best perm rec loss: 0.8541837334632874 for ['[CLS] engineer springs together especially tracing large general framework cost letting [SEP]']
[Init] best perm rec loss: 0.8541443347930908 for ['[CLS] engineer large tracing springs cost especially letting framework together general [SEP]']
[Init] best perm rec loss: 0.850818932056427 for ['[CLS] springs cost tracing together large especially engineer letting general framework [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.965 (perp=12.009, rec=0.567, cos=0.996), tot_loss_proj:4.287 [t=0.17s]
prediction: ['[CLS]. versus entry down added communion thighs noticed how imprint [SEP]']
[ 100/2000] tot_loss=3.986 (perp=12.569, rec=0.477, cos=0.995), tot_loss_proj:4.361 [t=0.17s]
prediction: ['[CLS] ; harper introducing including consulting excessivefurt noticed ( juice [SEP]']
[ 150/2000] tot_loss=3.895 (perp=12.211, rec=0.459, cos=0.994), tot_loss_proj:4.397 [t=0.17s]
prediction: ['[CLS] unclekill soda includingcher excessive appreciation noticed excessive appreciation [SEP]']
[ 200/2000] tot_loss=3.825 (perp=12.036, rec=0.421, cos=0.996), tot_loss_proj:4.348 [t=0.17s]
prediction: ['[CLS] mary john vowel hardcoreptive excessive appreciation noticed excessive appreciation [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.783 (perp=11.891, rec=0.409, cos=0.996), tot_loss_proj:4.309 [t=0.17s]
prediction: ['[CLS] mary ( vowel hardcoreptive excessive appreciation noticed excessive appreciation [SEP]']
[ 300/2000] tot_loss=3.860 (perp=12.366, rec=0.392, cos=0.995), tot_loss_proj:4.425 [t=0.17s]
prediction: ['[CLS] mary noticedriety াptive excessive appreciation noticed excessive appreciation [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.806 (perp=11.765, rec=0.461, cos=0.992), tot_loss_proj:4.184 [t=0.18s]
prediction: ['[CLS] mary subtle appeals caused ultra excessive appreciation noticed excessive owed [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.966 (perp=12.681, rec=0.438, cos=0.992), tot_loss_proj:4.458 [t=0.18s]
prediction: ['[CLS] mary initial ideas ultra excessive appreciation appeals noticed excessive retirement [SEP]']
[ 450/2000] tot_loss=3.869 (perp=12.408, rec=0.397, cos=0.991), tot_loss_proj:4.369 [t=0.18s]
prediction: ['[CLS] mary receives stuffed westfield excessive appreciationriety noticed excessive appreciation [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.540 (perp=10.810, rec=0.390, cos=0.988), tot_loss_proj:4.084 [t=0.18s]
prediction: ['[CLS] maryriety contempt of excessive appreciation subtle noticed excessive appreciation [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.682 (perp=11.568, rec=0.380, cos=0.989), tot_loss_proj:4.278 [t=0.18s]
prediction: ['[CLS] mary contempt of appeal excessive appreciation subtle noticed excessive appreciation [SEP]']
[ 600/2000] tot_loss=3.545 (perp=10.912, rec=0.372, cos=0.990), tot_loss_proj:4.123 [t=0.18s]
prediction: ['[CLS] mary contempt of exit excessive appreciation subtle noticed excessive appreciation [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.690 (perp=11.651, rec=0.369, cos=0.991), tot_loss_proj:4.117 [t=0.18s]
prediction: ['[CLS] mary covering myspace of excessive appreciation receives noticed excessive without [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=3.617 (perp=11.344, rec=0.357, cos=0.991), tot_loss_proj:4.092 [t=0.18s]
prediction: ['[CLS] mary myspace opinion of excessive appreciation receives noticed excessive without [SEP]']
[ 750/2000] tot_loss=3.673 (perp=11.672, rec=0.346, cos=0.992), tot_loss_proj:4.119 [t=0.17s]
prediction: ['[CLS] mary myspace causing of excessive appreciation subtle noticed excessive without [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.785 (perp=12.239, rec=0.344, cos=0.993), tot_loss_proj:4.300 [t=0.18s]
prediction: ['[CLS] mary exit coming forces excessive appreciation subtle noticed without excessive [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.689 (perp=11.752, rec=0.347, cos=0.992), tot_loss_proj:4.256 [t=0.18s]
prediction: ['[CLS] mary keeps coming forces excessive appreciation subtle noticed without excessive [SEP]']
[ 900/2000] tot_loss=3.786 (perp=12.305, rec=0.333, cos=0.992), tot_loss_proj:4.327 [t=0.18s]
prediction: ['[CLS] mary keeps coming forces excessive acknowledge subtle noticed without excessive [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.674 (perp=11.722, rec=0.338, cos=0.992), tot_loss_proj:4.200 [t=0.18s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge butterflies noticed disturb excessive [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=3.976 (perp=13.163, rec=0.351, cos=0.992), tot_loss_proj:4.430 [t=0.20s]
prediction: ['[CLS] mary nasal coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
[1050/2000] tot_loss=3.522 (perp=10.980, rec=0.334, cos=0.992), tot_loss_proj:4.142 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
Attempt swap
[1100/2000] tot_loss=3.512 (perp=10.980, rec=0.323, cos=0.992), tot_loss_proj:4.147 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
Attempt swap
[1150/2000] tot_loss=3.521 (perp=10.980, rec=0.332, cos=0.992), tot_loss_proj:4.150 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
[1200/2000] tot_loss=3.518 (perp=10.980, rec=0.329, cos=0.993), tot_loss_proj:4.142 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
Attempt swap
[1250/2000] tot_loss=3.513 (perp=10.980, rec=0.324, cos=0.993), tot_loss_proj:4.145 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
Attempt swap
[1300/2000] tot_loss=3.525 (perp=10.980, rec=0.336, cos=0.993), tot_loss_proj:4.151 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
[1350/2000] tot_loss=3.514 (perp=10.980, rec=0.325, cos=0.993), tot_loss_proj:4.149 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
Attempt swap
[1400/2000] tot_loss=3.513 (perp=10.980, rec=0.324, cos=0.993), tot_loss_proj:4.149 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
Attempt swap
[1450/2000] tot_loss=3.514 (perp=10.980, rec=0.324, cos=0.993), tot_loss_proj:4.146 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
[1500/2000] tot_loss=3.519 (perp=10.980, rec=0.329, cos=0.993), tot_loss_proj:4.143 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
Attempt swap
[1550/2000] tot_loss=3.515 (perp=10.980, rec=0.326, cos=0.993), tot_loss_proj:4.147 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
Attempt swap
[1600/2000] tot_loss=3.510 (perp=10.980, rec=0.321, cos=0.993), tot_loss_proj:4.148 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
[1650/2000] tot_loss=3.505 (perp=10.980, rec=0.315, cos=0.994), tot_loss_proj:4.147 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes disturb excessive [SEP]']
Attempt swap
[1700/2000] tot_loss=3.600 (perp=11.439, rec=0.319, cos=0.994), tot_loss_proj:4.216 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes decades excessive [SEP]']
Attempt swap
[1750/2000] tot_loss=3.612 (perp=11.439, rec=0.331, cos=0.994), tot_loss_proj:4.213 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes decades excessive [SEP]']
[1800/2000] tot_loss=3.604 (perp=11.439, rec=0.323, cos=0.994), tot_loss_proj:4.216 [t=0.17s]
prediction: ['[CLS] mary keeps coming without excessive acknowledge noticed eyes decades excessive [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=3.678 (perp=11.697, rec=0.345, cos=0.993), tot_loss_proj:4.197 [t=0.17s]
prediction: ['[CLS] maryplane without excessive appreciation noticed eyes coming decades excessive [SEP]']
Attempt swap
[1900/2000] tot_loss=3.671 (perp=11.697, rec=0.339, cos=0.993), tot_loss_proj:4.199 [t=0.17s]
prediction: ['[CLS] maryplane without excessive appreciation noticed eyes coming decades excessive [SEP]']
[1950/2000] tot_loss=3.840 (perp=12.584, rec=0.330, cos=0.993), tot_loss_proj:4.312 [t=0.17s]
prediction: ['[CLS] maryplane without excessive acknowledge noticed eyes coming disturb excessive [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=3.623 (perp=11.447, rec=0.343, cos=0.990), tot_loss_proj:4.093 [t=0.17s]
prediction: ['[CLS] mary acknowledgeplane without excessive noticed eyes coming disturb excessive [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] mary noticed john's excessive appreciation of himself. [SEP]
========================
predicted: 
========================
[CLS] mary keeps coming without excessive acknowledge noticed eyes decades excessive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 45.455 | p: 41.667 | r: 50.000
rouge2     | fm: 10.000 | p: 9.091 | r: 11.111
rougeL     | fm: 45.455 | p: 41.667 | r: 50.000
rougeLsum  | fm: 45.455 | p: 41.667 | r: 50.000
r1fm+r2fm = 55.455

[Aggregate metrics]:
rouge1     | fm: 82.198 | p: 82.283 | r: 82.405
rouge2     | fm: 33.950 | p: 33.926 | r: 34.173
rougeL     | fm: 66.091 | p: 66.101 | r: 66.230
rougeLsum  | fm: 66.154 | p: 66.142 | r: 66.361
r1fm+r2fm = 116.148

input #47 time: 0:07:24 | total time: 5:47:36


Running input #48 of 100.
reference: 
========================
John tagged Lewis with a regulation baseball on Tuesday.
========================
average of cosine similarity 0.9992913220295516
highest_index [0]
highest [0.9992913220295516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198, 26610,  4572,  2007,  1037,  7816,  3598,  2006,  9857,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]']
[Init] best rec loss: 1.0071521997451782 for ['[CLS]... spit opening tolerant lie officer 3rd wiener true li [SEP]']
[Init] best rec loss: 0.9635554552078247 for ['[CLS] stunt exclusively since bear toss temple calings whispers claimed [SEP]']
[Init] best rec loss: 0.9312321543693542 for ['[CLS]tative fc matched thorough kay responsible backward pali vera its [SEP]']
[Init] best rec loss: 0.9218538403511047 for ['[CLS] pride grams base telling ramstters shame olive stonerah [SEP]']
[Init] best rec loss: 0.9126393795013428 for ['[CLS] fine screened reference [SEP] industry brick liver fleetwr south [SEP]']
[Init] best perm rec loss: 0.9066827297210693 for ['[CLS]wr screened south fleet brick liver fine reference industry [SEP] [SEP]']
[Init] best perm rec loss: 0.9059775471687317 for ['[CLS] liver south fleet [SEP] fine brick reference screened industrywr [SEP]']
[Init] best perm rec loss: 0.9045016765594482 for ['[CLS] fine fleet [SEP] industry screened brick reference liver southwr [SEP]']
[Init] best perm rec loss: 0.903518557548523 for ['[CLS] screened industry south reference fine liver fleet [SEP]wr brick [SEP]']
[Init] best perm rec loss: 0.9033243656158447 for ['[CLS] south reference [SEP] fleet fine brick industry screened liverwr [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.934 (perp=12.086, rec=0.429, cos=0.088), tot_loss_proj:4.363 [t=0.17s]
prediction: ['[CLS] honeyearing hard. carlson delivered just in cisco real [SEP]']
[ 100/2000] tot_loss=2.560 (perp=10.907, rec=0.346, cos=0.033), tot_loss_proj:4.118 [t=0.17s]
prediction: ['[CLS], observations for [SEP] baseball tuesday delivery caught lewis freeman [SEP]']
[ 150/2000] tot_loss=2.538 (perp=11.162, rec=0.290, cos=0.016), tot_loss_proj:4.171 [t=0.17s]
prediction: ['[CLS], saturday [SEP]. baseball tuesday baseball tagged lewisense [SEP]']
[ 200/2000] tot_loss=2.500 (perp=11.159, rec=0.252, cos=0.017), tot_loss_proj:4.218 [t=0.17s]
prediction: ['[CLS]. saturday with. baseball tuesday baseball tagged lewis baseball [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.217 (perp=9.728, rec=0.252, cos=0.019), tot_loss_proj:3.902 [t=0.17s]
prediction: ['[CLS]. saturday with baseball tagged lewis. baseball tuesday baseball [SEP]']
[ 300/2000] tot_loss=2.114 (perp=9.524, rec=0.202, cos=0.008), tot_loss_proj:3.863 [t=0.17s]
prediction: ['[CLS]. regulation with baseball tagged lewis on baseball tuesday baseball [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.297 (perp=10.180, rec=0.246, cos=0.015), tot_loss_proj:3.920 [t=0.17s]
prediction: ['[CLS] professional with baseball tagged lewis shooter baseball tuesday baseball. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.958 (perp=8.718, rec=0.206, cos=0.009), tot_loss_proj:3.703 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with on baseball tuesday baseball. [SEP]']
[ 450/2000] tot_loss=1.927 (perp=8.718, rec=0.177, cos=0.007), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with on baseball tuesday baseball. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.677 (perp=7.542, rec=0.162, cos=0.006), tot_loss_proj:3.393 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.664 (perp=7.542, rec=0.151, cos=0.005), tot_loss_proj:3.401 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
[ 600/2000] tot_loss=1.678 (perp=7.542, rec=0.158, cos=0.012), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.651 (perp=7.542, rec=0.138, cos=0.004), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.652 (perp=7.542, rec=0.140, cos=0.004), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
[ 750/2000] tot_loss=1.637 (perp=7.542, rec=0.124, cos=0.005), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.629 (perp=7.542, rec=0.117, cos=0.004), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.636 (perp=7.542, rec=0.123, cos=0.005), tot_loss_proj:3.395 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
[ 900/2000] tot_loss=1.645 (perp=7.542, rec=0.133, cos=0.004), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.627 (perp=7.542, rec=0.115, cos=0.004), tot_loss_proj:3.394 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.626 (perp=7.542, rec=0.113, cos=0.004), tot_loss_proj:3.400 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
[1050/2000] tot_loss=1.627 (perp=7.542, rec=0.115, cos=0.004), tot_loss_proj:3.401 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.621 (perp=7.542, rec=0.110, cos=0.004), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.634 (perp=7.542, rec=0.122, cos=0.004), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
[1200/2000] tot_loss=1.619 (perp=7.542, rec=0.107, cos=0.004), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.613 (perp=7.542, rec=0.102, cos=0.004), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.622 (perp=7.542, rec=0.111, cos=0.003), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
[1350/2000] tot_loss=1.605 (perp=7.542, rec=0.093, cos=0.003), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.632 (perp=7.542, rec=0.120, cos=0.003), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.621 (perp=7.542, rec=0.110, cos=0.003), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
[1500/2000] tot_loss=1.611 (perp=7.542, rec=0.099, cos=0.003), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.626 (perp=7.542, rec=0.115, cos=0.003), tot_loss_proj:3.400 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.614 (perp=7.542, rec=0.103, cos=0.003), tot_loss_proj:3.404 [t=0.18s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
[1650/2000] tot_loss=1.613 (perp=7.542, rec=0.101, cos=0.003), tot_loss_proj:3.394 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.619 (perp=7.542, rec=0.107, cos=0.003), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.606 (perp=7.542, rec=0.095, cos=0.003), tot_loss_proj:3.404 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
[1800/2000] tot_loss=1.623 (perp=7.542, rec=0.111, cos=0.003), tot_loss_proj:3.393 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.605 (perp=7.542, rec=0.094, cos=0.003), tot_loss_proj:3.402 [t=0.18s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.618 (perp=7.542, rec=0.106, cos=0.003), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
[1950/2000] tot_loss=1.623 (perp=7.542, rec=0.111, cos=0.003), tot_loss_proj:3.400 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.608 (perp=7.542, rec=0.096, cos=0.003), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]
========================
predicted: 
========================
[CLS] regulation baseball tagged lewis with baseball on tuesday baseball. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 131.818

[Aggregate metrics]:
rouge1     | fm: 82.193 | p: 82.267 | r: 82.406
rouge2     | fm: 34.243 | p: 34.280 | r: 34.431
rougeL     | fm: 66.129 | p: 66.112 | r: 66.268
rougeLsum  | fm: 66.295 | p: 66.356 | r: 66.551
r1fm+r2fm = 116.437

input #48 time: 0:07:18 | total time: 5:54:55


Running input #49 of 100.
reference: 
========================
We all thought him to be unhappy
========================
average of cosine similarity 0.9993920717359353
highest_index [0]
highest [0.9993920717359353]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2057,  2035,  2245,  2032,  2000,  2022, 12511,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] we all thought him to be unhappy [SEP]']
[Init] best rec loss: 0.9411858320236206 for ['[CLS] mattermei visibly port brandenburgmissive le [SEP]']
[Init] best rec loss: 0.9296923875808716 for ['[CLS] smoke starary pmid feather consider line [SEP]']
[Init] best rec loss: 0.9013326168060303 for ['[CLS] studies brig numbered logan tour percent rex [SEP]']
[Init] best rec loss: 0.8935877680778503 for ['[CLS]vy threatened fragments straight long piper sign [SEP]']
[Init] best rec loss: 0.8891277313232422 for ['[CLS] cominglett than carrier holiday exposed long [SEP]']
[Init] best rec loss: 0.8783950805664062 for ['[CLS] added guinea gretchen nine cast patent closed [SEP]']
[Init] best rec loss: 0.8762047290802002 for ['[CLS] steppedine band yeshiva / mansion investment [SEP]']
[Init] best rec loss: 0.8750602602958679 for ['[CLS] turf rib hutually driven celine richards [SEP]']
[Init] best rec loss: 0.8677970170974731 for ['[CLS] kennedy drive hold ro steering sindhuising [SEP]']
[Init] best rec loss: 0.8665210604667664 for ['[CLS] rolandylus que phelps books haste yourselves [SEP]']
[Init] best perm rec loss: 0.8652602434158325 for ['[CLS] rolandylus books que phelps yourselves haste [SEP]']
[Init] best perm rec loss: 0.8644270896911621 for ['[CLS]ylus phelps que yourselves haste roland books [SEP]']
[Init] best perm rec loss: 0.8641104102134705 for ['[CLS] yourselves phelpsylus roland que books haste [SEP]']
[Init] best perm rec loss: 0.8639255166053772 for ['[CLS] yourselves roland books haste queylus phelps [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.437 (perp=9.203, rec=0.454, cos=0.142), tot_loss_proj:3.771 [t=0.17s]
prediction: ["[CLS] wrote'is! that honorary ball [SEP]"]
[ 100/2000] tot_loss=2.800 (perp=11.747, rec=0.386, cos=0.065), tot_loss_proj:4.220 [t=0.17s]
prediction: ['[CLS] whose was always think £1 hisign [SEP]']
[ 150/2000] tot_loss=2.414 (perp=10.181, rec=0.331, cos=0.047), tot_loss_proj:3.942 [t=0.17s]
prediction: ['[CLS] unhappy is him thought therefore his him [SEP]']
[ 200/2000] tot_loss=2.729 (perp=10.326, rec=0.487, cos=0.176), tot_loss_proj:4.012 [t=0.17s]
prediction: ['[CLS] martin all always thought terribly [ unhappy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.153 (perp=9.020, rec=0.315, cos=0.033), tot_loss_proj:3.691 [t=0.17s]
prediction: ['[CLS] [ we all thought fur martin unhappy [SEP]']
[ 300/2000] tot_loss=2.039 (perp=8.970, rec=0.230, cos=0.015), tot_loss_proj:3.771 [t=0.17s]
prediction: ['[CLS] he we all thought₁ him unhappy [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.939 (perp=8.831, rec=0.165, cos=0.008), tot_loss_proj:3.628 [t=0.17s]
prediction: ['[CLS] to we all thought him₁ unhappy [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.914 (perp=7.789, rec=0.310, cos=0.046), tot_loss_proj:3.443 [t=0.17s]
prediction: ['[CLS] he₃ we all thought him unhappy [SEP]']
[ 450/2000] tot_loss=1.667 (perp=7.166, rec=0.217, cos=0.016), tot_loss_proj:3.426 [t=0.17s]
prediction: ['[CLS] he think we all thought him unhappy [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.645 (perp=7.211, rec=0.192, cos=0.011), tot_loss_proj:3.348 [t=0.17s]
prediction: ['[CLS] we think him all thought him unhappy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.621 (perp=7.211, rec=0.170, cos=0.009), tot_loss_proj:3.340 [t=0.17s]
prediction: ['[CLS] we think him all thought him unhappy [SEP]']
[ 600/2000] tot_loss=1.606 (perp=7.211, rec=0.156, cos=0.008), tot_loss_proj:3.346 [t=0.17s]
prediction: ['[CLS] we think him all thought him unhappy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.594 (perp=7.211, rec=0.145, cos=0.007), tot_loss_proj:3.344 [t=0.17s]
prediction: ['[CLS] we think him all thought him unhappy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.589 (perp=7.211, rec=0.141, cos=0.006), tot_loss_proj:3.345 [t=0.17s]
prediction: ['[CLS] we think him all thought him unhappy [SEP]']
[ 750/2000] tot_loss=1.573 (perp=7.211, rec=0.126, cos=0.005), tot_loss_proj:3.344 [t=0.17s]
prediction: ['[CLS] we think him all thought him unhappy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.634 (perp=7.557, rec=0.118, cos=0.005), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] we think to all thought him unhappy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.626 (perp=7.557, rec=0.111, cos=0.004), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] we think to all thought him unhappy [SEP]']
[ 900/2000] tot_loss=1.620 (perp=7.557, rec=0.105, cos=0.003), tot_loss_proj:3.508 [t=0.17s]
prediction: ['[CLS] we think to all thought him unhappy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.604 (perp=7.557, rec=0.089, cos=0.003), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] we think to all thought him unhappy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.616 (perp=7.557, rec=0.101, cos=0.003), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] we think to all thought him unhappy [SEP]']
[1050/2000] tot_loss=1.774 (perp=8.355, rec=0.100, cos=0.003), tot_loss_proj:3.593 [t=0.17s]
prediction: ['[CLS] we be to all thought him unhappy [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.651 (perp=7.767, rec=0.095, cos=0.003), tot_loss_proj:3.439 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.654 (perp=7.767, rec=0.098, cos=0.003), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
[1200/2000] tot_loss=1.656 (perp=7.767, rec=0.100, cos=0.003), tot_loss_proj:3.434 [t=0.18s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.651 (perp=7.767, rec=0.095, cos=0.003), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.653 (perp=7.767, rec=0.097, cos=0.003), tot_loss_proj:3.438 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
[1350/2000] tot_loss=1.641 (perp=7.767, rec=0.085, cos=0.003), tot_loss_proj:3.435 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.637 (perp=7.767, rec=0.081, cos=0.003), tot_loss_proj:3.439 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.646 (perp=7.767, rec=0.091, cos=0.003), tot_loss_proj:3.434 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
[1500/2000] tot_loss=1.640 (perp=7.767, rec=0.085, cos=0.003), tot_loss_proj:3.435 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.647 (perp=7.767, rec=0.091, cos=0.003), tot_loss_proj:3.435 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.646 (perp=7.767, rec=0.090, cos=0.003), tot_loss_proj:3.435 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
[1650/2000] tot_loss=1.643 (perp=7.767, rec=0.087, cos=0.003), tot_loss_proj:3.435 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.638 (perp=7.767, rec=0.082, cos=0.003), tot_loss_proj:3.439 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.640 (perp=7.767, rec=0.084, cos=0.003), tot_loss_proj:3.438 [t=0.18s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
[1800/2000] tot_loss=1.642 (perp=7.767, rec=0.086, cos=0.003), tot_loss_proj:3.438 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.644 (perp=7.767, rec=0.089, cos=0.003), tot_loss_proj:3.437 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.652 (perp=7.767, rec=0.096, cos=0.003), tot_loss_proj:3.437 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
[1950/2000] tot_loss=1.645 (perp=7.767, rec=0.089, cos=0.003), tot_loss_proj:3.438 [t=0.18s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.639 (perp=7.767, rec=0.083, cos=0.003), tot_loss_proj:3.438 [t=0.17s]
prediction: ['[CLS] we be all thought to him unhappy [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] we all thought him to be unhappy [SEP]
========================
predicted: 
========================
[CLS] we be all thought to him unhappy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 82.570 | p: 82.636 | r: 82.788
rouge2     | fm: 34.516 | p: 34.499 | r: 34.524
rougeL     | fm: 66.412 | p: 66.351 | r: 66.614
rougeLsum  | fm: 66.524 | p: 66.590 | r: 66.699
r1fm+r2fm = 117.086

input #49 time: 0:07:16 | total time: 6:02:11


Running input #50 of 100.
reference: 
========================
Book is available in most countries.
========================
average of cosine similarity 0.999341484458915
highest_index [0]
highest [0.999341484458915]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2338, 2003, 2800, 1999, 2087, 3032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] book is available in most countries. [SEP]']
[Init] best rec loss: 0.7874211072921753 for ['[CLS] keyxy neither jenksuka chow administration [SEP]']
[Init] best rec loss: 0.7831349968910217 for ['[CLS] rev vaughn debut inspiration theme mind wonder [SEP]']
[Init] best rec loss: 0.7579970955848694 for ['[CLS] tapes [SEP] stronger u part radio tropical [SEP]']
[Init] best rec loss: 0.7362892627716064 for ['[CLS]ers quality thereafter small conversations gaius sven [SEP]']
[Init] best rec loss: 0.7306573987007141 for ['[CLS] po gustav room governors roger underpathic [SEP]']
[Init] best rec loss: 0.730445146560669 for ['[CLS]ping casualties election creditsiestitiafactory [SEP]']
[Init] best rec loss: 0.7263517379760742 for ['[CLS] reconnaissancefieldsffen switzerland humor spells scenario [SEP]']
[Init] best perm rec loss: 0.7249794006347656 for ['[CLS]ffen scenario spells switzerland humorfields reconnaissance [SEP]']
[Init] best perm rec loss: 0.7248560786247253 for ['[CLS] switzerlandffenfields reconnaissance humor scenario spells [SEP]']
[Init] best perm rec loss: 0.7243238091468811 for ['[CLS] switzerlandffen reconnaissance scenariofields humor spells [SEP]']
[Init] best perm rec loss: 0.7224777936935425 for ['[CLS] switzerland scenariofields humor reconnaissance spellsffen [SEP]']
[Init] best perm rec loss: 0.7222394943237305 for ['[CLS] spells reconnaissance scenariofieldsffen humor switzerland [SEP]']
[Init] best perm rec loss: 0.7190003991127014 for ['[CLS] scenariofieldsffen switzerland humor spells reconnaissance [SEP]']
[Init] best perm rec loss: 0.7169519662857056 for ['[CLS] switzerlandfields scenarioffen spells reconnaissance humor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.122 (perp=13.727, rec=0.338, cos=0.039), tot_loss_proj:3.805 [t=0.17s]
prediction: ['[CLS] ur makes leather jack library own chart [SEP]']
[ 100/2000] tot_loss=2.766 (perp=12.527, rec=0.242, cos=0.019), tot_loss_proj:3.657 [t=0.17s]
prediction: ['[CLS] entire is countries jack book availability book [SEP]']
[ 150/2000] tot_loss=2.309 (perp=10.521, rec=0.193, cos=0.011), tot_loss_proj:3.113 [t=0.17s]
prediction: ['[CLS] is is countries polish book available book [SEP]']
[ 200/2000] tot_loss=2.485 (perp=11.470, rec=0.179, cos=0.012), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] is countries countries available book available book [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.570 (perp=11.981, rec=0.162, cos=0.012), tot_loss_proj:3.518 [t=0.19s]
prediction: ['[CLS] is countries countries book available book finnish [SEP]']
[ 300/2000] tot_loss=2.525 (perp=11.981, rec=0.122, cos=0.007), tot_loss_proj:3.496 [t=0.23s]
prediction: ['[CLS] is countries countries book available book finnish [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.097 (perp=9.780, rec=0.134, cos=0.008), tot_loss_proj:2.980 [t=0.19s]
prediction: ['[CLS] is countries book finnish countries book available [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.960 (perp=9.145, rec=0.125, cos=0.006), tot_loss_proj:2.870 [t=0.17s]
prediction: ['[CLS] finnish countries book is countries book available [SEP]']
[ 450/2000] tot_loss=2.257 (perp=10.639, rec=0.124, cos=0.005), tot_loss_proj:3.220 [t=0.17s]
prediction: ['[CLS] finnish countries book is most which available [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.203 (perp=10.439, rec=0.110, cos=0.005), tot_loss_proj:3.020 [t=0.17s]
prediction: ['[CLS] book countries book is most finnish available [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.799 (perp=8.443, rec=0.104, cos=0.006), tot_loss_proj:2.761 [t=0.17s]
prediction: ['[CLS] which is most countries countries book available [SEP]']
[ 600/2000] tot_loss=1.789 (perp=8.443, rec=0.096, cos=0.005), tot_loss_proj:2.764 [t=0.17s]
prediction: ['[CLS] which is most countries countries book available [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.689 (perp=7.868, rec=0.110, cos=0.005), tot_loss_proj:2.707 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.672 (perp=7.868, rec=0.094, cos=0.004), tot_loss_proj:2.707 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
[ 750/2000] tot_loss=1.682 (perp=7.868, rec=0.104, cos=0.004), tot_loss_proj:2.710 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.680 (perp=7.868, rec=0.102, cos=0.004), tot_loss_proj:2.711 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.682 (perp=7.868, rec=0.104, cos=0.004), tot_loss_proj:2.711 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
[ 900/2000] tot_loss=1.672 (perp=7.868, rec=0.094, cos=0.004), tot_loss_proj:2.711 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.660 (perp=7.868, rec=0.083, cos=0.004), tot_loss_proj:2.715 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.676 (perp=7.868, rec=0.099, cos=0.004), tot_loss_proj:2.709 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
[1050/2000] tot_loss=1.679 (perp=7.868, rec=0.101, cos=0.004), tot_loss_proj:2.708 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.676 (perp=7.868, rec=0.099, cos=0.004), tot_loss_proj:2.710 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
[1150/2000] tot_loss=1.668 (perp=7.868, rec=0.090, cos=0.004), tot_loss_proj:2.710 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
[1200/2000] tot_loss=1.655 (perp=7.868, rec=0.078, cos=0.004), tot_loss_proj:2.714 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
[1250/2000] tot_loss=1.675 (perp=7.868, rec=0.098, cos=0.004), tot_loss_proj:2.716 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.668 (perp=7.868, rec=0.090, cos=0.004), tot_loss_proj:2.712 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
[1350/2000] tot_loss=1.678 (perp=7.868, rec=0.100, cos=0.004), tot_loss_proj:2.709 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
[1400/2000] tot_loss=1.662 (perp=7.868, rec=0.085, cos=0.004), tot_loss_proj:2.711 [t=0.19s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.673 (perp=7.868, rec=0.096, cos=0.004), tot_loss_proj:2.715 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
[1500/2000] tot_loss=1.652 (perp=7.868, rec=0.075, cos=0.004), tot_loss_proj:2.714 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
[1550/2000] tot_loss=1.678 (perp=7.868, rec=0.101, cos=0.004), tot_loss_proj:2.710 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.671 (perp=7.868, rec=0.094, cos=0.004), tot_loss_proj:2.707 [t=0.19s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
[1650/2000] tot_loss=1.677 (perp=7.868, rec=0.100, cos=0.004), tot_loss_proj:2.707 [t=0.21s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.671 (perp=7.868, rec=0.093, cos=0.004), tot_loss_proj:2.709 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
[1750/2000] tot_loss=1.658 (perp=7.868, rec=0.081, cos=0.004), tot_loss_proj:2.709 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
[1800/2000] tot_loss=1.653 (perp=7.868, rec=0.075, cos=0.004), tot_loss_proj:2.716 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.666 (perp=7.868, rec=0.089, cos=0.004), tot_loss_proj:2.709 [t=0.19s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
[1900/2000] tot_loss=1.650 (perp=7.868, rec=0.073, cos=0.004), tot_loss_proj:2.705 [t=0.19s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
[1950/2000] tot_loss=1.666 (perp=7.868, rec=0.089, cos=0.004), tot_loss_proj:2.702 [t=0.18s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.668 (perp=7.868, rec=0.091, cos=0.004), tot_loss_proj:2.712 [t=0.17s]
prediction: ['[CLS] which most countries countries book is available [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] book is available in most countries. [SEP]
========================
predicted: 
========================
[CLS] which most countries countries book is available [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 40.000 | p: 37.500 | r: 42.857
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 122.353

[Aggregate metrics]:
rouge1     | fm: 82.608 | p: 82.537 | r: 82.829
rouge2     | fm: 34.606 | p: 34.510 | r: 34.824
rougeL     | fm: 66.185 | p: 66.139 | r: 66.457
rougeLsum  | fm: 66.473 | p: 66.379 | r: 66.687
r1fm+r2fm = 117.214

input #50 time: 0:07:38 | total time: 6:09:50


Running input #51 of 100.
reference: 
========================
I could have little known that more trouble was just around the corner.
========================
average of cosine similarity 0.9993932192875968
highest_index [0]
highest [0.9993932192875968]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2071, 2031, 2210, 2124, 2008, 2062, 4390, 2001, 2074, 2105,
         1996, 3420, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i could have little known that more trouble was just around the corner. [SEP]']
[Init] best rec loss: 0.958308219909668 for ['[CLS] missing coincidence ten ideas gas need status singleton silver considered demolished tale convert grumbled [SEP]']
[Init] best rec loss: 0.9319798350334167 for ['[CLS] clshfalls chicago walled steps turn photos tell covers yet letter xx table [SEP]']
[Init] best rec loss: 0.8892698287963867 for ['[CLS] reason strength trains chance dawsonwyl milk diplomatic tie chance parked honey summer associated [SEP]']
[Init] best rec loss: 0.8843215703964233 for ['[CLS]ponecope calm social solemn milesling moodeersi demon position negativeif [SEP]']
[Init] best rec loss: 0.8748561143875122 for ['[CLS] theirform prevented throughoutnight younger ham near should mustizationite split individual [SEP]']
[Init] best rec loss: 0.860314667224884 for ['[CLS] temperatures ruth krishna metre cultural samurai acceleration visual oscar premiere hitter priest jo ps [SEP]']
[Init] best perm rec loss: 0.8551190495491028 for ['[CLS] ps temperatures samurai metre priest cultural premiere jo krishna oscar visual ruth hitter acceleration [SEP]']
[Init] best perm rec loss: 0.8518536686897278 for ['[CLS] temperatures metre krishna premiere cultural ps samurai ruth acceleration jo priest hitter visual oscar [SEP]']
[Init] best perm rec loss: 0.8513066172599792 for ['[CLS] cultural acceleration ruth metre temperatures oscar samurai krishna premiere jo visual ps priest hitter [SEP]']
[Init] best perm rec loss: 0.8505657911300659 for ['[CLS] premiere visual priest krishna oscar samurai metre acceleration temperatures cultural ps jo ruth hitter [SEP]']
[Init] best perm rec loss: 0.8491230607032776 for ['[CLS] oscar samurai priest temperatures hitter visual acceleration ruth premiere krishna jo cultural ps metre [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.751 (perp=11.102, rec=0.550, cos=0.980), tot_loss_proj:4.166 [t=0.17s]
prediction: ['[CLS] particularly : wyatt mr corps, consort. 1974 同 brigade different carrying walkover [SEP]']
[ 100/2000] tot_loss=3.474 (perp=10.761, rec=0.449, cos=0.873), tot_loss_proj:4.042 [t=0.18s]
prediction: ['[CLS] particularly had money gotten. was could. disadvantagefight cafe different carrying specialist [SEP]']
[ 150/2000] tot_loss=3.402 (perp=9.346, rec=0.556, cos=0.977), tot_loss_proj:3.733 [t=0.17s]
prediction: ['[CLS] usually,? family diocese got ) ( isles waters. possible bearing ( [SEP]']
[ 200/2000] tot_loss=3.358 (perp=9.821, rec=0.463, cos=0.931), tot_loss_proj:3.832 [t=0.19s]
prediction: ['[CLS] usually, notice mentioned diocese was already when isles within. impressive bearing was [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.638 (perp=10.186, rec=0.648, cos=0.952), tot_loss_proj:3.960 [t=0.19s]
prediction: ['[CLS] considered the career airing decades seemed controversy. july privateer initially. ( ( [SEP]']
[ 300/2000] tot_loss=3.680 (perp=11.354, rec=0.529, cos=0.880), tot_loss_proj:4.177 [t=0.19s]
prediction: ['[CLS] flooded the career airing decades seemed controversy. july narrow 1980s. 2015 → [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.540 (perp=11.304, rec=0.558, cos=0.721), tot_loss_proj:4.174 [t=0.19s]
prediction: ['[CLS] the suspected career participated decades seemed output. july narrow southern. they → [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.332 (perp=10.304, rec=0.551, cos=0.720), tot_loss_proj:3.983 [t=0.17s]
prediction: ['[CLS] the suspected career division decades seemed privateer, july criticism medley.. → [SEP]']
[ 450/2000] tot_loss=2.863 (perp=11.497, rec=0.445, cos=0.118), tot_loss_proj:4.232 [t=0.17s]
prediction: ['[CLS] the considered career division decades seemed narrow disaster july grammar diplomatic ;. → [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.389 (perp=9.865, rec=0.370, cos=0.046), tot_loss_proj:3.895 [t=0.17s]
prediction: ['[CLS] the considered hand division decades seemed narrow when. → july grammarwi ; [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.237 (perp=9.329, rec=0.339, cos=0.032), tot_loss_proj:3.831 [t=0.17s]
prediction: ['[CLS] hand considered the division decades seemed little trouble. → july grammarwi ; [SEP]']
[ 600/2000] tot_loss=2.459 (perp=10.573, rec=0.318, cos=0.027), tot_loss_proj:3.966 [t=0.17s]
prediction: ['[CLS] career considered the division decades seemed little trouble. was july grammarwi. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.320 (perp=9.965, rec=0.304, cos=0.023), tot_loss_proj:3.832 [t=0.17s]
prediction: ['[CLS] career considered the division decades seemed little trouble. july speculation waswi. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.952 (perp=8.147, rec=0.299, cos=0.023), tot_loss_proj:3.497 [t=0.17s]
prediction: ['[CLS] macmillan considered the division decades seemed little trouble. february speculation was hand. [SEP]']
[ 750/2000] tot_loss=2.230 (perp=9.595, rec=0.292, cos=0.019), tot_loss_proj:3.771 [t=0.17s]
prediction: ['[CLS] macmillan considered the division decades knew little trouble emma february controversy was hand. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.258 (perp=9.793, rec=0.283, cos=0.017), tot_loss_proj:3.815 [t=0.17s]
prediction: ['[CLS] apart considered the division february decades knew trouble trouble emma millie was in. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.147 (perp=9.272, rec=0.277, cos=0.016), tot_loss_proj:3.719 [t=0.19s]
prediction: ['[CLS] decades considered the division february apart knew trouble trouble emma millie was in. [SEP]']
[ 900/2000] tot_loss=2.144 (perp=9.272, rec=0.276, cos=0.014), tot_loss_proj:3.719 [t=0.18s]
prediction: ['[CLS] decades considered the division february apart knew trouble trouble emma millie was in. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.065 (perp=8.930, rec=0.265, cos=0.014), tot_loss_proj:3.673 [t=0.19s]
prediction: ['[CLS] decades in the division february apart knew trouble trouble emma millie was considered. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.010 (perp=8.658, rec=0.263, cos=0.016), tot_loss_proj:3.614 [t=0.19s]
prediction: ['[CLS] decades in trouble the division february apart knew trouble emma millie was considered. [SEP]']
[1050/2000] tot_loss=2.044 (perp=8.854, rec=0.260, cos=0.013), tot_loss_proj:3.691 [t=0.19s]
prediction: ['[CLS] decades in trouble the division february macmillan knew trouble emma millie was considered. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.975 (perp=8.547, rec=0.254, cos=0.012), tot_loss_proj:3.657 [t=0.19s]
prediction: ['[CLS] decades in trouble the february division macmillan knew trouble emma millie was considered. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.967 (perp=8.547, rec=0.246, cos=0.011), tot_loss_proj:3.654 [t=0.18s]
prediction: ['[CLS] decades in trouble the february division macmillan knew trouble emma millie was considered. [SEP]']
[1200/2000] tot_loss=1.962 (perp=8.524, rec=0.246, cos=0.011), tot_loss_proj:3.685 [t=0.18s]
prediction: ['[CLS] decades in trouble the february division macmillan knew trouble featuring millie was considered. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.967 (perp=8.524, rec=0.251, cos=0.010), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS] decades in trouble the february division macmillan knew trouble featuring millie was considered. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.957 (perp=8.524, rec=0.242, cos=0.010), tot_loss_proj:3.687 [t=0.18s]
prediction: ['[CLS] decades in trouble the february division macmillan knew trouble featuring millie was considered. [SEP]']
[1350/2000] tot_loss=2.041 (perp=8.951, rec=0.240, cos=0.010), tot_loss_proj:3.675 [t=0.18s]
prediction: ['[CLS] decades in trouble the february laws macmillan knew trouble mistake could was considered. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.981 (perp=8.678, rec=0.235, cos=0.011), tot_loss_proj:3.641 [t=0.18s]
prediction: ['[CLS] decades in trouble the february laws macmillan knew trouble could featuring was considered. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.063 (perp=9.082, rec=0.237, cos=0.010), tot_loss_proj:3.733 [t=0.18s]
prediction: ['[CLS] decades in trouble the? laws macmillan knew trouble could featuring was considered. [SEP]']
[1500/2000] tot_loss=2.066 (perp=9.082, rec=0.240, cos=0.010), tot_loss_proj:3.737 [t=0.18s]
prediction: ['[CLS] decades in trouble the? laws macmillan knew trouble could featuring was considered. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.898 (perp=8.270, rec=0.234, cos=0.010), tot_loss_proj:3.721 [t=0.18s]
prediction: ['[CLS] decades in trouble? the laws macmillan knew trouble could mistake was considered. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.900 (perp=8.319, rec=0.227, cos=0.009), tot_loss_proj:3.715 [t=0.18s]
prediction: ['[CLS] decades in trouble? the laws macmillan knew trouble could mistake was known. [SEP]']
[1650/2000] tot_loss=1.913 (perp=8.318, rec=0.240, cos=0.009), tot_loss_proj:3.538 [t=0.17s]
prediction: ['[CLS] decades in trouble? the laws corner knew trouble could mistake was known. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.903 (perp=8.318, rec=0.230, cos=0.009), tot_loss_proj:3.538 [t=0.18s]
prediction: ['[CLS] decades in trouble? the laws corner knew trouble could mistake was known. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.882 (perp=8.147, rec=0.239, cos=0.013), tot_loss_proj:3.510 [t=0.17s]
prediction: ['[CLS] decades in trouble? laws corner knew the trouble could bump was known. [SEP]']
[1800/2000] tot_loss=2.063 (perp=9.062, rec=0.240, cos=0.010), tot_loss_proj:3.677 [t=0.17s]
prediction: ['[CLS] decades in trouble? laws corner knew the trouble could bump was known more [SEP]']
Attempt swap
[1850/2000] tot_loss=2.060 (perp=9.062, rec=0.238, cos=0.010), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] decades in trouble? laws corner knew the trouble could bump was known more [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.958 (perp=8.535, rec=0.241, cos=0.010), tot_loss_proj:3.614 [t=0.18s]
prediction: ['[CLS] decades in trouble? laws corner knew the trouble could bump known was more [SEP]']
[1950/2000] tot_loss=1.946 (perp=8.535, rec=0.229, cos=0.010), tot_loss_proj:3.613 [t=0.17s]
prediction: ['[CLS] decades in trouble? laws corner knew the trouble could bump known was more [SEP]']
Attempt swap
[2000/2000] tot_loss=2.022 (perp=8.938, rec=0.225, cos=0.010), tot_loss_proj:3.648 [t=0.18s]
prediction: ['[CLS] had in trouble? laws corner knew the trouble could bump known was more [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] i could have little known that more trouble was just around the corner. [SEP]
========================
predicted: 
========================
[CLS] had in trouble? laws corner knew the trouble could bump known was more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 33.333 | p: 33.333 | r: 33.333
rougeLsum  | fm: 33.333 | p: 33.333 | r: 33.333
r1fm+r2fm = 60.000

[Aggregate metrics]:
rouge1     | fm: 82.056 | p: 82.035 | r: 82.387
rouge2     | fm: 33.743 | p: 33.694 | r: 33.972
rougeL     | fm: 65.627 | p: 65.611 | r: 65.790
rougeLsum  | fm: 65.671 | p: 65.655 | r: 65.953
r1fm+r2fm = 115.799

input #51 time: 0:07:32 | total time: 6:17:22


Running input #52 of 100.
reference: 
========================
John gave the books to Mary at Christmas, and the records to Sue for her birthday.
========================
average of cosine similarity 0.9992993920902845
highest_index [0]
highest [0.9992993920902845]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2198, 2435, 1996, 2808, 2000, 2984, 2012, 4234, 1010, 1998, 1996,
         2636, 2000, 9790, 2005, 2014, 5798, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]']
[Init] best rec loss: 0.9534174799919128 for ['[CLS] drama establishments wicket vocal willem presence arm australia dashed guineaturn hand converse sparrow mastof hueymined [SEP]']
[Init] best rec loss: 0.9517337083816528 for ['[CLS] thorn double opera y learnedmist maxi bow [SEP] hove flowering as gwen rug hiding style gold ku [SEP]']
[Init] best rec loss: 0.9427309036254883 for ['[CLS] miller balancelined crawl net ramsay frost platform moved eachcial report lay reflecting # gray army contributed [SEP]']
[Init] best rec loss: 0.9308578372001648 for ['[CLS] semi disks chartersnesia glasses hearth while farm motto jack from enoughyr chamber "grass already steven [SEP]']
[Init] best rec loss: 0.9264649152755737 for ['[CLS] titled gesture sc isaac musical officers afghanistan mineral squarekra chip inducted leaving who jon journal ethan ruse [SEP]']
[Init] best rec loss: 0.8957587480545044 for ['[CLS] widowed pat age tack collaroresuk : we finally characteristic [MASK] workingneyawa printingigraphy intelligence [SEP]']
[Init] best perm rec loss: 0.8955612182617188 for ['[CLS] printing working [MASK]awa pat characteristic finallyney tackores widowedigraphy ageuk collar : intelligence we [SEP]']
[Init] best perm rec loss: 0.8945481181144714 for ['[CLS] intelligenceney characteristic finallyawa we pat widowed printing tackigraphyores collar [MASK]uk age working : [SEP]']
[Init] best perm rec loss: 0.8907304406166077 for ['[CLS] age printingukoresigraphy finally intelligence we : widowed collar [MASK]neyawa pat working characteristic tack [SEP]']
[Init] best perm rec loss: 0.887945294380188 for ['[CLS] : [MASK] workingney characteristic weoresigraphy pat finallyawa tack age intelligenceuk widowed collar printing [SEP]']
[Init] best perm rec loss: 0.8872994780540466 for ['[CLS] :igraphyney working characteristic finally collar age printing tackores [MASK]awa pat intelligenceuk widowed we [SEP]']
[Init] best perm rec loss: 0.8868954181671143 for ['[CLS] : working weney pat finallyores [MASK] printingukawa intelligence characteristic collar tack age widowedigraphy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.347 (perp=13.754, rec=0.488, cos=0.108), tot_loss_proj:4.691 [t=0.18s]
prediction: ["[CLS] box'world pigeon dull carol harry court inheritance dodge jane room language gestureregion words speech questions [SEP]"]
[ 100/2000] tot_loss=2.799 (perp=12.027, rec=0.357, cos=0.036), tot_loss_proj:4.259 [t=0.18s]
prediction: ['[CLS] while if god cheerful christmas sarahvalent court inheritance sue home house a records to administration lecture sue [SEP]']
[ 150/2000] tot_loss=2.500 (perp=10.842, rec=0.309, cos=0.022), tot_loss_proj:4.081 [t=0.18s]
prediction: ['[CLS]. for named printed christmas maccabi violet court inheritance sue home store the records to mary lecture sue [SEP]']
[ 200/2000] tot_loss=2.393 (perp=10.585, rec=0.263, cos=0.014), tot_loss_proj:4.077 [t=0.18s]
prediction: ['[CLS] christmas for named printed christmas wooden violet court inheritance sue home records the records to mary records sue [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.563 (perp=10.417, rec=0.390, cos=0.090), tot_loss_proj:4.032 [t=0.18s]
prediction: ['[CLS] professor if poll printed books the pinkmanpher sue mother palace the so to sue mary books [SEP]']
[ 300/2000] tot_loss=2.191 (perp=9.421, rec=0.288, cos=0.018), tot_loss_proj:3.791 [t=0.18s]
prediction: ['[CLS] john, poll books books the maryman blog sue mother records angus so to sue mary books [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.825 (perp=7.808, rec=0.252, cos=0.011), tot_loss_proj:3.490 [t=0.18s]
prediction: ['[CLS] john. mary books books the morningman, sue mother records for and to sue gave books [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.019 (perp=8.891, rec=0.233, cos=0.008), tot_loss_proj:3.673 [t=0.18s]
prediction: ['[CLS] john as mary books ; the christmas o, sue culture records for and to sue gave books [SEP]']
[ 450/2000] tot_loss=1.986 (perp=8.891, rec=0.201, cos=0.007), tot_loss_proj:3.676 [t=0.18s]
prediction: ['[CLS] john as mary books ; the christmas o, sue culture records for and to sue gave books [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.758 (perp=7.810, rec=0.189, cos=0.007), tot_loss_proj:3.488 [t=0.18s]
prediction: ['[CLS] john as mary books ; the christmas o, and christmas records for sue to sue gave books [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.442 (perp=10.369, rec=0.317, cos=0.051), tot_loss_proj:3.879 [t=0.18s]
prediction: ['[CLS] john gave mary books summer the christmas ovan giftux records birthday sue to sue for books [SEP]']
[ 600/2000] tot_loss=2.297 (perp=10.144, rec=0.247, cos=0.022), tot_loss_proj:3.888 [t=0.18s]
prediction: ['[CLS] john gave mary books summer the christmas ovan gaveux records birthday sue to sue for books [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.086 (perp=9.185, rec=0.233, cos=0.017), tot_loss_proj:3.744 [t=0.18s]
prediction: ['[CLS] john gave mary the christmas o write gaveux books for records birthday sue to sue for books [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.954 (perp=8.657, rec=0.209, cos=0.013), tot_loss_proj:3.648 [t=0.18s]
prediction: ['[CLS] john gave mary the christmas o write gaveux books for records for sue to sue birthday books [SEP]']
[ 750/2000] tot_loss=1.939 (perp=8.657, rec=0.196, cos=0.011), tot_loss_proj:3.652 [t=0.18s]
prediction: ['[CLS] john gave mary the christmas o write gaveux books for records for sue to sue birthday books [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.849 (perp=8.189, rec=0.201, cos=0.010), tot_loss_proj:3.594 [t=0.18s]
prediction: ['[CLS] john gave mary the christmas o writeux books for records for sue gave to sue birthday books [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.817 (perp=8.062, rec=0.195, cos=0.010), tot_loss_proj:3.568 [t=0.18s]
prediction: ['[CLS] john gave mary the christmas books o writeux for records for sue gave to sue birthday books [SEP]']
[ 900/2000] tot_loss=1.800 (perp=8.062, rec=0.178, cos=0.009), tot_loss_proj:3.569 [t=0.18s]
prediction: ['[CLS] john gave mary the christmas books o writeux for records for sue gave to sue birthday books [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.784 (perp=7.923, rec=0.191, cos=0.009), tot_loss_proj:3.542 [t=0.18s]
prediction: ['[CLS] john gave mary the christmas books o writeux, records for sue gave to sue birthday books [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.765 (perp=7.875, rec=0.181, cos=0.009), tot_loss_proj:3.519 [t=0.18s]
prediction: ['[CLS] john gave mary the christmas books, o writeux records for sue gave to sue birthday books [SEP]']
[1050/2000] tot_loss=1.809 (perp=8.102, rec=0.181, cos=0.008), tot_loss_proj:3.574 [t=0.20s]
prediction: ['[CLS] john gave mary the christmas books for o writeux records for sue gave to sue birthday books [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.873 (perp=8.456, rec=0.173, cos=0.008), tot_loss_proj:3.528 [t=0.18s]
prediction: ['[CLS] john gave, the christmas. mary o writeux records for sue gave to sue birthday books [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.036 (perp=9.255, rec=0.177, cos=0.008), tot_loss_proj:3.820 [t=0.18s]
prediction: ['[CLS] john gavevan, the christmas books mary oux records for sue gave to sue birthday books [SEP]']
[1200/2000] tot_loss=1.954 (perp=8.861, rec=0.174, cos=0.008), tot_loss_proj:3.631 [t=0.18s]
prediction: ['[CLS] john gavevan, the christmas. mary!ux records for sue gave to sue birthday books [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.828 (perp=8.220, rec=0.176, cos=0.008), tot_loss_proj:3.567 [t=0.18s]
prediction: ['[CLS] john gavevan, the christmas mary.ux. records for sue gave to sue birthday books [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.816 (perp=8.218, rec=0.164, cos=0.008), tot_loss_proj:3.545 [t=0.18s]
prediction: ['[CLS] john gavevan, the christmas mary.ux. records gave for sue to sue birthday books [SEP]']
[1350/2000] tot_loss=1.893 (perp=8.609, rec=0.163, cos=0.008), tot_loss_proj:3.569 [t=0.18s]
prediction: ['[CLS] john gavevan for the christmas mary.ux. records gave for sue to sue birthday books [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.811 (perp=8.187, rec=0.165, cos=0.008), tot_loss_proj:3.515 [t=0.18s]
prediction: ['[CLS] john gaveux for the christmas mary. write. records gave for sue to sue birthday books [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.712 (perp=7.688, rec=0.166, cos=0.008), tot_loss_proj:3.405 [t=0.18s]
prediction: ['[CLS] john gave. for the christmas mary. writeux records gave for sue to sue birthday books [SEP]']
[1500/2000] tot_loss=1.732 (perp=7.786, rec=0.167, cos=0.008), tot_loss_proj:3.384 [t=0.18s]
prediction: ['[CLS] john gave. at the christmas mary. writeux records gave for sue to sue birthday books [SEP]']
Attempt swap
[1550/2000] tot_loss=1.729 (perp=7.786, rec=0.164, cos=0.008), tot_loss_proj:3.385 [t=0.18s]
prediction: ['[CLS] john gave. at the christmas mary. writeux records gave for sue to sue birthday books [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.700 (perp=7.607, rec=0.170, cos=0.008), tot_loss_proj:3.363 [t=0.18s]
prediction: ['[CLS] john gave books at the christmas mary. writeux records gave for sue to sue birthday. [SEP]']
[1650/2000] tot_loss=1.696 (perp=7.607, rec=0.167, cos=0.008), tot_loss_proj:3.368 [t=0.18s]
prediction: ['[CLS] john gave books at the christmas mary. writeux records gave for sue to sue birthday. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.659 (perp=7.446, rec=0.162, cos=0.008), tot_loss_proj:3.366 [t=0.18s]
prediction: ['[CLS] john gave books at the christmas mary. writeux records gave for sue birthday to sue. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.632 (perp=7.309, rec=0.162, cos=0.008), tot_loss_proj:3.362 [t=0.18s]
prediction: ['[CLS] john gave books at the christmas mary. writeux gave records for sue birthday to sue. [SEP]']
[1800/2000] tot_loss=1.629 (perp=7.309, rec=0.159, cos=0.008), tot_loss_proj:3.369 [t=0.18s]
prediction: ['[CLS] john gave books at the christmas mary. writeux gave records for sue birthday to sue. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.602 (perp=7.145, rec=0.165, cos=0.008), tot_loss_proj:3.176 [t=0.18s]
prediction: ['[CLS] john gave books at the christmas. mary writeux gave records for sue birthday to sue. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.605 (perp=7.145, rec=0.168, cos=0.008), tot_loss_proj:3.173 [t=0.18s]
prediction: ['[CLS] john gave books at the christmas. mary writeux gave records for sue birthday to sue. [SEP]']
[1950/2000] tot_loss=1.600 (perp=7.145, rec=0.163, cos=0.008), tot_loss_proj:3.175 [t=0.18s]
prediction: ['[CLS] john gave books at the christmas. mary writeux gave records for sue birthday to sue. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.600 (perp=7.145, rec=0.163, cos=0.007), tot_loss_proj:3.174 [t=0.18s]
prediction: ['[CLS] john gave books at the christmas. mary writeux gave records for sue birthday to sue. [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]
========================
predicted: 
========================
[CLS] john gave books at the christmas. mary writeux gave records for sue birthday to sue. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 82.353 | r: 77.778
rouge2     | fm: 18.182 | p: 18.750 | r: 17.647
rougeL     | fm: 57.143 | p: 58.824 | r: 55.556
rougeLsum  | fm: 57.143 | p: 58.824 | r: 55.556
r1fm+r2fm = 98.182

[Aggregate metrics]:
rouge1     | fm: 82.039 | p: 82.058 | r: 82.294
rouge2     | fm: 33.577 | p: 33.545 | r: 33.730
rougeL     | fm: 65.387 | p: 65.389 | r: 65.559
rougeLsum  | fm: 65.631 | p: 65.640 | r: 65.876
r1fm+r2fm = 115.616

input #52 time: 0:07:19 | total time: 6:24:42


Running input #53 of 100.
reference: 
========================
He said that himself was hungry.
========================
average of cosine similarity 0.9993481863787018
highest_index [0]
highest [0.9993481863787018]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2056, 2008, 2370, 2001, 7501, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he said that himself was hungry. [SEP]']
[Init] best rec loss: 0.9756957292556763 for ['[CLS] syncoc youth also returning jaguar flower [SEP]']
[Init] best rec loss: 0.9171878695487976 for ['[CLS] terms expireditanupt racing everuating [SEP]']
[Init] best rec loss: 0.8175871968269348 for ['[CLS] these once ofents intensive course vu [SEP]']
[Init] best rec loss: 0.8068182468414307 for ['[CLS] over breed [CLS] mentioned pitched genus memories [SEP]']
[Init] best rec loss: 0.7839474081993103 for ['[CLS] house chi browningchia himalayan audience appeal [SEP]']
[Init] best rec loss: 0.7613614201545715 for ['[CLS] " head rifle hate moved course youth [SEP]']
[Init] best rec loss: 0.7518348693847656 for ['[CLS] gravel shooter promotion rios press eve voyage [SEP]']
[Init] best rec loss: 0.738399863243103 for ['[CLS] 2002 faso tone averaged category wave doubt [SEP]']
[Init] best rec loss: 0.7359643578529358 for ['[CLS] sorry multi care by sherlock relief google [SEP]']
[Init] best perm rec loss: 0.7308405041694641 for ['[CLS] google multi sorry sherlock relief care by [SEP]']
[Init] best perm rec loss: 0.7285928726196289 for ['[CLS] care sorry by sherlock multi relief google [SEP]']
[Init] best perm rec loss: 0.7279585003852844 for ['[CLS] multi by sorry care google relief sherlock [SEP]']
[Init] best perm rec loss: 0.7274588346481323 for ['[CLS] multi care by sherlock sorry relief google [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.175 (perp=9.340, rec=0.295, cos=0.011), tot_loss_proj:2.686 [t=0.17s]
prediction: ['[CLS] composed that that that?. himself [SEP]']
[ 100/2000] tot_loss=1.820 (perp=7.968, rec=0.221, cos=0.006), tot_loss_proj:2.661 [t=0.17s]
prediction: ['[CLS]. says that that hungry. himself [SEP]']
[ 150/2000] tot_loss=1.493 (perp=6.701, rec=0.147, cos=0.006), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] he said that himself hungry. himself [SEP]']
[ 200/2000] tot_loss=1.648 (perp=7.631, rec=0.117, cos=0.005), tot_loss_proj:2.048 [t=0.18s]
prediction: ['[CLS] was said that himself hungry. himself [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.336 (perp=6.201, rec=0.091, cos=0.004), tot_loss_proj:1.719 [t=0.19s]
prediction: ['[CLS] was said that himself hungry himself. [SEP]']
[ 300/2000] tot_loss=1.338 (perp=6.201, rec=0.094, cos=0.004), tot_loss_proj:1.715 [t=0.19s]
prediction: ['[CLS] was said that himself hungry himself. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=0.957 (perp=4.367, rec=0.080, cos=0.004), tot_loss_proj:2.683 [t=0.19s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[ 400/2000] tot_loss=0.951 (perp=4.367, rec=0.074, cos=0.003), tot_loss_proj:2.680 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[ 450/2000] tot_loss=0.954 (perp=4.367, rec=0.077, cos=0.003), tot_loss_proj:2.684 [t=0.17s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[ 500/2000] tot_loss=0.958 (perp=4.367, rec=0.081, cos=0.003), tot_loss_proj:2.685 [t=0.17s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[ 550/2000] tot_loss=0.950 (perp=4.367, rec=0.073, cos=0.003), tot_loss_proj:2.680 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[ 600/2000] tot_loss=0.944 (perp=4.367, rec=0.067, cos=0.003), tot_loss_proj:2.687 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.937 (perp=4.367, rec=0.060, cos=0.003), tot_loss_proj:2.681 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.945 (perp=4.367, rec=0.068, cos=0.003), tot_loss_proj:2.690 [t=0.17s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[ 750/2000] tot_loss=0.952 (perp=4.367, rec=0.075, cos=0.003), tot_loss_proj:2.686 [t=0.17s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.950 (perp=4.367, rec=0.073, cos=0.003), tot_loss_proj:2.697 [t=0.20s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.947 (perp=4.367, rec=0.070, cos=0.003), tot_loss_proj:2.691 [t=0.17s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[ 900/2000] tot_loss=0.954 (perp=4.367, rec=0.078, cos=0.003), tot_loss_proj:2.691 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.956 (perp=4.367, rec=0.079, cos=0.003), tot_loss_proj:2.690 [t=0.17s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.955 (perp=4.367, rec=0.078, cos=0.003), tot_loss_proj:2.688 [t=0.17s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[1050/2000] tot_loss=0.944 (perp=4.367, rec=0.067, cos=0.003), tot_loss_proj:2.691 [t=0.20s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.953 (perp=4.367, rec=0.076, cos=0.003), tot_loss_proj:2.693 [t=0.17s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.937 (perp=4.367, rec=0.060, cos=0.003), tot_loss_proj:2.694 [t=0.23s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[1200/2000] tot_loss=0.942 (perp=4.367, rec=0.066, cos=0.003), tot_loss_proj:2.694 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.955 (perp=4.367, rec=0.078, cos=0.003), tot_loss_proj:2.692 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.949 (perp=4.367, rec=0.072, cos=0.003), tot_loss_proj:2.697 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[1350/2000] tot_loss=0.950 (perp=4.367, rec=0.073, cos=0.003), tot_loss_proj:2.693 [t=0.20s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.951 (perp=4.367, rec=0.074, cos=0.003), tot_loss_proj:2.689 [t=0.19s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.951 (perp=4.367, rec=0.075, cos=0.003), tot_loss_proj:2.696 [t=0.19s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[1500/2000] tot_loss=0.941 (perp=4.367, rec=0.064, cos=0.003), tot_loss_proj:2.692 [t=0.19s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.947 (perp=4.367, rec=0.070, cos=0.003), tot_loss_proj:2.701 [t=0.19s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.944 (perp=4.367, rec=0.068, cos=0.003), tot_loss_proj:2.695 [t=0.21s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[1650/2000] tot_loss=0.948 (perp=4.367, rec=0.072, cos=0.003), tot_loss_proj:2.693 [t=0.19s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.957 (perp=4.367, rec=0.080, cos=0.003), tot_loss_proj:2.695 [t=0.19s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.947 (perp=4.367, rec=0.070, cos=0.003), tot_loss_proj:2.696 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[1800/2000] tot_loss=0.948 (perp=4.367, rec=0.071, cos=0.003), tot_loss_proj:2.692 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.952 (perp=4.367, rec=0.075, cos=0.003), tot_loss_proj:2.697 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.952 (perp=4.367, rec=0.075, cos=0.003), tot_loss_proj:2.701 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
[1950/2000] tot_loss=0.956 (perp=4.367, rec=0.079, cos=0.003), tot_loss_proj:2.694 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.948 (perp=4.367, rec=0.071, cos=0.003), tot_loss_proj:2.701 [t=0.18s]
prediction: ['[CLS] said that he was hungry himself. [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] he said that himself was hungry. [SEP]
========================
predicted: 
========================
[CLS] said that he was hungry himself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 128.571

[Aggregate metrics]:
rouge1     | fm: 82.360 | p: 82.416 | r: 82.557
rouge2     | fm: 33.434 | p: 33.393 | r: 33.677
rougeL     | fm: 65.714 | p: 65.635 | r: 65.919
rougeLsum  | fm: 65.773 | p: 65.721 | r: 65.981
r1fm+r2fm = 115.795

input #53 time: 0:07:28 | total time: 6:32:10


Running input #54 of 100.
reference: 
========================
After reading the pamphlet, Judy threw them into the garbage can.
========================
average of cosine similarity 0.9993882826053118
highest_index [0]
highest [0.9993882826053118]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  2044,  3752,  1996, 19899,  1010, 12120,  4711,  2068,  2046,
          1996, 13044,  2064,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]']
[Init] best rec loss: 1.0086065530776978 for ['[CLS]position unavailable reporter wink zero do leaning double declared temple swift 2012 fine [SEP]']
[Init] best rec loss: 0.9829070568084717 for ['[CLS] crop jagger occurred badly oil alike destination [ session show sunrisehita you [SEP]']
[Init] best rec loss: 0.9422270059585571 for ['[CLS] electvic push warehouse humor aboutpiece lock eponymousgrant prison measure even [SEP]']
[Init] best rec loss: 0.9266153573989868 for ['[CLS] edward gwen daily ever consideredards erminafar quad river given why [SEP]']
[Init] best rec loss: 0.9201857447624207 for ['[CLS] eve battalion minutes strike twinned trip bond candidatesiarangleib lame macedonia [SEP]']
[Init] best rec loss: 0.9138299226760864 for ['[CLS]chi £ our melbourne back [MASK] damtec isn jake hangbution a [SEP]']
[Init] best rec loss: 0.9105693697929382 for ['[CLS]abyrase fin self beers graphic concentration rise odd coolerus sex flying [SEP]']
[Init] best perm rec loss: 0.9102561473846436 for ['[CLS] sex self graphic odd fin rise coolaby flying beersraseerus concentration [SEP]']
[Init] best perm rec loss: 0.9093592762947083 for ['[CLS] flying concentration odd fin graphicerus coolaby self sex beers riserase [SEP]']
[Init] best perm rec loss: 0.9088178873062134 for ['[CLS] rise beers odd self fin flyingrase graphic sexerusaby cool concentration [SEP]']
[Init] best perm rec loss: 0.9084143042564392 for ['[CLS] concentration coolaby self odd riseerus fin sexrase beers flying graphic [SEP]']
[Init] best perm rec loss: 0.9079568982124329 for ['[CLS] concentration riseerus fin graphicaby self oddrase sex flying beers cool [SEP]']
[Init] best perm rec loss: 0.9070364832878113 for ['[CLS]raseerus graphic cool fin selfaby beers flying sex concentration odd rise [SEP]']
[Init] best perm rec loss: 0.9065402150154114 for ['[CLS] graphic rise odd selfrase flying sex fin cool beersaby concentrationerus [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.202 (perp=13.112, rec=0.651, cos=0.928), tot_loss_proj:4.519 [t=0.17s]
prediction: ['[CLS] besidesworthy stigma hamish slogan amongdrive bottle hancock ) briggs for phil [SEP]']
[ 100/2000] tot_loss=3.890 (perp=11.676, rec=0.630, cos=0.925), tot_loss_proj:4.183 [t=0.18s]
prediction: ['[CLS]. biography these nedra disrupt pamphlet them mc becomes victory gibbs them ) [SEP]']
[ 150/2000] tot_loss=3.771 (perp=10.317, rec=0.730, cos=0.977), tot_loss_proj:3.929 [t=0.18s]
prediction: ['[CLS]. read elliot alex somewhere organize them. becomes tent gibbs to ) [SEP]']
[ 200/2000] tot_loss=3.561 (perp=9.998, rec=0.562, cos=1.000), tot_loss_proj:3.864 [t=0.18s]
prediction: ['[CLS] or term here hearingerate pamphlet them before are empty before ammunition. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.507 (perp=10.152, rec=0.477, cos=1.000), tot_loss_proj:3.923 [t=0.17s]
prediction: ['[CLS] here his reading hearing objects pamphlet them by kitty strength landmarks ammunition. [SEP]']
[ 300/2000] tot_loss=3.520 (perp=10.445, rec=0.431, cos=1.000), tot_loss_proj:4.022 [t=0.18s]
prediction: ['[CLS] pamphlet his reading hearing objects pamphlet them against became strength! ammunition. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.338 (perp=9.692, rec=0.404, cos=0.996), tot_loss_proj:3.873 [t=0.18s]
prediction: ['[CLS] hearing his reading pamphlet pamphlet pamphlet them against became object! ammunition. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.283 (perp=9.514, rec=0.396, cos=0.984), tot_loss_proj:3.831 [t=0.18s]
prediction: ['[CLS] hearing his reading pamphlet pamphlet pamphlet them against became object onto!. [SEP]']
[ 450/2000] tot_loss=2.943 (perp=9.431, rec=0.701, cos=0.355), tot_loss_proj:3.756 [t=0.18s]
prediction: ['[CLS] hearing historic reading pamphlet folder threw them in became object napkin!. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.651 (perp=11.233, rec=0.349, cos=0.055), tot_loss_proj:4.170 [t=0.18s]
prediction: ['[CLS] hearing historic books threw them [SEP] became powder onto! pamphlet pamphlet. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.137 (perp=9.209, rec=0.270, cos=0.025), tot_loss_proj:3.770 [t=0.18s]
prediction: ['[CLS] hearing historic books threw them into became metal onto pamphlet! pamphlet. [SEP]']
[ 600/2000] tot_loss=2.161 (perp=9.482, rec=0.250, cos=0.014), tot_loss_proj:3.834 [t=0.18s]
prediction: ['[CLS] hearing historic words threw them into became liquor onto pamphlet! pamphlet. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.150 (perp=9.581, rec=0.223, cos=0.011), tot_loss_proj:3.828 [t=0.18s]
prediction: ['[CLS] hearing writing words threw them into became liquor pamphlet into pamphlet!. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.070 (perp=9.200, rec=0.219, cos=0.011), tot_loss_proj:3.731 [t=0.18s]
prediction: ['[CLS] hearing reading pamphlet threw them into became liquor reading into pamphlet!. [SEP]']
[ 750/2000] tot_loss=2.047 (perp=9.200, rec=0.200, cos=0.007), tot_loss_proj:3.732 [t=0.18s]
prediction: ['[CLS] hearing reading pamphlet threw them into became liquor reading into pamphlet!. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.031 (perp=9.101, rec=0.204, cos=0.007), tot_loss_proj:3.751 [t=0.17s]
prediction: ['[CLS] hearing pamphlet reading threw them into threw liquor reading into pamphlet!. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.893 (perp=8.482, rec=0.190, cos=0.006), tot_loss_proj:3.759 [t=0.18s]
prediction: ['[CLS] hearing pamphlet reading threw them into reading threw liquor into judy!. [SEP]']
[ 900/2000] tot_loss=1.812 (perp=8.118, rec=0.183, cos=0.006), tot_loss_proj:3.667 [t=0.17s]
prediction: ['[CLS] hearing pamphlet reading threw them into reading threw garbage into judy!. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.950 (perp=8.807, rec=0.183, cos=0.005), tot_loss_proj:3.734 [t=0.18s]
prediction: ['[CLS] reading pamphlet hearing threw them into reading threw garbage into judy aback. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.852 (perp=8.294, rec=0.186, cos=0.007), tot_loss_proj:3.556 [t=0.17s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing judy affair. [SEP]']
[1050/2000] tot_loss=1.831 (perp=8.294, rec=0.167, cos=0.006), tot_loss_proj:3.557 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing judy affair. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.827 (perp=8.294, rec=0.163, cos=0.006), tot_loss_proj:3.560 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing judy affair. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.825 (perp=8.294, rec=0.161, cos=0.006), tot_loss_proj:3.560 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing judy affair. [SEP]']
[1200/2000] tot_loss=1.819 (perp=8.294, rec=0.155, cos=0.005), tot_loss_proj:3.556 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing judy affair. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.813 (perp=8.294, rec=0.149, cos=0.005), tot_loss_proj:3.555 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing judy affair. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.818 (perp=8.294, rec=0.155, cos=0.005), tot_loss_proj:3.556 [t=0.17s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing judy affair. [SEP]']
[1350/2000] tot_loss=1.785 (perp=8.171, rec=0.146, cos=0.004), tot_loss_proj:3.495 [t=0.17s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing judy during. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.792 (perp=8.171, rec=0.154, cos=0.004), tot_loss_proj:3.497 [t=0.17s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing judy during. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.769 (perp=8.080, rec=0.148, cos=0.005), tot_loss_proj:3.469 [t=0.17s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing during judy. [SEP]']
[1500/2000] tot_loss=1.770 (perp=8.080, rec=0.150, cos=0.005), tot_loss_proj:3.465 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing during judy. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.765 (perp=8.080, rec=0.145, cos=0.004), tot_loss_proj:3.468 [t=0.19s]
prediction: ['[CLS] reading pamphlet threw them into reading threw garbage into hearing during judy. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.761 (perp=8.009, rec=0.154, cos=0.005), tot_loss_proj:3.465 [t=0.19s]
prediction: ['[CLS] reading pamphlet threw them into judy threw garbage into hearing during reading. [SEP]']
[1650/2000] tot_loss=1.761 (perp=8.009, rec=0.155, cos=0.004), tot_loss_proj:3.464 [t=0.19s]
prediction: ['[CLS] reading pamphlet threw them into judy threw garbage into hearing during reading. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.759 (perp=8.009, rec=0.153, cos=0.004), tot_loss_proj:3.465 [t=0.19s]
prediction: ['[CLS] reading pamphlet threw them into judy threw garbage into hearing during reading. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.749 (perp=8.009, rec=0.143, cos=0.004), tot_loss_proj:3.463 [t=0.19s]
prediction: ['[CLS] reading pamphlet threw them into judy threw garbage into hearing during reading. [SEP]']
[1800/2000] tot_loss=1.749 (perp=8.009, rec=0.144, cos=0.004), tot_loss_proj:3.462 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into judy threw garbage into hearing during reading. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.747 (perp=8.009, rec=0.142, cos=0.004), tot_loss_proj:3.463 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into judy threw garbage into hearing during reading. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.751 (perp=8.009, rec=0.145, cos=0.004), tot_loss_proj:3.464 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into judy threw garbage into hearing during reading. [SEP]']
[1950/2000] tot_loss=1.748 (perp=8.009, rec=0.142, cos=0.004), tot_loss_proj:3.465 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into judy threw garbage into hearing during reading. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.009, rec=0.154, cos=0.004), tot_loss_proj:3.461 [t=0.18s]
prediction: ['[CLS] reading pamphlet threw them into judy threw garbage into hearing during reading. [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]
========================
predicted: 
========================
[CLS] reading pamphlet threw them into judy threw garbage into hearing during reading. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 64.286 | r: 69.231
rouge2     | fm: 24.000 | p: 23.077 | r: 25.000
rougeL     | fm: 59.259 | p: 57.143 | r: 61.538
rougeLsum  | fm: 59.259 | p: 57.143 | r: 61.538
r1fm+r2fm = 90.667

[Aggregate metrics]:
rouge1     | fm: 82.174 | p: 82.164 | r: 82.419
rouge2     | fm: 33.257 | p: 33.250 | r: 33.463
rougeL     | fm: 65.399 | p: 65.406 | r: 65.702
rougeLsum  | fm: 65.581 | p: 65.569 | r: 65.811
r1fm+r2fm = 115.431

input #54 time: 0:07:20 | total time: 6:39:30


Running input #55 of 100.
reference: 
========================
Collapsed Harry.
========================
average of cosine similarity 0.9993911323857784
highest_index [0]
highest [0.9993911323857784]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 7798, 4302, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] collapsed harry. [SEP]']
[Init] best rec loss: 0.9055206179618835 for ['[CLS] taken dana once [SEP]']
[Init] best rec loss: 0.8123528957366943 for ['[CLS] information op respect [SEP]']
[Init] best rec loss: 0.7759804129600525 for ['[CLS] lorieyer marrow [SEP]']
[Init] best rec loss: 0.723248302936554 for ['[CLS] class atlantic martins [SEP]']
[Init] best rec loss: 0.718425452709198 for ['[CLS] these how conditioning [SEP]']
[Init] best rec loss: 0.7074264287948608 for ['[CLS] coup pace lila [SEP]']
[Init] best rec loss: 0.6903390884399414 for ['[CLS] mage sharing roman [SEP]']
[Init] best perm rec loss: 0.6879101395606995 for ['[CLS] mage roman sharing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.966 (perp=12.542, rec=0.412, cos=0.046), tot_loss_proj:3.547 [t=0.17s]
prediction: ['[CLS]raction listed collapsed [SEP]']
[ 100/2000] tot_loss=2.671 (perp=11.946, rec=0.260, cos=0.021), tot_loss_proj:3.180 [t=0.17s]
prediction: ['[CLS] strength collapsed harry [SEP]']
[ 150/2000] tot_loss=2.720 (perp=12.580, rec=0.188, cos=0.016), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] catholicism collapsed harry [SEP]']
[ 200/2000] tot_loss=2.657 (perp=12.559, rec=0.135, cos=0.011), tot_loss_proj:3.646 [t=0.19s]
prediction: ['[CLS] collapsed collapsed harry [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.635 (perp=12.559, rec=0.118, cos=0.006), tot_loss_proj:3.589 [t=0.17s]
prediction: ['[CLS] collapsed collapsed harry [SEP]']
[ 300/2000] tot_loss=2.740 (perp=13.094, rec=0.114, cos=0.007), tot_loss_proj:3.512 [t=0.17s]
prediction: ['[CLS]tension collapsed harry [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.632 (perp=12.496, rec=0.124, cos=0.008), tot_loss_proj:3.469 [t=0.17s]
prediction: ['[CLS]tension harry collapsed [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.608 (perp=12.274, rec=0.138, cos=0.015), tot_loss_proj:3.510 [t=0.19s]
prediction: ['[CLS] harry fungus collapsed [SEP]']
[ 450/2000] tot_loss=2.067 (perp=9.787, rec=0.104, cos=0.005), tot_loss_proj:3.798 [t=0.19s]
prediction: ['[CLS] harry. collapsed [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.742 (perp=8.256, rec=0.086, cos=0.005), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.731 (perp=8.256, rec=0.078, cos=0.002), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
[ 600/2000] tot_loss=1.737 (perp=8.256, rec=0.084, cos=0.002), tot_loss_proj:3.482 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.738 (perp=8.256, rec=0.085, cos=0.002), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.723 (perp=8.256, rec=0.071, cos=0.001), tot_loss_proj:3.481 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
[ 750/2000] tot_loss=1.729 (perp=8.256, rec=0.077, cos=0.001), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.738 (perp=8.256, rec=0.085, cos=0.001), tot_loss_proj:3.485 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.722 (perp=8.256, rec=0.070, cos=0.001), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
[ 900/2000] tot_loss=1.731 (perp=8.256, rec=0.079, cos=0.001), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.723 (perp=8.256, rec=0.070, cos=0.001), tot_loss_proj:3.481 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.716 (perp=8.256, rec=0.064, cos=0.001), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1050/2000] tot_loss=1.720 (perp=8.256, rec=0.067, cos=0.001), tot_loss_proj:3.482 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.726 (perp=8.256, rec=0.073, cos=0.001), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.722 (perp=8.256, rec=0.070, cos=0.001), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1200/2000] tot_loss=1.721 (perp=8.256, rec=0.068, cos=0.001), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.717 (perp=8.256, rec=0.064, cos=0.001), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.729 (perp=8.256, rec=0.077, cos=0.001), tot_loss_proj:3.478 [t=0.18s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1350/2000] tot_loss=1.721 (perp=8.256, rec=0.068, cos=0.001), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.715 (perp=8.256, rec=0.063, cos=0.001), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.721 (perp=8.256, rec=0.069, cos=0.001), tot_loss_proj:3.482 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1500/2000] tot_loss=1.722 (perp=8.256, rec=0.070, cos=0.001), tot_loss_proj:3.485 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.720 (perp=8.256, rec=0.068, cos=0.001), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.729 (perp=8.256, rec=0.077, cos=0.001), tot_loss_proj:3.481 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1650/2000] tot_loss=1.713 (perp=8.256, rec=0.061, cos=0.001), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.728 (perp=8.256, rec=0.076, cos=0.001), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.721 (perp=8.256, rec=0.069, cos=0.001), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1800/2000] tot_loss=1.725 (perp=8.256, rec=0.073, cos=0.001), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.714 (perp=8.256, rec=0.061, cos=0.001), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.728 (perp=8.256, rec=0.075, cos=0.001), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
[1950/2000] tot_loss=1.712 (perp=8.256, rec=0.060, cos=0.001), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.720 (perp=8.256, rec=0.068, cos=0.001), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] harry collapsed. [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] collapsed harry. [SEP]
========================
predicted: 
========================
[CLS] harry collapsed. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 82.486 | p: 82.450 | r: 82.743
rouge2     | fm: 32.637 | p: 32.640 | r: 32.797
rougeL     | fm: 65.769 | p: 65.686 | r: 65.944
rougeLsum  | fm: 65.752 | p: 65.709 | r: 66.026
r1fm+r2fm = 115.123

input #55 time: 0:07:14 | total time: 6:46:44


Running input #56 of 100.
reference: 
========================
John was seeing his children.
========================
average of cosine similarity 0.9993522822859877
highest_index [0]
highest [0.9993522822859877]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2198, 2001, 3773, 2010, 2336, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john was seeing his children. [SEP]']
[Init] best rec loss: 0.9693037271499634 for ['[CLS] vampire artists at like edge into [SEP]']
[Init] best rec loss: 0.9084345102310181 for ['[CLS] banned scout fadeper residence nursery [SEP]']
[Init] best perm rec loss: 0.9078051447868347 for ['[CLS] banned residence fade scoutper nursery [SEP]']
[Init] best perm rec loss: 0.9077329635620117 for ['[CLS] scout nursery residence bannedper fade [SEP]']
[Init] best perm rec loss: 0.9056980013847351 for ['[CLS] residence fade nurseryper banned scout [SEP]']
[Init] best perm rec loss: 0.9053595662117004 for ['[CLS] residence fade bannedper scout nursery [SEP]']
[Init] best perm rec loss: 0.9046943187713623 for ['[CLS] banned residence fade scout nurseryper [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.962 (perp=12.667, rec=0.653, cos=0.776), tot_loss_proj:4.369 [t=0.17s]
prediction: ['[CLS] mind meant? breakfast a aftermath [SEP]']
[ 100/2000] tot_loss=3.069 (perp=8.138, rec=0.591, cos=0.850), tot_loss_proj:3.538 [t=0.17s]
prediction: ['[CLS]reate john? john was. [SEP]']
[ 150/2000] tot_loss=1.837 (perp=7.601, rec=0.291, cos=0.026), tot_loss_proj:3.207 [t=0.17s]
prediction: ['[CLS] seeing john was children was. [SEP]']
[ 200/2000] tot_loss=1.676 (perp=7.664, rec=0.137, cos=0.007), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] seeing john was children seeing. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.423 (perp=6.563, rec=0.105, cos=0.005), tot_loss_proj:3.471 [t=0.17s]
prediction: ['[CLS] seeing john was seeing children. [SEP]']
[ 300/2000] tot_loss=1.421 (perp=6.563, rec=0.104, cos=0.004), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] seeing john was seeing children. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.412 (perp=6.563, rec=0.096, cos=0.004), tot_loss_proj:3.477 [t=0.19s]
prediction: ['[CLS] seeing john was seeing children. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.414 (perp=6.563, rec=0.097, cos=0.004), tot_loss_proj:3.464 [t=0.17s]
prediction: ['[CLS] seeing john was seeing children. [SEP]']
[ 450/2000] tot_loss=1.410 (perp=6.563, rec=0.094, cos=0.003), tot_loss_proj:3.465 [t=0.17s]
prediction: ['[CLS] seeing john was seeing children. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.434 (perp=6.735, rec=0.084, cos=0.003), tot_loss_proj:2.927 [t=0.17s]
prediction: ['[CLS] his john was seeing children. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.322 (perp=6.084, rec=0.098, cos=0.007), tot_loss_proj:1.387 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[ 600/2000] tot_loss=1.310 (perp=6.084, rec=0.089, cos=0.004), tot_loss_proj:1.361 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.291 (perp=6.084, rec=0.071, cos=0.004), tot_loss_proj:1.343 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.288 (perp=6.084, rec=0.068, cos=0.004), tot_loss_proj:1.344 [t=0.19s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[ 750/2000] tot_loss=1.296 (perp=6.084, rec=0.076, cos=0.003), tot_loss_proj:1.353 [t=0.19s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.309 (perp=6.084, rec=0.089, cos=0.003), tot_loss_proj:1.354 [t=0.19s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.294 (perp=6.084, rec=0.074, cos=0.003), tot_loss_proj:1.350 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[ 900/2000] tot_loss=1.295 (perp=6.084, rec=0.075, cos=0.003), tot_loss_proj:1.357 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.297 (perp=6.084, rec=0.077, cos=0.003), tot_loss_proj:1.357 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.285 (perp=6.084, rec=0.065, cos=0.003), tot_loss_proj:1.363 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1050/2000] tot_loss=1.284 (perp=6.084, rec=0.064, cos=0.003), tot_loss_proj:1.351 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.288 (perp=6.084, rec=0.068, cos=0.003), tot_loss_proj:1.348 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.292 (perp=6.084, rec=0.072, cos=0.003), tot_loss_proj:1.341 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1200/2000] tot_loss=1.285 (perp=6.084, rec=0.065, cos=0.003), tot_loss_proj:1.343 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.278 (perp=6.084, rec=0.058, cos=0.003), tot_loss_proj:1.360 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.294 (perp=6.084, rec=0.074, cos=0.003), tot_loss_proj:1.349 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1350/2000] tot_loss=1.286 (perp=6.084, rec=0.066, cos=0.003), tot_loss_proj:1.352 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.284 (perp=6.084, rec=0.064, cos=0.003), tot_loss_proj:1.347 [t=0.19s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.284 (perp=6.084, rec=0.064, cos=0.003), tot_loss_proj:1.351 [t=0.20s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1500/2000] tot_loss=1.291 (perp=6.084, rec=0.071, cos=0.003), tot_loss_proj:1.357 [t=0.20s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.294 (perp=6.084, rec=0.075, cos=0.003), tot_loss_proj:1.348 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.292 (perp=6.084, rec=0.073, cos=0.003), tot_loss_proj:1.345 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1650/2000] tot_loss=1.291 (perp=6.084, rec=0.072, cos=0.003), tot_loss_proj:1.350 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.286 (perp=6.084, rec=0.066, cos=0.003), tot_loss_proj:1.347 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.299 (perp=6.084, rec=0.079, cos=0.003), tot_loss_proj:1.351 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1800/2000] tot_loss=1.295 (perp=6.084, rec=0.075, cos=0.003), tot_loss_proj:1.363 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.290 (perp=6.084, rec=0.070, cos=0.003), tot_loss_proj:1.338 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.287 (perp=6.084, rec=0.067, cos=0.003), tot_loss_proj:1.344 [t=0.18s]
prediction: ['[CLS] john was seeing his children. [SEP]']
[1950/2000] tot_loss=1.284 (perp=6.084, rec=0.064, cos=0.003), tot_loss_proj:1.348 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.289 (perp=6.084, rec=0.069, cos=0.003), tot_loss_proj:1.363 [t=0.17s]
prediction: ['[CLS] john was seeing his children. [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] john was seeing his children. [SEP]
========================
predicted: 
========================
[CLS] john was seeing his children. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.722 | p: 82.729 | r: 82.993
rouge2     | fm: 33.815 | p: 33.777 | r: 33.998
rougeL     | fm: 66.186 | p: 66.208 | r: 66.524
rougeLsum  | fm: 66.384 | p: 66.343 | r: 66.642
r1fm+r2fm = 116.538

input #56 time: 0:07:20 | total time: 6:54:05


Running input #57 of 100.
reference: 
========================
Carla mopped the floor under the furniture.
========================
average of cosine similarity 0.999410832505384
highest_index [0]
highest [0.999410832505384]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 17081,  9587, 11469,  1996,  2723,  2104,  1996,  7390,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] carla mopped the floor under the furniture. [SEP]']
[Init] best rec loss: 0.9423267245292664 for ['[CLS]ne gathering do their health retirement go enforce things [SEP]']
[Init] best rec loss: 0.9340547919273376 for ['[CLS]kes second loose late west allied creation utility evelyn [SEP]']
[Init] best rec loss: 0.9054117202758789 for ['[CLS]quent quadrant material seat inclusion kn difference vincent stubborn [SEP]']
[Init] best rec loss: 0.8925279974937439 for ['[CLS] mari guy identity episode use formsorescence nm fit [SEP]']
[Init] best rec loss: 0.8883852958679199 for ['[CLS] jack itself cheers elevation back sharing volunteeredthan solid [SEP]']
[Init] best perm rec loss: 0.8876361846923828 for ['[CLS] itself elevation back jack sharing solid volunteeredthan cheers [SEP]']
[Init] best perm rec loss: 0.8854588270187378 for ['[CLS] jack elevation back solid sharing cheers itself volunteeredthan [SEP]']
[Init] best perm rec loss: 0.8849825859069824 for ['[CLS] sharing jackthan cheers volunteered solid itself back elevation [SEP]']
[Init] best perm rec loss: 0.8849116563796997 for ['[CLS] back solid cheers jack elevation itselfthan volunteered sharing [SEP]']
[Init] best perm rec loss: 0.8840395212173462 for ['[CLS] itselfthan jack volunteered cheers solid sharing elevation back [SEP]']
[Init] best perm rec loss: 0.8835548162460327 for ['[CLS] solid cheers back elevation itself sharingthan jack volunteered [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.823 (perp=11.322, rec=0.441, cos=0.118), tot_loss_proj:4.086 [t=0.17s]
prediction: ['[CLS] economy matching monsters cut carla inhabited herself, siberia [SEP]']
[ 100/2000] tot_loss=3.066 (perp=13.078, rec=0.378, cos=0.073), tot_loss_proj:4.502 [t=0.17s]
prediction: ['[CLS] carla clean rough cut carlapped decommissioned - swamp [SEP]']
[ 150/2000] tot_loss=2.951 (perp=12.773, rec=0.344, cos=0.052), tot_loss_proj:4.439 [t=0.17s]
prediction: ['[CLS] carla own brown cut carlapped our - swamp [SEP]']
[ 200/2000] tot_loss=2.284 (perp=10.047, rec=0.257, cos=0.018), tot_loss_proj:3.902 [t=0.17s]
prediction: ['[CLS] carla using brownhole carlapped the floor floor [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.609 (perp=11.834, rec=0.226, cos=0.017), tot_loss_proj:4.199 [t=0.17s]
prediction: ['[CLS] carla underneath brown floor carlapped the floor caste [SEP]']
[ 300/2000] tot_loss=2.369 (perp=10.779, rec=0.202, cos=0.011), tot_loss_proj:3.975 [t=0.17s]
prediction: ['[CLS] carla under brown floor carlapped the floor mo [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.121 (perp=9.587, rec=0.194, cos=0.009), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] carla under brown under floor carlapped the floor [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.039 (perp=8.539, rec=0.285, cos=0.046), tot_loss_proj:3.585 [t=0.18s]
prediction: ['[CLS] carla under brown underpped carla under the floor [SEP]']
[ 450/2000] tot_loss=1.927 (perp=8.539, rec=0.204, cos=0.015), tot_loss_proj:3.574 [t=0.17s]
prediction: ['[CLS] carla under brown underpped carla under the floor [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.050 (perp=9.211, rec=0.193, cos=0.014), tot_loss_proj:3.683 [t=0.17s]
prediction: ['[CLS] carla under brown floorpped carla under the floor [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.979 (perp=8.658, rec=0.220, cos=0.027), tot_loss_proj:3.568 [t=0.17s]
prediction: ['[CLS] carla brown floor underpped carla under the floor [SEP]']
[ 600/2000] tot_loss=1.919 (perp=8.658, rec=0.176, cos=0.012), tot_loss_proj:3.563 [t=0.17s]
prediction: ['[CLS] carla brown floor underpped carla under the floor [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.020 (perp=9.197, rec=0.171, cos=0.009), tot_loss_proj:3.662 [t=0.17s]
prediction: ['[CLS] carla brown floor underpped carla under the furniture [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.000 (perp=9.197, rec=0.152, cos=0.008), tot_loss_proj:3.659 [t=0.17s]
prediction: ['[CLS] carla brown floor underpped carla under the furniture [SEP]']
[ 750/2000] tot_loss=2.423 (perp=11.202, rec=0.167, cos=0.016), tot_loss_proj:4.076 [t=0.17s]
prediction: ['[CLS] carla roof floor underpped carla under the furniture [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.065 (perp=9.519, rec=0.153, cos=0.007), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] carla under floor brownpped carla under the furniture [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.228 (perp=9.892, rec=0.213, cos=0.037), tot_loss_proj:3.782 [t=0.17s]
prediction: ['[CLS] under floor carla cookiespped carla under the furniture [SEP]']
[ 900/2000] tot_loss=2.145 (perp=9.892, rec=0.155, cos=0.011), tot_loss_proj:3.788 [t=0.17s]
prediction: ['[CLS] under floor carla cookiespped carla under the furniture [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.857 (perp=8.523, rec=0.143, cos=0.009), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] under floor carla brown carlapped under the furniture [SEP]']
Attempt swap
[1000/2000] tot_loss=1.853 (perp=8.523, rec=0.141, cos=0.008), tot_loss_proj:3.578 [t=0.17s]
prediction: ['[CLS] under floor carla brown carlapped under the furniture [SEP]']
[1050/2000] tot_loss=2.108 (perp=9.732, rec=0.154, cos=0.007), tot_loss_proj:3.811 [t=0.17s]
prediction: ['[CLS] under floor carla mo carlapped under the furniture [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.975 (perp=9.101, rec=0.147, cos=0.007), tot_loss_proj:3.718 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1150/2000] tot_loss=1.963 (perp=9.101, rec=0.136, cos=0.007), tot_loss_proj:3.710 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
[1200/2000] tot_loss=1.956 (perp=9.101, rec=0.130, cos=0.006), tot_loss_proj:3.712 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1250/2000] tot_loss=1.964 (perp=9.101, rec=0.138, cos=0.006), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1300/2000] tot_loss=1.965 (perp=9.101, rec=0.139, cos=0.006), tot_loss_proj:3.713 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
[1350/2000] tot_loss=1.965 (perp=9.101, rec=0.139, cos=0.006), tot_loss_proj:3.716 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1400/2000] tot_loss=1.964 (perp=9.101, rec=0.138, cos=0.006), tot_loss_proj:3.718 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1450/2000] tot_loss=1.955 (perp=9.101, rec=0.129, cos=0.006), tot_loss_proj:3.715 [t=0.18s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
[1500/2000] tot_loss=1.970 (perp=9.101, rec=0.144, cos=0.006), tot_loss_proj:3.715 [t=0.18s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1550/2000] tot_loss=1.949 (perp=9.101, rec=0.123, cos=0.006), tot_loss_proj:3.714 [t=0.18s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1600/2000] tot_loss=1.965 (perp=9.101, rec=0.138, cos=0.006), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
[1650/2000] tot_loss=1.963 (perp=9.101, rec=0.137, cos=0.006), tot_loss_proj:3.717 [t=0.18s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1700/2000] tot_loss=1.965 (perp=9.101, rec=0.138, cos=0.006), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1750/2000] tot_loss=1.957 (perp=9.101, rec=0.131, cos=0.006), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
[1800/2000] tot_loss=1.955 (perp=9.101, rec=0.129, cos=0.006), tot_loss_proj:3.712 [t=0.18s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1850/2000] tot_loss=1.949 (perp=9.101, rec=0.123, cos=0.006), tot_loss_proj:3.712 [t=0.18s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[1900/2000] tot_loss=1.953 (perp=9.101, rec=0.127, cos=0.006), tot_loss_proj:3.713 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
[1950/2000] tot_loss=1.953 (perp=9.101, rec=0.127, cos=0.006), tot_loss_proj:3.712 [t=0.18s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Attempt swap
[2000/2000] tot_loss=1.948 (perp=9.101, rec=0.122, cos=0.006), tot_loss_proj:3.718 [t=0.17s]
prediction: ['[CLS] under floor carla carla mopped under the furniture [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] carla mopped the floor under the furniture. [SEP]
========================
predicted: 
========================
[CLS] under floor carla carla mopped under the furniture [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 131.269

[Aggregate metrics]:
rouge1     | fm: 82.716 | p: 82.698 | r: 83.043
rouge2     | fm: 34.294 | p: 34.172 | r: 34.512
rougeL     | fm: 66.495 | p: 66.415 | r: 66.860
rougeLsum  | fm: 66.597 | p: 66.481 | r: 66.907
r1fm+r2fm = 117.010

input #57 time: 0:07:10 | total time: 7:01:15


Running input #58 of 100.
reference: 
========================
They expected us to should leave him.
========================
average of cosine similarity 0.9993178527703294
highest_index [0]
highest [0.9993178527703294]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2027, 3517, 2149, 2000, 2323, 2681, 2032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] they expected us to should leave him. [SEP]']
[Init] best rec loss: 1.01006019115448 for ['[CLS] like cal hazard far indiangence pair rolled [SEP]']
[Init] best rec loss: 0.9678995013237 for ['[CLS] suit agent special small crack still try cases [SEP]']
[Init] best rec loss: 0.7499859929084778 for ['[CLS] michellevable moved lottery fold °f ask collectively [SEP]']
[Init] best rec loss: 0.7345256805419922 for ['[CLS] fore primary pcs publishing source pu ra germany [SEP]']
[Init] best rec loss: 0.7178595662117004 for ['[CLS] cartoon bastionional pulitzer implant camp assistance away [SEP]']
[Init] best rec loss: 0.7141168117523193 for ['[CLS] satellite cum deserves specialized saw shoteral town [SEP]']
[Init] best perm rec loss: 0.7126652598381042 for ['[CLS] deserves shot town saw specialized satellite cumeral [SEP]']
[Init] best perm rec loss: 0.7116402387619019 for ['[CLS] cum town satellite deserves shot saweral specialized [SEP]']
[Init] best perm rec loss: 0.7094566226005554 for ['[CLS] shot cum deserves saweral town specialized satellite [SEP]']
[Init] best perm rec loss: 0.7093368172645569 for ['[CLS] specialized saw satellite cum shot town deserveseral [SEP]']
[Init] best perm rec loss: 0.7073099613189697 for ['[CLS] satellite shot deserves specialized cumeral town saw [SEP]']
[Init] best perm rec loss: 0.7069427371025085 for ['[CLS] deserves satellite town shot cumeral specialized saw [SEP]']
[Init] best perm rec loss: 0.7052599787712097 for ['[CLS] cum deserves shot towneral specialized satellite saw [SEP]']
[Init] best perm rec loss: 0.70352703332901 for ['[CLS] cum shot town satellite deserves saw specializederal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.103 (perp=8.660, rec=0.332, cos=0.039), tot_loss_proj:2.665 [t=0.17s]
prediction: ['[CLS] should cold slang should should shouldked. [SEP]']
[ 100/2000] tot_loss=2.371 (perp=10.318, rec=0.265, cos=0.043), tot_loss_proj:2.895 [t=0.17s]
prediction: ['[CLS] must should expected would should should leave oh [SEP]']
[ 150/2000] tot_loss=2.113 (perp=9.526, rec=0.191, cos=0.017), tot_loss_proj:2.828 [t=0.18s]
prediction: ['[CLS] we expected expected to should should leave she [SEP]']
[ 200/2000] tot_loss=2.147 (perp=9.615, rec=0.190, cos=0.034), tot_loss_proj:3.193 [t=0.19s]
prediction: ['[CLS] we him expected to should should leave she [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.741 (perp=7.944, rec=0.138, cos=0.015), tot_loss_proj:2.218 [t=0.18s]
prediction: ['[CLS] us expected him to should should leave him [SEP]']
[ 300/2000] tot_loss=1.720 (perp=7.944, rec=0.111, cos=0.020), tot_loss_proj:2.214 [t=0.17s]
prediction: ['[CLS] us expected him to should should leave him [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.724 (perp=7.944, rec=0.124, cos=0.011), tot_loss_proj:2.213 [t=0.19s]
prediction: ['[CLS] us expected him to should should leave him [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.705 (perp=7.944, rec=0.107, cos=0.009), tot_loss_proj:2.219 [t=0.17s]
prediction: ['[CLS] us expected him to should should leave him [SEP]']
[ 450/2000] tot_loss=2.243 (perp=7.944, rec=0.521, cos=0.133), tot_loss_proj:2.124 [t=0.17s]
prediction: ['[CLS] us expected him to should should leave him [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.874 (perp=8.126, rec=0.222, cos=0.028), tot_loss_proj:2.691 [t=0.17s]
prediction: ['[CLS] him expected us to leave should leave him [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.872 (perp=8.327, rec=0.186, cos=0.021), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] expected us to to him should leave him [SEP]']
[ 600/2000] tot_loss=1.839 (perp=8.327, rec=0.158, cos=0.015), tot_loss_proj:2.538 [t=0.17s]
prediction: ['[CLS] expected us to to him should leave him [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.564 (perp=7.039, rec=0.144, cos=0.013), tot_loss_proj:2.223 [t=0.17s]
prediction: ['[CLS] expected us to leave him should leave him [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.591 (perp=7.220, rec=0.136, cos=0.011), tot_loss_proj:2.217 [t=0.17s]
prediction: ['[CLS] expected us to leave them should leave him [SEP]']
[ 750/2000] tot_loss=1.578 (perp=7.220, rec=0.124, cos=0.010), tot_loss_proj:2.210 [t=0.17s]
prediction: ['[CLS] expected us to leave them should leave him [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.576 (perp=7.220, rec=0.123, cos=0.010), tot_loss_proj:2.214 [t=0.17s]
prediction: ['[CLS] expected us to leave them should leave him [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.579 (perp=7.220, rec=0.125, cos=0.009), tot_loss_proj:2.211 [t=0.17s]
prediction: ['[CLS] expected us to leave them should leave him [SEP]']
[ 900/2000] tot_loss=1.568 (perp=7.220, rec=0.115, cos=0.009), tot_loss_proj:2.219 [t=0.17s]
prediction: ['[CLS] expected us to leave them should leave him [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.540 (perp=7.087, rec=0.114, cos=0.008), tot_loss_proj:2.384 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1000/2000] tot_loss=1.535 (perp=7.087, rec=0.109, cos=0.009), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
[1050/2000] tot_loss=1.548 (perp=7.087, rec=0.123, cos=0.008), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1100/2000] tot_loss=1.530 (perp=7.087, rec=0.105, cos=0.008), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1150/2000] tot_loss=1.526 (perp=7.087, rec=0.100, cos=0.008), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
[1200/2000] tot_loss=1.532 (perp=7.087, rec=0.106, cos=0.008), tot_loss_proj:2.386 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1250/2000] tot_loss=1.535 (perp=7.087, rec=0.109, cos=0.008), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1300/2000] tot_loss=1.532 (perp=7.087, rec=0.106, cos=0.008), tot_loss_proj:2.381 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
[1350/2000] tot_loss=1.544 (perp=7.087, rec=0.118, cos=0.008), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1400/2000] tot_loss=1.537 (perp=7.087, rec=0.112, cos=0.008), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1450/2000] tot_loss=1.529 (perp=7.087, rec=0.103, cos=0.008), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
[1500/2000] tot_loss=1.534 (perp=7.087, rec=0.108, cos=0.008), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1550/2000] tot_loss=1.530 (perp=7.087, rec=0.104, cos=0.008), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1600/2000] tot_loss=1.543 (perp=7.087, rec=0.117, cos=0.008), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
[1650/2000] tot_loss=1.526 (perp=7.087, rec=0.101, cos=0.008), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1700/2000] tot_loss=1.530 (perp=7.087, rec=0.104, cos=0.008), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1750/2000] tot_loss=1.527 (perp=7.087, rec=0.102, cos=0.008), tot_loss_proj:2.395 [t=0.18s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
[1800/2000] tot_loss=1.537 (perp=7.087, rec=0.111, cos=0.008), tot_loss_proj:2.397 [t=0.18s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1850/2000] tot_loss=1.537 (perp=7.087, rec=0.112, cos=0.008), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[1900/2000] tot_loss=1.520 (perp=7.087, rec=0.095, cos=0.008), tot_loss_proj:2.385 [t=0.21s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
[1950/2000] tot_loss=1.529 (perp=7.087, rec=0.103, cos=0.008), tot_loss_proj:2.394 [t=0.22s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Attempt swap
[2000/2000] tot_loss=1.538 (perp=7.087, rec=0.113, cos=0.008), tot_loss_proj:2.392 [t=0.19s]
prediction: ['[CLS] expected us to leave they should leave him [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] they expected us to should leave him. [SEP]
========================
predicted: 
========================
[CLS] expected us to leave they should leave him [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 82.963 | p: 82.845 | r: 83.312
rouge2     | fm: 34.643 | p: 34.450 | r: 34.935
rougeL     | fm: 66.764 | p: 66.600 | r: 67.141
rougeLsum  | fm: 66.904 | p: 66.708 | r: 67.286
r1fm+r2fm = 117.606

input #58 time: 0:07:21 | total time: 7:08:37


Running input #59 of 100.
reference: 
========================
Mr Woodhouse sat in an armchair.
========================
average of cosine similarity 0.999401123526773
highest_index [0]
highest [0.999401123526773]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2720,  3536,  4580,  2938,  1999,  2019, 29372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[Init] best rec loss: 1.0133568048477173 for ['[CLS] zero treasurer kennedy vet when le bronze plans [SEP]']
[Init] best rec loss: 0.9783481359481812 for ['[CLS] greenbis wa ant chamber disks distinguishednine [SEP]']
[Init] best rec loss: 0.9641304016113281 for ['[CLS] geraldine draft side everythingion lack hamlet react [SEP]']
[Init] best rec loss: 0.9588362574577332 for ['[CLS] poll citizen heads chapter nor giants alec cinder [SEP]']
[Init] best rec loss: 0.9540868997573853 for ['[CLS] survivors tend bounce visitors guessed nomination miles independence [SEP]']
[Init] best rec loss: 0.9535396099090576 for ['[CLS] jaw sega indians no dug columbia tribe throughout [SEP]']
[Init] best perm rec loss: 0.9530171751976013 for ['[CLS] tribe throughout jaw sega dug columbia indians no [SEP]']
[Init] best perm rec loss: 0.9528425931930542 for ['[CLS] jaw tribe throughout sega columbia indians no dug [SEP]']
[Init] best perm rec loss: 0.9518237709999084 for ['[CLS] dug indians sega jaw columbia throughout tribe no [SEP]']
[Init] best perm rec loss: 0.9487836956977844 for ['[CLS] sega indians tribe dug jaw columbia no throughout [SEP]']
[Init] best perm rec loss: 0.9484539031982422 for ['[CLS] jaw dug throughout indians columbia no tribe sega [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.854 (perp=12.052, rec=0.385, cos=0.059), tot_loss_proj:4.198 [t=0.17s]
prediction: ['[CLS] cowboy found at of douglas mrhaven lagos [SEP]']
[ 100/2000] tot_loss=2.916 (perp=12.563, rec=0.349, cos=0.054), tot_loss_proj:4.471 [t=0.17s]
prediction: ['[CLS] mr sat ( cake douglas mr lose lagos [SEP]']
[ 150/2000] tot_loss=2.437 (perp=11.030, rec=0.215, cos=0.017), tot_loss_proj:4.017 [t=0.17s]
prediction: ['[CLS] mr sat wood sat douglas mr in ode [SEP]']
[ 200/2000] tot_loss=2.304 (perp=10.668, rec=0.162, cos=0.008), tot_loss_proj:4.148 [t=0.17s]
prediction: ['[CLS] mr armchair wood sathouse mr armchair of [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.718 (perp=7.827, rec=0.147, cos=0.006), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] mr armchair woodhouse sat mr armchair. [SEP]']
[ 300/2000] tot_loss=1.841 (perp=8.639, rec=0.110, cos=0.004), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS] mr armchair woodhouse sat mr in. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.597 (perp=7.462, rec=0.100, cos=0.004), tot_loss_proj:3.493 [t=0.17s]
prediction: ['[CLS] mr armchair woodhouse sat in mr. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.371 (perp=6.394, rec=0.088, cos=0.004), tot_loss_proj:2.915 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
[ 450/2000] tot_loss=1.378 (perp=6.394, rec=0.096, cos=0.003), tot_loss_proj:2.913 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.358 (perp=6.394, rec=0.076, cos=0.003), tot_loss_proj:2.908 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.368 (perp=6.394, rec=0.085, cos=0.004), tot_loss_proj:2.912 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
[ 600/2000] tot_loss=1.357 (perp=6.394, rec=0.075, cos=0.003), tot_loss_proj:2.912 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.365 (perp=6.394, rec=0.083, cos=0.003), tot_loss_proj:2.909 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.364 (perp=6.394, rec=0.082, cos=0.003), tot_loss_proj:2.911 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
[ 750/2000] tot_loss=1.367 (perp=6.394, rec=0.085, cos=0.003), tot_loss_proj:2.909 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.357 (perp=6.394, rec=0.075, cos=0.003), tot_loss_proj:2.907 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.357 (perp=6.394, rec=0.075, cos=0.003), tot_loss_proj:2.906 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
[ 900/2000] tot_loss=1.363 (perp=6.394, rec=0.082, cos=0.003), tot_loss_proj:2.910 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in mr armchair. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.567 (perp=7.433, rec=0.077, cos=0.003), tot_loss_proj:3.439 [t=0.17s]
prediction: ['[CLS] an woodhouse sat in mr armchair. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.155 (perp=5.368, rec=0.078, cos=0.003), tot_loss_proj:1.310 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[1050/2000] tot_loss=1.144 (perp=5.368, rec=0.067, cos=0.003), tot_loss_proj:1.312 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.155 (perp=5.368, rec=0.078, cos=0.003), tot_loss_proj:1.310 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.145 (perp=5.368, rec=0.068, cos=0.003), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[1200/2000] tot_loss=1.140 (perp=5.368, rec=0.063, cos=0.003), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.145 (perp=5.368, rec=0.069, cos=0.003), tot_loss_proj:1.311 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.140 (perp=5.368, rec=0.063, cos=0.003), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[1350/2000] tot_loss=1.143 (perp=5.368, rec=0.066, cos=0.003), tot_loss_proj:1.304 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.138 (perp=5.368, rec=0.061, cos=0.003), tot_loss_proj:1.305 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.153 (perp=5.368, rec=0.077, cos=0.003), tot_loss_proj:1.311 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[1500/2000] tot_loss=1.151 (perp=5.368, rec=0.074, cos=0.003), tot_loss_proj:1.316 [t=0.17s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.150 (perp=5.368, rec=0.074, cos=0.003), tot_loss_proj:1.309 [t=0.21s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.143 (perp=5.368, rec=0.067, cos=0.003), tot_loss_proj:1.318 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[1650/2000] tot_loss=1.153 (perp=5.368, rec=0.076, cos=0.003), tot_loss_proj:1.313 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.149 (perp=5.368, rec=0.072, cos=0.003), tot_loss_proj:1.306 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.146 (perp=5.368, rec=0.069, cos=0.003), tot_loss_proj:1.317 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[1800/2000] tot_loss=1.142 (perp=5.368, rec=0.065, cos=0.003), tot_loss_proj:1.303 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.146 (perp=5.368, rec=0.069, cos=0.003), tot_loss_proj:1.309 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.144 (perp=5.368, rec=0.067, cos=0.003), tot_loss_proj:1.314 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[1950/2000] tot_loss=1.141 (perp=5.368, rec=0.065, cos=0.003), tot_loss_proj:1.313 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.150 (perp=5.368, rec=0.073, cos=0.003), tot_loss_proj:1.313 [t=0.18s]
prediction: ['[CLS] mr woodhouse sat in an armchair. [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] mr woodhouse sat in an armchair. [SEP]
========================
predicted: 
========================
[CLS] mr woodhouse sat in an armchair. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.252 | p: 83.093 | r: 83.694
rouge2     | fm: 35.643 | p: 35.472 | r: 35.950
rougeL     | fm: 67.331 | p: 67.139 | r: 67.737
rougeLsum  | fm: 67.361 | p: 67.202 | r: 67.751
r1fm+r2fm = 118.895

input #59 time: 0:07:27 | total time: 7:16:05


Running input #60 of 100.
reference: 
========================
It is likely that Jean left.
========================
average of cosine similarity 0.9994653435805758
highest_index [0]
highest [0.9994653435805758]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2009, 2003, 3497, 2008, 3744, 2187, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] it is likely that jean left. [SEP]']
[Init] best rec loss: 1.0610324144363403 for ['[CLS]ach called vision sea age include wren [SEP]']
[Init] best rec loss: 0.9535291790962219 for ['[CLS] blue returnedisen within zur immediateores [SEP]']
[Init] best rec loss: 0.9524242281913757 for ['[CLS] threw presley dependent state safetyending hood [SEP]']
[Init] best rec loss: 0.9489620923995972 for ['[CLS] hazardous least thumbs politically play w contrast [SEP]']
[Init] best rec loss: 0.9254016876220703 for ['[CLS] knight cass labor force cap inspiration time [SEP]']
[Init] best perm rec loss: 0.9237791299819946 for ['[CLS] time cap labor inspiration knight cass force [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.555 (perp=10.323, rec=0.637, cos=0.854), tot_loss_proj:3.949 [t=0.17s]
prediction: ['[CLS] jean chan for girlfriend likely " meant [SEP]']
[ 100/2000] tot_loss=3.833 (perp=11.711, rec=0.599, cos=0.892), tot_loss_proj:4.016 [t=0.17s]
prediction: ['[CLS] jean estonia found feminist likely apparent likely [SEP]']
[ 150/2000] tot_loss=2.657 (perp=11.332, rec=0.352, cos=0.039), tot_loss_proj:4.030 [t=0.18s]
prediction: ['[CLS] jean flight maybe probably left? likely [SEP]']
[ 200/2000] tot_loss=2.344 (perp=10.616, rec=0.209, cos=0.012), tot_loss_proj:3.807 [t=0.17s]
prediction: ['[CLS] jean call jean likely left likely likely [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.351 (perp=10.901, rec=0.160, cos=0.011), tot_loss_proj:4.001 [t=0.18s]
prediction: ['[CLS] jean wing jean it likely likely left [SEP]']
[ 300/2000] tot_loss=1.818 (perp=8.477, rec=0.117, cos=0.006), tot_loss_proj:3.413 [t=0.18s]
prediction: ['[CLS] jean wing. is likely that left [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.071 (perp=9.262, rec=0.206, cos=0.012), tot_loss_proj:3.559 [t=0.19s]
prediction: ['[CLS] jean jean is likely that left crambidae [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.930 (perp=8.768, rec=0.167, cos=0.009), tot_loss_proj:3.500 [t=0.19s]
prediction: ['[CLS] jeanoured is likely that left jean [SEP]']
[ 450/2000] tot_loss=1.905 (perp=8.768, rec=0.144, cos=0.008), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] jeanoured is likely that left jean [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.902 (perp=8.797, rec=0.135, cos=0.007), tot_loss_proj:3.466 [t=0.17s]
prediction: ['[CLS] reign jean is likely that left jean [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.832 (perp=8.464, rec=0.132, cos=0.007), tot_loss_proj:3.419 [t=0.17s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
[ 600/2000] tot_loss=1.832 (perp=8.464, rec=0.133, cos=0.006), tot_loss_proj:3.418 [t=0.17s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.819 (perp=8.464, rec=0.120, cos=0.006), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.814 (perp=8.464, rec=0.116, cos=0.006), tot_loss_proj:3.418 [t=0.17s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
[ 750/2000] tot_loss=1.812 (perp=8.464, rec=0.113, cos=0.006), tot_loss_proj:3.418 [t=0.17s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.808 (perp=8.464, rec=0.109, cos=0.006), tot_loss_proj:3.414 [t=0.17s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.809 (perp=8.464, rec=0.111, cos=0.006), tot_loss_proj:3.415 [t=0.17s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
[ 900/2000] tot_loss=1.805 (perp=8.464, rec=0.107, cos=0.005), tot_loss_proj:3.419 [t=0.17s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.798 (perp=8.464, rec=0.100, cos=0.005), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
Attempt swap
[1000/2000] tot_loss=1.804 (perp=8.464, rec=0.106, cos=0.005), tot_loss_proj:3.420 [t=0.19s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
[1050/2000] tot_loss=1.798 (perp=8.464, rec=0.100, cos=0.005), tot_loss_proj:3.415 [t=0.19s]
prediction: ['[CLS] jean reign is likely that left jean [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.686 (perp=7.829, rec=0.114, cos=0.006), tot_loss_proj:3.303 [t=0.19s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1150/2000] tot_loss=1.680 (perp=7.829, rec=0.108, cos=0.006), tot_loss_proj:3.301 [t=0.19s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
[1200/2000] tot_loss=1.678 (perp=7.829, rec=0.107, cos=0.005), tot_loss_proj:3.305 [t=0.19s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1250/2000] tot_loss=1.678 (perp=7.829, rec=0.107, cos=0.005), tot_loss_proj:3.305 [t=0.19s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=7.829, rec=0.103, cos=0.005), tot_loss_proj:3.300 [t=0.17s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
[1350/2000] tot_loss=1.668 (perp=7.829, rec=0.097, cos=0.005), tot_loss_proj:3.304 [t=0.17s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1400/2000] tot_loss=1.676 (perp=7.829, rec=0.105, cos=0.005), tot_loss_proj:3.306 [t=0.21s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1450/2000] tot_loss=1.669 (perp=7.829, rec=0.098, cos=0.005), tot_loss_proj:3.306 [t=0.17s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
[1500/2000] tot_loss=1.674 (perp=7.829, rec=0.103, cos=0.005), tot_loss_proj:3.302 [t=0.17s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1550/2000] tot_loss=1.681 (perp=7.829, rec=0.110, cos=0.005), tot_loss_proj:3.303 [t=0.17s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1600/2000] tot_loss=1.668 (perp=7.829, rec=0.097, cos=0.005), tot_loss_proj:3.308 [t=0.19s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
[1650/2000] tot_loss=1.667 (perp=7.829, rec=0.096, cos=0.005), tot_loss_proj:3.300 [t=0.17s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1700/2000] tot_loss=1.669 (perp=7.829, rec=0.098, cos=0.005), tot_loss_proj:3.304 [t=0.17s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1750/2000] tot_loss=1.672 (perp=7.829, rec=0.101, cos=0.005), tot_loss_proj:3.304 [t=0.19s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
[1800/2000] tot_loss=1.671 (perp=7.829, rec=0.101, cos=0.005), tot_loss_proj:3.305 [t=0.17s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1850/2000] tot_loss=1.674 (perp=7.829, rec=0.103, cos=0.005), tot_loss_proj:3.307 [t=0.17s]
prediction: ['[CLS] jean reign is likely that jean left [SEP]']
Attempt swap
[1900/2000] tot_loss=1.698 (perp=7.968, rec=0.100, cos=0.005), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] jean! is likely that jean left [SEP]']
[1950/2000] tot_loss=1.698 (perp=7.968, rec=0.099, cos=0.005), tot_loss_proj:3.586 [t=0.19s]
prediction: ['[CLS] jean! is likely that jean left [SEP]']
Attempt swap
[2000/2000] tot_loss=1.695 (perp=7.968, rec=0.096, cos=0.005), tot_loss_proj:3.585 [t=0.17s]
prediction: ['[CLS] jean! is likely that jean left [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] it is likely that jean left. [SEP]
========================
predicted: 
========================
[CLS] jean reign is likely that jean left [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 66.667 | p: 62.500 | r: 71.429
rougeL     | fm: 82.353 | p: 77.778 | r: 87.500
rougeLsum  | fm: 82.353 | p: 77.778 | r: 87.500
r1fm+r2fm = 149.020

[Aggregate metrics]:
rouge1     | fm: 83.132 | p: 82.937 | r: 83.680
rouge2     | fm: 36.203 | p: 35.962 | r: 36.564
rougeL     | fm: 67.621 | p: 67.380 | r: 68.088
rougeLsum  | fm: 67.630 | p: 67.460 | r: 68.036
r1fm+r2fm = 119.335

input #60 time: 0:07:44 | total time: 7:23:49


Running input #61 of 100.
reference: 
========================
Physicists like yourself are a godsend.
========================
average of cosine similarity 0.9993168200569027
highest_index [0]
highest [0.9993168200569027]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 13702,  2015,  2066,  4426,  2024,  1037,  5932, 10497,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] physicists like yourself are a godsend. [SEP]']
[Init] best rec loss: 0.9368430376052856 for ['[CLS]serromatic rescue object morning which viable for seeking [SEP]']
[Init] best rec loss: 0.9271156191825867 for ['[CLS] realmsᵇ group mac en whoever " administrator canvas [SEP]']
[Init] best rec loss: 0.9082102179527283 for ['[CLS] bombardment symptoms ul memorial were worked gray haiti know [SEP]']
[Init] best rec loss: 0.9022470712661743 for ['[CLS] fixed commissioner manual church off stem pickup lips austin [SEP]']
[Init] best rec loss: 0.8885534405708313 for ['[CLS] first parental bill julius orthodox thank orson what knock [SEP]']
[Init] best perm rec loss: 0.8879454731941223 for ['[CLS] orson knock first thank julius bill parental what orthodox [SEP]']
[Init] best perm rec loss: 0.8876521587371826 for ['[CLS] parental what julius knock bill orthodox first thank orson [SEP]']
[Init] best perm rec loss: 0.8857608437538147 for ['[CLS] knock bill thank parental julius orthodox orson first what [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.673 (perp=10.734, rec=0.463, cos=0.063), tot_loss_proj:4.059 [t=0.17s]
prediction: ['[CLS] witches. themselves before liszt manually think residential myself [SEP]']
[ 100/2000] tot_loss=2.697 (perp=11.806, rec=0.309, cos=0.028), tot_loss_proj:4.241 [t=0.17s]
prediction: ['[CLS] physicist yourself mormon like yourselfign were tracy myself [SEP]']
[ 150/2000] tot_loss=2.190 (perp=9.313, rec=0.299, cos=0.028), tot_loss_proj:3.735 [t=0.17s]
prediction: ['[CLS] physicist yourselfin like himself like are episodes myself [SEP]']
[ 200/2000] tot_loss=2.467 (perp=9.503, rec=0.490, cos=0.076), tot_loss_proj:3.820 [t=0.17s]
prediction: ['[CLS] physicist your brilliance like stuff like are, point [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.595 (perp=10.653, rec=0.400, cos=0.064), tot_loss_proj:4.014 [t=0.21s]
prediction: ['[CLS] physicist your you like himself are likeoy grand [SEP]']
[ 300/2000] tot_loss=2.531 (perp=10.944, rec=0.316, cos=0.026), tot_loss_proj:4.093 [t=0.20s]
prediction: ['[CLS] physicist your your like yourself are likeoy signal [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.280 (perp=9.623, rec=0.336, cos=0.020), tot_loss_proj:3.915 [t=0.17s]
prediction: ['[CLS] your physicist yourself like yourself are likeas signal [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.816 (perp=7.302, rec=0.326, cos=0.030), tot_loss_proj:3.535 [t=0.17s]
prediction: ['[CLS] your physicists like science are like yourself imagine [SEP]']
[ 450/2000] tot_loss=1.917 (perp=8.172, rec=0.265, cos=0.018), tot_loss_proj:3.605 [t=0.17s]
prediction: ['[CLS] yourself physicists like science are like yourself gods [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.858 (perp=8.103, rec=0.220, cos=0.017), tot_loss_proj:3.610 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are likelous gods [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.883 (perp=8.391, rec=0.191, cos=0.014), tot_loss_proj:3.639 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are thoselous gods [SEP]']
[ 600/2000] tot_loss=1.865 (perp=8.391, rec=0.175, cos=0.012), tot_loss_proj:3.645 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are thoselous gods [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.145 (perp=8.889, rec=0.296, cos=0.072), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself areslous gods [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.955 (perp=8.822, rec=0.177, cos=0.013), tot_loss_proj:3.703 [t=0.18s]
prediction: ['[CLS] yourself physicists like yourself areendlous gods [SEP]']
[ 750/2000] tot_loss=1.932 (perp=8.822, rec=0.157, cos=0.011), tot_loss_proj:3.697 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself areendlous gods [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.923 (perp=8.822, rec=0.148, cos=0.010), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself areendlous gods [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.824 (perp=8.214, rec=0.163, cos=0.018), tot_loss_proj:3.605 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
[ 900/2000] tot_loss=1.796 (perp=8.214, rec=0.144, cos=0.010), tot_loss_proj:3.606 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.794 (perp=8.214, rec=0.142, cos=0.009), tot_loss_proj:3.608 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.795 (perp=8.214, rec=0.144, cos=0.008), tot_loss_proj:3.605 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
[1050/2000] tot_loss=1.786 (perp=8.214, rec=0.135, cos=0.008), tot_loss_proj:3.602 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.793 (perp=8.214, rec=0.142, cos=0.008), tot_loss_proj:3.609 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.786 (perp=8.214, rec=0.136, cos=0.007), tot_loss_proj:3.609 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
[1200/2000] tot_loss=1.792 (perp=8.214, rec=0.142, cos=0.007), tot_loss_proj:3.603 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.779 (perp=8.214, rec=0.129, cos=0.007), tot_loss_proj:3.604 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.778 (perp=8.214, rec=0.128, cos=0.007), tot_loss_proj:3.609 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
[1350/2000] tot_loss=1.773 (perp=8.214, rec=0.123, cos=0.007), tot_loss_proj:3.602 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsendlous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.793 (perp=8.248, rec=0.137, cos=0.007), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
Attempt swap
[1450/2000] tot_loss=1.783 (perp=8.248, rec=0.126, cos=0.007), tot_loss_proj:3.542 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
[1500/2000] tot_loss=1.785 (perp=8.248, rec=0.128, cos=0.007), tot_loss_proj:3.543 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
Attempt swap
[1550/2000] tot_loss=1.778 (perp=8.248, rec=0.122, cos=0.007), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
Attempt swap
[1600/2000] tot_loss=1.789 (perp=8.248, rec=0.132, cos=0.007), tot_loss_proj:3.538 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
[1650/2000] tot_loss=1.775 (perp=8.248, rec=0.118, cos=0.006), tot_loss_proj:3.549 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
Attempt swap
[1700/2000] tot_loss=1.791 (perp=8.248, rec=0.134, cos=0.006), tot_loss_proj:3.541 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
Attempt swap
[1750/2000] tot_loss=1.784 (perp=8.248, rec=0.128, cos=0.006), tot_loss_proj:3.544 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
[1800/2000] tot_loss=1.781 (perp=8.248, rec=0.125, cos=0.006), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
Attempt swap
[1850/2000] tot_loss=1.776 (perp=8.248, rec=0.120, cos=0.006), tot_loss_proj:3.544 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
Attempt swap
[1900/2000] tot_loss=1.778 (perp=8.248, rec=0.122, cos=0.006), tot_loss_proj:3.542 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
[1950/2000] tot_loss=1.785 (perp=8.248, rec=0.130, cos=0.006), tot_loss_proj:3.541 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
Attempt swap
[2000/2000] tot_loss=1.783 (perp=8.248, rec=0.127, cos=0.006), tot_loss_proj:3.543 [t=0.17s]
prediction: ['[CLS] yourself physicists like yourself are godsend yourself [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS] physicists like yourself are a godsend. [SEP]
========================
predicted: 
========================
[CLS] yourself physicists like yourself are godsend yourself [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 40.000 | p: 37.500 | r: 42.857
rougeL     | fm: 82.353 | p: 77.778 | r: 87.500
rougeLsum  | fm: 82.353 | p: 77.778 | r: 87.500
r1fm+r2fm = 122.353

[Aggregate metrics]:
rouge1     | fm: 83.244 | p: 82.901 | r: 83.871
rouge2     | fm: 36.237 | p: 35.991 | r: 36.580
rougeL     | fm: 67.754 | p: 67.454 | r: 68.271
rougeLsum  | fm: 67.844 | p: 67.530 | r: 68.424
r1fm+r2fm = 119.482

input #61 time: 0:07:44 | total time: 7:31:34


Running input #62 of 100.
reference: 
========================
Any pilot could be flying this plane.
========================
average of cosine similarity 0.9994980007326446
highest_index [0]
highest [0.9994980007326446]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2151, 4405, 2071, 2022, 3909, 2023, 4946, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] any pilot could be flying this plane. [SEP]']
[Init] best rec loss: 0.9977968335151672 for ['[CLS] events heat names cole issue. 505 regina [SEP]']
[Init] best rec loss: 0.9175378084182739 for ['[CLS] from actress le testament sooner pit confederacy oct [SEP]']
[Init] best rec loss: 0.8922759890556335 for ['[CLS]liest into holding complained discovery sutherland coast fork [SEP]']
[Init] best rec loss: 0.8342140913009644 for ['[CLS] reader leagues english our place guestfire mad [SEP]']
[Init] best perm rec loss: 0.8291640281677246 for ['[CLS] mad place englishfire our guest leagues reader [SEP]']
[Init] best perm rec loss: 0.8275080919265747 for ['[CLS] guest reader english place mad leagues ourfire [SEP]']
[Init] best perm rec loss: 0.824095606803894 for ['[CLS]fire guest english leagues mad our reader place [SEP]']
[Init] best perm rec loss: 0.823464035987854 for ['[CLS] mad guestfire leagues reader our english place [SEP]']
[Init] best perm rec loss: 0.8207629323005676 for ['[CLS] our readerfire mad guest leagues place english [SEP]']
[Init] best perm rec loss: 0.8206089735031128 for ['[CLS]fire guest mad our reader leagues place english [SEP]']
[Init] best perm rec loss: 0.8204890489578247 for ['[CLS] reader guest english leaguesfire our place mad [SEP]']
[Init] best perm rec loss: 0.8204536437988281 for ['[CLS] reader leagues english guest our place madfire [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.388 (perp=12.461, rec=0.634, cos=0.262), tot_loss_proj:4.421 [t=0.17s]
prediction: ['[CLS] if equestrian closet vampire! hollywood portuguesed [SEP]']
[ 100/2000] tot_loss=2.998 (perp=11.983, rec=0.443, cos=0.158), tot_loss_proj:4.325 [t=0.17s]
prediction: ['[CLS] if and bedroom vampire service hollywoodnifiedd [SEP]']
[ 150/2000] tot_loss=2.808 (perp=11.700, rec=0.372, cos=0.096), tot_loss_proj:4.276 [t=0.17s]
prediction: ['[CLS] if. were softly service...nifiedd [SEP]']
[ 200/2000] tot_loss=2.759 (perp=11.700, rec=0.347, cos=0.072), tot_loss_proj:4.277 [t=0.17s]
prediction: ['[CLS] if. were softly service...nifiedd [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.661 (perp=11.518, rec=0.308, cos=0.049), tot_loss_proj:4.241 [t=0.19s]
prediction: ['[CLS] anyone. could truck... softlynifiedd [SEP]']
[ 300/2000] tot_loss=2.250 (perp=9.745, rec=0.265, cos=0.037), tot_loss_proj:3.962 [t=0.17s]
prediction: ['[CLS] any. could truck.... babyd [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.483 (perp=10.592, rec=0.312, cos=0.053), tot_loss_proj:4.064 [t=0.17s]
prediction: ['[CLS] any transportation could - sea... babyd [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.424 (perp=10.607, rec=0.272, cos=0.031), tot_loss_proj:4.093 [t=0.17s]
prediction: ['[CLS] any plane could....¨ babyd [SEP]']
[ 450/2000] tot_loss=2.412 (perp=10.764, rec=0.235, cos=0.024), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] any plane could..¨ discod [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.228 (perp=9.713, rec=0.252, cos=0.034), tot_loss_proj:3.862 [t=0.17s]
prediction: ['[CLS] any plane₂. on could concreted [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.085 (perp=9.156, rec=0.230, cos=0.025), tot_loss_proj:3.812 [t=0.20s]
prediction: ['[CLS] any plane could₂. flying thesed [SEP]']
[ 600/2000] tot_loss=1.970 (perp=8.682, rec=0.213, cos=0.021), tot_loss_proj:3.716 [t=0.17s]
prediction: ['[CLS] any pilot could₂. flying thisd [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.823 (perp=7.965, rec=0.211, cos=0.020), tot_loss_proj:3.514 [t=0.18s]
prediction: ['[CLS] any flying pilot could₂. thisd [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.804 (perp=7.965, rec=0.195, cos=0.016), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS] any flying pilot could₂. thisd [SEP]']
[ 750/2000] tot_loss=1.800 (perp=7.965, rec=0.193, cos=0.014), tot_loss_proj:3.509 [t=0.17s]
prediction: ['[CLS] any flying pilot could₂. thisd [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.787 (perp=7.965, rec=0.181, cos=0.013), tot_loss_proj:3.508 [t=0.18s]
prediction: ['[CLS] any flying pilot could₂. thisd [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.774 (perp=7.965, rec=0.168, cos=0.013), tot_loss_proj:3.505 [t=0.18s]
prediction: ['[CLS] any flying pilot could₂. thisd [SEP]']
[ 900/2000] tot_loss=1.831 (perp=8.223, rec=0.174, cos=0.012), tot_loss_proj:3.587 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisd [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.823 (perp=8.223, rec=0.167, cos=0.012), tot_loss_proj:3.586 [t=0.18s]
prediction: ['[CLS] any plane pilot could₂. thisd [SEP]']
Attempt swap
[1000/2000] tot_loss=1.813 (perp=8.223, rec=0.157, cos=0.011), tot_loss_proj:3.586 [t=0.18s]
prediction: ['[CLS] any plane pilot could₂. thisd [SEP]']
[1050/2000] tot_loss=1.819 (perp=8.223, rec=0.163, cos=0.011), tot_loss_proj:3.582 [t=0.18s]
prediction: ['[CLS] any plane pilot could₂. thisd [SEP]']
Attempt swap
[1100/2000] tot_loss=1.803 (perp=8.223, rec=0.147, cos=0.011), tot_loss_proj:3.589 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisd [SEP]']
Attempt swap
[1150/2000] tot_loss=1.810 (perp=8.223, rec=0.154, cos=0.011), tot_loss_proj:3.589 [t=0.18s]
prediction: ['[CLS] any plane pilot could₂. thisd [SEP]']
[1200/2000] tot_loss=1.814 (perp=8.223, rec=0.159, cos=0.011), tot_loss_proj:3.589 [t=0.18s]
prediction: ['[CLS] any plane pilot could₂. thisd [SEP]']
Attempt swap
[1250/2000] tot_loss=1.810 (perp=8.223, rec=0.155, cos=0.010), tot_loss_proj:3.589 [t=0.18s]
prediction: ['[CLS] any plane pilot could₂. thisd [SEP]']
Attempt swap
[1300/2000] tot_loss=1.734 (perp=7.826, rec=0.159, cos=0.010), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
[1350/2000] tot_loss=1.736 (perp=7.826, rec=0.161, cos=0.010), tot_loss_proj:3.504 [t=0.18s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.727 (perp=7.826, rec=0.151, cos=0.010), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.722 (perp=7.826, rec=0.147, cos=0.010), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
[1500/2000] tot_loss=1.726 (perp=7.826, rec=0.150, cos=0.010), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.716 (perp=7.826, rec=0.141, cos=0.010), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.721 (perp=7.826, rec=0.146, cos=0.010), tot_loss_proj:3.508 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
[1650/2000] tot_loss=1.725 (perp=7.826, rec=0.150, cos=0.010), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.713 (perp=7.826, rec=0.138, cos=0.010), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.727 (perp=7.826, rec=0.151, cos=0.010), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
[1800/2000] tot_loss=1.716 (perp=7.826, rec=0.141, cos=0.010), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.716 (perp=7.826, rec=0.141, cos=0.010), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.723 (perp=7.826, rec=0.148, cos=0.010), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
[1950/2000] tot_loss=1.714 (perp=7.826, rec=0.139, cos=0.010), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.720 (perp=7.826, rec=0.144, cos=0.010), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] any plane pilot could₂. thisy [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] any pilot could be flying this plane. [SEP]
========================
predicted: 
========================
[CLS] any plane pilot could₂. thisy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 85.714 | r: 66.667
rouge2     | fm: 28.571 | p: 33.333 | r: 25.000
rougeL     | fm: 62.500 | p: 71.429 | r: 55.556
rougeLsum  | fm: 62.500 | p: 71.429 | r: 55.556
r1fm+r2fm = 103.571

[Aggregate metrics]:
rouge1     | fm: 83.170 | p: 83.020 | r: 83.622
rouge2     | fm: 36.175 | p: 36.014 | r: 36.417
rougeL     | fm: 67.685 | p: 67.532 | r: 68.117
rougeLsum  | fm: 67.760 | p: 67.641 | r: 68.160
r1fm+r2fm = 119.346

input #62 time: 0:07:10 | total time: 7:38:45


Running input #63 of 100.
reference: 
========================
We wonder if Bill left.
========================
average of cosine similarity 0.9993481792856471
highest_index [0]
highest [0.9993481792856471]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2057, 4687, 2065, 3021, 2187, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] we wonder if bill left. [SEP]']
[Init] best rec loss: 0.9412387609481812 for ['[CLS] affected maine effect streets studies its [SEP]']
[Init] best rec loss: 0.9324620366096497 for ['[CLS]creen past effortwn can pier [SEP]']
[Init] best rec loss: 0.9266335964202881 for ['[CLS]ining strata won suitedtis near [SEP]']
[Init] best rec loss: 0.8718317747116089 for ['[CLS] threatsης roman randy loganicative [SEP]']
[Init] best rec loss: 0.8663002848625183 for ['[CLS] fis project of somecoming elf [SEP]']
[Init] best perm rec loss: 0.8493537902832031 for ['[CLS] elf project somecoming of fis [SEP]']
[Init] best perm rec loss: 0.848770797252655 for ['[CLS] of some elf projectcoming fis [SEP]']
[Init] best perm rec loss: 0.8487182259559631 for ['[CLS] elfcoming some project of fis [SEP]']
[Init] best perm rec loss: 0.8484838008880615 for ['[CLS] elf some fis of projectcoming [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.252 (perp=12.751, rec=0.512, cos=0.190), tot_loss_proj:4.424 [t=0.19s]
prediction: ['[CLS] pierre classic jordan father moment movie [SEP]']
[ 100/2000] tot_loss=2.785 (perp=10.955, rec=0.482, cos=0.111), tot_loss_proj:4.028 [t=0.20s]
prediction: ['[CLS] we we bill father roll rear [SEP]']
[ 150/2000] tot_loss=2.694 (perp=11.017, rec=0.424, cos=0.067), tot_loss_proj:3.988 [t=0.17s]
prediction: ['[CLS] we declined bill where roll script [SEP]']
[ 200/2000] tot_loss=2.251 (perp=9.297, rec=0.345, cos=0.046), tot_loss_proj:3.689 [t=0.17s]
prediction: ['[CLS] we wonder bill if bill shudder [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.013 (perp=8.177, rec=0.332, cos=0.046), tot_loss_proj:3.463 [t=0.19s]
prediction: ['[CLS] we wonder if bill bill wondering [SEP]']
[ 300/2000] tot_loss=1.991 (perp=8.088, rec=0.343, cos=0.030), tot_loss_proj:3.455 [t=0.19s]
prediction: ['[CLS] we wonder if bill bill wonder [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.904 (perp=8.088, rec=0.261, cos=0.026), tot_loss_proj:3.455 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill wonder [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.861 (perp=8.088, rec=0.221, cos=0.022), tot_loss_proj:3.456 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill wonder [SEP]']
[ 450/2000] tot_loss=1.864 (perp=8.088, rec=0.227, cos=0.019), tot_loss_proj:3.456 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill wonder [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.850 (perp=8.088, rec=0.214, cos=0.018), tot_loss_proj:3.452 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill wonder [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.841 (perp=8.088, rec=0.201, cos=0.023), tot_loss_proj:3.453 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill wonder [SEP]']
[ 600/2000] tot_loss=1.814 (perp=8.088, rec=0.181, cos=0.016), tot_loss_proj:3.454 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill wonder [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.781 (perp=8.019, rec=0.164, cos=0.013), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.754 (perp=8.019, rec=0.139, cos=0.011), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
[ 750/2000] tot_loss=1.725 (perp=8.019, rec=0.114, cos=0.007), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.736 (perp=8.019, rec=0.125, cos=0.007), tot_loss_proj:3.502 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.728 (perp=8.019, rec=0.117, cos=0.007), tot_loss_proj:3.506 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
[ 900/2000] tot_loss=1.721 (perp=8.019, rec=0.110, cos=0.006), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.718 (perp=8.019, rec=0.108, cos=0.006), tot_loss_proj:3.499 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1000/2000] tot_loss=1.712 (perp=8.019, rec=0.102, cos=0.006), tot_loss_proj:3.504 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
[1050/2000] tot_loss=1.712 (perp=8.019, rec=0.102, cos=0.006), tot_loss_proj:3.510 [t=0.20s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1100/2000] tot_loss=1.710 (perp=8.019, rec=0.100, cos=0.006), tot_loss_proj:3.505 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1150/2000] tot_loss=1.716 (perp=8.019, rec=0.106, cos=0.006), tot_loss_proj:3.504 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
[1200/2000] tot_loss=1.705 (perp=8.019, rec=0.095, cos=0.006), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1250/2000] tot_loss=1.697 (perp=8.019, rec=0.087, cos=0.006), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1300/2000] tot_loss=1.709 (perp=8.019, rec=0.099, cos=0.006), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
[1350/2000] tot_loss=1.701 (perp=8.019, rec=0.091, cos=0.006), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1400/2000] tot_loss=1.711 (perp=8.019, rec=0.101, cos=0.006), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1450/2000] tot_loss=1.706 (perp=8.019, rec=0.096, cos=0.006), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
[1500/2000] tot_loss=1.712 (perp=8.019, rec=0.103, cos=0.006), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1550/2000] tot_loss=1.705 (perp=8.019, rec=0.095, cos=0.006), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1600/2000] tot_loss=1.706 (perp=8.019, rec=0.096, cos=0.006), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
[1650/2000] tot_loss=1.696 (perp=8.019, rec=0.086, cos=0.006), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1700/2000] tot_loss=1.705 (perp=8.019, rec=0.095, cos=0.006), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1750/2000] tot_loss=1.705 (perp=8.019, rec=0.095, cos=0.006), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
[1800/2000] tot_loss=1.709 (perp=8.019, rec=0.099, cos=0.006), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1850/2000] tot_loss=1.707 (perp=8.019, rec=0.097, cos=0.006), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[1900/2000] tot_loss=1.707 (perp=8.019, rec=0.097, cos=0.006), tot_loss_proj:3.508 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
[1950/2000] tot_loss=1.705 (perp=8.019, rec=0.095, cos=0.006), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Attempt swap
[2000/2000] tot_loss=1.705 (perp=8.019, rec=0.095, cos=0.006), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] we wonder if bill bill left [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] we wonder if bill left. [SEP]
========================
predicted: 
========================
[CLS] we wonder if bill bill left [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 92.308 | p: 85.714 | r: 100.000
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 185.641

[Aggregate metrics]:
rouge1     | fm: 83.187 | p: 82.982 | r: 83.809
rouge2     | fm: 37.053 | p: 36.738 | r: 37.592
rougeL     | fm: 68.110 | p: 67.939 | r: 68.622
rougeLsum  | fm: 68.261 | p: 67.966 | r: 68.700
r1fm+r2fm = 120.240

input #63 time: 0:07:11 | total time: 7:45:56


Running input #64 of 100.
reference: 
========================
Ellen talked with Helen about the problem.
========================
average of cosine similarity 0.9993768579649704
highest_index [0]
highest [0.9993768579649704]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9155, 5720, 2007, 6330, 2055, 1996, 3291, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] ellen talked with helen about the problem. [SEP]']
[Init] best rec loss: 1.0532675981521606 for ['[CLS] states gmina auction monument worthy than kennedy urban [SEP]']
[Init] best rec loss: 0.9713220000267029 for ['[CLS] dc partmona identity writer mary prime pool [SEP]']
[Init] best rec loss: 0.9620294570922852 for ['[CLS] me rough water diagnosed lanka numbered approved treatment [SEP]']
[Init] best rec loss: 0.955909788608551 for ['[CLS] king supporting sex dropping step emotional ave nodded [SEP]']
[Init] best rec loss: 0.9527767896652222 for ['[CLS] yards hospitals insteadware luis council evervc [SEP]']
[Init] best rec loss: 0.9495007991790771 for ['[CLS] caution h riding established science along usual julia [SEP]']
[Init] best rec loss: 0.9492765069007874 for ['[CLS] pistolsfc for german null express his aloud [SEP]']
[Init] best rec loss: 0.9482495784759521 for ['[CLS]yevenity cook viscount simon statpate lap [SEP]']
[Init] best rec loss: 0.9479407072067261 for ['[CLS] to valerietake hot gwen my cricketumen [SEP]']
[Init] best rec loss: 0.9380924105644226 for ['[CLS]ested static accounts credit anonymousey afternoon massachusetts [SEP]']
[Init] best perm rec loss: 0.9359466433525085 for ['[CLS] accounts staticested afternooney massachusetts anonymous credit [SEP]']
[Init] best perm rec loss: 0.9322394132614136 for ['[CLS]ey static afternoon anonymous creditested massachusetts accounts [SEP]']
[Init] best perm rec loss: 0.9310908913612366 for ['[CLS] static anonymous accountsested afternoon massachusettsey credit [SEP]']
[Init] best perm rec loss: 0.9301943778991699 for ['[CLS]ested afternoon static anonymousey accounts massachusetts credit [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.908 (perp=12.522, rec=0.628, cos=0.776), tot_loss_proj:4.352 [t=0.17s]
prediction: ['[CLS] ) beside bram headquarters without kincaid found real [SEP]']
[ 100/2000] tot_loss=3.891 (perp=12.646, rec=0.576, cos=0.785), tot_loss_proj:4.437 [t=0.17s]
prediction: ['[CLS] :ʔ cells serious without helen have didn [SEP]']
[ 150/2000] tot_loss=3.841 (perp=11.558, rec=0.617, cos=0.913), tot_loss_proj:4.367 [t=0.17s]
prediction: ['[CLS] springerŋ. ellen without helen about icon [SEP]']
[ 200/2000] tot_loss=2.906 (perp=12.196, rec=0.398, cos=0.069), tot_loss_proj:4.360 [t=0.17s]
prediction: ['[CLS] springerfied helen ellen talkedative maggie some [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.827 (perp=12.893, rec=0.238, cos=0.011), tot_loss_proj:4.602 [t=0.18s]
prediction: ['[CLS] helen problem ellen ellen talked problem talk five [SEP]']
[ 300/2000] tot_loss=2.888 (perp=13.415, rec=0.197, cos=0.008), tot_loss_proj:4.647 [t=0.18s]
prediction: ['[CLS] helen problem ellen ellen talked problem talked five [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.299 (perp=10.439, rec=0.202, cos=0.009), tot_loss_proj:4.058 [t=0.17s]
prediction: ['[CLS] helen ellen ellen talked problem discussed problem one [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.312 (perp=10.620, rec=0.180, cos=0.008), tot_loss_proj:4.153 [t=0.17s]
prediction: ['[CLS] helen ellen ellen talked problem talked problem one [SEP]']
[ 450/2000] tot_loss=2.052 (perp=9.435, rec=0.158, cos=0.007), tot_loss_proj:3.720 [t=0.17s]
prediction: ['[CLS] helen ellen ellen talked problem. problem one [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.305 (perp=10.687, rec=0.160, cos=0.007), tot_loss_proj:4.134 [t=0.17s]
prediction: ['[CLS] helen ellen ellen talked problem one problem talked [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.195 (perp=10.175, rec=0.154, cos=0.007), tot_loss_proj:3.887 [t=0.17s]
prediction: ['[CLS] helen ellen helen talked one problem problem. [SEP]']
[ 600/2000] tot_loss=2.192 (perp=10.175, rec=0.151, cos=0.006), tot_loss_proj:3.887 [t=0.18s]
prediction: ['[CLS] helen ellen helen talked one problem problem. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.059 (perp=9.407, rec=0.170, cos=0.007), tot_loss_proj:3.684 [t=0.18s]
prediction: ['[CLS] helen helen ellen talked one problem with talked [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.082 (perp=9.599, rec=0.156, cos=0.006), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked some problem with talked [SEP]']
[ 750/2000] tot_loss=2.087 (perp=9.599, rec=0.161, cos=0.006), tot_loss_proj:3.707 [t=0.18s]
prediction: ['[CLS] helen helen ellen talked some problem with talked [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.941 (perp=8.974, rec=0.140, cos=0.006), tot_loss_proj:3.602 [t=0.18s]
prediction: ['[CLS] helen helen ellen talked the problem with talked [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.940 (perp=8.974, rec=0.139, cos=0.006), tot_loss_proj:3.603 [t=0.18s]
prediction: ['[CLS] helen helen ellen talked the problem with talked [SEP]']
[ 900/2000] tot_loss=2.160 (perp=10.123, rec=0.130, cos=0.005), tot_loss_proj:3.817 [t=0.19s]
prediction: ['[CLS] helen helen ellen talked about problem with talked [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.013 (perp=9.311, rec=0.144, cos=0.006), tot_loss_proj:3.724 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1000/2000] tot_loss=2.007 (perp=9.311, rec=0.139, cos=0.006), tot_loss_proj:3.721 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
[1050/2000] tot_loss=2.010 (perp=9.311, rec=0.143, cos=0.005), tot_loss_proj:3.720 [t=0.18s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1100/2000] tot_loss=2.015 (perp=9.311, rec=0.147, cos=0.005), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1150/2000] tot_loss=2.008 (perp=9.311, rec=0.140, cos=0.005), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
[1200/2000] tot_loss=2.006 (perp=9.311, rec=0.139, cos=0.005), tot_loss_proj:3.719 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1250/2000] tot_loss=2.002 (perp=9.311, rec=0.134, cos=0.005), tot_loss_proj:3.721 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1300/2000] tot_loss=2.002 (perp=9.311, rec=0.135, cos=0.005), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
[1350/2000] tot_loss=2.005 (perp=9.311, rec=0.138, cos=0.005), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1400/2000] tot_loss=1.995 (perp=9.311, rec=0.127, cos=0.005), tot_loss_proj:3.713 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1450/2000] tot_loss=2.001 (perp=9.311, rec=0.134, cos=0.005), tot_loss_proj:3.715 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
[1500/2000] tot_loss=1.995 (perp=9.311, rec=0.128, cos=0.005), tot_loss_proj:3.715 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1550/2000] tot_loss=2.004 (perp=9.311, rec=0.137, cos=0.005), tot_loss_proj:3.715 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1600/2000] tot_loss=2.000 (perp=9.311, rec=0.132, cos=0.005), tot_loss_proj:3.716 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
[1650/2000] tot_loss=1.999 (perp=9.311, rec=0.132, cos=0.005), tot_loss_proj:3.721 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1700/2000] tot_loss=2.003 (perp=9.311, rec=0.135, cos=0.005), tot_loss_proj:3.716 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1750/2000] tot_loss=1.996 (perp=9.311, rec=0.129, cos=0.005), tot_loss_proj:3.718 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
[1800/2000] tot_loss=1.990 (perp=9.311, rec=0.123, cos=0.005), tot_loss_proj:3.715 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1850/2000] tot_loss=1.999 (perp=9.311, rec=0.131, cos=0.005), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[1900/2000] tot_loss=1.998 (perp=9.311, rec=0.130, cos=0.005), tot_loss_proj:3.715 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
[1950/2000] tot_loss=1.984 (perp=9.311, rec=0.117, cos=0.005), tot_loss_proj:3.716 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Attempt swap
[2000/2000] tot_loss=1.991 (perp=9.311, rec=0.124, cos=0.005), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] helen helen ellen talked with talked about problem [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] ellen talked with helen about the problem. [SEP]
========================
predicted: 
========================
[CLS] helen helen ellen talked with talked about problem [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 35.294 | p: 33.333 | r: 37.500
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 119.505

[Aggregate metrics]:
rouge1     | fm: 83.323 | p: 83.002 | r: 83.932
rouge2     | fm: 36.906 | p: 36.657 | r: 37.326
rougeL     | fm: 68.191 | p: 67.892 | r: 68.796
rougeLsum  | fm: 68.205 | p: 67.900 | r: 68.691
r1fm+r2fm = 120.228

input #64 time: 0:07:09 | total time: 7:53:05


Running input #65 of 100.
reference: 
========================
Mag Wildwood came to introduce the bartender but I came precisely not to.
========================
average of cosine similarity 0.999347258517335
highest_index [0]
highest [0.999347258517335]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101, 23848,  3748,  3702,  2234,  2000,  8970,  1996, 15812,  2021,
          1045,  2234, 10785,  2025,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]']
[Init] best rec loss: 0.9090550541877747 for ['[CLS] old shaw mcgill standminated chapter publication legal non penny cheekatics contemporary story fleet [SEP]']
[Init] best rec loss: 0.8861916661262512 for ['[CLS] mail shooting legends capture gen attention cpud graders democratic but lips suspicious suppressed out [SEP]']
[Init] best rec loss: 0.8844349980354309 for ['[CLS] groom ownership hd mellon field house of [SEP]zed lisa iranbreaker bypass short [SEP]']
[Init] best rec loss: 0.8687723278999329 for ['[CLS]ines organ salesmanisen sectionoise people ideal succession single humanunt shown monk black [SEP]']
[Init] best rec loss: 0.8403171896934509 for ['[CLS] question ibn calledevich gulfcting due instead mist end banks half mef butch [SEP]']
[Init] best perm rec loss: 0.8378674983978271 for ['[CLS]f mecting called ibn butch half banks end due instead gulfevich question mist [SEP]']
[Init] best perm rec loss: 0.8377445936203003 for ['[CLS] gulf butch me banks due mist insteadevich halff questioncting end called ibn [SEP]']
[Init] best perm rec loss: 0.8348801732063293 for ['[CLS] question banks me due half gulfevich mistcting called end butch ibn insteadf [SEP]']
[Init] best perm rec loss: 0.8347507119178772 for ['[CLS]cting end half banks mist instead dueevich me question called gulff ibn butch [SEP]']
[Init] best perm rec loss: 0.8344051837921143 for ['[CLS]f question end instead banks mecting gulfevich due ibn mist half called butch [SEP]']
[Init] best perm rec loss: 0.8343683481216431 for ['[CLS] ibn me called questionevich instead mist due banks half butchfcting gulf end [SEP]']
[Init] best perm rec loss: 0.8341259360313416 for ['[CLS] banks insteadevich ibn me end mistcting gulff called question due half butch [SEP]']
[Init] best perm rec loss: 0.8338921666145325 for ['[CLS] called me banks due instead halffevich ibncting question gulf end butch mist [SEP]']
[Init] best perm rec loss: 0.8312921524047852 for ['[CLS] called butch ibn me end question banksevich mist due instead gulfcting halff [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.216 (perp=12.763, rec=0.512, cos=0.151), tot_loss_proj:4.421 [t=0.17s]
prediction: ['[CLS] conclusion chinese su... r from sought ª except recruits appearance hireal - physics [SEP]']
[ 100/2000] tot_loss=3.094 (perp=13.276, rec=0.391, cos=0.047), tot_loss_proj:4.533 [t=0.18s]
prediction: ['[CLS] nak came females... feel then sought been episode haley actually ₊al - physics [SEP]']
[ 150/2000] tot_loss=2.930 (perp=12.768, rec=0.343, cos=0.033), tot_loss_proj:4.392 [t=0.18s]
prediction: ['[CLS] unsuccessful came pants... cl then goethe been appear exactly exactly ₊al -2 [SEP]']
[ 200/2000] tot_loss=2.714 (perp=11.853, rec=0.319, cos=0.025), tot_loss_proj:4.248 [t=0.18s]
prediction: ['[CLS] ba came bartender... cl came precisely but appear exactly exactly ₊. - ethics [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.821 (perp=12.368, rec=0.318, cos=0.030), tot_loss_proj:4.320 [t=0.20s]
prediction: ['[CLS] ba came bartender... exclusively came precisely but strand exactly cl ₊. - indeed [SEP]']
[ 300/2000] tot_loss=2.520 (perp=11.122, rec=0.270, cos=0.025), tot_loss_proj:4.093 [t=0.20s]
prediction: ['[CLS] ba came came... merely came precisely but strand exactly cl ₊. - indeed [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.389 (perp=10.598, rec=0.254, cos=0.016), tot_loss_proj:4.007 [t=0.18s]
prediction: ['[CLS] introduce came came... exactly exactly precisely but strand came came ₊. - indeed [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.650 (perp=11.856, rec=0.260, cos=0.018), tot_loss_proj:4.263 [t=0.17s]
prediction: ['[CLS] introduce came... came exactly bartender precisely but below came came ₊. playoffs robes [SEP]']
[ 450/2000] tot_loss=2.593 (perp=11.612, rec=0.246, cos=0.025), tot_loss_proj:4.217 [t=0.18s]
prediction: ['[CLS] introduce came? came precisely bartender precisely but foundation came came ₊. playoffs indeed [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.306 (perp=10.297, rec=0.233, cos=0.014), tot_loss_proj:3.979 [t=0.18s]
prediction: ['[CLS] introduce mag? came exactly precisely but toward bartender came came we. playoffs indeed [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.482 (perp=11.257, rec=0.220, cos=0.011), tot_loss_proj:4.094 [t=0.18s]
prediction: ['[CLS] introduce mag... came precisely precisely but toward bartender came indeed ₕ to playoffs came [SEP]']
[ 600/2000] tot_loss=2.453 (perp=11.178, rec=0.206, cos=0.012), tot_loss_proj:4.075 [t=0.18s]
prediction: ['[CLS] introduce mag... came precisely precisely but toward bartender came indeed i to to came [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.361 (perp=10.817, rec=0.188, cos=0.010), tot_loss_proj:4.011 [t=0.18s]
prediction: ['[CLS] introduce mag? came precisely precisely but toward bartender i came indeed not should came [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.419 (perp=11.055, rec=0.195, cos=0.013), tot_loss_proj:4.067 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but? bartender i came indeed not should came [SEP]']
[ 750/2000] tot_loss=2.217 (perp=10.151, rec=0.179, cos=0.007), tot_loss_proj:3.929 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but? bartender i came indeed not to came [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.136 (perp=9.771, rec=0.174, cos=0.008), tot_loss_proj:3.819 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender? i came indeed not to came [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.141 (perp=9.771, rec=0.179, cos=0.007), tot_loss_proj:3.819 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender? i came indeed not to came [SEP]']
[ 900/2000] tot_loss=2.126 (perp=9.771, rec=0.166, cos=0.006), tot_loss_proj:3.823 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender? i came indeed not to came [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.120 (perp=9.771, rec=0.160, cos=0.006), tot_loss_proj:3.822 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender? i came indeed not to came [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.057 (perp=9.428, rec=0.160, cos=0.012), tot_loss_proj:3.741 [t=0.23s]
prediction: ['[CLS] introduce magwood came precisely but precisely bartender? i came. not to came [SEP]']
[1050/2000] tot_loss=2.050 (perp=9.428, rec=0.158, cos=0.006), tot_loss_proj:3.744 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely but precisely bartender? i came. not to came [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.041 (perp=9.386, rec=0.158, cos=0.006), tot_loss_proj:3.729 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender? i came. not to came [SEP]']
Attempt swap
[1150/2000] tot_loss=2.037 (perp=9.386, rec=0.154, cos=0.006), tot_loss_proj:3.728 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender? i came. not to came [SEP]']
[1200/2000] tot_loss=1.937 (perp=8.903, rec=0.151, cos=0.006), tot_loss_proj:3.653 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender? i came. not to introduce [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.928 (perp=8.869, rec=0.148, cos=0.006), tot_loss_proj:3.614 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
Attempt swap
[1300/2000] tot_loss=1.932 (perp=8.869, rec=0.152, cos=0.005), tot_loss_proj:3.616 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
[1350/2000] tot_loss=1.928 (perp=8.869, rec=0.149, cos=0.005), tot_loss_proj:3.613 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
Attempt swap
[1400/2000] tot_loss=1.935 (perp=8.869, rec=0.156, cos=0.005), tot_loss_proj:3.616 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
Attempt swap
[1450/2000] tot_loss=1.923 (perp=8.869, rec=0.144, cos=0.005), tot_loss_proj:3.617 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
[1500/2000] tot_loss=1.917 (perp=8.869, rec=0.139, cos=0.005), tot_loss_proj:3.611 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
Attempt swap
[1550/2000] tot_loss=1.920 (perp=8.869, rec=0.141, cos=0.005), tot_loss_proj:3.614 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
Attempt swap
[1600/2000] tot_loss=1.920 (perp=8.869, rec=0.142, cos=0.005), tot_loss_proj:3.621 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
[1650/2000] tot_loss=1.915 (perp=8.869, rec=0.136, cos=0.005), tot_loss_proj:3.616 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.908 (perp=8.870, rec=0.129, cos=0.005), tot_loss_proj:3.641 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely but precisely bartender. i came? not to introduce [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.915 (perp=8.869, rec=0.137, cos=0.005), tot_loss_proj:3.616 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
[1800/2000] tot_loss=1.921 (perp=8.869, rec=0.142, cos=0.005), tot_loss_proj:3.612 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely precisely but bartender. i came? not to introduce [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.905 (perp=8.870, rec=0.126, cos=0.005), tot_loss_proj:3.641 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely but precisely bartender. i came? not to introduce [SEP]']
Attempt swap
[1900/2000] tot_loss=1.914 (perp=8.870, rec=0.135, cos=0.005), tot_loss_proj:3.633 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely but precisely bartender. i came? not to introduce [SEP]']
[1950/2000] tot_loss=1.906 (perp=8.870, rec=0.128, cos=0.005), tot_loss_proj:3.642 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely but precisely bartender. i came? not to introduce [SEP]']
Attempt swap
[2000/2000] tot_loss=1.914 (perp=8.870, rec=0.136, cos=0.005), tot_loss_proj:3.639 [t=0.18s]
prediction: ['[CLS] introduce magwood came precisely but precisely bartender. i came? not to introduce [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]
========================
predicted: 
========================
[CLS] introduce magwood came precisely but precisely bartender. i came? not to introduce [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.862 | p: 78.571 | r: 73.333
rouge2     | fm: 29.630 | p: 30.769 | r: 28.571
rougeL     | fm: 55.172 | p: 57.143 | r: 53.333
rougeLsum  | fm: 55.172 | p: 57.143 | r: 53.333
r1fm+r2fm = 105.492

[Aggregate metrics]:
rouge1     | fm: 83.223 | p: 82.948 | r: 83.766
rouge2     | fm: 36.620 | p: 36.392 | r: 37.059
rougeL     | fm: 67.904 | p: 67.674 | r: 68.550
rougeLsum  | fm: 67.910 | p: 67.619 | r: 68.524
r1fm+r2fm = 119.843

input #65 time: 0:07:34 | total time: 8:00:40


Running input #66 of 100.
reference: 
========================
There tried to be riots in Seoul.
========================
average of cosine similarity 0.9993414821455255
highest_index [0]
highest [0.9993414821455255]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2045,  2699,  2000,  2022, 12925,  1999, 10884,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] there tried to be riots in seoul. [SEP]']
[Init] best rec loss: 0.8370904326438904 for ['[CLS] mcdonnell mount activities death today game medal ng [SEP]']
[Init] best rec loss: 0.7445188164710999 for ['[CLS] vamp kada devil kent lizard home angels [SEP]']
[Init] best rec loss: 0.7357205748558044 for ['[CLS] general maryland head learners balancemm experience vehicles [SEP]']
[Init] best rec loss: 0.6963397860527039 for ['[CLS] kirk line may anniversary bee combined ladder doubtful [SEP]']
[Init] best rec loss: 0.6802833676338196 for ['[CLS] mainger soil music means numbers this left [SEP]']
[Init] best rec loss: 0.6790328025817871 for ['[CLS] duel paradise birdsfireshane express knows archives [SEP]']
[Init] best perm rec loss: 0.6775854825973511 for ['[CLS]hane express paradise birds archives knowsfires duel [SEP]']
[Init] best perm rec loss: 0.6764670610427856 for ['[CLS] express birds paradisehane duel knowsfires archives [SEP]']
[Init] best perm rec loss: 0.6757842898368835 for ['[CLS]fires paradisehane knows birds archives express duel [SEP]']
[Init] best perm rec loss: 0.6753475069999695 for ['[CLS] paradise duel express birds knows archivesfireshane [SEP]']
[Init] best perm rec loss: 0.6744402647018433 for ['[CLS] paradise archivesfires birdshane knows express duel [SEP]']
[Init] best perm rec loss: 0.6731578707695007 for ['[CLS] express duel paradisehane archives knows birdsfires [SEP]']
[Init] best perm rec loss: 0.6708163022994995 for ['[CLS] paradise knows duelhane express birds archivesfires [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.956 (perp=12.710, rec=0.381, cos=0.033), tot_loss_proj:3.280 [t=0.17s]
prediction: ['[CLS] unfortunately like swedish be bradford bot preserved wore [SEP]']
[ 100/2000] tot_loss=2.385 (perp=10.483, rec=0.273, cos=0.015), tot_loss_proj:2.818 [t=0.17s]
prediction: ['[CLS] there tried riots be bradford city in tried [SEP]']
[ 150/2000] tot_loss=2.097 (perp=9.658, rec=0.157, cos=0.008), tot_loss_proj:2.677 [t=0.22s]
prediction: ['[CLS] there tried riots be riots city riots was [SEP]']
[ 200/2000] tot_loss=2.674 (perp=12.712, rec=0.125, cos=0.006), tot_loss_proj:3.224 [t=0.24s]
prediction: ['[CLS] there tried seoul be riots seoul riots been [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.454 (perp=11.016, rec=0.229, cos=0.023), tot_loss_proj:2.927 [t=0.17s]
prediction: ['[CLS] there tried be riots seoul riots tokyo to [SEP]']
[ 300/2000] tot_loss=2.209 (perp=10.392, rec=0.124, cos=0.007), tot_loss_proj:2.698 [t=0.19s]
prediction: ['[CLS] there tried be riots seoul riots in to [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.699 (perp=7.932, rec=0.107, cos=0.005), tot_loss_proj:2.090 [t=0.18s]
prediction: ['[CLS] there tried be riots to riots in seoul [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.555 (perp=7.271, rec=0.095, cos=0.006), tot_loss_proj:1.753 [t=0.17s]
prediction: ['[CLS] there tried to be riots riots in seoul [SEP]']
[ 450/2000] tot_loss=1.545 (perp=7.271, rec=0.086, cos=0.004), tot_loss_proj:1.759 [t=0.17s]
prediction: ['[CLS] there tried to be riots riots in seoul [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.407 (perp=6.494, rec=0.104, cos=0.004), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.395 (perp=6.494, rec=0.093, cos=0.004), tot_loss_proj:1.817 [t=0.19s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
[ 600/2000] tot_loss=1.388 (perp=6.494, rec=0.086, cos=0.004), tot_loss_proj:1.809 [t=0.20s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.371 (perp=6.494, rec=0.069, cos=0.004), tot_loss_proj:1.813 [t=0.19s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.387 (perp=6.494, rec=0.085, cos=0.003), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
[ 750/2000] tot_loss=1.388 (perp=6.494, rec=0.086, cos=0.003), tot_loss_proj:1.816 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.368 (perp=6.494, rec=0.066, cos=0.003), tot_loss_proj:1.809 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.382 (perp=6.494, rec=0.080, cos=0.003), tot_loss_proj:1.816 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
[ 900/2000] tot_loss=1.376 (perp=6.494, rec=0.074, cos=0.003), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.376 (perp=6.494, rec=0.074, cos=0.003), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1000/2000] tot_loss=1.375 (perp=6.494, rec=0.073, cos=0.003), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
[1050/2000] tot_loss=1.381 (perp=6.494, rec=0.080, cos=0.003), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1100/2000] tot_loss=1.382 (perp=6.494, rec=0.080, cos=0.003), tot_loss_proj:1.817 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1150/2000] tot_loss=1.375 (perp=6.494, rec=0.073, cos=0.003), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
[1200/2000] tot_loss=1.379 (perp=6.494, rec=0.078, cos=0.003), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1250/2000] tot_loss=1.366 (perp=6.494, rec=0.064, cos=0.003), tot_loss_proj:1.812 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1300/2000] tot_loss=1.382 (perp=6.494, rec=0.080, cos=0.003), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
[1350/2000] tot_loss=1.378 (perp=6.494, rec=0.076, cos=0.003), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1400/2000] tot_loss=1.375 (perp=6.494, rec=0.073, cos=0.003), tot_loss_proj:1.809 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1450/2000] tot_loss=1.370 (perp=6.494, rec=0.069, cos=0.003), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
[1500/2000] tot_loss=1.382 (perp=6.494, rec=0.080, cos=0.003), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1550/2000] tot_loss=1.375 (perp=6.494, rec=0.073, cos=0.003), tot_loss_proj:1.813 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1600/2000] tot_loss=1.378 (perp=6.494, rec=0.076, cos=0.003), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
[1650/2000] tot_loss=1.379 (perp=6.494, rec=0.077, cos=0.003), tot_loss_proj:1.812 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1700/2000] tot_loss=1.370 (perp=6.494, rec=0.068, cos=0.003), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1750/2000] tot_loss=1.374 (perp=6.494, rec=0.072, cos=0.003), tot_loss_proj:1.813 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
[1800/2000] tot_loss=1.375 (perp=6.494, rec=0.074, cos=0.003), tot_loss_proj:1.810 [t=0.18s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1850/2000] tot_loss=1.372 (perp=6.494, rec=0.071, cos=0.003), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[1900/2000] tot_loss=1.374 (perp=6.494, rec=0.072, cos=0.003), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
[1950/2000] tot_loss=1.375 (perp=6.494, rec=0.074, cos=0.003), tot_loss_proj:1.813 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Attempt swap
[2000/2000] tot_loss=1.378 (perp=6.494, rec=0.076, cos=0.003), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] riots there tried to be riots in seoul [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] there tried to be riots in seoul. [SEP]
========================
predicted: 
========================
[CLS] riots there tried to be riots in seoul [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 82.353 | p: 77.778 | r: 87.500
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 177.090

[Aggregate metrics]:
rouge1     | fm: 83.397 | p: 83.087 | r: 83.972
rouge2     | fm: 37.306 | p: 36.993 | r: 37.896
rougeL     | fm: 68.375 | p: 68.035 | r: 69.005
rougeLsum  | fm: 68.370 | p: 67.958 | r: 68.995
r1fm+r2fm = 120.704

input #66 time: 0:07:16 | total time: 8:07:57


Running input #67 of 100.
reference: 
========================
Fido is the smarter dog than Spot.
========================
average of cosine similarity 0.9991866915016882
highest_index [0]
highest [0.9991866915016882]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 10882,  3527,  2003,  1996, 25670,  3899,  2084,  3962,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] fido is the smarter dog than spot. [SEP]']
[Init] best rec loss: 1.016399621963501 for ['[CLS] spec legend currently boarding reasons chapel assistance accomplish through [SEP]']
[Init] best rec loss: 0.9444090723991394 for ['[CLS] bi ride driveway° student " life representative bomb [SEP]']
[Init] best rec loss: 0.9167268872261047 for ['[CLS] silkrting relating break cigarette bail finger charts do [SEP]']
[Init] best rec loss: 0.8861123323440552 for ['[CLS] word cab healthychenifying ruled mills flat prison [SEP]']
[Init] best rec loss: 0.8842894434928894 for ['[CLS]vert prompt train circle being ableaco horror ada [SEP]']
[Init] best rec loss: 0.8251447081565857 for ['[CLS] canberra mountain terms first transit ladder rats running naval [SEP]']
[Init] best rec loss: 0.8203999996185303 for ['[CLS] date disease expert monkey ich determination only oncelow [SEP]']
[Init] best rec loss: 0.8164994716644287 for ['[CLS] ] house christ box swore rex marina limit replacement [SEP]']
[Init] best perm rec loss: 0.8159659504890442 for ['[CLS] house limit box ] marina christ rex replacement swore [SEP]']
[Init] best perm rec loss: 0.8144137263298035 for ['[CLS] limit replacement house rex box marina swore christ ] [SEP]']
[Init] best perm rec loss: 0.8091739416122437 for ['[CLS] box house replacement rex christ swore limit marina ] [SEP]']
[Init] best perm rec loss: 0.808587908744812 for ['[CLS] ] house box replacement marina christ rex limit swore [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.516 (perp=13.391, rec=0.643, cos=0.195), tot_loss_proj:3.989 [t=0.17s]
prediction: ['[CLS] tournament mvp robbie blacknesster sex is hub shame [SEP]']
[ 100/2000] tot_loss=3.155 (perp=13.395, rec=0.425, cos=0.051), tot_loss_proj:4.387 [t=0.17s]
prediction: ['[CLS] clock hybrid smarter scholar too dasless adaptation harald [SEP]']
[ 150/2000] tot_loss=2.645 (perp=11.266, rec=0.360, cos=0.032), tot_loss_proj:4.032 [t=0.17s]
prediction: ['[CLS] dogs footage smarter dog too thanless spot dog [SEP]']
[ 200/2000] tot_loss=2.789 (perp=10.247, rec=0.537, cos=0.203), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] ships dog smarter dog, skill dog spot dogs [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.720 (perp=10.620, rec=0.481, cos=0.115), tot_loss_proj:3.752 [t=0.17s]
prediction: ['[CLS] smarter ships dog dog each skill dog spot dog [SEP]']
[ 300/2000] tot_loss=2.625 (perp=11.015, rec=0.383, cos=0.040), tot_loss_proj:4.055 [t=0.17s]
prediction: ['[CLS] smarter aircraft crazy resource beyond than as spot dog [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.398 (perp=10.170, rec=0.341, cos=0.024), tot_loss_proj:3.869 [t=0.17s]
prediction: ['[CLS] smarter than crazy resource than aircraft as spot dog [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.462 (perp=10.757, rec=0.284, cos=0.026), tot_loss_proj:3.889 [t=0.17s]
prediction: ['[CLS] spot smarter than is than aircraft than spot dog [SEP]']
[ 450/2000] tot_loss=2.160 (perp=9.474, rec=0.241, cos=0.024), tot_loss_proj:3.624 [t=0.17s]
prediction: ['[CLS] spot smarter than is than dog than spot dog [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.183 (perp=9.408, rec=0.265, cos=0.036), tot_loss_proj:3.581 [t=0.17s]
prediction: ['[CLS] is smarter superiority aircraft dog than that spot dog [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.903 (perp=8.441, rec=0.196, cos=0.019), tot_loss_proj:3.449 [t=0.17s]
prediction: ['[CLS] is superiority smarter dog dog than that spot dog [SEP]']
[ 600/2000] tot_loss=2.165 (perp=9.953, rec=0.161, cos=0.014), tot_loss_proj:3.729 [t=0.17s]
prediction: ['[CLS] isho smarter spot dog than as spot dog [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.961 (perp=9.015, rec=0.146, cos=0.011), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] isho smarter as dog dog than spot dog [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.952 (perp=9.015, rec=0.139, cos=0.010), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] isho smarter as dog dog than spot dog [SEP]']
[ 750/2000] tot_loss=1.942 (perp=9.015, rec=0.130, cos=0.009), tot_loss_proj:3.468 [t=0.17s]
prediction: ['[CLS] isho smarter as dog dog than spot dog [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.853 (perp=8.532, rec=0.137, cos=0.009), tot_loss_proj:3.564 [t=0.17s]
prediction: ['[CLS] is is as smarter dog dog than spot dog [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.021 (perp=9.400, rec=0.132, cos=0.009), tot_loss_proj:3.695 [t=0.17s]
prediction: ['[CLS] is fi is than smarter dog than spot dog [SEP]']
[ 900/2000] tot_loss=2.022 (perp=9.400, rec=0.134, cos=0.008), tot_loss_proj:3.693 [t=0.17s]
prediction: ['[CLS] is fi is than smarter dog than spot dog [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.921 (perp=8.941, rec=0.124, cos=0.008), tot_loss_proj:3.284 [t=0.17s]
prediction: ['[CLS] is fi is smarter than dog than spot dog [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.910 (perp=8.910, rec=0.120, cos=0.008), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS] is is fi smarter than dog than spot dog [SEP]']
[1050/2000] tot_loss=1.907 (perp=8.910, rec=0.117, cos=0.008), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS] is is fi smarter than dog than spot dog [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.853 (perp=8.606, rec=0.124, cos=0.009), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1150/2000] tot_loss=1.848 (perp=8.606, rec=0.119, cos=0.008), tot_loss_proj:3.369 [t=0.17s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
[1200/2000] tot_loss=1.839 (perp=8.606, rec=0.111, cos=0.008), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1250/2000] tot_loss=1.838 (perp=8.606, rec=0.109, cos=0.007), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1300/2000] tot_loss=1.842 (perp=8.606, rec=0.114, cos=0.007), tot_loss_proj:3.361 [t=0.17s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
[1350/2000] tot_loss=1.841 (perp=8.606, rec=0.113, cos=0.007), tot_loss_proj:3.366 [t=0.17s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1400/2000] tot_loss=1.843 (perp=8.606, rec=0.115, cos=0.007), tot_loss_proj:3.363 [t=0.17s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1450/2000] tot_loss=1.840 (perp=8.606, rec=0.112, cos=0.007), tot_loss_proj:3.366 [t=0.17s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
[1500/2000] tot_loss=1.848 (perp=8.606, rec=0.120, cos=0.007), tot_loss_proj:3.368 [t=0.18s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1550/2000] tot_loss=1.837 (perp=8.606, rec=0.110, cos=0.006), tot_loss_proj:3.362 [t=0.18s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1600/2000] tot_loss=1.838 (perp=8.606, rec=0.111, cos=0.006), tot_loss_proj:3.362 [t=0.18s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
[1650/2000] tot_loss=1.832 (perp=8.606, rec=0.104, cos=0.006), tot_loss_proj:3.364 [t=0.18s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1700/2000] tot_loss=1.852 (perp=8.606, rec=0.125, cos=0.006), tot_loss_proj:3.362 [t=0.18s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1750/2000] tot_loss=1.834 (perp=8.606, rec=0.107, cos=0.006), tot_loss_proj:3.366 [t=0.18s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
[1800/2000] tot_loss=1.853 (perp=8.606, rec=0.126, cos=0.006), tot_loss_proj:3.363 [t=0.18s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1850/2000] tot_loss=1.840 (perp=8.606, rec=0.113, cos=0.006), tot_loss_proj:3.365 [t=0.18s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[1900/2000] tot_loss=1.849 (perp=8.606, rec=0.122, cos=0.006), tot_loss_proj:3.365 [t=0.18s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
[1950/2000] tot_loss=1.828 (perp=8.606, rec=0.100, cos=0.006), tot_loss_proj:3.358 [t=0.18s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Attempt swap
[2000/2000] tot_loss=1.819 (perp=8.606, rec=0.092, cos=0.006), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] is dog is fi smarter than dog than spot [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] fido is the smarter dog than spot. [SEP]
========================
predicted: 
========================
[CLS] is dog is fi smarter than dog than spot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.000 | p: 63.636 | r: 77.778
rouge2     | fm: 33.333 | p: 30.000 | r: 37.500
rougeL     | fm: 70.000 | p: 63.636 | r: 77.778
rougeLsum  | fm: 70.000 | p: 63.636 | r: 77.778
r1fm+r2fm = 103.333

[Aggregate metrics]:
rouge1     | fm: 83.152 | p: 82.804 | r: 83.848
rouge2     | fm: 37.285 | p: 36.848 | r: 37.870
rougeL     | fm: 68.426 | p: 68.001 | r: 69.167
rougeLsum  | fm: 68.403 | p: 68.002 | r: 69.069
r1fm+r2fm = 120.436

input #67 time: 0:06:57 | total time: 8:14:55


Running input #68 of 100.
reference: 
========================
John convinced the rice to be cooked by Bill.
========================
average of cosine similarity 0.9992469253349906
highest_index [0]
highest [0.9992469253349906]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198,  6427,  1996,  5785,  2000,  2022, 12984,  2011,  3021,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john convinced the rice to be cooked by bill. [SEP]']
[Init] best rec loss: 0.7907953262329102 for ['[CLS] rich plant ticket has an boat favorite malaysia showing procedures [SEP]']
[Init] best rec loss: 0.7299020886421204 for ['[CLS] ago participants bo charlie across formula alone fisheries core constantine [SEP]']
[Init] best rec loss: 0.7223528027534485 for ['[CLS] maintenance fr respectively sports alive turnoured acquisition barrow body [SEP]']
[Init] best rec loss: 0.7169906497001648 for ['[CLS] clouditedpath 23rch lying staff students waiting supreme [SEP]']
[Init] best rec loss: 0.7140128016471863 for ['[CLS] protested rob child truss privileged rise efforts saber [MASK] goat [SEP]']
[Init] best rec loss: 0.7135128378868103 for ['[CLS] buy miles figureider okay hit springs loving todd contract [SEP]']
[Init] best rec loss: 0.70791095495224 for ['[CLS] shipped pali elevation stacy mississippi spectacle [SEP] completely physical airlines [SEP]']
[Init] best rec loss: 0.6938566565513611 for ['[CLS] bail tallest moth twenty plate maybe verse story growing > [SEP]']
[Init] best perm rec loss: 0.6931449770927429 for ['[CLS] > bail plate moth verse twenty growing tallest maybe story [SEP]']
[Init] best perm rec loss: 0.6930882334709167 for ['[CLS] story maybe bail tallest verse twenty moth > plate growing [SEP]']
[Init] best perm rec loss: 0.6856919527053833 for ['[CLS] growing maybe story verse twenty > plate tallest moth bail [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.013 (perp=13.211, rec=0.318, cos=0.054), tot_loss_proj:3.773 [t=0.19s]
prediction: ['[CLS] convinced todayostal preserved mind its plate everyone convinced cough [SEP]']
[ 100/2000] tot_loss=2.848 (perp=12.326, rec=0.315, cos=0.068), tot_loss_proj:3.568 [t=0.19s]
prediction: ['[CLS] convinced chinese harold the rice a era everyone convinced cooked [SEP]']
[ 150/2000] tot_loss=2.590 (perp=11.865, rec=0.201, cos=0.016), tot_loss_proj:3.456 [t=0.19s]
prediction: ['[CLS] convinced large votes the rice to advantage john convinced cooked [SEP]']
[ 200/2000] tot_loss=2.502 (perp=11.770, rec=0.139, cos=0.009), tot_loss_proj:3.396 [t=0.19s]
prediction: ['[CLS] convinced cooked votes the the to rice john convinced cooked [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.610 (perp=12.158, rec=0.161, cos=0.017), tot_loss_proj:3.467 [t=0.17s]
prediction: ['[CLS] convinced cooked votes to the inally john convinced cooked [SEP]']
[ 300/2000] tot_loss=2.399 (perp=11.338, rec=0.126, cos=0.006), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS] convinced cooked bill to the by rice john convinced cooked [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.163 (perp=10.181, rec=0.121, cos=0.006), tot_loss_proj:3.010 [t=0.19s]
prediction: ['[CLS] possibly rice bill to the cooked rice john convinced cooked [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.920 (perp=8.785, rec=0.136, cos=0.027), tot_loss_proj:2.713 [t=0.19s]
prediction: ['[CLS] possibly rice bill convinced the cooked rice john to cooked [SEP]']
[ 450/2000] tot_loss=1.882 (perp=8.785, rec=0.119, cos=0.006), tot_loss_proj:2.706 [t=0.21s]
prediction: ['[CLS] possibly rice bill convinced the cooked rice john to cooked [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.876 (perp=8.785, rec=0.115, cos=0.005), tot_loss_proj:2.705 [t=0.19s]
prediction: ['[CLS] possibly rice bill convinced the cooked rice john to cooked [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.599 (perp=7.356, rec=0.117, cos=0.011), tot_loss_proj:2.238 [t=0.18s]
prediction: ['[CLS] cooked rice bill convinced the cooked rice john to be [SEP]']
[ 600/2000] tot_loss=1.836 (perp=8.699, rec=0.092, cos=0.004), tot_loss_proj:2.601 [t=0.19s]
prediction: ['[CLS] cooked rice bill convinced the cooked rice john to with [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=1.947 (perp=9.205, rec=0.100, cos=0.006), tot_loss_proj:2.974 [t=0.18s]
prediction: ['[CLS] with cooked rice bill convinced the cooked ள john to [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.861 (perp=8.768, rec=0.102, cos=0.005), tot_loss_proj:2.526 [t=0.17s]
prediction: ['[CLS] with cooked rice bill cooked convinced the ள john to [SEP]']
[ 750/2000] tot_loss=1.793 (perp=8.484, rec=0.091, cos=0.005), tot_loss_proj:2.584 [t=0.19s]
prediction: ['[CLS] with cooked rice bill cooked convinced the by john to [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.601 (perp=7.497, rec=0.097, cos=0.004), tot_loss_proj:2.209 [t=0.18s]
prediction: ['[CLS] with cooked rice bill cooked convinced by the john to [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.593 (perp=7.497, rec=0.090, cos=0.004), tot_loss_proj:2.205 [t=0.17s]
prediction: ['[CLS] with cooked rice bill cooked convinced by the john to [SEP]']
[ 900/2000] tot_loss=1.597 (perp=7.497, rec=0.094, cos=0.004), tot_loss_proj:2.214 [t=0.19s]
prediction: ['[CLS] with cooked rice bill cooked convinced by the john to [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.605 (perp=7.497, rec=0.102, cos=0.003), tot_loss_proj:2.205 [t=0.17s]
prediction: ['[CLS] with cooked rice bill cooked convinced by the john to [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.676 (perp=7.903, rec=0.091, cos=0.004), tot_loss_proj:2.738 [t=0.17s]
prediction: ['[CLS] bill cooked rice be cooked convinced by the john to [SEP]']
[1050/2000] tot_loss=1.676 (perp=7.903, rec=0.092, cos=0.003), tot_loss_proj:2.741 [t=0.17s]
prediction: ['[CLS] bill cooked rice be cooked convinced by the john to [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.861 (perp=8.842, rec=0.089, cos=0.004), tot_loss_proj:3.070 [t=0.17s]
prediction: ['[CLS] the be rice be cooked convinced by bill john to [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.806 (perp=8.532, rec=0.096, cos=0.004), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced by bill john to [SEP]']
[1200/2000] tot_loss=1.791 (perp=8.532, rec=0.081, cos=0.004), tot_loss_proj:2.575 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced by bill john to [SEP]']
Attempt swap
[1250/2000] tot_loss=1.800 (perp=8.532, rec=0.091, cos=0.003), tot_loss_proj:2.580 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced by bill john to [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.784 (perp=8.532, rec=0.074, cos=0.003), tot_loss_proj:2.558 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced by bill john to [SEP]']
[1350/2000] tot_loss=1.798 (perp=8.532, rec=0.089, cos=0.003), tot_loss_proj:2.562 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced by bill john to [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.788 (perp=8.532, rec=0.079, cos=0.003), tot_loss_proj:2.579 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced by bill john to [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.795 (perp=8.532, rec=0.085, cos=0.003), tot_loss_proj:2.557 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced by bill john to [SEP]']
[1500/2000] tot_loss=1.793 (perp=8.532, rec=0.084, cos=0.003), tot_loss_proj:2.561 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced by bill john to [SEP]']
Attempt swap
[1550/2000] tot_loss=1.799 (perp=8.532, rec=0.090, cos=0.003), tot_loss_proj:2.562 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced by bill john to [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.782 (perp=8.477, rec=0.083, cos=0.003), tot_loss_proj:3.092 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced bill by john to [SEP]']
[1650/2000] tot_loss=1.775 (perp=8.477, rec=0.077, cos=0.003), tot_loss_proj:3.091 [t=0.17s]
prediction: ['[CLS] the rice be be cooked convinced bill by john to [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.615 (perp=7.695, rec=0.073, cos=0.003), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] the rice to be cooked convinced bill by john be [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.631 (perp=7.673, rec=0.093, cos=0.003), tot_loss_proj:2.595 [t=0.17s]
prediction: ['[CLS] the rice to be cooked convinced be by john bill [SEP]']
[1800/2000] tot_loss=1.619 (perp=7.673, rec=0.082, cos=0.003), tot_loss_proj:2.596 [t=0.17s]
prediction: ['[CLS] the rice to be cooked convinced be by john bill [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.616 (perp=7.678, rec=0.078, cos=0.003), tot_loss_proj:2.606 [t=0.17s]
prediction: ['[CLS] the rice to be cooked convinced be by bill john [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.614 (perp=7.652, rec=0.080, cos=0.003), tot_loss_proj:2.639 [t=0.17s]
prediction: ['[CLS] the rice to be cooked convinced be bill by john [SEP]']
[1950/2000] tot_loss=1.615 (perp=7.652, rec=0.082, cos=0.003), tot_loss_proj:2.638 [t=0.17s]
prediction: ['[CLS] the rice to be cooked convinced be bill by john [SEP]']
Attempt swap
[2000/2000] tot_loss=1.608 (perp=7.652, rec=0.075, cos=0.003), tot_loss_proj:2.634 [t=0.17s]
prediction: ['[CLS] the rice to be cooked convinced be bill by john [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] john convinced the rice to be cooked by bill. [SEP]
========================
predicted: 
========================
[CLS] the rice be be cooked convinced by bill john to [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 28.571 | p: 27.273 | r: 30.000
rougeL     | fm: 69.565 | p: 66.667 | r: 72.727
rougeLsum  | fm: 69.565 | p: 66.667 | r: 72.727
r1fm+r2fm = 124.224

[Aggregate metrics]:
rouge1     | fm: 83.367 | p: 82.961 | r: 84.135
rouge2     | fm: 37.115 | p: 36.752 | r: 37.758
rougeL     | fm: 68.372 | p: 67.958 | r: 69.149
rougeLsum  | fm: 68.358 | p: 67.936 | r: 69.156
r1fm+r2fm = 120.482

input #68 time: 0:07:16 | total time: 8:22:11


Running input #69 of 100.
reference: 
========================
The squirrel ran straight quickly.
========================
average of cosine similarity 0.9993800710871901
highest_index [0]
highest [0.9993800710871901]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 18197,  2743,  3442,  2855,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the squirrel ran straight quickly. [SEP]']
[Init] best rec loss: 0.7449679970741272 for ['[CLS] theme skin alive won reach one [SEP]']
[Init] best rec loss: 0.7045864462852478 for ['[CLS] action ou defenceiom unto violence [SEP]']
[Init] best rec loss: 0.6891953349113464 for ['[CLS] pry material lay steadywled surveyor [SEP]']
[Init] best rec loss: 0.684439480304718 for ['[CLS]ango pieces wal ar upon bound [SEP]']
[Init] best rec loss: 0.6838079690933228 for ['[CLS] on years magazine belong eugen wah [SEP]']
[Init] best rec loss: 0.6556761860847473 for ['[CLS] brief forgetlyhawks husbandch [SEP]']
[Init] best perm rec loss: 0.6538225412368774 for ['[CLS] brieftlyhawks husband forgech [SEP]']
[Init] best perm rec loss: 0.6537908911705017 for ['[CLS]chtly briefhawks forge husband [SEP]']
[Init] best perm rec loss: 0.6512235999107361 for ['[CLS] briefhawks husband forgetlych [SEP]']
[Init] best perm rec loss: 0.6494418382644653 for ['[CLS] brieftly forgehawks husbandch [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.719 (perp=11.845, rec=0.318, cos=0.031), tot_loss_proj:3.629 [t=0.19s]
prediction: ['[CLS] bailey speed sent guard quickly track [SEP]']
[ 100/2000] tot_loss=2.722 (perp=12.398, rec=0.226, cos=0.016), tot_loss_proj:3.732 [t=0.19s]
prediction: ['[CLS] squirrel straight ran first quickly track [SEP]']
[ 150/2000] tot_loss=2.599 (perp=11.445, rec=0.272, cos=0.038), tot_loss_proj:3.076 [t=0.19s]
prediction: ['[CLS] squirrel straight ran i quickly straight [SEP]']
[ 200/2000] tot_loss=2.371 (perp=10.921, rec=0.176, cos=0.011), tot_loss_proj:2.896 [t=0.21s]
prediction: ['[CLS] squirrel straight ran. quickly straight [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.037 (perp=9.543, rec=0.122, cos=0.007), tot_loss_proj:2.637 [t=0.17s]
prediction: ['[CLS] squirrel ran straight. quickly straight [SEP]']
[ 300/2000] tot_loss=2.023 (perp=9.543, rec=0.108, cos=0.006), tot_loss_proj:2.630 [t=0.17s]
prediction: ['[CLS] squirrel ran straight. quickly straight [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.009 (perp=9.543, rec=0.096, cos=0.004), tot_loss_proj:2.607 [t=0.17s]
prediction: ['[CLS] squirrel ran straight. quickly straight [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.961 (perp=8.907, rec=0.152, cos=0.028), tot_loss_proj:2.253 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly, [SEP]']
[ 450/2000] tot_loss=1.705 (perp=7.949, rec=0.108, cos=0.007), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.689 (perp=7.949, rec=0.094, cos=0.005), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.683 (perp=7.949, rec=0.089, cos=0.004), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
[ 600/2000] tot_loss=1.675 (perp=7.949, rec=0.081, cos=0.004), tot_loss_proj:1.997 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.676 (perp=7.949, rec=0.082, cos=0.004), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.673 (perp=7.949, rec=0.079, cos=0.004), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
[ 750/2000] tot_loss=1.684 (perp=7.949, rec=0.090, cos=0.004), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.670 (perp=7.949, rec=0.077, cos=0.003), tot_loss_proj:2.003 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.685 (perp=7.949, rec=0.092, cos=0.003), tot_loss_proj:1.995 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
[ 900/2000] tot_loss=1.675 (perp=7.949, rec=0.082, cos=0.003), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.671 (perp=7.949, rec=0.078, cos=0.003), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.663 (perp=7.949, rec=0.070, cos=0.003), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
[1050/2000] tot_loss=1.664 (perp=7.949, rec=0.071, cos=0.003), tot_loss_proj:1.995 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.672 (perp=7.949, rec=0.079, cos=0.003), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.669 (perp=7.949, rec=0.077, cos=0.003), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
[1200/2000] tot_loss=1.670 (perp=7.949, rec=0.077, cos=0.003), tot_loss_proj:1.993 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.675 (perp=7.949, rec=0.082, cos=0.003), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.666 (perp=7.949, rec=0.074, cos=0.003), tot_loss_proj:1.995 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
[1350/2000] tot_loss=1.673 (perp=7.949, rec=0.080, cos=0.003), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.670 (perp=7.949, rec=0.077, cos=0.003), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.669 (perp=7.949, rec=0.076, cos=0.003), tot_loss_proj:1.992 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
[1500/2000] tot_loss=1.677 (perp=7.949, rec=0.084, cos=0.003), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.682 (perp=7.949, rec=0.089, cos=0.003), tot_loss_proj:2.002 [t=0.18s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.682 (perp=7.949, rec=0.090, cos=0.003), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
[1650/2000] tot_loss=1.675 (perp=7.949, rec=0.082, cos=0.003), tot_loss_proj:1.995 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.674 (perp=7.949, rec=0.081, cos=0.003), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.676 (perp=7.949, rec=0.083, cos=0.003), tot_loss_proj:1.995 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
[1800/2000] tot_loss=1.668 (perp=7.949, rec=0.075, cos=0.003), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.670 (perp=7.949, rec=0.077, cos=0.003), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.681 (perp=7.949, rec=0.088, cos=0.003), tot_loss_proj:1.994 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
[1950/2000] tot_loss=1.671 (perp=7.949, rec=0.078, cos=0.003), tot_loss_proj:2.003 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.671 (perp=7.949, rec=0.078, cos=0.003), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] squirrel ran straight straight quickly. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] the squirrel ran straight quickly. [SEP]
========================
predicted: 
========================
[CLS] squirrel ran straight straight quickly. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 152.381

[Aggregate metrics]:
rouge1     | fm: 83.369 | p: 82.913 | r: 84.131
rouge2     | fm: 37.715 | p: 37.358 | r: 38.361
rougeL     | fm: 68.648 | p: 68.134 | r: 69.447
rougeLsum  | fm: 68.691 | p: 68.266 | r: 69.412
r1fm+r2fm = 121.084

input #69 time: 0:07:14 | total time: 8:29:26


Running input #70 of 100.
reference: 
========================
I assumed to be innocent
========================
average of cosine similarity 0.9993176562362933
highest_index [0]
highest [0.9993176562362933]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 5071, 2000, 2022, 7036,  102]], device='cuda:0')
Debug: ref = ['[CLS] i assumed to be innocent [SEP]']
[Init] best rec loss: 0.7952191829681396 for ['[CLS] down op epithet medicine sick [SEP]']
[Init] best rec loss: 0.7703707814216614 for ['[CLS] small beings equation flightfall [SEP]']
[Init] best rec loss: 0.7321346402168274 for ['[CLS] allied breath road revelation airport [SEP]']
[Init] best rec loss: 0.728435754776001 for ['[CLS] [ across not inside stuff [SEP]']
[Init] best rec loss: 0.7198368906974792 for ['[CLS] breeding overseas signature activated points [SEP]']
[Init] best rec loss: 0.7161601781845093 for ['[CLS] honors protocolgne trackshis [SEP]']
[Init] best rec loss: 0.7038858532905579 for ['[CLS] oh kept middle pen opener [SEP]']
[Init] best perm rec loss: 0.7016999125480652 for ['[CLS] middle oh kept opener pen [SEP]']
[Init] best perm rec loss: 0.6995460987091064 for ['[CLS] pen opener kept middle oh [SEP]']
[Init] best perm rec loss: 0.6993598937988281 for ['[CLS] pen opener oh kept middle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.456 (perp=9.997, rec=0.407, cos=0.049), tot_loss_proj:2.820 [t=0.17s]
prediction: ['[CLS] poly was but was fact [SEP]']
[ 100/2000] tot_loss=1.697 (perp=7.099, rec=0.258, cos=0.019), tot_loss_proj:2.677 [t=0.17s]
prediction: ['[CLS] " assumed to be innocent [SEP]']
[ 150/2000] tot_loss=1.480 (perp=6.470, rec=0.177, cos=0.009), tot_loss_proj:1.514 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 200/2000] tot_loss=1.627 (perp=7.463, rec=0.130, cos=0.005), tot_loss_proj:2.653 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.602 (perp=7.463, rec=0.105, cos=0.004), tot_loss_proj:2.662 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[ 300/2000] tot_loss=1.601 (perp=7.463, rec=0.105, cos=0.004), tot_loss_proj:2.653 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.590 (perp=7.463, rec=0.094, cos=0.003), tot_loss_proj:2.651 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.585 (perp=7.463, rec=0.089, cos=0.003), tot_loss_proj:2.648 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[ 450/2000] tot_loss=1.592 (perp=7.463, rec=0.096, cos=0.003), tot_loss_proj:2.648 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.583 (perp=7.463, rec=0.088, cos=0.003), tot_loss_proj:2.642 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.591 (perp=7.463, rec=0.095, cos=0.003), tot_loss_proj:2.640 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[ 600/2000] tot_loss=1.597 (perp=7.463, rec=0.101, cos=0.003), tot_loss_proj:2.641 [t=0.18s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.588 (perp=7.463, rec=0.092, cos=0.003), tot_loss_proj:2.641 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.600 (perp=7.463, rec=0.104, cos=0.003), tot_loss_proj:2.633 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[ 750/2000] tot_loss=1.581 (perp=7.463, rec=0.086, cos=0.003), tot_loss_proj:2.629 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.577 (perp=7.463, rec=0.081, cos=0.003), tot_loss_proj:2.632 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.581 (perp=7.463, rec=0.086, cos=0.003), tot_loss_proj:2.628 [t=0.18s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[ 900/2000] tot_loss=1.583 (perp=7.463, rec=0.088, cos=0.003), tot_loss_proj:2.625 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.584 (perp=7.463, rec=0.088, cos=0.003), tot_loss_proj:2.626 [t=0.20s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.595 (perp=7.463, rec=0.099, cos=0.003), tot_loss_proj:2.620 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[1050/2000] tot_loss=1.582 (perp=7.463, rec=0.087, cos=0.003), tot_loss_proj:2.619 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.593 (perp=7.463, rec=0.097, cos=0.003), tot_loss_proj:2.618 [t=0.18s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.579 (perp=7.463, rec=0.083, cos=0.003), tot_loss_proj:2.620 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[1200/2000] tot_loss=1.587 (perp=7.463, rec=0.091, cos=0.003), tot_loss_proj:2.616 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.584 (perp=7.463, rec=0.089, cos=0.003), tot_loss_proj:2.616 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.590 (perp=7.463, rec=0.095, cos=0.003), tot_loss_proj:2.619 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[1350/2000] tot_loss=1.583 (perp=7.463, rec=0.087, cos=0.003), tot_loss_proj:2.612 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.587 (perp=7.463, rec=0.092, cos=0.003), tot_loss_proj:2.611 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.581 (perp=7.463, rec=0.085, cos=0.003), tot_loss_proj:2.604 [t=0.18s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[1500/2000] tot_loss=1.585 (perp=7.463, rec=0.090, cos=0.003), tot_loss_proj:2.610 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.586 (perp=7.463, rec=0.090, cos=0.003), tot_loss_proj:2.614 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.591 (perp=7.463, rec=0.096, cos=0.003), tot_loss_proj:2.606 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[1650/2000] tot_loss=1.590 (perp=7.463, rec=0.095, cos=0.003), tot_loss_proj:2.609 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.585 (perp=7.463, rec=0.090, cos=0.003), tot_loss_proj:2.609 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.591 (perp=7.463, rec=0.096, cos=0.003), tot_loss_proj:2.608 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[1800/2000] tot_loss=1.582 (perp=7.463, rec=0.087, cos=0.003), tot_loss_proj:2.606 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.593 (perp=7.463, rec=0.097, cos=0.003), tot_loss_proj:2.604 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.597 (perp=7.463, rec=0.101, cos=0.003), tot_loss_proj:2.602 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
[1950/2000] tot_loss=1.583 (perp=7.463, rec=0.088, cos=0.003), tot_loss_proj:2.607 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.589 (perp=7.463, rec=0.094, cos=0.003), tot_loss_proj:2.609 [t=0.17s]
prediction: ['[CLS] i assumed i be innocent [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] i assumed to be innocent [SEP]
========================
predicted: 
========================
[CLS] i assumed i be innocent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 152.381

[Aggregate metrics]:
rouge1     | fm: 83.427 | p: 82.961 | r: 84.222
rouge2     | fm: 38.087 | p: 37.756 | r: 38.637
rougeL     | fm: 69.001 | p: 68.535 | r: 69.734
rougeLsum  | fm: 68.868 | p: 68.453 | r: 69.564
r1fm+r2fm = 121.514

input #70 time: 0:07:11 | total time: 8:36:38


Running input #71 of 100.
reference: 
========================
He could not have been working.
========================
average of cosine similarity 0.9994072032581219
highest_index [0]
highest [0.9994072032581219]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2071, 2025, 2031, 2042, 2551, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he could not have been working. [SEP]']
[Init] best rec loss: 0.9744415879249573 for ['[CLS] winston q officer obedience maize creamkha [SEP]']
[Init] best rec loss: 0.9726535677909851 for ['[CLS] [CLS] holt mls urgent we hey following [SEP]']
[Init] best rec loss: 0.9473275542259216 for ['[CLS] source outside fairias bullet tyson accepted [SEP]']
[Init] best rec loss: 0.9002900719642639 for ['[CLS] production gojn species leaderern led [SEP]']
[Init] best rec loss: 0.8908352255821228 for ['[CLS] sykested abbey rhodesonia ne air [SEP]']
[Init] best rec loss: 0.8839952945709229 for ['[CLS] or led olympic fish pe studiespeed [SEP]']
[Init] best rec loss: 0.880422055721283 for ['[CLS] vincent families ass factoryper inhabited heaven [SEP]']
[Init] best rec loss: 0.8727516531944275 for ['[CLS] helpayaion gun quartersrdatitles [SEP]']
[Init] best rec loss: 0.8656829595565796 for ['[CLS] justice liner contra godizes sin colt [SEP]']
[Init] best rec loss: 0.8539422154426575 for ['[CLS] territory dale sienna yao aggregator see mother [SEP]']
[Init] best perm rec loss: 0.853902280330658 for ['[CLS] see dale aggregator sienna territory mother yao [SEP]']
[Init] best perm rec loss: 0.8496488928794861 for ['[CLS] aggregator see dale sienna mother territory yao [SEP]']
[Init] best perm rec loss: 0.8492418527603149 for ['[CLS] see sienna dale territory yao aggregator mother [SEP]']
[Init] best perm rec loss: 0.8487892150878906 for ['[CLS] see dale territory sienna mother aggregator yao [SEP]']
[Init] best perm rec loss: 0.846971869468689 for ['[CLS] sienna dale mother see yao aggregator territory [SEP]']
[Init] best perm rec loss: 0.8467850089073181 for ['[CLS] see territory dale yao mother aggregator sienna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.453 (perp=9.869, rec=0.556, cos=0.923), tot_loss_proj:3.765 [t=0.17s]
prediction: ['[CLS]ful organization.. she be thoughts [SEP]']
[ 100/2000] tot_loss=2.927 (perp=7.102, rec=0.530, cos=0.977), tot_loss_proj:3.289 [t=0.17s]
prediction: ['[CLS] not,.. she be working [SEP]']
[ 150/2000] tot_loss=2.229 (perp=9.197, rec=0.316, cos=0.073), tot_loss_proj:3.919 [t=0.17s]
prediction: ['[CLS] could times.? he be working [SEP]']
[ 200/2000] tot_loss=1.788 (perp=7.843, rec=0.202, cos=0.018), tot_loss_proj:3.509 [t=0.17s]
prediction: ['[CLS] could perhaps.. he be working [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.456 (perp=6.294, rec=0.180, cos=0.017), tot_loss_proj:2.718 [t=0.17s]
prediction: ['[CLS] perhaps.. he could be working [SEP]']
[ 300/2000] tot_loss=1.699 (perp=7.740, rec=0.140, cos=0.011), tot_loss_proj:3.485 [t=0.17s]
prediction: ['[CLS] perhaps. have he could be working [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.401 (perp=6.310, rec=0.131, cos=0.008), tot_loss_proj:3.135 [t=0.17s]
prediction: ['[CLS] perhaps have he could be working. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.290 (perp=5.858, rec=0.111, cos=0.007), tot_loss_proj:1.731 [t=0.17s]
prediction: ['[CLS] perhaps he could have be working. [SEP]']
[ 450/2000] tot_loss=1.288 (perp=5.858, rec=0.111, cos=0.006), tot_loss_proj:1.727 [t=0.17s]
prediction: ['[CLS] perhaps he could have be working. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.272 (perp=5.834, rec=0.100, cos=0.005), tot_loss_proj:3.082 [t=0.17s]
prediction: ['[CLS] not he could have be working. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.106 (perp=4.967, rec=0.106, cos=0.006), tot_loss_proj:1.391 [t=0.17s]
prediction: ['[CLS] he could have possibly been working. [SEP]']
[ 600/2000] tot_loss=1.183 (perp=5.366, rec=0.106, cos=0.004), tot_loss_proj:1.349 [t=0.17s]
prediction: ['[CLS] he could have not been working. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=0.894 (perp=4.026, rec=0.085, cos=0.003), tot_loss_proj:0.941 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.901 (perp=4.026, rec=0.093, cos=0.003), tot_loss_proj:0.937 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[ 750/2000] tot_loss=0.899 (perp=4.026, rec=0.091, cos=0.003), tot_loss_proj:0.945 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.898 (perp=4.026, rec=0.090, cos=0.003), tot_loss_proj:0.938 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.890 (perp=4.026, rec=0.082, cos=0.003), tot_loss_proj:0.944 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[ 900/2000] tot_loss=0.890 (perp=4.026, rec=0.082, cos=0.003), tot_loss_proj:0.950 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.894 (perp=4.026, rec=0.086, cos=0.003), tot_loss_proj:0.947 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.885 (perp=4.026, rec=0.077, cos=0.003), tot_loss_proj:0.944 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1050/2000] tot_loss=0.886 (perp=4.026, rec=0.079, cos=0.002), tot_loss_proj:0.939 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.891 (perp=4.026, rec=0.084, cos=0.001), tot_loss_proj:0.934 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.879 (perp=4.026, rec=0.073, cos=0.001), tot_loss_proj:0.940 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1200/2000] tot_loss=0.874 (perp=4.026, rec=0.067, cos=0.001), tot_loss_proj:0.948 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.868 (perp=4.026, rec=0.061, cos=0.001), tot_loss_proj:0.941 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.868 (perp=4.026, rec=0.062, cos=0.001), tot_loss_proj:0.944 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1350/2000] tot_loss=0.878 (perp=4.026, rec=0.071, cos=0.001), tot_loss_proj:0.933 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.874 (perp=4.026, rec=0.067, cos=0.001), tot_loss_proj:0.937 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.871 (perp=4.026, rec=0.065, cos=0.001), tot_loss_proj:0.931 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1500/2000] tot_loss=0.869 (perp=4.026, rec=0.062, cos=0.001), tot_loss_proj:0.946 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.880 (perp=4.026, rec=0.073, cos=0.001), tot_loss_proj:0.940 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.870 (perp=4.026, rec=0.064, cos=0.001), tot_loss_proj:0.940 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1650/2000] tot_loss=0.886 (perp=4.026, rec=0.079, cos=0.001), tot_loss_proj:0.944 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.881 (perp=4.026, rec=0.075, cos=0.001), tot_loss_proj:0.943 [t=0.20s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.867 (perp=4.026, rec=0.061, cos=0.001), tot_loss_proj:0.940 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1800/2000] tot_loss=0.873 (perp=4.026, rec=0.067, cos=0.001), tot_loss_proj:0.936 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.876 (perp=4.026, rec=0.070, cos=0.001), tot_loss_proj:0.933 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.872 (perp=4.026, rec=0.065, cos=0.001), tot_loss_proj:0.932 [t=0.19s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1950/2000] tot_loss=0.881 (perp=4.026, rec=0.075, cos=0.001), tot_loss_proj:0.938 [t=0.19s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.872 (perp=4.026, rec=0.065, cos=0.001), tot_loss_proj:0.942 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] he could not have been working. [SEP]
========================
predicted: 
========================
[CLS] he could not have been working. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.662 | p: 83.228 | r: 84.392
rouge2     | fm: 38.921 | p: 38.510 | r: 39.512
rougeL     | fm: 69.377 | p: 68.911 | r: 70.155
rougeLsum  | fm: 69.282 | p: 68.870 | r: 69.997
r1fm+r2fm = 122.582

input #71 time: 0:07:19 | total time: 8:43:58


Running input #72 of 100.
reference: 
========================
He goes.
========================
average of cosine similarity 0.9991964877569263
highest_index [0]
highest [0.9991964877569263]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 2002, 3632, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he goes. [SEP]']
[Init] best rec loss: 0.9233094453811646 for ['[CLS] prior keynes latter [SEP]']
[Init] best rec loss: 0.8991621136665344 for ['[CLS] diver prism theme [SEP]']
[Init] best rec loss: 0.8955864310264587 for ['[CLS] bbc coat coin [SEP]']
[Init] best rec loss: 0.8779672980308533 for ['[CLS] gets handsome fever [SEP]']
[Init] best rec loss: 0.8525456190109253 for ['[CLS]cat soldina [SEP]']
[Init] best rec loss: 0.8413464426994324 for ['[CLS] shouldn might wight [SEP]']
[Init] best perm rec loss: 0.8409014940261841 for ['[CLS] might wight shouldn [SEP]']
[Init] best perm rec loss: 0.8379490971565247 for ['[CLS] shouldn wight might [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.332 (perp=9.665, rec=0.337, cos=0.062), tot_loss_proj:4.023 [t=0.19s]
prediction: ['[CLS] goes. might [SEP]']
[ 100/2000] tot_loss=1.504 (perp=6.727, rec=0.142, cos=0.017), tot_loss_proj:3.323 [t=0.19s]
prediction: ['[CLS] he goes all [SEP]']
[ 150/2000] tot_loss=1.175 (perp=5.241, rec=0.116, cos=0.010), tot_loss_proj:1.244 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
[ 200/2000] tot_loss=1.169 (perp=5.241, rec=0.111, cos=0.009), tot_loss_proj:1.240 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.154 (perp=5.241, rec=0.097, cos=0.008), tot_loss_proj:1.233 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 300/2000] tot_loss=1.123 (perp=5.241, rec=0.073, cos=0.002), tot_loss_proj:1.208 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.125 (perp=5.241, rec=0.075, cos=0.002), tot_loss_proj:1.205 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.123 (perp=5.241, rec=0.073, cos=0.002), tot_loss_proj:1.224 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
[ 450/2000] tot_loss=1.103 (perp=5.241, rec=0.053, cos=0.002), tot_loss_proj:1.214 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.113 (perp=5.241, rec=0.063, cos=0.002), tot_loss_proj:1.217 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.116 (perp=5.241, rec=0.067, cos=0.002), tot_loss_proj:1.215 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 600/2000] tot_loss=1.107 (perp=5.241, rec=0.058, cos=0.002), tot_loss_proj:1.223 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.101 (perp=5.241, rec=0.051, cos=0.002), tot_loss_proj:1.219 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.106 (perp=5.241, rec=0.057, cos=0.002), tot_loss_proj:1.216 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 750/2000] tot_loss=1.122 (perp=5.241, rec=0.072, cos=0.002), tot_loss_proj:1.217 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.127 (perp=5.241, rec=0.077, cos=0.002), tot_loss_proj:1.221 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.101 (perp=5.241, rec=0.051, cos=0.002), tot_loss_proj:1.214 [t=0.22s]
prediction: ['[CLS] he goes. [SEP]']
[ 900/2000] tot_loss=1.116 (perp=5.241, rec=0.066, cos=0.002), tot_loss_proj:1.220 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.112 (perp=5.241, rec=0.062, cos=0.002), tot_loss_proj:1.217 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.116 (perp=5.241, rec=0.067, cos=0.002), tot_loss_proj:1.223 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1050/2000] tot_loss=1.112 (perp=5.241, rec=0.063, cos=0.002), tot_loss_proj:1.212 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.100 (perp=5.241, rec=0.051, cos=0.002), tot_loss_proj:1.215 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.103 (perp=5.241, rec=0.053, cos=0.002), tot_loss_proj:1.224 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1200/2000] tot_loss=1.110 (perp=5.241, rec=0.060, cos=0.002), tot_loss_proj:1.218 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.106 (perp=5.241, rec=0.057, cos=0.002), tot_loss_proj:1.225 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.112 (perp=5.241, rec=0.062, cos=0.002), tot_loss_proj:1.216 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1350/2000] tot_loss=1.107 (perp=5.241, rec=0.057, cos=0.002), tot_loss_proj:1.219 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.123 (perp=5.241, rec=0.073, cos=0.002), tot_loss_proj:1.219 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.115 (perp=5.241, rec=0.065, cos=0.002), tot_loss_proj:1.224 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1500/2000] tot_loss=1.099 (perp=5.241, rec=0.049, cos=0.002), tot_loss_proj:1.217 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.108 (perp=5.241, rec=0.058, cos=0.002), tot_loss_proj:1.209 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.115 (perp=5.241, rec=0.066, cos=0.002), tot_loss_proj:1.207 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1650/2000] tot_loss=1.108 (perp=5.241, rec=0.058, cos=0.002), tot_loss_proj:1.220 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.115 (perp=5.241, rec=0.065, cos=0.002), tot_loss_proj:1.226 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.115 (perp=5.241, rec=0.065, cos=0.002), tot_loss_proj:1.218 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1800/2000] tot_loss=1.114 (perp=5.241, rec=0.064, cos=0.002), tot_loss_proj:1.219 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.117 (perp=5.241, rec=0.068, cos=0.002), tot_loss_proj:1.219 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.127 (perp=5.241, rec=0.077, cos=0.002), tot_loss_proj:1.210 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1950/2000] tot_loss=1.103 (perp=5.241, rec=0.053, cos=0.002), tot_loss_proj:1.218 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.113 (perp=5.241, rec=0.063, cos=0.002), tot_loss_proj:1.216 [t=0.18s]
prediction: ['[CLS] he goes. [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] he goes. [SEP]
========================
predicted: 
========================
[CLS] he goes. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.795 | p: 83.337 | r: 84.551
rouge2     | fm: 39.853 | p: 39.430 | r: 40.335
rougeL     | fm: 69.801 | p: 69.433 | r: 70.544
rougeLsum  | fm: 69.662 | p: 69.248 | r: 70.375
r1fm+r2fm = 123.649

input #72 time: 0:07:09 | total time: 8:51:07


Running input #73 of 100.
reference: 
========================
This machine records well.
========================
average of cosine similarity 0.9994617040871804
highest_index [0]
highest [0.9994617040871804]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2023, 3698, 2636, 2092, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] this machine records well. [SEP]']
[Init] best rec loss: 0.8837974071502686 for ['[CLS] miss violet chord parole tempo [SEP]']
[Init] best rec loss: 0.871936559677124 for ['[CLS]dilly records fortune instituteberry [SEP]']
[Init] best rec loss: 0.8340340852737427 for ['[CLS] guest brushed news pursuing church [SEP]']
[Init] best perm rec loss: 0.8322038054466248 for ['[CLS] brushed news church pursuing guest [SEP]']
[Init] best perm rec loss: 0.8311283588409424 for ['[CLS] brushed news guest pursuing church [SEP]']
[Init] best perm rec loss: 0.8308789730072021 for ['[CLS] brushed news pursuing guest church [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.824 (perp=11.480, rec=0.588, cos=0.940), tot_loss_proj:4.172 [t=0.17s]
prediction: ['[CLS]. vantage quite, law [SEP]']
[ 100/2000] tot_loss=3.486 (perp=10.503, rec=0.526, cos=0.859), tot_loss_proj:4.101 [t=0.18s]
prediction: ['[CLS]. beetle quite. demanded [SEP]']
[ 150/2000] tot_loss=3.821 (perp=10.361, rec=1.008, cos=0.741), tot_loss_proj:4.059 [t=0.17s]
prediction: ['[CLS] records genus quite. records [SEP]']
[ 200/2000] tot_loss=3.591 (perp=11.069, rec=0.628, cos=0.749), tot_loss_proj:4.235 [t=0.20s]
prediction: ['[CLS] records genera today that taylor [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.734 (perp=11.433, rec=0.375, cos=0.072), tot_loss_proj:4.274 [t=0.17s]
prediction: ['[CLS] records machine genusry records [SEP]']
[ 300/2000] tot_loss=2.392 (perp=10.263, rec=0.306, cos=0.034), tot_loss_proj:3.776 [t=0.17s]
prediction: ['[CLS] records machine technique standard records [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.069 (perp=8.791, rec=0.288, cos=0.023), tot_loss_proj:3.421 [t=0.17s]
prediction: ['[CLS] machine records technique records records [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.033 (perp=8.791, rec=0.255, cos=0.020), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] machine records technique records records [SEP]']
[ 450/2000] tot_loss=2.341 (perp=10.399, rec=0.243, cos=0.018), tot_loss_proj:3.861 [t=0.17s]
prediction: ['[CLS] machine records fill well records [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.315 (perp=10.399, rec=0.219, cos=0.016), tot_loss_proj:3.862 [t=0.17s]
prediction: ['[CLS] machine records fill well records [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.761 (perp=12.136, rec=0.298, cos=0.037), tot_loss_proj:4.223 [t=0.17s]
prediction: ['[CLS] records machine fill enough machine [SEP]']
[ 600/2000] tot_loss=2.608 (perp=11.727, rec=0.244, cos=0.019), tot_loss_proj:4.410 [t=0.17s]
prediction: ['[CLS] records machine fill well records [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.324 (perp=10.399, rec=0.228, cos=0.016), tot_loss_proj:3.889 [t=0.17s]
prediction: ['[CLS] machine records fill well records [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.089 (perp=9.267, rec=0.217, cos=0.019), tot_loss_proj:3.690 [t=0.17s]
prediction: ['[CLS] machine records well fill records [SEP]']
[ 750/2000] tot_loss=2.163 (perp=9.708, rec=0.207, cos=0.015), tot_loss_proj:3.955 [t=0.17s]
prediction: ['[CLS] machine records well switch records [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.971 (perp=8.766, rec=0.202, cos=0.016), tot_loss_proj:3.662 [t=0.17s]
prediction: ['[CLS] well records machine switch records [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.968 (perp=8.766, rec=0.200, cos=0.015), tot_loss_proj:3.664 [t=0.17s]
prediction: ['[CLS] well records machine switch records [SEP]']
[ 900/2000] tot_loss=1.990 (perp=8.854, rec=0.205, cos=0.015), tot_loss_proj:3.774 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.976 (perp=8.854, rec=0.191, cos=0.015), tot_loss_proj:3.773 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1000/2000] tot_loss=1.975 (perp=8.854, rec=0.190, cos=0.014), tot_loss_proj:3.772 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
[1050/2000] tot_loss=1.982 (perp=8.854, rec=0.197, cos=0.014), tot_loss_proj:3.771 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1100/2000] tot_loss=1.976 (perp=8.854, rec=0.192, cos=0.014), tot_loss_proj:3.774 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1150/2000] tot_loss=1.976 (perp=8.854, rec=0.191, cos=0.014), tot_loss_proj:3.773 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
[1200/2000] tot_loss=1.972 (perp=8.854, rec=0.187, cos=0.013), tot_loss_proj:3.773 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1250/2000] tot_loss=1.963 (perp=8.854, rec=0.179, cos=0.013), tot_loss_proj:3.771 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1300/2000] tot_loss=1.964 (perp=8.854, rec=0.180, cos=0.013), tot_loss_proj:3.770 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
[1350/2000] tot_loss=1.962 (perp=8.854, rec=0.178, cos=0.013), tot_loss_proj:3.770 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1400/2000] tot_loss=1.955 (perp=8.854, rec=0.171, cos=0.013), tot_loss_proj:3.772 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1450/2000] tot_loss=1.963 (perp=8.854, rec=0.180, cos=0.013), tot_loss_proj:3.773 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
[1500/2000] tot_loss=1.951 (perp=8.854, rec=0.168, cos=0.012), tot_loss_proj:3.770 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1550/2000] tot_loss=1.953 (perp=8.854, rec=0.170, cos=0.012), tot_loss_proj:3.773 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1600/2000] tot_loss=1.945 (perp=8.854, rec=0.162, cos=0.012), tot_loss_proj:3.773 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
[1650/2000] tot_loss=1.949 (perp=8.854, rec=0.166, cos=0.012), tot_loss_proj:3.776 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1700/2000] tot_loss=1.947 (perp=8.854, rec=0.164, cos=0.012), tot_loss_proj:3.772 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1750/2000] tot_loss=1.948 (perp=8.854, rec=0.165, cos=0.012), tot_loss_proj:3.770 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
[1800/2000] tot_loss=1.934 (perp=8.854, rec=0.153, cos=0.010), tot_loss_proj:3.775 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1850/2000] tot_loss=1.940 (perp=8.854, rec=0.161, cos=0.009), tot_loss_proj:3.771 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[1900/2000] tot_loss=1.923 (perp=8.854, rec=0.144, cos=0.009), tot_loss_proj:3.767 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
[1950/2000] tot_loss=1.917 (perp=8.854, rec=0.137, cos=0.009), tot_loss_proj:3.772 [t=0.17s]
prediction: ['[CLS] well this machine switch records [SEP]']
Attempt swap
[2000/2000] tot_loss=1.916 (perp=8.854, rec=0.136, cos=0.009), tot_loss_proj:3.772 [t=0.18s]
prediction: ['[CLS] well this machine switch records [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] this machine records well. [SEP]
========================
predicted: 
========================
[CLS] well this machine switch records [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 18.182 | p: 16.667 | r: 20.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 110.490

[Aggregate metrics]:
rouge1     | fm: 83.996 | p: 83.454 | r: 84.868
rouge2     | fm: 39.590 | p: 39.201 | r: 40.141
rougeL     | fm: 69.944 | p: 69.419 | r: 70.691
rougeLsum  | fm: 69.725 | p: 69.210 | r: 70.557
r1fm+r2fm = 123.586

input #73 time: 0:06:59 | total time: 8:58:07


Running input #74 of 100.
reference: 
========================
Love her though I may, that won't affect the grade.
========================
average of cosine similarity 0.9993168384864592
highest_index [0]
highest [0.9993168384864592]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2293, 2014, 2295, 1045, 2089, 1010, 2008, 2180, 1005, 1056, 7461,
         1996, 3694, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] love her though i may, that won't affect the grade. [SEP]"]
[Init] best rec loss: 1.0024644136428833 for ['[CLS] charm joke classification lemon vhs d （ alzheimer minogueify gunslinger part used club [SEP]']
[Init] best rec loss: 0.9267971515655518 for ['[CLS] blast health charliebase can through letterns door alternatives attenditatedatin competed [SEP]']
[Init] best rec loss: 0.9037371873855591 for ['[CLS] passed eva with two history outward box cai shuffleeritt wonders temple aware [SEP]']
[Init] best rec loss: 0.892467737197876 for ['[CLS] orient conner dresser canada came belly sing sri front jacobdate pharaoh? devon [SEP]']
[Init] best rec loss: 0.875771701335907 for ['[CLS] inflation frowned knew clapped rosalie executed affecteda wild blue keptrcle za rafe [SEP]']
[Init] best rec loss: 0.8655742406845093 for ['[CLS] dot topic strip investigation kg facing chang mani causedond have millie bank divided [SEP]']
[Init] best rec loss: 0.854909360408783 for ['[CLS] par animals gavin hokkaido fisherman gttwined yetrgy sexual thank sophia aim gag [SEP]']
[Init] best perm rec loss: 0.8548519015312195 for ['[CLS] hokkaido gt thank par sophiatwinedrgy aim yet gavin fisherman gag animals sexual [SEP]']
[Init] best perm rec loss: 0.8532049655914307 for ['[CLS] animalsrgy gag aim sophia hokkaido fisherman par thank sexual gt gavin yettwined [SEP]']
[Init] best perm rec loss: 0.8515307903289795 for ['[CLS]rgy gag sophia sexual gavintwined thank fisherman par hokkaido aim animals gt yet [SEP]']
[Init] best perm rec loss: 0.84995037317276 for ['[CLS] parrgy sophiatwined gavin aim thank gt sexual yet fisherman animals hokkaido gag [SEP]']
[Init] best perm rec loss: 0.8490588068962097 for ['[CLS] sexualrgy animals gavin gag fisherman partwined hokkaido aim gt thank yet sophia [SEP]']
[Init] best perm rec loss: 0.8482096195220947 for ['[CLS] aim thank animalstwined par gavin hokkaido yetrgy fisherman gag sexual gt sophia [SEP]']
[Init] best perm rec loss: 0.8481844067573547 for ['[CLS] par gavin hokkaido thank fishermantwined sexual gag aim yet gtrgy sophia animals [SEP]']
[Init] best perm rec loss: 0.845284104347229 for ['[CLS] sexual gagtwined sophia gavin gt thank hokkaido fisherman animals yetrgy par aim [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.993 (perp=10.672, rec=0.622, cos=0.237), tot_loss_proj:4.062 [t=0.17s]
prediction: ['[CLS] - : roger de smashwords interests thomas anymore, your yet eat residence playing [SEP]']
[ 100/2000] tot_loss=3.032 (perp=11.995, rec=0.484, cos=0.148), tot_loss_proj:4.306 [t=0.17s]
prediction: ['[CLS] my :lt jin, carefullyr sudden picturesright fantasy classroom how little [SEP]']
[ 150/2000] tot_loss=2.750 (perp=10.937, rec=0.447, cos=0.116), tot_loss_proj:4.093 [t=0.19s]
prediction: ['[CLS] my how ep scottish! mostly flynn love novelfa rhythm avery his. [SEP]']
[ 200/2000] tot_loss=2.420 (perp=10.238, rec=0.341, cos=0.031), tot_loss_proj:3.970 [t=0.17s]
prediction: ['[CLS] love how. scotland. mostly would love novelfa the grade her. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.100 (perp=8.848, rec=0.302, cos=0.028), tot_loss_proj:3.674 [t=0.17s]
prediction: ['[CLS]fa how. love, mostly would love dreams love science grade her. [SEP]']
[ 300/2000] tot_loss=1.983 (perp=8.490, rec=0.267, cos=0.018), tot_loss_proj:3.597 [t=0.17s]
prediction: ['[CLS]fa how anyway love, mostly would love or love the grade her. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.723 (perp=7.319, rec=0.241, cos=0.018), tot_loss_proj:3.383 [t=0.17s]
prediction: ['[CLS]nt how mostly love, anyway would love or love the grade her. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.704 (perp=7.277, rec=0.230, cos=0.019), tot_loss_proj:3.395 [t=0.17s]
prediction: ['[CLS]nt would mostly love anyway, would love or i the grade her. [SEP]']
[ 450/2000] tot_loss=1.909 (perp=7.680, rec=0.297, cos=0.076), tot_loss_proj:3.491 [t=0.17s]
prediction: ['[CLS]nt would mostly love though, would love or i the grade her. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.598 (perp=6.868, rec=0.209, cos=0.015), tot_loss_proj:3.302 [t=0.17s]
prediction: ['[CLS]nt would mostly love though, the love or i would grade her. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.642 (perp=7.187, rec=0.194, cos=0.011), tot_loss_proj:3.330 [t=0.17s]
prediction: ['[CLS]nt would mostly loved though, the love or i would grade her. [SEP]']
[ 600/2000] tot_loss=1.674 (perp=7.360, rec=0.192, cos=0.010), tot_loss_proj:3.393 [t=0.17s]
prediction: ['[CLS]nt though mostly loved though, the love or i would grade her. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.783 (perp=7.921, rec=0.189, cos=0.010), tot_loss_proj:3.487 [t=0.17s]
prediction: ['[CLS]nt though mostly loved though, affect love or i would grade her. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.847 (perp=7.927, rec=0.233, cos=0.029), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] mostly thoughfa loved though, the love or i would grade her. [SEP]']
[ 750/2000] tot_loss=1.843 (perp=8.190, rec=0.192, cos=0.013), tot_loss_proj:3.524 [t=0.17s]
prediction: ['[CLS] mostly thoughr loved though, affect love or i would grade her. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.722 (perp=7.664, rec=0.179, cos=0.011), tot_loss_proj:3.435 [t=0.17s]
prediction: ['[CLS]r though mostly love though, affect love or i would grade her. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.832 (perp=8.045, rec=0.200, cos=0.023), tot_loss_proj:3.482 [t=0.17s]
prediction: ['[CLS]r though mostly affect, though affect love or i would grade her. [SEP]']
[ 900/2000] tot_loss=1.747 (perp=7.857, rec=0.164, cos=0.012), tot_loss_proj:3.485 [t=0.17s]
prediction: ['[CLS]r though mostly affect, might affect love or i would grade her. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.646 (perp=7.395, rec=0.156, cos=0.010), tot_loss_proj:3.379 [t=0.19s]
prediction: ['[CLS]r though though affect or might affect love, i would grade her. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.704 (perp=7.650, rec=0.163, cos=0.011), tot_loss_proj:3.423 [t=0.20s]
prediction: ['[CLS]r though though or affect might affect love, i would grade her. [SEP]']
[1050/2000] tot_loss=1.662 (perp=7.437, rec=0.164, cos=0.010), tot_loss_proj:3.377 [t=0.19s]
prediction: ['[CLS]r though though or affect may affect love, i would grade her. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.601 (perp=7.186, rec=0.153, cos=0.010), tot_loss_proj:3.347 [t=0.17s]
prediction: ['[CLS] though thoughr or affect may affect love, i would grade her. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.584 (perp=7.060, rec=0.161, cos=0.011), tot_loss_proj:3.328 [t=0.17s]
prediction: ['[CLS] though though or affectr may affect love, i would grade her. [SEP]']
[1200/2000] tot_loss=1.574 (perp=7.084, rec=0.148, cos=0.009), tot_loss_proj:3.339 [t=0.17s]
prediction: ['[CLS] though though, affectr may affect love, i would grade her. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.578 (perp=7.084, rec=0.152, cos=0.010), tot_loss_proj:3.341 [t=0.17s]
prediction: ['[CLS] though though, affectr may affect love, i would grade her. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.574 (perp=7.084, rec=0.148, cos=0.009), tot_loss_proj:3.340 [t=0.17s]
prediction: ['[CLS] though though, affectr may affect love, i would grade her. [SEP]']
[1350/2000] tot_loss=1.571 (perp=7.110, rec=0.140, cos=0.008), tot_loss_proj:3.336 [t=0.17s]
prediction: ['[CLS] though though, affectedr may affect love, i would grade her. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.566 (perp=7.110, rec=0.135, cos=0.008), tot_loss_proj:3.339 [t=0.17s]
prediction: ['[CLS] though though, affectedr may affect love, i would grade her. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.565 (perp=7.110, rec=0.135, cos=0.008), tot_loss_proj:3.338 [t=0.17s]
prediction: ['[CLS] though though, affectedr may affect love, i would grade her. [SEP]']
[1500/2000] tot_loss=1.575 (perp=7.110, rec=0.145, cos=0.008), tot_loss_proj:3.336 [t=0.17s]
prediction: ['[CLS] though though, affectedr may affect love, i would grade her. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.580 (perp=7.110, rec=0.150, cos=0.008), tot_loss_proj:3.337 [t=0.19s]
prediction: ['[CLS] though though, affectedr may affect love, i would grade her. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.573 (perp=7.110, rec=0.143, cos=0.008), tot_loss_proj:3.339 [t=0.17s]
prediction: ['[CLS] though though, affectedr may affect love, i would grade her. [SEP]']
[1650/2000] tot_loss=1.567 (perp=7.110, rec=0.137, cos=0.008), tot_loss_proj:3.333 [t=0.19s]
prediction: ['[CLS] though though, affectedr may affect love, i would grade her. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.552 (perp=7.048, rec=0.135, cos=0.008), tot_loss_proj:3.304 [t=0.17s]
prediction: ['[CLS]r though, affected though may affect love, i would grade her. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.499 (perp=6.715, rec=0.146, cos=0.010), tot_loss_proj:3.254 [t=0.17s]
prediction: ['[CLS]r though, though affected may affect love, i would grade her. [SEP]']
[1800/2000] tot_loss=1.501 (perp=6.715, rec=0.150, cos=0.008), tot_loss_proj:3.254 [t=0.17s]
prediction: ['[CLS]r though, though affected may affect love, i would grade her. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.489 (perp=6.715, rec=0.138, cos=0.008), tot_loss_proj:3.258 [t=0.18s]
prediction: ['[CLS]r though, though affected may affect love, i would grade her. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.488 (perp=6.715, rec=0.137, cos=0.008), tot_loss_proj:3.248 [t=0.17s]
prediction: ['[CLS]r though, though affected may affect love, i would grade her. [SEP]']
[1950/2000] tot_loss=1.493 (perp=6.715, rec=0.142, cos=0.008), tot_loss_proj:3.253 [t=0.17s]
prediction: ['[CLS]r though, though affected may affect love, i would grade her. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.486 (perp=6.715, rec=0.135, cos=0.008), tot_loss_proj:3.251 [t=0.17s]
prediction: ['[CLS]r though, though affected may affect love, i would grade her. [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] love her though i may, that won't affect the grade. [SEP]
========================
predicted: 
========================
[CLS]r though, though affected may affect love, i would grade her. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.231 | p: 69.231 | r: 69.231
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 46.154 | p: 46.154 | r: 46.154
rougeLsum  | fm: 46.154 | p: 46.154 | r: 46.154
r1fm+r2fm = 69.231

[Aggregate metrics]:
rouge1     | fm: 83.792 | p: 83.249 | r: 84.623
rouge2     | fm: 38.817 | p: 38.480 | r: 39.333
rougeL     | fm: 69.565 | p: 69.091 | r: 70.342
rougeLsum  | fm: 69.518 | p: 69.038 | r: 70.346
r1fm+r2fm = 122.609

input #74 time: 0:07:11 | total time: 9:05:18


Running input #75 of 100.
reference: 
========================
I have been flying helicopters for years.
========================
average of cosine similarity 0.9993561168596996
highest_index [0]
highest [0.9993561168596996]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1045,  2031,  2042,  3909, 12400,  2005,  2086,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have been flying helicopters for years. [SEP]']
[Init] best rec loss: 0.9605770111083984 for ['[CLS] lindsey exposed gov recreation touch approaching lack troubles [SEP]']
[Init] best rec loss: 0.9479166865348816 for ['[CLS] typical who paul slavery { distinction summit loop [SEP]']
[Init] best rec loss: 0.9144813418388367 for ['[CLS] caineding venture goethe protocolht base great [SEP]']
[Init] best perm rec loss: 0.9137658476829529 for ['[CLS]ding goethe great caine base protocol ventureht [SEP]']
[Init] best perm rec loss: 0.9111108779907227 for ['[CLS] caineding venture goethe baseht great protocol [SEP]']
[Init] best perm rec loss: 0.9083705544471741 for ['[CLS] goethe caine ventureding base protocol greatht [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.519 (perp=10.581, rec=0.356, cos=0.047), tot_loss_proj:3.891 [t=0.17s]
prediction: ['[CLS] damn thewood conducting helicopters helicopters patrol. [SEP]']
[ 100/2000] tot_loss=2.152 (perp=9.629, rec=0.213, cos=0.013), tot_loss_proj:3.742 [t=0.17s]
prediction: ['[CLS] i flyinghammer flying helicopters helicopters years. [SEP]']
[ 150/2000] tot_loss=2.401 (perp=11.110, rec=0.169, cos=0.010), tot_loss_proj:4.004 [t=0.17s]
prediction: ['[CLS] i recentnant flying helicopters helicopters years. [SEP]']
[ 200/2000] tot_loss=1.373 (perp=6.201, rec=0.128, cos=0.005), tot_loss_proj:3.325 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.363 (perp=6.201, rec=0.119, cos=0.004), tot_loss_proj:3.311 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
[ 300/2000] tot_loss=1.346 (perp=6.201, rec=0.102, cos=0.004), tot_loss_proj:3.307 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.346 (perp=6.201, rec=0.102, cos=0.004), tot_loss_proj:3.304 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.357 (perp=6.201, rec=0.113, cos=0.004), tot_loss_proj:3.302 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
[ 450/2000] tot_loss=1.344 (perp=6.201, rec=0.100, cos=0.004), tot_loss_proj:3.300 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.348 (perp=6.201, rec=0.105, cos=0.003), tot_loss_proj:3.298 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.346 (perp=6.201, rec=0.102, cos=0.004), tot_loss_proj:3.297 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
[ 600/2000] tot_loss=1.356 (perp=6.201, rec=0.113, cos=0.003), tot_loss_proj:3.289 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.344 (perp=6.201, rec=0.101, cos=0.003), tot_loss_proj:3.295 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.340 (perp=6.201, rec=0.097, cos=0.003), tot_loss_proj:3.287 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
[ 750/2000] tot_loss=1.350 (perp=6.201, rec=0.107, cos=0.003), tot_loss_proj:3.288 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.345 (perp=6.201, rec=0.101, cos=0.003), tot_loss_proj:3.291 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.351 (perp=6.201, rec=0.108, cos=0.003), tot_loss_proj:3.290 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
[ 900/2000] tot_loss=1.332 (perp=6.201, rec=0.089, cos=0.003), tot_loss_proj:3.292 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.336 (perp=6.201, rec=0.093, cos=0.003), tot_loss_proj:3.291 [t=0.18s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.342 (perp=6.201, rec=0.099, cos=0.003), tot_loss_proj:3.283 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters years have. [SEP]']
[1050/2000] tot_loss=1.849 (perp=8.814, rec=0.084, cos=0.003), tot_loss_proj:3.676 [t=0.17s]
prediction: ['[CLS] i for been flying helicopters years have. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.819 (perp=8.620, rec=0.093, cos=0.003), tot_loss_proj:3.644 [t=0.17s]
prediction: ['[CLS] i for been flying helicopters have years. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.355 (perp=6.236, rec=0.103, cos=0.005), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] i been flying helicopters have for years. [SEP]']
[1200/2000] tot_loss=1.354 (perp=6.236, rec=0.103, cos=0.003), tot_loss_proj:3.388 [t=0.17s]
prediction: ['[CLS] i been flying helicopters have for years. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=0.975 (perp=4.434, rec=0.086, cos=0.003), tot_loss_proj:1.002 [t=0.18s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.968 (perp=4.434, rec=0.078, cos=0.002), tot_loss_proj:1.007 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
[1350/2000] tot_loss=0.970 (perp=4.434, rec=0.081, cos=0.002), tot_loss_proj:1.004 [t=0.18s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.973 (perp=4.434, rec=0.084, cos=0.002), tot_loss_proj:1.009 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.968 (perp=4.434, rec=0.079, cos=0.001), tot_loss_proj:1.015 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
[1500/2000] tot_loss=0.959 (perp=4.434, rec=0.071, cos=0.001), tot_loss_proj:1.012 [t=0.18s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.964 (perp=4.434, rec=0.076, cos=0.001), tot_loss_proj:1.007 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.957 (perp=4.434, rec=0.069, cos=0.001), tot_loss_proj:1.005 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
[1650/2000] tot_loss=0.957 (perp=4.434, rec=0.069, cos=0.001), tot_loss_proj:1.011 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.956 (perp=4.434, rec=0.068, cos=0.001), tot_loss_proj:1.000 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.964 (perp=4.434, rec=0.076, cos=0.001), tot_loss_proj:1.008 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
[1800/2000] tot_loss=0.962 (perp=4.434, rec=0.074, cos=0.001), tot_loss_proj:1.006 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.961 (perp=4.434, rec=0.073, cos=0.001), tot_loss_proj:1.002 [t=0.18s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.948 (perp=4.434, rec=0.060, cos=0.001), tot_loss_proj:1.007 [t=0.21s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
[1950/2000] tot_loss=0.966 (perp=4.434, rec=0.078, cos=0.001), tot_loss_proj:1.008 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.961 (perp=4.434, rec=0.073, cos=0.001), tot_loss_proj:1.010 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] i have been flying helicopters for years. [SEP]
========================
predicted: 
========================
[CLS] i have been flying helicopters for years. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 84.011 | p: 83.499 | r: 84.782
rouge2     | fm: 39.730 | p: 39.376 | r: 40.319
rougeL     | fm: 69.948 | p: 69.378 | r: 70.719
rougeLsum  | fm: 69.986 | p: 69.419 | r: 70.688
r1fm+r2fm = 123.741

input #75 time: 0:07:05 | total time: 9:12:23


Running input #76 of 100.
reference: 
========================
the person stand on my foot is heavy.
========================
average of cosine similarity 0.9993156362431244
highest_index [0]
highest [0.9993156362431244]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2711, 3233, 2006, 2026, 3329, 2003, 3082, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the person stand on my foot is heavy. [SEP]']
[Init] best rec loss: 0.8294539451599121 for ['[CLS] yes motorway has entering lin trust d dante without [SEP]']
[Init] best rec loss: 0.8037463426589966 for ['[CLS] concrete supportke police liszt gracelay masjid empress [SEP]']
[Init] best rec loss: 0.798318088054657 for ['[CLS] right atgang connecting naturalistpy half use feud [SEP]']
[Init] best rec loss: 0.7697778344154358 for ['[CLS] speech largest endemicner flow stateism decenttrust [SEP]']
[Init] best rec loss: 0.7677800059318542 for ['[CLS] tag merlin heardhang land anywayimeter anastasia compare [SEP]']
[Init] best rec loss: 0.7535086870193481 for ['[CLS]xt missionary drive draft vancouver camp glory walker un [SEP]']
[Init] best rec loss: 0.7463003396987915 for ['[CLS] faster hope outcome scribe windsor cherry zoe pounder viewing [SEP]']
[Init] best rec loss: 0.6924082636833191 for ['[CLS] landfall day resulted kenton institute kate holland learning recorder [SEP]']
[Init] best rec loss: 0.68180251121521 for ['[CLS] officer laughed reigning taking chronic oldborn coupled meeting [SEP]']
[Init] best perm rec loss: 0.6811312437057495 for ['[CLS] meeting laughed taking old officer chronicborn reigning coupled [SEP]']
[Init] best perm rec loss: 0.6787684559822083 for ['[CLS] reigningborn laughed officer taking meeting coupled old chronic [SEP]']
[Init] best perm rec loss: 0.6758812665939331 for ['[CLS] laughed officer old reigning taking coupled meeting chronicborn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.532 (perp=10.692, rec=0.373, cos=0.021), tot_loss_proj:3.431 [t=0.17s]
prediction: ['[CLS] someone officer 3rd was taking. knee person person [SEP]']
[ 100/2000] tot_loss=2.382 (perp=10.399, rec=0.291, cos=0.012), tot_loss_proj:2.959 [t=0.17s]
prediction: ['[CLS] person person a heavy position is foot heavy person [SEP]']
[ 150/2000] tot_loss=2.533 (perp=11.321, rec=0.259, cos=0.009), tot_loss_proj:3.049 [t=0.17s]
prediction: ['[CLS] person person the stand stand on foot heavy person [SEP]']
[ 200/2000] tot_loss=2.212 (perp=9.772, rec=0.250, cos=0.007), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] person person the stand is on foot heavy foot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.253 (perp=10.133, rec=0.220, cos=0.006), tot_loss_proj:2.749 [t=0.19s]
prediction: ['[CLS] person the stand stand is my foot heavy foot [SEP]']
[ 300/2000] tot_loss=2.194 (perp=10.108, rec=0.167, cos=0.006), tot_loss_proj:2.756 [t=0.17s]
prediction: ['[CLS] person the stand stand is my foot heavy on [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.883 (perp=8.702, rec=0.138, cos=0.004), tot_loss_proj:2.345 [t=0.17s]
prediction: ['[CLS] person the heavy stand is my foot stand on [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.657 (perp=7.623, rec=0.129, cos=0.004), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] person the heavy stand is my stand on foot [SEP]']
[ 450/2000] tot_loss=1.631 (perp=7.658, rec=0.095, cos=0.003), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] person the heavy is is my stand on foot [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.528 (perp=7.102, rec=0.104, cos=0.003), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.516 (perp=7.102, rec=0.092, cos=0.003), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
[ 600/2000] tot_loss=1.510 (perp=7.102, rec=0.086, cos=0.003), tot_loss_proj:2.146 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.502 (perp=7.102, rec=0.078, cos=0.003), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.510 (perp=7.102, rec=0.087, cos=0.003), tot_loss_proj:2.138 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
[ 750/2000] tot_loss=1.506 (perp=7.102, rec=0.083, cos=0.003), tot_loss_proj:2.142 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.502 (perp=7.102, rec=0.079, cos=0.003), tot_loss_proj:2.142 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.505 (perp=7.102, rec=0.082, cos=0.003), tot_loss_proj:2.139 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
[ 900/2000] tot_loss=1.496 (perp=7.102, rec=0.072, cos=0.003), tot_loss_proj:2.144 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.503 (perp=7.102, rec=0.080, cos=0.003), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1000/2000] tot_loss=1.504 (perp=7.102, rec=0.081, cos=0.003), tot_loss_proj:2.142 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
[1050/2000] tot_loss=1.499 (perp=7.102, rec=0.075, cos=0.003), tot_loss_proj:2.141 [t=0.18s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1100/2000] tot_loss=1.494 (perp=7.102, rec=0.071, cos=0.003), tot_loss_proj:2.145 [t=0.18s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1150/2000] tot_loss=1.495 (perp=7.102, rec=0.072, cos=0.003), tot_loss_proj:2.143 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
[1200/2000] tot_loss=1.496 (perp=7.102, rec=0.073, cos=0.003), tot_loss_proj:2.146 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1250/2000] tot_loss=1.505 (perp=7.102, rec=0.082, cos=0.003), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1300/2000] tot_loss=1.493 (perp=7.102, rec=0.070, cos=0.003), tot_loss_proj:2.139 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
[1350/2000] tot_loss=1.499 (perp=7.102, rec=0.076, cos=0.003), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1400/2000] tot_loss=1.505 (perp=7.102, rec=0.082, cos=0.003), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1450/2000] tot_loss=1.487 (perp=7.102, rec=0.064, cos=0.003), tot_loss_proj:2.142 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
[1500/2000] tot_loss=1.503 (perp=7.102, rec=0.080, cos=0.003), tot_loss_proj:2.140 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1550/2000] tot_loss=1.491 (perp=7.102, rec=0.068, cos=0.003), tot_loss_proj:2.140 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1600/2000] tot_loss=1.504 (perp=7.102, rec=0.081, cos=0.003), tot_loss_proj:2.143 [t=0.18s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
[1650/2000] tot_loss=1.487 (perp=7.102, rec=0.064, cos=0.003), tot_loss_proj:2.147 [t=0.18s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1700/2000] tot_loss=1.496 (perp=7.102, rec=0.073, cos=0.003), tot_loss_proj:2.136 [t=0.18s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1750/2000] tot_loss=1.495 (perp=7.102, rec=0.072, cos=0.003), tot_loss_proj:2.145 [t=0.18s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
[1800/2000] tot_loss=1.495 (perp=7.102, rec=0.072, cos=0.003), tot_loss_proj:2.140 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1850/2000] tot_loss=1.494 (perp=7.102, rec=0.071, cos=0.003), tot_loss_proj:2.143 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[1900/2000] tot_loss=1.504 (perp=7.102, rec=0.081, cos=0.003), tot_loss_proj:2.141 [t=0.18s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
[1950/2000] tot_loss=1.505 (perp=7.102, rec=0.082, cos=0.003), tot_loss_proj:2.145 [t=0.17s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Attempt swap
[2000/2000] tot_loss=1.505 (perp=7.102, rec=0.082, cos=0.003), tot_loss_proj:2.142 [t=0.19s]
prediction: ['[CLS] is the heavy person is my stand on foot [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS] the person stand on my foot is heavy. [SEP]
========================
predicted: 
========================
[CLS] is the heavy person is my stand on foot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 10.526 | p: 10.000 | r: 11.111
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 105.764

[Aggregate metrics]:
rouge1     | fm: 84.197 | p: 83.642 | r: 85.073
rouge2     | fm: 39.287 | p: 38.951 | r: 39.829
rougeL     | fm: 69.915 | p: 69.405 | r: 70.741
rougeLsum  | fm: 69.751 | p: 69.251 | r: 70.623
r1fm+r2fm = 123.484

input #76 time: 0:07:08 | total time: 9:19:32


Running input #77 of 100.
reference: 
========================
My mother baked a cake for me.
========================
average of cosine similarity 0.9994064498635338
highest_index [0]
highest [0.9994064498635338]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2026,  2388, 17776,  1037,  9850,  2005,  2033,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] my mother baked a cake for me. [SEP]']
[Init] best rec loss: 1.0671769380569458 for ['[CLS] mysterious statistical its owner soft bodo network posting [SEP]']
[Init] best rec loss: 1.0210918188095093 for ['[CLS] baby jolink & spinal is andre youngest [SEP]']
[Init] best rec loss: 0.978882372379303 for ['[CLS] helmetgating shaking external closed )ations oldest [SEP]']
[Init] best rec loss: 0.977277934551239 for ['[CLS] catch as [UNK] visitraph meet found your [SEP]']
[Init] best rec loss: 0.9744843244552612 for ['[CLS] voice free knuckles citizen dean senior private much [SEP]']
[Init] best perm rec loss: 0.968231201171875 for ['[CLS] voice citizen knuckles dean senior free much private [SEP]']
[Init] best perm rec loss: 0.9661933779716492 for ['[CLS] senior voice citizen much private knuckles dean free [SEP]']
[Init] best perm rec loss: 0.9661873579025269 for ['[CLS] dean citizen senior voice free much private knuckles [SEP]']
[Init] best perm rec loss: 0.9657464623451233 for ['[CLS] private senior voice dean much citizen knuckles free [SEP]']
[Init] best perm rec loss: 0.9645711183547974 for ['[CLS] citizen dean voice knuckles free senior much private [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.930 (perp=12.652, rec=0.675, cos=0.724), tot_loss_proj:4.384 [t=0.17s]
prediction: ['[CLS] uh cyclone instrument films disabled demolished ice by [SEP]']
[ 100/2000] tot_loss=3.380 (perp=12.167, rec=0.586, cos=0.361), tot_loss_proj:4.248 [t=0.21s]
prediction: ['[CLS] becomes parliamentaryaceaem button demolishedoft. [SEP]']
[ 150/2000] tot_loss=4.031 (perp=13.181, rec=0.607, cos=0.788), tot_loss_proj:4.477 [t=0.17s]
prediction: ['[CLS] aye batteraceae through step. housing steam [SEP]']
[ 200/2000] tot_loss=3.488 (perp=13.528, rec=0.571, cos=0.211), tot_loss_proj:4.484 [t=0.17s]
prediction: ['[CLS] kw mike balloonic protocol baked housing steam [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.993 (perp=11.865, rec=0.861, cos=0.759), tot_loss_proj:4.237 [t=0.17s]
prediction: ['[CLS] gma on bu in save incumbent color mike [SEP]']
[ 300/2000] tot_loss=3.915 (perp=11.196, rec=0.825, cos=0.851), tot_loss_proj:4.033 [t=0.19s]
prediction: ['[CLS] sqam helicopters in advertisement average color get [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.972 (perp=11.540, rec=0.823, cos=0.841), tot_loss_proj:4.410 [t=0.18s]
prediction: ['[CLS] giam vhs ; in neighborhood color very [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.078 (perp=8.733, rec=0.651, cos=0.681), tot_loss_proj:3.741 [t=0.17s]
prediction: ['[CLS] sir 2009 advertisement in neighborhood tea giant ; [SEP]']
[ 450/2000] tot_loss=3.045 (perp=9.117, rec=0.609, cos=0.613), tot_loss_proj:3.615 [t=0.18s]
prediction: ['[CLS] seamus off advertisement for neighborhood tea giant ; [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.497 (perp=10.992, rec=0.636, cos=0.662), tot_loss_proj:4.117 [t=0.17s]
prediction: ['[CLS] baked mum in tributaries neighborhood tea social ; [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=3.247 (perp=10.895, rec=0.578, cos=0.489), tot_loss_proj:3.953 [t=0.17s]
prediction: ['[CLS] baked social apply for tributaries baked colour ; [SEP]']
[ 600/2000] tot_loss=3.146 (perp=11.009, rec=0.555, cos=0.389), tot_loss_proj:3.983 [t=0.17s]
prediction: ['[CLS] baked social apply in tributaries baked colour ; [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.945 (perp=10.303, rec=0.549, cos=0.336), tot_loss_proj:3.860 [t=0.18s]
prediction: ['[CLS] baked socialdbergを for baked colour ; [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=4.179 (perp=12.549, rec=0.933, cos=0.736), tot_loss_proj:4.288 [t=0.17s]
prediction: ['[CLS] poems baked god message him baked ski almond [SEP]']
[ 750/2000] tot_loss=3.700 (perp=10.607, rec=0.812, cos=0.767), tot_loss_proj:3.926 [t=0.18s]
prediction: ['[CLS] parents baked god message him baked : almond [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.541 (perp=9.817, rec=0.767, cos=0.811), tot_loss_proj:3.993 [t=0.17s]
prediction: ['[CLS] parents baked god baked him message : almond [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.623 (perp=10.248, rec=0.732, cos=0.842), tot_loss_proj:3.810 [t=0.17s]
prediction: ['[CLS] parents baked god baked visit. almond message [SEP]']
[ 900/2000] tot_loss=3.674 (perp=10.566, rec=0.690, cos=0.871), tot_loss_proj:3.936 [t=0.18s]
prediction: ['[CLS] parents baked god baked visit. season message [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.501 (perp=9.739, rec=0.675, cos=0.878), tot_loss_proj:3.797 [t=0.18s]
prediction: ['[CLS] today baked god baked message. season visit [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.397 (perp=9.336, rec=0.659, cos=0.871), tot_loss_proj:3.710 [t=0.18s]
prediction: ['[CLS] baked god baked message today. season visit [SEP]']
[1050/2000] tot_loss=3.393 (perp=9.336, rec=0.641, cos=0.885), tot_loss_proj:3.708 [t=0.18s]
prediction: ['[CLS] baked god baked message today. season visit [SEP]']
Attempt swap
[1100/2000] tot_loss=3.381 (perp=9.336, rec=0.620, cos=0.893), tot_loss_proj:3.707 [t=0.18s]
prediction: ['[CLS] baked god baked message today. season visit [SEP]']
Attempt swap
[1150/2000] tot_loss=3.399 (perp=9.491, rec=0.599, cos=0.902), tot_loss_proj:3.723 [t=0.18s]
prediction: ['[CLS] baked god baked message today. season her [SEP]']
[1200/2000] tot_loss=3.409 (perp=9.491, rec=0.602, cos=0.909), tot_loss_proj:3.725 [t=0.18s]
prediction: ['[CLS] baked god baked message today. season her [SEP]']
Attempt swap
[1250/2000] tot_loss=3.407 (perp=9.491, rec=0.591, cos=0.918), tot_loss_proj:3.722 [t=0.18s]
prediction: ['[CLS] baked god baked message today. season her [SEP]']
Attempt swap
[1300/2000] tot_loss=3.408 (perp=9.491, rec=0.583, cos=0.927), tot_loss_proj:3.725 [t=0.18s]
prediction: ['[CLS] baked god baked message today. season her [SEP]']
[1350/2000] tot_loss=3.401 (perp=9.491, rec=0.565, cos=0.938), tot_loss_proj:3.726 [t=0.18s]
prediction: ['[CLS] baked god baked message today. season her [SEP]']
Attempt swap
[1400/2000] tot_loss=3.406 (perp=9.491, rec=0.560, cos=0.948), tot_loss_proj:3.725 [t=0.20s]
prediction: ['[CLS] baked god baked message today. season her [SEP]']
Attempt swap
[1450/2000] tot_loss=3.377 (perp=9.269, rec=0.565, cos=0.959), tot_loss_proj:3.675 [t=0.18s]
prediction: ['[CLS] baked god baked message today. seasoncake [SEP]']
[1500/2000] tot_loss=3.379 (perp=9.269, rec=0.554, cos=0.971), tot_loss_proj:3.681 [t=0.18s]
prediction: ['[CLS] baked god baked message today. seasoncake [SEP]']
Attempt swap
[1550/2000] tot_loss=3.358 (perp=9.130, rec=0.550, cos=0.981), tot_loss_proj:3.657 [t=0.19s]
prediction: ['[CLS] baked god baked message today. season cake [SEP]']
Attempt swap
[1600/2000] tot_loss=3.360 (perp=9.130, rec=0.543, cos=0.992), tot_loss_proj:3.654 [t=0.19s]
prediction: ['[CLS] baked god baked message today. season cake [SEP]']
[1650/2000] tot_loss=3.363 (perp=9.130, rec=0.538, cos=0.998), tot_loss_proj:3.653 [t=0.18s]
prediction: ['[CLS] baked god baked message today. season cake [SEP]']
Attempt swap
[1700/2000] tot_loss=3.365 (perp=9.130, rec=0.540, cos=0.999), tot_loss_proj:3.659 [t=0.17s]
prediction: ['[CLS] baked god baked message today. season cake [SEP]']
Attempt swap
[1750/2000] tot_loss=3.343 (perp=9.130, rec=0.528, cos=0.989), tot_loss_proj:3.657 [t=0.17s]
prediction: ['[CLS] baked god baked message today. season cake [SEP]']
[1800/2000] tot_loss=3.312 (perp=9.130, rec=0.525, cos=0.960), tot_loss_proj:3.654 [t=0.17s]
prediction: ['[CLS] baked god baked message today. season cake [SEP]']
Attempt swap
[1850/2000] tot_loss=3.252 (perp=9.130, rec=0.524, cos=0.903), tot_loss_proj:3.657 [t=0.17s]
prediction: ['[CLS] baked god baked message today. season cake [SEP]']
Attempt swap
[1900/2000] tot_loss=3.148 (perp=9.130, rec=0.510, cos=0.812), tot_loss_proj:3.659 [t=0.19s]
prediction: ['[CLS] baked god baked message today. season cake [SEP]']
[1950/2000] tot_loss=3.045 (perp=9.130, rec=0.510, cos=0.709), tot_loss_proj:3.651 [t=0.19s]
prediction: ['[CLS] baked god baked message today. season cake [SEP]']
Attempt swap
[2000/2000] tot_loss=2.987 (perp=9.353, rec=0.510, cos=0.606), tot_loss_proj:3.658 [t=0.19s]
prediction: ['[CLS] baked god baked message today. sounding cake [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] my mother baked a cake for me. [SEP]
========================
predicted: 
========================
[CLS] baked god baked message today. sounding cake [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 44.444 | p: 44.444 | r: 44.444
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 44.444

[Aggregate metrics]:
rouge1     | fm: 83.677 | p: 83.117 | r: 84.462
rouge2     | fm: 38.936 | p: 38.554 | r: 39.498
rougeL     | fm: 69.569 | p: 69.047 | r: 70.381
rougeLsum  | fm: 69.534 | p: 68.994 | r: 70.316
r1fm+r2fm = 122.613

input #77 time: 0:07:16 | total time: 9:26:48


Running input #78 of 100.
reference: 
========================
I read some book.
========================
average of cosine similarity 0.9993794737153854
highest_index [0]
highest [0.9993794737153854]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 3191, 2070, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i read some book. [SEP]']
[Init] best rec loss: 0.9242171049118042 for ['[CLS]ys sponsored ni patience courts [SEP]']
[Init] best rec loss: 0.9155153632164001 for ['[CLS] sealing wrestlemania profile sense ar [SEP]']
[Init] best rec loss: 0.813995361328125 for ['[CLS] am iv pregnant lagoon ample [SEP]']
[Init] best rec loss: 0.8045976758003235 for ['[CLS] tour fucking ax him banking [SEP]']
[Init] best rec loss: 0.8032265305519104 for ['[CLS] epidemic deceased accused flames zone [SEP]']
[Init] best rec loss: 0.7923592925071716 for ['[CLS] solitary jumps squeakchev tangled [SEP]']
[Init] best perm rec loss: 0.7846071720123291 for ['[CLS] solitarychev squeak tangled jumps [SEP]']
[Init] best perm rec loss: 0.7840006947517395 for ['[CLS]chev jumps tangled squeak solitary [SEP]']
[Init] best perm rec loss: 0.7813184261322021 for ['[CLS]chev squeak tangled solitary jumps [SEP]']
[Init] best perm rec loss: 0.7804632186889648 for ['[CLS] tangled squeak solitarychev jumps [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.397 (perp=8.627, rec=0.568, cos=0.103), tot_loss_proj:3.002 [t=0.17s]
prediction: ['[CLS] during book times followed before [SEP]']
[ 100/2000] tot_loss=2.519 (perp=9.716, rec=0.510, cos=0.066), tot_loss_proj:3.462 [t=0.17s]
prediction: ['[CLS] some book,us before [SEP]']
[ 150/2000] tot_loss=2.334 (perp=9.513, rec=0.398, cos=0.034), tot_loss_proj:3.114 [t=0.22s]
prediction: ['[CLS] some book some band short [SEP]']
[ 200/2000] tot_loss=2.342 (perp=9.282, rec=0.429, cos=0.056), tot_loss_proj:3.471 [t=0.20s]
prediction: ['[CLS] book book someen is [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.223 (perp=9.449, rec=0.307, cos=0.026), tot_loss_proj:3.018 [t=0.19s]
prediction: ['[CLS] book some some book book [SEP]']
[ 300/2000] tot_loss=2.230 (perp=10.063, rec=0.202, cos=0.015), tot_loss_proj:3.121 [t=0.18s]
prediction: ['[CLS] book read someen book [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.917 (perp=8.719, rec=0.162, cos=0.011), tot_loss_proj:3.011 [t=0.18s]
prediction: ['[CLS] readen read some book [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.898 (perp=8.719, rec=0.145, cos=0.009), tot_loss_proj:3.003 [t=0.19s]
prediction: ['[CLS] readen read some book [SEP]']
[ 450/2000] tot_loss=1.663 (perp=7.653, rec=0.125, cos=0.008), tot_loss_proj:2.401 [t=0.18s]
prediction: ['[CLS] read i read some book [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.607 (perp=7.353, rec=0.128, cos=0.008), tot_loss_proj:2.444 [t=0.18s]
prediction: ['[CLS] i read read some book [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.416 (perp=6.479, rec=0.113, cos=0.007), tot_loss_proj:1.971 [t=0.19s]
prediction: ['[CLS] i read some book read [SEP]']
[ 600/2000] tot_loss=1.404 (perp=6.479, rec=0.102, cos=0.006), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.389 (perp=6.479, rec=0.088, cos=0.006), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.400 (perp=6.479, rec=0.099, cos=0.006), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
[ 750/2000] tot_loss=1.395 (perp=6.479, rec=0.094, cos=0.006), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.410 (perp=6.479, rec=0.108, cos=0.006), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.388 (perp=6.479, rec=0.087, cos=0.005), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
[ 900/2000] tot_loss=1.397 (perp=6.479, rec=0.096, cos=0.005), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.382 (perp=6.479, rec=0.081, cos=0.005), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1000/2000] tot_loss=1.381 (perp=6.479, rec=0.080, cos=0.005), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
[1050/2000] tot_loss=1.384 (perp=6.479, rec=0.083, cos=0.005), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1100/2000] tot_loss=1.392 (perp=6.479, rec=0.091, cos=0.005), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1150/2000] tot_loss=1.386 (perp=6.479, rec=0.085, cos=0.005), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
[1200/2000] tot_loss=1.381 (perp=6.479, rec=0.080, cos=0.005), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1250/2000] tot_loss=1.379 (perp=6.479, rec=0.078, cos=0.005), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1300/2000] tot_loss=1.389 (perp=6.479, rec=0.088, cos=0.005), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
[1350/2000] tot_loss=1.382 (perp=6.479, rec=0.081, cos=0.005), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1400/2000] tot_loss=1.389 (perp=6.479, rec=0.088, cos=0.005), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1450/2000] tot_loss=1.390 (perp=6.479, rec=0.089, cos=0.005), tot_loss_proj:1.978 [t=0.20s]
prediction: ['[CLS] i read some book read [SEP]']
[1500/2000] tot_loss=1.389 (perp=6.479, rec=0.088, cos=0.005), tot_loss_proj:1.975 [t=0.18s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1550/2000] tot_loss=1.391 (perp=6.479, rec=0.090, cos=0.005), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1600/2000] tot_loss=1.378 (perp=6.479, rec=0.077, cos=0.005), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
[1650/2000] tot_loss=1.392 (perp=6.479, rec=0.091, cos=0.005), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1700/2000] tot_loss=1.386 (perp=6.479, rec=0.085, cos=0.005), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1750/2000] tot_loss=1.388 (perp=6.479, rec=0.087, cos=0.005), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
[1800/2000] tot_loss=1.383 (perp=6.479, rec=0.082, cos=0.005), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1850/2000] tot_loss=1.388 (perp=6.479, rec=0.087, cos=0.005), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[1900/2000] tot_loss=1.382 (perp=6.479, rec=0.082, cos=0.005), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
[1950/2000] tot_loss=1.387 (perp=6.479, rec=0.086, cos=0.005), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Attempt swap
[2000/2000] tot_loss=1.387 (perp=6.479, rec=0.086, cos=0.005), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS] i read some book read [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] i read some book. [SEP]
========================
predicted: 
========================
[CLS] i read some book read [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 72.727 | p: 66.667 | r: 80.000
rougeL     | fm: 92.308 | p: 85.714 | r: 100.000
rougeLsum  | fm: 92.308 | p: 85.714 | r: 100.000
r1fm+r2fm = 165.035

[Aggregate metrics]:
rouge1     | fm: 83.771 | p: 83.172 | r: 84.666
rouge2     | fm: 39.274 | p: 38.813 | r: 39.860
rougeL     | fm: 69.897 | p: 69.241 | r: 70.760
rougeLsum  | fm: 69.815 | p: 69.197 | r: 70.756
r1fm+r2fm = 123.045

input #78 time: 0:07:07 | total time: 9:33:56


Running input #79 of 100.
reference: 
========================
The umpire called it of.
========================
average of cosine similarity 0.9993217640206553
highest_index [0]
highest [0.9993217640206553]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 20887,  2170,  2009,  1997,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the umpire called it of. [SEP]']
[Init] best rec loss: 0.9944065809249878 for ['[CLS]tlement gi professional julian reaching wingspan [SEP]']
[Init] best rec loss: 0.9885329008102417 for ['[CLS] ′ ears natural developed star quest [SEP]']
[Init] best rec loss: 0.9714334607124329 for ['[CLS] exposure april located cheesequal enough [SEP]']
[Init] best rec loss: 0.9517230987548828 for ['[CLS] consulted ‖ deputy from back alley [SEP]']
[Init] best rec loss: 0.9444591999053955 for ['[CLS] sub nu mode fish calderon? [SEP]']
[Init] best rec loss: 0.9425790905952454 for ['[CLS] investigatoreve sea hell mali otherwise [SEP]']
[Init] best rec loss: 0.9382247924804688 for ['[CLS] immediately... ordinary variouspre extra [SEP]']
[Init] best rec loss: 0.9181168675422668 for ['[CLS]oca named hall would google guard [SEP]']
[Init] best perm rec loss: 0.9179900288581848 for ['[CLS]oca hall would google guard named [SEP]']
[Init] best perm rec loss: 0.9177843928337097 for ['[CLS] guard halloca named google would [SEP]']
[Init] best perm rec loss: 0.9168456792831421 for ['[CLS]oca hall guard would named google [SEP]']
[Init] best perm rec loss: 0.9167401790618896 for ['[CLS] guard named hall would googleoca [SEP]']
[Init] best perm rec loss: 0.9162608981132507 for ['[CLS]oca hall would named google guard [SEP]']
[Init] best perm rec loss: 0.9160237908363342 for ['[CLS]oca would guard google named hall [SEP]']
[Init] best perm rec loss: 0.9141231179237366 for ['[CLS]oca would guard named hall google [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.485 (perp=14.203, rec=0.645, cos=1.000), tot_loss_proj:4.705 [t=0.19s]
prediction: ['[CLS] umpire wouldperdre bill happy [SEP]']
[ 100/2000] tot_loss=3.817 (perp=11.404, rec=0.537, cos=0.999), tot_loss_proj:4.133 [t=0.17s]
prediction: ['[CLS] umpire umpire事 ones disc. [SEP]']
[ 150/2000] tot_loss=3.290 (perp=9.063, rec=0.487, cos=0.990), tot_loss_proj:3.738 [t=0.18s]
prediction: ['[CLS] umpire umpire umpire hms scored. [SEP]']
[ 200/2000] tot_loss=3.450 (perp=10.137, rec=0.448, cos=0.975), tot_loss_proj:3.953 [t=0.19s]
prediction: ['[CLS] umpire umpire事eland scored. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.534 (perp=9.692, rec=0.610, cos=0.986), tot_loss_proj:3.855 [t=0.20s]
prediction: ['[CLS] umpire the should spot.. [SEP]']
[ 300/2000] tot_loss=3.622 (perp=10.969, rec=0.489, cos=0.940), tot_loss_proj:4.089 [t=0.20s]
prediction: ['[CLS] umpire cease should spot how. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.610 (perp=11.123, rec=0.458, cos=0.927), tot_loss_proj:4.082 [t=0.18s]
prediction: ['[CLS] umpire topical called <lessness. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.346 (perp=10.004, rec=0.452, cos=0.893), tot_loss_proj:3.967 [t=0.17s]
prediction: ['[CLS] called provides umpire < allotted. [SEP]']
[ 450/2000] tot_loss=3.300 (perp=10.311, rec=0.425, cos=0.813), tot_loss_proj:4.029 [t=0.18s]
prediction: ['[CLS] called issued umpire \\ allotted. [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.976 (perp=10.533, rec=0.540, cos=0.329), tot_loss_proj:4.131 [t=0.17s]
prediction: ['[CLS] umpire options umpire \\ opener. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.925 (perp=12.795, rec=0.309, cos=0.058), tot_loss_proj:4.502 [t=0.17s]
prediction: ['[CLS]breakers umpire options int initially. [SEP]']
[ 600/2000] tot_loss=2.619 (perp=11.615, rec=0.259, cos=0.037), tot_loss_proj:4.288 [t=0.17s]
prediction: ['[CLS] considered umpire options int initially. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.213 (perp=9.560, rec=0.268, cos=0.033), tot_loss_proj:3.908 [t=0.17s]
prediction: ['[CLS] initially considered umpire options int. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.590 (perp=11.569, rec=0.251, cos=0.025), tot_loss_proj:4.168 [t=0.17s]
prediction: ['[CLS] initially something umpire options int. [SEP]']
[ 750/2000] tot_loss=2.145 (perp=9.436, rec=0.237, cos=0.021), tot_loss_proj:3.833 [t=0.17s]
prediction: ['[CLS] called something umpire options or. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.945 (perp=8.441, rec=0.238, cos=0.019), tot_loss_proj:3.626 [t=0.17s]
prediction: ['[CLS] called something umpire or there. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.858 (perp=8.095, rec=0.221, cos=0.018), tot_loss_proj:3.624 [t=0.18s]
prediction: ['[CLS] called it called or umpire. [SEP]']
[ 900/2000] tot_loss=1.864 (perp=8.135, rec=0.221, cos=0.016), tot_loss_proj:3.486 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.853 (perp=8.135, rec=0.211, cos=0.015), tot_loss_proj:3.490 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.846 (perp=8.135, rec=0.205, cos=0.014), tot_loss_proj:3.490 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
[1050/2000] tot_loss=1.846 (perp=8.135, rec=0.205, cos=0.014), tot_loss_proj:3.490 [t=0.17s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.835 (perp=8.135, rec=0.195, cos=0.014), tot_loss_proj:3.483 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.832 (perp=8.135, rec=0.192, cos=0.013), tot_loss_proj:3.491 [t=0.17s]
prediction: ['[CLS] called it called of umpire. [SEP]']
[1200/2000] tot_loss=1.828 (perp=8.135, rec=0.189, cos=0.012), tot_loss_proj:3.490 [t=0.17s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.827 (perp=8.135, rec=0.189, cos=0.012), tot_loss_proj:3.490 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.819 (perp=8.135, rec=0.181, cos=0.011), tot_loss_proj:3.488 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
[1350/2000] tot_loss=1.819 (perp=8.135, rec=0.182, cos=0.010), tot_loss_proj:3.493 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.809 (perp=8.135, rec=0.172, cos=0.010), tot_loss_proj:3.488 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.810 (perp=8.135, rec=0.174, cos=0.010), tot_loss_proj:3.486 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
[1500/2000] tot_loss=1.805 (perp=8.135, rec=0.168, cos=0.010), tot_loss_proj:3.491 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.801 (perp=8.135, rec=0.165, cos=0.009), tot_loss_proj:3.490 [t=0.17s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.808 (perp=8.135, rec=0.172, cos=0.009), tot_loss_proj:3.489 [t=0.17s]
prediction: ['[CLS] called it called of umpire. [SEP]']
[1650/2000] tot_loss=1.804 (perp=8.135, rec=0.168, cos=0.009), tot_loss_proj:3.491 [t=0.19s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.801 (perp=8.135, rec=0.165, cos=0.009), tot_loss_proj:3.488 [t=0.19s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.792 (perp=8.135, rec=0.156, cos=0.009), tot_loss_proj:3.488 [t=0.18s]
prediction: ['[CLS] called it called of umpire. [SEP]']
[1800/2000] tot_loss=1.788 (perp=8.135, rec=0.152, cos=0.009), tot_loss_proj:3.492 [t=0.20s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.791 (perp=8.135, rec=0.156, cos=0.009), tot_loss_proj:3.489 [t=0.17s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.798 (perp=8.135, rec=0.162, cos=0.009), tot_loss_proj:3.488 [t=0.17s]
prediction: ['[CLS] called it called of umpire. [SEP]']
[1950/2000] tot_loss=1.802 (perp=8.135, rec=0.166, cos=0.009), tot_loss_proj:3.488 [t=0.17s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.797 (perp=8.135, rec=0.162, cos=0.009), tot_loss_proj:3.495 [t=0.17s]
prediction: ['[CLS] called it called of umpire. [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] the umpire called it of. [SEP]
========================
predicted: 
========================
[CLS] called it called of umpire. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 83.816 | p: 83.239 | r: 84.776
rouge2     | fm: 39.047 | p: 38.607 | r: 39.581
rougeL     | fm: 69.866 | p: 69.177 | r: 70.765
rougeLsum  | fm: 69.844 | p: 69.310 | r: 70.729
r1fm+r2fm = 122.863

input #79 time: 0:07:26 | total time: 9:41:23


Running input #80 of 100.
reference: 
========================
The rock placed the sky with the fork.
========================
average of cosine similarity 0.9993117236696568
highest_index [0]
highest [0.9993117236696568]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2600, 2872, 1996, 3712, 2007, 1996, 9292, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the rock placed the sky with the fork. [SEP]']
[Init] best rec loss: 0.9175726175308228 for ['[CLS] female scared marcus humble ramp bracket hybrid marieeur [SEP]']
[Init] best rec loss: 0.891436755657196 for ['[CLS] kind plan loft [MASK]?elin unincorporated beard points [SEP]']
[Init] best rec loss: 0.8769033551216125 for ['[CLS] a bowl documentary position deficiency brand shoulders clinic counties [SEP]']
[Init] best rec loss: 0.8643680214881897 for ['[CLS] between lawrence policiessphere webb hari aria which com [SEP]']
[Init] best rec loss: 0.8254552483558655 for ['[CLS]own volunteers byte carr bold grace interchange chalk our [SEP]']
[Init] best rec loss: 0.7917901277542114 for ['[CLS] rib our ball spelling asleepille oval ash teaching [SEP]']
[Init] best rec loss: 0.7806429266929626 for ["[CLS] cassie guy preneas lake more'rocker jury [SEP]"]
[Init] best rec loss: 0.7527327537536621 for ['[CLS]tos young noah golfer healthy belong notitation modern [SEP]']
[Init] best perm rec loss: 0.752642035484314 for ['[CLS] noah golfer not healthytos belong youngitation modern [SEP]']
[Init] best perm rec loss: 0.7477012276649475 for ['[CLS] moderntositation healthy young not belong golfer noah [SEP]']
[Init] best perm rec loss: 0.747452974319458 for ['[CLS] modern not noah young belongitation healthytos golfer [SEP]']
[Init] best perm rec loss: 0.7451422214508057 for ['[CLS] not healthy youngtos belong modernitation golfer noah [SEP]']
[Init] best perm rec loss: 0.7439910769462585 for ['[CLS]tos not healthy golferitation young belong noah modern [SEP]']
[Init] best perm rec loss: 0.7436251640319824 for ['[CLS]tos noah golfer belong young modern notitation healthy [SEP]']
[Init] best perm rec loss: 0.7427157163619995 for ['[CLS] golfertos healthy belong youngitation not modern noah [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.917 (perp=13.105, rec=0.284, cos=0.012), tot_loss_proj:3.861 [t=0.17s]
prediction: ['[CLS] metal fall placed max cactus week rock emma the [SEP]']
[ 100/2000] tot_loss=2.162 (perp=9.585, rec=0.236, cos=0.009), tot_loss_proj:2.575 [t=0.17s]
prediction: ['[CLS] the rock placed you fork year rock. the [SEP]']
[ 150/2000] tot_loss=2.007 (perp=9.285, rec=0.144, cos=0.005), tot_loss_proj:2.673 [t=0.17s]
prediction: ['[CLS] the rock placed sky fork sky rock with the [SEP]']
[ 200/2000] tot_loss=1.931 (perp=9.114, rec=0.105, cos=0.004), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS] the sky placed sky fork sky rock with the [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.811 (perp=8.425, rec=0.123, cos=0.004), tot_loss_proj:2.166 [t=0.17s]
prediction: ['[CLS] the rock placed ghostly fork sky with the rock [SEP]']
[ 300/2000] tot_loss=1.893 (perp=8.981, rec=0.094, cos=0.003), tot_loss_proj:2.269 [t=0.17s]
prediction: ['[CLS] the sky placed those fork sky with the rock [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.655 (perp=7.824, rec=0.087, cos=0.003), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] the sky placed those sky with the rock fork [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.698 (perp=7.994, rec=0.097, cos=0.003), tot_loss_proj:2.311 [t=0.17s]
prediction: ['[CLS] the sky placed. sky with the rock fork [SEP]']
[ 450/2000] tot_loss=1.698 (perp=7.994, rec=0.096, cos=0.002), tot_loss_proj:2.314 [t=0.17s]
prediction: ['[CLS] the sky placed. sky with the rock fork [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.605 (perp=7.586, rec=0.085, cos=0.002), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] the sky placed fork sky with the rock. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.610 (perp=7.653, rec=0.076, cos=0.003), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] the richard placed sky with the rock fork. [SEP]']
[ 600/2000] tot_loss=1.602 (perp=7.653, rec=0.070, cos=0.002), tot_loss_proj:2.130 [t=0.18s]
prediction: ['[CLS] the richard placed sky with the rock fork. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.609 (perp=7.653, rec=0.076, cos=0.002), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] the richard placed sky with the rock fork. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.579 (perp=7.417, rec=0.093, cos=0.002), tot_loss_proj:2.577 [t=0.17s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
[ 750/2000] tot_loss=1.570 (perp=7.417, rec=0.084, cos=0.002), tot_loss_proj:2.576 [t=0.17s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.563 (perp=7.417, rec=0.078, cos=0.002), tot_loss_proj:2.575 [t=0.19s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.559 (perp=7.417, rec=0.074, cos=0.002), tot_loss_proj:2.568 [t=0.18s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
[ 900/2000] tot_loss=1.562 (perp=7.417, rec=0.076, cos=0.002), tot_loss_proj:2.574 [t=0.19s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.559 (perp=7.417, rec=0.073, cos=0.002), tot_loss_proj:2.568 [t=0.21s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.550 (perp=7.417, rec=0.064, cos=0.002), tot_loss_proj:2.573 [t=0.19s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
[1050/2000] tot_loss=1.441 (perp=6.854, rec=0.068, cos=0.003), tot_loss_proj:1.899 [t=0.19s]
prediction: ['[CLS] the fortress placed rock with the sky fork. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.564 (perp=7.417, rec=0.078, cos=0.002), tot_loss_proj:2.577 [t=0.17s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.562 (perp=7.417, rec=0.076, cos=0.002), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
[1200/2000] tot_loss=1.562 (perp=7.417, rec=0.077, cos=0.002), tot_loss_proj:2.571 [t=0.17s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.567 (perp=7.417, rec=0.081, cos=0.002), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.557 (perp=7.417, rec=0.071, cos=0.002), tot_loss_proj:2.572 [t=0.18s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
[1350/2000] tot_loss=1.557 (perp=7.417, rec=0.071, cos=0.002), tot_loss_proj:2.569 [t=0.18s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.558 (perp=7.417, rec=0.072, cos=0.002), tot_loss_proj:2.566 [t=0.17s]
prediction: ['[CLS] the richard placed rock with the sky fork. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.587 (perp=7.575, rec=0.069, cos=0.002), tot_loss_proj:2.446 [t=0.18s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
[1500/2000] tot_loss=1.576 (perp=7.575, rec=0.058, cos=0.002), tot_loss_proj:2.451 [t=0.18s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.582 (perp=7.575, rec=0.064, cos=0.002), tot_loss_proj:2.452 [t=0.18s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.599 (perp=7.575, rec=0.081, cos=0.002), tot_loss_proj:2.455 [t=0.21s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
[1650/2000] tot_loss=1.596 (perp=7.575, rec=0.079, cos=0.002), tot_loss_proj:2.442 [t=0.19s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.575, rec=0.079, cos=0.002), tot_loss_proj:2.457 [t=0.18s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.588 (perp=7.575, rec=0.071, cos=0.002), tot_loss_proj:2.446 [t=0.20s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
[1800/2000] tot_loss=1.581 (perp=7.575, rec=0.064, cos=0.002), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.597 (perp=7.575, rec=0.080, cos=0.002), tot_loss_proj:2.448 [t=0.18s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.581 (perp=7.575, rec=0.064, cos=0.002), tot_loss_proj:2.453 [t=0.17s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
[1950/2000] tot_loss=1.588 (perp=7.575, rec=0.071, cos=0.002), tot_loss_proj:2.458 [t=0.18s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.596 (perp=7.575, rec=0.078, cos=0.002), tot_loss_proj:2.445 [t=0.18s]
prediction: ['[CLS] theoz placed rock with the sky fork. [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] the rock placed the sky with the fork. [SEP]
========================
predicted: 
========================
[CLS] the richard placed rock with the sky fork. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 44.444 | p: 44.444 | r: 44.444
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 134.444

[Aggregate metrics]:
rouge1     | fm: 83.919 | p: 83.320 | r: 84.779
rouge2     | fm: 39.053 | p: 38.589 | r: 39.628
rougeL     | fm: 69.881 | p: 69.289 | r: 70.719
rougeLsum  | fm: 69.881 | p: 69.295 | r: 70.747
r1fm+r2fm = 122.971

input #80 time: 0:07:22 | total time: 9:48:46


Running input #81 of 100.
reference: 
========================
Tagalog is speaks in the Philippines.
========================
average of cosine similarity 0.999340695785271
highest_index [0]
highest [0.999340695785271]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  6415, 23067,  2290,  2003,  8847,  1999,  1996,  5137,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] tagalog is speaks in the philippines. [SEP]']
[Init] best rec loss: 0.8218028545379639 for ['[CLS]lch scotland uhf qualifying claude worse attempt faye costs [SEP]']
[Init] best rec loss: 0.8192242980003357 for ['[CLS] college school hismic nord mate genes transfer heir [SEP]']
[Init] best rec loss: 0.7856317758560181 for ['[CLS] extraburo and committed method pali co guess ir [SEP]']
[Init] best rec loss: 0.7316059470176697 for ['[CLS]ei understand turn infrastructure galley project tracks annual [SEP]']
[Init] best rec loss: 0.7133926153182983 for ['[CLS] opened grtain ft slow lattice season brake miriam [SEP]']
[Init] best rec loss: 0.705670177936554 for ['[CLS] horticultural example overlooking againstside anita hours ; followed [SEP]']
[Init] best rec loss: 0.6805224418640137 for ['[CLS] bigger maxim when interchange for cavity ª before apps [SEP]']
[Init] best perm rec loss: 0.6777098178863525 for ['[CLS] apps bigger when maxim ª cavity interchange for before [SEP]']
[Init] best perm rec loss: 0.6731835007667542 for ['[CLS] maxim apps interchange before when bigger cavity for ª [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.862 (perp=12.603, rec=0.315, cos=0.027), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS] tim australiangi is paradisenbc us is tasted [SEP]']
[ 100/2000] tot_loss=2.487 (perp=11.140, rec=0.245, cos=0.014), tot_loss_proj:3.012 [t=0.17s]
prediction: ['[CLS] speak philippinesdo is philippines speaks tag. speaks [SEP]']
[ 150/2000] tot_loss=1.974 (perp=8.880, rec=0.187, cos=0.011), tot_loss_proj:2.642 [t=0.17s]
prediction: ['[CLS] in philippinesg is philippines. tag. speaks [SEP]']
[ 200/2000] tot_loss=1.682 (perp=7.625, rec=0.150, cos=0.007), tot_loss_proj:2.345 [t=0.17s]
prediction: ['[CLS] in tagg is philippines. tag. speaks [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.675 (perp=7.765, rec=0.118, cos=0.004), tot_loss_proj:2.231 [t=0.17s]
prediction: ['[CLS] in tagg is philippines.alo speaks. [SEP]']
[ 300/2000] tot_loss=2.119 (perp=7.772, rec=0.467, cos=0.097), tot_loss_proj:2.365 [t=0.17s]
prediction: ['[CLS] the tagg is philippines.alo speaks, [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.040 (perp=7.812, rec=0.412, cos=0.065), tot_loss_proj:2.341 [t=0.17s]
prediction: ['[CLS] the philippineg is philippines.alo speaks, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.095 (perp=8.307, rec=0.384, cos=0.049), tot_loss_proj:2.307 [t=0.17s]
prediction: ['[CLS] thealog is philippines. philippine speaks in [SEP]']
[ 450/2000] tot_loss=2.166 (perp=8.884, rec=0.351, cos=0.038), tot_loss_proj:2.544 [t=0.17s]
prediction: ['[CLS] thealog is philippines. tag speaks in [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.682 (perp=6.579, rec=0.335, cos=0.031), tot_loss_proj:1.992 [t=0.17s]
prediction: ['[CLS] the tagalog is philippines. speaks in [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.817 (perp=7.388, rec=0.313, cos=0.027), tot_loss_proj:2.195 [t=0.17s]
prediction: ['[CLS] the philippinealog is philippines in speaks. [SEP]']
[ 600/2000] tot_loss=1.785 (perp=7.388, rec=0.287, cos=0.021), tot_loss_proj:2.190 [t=0.17s]
prediction: ['[CLS] the philippinealog is philippines in speaks. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.933 (perp=8.179, rec=0.278, cos=0.018), tot_loss_proj:2.416 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in tag. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.497 (perp=6.062, rec=0.270, cos=0.015), tot_loss_proj:1.821 [t=0.17s]
prediction: ['[CLS] in tagalog is philippines in speaks. [SEP]']
[ 750/2000] tot_loss=1.745 (perp=7.436, rec=0.245, cos=0.013), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] in philippinealog is philippines in speaks. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.637 (perp=6.894, rec=0.245, cos=0.013), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.634 (perp=6.894, rec=0.243, cos=0.013), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
[ 900/2000] tot_loss=1.621 (perp=6.894, rec=0.231, cos=0.012), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.613 (perp=6.894, rec=0.222, cos=0.012), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.610 (perp=6.894, rec=0.220, cos=0.011), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
[1050/2000] tot_loss=1.616 (perp=6.894, rec=0.226, cos=0.011), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.609 (perp=6.894, rec=0.220, cos=0.011), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.604 (perp=6.894, rec=0.214, cos=0.011), tot_loss_proj:2.124 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
[1200/2000] tot_loss=1.605 (perp=6.894, rec=0.215, cos=0.011), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.603 (perp=6.894, rec=0.214, cos=0.011), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.598 (perp=6.894, rec=0.208, cos=0.011), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
[1350/2000] tot_loss=1.600 (perp=6.894, rec=0.210, cos=0.011), tot_loss_proj:2.111 [t=0.18s]
prediction: ['[CLS] in speaksalog is philippines in philippine. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.679 (perp=7.284, rec=0.211, cos=0.011), tot_loss_proj:2.225 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.673 (perp=7.284, rec=0.206, cos=0.011), tot_loss_proj:2.221 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
[1500/2000] tot_loss=1.673 (perp=7.284, rec=0.205, cos=0.011), tot_loss_proj:2.220 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.666 (perp=7.284, rec=0.198, cos=0.011), tot_loss_proj:2.223 [t=0.18s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.665 (perp=7.284, rec=0.198, cos=0.011), tot_loss_proj:2.232 [t=0.19s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
[1650/2000] tot_loss=1.666 (perp=7.284, rec=0.199, cos=0.011), tot_loss_proj:2.222 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.656 (perp=7.284, rec=0.189, cos=0.011), tot_loss_proj:2.228 [t=0.18s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.663 (perp=7.284, rec=0.196, cos=0.010), tot_loss_proj:2.226 [t=0.19s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
[1800/2000] tot_loss=1.663 (perp=7.284, rec=0.196, cos=0.010), tot_loss_proj:2.221 [t=0.18s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.661 (perp=7.284, rec=0.194, cos=0.010), tot_loss_proj:2.226 [t=0.19s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.654 (perp=7.284, rec=0.187, cos=0.010), tot_loss_proj:2.222 [t=0.19s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
[1950/2000] tot_loss=1.661 (perp=7.284, rec=0.194, cos=0.010), tot_loss_proj:2.227 [t=0.19s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.662 (perp=7.284, rec=0.195, cos=0.010), tot_loss_proj:2.223 [t=0.17s]
prediction: ['[CLS] in speaksalog is philippines in philippines. [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] tagalog is speaks in the philippines. [SEP]
========================
predicted: 
========================
[CLS] in tagg is philippines.alo speaks. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 75.000

[Aggregate metrics]:
rouge1     | fm: 83.780 | p: 83.208 | r: 84.594
rouge2     | fm: 38.622 | p: 38.227 | r: 39.320
rougeL     | fm: 69.644 | p: 69.036 | r: 70.515
rougeLsum  | fm: 69.635 | p: 68.966 | r: 70.523
r1fm+r2fm = 122.401

input #81 time: 0:07:06 | total time: 9:55:53


Running input #82 of 100.
reference: 
========================
He waltzed her across the floor.
========================
average of cosine similarity 0.9995051539996082
highest_index [0]
highest [0.9995051539996082]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2002, 17569,  2098,  2014,  2408,  1996,  2723,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] he waltzed her across the floor. [SEP]']
[Init] best rec loss: 1.0006637573242188 for ['[CLS] beverly womenboat [MASK] greatly waterfold bears [SEP]']
[Init] best rec loss: 1.0003470182418823 for ['[CLS] because star usc but ginger boltontial nat [SEP]']
[Init] best rec loss: 1.0000369548797607 for ['[CLS] bottom especially fed wake ingpy existencerted [SEP]']
[Init] best rec loss: 0.9792600870132446 for ['[CLS]yreang mythopped older jackson cause ɡ [SEP]']
[Init] best rec loss: 0.9738048315048218 for ['[CLS] 50 formed viewing trevorple meeting bundle live [SEP]']
[Init] best rec loss: 0.9515565037727356 for ['[CLS] fraternity concern there times menu stoptford studio [SEP]']
[Init] best rec loss: 0.9510055184364319 for ['[CLS] tor cox flooread maintain km² fledged grupo [SEP]']
[Init] best rec loss: 0.9505051970481873 for ['[CLS] needed brieflyuth doing further here those honour [SEP]']
[Init] best rec loss: 0.9423287510871887 for ['[CLS] exhibited samson mix posing sc issued ernie program [SEP]']
[Init] best perm rec loss: 0.9409102201461792 for ['[CLS] issued ernie exhibited program samson posing mix sc [SEP]']
[Init] best perm rec loss: 0.940762996673584 for ['[CLS] program sc samson issued exhibited mix ernie posing [SEP]']
[Init] best perm rec loss: 0.9402257800102234 for ['[CLS] program ernie exhibited posing sc mix issued samson [SEP]']
[Init] best perm rec loss: 0.9393174648284912 for ['[CLS] program sc issued exhibited ernie posing mix samson [SEP]']
[Init] best perm rec loss: 0.93841952085495 for ['[CLS] ernie sc samson issued program exhibited mix posing [SEP]']
[Init] best perm rec loss: 0.9383668303489685 for ['[CLS] program posing sc samson exhibited ernie issued mix [SEP]']
[Init] best perm rec loss: 0.9381166696548462 for ['[CLS] ernie sc program samson exhibited issued mix posing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.911 (perp=11.663, rec=0.662, cos=0.916), tot_loss_proj:4.207 [t=0.17s]
prediction: ['[CLS] ernie crossover us dance knock delivered the sophisticated [SEP]']
[ 100/2000] tot_loss=2.430 (perp=9.985, rec=0.386, cos=0.048), tot_loss_proj:3.999 [t=0.18s]
prediction: ['[CLS]ed waltz you waltz floor chains of names [SEP]']
[ 150/2000] tot_loss=2.071 (perp=8.872, rec=0.283, cos=0.014), tot_loss_proj:3.716 [t=0.18s]
prediction: ['[CLS] waltz waltzed waltz floor waltz her crossed [SEP]']
[ 200/2000] tot_loss=2.238 (perp=10.087, rec=0.211, cos=0.010), tot_loss_proj:3.983 [t=0.17s]
prediction: ['[CLS] waltz her across waltz floor waltz her across [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.362 (perp=10.962, rec=0.161, cos=0.008), tot_loss_proj:4.064 [t=0.19s]
prediction: ['[CLS] he her across waltz floor waltz floor across [SEP]']
[ 300/2000] tot_loss=2.344 (perp=10.962, rec=0.146, cos=0.006), tot_loss_proj:4.068 [t=0.19s]
prediction: ['[CLS] he her across waltz floor waltz floor across [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.115 (perp=9.630, rec=0.180, cos=0.010), tot_loss_proj:3.772 [t=0.20s]
prediction: ['[CLS] he her across waltz floor waltz things. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.853 (perp=8.546, rec=0.136, cos=0.008), tot_loss_proj:3.541 [t=0.17s]
prediction: ['[CLS] he floor her across waltz waltz things. [SEP]']
[ 450/2000] tot_loss=1.840 (perp=8.546, rec=0.125, cos=0.006), tot_loss_proj:3.549 [t=0.17s]
prediction: ['[CLS] he floor her across waltz waltz things. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.810 (perp=8.415, rec=0.121, cos=0.006), tot_loss_proj:3.635 [t=0.17s]
prediction: ['[CLS] he things her across waltz waltz floor. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.886 (perp=8.813, rec=0.118, cos=0.005), tot_loss_proj:3.805 [t=0.17s]
prediction: ['[CLS] he things her across waltzers floor. [SEP]']
[ 600/2000] tot_loss=1.877 (perp=8.813, rec=0.110, cos=0.005), tot_loss_proj:3.803 [t=0.18s]
prediction: ['[CLS] he things her across waltzers floor. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.816 (perp=8.531, rec=0.105, cos=0.005), tot_loss_proj:3.730 [t=0.17s]
prediction: ['[CLS] he things her across waltz floorers. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.815 (perp=8.531, rec=0.105, cos=0.004), tot_loss_proj:3.727 [t=0.17s]
prediction: ['[CLS] he things her across waltz floorers. [SEP]']
[ 750/2000] tot_loss=1.812 (perp=8.531, rec=0.102, cos=0.004), tot_loss_proj:3.729 [t=0.17s]
prediction: ['[CLS] he things her across waltz floorers. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.958 (perp=9.230, rec=0.108, cos=0.004), tot_loss_proj:3.735 [t=0.18s]
prediction: ['[CLS] he things her across waltz floor swung. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.714 (perp=8.021, rec=0.104, cos=0.005), tot_loss_proj:3.633 [t=0.17s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
[ 900/2000] tot_loss=1.709 (perp=8.021, rec=0.101, cos=0.004), tot_loss_proj:3.637 [t=0.17s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.709 (perp=8.021, rec=0.101, cos=0.004), tot_loss_proj:3.640 [t=0.18s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.704 (perp=8.021, rec=0.097, cos=0.003), tot_loss_proj:3.633 [t=0.18s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
[1050/2000] tot_loss=1.702 (perp=8.021, rec=0.095, cos=0.003), tot_loss_proj:3.639 [t=0.17s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.703 (perp=8.021, rec=0.096, cos=0.003), tot_loss_proj:3.639 [t=0.18s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.694 (perp=8.021, rec=0.088, cos=0.002), tot_loss_proj:3.634 [t=0.17s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
[1200/2000] tot_loss=1.690 (perp=8.021, rec=0.084, cos=0.002), tot_loss_proj:3.638 [t=0.19s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.689 (perp=8.021, rec=0.083, cos=0.002), tot_loss_proj:3.631 [t=0.17s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.689 (perp=8.021, rec=0.083, cos=0.002), tot_loss_proj:3.638 [t=0.17s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
[1350/2000] tot_loss=1.683 (perp=8.021, rec=0.077, cos=0.002), tot_loss_proj:3.636 [t=0.17s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.682 (perp=8.021, rec=0.076, cos=0.002), tot_loss_proj:3.635 [t=0.17s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.681 (perp=8.021, rec=0.075, cos=0.002), tot_loss_proj:3.636 [t=0.17s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
[1500/2000] tot_loss=1.678 (perp=8.021, rec=0.072, cos=0.002), tot_loss_proj:3.632 [t=0.17s]
prediction: ['[CLS] he things her across waltzed floor. [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.656 (perp=7.892, rec=0.076, cos=0.002), tot_loss_proj:3.408 [t=0.17s]
prediction: ['[CLS] he across things her waltzed floor. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.603 (perp=7.593, rec=0.082, cos=0.002), tot_loss_proj:3.499 [t=0.19s]
prediction: ['[CLS] he things across her waltzed floor. [SEP]']
[1650/2000] tot_loss=1.597 (perp=7.593, rec=0.077, cos=0.002), tot_loss_proj:3.505 [t=0.19s]
prediction: ['[CLS] he things across her waltzed floor. [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.409 (perp=6.630, rec=0.081, cos=0.002), tot_loss_proj:3.234 [t=0.17s]
prediction: ['[CLS] he things waltzed across her floor. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.328 (perp=6.198, rec=0.086, cos=0.002), tot_loss_proj:2.677 [t=0.17s]
prediction: ['[CLS] he waltzed things across her floor. [SEP]']
[1800/2000] tot_loss=1.321 (perp=6.198, rec=0.079, cos=0.002), tot_loss_proj:2.678 [t=0.17s]
prediction: ['[CLS] he waltzed things across her floor. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.317 (perp=6.198, rec=0.075, cos=0.002), tot_loss_proj:2.678 [t=0.17s]
prediction: ['[CLS] he waltzed things across her floor. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.316 (perp=6.198, rec=0.075, cos=0.002), tot_loss_proj:2.674 [t=0.17s]
prediction: ['[CLS] he waltzed things across her floor. [SEP]']
[1950/2000] tot_loss=1.312 (perp=6.198, rec=0.070, cos=0.002), tot_loss_proj:2.674 [t=0.17s]
prediction: ['[CLS] he waltzed things across her floor. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.308 (perp=6.198, rec=0.067, cos=0.002), tot_loss_proj:2.675 [t=0.17s]
prediction: ['[CLS] he waltzed things across her floor. [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] he waltzed her across the floor. [SEP]
========================
predicted: 
========================
[CLS] he waltzed things across her floor. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 130.357

[Aggregate metrics]:
rouge1     | fm: 83.801 | p: 83.223 | r: 84.637
rouge2     | fm: 38.547 | p: 38.112 | r: 39.142
rougeL     | fm: 69.705 | p: 69.088 | r: 70.572
rougeLsum  | fm: 69.707 | p: 69.080 | r: 70.530
r1fm+r2fm = 122.349

input #82 time: 0:07:16 | total time: 10:03:10


Running input #83 of 100.
reference: 
========================
How easy to please John is it?
========================
average of cosine similarity 0.9991972001687286
highest_index [0]
highest [0.9991972001687286]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2129, 3733, 2000, 3531, 2198, 2003, 2009, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] how easy to please john is it? [SEP]']
[Init] best rec loss: 0.9373605251312256 for ['[CLS] blacksmith straight heart comprises works right wa would [SEP]']
[Init] best rec loss: 0.7622125744819641 for ['[CLS] god bay hungarianaround dad pony medal i [SEP]']
[Init] best rec loss: 0.7569143772125244 for ['[CLS] trevorntsgni midway coup eye denied disputed [SEP]']
[Init] best rec loss: 0.7506915330886841 for ['[CLS] lead addressed cruz irish nice motion | father [SEP]']
[Init] best rec loss: 0.7334410548210144 for ['[CLS] motor pacificeni confined near abby holding curled [SEP]']
[Init] best rec loss: 0.7291074395179749 for ['[CLS] buddy city piccoloweed ledger bulb print second [SEP]']
[Init] best rec loss: 0.7228348255157471 for ['[CLS] tonight stupid covering to scores up storm fake [SEP]']
[Init] best rec loss: 0.7001823782920837 for ['[CLS] spent tr paddington kingdoms ryder master jr sides [SEP]']
[Init] best perm rec loss: 0.698954701423645 for ['[CLS] master sides spent ryder kingdoms paddington jr tr [SEP]']
[Init] best perm rec loss: 0.6988367438316345 for ['[CLS] spent master sides paddington ryder jr tr kingdoms [SEP]']
[Init] best perm rec loss: 0.6987406611442566 for ['[CLS] spent paddington ryder master tr kingdoms jr sides [SEP]']
[Init] best perm rec loss: 0.6986838579177856 for ['[CLS] sides master paddington ryder tr spent jr kingdoms [SEP]']
[Init] best perm rec loss: 0.698501467704773 for ['[CLS] sides spent master ryder kingdoms tr jr paddington [SEP]']
[Init] best perm rec loss: 0.6980337500572205 for ['[CLS] jr tr master paddington kingdoms spent ryder sides [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.272 (perp=14.131, rec=0.404, cos=0.042), tot_loss_proj:3.841 [t=0.17s]
prediction: ['[CLS] geneva change no keith style decent rick cannot [SEP]']
[ 100/2000] tot_loss=1.927 (perp=7.517, rec=0.382, cos=0.042), tot_loss_proj:2.665 [t=0.17s]
prediction: ['[CLS] john always which please, please please please [SEP]']
[ 150/2000] tot_loss=2.158 (perp=9.099, rec=0.309, cos=0.029), tot_loss_proj:3.127 [t=0.17s]
prediction: ['[CLS] john always how please is please please please [SEP]']
[ 200/2000] tot_loss=2.218 (perp=8.954, rec=0.307, cos=0.121), tot_loss_proj:2.885 [t=0.17s]
prediction: ['[CLS] john easy how easy is please please please [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.805 (perp=7.383, rec=0.302, cos=0.027), tot_loss_proj:2.277 [t=0.17s]
prediction: ['[CLS] how easy is please please please john easy [SEP]']
[ 300/2000] tot_loss=1.835 (perp=8.131, rec=0.197, cos=0.012), tot_loss_proj:2.673 [t=0.17s]
prediction: ['[CLS] how easy is please john please john easy [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.737 (perp=7.753, rec=0.176, cos=0.010), tot_loss_proj:2.665 [t=0.17s]
prediction: ['[CLS] how easy please john is please is easy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.806 (perp=8.212, rec=0.155, cos=0.009), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] how easy please john is please? easy [SEP]']
[ 450/2000] tot_loss=1.558 (perp=7.085, rec=0.133, cos=0.009), tot_loss_proj:2.466 [t=0.17s]
prediction: ['[CLS] how easy please john is it? it [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.454 (perp=6.628, rec=0.123, cos=0.005), tot_loss_proj:2.913 [t=0.17s]
prediction: ['[CLS] how easy please john is it it? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.391 (perp=6.391, rec=0.109, cos=0.004), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] how easy please john is to it? [SEP]']
[ 600/2000] tot_loss=1.385 (perp=6.391, rec=0.104, cos=0.003), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] how easy please john is to it? [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.240 (perp=5.693, rec=0.098, cos=0.004), tot_loss_proj:1.337 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.225 (perp=5.693, rec=0.084, cos=0.002), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[ 750/2000] tot_loss=1.226 (perp=5.693, rec=0.085, cos=0.002), tot_loss_proj:1.318 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.217 (perp=5.693, rec=0.077, cos=0.002), tot_loss_proj:1.316 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.209 (perp=5.693, rec=0.069, cos=0.002), tot_loss_proj:1.300 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[ 900/2000] tot_loss=1.202 (perp=5.693, rec=0.062, cos=0.002), tot_loss_proj:1.302 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.207 (perp=5.693, rec=0.067, cos=0.002), tot_loss_proj:1.306 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.217 (perp=5.693, rec=0.077, cos=0.002), tot_loss_proj:1.309 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1050/2000] tot_loss=1.207 (perp=5.693, rec=0.066, cos=0.002), tot_loss_proj:1.303 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.210 (perp=5.693, rec=0.070, cos=0.002), tot_loss_proj:1.304 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.213 (perp=5.693, rec=0.073, cos=0.002), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1200/2000] tot_loss=1.197 (perp=5.693, rec=0.057, cos=0.002), tot_loss_proj:1.313 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.203 (perp=5.693, rec=0.063, cos=0.002), tot_loss_proj:1.297 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.211 (perp=5.693, rec=0.071, cos=0.002), tot_loss_proj:1.303 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1350/2000] tot_loss=1.202 (perp=5.693, rec=0.062, cos=0.002), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.208 (perp=5.693, rec=0.068, cos=0.002), tot_loss_proj:1.312 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.190 (perp=5.693, rec=0.050, cos=0.002), tot_loss_proj:1.309 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1500/2000] tot_loss=1.201 (perp=5.693, rec=0.061, cos=0.002), tot_loss_proj:1.313 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.206 (perp=5.693, rec=0.066, cos=0.002), tot_loss_proj:1.316 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.219 (perp=5.693, rec=0.078, cos=0.002), tot_loss_proj:1.307 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1650/2000] tot_loss=1.202 (perp=5.693, rec=0.062, cos=0.002), tot_loss_proj:1.308 [t=0.34s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.199 (perp=5.693, rec=0.059, cos=0.002), tot_loss_proj:1.302 [t=0.19s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.207 (perp=5.693, rec=0.067, cos=0.002), tot_loss_proj:1.301 [t=0.20s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1800/2000] tot_loss=1.200 (perp=5.693, rec=0.060, cos=0.002), tot_loss_proj:1.315 [t=0.17s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.210 (perp=5.693, rec=0.070, cos=0.002), tot_loss_proj:1.302 [t=0.18s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.207 (perp=5.693, rec=0.067, cos=0.002), tot_loss_proj:1.312 [t=0.18s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
[1950/2000] tot_loss=1.201 (perp=5.693, rec=0.061, cos=0.002), tot_loss_proj:1.308 [t=0.18s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.206 (perp=5.693, rec=0.066, cos=0.002), tot_loss_proj:1.302 [t=0.18s]
prediction: ['[CLS] how easy to please john is it? [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] how easy to please john is it? [SEP]
========================
predicted: 
========================
[CLS] how easy to please john is it? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 84.061 | p: 83.459 | r: 84.891
rouge2     | fm: 39.414 | p: 38.964 | r: 40.029
rougeL     | fm: 70.138 | p: 69.505 | r: 70.931
rougeLsum  | fm: 70.100 | p: 69.534 | r: 70.954
r1fm+r2fm = 123.475

input #83 time: 0:07:19 | total time: 10:10:30


Running input #84 of 100.
reference: 
========================
That the king or queen be present is a requirement on all Royal weddings.
========================
average of cosine similarity 0.9993769048273349
highest_index [0]
highest [0.9993769048273349]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2008,  1996,  2332,  2030,  3035,  2022,  2556,  2003,  1037,
          9095,  2006,  2035,  2548, 20429,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]']
[Init] best rec loss: 0.9533893465995789 for ['[CLS] y during udnsorlot shed art closed described power na seriously guild le grinding [SEP]']
[Init] best rec loss: 0.9478017091751099 for ['[CLS] calling time action restrictionhui edge still equality municipality part genieint compelledomp remainder [SEP]']
[Init] best rec loss: 0.9476109743118286 for ['[CLS] mold awful sighs ever shane scottish saetan tu way pin then band paintingssp ridley [SEP]']
[Init] best rec loss: 0.9459329843521118 for ['[CLS] multi class epic average consensus ) international mine heels trim bone erica drama say ren [SEP]']
[Init] best rec loss: 0.9199742078781128 for ['[CLS] metro coulddilly sees command vanessacter zane bend deadly his ledger day 95 poetry [SEP]']
[Init] best rec loss: 0.9192661643028259 for ['[CLS] mid village eastern though sold trafficking royce thanks concerned google member cross humorous climbingtom [SEP]']
[Init] best rec loss: 0.9171982407569885 for ['[CLS] leads reputation amassed as sept education mona t everything questions state ground safety inside kick [SEP]']
[Init] best rec loss: 0.9159625768661499 for ['[CLS] beatmission round truck dissolvedκ wishes residential problems tadestinalinavina imp spirit [SEP]']
[Init] best rec loss: 0.9154359102249146 for ['[CLS] barracks replacedmanful reid avenueorous ads kurt text criminalicing sloane feel brand [SEP]']
[Init] best rec loss: 0.9110174179077148 for ['[CLS]eon way grove church [MASK] style redistribution war better sherry dock traffic bound admission blessing [SEP]']
[Init] best rec loss: 0.9109504222869873 for ['[CLS]bedo legal will pregnant hewitt camera earlier ongoingrralł o mouth would regardedown [SEP]']
[Init] best perm rec loss: 0.9088231325149536 for ['[CLS] pregnant camera ongoingł legalbedo would regarded earlierrral mouth hewitt oown will [SEP]']
[Init] best perm rec loss: 0.9083888530731201 for ['[CLS] regardedown pregnant ongoing earlier mouth legal hewitt would camerałbedo orral will [SEP]']
[Init] best perm rec loss: 0.90836501121521 for ['[CLS] ongoing will pregnantbedo camera legal regarded hewittrral mouth earlierown wouldł o [SEP]']
[Init] best perm rec loss: 0.9055202007293701 for ['[CLS] ongoing regarded camera earlier o pregnantrral will mouthbedoł legal hewitt wouldown [SEP]']
[Init] best perm rec loss: 0.9041357040405273 for ['[CLS] o would regarded mouth camera earlier pregnant ongoing willrralbedoł legalown hewitt [SEP]']
[Init] best perm rec loss: 0.9036893248558044 for ['[CLS] o ongoing earlier willown pregnant regardedł legal mouth hewitt camera wouldbedorral [SEP]']
[Init] best perm rec loss: 0.9027160406112671 for ['[CLS] ongoingł o legalrralownbedo would pregnant camera mouth hewitt will earlier regarded [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.499 (perp=10.627, rec=0.350, cos=0.024), tot_loss_proj:3.926 [t=0.18s]
prediction: ['[CLS]ium was royal weddings aidan visit the moth allowed mrs john students, playing as [SEP]']
[ 100/2000] tot_loss=2.230 (perp=9.669, rec=0.282, cos=0.015), tot_loss_proj:3.804 [t=0.18s]
prediction: ['[CLS] is was royal weddings royal queen a royal allowed weddings john afterwards on. even [SEP]']
[ 150/2000] tot_loss=2.154 (perp=9.523, rec=0.239, cos=0.011), tot_loss_proj:3.762 [t=0.18s]
prediction: ['[CLS] all was royal weddings royal queen a royal allows weddings spouse king on. even [SEP]']
[ 200/2000] tot_loss=2.128 (perp=9.605, rec=0.200, cos=0.007), tot_loss_proj:3.745 [t=0.19s]
prediction: ['[CLS] all was royal weddings queen king a regal allows spouse upon king on. even [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.249 (perp=10.283, rec=0.185, cos=0.008), tot_loss_proj:3.864 [t=0.18s]
prediction: ['[CLS] all was royal weddings queen king the be spouse allows upon king on all existing [SEP]']
[ 300/2000] tot_loss=2.262 (perp=10.451, rec=0.165, cos=0.006), tot_loss_proj:3.893 [t=0.18s]
prediction: ['[CLS] requirement was royal weddings queen king the be spouse requirement upon king on all requirement [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.008 (perp=9.209, rec=0.161, cos=0.006), tot_loss_proj:3.662 [t=0.18s]
prediction: ['[CLS] requirement not royal weddings queen the queen be spouse requirement upon present on all or [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.084 (perp=9.643, rec=0.151, cos=0.005), tot_loss_proj:3.719 [t=0.18s]
prediction: ['[CLS] any not royal weddings queen the queen be jaenelle requirement upon present on all requirement [SEP]']
[ 450/2000] tot_loss=2.077 (perp=9.666, rec=0.140, cos=0.004), tot_loss_proj:3.750 [t=0.18s]
prediction: ['[CLS] present the royal weddings queen the queen be jaenelle requirement upon present on all requirement [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.042 (perp=9.495, rec=0.140, cos=0.004), tot_loss_proj:3.692 [t=0.18s]
prediction: ['[CLS] present the royal weddings be that queen the jaenelle requirement because present on all requirement [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.990 (perp=9.279, rec=0.130, cos=0.005), tot_loss_proj:3.663 [t=0.18s]
prediction: ['[CLS] queen the royal weddings be that be be jaenelle is because present on all requirement [SEP]']
[ 600/2000] tot_loss=1.866 (perp=8.712, rec=0.120, cos=0.003), tot_loss_proj:3.549 [t=0.18s]
prediction: ['[CLS] queen a royal weddings be that be be or is because present on all requirement [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.737 (perp=8.150, rec=0.104, cos=0.003), tot_loss_proj:3.433 [t=0.18s]
prediction: ['[CLS] be a royal weddings be that queen be or is because present on all requirement [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.707 (perp=8.037, rec=0.097, cos=0.003), tot_loss_proj:3.414 [t=0.18s]
prediction: ['[CLS] present a royal weddings be that a queen or is or present on all requirement [SEP]']
[ 750/2000] tot_loss=1.722 (perp=8.113, rec=0.096, cos=0.003), tot_loss_proj:3.443 [t=0.18s]
prediction: ['[CLS] present a royal weddings be that the queen or is or present on all requirement [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.547 (perp=7.240, rec=0.096, cos=0.003), tot_loss_proj:3.272 [t=0.18s]
prediction: ['[CLS] be or royal weddings be that the queen or is a present on all requirement [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.486 (perp=6.959, rec=0.091, cos=0.003), tot_loss_proj:3.222 [t=0.18s]
prediction: ['[CLS] be royal or weddings be that the queen or is a present on all requirement [SEP]']
[ 900/2000] tot_loss=1.531 (perp=7.184, rec=0.091, cos=0.003), tot_loss_proj:3.251 [t=0.18s]
prediction: ['[CLS] present royal or weddings be that the queen or is a present on all requirement [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.499 (perp=6.980, rec=0.101, cos=0.003), tot_loss_proj:3.210 [t=0.18s]
prediction: ['[CLS] present royal weddings or be that the queen or is a present on all requirement [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.428 (perp=6.525, rec=0.118, cos=0.005), tot_loss_proj:3.134 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present present on all requirement [SEP]']
[1050/2000] tot_loss=1.407 (perp=6.525, rec=0.098, cos=0.004), tot_loss_proj:3.133 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present present on all requirement [SEP]']
Attempt swap
[1100/2000] tot_loss=1.498 (perp=7.060, rec=0.083, cos=0.003), tot_loss_proj:3.245 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a be present on all requirement [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.427 (perp=6.642, rec=0.095, cos=0.003), tot_loss_proj:3.141 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present on all be requirement [SEP]']
[1200/2000] tot_loss=1.425 (perp=6.642, rec=0.093, cos=0.003), tot_loss_proj:3.139 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present on all be requirement [SEP]']
Attempt swap
[1250/2000] tot_loss=1.455 (perp=6.803, rec=0.091, cos=0.003), tot_loss_proj:3.187 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present on all queen requirement [SEP]']
Attempt swap
[1300/2000] tot_loss=1.454 (perp=6.803, rec=0.091, cos=0.003), tot_loss_proj:3.182 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present on all queen requirement [SEP]']
[1350/2000] tot_loss=1.444 (perp=6.803, rec=0.080, cos=0.003), tot_loss_proj:3.185 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present on all queen requirement [SEP]']
Attempt swap
[1400/2000] tot_loss=1.444 (perp=6.803, rec=0.080, cos=0.003), tot_loss_proj:3.184 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present on all queen requirement [SEP]']
Attempt swap
[1450/2000] tot_loss=1.459 (perp=6.803, rec=0.096, cos=0.003), tot_loss_proj:3.182 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present on all queen requirement [SEP]']
[1500/2000] tot_loss=1.452 (perp=6.803, rec=0.088, cos=0.003), tot_loss_proj:3.187 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present on all queen requirement [SEP]']
Attempt swap
[1550/2000] tot_loss=1.454 (perp=6.803, rec=0.090, cos=0.003), tot_loss_proj:3.182 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or is a present on all queen requirement [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.276 (perp=5.885, rec=0.096, cos=0.003), tot_loss_proj:3.050 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or queen is a present on all requirement [SEP]']
[1650/2000] tot_loss=1.272 (perp=5.885, rec=0.092, cos=0.003), tot_loss_proj:3.046 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or queen is a present on all requirement [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.237 (perp=5.681, rec=0.098, cos=0.003), tot_loss_proj:3.071 [t=0.17s]
prediction: ['[CLS] royal weddings or be that the king or queen is a present requirement on all [SEP]']
Attempt swap
[1750/2000] tot_loss=1.227 (perp=5.681, rec=0.088, cos=0.003), tot_loss_proj:3.068 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or queen is a present requirement on all [SEP]']
[1800/2000] tot_loss=1.230 (perp=5.681, rec=0.091, cos=0.003), tot_loss_proj:3.067 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or queen is a present requirement on all [SEP]']
Attempt swap
[1850/2000] tot_loss=1.229 (perp=5.681, rec=0.090, cos=0.003), tot_loss_proj:3.065 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or queen is a present requirement on all [SEP]']
Attempt swap
[1900/2000] tot_loss=1.227 (perp=5.681, rec=0.088, cos=0.003), tot_loss_proj:3.066 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or queen is a present requirement on all [SEP]']
[1950/2000] tot_loss=1.224 (perp=5.681, rec=0.085, cos=0.003), tot_loss_proj:3.069 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or queen is a present requirement on all [SEP]']
Attempt swap
[2000/2000] tot_loss=1.230 (perp=5.681, rec=0.091, cos=0.003), tot_loss_proj:3.066 [t=0.18s]
prediction: ['[CLS] royal weddings or be that the king or queen is a present requirement on all [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]
========================
predicted: 
========================
[CLS] royal weddings or be that the king or queen is a present requirement on all [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.970 | p: 94.118 | r: 100.000
rouge2     | fm: 51.613 | p: 50.000 | r: 53.333
rougeL     | fm: 72.727 | p: 70.588 | r: 75.000
rougeLsum  | fm: 72.727 | p: 70.588 | r: 75.000
r1fm+r2fm = 148.583

[Aggregate metrics]:
rouge1     | fm: 84.187 | p: 83.599 | r: 85.037
rouge2     | fm: 39.564 | p: 39.160 | r: 40.148
rougeL     | fm: 70.081 | p: 69.488 | r: 70.985
rougeLsum  | fm: 70.067 | p: 69.434 | r: 70.926
r1fm+r2fm = 123.750

input #84 time: 0:07:06 | total time: 10:17:36


Running input #85 of 100.
reference: 
========================
Aphrodite stinks to be omnipotent.
========================
average of cosine similarity 0.9992293766306254
highest_index [0]
highest [0.9992293766306254]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  9706,  8093,  7716,  4221, 27136,  2015,  2000,  2022, 18168,
          3490, 11008,  4765,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] aphrodite stinks to be omnipotent. [SEP]']
[Init] best rec loss: 0.963916003704071 for ['[CLS] grandchildren ghosts course [SEP]et chief view matt single ko pass rural entered [SEP]']
[Init] best rec loss: 0.8446941375732422 for ['[CLS] glancedュ lowell anna bathtana range focus deafules ball look shortened [SEP]']
[Init] best rec loss: 0.8403056263923645 for ['[CLS] bang hd people essential cell [UNK]ckweight wonder origin unique joshua pick [SEP]']
[Init] best rec loss: 0.8182287216186523 for ['[CLS] march mayoralloadsman greatuled coverskieox monuments res bree thomas [SEP]']
[Init] best rec loss: 0.7831145524978638 for ['[CLS] beneath asked string wrath chief premiere general kneltabas expected minute taiwanese careful [SEP]']
[Init] best rec loss: 0.7647914886474609 for ['[CLS] go legged camille song xavier greg corinne most minus fever formation pair se [SEP]']
[Init] best perm rec loss: 0.7635236978530884 for ['[CLS] minus most se legged fever camille xavier go song corinne formation greg pair [SEP]']
[Init] best perm rec loss: 0.7634173631668091 for ['[CLS] pair minus camille greg song corinne formation most xavier se fever legged go [SEP]']
[Init] best perm rec loss: 0.7633981704711914 for ['[CLS] formation song most camille legged greg pair minus se fever xavier go corinne [SEP]']
[Init] best perm rec loss: 0.7631508708000183 for ['[CLS] fever pair go song greg most xavier corinne formation minus camille se legged [SEP]']
[Init] best perm rec loss: 0.762401282787323 for ['[CLS] se go greg formation most song camille fever legged xavier minus pair corinne [SEP]']
[Init] best perm rec loss: 0.7608497738838196 for ['[CLS] most song minus legged greg formation corinne go pair camille fever se xavier [SEP]']
[Init] best perm rec loss: 0.7602949142456055 for ['[CLS] fever go xavier most corinne song legged pair minus camille greg formation se [SEP]']
[Init] best perm rec loss: 0.7601321339607239 for ['[CLS] se minus legged go pair formation xavier greg most camille song corinne fever [SEP]']
[Init] best perm rec loss: 0.7598096132278442 for ['[CLS] camille legged minus corinne fever formation song se most go pair xavier greg [SEP]']
[Init] best perm rec loss: 0.7597153186798096 for ['[CLS] corinne minus camille fever most greg song pair legged formation go xavier se [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.461 (perp=14.672, rec=0.440, cos=0.087), tot_loss_proj:4.228 [t=0.17s]
prediction: ['[CLS] householdwoman gain liveishmentmen record eagle bow fc capita penalty ″ [SEP]']
[ 100/2000] tot_loss=3.165 (perp=13.899, rec=0.355, cos=0.030), tot_loss_proj:4.026 [t=0.17s]
prediction: ['[CLS]ite speed stink be canarymenura each ap dragonitical episode bears [SEP]']
[ 150/2000] tot_loss=3.085 (perp=13.822, rec=0.302, cos=0.019), tot_loss_proj:4.062 [t=0.17s]
prediction: ['[CLS]ite stink stink be canaryiteura herodite stinkpot stink [SEP]']
[ 200/2000] tot_loss=2.685 (perp=12.123, rec=0.241, cos=0.019), tot_loss_proj:3.531 [t=0.17s]
prediction: ['[CLS]ite stink stink beodite robin herodite stinkpotyles [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.524 (perp=10.804, rec=0.324, cos=0.039), tot_loss_proj:3.567 [t=0.19s]
prediction: ['[CLS]ite stink tooditeies stink theodite bepot. [SEP]']
[ 300/2000] tot_loss=2.357 (perp=10.243, rec=0.254, cos=0.054), tot_loss_proj:3.216 [t=0.19s]
prediction: ['[CLS]ite stink toodite pyramids of aprum bepot. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.619 (perp=11.762, rec=0.244, cos=0.022), tot_loss_proj:3.747 [t=0.17s]
prediction: ['[CLS]ite stink toodite guardss the beten appot. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.357 (perp=10.704, rec=0.203, cos=0.013), tot_loss_proj:3.761 [t=0.17s]
prediction: ['[CLS]pot stink tooditeaps the betenitepot. [SEP]']
[ 450/2000] tot_loss=2.452 (perp=11.298, rec=0.180, cos=0.012), tot_loss_proj:3.693 [t=0.17s]
prediction: ['[CLS]pot stink tooditegts the beentitepot. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.430 (perp=11.250, rec=0.174, cos=0.006), tot_loss_proj:3.959 [t=0.17s]
prediction: ['[CLS]pot stink rankingsodite tos of beentitepot. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.446 (perp=11.397, rec=0.161, cos=0.005), tot_loss_proj:3.419 [t=0.17s]
prediction: ['[CLS]pot stinkpotodite tos ap beentitelo. [SEP]']
[ 600/2000] tot_loss=2.437 (perp=11.397, rec=0.153, cos=0.005), tot_loss_proj:3.423 [t=0.17s]
prediction: ['[CLS]pot stinkpotodite tos ap beentitelo. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.116 (perp=9.788, rec=0.155, cos=0.004), tot_loss_proj:3.547 [t=0.17s]
prediction: ['[CLS]pot stink apodite tospot beentitelo. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.925 (perp=8.871, rec=0.145, cos=0.005), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS]pot stink apodite tos bepotentite reports. [SEP]']
[ 750/2000] tot_loss=1.946 (perp=9.035, rec=0.136, cos=0.003), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS]pot stink apodite tos bepotentitepot. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.960 (perp=9.104, rec=0.136, cos=0.003), tot_loss_proj:3.491 [t=0.17s]
prediction: ['[CLS]pot stink apodite tos bepotiteloent. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.903 (perp=8.745, rec=0.149, cos=0.005), tot_loss_proj:3.176 [t=0.17s]
prediction: ['[CLS]pot stink apodite topotites beloent. [SEP]']
[ 900/2000] tot_loss=1.873 (perp=8.745, rec=0.121, cos=0.002), tot_loss_proj:3.181 [t=0.17s]
prediction: ['[CLS]pot stink apodite topotites beloent. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.788 (perp=8.266, rec=0.133, cos=0.002), tot_loss_proj:3.415 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.784 (perp=8.266, rec=0.129, cos=0.002), tot_loss_proj:3.419 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
[1050/2000] tot_loss=1.771 (perp=8.266, rec=0.116, cos=0.002), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.779 (perp=8.266, rec=0.123, cos=0.002), tot_loss_proj:3.414 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.777 (perp=8.266, rec=0.122, cos=0.002), tot_loss_proj:3.414 [t=0.18s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
[1200/2000] tot_loss=1.767 (perp=8.266, rec=0.112, cos=0.002), tot_loss_proj:3.413 [t=0.18s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.772 (perp=8.266, rec=0.117, cos=0.002), tot_loss_proj:3.415 [t=0.18s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.779 (perp=8.266, rec=0.124, cos=0.002), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
[1350/2000] tot_loss=1.770 (perp=8.266, rec=0.115, cos=0.002), tot_loss_proj:3.416 [t=0.18s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.764 (perp=8.266, rec=0.109, cos=0.002), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.772 (perp=8.266, rec=0.117, cos=0.002), tot_loss_proj:3.412 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
[1500/2000] tot_loss=1.771 (perp=8.266, rec=0.115, cos=0.002), tot_loss_proj:3.414 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.761 (perp=8.266, rec=0.106, cos=0.002), tot_loss_proj:3.415 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.764 (perp=8.266, rec=0.109, cos=0.002), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
[1650/2000] tot_loss=1.770 (perp=8.266, rec=0.114, cos=0.002), tot_loss_proj:3.411 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.765 (perp=8.266, rec=0.110, cos=0.002), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.771 (perp=8.266, rec=0.116, cos=0.002), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
[1800/2000] tot_loss=1.767 (perp=8.266, rec=0.112, cos=0.002), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.763 (perp=8.266, rec=0.108, cos=0.002), tot_loss_proj:3.412 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.766 (perp=8.266, rec=0.111, cos=0.002), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
[1950/2000] tot_loss=1.763 (perp=8.266, rec=0.108, cos=0.002), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.761 (perp=8.266, rec=0.106, cos=0.002), tot_loss_proj:3.410 [t=0.17s]
prediction: ['[CLS]pot stink apoditespotite to beloent. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] aphrodite stinks to be omnipotent. [SEP]
========================
predicted: 
========================
[CLS]pot stink apoditespotite to beloent. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 42.857 | p: 42.857 | r: 42.857
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.857 | p: 42.857 | r: 42.857
rougeLsum  | fm: 42.857 | p: 42.857 | r: 42.857
r1fm+r2fm = 42.857

[Aggregate metrics]:
rouge1     | fm: 83.710 | p: 83.137 | r: 84.565
rouge2     | fm: 39.047 | p: 38.594 | r: 39.717
rougeL     | fm: 69.797 | p: 69.219 | r: 70.647
rougeLsum  | fm: 69.747 | p: 69.145 | r: 70.606
r1fm+r2fm = 122.757

input #85 time: 0:07:35 | total time: 10:25:11


Running input #86 of 100.
reference: 
========================
I lifted him up the books.
========================
average of cosine similarity 0.9993153968093855
highest_index [0]
highest [0.9993153968093855]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1045, 4196, 2032, 2039, 1996, 2808, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i lifted him up the books. [SEP]']
[Init] best rec loss: 0.8596559762954712 for ['[CLS] associates kill blockade musica [SEP] bees... [SEP]']
[Init] best rec loss: 0.8160300850868225 for ['[CLS] geekping converted order early franchise pressing [SEP]']
[Init] best rec loss: 0.808757483959198 for ['[CLS] schools team legal lateents laird each [SEP]']
[Init] best rec loss: 0.7976799607276917 for ['[CLS] cara jar orchard wolf walking this negative [SEP]']
[Init] best rec loss: 0.7589608430862427 for ['[CLS] interest check indytute watch pitched licence [SEP]']
[Init] best rec loss: 0.739559531211853 for ['[CLS] did chin rearن spray davyologist [SEP]']
[Init] best rec loss: 0.7275917530059814 for ['[CLS]tonic based coveren booth novels infrared [SEP]']
[Init] best rec loss: 0.7006744742393494 for ['[CLS] made par letters imp carrier obviouss [SEP]']
[Init] best rec loss: 0.6927193999290466 for ['[CLS]arus bank groups bare primetime rub reviewer [SEP]']
[Init] best perm rec loss: 0.6910474300384521 for ['[CLS] reviewer rubarus groups bank primetime bare [SEP]']
[Init] best perm rec loss: 0.6876217722892761 for ['[CLS] rubarus bare bank groups reviewer primetime [SEP]']
[Init] best perm rec loss: 0.6860266923904419 for ['[CLS] rub bank primetime groupsarus reviewer bare [SEP]']
[Init] best perm rec loss: 0.6856589317321777 for ['[CLS] rub primetimearus reviewer groups bank bare [SEP]']
[Init] best perm rec loss: 0.6850431561470032 for ['[CLS] rub bank reviewerarus primetime groups bare [SEP]']
[Init] best perm rec loss: 0.6846989393234253 for ['[CLS] reviewer bare groups bank rub primetimearus [SEP]']
[Init] best perm rec loss: 0.6846939921379089 for ['[CLS] primetime bare groups bank rub reviewerarus [SEP]']
[Init] best perm rec loss: 0.6846843361854553 for ['[CLS] bare reviewerarus bank rub primetime groups [SEP]']
[Init] best perm rec loss: 0.683734655380249 for ['[CLS]arus groups reviewer bank bare rub primetime [SEP]']
[Init] best perm rec loss: 0.6832753419876099 for ['[CLS]arus bare primetime reviewer groups bank rub [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.431 (perp=9.414, rec=0.493, cos=0.055), tot_loss_proj:2.810 [t=0.17s]
prediction: ['[CLS] my can cost two ones songs yet [SEP]']
[ 100/2000] tot_loss=2.153 (perp=8.931, rec=0.339, cos=0.028), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS] myol up the ones things. [SEP]']
[ 150/2000] tot_loss=2.071 (perp=9.119, rec=0.232, cos=0.015), tot_loss_proj:2.736 [t=0.17s]
prediction: ['[CLS] liftederic up the ones books. [SEP]']
[ 200/2000] tot_loss=1.875 (perp=8.461, rec=0.173, cos=0.009), tot_loss_proj:2.500 [t=0.17s]
prediction: ['[CLS] liftederic up the his books. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.804 (perp=7.920, rec=0.199, cos=0.021), tot_loss_proj:2.228 [t=0.17s]
prediction: ['[CLS] potential lifted up the him books. [SEP]']
[ 300/2000] tot_loss=1.689 (perp=7.407, rec=0.179, cos=0.028), tot_loss_proj:2.196 [t=0.17s]
prediction: ['[CLS] any lifted up the him books. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.570 (perp=7.241, rec=0.115, cos=0.007), tot_loss_proj:2.359 [t=0.17s]
prediction: ['[CLS] us lifted up the books him. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.447 (perp=6.605, rec=0.118, cos=0.008), tot_loss_proj:1.781 [t=0.17s]
prediction: ['[CLS] us lifted him up the books. [SEP]']
[ 450/2000] tot_loss=1.427 (perp=6.605, rec=0.100, cos=0.006), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] us lifted him up the books. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.430 (perp=6.605, rec=0.104, cos=0.005), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] us lifted him up the books. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.199 (perp=5.534, rec=0.087, cos=0.005), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[ 600/2000] tot_loss=1.199 (perp=5.534, rec=0.089, cos=0.004), tot_loss_proj:1.636 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.198 (perp=5.534, rec=0.088, cos=0.003), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.206 (perp=5.534, rec=0.096, cos=0.003), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[ 750/2000] tot_loss=1.191 (perp=5.534, rec=0.081, cos=0.003), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.189 (perp=5.534, rec=0.080, cos=0.003), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.186 (perp=5.534, rec=0.076, cos=0.003), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[ 900/2000] tot_loss=1.185 (perp=5.534, rec=0.076, cos=0.003), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.185 (perp=5.534, rec=0.075, cos=0.003), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.177 (perp=5.534, rec=0.067, cos=0.003), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1050/2000] tot_loss=1.186 (perp=5.534, rec=0.077, cos=0.003), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.176 (perp=5.534, rec=0.067, cos=0.003), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.178 (perp=5.534, rec=0.068, cos=0.003), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1200/2000] tot_loss=1.189 (perp=5.534, rec=0.079, cos=0.003), tot_loss_proj:1.610 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.185 (perp=5.534, rec=0.076, cos=0.003), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.179 (perp=5.534, rec=0.070, cos=0.003), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1350/2000] tot_loss=1.181 (perp=5.534, rec=0.072, cos=0.003), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.176 (perp=5.534, rec=0.066, cos=0.003), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.175 (perp=5.534, rec=0.066, cos=0.003), tot_loss_proj:1.603 [t=0.18s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1500/2000] tot_loss=1.163 (perp=5.534, rec=0.054, cos=0.003), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.175 (perp=5.534, rec=0.066, cos=0.003), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.184 (perp=5.534, rec=0.074, cos=0.003), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1650/2000] tot_loss=1.186 (perp=5.534, rec=0.077, cos=0.003), tot_loss_proj:1.606 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.179 (perp=5.534, rec=0.069, cos=0.003), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.170 (perp=5.534, rec=0.060, cos=0.003), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1800/2000] tot_loss=1.176 (perp=5.534, rec=0.067, cos=0.003), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.168 (perp=5.534, rec=0.059, cos=0.003), tot_loss_proj:1.609 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.177 (perp=5.534, rec=0.068, cos=0.003), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
[1950/2000] tot_loss=1.178 (perp=5.534, rec=0.068, cos=0.003), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.174 (perp=5.534, rec=0.064, cos=0.003), tot_loss_proj:1.598 [t=0.18s]
prediction: ['[CLS] i lifted him up the books. [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] i lifted him up the books. [SEP]
========================
predicted: 
========================
[CLS] i lifted him up the books. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 83.887 | p: 83.307 | r: 84.811
rouge2     | fm: 39.633 | p: 39.224 | r: 40.282
rougeL     | fm: 70.142 | p: 69.579 | r: 70.966
rougeLsum  | fm: 70.106 | p: 69.502 | r: 70.960
r1fm+r2fm = 123.520

input #86 time: 0:06:57 | total time: 10:32:08


Running input #87 of 100.
reference: 
========================
Heidi thinks that Andy has eaten salmon flavored candy bars.
========================
average of cosine similarity 0.9993324758205361
highest_index [0]
highest [0.9993324758205361]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101, 21372,  6732,  2008,  5557,  2038,  8828, 11840, 14894,  2098,
          9485,  6963,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]']
[Init] best rec loss: 1.0333819389343262 for ['[CLS] flood but! means roe vietnam after partial owe cult novel question [SEP]']
[Init] best rec loss: 0.9575434923171997 for ['[CLS] remained rates made glacier beginning gift pianoril department springsuratie [SEP]']
[Init] best rec loss: 0.9186620116233826 for ['[CLS] moreplppet children bank henri she entertainment expression clipped emotions webber [SEP]']
[Init] best perm rec loss: 0.9178486466407776 for ['[CLS] more expression clippedppet webber emotions entertainmentpl she bank children henri [SEP]']
[Init] best perm rec loss: 0.9169323444366455 for ['[CLS] henri expression entertainment she webber clipped children moreppetpl emotions bank [SEP]']
[Init] best perm rec loss: 0.9160096049308777 for ['[CLS] webber emotions expression childrenppet clipped entertainmentpl more henri bank she [SEP]']
[Init] best perm rec loss: 0.9155099391937256 for ['[CLS] bank webber entertainment expression she henri more clipped children emotionsplppet [SEP]']
[Init] best perm rec loss: 0.9128410816192627 for ['[CLS]plppet emotions clipped entertainment bank children she webber expression more henri [SEP]']
[Init] best perm rec loss: 0.9127443432807922 for ['[CLS] entertainment clippedppet emotions children henri bankpl expression webber she more [SEP]']
[Init] best perm rec loss: 0.911577582359314 for ['[CLS]ppet bank children expression entertainment clipped henri she emotions webber morepl [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.275 (perp=13.667, rec=0.627, cos=0.915), tot_loss_proj:4.619 [t=0.17s]
prediction: ['[CLS] many compliment money stairs jason mansion excellenceop employees layla nedra mocking [SEP]']
[ 100/2000] tot_loss=2.708 (perp=11.829, rec=0.310, cos=0.031), tot_loss_proj:4.333 [t=0.18s]
prediction: ['[CLS] advertising flavor heidi. heidi heidi users heidi think animal goods saw [SEP]']
[ 150/2000] tot_loss=2.434 (perp=11.166, rec=0.193, cos=0.008), tot_loss_proj:4.066 [t=0.18s]
prediction: ['[CLS] heidi flavor heidi. heidi andy eaten heidi thinks steak candy saw [SEP]']
[ 200/2000] tot_loss=2.751 (perp=12.907, rec=0.164, cos=0.006), tot_loss_proj:4.419 [t=0.18s]
prediction: ['[CLS] andy flavor salmon eaten heidi andy eaten andy thinks candy candy witnessed [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.414 (perp=11.379, rec=0.130, cos=0.007), tot_loss_proj:4.198 [t=0.17s]
prediction: ['[CLS] andy flavor salmon heidi eaten andy has andy thinks candy candy has [SEP]']
[ 300/2000] tot_loss=2.393 (perp=11.379, rec=0.113, cos=0.004), tot_loss_proj:4.193 [t=0.17s]
prediction: ['[CLS] andy flavor salmon heidi eaten andy has andy thinks candy candy has [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.385 (perp=11.290, rec=0.122, cos=0.004), tot_loss_proj:4.263 [t=0.17s]
prediction: ['[CLS] andy that salmon heidi eaten. has andy thinks candy candy flavor [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.084 (perp=9.811, rec=0.117, cos=0.004), tot_loss_proj:3.984 [t=0.17s]
prediction: ['[CLS] andy that salmon heidi has eaten. andy thinks candy candy flavor [SEP]']
[ 450/2000] tot_loss=2.056 (perp=9.811, rec=0.091, cos=0.003), tot_loss_proj:3.984 [t=0.17s]
prediction: ['[CLS] andy that salmon heidi has eaten. andy thinks candy candy flavor [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.895 (perp=8.976, rec=0.097, cos=0.003), tot_loss_proj:3.821 [t=0.18s]
prediction: ['[CLS] andy salmon that heidi has eaten. andy thinks candy candy flavor [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.106 (perp=10.007, rec=0.100, cos=0.004), tot_loss_proj:3.899 [t=0.18s]
prediction: ['[CLS] andy salmon that heidi has eaten andy thinks candy candy flavortan [SEP]']
[ 600/2000] tot_loss=2.159 (perp=10.346, rec=0.087, cos=0.003), tot_loss_proj:3.931 [t=0.18s]
prediction: ['[CLS] andy salmon that heidi has eaten andy thinksed candy flavortan [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.870 (perp=8.960, rec=0.075, cos=0.003), tot_loss_proj:3.727 [t=0.17s]
prediction: ['[CLS] andy salmon that heidi has eaten andy thinks flavored candytan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.560 (perp=7.344, rec=0.088, cos=0.003), tot_loss_proj:3.415 [t=0.17s]
prediction: ['[CLS] andy salmon that heidi has eaten andy thinks flavored candy. [SEP]']
[ 750/2000] tot_loss=1.556 (perp=7.344, rec=0.084, cos=0.003), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS] andy salmon that heidi has eaten andy thinks flavored candy. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.475 (perp=6.956, rec=0.081, cos=0.003), tot_loss_proj:2.034 [t=0.18s]
prediction: ['[CLS] andy thinks that heidi has eaten andy salmon flavored candy. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.431 (perp=6.745, rec=0.079, cos=0.003), tot_loss_proj:1.647 [t=0.18s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
[ 900/2000] tot_loss=1.435 (perp=6.745, rec=0.084, cos=0.003), tot_loss_proj:1.649 [t=0.18s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.436 (perp=6.745, rec=0.084, cos=0.003), tot_loss_proj:1.658 [t=0.18s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.437 (perp=6.745, rec=0.085, cos=0.003), tot_loss_proj:1.658 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
[1050/2000] tot_loss=1.432 (perp=6.745, rec=0.080, cos=0.003), tot_loss_proj:1.651 [t=0.18s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.429 (perp=6.745, rec=0.077, cos=0.003), tot_loss_proj:1.643 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.429 (perp=6.745, rec=0.077, cos=0.003), tot_loss_proj:1.648 [t=0.18s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
[1200/2000] tot_loss=1.426 (perp=6.745, rec=0.074, cos=0.003), tot_loss_proj:1.657 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.432 (perp=6.745, rec=0.080, cos=0.003), tot_loss_proj:1.652 [t=0.18s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.428 (perp=6.745, rec=0.076, cos=0.003), tot_loss_proj:1.652 [t=0.18s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
[1350/2000] tot_loss=1.432 (perp=6.745, rec=0.080, cos=0.002), tot_loss_proj:1.658 [t=0.19s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.431 (perp=6.745, rec=0.080, cos=0.003), tot_loss_proj:1.650 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.419 (perp=6.745, rec=0.068, cos=0.002), tot_loss_proj:1.655 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
[1500/2000] tot_loss=1.427 (perp=6.745, rec=0.075, cos=0.002), tot_loss_proj:1.652 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.430 (perp=6.745, rec=0.078, cos=0.002), tot_loss_proj:1.650 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.427 (perp=6.745, rec=0.075, cos=0.002), tot_loss_proj:1.652 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
[1650/2000] tot_loss=1.433 (perp=6.745, rec=0.082, cos=0.002), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.424 (perp=6.745, rec=0.073, cos=0.002), tot_loss_proj:1.650 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.432 (perp=6.745, rec=0.081, cos=0.002), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
[1800/2000] tot_loss=1.431 (perp=6.745, rec=0.079, cos=0.002), tot_loss_proj:1.649 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.434 (perp=6.745, rec=0.082, cos=0.002), tot_loss_proj:1.648 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.428 (perp=6.745, rec=0.077, cos=0.002), tot_loss_proj:1.656 [t=0.18s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
[1950/2000] tot_loss=1.434 (perp=6.745, rec=0.083, cos=0.002), tot_loss_proj:1.649 [t=0.17s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.425 (perp=6.745, rec=0.074, cos=0.002), tot_loss_proj:1.653 [t=0.18s]
prediction: ['[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]
========================
predicted: 
========================
[CLS] andy thinks that heidi has eaten salmon flavored candy. andy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 45.455 | p: 45.455 | r: 45.455
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 137.121

[Aggregate metrics]:
rouge1     | fm: 84.011 | p: 83.410 | r: 84.861
rouge2     | fm: 39.775 | p: 39.329 | r: 40.355
rougeL     | fm: 70.174 | p: 69.612 | r: 71.030
rougeLsum  | fm: 70.158 | p: 69.538 | r: 71.021
r1fm+r2fm = 123.786

input #87 time: 0:06:58 | total time: 10:39:06


Running input #88 of 100.
reference: 
========================
He bought these flowers for Aaron.
========================
average of cosine similarity 0.9993928411345322
highest_index [0]
highest [0.9993928411345322]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 4149, 2122, 4870, 2005, 7158, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he bought these flowers for aaron. [SEP]']
[Init] best rec loss: 1.034036636352539 for ['[CLS] wi rio xx irving ou obligations tang [SEP]']
[Init] best rec loss: 1.0049952268600464 for ['[CLS]ing rahman medina volume!lyn put [SEP]']
[Init] best rec loss: 0.9832890629768372 for ['[CLS]iateddication media familiar cas re threshold [SEP]']
[Init] best rec loss: 0.9699617624282837 for ['[CLS]card logan bamboo acting phi market query [SEP]']
[Init] best rec loss: 0.9513040781021118 for ['[CLS] drum representative kai edges evolutionary theories abandonment [SEP]']
[Init] best rec loss: 0.9334592223167419 for ['[CLS] americanaur− laughter peedy stock [SEP]']
[Init] best perm rec loss: 0.9307273030281067 for ['[CLS] peedy stock−aur laughter american [SEP]']
[Init] best perm rec loss: 0.9302306175231934 for ['[CLS] american laughter peedy stock−aur [SEP]']
[Init] best perm rec loss: 0.9283412098884583 for ['[CLS] stockdyaur american laughter− pee [SEP]']
[Init] best perm rec loss: 0.9273785352706909 for ['[CLS]dy stock pee laughter−aur american [SEP]']
[Init] best perm rec loss: 0.9272459149360657 for ['[CLS]dy laughter stock pee american−aur [SEP]']
[Init] best perm rec loss: 0.9270510077476501 for ['[CLS] stockdy pee american laughteraur− [SEP]']
[Init] best perm rec loss: 0.9263805747032166 for ['[CLS] pee− laughter stockdy americanaur [SEP]']
[Init] best perm rec loss: 0.9263287782669067 for ['[CLS]aur pee stock laughter−dy american [SEP]']
[Init] best perm rec loss: 0.9248601198196411 for ['[CLS]aur laughter stock peedy− american [SEP]']
[Init] best perm rec loss: 0.9246683120727539 for ['[CLS] laughter stockaur− peedy american [SEP]']
[Init] best perm rec loss: 0.9239789247512817 for ['[CLS] stock laughter− peeaur americandy [SEP]']
[Init] best perm rec loss: 0.9223710298538208 for ['[CLS] laughter− stockdyaur pee american [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.420 (perp=13.921, rec=0.520, cos=0.116), tot_loss_proj:4.597 [t=0.17s]
prediction: ['[CLS]cope cream ass once houses aaronji [SEP]']
[ 100/2000] tot_loss=2.532 (perp=10.062, rec=0.445, cos=0.075), tot_loss_proj:3.751 [t=0.18s]
prediction: ['[CLS] bought bought the bought store aaron flowers [SEP]']
[ 150/2000] tot_loss=2.578 (perp=10.908, rec=0.359, cos=0.037), tot_loss_proj:4.064 [t=0.18s]
prediction: ['[CLS] bought bought for bought place aaron flowers [SEP]']
[ 200/2000] tot_loss=2.250 (perp=10.182, rec=0.202, cos=0.011), tot_loss_proj:3.834 [t=0.18s]
prediction: ['[CLS] bought bought these bought for aaron flowers [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.172 (perp=10.182, rec=0.128, cos=0.008), tot_loss_proj:3.841 [t=0.21s]
prediction: ['[CLS] bought bought these bought for aaron flowers [SEP]']
[ 300/2000] tot_loss=2.287 (perp=10.948, rec=0.093, cos=0.005), tot_loss_proj:3.978 [t=0.20s]
prediction: ['[CLS] bought bought these he for aaron flowers [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.147 (perp=10.221, rec=0.099, cos=0.004), tot_loss_proj:3.842 [t=0.22s]
prediction: ['[CLS] bought these he linen for aaron flowers [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.006 (perp=9.582, rec=0.085, cos=0.004), tot_loss_proj:3.722 [t=0.19s]
prediction: ['[CLS] he bought these roy for aaron flowers [SEP]']
[ 450/2000] tot_loss=1.998 (perp=9.582, rec=0.078, cos=0.004), tot_loss_proj:3.730 [t=0.19s]
prediction: ['[CLS] he bought these roy for aaron flowers [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.708 (perp=8.132, rec=0.078, cos=0.004), tot_loss_proj:2.272 [t=0.19s]
prediction: ['[CLS] he bought these flowers for aaron just [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.736 (perp=8.255, rec=0.081, cos=0.004), tot_loss_proj:2.488 [t=0.20s]
prediction: ['[CLS] he properly bought these flowers for aaron [SEP]']
[ 600/2000] tot_loss=1.737 (perp=8.255, rec=0.082, cos=0.003), tot_loss_proj:2.480 [t=0.19s]
prediction: ['[CLS] he properly bought these flowers for aaron [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.741 (perp=8.255, rec=0.086, cos=0.003), tot_loss_proj:2.484 [t=0.19s]
prediction: ['[CLS] he properly bought these flowers for aaron [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.737 (perp=8.255, rec=0.082, cos=0.003), tot_loss_proj:2.480 [t=0.19s]
prediction: ['[CLS] he properly bought these flowers for aaron [SEP]']
[ 750/2000] tot_loss=1.737 (perp=8.255, rec=0.083, cos=0.003), tot_loss_proj:2.491 [t=0.19s]
prediction: ['[CLS] he properly bought these flowers for aaron [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.735 (perp=8.255, rec=0.081, cos=0.003), tot_loss_proj:2.480 [t=0.19s]
prediction: ['[CLS] he properly bought these flowers for aaron [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.842 (perp=8.764, rec=0.086, cos=0.003), tot_loss_proj:3.708 [t=0.19s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
[ 900/2000] tot_loss=1.837 (perp=8.764, rec=0.081, cos=0.003), tot_loss_proj:3.706 [t=0.17s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.844 (perp=8.764, rec=0.088, cos=0.003), tot_loss_proj:3.704 [t=0.19s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
Attempt swap
[1000/2000] tot_loss=1.834 (perp=8.764, rec=0.078, cos=0.003), tot_loss_proj:3.704 [t=0.19s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
[1050/2000] tot_loss=1.837 (perp=8.764, rec=0.081, cos=0.003), tot_loss_proj:3.700 [t=0.21s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
Attempt swap
[1100/2000] tot_loss=1.837 (perp=8.764, rec=0.082, cos=0.003), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
Attempt swap
[1150/2000] tot_loss=1.831 (perp=8.764, rec=0.075, cos=0.003), tot_loss_proj:3.699 [t=0.17s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
[1200/2000] tot_loss=1.782 (perp=8.476, rec=0.084, cos=0.003), tot_loss_proj:3.803 [t=0.17s]
prediction: ['[CLS] he bought. these flowers for aaron [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.995 (perp=9.532, rec=0.086, cos=0.003), tot_loss_proj:3.996 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron wrap [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.832 (perp=8.764, rec=0.075, cos=0.003), tot_loss_proj:3.696 [t=0.21s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
[1350/2000] tot_loss=1.839 (perp=8.764, rec=0.083, cos=0.003), tot_loss_proj:3.690 [t=0.22s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
Attempt swap
[1400/2000] tot_loss=1.829 (perp=8.764, rec=0.073, cos=0.003), tot_loss_proj:3.696 [t=0.22s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.989 (perp=9.532, rec=0.080, cos=0.003), tot_loss_proj:3.991 [t=0.20s]
prediction: ['[CLS] he bought these flowers for aaron wrap [SEP]']
[1500/2000] tot_loss=1.985 (perp=9.532, rec=0.076, cos=0.003), tot_loss_proj:3.991 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron wrap [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.835 (perp=8.764, rec=0.079, cos=0.003), tot_loss_proj:3.689 [t=0.18s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
Attempt swap
[1600/2000] tot_loss=1.769 (perp=8.476, rec=0.071, cos=0.003), tot_loss_proj:3.792 [t=0.18s]
prediction: ['[CLS] he bought. these flowers for aaron [SEP]']
[1650/2000] tot_loss=1.785 (perp=8.476, rec=0.087, cos=0.003), tot_loss_proj:3.791 [t=0.19s]
prediction: ['[CLS] he bought. these flowers for aaron [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.994 (perp=9.532, rec=0.084, cos=0.003), tot_loss_proj:3.990 [t=0.19s]
prediction: ['[CLS] he bought these flowers for aaron wrap [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.844 (perp=8.764, rec=0.088, cos=0.003), tot_loss_proj:3.687 [t=0.17s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
[1800/2000] tot_loss=1.834 (perp=8.764, rec=0.078, cos=0.003), tot_loss_proj:3.684 [t=0.17s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
Attempt swap
[1850/2000] tot_loss=1.772 (perp=8.476, rec=0.074, cos=0.003), tot_loss_proj:3.790 [t=0.17s]
prediction: ['[CLS] he bought. these flowers for aaron [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.988 (perp=9.532, rec=0.078, cos=0.004), tot_loss_proj:3.993 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron wrap [SEP]']
[1950/2000] tot_loss=1.980 (perp=9.532, rec=0.071, cos=0.003), tot_loss_proj:3.992 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron wrap [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.845 (perp=8.764, rec=0.089, cos=0.003), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS] he bought wrap these flowers for aaron [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] he bought these flowers for aaron. [SEP]
========================
predicted: 
========================
[CLS] he bought these flowers for aaron wrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 80.000 | p: 75.000 | r: 85.714
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 174.118

[Aggregate metrics]:
rouge1     | fm: 84.123 | p: 83.517 | r: 85.006
rouge2     | fm: 40.252 | p: 39.762 | r: 40.837
rougeL     | fm: 70.487 | p: 69.789 | r: 71.327
rougeLsum  | fm: 70.399 | p: 69.757 | r: 71.263
r1fm+r2fm = 124.375

input #88 time: 0:07:21 | total time: 10:46:28


Running input #89 of 100.
reference: 
========================
Handsome though they told me that Tom is, I still won't date him.
========================
average of cosine similarity 0.9993499747712495
highest_index [0]
highest [0.9993499747712495]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[ 101, 8502, 2295, 2027, 2409, 2033, 2008, 3419, 2003, 1010, 1045, 2145,
         2180, 1005, 1056, 3058, 2032, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] handsome though they told me that tom is, i still won't date him. [SEP]"]
[Init] best rec loss: 0.9502671360969543 for ['[CLS] save jersey myanmar walkedfkthic ˢ wife dealing tomorrow lola e bit ll show ˈ competitions [SEP]']
[Init] best rec loss: 0.9151517748832703 for ['[CLS] listential calling liesnified sesame solution hop failure colonel sign rms wil ever parsons [CLS] punk [SEP]']
[Init] best rec loss: 0.8847743272781372 for ['[CLS] airports in generic root administrative capitol wisconsin blind municipality remainder prasad squirrelswise antioch programricted palmer [SEP]']
[Init] best rec loss: 0.8470215201377869 for ['[CLS] for means dissolved truceuming pere honoured utc richards fl spike shower when quantum gray huge com [SEP]']
[Init] best rec loss: 0.8421288728713989 for ['[CLS] charactersgut 11 flow rocked sigh entitled eurovision termsbridge question rocdictow 3 dj inspired [SEP]']
[Init] best rec loss: 0.8383911848068237 for ['[CLS] mat leader michael gel making underworld problems fast lake wouldn hundred texts couple after de family 1970s [SEP]']
[Init] best rec loss: 0.825195848941803 for ['[CLS] hopes devicesrued iv governor swap that saskatchewan pup under ultimate section drugged voivodeship should morning 500 [SEP]']
[Init] best rec loss: 0.8245096206665039 for ['[CLS] sectionsfest family spacekes upon double oak gas tackplay easy if cryky distinct nautical [SEP]']
[Init] best perm rec loss: 0.8197810053825378 for ['[CLS]play sections familykesfest space distinct easy nautical gas cry ifky upon oak double tack [SEP]']
[Init] best perm rec loss: 0.8192011713981628 for ['[CLS] gas distinct upon oak familykes if tack spacefest easy sectionsplay doubleky nautical cry [SEP]']
[Init] best perm rec loss: 0.819103479385376 for ['[CLS]ky space distinct oak family if upon gas easy tackplay cry double sectionsfest nauticalkes [SEP]']
[Init] best perm rec loss: 0.8139406442642212 for ['[CLS]kes gas distinct iffest oak tack nautical cry easy double space sections familyplayky upon [SEP]']
[Init] best perm rec loss: 0.8118587136268616 for ['[CLS] tack gasplay distinct cry family oakkykes double easyfest sections space nautical if upon [SEP]']
[Init] best perm rec loss: 0.8108945488929749 for ['[CLS]playkykes distinct cry if sections familyfest oak space easy nautical upon double tack gas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.803 (perp=11.516, rec=0.436, cos=0.064), tot_loss_proj:4.257 [t=0.18s]
prediction: ['[CLS] gaming thoughsos from males but education kim were ; nothing why river as bystanding building [SEP]']
[ 100/2000] tot_loss=2.367 (perp=10.167, rec=0.312, cos=0.022), tot_loss_proj:3.932 [t=0.18s]
prediction: ['[CLS] never though they directions german but is penis were iers why husband him, is i [SEP]']
[ 150/2000] tot_loss=2.017 (perp=8.610, rec=0.263, cos=0.032), tot_loss_proj:3.725 [t=0.19s]
prediction: ['[CLS] cannot though they told handsome is is tom, i it why handsome him, is i [SEP]']
[ 200/2000] tot_loss=2.280 (perp=10.127, rec=0.234, cos=0.021), tot_loss_proj:3.913 [t=0.18s]
prediction: ['[CLS] definitely though they told handsome is is tom, i him remain handsome learnedomi is i [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.161 (perp=9.553, rec=0.221, cos=0.029), tot_loss_proj:3.768 [t=0.19s]
prediction: ['[CLS] remain though they told handsome is is tom i,r never handsome him until is i [SEP]']
[ 300/2000] tot_loss=2.158 (perp=9.874, rec=0.154, cos=0.030), tot_loss_proj:3.858 [t=0.19s]
prediction: ['[CLS] remain though they told handsome is is tom i,p would handsome that until is i [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.951 (perp=8.752, rec=0.175, cos=0.026), tot_loss_proj:3.622 [t=0.19s]
prediction: ['[CLS] date though they told handsome is tom tom i, pu would he said dinner is. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.687 (perp=7.586, rec=0.150, cos=0.020), tot_loss_proj:3.445 [t=0.19s]
prediction: ["[CLS] though date they told handsome is tom tom i,'wouldn he said dinner is. [SEP]"]
[ 450/2000] tot_loss=1.782 (perp=8.300, rec=0.115, cos=0.007), tot_loss_proj:3.524 [t=0.19s]
prediction: ['[CLS] though date they told handsome is tom tom i, still wouldn he said? is. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.644 (perp=7.602, rec=0.116, cos=0.007), tot_loss_proj:3.301 [t=0.20s]
prediction: ['[CLS] though date they told handsome is tom tom i still wouldn, he said? is. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.709 (perp=7.900, rec=0.120, cos=0.009), tot_loss_proj:3.523 [t=0.20s]
prediction: ['[CLS] though that they date handsome is tom tom i still wouldn, he told varsity is. [SEP]']
[ 600/2000] tot_loss=1.699 (perp=7.900, rec=0.114, cos=0.005), tot_loss_proj:3.527 [t=0.19s]
prediction: ['[CLS] though that they date handsome is tom tom i still wouldn, he told varsity is. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.735 (perp=8.140, rec=0.103, cos=0.004), tot_loss_proj:3.565 [t=0.20s]
prediction: ['[CLS] though that they date handsome is tom tom i still won, him told is varsity. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.611 (perp=7.525, rec=0.101, cos=0.004), tot_loss_proj:3.392 [t=0.20s]
prediction: ['[CLS] though that they date handsome is told tom i still won, told him is?. [SEP]']
[ 750/2000] tot_loss=1.662 (perp=7.819, rec=0.095, cos=0.003), tot_loss_proj:3.527 [t=0.20s]
prediction: ['[CLS] though that they date handsome is told tom i still won, told him is varsity. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.660 (perp=7.819, rec=0.094, cos=0.003), tot_loss_proj:3.528 [t=0.18s]
prediction: ['[CLS] though that they date handsome is told tom i still won, told him is varsity. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.661 (perp=7.819, rec=0.095, cos=0.003), tot_loss_proj:3.533 [t=0.20s]
prediction: ['[CLS] though that they date handsome is told tom i still won, told him is varsity. [SEP]']
[ 900/2000] tot_loss=1.662 (perp=7.819, rec=0.096, cos=0.003), tot_loss_proj:3.529 [t=0.20s]
prediction: ['[CLS] though that they date handsome is told tom i still won, told him is varsity. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.635 (perp=7.713, rec=0.090, cos=0.002), tot_loss_proj:3.471 [t=0.18s]
prediction: ['[CLS] though that they date handsome is told tom i still won varsity, told him is. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.610 (perp=7.593, rec=0.089, cos=0.003), tot_loss_proj:3.502 [t=0.18s]
prediction: ['[CLS] though that they date handsome is told tom i still won varsity, him is told. [SEP]']
[1050/2000] tot_loss=1.603 (perp=7.593, rec=0.082, cos=0.002), tot_loss_proj:3.504 [t=0.18s]
prediction: ['[CLS] though that they date handsome is told tom i still won varsity, him is told. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.560 (perp=7.332, rec=0.091, cos=0.003), tot_loss_proj:3.403 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won varsity, him is told. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.521 (perp=7.118, rec=0.093, cos=0.004), tot_loss_proj:3.264 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won?, is told him. [SEP]']
[1200/2000] tot_loss=1.534 (perp=7.245, rec=0.082, cos=0.002), tot_loss_proj:3.335 [t=0.20s]
prediction: ['[CLS] though handsome that they date is told tom i still won me, is told him. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.470 (perp=6.882, rec=0.091, cos=0.002), tot_loss_proj:3.260 [t=0.20s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.460 (perp=6.882, rec=0.081, cos=0.002), tot_loss_proj:3.262 [t=0.20s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
[1350/2000] tot_loss=1.452 (perp=6.882, rec=0.074, cos=0.002), tot_loss_proj:3.258 [t=0.20s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.465 (perp=6.882, rec=0.087, cos=0.002), tot_loss_proj:3.255 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.462 (perp=6.882, rec=0.083, cos=0.002), tot_loss_proj:3.255 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
[1500/2000] tot_loss=1.466 (perp=6.882, rec=0.087, cos=0.002), tot_loss_proj:3.261 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.468 (perp=6.882, rec=0.089, cos=0.002), tot_loss_proj:3.261 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.461 (perp=6.882, rec=0.082, cos=0.002), tot_loss_proj:3.256 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
[1650/2000] tot_loss=1.467 (perp=6.882, rec=0.088, cos=0.002), tot_loss_proj:3.258 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.474 (perp=6.882, rec=0.095, cos=0.002), tot_loss_proj:3.255 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.457 (perp=6.882, rec=0.079, cos=0.002), tot_loss_proj:3.258 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
[1800/2000] tot_loss=1.460 (perp=6.882, rec=0.081, cos=0.002), tot_loss_proj:3.258 [t=0.19s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.467 (perp=6.882, rec=0.089, cos=0.002), tot_loss_proj:3.257 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.456 (perp=6.882, rec=0.078, cos=0.002), tot_loss_proj:3.257 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
[1950/2000] tot_loss=1.459 (perp=6.882, rec=0.081, cos=0.002), tot_loss_proj:3.258 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.473 (perp=6.882, rec=0.094, cos=0.002), tot_loss_proj:3.257 [t=0.18s]
prediction: ['[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] handsome though they told me that tom is, i still won't date him. [SEP]
========================
predicted: 
========================
[CLS] though handsome that they date is told tom i still won him, is told me. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 88.235 | r: 93.750
rouge2     | fm: 19.355 | p: 18.750 | r: 20.000
rougeL     | fm: 60.606 | p: 58.824 | r: 62.500
rougeLsum  | fm: 60.606 | p: 58.824 | r: 62.500
r1fm+r2fm = 110.264

[Aggregate metrics]:
rouge1     | fm: 84.135 | p: 83.507 | r: 85.099
rouge2     | fm: 39.917 | p: 39.434 | r: 40.564
rougeL     | fm: 70.350 | p: 69.684 | r: 71.190
rougeLsum  | fm: 70.308 | p: 69.675 | r: 71.274
r1fm+r2fm = 124.053

input #89 time: 0:07:24 | total time: 10:53:53


Running input #90 of 100.
reference: 
========================
Moya's football team loved her
========================
average of cosine similarity 0.9993060410574175
highest_index [0]
highest [0.9993060410574175]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9587, 3148, 1005, 1055, 2374, 2136, 3866, 2014,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] moya's football team loved her [SEP]"]
[Init] best rec loss: 0.8754562735557556 for ['[CLS]rra person gasp shit rex become snow dunn [SEP]']
[Init] best rec loss: 0.8286807537078857 for ['[CLS] company slightly describe eager izzy poetryneyox [SEP]']
[Init] best rec loss: 0.8254004716873169 for ['[CLS] roman oclc consultantjust countrieslic relief kam [SEP]']
[Init] best perm rec loss: 0.8226989507675171 for ['[CLS] oclc roman consultant relief countriesjustlic kam [SEP]']
[Init] best perm rec loss: 0.8145224452018738 for ['[CLS] romanjust consultant oclc countries relief kamlic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.157 (perp=13.012, rec=0.455, cos=0.099), tot_loss_proj:4.471 [t=0.17s]
prediction: ['[CLS] miatight hence the wanna congratulationsal was [SEP]']
[ 100/2000] tot_loss=2.837 (perp=11.696, rec=0.422, cos=0.075), tot_loss_proj:4.257 [t=0.19s]
prediction: ['[CLS] ki barbara loved it america evenja today [SEP]']
[ 150/2000] tot_loss=2.557 (perp=11.108, rec=0.308, cos=0.027), tot_loss_proj:4.097 [t=0.18s]
prediction: ['[CLS] series laura loved its basketball sisterya today [SEP]']
[ 200/2000] tot_loss=2.352 (perp=10.253, rec=0.278, cos=0.023), tot_loss_proj:3.975 [t=0.20s]
prediction: ['[CLS] ma laura loved her football moya her [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.135 (perp=9.213, rec=0.261, cos=0.031), tot_loss_proj:3.684 [t=0.17s]
prediction: ['[CLS] laura loved her football mo moya her [SEP]']
[ 300/2000] tot_loss=2.360 (perp=10.361, rec=0.251, cos=0.037), tot_loss_proj:3.950 [t=0.17s]
prediction: ['[CLS] peterson loved her football mo youya her [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.124 (perp=9.698, rec=0.174, cos=0.011), tot_loss_proj:3.842 [t=0.18s]
prediction: ['[CLS] mo loved her football mo mikeya her [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.263 (perp=9.993, rec=0.231, cos=0.033), tot_loss_proj:3.896 [t=0.17s]
prediction: ['[CLS] you loved program football yesterday moya her [SEP]']
[ 450/2000] tot_loss=2.098 (perp=9.654, rec=0.159, cos=0.009), tot_loss_proj:3.829 [t=0.17s]
prediction: ['[CLS] you loved team football wireless moya her [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.245 (perp=10.559, rec=0.128, cos=0.005), tot_loss_proj:4.013 [t=0.17s]
prediction: ['[CLS] you loved s team teams moya her [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.115 (perp=9.899, rec=0.126, cos=0.009), tot_loss_proj:3.874 [t=0.17s]
prediction: ['[CLS] you loved teams team s moya her [SEP]']
[ 600/2000] tot_loss=2.051 (perp=9.671, rec=0.112, cos=0.004), tot_loss_proj:3.817 [t=0.18s]
prediction: ['[CLS] you loved team team s moya her [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.239 (perp=10.651, rec=0.105, cos=0.004), tot_loss_proj:4.015 [t=0.17s]
prediction: ['[CLS] football loved team s team moya her [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.917 (perp=8.994, rec=0.113, cos=0.005), tot_loss_proj:3.684 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
[ 750/2000] tot_loss=1.905 (perp=8.994, rec=0.103, cos=0.003), tot_loss_proj:3.681 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.909 (perp=8.994, rec=0.108, cos=0.003), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.901 (perp=8.994, rec=0.100, cos=0.003), tot_loss_proj:3.686 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
[ 900/2000] tot_loss=1.896 (perp=8.994, rec=0.094, cos=0.003), tot_loss_proj:3.685 [t=0.18s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.898 (perp=8.994, rec=0.097, cos=0.002), tot_loss_proj:3.681 [t=0.18s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1000/2000] tot_loss=1.895 (perp=8.994, rec=0.094, cos=0.002), tot_loss_proj:3.681 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
[1050/2000] tot_loss=1.898 (perp=8.994, rec=0.097, cos=0.002), tot_loss_proj:3.677 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1100/2000] tot_loss=1.895 (perp=8.994, rec=0.094, cos=0.002), tot_loss_proj:3.684 [t=0.18s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1150/2000] tot_loss=1.886 (perp=8.994, rec=0.085, cos=0.002), tot_loss_proj:3.685 [t=0.21s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
[1200/2000] tot_loss=1.889 (perp=8.994, rec=0.088, cos=0.002), tot_loss_proj:3.683 [t=0.19s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1250/2000] tot_loss=1.892 (perp=8.994, rec=0.091, cos=0.002), tot_loss_proj:3.682 [t=0.20s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1300/2000] tot_loss=1.889 (perp=8.994, rec=0.088, cos=0.002), tot_loss_proj:3.679 [t=0.19s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
[1350/2000] tot_loss=1.889 (perp=8.994, rec=0.088, cos=0.002), tot_loss_proj:3.684 [t=0.19s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1400/2000] tot_loss=1.889 (perp=8.994, rec=0.089, cos=0.002), tot_loss_proj:3.679 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1450/2000] tot_loss=1.881 (perp=8.994, rec=0.080, cos=0.002), tot_loss_proj:3.679 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
[1500/2000] tot_loss=1.881 (perp=8.994, rec=0.080, cos=0.002), tot_loss_proj:3.681 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1550/2000] tot_loss=1.894 (perp=8.994, rec=0.094, cos=0.002), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1600/2000] tot_loss=1.883 (perp=8.994, rec=0.082, cos=0.002), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
[1650/2000] tot_loss=1.888 (perp=8.994, rec=0.087, cos=0.002), tot_loss_proj:3.681 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1700/2000] tot_loss=1.889 (perp=8.994, rec=0.088, cos=0.002), tot_loss_proj:3.683 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1750/2000] tot_loss=1.886 (perp=8.994, rec=0.086, cos=0.002), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
[1800/2000] tot_loss=1.884 (perp=8.994, rec=0.084, cos=0.002), tot_loss_proj:3.683 [t=0.18s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1850/2000] tot_loss=1.884 (perp=8.994, rec=0.083, cos=0.002), tot_loss_proj:3.685 [t=0.18s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[1900/2000] tot_loss=1.888 (perp=8.994, rec=0.087, cos=0.002), tot_loss_proj:3.680 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
[1950/2000] tot_loss=1.882 (perp=8.994, rec=0.081, cos=0.002), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Attempt swap
[2000/2000] tot_loss=1.887 (perp=8.994, rec=0.086, cos=0.002), tot_loss_proj:3.684 [t=0.17s]
prediction: ['[CLS] s loved team football team moya her [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] moya's football team loved her [SEP]
========================
predicted: 
========================
[CLS] s loved team football team moya her [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 26.667 | p: 25.000 | r: 28.571
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 120.784

[Aggregate metrics]:
rouge1     | fm: 84.286 | p: 83.550 | r: 85.272
rouge2     | fm: 39.851 | p: 39.357 | r: 40.483
rougeL     | fm: 70.366 | p: 69.670 | r: 71.248
rougeLsum  | fm: 70.311 | p: 69.579 | r: 71.249
r1fm+r2fm = 124.138

input #90 time: 0:07:06 | total time: 11:00:59


Running input #91 of 100.
reference: 
========================
They investigated the problem.
========================
average of cosine similarity 0.9994048200497065
highest_index [0]
highest [0.9994048200497065]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2027, 10847,  1996,  3291,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] they investigated the problem. [SEP]']
[Init] best rec loss: 1.0008985996246338 for ['[CLS] non trap brackets opposite mbe [SEP]']
[Init] best rec loss: 0.9636040925979614 for ['[CLS] nope rare chief steveyon [SEP]']
[Init] best rec loss: 0.9533264636993408 for ['[CLS] new award assistant river ce [SEP]']
[Init] best rec loss: 0.946533203125 for ['[CLS] 3 solid property video cane [SEP]']
[Init] best rec loss: 0.9368292093276978 for ['[CLS] communication seat professional delivery lankan [SEP]']
[Init] best rec loss: 0.9343482255935669 for ['[CLS] tongue ways na flush region [SEP]']
[Init] best rec loss: 0.9309041500091553 for ['[CLS] central rosen fashion rounds be [SEP]']
[Init] best rec loss: 0.8867634534835815 for ['[CLS]w czech real mrference [SEP]']
[Init] best rec loss: 0.8775110244750977 for ['[CLS] log hitler heath belgium lynne [SEP]']
[Init] best perm rec loss: 0.8742671608924866 for ['[CLS] lynne log heath belgium hitler [SEP]']
[Init] best perm rec loss: 0.8742567300796509 for ['[CLS] hitler lynne belgium heath log [SEP]']
[Init] best perm rec loss: 0.8719561696052551 for ['[CLS] hitler belgium lynne log heath [SEP]']
[Init] best perm rec loss: 0.8709571361541748 for ['[CLS] hitler log belgium heath lynne [SEP]']
[Init] best perm rec loss: 0.8697481155395508 for ['[CLS] belgium log hitler lynne heath [SEP]']
[Init] best perm rec loss: 0.8682686686515808 for ['[CLS] belgium log heath hitler lynne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.838 (perp=10.972, rec=0.498, cos=0.146), tot_loss_proj:4.156 [t=0.19s]
prediction: ['[CLS] wesleyfield symmetry.runner [SEP]']
[ 100/2000] tot_loss=2.489 (perp=10.241, rec=0.373, cos=0.067), tot_loss_proj:3.894 [t=0.17s]
prediction: ['[CLS] wesleyhire charity. dex [SEP]']
[ 150/2000] tot_loss=2.354 (perp=10.023, rec=0.308, cos=0.041), tot_loss_proj:3.833 [t=0.17s]
prediction: ['[CLS] theyfield investigated. finn [SEP]']
[ 200/2000] tot_loss=2.328 (perp=10.548, rec=0.203, cos=0.016), tot_loss_proj:3.829 [t=0.17s]
prediction: ['[CLS] they ramsey investigated. problem [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.248 (perp=10.548, rec=0.129, cos=0.009), tot_loss_proj:3.835 [t=0.17s]
prediction: ['[CLS] they ramsey investigated. problem [SEP]']
[ 300/2000] tot_loss=2.225 (perp=10.548, rec=0.108, cos=0.008), tot_loss_proj:3.838 [t=0.17s]
prediction: ['[CLS] they ramsey investigated. problem [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.228 (perp=10.548, rec=0.112, cos=0.006), tot_loss_proj:3.839 [t=0.17s]
prediction: ['[CLS] they ramsey investigated. problem [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.261 (perp=10.695, rec=0.118, cos=0.004), tot_loss_proj:3.866 [t=0.17s]
prediction: ['[CLS] they discussed investigated. problem [SEP]']
[ 450/2000] tot_loss=2.113 (perp=10.006, rec=0.108, cos=0.004), tot_loss_proj:3.780 [t=0.17s]
prediction: ['[CLS] they the investigated. problem [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.539 (perp=7.231, rec=0.091, cos=0.002), tot_loss_proj:3.208 [t=0.17s]
prediction: ['[CLS] they investigated. the problem [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.023 (perp=4.684, rec=0.084, cos=0.001), tot_loss_proj:1.063 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[ 600/2000] tot_loss=1.016 (perp=4.684, rec=0.078, cos=0.001), tot_loss_proj:1.060 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.007 (perp=4.684, rec=0.069, cos=0.001), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.014 (perp=4.684, rec=0.075, cos=0.001), tot_loss_proj:1.066 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[ 750/2000] tot_loss=1.009 (perp=4.684, rec=0.071, cos=0.001), tot_loss_proj:1.057 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.008 (perp=4.684, rec=0.070, cos=0.001), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.009 (perp=4.684, rec=0.071, cos=0.001), tot_loss_proj:1.062 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[ 900/2000] tot_loss=1.007 (perp=4.684, rec=0.069, cos=0.001), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.011 (perp=4.684, rec=0.073, cos=0.001), tot_loss_proj:1.054 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.996 (perp=4.684, rec=0.058, cos=0.001), tot_loss_proj:1.070 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1050/2000] tot_loss=1.007 (perp=4.684, rec=0.069, cos=0.001), tot_loss_proj:1.062 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.002 (perp=4.684, rec=0.064, cos=0.001), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.003 (perp=4.684, rec=0.065, cos=0.001), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1200/2000] tot_loss=1.003 (perp=4.684, rec=0.065, cos=0.001), tot_loss_proj:1.060 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.994 (perp=4.684, rec=0.056, cos=0.001), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.003 (perp=4.684, rec=0.065, cos=0.001), tot_loss_proj:1.060 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1350/2000] tot_loss=1.008 (perp=4.684, rec=0.070, cos=0.001), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.007 (perp=4.684, rec=0.069, cos=0.001), tot_loss_proj:1.053 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.998 (perp=4.684, rec=0.060, cos=0.001), tot_loss_proj:1.066 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1500/2000] tot_loss=0.997 (perp=4.684, rec=0.058, cos=0.001), tot_loss_proj:1.060 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.999 (perp=4.684, rec=0.061, cos=0.001), tot_loss_proj:1.054 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.994 (perp=4.684, rec=0.056, cos=0.001), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1650/2000] tot_loss=1.004 (perp=4.684, rec=0.066, cos=0.001), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.999 (perp=4.684, rec=0.061, cos=0.001), tot_loss_proj:1.061 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.010 (perp=4.684, rec=0.072, cos=0.001), tot_loss_proj:1.062 [t=0.21s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1800/2000] tot_loss=1.006 (perp=4.684, rec=0.068, cos=0.001), tot_loss_proj:1.047 [t=0.20s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.002 (perp=4.684, rec=0.064, cos=0.001), tot_loss_proj:1.058 [t=0.19s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.002 (perp=4.684, rec=0.064, cos=0.001), tot_loss_proj:1.053 [t=0.20s]
prediction: ['[CLS] they investigated the problem. [SEP]']
[1950/2000] tot_loss=1.000 (perp=4.684, rec=0.062, cos=0.001), tot_loss_proj:1.063 [t=0.19s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.997 (perp=4.684, rec=0.059, cos=0.001), tot_loss_proj:1.071 [t=0.17s]
prediction: ['[CLS] they investigated the problem. [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] they investigated the problem. [SEP]
========================
predicted: 
========================
[CLS] they investigated the problem. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 84.464 | p: 83.776 | r: 85.436
rouge2     | fm: 40.435 | p: 39.927 | r: 41.097
rougeL     | fm: 70.690 | p: 70.031 | r: 71.658
rougeLsum  | fm: 70.588 | p: 69.940 | r: 71.504
r1fm+r2fm = 124.899

input #91 time: 0:07:00 | total time: 11:07:59


Running input #92 of 100.
reference: 
========================
Andy promised that we would go.
========================
average of cosine similarity 0.99925545607284
highest_index [0]
highest [0.99925545607284]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 5557, 5763, 2008, 2057, 2052, 2175, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] andy promised that we would go. [SEP]']
[Init] best rec loss: 1.0239042043685913 for ['[CLS] church shade features forwardlateral one ⟨ [SEP]']
[Init] best rec loss: 0.998636782169342 for ['[CLS] parental expected chase years fighting ego in [SEP]']
[Init] best rec loss: 0.9670264720916748 for ['[CLS] mateo namely there electronics resort with knows [SEP]']
[Init] best rec loss: 0.9609618782997131 for ['[CLS] municipal over ahead hoping proved energy ui [SEP]']
[Init] best rec loss: 0.9385711550712585 for ['[CLS] internal fulfillinghel church hanging choice heath [SEP]']
[Init] best rec loss: 0.9254687428474426 for ['[CLS] bearerfor game trade suit conference bailey [SEP]']
[Init] best rec loss: 0.9024503231048584 for ['[CLS] deputy clint node ra measured wonders light [SEP]']
[Init] best perm rec loss: 0.9020792841911316 for ['[CLS] clint light deputy ra node wonders measured [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.855 (perp=11.176, rec=0.638, cos=0.981), tot_loss_proj:4.071 [t=0.17s]
prediction: ['[CLS] settings ( exclaimed we swami spoke once [SEP]']
[ 100/2000] tot_loss=2.807 (perp=12.153, rec=0.332, cos=0.044), tot_loss_proj:4.258 [t=0.17s]
prediction: ['[CLS] andylot promised promised promised want would [SEP]']
[ 150/2000] tot_loss=2.470 (perp=11.263, rec=0.205, cos=0.013), tot_loss_proj:4.095 [t=0.17s]
prediction: ['[CLS] andy andy promised promised promised go would [SEP]']
[ 200/2000] tot_loss=1.981 (perp=9.253, rec=0.124, cos=0.006), tot_loss_proj:3.788 [t=0.20s]
prediction: ['[CLS] that andy promised would we go would [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.772 (perp=8.334, rec=0.101, cos=0.004), tot_loss_proj:3.216 [t=0.17s]
prediction: ['[CLS] that andy promised we would go would [SEP]']
[ 300/2000] tot_loss=1.757 (perp=8.334, rec=0.087, cos=0.003), tot_loss_proj:3.211 [t=0.18s]
prediction: ['[CLS] that andy promised we would go would [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.403 (perp=6.570, rec=0.085, cos=0.003), tot_loss_proj:2.093 [t=0.17s]
prediction: ['[CLS] that andy promised we would go. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.455 (perp=5.852, rec=0.259, cos=0.026), tot_loss_proj:1.482 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[ 450/2000] tot_loss=1.324 (perp=5.852, rec=0.147, cos=0.007), tot_loss_proj:1.329 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.295 (perp=5.852, rec=0.121, cos=0.004), tot_loss_proj:1.332 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.267 (perp=5.852, rec=0.094, cos=0.003), tot_loss_proj:1.325 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[ 600/2000] tot_loss=1.265 (perp=5.852, rec=0.092, cos=0.003), tot_loss_proj:1.322 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.259 (perp=5.852, rec=0.086, cos=0.002), tot_loss_proj:1.324 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.262 (perp=5.852, rec=0.090, cos=0.002), tot_loss_proj:1.327 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[ 750/2000] tot_loss=1.255 (perp=5.852, rec=0.083, cos=0.002), tot_loss_proj:1.319 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.251 (perp=5.852, rec=0.079, cos=0.002), tot_loss_proj:1.320 [t=0.20s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.241 (perp=5.852, rec=0.069, cos=0.002), tot_loss_proj:1.321 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[ 900/2000] tot_loss=1.242 (perp=5.852, rec=0.070, cos=0.002), tot_loss_proj:1.315 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.248 (perp=5.852, rec=0.076, cos=0.002), tot_loss_proj:1.320 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.241 (perp=5.852, rec=0.069, cos=0.002), tot_loss_proj:1.321 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1050/2000] tot_loss=1.236 (perp=5.852, rec=0.064, cos=0.002), tot_loss_proj:1.321 [t=0.19s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.241 (perp=5.852, rec=0.070, cos=0.002), tot_loss_proj:1.322 [t=0.20s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.238 (perp=5.852, rec=0.066, cos=0.002), tot_loss_proj:1.327 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1200/2000] tot_loss=1.244 (perp=5.852, rec=0.072, cos=0.002), tot_loss_proj:1.321 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.249 (perp=5.852, rec=0.077, cos=0.002), tot_loss_proj:1.322 [t=0.18s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.248 (perp=5.852, rec=0.076, cos=0.002), tot_loss_proj:1.311 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1350/2000] tot_loss=1.247 (perp=5.852, rec=0.076, cos=0.001), tot_loss_proj:1.319 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.235 (perp=5.852, rec=0.063, cos=0.001), tot_loss_proj:1.326 [t=0.18s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.249 (perp=5.852, rec=0.077, cos=0.001), tot_loss_proj:1.317 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1500/2000] tot_loss=1.237 (perp=5.852, rec=0.065, cos=0.001), tot_loss_proj:1.314 [t=0.18s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.243 (perp=5.852, rec=0.071, cos=0.001), tot_loss_proj:1.316 [t=0.18s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.249 (perp=5.852, rec=0.078, cos=0.001), tot_loss_proj:1.322 [t=0.18s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1650/2000] tot_loss=1.252 (perp=5.852, rec=0.080, cos=0.001), tot_loss_proj:1.321 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.230 (perp=5.852, rec=0.058, cos=0.001), tot_loss_proj:1.327 [t=0.19s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.249 (perp=5.852, rec=0.077, cos=0.001), tot_loss_proj:1.325 [t=0.18s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1800/2000] tot_loss=1.241 (perp=5.852, rec=0.069, cos=0.001), tot_loss_proj:1.325 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.230 (perp=5.852, rec=0.058, cos=0.001), tot_loss_proj:1.319 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.236 (perp=5.852, rec=0.064, cos=0.001), tot_loss_proj:1.325 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
[1950/2000] tot_loss=1.242 (perp=5.852, rec=0.070, cos=0.001), tot_loss_proj:1.327 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.234 (perp=5.852, rec=0.062, cos=0.001), tot_loss_proj:1.328 [t=0.17s]
prediction: ['[CLS] andy promised that we would go. [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] andy promised that we would go. [SEP]
========================
predicted: 
========================
[CLS] andy promised that we would go. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 84.647 | p: 83.915 | r: 85.605
rouge2     | fm: 41.093 | p: 40.631 | r: 41.766
rougeL     | fm: 70.947 | p: 70.293 | r: 71.863
rougeLsum  | fm: 70.904 | p: 70.262 | r: 71.826
r1fm+r2fm = 125.740

input #92 time: 0:07:01 | total time: 11:15:00


Running input #93 of 100.
reference: 
========================
I saw these dancers and those musicians smoking something.
========================
average of cosine similarity 0.999405837791129
highest_index [0]
highest [0.999405837791129]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1045,  2387,  2122, 10487,  1998,  2216,  5389,  9422,  2242,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] i saw these dancers and those musicians smoking something. [SEP]']
[Init] best rec loss: 0.9399735331535339 for ['[CLS] choir torque titled uttar 25 tell even hitch encounter choosing [SEP]']
[Init] best rec loss: 0.9395652413368225 for ['[CLS] version ltd blur ringinghs chip astro bandrized federal [SEP]']
[Init] best rec loss: 0.9121893048286438 for ['[CLS] globe ~ titled scoredна japanese lynne they hardly lucas [SEP]']
[Init] best rec loss: 0.9106736779212952 for ['[CLS] existing ten exposurekti understandvirus beyond appear cubs planted [SEP]']
[Init] best rec loss: 0.9029486775398254 for ['[CLS] married formora wrong [CLS] enoughoft unanimouscturing spring [SEP]']
[Init] best rec loss: 0.8923229575157166 for ['[CLS] depending little you criteria remarriedmy within local flame conversion [SEP]']
[Init] best rec loss: 0.8887438774108887 for ['[CLS] sulfate basball shit begin collapse say full matches ems [SEP]']
[Init] best rec loss: 0.8878989219665527 for ['[CLS] applied ze milwaukee sharks though goods taken hour yin apps [SEP]']
[Init] best rec loss: 0.8873622417449951 for ['[CLS] aerospacelore no scheme ground overhead coach clearance under cal [SEP]']
[Init] best perm rec loss: 0.8865259289741516 for ['[CLS] aerospace scheme clearancelore ground overhead no coach cal under [SEP]']
[Init] best perm rec loss: 0.8864747285842896 for ['[CLS] coach clearance no scheme underlore aerospace cal overhead ground [SEP]']
[Init] best perm rec loss: 0.88502037525177 for ['[CLS] cal aerospace scheme overhead ground clearance nolore coach under [SEP]']
[Init] best perm rec loss: 0.8849398493766785 for ['[CLS] overheadlore ground aerospace no cal clearance coach scheme under [SEP]']
[Init] best perm rec loss: 0.8823032379150391 for ['[CLS] ground callore scheme clearance coach no aerospace overhead under [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.096 (perp=12.547, rec=0.594, cos=0.993), tot_loss_proj:4.247 [t=0.17s]
prediction: ['[CLS] tristan organizationversion once dark those album associate measurement their [SEP]']
[ 100/2000] tot_loss=4.062 (perp=12.797, rec=0.507, cos=0.995), tot_loss_proj:4.385 [t=0.17s]
prediction: ['[CLS] tristan organization robert these smoking those denise ( rent those [SEP]']
[ 150/2000] tot_loss=3.750 (perp=11.482, rec=0.454, cos=0.999), tot_loss_proj:4.124 [t=0.17s]
prediction: ['[CLS] trumpeter factions robert these musicians those odds ( smoking something [SEP]']
[ 200/2000] tot_loss=3.985 (perp=12.722, rec=0.444, cos=0.997), tot_loss_proj:4.360 [t=0.17s]
prediction: ['[CLS] trumpeter brows those these dancers thoseooped casey smoking something [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.611 (perp=10.959, rec=0.421, cos=0.999), tot_loss_proj:3.895 [t=0.17s]
prediction: ['[CLS] rebounds brows these these dancers thoseooped and smoking something [SEP]']
[ 300/2000] tot_loss=3.634 (perp=11.277, rec=0.380, cos=0.999), tot_loss_proj:3.960 [t=0.17s]
prediction: ['[CLS] yeah brows these these dancers those scores and smoking something [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.722 (perp=10.895, rec=0.545, cos=0.998), tot_loss_proj:3.886 [t=0.17s]
prediction: ['[CLS] minutes and trumpeter those dancers presidential contributions and smoking something [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.325 (perp=9.501, rec=0.427, cos=0.998), tot_loss_proj:3.598 [t=0.17s]
prediction: ['[CLS] minutes and those those dancers trumpeter executions and smoking something [SEP]']
[ 450/2000] tot_loss=3.410 (perp=10.123, rec=0.386, cos=0.999), tot_loss_proj:3.761 [t=0.17s]
prediction: ['[CLS] brows and those those dancers they executions and smoking something [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.431 (perp=10.326, rec=0.366, cos=0.999), tot_loss_proj:3.803 [t=0.17s]
prediction: ['[CLS] brows saw those those dancers executions and bandages smoking something [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.532 (perp=10.816, rec=0.370, cos=1.000), tot_loss_proj:3.936 [t=0.17s]
prediction: ['[CLS] browsɴ those dancers executions and observed those smoking something [SEP]']
[ 600/2000] tot_loss=3.240 (perp=9.445, rec=0.351, cos=1.000), tot_loss_proj:3.715 [t=0.17s]
prediction: ['[CLS] brows saw those dancers executions and observed those smoking something [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.193 (perp=9.299, rec=0.333, cos=1.000), tot_loss_proj:3.925 [t=0.17s]
prediction: ['[CLS] beak saw those dancers executions and observed those smoking something [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.194 (perp=9.299, rec=0.334, cos=1.000), tot_loss_proj:3.921 [t=0.17s]
prediction: ['[CLS] beak saw those dancers executions and observed those smoking something [SEP]']
[ 750/2000] tot_loss=3.321 (perp=10.005, rec=0.321, cos=1.000), tot_loss_proj:3.974 [t=0.17s]
prediction: ['[CLS] beak saw those dancerschemist and observed those smoking something [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.361 (perp=10.253, rec=0.311, cos=1.000), tot_loss_proj:3.879 [t=0.17s]
prediction: ['[CLS] beak saw those dancerschemist and coins those smoking something [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.369 (perp=10.253, rec=0.319, cos=0.999), tot_loss_proj:3.878 [t=0.17s]
prediction: ['[CLS] beak saw those dancerschemist and coins those smoking something [SEP]']
[ 900/2000] tot_loss=3.440 (perp=10.637, rec=0.314, cos=0.999), tot_loss_proj:3.904 [t=0.17s]
prediction: ['[CLS] pancakes saw those dancerschemist and we those smoking something [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=3.309 (perp=9.965, rec=0.317, cos=0.999), tot_loss_proj:3.826 [t=0.17s]
prediction: ['[CLS] pancakes saw those dancers and wechemist those smoking something [SEP]']
Attempt swap
[1000/2000] tot_loss=3.392 (perp=10.378, rec=0.317, cos=0.999), tot_loss_proj:4.046 [t=0.17s]
prediction: ['[CLS] pancakes saw those dancers and wechemist bits smoking something [SEP]']
[1050/2000] tot_loss=3.379 (perp=10.378, rec=0.304, cos=0.999), tot_loss_proj:4.043 [t=0.17s]
prediction: ['[CLS] pancakes saw those dancers and wechemist bits smoking something [SEP]']
Attempt swap
[1100/2000] tot_loss=3.381 (perp=10.378, rec=0.307, cos=0.999), tot_loss_proj:4.045 [t=0.17s]
prediction: ['[CLS] pancakes saw those dancers and wechemist bits smoking something [SEP]']
Attempt swap
[1150/2000] tot_loss=3.381 (perp=10.378, rec=0.307, cos=0.999), tot_loss_proj:4.047 [t=0.17s]
prediction: ['[CLS] pancakes saw those dancers and wechemist bits smoking something [SEP]']
[1200/2000] tot_loss=3.370 (perp=10.378, rec=0.295, cos=0.999), tot_loss_proj:4.041 [t=0.17s]
prediction: ['[CLS] pancakes saw those dancers and wechemist bits smoking something [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.199 (perp=9.457, rec=0.309, cos=0.998), tot_loss_proj:3.942 [t=0.17s]
prediction: ['[CLS] we saw those dancers and congratulationschemist bits smoking something [SEP]']
Attempt swap
[1300/2000] tot_loss=3.105 (perp=8.988, rec=0.310, cos=0.998), tot_loss_proj:3.900 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
[1350/2000] tot_loss=3.098 (perp=8.988, rec=0.302, cos=0.998), tot_loss_proj:3.894 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
Attempt swap
[1400/2000] tot_loss=3.101 (perp=8.988, rec=0.305, cos=0.998), tot_loss_proj:3.899 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
Attempt swap
[1450/2000] tot_loss=3.095 (perp=8.988, rec=0.299, cos=0.998), tot_loss_proj:3.895 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
[1500/2000] tot_loss=3.100 (perp=8.988, rec=0.304, cos=0.998), tot_loss_proj:3.895 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
Attempt swap
[1550/2000] tot_loss=3.099 (perp=8.988, rec=0.304, cos=0.998), tot_loss_proj:3.892 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
Attempt swap
[1600/2000] tot_loss=3.091 (perp=8.988, rec=0.296, cos=0.998), tot_loss_proj:3.896 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
[1650/2000] tot_loss=3.103 (perp=8.988, rec=0.307, cos=0.998), tot_loss_proj:3.896 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
Attempt swap
[1700/2000] tot_loss=3.091 (perp=8.988, rec=0.296, cos=0.998), tot_loss_proj:3.894 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
Attempt swap
[1750/2000] tot_loss=3.094 (perp=8.988, rec=0.298, cos=0.998), tot_loss_proj:3.891 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
[1800/2000] tot_loss=3.090 (perp=8.988, rec=0.295, cos=0.998), tot_loss_proj:3.896 [t=0.19s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
Attempt swap
[1850/2000] tot_loss=3.093 (perp=8.988, rec=0.298, cos=0.998), tot_loss_proj:3.896 [t=0.21s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
Attempt swap
[1900/2000] tot_loss=3.091 (perp=8.988, rec=0.296, cos=0.998), tot_loss_proj:3.893 [t=0.18s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
[1950/2000] tot_loss=3.094 (perp=8.988, rec=0.298, cos=0.998), tot_loss_proj:3.891 [t=0.17s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
Attempt swap
[2000/2000] tot_loss=3.093 (perp=8.988, rec=0.297, cos=0.998), tot_loss_proj:3.894 [t=0.18s]
prediction: ['[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] i saw these dancers and those musicians smoking something. [SEP]
========================
predicted: 
========================
[CLS] we saw those dancers and pancakeschemist bits smoking something [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 72.727 | r: 72.727
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 102.727

[Aggregate metrics]:
rouge1     | fm: 84.507 | p: 83.807 | r: 85.467
rouge2     | fm: 40.869 | p: 40.431 | r: 41.568
rougeL     | fm: 70.916 | p: 70.241 | r: 71.818
rougeLsum  | fm: 70.886 | p: 70.205 | r: 71.822
r1fm+r2fm = 125.375

input #93 time: 0:07:01 | total time: 11:22:02


Running input #94 of 100.
reference: 
========================
Ayala sent back her cousin the diamond necklace.
========================
average of cosine similarity 0.9992840849473748
highest_index [0]
highest [0.9992840849473748]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  2067,  2014,  5542,  1996,  6323, 13016,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ayala sent back her cousin the diamond necklace. [SEP]']
[Init] best rec loss: 1.0233622789382935 for ['[CLS] universe car flight volume stem? fangs naturally port produced [SEP]']
[Init] best rec loss: 0.810341477394104 for ['[CLS] c2 guysament means tucker indicated corresponding likes instead shifters [SEP]']
[Init] best rec loss: 0.8015455603599548 for ['[CLS] crocodile potter entertainment nearlaw chapel issues dive mohamedistle [SEP]']
[Init] best rec loss: 0.753000020980835 for ['[CLS] nina weights micah economy ladyaciesffled feeling harbor mt [SEP]']
[Init] best rec loss: 0.7525247931480408 for ['[CLS] commander system country ca young orleans facial yhaus boring [SEP]']
[Init] best rec loss: 0.7276646494865417 for ['[CLS] chartered cult4chment boat six cinder bothered eminentacies [SEP]']
[Init] best rec loss: 0.7244107127189636 for ['[CLS] henrytrip rs earlier ranks tr countries collection eye going [SEP]']
[Init] best rec loss: 0.7231367230415344 for ['[CLS] relegation unincorporated q hang separated arrive place settled up drawing [SEP]']
[Init] best rec loss: 0.7114856839179993 for ['[CLS]edge awareness champions being herself h derek label missions fits [SEP]']
[Init] best rec loss: 0.7034398317337036 for ['[CLS] o planned emirates fra conditioned simpsonlund client regulations friendly [SEP]']
[Init] best perm rec loss: 0.7031844854354858 for ['[CLS] simpsonlund conditioned planned emirates fra o client regulations friendly [SEP]']
[Init] best perm rec loss: 0.7023455500602722 for ['[CLS] client planned conditionedlund fra friendly regulations o simpson emirates [SEP]']
[Init] best perm rec loss: 0.7006390690803528 for ['[CLS] clientlund fra planned conditioned o friendly emirates simpson regulations [SEP]']
[Init] best perm rec loss: 0.699734091758728 for ['[CLS] fra emirates o conditioned simpson regulations planned clientlund friendly [SEP]']
[Init] best perm rec loss: 0.6980162858963013 for ['[CLS]lund regulations o client conditioned fra simpson planned emirates friendly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.149 (perp=13.268, rec=0.411, cos=0.085), tot_loss_proj:3.596 [t=0.17s]
prediction: ['[CLS] my return guggenheim paintings hinduism sent inca nicole booth things [SEP]']
[ 100/2000] tot_loss=2.307 (perp=9.775, rec=0.322, cos=0.030), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] his return sale paintings scientology sent back convent diamond. [SEP]']
[ 150/2000] tot_loss=2.248 (perp=9.690, rec=0.290, cos=0.020), tot_loss_proj:2.716 [t=0.17s]
prediction: ['[CLS] his her niece necklace vuelta sent back natalie diamond. [SEP]']
[ 200/2000] tot_loss=2.067 (perp=8.867, rec=0.267, cos=0.027), tot_loss_proj:3.046 [t=0.17s]
prediction: ['[CLS] her her back necklaceyala sent back back diamond. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.455 (perp=8.819, rec=0.550, cos=0.141), tot_loss_proj:2.911 [t=0.17s]
prediction: ['[CLS] his locomotives back againyala sent back her diamond " [SEP]']
[ 300/2000] tot_loss=2.304 (perp=9.753, rec=0.297, cos=0.057), tot_loss_proj:3.273 [t=0.17s]
prediction: ['[CLS] her necklace back his tribe sent back back jewelryque [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.081 (perp=9.135, rec=0.218, cos=0.035), tot_loss_proj:3.050 [t=0.17s]
prediction: ['[CLS] her necklace back the tribe sent diamonds back diamond cousin [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.176 (perp=9.758, rec=0.201, cos=0.023), tot_loss_proj:3.261 [t=0.18s]
prediction: ['[CLS] her sent back the hawaiian necklace necklace cousin necklace cousin [SEP]']
[ 450/2000] tot_loss=2.293 (perp=10.546, rec=0.170, cos=0.014), tot_loss_proj:2.939 [t=0.18s]
prediction: ['[CLS]yala sent back theyala necklace necklace cousin necklace cousin [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.177 (perp=10.085, rec=0.149, cos=0.010), tot_loss_proj:2.983 [t=0.18s]
prediction: ['[CLS]yala sent back the cousin necklace necklace cousin necklaceyala [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.145 (perp=9.925, rec=0.146, cos=0.013), tot_loss_proj:2.839 [t=0.18s]
prediction: ['[CLS]yala sent back the cousin necklace cousin necklace necklaceyala [SEP]']
[ 600/2000] tot_loss=2.126 (perp=9.925, rec=0.134, cos=0.008), tot_loss_proj:2.838 [t=0.18s]
prediction: ['[CLS]yala sent back the cousin necklace cousin necklace necklaceyala [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.127 (perp=9.925, rec=0.136, cos=0.007), tot_loss_proj:2.836 [t=0.18s]
prediction: ['[CLS]yala sent back the cousin necklace cousin necklace necklaceyala [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.116 (perp=9.925, rec=0.124, cos=0.006), tot_loss_proj:2.838 [t=0.18s]
prediction: ['[CLS]yala sent back the cousin necklace cousin necklace necklaceyala [SEP]']
[ 750/2000] tot_loss=2.186 (perp=10.290, rec=0.122, cos=0.006), tot_loss_proj:2.832 [t=0.18s]
prediction: ['[CLS]yala sent back the her necklace cousin necklace necklaceyala [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.949 (perp=9.116, rec=0.119, cos=0.008), tot_loss_proj:2.972 [t=0.18s]
prediction: ['[CLS]yala sent back her necklace cousin the necklace necklaceyala [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.932 (perp=9.116, rec=0.103, cos=0.006), tot_loss_proj:2.969 [t=0.18s]
prediction: ['[CLS]yala sent back her necklace cousin the necklace necklaceyala [SEP]']
[ 900/2000] tot_loss=1.922 (perp=9.116, rec=0.093, cos=0.005), tot_loss_proj:2.969 [t=0.18s]
prediction: ['[CLS]yala sent back her necklace cousin the necklace necklaceyala [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.010 (perp=9.545, rec=0.096, cos=0.005), tot_loss_proj:3.022 [t=0.19s]
prediction: ['[CLS]yala sent back her necklace cousin the necklace diamondyala [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.825 (perp=8.652, rec=0.089, cos=0.005), tot_loss_proj:2.650 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
[1050/2000] tot_loss=1.831 (perp=8.652, rec=0.096, cos=0.005), tot_loss_proj:2.646 [t=0.20s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1100/2000] tot_loss=1.837 (perp=8.652, rec=0.102, cos=0.005), tot_loss_proj:2.649 [t=0.18s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1150/2000] tot_loss=1.827 (perp=8.652, rec=0.092, cos=0.005), tot_loss_proj:2.648 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
[1200/2000] tot_loss=1.834 (perp=8.652, rec=0.098, cos=0.005), tot_loss_proj:2.645 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1250/2000] tot_loss=1.837 (perp=8.652, rec=0.102, cos=0.005), tot_loss_proj:2.645 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1300/2000] tot_loss=1.836 (perp=8.652, rec=0.101, cos=0.005), tot_loss_proj:2.646 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
[1350/2000] tot_loss=1.830 (perp=8.652, rec=0.095, cos=0.005), tot_loss_proj:2.639 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1400/2000] tot_loss=1.823 (perp=8.652, rec=0.088, cos=0.005), tot_loss_proj:2.641 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1450/2000] tot_loss=1.818 (perp=8.652, rec=0.083, cos=0.005), tot_loss_proj:2.641 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
[1500/2000] tot_loss=1.824 (perp=8.652, rec=0.088, cos=0.005), tot_loss_proj:2.642 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1550/2000] tot_loss=1.829 (perp=8.652, rec=0.094, cos=0.005), tot_loss_proj:2.643 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1600/2000] tot_loss=1.832 (perp=8.652, rec=0.097, cos=0.005), tot_loss_proj:2.642 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
[1650/2000] tot_loss=1.826 (perp=8.652, rec=0.090, cos=0.005), tot_loss_proj:2.643 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1700/2000] tot_loss=1.834 (perp=8.652, rec=0.099, cos=0.005), tot_loss_proj:2.642 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1750/2000] tot_loss=1.825 (perp=8.652, rec=0.090, cos=0.005), tot_loss_proj:2.646 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
[1800/2000] tot_loss=1.825 (perp=8.652, rec=0.089, cos=0.005), tot_loss_proj:2.647 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1850/2000] tot_loss=1.826 (perp=8.652, rec=0.091, cos=0.005), tot_loss_proj:2.629 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[1900/2000] tot_loss=1.818 (perp=8.652, rec=0.083, cos=0.005), tot_loss_proj:2.639 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
[1950/2000] tot_loss=1.830 (perp=8.652, rec=0.095, cos=0.005), tot_loss_proj:2.634 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Attempt swap
[2000/2000] tot_loss=1.825 (perp=8.652, rec=0.090, cos=0.005), tot_loss_proj:2.641 [t=0.17s]
prediction: ['[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] ayala sent back her cousin the diamond necklace. [SEP]
========================
predicted: 
========================
[CLS]yala sent back her necklace cousin the diamond necklaceyala [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 42.105 | p: 40.000 | r: 44.444
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 127.820

[Aggregate metrics]:
rouge1     | fm: 84.496 | p: 83.775 | r: 85.456
rouge2     | fm: 40.971 | p: 40.429 | r: 41.624
rougeL     | fm: 70.938 | p: 70.282 | r: 71.916
rougeLsum  | fm: 70.897 | p: 70.244 | r: 71.877
r1fm+r2fm = 125.466

input #94 time: 0:07:02 | total time: 11:29:04


Running input #95 of 100.
reference: 
========================
Brenda met.
========================
average of cosine similarity 0.9992582990211568
highest_index [0]
highest [0.9992582990211568]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15507,  2777,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] brenda met. [SEP]']
[Init] best rec loss: 0.9856793880462646 for ['[CLS]eptive day less [SEP]']
[Init] best rec loss: 0.931098461151123 for ['[CLS]fall few why [SEP]']
[Init] best rec loss: 0.8573922514915466 for ['[CLS] princess horses domesday [SEP]']
[Init] best rec loss: 0.826335608959198 for ['[CLS]ave recorded head [SEP]']
[Init] best rec loss: 0.753989040851593 for ['[CLS] boss back michigan [SEP]']
[Init] best rec loss: 0.7457810044288635 for ['[CLS] pseudonym mill joyah [SEP]']
[Init] best rec loss: 0.728053867816925 for ['[CLS] mary scott pending [SEP]']
[Init] best perm rec loss: 0.7271443605422974 for ['[CLS] scott mary pending [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.683 (perp=7.451, rec=0.184, cos=0.009), tot_loss_proj:1.593 [t=0.20s]
prediction: ['[CLS] brenda met. [SEP]']
[ 100/2000] tot_loss=1.587 (perp=7.451, rec=0.094, cos=0.002), tot_loss_proj:1.593 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
[ 150/2000] tot_loss=1.564 (perp=7.451, rec=0.072, cos=0.002), tot_loss_proj:1.584 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
[ 200/2000] tot_loss=1.563 (perp=7.451, rec=0.072, cos=0.001), tot_loss_proj:1.579 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.541 (perp=7.451, rec=0.050, cos=0.001), tot_loss_proj:1.578 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 300/2000] tot_loss=1.552 (perp=7.451, rec=0.061, cos=0.001), tot_loss_proj:1.577 [t=0.20s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.552 (perp=7.451, rec=0.060, cos=0.001), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.562 (perp=7.451, rec=0.070, cos=0.002), tot_loss_proj:1.582 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[ 450/2000] tot_loss=1.556 (perp=7.451, rec=0.064, cos=0.001), tot_loss_proj:1.577 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.551 (perp=7.451, rec=0.060, cos=0.001), tot_loss_proj:1.585 [t=0.20s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.552 (perp=7.451, rec=0.060, cos=0.001), tot_loss_proj:1.580 [t=0.20s]
prediction: ['[CLS] brenda met. [SEP]']
[ 600/2000] tot_loss=1.554 (perp=7.451, rec=0.062, cos=0.001), tot_loss_proj:1.576 [t=0.21s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.577 [t=0.20s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.551 (perp=7.451, rec=0.060, cos=0.001), tot_loss_proj:1.578 [t=0.20s]
prediction: ['[CLS] brenda met. [SEP]']
[ 750/2000] tot_loss=1.558 (perp=7.451, rec=0.066, cos=0.001), tot_loss_proj:1.586 [t=0.20s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.552 (perp=7.451, rec=0.060, cos=0.001), tot_loss_proj:1.583 [t=0.20s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.553 (perp=7.451, rec=0.061, cos=0.001), tot_loss_proj:1.584 [t=0.21s]
prediction: ['[CLS] brenda met. [SEP]']
[ 900/2000] tot_loss=1.556 (perp=7.451, rec=0.064, cos=0.001), tot_loss_proj:1.586 [t=0.21s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.548 (perp=7.451, rec=0.056, cos=0.001), tot_loss_proj:1.577 [t=0.20s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.542 (perp=7.451, rec=0.050, cos=0.001), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1050/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.577 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.549 (perp=7.451, rec=0.057, cos=0.001), tot_loss_proj:1.580 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.550 (perp=7.451, rec=0.058, cos=0.001), tot_loss_proj:1.580 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1200/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.553 (perp=7.451, rec=0.061, cos=0.001), tot_loss_proj:1.578 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.552 (perp=7.451, rec=0.061, cos=0.001), tot_loss_proj:1.574 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1350/2000] tot_loss=1.541 (perp=7.451, rec=0.050, cos=0.001), tot_loss_proj:1.574 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.548 (perp=7.451, rec=0.056, cos=0.001), tot_loss_proj:1.567 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.538 (perp=7.451, rec=0.047, cos=0.001), tot_loss_proj:1.568 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1500/2000] tot_loss=1.554 (perp=7.451, rec=0.062, cos=0.001), tot_loss_proj:1.574 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.551 (perp=7.451, rec=0.059, cos=0.001), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.542 (perp=7.451, rec=0.050, cos=0.001), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1650/2000] tot_loss=1.556 (perp=7.451, rec=0.065, cos=0.001), tot_loss_proj:1.587 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.551 (perp=7.451, rec=0.059, cos=0.001), tot_loss_proj:1.581 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1800/2000] tot_loss=1.541 (perp=7.451, rec=0.049, cos=0.001), tot_loss_proj:1.578 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.561 (perp=7.451, rec=0.069, cos=0.001), tot_loss_proj:1.576 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1950/2000] tot_loss=1.549 (perp=7.451, rec=0.057, cos=0.001), tot_loss_proj:1.580 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.565 (perp=7.451, rec=0.073, cos=0.001), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] brenda met. [SEP]
========================
predicted: 
========================
[CLS] brenda met. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 84.704 | p: 83.986 | r: 85.652
rouge2     | fm: 41.573 | p: 41.101 | r: 42.276
rougeL     | fm: 71.264 | p: 70.549 | r: 72.104
rougeLsum  | fm: 71.224 | p: 70.546 | r: 72.166
r1fm+r2fm = 126.277

input #95 time: 0:07:15 | total time: 11:36:19


Running input #96 of 100.
reference: 
========================
Today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might.
========================
average of cosine similarity 0.9994474553270568
highest_index [0]
highest [0.9994474553270568]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  2651,  2045,  2003,  2210,  2030,  2053,  2880, 16011,  1997,
         11690,  2015,  1998,  5637,  2015,  2011,  1996,  2120,  2231,  1010,
          2348,  8392,  6867,  2453,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]']
[Init] best rec loss: 0.9376290440559387 for ['[CLS] typeilised exiary radha legislative spotlight latter jesse wonder passing opened church charm dropping santa authorities loan youth firm regarding 1930s border kirk [SEP]']
[Init] best rec loss: 0.930988609790802 for ['[CLS] library could quicknco quicklylerrradoum prose biology over spencer dirty? ebony room ltd laugh fiber 」 berlin twinned joe lucas [SEP]']
[Init] best rec loss: 0.9283707141876221 for ['[CLS] including viifactory spot mom avatar terms sikhcentric brandч hilton policemen hiding similarity extension press starring hold by upon were flood duc [SEP]']
[Init] best rec loss: 0.926461398601532 for ['[CLS]ed prepared aloud much directions department kendra wearing imperialism being software idea dyer bet and warner mu 30 bud prem happened operations napoleon silence [SEP]']
[Init] best rec loss: 0.9054527878761292 for ['[CLS] period roster assured disc guess proved au column three kapoor caesar regretphyator sometimes radical patel strait below recognition lori apparatus christiangration [SEP]']
[Init] best rec loss: 0.8999266624450684 for ['[CLS] radio ontogoing ammunition sleep sea invitation or abroad turkey stoneuringuidacious if lexington altar quality plus sum shower license o handy [SEP]']
[Init] best perm rec loss: 0.8994612097740173 for ['[CLS] plusacious if ouid or ammunition stone sleep invitation abroad altar radio license sea sumuring showergoing quality handy onto lexington turkey [SEP]']
[Init] best perm rec loss: 0.8985669016838074 for ['[CLS] sum lexingtonuid stone abroad plusgoing o or turkey invitationacious onto seauring sleep license shower if radio handy altar quality ammunition [SEP]']
[Init] best perm rec loss: 0.898284375667572 for ['[CLS] onto turkey or altar shower invitation abroad lexington qualityuid if stone ammunition ouring seagoingacious handy sleep plus sum license radio [SEP]']
[Init] best perm rec loss: 0.8974266052246094 for ['[CLS]going ontouringuid invitation sleep quality or sea if altar sum radio stone lexington turkey license ammunition o plus shower abroad handyacious [SEP]']
[Init] best perm rec loss: 0.8958510160446167 for ['[CLS] lexingtonuringuidacious stone sleep ammunition ifgoing license invitation radio shower sum onto abroad turkey o altar plus handy quality sea or [SEP]']
[Init] best perm rec loss: 0.8948376178741455 for ['[CLS]uring turkey onto lexington plus qualityuid if license altar sea handy stone ogoing sum or sleep radio abroad invitation shower ammunitionacious [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.371 (perp=12.380, rec=0.550, cos=0.346), tot_loss_proj:4.259 [t=0.20s]
prediction: ['[CLS]wear subsequently preserve unions thank % toward although warships simply 1990 about if, geography this pilot know ship although indoors trails these disguise [SEP]']
[ 100/2000] tot_loss=2.671 (perp=11.683, rec=0.310, cos=0.025), tot_loss_proj:4.136 [t=0.20s]
prediction: ['[CLS] proteins subsequently reputation─ legislative lesbian toward although killers otherwise 1990 about if. government the official kill central gay behaviour flags, politics [SEP]']
[ 150/2000] tot_loss=2.642 (perp=11.574, rec=0.305, cos=0.022), tot_loss_proj:4.165 [t=0.20s]
prediction: ['[CLS]quil democratic current ª government lesbian within although champions well 1990 : until invading national the official kill national lesbian! laws. facto [SEP]']
[ 200/2000] tot_loss=2.414 (perp=10.615, rec=0.259, cos=0.032), tot_loss_proj:3.943 [t=0.21s]
prediction: ['[CLS] marriages autonomous today ª government lesbian within although harassment well 1990 : until. national the official sex government lesbian ships laws. politics [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.152 (perp=9.610, rec=0.212, cos=0.019), tot_loss_proj:3.736 [t=0.18s]
prediction: ['[CLS] oriented autonomous today ª government lesbian of although harassment or 1990 ( until. national the official lesbian government of lesbian laws. politics [SEP]']
[ 300/2000] tot_loss=2.094 (perp=9.246, rec=0.228, cos=0.017), tot_loss_proj:3.640 [t=0.18s]
prediction: ['[CLS] oriented autonomous today never government lesbian of by harassment or 1990 ( if might national the official lesbian government of lesbian laws. politics [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.905 (perp=8.655, rec=0.170, cos=0.004), tot_loss_proj:3.560 [t=0.18s]
prediction: ['[CLS] oriented autonomous if never government lesbian of by harassment or national ( today might national the official lesbian government of lesbian laws. politics [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.078 (perp=9.294, rec=0.203, cos=0.016), tot_loss_proj:3.688 [t=0.18s]
prediction: ['[CLS]founded autonomous if never government lesbian of national harassment or national product today least other no official gay government. lesbian laws. facto [SEP]']
[ 450/2000] tot_loss=2.028 (perp=8.813, rec=0.237, cos=0.028), tot_loss_proj:3.624 [t=0.18s]
prediction: ['[CLS] oriented autonomous if never government lesbian of national harassment or national small today. by no official gay government. lesbian laws of facto [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.646 (perp=11.118, rec=0.356, cos=0.066), tot_loss_proj:4.094 [t=0.18s]
prediction: ['[CLS] mana fellowshipraph lesbian deny government of national harassment play 19th small today, prominent the official hanging government of lesbian dams of facto [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.282 (perp=9.641, rec=0.305, cos=0.049), tot_loss_proj:3.830 [t=0.18s]
prediction: ['[CLS] pradesh fellowshipraph lesbian never government of national harassment play 19th small today, facto the official performance government of lesbian governments of prominent [SEP]']
[ 600/2000] tot_loss=2.290 (perp=9.947, rec=0.270, cos=0.031), tot_loss_proj:3.902 [t=0.18s]
prediction: ['[CLS] pradesh fellowshipraph lesbian never government of national harassment play 19th small today, might the official performance government of lesbian governments of prominent [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.069 (perp=8.899, rec=0.261, cos=0.028), tot_loss_proj:3.652 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment play 19th small pradesh, facto the official performance government of lesbian governments of other [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.162 (perp=9.435, rec=0.253, cos=0.023), tot_loss_proj:3.741 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment play consider might small pradesh, the official performance government of gay governments of other [SEP]']
[ 750/2000] tot_loss=2.078 (perp=9.111, rec=0.237, cos=0.019), tot_loss_proj:3.738 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment play consider facto small pradesh, the official performance government of gay governments of other [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.998 (perp=8.774, rec=0.226, cos=0.017), tot_loss_proj:3.574 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment, consider facto small pradesh play the official performance government of gay governments of other [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.988 (perp=8.774, rec=0.218, cos=0.016), tot_loss_proj:3.568 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment, consider facto small pradesh play the official performance government of gay governments of other [SEP]']
[ 900/2000] tot_loss=2.002 (perp=8.859, rec=0.216, cos=0.014), tot_loss_proj:3.564 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment. consider facto small pradesh play the official performance government of gay governments of other [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.006 (perp=8.859, rec=0.221, cos=0.014), tot_loss_proj:3.561 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment. consider facto small pradesh play the official performance government of gay governments of other [SEP]']
Attempt swap
[1000/2000] tot_loss=2.004 (perp=8.859, rec=0.219, cos=0.013), tot_loss_proj:3.564 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment. consider facto small pradesh play the official performance government of gay governments of other [SEP]']
[1050/2000] tot_loss=2.080 (perp=9.311, rec=0.205, cos=0.012), tot_loss_proj:3.653 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment. depends facto small pradesh play the official performance government of gay governments of other [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.046 (perp=9.184, rec=0.197, cos=0.012), tot_loss_proj:3.622 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment. depends small facto pradesh play the official performance government of gay governments of other [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.980 (perp=8.814, rec=0.206, cos=0.011), tot_loss_proj:3.551 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment depends. small facto pradesh play the official performance government of gay governments of other [SEP]']
[1200/2000] tot_loss=1.954 (perp=8.693, rec=0.205, cos=0.011), tot_loss_proj:3.550 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment depends. small might pradesh play the official performance government of gay governments of other [SEP]']
Attempt swap
[1250/2000] tot_loss=1.949 (perp=8.693, rec=0.200, cos=0.011), tot_loss_proj:3.547 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment depends. small might pradesh play the official performance government of gay governments of other [SEP]']
Attempt swap
[1300/2000] tot_loss=1.945 (perp=8.693, rec=0.196, cos=0.010), tot_loss_proj:3.550 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment depends. small might pradesh play the official performance government of gay governments of other [SEP]']
[1350/2000] tot_loss=1.941 (perp=8.693, rec=0.193, cos=0.010), tot_loss_proj:3.547 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment depends. small might pradesh play the official performance government of gay governments of other [SEP]']
Attempt swap
[1400/2000] tot_loss=1.946 (perp=8.693, rec=0.198, cos=0.010), tot_loss_proj:3.547 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment depends. small might pradesh play the official performance government of gay governments of other [SEP]']
Attempt swap
[1450/2000] tot_loss=1.935 (perp=8.693, rec=0.187, cos=0.010), tot_loss_proj:3.550 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment depends. small might pradesh play the official performance government of gay governments of other [SEP]']
[1500/2000] tot_loss=1.947 (perp=8.693, rec=0.199, cos=0.009), tot_loss_proj:3.550 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment depends. small might pradesh play the official performance government of gay governments of other [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.915 (perp=8.570, rec=0.191, cos=0.009), tot_loss_proj:3.534 [t=0.18s]
prediction: ['[CLS] today fellowshipraph lesbian never government of national harassment depends. small pradesh might play the official performance government of gay governments of other [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.892 (perp=8.465, rec=0.190, cos=0.010), tot_loss_proj:3.512 [t=0.18s]
prediction: ['[CLS] today smallraph lesbian never government of national harassment depends. fellowship pradesh might play the official performance government of gay governments of other [SEP]']
[1650/2000] tot_loss=1.890 (perp=8.465, rec=0.188, cos=0.009), tot_loss_proj:3.510 [t=0.18s]
prediction: ['[CLS] today smallraph lesbian never government of national harassment depends. fellowship pradesh might play the official performance government of gay governments of other [SEP]']
Attempt swap
[1700/2000] tot_loss=1.890 (perp=8.465, rec=0.188, cos=0.009), tot_loss_proj:3.510 [t=0.18s]
prediction: ['[CLS] today smallraph lesbian never government of national harassment depends. fellowship pradesh might play the official performance government of gay governments of other [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.894 (perp=8.449, rec=0.193, cos=0.011), tot_loss_proj:3.572 [t=0.18s]
prediction: ['[CLS] today small fellowship lesbian never government of national harassment depends.raph pradesh might play the official hung government of gay governments of other [SEP]']
[1800/2000] tot_loss=1.892 (perp=8.449, rec=0.192, cos=0.010), tot_loss_proj:3.575 [t=0.18s]
prediction: ['[CLS] today small fellowship lesbian never government of national harassment depends.raph pradesh might play the official hung government of gay governments of other [SEP]']
Attempt swap
[1850/2000] tot_loss=1.893 (perp=8.449, rec=0.194, cos=0.010), tot_loss_proj:3.574 [t=0.18s]
prediction: ['[CLS] today small fellowship lesbian never government of national harassment depends.raph pradesh might play the official hung government of gay governments of other [SEP]']
Attempt swap
[1900/2000] tot_loss=1.897 (perp=8.449, rec=0.197, cos=0.009), tot_loss_proj:3.571 [t=0.18s]
prediction: ['[CLS] today small fellowship lesbian never government of national harassment depends.raph pradesh might play the official hung government of gay governments of other [SEP]']
[1950/2000] tot_loss=1.886 (perp=8.449, rec=0.187, cos=0.009), tot_loss_proj:3.571 [t=0.18s]
prediction: ['[CLS] today small fellowship lesbian never government of national harassment depends.raph pradesh might play the official hung government of gay governments of other [SEP]']
Attempt swap
[2000/2000] tot_loss=1.886 (perp=8.449, rec=0.187, cos=0.009), tot_loss_proj:3.569 [t=0.18s]
prediction: ['[CLS] today small fellowship lesbian never government of national harassment depends.raph pradesh might play the official hung government of gay governments of other [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]
========================
predicted: 
========================
[CLS] oriented autonomous if never government lesbian of by harassment or national ( today might national the official lesbian government of lesbian government. politics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.522 | p: 54.167 | r: 59.091
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 26.087 | p: 25.000 | r: 27.273
rougeLsum  | fm: 26.087 | p: 25.000 | r: 27.273
r1fm+r2fm = 56.522

[Aggregate metrics]:
rouge1     | fm: 84.394 | p: 83.632 | r: 85.448
rouge2     | fm: 41.246 | p: 40.785 | r: 41.903
rougeL     | fm: 70.842 | p: 70.148 | r: 71.725
rougeLsum  | fm: 70.715 | p: 70.029 | r: 71.615
r1fm+r2fm = 125.640

input #96 time: 0:07:04 | total time: 11:43:24


Running input #97 of 100.
reference: 
========================
This oven cooks well.
========================
average of cosine similarity 0.999361289301567
highest_index [0]
highest [0.999361289301567]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2023, 17428, 26929,  2092,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] this oven cooks well. [SEP]']
[Init] best rec loss: 1.0609800815582275 for ['[CLS] representing savedm ft dynasty [SEP]']
[Init] best rec loss: 1.0057979822158813 for ['[CLS] diagnosed timothy besides jump lab [SEP]']
[Init] best rec loss: 0.9389415383338928 for ['[CLS]gence charity g rain plain [SEP]']
[Init] best rec loss: 0.9305325150489807 for ['[CLS] tre river wil chamberlain donkey [SEP]']
[Init] best rec loss: 0.9199353456497192 for ['[CLS] emotional lara renewed [CLS] ve [SEP]']
[Init] best rec loss: 0.9128320813179016 for ['[CLS] alive sas mass fall why [SEP]']
[Init] best rec loss: 0.8864938020706177 for ['[CLS] led pure simulations lester junior [SEP]']
[Init] best rec loss: 0.8652690052986145 for ['[CLS] gael gearbox deserve enough air [SEP]']
[Init] best perm rec loss: 0.8601428866386414 for ['[CLS] gearbox enough deserve air gael [SEP]']
[Init] best perm rec loss: 0.8588325381278992 for ['[CLS] enough gearbox air gael deserve [SEP]']
[Init] best perm rec loss: 0.8585264682769775 for ['[CLS] enough deserve air gael gearbox [SEP]']
[Init] best perm rec loss: 0.8566455841064453 for ['[CLS] air deserve gael gearbox enough [SEP]']
[Init] best perm rec loss: 0.8556789755821228 for ['[CLS] gael air deserve gearbox enough [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.307 (perp=8.562, rec=0.620, cos=0.975), tot_loss_proj:3.436 [t=0.17s]
prediction: ['[CLS] cook. supplied favourable. [SEP]']
[ 100/2000] tot_loss=3.366 (perp=9.217, rec=0.585, cos=0.938), tot_loss_proj:3.784 [t=0.17s]
prediction: ['[CLS] oven..ivate enough [SEP]']
[ 150/2000] tot_loss=3.482 (perp=10.425, rec=0.552, cos=0.845), tot_loss_proj:4.066 [t=0.17s]
prediction: ['[CLS] oven. oven off circuit [SEP]']
[ 200/2000] tot_loss=2.423 (perp=10.034, rec=0.355, cos=0.061), tot_loss_proj:3.666 [t=0.17s]
prediction: ['[CLS] oven. oven { circuit [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.250 (perp=9.625, rec=0.294, cos=0.031), tot_loss_proj:3.937 [t=0.17s]
prediction: ['[CLS] oven oven... ( oven [SEP]']
[ 300/2000] tot_loss=2.201 (perp=9.737, rec=0.236, cos=0.017), tot_loss_proj:3.965 [t=0.17s]
prediction: ['[CLS] oven oven.... oven [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.297 (perp=9.334, rec=0.378, cos=0.052), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] oven burned because great. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.290 (perp=9.525, rec=0.345, cos=0.040), tot_loss_proj:3.751 [t=0.17s]
prediction: ['[CLS] great cooked because oven. [SEP]']
[ 450/2000] tot_loss=2.176 (perp=9.273, rec=0.293, cos=0.028), tot_loss_proj:3.697 [t=0.17s]
prediction: ['[CLS] overall cooked this oven. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.825 (perp=7.770, rec=0.248, cos=0.022), tot_loss_proj:3.535 [t=0.17s]
prediction: ['[CLS] well this cooked oven. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.783 (perp=7.770, rec=0.215, cos=0.015), tot_loss_proj:3.540 [t=0.17s]
prediction: ['[CLS] well this cooked oven. [SEP]']
[ 600/2000] tot_loss=1.757 (perp=7.770, rec=0.192, cos=0.011), tot_loss_proj:3.547 [t=0.17s]
prediction: ['[CLS] well this cooked oven. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.820 (perp=8.173, rec=0.176, cos=0.009), tot_loss_proj:3.579 [t=0.17s]
prediction: ['[CLS] well this cook oven. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.812 (perp=8.173, rec=0.170, cos=0.007), tot_loss_proj:3.586 [t=0.17s]
prediction: ['[CLS] well this cook oven. [SEP]']
[ 750/2000] tot_loss=1.803 (perp=8.173, rec=0.162, cos=0.006), tot_loss_proj:3.585 [t=0.17s]
prediction: ['[CLS] well this cook oven. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.830 (perp=8.331, rec=0.159, cos=0.005), tot_loss_proj:3.540 [t=0.17s]
prediction: ['[CLS] well this cooks oven. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.822 (perp=8.331, rec=0.151, cos=0.005), tot_loss_proj:3.539 [t=0.17s]
prediction: ['[CLS] well this cooks oven. [SEP]']
[ 900/2000] tot_loss=1.821 (perp=8.331, rec=0.151, cos=0.004), tot_loss_proj:3.532 [t=0.17s]
prediction: ['[CLS] well this cooks oven. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.802 (perp=8.331, rec=0.132, cos=0.004), tot_loss_proj:3.534 [t=0.17s]
prediction: ['[CLS] well this cooks oven. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.804 (perp=8.331, rec=0.134, cos=0.004), tot_loss_proj:3.536 [t=0.17s]
prediction: ['[CLS] well this cooks oven. [SEP]']
[1050/2000] tot_loss=1.808 (perp=8.331, rec=0.138, cos=0.004), tot_loss_proj:3.544 [t=0.17s]
prediction: ['[CLS] well this cooks oven. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.796 (perp=8.331, rec=0.126, cos=0.003), tot_loss_proj:3.537 [t=0.17s]
prediction: ['[CLS] well this cooks oven. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.772 (perp=8.130, rec=0.141, cos=0.005), tot_loss_proj:3.550 [t=0.17s]
prediction: ['[CLS] this cooks oven well. [SEP]']
[1200/2000] tot_loss=1.758 (perp=8.130, rec=0.128, cos=0.004), tot_loss_proj:3.557 [t=0.17s]
prediction: ['[CLS] this cooks oven well. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.611 (perp=7.419, rec=0.123, cos=0.004), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.606 (perp=7.419, rec=0.119, cos=0.003), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1350/2000] tot_loss=1.602 (perp=7.419, rec=0.115, cos=0.003), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.604 (perp=7.419, rec=0.117, cos=0.003), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.597 (perp=7.419, rec=0.110, cos=0.003), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1500/2000] tot_loss=1.595 (perp=7.419, rec=0.108, cos=0.003), tot_loss_proj:1.594 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.603 (perp=7.419, rec=0.116, cos=0.003), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.602 (perp=7.419, rec=0.116, cos=0.003), tot_loss_proj:1.580 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1650/2000] tot_loss=1.585 (perp=7.419, rec=0.098, cos=0.003), tot_loss_proj:1.581 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.593 (perp=7.419, rec=0.106, cos=0.003), tot_loss_proj:1.591 [t=0.18s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.593 (perp=7.419, rec=0.106, cos=0.003), tot_loss_proj:1.594 [t=0.18s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1800/2000] tot_loss=1.592 (perp=7.419, rec=0.106, cos=0.003), tot_loss_proj:1.593 [t=0.18s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.584 (perp=7.419, rec=0.098, cos=0.003), tot_loss_proj:1.581 [t=0.18s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.595 (perp=7.419, rec=0.108, cos=0.003), tot_loss_proj:1.592 [t=0.18s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.419, rec=0.101, cos=0.003), tot_loss_proj:1.586 [t=0.18s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.590 (perp=7.419, rec=0.104, cos=0.002), tot_loss_proj:1.589 [t=0.18s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] this oven cooks well. [SEP]
========================
predicted: 
========================
[CLS] this oven cooks well. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 84.500 | p: 83.800 | r: 85.522
rouge2     | fm: 41.820 | p: 41.339 | r: 42.435
rougeL     | fm: 71.092 | p: 70.452 | r: 71.970
rougeLsum  | fm: 71.123 | p: 70.448 | r: 72.024
r1fm+r2fm = 126.320

input #97 time: 0:06:55 | total time: 11:50:19


Running input #98 of 100.
reference: 
========================
Sarah devoured the cakes in the kitchen last night.
========================
average of cosine similarity 0.9993452529147651
highest_index [0]
highest [0.9993452529147651]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  4532, 16475, 16777,  1996, 22619,  1999,  1996,  3829,  2197,
          2305,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sarah devoured the cakes in the kitchen last night. [SEP]']
[Init] best rec loss: 0.9987524151802063 for ['[CLS] socialced coordination umbrella louder require paper plank parallel hi dame [SEP]']
[Init] best rec loss: 0.9721340537071228 for ['[CLS]mission instruments overnton _ revenge touch cole palettescent die [SEP]']
[Init] best rec loss: 0.9537109732627869 for ['[CLS] agreed cold indexed clip troops crazy basic methodology low mai burns [SEP]']
[Init] best rec loss: 0.9328851103782654 for ['[CLS] excited hadley coverage theatreere schoolhouse then scored point carpenter nature [SEP]']
[Init] best perm rec loss: 0.932117760181427 for ['[CLS] point schoolhouse theatre scored hadleyere nature excited carpenter then coverage [SEP]']
[Init] best perm rec loss: 0.9296472668647766 for ['[CLS] schoolhouse excited carpenterere hadley theatre coverage nature scored point then [SEP]']
[Init] best perm rec loss: 0.9284753203392029 for ['[CLS]ere excited nature carpenter scored theatre then hadley schoolhouse point coverage [SEP]']
[Init] best perm rec loss: 0.9283377528190613 for ['[CLS] carpenter hadley theatre coverage then excited scored natureere point schoolhouse [SEP]']
[Init] best perm rec loss: 0.9256162047386169 for ['[CLS] nature coverageere excited theatre schoolhouse then hadley scored point carpenter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.459 (perp=14.761, rec=0.447, cos=0.059), tot_loss_proj:4.713 [t=0.17s]
prediction: ['[CLS] speciesße bandwidth caution village built originally sarah teacher highest era [SEP]']
[ 100/2000] tot_loss=2.758 (perp=12.265, rec=0.289, cos=0.017), tot_loss_proj:4.404 [t=0.17s]
prediction: ['[CLS] cooking siege bandwidth afternoon night in originally sarah sarah garden peasant [SEP]']
[ 150/2000] tot_loss=2.383 (perp=10.981, rec=0.179, cos=0.008), tot_loss_proj:4.058 [t=0.17s]
prediction: ['[CLS]oured divinity cakes last kitchen in kitchens sarah sarah in bourgeois [SEP]']
[ 200/2000] tot_loss=2.390 (perp=11.218, rec=0.140, cos=0.006), tot_loss_proj:4.162 [t=0.17s]
prediction: ['[CLS]oured lilith cakes last kitchen the kitchens sarah sarah in precious [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.604 (perp=11.490, rec=0.274, cos=0.032), tot_loss_proj:4.334 [t=0.17s]
prediction: ['[CLS]oured pot cakes sarah kitchen terms evening sarah last in predator [SEP]']
[ 300/2000] tot_loss=2.391 (perp=11.063, rec=0.169, cos=0.010), tot_loss_proj:4.131 [t=0.17s]
prediction: ['[CLS]oured pot cakes sarah kitchen terms night sarah last in food [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.071 (perp=9.535, rec=0.156, cos=0.008), tot_loss_proj:3.934 [t=0.17s]
prediction: ['[CLS]oured among cakes sarah kitchen terms sarah last night in food [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.902 (perp=8.780, rec=0.138, cos=0.008), tot_loss_proj:3.866 [t=0.17s]
prediction: ['[CLS]oured food cakes sarah kitchen terms sarah last night in the [SEP]']
[ 450/2000] tot_loss=1.885 (perp=8.780, rec=0.122, cos=0.007), tot_loss_proj:3.868 [t=0.17s]
prediction: ['[CLS]oured food cakes sarah kitchen terms sarah last night in the [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.977 (perp=9.335, rec=0.103, cos=0.007), tot_loss_proj:3.911 [t=0.19s]
prediction: ['[CLS]oured honey sarah cakes kitchen terms sarah last night in the [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.883 (perp=8.686, rec=0.138, cos=0.007), tot_loss_proj:3.653 [t=0.18s]
prediction: ['[CLS]oured honey sarah cakes the terms sarah last night in kitchen [SEP]']
[ 600/2000] tot_loss=1.872 (perp=8.686, rec=0.129, cos=0.006), tot_loss_proj:3.651 [t=0.17s]
prediction: ['[CLS]oured honey sarah cakes the terms sarah last night in kitchen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.855 (perp=8.686, rec=0.112, cos=0.006), tot_loss_proj:3.653 [t=0.17s]
prediction: ['[CLS]oured honey sarah cakes the terms sarah last night in kitchen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.861 (perp=8.686, rec=0.118, cos=0.006), tot_loss_proj:3.652 [t=0.17s]
prediction: ['[CLS]oured honey sarah cakes the terms sarah last night in kitchen [SEP]']
[ 750/2000] tot_loss=2.179 (perp=10.365, rec=0.100, cos=0.006), tot_loss_proj:4.048 [t=0.17s]
prediction: ['[CLS]oured apples sarah cakes dev terms sarah last night in kitchen [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.901 (perp=8.922, rec=0.111, cos=0.006), tot_loss_proj:3.616 [t=0.17s]
prediction: ['[CLS] termsgenic sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.831 (perp=8.494, rec=0.126, cos=0.006), tot_loss_proj:3.561 [t=0.17s]
prediction: ['[CLS] terms in sarah cakes devoured sarah last nighty kitchen [SEP]']
[ 900/2000] tot_loss=1.819 (perp=8.494, rec=0.114, cos=0.006), tot_loss_proj:3.558 [t=0.17s]
prediction: ['[CLS] terms in sarah cakes devoured sarah last nighty kitchen [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.754 (perp=8.198, rec=0.109, cos=0.006), tot_loss_proj:3.517 [t=0.17s]
prediction: ['[CLS] termsy sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.762 (perp=8.198, rec=0.117, cos=0.006), tot_loss_proj:3.524 [t=0.17s]
prediction: ['[CLS] termsy sarah cakes devoured sarah last night in kitchen [SEP]']
[1050/2000] tot_loss=1.743 (perp=8.198, rec=0.098, cos=0.006), tot_loss_proj:3.520 [t=0.17s]
prediction: ['[CLS] termsy sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.750 (perp=8.198, rec=0.105, cos=0.005), tot_loss_proj:3.519 [t=0.17s]
prediction: ['[CLS] termsy sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.766 (perp=8.261, rec=0.109, cos=0.005), tot_loss_proj:3.434 [t=0.17s]
prediction: ['[CLS] terms young sarah cakes devoured sarah last night in kitchen [SEP]']
[1200/2000] tot_loss=1.754 (perp=8.261, rec=0.096, cos=0.005), tot_loss_proj:3.429 [t=0.17s]
prediction: ['[CLS] terms young sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.896 (perp=8.956, rec=0.099, cos=0.005), tot_loss_proj:3.667 [t=0.17s]
prediction: ['[CLS] termsiom sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.901 (perp=8.956, rec=0.105, cos=0.005), tot_loss_proj:3.671 [t=0.17s]
prediction: ['[CLS] termsiom sarah cakes devoured sarah last night in kitchen [SEP]']
[1350/2000] tot_loss=1.896 (perp=8.956, rec=0.099, cos=0.005), tot_loss_proj:3.669 [t=0.17s]
prediction: ['[CLS] termsiom sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.901 (perp=8.956, rec=0.104, cos=0.005), tot_loss_proj:3.673 [t=0.17s]
prediction: ['[CLS] termsiom sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.898 (perp=8.956, rec=0.101, cos=0.005), tot_loss_proj:3.668 [t=0.17s]
prediction: ['[CLS] termsiom sarah cakes devoured sarah last night in kitchen [SEP]']
[1500/2000] tot_loss=1.889 (perp=8.956, rec=0.093, cos=0.005), tot_loss_proj:3.672 [t=0.17s]
prediction: ['[CLS] termsiom sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.866 (perp=8.891, rec=0.082, cos=0.005), tot_loss_proj:3.630 [t=0.17s]
prediction: ['[CLS] sarahy terms cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.747 (perp=8.198, rec=0.102, cos=0.005), tot_loss_proj:3.520 [t=0.17s]
prediction: ['[CLS] termsy sarah cakes devoured sarah last night in kitchen [SEP]']
[1650/2000] tot_loss=1.746 (perp=8.198, rec=0.101, cos=0.005), tot_loss_proj:3.517 [t=0.17s]
prediction: ['[CLS] termsy sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.739 (perp=8.198, rec=0.095, cos=0.005), tot_loss_proj:3.517 [t=0.17s]
prediction: ['[CLS] termsy sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.739 (perp=8.198, rec=0.094, cos=0.005), tot_loss_proj:3.516 [t=0.17s]
prediction: ['[CLS] termsy sarah cakes devoured sarah last night in kitchen [SEP]']
[1800/2000] tot_loss=1.729 (perp=8.198, rec=0.084, cos=0.005), tot_loss_proj:3.518 [t=0.17s]
prediction: ['[CLS] termsy sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.701 (perp=8.013, rec=0.094, cos=0.005), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS] terms the sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.606 (perp=7.479, rec=0.105, cos=0.005), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] the terms sarah cakes devoured sarah last night in kitchen [SEP]']
[1950/2000] tot_loss=1.607 (perp=7.479, rec=0.106, cos=0.005), tot_loss_proj:3.374 [t=0.17s]
prediction: ['[CLS] the terms sarah cakes devoured sarah last night in kitchen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.599 (perp=7.479, rec=0.098, cos=0.005), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] the terms sarah cakes devoured sarah last night in kitchen [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] sarah devoured the cakes in the kitchen last night. [SEP]
========================
predicted: 
========================
[CLS] the terms sarah cakes devoured sarah last night in kitchen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 9.524 | p: 9.091 | r: 10.000
rougeL     | fm: 52.174 | p: 50.000 | r: 54.545
rougeLsum  | fm: 52.174 | p: 50.000 | r: 54.545
r1fm+r2fm = 96.480

[Aggregate metrics]:
rouge1     | fm: 84.500 | p: 83.766 | r: 85.561
rouge2     | fm: 41.395 | p: 40.926 | r: 42.055
rougeL     | fm: 70.960 | p: 70.302 | r: 71.891
rougeLsum  | fm: 70.893 | p: 70.185 | r: 71.876
r1fm+r2fm = 125.895

input #98 time: 0:06:57 | total time: 11:57:17


Running input #99 of 100.
reference: 
========================
The box contains the ball.
========================
average of cosine similarity 0.999440902871247
highest_index [0]
highest [0.999440902871247]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 1996, 3482, 3397, 1996, 3608, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the box contains the ball. [SEP]']
[Init] best rec loss: 0.9730719327926636 for ['[CLS] point bono dry position nothing using [SEP]']
[Init] best rec loss: 0.9256172180175781 for ['[CLS] tense childhood port oman mo earl [SEP]']
[Init] best rec loss: 0.9026228785514832 for ['[CLS] storage theatergraphic scholarships africa minorities [SEP]']
[Init] best rec loss: 0.9006547927856445 for ['[CLS] quoien hang town purse savings [SEP]']
[Init] best rec loss: 0.897529661655426 for ['[CLS] especiallylink but merchantywood rapid [SEP]']
[Init] best rec loss: 0.8682069182395935 for ['[CLS] [MASK] tennis reacherェ one note [SEP]']
[Init] best rec loss: 0.8641061186790466 for ['[CLS] returned raphael2 dragon sato deco [SEP]']
[Init] best perm rec loss: 0.8624070286750793 for ['[CLS]2 returned deco sato raphael dragon [SEP]']
[Init] best perm rec loss: 0.8620513677597046 for ['[CLS] deco sato raphael returned2 dragon [SEP]']
[Init] best perm rec loss: 0.8598130345344543 for ['[CLS] returned sato2 deco raphael dragon [SEP]']
[Init] best perm rec loss: 0.8590118885040283 for ['[CLS] sato deco2 returned dragon raphael [SEP]']
[Init] best perm rec loss: 0.8577542901039124 for ['[CLS]2 sato deco returned dragon raphael [SEP]']
[Init] best perm rec loss: 0.8570127487182617 for ['[CLS]2 deco returned dragon raphael sato [SEP]']
[Init] best perm rec loss: 0.8554680347442627 for ['[CLS]2 sato deco dragon returned raphael [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.676 (perp=11.331, rec=0.359, cos=0.051), tot_loss_proj:4.184 [t=0.17s]
prediction: ['[CLS]zia bag ball. glove - [SEP]']
[ 100/2000] tot_loss=2.420 (perp=10.585, rec=0.260, cos=0.043), tot_loss_proj:4.182 [t=0.17s]
prediction: ['[CLS]rangle the ball. contains box [SEP]']
[ 150/2000] tot_loss=2.339 (perp=10.585, rec=0.204, cos=0.018), tot_loss_proj:4.189 [t=0.17s]
prediction: ['[CLS]rangle the ball. contains box [SEP]']
[ 200/2000] tot_loss=2.297 (perp=10.585, rec=0.162, cos=0.018), tot_loss_proj:4.180 [t=0.17s]
prediction: ['[CLS]rangle the ball. contains box [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.761 (perp=7.909, rec=0.165, cos=0.014), tot_loss_proj:3.620 [t=0.17s]
prediction: ['[CLS] the spherical ball. contains box [SEP]']
[ 300/2000] tot_loss=1.734 (perp=7.909, rec=0.139, cos=0.013), tot_loss_proj:3.626 [t=0.17s]
prediction: ['[CLS] the spherical ball. contains box [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.506 (perp=6.831, rec=0.130, cos=0.011), tot_loss_proj:3.261 [t=0.17s]
prediction: ['[CLS] the spherical ball box contains. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.452 (perp=6.620, rec=0.119, cos=0.009), tot_loss_proj:3.301 [t=0.17s]
prediction: ['[CLS] the spherical ball contains box. [SEP]']
[ 450/2000] tot_loss=1.433 (perp=6.620, rec=0.102, cos=0.007), tot_loss_proj:3.328 [t=0.17s]
prediction: ['[CLS] the spherical ball contains box. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.725 (perp=7.861, rec=0.133, cos=0.020), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS] the spherical ball contains box? [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.576 (perp=7.295, rec=0.108, cos=0.010), tot_loss_proj:3.484 [t=0.17s]
prediction: ['[CLS] the spherical ball box contains? [SEP]']
[ 600/2000] tot_loss=1.579 (perp=7.295, rec=0.112, cos=0.009), tot_loss_proj:3.484 [t=0.17s]
prediction: ['[CLS] the spherical ball box contains? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.566 (perp=7.295, rec=0.099, cos=0.009), tot_loss_proj:3.485 [t=0.17s]
prediction: ['[CLS] the spherical ball box contains? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.577 (perp=7.295, rec=0.110, cos=0.008), tot_loss_proj:3.487 [t=0.17s]
prediction: ['[CLS] the spherical ball box contains? [SEP]']
[ 750/2000] tot_loss=1.573 (perp=7.295, rec=0.106, cos=0.008), tot_loss_proj:3.482 [t=0.17s]
prediction: ['[CLS] the spherical ball box contains? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.554 (perp=7.295, rec=0.087, cos=0.008), tot_loss_proj:3.481 [t=0.17s]
prediction: ['[CLS] the spherical ball box contains? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.569 (perp=7.295, rec=0.102, cos=0.008), tot_loss_proj:3.487 [t=0.17s]
prediction: ['[CLS] the spherical ball box contains? [SEP]']
[ 900/2000] tot_loss=1.570 (perp=7.295, rec=0.104, cos=0.008), tot_loss_proj:3.482 [t=0.17s]
prediction: ['[CLS] the spherical ball box contains? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.563 (perp=7.295, rec=0.096, cos=0.008), tot_loss_proj:3.485 [t=0.17s]
prediction: ['[CLS] the spherical ball box contains? [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.703 (perp=7.804, rec=0.127, cos=0.015), tot_loss_proj:3.597 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
[1050/2000] tot_loss=1.672 (perp=7.804, rec=0.102, cos=0.010), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.681 (perp=7.804, rec=0.112, cos=0.009), tot_loss_proj:3.596 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.675 (perp=7.804, rec=0.106, cos=0.009), tot_loss_proj:3.596 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
[1200/2000] tot_loss=1.669 (perp=7.804, rec=0.100, cos=0.008), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.668 (perp=7.804, rec=0.099, cos=0.008), tot_loss_proj:3.597 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.664 (perp=7.804, rec=0.095, cos=0.008), tot_loss_proj:3.592 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
[1350/2000] tot_loss=1.662 (perp=7.804, rec=0.094, cos=0.008), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.670 (perp=7.804, rec=0.101, cos=0.008), tot_loss_proj:3.599 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.676 (perp=7.804, rec=0.107, cos=0.008), tot_loss_proj:3.597 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
[1500/2000] tot_loss=1.675 (perp=7.804, rec=0.107, cos=0.008), tot_loss_proj:3.593 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.662 (perp=7.804, rec=0.094, cos=0.007), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.663 (perp=7.804, rec=0.095, cos=0.007), tot_loss_proj:3.588 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
[1650/2000] tot_loss=1.662 (perp=7.804, rec=0.094, cos=0.007), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.664 (perp=7.804, rec=0.095, cos=0.007), tot_loss_proj:3.593 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.661 (perp=7.804, rec=0.093, cos=0.007), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
[1800/2000] tot_loss=1.657 (perp=7.804, rec=0.089, cos=0.007), tot_loss_proj:3.595 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.660 (perp=7.804, rec=0.092, cos=0.007), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.662 (perp=7.804, rec=0.094, cos=0.007), tot_loss_proj:3.593 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
[1950/2000] tot_loss=1.662 (perp=7.804, rec=0.094, cos=0.007), tot_loss_proj:3.591 [t=0.18s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.671 (perp=7.804, rec=0.103, cos=0.007), tot_loss_proj:3.592 [t=0.17s]
prediction: ['[CLS] the claus box ball contains? [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] the box contains the ball. [SEP]
========================
predicted: 
========================
[CLS] the claus box ball contains? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 84.603 | p: 83.827 | r: 85.630
rouge2     | fm: 41.125 | p: 40.667 | r: 41.793
rougeL     | fm: 70.939 | p: 70.225 | r: 71.923
rougeLsum  | fm: 70.896 | p: 70.219 | r: 71.793
r1fm+r2fm = 125.728

input #99 time: 0:06:57 | total time: 12:04:15


Average Cosine Similarity: 0.9993532828782739
Done with all.
