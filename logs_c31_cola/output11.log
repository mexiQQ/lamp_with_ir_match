


Command: attack4.py --dataset cola --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola --n_steps 2000 --coeff_pooler_match 0.0 --coeff_pooler_match_margin 0.0 --pooler_match_for_init yes --pooler_match_for_optimization no --pooler_match_for_swap yes 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 1450.98it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-cola and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
Harriet alternated folk songs and pop songs together.
========================
average of cosine similarity 0.9993562480586127
highest_index [0]
highest [0.9993562480586127]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 14207,  6585,  2094,  5154,  2774,  1998,  3769,  2774,  2362,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] harriet alternated folk songs and pop songs together. [SEP]']
[Init] best rec loss: 1.8804733753204346 for ['[CLS] study showing exchange victorywall same bryant compulsory cl regiments [SEP]']
[Init] best rec loss: 1.8185855150222778 for ['[CLS] report make baglary fell paul max rape younger broken [SEP]']
[Init] best rec loss: 1.7533365488052368 for ['[CLS]ege about sovereign allan path associate emancipation newton statercle [SEP]']
[Init] best rec loss: 1.7515984773635864 for ['[CLS] lo hr positionperation trees temperance madonnaguard minutes vs [SEP]']
[Init] best rec loss: 1.693070650100708 for ['[CLS] ) monitor witch market issue healing stole dia indoor lane [SEP]']
[Init] best perm rec loss: 1.6930311918258667 for ['[CLS] indoor monitor market ) issue lane stole witch dia healing [SEP]']
[Init] best perm rec loss: 1.691406488418579 for ['[CLS] lane indoor market ) dia healing stole monitor issue witch [SEP]']
[Init] best perm rec loss: 1.6903244256973267 for ['[CLS] indoor stole market ) issue lane witch dia healing monitor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.974 (perp=11.424, rec=0.458, cos=0.232), tot_loss_proj:4.243 [t=0.22s]
prediction: ['[CLS] forged being thing album season ritual urban hers spouse songs [SEP]']
[ 100/2000] tot_loss=2.307 (perp=9.766, rec=0.306, cos=0.049), tot_loss_proj:3.898 [t=0.19s]
prediction: ['[CLS] alternateed harriet songs songs alternate songs respectively harriet songs [SEP]']
[ 150/2000] tot_loss=2.224 (perp=9.274, rec=0.303, cos=0.067), tot_loss_proj:3.701 [t=0.23s]
prediction: ['[CLS] alternateed harriet songs songs alternate songs together harriet songs [SEP]']
[ 200/2000] tot_loss=2.116 (perp=8.908, rec=0.268, cos=0.066), tot_loss_proj:3.734 [t=0.23s]
prediction: ['[CLS] alternated harriet and songs alternate songs together harriet songs [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.965 (perp=8.984, rec=0.155, cos=0.013), tot_loss_proj:3.745 [t=0.18s]
prediction: ['[CLS] alternated harriet songs and alternate songs together harriet pop [SEP]']
[ 300/2000] tot_loss=1.939 (perp=8.984, rec=0.132, cos=0.009), tot_loss_proj:3.749 [t=0.23s]
prediction: ['[CLS] alternated harriet songs and alternate songs together harriet pop [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.733 (perp=7.984, rec=0.125, cos=0.011), tot_loss_proj:3.418 [t=0.20s]
prediction: ['[CLS] alternated harriet songs and harriet songs together alternate pop [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.960 (perp=9.151, rec=0.119, cos=0.011), tot_loss_proj:3.726 [t=0.19s]
prediction: ['[CLS] alternated harriet songs and harriet folk together alternate pop [SEP]']
[ 450/2000] tot_loss=2.072 (perp=9.743, rec=0.113, cos=0.010), tot_loss_proj:3.833 [t=0.18s]
prediction: ['[CLS] alternated harriet songs and harriet folk togethered pop [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.952 (perp=9.196, rec=0.104, cos=0.009), tot_loss_proj:3.737 [t=0.21s]
prediction: ['[CLS] alternated harriet songs and harriet folk pop togethered [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.854 (perp=8.633, rec=0.116, cos=0.011), tot_loss_proj:3.645 [t=0.20s]
prediction: ['[CLS] alternated songs harriet and harriet folk pop togethered [SEP]']
[ 600/2000] tot_loss=1.843 (perp=8.690, rec=0.099, cos=0.006), tot_loss_proj:3.667 [t=0.18s]
prediction: ['[CLS] alternated songs harriet and harriet folk pop togetherd [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.702 (perp=7.955, rec=0.101, cos=0.010), tot_loss_proj:3.513 [t=0.19s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.696 (perp=7.955, rec=0.098, cos=0.007), tot_loss_proj:3.511 [t=0.20s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
[ 750/2000] tot_loss=1.688 (perp=7.955, rec=0.091, cos=0.006), tot_loss_proj:3.505 [t=0.18s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.679 (perp=7.955, rec=0.082, cos=0.006), tot_loss_proj:3.510 [t=0.27s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.689 (perp=7.955, rec=0.090, cos=0.007), tot_loss_proj:3.509 [t=0.18s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
[ 900/2000] tot_loss=1.686 (perp=7.955, rec=0.086, cos=0.009), tot_loss_proj:3.510 [t=0.18s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.686 (perp=7.955, rec=0.089, cos=0.006), tot_loss_proj:3.509 [t=0.20s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1000/2000] tot_loss=1.677 (perp=7.955, rec=0.080, cos=0.006), tot_loss_proj:3.511 [t=0.26s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
[1050/2000] tot_loss=1.681 (perp=7.955, rec=0.084, cos=0.006), tot_loss_proj:3.508 [t=0.26s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1100/2000] tot_loss=1.684 (perp=7.955, rec=0.088, cos=0.005), tot_loss_proj:3.505 [t=0.23s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1150/2000] tot_loss=1.684 (perp=7.955, rec=0.088, cos=0.005), tot_loss_proj:3.512 [t=0.25s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
[1200/2000] tot_loss=1.681 (perp=7.955, rec=0.085, cos=0.005), tot_loss_proj:3.509 [t=0.27s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1250/2000] tot_loss=1.682 (perp=7.955, rec=0.086, cos=0.005), tot_loss_proj:3.508 [t=0.19s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1300/2000] tot_loss=1.672 (perp=7.955, rec=0.076, cos=0.005), tot_loss_proj:3.513 [t=0.18s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
[1350/2000] tot_loss=1.684 (perp=7.955, rec=0.088, cos=0.005), tot_loss_proj:3.508 [t=0.21s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1400/2000] tot_loss=1.686 (perp=7.955, rec=0.090, cos=0.005), tot_loss_proj:3.508 [t=0.18s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1450/2000] tot_loss=1.677 (perp=7.955, rec=0.081, cos=0.005), tot_loss_proj:3.510 [t=0.21s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
[1500/2000] tot_loss=1.679 (perp=7.955, rec=0.083, cos=0.005), tot_loss_proj:3.510 [t=0.24s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1550/2000] tot_loss=1.668 (perp=7.955, rec=0.072, cos=0.005), tot_loss_proj:3.511 [t=0.18s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1600/2000] tot_loss=1.687 (perp=7.955, rec=0.091, cos=0.005), tot_loss_proj:3.504 [t=0.20s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
[1650/2000] tot_loss=1.675 (perp=7.955, rec=0.079, cos=0.005), tot_loss_proj:3.509 [t=0.23s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1700/2000] tot_loss=1.673 (perp=7.955, rec=0.077, cos=0.005), tot_loss_proj:3.509 [t=0.19s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1750/2000] tot_loss=1.674 (perp=7.955, rec=0.078, cos=0.005), tot_loss_proj:3.511 [t=0.23s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
[1800/2000] tot_loss=1.675 (perp=7.955, rec=0.080, cos=0.005), tot_loss_proj:3.513 [t=0.19s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1850/2000] tot_loss=1.684 (perp=7.955, rec=0.089, cos=0.005), tot_loss_proj:3.514 [t=0.19s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[1900/2000] tot_loss=1.678 (perp=7.955, rec=0.083, cos=0.005), tot_loss_proj:3.509 [t=0.18s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
[1950/2000] tot_loss=1.675 (perp=7.955, rec=0.079, cos=0.005), tot_loss_proj:3.512 [t=0.22s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Attempt swap
[2000/2000] tot_loss=1.674 (perp=7.955, rec=0.078, cos=0.005), tot_loss_proj:3.511 [t=0.19s]
prediction: ['[CLS] alternated songs harriet and harriet folk popd together [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] harriet alternated folk songs and pop songs together. [SEP]
========================
predicted: 
========================
[CLS] alternated songs harriet and harriet folk popd together [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 91.111

[Aggregate metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 91.111

input #0 time: 0:08:31 | total time: 0:08:31


Running input #1 of 100.
reference: 
========================
Who do you think that will question Seamus first?
========================
average of cosine similarity 0.9991835207453212
highest_index [0]
highest [0.9991835207453212]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2040,  2079,  2017,  2228,  2008,  2097,  3160, 24993,  2034,
          1029,   102]], device='cuda:0')
Debug: ref = ['[CLS] who do you think that will question seamus first? [SEP]']
[Init] best rec loss: 1.3800342082977295 for ['[CLS] singerии middlesbrough tells certificate numbering century sung nowhere go [SEP]']
[Init] best rec loss: 1.2355537414550781 for ['[CLS] can kerr dry jack hood shownnsed powered feet [CLS] [SEP]']
[Init] best rec loss: 1.0515960454940796 for ['[CLS] because richest soc final melbourne gallo building mob might storm [SEP]']
[Init] best rec loss: 1.0193814039230347 for ['[CLS]less millennium billboard ron trial marino empire clerk kai brand [SEP]']
[Init] best rec loss: 1.0176372528076172 for ['[CLS] whitney paid space besides itself freedomud white waist there [SEP]']
[Init] best rec loss: 0.969215452671051 for ['[CLS] ever those for markings cannabisigen roger thinking striker best [SEP]']
[Init] best rec loss: 0.9534900188446045 for ['[CLS]lance spiders roman above selectcarriageoured towardsiness page [SEP]']
[Init] best perm rec loss: 0.942471981048584 for ['[CLS] above towards romancarriageoured spidersinesslance page select [SEP]']
[Init] best perm rec loss: 0.9419404864311218 for ['[CLS] above towardsoured page spidersiness selectlance romancarriage [SEP]']
[Init] best perm rec loss: 0.9418970346450806 for ['[CLS]ourediness romancarriage page spiders above selectlance towards [SEP]']
[Init] best perm rec loss: 0.9394780397415161 for ['[CLS] towardscarriagelanceinessoured roman spiders above select page [SEP]']
[Init] best perm rec loss: 0.9393749237060547 for ['[CLS]iness roman abovecarriage towards pageoured spiders selectlance [SEP]']
[Init] best perm rec loss: 0.9391114711761475 for ['[CLS] towardsiness page selectoured spiders abovelance romancarriage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.069 (perp=13.039, rec=0.402, cos=0.059), tot_loss_proj:3.757 [t=0.18s]
prediction: ['[CLS] tells brandy havegum last completely therefore in turing anal [SEP]']
[ 100/2000] tot_loss=2.412 (perp=10.333, rec=0.316, cos=0.029), tot_loss_proj:3.579 [t=0.22s]
prediction: ['[CLS] think brandy do you last completely east have seamus that [SEP]']
[ 150/2000] tot_loss=2.409 (perp=10.657, rec=0.245, cos=0.033), tot_loss_proj:3.324 [t=0.24s]
prediction: ['[CLS] think seamus who you seamus could east would seamus that [SEP]']
[ 200/2000] tot_loss=2.227 (perp=10.179, rec=0.173, cos=0.019), tot_loss_proj:3.029 [t=0.19s]
prediction: ['[CLS] think seamus who you seamus will east have seamus that [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.308 (perp=10.407, rec=0.201, cos=0.025), tot_loss_proj:2.904 [t=0.24s]
prediction: ['[CLS] you think seamus who phd willsh question seamus that [SEP]']
[ 300/2000] tot_loss=2.168 (perp=10.105, rec=0.131, cos=0.015), tot_loss_proj:2.819 [t=0.18s]
prediction: ['[CLS] you think seamus who fifth willsh question seamus that [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.049 (perp=9.554, rec=0.126, cos=0.013), tot_loss_proj:2.601 [t=0.23s]
prediction: ['[CLS] you think seamus who will fifthsh question seamus that [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.017 (perp=9.513, rec=0.104, cos=0.010), tot_loss_proj:2.710 [t=0.19s]
prediction: ['[CLS] do who think seamus will fifthsh question? that [SEP]']
[ 450/2000] tot_loss=2.019 (perp=9.513, rec=0.110, cos=0.007), tot_loss_proj:2.709 [t=0.18s]
prediction: ['[CLS] do who think seamus will fifthsh question? that [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.904 (perp=9.013, rec=0.095, cos=0.006), tot_loss_proj:3.295 [t=0.19s]
prediction: ['[CLS] do who think seamus will fifthsh question that? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.900 (perp=9.013, rec=0.091, cos=0.006), tot_loss_proj:3.299 [t=0.18s]
prediction: ['[CLS] do who think seamus will fifthsh question that? [SEP]']
[ 600/2000] tot_loss=1.899 (perp=9.013, rec=0.091, cos=0.006), tot_loss_proj:3.292 [t=0.18s]
prediction: ['[CLS] do who think seamus will fifthsh question that? [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.684 (perp=7.947, rec=0.089, cos=0.005), tot_loss_proj:3.247 [t=0.23s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.679 (perp=7.947, rec=0.085, cos=0.005), tot_loss_proj:3.251 [t=0.19s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
[ 750/2000] tot_loss=1.686 (perp=7.947, rec=0.091, cos=0.005), tot_loss_proj:3.248 [t=0.19s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.684 (perp=7.947, rec=0.089, cos=0.005), tot_loss_proj:3.249 [t=0.21s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.675 (perp=7.947, rec=0.080, cos=0.005), tot_loss_proj:3.243 [t=0.19s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
[ 900/2000] tot_loss=1.673 (perp=7.947, rec=0.078, cos=0.005), tot_loss_proj:3.242 [t=0.23s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.682 (perp=7.947, rec=0.087, cos=0.005), tot_loss_proj:3.244 [t=0.19s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.800 (perp=8.542, rec=0.086, cos=0.005), tot_loss_proj:2.752 [t=0.24s]
prediction: ['[CLS] do who think seamus will east that question fifth? [SEP]']
[1050/2000] tot_loss=1.798 (perp=8.542, rec=0.084, cos=0.005), tot_loss_proj:2.762 [t=0.18s]
prediction: ['[CLS] do who think seamus will east that question fifth? [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.684 (perp=7.947, rec=0.089, cos=0.005), tot_loss_proj:3.246 [t=0.24s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.679 (perp=7.947, rec=0.084, cos=0.005), tot_loss_proj:3.244 [t=0.23s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
[1200/2000] tot_loss=1.670 (perp=7.947, rec=0.075, cos=0.005), tot_loss_proj:3.241 [t=0.19s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.671 (perp=7.947, rec=0.077, cos=0.005), tot_loss_proj:3.243 [t=0.19s]
prediction: ['[CLS] do who think seamus will fifth that question east? [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.724 (perp=8.181, rec=0.082, cos=0.005), tot_loss_proj:2.406 [t=0.19s]
prediction: ['[CLS] do who think seamus will you that question fifth? [SEP]']
[1350/2000] tot_loss=1.534 (perp=7.236, rec=0.082, cos=0.005), tot_loss_proj:2.909 [t=0.18s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.543 (perp=7.236, rec=0.090, cos=0.005), tot_loss_proj:2.914 [t=0.19s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.537 (perp=7.236, rec=0.085, cos=0.005), tot_loss_proj:2.907 [t=0.19s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
[1500/2000] tot_loss=1.537 (perp=7.236, rec=0.085, cos=0.005), tot_loss_proj:2.910 [t=0.18s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.542 (perp=7.236, rec=0.090, cos=0.005), tot_loss_proj:2.908 [t=0.18s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.530 (perp=7.236, rec=0.077, cos=0.005), tot_loss_proj:2.913 [t=0.26s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
[1650/2000] tot_loss=1.536 (perp=7.236, rec=0.084, cos=0.005), tot_loss_proj:2.907 [t=0.26s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.542 (perp=7.236, rec=0.089, cos=0.005), tot_loss_proj:2.911 [t=0.25s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.542 (perp=7.236, rec=0.090, cos=0.005), tot_loss_proj:2.906 [t=0.25s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
[1800/2000] tot_loss=1.528 (perp=7.236, rec=0.076, cos=0.005), tot_loss_proj:2.915 [t=0.18s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.545 (perp=7.236, rec=0.093, cos=0.005), tot_loss_proj:2.914 [t=0.25s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.541 (perp=7.236, rec=0.089, cos=0.005), tot_loss_proj:2.909 [t=0.18s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
[1950/2000] tot_loss=1.549 (perp=7.236, rec=0.096, cos=0.005), tot_loss_proj:2.905 [t=0.23s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.536 (perp=7.236, rec=0.084, cos=0.005), tot_loss_proj:2.909 [t=0.18s]
prediction: ['[CLS] do who think seamus will do that question fifth? [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] who do you think that will question seamus first? [SEP]
========================
predicted: 
========================
[CLS] do who think seamus will do that question fifth? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 81.818

[Aggregate metrics]:
rouge1     | fm: 80.909 | p: 80.909 | r: 80.909
rouge2     | fm: 5.556 | p: 5.556 | r: 5.556
rougeL     | fm: 57.273 | p: 57.273 | r: 57.273
rougeLsum  | fm: 57.273 | p: 57.273 | r: 57.273
r1fm+r2fm = 86.465

input #1 time: 0:08:19 | total time: 0:16:51


Running input #2 of 100.
reference: 
========================
The boy ran.
========================
average of cosine similarity 0.999382605741486
highest_index [0]
highest [0.999382605741486]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 1996, 2879, 2743, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the boy ran. [SEP]']
[Init] best rec loss: 1.87901771068573 for ['[CLS] animation equal wickets gran [SEP]']
[Init] best rec loss: 1.8729346990585327 for ['[CLS] described study condo relegated [SEP]']
[Init] best rec loss: 1.8475092649459839 for ['[CLS] parliamentill ho has [SEP]']
[Init] best rec loss: 1.81038498878479 for ['[CLS] depot double surrounding inches [SEP]']
[Init] best rec loss: 1.803326964378357 for ['[CLS] pakistanzee knife hr [SEP]']
[Init] best rec loss: 1.7923535108566284 for ['[CLS] jerry observatory fix ny [SEP]']
[Init] best rec loss: 1.7531903982162476 for ['[CLS] beginning culture both business [SEP]']
[Init] best perm rec loss: 1.7515801191329956 for ['[CLS] beginning both culture business [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.862 (perp=10.978, rec=0.669, cos=0.998), tot_loss_proj:4.022 [t=0.24s]
prediction: ['[CLS] pace this ran its [SEP]']
[ 100/2000] tot_loss=2.429 (perp=10.213, rec=0.321, cos=0.065), tot_loss_proj:4.207 [t=0.18s]
prediction: ['[CLS] ran boy ran running [SEP]']
[ 150/2000] tot_loss=1.837 (perp=8.027, rec=0.212, cos=0.020), tot_loss_proj:3.588 [t=0.19s]
prediction: ['[CLS] was boy ran. [SEP]']
[ 200/2000] tot_loss=1.772 (perp=8.177, rec=0.128, cos=0.009), tot_loss_proj:3.708 [t=0.19s]
prediction: ['[CLS] ran boy ran. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.773 (perp=8.177, rec=0.131, cos=0.007), tot_loss_proj:3.715 [t=0.18s]
prediction: ['[CLS] ran boy ran. [SEP]']
[ 300/2000] tot_loss=1.759 (perp=8.177, rec=0.117, cos=0.007), tot_loss_proj:3.717 [t=0.18s]
prediction: ['[CLS] ran boy ran. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.448 (perp=6.647, rec=0.111, cos=0.007), tot_loss_proj:2.133 [t=0.18s]
prediction: ['[CLS] our boy ran. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.438 (perp=6.647, rec=0.101, cos=0.007), tot_loss_proj:2.133 [t=0.19s]
prediction: ['[CLS] our boy ran. [SEP]']
[ 450/2000] tot_loss=1.697 (perp=7.930, rec=0.104, cos=0.007), tot_loss_proj:3.453 [t=0.23s]
prediction: ['[CLS] just boy ran. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.697 (perp=7.930, rec=0.104, cos=0.007), tot_loss_proj:3.454 [t=0.22s]
prediction: ['[CLS] just boy ran. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.686 (perp=7.930, rec=0.092, cos=0.007), tot_loss_proj:3.453 [t=0.19s]
prediction: ['[CLS] just boy ran. [SEP]']
[ 600/2000] tot_loss=1.697 (perp=7.930, rec=0.104, cos=0.007), tot_loss_proj:3.456 [t=0.18s]
prediction: ['[CLS] just boy ran. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.436 (perp=6.647, rec=0.099, cos=0.007), tot_loss_proj:2.128 [t=0.19s]
prediction: ['[CLS] our boy ran. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.423 (perp=6.647, rec=0.086, cos=0.007), tot_loss_proj:2.127 [t=0.19s]
prediction: ['[CLS] our boy ran. [SEP]']
[ 750/2000] tot_loss=1.438 (perp=6.647, rec=0.101, cos=0.008), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] our boy ran. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.628 (perp=7.536, rec=0.114, cos=0.007), tot_loss_proj:2.932 [t=0.27s]
prediction: ['[CLS]. boy ran. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.616 (perp=7.536, rec=0.101, cos=0.007), tot_loss_proj:2.935 [t=0.25s]
prediction: ['[CLS]. boy ran. [SEP]']
[ 900/2000] tot_loss=1.438 (perp=6.647, rec=0.102, cos=0.007), tot_loss_proj:2.125 [t=0.18s]
prediction: ['[CLS] our boy ran. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.435 (perp=6.647, rec=0.099, cos=0.007), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] our boy ran. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.327 (perp=6.128, rec=0.095, cos=0.007), tot_loss_proj:1.340 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[1050/2000] tot_loss=1.319 (perp=6.128, rec=0.086, cos=0.007), tot_loss_proj:1.338 [t=0.19s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.338 (perp=6.128, rec=0.105, cos=0.007), tot_loss_proj:1.341 [t=0.21s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.328 (perp=6.128, rec=0.095, cos=0.008), tot_loss_proj:1.340 [t=0.27s]
prediction: ['[CLS] the boy ran. [SEP]']
[1200/2000] tot_loss=1.333 (perp=6.128, rec=0.100, cos=0.007), tot_loss_proj:1.339 [t=0.27s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.325 (perp=6.128, rec=0.093, cos=0.007), tot_loss_proj:1.349 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.330 (perp=6.128, rec=0.098, cos=0.006), tot_loss_proj:1.342 [t=0.23s]
prediction: ['[CLS] the boy ran. [SEP]']
[1350/2000] tot_loss=1.320 (perp=6.128, rec=0.088, cos=0.006), tot_loss_proj:1.364 [t=0.20s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.332 (perp=6.128, rec=0.100, cos=0.006), tot_loss_proj:1.344 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.330 (perp=6.128, rec=0.098, cos=0.006), tot_loss_proj:1.350 [t=0.19s]
prediction: ['[CLS] the boy ran. [SEP]']
[1500/2000] tot_loss=1.318 (perp=6.128, rec=0.086, cos=0.006), tot_loss_proj:1.346 [t=0.26s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.326 (perp=6.128, rec=0.095, cos=0.006), tot_loss_proj:1.346 [t=0.19s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.323 (perp=6.128, rec=0.092, cos=0.006), tot_loss_proj:1.335 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[1650/2000] tot_loss=1.336 (perp=6.128, rec=0.105, cos=0.006), tot_loss_proj:1.335 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.329 (perp=6.128, rec=0.097, cos=0.006), tot_loss_proj:1.350 [t=0.24s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.333 (perp=6.128, rec=0.101, cos=0.006), tot_loss_proj:1.337 [t=0.19s]
prediction: ['[CLS] the boy ran. [SEP]']
[1800/2000] tot_loss=1.333 (perp=6.128, rec=0.101, cos=0.006), tot_loss_proj:1.336 [t=0.22s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.334 (perp=6.128, rec=0.102, cos=0.006), tot_loss_proj:1.343 [t=0.19s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.324 (perp=6.128, rec=0.092, cos=0.006), tot_loss_proj:1.349 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
[1950/2000] tot_loss=1.328 (perp=6.128, rec=0.097, cos=0.006), tot_loss_proj:1.340 [t=0.18s]
prediction: ['[CLS] the boy ran. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.331 (perp=6.128, rec=0.099, cos=0.006), tot_loss_proj:1.347 [t=0.26s]
prediction: ['[CLS] the boy ran. [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] the boy ran. [SEP]
========================
predicted: 
========================
[CLS] the boy ran. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.273 | p: 87.273 | r: 87.273
rouge2     | fm: 37.037 | p: 37.037 | r: 37.037
rougeL     | fm: 71.515 | p: 71.515 | r: 71.515
rougeLsum  | fm: 71.515 | p: 71.515 | r: 71.515
r1fm+r2fm = 124.310

input #2 time: 0:08:20 | total time: 0:25:12


Running input #3 of 100.
reference: 
========================
I wonder who Bill saw and liked Mary.
========================
average of cosine similarity 0.9993519691025421
highest_index [0]
highest [0.9993519691025421]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1045, 4687, 2040, 3021, 2387, 1998, 4669, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i wonder who bill saw and liked mary. [SEP]']
[Init] best rec loss: 1.3352394104003906 for ['[CLS] term acute turner ren reunion streets strikes still preservation [SEP]']
[Init] best rec loss: 1.3224459886550903 for ['[CLS] beginning did programs fame ll fullyight sussex slalom [SEP]']
[Init] best rec loss: 1.3066860437393188 for ['[CLS] positive included vein casino easily publici airport peat [SEP]']
[Init] best rec loss: 1.2308356761932373 for ['[CLS] matthew marked studies offensive titular sneak de drama escort [SEP]']
[Init] best rec loss: 1.2182968854904175 for ['[CLS] sign speed die doc spitfire set yes lunch an [SEP]']
[Init] best rec loss: 1.215499758720398 for ['[CLS] switch aged trying ta asher issue striking allglia [SEP]']
[Init] best rec loss: 1.1909152269363403 for ['[CLS]logist felt sympathetic analogy apr thick dakota origin barracks [SEP]']
[Init] best perm rec loss: 1.1885956525802612 for ['[CLS] analogy origin thick dakota felt barracks sympathetic aprlogist [SEP]']
[Init] best perm rec loss: 1.1847997903823853 for ['[CLS] origin analogy dakotalogist apr felt sympathetic barracks thick [SEP]']
[Init] best perm rec loss: 1.1829677820205688 for ['[CLS] apr thick barracks feltlogist sympathetic analogy dakota origin [SEP]']
[Init] best perm rec loss: 1.1797758340835571 for ['[CLS]logist felt thick analogy dakota origin barracks sympathetic apr [SEP]']
[Init] best perm rec loss: 1.178873896598816 for ['[CLS] dakota analogy thick felt origin aprlogist barracks sympathetic [SEP]']
[Init] best perm rec loss: 1.1760326623916626 for ['[CLS] thick dakota origin felt barracks aprlogist sympathetic analogy [SEP]']
[Init] best perm rec loss: 1.1760096549987793 for ['[CLS] thicklogist sympathetic analogy felt dakota barracks apr origin [SEP]']
[Init] best perm rec loss: 1.1723597049713135 for ['[CLS] thick origin dakota apr feltlogist analogy barracks sympathetic [SEP]']
[Init] best perm rec loss: 1.1723473072052002 for ['[CLS] thick origin apr dakota felt analogylogist barracks sympathetic [SEP]']
[Init] best perm rec loss: 1.169184684753418 for ['[CLS]logist dakota thick barracks felt apr analogy sympathetic origin [SEP]']
[Init] best perm rec loss: 1.1688460111618042 for ['[CLS] dakota felt barracks analogylogist thick sympathetic origin apr [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.044 (perp=12.130, rec=0.454, cos=0.164), tot_loss_proj:3.705 [t=0.31s]
prediction: ['[CLS] adi _ lives tiles eddie ) nbc mixtape 2013 [SEP]']
[ 100/2000] tot_loss=2.843 (perp=11.747, rec=0.379, cos=0.115), tot_loss_proj:3.459 [t=0.23s]
prediction: ['[CLS] what whom. liked eddie and volunteers wonder 2013 [SEP]']
[ 150/2000] tot_loss=2.545 (perp=10.269, rec=0.378, cos=0.112), tot_loss_proj:3.061 [t=0.27s]
prediction: ['[CLS] who who whom liked mary and damned wonder 2013 [SEP]']
[ 200/2000] tot_loss=2.174 (perp=9.060, rec=0.298, cos=0.064), tot_loss_proj:2.736 [t=0.20s]
prediction: ['[CLS] who who. liked mary and liked wonder wondering [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.531 (perp=10.093, rec=0.406, cos=0.107), tot_loss_proj:3.670 [t=0.18s]
prediction: ['[CLS] who and whom liked mary bill wonder who wondering [SEP]']
[ 300/2000] tot_loss=2.146 (perp=8.954, rec=0.274, cos=0.081), tot_loss_proj:3.244 [t=0.26s]
prediction: ['[CLS] who and who liked mary bill wonder who watch [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.954 (perp=8.498, rec=0.216, cos=0.038), tot_loss_proj:3.113 [t=0.24s]
prediction: ['[CLS] who bill who liked mary and wonder who reads [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.917 (perp=8.266, rec=0.222, cos=0.041), tot_loss_proj:2.900 [t=0.19s]
prediction: ['[CLS] who bill who liked mary and wonder! who [SEP]']
[ 450/2000] tot_loss=2.012 (perp=8.835, rec=0.185, cos=0.060), tot_loss_proj:2.640 [t=0.24s]
prediction: ['[CLS] who bill sees liked mary and wonder! who [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.764 (perp=7.919, rec=0.154, cos=0.026), tot_loss_proj:2.502 [t=0.19s]
prediction: ['[CLS] who bill sees liked mary and wonder who. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.711 (perp=7.542, rec=0.177, cos=0.025), tot_loss_proj:2.477 [t=0.18s]
prediction: ['[CLS] who sees bill liked mary and wonder who. [SEP]']
[ 600/2000] tot_loss=1.675 (perp=7.542, rec=0.144, cos=0.023), tot_loss_proj:2.476 [t=0.19s]
prediction: ['[CLS] who sees bill liked mary and wonder who. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.675 (perp=7.542, rec=0.146, cos=0.021), tot_loss_proj:2.485 [t=0.23s]
prediction: ['[CLS] who sees bill liked mary and wonder who. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.670 (perp=7.542, rec=0.142, cos=0.020), tot_loss_proj:2.479 [t=0.24s]
prediction: ['[CLS] who sees bill liked mary and wonder who. [SEP]']
[ 750/2000] tot_loss=1.667 (perp=7.542, rec=0.140, cos=0.019), tot_loss_proj:2.480 [t=0.22s]
prediction: ['[CLS] who sees bill liked mary and wonder who. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.667 (perp=7.542, rec=0.139, cos=0.020), tot_loss_proj:2.482 [t=0.24s]
prediction: ['[CLS] who sees bill liked mary and wonder who. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.658 (perp=7.542, rec=0.132, cos=0.018), tot_loss_proj:2.475 [t=0.23s]
prediction: ['[CLS] who sees bill liked mary and wonder who. [SEP]']
[ 900/2000] tot_loss=1.661 (perp=7.542, rec=0.135, cos=0.018), tot_loss_proj:2.474 [t=0.18s]
prediction: ['[CLS] who sees bill liked mary and wonder who. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.659 (perp=7.542, rec=0.134, cos=0.017), tot_loss_proj:2.474 [t=0.18s]
prediction: ['[CLS] who sees bill liked mary and wonder who. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.635 (perp=7.428, rec=0.134, cos=0.016), tot_loss_proj:2.353 [t=0.27s]
prediction: ['[CLS] who saw bill liked mary and wonder who. [SEP]']
[1050/2000] tot_loss=1.623 (perp=7.428, rec=0.124, cos=0.014), tot_loss_proj:2.349 [t=0.18s]
prediction: ['[CLS] who saw bill liked mary and wonder who. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.598 (perp=7.307, rec=0.125, cos=0.012), tot_loss_proj:2.515 [t=0.19s]
prediction: ['[CLS] who saw bill liked mary and wonder.. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.593 (perp=7.307, rec=0.121, cos=0.011), tot_loss_proj:2.516 [t=0.18s]
prediction: ['[CLS] who saw bill liked mary and wonder.. [SEP]']
[1200/2000] tot_loss=1.600 (perp=7.307, rec=0.128, cos=0.010), tot_loss_proj:2.516 [t=0.19s]
prediction: ['[CLS] who saw bill liked mary and wonder.. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.489 (perp=6.870, rec=0.108, cos=0.006), tot_loss_proj:2.474 [t=0.18s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.481 (perp=6.870, rec=0.102, cos=0.006), tot_loss_proj:2.478 [t=0.19s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
[1350/2000] tot_loss=1.484 (perp=6.870, rec=0.105, cos=0.005), tot_loss_proj:2.477 [t=0.26s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.483 (perp=6.870, rec=0.104, cos=0.005), tot_loss_proj:2.473 [t=0.23s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.479 (perp=6.870, rec=0.100, cos=0.005), tot_loss_proj:2.476 [t=0.19s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
[1500/2000] tot_loss=1.485 (perp=6.870, rec=0.106, cos=0.005), tot_loss_proj:2.480 [t=0.25s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.476 (perp=6.870, rec=0.097, cos=0.004), tot_loss_proj:2.471 [t=0.19s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.469 (perp=6.870, rec=0.091, cos=0.004), tot_loss_proj:2.474 [t=0.19s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
[1650/2000] tot_loss=1.475 (perp=6.870, rec=0.097, cos=0.004), tot_loss_proj:2.470 [t=0.19s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.466 (perp=6.870, rec=0.088, cos=0.004), tot_loss_proj:2.474 [t=0.18s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.480 (perp=6.870, rec=0.102, cos=0.004), tot_loss_proj:2.464 [t=0.19s]
prediction: ['[CLS] who saw bill liked. and wonder mary. [SEP]']
[1800/2000] tot_loss=1.604 (perp=7.509, rec=0.099, cos=0.004), tot_loss_proj:2.835 [t=0.18s]
prediction: ['[CLS] who saw bill liked i and wonder mary. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.603 (perp=7.509, rec=0.097, cos=0.004), tot_loss_proj:2.833 [t=0.26s]
prediction: ['[CLS] who saw bill liked i and wonder mary. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.587 (perp=7.509, rec=0.082, cos=0.003), tot_loss_proj:2.839 [t=0.21s]
prediction: ['[CLS] who saw bill liked i and wonder mary. [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.509, rec=0.082, cos=0.003), tot_loss_proj:2.836 [t=0.18s]
prediction: ['[CLS] who saw bill liked i and wonder mary. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.538 (perp=7.165, rec=0.100, cos=0.005), tot_loss_proj:2.418 [t=0.28s]
prediction: ['[CLS] who saw i liked bill and wonder mary. [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] i wonder who bill saw and liked mary. [SEP]
========================
predicted: 
========================
[CLS] who saw bill liked i and wonder mary. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 11.111 | p: 11.111 | r: 11.111
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 111.111

[Aggregate metrics]:
rouge1     | fm: 90.455 | p: 90.455 | r: 90.455
rouge2     | fm: 30.556 | p: 30.556 | r: 30.556
rougeL     | fm: 68.636 | p: 68.636 | r: 68.636
rougeLsum  | fm: 68.636 | p: 68.636 | r: 68.636
r1fm+r2fm = 121.010

input #3 time: 0:08:24 | total time: 0:33:36


Running input #4 of 100.
reference: 
========================
While I might want to, this is the kind of thing that Harris has already suggested.
========================
average of cosine similarity 0.9993692677558084
highest_index [0]
highest [0.9993692677558084]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2096, 1045, 2453, 2215, 2000, 1010, 2023, 2003, 1996, 2785, 1997,
         2518, 2008, 5671, 2038, 2525, 4081, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]']
[Init] best rec loss: 1.9940308332443237 for ['[CLS] june stuffed eponymousdaepathic white bump earth critical security tata fraa area che range soory [SEP]']
[Init] best rec loss: 1.9101805686950684 for ['[CLS] rather againnae henry program seek csi finish et maya alternate drive airport r ke vermont witness 2011 [SEP]']
[Init] best rec loss: 1.8902432918548584 for ['[CLS] val phoenix close staffness newly forbes becomes here tree centimetres hourly margin tone hammer glare ash female [SEP]']
[Init] best rec loss: 1.8577388525009155 for ['[CLS] dutchiers courageael whose number gotta rough ruled againstct sources chain sensed impressed rest ll protection [SEP]']
[Init] best rec loss: 1.8444522619247437 for ['[CLS] handled off entirely seemedless need elsewhere paper quality trouble presence food anything wood along look tel hot [SEP]']
[Init] best rec loss: 1.835652470588684 for ['[CLS] sign hiddenslindents coincidence claimed airremmbs heritage magazine supporters courage whispered, otherwise water left [SEP]']
[Init] best rec loss: 1.8290282487869263 for ['[CLS] lose being testosterone why novak nba local redding buenos while ngo [CLS] transported middleganhanlift neighboring [SEP]']
[Init] best perm rec loss: 1.8285112380981445 for ['[CLS] middle ngo lose whilelift novakhan testosterone neighboring why local nba buenos [CLS] beinggan redding transported [SEP]']
[Init] best perm rec loss: 1.8263705968856812 for ['[CLS] whygan nba buenos testosterone while [CLS] ngo transportedhan being middle redding neighboring novak lose locallift [SEP]']
[Init] best perm rec loss: 1.8234598636627197 for ['[CLS]han transported testosteronegan being why nba lose ngo redding neighboring local middle whilelift novak buenos [CLS] [SEP]']
[Init] best perm rec loss: 1.8234483003616333 for ['[CLS] transportedhan being neighboring lose ngo whilegan buenos local novaklift [CLS] middle nba testosterone why redding [SEP]']
[Init] best perm rec loss: 1.8233933448791504 for ['[CLS] ngo why transported nba redding neighboring [CLS] lose novak testosterone beinghanganlift local buenos while middle [SEP]']
[Init] best perm rec loss: 1.821812629699707 for ['[CLS] being novak ngo transported redding why losehan middle [CLS]gan local nba testosteronelift neighboring while buenos [SEP]']
[Init] best perm rec loss: 1.82129967212677 for ['[CLS]gan local buenos redding testosteronelifthan ngo [CLS] middle lose nba transported neighboring while novak why being [SEP]']
[Init] best perm rec loss: 1.8189640045166016 for ['[CLS] whylift ngohan buenos novak being middle [CLS] localgan lose redding testosterone neighboring while nba transported [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.718 (perp=10.624, rec=0.605, cos=0.989), tot_loss_proj:4.041 [t=0.24s]
prediction: ['[CLS] which problem!, june ;. ship if crazy a selection surrounding enemiesrail local. have [SEP]']
[ 100/2000] tot_loss=3.460 (perp=9.367, rec=0.596, cos=0.990), tot_loss_proj:3.772 [t=0.29s]
prediction: ['[CLS] that alex species 2017 june? my. if lucky the, restriction was the silent.. [SEP]']
[ 150/2000] tot_loss=3.066 (perp=7.908, rec=0.487, cos=0.998), tot_loss_proj:3.532 [t=0.25s]
prediction: ['[CLS] that david species 2017 operation! my. have said., harris was. together.. [SEP]']
[ 200/2000] tot_loss=3.595 (perp=9.731, rec=0.773, cos=0.876), tot_loss_proj:3.890 [t=0.20s]
prediction: ['[CLS]. giant would ) did vegas. harris having announced ;.roud residents the together. of [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.398 (perp=9.031, rec=0.621, cos=0.972), tot_loss_proj:3.739 [t=0.21s]
prediction: ['[CLS]. giant though after horses,., having announced, ofroud. thehear -. [SEP]']
[ 300/2000] tot_loss=3.334 (perp=9.026, rec=0.538, cos=0.990), tot_loss_proj:3.768 [t=0.23s]
prediction: ['[CLS]. giant though and did ;. harris has announced, couldroud..hear -. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.182 (perp=8.449, rec=0.495, cos=0.997), tot_loss_proj:3.630 [t=0.19s]
prediction: ['[CLS]. ; though go did giant. harris has constructed, could harris..hear (. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.081 (perp=8.013, rec=0.480, cos=0.999), tot_loss_proj:3.591 [t=0.18s]
prediction: ['[CLS]. ; though as did giant. harris has constructed, with harris. andhear would should [SEP]']
[ 450/2000] tot_loss=3.001 (perp=7.735, rec=0.454, cos=1.000), tot_loss_proj:3.469 [t=0.19s]
prediction: ['[CLS].. though as did sir. harris has constructed, with harris. andhear would outsider [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.142 (perp=8.543, rec=0.433, cos=1.000), tot_loss_proj:3.614 [t=0.18s]
prediction: ['[CLS]. any and though did sir. harris has constructed, with harris. andhear would outsider [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.742 (perp=10.117, rec=0.835, cos=0.883), tot_loss_proj:3.910 [t=0.19s]
prediction: ['[CLS].. went though titus giant. harris having sized ending. fitted. the could in deserves [SEP]']
[ 600/2000] tot_loss=3.608 (perp=9.795, rec=0.689, cos=0.960), tot_loss_proj:3.804 [t=0.19s]
prediction: ['[CLS].. went though titus yes. harris having sized ending. fitted is the could in suits [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.314 (perp=8.476, rec=0.622, cos=0.997), tot_loss_proj:3.591 [t=0.19s]
prediction: ['[CLS].. went though including. yes. harris having sizedd harris is the could in backing [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.245 (perp=8.832, rec=0.543, cos=0.935), tot_loss_proj:3.647 [t=0.19s]
prediction: ['[CLS] of yes went though treasure... harris having sizedd harris is the could in backing [SEP]']
[ 750/2000] tot_loss=3.074 (perp=9.067, rec=0.481, cos=0.780), tot_loss_proj:3.687 [t=0.20s]
prediction: ['[CLS] of yes examples though treasure... harris has sizedd harris is the could for backing [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.439 (perp=8.191, rec=0.426, cos=0.375), tot_loss_proj:3.506 [t=0.19s]
prediction: ['[CLS] of yes could limit including... harris has sized " harris is the went from backing [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.229 (perp=8.571, rec=0.373, cos=0.142), tot_loss_proj:3.594 [t=0.23s]
prediction: ['[CLS] with yes could limit including... harris has sizedd harris has and went from name [SEP]']
[ 900/2000] tot_loss=2.222 (perp=8.889, rec=0.349, cos=0.096), tot_loss_proj:3.655 [t=0.19s]
prediction: ['[CLS] with yes could limit including,.. harris has sized ( harris has and went frompack [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.150 (perp=8.712, rec=0.335, cos=0.072), tot_loss_proj:3.640 [t=0.19s]
prediction: ['[CLS] with yes could limit including,.. harris has sized ( harris has and went fromnished [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.135 (perp=8.739, rec=0.324, cos=0.064), tot_loss_proj:3.655 [t=0.20s]
prediction: ['[CLS] with yes could harris did,.. type has master ( harris has and went fromnished [SEP]']
[1050/2000] tot_loss=2.059 (perp=8.478, rec=0.308, cos=0.055), tot_loss_proj:3.602 [t=0.19s]
prediction: ['[CLS] with yes could harris did,.. type has master ( harris has and went from name [SEP]']
Attempt swap
[1100/2000] tot_loss=2.168 (perp=9.048, rec=0.309, cos=0.049), tot_loss_proj:3.689 [t=0.19s]
prediction: ['[CLS] with yeah could harris did,.. type has harris ( harris is and went fromquisite [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.089 (perp=8.698, rec=0.299, cos=0.050), tot_loss_proj:3.605 [t=0.23s]
prediction: ['[CLS] with is could harris did,.. type has harris ( harris yeah and went from bottle [SEP]']
[1200/2000] tot_loss=2.031 (perp=8.487, rec=0.290, cos=0.044), tot_loss_proj:3.569 [t=0.19s]
prediction: ['[CLS] with is could harris did,.. type has harris ( harris yeah and went from name [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.975 (perp=8.222, rec=0.290, cos=0.041), tot_loss_proj:3.506 [t=0.20s]
prediction: ['[CLS] with is could harris did,.. harris has type ( harris yeah and went from bottle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.960 (perp=8.222, rec=0.278, cos=0.038), tot_loss_proj:3.504 [t=0.23s]
prediction: ['[CLS] with is could harris did,.. harris has type ( harris yeah and went from bottle [SEP]']
[1350/2000] tot_loss=1.950 (perp=8.222, rec=0.270, cos=0.036), tot_loss_proj:3.508 [t=0.26s]
prediction: ['[CLS] with is could harris did,.. harris has type ( harris yeah and went from bottle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.957 (perp=8.222, rec=0.277, cos=0.035), tot_loss_proj:3.510 [t=0.19s]
prediction: ['[CLS] with is could harris did,.. harris has type ( harris yeah and went from bottle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.951 (perp=8.222, rec=0.273, cos=0.033), tot_loss_proj:3.506 [t=0.25s]
prediction: ['[CLS] with is could harris did,.. harris has type ( harris yeah and went from bottle [SEP]']
[1500/2000] tot_loss=1.973 (perp=8.366, rec=0.266, cos=0.033), tot_loss_proj:3.558 [t=0.25s]
prediction: ['[CLS] with is could harris did,.. harris might type ( harris yeah and went from bottle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.969 (perp=8.366, rec=0.264, cos=0.032), tot_loss_proj:3.558 [t=0.19s]
prediction: ['[CLS] with is could harris did,.. harris might type ( harris yeah and went from bottle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.971 (perp=8.366, rec=0.267, cos=0.031), tot_loss_proj:3.556 [t=0.25s]
prediction: ['[CLS] with is could harris did,.. harris might type ( harris yeah and went from bottle [SEP]']
[1650/2000] tot_loss=1.968 (perp=8.366, rec=0.264, cos=0.030), tot_loss_proj:3.560 [t=0.19s]
prediction: ['[CLS] with is could harris did,.. harris might type ( harris yeah and went from bottle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.964 (perp=8.366, rec=0.260, cos=0.030), tot_loss_proj:3.557 [t=0.22s]
prediction: ['[CLS] with is could harris did,.. harris might type ( harris yeah and went from bottle [SEP]']
Attempt swap
[1750/2000] tot_loss=2.081 (perp=8.933, rec=0.265, cos=0.029), tot_loss_proj:3.679 [t=0.19s]
prediction: ['[CLS] with is could harris did,.. harris might typeout harris yeah and went from bottle [SEP]']
[1800/2000] tot_loss=2.075 (perp=8.933, rec=0.259, cos=0.029), tot_loss_proj:3.675 [t=0.21s]
prediction: ['[CLS] with is could harris did,.. harris might typeout harris yeah and went from bottle [SEP]']
Attempt swap
[1850/2000] tot_loss=2.074 (perp=8.933, rec=0.259, cos=0.028), tot_loss_proj:3.675 [t=0.24s]
prediction: ['[CLS] with is could harris did,.. harris might typeout harris yeah and went from bottle [SEP]']
Attempt swap
[1900/2000] tot_loss=2.045 (perp=8.807, rec=0.256, cos=0.028), tot_loss_proj:3.632 [t=0.23s]
prediction: ['[CLS] with is could harris did,.. harris might type that harris yeah and went from bottle [SEP]']
[1950/2000] tot_loss=2.043 (perp=8.807, rec=0.254, cos=0.028), tot_loss_proj:3.631 [t=0.19s]
prediction: ['[CLS] with is could harris did,.. harris might type that harris yeah and went from bottle [SEP]']
Attempt swap
[2000/2000] tot_loss=2.049 (perp=8.807, rec=0.260, cos=0.027), tot_loss_proj:3.630 [t=0.19s]
prediction: ['[CLS] with is could harris did,.. harris might type that harris yeah and went from bottle [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] while i might want to, this is the kind of thing that harris has already suggested. [SEP]
========================
predicted: 
========================
[CLS] with is could harris did,.. harris might type that harris yeah and went from bottle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 34.286 | p: 35.294 | r: 33.333
rouge2     | fm: 6.061 | p: 6.250 | r: 5.882
rougeL     | fm: 28.571 | p: 29.412 | r: 27.778
rougeLsum  | fm: 28.571 | p: 29.412 | r: 27.778
r1fm+r2fm = 40.346

[Aggregate metrics]:
rouge1     | fm: 79.584 | p: 79.786 | r: 79.394
rouge2     | fm: 25.657 | p: 25.694 | r: 25.621
rougeL     | fm: 60.623 | p: 60.791 | r: 60.465
rougeLsum  | fm: 60.623 | p: 60.791 | r: 60.465
r1fm+r2fm = 105.241

input #4 time: 0:08:28 | total time: 0:42:04


Running input #5 of 100.
reference: 
========================
Who has seen my snorkel?
========================
average of cosine similarity 0.9994131902913327
highest_index [0]
highest [0.9994131902913327]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2040,  2038,  2464,  2026,  1055, 12131, 11705,  1029,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] who has seen my snorkel? [SEP]']
[Init] best rec loss: 1.9208405017852783 for ['[CLS] second lot dimensions absolutelyavia nuclear second century [SEP]']
[Init] best rec loss: 1.915509819984436 for ['[CLS] softzzled 10 dark ob subscription fury cold [SEP]']
[Init] best rec loss: 1.9136182069778442 for ['[CLS] overall its gallo paintings playing percival crater huge [SEP]']
[Init] best rec loss: 1.895763874053955 for ['[CLS] america discussionitor monopoly expert member formation stuff [SEP]']
[Init] best rec loss: 1.889032006263733 for ['[CLS] always admitted tests iso planet more fields person [SEP]']
[Init] best rec loss: 1.8454792499542236 for ['[CLS] driven watering house corner head same advertisements show [SEP]']
[Init] best rec loss: 1.799236536026001 for ['[CLS] the 10 surprise dear relieve leaf blair its [SEP]']
[Init] best rec loss: 1.7598447799682617 for ['[CLS] celeste deal > protection seal method footlly [SEP]']
[Init] best perm rec loss: 1.759735107421875 for ['[CLS] deal foot seal method > celestelly protection [SEP]']
[Init] best perm rec loss: 1.7588447332382202 for ['[CLS] seallly foot method > deal celeste protection [SEP]']
[Init] best perm rec loss: 1.7578189373016357 for ['[CLS] foot deallly > seal method protection celeste [SEP]']
[Init] best perm rec loss: 1.7562793493270874 for ['[CLS] deallly method protection foot > celeste seal [SEP]']
[Init] best perm rec loss: 1.7552982568740845 for ['[CLS] seal deal method >lly protection foot celeste [SEP]']
[Init] best perm rec loss: 1.753951907157898 for ['[CLS] protection methodlly seal deal > celeste foot [SEP]']
[Init] best perm rec loss: 1.753735899925232 for ['[CLS] deal methodlly foot > celeste seal protection [SEP]']
[Init] best perm rec loss: 1.7509896755218506 for ['[CLS]lly seal deal > foot method celeste protection [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.333 (perp=13.587, rec=0.458, cos=0.157), tot_loss_proj:4.616 [t=0.18s]
prediction: ['[CLS] ft miller named rock chili go god je [SEP]']
[ 100/2000] tot_loss=2.902 (perp=12.569, rec=0.329, cos=0.060), tot_loss_proj:4.436 [t=0.26s]
prediction: ['[CLS] never millerkel yourggy your godkar [SEP]']
[ 150/2000] tot_loss=2.550 (perp=10.980, rec=0.299, cos=0.055), tot_loss_proj:4.050 [t=0.19s]
prediction: ['[CLS] who cancelledkel my own has iskel [SEP]']
[ 200/2000] tot_loss=2.218 (perp=9.756, rec=0.235, cos=0.032), tot_loss_proj:3.880 [t=0.18s]
prediction: ['[CLS] who hasnor mykel has haskel [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.706 (perp=7.385, rec=0.200, cos=0.029), tot_loss_proj:3.461 [t=0.22s]
prediction: ['[CLS] who has mynorkel yournorkel [SEP]']
[ 300/2000] tot_loss=1.738 (perp=7.924, rec=0.142, cos=0.011), tot_loss_proj:3.563 [t=0.18s]
prediction: ['[CLS] who has mynorkel?norkel [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.521 (perp=7.011, rec=0.110, cos=0.009), tot_loss_proj:3.385 [t=0.27s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.521 (perp=7.011, rec=0.112, cos=0.007), tot_loss_proj:3.379 [t=0.18s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
[ 450/2000] tot_loss=1.511 (perp=7.011, rec=0.102, cos=0.007), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.505 (perp=7.011, rec=0.097, cos=0.006), tot_loss_proj:3.386 [t=0.28s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.508 (perp=7.011, rec=0.100, cos=0.006), tot_loss_proj:3.387 [t=0.28s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
[ 600/2000] tot_loss=1.505 (perp=7.011, rec=0.096, cos=0.006), tot_loss_proj:3.380 [t=0.23s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.496 (perp=7.011, rec=0.088, cos=0.006), tot_loss_proj:3.384 [t=0.24s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.501 (perp=7.011, rec=0.093, cos=0.006), tot_loss_proj:3.387 [t=0.25s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
[ 750/2000] tot_loss=1.500 (perp=7.011, rec=0.092, cos=0.006), tot_loss_proj:3.383 [t=0.21s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.501 (perp=7.011, rec=0.094, cos=0.006), tot_loss_proj:3.385 [t=0.29s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.496 (perp=7.011, rec=0.089, cos=0.005), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
[ 900/2000] tot_loss=1.503 (perp=7.011, rec=0.096, cos=0.005), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] who has mynor snorkel? [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.071 (perp=9.902, rec=0.087, cos=0.004), tot_loss_proj:3.901 [t=0.31s]
prediction: ['[CLS] who has mynor s seenkel? [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.535 (perp=7.177, rec=0.095, cos=0.005), tot_loss_proj:3.343 [t=0.18s]
prediction: ['[CLS] who has my seen snorkel? [SEP]']
[1050/2000] tot_loss=1.507 (perp=7.177, rec=0.070, cos=0.002), tot_loss_proj:3.345 [t=0.18s]
prediction: ['[CLS] who has my seen snorkel? [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.352 (perp=6.407, rec=0.069, cos=0.002), tot_loss_proj:1.406 [t=0.21s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.338 (perp=6.407, rec=0.055, cos=0.001), tot_loss_proj:1.402 [t=0.24s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
[1200/2000] tot_loss=1.347 (perp=6.407, rec=0.065, cos=0.001), tot_loss_proj:1.405 [t=0.31s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.342 (perp=6.407, rec=0.059, cos=0.001), tot_loss_proj:1.401 [t=0.24s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.358 (perp=6.407, rec=0.075, cos=0.001), tot_loss_proj:1.402 [t=0.19s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
[1350/2000] tot_loss=1.349 (perp=6.407, rec=0.066, cos=0.001), tot_loss_proj:1.409 [t=0.20s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.344 (perp=6.407, rec=0.061, cos=0.001), tot_loss_proj:1.400 [t=0.19s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.341 (perp=6.407, rec=0.059, cos=0.001), tot_loss_proj:1.393 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
[1500/2000] tot_loss=1.350 (perp=6.407, rec=0.067, cos=0.001), tot_loss_proj:1.398 [t=0.19s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.344 (perp=6.407, rec=0.061, cos=0.001), tot_loss_proj:1.405 [t=0.19s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.351 (perp=6.407, rec=0.068, cos=0.001), tot_loss_proj:1.389 [t=0.19s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
[1650/2000] tot_loss=1.341 (perp=6.407, rec=0.059, cos=0.001), tot_loss_proj:1.406 [t=0.18s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.337 (perp=6.407, rec=0.054, cos=0.001), tot_loss_proj:1.409 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.350 (perp=6.407, rec=0.067, cos=0.001), tot_loss_proj:1.410 [t=0.20s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
[1800/2000] tot_loss=1.349 (perp=6.407, rec=0.066, cos=0.001), tot_loss_proj:1.404 [t=0.22s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.345 (perp=6.407, rec=0.063, cos=0.001), tot_loss_proj:1.399 [t=0.18s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.342 (perp=6.407, rec=0.060, cos=0.001), tot_loss_proj:1.396 [t=0.18s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
[1950/2000] tot_loss=1.355 (perp=6.407, rec=0.072, cos=0.001), tot_loss_proj:1.401 [t=0.23s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.347 (perp=6.407, rec=0.065, cos=0.001), tot_loss_proj:1.400 [t=0.18s]
prediction: ['[CLS] who has seen my snorkel? [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] who has seen my snorkel? [SEP]
========================
predicted: 
========================
[CLS] who has seen my snorkel? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.987 | p: 83.155 | r: 82.828
rouge2     | fm: 38.047 | p: 38.079 | r: 38.017
rougeL     | fm: 67.186 | p: 67.326 | r: 67.054
rougeLsum  | fm: 67.186 | p: 67.326 | r: 67.054
r1fm+r2fm = 121.034

input #5 time: 0:08:55 | total time: 0:51:00


Running input #6 of 100.
reference: 
========================
Which goddess helped us?
========================
average of cosine similarity 0.999551417969332
highest_index [0]
highest [0.999551417969332]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2029, 7804, 3271, 2149, 1029,  102]], device='cuda:0')
Debug: ref = ['[CLS] which goddess helped us? [SEP]']
[Init] best rec loss: 1.8528621196746826 for ['[CLS] naked scoring southeastvyn taliban [SEP]']
[Init] best rec loss: 1.8496613502502441 for ['[CLS] whig mostly ruled appliedisto [SEP]']
[Init] best rec loss: 1.8215363025665283 for ['[CLS] wearinghorpe houghton junior classroom [SEP]']
[Init] best rec loss: 1.8076171875 for ['[CLS] theatrical lord % oldest ship [SEP]']
[Init] best rec loss: 1.7265770435333252 for ['[CLS] heronhesive faye bachelorcom [SEP]']
[Init] best rec loss: 1.5618332624435425 for ['[CLS]nation convenient heal exactly ljubljana [SEP]']
[Init] best perm rec loss: 1.5606716871261597 for ['[CLS] ljubljana healnation exactly convenient [SEP]']
[Init] best perm rec loss: 1.5584285259246826 for ['[CLS] healnation convenient exactly ljubljana [SEP]']
[Init] best perm rec loss: 1.5568522214889526 for ['[CLS] heal ljubljana convenientnation exactly [SEP]']
[Init] best perm rec loss: 1.5559192895889282 for ['[CLS] ljubljananation convenient heal exactly [SEP]']
[Init] best perm rec loss: 1.5545248985290527 for ['[CLS] ljubljananation heal convenient exactly [SEP]']
[Init] best perm rec loss: 1.5531717538833618 for ['[CLS] exactlynation heal convenient ljubljana [SEP]']
[Init] best perm rec loss: 1.5527359247207642 for ['[CLS] heal exactlynation convenient ljubljana [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.822 (perp=11.113, rec=0.630, cos=0.969), tot_loss_proj:4.170 [t=0.26s]
prediction: ['[CLS] inspiredless using novelty road [SEP]']
[ 100/2000] tot_loss=4.038 (perp=12.622, rec=0.545, cos=0.969), tot_loss_proj:4.569 [t=0.27s]
prediction: ['[CLS] goddess sync goddess elaine helped [SEP]']
[ 150/2000] tot_loss=3.679 (perp=11.280, rec=0.492, cos=0.932), tot_loss_proj:4.218 [t=0.28s]
prediction: ['[CLS] goddess accounted goddess which helped [SEP]']
[ 200/2000] tot_loss=3.203 (perp=9.029, rec=0.474, cos=0.923), tot_loss_proj:3.868 [t=0.30s]
prediction: ['[CLS] goddess goddess goddess which? [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.164 (perp=9.029, rec=0.432, cos=0.927), tot_loss_proj:3.871 [t=0.26s]
prediction: ['[CLS] goddess goddess goddess which? [SEP]']
[ 300/2000] tot_loss=3.538 (perp=10.964, rec=0.422, cos=0.923), tot_loss_proj:4.133 [t=0.18s]
prediction: ['[CLS] goddess goddess starring which goddess [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.255 (perp=9.634, rec=0.395, cos=0.933), tot_loss_proj:3.817 [t=0.18s]
prediction: ['[CLS] goddess goddess helped which goddess [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.402 (perp=10.073, rec=0.531, cos=0.857), tot_loss_proj:4.057 [t=0.19s]
prediction: ['[CLS] goddess companies which helped goddess [SEP]']
[ 450/2000] tot_loss=3.289 (perp=9.955, rec=0.427, cos=0.871), tot_loss_proj:3.984 [t=0.19s]
prediction: ['[CLS] goddess ladies which helped goddess [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.243 (perp=9.955, rec=0.384, cos=0.868), tot_loss_proj:3.982 [t=0.19s]
prediction: ['[CLS] goddess ladies which helped goddess [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.213 (perp=9.955, rec=0.357, cos=0.866), tot_loss_proj:3.984 [t=0.21s]
prediction: ['[CLS] goddess ladies which helped goddess [SEP]']
[ 600/2000] tot_loss=3.205 (perp=9.955, rec=0.352, cos=0.862), tot_loss_proj:3.987 [t=0.18s]
prediction: ['[CLS] goddess ladies which helped goddess [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.298 (perp=10.024, rec=0.442, cos=0.851), tot_loss_proj:4.035 [t=0.26s]
prediction: ['[CLS] goddess goddess which helped precedence [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.251 (perp=10.024, rec=0.391, cos=0.855), tot_loss_proj:4.032 [t=0.19s]
prediction: ['[CLS] goddess goddess which helped precedence [SEP]']
[ 750/2000] tot_loss=3.233 (perp=10.024, rec=0.365, cos=0.863), tot_loss_proj:4.027 [t=0.20s]
prediction: ['[CLS] goddess goddess which helped precedence [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.246 (perp=10.024, rec=0.373, cos=0.868), tot_loss_proj:4.025 [t=0.19s]
prediction: ['[CLS] goddess goddess which helped precedence [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.257 (perp=10.133, rec=0.362, cos=0.868), tot_loss_proj:4.076 [t=0.18s]
prediction: ['[CLS] goddess goddess which helped baltimore [SEP]']
[ 900/2000] tot_loss=3.255 (perp=10.133, rec=0.361, cos=0.867), tot_loss_proj:4.076 [t=0.19s]
prediction: ['[CLS] goddess goddess which helped baltimore [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.233 (perp=10.133, rec=0.339, cos=0.867), tot_loss_proj:4.076 [t=0.22s]
prediction: ['[CLS] goddess goddess which helped baltimore [SEP]']
Attempt swap
[1000/2000] tot_loss=3.280 (perp=10.306, rec=0.354, cos=0.865), tot_loss_proj:4.026 [t=0.18s]
prediction: ['[CLS] goddess goddess which helped proven [SEP]']
[1050/2000] tot_loss=3.264 (perp=10.306, rec=0.338, cos=0.865), tot_loss_proj:4.025 [t=0.22s]
prediction: ['[CLS] goddess goddess which helped proven [SEP]']
Attempt swap
[1100/2000] tot_loss=3.263 (perp=10.306, rec=0.338, cos=0.864), tot_loss_proj:4.022 [t=0.18s]
prediction: ['[CLS] goddess goddess which helped proven [SEP]']
Attempt swap
[1150/2000] tot_loss=3.259 (perp=10.306, rec=0.333, cos=0.864), tot_loss_proj:4.023 [t=0.18s]
prediction: ['[CLS] goddess goddess which helped proven [SEP]']
[1200/2000] tot_loss=3.264 (perp=10.306, rec=0.339, cos=0.864), tot_loss_proj:4.024 [t=0.18s]
prediction: ['[CLS] goddess goddess which helped proven [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.281 (perp=10.373, rec=0.347, cos=0.859), tot_loss_proj:4.098 [t=0.18s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Attempt swap
[1300/2000] tot_loss=3.277 (perp=10.373, rec=0.339, cos=0.864), tot_loss_proj:4.102 [t=0.25s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
[1350/2000] tot_loss=3.274 (perp=10.373, rec=0.336, cos=0.864), tot_loss_proj:4.098 [t=0.18s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Attempt swap
[1400/2000] tot_loss=3.268 (perp=10.373, rec=0.330, cos=0.864), tot_loss_proj:4.108 [t=0.19s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Attempt swap
[1450/2000] tot_loss=3.264 (perp=10.373, rec=0.326, cos=0.864), tot_loss_proj:4.098 [t=0.19s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
[1500/2000] tot_loss=3.275 (perp=10.373, rec=0.337, cos=0.863), tot_loss_proj:4.091 [t=0.19s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Attempt swap
[1550/2000] tot_loss=3.268 (perp=10.373, rec=0.330, cos=0.863), tot_loss_proj:4.100 [t=0.18s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Attempt swap
[1600/2000] tot_loss=3.267 (perp=10.373, rec=0.330, cos=0.863), tot_loss_proj:4.102 [t=0.19s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
[1650/2000] tot_loss=3.266 (perp=10.373, rec=0.329, cos=0.863), tot_loss_proj:4.101 [t=0.19s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Attempt swap
[1700/2000] tot_loss=3.261 (perp=10.373, rec=0.324, cos=0.862), tot_loss_proj:4.098 [t=0.26s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Attempt swap
[1750/2000] tot_loss=3.260 (perp=10.373, rec=0.323, cos=0.862), tot_loss_proj:4.097 [t=0.18s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
[1800/2000] tot_loss=3.262 (perp=10.373, rec=0.324, cos=0.863), tot_loss_proj:4.091 [t=0.20s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Attempt swap
[1850/2000] tot_loss=3.271 (perp=10.373, rec=0.334, cos=0.863), tot_loss_proj:4.100 [t=0.20s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Attempt swap
[1900/2000] tot_loss=3.264 (perp=10.373, rec=0.326, cos=0.863), tot_loss_proj:4.102 [t=0.19s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
[1950/2000] tot_loss=3.247 (perp=10.373, rec=0.310, cos=0.863), tot_loss_proj:4.110 [t=0.18s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Attempt swap
[2000/2000] tot_loss=3.264 (perp=10.373, rec=0.327, cos=0.863), tot_loss_proj:4.101 [t=0.21s]
prediction: ['[CLS] goddess which goddess helped letting [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] which goddess helped us? [SEP]
========================
predicted: 
========================
[CLS] goddess which goddess helped letting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 113.287

[Aggregate metrics]:
rouge1     | fm: 82.301 | p: 82.041 | r: 83.117
rouge2     | fm: 37.807 | p: 37.401 | r: 38.301
rougeL     | fm: 68.577 | p: 67.912 | r: 69.380
rougeLsum  | fm: 68.577 | p: 67.912 | r: 69.380
r1fm+r2fm = 120.107

input #6 time: 0:08:31 | total time: 0:59:31


Running input #7 of 100.
reference: 
========================
They have no old.
========================
average of cosine similarity 0.9993867448742303
highest_index [0]
highest [0.9993867448742303]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2027, 2031, 2053, 2214, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] they have no old. [SEP]']
[Init] best rec loss: 1.3582576513290405 for ['[CLS] devices buck 1947 business ji [SEP]']
[Init] best rec loss: 1.3470033407211304 for ['[CLS] talk f edited manny huskies [SEP]']
[Init] best rec loss: 1.1678038835525513 for ['[CLS]emi streamed including same rugby [SEP]']
[Init] best rec loss: 1.0638848543167114 for ['[CLS] nopecharged practiced 2011 jersey [SEP]']
[Init] best rec loss: 1.0248819589614868 for ['[CLS] necessary nino shin sensory hank [SEP]']
[Init] best rec loss: 0.967505693435669 for ['[CLS] read approach dissolve present least [SEP]']
[Init] best rec loss: 0.9421233534812927 for ['[CLS] presents contact managed dontlement [SEP]']
[Init] best rec loss: 0.9387728571891785 for ['[CLS] zhang just plum class bills [SEP]']
[Init] best rec loss: 0.9022654294967651 for ['[CLS] cargo dalton trafficking empire [SEP] [SEP]']
[Init] best perm rec loss: 0.8994971513748169 for ['[CLS] trafficking dalton cargo empire [SEP] [SEP]']
[Init] best perm rec loss: 0.8968509435653687 for ['[CLS] [SEP] dalton cargo empire trafficking [SEP]']
[Init] best perm rec loss: 0.8957321047782898 for ['[CLS] trafficking dalton cargo [SEP] empire [SEP]']
[Init] best perm rec loss: 0.8910158276557922 for ['[CLS] dalton cargo trafficking [SEP] empire [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.979 (perp=7.831, rec=0.352, cos=0.061), tot_loss_proj:3.387 [t=0.18s]
prediction: ['[CLS] they have that old old [SEP]']
[ 100/2000] tot_loss=1.710 (perp=7.728, rec=0.153, cos=0.011), tot_loss_proj:3.257 [t=0.18s]
prediction: ['[CLS] they have no old old [SEP]']
[ 150/2000] tot_loss=1.679 (perp=7.728, rec=0.124, cos=0.010), tot_loss_proj:3.254 [t=0.20s]
prediction: ['[CLS] they have no old old [SEP]']
[ 200/2000] tot_loss=1.664 (perp=7.728, rec=0.109, cos=0.009), tot_loss_proj:3.250 [t=0.19s]
prediction: ['[CLS] they have no old old [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.658 (perp=7.728, rec=0.104, cos=0.008), tot_loss_proj:3.247 [t=0.24s]
prediction: ['[CLS] they have no old old [SEP]']
[ 300/2000] tot_loss=1.646 (perp=7.728, rec=0.092, cos=0.008), tot_loss_proj:3.239 [t=0.18s]
prediction: ['[CLS] they have no old old [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.656 (perp=7.728, rec=0.104, cos=0.006), tot_loss_proj:3.260 [t=0.19s]
prediction: ['[CLS] they have no old old [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.646 (perp=7.728, rec=0.094, cos=0.006), tot_loss_proj:3.257 [t=0.18s]
prediction: ['[CLS] they have no old old [SEP]']
[ 450/2000] tot_loss=1.268 (perp=5.839, rec=0.095, cos=0.006), tot_loss_proj:1.496 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.261 (perp=5.839, rec=0.087, cos=0.006), tot_loss_proj:1.495 [t=0.21s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.267 (perp=5.839, rec=0.093, cos=0.006), tot_loss_proj:1.479 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
[ 600/2000] tot_loss=1.288 (perp=5.839, rec=0.117, cos=0.004), tot_loss_proj:1.692 [t=0.21s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.243 (perp=5.839, rec=0.073, cos=0.002), tot_loss_proj:1.465 [t=0.23s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.239 (perp=5.839, rec=0.070, cos=0.001), tot_loss_proj:1.488 [t=0.19s]
prediction: ['[CLS] they have no old. [SEP]']
[ 750/2000] tot_loss=1.249 (perp=5.839, rec=0.080, cos=0.001), tot_loss_proj:1.478 [t=0.19s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.248 (perp=5.839, rec=0.079, cos=0.001), tot_loss_proj:1.480 [t=0.20s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.235 (perp=5.839, rec=0.066, cos=0.001), tot_loss_proj:1.481 [t=0.19s]
prediction: ['[CLS] they have no old. [SEP]']
[ 900/2000] tot_loss=1.243 (perp=5.839, rec=0.074, cos=0.001), tot_loss_proj:1.484 [t=0.19s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.242 (perp=5.839, rec=0.073, cos=0.001), tot_loss_proj:1.482 [t=0.27s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.245 (perp=5.839, rec=0.076, cos=0.001), tot_loss_proj:1.477 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
[1050/2000] tot_loss=1.234 (perp=5.839, rec=0.065, cos=0.001), tot_loss_proj:1.496 [t=0.20s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.242 (perp=5.839, rec=0.073, cos=0.001), tot_loss_proj:1.479 [t=0.19s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.241 (perp=5.839, rec=0.072, cos=0.001), tot_loss_proj:1.485 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
[1200/2000] tot_loss=1.233 (perp=5.839, rec=0.064, cos=0.001), tot_loss_proj:1.479 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.241 (perp=5.839, rec=0.072, cos=0.001), tot_loss_proj:1.470 [t=0.20s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.222 (perp=5.839, rec=0.053, cos=0.001), tot_loss_proj:1.473 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
[1350/2000] tot_loss=1.231 (perp=5.839, rec=0.062, cos=0.001), tot_loss_proj:1.479 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.237 (perp=5.839, rec=0.068, cos=0.001), tot_loss_proj:1.474 [t=0.21s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.227 (perp=5.839, rec=0.058, cos=0.001), tot_loss_proj:1.478 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
[1500/2000] tot_loss=1.238 (perp=5.839, rec=0.069, cos=0.001), tot_loss_proj:1.470 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.233 (perp=5.839, rec=0.064, cos=0.001), tot_loss_proj:1.475 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.237 (perp=5.839, rec=0.069, cos=0.001), tot_loss_proj:1.475 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
[1650/2000] tot_loss=1.218 (perp=5.839, rec=0.049, cos=0.001), tot_loss_proj:1.479 [t=0.19s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.230 (perp=5.839, rec=0.061, cos=0.001), tot_loss_proj:1.484 [t=0.20s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.255 (perp=5.839, rec=0.086, cos=0.001), tot_loss_proj:1.469 [t=0.20s]
prediction: ['[CLS] they have no old. [SEP]']
[1800/2000] tot_loss=1.236 (perp=5.839, rec=0.067, cos=0.001), tot_loss_proj:1.486 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.218 (perp=5.839, rec=0.049, cos=0.001), tot_loss_proj:1.485 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.230 (perp=5.839, rec=0.061, cos=0.001), tot_loss_proj:1.486 [t=0.25s]
prediction: ['[CLS] they have no old. [SEP]']
[1950/2000] tot_loss=1.237 (perp=5.839, rec=0.068, cos=0.001), tot_loss_proj:1.476 [t=0.18s]
prediction: ['[CLS] they have no old. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.239 (perp=5.839, rec=0.070, cos=0.001), tot_loss_proj:1.485 [t=0.22s]
prediction: ['[CLS] they have no old. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] they have no old. [SEP]
========================
predicted: 
========================
[CLS] they have no old. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 84.740 | p: 84.639 | r: 85.966
rouge2     | fm: 44.949 | p: 44.444 | r: 45.359
rougeL     | fm: 72.955 | p: 72.175 | r: 73.636
rougeLsum  | fm: 72.505 | p: 72.175 | r: 73.636
r1fm+r2fm = 129.690

input #7 time: 0:08:12 | total time: 1:07:44


Running input #8 of 100.
reference: 
========================
John tries to meet not Mary.
========================
average of cosine similarity 0.9992857817396013
highest_index [0]
highest [0.9992857817396013]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2198, 5363, 2000, 3113, 2025, 2984, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] john tries to meet not mary. [SEP]']
[Init] best rec loss: 1.6854177713394165 for ['[CLS]udeau secretary steinerc pennypeed press [SEP]']
[Init] best rec loss: 1.1189523935317993 for ['[CLS] fresh contact beaten image angle form confederate [SEP]']
[Init] best rec loss: 1.0472540855407715 for ['[CLS] further big instance schedule ahead caftium [SEP]']
[Init] best rec loss: 1.0009175539016724 for ['[CLS] judge no will power us missing cry [SEP]']
[Init] best rec loss: 0.9680979251861572 for ['[CLS] die america won family vic ruleherton [SEP]']
[Init] best perm rec loss: 0.9668872356414795 for ['[CLS] america won die rule vicherton family [SEP]']
[Init] best perm rec loss: 0.9600526094436646 for ['[CLS] america dieherton vic won family rule [SEP]']
[Init] best perm rec loss: 0.9571626782417297 for ['[CLS] americaherton vic die family won rule [SEP]']
[Init] best perm rec loss: 0.956466555595398 for ['[CLS] family america die vic ruleherton won [SEP]']
[Init] best perm rec loss: 0.9549247622489929 for ['[CLS] dieherton america vic family rule won [SEP]']
[Init] best perm rec loss: 0.9546185731887817 for ['[CLS] america vic dieherton rule won family [SEP]']
[Init] best perm rec loss: 0.9513161778450012 for ['[CLS] vic america die rule familyherton won [SEP]']
[Init] best perm rec loss: 0.9464889168739319 for ['[CLS]herton america die rule vic won family [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.706 (perp=11.574, rec=0.374, cos=0.018), tot_loss_proj:2.890 [t=0.18s]
prediction: ['[CLS] john meet presence mary not you vehicle [SEP]']
[ 100/2000] tot_loss=1.729 (perp=7.623, rec=0.198, cos=0.006), tot_loss_proj:2.082 [t=0.30s]
prediction: ['[CLS] mary meet was mary not mary. [SEP]']
[ 150/2000] tot_loss=1.858 (perp=8.583, rec=0.137, cos=0.005), tot_loss_proj:2.285 [t=0.29s]
prediction: ['[CLS] mary meet could mary not mary. [SEP]']
[ 200/2000] tot_loss=1.931 (perp=9.095, rec=0.109, cos=0.003), tot_loss_proj:2.628 [t=0.28s]
prediction: ['[CLS] john meet tries mary not mary. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.811 (perp=8.525, rec=0.103, cos=0.003), tot_loss_proj:2.532 [t=0.30s]
prediction: ['[CLS] john tries meet mary not mary. [SEP]']
[ 300/2000] tot_loss=1.792 (perp=8.525, rec=0.085, cos=0.002), tot_loss_proj:2.547 [t=0.27s]
prediction: ['[CLS] john tries meet mary not mary. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.646 (perp=7.774, rec=0.089, cos=0.002), tot_loss_proj:2.210 [t=0.24s]
prediction: ['[CLS] mary tries meet mary not mary. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.637 (perp=7.774, rec=0.081, cos=0.002), tot_loss_proj:2.211 [t=0.18s]
prediction: ['[CLS] mary tries meet mary not mary. [SEP]']
[ 450/2000] tot_loss=1.639 (perp=7.774, rec=0.083, cos=0.002), tot_loss_proj:2.209 [t=0.19s]
prediction: ['[CLS] mary tries meet mary not mary. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.637 (perp=7.774, rec=0.081, cos=0.002), tot_loss_proj:2.211 [t=0.18s]
prediction: ['[CLS] mary tries meet mary not mary. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.661 (perp=7.774, rec=0.103, cos=0.003), tot_loss_proj:2.212 [t=0.25s]
prediction: ['[CLS] mary tries meet mary not mary. [SEP]']
[ 600/2000] tot_loss=1.634 (perp=7.774, rec=0.077, cos=0.002), tot_loss_proj:2.219 [t=0.18s]
prediction: ['[CLS] mary tries meet mary not mary. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.609 (perp=7.683, rec=0.070, cos=0.002), tot_loss_proj:2.247 [t=0.21s]
prediction: ['[CLS] mary mary tries meet not mary. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.608 (perp=7.683, rec=0.069, cos=0.002), tot_loss_proj:2.256 [t=0.18s]
prediction: ['[CLS] mary mary tries meet not mary. [SEP]']
[ 750/2000] tot_loss=1.620 (perp=7.683, rec=0.081, cos=0.002), tot_loss_proj:2.256 [t=0.19s]
prediction: ['[CLS] mary mary tries meet not mary. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.609 (perp=7.683, rec=0.070, cos=0.002), tot_loss_proj:2.268 [t=0.18s]
prediction: ['[CLS] mary mary tries meet not mary. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.775 (perp=8.525, rec=0.068, cos=0.002), tot_loss_proj:2.583 [t=0.22s]
prediction: ['[CLS] john tries meet mary not mary. [SEP]']
[ 900/2000] tot_loss=1.778 (perp=8.525, rec=0.072, cos=0.002), tot_loss_proj:2.590 [t=0.18s]
prediction: ['[CLS] john tries meet mary not mary. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.720 (perp=8.213, rec=0.075, cos=0.002), tot_loss_proj:2.364 [t=0.25s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.722 (perp=8.213, rec=0.078, cos=0.002), tot_loss_proj:2.370 [t=0.18s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
[1050/2000] tot_loss=1.714 (perp=8.213, rec=0.069, cos=0.002), tot_loss_proj:2.372 [t=0.19s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.708 (perp=8.213, rec=0.064, cos=0.002), tot_loss_proj:2.373 [t=0.19s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.709 (perp=8.213, rec=0.065, cos=0.002), tot_loss_proj:2.372 [t=0.20s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
[1200/2000] tot_loss=1.718 (perp=8.213, rec=0.074, cos=0.002), tot_loss_proj:2.368 [t=0.18s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.703 (perp=8.213, rec=0.059, cos=0.002), tot_loss_proj:2.366 [t=0.27s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.717 (perp=8.213, rec=0.072, cos=0.002), tot_loss_proj:2.381 [t=0.19s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
[1350/2000] tot_loss=1.708 (perp=8.213, rec=0.063, cos=0.002), tot_loss_proj:2.372 [t=0.19s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.711 (perp=8.213, rec=0.067, cos=0.002), tot_loss_proj:2.369 [t=0.26s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.709 (perp=8.213, rec=0.064, cos=0.002), tot_loss_proj:2.359 [t=0.18s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
[1500/2000] tot_loss=1.705 (perp=8.213, rec=0.060, cos=0.002), tot_loss_proj:2.373 [t=0.18s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.717 (perp=8.213, rec=0.072, cos=0.002), tot_loss_proj:2.367 [t=0.26s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.721 (perp=8.213, rec=0.077, cos=0.002), tot_loss_proj:2.364 [t=0.19s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
[1650/2000] tot_loss=1.709 (perp=8.213, rec=0.065, cos=0.002), tot_loss_proj:2.363 [t=0.23s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.710 (perp=8.213, rec=0.065, cos=0.002), tot_loss_proj:2.371 [t=0.18s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.706 (perp=8.213, rec=0.062, cos=0.002), tot_loss_proj:2.367 [t=0.19s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
[1800/2000] tot_loss=1.713 (perp=8.213, rec=0.069, cos=0.002), tot_loss_proj:2.360 [t=0.26s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.714 (perp=8.213, rec=0.069, cos=0.002), tot_loss_proj:2.364 [t=0.19s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.722 (perp=8.213, rec=0.078, cos=0.002), tot_loss_proj:2.354 [t=0.26s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
[1950/2000] tot_loss=1.721 (perp=8.213, rec=0.077, cos=0.002), tot_loss_proj:2.367 [t=0.18s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.721 (perp=8.213, rec=0.076, cos=0.002), tot_loss_proj:2.367 [t=0.19s]
prediction: ['[CLS] mary tries meet john not mary. [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS] john tries to meet not mary. [SEP]
========================
predicted: 
========================
[CLS] mary tries meet john not mary. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 116.071

[Aggregate metrics]:
rouge1     | fm: 85.678 | p: 85.130 | r: 86.254
rouge2     | fm: 43.547 | p: 43.287 | r: 44.040
rougeL     | fm: 72.797 | p: 72.474 | r: 73.406
rougeLsum  | fm: 73.104 | p: 72.662 | r: 73.827
r1fm+r2fm = 129.225

input #8 time: 0:08:29 | total time: 1:16:13


Running input #9 of 100.
reference: 
========================
The unidentified victim was apparently struck during the early morning hours.
========================
average of cosine similarity 0.9994535457719615
highest_index [0]
highest [0.9994535457719615]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  1996, 20293,  6778,  2001,  4593,  4930,  2076,  1996,  2220,
          2851,  2847,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]']
[Init] best rec loss: 1.8585201501846313 for ['[CLS]re took vie one ioc reading triangle willmour just grantedated [SEP]']
[Init] best rec loss: 1.8456511497497559 for ['[CLS] earth thishman young detailed nice christianity visas suddenlys written all [SEP]']
[Init] best rec loss: 1.8294862508773804 for ['[CLS] protein : bed fm roughly globe cloud frigates sarah lo season fright [SEP]']
[Init] best rec loss: 1.8107002973556519 for ['[CLS] against attorneylase wave livelihood bath blast [SEP] scouting ) alike & [SEP]']
[Init] best rec loss: 1.8001291751861572 for ['[CLS] questioned piecesatory www caseness coraluled colorado below invited layla [SEP]']
[Init] best rec loss: 1.7578116655349731 for ['[CLS] drinking recession given surrender angel director beltanial present theirs looking starring [SEP]']
[Init] best rec loss: 1.7566722631454468 for ['[CLS] past beyond p else north magazine already making press christianity test describe [SEP]']
[Init] best perm rec loss: 1.7552826404571533 for ['[CLS] magazine past north else p making beyond press describe christianity already test [SEP]']
[Init] best perm rec loss: 1.754188895225525 for ['[CLS] north p past making else test christianity already press beyond describe magazine [SEP]']
[Init] best perm rec loss: 1.7526164054870605 for ['[CLS] describe p press christianity past north test else magazine beyond already making [SEP]']
[Init] best perm rec loss: 1.749539852142334 for ['[CLS] describe else p test past magazine north christianity press already making beyond [SEP]']
[Init] best perm rec loss: 1.7492481470108032 for ['[CLS] press p past else christianity north already test beyond magazine describe making [SEP]']
[Init] best perm rec loss: 1.7476677894592285 for ['[CLS] beyond else describe past making test already magazine press p north christianity [SEP]']
[Init] best perm rec loss: 1.7463717460632324 for ['[CLS] already past else test making north magazine p christianity describe beyond press [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.493 (perp=14.578, rec=0.585, cos=0.992), tot_loss_proj:4.750 [t=0.21s]
prediction: ['[CLS] mountain scent tissue delivered caughtwi bombardment apparently strange wa expresses compliant [SEP]']
[ 100/2000] tot_loss=2.608 (perp=11.314, rec=0.292, cos=0.053), tot_loss_proj:4.254 [t=0.22s]
prediction: ['[CLS] inner victims suffered victim women lieutenant lieutenant victim she & apparently reported [SEP]']
[ 150/2000] tot_loss=2.563 (perp=11.628, rec=0.219, cos=0.018), tot_loss_proj:4.176 [t=0.19s]
prediction: ['[CLS] unidentified victim were struck evening diocese victim victims struck apparently unidentified [SEP]']
[ 200/2000] tot_loss=2.424 (perp=11.095, rec=0.192, cos=0.013), tot_loss_proj:3.974 [t=0.18s]
prediction: ['[CLS] unidentified victim were struck however diocese victim victim the struck apparently unidentified [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.211 (perp=9.767, rec=0.232, cos=0.026), tot_loss_proj:3.642 [t=0.20s]
prediction: ['[CLS] unidentified victim were struck been the victim victim. struck apparently unidentified [SEP]']
[ 300/2000] tot_loss=2.282 (perp=10.552, rec=0.162, cos=0.010), tot_loss_proj:4.001 [t=0.24s]
prediction: ['[CLS] unidentified hours were struck a the unidentified victim morning struck apparently unidentified [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.105 (perp=9.779, rec=0.142, cos=0.008), tot_loss_proj:3.817 [t=0.18s]
prediction: ['[CLS] unidentified hours were struck a apparently unidentified victim morning struck the unidentified [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.721 (perp=7.954, rec=0.124, cos=0.007), tot_loss_proj:3.325 [t=0.23s]
prediction: ['[CLS] unidentified hours were was a apparently unidentified victim. the unidentified struck [SEP]']
[ 450/2000] tot_loss=1.701 (perp=7.954, rec=0.105, cos=0.005), tot_loss_proj:3.326 [t=0.19s]
prediction: ['[CLS] unidentified hours were was a apparently unidentified victim. the unidentified struck [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.738 (perp=8.175, rec=0.098, cos=0.005), tot_loss_proj:3.398 [t=0.18s]
prediction: ['[CLS] during hours were was the apparently unidentified victim. the unidentified struck [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.431 (perp=8.642, rec=0.939, cos=0.764), tot_loss_proj:3.749 [t=0.18s]
prediction: ['[CLS] during hours [MASK] was apparently the unidentified victim during the unidentified struck [SEP]']
[ 600/2000] tot_loss=3.372 (perp=8.642, rec=0.792, cos=0.851), tot_loss_proj:3.767 [t=0.21s]
prediction: ['[CLS] during hours [MASK] was apparently the unidentified victim during the unidentified struck [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.430 (perp=8.858, rec=0.721, cos=0.938), tot_loss_proj:3.781 [t=0.23s]
prediction: ['[CLS] during hours [MASK] was apparently the unidentified victim struck during is unidentified [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.273 (perp=8.066, rec=0.661, cos=0.999), tot_loss_proj:3.714 [t=0.18s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck during is unidentified [SEP]']
[ 750/2000] tot_loss=3.082 (perp=8.066, rec=0.576, cos=0.893), tot_loss_proj:3.712 [t=0.18s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck during is unidentified [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.691 (perp=8.066, rec=0.510, cos=0.567), tot_loss_proj:3.711 [t=0.18s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck during is unidentified [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.461 (perp=8.332, rec=0.450, cos=0.344), tot_loss_proj:3.755 [t=0.25s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck apparently is unidentified [SEP]']
[ 900/2000] tot_loss=2.316 (perp=8.332, rec=0.414, cos=0.236), tot_loss_proj:3.757 [t=0.22s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck apparently is unidentified [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.233 (perp=8.716, rec=0.366, cos=0.123), tot_loss_proj:3.758 [t=0.18s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck respective is unidentified [SEP]']
Attempt swap
[1000/2000] tot_loss=2.149 (perp=8.716, rec=0.322, cos=0.083), tot_loss_proj:3.752 [t=0.20s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck respective is unidentified [SEP]']
[1050/2000] tot_loss=2.138 (perp=8.818, rec=0.310, cos=0.064), tot_loss_proj:3.803 [t=0.19s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck respective. unidentified [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.899 (perp=7.716, rec=0.300, cos=0.056), tot_loss_proj:3.684 [t=0.31s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.869 (perp=7.716, rec=0.278, cos=0.048), tot_loss_proj:3.683 [t=0.24s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
[1200/2000] tot_loss=1.855 (perp=7.716, rec=0.268, cos=0.044), tot_loss_proj:3.684 [t=0.26s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.846 (perp=7.716, rec=0.262, cos=0.040), tot_loss_proj:3.686 [t=0.27s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.830 (perp=7.716, rec=0.250, cos=0.038), tot_loss_proj:3.686 [t=0.25s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
[1350/2000] tot_loss=1.825 (perp=7.716, rec=0.246, cos=0.035), tot_loss_proj:3.685 [t=0.28s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.817 (perp=7.716, rec=0.241, cos=0.033), tot_loss_proj:3.680 [t=0.29s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.807 (perp=7.716, rec=0.233, cos=0.030), tot_loss_proj:3.689 [t=0.21s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
[1500/2000] tot_loss=1.804 (perp=7.716, rec=0.232, cos=0.029), tot_loss_proj:3.686 [t=0.18s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.805 (perp=7.716, rec=0.235, cos=0.027), tot_loss_proj:3.686 [t=0.20s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.792 (perp=7.716, rec=0.223, cos=0.026), tot_loss_proj:3.692 [t=0.23s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
[1650/2000] tot_loss=1.788 (perp=7.716, rec=0.220, cos=0.025), tot_loss_proj:3.686 [t=0.18s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.791 (perp=7.716, rec=0.224, cos=0.024), tot_loss_proj:3.692 [t=0.18s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.783 (perp=7.716, rec=0.216, cos=0.023), tot_loss_proj:3.682 [t=0.18s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
[1800/2000] tot_loss=1.786 (perp=7.716, rec=0.221, cos=0.022), tot_loss_proj:3.687 [t=0.19s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.785 (perp=7.716, rec=0.220, cos=0.022), tot_loss_proj:3.687 [t=0.21s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.769 (perp=7.716, rec=0.204, cos=0.021), tot_loss_proj:3.690 [t=0.18s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
[1950/2000] tot_loss=1.781 (perp=7.716, rec=0.217, cos=0.021), tot_loss_proj:3.689 [t=0.18s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.772 (perp=7.716, rec=0.209, cos=0.021), tot_loss_proj:3.688 [t=0.25s]
prediction: ['[CLS] during unidentified hours [MASK] was apparently the victim struck briefly unidentified. [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] the unidentified victim was apparently struck during the early morning hours. [SEP]
========================
predicted: 
========================
[CLS] during hours were was the apparently unidentified victim. the unidentified struck [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 84.615 | r: 84.615
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 46.154 | p: 46.154 | r: 46.154
rougeLsum  | fm: 46.154 | p: 46.154 | r: 46.154
r1fm+r2fm = 101.282

[Aggregate metrics]:
rouge1     | fm: 85.303 | p: 84.854 | r: 85.938
rouge2     | fm: 40.707 | p: 40.327 | r: 41.239
rougeL     | fm: 70.119 | p: 69.654 | r: 70.625
rougeLsum  | fm: 70.582 | p: 70.011 | r: 71.024
r1fm+r2fm = 126.010

input #9 time: 0:08:31 | total time: 1:24:45


Running input #10 of 100.
reference: 
========================
the logs piled the barge high.
========================
average of cosine similarity 0.9992999377037376
highest_index [0]
highest [0.9992999377037376]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996, 15664, 17835,  1996, 19398,  2152,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the logs piled the barge high. [SEP]']
[Init] best rec loss: 1.4807376861572266 for ['[CLS] my honey queensus suchbble [CLS] [SEP]']
[Init] best rec loss: 1.2647329568862915 for ['[CLS] shots acheron outsider associations seed an using [SEP]']
[Init] best rec loss: 1.0237147808074951 for ['[CLS] papua sorrow arden [MASK] provides sidri [SEP]']
[Init] best rec loss: 1.0180096626281738 for ['[CLS] cueloudition joan kettle russ lucy [SEP]']
[Init] best rec loss: 0.8237629532814026 for ['[CLS] excellence stationary bread otherwise heel least least [SEP]']
[Init] best perm rec loss: 0.7967236042022705 for ['[CLS] least otherwise heel excellence stationary bread least [SEP]']
[Init] best perm rec loss: 0.795767068862915 for ['[CLS] least stationary excellence least heel otherwise bread [SEP]']
[Init] best perm rec loss: 0.7945294380187988 for ['[CLS] least otherwise least excellence heel stationary bread [SEP]']
[Init] best perm rec loss: 0.7930511236190796 for ['[CLS] least otherwise stationary least heel excellence bread [SEP]']
[Init] best perm rec loss: 0.79271399974823 for ['[CLS] least otherwise heel least bread excellence stationary [SEP]']
[Init] best perm rec loss: 0.791594386100769 for ['[CLS] least excellence least otherwise bread heel stationary [SEP]']
[Init] best perm rec loss: 0.7894934415817261 for ['[CLS] otherwise least least bread excellence heel stationary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.943 (perp=13.217, rec=0.282, cos=0.018), tot_loss_proj:3.706 [t=0.19s]
prediction: ['[CLS] piled highways establishments bearer. typhoon piled [SEP]']
[ 100/2000] tot_loss=2.606 (perp=11.964, rec=0.201, cos=0.012), tot_loss_proj:3.506 [t=0.19s]
prediction: ['[CLS] piled piled establishments barge. piled logs [SEP]']
[ 150/2000] tot_loss=2.345 (perp=10.803, rec=0.175, cos=0.009), tot_loss_proj:3.452 [t=0.18s]
prediction: ['[CLS] piled logs piled barge. high logs [SEP]']
[ 200/2000] tot_loss=2.126 (perp=10.062, rec=0.108, cos=0.005), tot_loss_proj:3.069 [t=0.18s]
prediction: ['[CLS] piled the low barge. high logs [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.140 (perp=9.479, rec=0.232, cos=0.013), tot_loss_proj:2.494 [t=0.24s]
prediction: ['[CLS] the piled the barge. high logs [SEP]']
[ 300/2000] tot_loss=2.027 (perp=9.479, rec=0.126, cos=0.005), tot_loss_proj:2.514 [t=0.23s]
prediction: ['[CLS] the piled the barge. high logs [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.949 (perp=9.172, rec=0.110, cos=0.004), tot_loss_proj:2.621 [t=0.18s]
prediction: ['[CLS] the piled the barge logs high, [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.760 (perp=8.273, rec=0.101, cos=0.004), tot_loss_proj:1.802 [t=0.23s]
prediction: ['[CLS] the logs piled the barge high, [SEP]']
[ 450/2000] tot_loss=1.731 (perp=8.273, rec=0.073, cos=0.003), tot_loss_proj:1.812 [t=0.18s]
prediction: ['[CLS] the logs piled the barge high, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.650 (perp=7.811, rec=0.084, cos=0.003), tot_loss_proj:1.660 [t=0.27s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.644 (perp=7.811, rec=0.078, cos=0.003), tot_loss_proj:1.647 [t=0.21s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
[ 600/2000] tot_loss=1.657 (perp=7.811, rec=0.092, cos=0.003), tot_loss_proj:1.660 [t=0.25s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.643 (perp=7.811, rec=0.077, cos=0.003), tot_loss_proj:1.657 [t=0.21s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.643 (perp=7.811, rec=0.078, cos=0.003), tot_loss_proj:1.654 [t=0.19s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
[ 750/2000] tot_loss=1.642 (perp=7.811, rec=0.077, cos=0.003), tot_loss_proj:1.653 [t=0.23s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.646 (perp=7.811, rec=0.081, cos=0.003), tot_loss_proj:1.656 [t=0.19s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.633 (perp=7.811, rec=0.068, cos=0.003), tot_loss_proj:1.661 [t=0.22s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
[ 900/2000] tot_loss=1.642 (perp=7.811, rec=0.076, cos=0.003), tot_loss_proj:1.659 [t=0.21s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.643 (perp=7.811, rec=0.078, cos=0.003), tot_loss_proj:1.667 [t=0.20s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.632 (perp=7.811, rec=0.067, cos=0.003), tot_loss_proj:1.662 [t=0.18s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
[1050/2000] tot_loss=1.645 (perp=7.811, rec=0.080, cos=0.003), tot_loss_proj:1.661 [t=0.19s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.642 (perp=7.811, rec=0.076, cos=0.003), tot_loss_proj:1.657 [t=0.25s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.634 (perp=7.811, rec=0.068, cos=0.003), tot_loss_proj:1.660 [t=0.18s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
[1200/2000] tot_loss=1.633 (perp=7.811, rec=0.068, cos=0.003), tot_loss_proj:1.650 [t=0.24s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.637 (perp=7.811, rec=0.071, cos=0.003), tot_loss_proj:1.669 [t=0.22s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.637 (perp=7.811, rec=0.072, cos=0.003), tot_loss_proj:1.660 [t=0.18s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
[1350/2000] tot_loss=1.635 (perp=7.811, rec=0.070, cos=0.003), tot_loss_proj:1.651 [t=0.18s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.635 (perp=7.811, rec=0.069, cos=0.003), tot_loss_proj:1.661 [t=0.18s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.645 (perp=7.811, rec=0.079, cos=0.003), tot_loss_proj:1.654 [t=0.26s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
[1500/2000] tot_loss=1.639 (perp=7.811, rec=0.074, cos=0.003), tot_loss_proj:1.662 [t=0.29s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.644 (perp=7.811, rec=0.078, cos=0.003), tot_loss_proj:1.657 [t=0.29s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.648 (perp=7.811, rec=0.083, cos=0.003), tot_loss_proj:1.661 [t=0.19s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
[1650/2000] tot_loss=1.644 (perp=7.811, rec=0.079, cos=0.003), tot_loss_proj:1.661 [t=0.17s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.648 (perp=7.811, rec=0.083, cos=0.003), tot_loss_proj:1.659 [t=0.18s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.639 (perp=7.811, rec=0.073, cos=0.003), tot_loss_proj:1.656 [t=0.19s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
[1800/2000] tot_loss=1.639 (perp=7.811, rec=0.074, cos=0.003), tot_loss_proj:1.668 [t=0.18s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.641 (perp=7.811, rec=0.075, cos=0.003), tot_loss_proj:1.673 [t=0.19s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.644 (perp=7.811, rec=0.079, cos=0.003), tot_loss_proj:1.648 [t=0.20s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
[1950/2000] tot_loss=1.639 (perp=7.811, rec=0.073, cos=0.003), tot_loss_proj:1.655 [t=0.18s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.646 (perp=7.811, rec=0.081, cos=0.003), tot_loss_proj:1.651 [t=0.18s]
prediction: ['[CLS] the logs piled the barge high. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] the logs piled the barge high. [SEP]
========================
predicted: 
========================
[CLS] the logs piled the barge high. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.867 | p: 86.192 | r: 87.490
rouge2     | fm: 46.720 | p: 46.528 | r: 47.006
rougeL     | fm: 73.099 | p: 72.714 | r: 73.608
rougeLsum  | fm: 73.387 | p: 72.890 | r: 73.845
r1fm+r2fm = 133.587

input #10 time: 0:08:30 | total time: 1:33:15


Running input #11 of 100.
reference: 
========================
During the early evening, Saturn can be found in the north, while Jupiter rises in the east.
========================
average of cosine similarity 0.9993928571086103
highest_index [0]
highest [0.9993928571086103]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2076,  1996,  2220,  3944,  1010, 14784,  2064,  2022,  2179,
          1999,  1996,  2167,  1010,  2096, 13035,  9466,  1999,  1996,  2264,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]']
[Init] best rec loss: 1.9073803424835205 for ['[CLS] triedya radcliffe whitney pepper since only ranges beingshibreaker sharedpower kn bn nest o day you detention [SEP]']
[Init] best rec loss: 1.8852497339248657 for ['[CLS] degreess become panted eric like there ⟩nt obeyed gwen supernatural living mexicanard consider launch due griffin block [SEP]']
[Init] best rec loss: 1.856112003326416 for ['[CLS] snail order rapidyl arnoldæ bothtteringtablished building healthт theory august essay inaugural gold gay hayes phone [SEP]']
[Init] best rec loss: 1.8239604234695435 for ['[CLS] brands anyway society m founding \\ whichptive dating pop vol days contraction planes moses cooling... scrap warning just [SEP]']
[Init] best rec loss: 1.8196566104888916 for ['[CLS]dim da informal chessen balloon belgianttal qualified maniucheong past rust explosion descent series grace pack hospital [SEP]']
[Init] best rec loss: 1.8096710443496704 for ['[CLS] rose dismissed request governorly elle scale television former punk reflect both previously celia bank farm secret issueyn captain [SEP]']
[Init] best rec loss: 1.7994128465652466 for ['[CLS] how format behind tram mid off afb davechang binding shipbuildinglent co₂ events artwork cross powerfulyn transport ski [SEP]']
[Init] best perm rec loss: 1.7982319593429565 for ['[CLS] behind co₂ events tramlent dave crosschang shipbuilding binding transport artwork afb mid format powerfulyn how ski off [SEP]']
[Init] best perm rec loss: 1.7951405048370361 for ['[CLS] how co₂ events powerfulyn behind mid shipbuilding ski artwork binding afb davelent transport off formatchang cross tram [SEP]']
[Init] best perm rec loss: 1.7937742471694946 for ['[CLS]lent mid behind offyn bindingchang format dave shipbuilding afb how transport cross artwork events co₂ ski tram powerful [SEP]']
[Init] best perm rec loss: 1.7932608127593994 for ['[CLS]yn cross binding powerful artwork ski afb behind mid dave eventslent off tram co₂ shipbuilding transportchang format how [SEP]']
[Init] best perm rec loss: 1.7932302951812744 for ['[CLS] events format powerful shipbuildingchangyn dave mid transport tram cross behind off ski binding co₂ how artwork afblent [SEP]']
[Init] best perm rec loss: 1.79204523563385 for ['[CLS] dave behindyn powerful mid tram format co₂ artwork ski transport cross binding off events afbchanglent how shipbuilding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.782 (perp=11.024, rec=0.578, cos=0.999), tot_loss_proj:4.048 [t=0.25s]
prediction: ['[CLS] your when like george your.! electors brink.. armed continue stars. suppose expression pressure chief fighter [SEP]']
[ 100/2000] tot_loss=3.599 (perp=10.574, rec=0.487, cos=0.997), tot_loss_proj:3.935 [t=0.18s]
prediction: ['[CLS] in north fool jupiter titan the? shall rei.. open easy within. occurza pressure jupiter fighter [SEP]']
[ 150/2000] tot_loss=3.577 (perp=10.697, rec=0.439, cos=0.999), tot_loss_proj:4.012 [t=0.19s]
prediction: ['[CLS] during north did jupiter jupiter the?nius rei..going easy saturn. the remedy pressure jupiter fighter [SEP]']
[ 200/2000] tot_loss=3.461 (perp=10.262, rec=0.408, cos=1.000), tot_loss_proj:3.880 [t=0.24s]
prediction: ['[CLS] during north did jupiter jupiter the!nius known..going bearing saturn. the services ground jupiter fighter [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.334 (perp=9.659, rec=0.402, cos=1.000), tot_loss_proj:3.800 [t=0.19s]
prediction: ['[CLS] during north did! jupiter the jupiter evening south.. prey bearing saturn during the services ground jupiter development [SEP]']
[ 300/2000] tot_loss=4.027 (perp=11.961, rec=0.636, cos=0.999), tot_loss_proj:4.234 [t=0.26s]
prediction: ['[CLS] concerning north rus arrived evening the jupiter afternoon such in noctuidae offensive oclc days from have morning press jupiterni [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.735 (perp=11.300, rec=0.475, cos=1.000), tot_loss_proj:4.103 [t=0.22s]
prediction: ['[CLS] during north jupiter arrived evening never jupiter afternoon north in. economic ( days fromky in 1st did ( [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.596 (perp=10.796, rec=0.437, cos=1.000), tot_loss_proj:4.017 [t=0.23s]
prediction: ['[CLS] during north jupiter ; evening strongly saturn afternoon north in. septembersters days fromky in erroneously → ( [SEP]']
[ 450/2000] tot_loss=3.523 (perp=10.493, rec=0.425, cos=1.000), tot_loss_proj:3.969 [t=0.18s]
prediction: ['[CLS] during east jupiter ; evening strongly saturn evening the in. september morning days fromky in erroneously → formation [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.558 (perp=10.425, rec=0.473, cos=1.000), tot_loss_proj:3.909 [t=0.18s]
prediction: ['[CLS] during broadly saturn morning generally : saturn evening ar filmfare. september in from fromky inperation does - [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.439 (perp=10.029, rec=0.433, cos=1.000), tot_loss_proj:3.786 [t=0.25s]
prediction: ['[CLS] during broadly saturn evening generally habits saturn evening september when. because in days fromky inperation does - [SEP]']
[ 600/2000] tot_loss=3.635 (perp=11.110, rec=0.414, cos=1.000), tot_loss_proj:4.020 [t=0.23s]
prediction: ['[CLS] during broadly saturn evening generally forewings saturn evening september when. because in days from have inperation does - [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.425 (perp=10.133, rec=0.399, cos=1.000), tot_loss_proj:3.829 [t=0.25s]
prediction: ['[CLS] during reviews saturn evening generally - saturn evening september easily. because in days from have inperation does forewings [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.548 (perp=10.786, rec=0.392, cos=1.000), tot_loss_proj:3.989 [t=0.19s]
prediction: ['[CLS] during reviews saturn evening historically - saturn evening september easily. because in days ª the in from does forewings [SEP]']
[ 750/2000] tot_loss=3.582 (perp=11.011, rec=0.380, cos=1.000), tot_loss_proj:4.041 [t=0.18s]
prediction: ['[CLS] during reviews saturn evening historically - saturn evening september easily. because eve days ª the in from does forewings [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.491 (perp=10.572, rec=0.377, cos=1.000), tot_loss_proj:3.941 [t=0.19s]
prediction: ['[CLS] does reviews saturn evening historically - saturn evening september easily. because eve days ª the in from during forewings [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.407 (perp=10.068, rec=0.394, cos=1.000), tot_loss_proj:3.850 [t=0.23s]
prediction: ['[CLS] does reviews saturn evening sharply from saturn evening september easily. because eve days ª the in - during forewings [SEP]']
[ 900/2000] tot_loss=3.399 (perp=10.147, rec=0.369, cos=1.000), tot_loss_proj:3.856 [t=0.18s]
prediction: ['[CLS] does reviews saturn evening commonly from saturn evening september easily. because eve days ª the in - during forewings [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.357 (perp=9.957, rec=0.366, cos=1.000), tot_loss_proj:3.814 [t=0.18s]
prediction: ['[CLS] does reviews saturn evening from commonly saturn evening september easily. because eve days ª the in - during forewings [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.408 (perp=10.090, rec=0.391, cos=1.000), tot_loss_proj:3.880 [t=0.19s]
prediction: ['[CLS] the reviews saturn evening from commonly saturn evening september easily. because days eve ª the in - during } [SEP]']
[1050/2000] tot_loss=3.399 (perp=10.142, rec=0.371, cos=1.000), tot_loss_proj:3.860 [t=0.19s]
prediction: ['[CLS] the reviews saturn evening from traditionally saturn evening september easily. because days eve hurdles the in - during forewings [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.352 (perp=9.944, rec=0.363, cos=1.000), tot_loss_proj:3.814 [t=0.18s]
prediction: ['[CLS] during reviews saturn evening from traditionally saturn evening september easily. because days eve hurdles the in - the forewings [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.338 (perp=9.869, rec=0.364, cos=1.000), tot_loss_proj:3.852 [t=0.18s]
prediction: ['[CLS] during evening saturn evening from traditionally saturn reviews discus easily. because evening eve hurdles the in - the forewings [SEP]']
[1200/2000] tot_loss=3.377 (perp=10.069, rec=0.364, cos=1.000), tot_loss_proj:3.871 [t=0.23s]
prediction: ['[CLS] during evening saturn evening from during saturn ª discus easily. because evening eve hurdles the in - the forewings [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.292 (perp=9.658, rec=0.361, cos=1.000), tot_loss_proj:3.787 [t=0.22s]
prediction: ['[CLS] during evening saturn evening from commonly saturn ª discus easily. because the eve hurdles evening in - the forewings [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=3.270 (perp=9.554, rec=0.360, cos=1.000), tot_loss_proj:3.758 [t=0.18s]
prediction: ['[CLS] during evening saturn evening from commonly saturn ª discus easily. because the eve hurdles in evening - the powerplant [SEP]']
[1350/2000] tot_loss=3.270 (perp=9.554, rec=0.360, cos=1.000), tot_loss_proj:3.757 [t=0.23s]
prediction: ['[CLS] during evening saturn evening from commonly saturn ª discus easily. because the eve hurdles in evening - the powerplant [SEP]']
Attempt swap
[1400/2000] tot_loss=3.266 (perp=9.540, rec=0.358, cos=1.000), tot_loss_proj:3.791 [t=0.19s]
prediction: ['[CLS] during evening saturn eveningly during saturn ª discus easily. because the eve hurdles in evening - the powerplant [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=3.250 (perp=9.433, rec=0.364, cos=1.000), tot_loss_proj:3.794 [t=0.18s]
prediction: ['[CLS] during evening saturn eveningly commonly evening ª discus easily. because the eve hurdles in saturn - the powerplant [SEP]']
[1500/2000] tot_loss=3.124 (perp=8.855, rec=0.354, cos=1.000), tot_loss_proj:3.667 [t=0.23s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the eve hurdles in saturn - the powerplant [SEP]']
Attempt swap
[1550/2000] tot_loss=3.124 (perp=8.855, rec=0.353, cos=1.000), tot_loss_proj:3.665 [t=0.25s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the eve hurdles in saturn - the powerplant [SEP]']
Attempt swap
[1600/2000] tot_loss=3.114 (perp=8.807, rec=0.352, cos=1.000), tot_loss_proj:3.670 [t=0.23s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the north hurdles in saturn - the powerplant [SEP]']
[1650/2000] tot_loss=3.120 (perp=8.807, rec=0.358, cos=1.000), tot_loss_proj:3.669 [t=0.20s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the north hurdles in saturn - the powerplant [SEP]']
Attempt swap
[1700/2000] tot_loss=3.108 (perp=8.807, rec=0.346, cos=1.000), tot_loss_proj:3.671 [t=0.24s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the north hurdles in saturn - the powerplant [SEP]']
Attempt swap
[1750/2000] tot_loss=3.108 (perp=8.807, rec=0.347, cos=1.000), tot_loss_proj:3.669 [t=0.19s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the north hurdles in saturn - the powerplant [SEP]']
[1800/2000] tot_loss=3.109 (perp=8.807, rec=0.348, cos=1.000), tot_loss_proj:3.670 [t=0.19s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the north hurdles in saturn - the powerplant [SEP]']
Attempt swap
[1850/2000] tot_loss=3.117 (perp=8.807, rec=0.356, cos=1.000), tot_loss_proj:3.664 [t=0.28s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the north hurdles in saturn - the powerplant [SEP]']
Attempt swap
[1900/2000] tot_loss=3.107 (perp=8.807, rec=0.346, cos=1.000), tot_loss_proj:3.671 [t=0.18s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the north hurdles in saturn - the powerplant [SEP]']
[1950/2000] tot_loss=3.111 (perp=8.807, rec=0.350, cos=1.000), tot_loss_proj:3.668 [t=0.23s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the north hurdles in saturn - the powerplant [SEP]']
Attempt swap
[2000/2000] tot_loss=3.111 (perp=8.807, rec=0.350, cos=1.000), tot_loss_proj:3.668 [t=0.27s]
prediction: ['[CLS] during evening saturn eveningly during evening ª discus easily. because the north hurdles in saturn - the powerplant [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] during the early evening, saturn can be found in the north, while jupiter rises in the east. [SEP]
========================
predicted: 
========================
[CLS] during evening saturn eveningly during evening ª discus easily. because the north hurdles in saturn - the powerplant [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.649 | p: 50.000 | r: 47.368
rouge2     | fm: 17.143 | p: 17.647 | r: 16.667
rougeL     | fm: 48.649 | p: 50.000 | r: 47.368
rougeLsum  | fm: 48.649 | p: 50.000 | r: 47.368
r1fm+r2fm = 65.792

[Aggregate metrics]:
rouge1     | fm: 83.568 | p: 83.378 | r: 83.912
rouge2     | fm: 44.141 | p: 43.806 | r: 44.327
rougeL     | fm: 70.719 | p: 70.153 | r: 70.977
rougeLsum  | fm: 71.307 | p: 70.988 | r: 71.872
r1fm+r2fm = 127.709

input #11 time: 0:08:27 | total time: 1:41:42


Running input #12 of 100.
reference: 
========================
He walked up the hill.
========================
average of cosine similarity 0.9993584436723262
highest_index [0]
highest [0.9993584436723262]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2002, 2939, 2039, 1996, 2940, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he walked up the hill. [SEP]']
[Init] best rec loss: 1.9859498739242554 for ['[CLS] stars sans january canvas gdansk beauty [SEP]']
[Init] best rec loss: 1.85741126537323 for ['[CLS]thevert banks councillors respective puerto [SEP]']
[Init] best rec loss: 1.7674667835235596 for ['[CLS] articles gin keen monster plot baldwin [SEP]']
[Init] best rec loss: 1.7430577278137207 for ['[CLS] residence [SEP] stationfus full cds [SEP]']
[Init] best rec loss: 1.7401072978973389 for ['[CLS]ound laptail conference charge honored [SEP]']
[Init] best rec loss: 1.7192918062210083 for ['[CLS]meral arrondissement repairunce trent next [SEP]']
[Init] best perm rec loss: 1.717777132987976 for ['[CLS] arrondissementunce next repair trentmeral [SEP]']
[Init] best perm rec loss: 1.7145639657974243 for ['[CLS] arrondissementunce trent repair nextmeral [SEP]']
[Init] best perm rec loss: 1.714105486869812 for ['[CLS]unce trent arrondissement repair nextmeral [SEP]']
[Init] best perm rec loss: 1.7136735916137695 for ['[CLS] repair arrondissementunce trentmeral next [SEP]']
[Init] best perm rec loss: 1.7133811712265015 for ['[CLS] trent arrondissementunce repair nextmeral [SEP]']
[Init] best perm rec loss: 1.7127453088760376 for ['[CLS] next arrondissement repair trentuncemeral [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.696 (perp=10.271, rec=0.668, cos=0.974), tot_loss_proj:3.861 [t=0.18s]
prediction: ['[CLS] children lift hill ; worker brought [SEP]']
[ 100/2000] tot_loss=1.912 (perp=8.280, rec=0.230, cos=0.027), tot_loss_proj:3.650 [t=0.18s]
prediction: ['[CLS] he walked hill. hill up [SEP]']
[ 150/2000] tot_loss=1.828 (perp=8.280, rec=0.157, cos=0.014), tot_loss_proj:3.644 [t=0.18s]
prediction: ['[CLS] he walked hill. hill up [SEP]']
[ 200/2000] tot_loss=1.818 (perp=8.280, rec=0.151, cos=0.012), tot_loss_proj:3.648 [t=0.18s]
prediction: ['[CLS] he walked hill. hill up [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.676 (perp=7.131, rec=0.232, cos=0.018), tot_loss_proj:3.461 [t=0.19s]
prediction: ['[CLS] he walked hill naked today. [SEP]']
[ 300/2000] tot_loss=1.576 (perp=7.101, rec=0.148, cos=0.008), tot_loss_proj:3.261 [t=0.18s]
prediction: ['[CLS] he walked hill asleep upstairs. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.688 (perp=7.704, rec=0.141, cos=0.006), tot_loss_proj:3.563 [t=0.25s]
prediction: ['[CLS] he walked hill away today. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.589 (perp=7.267, rec=0.130, cos=0.006), tot_loss_proj:3.241 [t=0.21s]
prediction: ['[CLS] he walked hill today away. [SEP]']
[ 450/2000] tot_loss=1.590 (perp=7.267, rec=0.131, cos=0.006), tot_loss_proj:3.233 [t=0.18s]
prediction: ['[CLS] he walked hill today away. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.591 (perp=7.267, rec=0.132, cos=0.006), tot_loss_proj:3.233 [t=0.20s]
prediction: ['[CLS] he walked hill today away. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.590 (perp=7.267, rec=0.131, cos=0.006), tot_loss_proj:3.237 [t=0.19s]
prediction: ['[CLS] he walked hill today away. [SEP]']
[ 600/2000] tot_loss=1.583 (perp=7.267, rec=0.124, cos=0.006), tot_loss_proj:3.235 [t=0.24s]
prediction: ['[CLS] he walked hill today away. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.587 (perp=7.267, rec=0.128, cos=0.006), tot_loss_proj:3.230 [t=0.19s]
prediction: ['[CLS] he walked hill today away. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.588 (perp=7.267, rec=0.129, cos=0.005), tot_loss_proj:3.228 [t=0.23s]
prediction: ['[CLS] he walked hill today away. [SEP]']
[ 750/2000] tot_loss=1.624 (perp=7.435, rec=0.132, cos=0.005), tot_loss_proj:3.155 [t=0.18s]
prediction: ['[CLS] he walked hill today up. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.618 (perp=7.435, rec=0.125, cos=0.005), tot_loss_proj:3.155 [t=0.22s]
prediction: ['[CLS] he walked hill today up. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.526 (perp=6.909, rec=0.137, cos=0.006), tot_loss_proj:3.300 [t=0.18s]
prediction: ['[CLS] he walked hill up today. [SEP]']
[ 900/2000] tot_loss=1.514 (perp=6.909, rec=0.127, cos=0.005), tot_loss_proj:3.295 [t=0.19s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.512 (perp=6.909, rec=0.125, cos=0.005), tot_loss_proj:3.289 [t=0.18s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.505 (perp=6.909, rec=0.118, cos=0.005), tot_loss_proj:3.290 [t=0.30s]
prediction: ['[CLS] he walked hill up today. [SEP]']
[1050/2000] tot_loss=1.504 (perp=6.909, rec=0.117, cos=0.005), tot_loss_proj:3.291 [t=0.22s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.503 (perp=6.909, rec=0.116, cos=0.005), tot_loss_proj:3.286 [t=0.23s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.515 (perp=6.909, rec=0.128, cos=0.005), tot_loss_proj:3.292 [t=0.18s]
prediction: ['[CLS] he walked hill up today. [SEP]']
[1200/2000] tot_loss=1.514 (perp=6.909, rec=0.126, cos=0.005), tot_loss_proj:3.288 [t=0.18s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.505 (perp=6.909, rec=0.118, cos=0.005), tot_loss_proj:3.291 [t=0.19s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.516 (perp=6.909, rec=0.129, cos=0.005), tot_loss_proj:3.293 [t=0.19s]
prediction: ['[CLS] he walked hill up today. [SEP]']
[1350/2000] tot_loss=1.512 (perp=6.909, rec=0.125, cos=0.005), tot_loss_proj:3.293 [t=0.18s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.511 (perp=6.909, rec=0.124, cos=0.005), tot_loss_proj:3.295 [t=0.21s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.511 (perp=6.909, rec=0.124, cos=0.005), tot_loss_proj:3.291 [t=0.22s]
prediction: ['[CLS] he walked hill up today. [SEP]']
[1500/2000] tot_loss=1.513 (perp=6.909, rec=0.126, cos=0.005), tot_loss_proj:3.289 [t=0.18s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.507 (perp=6.909, rec=0.120, cos=0.005), tot_loss_proj:3.292 [t=0.22s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.511 (perp=6.909, rec=0.124, cos=0.005), tot_loss_proj:3.288 [t=0.18s]
prediction: ['[CLS] he walked hill up today. [SEP]']
[1650/2000] tot_loss=1.512 (perp=6.909, rec=0.125, cos=0.005), tot_loss_proj:3.289 [t=0.20s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.510 (perp=6.909, rec=0.123, cos=0.005), tot_loss_proj:3.291 [t=0.24s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.504 (perp=6.909, rec=0.117, cos=0.005), tot_loss_proj:3.290 [t=0.18s]
prediction: ['[CLS] he walked hill up today. [SEP]']
[1800/2000] tot_loss=1.509 (perp=6.909, rec=0.122, cos=0.005), tot_loss_proj:3.294 [t=0.18s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.500 (perp=6.909, rec=0.113, cos=0.005), tot_loss_proj:3.293 [t=0.26s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.505 (perp=6.909, rec=0.118, cos=0.005), tot_loss_proj:3.294 [t=0.19s]
prediction: ['[CLS] he walked hill up today. [SEP]']
[1950/2000] tot_loss=1.518 (perp=6.909, rec=0.131, cos=0.005), tot_loss_proj:3.293 [t=0.18s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.506 (perp=6.909, rec=0.119, cos=0.005), tot_loss_proj:3.292 [t=0.24s]
prediction: ['[CLS] he walked hill up today. [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] he walked up the hill. [SEP]
========================
predicted: 
========================
[CLS] he walked hill up today. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 119.048

[Aggregate metrics]:
rouge1     | fm: 83.665 | p: 83.375 | r: 83.992
rouge2     | fm: 43.193 | p: 42.891 | r: 43.389
rougeL     | fm: 70.880 | p: 70.624 | r: 71.298
rougeLsum  | fm: 71.066 | p: 70.888 | r: 71.453
r1fm+r2fm = 126.858

input #12 time: 0:08:18 | total time: 1:50:01


Running input #13 of 100.
reference: 
========================
It is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters.
========================
average of cosine similarity 0.9993068673747104
highest_index [0]
highest [0.9993068673747104]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2009,  2003,  2023,  3291,  2008,  1996, 10076,  2017,  9611,
          1996,  2062,  4089,  2017,  1005,  2222, 13225,  1996, 12455,  2039,
          2012,  5971,  4075,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]"]
[Init] best rec loss: 1.9335592985153198 for ['[CLS] id brand fault sciences treated allows american person perceive directions alleyulating pentagonette modern declaration material devoid having participation artistic ricardooration [SEP]']
[Init] best rec loss: 1.8713160753250122 for ['[CLS] independenternussnor beat shelley pattierty better newspapers chanceocation customsdi broke nolanrona tennesseeed drummer worked analog nap [SEP]']
[Init] best rec loss: 1.8637337684631348 for ['[CLS] black sox eric concordia guy manual separate belgium su markings exhaled below use equality winterenburgchio program pike wedge note reality leon [SEP]']
[Init] best perm rec loss: 1.861586093902588 for ['[CLS] guy reality markings belgiumenburg pike below leon winter black use exhaledchio equality concordia wedge manual separate eric sox note su program [SEP]']
[Init] best perm rec loss: 1.8603471517562866 for ['[CLS] separate sox equality reality belgium leonenburg use wedge guy concordia su black eric manual note pike winter markingschio below exhaled program [SEP]']
[Init] best perm rec loss: 1.8592904806137085 for ['[CLS] program winter manualchio eric leonenburg below wedge black note sox guy separate use belgium exhaled concordia su equality markings pike reality [SEP]']
[Init] best perm rec loss: 1.858208179473877 for ['[CLS] use wedge concordia below manual separate black sox equality markings exhaled note su winter program eric pike guyenburgchio leon reality belgium [SEP]']
[Init] best perm rec loss: 1.855011224746704 for ['[CLS] su exhaled reality below manual wedge pike program leon black sox separate markings note ericenburg guy concordiachio equality belgium winter use [SEP]']
[Init] best perm rec loss: 1.8541884422302246 for ['[CLS] winter manual concordia soxchio markings exhaled program black wedge below eric su realityenburg use note pike equality guy belgium separate leon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.884 (perp=11.972, rec=0.394, cos=0.095), tot_loss_proj:4.326 [t=0.19s]
prediction: ['[CLS] first vo 6 james, dragon smile bounty black thinking metres and warrior tonic spec advantage learned chance shotgun over t august characters [SEP]']
[ 100/2000] tot_loss=3.136 (perp=13.138, rec=0.403, cos=0.105), tot_loss_proj:4.553 [t=0.20s]
prediction: ['[CLS] task john tonight james. dragon ached enjoyyk thinkingzong hard dimitri solutions wrong advantage anniversary your fairy over t economic featured [SEP]']
[ 150/2000] tot_loss=2.381 (perp=10.303, rec=0.291, cos=0.029), tot_loss_proj:4.018 [t=0.19s]
prediction: ['[CLS] task your tonight corporate. a rex safer the this anyway need skin your your folks forgot your shotgun over away political event [SEP]']
[ 200/2000] tot_loss=2.495 (perp=10.775, rec=0.300, cos=0.040), tot_loss_proj:4.108 [t=0.19s]
prediction: ['[CLS] application # ♥ corporate. magic dioxide sooner purple offer folks understand gallery the should folks your your mind over. the crowd [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.474 (perp=10.852, rec=0.275, cos=0.029), tot_loss_proj:4.137 [t=0.30s]
prediction: ['[CLS] inform this ♥ corporate task magic dioxide sooner super. folks solve grove the we folks your you mind around. the folks [SEP]']
[ 300/2000] tot_loss=2.778 (perp=11.810, rec=0.341, cos=0.075), tot_loss_proj:4.305 [t=0.28s]
prediction: ['[CLS] equations this 我 corporate its magic aires sooner about. expedition votes your your we folks reviewer of shotgun back corporation many [ [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.410 (perp=10.581, rec=0.267, cos=0.027), tot_loss_proj:4.030 [t=0.25s]
prediction: ['[CLS] # this this corporate thelous understand sooner about your expedition easily your. we folks certificate at shotgun back corporation folks ] [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.374 (perp=10.367, rec=0.270, cos=0.030), tot_loss_proj:4.034 [t=0.18s]
prediction: ['[CLS] # this this. thelous understand sooner about your expedition easily your corporate we folks certificate at folks around corporate folks ] [SEP]']
[ 450/2000] tot_loss=2.412 (perp=10.803, rec=0.235, cos=0.017), tot_loss_proj:4.107 [t=0.25s]
prediction: ['[CLS] # this this. thelous understand sooner a your solve easily your corporate we folks certificate at folks around corporate folks ] [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.261 (perp=10.190, rec=0.210, cos=0.014), tot_loss_proj:3.979 [t=0.19s]
prediction: ['[CLS] # this this. thelous understand sooner a you folks easily your corporate we solve certificate at folks up corporate folks ] [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.053 (perp=9.155, rec=0.210, cos=0.012), tot_loss_proj:3.792 [t=0.26s]
prediction: ['[CLS] is this this. thelous understand sooner " you corporate folks solve your the solve certificate at folks up corporate folks ] [SEP]']
[ 600/2000] tot_loss=1.958 (perp=8.728, rec=0.203, cos=0.010), tot_loss_proj:3.712 [t=0.20s]
prediction: ['[CLS] is this this. the the understand sooner " you corporate folks solve your the solve certificate at folks up corporate folks ] [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.086 (perp=9.409, rec=0.194, cos=0.010), tot_loss_proj:3.800 [t=0.25s]
prediction: ['[CLS] is this this. problem the understand sooner a you corporate folks your solve the satisfy certificate at folks up corporate folks ] [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.929 (perp=8.729, rec=0.175, cos=0.008), tot_loss_proj:3.668 [t=0.19s]
prediction: ['[CLS] is this this problem. the understand sooner a you corporate folks your solve the solve certificate at folks up corporate folks cooking [SEP]']
[ 750/2000] tot_loss=1.904 (perp=8.619, rec=0.173, cos=0.008), tot_loss_proj:3.640 [t=0.21s]
prediction: ['[CLS] is this this problem. the understand sooner the you corporate folks your solve the solve certificate at folks up corporate folks ] [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.843 (perp=8.297, rec=0.176, cos=0.008), tot_loss_proj:3.566 [t=0.22s]
prediction: ['[CLS] is this this problem. the understand the sooner you corporate folks your solve the solve certificate at folks up corporate folks ] [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.852 (perp=8.354, rec=0.173, cos=0.008), tot_loss_proj:3.573 [t=0.19s]
prediction: ['[CLS] is this is problem. the understand the sooner you corporate folks your solve the solve certificate at folks up corporate folks ] [SEP]']
[ 900/2000] tot_loss=1.901 (perp=8.594, rec=0.174, cos=0.008), tot_loss_proj:3.619 [t=0.18s]
prediction: ['[CLS] is this is problem. the understand the sooner you corporate folks your solve the solve certificate at folks up corporate folks requirements [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.856 (perp=8.462, rec=0.156, cos=0.008), tot_loss_proj:3.600 [t=0.23s]
prediction: ['[CLS] is this is problem. the understand the sooner you corporate folks your solve the solve certificate at folks up corporate folks needs [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.831 (perp=8.311, rec=0.160, cos=0.009), tot_loss_proj:3.571 [t=0.29s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve certificate at folks up corporate folks needs [SEP]']
[1050/2000] tot_loss=1.798 (perp=8.179, rec=0.155, cos=0.008), tot_loss_proj:3.542 [t=0.27s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve certificate of folks up corporate folks needs [SEP]']
Attempt swap
[1100/2000] tot_loss=1.842 (perp=8.395, rec=0.156, cos=0.007), tot_loss_proj:3.581 [t=0.19s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve ll of folks up corporate folks needs [SEP]']
Attempt swap
[1150/2000] tot_loss=1.828 (perp=8.395, rec=0.142, cos=0.007), tot_loss_proj:3.582 [t=0.18s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve ll of folks up corporate folks needs [SEP]']
[1200/2000] tot_loss=1.840 (perp=8.395, rec=0.154, cos=0.007), tot_loss_proj:3.585 [t=0.18s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve ll of folks up corporate folks needs [SEP]']
Attempt swap
[1250/2000] tot_loss=1.831 (perp=8.395, rec=0.146, cos=0.007), tot_loss_proj:3.580 [t=0.18s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve ll of folks up corporate folks needs [SEP]']
Attempt swap
[1300/2000] tot_loss=1.835 (perp=8.395, rec=0.149, cos=0.007), tot_loss_proj:3.586 [t=0.18s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve ll of folks up corporate folks needs [SEP]']
[1350/2000] tot_loss=1.829 (perp=8.395, rec=0.144, cos=0.006), tot_loss_proj:3.579 [t=0.22s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve ll of folks up corporate folks needs [SEP]']
Attempt swap
[1400/2000] tot_loss=1.816 (perp=8.395, rec=0.130, cos=0.006), tot_loss_proj:3.578 [t=0.19s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve ll of folks up corporate folks needs [SEP]']
Attempt swap
[1450/2000] tot_loss=1.819 (perp=8.395, rec=0.134, cos=0.006), tot_loss_proj:3.583 [t=0.19s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve ll of folks up corporate folks needs [SEP]']
[1500/2000] tot_loss=1.824 (perp=8.395, rec=0.139, cos=0.006), tot_loss_proj:3.579 [t=0.23s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve the solve ll of folks up corporate folks needs [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.833 (perp=8.422, rec=0.142, cos=0.006), tot_loss_proj:3.643 [t=0.18s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve ll solve the of folks up headquarters folks needs [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.807 (perp=8.323, rec=0.136, cos=0.006), tot_loss_proj:3.607 [t=0.18s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve ll solve the of folks up headquarters needs folks [SEP]']
[1650/2000] tot_loss=1.815 (perp=8.323, rec=0.145, cos=0.006), tot_loss_proj:3.605 [t=0.18s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate folks solve ll solve the of folks up headquarters needs folks [SEP]']
Attempt swap
[1700/2000] tot_loss=1.890 (perp=8.755, rec=0.133, cos=0.006), tot_loss_proj:3.673 [t=0.25s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate satisfy solve ll solve the of folks up headquarters needs folks [SEP]']
Attempt swap
[1750/2000] tot_loss=1.894 (perp=8.755, rec=0.136, cos=0.006), tot_loss_proj:3.675 [t=0.18s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate satisfy solve ll solve the of folks up headquarters needs folks [SEP]']
[1800/2000] tot_loss=1.903 (perp=8.755, rec=0.146, cos=0.006), tot_loss_proj:3.674 [t=0.27s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate satisfy solve ll solve the of folks up headquarters needs folks [SEP]']
Attempt swap
[1850/2000] tot_loss=1.894 (perp=8.755, rec=0.137, cos=0.006), tot_loss_proj:3.672 [t=0.21s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate satisfy solve ll solve the of folks up headquarters needs folks [SEP]']
Attempt swap
[1900/2000] tot_loss=1.845 (perp=8.556, rec=0.128, cos=0.006), tot_loss_proj:3.631 [t=0.27s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate satisfy solve ll solve the more folks up headquarters needs folks [SEP]']
[1950/2000] tot_loss=1.859 (perp=8.556, rec=0.142, cos=0.006), tot_loss_proj:3.628 [t=0.21s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate satisfy solve ll solve the more folks up headquarters needs folks [SEP]']
Attempt swap
[2000/2000] tot_loss=1.857 (perp=8.556, rec=0.140, cos=0.006), tot_loss_proj:3.631 [t=0.18s]
prediction: ['[CLS] is this is problem. the understand the sooner you your corporate satisfy solve ll solve the more folks up headquarters needs folks [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] it is this problem that the sooner you solve the more easily you'll satisfy the folks up at corporate headquarters. [SEP]
========================
predicted: 
========================
[CLS] is this is problem. the understand the sooner you your corporate satisfy solve ll solve the more folks up headquarters needs folks [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.596 | p: 75.000 | r: 78.261
rouge2     | fm: 26.667 | p: 26.087 | r: 27.273
rougeL     | fm: 59.574 | p: 58.333 | r: 60.870
rougeLsum  | fm: 59.574 | p: 58.333 | r: 60.870
r1fm+r2fm = 103.262

[Aggregate metrics]:
rouge1     | fm: 83.087 | p: 82.754 | r: 83.582
rouge2     | fm: 41.958 | p: 41.719 | r: 42.216
rougeL     | fm: 70.077 | p: 69.677 | r: 70.447
rougeLsum  | fm: 70.363 | p: 69.953 | r: 70.750
r1fm+r2fm = 125.044

input #13 time: 0:08:32 | total time: 1:58:33


Running input #14 of 100.
reference: 
========================
Mary has never kissed a man who is taller than John.
========================
average of cosine similarity 0.9993000739577431
highest_index [0]
highest [0.9993000739577431]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2984,  2038,  2196,  4782,  1037,  2158,  2040,  2003, 12283,
          2084,  2198,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mary has never kissed a man who is taller than john. [SEP]']
[Init] best rec loss: 1.8863089084625244 for ['[CLS] isa jude jon force boysraction louise work tip bigger dick sets [SEP]']
[Init] best rec loss: 1.8835545778274536 for ['[CLS] tennessee rat bee shadow quitekarrita ships dates lens hard hamish [SEP]']
[Init] best rec loss: 1.8547275066375732 for ['[CLS]nton integratinglor half inserted al locks cbright family exhibition range [SEP]']
[Init] best rec loss: 1.8501254320144653 for ['[CLS] roads [SEP] period sim decree jennacle tailed japanese operation sacrificed central [SEP]']
[Init] best rec loss: 1.8447027206420898 for ['[CLS] claiming dragon hivmerie pace emersonws bandclass how socialist adult [SEP]']
[Init] best rec loss: 1.836841106414795 for ['[CLS] trackingadt roy says includingureqihand wide shut perite [SEP]']
[Init] best rec loss: 1.8347331285476685 for ['[CLS] leighton net motivation broad they betweencuting boundary jeffersonrry cut pere [SEP]']
[Init] best rec loss: 1.8282880783081055 for ['[CLS] answering french deadmonesh jesus win cain says oh dynasty watershed [SEP]']
[Init] best perm rec loss: 1.8281245231628418 for ['[CLS] oh answering dynastyesh watershed french cainmon jesus dead says win [SEP]']
[Init] best perm rec loss: 1.8279560804367065 for ['[CLS] watershed answering says cain frenchmon jesus oh dynastyesh win dead [SEP]']
[Init] best perm rec loss: 1.8267709016799927 for ['[CLS] french winmon cain oh jesusesh dynasty dead says answering watershed [SEP]']
[Init] best perm rec loss: 1.8236889839172363 for ['[CLS] dead watershed jesus cainmonesh win french dynasty says answering oh [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.421 (perp=13.141, rec=0.479, cos=0.314), tot_loss_proj:4.532 [t=0.20s]
prediction: ['[CLS] isis acclaimed julia sun seat? high hot straight yellowinium world [SEP]']
[ 100/2000] tot_loss=2.870 (perp=11.592, rec=0.398, cos=0.153), tot_loss_proj:4.232 [t=0.20s]
prediction: ['[CLS] mary william julia inter.. race kissthorpe licked hello funk [SEP]']
[ 150/2000] tot_loss=2.152 (perp=8.711, rec=0.336, cos=0.073), tot_loss_proj:3.561 [t=0.19s]
prediction: ['[CLS] mary john. mary. ; woman dancedvierان originally. [SEP]']
[ 200/2000] tot_loss=1.560 (perp=6.241, rec=0.271, cos=0.041), tot_loss_proj:2.747 [t=0.18s]
prediction: ['[CLS] mary mary is mary. ; woman never never never never. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.907 (perp=7.670, rec=0.314, cos=0.059), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS] mary mary never mary obviously ; woman never never without never. [SEP]']
[ 300/2000] tot_loss=2.188 (perp=9.685, rec=0.223, cos=0.027), tot_loss_proj:3.841 [t=0.23s]
prediction: ['[CLS] mary john never mary [ a men never never employed forests. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.978 (perp=8.779, rec=0.205, cos=0.017), tot_loss_proj:3.572 [t=0.18s]
prediction: ['[CLS] mary john never mary [ a man never kissing never forests. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.944 (perp=8.364, rec=0.246, cos=0.026), tot_loss_proj:3.540 [t=0.18s]
prediction: ['[CLS] mary never john never mary is kissed man never kissing forests. [SEP]']
[ 450/2000] tot_loss=1.758 (perp=7.769, rec=0.189, cos=0.015), tot_loss_proj:3.396 [t=0.21s]
prediction: ['[CLS] mary never john never mary is kissed man never kissed kissed. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.640 (perp=7.246, rec=0.178, cos=0.012), tot_loss_proj:3.291 [t=0.18s]
prediction: ['[CLS] mary never john never kissed mary is man never kissed kissed. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.572 (perp=6.838, rec=0.189, cos=0.016), tot_loss_proj:3.294 [t=0.18s]
prediction: ['[CLS] mary john never kissed mary is never man never kissed kissed. [SEP]']
[ 600/2000] tot_loss=1.548 (perp=6.838, rec=0.170, cos=0.011), tot_loss_proj:3.294 [t=0.21s]
prediction: ['[CLS] mary john never kissed mary is never man never kissed kissed. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.516 (perp=6.703, rec=0.165, cos=0.010), tot_loss_proj:3.255 [t=0.19s]
prediction: ['[CLS] mary john never kissed mary is never man kissed never kissed. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.720 (perp=7.782, rec=0.154, cos=0.010), tot_loss_proj:3.508 [t=0.18s]
prediction: ['[CLS] mary john has kissed mary is never man never kissed taller. [SEP]']
[ 750/2000] tot_loss=1.764 (perp=8.045, rec=0.146, cos=0.009), tot_loss_proj:3.514 [t=0.26s]
prediction: ['[CLS] mary john has a mary is never man never kissed taller. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.679 (perp=7.674, rec=0.135, cos=0.009), tot_loss_proj:3.453 [t=0.25s]
prediction: ['[CLS] john mary has a mary is never man never kissed taller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.680 (perp=7.674, rec=0.137, cos=0.008), tot_loss_proj:3.450 [t=0.21s]
prediction: ['[CLS] john mary has a mary is never man never kissed taller. [SEP]']
[ 900/2000] tot_loss=1.687 (perp=7.674, rec=0.144, cos=0.008), tot_loss_proj:3.449 [t=0.19s]
prediction: ['[CLS] john mary has a mary is never man never kissed taller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.678 (perp=7.674, rec=0.135, cos=0.008), tot_loss_proj:3.448 [t=0.22s]
prediction: ['[CLS] john mary has a mary is never man never kissed taller. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.655 (perp=7.499, rec=0.145, cos=0.011), tot_loss_proj:3.452 [t=0.25s]
prediction: ['[CLS] john mary has kissed mary is never man never kissed taller. [SEP]']
[1050/2000] tot_loss=1.645 (perp=7.499, rec=0.137, cos=0.008), tot_loss_proj:3.452 [t=0.24s]
prediction: ['[CLS] john mary has kissed mary is never man never kissed taller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.633 (perp=7.499, rec=0.125, cos=0.008), tot_loss_proj:3.458 [t=0.19s]
prediction: ['[CLS] john mary has kissed mary is never man never kissed taller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.570 (perp=7.187, rec=0.125, cos=0.008), tot_loss_proj:3.383 [t=0.18s]
prediction: ['[CLS] john mary has kissed mary is never man never a taller. [SEP]']
[1200/2000] tot_loss=1.562 (perp=7.187, rec=0.117, cos=0.008), tot_loss_proj:3.388 [t=0.18s]
prediction: ['[CLS] john mary has kissed mary is never man never a taller. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.474 (perp=6.717, rec=0.123, cos=0.008), tot_loss_proj:3.274 [t=0.22s]
prediction: ['[CLS] john mary has kissed mary is a man never never taller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.471 (perp=6.717, rec=0.120, cos=0.008), tot_loss_proj:3.275 [t=0.18s]
prediction: ['[CLS] john mary has kissed mary is a man never never taller. [SEP]']
[1350/2000] tot_loss=1.474 (perp=6.717, rec=0.123, cos=0.008), tot_loss_proj:3.276 [t=0.23s]
prediction: ['[CLS] john mary has kissed mary is a man never never taller. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.386 (perp=6.282, rec=0.121, cos=0.008), tot_loss_proj:3.162 [t=0.25s]
prediction: ['[CLS] john mary has never kissed mary is a man never taller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.389 (perp=6.282, rec=0.124, cos=0.008), tot_loss_proj:3.165 [t=0.18s]
prediction: ['[CLS] john mary has never kissed mary is a man never taller. [SEP]']
[1500/2000] tot_loss=1.388 (perp=6.282, rec=0.124, cos=0.008), tot_loss_proj:3.168 [t=0.21s]
prediction: ['[CLS] john mary has never kissed mary is a man never taller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.390 (perp=6.282, rec=0.126, cos=0.008), tot_loss_proj:3.168 [t=0.19s]
prediction: ['[CLS] john mary has never kissed mary is a man never taller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.381 (perp=6.282, rec=0.117, cos=0.008), tot_loss_proj:3.168 [t=0.26s]
prediction: ['[CLS] john mary has never kissed mary is a man never taller. [SEP]']
[1650/2000] tot_loss=1.387 (perp=6.282, rec=0.123, cos=0.007), tot_loss_proj:3.163 [t=0.19s]
prediction: ['[CLS] john mary has never kissed mary is a man never taller. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.370 (perp=6.191, rec=0.124, cos=0.008), tot_loss_proj:3.142 [t=0.26s]
prediction: ['[CLS] john never mary has kissed mary is a man never taller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.366 (perp=6.191, rec=0.120, cos=0.008), tot_loss_proj:3.144 [t=0.21s]
prediction: ['[CLS] john never mary has kissed mary is a man never taller. [SEP]']
[1800/2000] tot_loss=1.369 (perp=6.191, rec=0.123, cos=0.007), tot_loss_proj:3.141 [t=0.18s]
prediction: ['[CLS] john never mary has kissed mary is a man never taller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.367 (perp=6.191, rec=0.122, cos=0.007), tot_loss_proj:3.138 [t=0.18s]
prediction: ['[CLS] john never mary has kissed mary is a man never taller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.366 (perp=6.191, rec=0.120, cos=0.007), tot_loss_proj:3.139 [t=0.18s]
prediction: ['[CLS] john never mary has kissed mary is a man never taller. [SEP]']
[1950/2000] tot_loss=1.357 (perp=6.191, rec=0.112, cos=0.007), tot_loss_proj:3.141 [t=0.27s]
prediction: ['[CLS] john never mary has kissed mary is a man never taller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.364 (perp=6.191, rec=0.119, cos=0.007), tot_loss_proj:3.139 [t=0.28s]
prediction: ['[CLS] john never mary has kissed mary is a man never taller. [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] mary has never kissed a man who is taller than john. [SEP]
========================
predicted: 
========================
[CLS] john never mary has kissed mary is a man never taller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 84.615 | r: 84.615
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 61.538 | p: 61.538 | r: 61.538
rougeLsum  | fm: 61.538 | p: 61.538 | r: 61.538
r1fm+r2fm = 101.282

[Aggregate metrics]:
rouge1     | fm: 83.371 | p: 83.042 | r: 83.829
rouge2     | fm: 39.902 | p: 39.771 | r: 40.109
rougeL     | fm: 69.634 | p: 69.247 | r: 69.975
rougeLsum  | fm: 69.610 | p: 69.485 | r: 70.040
r1fm+r2fm = 123.273

input #14 time: 0:08:15 | total time: 2:06:48


Running input #15 of 100.
reference: 
========================
After ten soldiers had left, seven more ones came in.
========================
average of cosine similarity 0.9993145518230557
highest_index [0]
highest [0.9993145518230557]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2044, 2702, 3548, 2018, 2187, 1010, 2698, 2062, 3924, 2234, 1999,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] after ten soldiers had left, seven more ones came in. [SEP]']
[Init] best rec loss: 1.781247854232788 for ['[CLS] war ne soaking kelly moment another carried ahead fk inches chasing deal [SEP]']
[Init] best rec loss: 1.5055463314056396 for ['[CLS] clear love instrument patient commentaryhipversder cowboys progression what tens [SEP]']
[Init] best rec loss: 1.2471493482589722 for ['[CLS] trainedpower mere exception meeting spokanemin cash vested large myselffish [SEP]']
[Init] best rec loss: 1.218926191329956 for ['[CLS] practice fuck sophieostal flames syrian expression cost charleston 9 drugs lgbt [SEP]']
[Init] best rec loss: 1.19851553440094 for ['[CLS]d club linked bachelor awfe honored after award wu common ~ [SEP]']
[Init] best rec loss: 1.1261471509933472 for ['[CLS] cale his!ern indeed an may want debut fashionvah waste [SEP]']
[Init] best rec loss: 1.12026846408844 for ['[CLS]fat solar larry escape spec rest caliber collect inside? piss shepard [SEP]']
[Init] best perm rec loss: 1.0728955268859863 for ['[CLS] collect caliber larry shepard inside rest? escape piss specfat solar [SEP]']
[Init] best perm rec loss: 1.070906400680542 for ['[CLS]? larry shepard rest inside pissfat caliber spec solar escape collect [SEP]']
[Init] best perm rec loss: 1.069460153579712 for ['[CLS] collect restfat? escape caliber spec inside shepard solar larry piss [SEP]']
[Init] best perm rec loss: 1.0689373016357422 for ['[CLS] escape collect rest larry inside solar spec caliber shepardfat piss? [SEP]']
[Init] best perm rec loss: 1.065313696861267 for ['[CLS] collect? larry shepard inside escape spec caliber solar restfat piss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.801 (perp=12.045, rec=0.347, cos=0.045), tot_loss_proj:3.288 [t=0.18s]
prediction: ['[CLS] eight in million ready b ones rep ones colonel seven passes guinness [SEP]']
[ 100/2000] tot_loss=2.498 (perp=11.009, rec=0.273, cos=0.024), tot_loss_proj:3.156 [t=0.18s]
prediction: ['[CLS] seven have ten soldiers after ones ones ones more seven :tern [SEP]']
[ 150/2000] tot_loss=2.084 (perp=9.159, rec=0.223, cos=0.029), tot_loss_proj:2.791 [t=0.20s]
prediction: ['[CLS] seven has ten soldiers after ones entered ones. seven. came [SEP]']
[ 200/2000] tot_loss=2.007 (perp=8.999, rec=0.189, cos=0.018), tot_loss_proj:2.627 [t=0.21s]
prediction: ['[CLS] five had ten soldiers after came came ones. seven. after [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.362 (perp=9.154, rec=0.400, cos=0.132), tot_loss_proj:3.277 [t=0.23s]
prediction: ['[CLS] after had ten soldiers came entered ones additional had seven. they [SEP]']
[ 300/2000] tot_loss=2.202 (perp=9.416, rec=0.285, cos=0.034), tot_loss_proj:3.458 [t=0.19s]
prediction: ['[CLS] after after six soldiers came came ones quickly captive seven. they [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.899 (perp=8.298, rec=0.218, cos=0.021), tot_loss_proj:2.861 [t=0.18s]
prediction: ['[CLS] came had seven soldiers came after ones later, seven. they [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.126 (perp=8.395, rec=0.361, cos=0.086), tot_loss_proj:2.950 [t=0.24s]
prediction: ['[CLS] came had seven soldiers, after ones segments came seven. they [SEP]']
[ 450/2000] tot_loss=1.891 (perp=8.251, rec=0.222, cos=0.019), tot_loss_proj:2.845 [t=0.27s]
prediction: ['[CLS] came that seven soldiers, after ones themselves came seven. left [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.790 (perp=7.927, rec=0.191, cos=0.013), tot_loss_proj:2.614 [t=0.18s]
prediction: ['[CLS] came had left seven soldiers, after ones ones came seven. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.801 (perp=8.002, rec=0.189, cos=0.012), tot_loss_proj:2.856 [t=0.21s]
prediction: ['[CLS] came had left seven soldiers, after ones came seven leslie. [SEP]']
[ 600/2000] tot_loss=1.775 (perp=8.002, rec=0.165, cos=0.009), tot_loss_proj:2.871 [t=0.23s]
prediction: ['[CLS] came had left seven soldiers, after ones came seven leslie. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.634 (perp=7.366, rec=0.152, cos=0.009), tot_loss_proj:2.392 [t=0.22s]
prediction: ['[CLS] came had left seven soldiers, seven ones came after leslie. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.651 (perp=7.527, rec=0.138, cos=0.008), tot_loss_proj:2.354 [t=0.21s]
prediction: ['[CLS] came had left seven soldiers, ones came after seven internally. [SEP]']
[ 750/2000] tot_loss=1.638 (perp=7.452, rec=0.141, cos=0.007), tot_loss_proj:2.366 [t=0.19s]
prediction: ['[CLS] came had left seven soldiers, ones came after seven indeed. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.582 (perp=7.160, rec=0.144, cos=0.006), tot_loss_proj:2.608 [t=0.19s]
prediction: ['[CLS] came had ten soldiers left, ones came after seven internally. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.568 (perp=7.130, rec=0.136, cos=0.006), tot_loss_proj:2.571 [t=0.19s]
prediction: ['[CLS] came had ten soldiers left, ones came after seven indeed. [SEP]']
[ 900/2000] tot_loss=1.668 (perp=7.618, rec=0.139, cos=0.005), tot_loss_proj:2.413 [t=0.19s]
prediction: ['[CLS] in had ten soldiers left, ones came after seven indeed. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.572 (perp=7.182, rec=0.130, cos=0.005), tot_loss_proj:2.106 [t=0.18s]
prediction: ['[CLS] in ten had soldiers left, ones came after seven indeed. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.557 (perp=7.182, rec=0.115, cos=0.005), tot_loss_proj:2.109 [t=0.18s]
prediction: ['[CLS] in ten had soldiers left, ones came after seven indeed. [SEP]']
[1050/2000] tot_loss=1.556 (perp=7.182, rec=0.115, cos=0.005), tot_loss_proj:2.101 [t=0.23s]
prediction: ['[CLS] in ten had soldiers left, ones came after seven indeed. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.517 (perp=6.947, rec=0.123, cos=0.005), tot_loss_proj:1.984 [t=0.26s]
prediction: ['[CLS] in ten soldiers had left, ones came after seven indeed. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.456 (perp=6.503, rec=0.148, cos=0.008), tot_loss_proj:1.777 [t=0.18s]
prediction: ['[CLS] after ten soldiers had left, ones came in seven indeed. [SEP]']
[1200/2000] tot_loss=1.424 (perp=6.503, rec=0.118, cos=0.005), tot_loss_proj:1.780 [t=0.18s]
prediction: ['[CLS] after ten soldiers had left, ones came in seven indeed. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.413 (perp=6.450, rec=0.118, cos=0.005), tot_loss_proj:1.947 [t=0.21s]
prediction: ['[CLS] after ten soldiers had left, ones came in seven when. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.405 (perp=6.450, rec=0.109, cos=0.005), tot_loss_proj:1.951 [t=0.27s]
prediction: ['[CLS] after ten soldiers had left, ones came in seven when. [SEP]']
[1350/2000] tot_loss=1.415 (perp=6.450, rec=0.120, cos=0.005), tot_loss_proj:1.944 [t=0.29s]
prediction: ['[CLS] after ten soldiers had left, ones came in seven when. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.364 (perp=6.218, rec=0.115, cos=0.005), tot_loss_proj:1.812 [t=0.22s]
prediction: ['[CLS] after ten soldiers had left, ones came in. when seven [SEP]']
Attempt swap
[1450/2000] tot_loss=1.360 (perp=6.218, rec=0.112, cos=0.005), tot_loss_proj:1.811 [t=0.18s]
prediction: ['[CLS] after ten soldiers had left, ones came in. when seven [SEP]']
[1500/2000] tot_loss=1.366 (perp=6.218, rec=0.117, cos=0.005), tot_loss_proj:1.810 [t=0.19s]
prediction: ['[CLS] after ten soldiers had left, ones came in. when seven [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.309 (perp=5.944, rec=0.115, cos=0.005), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] after ten soldiers had left when seven, ones came in. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.305 (perp=5.944, rec=0.112, cos=0.005), tot_loss_proj:2.013 [t=0.18s]
prediction: ['[CLS] after ten soldiers had left when seven, ones came in. [SEP]']
[1650/2000] tot_loss=1.310 (perp=5.944, rec=0.116, cos=0.005), tot_loss_proj:2.015 [t=0.18s]
prediction: ['[CLS] after ten soldiers had left when seven, ones came in. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.259 (perp=5.727, rec=0.108, cos=0.005), tot_loss_proj:1.747 [t=0.19s]
prediction: ['[CLS] after ten soldiers had left, seven when ones came in. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.262 (perp=5.727, rec=0.112, cos=0.005), tot_loss_proj:1.742 [t=0.18s]
prediction: ['[CLS] after ten soldiers had left, seven when ones came in. [SEP]']
[1800/2000] tot_loss=1.268 (perp=5.727, rec=0.117, cos=0.005), tot_loss_proj:1.748 [t=0.18s]
prediction: ['[CLS] after ten soldiers had left, seven when ones came in. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.260 (perp=5.727, rec=0.110, cos=0.005), tot_loss_proj:1.741 [t=0.26s]
prediction: ['[CLS] after ten soldiers had left, seven when ones came in. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.245 (perp=5.727, rec=0.095, cos=0.005), tot_loss_proj:1.740 [t=0.18s]
prediction: ['[CLS] after ten soldiers had left, seven when ones came in. [SEP]']
[1950/2000] tot_loss=1.260 (perp=5.727, rec=0.110, cos=0.005), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] after ten soldiers had left, seven when ones came in. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.252 (perp=5.727, rec=0.101, cos=0.005), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] after ten soldiers had left, seven when ones came in. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] after ten soldiers had left, seven more ones came in. [SEP]
========================
predicted: 
========================
[CLS] after ten soldiers had left, seven when ones came in. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 81.818 | p: 81.818 | r: 81.818
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 173.485

[Aggregate metrics]:
rouge1     | fm: 83.686 | p: 83.353 | r: 84.133
rouge2     | fm: 42.906 | p: 42.613 | r: 43.158
rougeL     | fm: 70.971 | p: 70.614 | r: 71.421
rougeLsum  | fm: 71.284 | p: 70.900 | r: 71.622
r1fm+r2fm = 126.593

input #15 time: 0:08:28 | total time: 2:15:17


Running input #16 of 100.
reference: 
========================
Willy is taller than that Bill is is generally believed.
========================
average of cosine similarity 0.9992796327127058
highest_index [0]
highest [0.9992796327127058]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101, 16172,  2003, 12283,  2084,  2008,  3021,  2003,  2003,  3227,
          3373,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] willy is taller than that bill is is generally believed. [SEP]']
[Init] best rec loss: 1.2438404560089111 for ['[CLS] g shared jump inch addition ted poker feel show paul initiative [SEP]']
[Init] best rec loss: 1.1334658861160278 for ['[CLS] college jeff isolated by dick voivodeship past awards premier depth avoid [SEP]']
[Init] best rec loss: 1.0531833171844482 for ['[CLS]ette water home campus ceilingblood hillary appeared unfamiliar dead spend [SEP]']
[Init] best rec loss: 0.9918103218078613 for ['[CLS] halfway ˢ folkhedblesches trainee itsescor indoor [SEP]']
[Init] best rec loss: 0.9900586009025574 for ['[CLS] fashionunt wood freedom finale drake trail incumbent much possibly away [SEP]']
[Init] best perm rec loss: 0.9811928272247314 for ['[CLS] incumbent muchunt finale fashion possibly drake freedom away trail wood [SEP]']
[Init] best perm rec loss: 0.9809790849685669 for ['[CLS] finale drake wood fashion much away possibly freedom trail incumbentunt [SEP]']
[Init] best perm rec loss: 0.9807681441307068 for ['[CLS] fashion trailunt much wood possibly drake freedom away incumbent finale [SEP]']
[Init] best perm rec loss: 0.9802523851394653 for ['[CLS] freedom incumbent finale fashion possibly wood drake muchunt away trail [SEP]']
[Init] best perm rec loss: 0.9776628017425537 for ['[CLS] possiblyunt trail much fashion wood incumbent drake freedom away finale [SEP]']
[Init] best perm rec loss: 0.9760246872901917 for ['[CLS] finale drakeunt possibly trail much fashion incumbent freedom away wood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.730 (perp=11.491, rec=0.376, cos=0.056), tot_loss_proj:3.336 [t=0.26s]
prediction: ['[CLS] must jury ethnic force. was tolerate willy any mph originally [SEP]']
[ 100/2000] tot_loss=2.784 (perp=11.787, rec=0.370, cos=0.057), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] mig jury using thin is is than willy any mph is [SEP]']
[ 150/2000] tot_loss=2.398 (perp=10.525, rec=0.266, cos=0.027), tot_loss_proj:3.063 [t=0.18s]
prediction: ['[CLS] zeus is any taller is is than bill any mph is [SEP]']
[ 200/2000] tot_loss=2.363 (perp=10.635, rec=0.211, cos=0.026), tot_loss_proj:3.207 [t=0.23s]
prediction: ['[CLS] certainly believed total taller than is than bill is is is [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.213 (perp=9.357, rec=0.300, cos=0.042), tot_loss_proj:2.576 [t=0.22s]
prediction: ['[CLS] surely艹 taller than believed is than bill average american is [SEP]']
[ 300/2000] tot_loss=1.820 (perp=8.080, rec=0.183, cos=0.022), tot_loss_proj:2.441 [t=0.18s]
prediction: ['[CLS] nor often taller than believed is that bill average cm is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.988 (perp=9.043, rec=0.164, cos=0.015), tot_loss_proj:2.572 [t=0.18s]
prediction: ['[CLS] ho often taller than believed is that bill generally considered is [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.962 (perp=8.839, rec=0.178, cos=0.017), tot_loss_proj:2.608 [t=0.21s]
prediction: ['[CLS] ho that taller than believed is commonly bill generally considered is [SEP]']
[ 450/2000] tot_loss=2.026 (perp=9.317, rec=0.149, cos=0.013), tot_loss_proj:3.073 [t=0.18s]
prediction: ['[CLS] ho that taller than believed is often bill generally deviation is [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.957 (perp=9.011, rec=0.144, cos=0.011), tot_loss_proj:2.863 [t=0.19s]
prediction: ['[CLS] gr often taller than believed is that bill generally deviation is [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.036 (perp=9.516, rec=0.124, cos=0.010), tot_loss_proj:2.767 [t=0.27s]
prediction: ['[CLS] ho than taller than believed is that bill than is generally [SEP]']
[ 600/2000] tot_loss=2.001 (perp=9.361, rec=0.121, cos=0.008), tot_loss_proj:2.565 [t=0.18s]
prediction: ['[CLS] ho than taller than believed is that bill considered is generally [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.008 (perp=9.432, rec=0.114, cos=0.007), tot_loss_proj:2.592 [t=0.18s]
prediction: ['[CLS] grand taller than than believed is that bill considered is generally [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.949 (perp=9.163, rec=0.110, cos=0.007), tot_loss_proj:2.539 [t=0.19s]
prediction: ['[CLS] grand taller than than believed is that bill is considered willy [SEP]']
[ 750/2000] tot_loss=1.936 (perp=9.163, rec=0.097, cos=0.007), tot_loss_proj:2.545 [t=0.27s]
prediction: ['[CLS] grand taller than than believed is that bill is considered willy [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.901 (perp=8.922, rec=0.110, cos=0.006), tot_loss_proj:2.486 [t=0.18s]
prediction: ['[CLS] grand than taller than believed is that bill is considered willy [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.794 (perp=8.430, rec=0.102, cos=0.006), tot_loss_proj:2.441 [t=0.18s]
prediction: ['[CLS] grand than taller than believed is that bill willy is considered [SEP]']
[ 900/2000] tot_loss=1.788 (perp=8.430, rec=0.096, cos=0.006), tot_loss_proj:2.436 [t=0.26s]
prediction: ['[CLS] grand than taller than believed is that bill willy is considered [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.796 (perp=8.430, rec=0.104, cos=0.005), tot_loss_proj:2.439 [t=0.24s]
prediction: ['[CLS] grand than taller than believed is that bill willy is considered [SEP]']
Attempt swap
[1000/2000] tot_loss=1.798 (perp=8.430, rec=0.107, cos=0.006), tot_loss_proj:2.440 [t=0.18s]
prediction: ['[CLS] grand than taller than believed is that bill willy is considered [SEP]']
[1050/2000] tot_loss=1.786 (perp=8.430, rec=0.095, cos=0.005), tot_loss_proj:2.438 [t=0.18s]
prediction: ['[CLS] grand than taller than believed is that bill willy is considered [SEP]']
Attempt swap
[1100/2000] tot_loss=1.789 (perp=8.430, rec=0.098, cos=0.005), tot_loss_proj:2.429 [t=0.18s]
prediction: ['[CLS] grand than taller than believed is that bill willy is considered [SEP]']
Attempt swap
[1150/2000] tot_loss=1.785 (perp=8.430, rec=0.094, cos=0.005), tot_loss_proj:2.435 [t=0.22s]
prediction: ['[CLS] grand than taller than believed is that bill willy is considered [SEP]']
[1200/2000] tot_loss=1.789 (perp=8.430, rec=0.097, cos=0.005), tot_loss_proj:2.440 [t=0.20s]
prediction: ['[CLS] grand than taller than believed is that bill willy is considered [SEP]']
Attempt swap
[1250/2000] tot_loss=1.852 (perp=8.749, rec=0.097, cos=0.005), tot_loss_proj:2.432 [t=0.18s]
prediction: ['[CLS] grand than taller than believed is that bill willy is often [SEP]']
Attempt swap
[1300/2000] tot_loss=1.857 (perp=8.749, rec=0.101, cos=0.005), tot_loss_proj:2.432 [t=0.19s]
prediction: ['[CLS] grand than taller than believed is that bill willy is often [SEP]']
[1350/2000] tot_loss=1.843 (perp=8.749, rec=0.088, cos=0.005), tot_loss_proj:2.428 [t=0.18s]
prediction: ['[CLS] grand than taller than believed is that bill willy is often [SEP]']
Attempt swap
[1400/2000] tot_loss=1.862 (perp=8.749, rec=0.107, cos=0.005), tot_loss_proj:2.436 [t=0.20s]
prediction: ['[CLS] grand than taller than believed is that bill willy is often [SEP]']
Attempt swap
[1450/2000] tot_loss=1.848 (perp=8.749, rec=0.093, cos=0.005), tot_loss_proj:2.428 [t=0.25s]
prediction: ['[CLS] grand than taller than believed is that bill willy is often [SEP]']
[1500/2000] tot_loss=1.773 (perp=8.364, rec=0.095, cos=0.005), tot_loss_proj:2.349 [t=0.18s]
prediction: ['[CLS] grand is taller than believed is that bill willy is generally [SEP]']
Attempt swap
[1550/2000] tot_loss=1.758 (perp=8.364, rec=0.080, cos=0.005), tot_loss_proj:2.343 [t=0.28s]
prediction: ['[CLS] grand is taller than believed is that bill willy is generally [SEP]']
Attempt swap
[1600/2000] tot_loss=1.766 (perp=8.364, rec=0.088, cos=0.005), tot_loss_proj:2.348 [t=0.28s]
prediction: ['[CLS] grand is taller than believed is that bill willy is generally [SEP]']
[1650/2000] tot_loss=1.770 (perp=8.364, rec=0.092, cos=0.005), tot_loss_proj:2.347 [t=0.21s]
prediction: ['[CLS] grand is taller than believed is that bill willy is generally [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.698 (perp=7.958, rec=0.101, cos=0.006), tot_loss_proj:3.179 [t=0.18s]
prediction: ['[CLS] grand is taller than is believed that bill willy is generally [SEP]']
Attempt swap
[1750/2000] tot_loss=1.694 (perp=7.958, rec=0.097, cos=0.006), tot_loss_proj:3.182 [t=0.18s]
prediction: ['[CLS] grand is taller than is believed that bill willy is generally [SEP]']
[1800/2000] tot_loss=1.699 (perp=7.958, rec=0.102, cos=0.006), tot_loss_proj:3.179 [t=0.26s]
prediction: ['[CLS] grand is taller than is believed that bill willy is generally [SEP]']
Attempt swap
[1850/2000] tot_loss=1.692 (perp=7.958, rec=0.095, cos=0.005), tot_loss_proj:3.184 [t=0.19s]
prediction: ['[CLS] grand is taller than is believed that bill willy is generally [SEP]']
Attempt swap
[1900/2000] tot_loss=1.695 (perp=7.958, rec=0.098, cos=0.005), tot_loss_proj:3.176 [t=0.24s]
prediction: ['[CLS] grand is taller than is believed that bill willy is generally [SEP]']
[1950/2000] tot_loss=1.684 (perp=7.958, rec=0.087, cos=0.005), tot_loss_proj:3.183 [t=0.18s]
prediction: ['[CLS] grand is taller than is believed that bill willy is generally [SEP]']
Attempt swap
[2000/2000] tot_loss=1.683 (perp=7.958, rec=0.086, cos=0.005), tot_loss_proj:3.174 [t=0.18s]
prediction: ['[CLS] grand is taller than is believed that bill willy is generally [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] willy is taller than that bill is is generally believed. [SEP]
========================
predicted: 
========================
[CLS] grand is taller than believed is that bill willy is generally [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 43.478 | p: 41.667 | r: 45.455
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 139.478

[Aggregate metrics]:
rouge1     | fm: 84.571 | p: 84.070 | r: 85.201
rouge2     | fm: 42.404 | p: 42.180 | r: 42.723
rougeL     | fm: 70.620 | p: 70.266 | r: 71.087
rougeLsum  | fm: 70.897 | p: 70.485 | r: 71.340
r1fm+r2fm = 126.974

input #16 time: 0:08:20 | total time: 2:23:37


Running input #17 of 100.
reference: 
========================
José is eating cabbage, and Holly is too.
========================
average of cosine similarity 0.9992581872479298
highest_index [0]
highest [0.9992581872479298]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  4560,  2003,  5983, 28540,  1010,  1998,  9079,  2003,  2205,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] jose is eating cabbage, and holly is too. [SEP]']
[Init] best rec loss: 1.7681305408477783 for ['[CLS] happenedgil revolution parallelsta right finding flag taiwan bella [SEP]']
[Init] best rec loss: 1.7674344778060913 for ['[CLS] binding ras screenwriter conditions solo gallagher parliament nanny one passed [SEP]']
[Init] best perm rec loss: 1.7648096084594727 for ['[CLS] ras binding parliament screenwriter nanny passed conditions gallagher solo one [SEP]']
[Init] best perm rec loss: 1.7646642923355103 for ['[CLS] parliament nanny binding passed ras gallagher screenwriter one conditions solo [SEP]']
[Init] best perm rec loss: 1.7638198137283325 for ['[CLS] conditions binding nanny passed ras screenwriter gallagher solo parliament one [SEP]']
[Init] best perm rec loss: 1.763205885887146 for ['[CLS] screenwriter conditions ras gallagher solo passed binding parliament one nanny [SEP]']
[Init] best perm rec loss: 1.763203740119934 for ['[CLS] passed nanny parliament screenwriter binding conditions ras gallagher one solo [SEP]']
[Init] best perm rec loss: 1.762999176979065 for ['[CLS] nanny passed gallagher solo binding parliament screenwriter ras one conditions [SEP]']
[Init] best perm rec loss: 1.7623637914657593 for ['[CLS] nanny ras gallagher conditions screenwriter passed parliament binding one solo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.720 (perp=10.400, rec=0.644, cos=0.996), tot_loss_proj:3.824 [t=0.18s]
prediction: ['[CLS] whereaboutsological arab persons were is 1998 and league. [SEP]']
[ 100/2000] tot_loss=3.628 (perp=10.257, rec=0.763, cos=0.813), tot_loss_proj:3.754 [t=0.18s]
prediction: ['[CLS] tributary beers cedar too were is remains and too is [SEP]']
[ 150/2000] tot_loss=3.943 (perp=11.896, rec=0.572, cos=0.992), tot_loss_proj:4.145 [t=0.18s]
prediction: ['[CLS] heroes hollow hurling too to is coca and sc is [SEP]']
[ 200/2000] tot_loss=3.540 (perp=9.525, rec=0.746, cos=0.889), tot_loss_proj:3.672 [t=0.26s]
prediction: ['[CLS] zagreb burning flour became of. seed is croix. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.426 (perp=9.245, rec=0.577, cos=1.000), tot_loss_proj:3.614 [t=0.24s]
prediction: ['[CLS] gotta. flour too to - seed is sc. [SEP]']
[ 300/2000] tot_loss=3.294 (perp=8.914, rec=0.512, cos=0.999), tot_loss_proj:3.631 [t=0.18s]
prediction: ['[CLS] valkyrie. ་ too to. orange isville. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.970 (perp=7.518, rec=0.468, cos=0.998), tot_loss_proj:3.379 [t=0.19s]
prediction: ['[CLS] valkyrie. ་ too. orange too too :. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.040 (perp=7.988, rec=0.444, cos=0.998), tot_loss_proj:3.590 [t=0.18s]
prediction: ['[CLS] (. ་ too equals orange too too :. [SEP]']
[ 450/2000] tot_loss=3.077 (perp=7.894, rec=0.500, cos=0.999), tot_loss_proj:3.559 [t=0.28s]
prediction: ['[CLS].. ་ too equals orange too is ª. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.206 (perp=8.870, rec=0.434, cos=0.998), tot_loss_proj:3.612 [t=0.27s]
prediction: ['[CLS]. is holly too equals holly is too overs. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.530 (perp=10.479, rec=0.434, cos=0.999), tot_loss_proj:3.940 [t=0.18s]
prediction: ['[CLS] ( is holly too pollard holly too too overs. [SEP]']
[ 600/2000] tot_loss=3.612 (perp=11.051, rec=0.404, cos=0.997), tot_loss_proj:3.999 [t=0.18s]
prediction: ['[CLS] ( holly holly too gunfire holly is too looks. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.342 (perp=9.755, rec=0.394, cos=0.997), tot_loss_proj:3.720 [t=0.20s]
prediction: ['[CLS] ( holly looks too gunfire holly is is holly. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.420 (perp=10.175, rec=0.387, cos=0.997), tot_loss_proj:3.790 [t=0.20s]
prediction: ['[CLS] gunfire missionary holly looks too holly is is holly. [SEP]']
[ 750/2000] tot_loss=3.592 (perp=11.187, rec=0.358, cos=0.996), tot_loss_proj:3.966 [t=0.18s]
prediction: ['[CLS] gunfire missionary holly looks tooneas is is holly. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.512 (perp=10.880, rec=0.338, cos=0.997), tot_loss_proj:3.895 [t=0.24s]
prediction: ['[CLS] gunfire is holly looks tooneas isroid holly. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.318 (perp=9.984, rec=0.324, cos=0.997), tot_loss_proj:3.713 [t=0.24s]
prediction: ['[CLS] gunfire is holly looks tooneas is is holly. [SEP]']
[ 900/2000] tot_loss=3.155 (perp=9.193, rec=0.319, cos=0.997), tot_loss_proj:3.590 [t=0.20s]
prediction: ['[CLS] surprising is holly looks tooneas is is holly. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=3.090 (perp=8.896, rec=0.313, cos=0.998), tot_loss_proj:3.523 [t=0.21s]
prediction: ['[CLS] surprising is holly looks tooneas is holly is. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.019 (perp=8.564, rec=0.308, cos=0.998), tot_loss_proj:3.445 [t=0.18s]
prediction: ['[CLS] surprising is too holly looksneas is holly is. [SEP]']
[1050/2000] tot_loss=3.289 (perp=9.888, rec=0.314, cos=0.997), tot_loss_proj:3.693 [t=0.19s]
prediction: ['[CLS]pies is too holly looksneas is holly is. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.158 (perp=9.250, rec=0.310, cos=0.997), tot_loss_proj:3.579 [t=0.25s]
prediction: ['[CLS]pies is holly looksneas is holly is too. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.158 (perp=9.250, rec=0.310, cos=0.998), tot_loss_proj:3.575 [t=0.22s]
prediction: ['[CLS]pies is holly looksneas is holly is too. [SEP]']
[1200/2000] tot_loss=3.152 (perp=9.250, rec=0.305, cos=0.998), tot_loss_proj:3.572 [t=0.25s]
prediction: ['[CLS]pies is holly looksneas is holly is too. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.155 (perp=9.250, rec=0.307, cos=0.998), tot_loss_proj:3.580 [t=0.29s]
prediction: ['[CLS]pies is holly looksneas is holly is too. [SEP]']
Attempt swap
[1300/2000] tot_loss=2.991 (perp=8.471, rec=0.299, cos=0.998), tot_loss_proj:3.423 [t=0.18s]
prediction: ['[CLS] staying is holly looksneas is holly is too. [SEP]']
[1350/2000] tot_loss=2.995 (perp=8.471, rec=0.303, cos=0.998), tot_loss_proj:3.421 [t=0.19s]
prediction: ['[CLS] staying is holly looksneas is holly is too. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.982 (perp=8.471, rec=0.290, cos=0.998), tot_loss_proj:3.418 [t=0.22s]
prediction: ['[CLS] staying is holly looksneas is holly is too. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=3.032 (perp=8.660, rec=0.303, cos=0.997), tot_loss_proj:3.499 [t=0.26s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
[1500/2000] tot_loss=3.020 (perp=8.660, rec=0.291, cos=0.998), tot_loss_proj:3.505 [t=0.19s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.027 (perp=8.660, rec=0.298, cos=0.998), tot_loss_proj:3.497 [t=0.18s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.020 (perp=8.660, rec=0.290, cos=0.998), tot_loss_proj:3.494 [t=0.23s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
[1650/2000] tot_loss=3.022 (perp=8.660, rec=0.292, cos=0.998), tot_loss_proj:3.497 [t=0.18s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.024 (perp=8.660, rec=0.294, cos=0.998), tot_loss_proj:3.495 [t=0.19s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.030 (perp=8.660, rec=0.300, cos=0.998), tot_loss_proj:3.496 [t=0.18s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
[1800/2000] tot_loss=3.022 (perp=8.660, rec=0.292, cos=0.998), tot_loss_proj:3.503 [t=0.18s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.012 (perp=8.660, rec=0.283, cos=0.998), tot_loss_proj:3.498 [t=0.25s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.020 (perp=8.660, rec=0.290, cos=0.998), tot_loss_proj:3.499 [t=0.22s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
[1950/2000] tot_loss=3.014 (perp=8.660, rec=0.284, cos=0.998), tot_loss_proj:3.499 [t=0.19s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.015 (perp=8.660, rec=0.285, cos=0.998), tot_loss_proj:3.497 [t=0.25s]
prediction: ['[CLS] looks is holly plantsneas is holly is too. [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] jose is eating cabbage, and holly is too. [SEP]
========================
predicted: 
========================
[CLS] looks is holly plantsneas is holly is too. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 93.333

[Aggregate metrics]:
rouge1     | fm: 83.025 | p: 82.552 | r: 83.717
rouge2     | fm: 41.698 | p: 41.456 | r: 41.877
rougeL     | fm: 69.931 | p: 69.505 | r: 70.458
rougeLsum  | fm: 70.287 | p: 69.891 | r: 70.706
r1fm+r2fm = 124.723

input #17 time: 0:08:25 | total time: 2:32:03


Running input #18 of 100.
reference: 
========================
John demanded that she stop phoning him.
========================
average of cosine similarity 0.9994126222039297
highest_index [0]
highest [0.9994126222039297]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2198,  6303,  2008,  2016,  2644,  6887, 13369,  2032,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] john demanded that she stop phoning him. [SEP]']
[Init] best rec loss: 1.8964049816131592 for ['[CLS] layton fewer consult school lu bounced choose switzerland years [SEP]']
[Init] best rec loss: 1.8624707460403442 for ['[CLS] hearing identity rein matcheslord prepares throughumber finished [SEP]']
[Init] best rec loss: 1.774194598197937 for ['[CLS] robert hides hits so spoiled category lover ontario limited [SEP]']
[Init] best rec loss: 1.7741047143936157 for ['[CLS] shrineeral ba br outlets requiem sang ben do [SEP]']
[Init] best rec loss: 1.771346926689148 for ['[CLS] live universe mess direct literacyding d bridge later [SEP]']
[Init] best rec loss: 1.7408503293991089 for ['[CLS]? funding murray know port organization yeah september sw [SEP]']
[Init] best perm rec loss: 1.7406840324401855 for ['[CLS] know funding yeah organization? september port sw murray [SEP]']
[Init] best perm rec loss: 1.7393075227737427 for ['[CLS] organization port yeah murray know september sw funding? [SEP]']
[Init] best perm rec loss: 1.7379651069641113 for ['[CLS] know september sw funding port murray yeah? organization [SEP]']
[Init] best perm rec loss: 1.7348406314849854 for ['[CLS] september? port know organization sw funding yeah murray [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.105 (perp=12.405, rec=0.624, cos=1.000), tot_loss_proj:4.501 [t=0.28s]
prediction: ['[CLS] when. masonicraya marcus wwe scoring ; barry [SEP]']
[ 100/2000] tot_loss=3.776 (perp=11.219, rec=0.539, cos=0.994), tot_loss_proj:4.101 [t=0.18s]
prediction: ['[CLS] when he consequences demanded demandedoning platinum. dr [SEP]']
[ 150/2000] tot_loss=4.217 (perp=13.470, rec=0.720, cos=0.803), tot_loss_proj:4.473 [t=0.20s]
prediction: ['[CLS]iaceae he moss were she demanded airborne. sean [SEP]']
[ 200/2000] tot_loss=3.884 (perp=11.754, rec=0.597, cos=0.936), tot_loss_proj:4.305 [t=0.19s]
prediction: ['[CLS] larvae he representing demanded she demanded intake. dr [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=4.106 (perp=12.608, rec=0.585, cos=1.000), tot_loss_proj:4.341 [t=0.22s]
prediction: ['[CLS]bit he rematch demanded sheor demandederine timer [SEP]']
[ 300/2000] tot_loss=3.931 (perp=11.528, rec=0.663, cos=0.963), tot_loss_proj:4.116 [t=0.20s]
prediction: ['[CLS] mouth she cuff demanded she.oning consonants explanation [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.282 (perp=9.347, rec=0.350, cos=0.063), tot_loss_proj:3.731 [t=0.24s]
prediction: ['[CLS]? she boundary demanded she sister demanded slalom. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.393 (perp=10.692, rec=0.237, cos=0.018), tot_loss_proj:3.987 [t=0.26s]
prediction: ['[CLS]? heoning demanded she demanded friar sick. [SEP]']
[ 450/2000] tot_loss=2.173 (perp=9.786, rec=0.205, cos=0.011), tot_loss_proj:3.767 [t=0.24s]
prediction: ['[CLS] did heoning demanded she demanded ep him. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.841 (perp=8.235, rec=0.185, cos=0.009), tot_loss_proj:3.582 [t=0.26s]
prediction: ['[CLS] did heoning demanded she demanded him stop. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.019 (perp=9.182, rec=0.174, cos=0.008), tot_loss_proj:3.812 [t=0.18s]
prediction: ['[CLS] did johnoning demanded she demanded him stop. [SEP]']
[ 600/2000] tot_loss=2.103 (perp=9.655, rec=0.165, cos=0.007), tot_loss_proj:3.863 [t=0.19s]
prediction: ['[CLS] did johnoning demanded sheoning him stop. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.985 (perp=9.182, rec=0.142, cos=0.006), tot_loss_proj:3.813 [t=0.25s]
prediction: ['[CLS] did johnoning demanded she demanded him stop. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.888 (perp=8.713, rec=0.139, cos=0.006), tot_loss_proj:3.687 [t=0.19s]
prediction: ['[CLS] john didoning demanded she demanded him stop. [SEP]']
[ 750/2000] tot_loss=1.874 (perp=8.713, rec=0.127, cos=0.005), tot_loss_proj:3.686 [t=0.21s]
prediction: ['[CLS] john didoning demanded she demanded him stop. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.765 (perp=8.160, rec=0.127, cos=0.006), tot_loss_proj:3.578 [t=0.27s]
prediction: ['[CLS] john that didoning she demanded him stop. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.591 (perp=7.289, rec=0.126, cos=0.007), tot_loss_proj:3.433 [t=0.21s]
prediction: ['[CLS] that john didoning she demanded him stop. [SEP]']
[ 900/2000] tot_loss=1.586 (perp=7.289, rec=0.122, cos=0.005), tot_loss_proj:3.435 [t=0.18s]
prediction: ['[CLS] that john didoning she demanded him stop. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.585 (perp=7.289, rec=0.122, cos=0.005), tot_loss_proj:3.433 [t=0.19s]
prediction: ['[CLS] that john didoning she demanded him stop. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.075 (perp=9.773, rec=0.116, cos=0.005), tot_loss_proj:3.863 [t=0.22s]
prediction: ['[CLS] that john didoning she demanded ph stop. [SEP]']
[1050/2000] tot_loss=2.065 (perp=9.773, rec=0.106, cos=0.004), tot_loss_proj:3.864 [t=0.18s]
prediction: ['[CLS] that john didoning she demanded ph stop. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.521 (perp=7.011, rec=0.114, cos=0.005), tot_loss_proj:3.430 [t=0.19s]
prediction: ['[CLS] that john did stop she demanded phoning. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.459 (perp=6.481, rec=0.151, cos=0.012), tot_loss_proj:3.301 [t=0.18s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
[1200/2000] tot_loss=1.436 (perp=6.481, rec=0.131, cos=0.009), tot_loss_proj:3.305 [t=0.18s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.436 (perp=6.481, rec=0.132, cos=0.008), tot_loss_proj:3.303 [t=0.19s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.422 (perp=6.481, rec=0.118, cos=0.008), tot_loss_proj:3.307 [t=0.18s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
[1350/2000] tot_loss=1.427 (perp=6.481, rec=0.124, cos=0.007), tot_loss_proj:3.309 [t=0.21s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.427 (perp=6.481, rec=0.124, cos=0.007), tot_loss_proj:3.303 [t=0.18s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.430 (perp=6.481, rec=0.127, cos=0.007), tot_loss_proj:3.300 [t=0.22s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
[1500/2000] tot_loss=1.425 (perp=6.481, rec=0.122, cos=0.007), tot_loss_proj:3.303 [t=0.19s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.418 (perp=6.481, rec=0.115, cos=0.007), tot_loss_proj:3.307 [t=0.24s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.425 (perp=6.481, rec=0.122, cos=0.007), tot_loss_proj:3.300 [t=0.18s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
[1650/2000] tot_loss=1.409 (perp=6.481, rec=0.106, cos=0.007), tot_loss_proj:3.300 [t=0.26s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.417 (perp=6.481, rec=0.114, cos=0.006), tot_loss_proj:3.309 [t=0.26s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.415 (perp=6.481, rec=0.113, cos=0.006), tot_loss_proj:3.303 [t=0.18s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
[1800/2000] tot_loss=1.408 (perp=6.481, rec=0.106, cos=0.006), tot_loss_proj:3.302 [t=0.19s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.410 (perp=6.481, rec=0.107, cos=0.006), tot_loss_proj:3.307 [t=0.22s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.416 (perp=6.481, rec=0.113, cos=0.006), tot_loss_proj:3.301 [t=0.25s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
[1950/2000] tot_loss=1.414 (perp=6.481, rec=0.111, cos=0.006), tot_loss_proj:3.308 [t=0.18s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.419 (perp=6.481, rec=0.117, cos=0.006), tot_loss_proj:3.306 [t=0.22s]
prediction: ['[CLS] that john. demanded she stop phoning. [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] john demanded that she stop phoning him. [SEP]
========================
predicted: 
========================
[CLS] that john. demanded she stop phoning. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 100.000 | r: 88.889
rouge2     | fm: 40.000 | p: 42.857 | r: 37.500
rougeL     | fm: 82.353 | p: 87.500 | r: 77.778
rougeLsum  | fm: 82.353 | p: 87.500 | r: 77.778
r1fm+r2fm = 134.118

[Aggregate metrics]:
rouge1     | fm: 83.548 | p: 83.444 | r: 83.883
rouge2     | fm: 41.615 | p: 41.548 | r: 41.727
rougeL     | fm: 70.780 | p: 70.604 | r: 70.923
rougeLsum  | fm: 70.732 | p: 70.631 | r: 70.994
r1fm+r2fm = 125.163

input #18 time: 0:08:28 | total time: 2:40:32


Running input #19 of 100.
reference: 
========================
I have six too many marbles.
========================
average of cosine similarity 0.999305888550308
highest_index [0]
highest [0.999305888550308]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 1045, 2031, 2416, 2205, 2116, 7720, 2015, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have six too many marbles. [SEP]']
[Init] best rec loss: 1.9144606590270996 for ['[CLS] endemicston card horsevere kira particular glasses [SEP]']
[Init] best rec loss: 1.8149117231369019 for ['[CLS] they future math note ] chaseanza bore [SEP]']
[Init] best rec loss: 1.7958660125732422 for ['[CLS] make various los♥ that fraternity garden exported [SEP]']
[Init] best rec loss: 1.7395936250686646 for ['[CLS] screen ran livingston game [CLS] unknown that oclc [SEP]']
[Init] best rec loss: 1.7116552591323853 for ['[CLS] liability bleak later itpta doinʁ wilde [SEP]']
[Init] best rec loss: 1.6963130235671997 for ['[CLS] rear itself period def chargelth length contract [SEP]']
[Init] best perm rec loss: 1.692842721939087 for ['[CLS] chargelth itself def contract period length rear [SEP]']
[Init] best perm rec loss: 1.687497854232788 for ['[CLS] rear itself def chargelth period contract length [SEP]']
[Init] best perm rec loss: 1.6872018575668335 for ['[CLS] charge def itself rear periodlth contract length [SEP]']
[Init] best perm rec loss: 1.6820350885391235 for ['[CLS] charge def itself length period contractlth rear [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.313 (perp=12.991, rec=0.489, cos=0.226), tot_loss_proj:4.383 [t=0.21s]
prediction: ['[CLS] right max foreign multiple advantage reputation super belgian [SEP]']
[ 100/2000] tot_loss=3.235 (perp=13.294, rec=0.434, cos=0.143), tot_loss_proj:4.597 [t=0.18s]
prediction: ['[CLS] nice used sidereate advantage marble super belgian [SEP]']
[ 150/2000] tot_loss=2.705 (perp=10.845, rec=0.410, cos=0.125), tot_loss_proj:4.133 [t=0.23s]
prediction: ['[CLS] nice used have six marble marble super athletic [SEP]']
[ 200/2000] tot_loss=1.938 (perp=7.911, rec=0.291, cos=0.064), tot_loss_proj:3.182 [t=0.21s]
prediction: ['[CLS] my i have six hundred marble. did [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.422 (perp=10.091, rec=0.337, cos=0.068), tot_loss_proj:3.948 [t=0.19s]
prediction: ['[CLS] nice i lex have several eight marble. [SEP]']
[ 300/2000] tot_loss=2.162 (perp=9.204, rec=0.275, cos=0.047), tot_loss_proj:3.784 [t=0.19s]
prediction: ['[CLS] must too bull have six eight marble. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.798 (perp=7.575, rec=0.242, cos=0.041), tot_loss_proj:3.382 [t=0.18s]
prediction: ['[CLS] i too previously have six hundred marble. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.799 (perp=7.693, rec=0.226, cos=0.034), tot_loss_proj:3.581 [t=0.24s]
prediction: ['[CLS] i too many have six many marble. [SEP]']
[ 450/2000] tot_loss=1.728 (perp=7.693, rec=0.164, cos=0.025), tot_loss_proj:3.578 [t=0.25s]
prediction: ['[CLS] i too many have six many marble. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.743 (perp=7.978, rec=0.132, cos=0.015), tot_loss_proj:3.621 [t=0.26s]
prediction: ['[CLS] i too several have many six marble. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.799 (perp=8.120, rec=0.152, cos=0.024), tot_loss_proj:3.630 [t=0.18s]
prediction: ['[CLS] i sized many too many six marble. [SEP]']
[ 600/2000] tot_loss=1.751 (perp=8.120, rec=0.115, cos=0.012), tot_loss_proj:3.635 [t=0.18s]
prediction: ['[CLS] i sized many too many six marble. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.648 (perp=7.662, rec=0.104, cos=0.011), tot_loss_proj:3.532 [t=0.18s]
prediction: ['[CLS] have obviously three too many six marble. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.600 (perp=7.389, rec=0.111, cos=0.012), tot_loss_proj:3.514 [t=0.19s]
prediction: ['[CLS] obviously have three too many six marble. [SEP]']
[ 750/2000] tot_loss=1.603 (perp=7.389, rec=0.115, cos=0.011), tot_loss_proj:3.511 [t=0.23s]
prediction: ['[CLS] obviously have three too many six marble. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.737 (perp=8.097, rec=0.107, cos=0.011), tot_loss_proj:3.602 [t=0.23s]
prediction: ['[CLS] sized have three too many six marble. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.666 (perp=7.690, rec=0.116, cos=0.012), tot_loss_proj:3.426 [t=0.23s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
[ 900/2000] tot_loss=1.666 (perp=7.690, rec=0.117, cos=0.011), tot_loss_proj:3.425 [t=0.21s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.653 (perp=7.690, rec=0.105, cos=0.010), tot_loss_proj:3.423 [t=0.22s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.651 (perp=7.690, rec=0.103, cos=0.010), tot_loss_proj:3.420 [t=0.24s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
[1050/2000] tot_loss=1.653 (perp=7.690, rec=0.105, cos=0.010), tot_loss_proj:3.425 [t=0.24s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.658 (perp=7.690, rec=0.110, cos=0.009), tot_loss_proj:3.424 [t=0.18s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.647 (perp=7.690, rec=0.100, cos=0.009), tot_loss_proj:3.420 [t=0.23s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
[1200/2000] tot_loss=1.641 (perp=7.690, rec=0.094, cos=0.009), tot_loss_proj:3.424 [t=0.21s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.644 (perp=7.690, rec=0.097, cos=0.009), tot_loss_proj:3.428 [t=0.22s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.644 (perp=7.690, rec=0.097, cos=0.009), tot_loss_proj:3.423 [t=0.18s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
[1350/2000] tot_loss=1.641 (perp=7.690, rec=0.094, cos=0.009), tot_loss_proj:3.422 [t=0.18s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.647 (perp=7.690, rec=0.100, cos=0.009), tot_loss_proj:3.423 [t=0.24s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.644 (perp=7.690, rec=0.097, cos=0.009), tot_loss_proj:3.426 [t=0.19s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
[1500/2000] tot_loss=1.647 (perp=7.690, rec=0.100, cos=0.009), tot_loss_proj:3.425 [t=0.26s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.648 (perp=7.690, rec=0.101, cos=0.009), tot_loss_proj:3.422 [t=0.19s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.652 (perp=7.690, rec=0.105, cos=0.009), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
[1650/2000] tot_loss=1.654 (perp=7.690, rec=0.107, cos=0.009), tot_loss_proj:3.422 [t=0.18s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.640 (perp=7.690, rec=0.093, cos=0.009), tot_loss_proj:3.426 [t=0.18s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.643 (perp=7.690, rec=0.096, cos=0.009), tot_loss_proj:3.421 [t=0.18s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
[1800/2000] tot_loss=1.639 (perp=7.690, rec=0.092, cos=0.009), tot_loss_proj:3.424 [t=0.18s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.643 (perp=7.690, rec=0.096, cos=0.009), tot_loss_proj:3.423 [t=0.19s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.647 (perp=7.690, rec=0.101, cos=0.009), tot_loss_proj:3.428 [t=0.18s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
[1950/2000] tot_loss=1.654 (perp=7.690, rec=0.108, cos=0.009), tot_loss_proj:3.429 [t=0.29s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.656 (perp=7.690, rec=0.110, cos=0.009), tot_loss_proj:3.428 [t=0.20s]
prediction: ['[CLS] have three too many six sized marble. [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] i have six too many marbles. [SEP]
========================
predicted: 
========================
[CLS] have three too many six sized marble. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 66.667 | r: 75.000
rouge2     | fm: 13.333 | p: 12.500 | r: 14.286
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 83.922

[Aggregate metrics]:
rouge1     | fm: 82.964 | p: 82.552 | r: 83.453
rouge2     | fm: 40.184 | p: 40.088 | r: 40.379
rougeL     | fm: 70.194 | p: 69.877 | r: 70.599
rougeLsum  | fm: 70.272 | p: 70.081 | r: 70.671
r1fm+r2fm = 123.148

input #19 time: 0:08:19 | total time: 2:48:51


Running input #20 of 100.
reference: 
========================
Mark's single mindedness terrified me.
========================
average of cosine similarity 0.9994279625663224
highest_index [0]
highest [0.9994279625663224]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2928,  1005,  1055,  2309, 13128,  2791, 10215,  2033,  1012,
           102]], device='cuda:0')
Debug: ref = ["[CLS] mark's single mindedness terrified me. [SEP]"]
[Init] best rec loss: 1.9891088008880615 for ['[CLS] [CLS] asked sirius accessed ling women emphasis disc height [SEP]']
[Init] best rec loss: 1.9429240226745605 for ['[CLS]se guitarfirmed sky 2015 begging box simply agreed [SEP]']
[Init] best rec loss: 1.908393144607544 for ['[CLS] buried popular asian steps practicing crack ideology no yeah [SEP]']
[Init] best rec loss: 1.904714822769165 for ['[CLS] tree km² bal possible dom surf part lips blues [SEP]']
[Init] best rec loss: 1.9005889892578125 for ['[CLS]ul dvdriety ex wisconsin most yep permanent crazy [SEP]']
[Init] best rec loss: 1.8947889804840088 for ['[CLS] regional sat dubbed plantciationicio acquired its bet [SEP]']
[Init] best rec loss: 1.8764984607696533 for ['[CLS] federal fine bolt sc jacket smith tribute imagination lizards [SEP]']
[Init] best rec loss: 1.8753199577331543 for ['[CLS] highest warmly jenny bit shell method regard kentrated [SEP]']
[Init] best rec loss: 1.8703618049621582 for ['[CLS]inae daly daphne needs sciences : collapsed aviation near [SEP]']
[Init] best rec loss: 1.8272682428359985 for ['[CLS] heives judgmentsitorecarch hal youtube salon [SEP]']
[Init] best perm rec loss: 1.8261959552764893 for ['[CLS]sitor youtube halivesrch judgment he saloneca [SEP]']
[Init] best perm rec loss: 1.8253557682037354 for ['[CLS] salon judgmentrchivessitor hal heeca youtube [SEP]']
[Init] best perm rec loss: 1.8252971172332764 for ['[CLS] he judgment halecaivessitor youtube salonrch [SEP]']
[Init] best perm rec loss: 1.8245997428894043 for ['[CLS]rch judgmentsitorives saloneca youtube hal he [SEP]']
[Init] best perm rec loss: 1.82353675365448 for ['[CLS] salon herchives judgmentsitor youtube haleca [SEP]']
[Init] best perm rec loss: 1.823007583618164 for ['[CLS] halsitor youtubeecaives herch salon judgment [SEP]']
[Init] best perm rec loss: 1.8224409818649292 for ['[CLS] youtuberchsitoriveseca judgment salon he hal [SEP]']
[Init] best perm rec loss: 1.8214843273162842 for ['[CLS] he halivesrch youtube judgmentsitoreca salon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.878 (perp=11.056, rec=0.769, cos=0.898), tot_loss_proj:4.139 [t=0.18s]
prediction: ['[CLS]. than ezio my coming risk appeared unknown taken [SEP]']
[ 100/2000] tot_loss=3.877 (perp=11.133, rec=0.694, cos=0.956), tot_loss_proj:4.241 [t=0.18s]
prediction: ['[CLS]. percent ezio my nature corruption blind mystery taken [SEP]']
[ 150/2000] tot_loss=3.101 (perp=12.741, rec=0.422, cos=0.130), tot_loss_proj:4.506 [t=0.18s]
prediction: ['[CLS]. ko ♥ title nature brahms terrified necessity literally [SEP]']
[ 200/2000] tot_loss=2.652 (perp=11.640, rec=0.283, cos=0.041), tot_loss_proj:4.322 [t=0.18s]
prediction: ['[CLS]. ae nate single nature minded terrified necessity literally [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.881 (perp=8.036, rec=0.240, cos=0.033), tot_loss_proj:3.671 [t=0.21s]
prediction: ['[CLS] loving minded mark single mindedness terrified him. [SEP]']
[ 300/2000] tot_loss=1.826 (perp=8.261, rec=0.165, cos=0.009), tot_loss_proj:3.784 [t=0.24s]
prediction: ['[CLS] loving minded mark single mindedness terrified me. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.611 (perp=12.373, rec=0.131, cos=0.005), tot_loss_proj:4.630 [t=0.19s]
prediction: ['[CLS] mark single loving s mindedness terrified me me [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.302 (perp=10.925, rec=0.112, cos=0.005), tot_loss_proj:3.684 [t=0.28s]
prediction: ['[CLS] mark s mono single mindedness terrified me me [SEP]']
[ 450/2000] tot_loss=2.291 (perp=10.925, rec=0.101, cos=0.005), tot_loss_proj:3.710 [t=0.22s]
prediction: ['[CLS] mark s mono single mindedness terrified me me [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.225 (perp=10.632, rec=0.094, cos=0.005), tot_loss_proj:2.599 [t=0.19s]
prediction: ['[CLS] mark s single mono mindedness terrified me me [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.073 (perp=9.793, rec=0.110, cos=0.005), tot_loss_proj:4.088 [t=0.18s]
prediction: ['[CLS] mark s single mono minded meness terrified me [SEP]']
[ 600/2000] tot_loss=2.053 (perp=9.793, rec=0.090, cos=0.005), tot_loss_proj:4.090 [t=0.25s]
prediction: ['[CLS] mark s single mono minded meness terrified me [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.061 (perp=9.793, rec=0.098, cos=0.004), tot_loss_proj:4.094 [t=0.18s]
prediction: ['[CLS] mark s single mono minded meness terrified me [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.042 (perp=9.793, rec=0.080, cos=0.004), tot_loss_proj:4.095 [t=0.18s]
prediction: ['[CLS] mark s single mono minded meness terrified me [SEP]']
[ 750/2000] tot_loss=2.049 (perp=9.793, rec=0.086, cos=0.004), tot_loss_proj:4.096 [t=0.18s]
prediction: ['[CLS] mark s single mono minded meness terrified me [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.994 (perp=9.506, rec=0.088, cos=0.004), tot_loss_proj:3.811 [t=0.18s]
prediction: ['[CLS] mark s single mono minded me terrifiedness me [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.986 (perp=9.506, rec=0.080, cos=0.004), tot_loss_proj:3.808 [t=0.18s]
prediction: ['[CLS] mark s single mono minded me terrifiedness me [SEP]']
[ 900/2000] tot_loss=1.980 (perp=9.506, rec=0.074, cos=0.004), tot_loss_proj:3.812 [t=0.18s]
prediction: ['[CLS] mark s single mono minded me terrifiedness me [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.990 (perp=9.506, rec=0.085, cos=0.004), tot_loss_proj:3.809 [t=0.19s]
prediction: ['[CLS] mark s single mono minded me terrifiedness me [SEP]']
Attempt swap
[1000/2000] tot_loss=1.983 (perp=9.506, rec=0.077, cos=0.004), tot_loss_proj:3.813 [t=0.18s]
prediction: ['[CLS] mark s single mono minded me terrifiedness me [SEP]']
[1050/2000] tot_loss=1.984 (perp=9.506, rec=0.079, cos=0.004), tot_loss_proj:3.807 [t=0.18s]
prediction: ['[CLS] mark s single mono minded me terrifiedness me [SEP]']
Attempt swap
[1100/2000] tot_loss=1.909 (perp=9.100, rec=0.085, cos=0.004), tot_loss_proj:3.729 [t=0.18s]
prediction: ["[CLS] mark'single mono minded me terrifiedness me [SEP]"]
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.859 (perp=8.851, rec=0.085, cos=0.004), tot_loss_proj:3.721 [t=0.18s]
prediction: ["[CLS] mark'single mono mindedness me terrified me [SEP]"]
[1200/2000] tot_loss=2.027 (perp=9.701, rec=0.083, cos=0.004), tot_loss_proj:3.887 [t=0.19s]
prediction: ['[CLS] mark s single mono mindedness me terrified me [SEP]']
Attempt swap
[1250/2000] tot_loss=1.861 (perp=8.851, rec=0.087, cos=0.004), tot_loss_proj:3.717 [t=0.23s]
prediction: ["[CLS] mark'single mono mindedness me terrified me [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.864 (perp=8.851, rec=0.090, cos=0.004), tot_loss_proj:3.715 [t=0.18s]
prediction: ["[CLS] mark'single mono mindedness me terrified me [SEP]"]
[1350/2000] tot_loss=1.863 (perp=8.851, rec=0.089, cos=0.004), tot_loss_proj:3.716 [t=0.19s]
prediction: ["[CLS] mark'single mono mindedness me terrified me [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=1.687 (perp=7.952, rec=0.093, cos=0.004), tot_loss_proj:2.329 [t=0.19s]
prediction: ["[CLS] mark'single mono mindedness terrified me. [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.830 (perp=8.724, rec=0.080, cos=0.004), tot_loss_proj:3.126 [t=0.29s]
prediction: ["[CLS] mark'mono single mindedness terrified me. [SEP]"]
[1500/2000] tot_loss=1.835 (perp=8.724, rec=0.086, cos=0.004), tot_loss_proj:3.129 [t=0.22s]
prediction: ["[CLS] mark'mono single mindedness terrified me. [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.673 (perp=7.952, rec=0.078, cos=0.004), tot_loss_proj:2.324 [t=0.18s]
prediction: ["[CLS] mark'single mono mindedness terrified me. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.674 (perp=7.952, rec=0.080, cos=0.004), tot_loss_proj:2.322 [t=0.22s]
prediction: ["[CLS] mark'single mono mindedness terrified me. [SEP]"]
[1650/2000] tot_loss=1.674 (perp=7.952, rec=0.079, cos=0.004), tot_loss_proj:2.322 [t=0.24s]
prediction: ["[CLS] mark'single mono mindedness terrified me. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.675 (perp=7.952, rec=0.081, cos=0.004), tot_loss_proj:2.329 [t=0.18s]
prediction: ["[CLS] mark'single mono mindedness terrified me. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.675 (perp=7.952, rec=0.081, cos=0.004), tot_loss_proj:2.325 [t=0.18s]
prediction: ["[CLS] mark'single mono mindedness terrified me. [SEP]"]
[1800/2000] tot_loss=1.667 (perp=7.952, rec=0.073, cos=0.004), tot_loss_proj:2.322 [t=0.25s]
prediction: ["[CLS] mark'single mono mindedness terrified me. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.682 (perp=7.952, rec=0.088, cos=0.004), tot_loss_proj:2.319 [t=0.20s]
prediction: ["[CLS] mark'single mono mindedness terrified me. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.669 (perp=7.952, rec=0.074, cos=0.004), tot_loss_proj:2.326 [t=0.22s]
prediction: ["[CLS] mark'single mono mindedness terrified me. [SEP]"]
[1950/2000] tot_loss=1.669 (perp=7.952, rec=0.075, cos=0.004), tot_loss_proj:2.322 [t=0.18s]
prediction: ["[CLS] mark'single mono mindedness terrified me. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.676 (perp=8.020, rec=0.068, cos=0.004), tot_loss_proj:1.892 [t=0.19s]
prediction: ["[CLS] mark'single s mindedness terrified me. [SEP]"]
Done with input #20 of 100.
reference: 
========================
[CLS] mark's single mindedness terrified me. [SEP]
========================
predicted: 
========================
[CLS] mark'single mono mindedness terrified me. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 144.643

[Aggregate metrics]:
rouge1     | fm: 83.128 | p: 82.884 | r: 83.628
rouge2     | fm: 41.287 | p: 41.154 | r: 41.481
rougeL     | fm: 70.909 | p: 70.708 | r: 71.336
rougeLsum  | fm: 71.104 | p: 70.743 | r: 71.403
r1fm+r2fm = 124.416

input #20 time: 0:08:28 | total time: 2:57:19


Running input #21 of 100.
reference: 
========================
Her indiscretions were made light of.
========================
average of cosine similarity 0.9994566039006179
highest_index [0]
highest [0.9994566039006179]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2014, 27427,  2483, 16748,  9285,  2020,  2081,  2422,  1997,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] her indiscretions were made light of. [SEP]']
[Init] best rec loss: 1.877549171447754 for ['[CLS] dung help makei de blinds commissioned "z graders [SEP]']
[Init] best rec loss: 1.8656965494155884 for ['[CLS] germanyerate basic knee transient rack but triangle imperial toll [SEP]']
[Init] best rec loss: 1.7894986867904663 for ['[CLS]nufi sloop includesc mass bills stance ☆ business [SEP]']
[Init] best rec loss: 1.7651124000549316 for ['[CLS] nerve interfacesglersson venicer duringteryballs expecting [SEP]']
[Init] best rec loss: 1.7578039169311523 for ['[CLS] section table tatum chose grey caught thief cool sets solid [SEP]']
[Init] best rec loss: 1.732373833656311 for ['[CLS]phobic aisle centre saw failed leading co those whisky growing [SEP]']
[Init] best perm rec loss: 1.7280911207199097 for ['[CLS] centre growing saw leading co failed aislephobic whisky those [SEP]']
[Init] best perm rec loss: 1.7280457019805908 for ['[CLS] failed growing those leading aisle whiskyphobic centre co saw [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.242 (perp=12.542, rec=0.490, cos=0.244), tot_loss_proj:4.250 [t=0.23s]
prediction: ['[CLS] internationalyam unfortunately popularity. few wasrran [SEP] was [SEP]']
[ 100/2000] tot_loss=2.580 (perp=10.460, rec=0.378, cos=0.110), tot_loss_proj:3.835 [t=0.22s]
prediction: ['[CLS] internationalyam pulled popularity. few was mainland [SEP]. [SEP]']
[ 150/2000] tot_loss=2.674 (perp=11.449, rec=0.324, cos=0.061), tot_loss_proj:4.137 [t=0.19s]
prediction: ['[CLS]lessed pulled demon. þ aqua− former. [SEP]']
[ 200/2000] tot_loss=2.663 (perp=11.604, rec=0.299, cos=0.043), tot_loss_proj:4.120 [t=0.18s]
prediction: ['[CLS]lesstions pulled demon. þ collided−orted. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.435 (perp=10.307, rec=0.320, cos=0.053), tot_loss_proj:3.893 [t=0.19s]
prediction: ['[CLS]less pulledtions demon. christina bis mainlandorted. [SEP]']
[ 300/2000] tot_loss=2.406 (perp=10.494, rec=0.274, cos=0.032), tot_loss_proj:4.016 [t=0.25s]
prediction: ['[CLS]less pulledtions demon. shakespeare bis−orted. [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.375 (perp=10.477, rec=0.253, cos=0.026), tot_loss_proj:3.945 [t=0.21s]
prediction: ['[CLS]less pulledtions demon. portraits reflection−orted. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.379 (perp=10.572, rec=0.241, cos=0.023), tot_loss_proj:3.994 [t=0.18s]
prediction: ['[CLS]less pulledtions demon. portraits− reflectioncre. [SEP]']
[ 450/2000] tot_loss=2.353 (perp=10.509, rec=0.230, cos=0.022), tot_loss_proj:4.007 [t=0.19s]
prediction: ['[CLS]less pulledtions demon. portraits− werecre. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.186 (perp=9.714, rec=0.222, cos=0.021), tot_loss_proj:3.870 [t=0.20s]
prediction: ['[CLS]less pulledtions demon. portraits were−cre. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.375 (perp=10.692, rec=0.217, cos=0.019), tot_loss_proj:3.959 [t=0.22s]
prediction: ['[CLS]less pulledtions demon her portraits wereationscre. [SEP]']
[ 600/2000] tot_loss=2.469 (perp=11.202, rec=0.212, cos=0.017), tot_loss_proj:4.042 [t=0.18s]
prediction: ['[CLS] made madetions demon her dim wereationscre. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.484 (perp=11.249, rec=0.218, cos=0.017), tot_loss_proj:3.993 [t=0.19s]
prediction: ['[CLS] made dimtions pokemon her made wereationscre. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.156 (perp=9.608, rec=0.216, cos=0.018), tot_loss_proj:3.683 [t=0.25s]
prediction: ['[CLS] madecretions pokemon her made wereations dim. [SEP]']
[ 750/2000] tot_loss=2.306 (perp=10.446, rec=0.202, cos=0.015), tot_loss_proj:3.841 [t=0.18s]
prediction: ['[CLS] madecretionstine her made wereations carvings. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.344 (perp=10.618, rec=0.206, cos=0.014), tot_loss_proj:3.879 [t=0.18s]
prediction: ['[CLS] madecretionstineations made were her oct. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.376 (perp=10.844, rec=0.193, cos=0.014), tot_loss_proj:3.956 [t=0.19s]
prediction: ['[CLS] werecretionstine madeicular were her oct. [SEP]']
[ 900/2000] tot_loss=2.299 (perp=10.438, rec=0.199, cos=0.012), tot_loss_proj:3.823 [t=0.21s]
prediction: ['[CLS] werecretionstine made light were her oct. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.100 (perp=9.432, rec=0.202, cos=0.012), tot_loss_proj:3.821 [t=0.20s]
prediction: ['[CLS] werecretions hertine made light were oct. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.854 (perp=8.198, rec=0.201, cos=0.013), tot_loss_proj:3.406 [t=0.18s]
prediction: ['[CLS] hercretions weretine made light were oct. [SEP]']
[1050/2000] tot_loss=1.789 (perp=7.944, rec=0.190, cos=0.010), tot_loss_proj:3.381 [t=0.19s]
prediction: ['[CLS] hercretions weretine made light were carvings. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.702 (perp=7.568, rec=0.178, cos=0.010), tot_loss_proj:3.324 [t=0.18s]
prediction: ['[CLS] hercretions were were made lighttine carvings. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.694 (perp=7.568, rec=0.171, cos=0.009), tot_loss_proj:3.323 [t=0.18s]
prediction: ['[CLS] hercretions were were made lighttine carvings. [SEP]']
[1200/2000] tot_loss=1.826 (perp=8.145, rec=0.188, cos=0.009), tot_loss_proj:3.380 [t=0.19s]
prediction: ['[CLS] hercretions were were made lighttinetions. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.135 (perp=9.720, rec=0.183, cos=0.008), tot_loss_proj:3.729 [t=0.19s]
prediction: ['[CLS] hertinetions were made made lightcrecre. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.865 (perp=8.322, rec=0.189, cos=0.012), tot_loss_proj:3.435 [t=0.26s]
prediction: ['[CLS] hertinecretions were made made lightcre. [SEP]']
[1350/2000] tot_loss=1.842 (perp=8.322, rec=0.168, cos=0.009), tot_loss_proj:3.438 [t=0.20s]
prediction: ['[CLS] hertinecretions were made made lightcre. [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.752 (perp=7.790, rec=0.185, cos=0.009), tot_loss_proj:3.308 [t=0.18s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.741 (perp=7.790, rec=0.175, cos=0.008), tot_loss_proj:3.306 [t=0.18s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
[1500/2000] tot_loss=1.722 (perp=7.790, rec=0.157, cos=0.008), tot_loss_proj:3.300 [t=0.18s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.734 (perp=7.790, rec=0.169, cos=0.007), tot_loss_proj:3.301 [t=0.18s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.733 (perp=7.790, rec=0.168, cos=0.007), tot_loss_proj:3.304 [t=0.23s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
[1650/2000] tot_loss=1.731 (perp=7.790, rec=0.166, cos=0.007), tot_loss_proj:3.302 [t=0.23s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.729 (perp=7.790, rec=0.164, cos=0.007), tot_loss_proj:3.306 [t=0.23s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.731 (perp=7.790, rec=0.167, cos=0.007), tot_loss_proj:3.305 [t=0.21s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
[1800/2000] tot_loss=1.716 (perp=7.790, rec=0.151, cos=0.006), tot_loss_proj:3.306 [t=0.19s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.733 (perp=7.790, rec=0.168, cos=0.006), tot_loss_proj:3.300 [t=0.18s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.727 (perp=7.790, rec=0.163, cos=0.006), tot_loss_proj:3.302 [t=0.19s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
[1950/2000] tot_loss=1.724 (perp=7.790, rec=0.160, cos=0.006), tot_loss_proj:3.304 [t=0.19s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.726 (perp=7.790, rec=0.162, cos=0.006), tot_loss_proj:3.301 [t=0.19s]
prediction: ['[CLS] hercretions were made made lightcretine. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] her indiscretions were made light of. [SEP]
========================
predicted: 
========================
[CLS] hercretions were made made lightcretine. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.333 | p: 57.143 | r: 50.000
rouge2     | fm: 15.385 | p: 16.667 | r: 14.286
rougeL     | fm: 53.333 | p: 57.143 | r: 50.000
rougeLsum  | fm: 53.333 | p: 57.143 | r: 50.000
r1fm+r2fm = 68.718

[Aggregate metrics]:
rouge1     | fm: 81.783 | p: 81.542 | r: 82.092
rouge2     | fm: 39.912 | p: 39.900 | r: 40.108
rougeL     | fm: 69.969 | p: 69.900 | r: 70.258
rougeLsum  | fm: 70.260 | p: 70.220 | r: 70.489
r1fm+r2fm = 121.695

input #21 time: 0:08:17 | total time: 3:05:37


Running input #22 of 100.
reference: 
========================
Each of the boys fought with the other boys.
========================
average of cosine similarity 0.9994588680226513
highest_index [0]
highest [0.9994588680226513]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2169, 1997, 1996, 3337, 4061, 2007, 1996, 2060, 3337, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] each of the boys fought with the other boys. [SEP]']
[Init] best rec loss: 1.8880624771118164 for ['[CLS] hers hours woundmund totaling pd hailey stone aftermath tortricidae [SEP]']
[Init] best rec loss: 1.879317283630371 for ['[CLS] rises mcleod lady pour jumpert waste brewing 3rduma [SEP]']
[Init] best rec loss: 1.8766204118728638 for ['[CLS] died type despite html rare main opening history ss control [SEP]']
[Init] best rec loss: 1.8683578968048096 for ['[CLS] hotterpath started regional chew intention concert bet outsiders labour [SEP]']
[Init] best rec loss: 1.8384689092636108 for ['[CLS] come green referencepenarus approved breed teacher highs na [SEP]']
[Init] best rec loss: 1.8071972131729126 for ['[CLS] niall sabre segment andrew africa lane indonesia decade permanent post [SEP]']
[Init] best rec loss: 1.7989143133163452 for ['[CLS] court fund surge opener pair fcaneousfatlam scent [SEP]']
[Init] best rec loss: 1.7909432649612427 for ['[CLS] shortata inn process multi city galleryh cell prince [SEP]']
[Init] best rec loss: 1.7883890867233276 for ['[CLS] tons faye sun barry followed jessie many graduated bowed likely [SEP]']
[Init] best rec loss: 1.778902530670166 for ['[CLS] jack san fire rican except donna encryption seen property european [SEP]']
[Init] best rec loss: 1.762405514717102 for ['[CLS] complexion federal threats u shadow megan some future rules ir [SEP]']
[Init] best perm rec loss: 1.7613344192504883 for ['[CLS] complexion ir some rules u shadow federal threats future megan [SEP]']
[Init] best perm rec loss: 1.7613062858581543 for ['[CLS] future ir some u shadow rules federal threats megan complexion [SEP]']
[Init] best perm rec loss: 1.7612476348876953 for ['[CLS] u federal threats shadow megan rules some future ir complexion [SEP]']
[Init] best perm rec loss: 1.7591568231582642 for ['[CLS] federal some rules ir shadow future u threats megan complexion [SEP]']
[Init] best perm rec loss: 1.7591148614883423 for ['[CLS] rules federal ir some u threats future megan shadow complexion [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.988 (perp=11.955, rec=0.620, cos=0.977), tot_loss_proj:4.136 [t=0.19s]
prediction: ['[CLS] ign oftledsome which both with each positions with [SEP]']
[ 100/2000] tot_loss=3.612 (perp=10.362, rec=0.544, cos=0.996), tot_loss_proj:4.051 [t=0.31s]
prediction: ['[CLS] warriors the fought boys both fight boys subsequent fight complement [SEP]']
[ 150/2000] tot_loss=3.849 (perp=11.586, rec=0.533, cos=0.998), tot_loss_proj:4.161 [t=0.27s]
prediction: ["[CLS] coverage each fought boys both fight boysules fight'[SEP]"]
[ 200/2000] tot_loss=3.629 (perp=10.708, rec=0.488, cos=0.999), tot_loss_proj:3.958 [t=0.25s]
prediction: ['[CLS] immediately each fought each both fought boys thugs fight. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=4.155 (perp=13.090, rec=0.539, cos=0.999), tot_loss_proj:4.449 [t=0.22s]
prediction: ['[CLS] coverageules fought each both fight boys each mcc probably [SEP]']
[ 300/2000] tot_loss=3.569 (perp=10.341, rec=0.501, cos=1.000), tot_loss_proj:3.903 [t=0.26s]
prediction: ['[CLS] coverage diane fought each both fought boys the fight with [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.761 (perp=11.508, rec=0.459, cos=1.000), tot_loss_proj:4.187 [t=0.19s]
prediction: ['[CLS] eachules fought each both fought. each both boys [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=4.052 (perp=12.642, rec=0.526, cos=0.998), tot_loss_proj:4.452 [t=0.23s]
prediction: ['[CLS] epithet fought each ivy both fought. each mcc boys [SEP]']
[ 450/2000] tot_loss=3.456 (perp=10.046, rec=0.449, cos=0.999), tot_loss_proj:3.854 [t=0.24s]
prediction: ['[CLS] each fought eachules both fought. each both boys [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.213 (perp=8.937, rec=0.428, cos=0.998), tot_loss_proj:3.675 [t=0.26s]
prediction: ['[CLS] each fought each fought bothules. each both boys [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.694 (perp=11.210, rec=0.453, cos=0.998), tot_loss_proj:4.176 [t=0.28s]
prediction: ['[CLS] each fought alzheimer each foughtules. each stay boys [SEP]']
[ 600/2000] tot_loss=3.279 (perp=9.356, rec=0.410, cos=0.998), tot_loss_proj:3.795 [t=0.23s]
prediction: ['[CLS] each foughtics each foughtules. each stay boys [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.526 (perp=10.672, rec=0.393, cos=0.998), tot_loss_proj:4.096 [t=0.26s]
prediction: ['[CLS] each fought emeritus each foughtules. each stay boys [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.570 (perp=10.870, rec=0.398, cos=0.998), tot_loss_proj:4.140 [t=0.23s]
prediction: ['[CLS] each fought emeritus each stayules. every fought boys [SEP]']
[ 750/2000] tot_loss=3.444 (perp=10.277, rec=0.392, cos=0.997), tot_loss_proj:3.934 [t=0.25s]
prediction: ['[CLS] each fought emeritus each stayules. the fought boys [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.549 (perp=10.844, rec=0.383, cos=0.997), tot_loss_proj:4.123 [t=0.21s]
prediction: ['[CLS] each fought emeritus each stayules. every boys fought [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.510 (perp=10.658, rec=0.381, cos=0.997), tot_loss_proj:4.218 [t=0.18s]
prediction: ['[CLS] each emeritus fought each stayules. every boys fought [SEP]']
[ 900/2000] tot_loss=3.441 (perp=10.343, rec=0.375, cos=0.997), tot_loss_proj:4.141 [t=0.27s]
prediction: ['[CLS] each milos fought each stayules. every boys fought [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.346 (perp=9.894, rec=0.370, cos=0.997), tot_loss_proj:3.979 [t=0.19s]
prediction: ['[CLS] each milos fought each stayules. the boys alongside [SEP]']
Attempt swap
[1000/2000] tot_loss=3.346 (perp=9.894, rec=0.370, cos=0.997), tot_loss_proj:3.977 [t=0.18s]
prediction: ['[CLS] each milos fought each stayules. the boys alongside [SEP]']
[1050/2000] tot_loss=3.163 (perp=9.026, rec=0.361, cos=0.997), tot_loss_proj:3.771 [t=0.18s]
prediction: ['[CLS] each milos fought each withules. the boys alongside [SEP]']
Attempt swap
[1100/2000] tot_loss=3.161 (perp=9.026, rec=0.358, cos=0.997), tot_loss_proj:3.770 [t=0.22s]
prediction: ['[CLS] each milos fought each withules. the boys alongside [SEP]']
Attempt swap
[1150/2000] tot_loss=3.160 (perp=9.026, rec=0.357, cos=0.998), tot_loss_proj:3.770 [t=0.18s]
prediction: ['[CLS] each milos fought each withules. the boys alongside [SEP]']
[1200/2000] tot_loss=3.165 (perp=9.026, rec=0.363, cos=0.998), tot_loss_proj:3.768 [t=0.19s]
prediction: ['[CLS] each milos fought each withules. the boys alongside [SEP]']
Attempt swap
[1250/2000] tot_loss=3.158 (perp=9.026, rec=0.355, cos=0.998), tot_loss_proj:3.765 [t=0.25s]
prediction: ['[CLS] each milos fought each withules. the boys alongside [SEP]']
Attempt swap
[1300/2000] tot_loss=3.153 (perp=9.026, rec=0.350, cos=0.998), tot_loss_proj:3.771 [t=0.24s]
prediction: ['[CLS] each milos fought each withules. the boys alongside [SEP]']
[1350/2000] tot_loss=3.322 (perp=9.836, rec=0.356, cos=0.998), tot_loss_proj:3.925 [t=0.26s]
prediction: ['[CLS] each milos fought eachurules. the boys alongside [SEP]']
Attempt swap
[1400/2000] tot_loss=3.319 (perp=9.836, rec=0.354, cos=0.998), tot_loss_proj:3.929 [t=0.18s]
prediction: ['[CLS] each milos fought eachurules. the boys alongside [SEP]']
Attempt swap
[1450/2000] tot_loss=3.317 (perp=9.836, rec=0.352, cos=0.998), tot_loss_proj:3.929 [t=0.19s]
prediction: ['[CLS] each milos fought eachurules. the boys alongside [SEP]']
[1500/2000] tot_loss=3.312 (perp=9.836, rec=0.347, cos=0.998), tot_loss_proj:3.929 [t=0.18s]
prediction: ['[CLS] each milos fought eachurules. the boys alongside [SEP]']
Attempt swap
[1550/2000] tot_loss=3.239 (perp=9.515, rec=0.338, cos=0.998), tot_loss_proj:3.884 [t=0.18s]
prediction: ['[CLS] each milos fought withurules. the boys alongside [SEP]']
Attempt swap
[1600/2000] tot_loss=3.257 (perp=9.515, rec=0.356, cos=0.998), tot_loss_proj:3.884 [t=0.18s]
prediction: ['[CLS] each milos fought withurules. the boys alongside [SEP]']
[1650/2000] tot_loss=3.248 (perp=9.515, rec=0.347, cos=0.998), tot_loss_proj:3.883 [t=0.18s]
prediction: ['[CLS] each milos fought withurules. the boys alongside [SEP]']
Attempt swap
[1700/2000] tot_loss=3.243 (perp=9.515, rec=0.342, cos=0.998), tot_loss_proj:3.890 [t=0.18s]
prediction: ['[CLS] each milos fought withurules. the boys alongside [SEP]']
Attempt swap
[1750/2000] tot_loss=3.257 (perp=9.515, rec=0.356, cos=0.998), tot_loss_proj:3.888 [t=0.19s]
prediction: ['[CLS] each milos fought withurules. the boys alongside [SEP]']
[1800/2000] tot_loss=3.238 (perp=9.515, rec=0.337, cos=0.998), tot_loss_proj:3.889 [t=0.19s]
prediction: ['[CLS] each milos fought withurules. the boys alongside [SEP]']
Attempt swap
[1850/2000] tot_loss=3.245 (perp=9.515, rec=0.344, cos=0.998), tot_loss_proj:3.885 [t=0.18s]
prediction: ['[CLS] each milos fought withurules. the boys alongside [SEP]']
Attempt swap
[1900/2000] tot_loss=3.242 (perp=9.515, rec=0.341, cos=0.998), tot_loss_proj:3.887 [t=0.18s]
prediction: ['[CLS] each milos fought withurules. the boys alongside [SEP]']
[1950/2000] tot_loss=3.246 (perp=9.515, rec=0.345, cos=0.998), tot_loss_proj:3.883 [t=0.22s]
prediction: ['[CLS] each milos fought withurules. the boys alongside [SEP]']
Attempt swap
[2000/2000] tot_loss=3.490 (perp=10.765, rec=0.339, cos=0.998), tot_loss_proj:4.071 [t=0.18s]
prediction: ['[CLS] each milos fought withurules. every boys alongside [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] each of the boys fought with the other boys. [SEP]
========================
predicted: 
========================
[CLS] each milos fought withurules. the boys alongside [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 66.667 | r: 54.545
rouge2     | fm: 22.222 | p: 25.000 | r: 20.000
rougeL     | fm: 60.000 | p: 66.667 | r: 54.545
rougeLsum  | fm: 60.000 | p: 66.667 | r: 54.545
r1fm+r2fm = 82.222

[Aggregate metrics]:
rouge1     | fm: 80.663 | p: 80.867 | r: 80.777
rouge2     | fm: 39.071 | p: 39.130 | r: 39.097
rougeL     | fm: 69.639 | p: 69.818 | r: 69.524
rougeLsum  | fm: 69.876 | p: 70.079 | r: 69.750
r1fm+r2fm = 119.734

input #22 time: 0:08:25 | total time: 3:14:02


Running input #23 of 100.
reference: 
========================
Herman mixed the eggs with the cream.
========================
average of cosine similarity 0.999419669419539
highest_index [0]
highest [0.999419669419539]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 11458,  3816,  1996,  6763,  2007,  1996,  6949,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] herman mixed the eggs with the cream. [SEP]']
[Init] best rec loss: 1.8405945301055908 for ['[CLS] digital borrow applied lodging luc reconciliation rhys toe [SEP]']
[Init] best rec loss: 1.8244470357894897 for ['[CLS] million subsequently acclaimed asking races antique population un [SEP]']
[Init] best rec loss: 1.787903904914856 for ['[CLS] town noah space adult defaultmana chronologicalously [SEP]']
[Init] best rec loss: 1.7410615682601929 for ['[CLS]dic help ley located a stages avenueted [SEP]']
[Init] best rec loss: 1.7157344818115234 for ['[CLS]. party lenav recruited corporate as circulation [SEP]']
[Init] best perm rec loss: 1.7131911516189575 for ['[CLS] len recruited corporate. party circulation asav [SEP]']
[Init] best perm rec loss: 1.7125203609466553 for ['[CLS] recruited corporate. circulation lenav party as [SEP]']
[Init] best perm rec loss: 1.7110145092010498 for ['[CLS] circulation party corporate. len recruitedav as [SEP]']
[Init] best perm rec loss: 1.7109320163726807 for ['[CLS] recruited circulation.av corporate len as party [SEP]']
[Init] best perm rec loss: 1.7109036445617676 for ['[CLS] corporate. party circulation recruited lenav as [SEP]']
[Init] best perm rec loss: 1.7097285985946655 for ['[CLS] circulation. as party len recruited corporateav [SEP]']
[Init] best perm rec loss: 1.7071396112442017 for ['[CLS]. party corporate circulation len recruited asav [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.947 (perp=11.740, rec=0.795, cos=0.804), tot_loss_proj:4.384 [t=0.18s]
prediction: ['[CLS] eggs descendant secrets avant with controls en eggs [SEP]']
[ 100/2000] tot_loss=3.797 (perp=11.388, rec=0.554, cos=0.966), tot_loss_proj:4.074 [t=0.27s]
prediction: ['[CLS] the slave ordained rap with led with eggs [SEP]']
[ 150/2000] tot_loss=2.168 (perp=9.449, rec=0.248, cos=0.030), tot_loss_proj:3.683 [t=0.24s]
prediction: ['[CLS] eggs cream mixed ab with. the eggs [SEP]']
[ 200/2000] tot_loss=2.244 (perp=10.346, rec=0.163, cos=0.011), tot_loss_proj:3.834 [t=0.19s]
prediction: ['[CLS] eggs cream mixed the with eggs the herman [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.917 (perp=8.863, rec=0.136, cos=0.009), tot_loss_proj:3.857 [t=0.25s]
prediction: ['[CLS] eggs cream mixed the eggs with the herman [SEP]']
[ 300/2000] tot_loss=1.887 (perp=8.863, rec=0.108, cos=0.007), tot_loss_proj:3.849 [t=0.19s]
prediction: ['[CLS] eggs cream mixed the eggs with the herman [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.638 (perp=7.647, rec=0.103, cos=0.006), tot_loss_proj:3.419 [t=0.24s]
prediction: ['[CLS] the cream mixed the cream with eggs herman [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.629 (perp=7.647, rec=0.094, cos=0.005), tot_loss_proj:3.420 [t=0.18s]
prediction: ['[CLS] the cream mixed the cream with eggs herman [SEP]']
[ 450/2000] tot_loss=1.629 (perp=7.647, rec=0.094, cos=0.005), tot_loss_proj:3.419 [t=0.18s]
prediction: ['[CLS] the cream mixed the cream with eggs herman [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.545 (perp=7.233, rec=0.093, cos=0.005), tot_loss_proj:3.516 [t=0.23s]
prediction: ['[CLS] the cream mixed with the cream eggs herman [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.538 (perp=7.233, rec=0.087, cos=0.005), tot_loss_proj:3.518 [t=0.18s]
prediction: ['[CLS] the cream mixed with the cream eggs herman [SEP]']
[ 600/2000] tot_loss=1.543 (perp=7.233, rec=0.091, cos=0.005), tot_loss_proj:3.517 [t=0.19s]
prediction: ['[CLS] the cream mixed with the cream eggs herman [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.128 (perp=9.318, rec=0.228, cos=0.036), tot_loss_proj:3.801 [t=0.21s]
prediction: ['[CLS] the cream mixed with. cream eggs herman [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.603 (perp=7.214, rec=0.152, cos=0.008), tot_loss_proj:3.229 [t=0.18s]
prediction: ['[CLS] the cream mixed with cream eggs herman. [SEP]']
[ 750/2000] tot_loss=1.569 (perp=7.214, rec=0.121, cos=0.005), tot_loss_proj:3.223 [t=0.18s]
prediction: ['[CLS] the cream mixed with cream eggs herman. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.392 (perp=6.308, rec=0.126, cos=0.005), tot_loss_proj:3.058 [t=0.26s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.379 (perp=6.308, rec=0.113, cos=0.004), tot_loss_proj:3.041 [t=0.28s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
[ 900/2000] tot_loss=1.379 (perp=6.308, rec=0.113, cos=0.004), tot_loss_proj:3.031 [t=0.21s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.366 (perp=6.308, rec=0.101, cos=0.004), tot_loss_proj:3.023 [t=0.21s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.367 (perp=6.308, rec=0.102, cos=0.003), tot_loss_proj:3.028 [t=0.19s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
[1050/2000] tot_loss=1.369 (perp=6.308, rec=0.104, cos=0.003), tot_loss_proj:3.028 [t=0.18s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.361 (perp=6.308, rec=0.096, cos=0.003), tot_loss_proj:3.018 [t=0.21s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.353 (perp=6.308, rec=0.088, cos=0.003), tot_loss_proj:3.021 [t=0.19s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
[1200/2000] tot_loss=1.354 (perp=6.308, rec=0.089, cos=0.003), tot_loss_proj:3.024 [t=0.25s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.367 (perp=6.308, rec=0.102, cos=0.003), tot_loss_proj:3.024 [t=0.20s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.372 (perp=6.308, rec=0.108, cos=0.003), tot_loss_proj:3.023 [t=0.18s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
[1350/2000] tot_loss=1.359 (perp=6.308, rec=0.095, cos=0.003), tot_loss_proj:3.023 [t=0.19s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.356 (perp=6.308, rec=0.091, cos=0.003), tot_loss_proj:3.019 [t=0.19s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.362 (perp=6.308, rec=0.097, cos=0.003), tot_loss_proj:3.020 [t=0.18s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
[1500/2000] tot_loss=1.360 (perp=6.308, rec=0.096, cos=0.003), tot_loss_proj:3.019 [t=0.24s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.351 (perp=6.308, rec=0.087, cos=0.003), tot_loss_proj:3.019 [t=0.18s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.362 (perp=6.308, rec=0.097, cos=0.003), tot_loss_proj:3.019 [t=0.19s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
[1650/2000] tot_loss=1.354 (perp=6.308, rec=0.090, cos=0.003), tot_loss_proj:3.023 [t=0.19s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.352 (perp=6.308, rec=0.088, cos=0.003), tot_loss_proj:3.022 [t=0.19s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.356 (perp=6.308, rec=0.091, cos=0.003), tot_loss_proj:3.022 [t=0.19s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
[1800/2000] tot_loss=1.358 (perp=6.308, rec=0.094, cos=0.003), tot_loss_proj:3.025 [t=0.24s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.364 (perp=6.308, rec=0.100, cos=0.002), tot_loss_proj:3.021 [t=0.19s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.346 (perp=6.308, rec=0.081, cos=0.002), tot_loss_proj:3.018 [t=0.18s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
[1950/2000] tot_loss=1.357 (perp=6.308, rec=0.093, cos=0.002), tot_loss_proj:3.020 [t=0.18s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.349 (perp=6.308, rec=0.085, cos=0.002), tot_loss_proj:3.020 [t=0.19s]
prediction: ['[CLS] the cream mixed with cream herman eggs. [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] herman mixed the eggs with the cream. [SEP]
========================
predicted: 
========================
[CLS] the cream mixed with the cream eggs herman [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 23.529 | p: 22.222 | r: 25.000
rougeL     | fm: 63.158 | p: 60.000 | r: 66.667
rougeLsum  | fm: 63.158 | p: 60.000 | r: 66.667
r1fm+r2fm = 118.266

[Aggregate metrics]:
rouge1     | fm: 81.481 | p: 81.408 | r: 81.667
rouge2     | fm: 38.314 | p: 38.309 | r: 38.369
rougeL     | fm: 69.322 | p: 69.443 | r: 69.481
rougeLsum  | fm: 69.338 | p: 69.503 | r: 69.490
r1fm+r2fm = 119.795

input #23 time: 0:08:25 | total time: 3:22:27


Running input #24 of 100.
reference: 
========================
No John Smiths attended the meeting.
========================
average of cosine similarity 0.9993669078291529
highest_index [0]
highest [0.9993669078291529]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2053, 2198, 3044, 2015, 3230, 1996, 3116, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] no john smiths attended the meeting. [SEP]']
[Init] best rec loss: 1.9060922861099243 for ['[CLS] performance maybe rae tri / window grace lockheed [SEP]']
[Init] best rec loss: 1.8988842964172363 for ['[CLS] gideon capture natural islamic conesdicate ride practice [SEP]']
[Init] best rec loss: 1.8985053300857544 for ['[CLS] thin southwest laurel body [MASK] minority statue in [SEP]']
[Init] best rec loss: 1.8933466672897339 for ['[CLS] skin ft km² ass played radio left forte [SEP]']
[Init] best rec loss: 1.8780266046524048 for ['[CLS] evan peninsular animation however conduct constituencygame duc [SEP]']
[Init] best rec loss: 1.8745471239089966 for ['[CLS] orange energy stayed tucker someone turkey himselfbach [SEP]']
[Init] best rec loss: 1.8721801042556763 for ['[CLS] commanded belts twilight cameo so mountain 0 radio [SEP]']
[Init] best rec loss: 1.7999194860458374 for ['[CLS]al cousin owned ) term be monthly movement [SEP]']
[Init] best perm rec loss: 1.798912525177002 for ['[CLS] movement ownedal term monthly ) be cousin [SEP]']
[Init] best perm rec loss: 1.7977782487869263 for ['[CLS] monthlyal movement be ) cousin term owned [SEP]']
[Init] best perm rec loss: 1.796817660331726 for ['[CLS]al cousin ) term monthly be movement owned [SEP]']
[Init] best perm rec loss: 1.7953660488128662 for ['[CLS]al ) term monthly movement owned be cousin [SEP]']
[Init] best perm rec loss: 1.7935487031936646 for ['[CLS] ) term cousin monthlyal movement owned be [SEP]']
[Init] best perm rec loss: 1.790727972984314 for ['[CLS] monthly cousin term be ) ownedal movement [SEP]']
[Init] best perm rec loss: 1.7893363237380981 for ['[CLS] monthly )al term movement cousin be owned [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.781 (perp=11.256, rec=0.559, cos=0.970), tot_loss_proj:4.151 [t=0.18s]
prediction: ['[CLS] makes nodded. withoutович lawsuit less organized [SEP]']
[ 100/2000] tot_loss=3.573 (perp=10.523, rec=0.528, cos=0.940), tot_loss_proj:4.041 [t=0.26s]
prediction: ['[CLS] no smith. smith invited lawsuit attendance documentary [SEP]']
[ 150/2000] tot_loss=3.379 (perp=10.011, rec=0.438, cos=0.938), tot_loss_proj:3.853 [t=0.27s]
prediction: ['[CLS] no smith smith without attending meeting meeting meeting [SEP]']
[ 200/2000] tot_loss=3.751 (perp=9.561, rec=0.861, cos=0.978), tot_loss_proj:3.837 [t=0.22s]
prediction: ['[CLS] no smith smith. attending meeting meeting meeting [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.792 (perp=11.255, rec=0.593, cos=0.948), tot_loss_proj:4.154 [t=0.18s]
prediction: ['[CLS] john smith attended novirus smithsonian than lunch [SEP]']
[ 300/2000] tot_loss=3.350 (perp=9.581, rec=0.495, cos=0.938), tot_loss_proj:3.830 [t=0.18s]
prediction: ['[CLS] john smith attended no awards attend the arrival [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.057 (perp=8.449, rec=0.446, cos=0.922), tot_loss_proj:3.626 [t=0.18s]
prediction: ['[CLS] john smith attended no meeting attend the arrival [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.536 (perp=10.984, rec=0.446, cos=0.893), tot_loss_proj:4.118 [t=0.19s]
prediction: ['[CLS] smith smith attended handball meeting arrive attendance moment [SEP]']
[ 450/2000] tot_loss=3.610 (perp=11.588, rec=0.391, cos=0.901), tot_loss_proj:4.256 [t=0.25s]
prediction: ['[CLS] no smith attended handball meetingius attendance moment [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.370 (perp=10.455, rec=0.377, cos=0.903), tot_loss_proj:4.000 [t=0.23s]
prediction: ['[CLS] no smith attended moment handball meeting sc attendance [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.328 (perp=10.317, rec=0.363, cos=0.901), tot_loss_proj:3.932 [t=0.21s]
prediction: ['[CLS] no smith attended no meeting handballius attendance [SEP]']
[ 600/2000] tot_loss=3.321 (perp=10.317, rec=0.350, cos=0.908), tot_loss_proj:3.933 [t=0.18s]
prediction: ['[CLS] no smith attended no meeting handballius attendance [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.161 (perp=9.552, rec=0.343, cos=0.908), tot_loss_proj:3.852 [t=0.23s]
prediction: ['[CLS] no smith attended no aye manuscript meeting attendance [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.266 (perp=10.109, rec=0.337, cos=0.907), tot_loss_proj:3.998 [t=0.22s]
prediction: ['[CLS] no smith attended no ayeian meeting attendance [SEP]']
[ 750/2000] tot_loss=3.267 (perp=10.109, rec=0.333, cos=0.911), tot_loss_proj:4.001 [t=0.18s]
prediction: ['[CLS] no smith attended no ayeian meeting attendance [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=3.263 (perp=10.102, rec=0.329, cos=0.914), tot_loss_proj:3.901 [t=0.23s]
prediction: ['[CLS] no smith manuscript attended which aye meeting the [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=3.179 (perp=9.679, rec=0.331, cos=0.912), tot_loss_proj:3.812 [t=0.22s]
prediction: ['[CLS] no smith attended which aye meeting the arrivals [SEP]']
[ 900/2000] tot_loss=3.369 (perp=10.580, rec=0.337, cos=0.916), tot_loss_proj:3.999 [t=0.23s]
prediction: ['[CLS] no smith attended which lamp meeting the conduct [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.247 (perp=9.994, rec=0.333, cos=0.916), tot_loss_proj:3.870 [t=0.19s]
prediction: ['[CLS] no smith attended which conduct meeting blu lamp [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.333 (perp=10.461, rec=0.325, cos=0.916), tot_loss_proj:3.939 [t=0.22s]
prediction: ['[CLS] no smith attended which meeting blu lamp arrivals [SEP]']
[1050/2000] tot_loss=3.367 (perp=10.584, rec=0.334, cos=0.916), tot_loss_proj:3.999 [t=0.18s]
prediction: ['[CLS] no smith attended any meeting blu lamp conduct [SEP]']
Attempt swap
[1100/2000] tot_loss=3.345 (perp=10.584, rec=0.312, cos=0.917), tot_loss_proj:3.998 [t=0.19s]
prediction: ['[CLS] no smith attended any meeting blu lamp conduct [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.996 (perp=8.796, rec=0.324, cos=0.913), tot_loss_proj:3.733 [t=0.26s]
prediction: ['[CLS] no smithian attended which meeting the lamp [SEP]']
[1200/2000] tot_loss=3.001 (perp=8.796, rec=0.325, cos=0.916), tot_loss_proj:3.731 [t=0.18s]
prediction: ['[CLS] no smithian attended which meeting the lamp [SEP]']
Attempt swap
[1250/2000] tot_loss=3.154 (perp=9.557, rec=0.326, cos=0.916), tot_loss_proj:3.845 [t=0.25s]
prediction: ['[CLS] no smithian attended any meeting the lamp [SEP]']
Attempt swap
[1300/2000] tot_loss=3.290 (perp=10.268, rec=0.319, cos=0.917), tot_loss_proj:3.970 [t=0.25s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
[1350/2000] tot_loss=3.288 (perp=10.268, rec=0.317, cos=0.917), tot_loss_proj:3.971 [t=0.20s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
Attempt swap
[1400/2000] tot_loss=3.280 (perp=10.268, rec=0.308, cos=0.918), tot_loss_proj:3.972 [t=0.19s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
Attempt swap
[1450/2000] tot_loss=3.286 (perp=10.268, rec=0.314, cos=0.918), tot_loss_proj:3.971 [t=0.23s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
[1500/2000] tot_loss=3.288 (perp=10.268, rec=0.317, cos=0.918), tot_loss_proj:3.976 [t=0.19s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
Attempt swap
[1550/2000] tot_loss=3.287 (perp=10.268, rec=0.315, cos=0.919), tot_loss_proj:3.973 [t=0.18s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
Attempt swap
[1600/2000] tot_loss=3.285 (perp=10.268, rec=0.312, cos=0.919), tot_loss_proj:3.976 [t=0.18s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
[1650/2000] tot_loss=3.286 (perp=10.268, rec=0.313, cos=0.919), tot_loss_proj:3.972 [t=0.21s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
Attempt swap
[1700/2000] tot_loss=3.287 (perp=10.268, rec=0.314, cos=0.919), tot_loss_proj:3.971 [t=0.22s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
Attempt swap
[1750/2000] tot_loss=3.289 (perp=10.268, rec=0.316, cos=0.920), tot_loss_proj:3.973 [t=0.18s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
[1800/2000] tot_loss=3.289 (perp=10.268, rec=0.315, cos=0.920), tot_loss_proj:3.973 [t=0.18s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
Attempt swap
[1850/2000] tot_loss=3.284 (perp=10.268, rec=0.310, cos=0.920), tot_loss_proj:3.973 [t=0.19s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
Attempt swap
[1900/2000] tot_loss=3.284 (perp=10.268, rec=0.311, cos=0.920), tot_loss_proj:3.972 [t=0.23s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
[1950/2000] tot_loss=3.289 (perp=10.268, rec=0.316, cos=0.920), tot_loss_proj:3.973 [t=0.18s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
Attempt swap
[2000/2000] tot_loss=3.276 (perp=10.268, rec=0.303, cos=0.920), tot_loss_proj:3.970 [t=0.22s]
prediction: ['[CLS] no smithian attended any meeting blu lamp [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] no john smiths attended the meeting. [SEP]
========================
predicted: 
========================
[CLS] no smithian attended any meeting blu lamp [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.824 | p: 55.556 | r: 62.500
rouge2     | fm: 13.333 | p: 12.500 | r: 14.286
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 72.157

[Aggregate metrics]:
rouge1     | fm: 80.412 | p: 80.258 | r: 80.825
rouge2     | fm: 37.611 | p: 37.593 | r: 37.787
rougeL     | fm: 68.909 | p: 68.848 | r: 69.159
rougeLsum  | fm: 68.975 | p: 68.916 | r: 69.218
r1fm+r2fm = 118.024

input #24 time: 0:08:18 | total time: 3:30:46


Running input #25 of 100.
reference: 
========================
I did not, as Bill had thought, go to the store.
========================
average of cosine similarity 0.9993283700816344
highest_index [0]
highest [0.9993283700816344]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2106, 2025, 1010, 2004, 3021, 2018, 2245, 1010, 2175, 2000,
         1996, 3573, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i did not, as bill had thought, go to the store. [SEP]']
[Init] best rec loss: 1.9017608165740967 for ['[CLS] zu sussex wig son committed koppen youth part sc missile combat carrier licence magazine [SEP]']
[Init] best rec loss: 1.900500774383545 for ['[CLS] air moisture each van kind pl tribes fulltou nod resolvedhesivevan affair [SEP]']
[Init] best rec loss: 1.8879952430725098 for ['[CLS] changingize fire lucky fee dream club example sniffedoverbling step over ship [SEP]']
[Init] best rec loss: 1.8765908479690552 for ['[CLS]ɛ 4 meanwhile wherever sindh hebrew college offers premiered mount growlingction santaerry [SEP]']
[Init] best rec loss: 1.8658175468444824 for ['[CLS] master wolf fog knuckles marines scale vest real rain miracle candidate fingernails urban everyone [SEP]']
[Init] best rec loss: 1.8552042245864868 for ['[CLS] ut floor metropolis policerates cpc ft undertitles king dir drawn ( independently [SEP]']
[Init] best rec loss: 1.8394663333892822 for ['[CLS] taxes middle waters viable started stockrea blessings zombieq position chinese crushed fact [SEP]']
[Init] best rec loss: 1.835187315940857 for ['[CLS] stars rest spread detail yet defect anythingditional strength sharp syndrome untilpathic empty [SEP]']
[Init] best perm rec loss: 1.8350266218185425 for ['[CLS] empty yet rest spread untilditional sharp anything detailpathic strength stars defect syndrome [SEP]']
[Init] best perm rec loss: 1.8339860439300537 for ['[CLS] empty detail sharp defect spread stars untilpathic syndromeditional strength anything rest yet [SEP]']
[Init] best perm rec loss: 1.8323661088943481 for ['[CLS] rest empty stars detail strength anythingpathic spread until sharp syndrome yet defectditional [SEP]']
[Init] best perm rec loss: 1.8307204246520996 for ['[CLS] rest anything empty yet stars untilditional spread strengthpathic syndrome defect sharp detail [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.334 (perp=13.955, rec=0.457, cos=0.086), tot_loss_proj:4.614 [t=0.23s]
prediction: ['[CLS] leroy father contract trenton neutron david glen witness academic would named. expected also [SEP]']
[ 100/2000] tot_loss=2.815 (perp=11.799, rec=0.402, cos=0.053), tot_loss_proj:4.297 [t=0.28s]
prediction: ['[CLS] i, gubernatorial [ store parish buildings crash. would ;. [SEP] has [SEP]']
[ 150/2000] tot_loss=2.350 (perp=10.000, rec=0.325, cos=0.025), tot_loss_proj:3.922 [t=0.31s]
prediction: ['[CLS] i, suit - thought bill also leave. would ;. bill have [SEP]']
[ 200/2000] tot_loss=1.979 (perp=8.172, rec=0.320, cos=0.025), tot_loss_proj:3.472 [t=0.24s]
prediction: ['[CLS] i not drinking - thought bill ( coat as would,. bill. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.886 (perp=9.973, rec=0.898, cos=0.994), tot_loss_proj:3.958 [t=0.19s]
prediction: ['[CLS] meant no commercial ( giant. villains cold house disappear... rugby [SEP]']
[ 300/2000] tot_loss=3.948 (perp=10.995, rec=0.784, cos=0.965), tot_loss_proj:4.124 [t=0.18s]
prediction: ['[CLS] seenfer commercial ; giant. villains armed located greek?.. batsman [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=3.685 (perp=9.935, rec=0.735, cos=0.964), tot_loss_proj:3.891 [t=0.18s]
prediction: ['[CLS].. batsman meantfer england ; store. villains armed located shoe. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.460 (perp=8.986, rec=0.700, cos=0.962), tot_loss_proj:3.726 [t=0.18s]
prediction: ['[CLS].. ─ meant not england ; store. armed villains locatedieg. [SEP]']
[ 450/2000] tot_loss=3.573 (perp=9.739, rec=0.666, cos=0.960), tot_loss_proj:3.879 [t=0.23s]
prediction: ['[CLS].. boost meant not england ; store. armed secondary locatedieg. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.499 (perp=9.457, rec=0.650, cos=0.957), tot_loss_proj:3.825 [t=0.18s]
prediction: ['[CLS]. ; boost meant not england ; armed store. secondary locatedieg. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.369 (perp=8.902, rec=0.639, cos=0.949), tot_loss_proj:3.712 [t=0.21s]
prediction: ['[CLS]. ; blow meant not casino ; armed store. british locatedieg. [SEP]']
[ 600/2000] tot_loss=3.713 (perp=10.738, rec=0.618, cos=0.948), tot_loss_proj:4.094 [t=0.18s]
prediction: ['[CLS]. particularly blow meant car secondary ; armed store. british locatedieg. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.606 (perp=10.248, rec=0.610, cos=0.946), tot_loss_proj:3.970 [t=0.25s]
prediction: ['[CLS]. particularly blow ; car secondary meant armed store.ing locatedieg. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.533 (perp=9.888, rec=0.605, cos=0.951), tot_loss_proj:3.928 [t=0.18s]
prediction: ['[CLS]. particularly - ; car secondary meant armed store. blow locatedieg. [SEP]']
[ 750/2000] tot_loss=3.518 (perp=9.918, rec=0.589, cos=0.945), tot_loss_proj:3.926 [t=0.22s]
prediction: ['[CLS]. particularlying ; car secondary meant armed store. blow locatedieg. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.503 (perp=9.896, rec=0.581, cos=0.943), tot_loss_proj:3.906 [t=0.26s]
prediction: ['[CLS]. particularlying, car secondary meant armed store. blow locatedieg. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.361 (perp=9.175, rec=0.598, cos=0.927), tot_loss_proj:3.777 [t=0.27s]
prediction: ['[CLS]. particularlying, located casino meant armed store. blow carieg. [SEP]']
[ 900/2000] tot_loss=3.366 (perp=9.281, rec=0.579, cos=0.931), tot_loss_proj:3.774 [t=0.18s]
prediction: ['[CLS]. particularlying ; located casino meant armed store. blow carieg. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.329 (perp=9.129, rec=0.573, cos=0.931), tot_loss_proj:3.740 [t=0.26s]
prediction: ['[CLS]. especiallying ; located casino meant armed store. blow carieg. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.327 (perp=9.129, rec=0.571, cos=0.930), tot_loss_proj:3.740 [t=0.22s]
prediction: ['[CLS]. especiallying ; located casino meant armed store. blow carieg. [SEP]']
[1050/2000] tot_loss=3.320 (perp=9.129, rec=0.565, cos=0.928), tot_loss_proj:3.742 [t=0.18s]
prediction: ['[CLS]. especiallying ; located casino meant armed store. blow carieg. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.216 (perp=8.607, rec=0.569, cos=0.926), tot_loss_proj:3.616 [t=0.18s]
prediction: ['[CLS]. especially armed ; located casino meanting store. blow carieg. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.237 (perp=8.736, rec=0.567, cos=0.923), tot_loss_proj:3.689 [t=0.24s]
prediction: ['[CLS]. especially armed, located casino meanting store. blow carieg. [SEP]']
[1200/2000] tot_loss=3.232 (perp=8.736, rec=0.562, cos=0.922), tot_loss_proj:3.688 [t=0.23s]
prediction: ['[CLS]. especially armed, located casino meanting store. blow carieg. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.229 (perp=8.736, rec=0.560, cos=0.922), tot_loss_proj:3.685 [t=0.18s]
prediction: ['[CLS]. especially armed, located casino meanting store. blow carieg. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.224 (perp=8.736, rec=0.556, cos=0.921), tot_loss_proj:3.683 [t=0.26s]
prediction: ['[CLS]. especially armed, located casino meanting store. blow carieg. [SEP]']
[1350/2000] tot_loss=3.220 (perp=8.736, rec=0.552, cos=0.921), tot_loss_proj:3.685 [t=0.19s]
prediction: ['[CLS]. especially armed, located casino meanting store. blow carieg. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.364 (perp=9.467, rec=0.550, cos=0.921), tot_loss_proj:3.821 [t=0.26s]
prediction: ['[CLS]. especially armed, club casino meanting store. blow carzo. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=3.336 (perp=9.317, rec=0.555, cos=0.918), tot_loss_proj:3.753 [t=0.19s]
prediction: ['[CLS]. especially armed, meant casino locateding store. blow carzo. [SEP]']
[1500/2000] tot_loss=3.438 (perp=9.876, rec=0.545, cos=0.918), tot_loss_proj:3.877 [t=0.18s]
prediction: ['[CLS]. especially armed, meant casino understooding store. blow carzo. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=3.237 (perp=8.858, rec=0.545, cos=0.920), tot_loss_proj:3.657 [t=0.26s]
prediction: ['[CLS]. especially armed, understood casino meanting store. blow car jeans. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.294 (perp=9.131, rec=0.548, cos=0.920), tot_loss_proj:3.714 [t=0.19s]
prediction: ['[CLS]. especially armed, understood casino meanting store. blow carzo. [SEP]']
[1650/2000] tot_loss=3.285 (perp=9.131, rec=0.539, cos=0.920), tot_loss_proj:3.719 [t=0.23s]
prediction: ['[CLS]. especially armed, understood casino meanting store. blow carzo. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.292 (perp=9.131, rec=0.546, cos=0.920), tot_loss_proj:3.718 [t=0.25s]
prediction: ['[CLS]. especially armed, understood casino meanting store. blow carzo. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.287 (perp=9.131, rec=0.541, cos=0.919), tot_loss_proj:3.715 [t=0.25s]
prediction: ['[CLS]. especially armed, understood casino meanting store. blow carzo. [SEP]']
[1800/2000] tot_loss=3.356 (perp=9.467, rec=0.543, cos=0.919), tot_loss_proj:3.824 [t=0.19s]
prediction: ['[CLS]. especially armed, club casino meanting store. blow carzo. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=3.433 (perp=9.876, rec=0.544, cos=0.915), tot_loss_proj:3.883 [t=0.22s]
prediction: ['[CLS]. especially armed, meant casino understooding store. blow carzo. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=3.384 (perp=9.590, rec=0.551, cos=0.915), tot_loss_proj:3.853 [t=0.18s]
prediction: ['[CLS]. especially armed, meant casino understood storeing. blow carzo. [SEP]']
[1950/2000] tot_loss=3.376 (perp=9.590, rec=0.543, cos=0.915), tot_loss_proj:3.854 [t=0.22s]
prediction: ['[CLS]. especially armed, meant casino understood storeing. blow carzo. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=3.277 (perp=9.060, rec=0.546, cos=0.918), tot_loss_proj:3.708 [t=0.19s]
prediction: ['[CLS]. especially armed, understood casino meant storeing. blow carzo. [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] i did not, as bill had thought, go to the store. [SEP]
========================
predicted: 
========================
[CLS] i not going - thought bill ( coat as would,. bill. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.333 | p: 63.636 | r: 53.846
rouge2     | fm: 9.091 | p: 10.000 | r: 8.333
rougeL     | fm: 50.000 | p: 54.545 | r: 46.154
rougeLsum  | fm: 50.000 | p: 54.545 | r: 46.154
r1fm+r2fm = 67.424

[Aggregate metrics]:
rouge1     | fm: 79.629 | p: 79.715 | r: 79.850
rouge2     | fm: 36.418 | p: 36.330 | r: 36.549
rougeL     | fm: 68.309 | p: 68.429 | r: 68.380
rougeLsum  | fm: 68.314 | p: 68.426 | r: 68.397
r1fm+r2fm = 116.047

input #25 time: 0:08:25 | total time: 3:39:12


Running input #26 of 100.
reference: 
========================
Who will John ask for information about summer courses?
========================
average of cosine similarity 0.9994149465253206
highest_index [0]
highest [0.9994149465253206]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2040, 2097, 2198, 3198, 2005, 2592, 2055, 2621, 5352, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] who will john ask for information about summer courses? [SEP]']
[Init] best rec loss: 1.8347195386886597 for ['[CLS] certified bowedhorn ( lunch dedicated normally played stones nj [SEP]']
[Init] best rec loss: 1.8226964473724365 for ['[CLS] choice guo mn arc myself peterice sight weigh second [SEP]']
[Init] best rec loss: 1.80668306350708 for ['[CLS] rock mel stagelowejic sql certain umbrella yank stand [SEP]']
[Init] best rec loss: 1.796655535697937 for ['[CLS] brotherhooddial tequila rhapsody suspensiongilfide hydro janice talk [SEP]']
[Init] best rec loss: 1.7534185647964478 for ['[CLS] hardy built offered despite sewing sick greyhound bands third god [SEP]']
[Init] best perm rec loss: 1.7530946731567383 for ['[CLS] despite built sewing offered hardy bands third greyhound god sick [SEP]']
[Init] best perm rec loss: 1.750139832496643 for ['[CLS] hardy greyhound offered sewing sick despite god built third bands [SEP]']
[Init] best perm rec loss: 1.7495524883270264 for ['[CLS] despite sewing god offered built greyhound third bands hardy sick [SEP]']
[Init] best perm rec loss: 1.7456679344177246 for ['[CLS] greyhound hardy bands sick sewing god built offered third despite [SEP]']
[Init] best perm rec loss: 1.7456462383270264 for ['[CLS] sewing god sick built greyhound offered despite bands hardy third [SEP]']
[Init] best perm rec loss: 1.7442572116851807 for ['[CLS] greyhound offered god built sewing bands hardy third sick despite [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.073 (perp=11.412, rec=0.497, cos=0.293), tot_loss_proj:4.178 [t=0.18s]
prediction: ['[CLS]pha shouting round social end? inside? why magnus [SEP]']
[ 100/2000] tot_loss=2.809 (perp=11.387, rec=0.427, cos=0.105), tot_loss_proj:4.090 [t=0.23s]
prediction: ['[CLS] pay shouting poker asked morning for inside? willicular [SEP]']
[ 150/2000] tot_loss=1.971 (perp=7.992, rec=0.323, cos=0.050), tot_loss_proj:3.531 [t=0.26s]
prediction: ['[CLS] who could ask asked knowing for news? will john [SEP]']
[ 200/2000] tot_loss=1.915 (perp=7.788, rec=0.288, cos=0.070), tot_loss_proj:3.308 [t=0.18s]
prediction: ['[CLS] who will ask scholar information for information? will john [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.789 (perp=7.788, rec=0.210, cos=0.021), tot_loss_proj:3.306 [t=0.19s]
prediction: ['[CLS] who will ask scholar information for information? will john [SEP]']
[ 300/2000] tot_loss=1.673 (perp=7.416, rec=0.172, cos=0.017), tot_loss_proj:2.806 [t=0.19s]
prediction: ['[CLS] who will ask summer information for information? will john [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.544 (perp=7.109, rec=0.117, cos=0.006), tot_loss_proj:3.310 [t=0.19s]
prediction: ['[CLS] who will ask john summer information for information? will [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.520 (perp=7.109, rec=0.095, cos=0.003), tot_loss_proj:3.308 [t=0.18s]
prediction: ['[CLS] who will ask john summer information for information? will [SEP]']
[ 450/2000] tot_loss=1.760 (perp=8.319, rec=0.094, cos=0.003), tot_loss_proj:3.530 [t=0.25s]
prediction: ['[CLS] who information ask john summer asking for information? will [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.711 (perp=8.115, rec=0.085, cos=0.003), tot_loss_proj:3.557 [t=0.23s]
prediction: ['[CLS] who information john ask summer asking for information? will [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.704 (perp=8.115, rec=0.078, cos=0.002), tot_loss_proj:3.565 [t=0.28s]
prediction: ['[CLS] who information john ask summer asking for information? will [SEP]']
[ 600/2000] tot_loss=1.820 (perp=8.680, rec=0.082, cos=0.002), tot_loss_proj:3.711 [t=0.19s]
prediction: ['[CLS] who information john ask summer ask for information? will [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.812 (perp=8.680, rec=0.074, cos=0.002), tot_loss_proj:3.710 [t=0.22s]
prediction: ['[CLS] who information john ask summer ask for information? will [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.655 (perp=7.804, rec=0.090, cos=0.004), tot_loss_proj:3.498 [t=0.19s]
prediction: ['[CLS] who information john ask summer will ask for information? [SEP]']
[ 750/2000] tot_loss=1.645 (perp=7.804, rec=0.082, cos=0.002), tot_loss_proj:3.501 [t=0.19s]
prediction: ['[CLS] who information john ask summer will ask for information? [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.637 (perp=7.804, rec=0.074, cos=0.002), tot_loss_proj:3.496 [t=0.18s]
prediction: ['[CLS] who information john ask summer will ask for information? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.635 (perp=7.804, rec=0.072, cos=0.002), tot_loss_proj:3.490 [t=0.18s]
prediction: ['[CLS] who information john ask summer will ask for information? [SEP]']
[ 900/2000] tot_loss=1.639 (perp=7.804, rec=0.076, cos=0.002), tot_loss_proj:3.487 [t=0.26s]
prediction: ['[CLS] who information john ask summer will ask for information? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.649 (perp=7.804, rec=0.086, cos=0.002), tot_loss_proj:3.499 [t=0.19s]
prediction: ['[CLS] who information john ask summer will ask for information? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.641 (perp=7.804, rec=0.078, cos=0.002), tot_loss_proj:3.497 [t=0.18s]
prediction: ['[CLS] who information john ask summer will ask for information? [SEP]']
[1050/2000] tot_loss=1.641 (perp=7.804, rec=0.078, cos=0.002), tot_loss_proj:3.501 [t=0.18s]
prediction: ['[CLS] who information john ask summer will ask for information? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.595 (perp=7.615, rec=0.070, cos=0.002), tot_loss_proj:3.421 [t=0.21s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.606 (perp=7.615, rec=0.081, cos=0.002), tot_loss_proj:3.421 [t=0.19s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
[1200/2000] tot_loss=1.611 (perp=7.615, rec=0.086, cos=0.002), tot_loss_proj:3.421 [t=0.20s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.599 (perp=7.615, rec=0.074, cos=0.002), tot_loss_proj:3.419 [t=0.24s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.600 (perp=7.615, rec=0.076, cos=0.002), tot_loss_proj:3.422 [t=0.24s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
[1350/2000] tot_loss=1.597 (perp=7.615, rec=0.073, cos=0.002), tot_loss_proj:3.421 [t=0.18s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.601 (perp=7.615, rec=0.076, cos=0.002), tot_loss_proj:3.424 [t=0.19s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.595 (perp=7.615, rec=0.070, cos=0.002), tot_loss_proj:3.421 [t=0.21s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
[1500/2000] tot_loss=1.596 (perp=7.615, rec=0.071, cos=0.002), tot_loss_proj:3.418 [t=0.19s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.599 (perp=7.615, rec=0.074, cos=0.002), tot_loss_proj:3.422 [t=0.28s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.593 (perp=7.615, rec=0.068, cos=0.002), tot_loss_proj:3.427 [t=0.20s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
[1650/2000] tot_loss=1.596 (perp=7.615, rec=0.071, cos=0.002), tot_loss_proj:3.422 [t=0.23s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.598 (perp=7.615, rec=0.074, cos=0.002), tot_loss_proj:3.424 [t=0.25s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.595 (perp=7.615, rec=0.070, cos=0.002), tot_loss_proj:3.422 [t=0.18s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
[1800/2000] tot_loss=1.595 (perp=7.615, rec=0.070, cos=0.002), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.591 (perp=7.615, rec=0.066, cos=0.002), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.596 (perp=7.615, rec=0.072, cos=0.002), tot_loss_proj:3.422 [t=0.18s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
[1950/2000] tot_loss=1.601 (perp=7.615, rec=0.076, cos=0.002), tot_loss_proj:3.423 [t=0.22s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.596 (perp=7.615, rec=0.071, cos=0.002), tot_loss_proj:3.424 [t=0.19s]
prediction: ['[CLS] who about john ask summer will ask for information? [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] who will john ask for information about summer courses? [SEP]
========================
predicted: 
========================
[CLS] who about john ask summer will ask for information? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 130.909

[Aggregate metrics]:
rouge1     | fm: 80.029 | p: 80.036 | r: 80.269
rouge2     | fm: 36.443 | p: 36.422 | r: 36.557
rougeL     | fm: 68.169 | p: 68.212 | r: 68.207
rougeLsum  | fm: 68.024 | p: 68.216 | r: 67.995
r1fm+r2fm = 116.472

input #26 time: 0:08:28 | total time: 3:47:40


Running input #27 of 100.
reference: 
========================
Ron wanted to wear a tuxedo to the party, but Caspar couldn't decide whether to.
========================
average of cosine similarity 0.9993526850364247
highest_index [0]
highest [0.9993526850364247]
Debug: ids_shape = 24, pads = [24]
Debug: input ids = tensor([[  101,  6902,  2359,  2000,  4929,  1037, 10722, 19068,  2080,  2000,
          1996,  2283,  1010,  2021, 25222, 19362,  2481,  1005,  1056,  5630,
          3251,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]"]
[Init] best rec loss: 1.9052623510360718 for ['[CLS]ig operated already block sad pac further armenians songs, fund book waters line buy willis relief strike collaborative tack violet bring [SEP]']
[Init] best rec loss: 1.8660808801651 for ['[CLS]bro hardcover surprise audience viewpoint... inc along protective speechless [UNK] /orough cureling dyed [MASK] eggschan mccarthy such asean [SEP]']
[Init] best rec loss: 1.8649427890777588 for ['[CLS]vent fromriety belmont kill telephone directions matches director throughout cerebral circuit thrusts million us medicine cause multi tone domesdaydity fireworks [SEP]']
[Init] best rec loss: 1.8633061647415161 for ['[CLS] breathing neighborhoodain shooting less avoidingalis mass cards by cratesver song hellrov italian imperial substance protections intelligence chronicles campuses [SEP]']
[Init] best perm rec loss: 1.8594352006912231 for ['[CLS] neighborhood song campuses chronicles imperial by crates avoidingalis mass intelligence cardsain protectionsver hellrov italian shooting substance breathing less [SEP]']
[Init] best perm rec loss: 1.8582879304885864 for ['[CLS]veralis intelligence hell italian campuses shooting imperial breathingrov mass neighborhood substance protections cards by song less cratesain chronicles avoiding [SEP]']
[Init] best perm rec loss: 1.8582007884979248 for ['[CLS]ain byalis protections avoiding crates substance breathingrov cards neighborhood campuses song intelligence chronicles lessver italian hell shooting mass imperial [SEP]']
[Init] best perm rec loss: 1.8573405742645264 for ['[CLS]verrov campuses substance mass chronicles breathing neighborhood italianain cards protections by intelligence crates shooting imperial avoidingalis hell song less [SEP]']
[Init] best perm rec loss: 1.8572800159454346 for ['[CLS] intelligenceainalis substance cards hell less song italian protections neighborhood imperial crates avoidingrovver chronicles mass shooting campuses by breathing [SEP]']
[Init] best perm rec loss: 1.8572150468826294 for ['[CLS] avoiding campuses by crates massainrov hell less imperial neighborhood italian intelligence substance protections breathing cards shootingver chronicles songalis [SEP]']
[Init] best perm rec loss: 1.8562687635421753 for ['[CLS]ver campuses substance crates song neighborhoodrov mass protections by intelligenceain hell imperial breathing cards chronicles italian shootingalis less avoiding [SEP]']
[Init] best perm rec loss: 1.8560720682144165 for ['[CLS] italianain campuses neighborhood imperial cratesalis by breathing songrov mass substance protections shooting hell chronicles less cards intelligencever avoiding [SEP]']
[Init] best perm rec loss: 1.8549994230270386 for ['[CLS] intelligence protections avoiding cardsrov less imperial massver chronicles campuses italian hellalis breathing song by substanceain shooting crates neighborhood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.207 (perp=13.359, rec=0.411, cos=0.125), tot_loss_proj:4.535 [t=0.23s]
prediction: ['[CLS] gal customs typically the - is ridge once trip arthur [SEP].ive member features law isman missing findingwright wig [SEP]']
[ 100/2000] tot_loss=2.754 (perp=12.273, rec=0.269, cos=0.030), tot_loss_proj:4.297 [t=0.18s]
prediction: ['[CLS] ron customs pretty the caspar ron miniature trip ron [SEP]. reasons member chance whether - himself missing tyler wes wig [SEP]']
[ 150/2000] tot_loss=2.520 (perp=10.858, rec=0.294, cos=0.054), tot_loss_proj:4.010 [t=0.19s]
prediction: ['[CLS] ron chicken wanted the caspar ron under trip ron could but irish member chance whether was himself wanted danny wes. [SEP]']
[ 200/2000] tot_loss=2.415 (perp=11.001, rec=0.200, cos=0.015), tot_loss_proj:4.013 [t=0.19s]
prediction: ['[CLS] ron buttons wanted cas caspar ron to torture ron could but irishder chance cas - herself wanted although liam. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.239 (perp=10.341, rec=0.161, cos=0.010), tot_loss_proj:3.946 [t=0.23s]
prediction: ["[CLS] ron buttons wanted cas caspar ron to want ron could'irish but whether cas - couldn wanted stitch whether. [SEP]"]
[ 300/2000] tot_loss=2.042 (perp=9.470, rec=0.140, cos=0.008), tot_loss_proj:3.704 [t=0.19s]
prediction: ["[CLS] ron necklace wanted a caspar ron to! ron could'framed but whether whether - couldn want stitch whether. [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.363 (perp=11.038, rec=0.145, cos=0.011), tot_loss_proj:4.049 [t=0.22s]
prediction: ["[CLS] ron wear wanted caspar cas ron a party ron could'framed but whether whether brows couldn to jackie whatever. [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.488 (perp=10.696, rec=0.298, cos=0.051), tot_loss_proj:3.963 [t=0.20s]
prediction: ['[CLS] ron wear wanted caspar old ron large party ron wants wife wearing but to decide mechanical pursed could heck bringing. [SEP]']
[ 450/2000] tot_loss=2.309 (perp=10.531, rec=0.187, cos=0.017), tot_loss_proj:3.951 [t=0.28s]
prediction: ['[CLS] ron wear wanted caspar old mo large party ron wants dog wearing but to decide route chosen could savoy domingo. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.079 (perp=9.577, rec=0.152, cos=0.011), tot_loss_proj:3.787 [t=0.25s]
prediction: ['[CLS] ron wanted caspar wear thexed large party ron wants dog wearing but to decide to regarding could savoy whether. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.997 (perp=9.188, rec=0.149, cos=0.010), tot_loss_proj:3.720 [t=0.28s]
prediction: ['[CLS] ron wanted caspar wear thexed tu party ron wants dog wearing but could decide to regarding to dixie whether. [SEP]']
[ 600/2000] tot_loss=2.057 (perp=9.539, rec=0.142, cos=0.008), tot_loss_proj:3.762 [t=0.30s]
prediction: ['[CLS] ron wanted caspar wear thexed tu party ron wants dog wearing but couldn decide to regarding to sonya whether. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.981 (perp=9.202, rec=0.134, cos=0.007), tot_loss_proj:3.706 [t=0.25s]
prediction: ['[CLS] ron wanted caspar wear the tuxed party ron wants dog wear but couldn decide to regarding to sonya whether. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.972 (perp=9.138, rec=0.138, cos=0.006), tot_loss_proj:3.707 [t=0.23s]
prediction: ['[CLS] ron wanted caspar wear the tuxed party ron wants dog wear but couldn decide to whether to sonya whether. [SEP]']
[ 750/2000] tot_loss=1.947 (perp=9.086, rec=0.124, cos=0.006), tot_loss_proj:3.712 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear the tuxed party ron wants dog wear but couldn decide to whether toply whether. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.899 (perp=8.859, rec=0.121, cos=0.006), tot_loss_proj:3.691 [t=0.18s]
prediction: ['[CLS] ron wanted caspar wear the tuxed party ron wants to wear but couldn decide dog whether toply whether. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.433 (perp=11.064, rec=0.192, cos=0.028), tot_loss_proj:4.094 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear bon tuxed party ron stayed if wear but couldn decide whether to dog⁄ whether. [SEP]']
[ 900/2000] tot_loss=2.310 (perp=10.785, rec=0.144, cos=0.009), tot_loss_proj:4.022 [t=0.18s]
prediction: ['[CLS] ron wanted caspar wear 1st tu km party ron though whether wear but couldn decide whether to " which whether. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.199 (perp=10.246, rec=0.142, cos=0.008), tot_loss_proj:3.917 [t=0.20s]
prediction: ['[CLS] ron wanted caspar wear 1stxed party ron though whether tu wear but couldn decide whether to " which whether. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.171 (perp=10.152, rec=0.133, cos=0.007), tot_loss_proj:3.909 [t=0.18s]
prediction: ['[CLS] ron wanted caspar wear "xed party ron though whether tu wear but couldn decide whether to 1st⁄ whether. [SEP]']
[1050/2000] tot_loss=2.167 (perp=10.152, rec=0.130, cos=0.007), tot_loss_proj:3.910 [t=0.20s]
prediction: ['[CLS] ron wanted caspar wear "xed party ron though whether tu wear but couldn decide whether to 1st⁄ whether. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.118 (perp=9.939, rec=0.124, cos=0.007), tot_loss_proj:3.840 [t=0.24s]
prediction: ['[CLS] ron wanted caspar wear " signed party ron though whether tu wear but couldn decide whether whether to 1st⁄. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.059 (perp=9.669, rec=0.118, cos=0.007), tot_loss_proj:3.779 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear " whether party ron though signed tu wear but couldn decide whether whether to 1st⁄. [SEP]']
[1200/2000] tot_loss=2.009 (perp=9.408, rec=0.121, cos=0.006), tot_loss_proj:3.726 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear " whether party ron did signed tu wear but couldn decide whether party to 1st⁄. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.968 (perp=9.192, rec=0.123, cos=0.006), tot_loss_proj:3.729 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear " whether party ron did party tu wear but couldn decide whether signed to 1st⁄. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.958 (perp=9.119, rec=0.127, cos=0.007), tot_loss_proj:3.692 [t=0.22s]
prediction: ['[CLS] ron wanted caspar wear " whether party ron did party 1st wear but couldn decide whether signed to tu⁄. [SEP]']
[1350/2000] tot_loss=1.930 (perp=9.041, rec=0.116, cos=0.006), tot_loss_proj:3.652 [t=0.26s]
prediction: ['[CLS] ron wanted caspar wear " whether party ron did party every wear but couldn decide whether signed to tu⁄. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.918 (perp=8.974, rec=0.117, cos=0.006), tot_loss_proj:3.663 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear " whether party⁄ did party every wear but couldn decide whether signed to tu ron. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.885 (perp=8.834, rec=0.113, cos=0.006), tot_loss_proj:3.635 [t=0.23s]
prediction: ['[CLS] ron wanted caspar wear " whether party party did⁄ every wear but couldn decide whether signed to tu ron. [SEP]']
[1500/2000] tot_loss=1.908 (perp=8.960, rec=0.111, cos=0.005), tot_loss_proj:3.658 [t=0.24s]
prediction: ['[CLS] ron wanted caspar wear " whether party party did⁄ the wear but couldn decide whether signed to tu ron. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.959 (perp=9.169, rec=0.119, cos=0.006), tot_loss_proj:3.691 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear " whether party party did but the wear⁄ couldn decide whether tu to tu ron. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.898 (perp=8.840, rec=0.124, cos=0.006), tot_loss_proj:3.589 [t=0.18s]
prediction: ['[CLS] ron wanted caspar wear " whether party tu did but the wear whether couldn decide whether tu to party ron. [SEP]']
[1650/2000] tot_loss=1.886 (perp=8.840, rec=0.113, cos=0.005), tot_loss_proj:3.597 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear " whether party tu did but the wear whether couldn decide whether tu to party ron. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.769 (perp=8.228, rec=0.118, cos=0.006), tot_loss_proj:3.520 [t=0.26s]
prediction: ['[CLS] ron wanted caspar wear " whether party tu did but the wear whether tu couldn decide whether to party ron. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.711 (perp=7.941, rec=0.117, cos=0.007), tot_loss_proj:3.468 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear " whether the party tu did but wear whether tu couldn decide whether to party ron. [SEP]']
[1800/2000] tot_loss=1.713 (perp=7.941, rec=0.119, cos=0.006), tot_loss_proj:3.469 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear " whether the party tu did but wear whether tu couldn decide whether to party ron. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.876 (perp=8.780, rec=0.115, cos=0.005), tot_loss_proj:3.589 [t=0.24s]
prediction: ['[CLS] ron wanted caspar wear " whether the party tu did but wear whether party signed couldn decide whether to ron. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.837 (perp=8.597, rec=0.113, cos=0.005), tot_loss_proj:3.554 [t=0.19s]
prediction: ['[CLS] ron wanted caspar wear " whether the party signed did but wear whether party tu couldn decide whether to ron. [SEP]']
[1950/2000] tot_loss=1.836 (perp=8.597, rec=0.111, cos=0.005), tot_loss_proj:3.558 [t=0.18s]
prediction: ['[CLS] ron wanted caspar wear " whether the party signed did but wear whether party tu couldn decide whether to ron. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.796 (perp=8.398, rec=0.111, cos=0.005), tot_loss_proj:3.511 [t=0.25s]
prediction: ['[CLS] ron wanted caspar wear " to the party signed but did wear whether party tu couldn decide whether to ron. [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] ron wanted to wear a tuxedo to the party, but caspar couldn't decide whether to. [SEP]
========================
predicted: 
========================
[CLS] ron wanted caspar wear " to the party signed but did wear whether party tu couldn decide whether to ron. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.795 | p: 66.667 | r: 77.778
rouge2     | fm: 32.432 | p: 30.000 | r: 35.294
rougeL     | fm: 66.667 | p: 61.905 | r: 72.222
rougeLsum  | fm: 66.667 | p: 61.905 | r: 72.222
r1fm+r2fm = 104.227

[Aggregate metrics]:
rouge1     | fm: 79.679 | p: 79.584 | r: 80.061
rouge2     | fm: 36.447 | p: 36.344 | r: 36.628
rougeL     | fm: 67.976 | p: 67.972 | r: 68.279
rougeLsum  | fm: 68.077 | p: 68.099 | r: 68.455
r1fm+r2fm = 116.126

input #27 time: 0:08:36 | total time: 3:56:16


Running input #28 of 100.
reference: 
========================
Bill gave Sue the book.
========================
average of cosine similarity 0.9992527833287079
highest_index [0]
highest [0.9992527833287079]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 3021, 2435, 9790, 1996, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bill gave sue the book. [SEP]']
[Init] best rec loss: 1.8090617656707764 for ['[CLS] martin links ponder _ borntist [SEP]']
[Init] best rec loss: 1.7971588373184204 for ['[CLS] current crossing " written mast tracking [SEP]']
[Init] best rec loss: 1.784091830253601 for ['[CLS] [SEP] into whom computer unofficial se [SEP]']
[Init] best rec loss: 1.7711749076843262 for ['[CLS]fold determination humour td limit supplies [SEP]']
[Init] best rec loss: 1.7654660940170288 for ['[CLS]back rock yun su nothing col [SEP]']
[Init] best perm rec loss: 1.7637385129928589 for ['[CLS] nothing rock colback su yun [SEP]']
[Init] best perm rec loss: 1.763046383857727 for ['[CLS]back nothing rock col su yun [SEP]']
[Init] best perm rec loss: 1.7615536451339722 for ['[CLS] rockback col nothing yun su [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.144 (perp=8.802, rec=0.324, cos=0.060), tot_loss_proj:3.407 [t=0.24s]
prediction: ['[CLS]. bill gave books. sue [SEP]']
[ 100/2000] tot_loss=1.905 (perp=8.420, rec=0.203, cos=0.018), tot_loss_proj:3.504 [t=0.28s]
prediction: ['[CLS]. bill gave book, sue [SEP]']
[ 150/2000] tot_loss=2.160 (perp=10.173, rec=0.117, cos=0.009), tot_loss_proj:3.920 [t=0.20s]
prediction: ['[CLS]. bill gave book the sue [SEP]']
[ 200/2000] tot_loss=1.895 (perp=9.014, rec=0.088, cos=0.005), tot_loss_proj:3.636 [t=0.19s]
prediction: ['[CLS]. bill gave book. sue [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.660 (perp=7.847, rec=0.087, cos=0.004), tot_loss_proj:3.503 [t=0.27s]
prediction: ['[CLS] bill gave the book. sue [SEP]']
[ 300/2000] tot_loss=1.546 (perp=7.279, rec=0.087, cos=0.003), tot_loss_proj:3.442 [t=0.27s]
prediction: ['[CLS] bill gave the book, sue [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.643 (perp=7.847, rec=0.071, cos=0.003), tot_loss_proj:3.501 [t=0.28s]
prediction: ['[CLS] bill gave the book. sue [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.544 (perp=7.260, rec=0.088, cos=0.003), tot_loss_proj:3.274 [t=0.26s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[ 450/2000] tot_loss=1.527 (perp=7.260, rec=0.072, cos=0.003), tot_loss_proj:3.276 [t=0.18s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.528 (perp=7.260, rec=0.073, cos=0.003), tot_loss_proj:3.272 [t=0.17s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.524 (perp=7.260, rec=0.069, cos=0.003), tot_loss_proj:3.276 [t=0.26s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[ 600/2000] tot_loss=1.519 (perp=7.260, rec=0.064, cos=0.003), tot_loss_proj:3.273 [t=0.23s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.524 (perp=7.260, rec=0.070, cos=0.003), tot_loss_proj:3.277 [t=0.18s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.513 (perp=7.260, rec=0.059, cos=0.003), tot_loss_proj:3.274 [t=0.26s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[ 750/2000] tot_loss=1.515 (perp=7.260, rec=0.060, cos=0.003), tot_loss_proj:3.276 [t=0.18s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.535 (perp=7.260, rec=0.080, cos=0.003), tot_loss_proj:3.273 [t=0.19s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.533 (perp=7.260, rec=0.078, cos=0.003), tot_loss_proj:3.280 [t=0.18s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[ 900/2000] tot_loss=1.532 (perp=7.260, rec=0.077, cos=0.003), tot_loss_proj:3.278 [t=0.18s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.529 (perp=7.260, rec=0.074, cos=0.003), tot_loss_proj:3.274 [t=0.18s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.524 (perp=7.260, rec=0.070, cos=0.003), tot_loss_proj:3.276 [t=0.26s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[1050/2000] tot_loss=1.531 (perp=7.260, rec=0.076, cos=0.003), tot_loss_proj:3.272 [t=0.21s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.538 (perp=7.260, rec=0.083, cos=0.003), tot_loss_proj:3.278 [t=0.18s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.519 (perp=7.260, rec=0.064, cos=0.003), tot_loss_proj:3.271 [t=0.19s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[1200/2000] tot_loss=1.515 (perp=7.260, rec=0.060, cos=0.003), tot_loss_proj:3.277 [t=0.21s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.510 (perp=7.260, rec=0.055, cos=0.003), tot_loss_proj:3.273 [t=0.26s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.517 (perp=7.260, rec=0.062, cos=0.003), tot_loss_proj:3.270 [t=0.19s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[1350/2000] tot_loss=1.530 (perp=7.260, rec=0.075, cos=0.003), tot_loss_proj:3.274 [t=0.19s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.527 (perp=7.260, rec=0.072, cos=0.003), tot_loss_proj:3.275 [t=0.22s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.523 (perp=7.260, rec=0.068, cos=0.003), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[1500/2000] tot_loss=1.515 (perp=7.260, rec=0.060, cos=0.003), tot_loss_proj:3.275 [t=0.26s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.523 (perp=7.260, rec=0.068, cos=0.003), tot_loss_proj:3.272 [t=0.19s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.521 (perp=7.260, rec=0.066, cos=0.003), tot_loss_proj:3.276 [t=0.19s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[1650/2000] tot_loss=1.539 (perp=7.260, rec=0.084, cos=0.003), tot_loss_proj:3.270 [t=0.27s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.530 (perp=7.260, rec=0.075, cos=0.003), tot_loss_proj:3.268 [t=0.18s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.512 (perp=7.260, rec=0.057, cos=0.003), tot_loss_proj:3.271 [t=0.18s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[1800/2000] tot_loss=1.520 (perp=7.260, rec=0.065, cos=0.003), tot_loss_proj:3.279 [t=0.20s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.524 (perp=7.260, rec=0.069, cos=0.003), tot_loss_proj:3.272 [t=0.24s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.519 (perp=7.260, rec=0.064, cos=0.003), tot_loss_proj:3.276 [t=0.21s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
[1950/2000] tot_loss=1.530 (perp=7.260, rec=0.075, cos=0.003), tot_loss_proj:3.275 [t=0.19s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.513 (perp=7.260, rec=0.059, cos=0.003), tot_loss_proj:3.271 [t=0.27s]
prediction: ['[CLS] bill gave the book sue. [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] bill gave sue the book. [SEP]
========================
predicted: 
========================
[CLS] bill gave the book sue. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 80.501 | p: 80.328 | r: 80.835
rouge2     | fm: 37.049 | p: 36.955 | r: 37.260
rougeL     | fm: 68.619 | p: 68.571 | r: 68.892
rougeLsum  | fm: 68.740 | p: 68.658 | r: 68.992
r1fm+r2fm = 117.550

input #28 time: 0:08:32 | total time: 4:04:49


Running input #29 of 100.
reference: 
========================
The bread was chewed by Martha.
========================
average of cosine similarity 0.9994577127920362
highest_index [0]
highest [0.9994577127920362]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  1996,  7852,  2001, 18362,  2011,  9246,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the bread was chewed by martha. [SEP]']
[Init] best rec loss: 1.9645967483520508 for ['[CLS] squeezed pace bonnie know plantsoic bishop [SEP]']
[Init] best rec loss: 1.9125432968139648 for ['[CLS] party morrison #ramet animated fluent [SEP]']
[Init] best rec loss: 1.8822089433670044 for ['[CLS] dream meters current disabilities first brother by [SEP]']
[Init] best rec loss: 1.856218934059143 for ['[CLS] witnessing remained transmitter phantom lunch americas angeles [SEP]']
[Init] best rec loss: 1.7931849956512451 for ['[CLS] leader impressedgin nr depends irish representation [SEP]']
[Init] best rec loss: 1.7745485305786133 for ['[CLS] anywhere landon t revolveruce suffered anything [SEP]']
[Init] best rec loss: 1.7534499168395996 for ['[CLS] sound expecting asian ve slope rwanda lay [SEP]']
[Init] best rec loss: 1.7343236207962036 for ['[CLS] as soundtrack alice sounding merchandise dorian magnus [SEP]']
[Init] best rec loss: 1.7305575609207153 for ['[CLS] gallery approached annie l enough later cb [SEP]']
[Init] best perm rec loss: 1.7282968759536743 for ['[CLS] l enough later approached annie gallery cb [SEP]']
[Init] best perm rec loss: 1.725870132446289 for ['[CLS] cb l later annie gallery enough approached [SEP]']
[Init] best perm rec loss: 1.7250057458877563 for ['[CLS] enough cb gallery annie approached later l [SEP]']
[Init] best perm rec loss: 1.7233729362487793 for ['[CLS] cb gallery l enough annie approached later [SEP]']
[Init] best perm rec loss: 1.7231544256210327 for ['[CLS] enough later l gallery annie approached cb [SEP]']
[Init] best perm rec loss: 1.7224928140640259 for ['[CLS] enough l gallery later annie approached cb [SEP]']
[Init] best perm rec loss: 1.721488356590271 for ['[CLS] enough cb l annie gallery approached later [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.926 (perp=11.267, rec=0.734, cos=0.939), tot_loss_proj:3.974 [t=0.26s]
prediction: ['[CLS] tomorrow clock subsequently q three went. [SEP]']
[ 100/2000] tot_loss=2.547 (perp=8.994, rec=0.480, cos=0.268), tot_loss_proj:3.560 [t=0.18s]
prediction: ['[CLS] tomorrow was whispers are bread chewed. [SEP]']
[ 150/2000] tot_loss=2.368 (perp=10.075, rec=0.319, cos=0.034), tot_loss_proj:3.784 [t=0.19s]
prediction: ['[CLS] bread became martha are bread chewed. [SEP]']
[ 200/2000] tot_loss=2.418 (perp=10.624, rec=0.269, cos=0.025), tot_loss_proj:4.023 [t=0.18s]
prediction: ['[CLS] bread became martha be bread chewed. [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.052 (perp=8.970, rec=0.241, cos=0.016), tot_loss_proj:3.851 [t=0.20s]
prediction: ['[CLS] bread became martha. bread chewed. [SEP]']
[ 300/2000] tot_loss=2.177 (perp=9.762, rec=0.212, cos=0.013), tot_loss_proj:3.690 [t=0.19s]
prediction: ['[CLS] bread became martha chewed bread chewed. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.103 (perp=9.377, rec=0.212, cos=0.016), tot_loss_proj:3.637 [t=0.18s]
prediction: ['[CLS] bread martha became chewed bread chewed. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.958 (perp=8.777, rec=0.188, cos=0.015), tot_loss_proj:3.441 [t=0.24s]
prediction: ['[CLS] bread chewed martha was chewed bread. [SEP]']
[ 450/2000] tot_loss=1.912 (perp=8.906, rec=0.127, cos=0.004), tot_loss_proj:3.444 [t=0.25s]
prediction: ['[CLS] bread chewed martha was chewed by. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.749 (perp=8.240, rec=0.098, cos=0.003), tot_loss_proj:3.711 [t=0.27s]
prediction: ['[CLS] was bread martha was chewed by. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.700 (perp=8.026, rec=0.091, cos=0.003), tot_loss_proj:3.374 [t=0.18s]
prediction: ['[CLS] was bread became chewed by martha. [SEP]']
[ 600/2000] tot_loss=1.684 (perp=8.026, rec=0.077, cos=0.002), tot_loss_proj:3.368 [t=0.18s]
prediction: ['[CLS] was bread became chewed by martha. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.299 (perp=6.120, rec=0.073, cos=0.002), tot_loss_proj:1.332 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.304 (perp=6.120, rec=0.078, cos=0.002), tot_loss_proj:1.326 [t=0.22s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 750/2000] tot_loss=1.290 (perp=6.120, rec=0.064, cos=0.002), tot_loss_proj:1.331 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.294 (perp=6.120, rec=0.069, cos=0.001), tot_loss_proj:1.332 [t=0.23s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.294 (perp=6.120, rec=0.069, cos=0.001), tot_loss_proj:1.323 [t=0.21s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[ 900/2000] tot_loss=1.292 (perp=6.120, rec=0.067, cos=0.001), tot_loss_proj:1.321 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.289 (perp=6.120, rec=0.064, cos=0.001), tot_loss_proj:1.328 [t=0.23s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.290 (perp=6.120, rec=0.065, cos=0.001), tot_loss_proj:1.339 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1050/2000] tot_loss=1.292 (perp=6.120, rec=0.066, cos=0.001), tot_loss_proj:1.323 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.297 (perp=6.120, rec=0.072, cos=0.001), tot_loss_proj:1.322 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.286 (perp=6.120, rec=0.061, cos=0.001), tot_loss_proj:1.327 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1200/2000] tot_loss=1.280 (perp=6.120, rec=0.055, cos=0.001), tot_loss_proj:1.324 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.296 (perp=6.120, rec=0.070, cos=0.001), tot_loss_proj:1.336 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.288 (perp=6.120, rec=0.062, cos=0.001), tot_loss_proj:1.332 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1350/2000] tot_loss=1.281 (perp=6.120, rec=0.056, cos=0.001), tot_loss_proj:1.333 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.292 (perp=6.120, rec=0.066, cos=0.001), tot_loss_proj:1.333 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.281 (perp=6.120, rec=0.056, cos=0.001), tot_loss_proj:1.323 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1500/2000] tot_loss=1.292 (perp=6.120, rec=0.067, cos=0.001), tot_loss_proj:1.324 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.295 (perp=6.120, rec=0.070, cos=0.001), tot_loss_proj:1.319 [t=0.24s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.278 (perp=6.120, rec=0.053, cos=0.001), tot_loss_proj:1.323 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1650/2000] tot_loss=1.295 (perp=6.120, rec=0.070, cos=0.001), tot_loss_proj:1.329 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.275 (perp=6.120, rec=0.050, cos=0.001), tot_loss_proj:1.332 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.288 (perp=6.120, rec=0.063, cos=0.001), tot_loss_proj:1.329 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1800/2000] tot_loss=1.290 (perp=6.120, rec=0.065, cos=0.001), tot_loss_proj:1.335 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.290 (perp=6.120, rec=0.065, cos=0.001), tot_loss_proj:1.334 [t=0.19s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.290 (perp=6.120, rec=0.064, cos=0.001), tot_loss_proj:1.338 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
[1950/2000] tot_loss=1.295 (perp=6.120, rec=0.070, cos=0.001), tot_loss_proj:1.327 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.281 (perp=6.120, rec=0.056, cos=0.001), tot_loss_proj:1.328 [t=0.18s]
prediction: ['[CLS] the bread was chewed by martha. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] the bread was chewed by martha. [SEP]
========================
predicted: 
========================
[CLS] the bread was chewed by martha. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.162 | p: 80.956 | r: 81.513
rouge2     | fm: 39.009 | p: 38.957 | r: 39.140
rougeL     | fm: 69.731 | p: 69.684 | r: 70.015
rougeLsum  | fm: 69.672 | p: 69.661 | r: 69.934
r1fm+r2fm = 120.171

input #29 time: 0:08:19 | total time: 4:13:08


Running input #30 of 100.
reference: 
========================
Read Fred's story, I also want to.
========================
average of cosine similarity 0.9993327887556609
highest_index [0]
highest [0.9993327887556609]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 3191, 5965, 1005, 1055, 2466, 1010, 1045, 2036, 2215, 2000, 1012,
          102]], device='cuda:0')
Debug: ref = ["[CLS] read fred's story, i also want to. [SEP]"]
[Init] best rec loss: 1.9111818075180054 for ['[CLS] design tourea chargessionkan voicesitatingrak freedom mild [SEP]']
[Init] best rec loss: 1.897634744644165 for ['[CLS] liz linuxpile some within context airport actions henri disposal ʎ [SEP]']
[Init] best rec loss: 1.88653564453125 for ['[CLS] oil thornton sc platoon scouts reserves town perennial mounted fundamental of [SEP]']
[Init] best rec loss: 1.8615144491195679 for ['[CLS] pec creek translation from,ept word inter isolated fishing [SEP]']
[Init] best rec loss: 1.826253890991211 for ['[CLS] withdrawnnesia lucas planned coloursix oak amin cooper morgan houses [SEP]']
[Init] best rec loss: 1.8057081699371338 for ['[CLS] fellows purposeded zanemeral challenge bark briggsdun uniformly water [SEP]']
[Init] best rec loss: 1.7915918827056885 for ['[CLS] set breath kiara sheldon bureaule r us when turtle synod [SEP]']
[Init] best rec loss: 1.7898919582366943 for ['[CLS] [CLS] kennedy poor found doinginium sabha stroke fixed viral la [SEP]']
[Init] best rec loss: 1.7768586874008179 for ['[CLS] doyle amir mostxa large dragon snapping artiststerol scheduled riff [SEP]']
[Init] best perm rec loss: 1.7759594917297363 for ['[CLS] riff scheduledterol doylexa large dragon snapping amir artists most [SEP]']
[Init] best perm rec loss: 1.775405764579773 for ['[CLS] snapping doyle artists amir large riffxa dragon scheduledterol most [SEP]']
[Init] best perm rec loss: 1.7694767713546753 for ['[CLS] large riff artists dragon mostxa scheduledterol snapping doyle amir [SEP]']
[Init] best perm rec loss: 1.7694395780563354 for ['[CLS] large amir snappingterol scheduled dragonxa most riff doyle artists [SEP]']
[Init] best perm rec loss: 1.7646902799606323 for ['[CLS]terolxa scheduled amir dragon artists doyle riff snapping most large [SEP]']
[Init] best perm rec loss: 1.7590125799179077 for ['[CLS]xa amir snapping doyle riff scheduled dragonterol large most artists [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.877 (perp=11.116, rec=0.654, cos=0.999), tot_loss_proj:4.116 [t=0.24s]
prediction: ['[CLS] ª officer jeff offered their faded coffee soap inbers are [SEP]']
[ 100/2000] tot_loss=3.752 (perp=11.170, rec=0.527, cos=0.991), tot_loss_proj:4.089 [t=0.18s]
prediction: ['[CLS] artist bear john read their matching book storybelt more she [SEP]']
[ 150/2000] tot_loss=3.553 (perp=10.311, rec=0.492, cos=0.999), tot_loss_proj:3.810 [t=0.25s]
prediction: ['[CLS] read even tony read their usually respect readdel during. [SEP]']
[ 200/2000] tot_loss=3.612 (perp=10.939, rec=0.439, cos=0.985), tot_loss_proj:4.022 [t=0.22s]
prediction: ['[CLS] read henry tony read alexis usually presidential story income elsewhere. [SEP]']
Attempt swap
[ 250/2000] tot_loss=4.064 (perp=11.890, rec=0.712, cos=0.974), tot_loss_proj:4.158 [t=0.19s]
prediction: ['[CLS] read want chromosome read fred client story story income whilst. [SEP]']
[ 300/2000] tot_loss=3.733 (perp=11.146, rec=0.511, cos=0.993), tot_loss_proj:4.069 [t=0.18s]
prediction: ['[CLS] read locomotive sarah read fred practitioner bandit story showing else. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=3.536 (perp=10.388, rec=0.470, cos=0.988), tot_loss_proj:3.978 [t=0.25s]
prediction: ['[CLS] liz read his assured she ( bandit story showing anyway. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.645 (perp=11.303, rec=0.417, cos=0.967), tot_loss_proj:4.042 [t=0.18s]
prediction: ['[CLS] fred read liz sure she ( tea story clara anyway. [SEP]']
[ 450/2000] tot_loss=3.795 (perp=12.168, rec=0.390, cos=0.972), tot_loss_proj:4.300 [t=0.19s]
prediction: ['[CLS] fred readₙ sure cavalry ( gene story clara anyway. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.400 (perp=10.229, rec=0.389, cos=0.965), tot_loss_proj:3.849 [t=0.19s]
prediction: ['[CLS] sure cavalry fred readₙ ( daddy story getting anyway. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.272 (perp=9.644, rec=0.378, cos=0.966), tot_loss_proj:3.738 [t=0.23s]
prediction: ['[CLS] suppose cavalry fred read. suppose gene story getting anyway. [SEP]']
[ 600/2000] tot_loss=3.327 (perp=9.959, rec=0.368, cos=0.967), tot_loss_proj:3.869 [t=0.23s]
prediction: ['[CLS] suppose cavalry fred read. suppose gene story getting erebidae. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.252 (perp=9.572, rec=0.371, cos=0.966), tot_loss_proj:3.771 [t=0.22s]
prediction: ['[CLS] suppose cavalry fred read. suppose erebidae story getting gene. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.198 (perp=9.369, rec=0.355, cos=0.969), tot_loss_proj:3.696 [t=0.18s]
prediction: ['[CLS] suppose everyone fred read. suppose erebidae story getting gene. [SEP]']
[ 750/2000] tot_loss=3.393 (perp=10.375, rec=0.348, cos=0.970), tot_loss_proj:3.874 [t=0.18s]
prediction: ['[CLS] parkinson everyone fred read. suppose erebidae story getting gene. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.408 (perp=10.397, rec=0.359, cos=0.970), tot_loss_proj:3.852 [t=0.19s]
prediction: ['[CLS] aliens alex fred read. suppose erebidae story getting gene. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.214 (perp=9.453, rec=0.352, cos=0.971), tot_loss_proj:3.708 [t=0.19s]
prediction: ['[CLS] aliens fred alex read. suppose erebidae story getting deleted. [SEP]']
[ 900/2000] tot_loss=3.202 (perp=9.453, rec=0.341, cos=0.970), tot_loss_proj:3.708 [t=0.20s]
prediction: ['[CLS] aliens fred alex read. suppose erebidae story getting deleted. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=3.298 (perp=9.916, rec=0.344, cos=0.971), tot_loss_proj:3.842 [t=0.21s]
prediction: ['[CLS] aliens fred read. suppose alex want story gettingroving. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=3.310 (perp=9.983, rec=0.343, cos=0.970), tot_loss_proj:3.792 [t=0.18s]
prediction: ['[CLS] aliens fred read. suppose erebidae alex story gettingroving. [SEP]']
[1050/2000] tot_loss=3.171 (perp=9.295, rec=0.341, cos=0.971), tot_loss_proj:3.678 [t=0.18s]
prediction: ['[CLS] aliens fred read. suppose erebidae alex story getting deleted. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.056 (perp=8.758, rec=0.334, cos=0.971), tot_loss_proj:3.549 [t=0.18s]
prediction: ['[CLS] aliens fred read. suppose want alex story getting deleted. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.048 (perp=8.758, rec=0.325, cos=0.971), tot_loss_proj:3.553 [t=0.26s]
prediction: ['[CLS] aliens fred read. suppose want alex story getting deleted. [SEP]']
[1200/2000] tot_loss=3.109 (perp=9.022, rec=0.333, cos=0.971), tot_loss_proj:3.680 [t=0.18s]
prediction: ['[CLS] aliens fred read, my want alex story getting deleted. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.106 (perp=9.022, rec=0.330, cos=0.972), tot_loss_proj:3.677 [t=0.18s]
prediction: ['[CLS] aliens fred read, my want alex story getting deleted. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=3.055 (perp=8.693, rec=0.344, cos=0.972), tot_loss_proj:3.574 [t=0.18s]
prediction: ['[CLS] aliens fred read, my want deleted story getting alex. [SEP]']
[1350/2000] tot_loss=3.030 (perp=8.693, rec=0.320, cos=0.972), tot_loss_proj:3.573 [t=0.19s]
prediction: ['[CLS] aliens fred read, my want deleted story getting alex. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.038 (perp=8.693, rec=0.327, cos=0.972), tot_loss_proj:3.569 [t=0.18s]
prediction: ['[CLS] aliens fred read, my want deleted story getting alex. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.034 (perp=8.693, rec=0.323, cos=0.972), tot_loss_proj:3.575 [t=0.27s]
prediction: ['[CLS] aliens fred read, my want deleted story getting alex. [SEP]']
[1500/2000] tot_loss=3.036 (perp=8.693, rec=0.324, cos=0.973), tot_loss_proj:3.578 [t=0.27s]
prediction: ['[CLS] aliens fred read, my want deleted story getting alex. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.040 (perp=8.693, rec=0.329, cos=0.973), tot_loss_proj:3.575 [t=0.19s]
prediction: ['[CLS] aliens fred read, my want deleted story getting alex. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.192 (perp=9.498, rec=0.319, cos=0.973), tot_loss_proj:3.784 [t=0.20s]
prediction: ['[CLS] aliens fred read, my wantudence story getting alex. [SEP]']
[1650/2000] tot_loss=3.183 (perp=9.498, rec=0.310, cos=0.973), tot_loss_proj:3.782 [t=0.21s]
prediction: ['[CLS] aliens fred read, my wantudence story getting alex. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.189 (perp=9.498, rec=0.316, cos=0.974), tot_loss_proj:3.785 [t=0.29s]
prediction: ['[CLS] aliens fred read, my wantudence story getting alex. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=3.112 (perp=9.038, rec=0.330, cos=0.974), tot_loss_proj:3.701 [t=0.19s]
prediction: ['[CLS] aliens fred read getting my wantudence story, alex. [SEP]']
[1800/2000] tot_loss=3.102 (perp=9.038, rec=0.320, cos=0.974), tot_loss_proj:3.706 [t=0.23s]
prediction: ['[CLS] aliens fred read getting my wantudence story, alex. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.101 (perp=9.038, rec=0.319, cos=0.975), tot_loss_proj:3.708 [t=0.18s]
prediction: ['[CLS] aliens fred read getting my wantudence story, alex. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.097 (perp=9.038, rec=0.315, cos=0.975), tot_loss_proj:3.704 [t=0.18s]
prediction: ['[CLS] aliens fred read getting my wantudence story, alex. [SEP]']
[1950/2000] tot_loss=3.105 (perp=9.038, rec=0.323, cos=0.975), tot_loss_proj:3.702 [t=0.20s]
prediction: ['[CLS] aliens fred read getting my wantudence story, alex. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.099 (perp=9.038, rec=0.316, cos=0.975), tot_loss_proj:3.703 [t=0.28s]
prediction: ['[CLS] aliens fred read getting my wantudence story, alex. [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] read fred's story, i also want to. [SEP]
========================
predicted: 
========================
[CLS] aliens fred read getting my wantudence story, alex. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 50.000 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 40.000 | r: 40.000
rougeLsum  | fm: 40.000 | p: 40.000 | r: 40.000
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 80.075 | p: 79.908 | r: 80.475
rouge2     | fm: 37.823 | p: 37.749 | r: 37.951
rougeL     | fm: 68.789 | p: 68.678 | r: 69.115
rougeLsum  | fm: 68.971 | p: 68.971 | r: 69.237
r1fm+r2fm = 117.897

input #30 time: 0:08:14 | total time: 4:21:23


Running input #31 of 100.
reference: 
========================
Some of the water from melted snow also goes into the ground for plants.
========================
average of cosine similarity 0.9992295707454686
highest_index [0]
highest [0.9992295707454686]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2070,  1997,  1996,  2300,  2013, 12501,  4586,  2036,  3632,
          2046,  1996,  2598,  2005,  4264,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]']
[Init] best rec loss: 1.9074965715408325 for ["[CLS] girlfriend set faculty clay angeles boom cross bandonus sh 'tical mistake inn ballard [SEP]"]
[Init] best rec loss: 1.888719081878662 for ['[CLS] ace brady declared temples eight simply { doi clapped content unit foot npr chargedtro [SEP]']
[Init] best rec loss: 1.8702856302261353 for ['[CLS] langdon jump japanese prop uniformberry meanwhileaceous an recall cm contact maybe bio goal [SEP]']
[Init] best rec loss: 1.862776756286621 for ['[CLS] carolina wonder calendar macy rocktill students power search under length laketia greg lowest [SEP]']
[Init] best rec loss: 1.8524404764175415 for ['[CLS] itself marta daughters pest soongarh lines ride material corner black major cook feeling 3 [SEP]']
[Init] best rec loss: 1.8378396034240723 for ['[CLS] spring run inside list kiran aria fiviere promise however stadium divided wingspanable € [SEP]']
[Init] best rec loss: 1.8244494199752808 for ['[CLS]power specifically hip cherry marguerite moors moment officergence began output geometric bending registeredavia [SEP]']
[Init] best rec loss: 1.8187201023101807 for ['[CLS] leading programled collier between mad recovery particular and jeannecar indian gemma alpha robinson [SEP]']
[Init] best perm rec loss: 1.8167808055877686 for ['[CLS] robinson leading mad betweenled gemma recoverycar particular collier and jeanne program indian alpha [SEP]']
[Init] best perm rec loss: 1.814731240272522 for ['[CLS] and recovery jeanneled between alphacar gemma mad robinson collier indian program leading particular [SEP]']
[Init] best perm rec loss: 1.8138445615768433 for ['[CLS] jeanne gemma program collier robinsoncar particularled indian and recovery mad alpha between leading [SEP]']
[Init] best perm rec loss: 1.8132107257843018 for ['[CLS] recovery betweenledcar and alpha jeanne indian mad robinson program collier gemma leading particular [SEP]']
[Init] best perm rec loss: 1.8128342628479004 for ['[CLS] leading particular jeanne program robinson madled alpha between indian and collier recovery gemmacar [SEP]']
[Init] best perm rec loss: 1.8117716312408447 for ['[CLS] leading jeanneled mad recovery between indian alpha program particular and collier robinsoncar gemma [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.478 (perp=12.295, rec=0.577, cos=0.442), tot_loss_proj:4.333 [t=0.18s]
prediction: ['[CLS] aftercles whereas municipality mix trees! : tree? nations liter in became back [SEP]']
[ 100/2000] tot_loss=2.550 (perp=10.670, rec=0.354, cos=0.062), tot_loss_proj:3.949 [t=0.21s]
prediction: ['[CLS] intentionally water exchange water chicken from from liquid snow from human meat from became where [SEP]']
[ 150/2000] tot_loss=2.439 (perp=10.045, rec=0.366, cos=0.063), tot_loss_proj:3.797 [t=0.18s]
prediction: ['[CLS] extra water. wind golden between ) green snow from cold meat br falls rained [SEP]']
[ 200/2000] tot_loss=2.479 (perp=10.716, rec=0.299, cos=0.037), tot_loss_proj:4.010 [t=0.28s]
prediction: ['[CLS] extra water for snow golden ground units liquid snow from cold meat br from rained [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.224 (perp=9.568, rec=0.278, cos=0.033), tot_loss_proj:3.785 [t=0.22s]
prediction: ['[CLS] additional water for plants golden ground from liquid snow from brworth cold goes rained [SEP]']
[ 300/2000] tot_loss=2.134 (perp=9.386, rec=0.237, cos=0.020), tot_loss_proj:3.734 [t=0.18s]
prediction: ['[CLS] other water for plants golden ground from water snow from brworth melted goes rained [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.151 (perp=9.408, rec=0.246, cos=0.023), tot_loss_proj:3.720 [t=0.19s]
prediction: ['[CLS] some plants for water golden ground from some snow from br cold sometimes goes rained [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.128 (perp=9.466, rec=0.218, cos=0.016), tot_loss_proj:3.705 [t=0.19s]
prediction: ['[CLS] br plants for water golden ground from. snow from some cold also goes rained [SEP]']
[ 450/2000] tot_loss=1.941 (perp=8.704, rec=0.189, cos=0.012), tot_loss_proj:3.584 [t=0.18s]
prediction: ['[CLS] plant plants for water snow ground water. snow from some melted also goes rained [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.771 (perp=7.949, rec=0.171, cos=0.010), tot_loss_proj:3.452 [t=0.18s]
prediction: ['[CLS] some plants for water snow ground water. snow from plants melted also goes rained [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.771 (perp=7.894, rec=0.178, cos=0.014), tot_loss_proj:3.429 [t=0.18s]
prediction: ['[CLS] some plants for snow water ground water the snow from plants melted also goes rained [SEP]']
[ 600/2000] tot_loss=1.746 (perp=7.894, rec=0.158, cos=0.010), tot_loss_proj:3.432 [t=0.23s]
prediction: ['[CLS] some plants for snow water ground water the snow from plants melted also goes rained [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.636 (perp=7.404, rec=0.145, cos=0.010), tot_loss_proj:3.318 [t=0.22s]
prediction: ['[CLS] some plants for snow water water ground the snow from plants melted also goes snow [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.629 (perp=7.404, rec=0.140, cos=0.008), tot_loss_proj:3.317 [t=0.24s]
prediction: ['[CLS] some plants for snow water water ground the snow from plants melted also goes snow [SEP]']
[ 750/2000] tot_loss=1.618 (perp=7.404, rec=0.129, cos=0.008), tot_loss_proj:3.318 [t=0.25s]
prediction: ['[CLS] some plants for snow water water ground the snow from plants melted also goes snow [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.599 (perp=7.320, rec=0.127, cos=0.008), tot_loss_proj:3.308 [t=0.20s]
prediction: ['[CLS] some plants for snow water water ground the snow from plants melted also snow goes [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.573 (perp=7.223, rec=0.122, cos=0.007), tot_loss_proj:3.282 [t=0.20s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
[ 900/2000] tot_loss=1.577 (perp=7.223, rec=0.125, cos=0.007), tot_loss_proj:3.281 [t=0.27s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.565 (perp=7.223, rec=0.114, cos=0.007), tot_loss_proj:3.282 [t=0.18s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.565 (perp=7.223, rec=0.114, cos=0.007), tot_loss_proj:3.280 [t=0.20s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
[1050/2000] tot_loss=1.563 (perp=7.223, rec=0.112, cos=0.007), tot_loss_proj:3.284 [t=0.18s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.563 (perp=7.223, rec=0.111, cos=0.006), tot_loss_proj:3.278 [t=0.21s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.561 (perp=7.223, rec=0.110, cos=0.006), tot_loss_proj:3.280 [t=0.19s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
[1200/2000] tot_loss=1.561 (perp=7.223, rec=0.110, cos=0.006), tot_loss_proj:3.282 [t=0.19s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.567 (perp=7.223, rec=0.116, cos=0.006), tot_loss_proj:3.280 [t=0.23s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.558 (perp=7.223, rec=0.107, cos=0.006), tot_loss_proj:3.282 [t=0.28s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
[1350/2000] tot_loss=1.554 (perp=7.223, rec=0.103, cos=0.006), tot_loss_proj:3.281 [t=0.23s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.556 (perp=7.223, rec=0.105, cos=0.006), tot_loss_proj:3.282 [t=0.19s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.556 (perp=7.223, rec=0.105, cos=0.006), tot_loss_proj:3.278 [t=0.28s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
[1500/2000] tot_loss=1.556 (perp=7.223, rec=0.106, cos=0.006), tot_loss_proj:3.282 [t=0.18s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.559 (perp=7.223, rec=0.109, cos=0.006), tot_loss_proj:3.283 [t=0.18s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.555 (perp=7.223, rec=0.105, cos=0.006), tot_loss_proj:3.283 [t=0.19s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
[1650/2000] tot_loss=1.558 (perp=7.223, rec=0.107, cos=0.006), tot_loss_proj:3.280 [t=0.27s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.552 (perp=7.223, rec=0.101, cos=0.006), tot_loss_proj:3.282 [t=0.18s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.553 (perp=7.223, rec=0.102, cos=0.006), tot_loss_proj:3.281 [t=0.19s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
[1800/2000] tot_loss=1.563 (perp=7.223, rec=0.112, cos=0.006), tot_loss_proj:3.282 [t=0.25s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.557 (perp=7.223, rec=0.106, cos=0.006), tot_loss_proj:3.281 [t=0.19s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.557 (perp=7.223, rec=0.106, cos=0.006), tot_loss_proj:3.285 [t=0.26s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
[1950/2000] tot_loss=1.555 (perp=7.223, rec=0.104, cos=0.006), tot_loss_proj:3.281 [t=0.20s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.555 (perp=7.223, rec=0.104, cos=0.006), tot_loss_proj:3.278 [t=0.19s]
prediction: ['[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] some of the water from melted snow also goes into the ground for plants. [SEP]
========================
predicted: 
========================
[CLS] some plants for snow water water ground the snow from melted plants also snow goes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.788 | p: 76.471 | r: 81.250
rouge2     | fm: 12.903 | p: 12.500 | r: 13.333
rougeL     | fm: 48.485 | p: 47.059 | r: 50.000
rougeLsum  | fm: 48.485 | p: 47.059 | r: 50.000
r1fm+r2fm = 91.691

[Aggregate metrics]:
rouge1     | fm: 80.095 | p: 79.845 | r: 80.554
rouge2     | fm: 36.871 | p: 36.767 | r: 37.108
rougeL     | fm: 68.155 | p: 68.028 | r: 68.458
rougeLsum  | fm: 68.140 | p: 67.996 | r: 68.425
r1fm+r2fm = 116.966

input #31 time: 0:08:30 | total time: 4:29:53


Running input #32 of 100.
reference: 
========================
Bob is very serious about Mary, but less so than Paul.
========================
average of cosine similarity 0.9993563156377977
highest_index [0]
highest [0.9993563156377977]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[ 101, 3960, 2003, 2200, 3809, 2055, 2984, 1010, 2021, 2625, 2061, 2084,
         2703, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] bob is very serious about mary, but less so than paul. [SEP]']
[Init] best rec loss: 1.8635272979736328 for ['[CLS] archery dual„ pam an arrows kings beyond if rev up place behind [SEP]']
[Init] best rec loss: 1.8503553867340088 for ['[CLS] timeny on tierney ⁰ [UNK] casual now interests pounder valentine apartheid born [SEP]']
[Init] best rec loss: 1.8387796878814697 for ['[CLS] records copy middle sr ( partly challenged skin dowager must warner with pick [SEP]']
[Init] best rec loss: 1.8074909448623657 for ['[CLS] no fa been short operational revolution ft blondtow toilet acoustic cody doubled [SEP]']
[Init] best perm rec loss: 1.8073880672454834 for ['[CLS] blond toilet ft cody been no doubled acoustic operational fa revolution shorttow [SEP]']
[Init] best perm rec loss: 1.8045835494995117 for ['[CLS] ft operational doubled fatow been cody no acoustic blond toilet short revolution [SEP]']
[Init] best perm rec loss: 1.8019564151763916 for ['[CLS] ft toilettow doubled fa revolution operational short no been cody blond acoustic [SEP]']
[Init] best perm rec loss: 1.8003883361816406 for ['[CLS] toilet no acoustic revolution doubled blond fatow short been ft operational cody [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.596 (perp=10.831, rec=0.733, cos=0.696), tot_loss_proj:4.115 [t=0.25s]
prediction: ['[CLS] cracked trading domestic board pacific leaving gap british sovereign on programme london prof [SEP]']
[ 100/2000] tot_loss=3.121 (perp=12.759, rec=0.448, cos=0.121), tot_loss_proj:4.429 [t=0.27s]
prediction: ['[CLS] traffic electric that port painted sex on winston sovereign ken programme paul analyst [SEP]']
[ 150/2000] tot_loss=3.087 (perp=12.048, rec=0.504, cos=0.173), tot_loss_proj:4.272 [t=0.24s]
prediction: ['[CLS] misconduct special environmentally company given odd paul paul mary bob mission paul about [SEP]']
[ 200/2000] tot_loss=2.575 (perp=11.042, rec=0.327, cos=0.040), tot_loss_proj:4.107 [t=0.26s]
prediction: ['[CLS] california special less signal should older paul paul mary bob mission iii : [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.483 (perp=10.742, rec=0.303, cos=0.032), tot_loss_proj:4.000 [t=0.24s]
prediction: ['[CLS] california special definitely sent least our less mary mary bob iii mission is [SEP]']
[ 300/2000] tot_loss=2.433 (perp=10.700, rec=0.272, cos=0.021), tot_loss_proj:4.084 [t=0.21s]
prediction: ['[CLS] california special serious message less than paul mary mary bob iii river is [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.593 (perp=11.647, rec=0.248, cos=0.015), tot_loss_proj:4.158 [t=0.18s]
prediction: ['[CLS] science special serious -, than paul mary than point bob john is [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.186 (perp=9.618, rec=0.245, cos=0.017), tot_loss_proj:3.853 [t=0.27s]
prediction: ['[CLS] bob special serious - more than annie mary than paul bob paul is [SEP]']
[ 450/2000] tot_loss=2.139 (perp=9.578, rec=0.212, cos=0.012), tot_loss_proj:3.877 [t=0.28s]
prediction: ['[CLS] bob special serious - less than annie mary than paul bob paul is [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.983 (perp=8.858, rec=0.201, cos=0.010), tot_loss_proj:3.699 [t=0.23s]
prediction: ['[CLS] bob about annie - less about serious mary than paul bob paul is [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.003 (perp=8.913, rec=0.209, cos=0.012), tot_loss_proj:3.709 [t=0.25s]
prediction: ['[CLS] paul about bay serious less about serious mary paul than bob john is [SEP]']
[ 600/2000] tot_loss=2.064 (perp=9.372, rec=0.181, cos=0.009), tot_loss_proj:3.774 [t=0.18s]
prediction: ['[CLS] paul about point serious but about serious mary paul than bob john is [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.976 (perp=9.011, rec=0.165, cos=0.009), tot_loss_proj:3.645 [t=0.27s]
prediction: ['[CLS] paul about paul serious but about serious mary paul than bob so is [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.936 (perp=8.793, rec=0.168, cos=0.009), tot_loss_proj:3.586 [t=0.18s]
prediction: ['[CLS] paul about paul serious but about serious mary than bob annie so is [SEP]']
[ 750/2000] tot_loss=1.919 (perp=8.793, rec=0.152, cos=0.009), tot_loss_proj:3.585 [t=0.18s]
prediction: ['[CLS] paul about paul serious but about serious mary than bob annie so is [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.870 (perp=8.291, rec=0.196, cos=0.016), tot_loss_proj:3.521 [t=0.21s]
prediction: ['[CLS] paul about paul - but about serious mary than annie so bob is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.847 (perp=8.291, rec=0.176, cos=0.013), tot_loss_proj:3.518 [t=0.21s]
prediction: ['[CLS] paul about paul - but about serious mary than annie so bob is [SEP]']
[ 900/2000] tot_loss=2.004 (perp=9.203, rec=0.152, cos=0.012), tot_loss_proj:3.671 [t=0.19s]
prediction: ['[CLS] paul about very post but about serious mary than annie so bob is [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.001 (perp=9.203, rec=0.150, cos=0.010), tot_loss_proj:3.670 [t=0.22s]
prediction: ['[CLS] paul about very post but about serious mary than annie so bob is [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.933 (perp=8.867, rec=0.150, cos=0.010), tot_loss_proj:3.596 [t=0.26s]
prediction: ['[CLS] paul is very post but about serious mary than annie so bob about [SEP]']
[1050/2000] tot_loss=1.932 (perp=8.867, rec=0.150, cos=0.009), tot_loss_proj:3.596 [t=0.26s]
prediction: ['[CLS] paul is very post but about serious mary than annie so bob about [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.819 (perp=8.316, rec=0.148, cos=0.009), tot_loss_proj:3.516 [t=0.19s]
prediction: ['[CLS] paul is very post but serious about mary than annie so bob about [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.681 (perp=7.605, rec=0.151, cos=0.008), tot_loss_proj:3.461 [t=0.18s]
prediction: ['[CLS] paul is very - but serious about mary than annie so about bob [SEP]']
[1200/2000] tot_loss=1.662 (perp=7.605, rec=0.133, cos=0.008), tot_loss_proj:3.465 [t=0.18s]
prediction: ['[CLS] paul is very - but serious about mary than annie so about bob [SEP]']
Attempt swap
[1250/2000] tot_loss=1.665 (perp=7.605, rec=0.136, cos=0.008), tot_loss_proj:3.460 [t=0.26s]
prediction: ['[CLS] paul is very - but serious about mary than annie so about bob [SEP]']
Attempt swap
[1300/2000] tot_loss=1.672 (perp=7.605, rec=0.143, cos=0.008), tot_loss_proj:3.457 [t=0.23s]
prediction: ['[CLS] paul is very - but serious about mary than annie so about bob [SEP]']
[1350/2000] tot_loss=1.662 (perp=7.605, rec=0.134, cos=0.007), tot_loss_proj:3.461 [t=0.18s]
prediction: ['[CLS] paul is very - but serious about mary than annie so about bob [SEP]']
Attempt swap
[1400/2000] tot_loss=1.662 (perp=7.605, rec=0.134, cos=0.007), tot_loss_proj:3.456 [t=0.18s]
prediction: ['[CLS] paul is very - but serious about mary than annie so about bob [SEP]']
Attempt swap
[1450/2000] tot_loss=1.665 (perp=7.605, rec=0.137, cos=0.007), tot_loss_proj:3.460 [t=0.19s]
prediction: ['[CLS] paul is very - but serious about mary than annie so about bob [SEP]']
[1500/2000] tot_loss=1.658 (perp=7.605, rec=0.130, cos=0.007), tot_loss_proj:3.459 [t=0.20s]
prediction: ['[CLS] paul is very - but serious about mary than annie so about bob [SEP]']
Attempt swap
[1550/2000] tot_loss=1.529 (perp=6.949, rec=0.132, cos=0.007), tot_loss_proj:3.349 [t=0.24s]
prediction: ['[CLS] paul is very serious but serious about mary than annie so about bob [SEP]']
Attempt swap
[1600/2000] tot_loss=1.525 (perp=6.949, rec=0.128, cos=0.007), tot_loss_proj:3.351 [t=0.19s]
prediction: ['[CLS] paul is very serious but serious about mary than annie so about bob [SEP]']
[1650/2000] tot_loss=1.586 (perp=7.259, rec=0.127, cos=0.007), tot_loss_proj:3.425 [t=0.27s]
prediction: ['[CLS] paul is so serious but serious about mary than annie so about bob [SEP]']
Attempt swap
[1700/2000] tot_loss=1.594 (perp=7.259, rec=0.135, cos=0.007), tot_loss_proj:3.416 [t=0.19s]
prediction: ['[CLS] paul is so serious but serious about mary than annie so about bob [SEP]']
Attempt swap
[1750/2000] tot_loss=1.592 (perp=7.259, rec=0.133, cos=0.007), tot_loss_proj:3.423 [t=0.19s]
prediction: ['[CLS] paul is so serious but serious about mary than annie so about bob [SEP]']
[1800/2000] tot_loss=1.586 (perp=7.259, rec=0.127, cos=0.007), tot_loss_proj:3.426 [t=0.19s]
prediction: ['[CLS] paul is so serious but serious about mary than annie so about bob [SEP]']
Attempt swap
[1850/2000] tot_loss=1.696 (perp=7.814, rec=0.126, cos=0.007), tot_loss_proj:3.508 [t=0.22s]
prediction: ['[CLS] paul is so - but serious about mary than annie so about bob [SEP]']
Attempt swap
[1900/2000] tot_loss=1.692 (perp=7.814, rec=0.123, cos=0.007), tot_loss_proj:3.508 [t=0.18s]
prediction: ['[CLS] paul is so - but serious about mary than annie so about bob [SEP]']
[1950/2000] tot_loss=1.689 (perp=7.814, rec=0.119, cos=0.007), tot_loss_proj:3.507 [t=0.18s]
prediction: ['[CLS] paul is so - but serious about mary than annie so about bob [SEP]']
Attempt swap
[2000/2000] tot_loss=1.699 (perp=7.814, rec=0.129, cos=0.007), tot_loss_proj:3.507 [t=0.18s]
prediction: ['[CLS] paul is so - but serious about mary than annie so about bob [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] bob is very serious about mary, but less so than paul. [SEP]
========================
predicted: 
========================
[CLS] paul is so serious but serious about mary than annie so about bob [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 73.333 | r: 84.615
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 50.000 | p: 46.667 | r: 53.846
rougeLsum  | fm: 50.000 | p: 46.667 | r: 53.846
r1fm+r2fm = 93.956

[Aggregate metrics]:
rouge1     | fm: 80.022 | p: 79.612 | r: 80.615
rouge2     | fm: 36.887 | p: 36.783 | r: 37.044
rougeL     | fm: 67.608 | p: 67.415 | r: 68.076
rougeLsum  | fm: 67.849 | p: 67.576 | r: 68.177
r1fm+r2fm = 116.909

input #32 time: 0:08:22 | total time: 4:38:15


Running input #33 of 100.
reference: 
========================
Ayala sent the diamond necklace back.
========================
average of cosine similarity 0.9993190743310341
highest_index [0]
highest [0.9993190743310341]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  1996,  6323, 13016,  2067,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] ayala sent the diamond necklace back. [SEP]']
[Init] best rec loss: 1.933242678642273 for ['[CLS] terms primary contribution an soil all competition dug [SEP]']
[Init] best rec loss: 1.8990107774734497 for ['[CLS] militiaiom slim lei daryl dip bay well [SEP]']
[Init] best rec loss: 1.891861915588379 for ['[CLS] langley 9 shoe soon tray originally ha inclined [SEP]']
[Init] best rec loss: 1.861467957496643 for ['[CLS] captive purpose ponytail auracat vocabulary 2 severity [SEP]']
[Init] best rec loss: 1.8396992683410645 for ['[CLS] ending answered cocaine recordity aloud strange al [SEP]']
[Init] best rec loss: 1.8250480890274048 for ['[CLS] last guards metal ten tan live wings orange [SEP]']
[Init] best rec loss: 1.8202368021011353 for ['[CLS] k both ultimate wine australia road instead service [SEP]']
[Init] best rec loss: 1.8071019649505615 for ['[CLS] him raaf peace sandy re havilland measureduddin [SEP]']
[Init] best rec loss: 1.8056987524032593 for ['[CLS] heads schwarz putting lending track philippines proof available [SEP]']
[Init] best perm rec loss: 1.8044240474700928 for ['[CLS] schwarz lending heads proof philippines putting available track [SEP]']
[Init] best perm rec loss: 1.8034542798995972 for ['[CLS] lending schwarz heads proof putting track available philippines [SEP]']
[Init] best perm rec loss: 1.8032727241516113 for ['[CLS] available schwarz heads track philippines lending putting proof [SEP]']
[Init] best perm rec loss: 1.802367925643921 for ['[CLS] heads schwarz track putting philippines lending proof available [SEP]']
[Init] best perm rec loss: 1.8021165132522583 for ['[CLS] lending schwarz track heads available proof putting philippines [SEP]']
[Init] best perm rec loss: 1.8018345832824707 for ['[CLS] available schwarz track heads lending putting philippines proof [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.361 (perp=12.890, rec=0.507, cos=0.275), tot_loss_proj:4.665 [t=0.22s]
prediction: ['[CLS] representatives seek into row throwing slips angeles § [SEP]']
[ 100/2000] tot_loss=2.867 (perp=13.085, rec=0.234, cos=0.017), tot_loss_proj:4.520 [t=0.30s]
prediction: ['[CLS]yala sent broyala necklace sonata back sent [SEP]']
[ 150/2000] tot_loss=2.320 (perp=10.913, rec=0.129, cos=0.008), tot_loss_proj:4.077 [t=0.26s]
prediction: ['[CLS]yala sent ayala necklaceyala back the [SEP]']
[ 200/2000] tot_loss=2.249 (perp=10.750, rec=0.093, cos=0.006), tot_loss_proj:3.957 [t=0.23s]
prediction: ['[CLS]yala sent a. necklaceyala back the [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.118 (perp=9.939, rec=0.120, cos=0.010), tot_loss_proj:3.991 [t=0.28s]
prediction: ['[CLS]yala sent ayala the necklace desperately back [SEP]']
[ 300/2000] tot_loss=2.357 (perp=11.251, rec=0.100, cos=0.007), tot_loss_proj:4.078 [t=0.25s]
prediction: ['[CLS]yala sent a radius the necklace desperately back [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.186 (perp=10.422, rec=0.095, cos=0.006), tot_loss_proj:4.052 [t=0.29s]
prediction: ['[CLS]yala sent a necklace the radius desperately back [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.186 (perp=10.422, rec=0.095, cos=0.006), tot_loss_proj:4.053 [t=0.19s]
prediction: ['[CLS]yala sent a necklace the radius desperately back [SEP]']
[ 450/2000] tot_loss=2.087 (perp=9.939, rec=0.093, cos=0.006), tot_loss_proj:3.964 [t=0.18s]
prediction: ['[CLS]yala sent a necklace the diamond? back [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.863 (perp=8.807, rec=0.095, cos=0.007), tot_loss_proj:3.904 [t=0.18s]
prediction: ['[CLS]yala sent a? the diamond necklace back [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.810 (perp=8.557, rec=0.091, cos=0.007), tot_loss_proj:3.801 [t=0.19s]
prediction: ['[CLS] desperately sent ayala the diamond necklace back [SEP]']
[ 600/2000] tot_loss=1.648 (perp=7.734, rec=0.095, cos=0.007), tot_loss_proj:3.225 [t=0.25s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.646 (perp=7.734, rec=0.093, cos=0.006), tot_loss_proj:3.239 [t=0.24s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.640 (perp=7.734, rec=0.087, cos=0.006), tot_loss_proj:3.229 [t=0.25s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
[ 750/2000] tot_loss=1.645 (perp=7.734, rec=0.091, cos=0.006), tot_loss_proj:3.225 [t=0.24s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.636 (perp=7.734, rec=0.083, cos=0.006), tot_loss_proj:3.196 [t=0.28s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.641 (perp=7.734, rec=0.088, cos=0.006), tot_loss_proj:3.182 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
[ 900/2000] tot_loss=1.650 (perp=7.734, rec=0.097, cos=0.006), tot_loss_proj:3.179 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.635 (perp=7.734, rec=0.082, cos=0.006), tot_loss_proj:3.204 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
[1000/2000] tot_loss=1.640 (perp=7.734, rec=0.087, cos=0.006), tot_loss_proj:3.204 [t=0.25s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
[1050/2000] tot_loss=1.643 (perp=7.734, rec=0.090, cos=0.006), tot_loss_proj:3.196 [t=0.32s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
[1100/2000] tot_loss=1.641 (perp=7.734, rec=0.088, cos=0.006), tot_loss_proj:3.194 [t=0.25s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
[1150/2000] tot_loss=1.644 (perp=7.734, rec=0.091, cos=0.006), tot_loss_proj:3.190 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
[1200/2000] tot_loss=1.644 (perp=7.734, rec=0.091, cos=0.006), tot_loss_proj:3.188 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
[1250/2000] tot_loss=1.637 (perp=7.734, rec=0.084, cos=0.006), tot_loss_proj:3.180 [t=0.23s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.638 (perp=7.734, rec=0.085, cos=0.006), tot_loss_proj:3.158 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
[1350/2000] tot_loss=1.633 (perp=7.734, rec=0.080, cos=0.006), tot_loss_proj:3.152 [t=0.23s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.644 (perp=7.734, rec=0.091, cos=0.006), tot_loss_proj:3.179 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
[1450/2000] tot_loss=1.642 (perp=7.734, rec=0.089, cos=0.006), tot_loss_proj:3.180 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
[1500/2000] tot_loss=1.648 (perp=7.734, rec=0.095, cos=0.006), tot_loss_proj:3.173 [t=0.19s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
[1550/2000] tot_loss=1.639 (perp=7.734, rec=0.086, cos=0.006), tot_loss_proj:3.168 [t=0.22s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.644 (perp=7.734, rec=0.091, cos=0.006), tot_loss_proj:3.142 [t=0.19s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
[1650/2000] tot_loss=1.643 (perp=7.734, rec=0.090, cos=0.006), tot_loss_proj:3.138 [t=0.19s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.639 (perp=7.734, rec=0.087, cos=0.006), tot_loss_proj:3.167 [t=0.21s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
[1750/2000] tot_loss=1.642 (perp=7.734, rec=0.089, cos=0.006), tot_loss_proj:3.168 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
[1800/2000] tot_loss=1.636 (perp=7.734, rec=0.083, cos=0.006), tot_loss_proj:3.167 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.648 (perp=7.734, rec=0.096, cos=0.006), tot_loss_proj:3.138 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.636 (perp=7.734, rec=0.083, cos=0.006), tot_loss_proj:3.170 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
[1950/2000] tot_loss=1.642 (perp=7.734, rec=0.089, cos=0.006), tot_loss_proj:3.173 [t=0.18s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Attempt swap
[2000/2000] tot_loss=1.641 (perp=7.734, rec=0.088, cos=0.006), tot_loss_proj:3.172 [t=0.22s]
prediction: ['[CLS] diamond sent ayala the diamond necklace back [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] ayala sent the diamond necklace back. [SEP]
========================
predicted: 
========================
[CLS] diamond sent ayala the diamond necklace back [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 53.333 | p: 50.000 | r: 57.143
rougeL     | fm: 82.353 | p: 77.778 | r: 87.500
rougeLsum  | fm: 82.353 | p: 77.778 | r: 87.500
r1fm+r2fm = 147.451

[Aggregate metrics]:
rouge1     | fm: 80.273 | p: 79.865 | r: 80.981
rouge2     | fm: 37.215 | p: 36.916 | r: 37.512
rougeL     | fm: 68.020 | p: 67.744 | r: 68.591
rougeLsum  | fm: 68.242 | p: 67.845 | r: 68.695
r1fm+r2fm = 117.488

input #33 time: 0:08:39 | total time: 4:46:55


Running input #34 of 100.
reference: 
========================
Jessica sprayed paint under the table.
========================
average of cosine similarity 0.9993079982050087
highest_index [0]
highest [0.9993079982050087]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  8201, 25401,  6773,  2104,  1996,  2795,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] jessica sprayed paint under the table. [SEP]']
[Init] best rec loss: 1.8023942708969116 for ['[CLS] solvent pure sitting returns open penelope gerais [SEP]']
[Init] best rec loss: 1.7648147344589233 for ['[CLS] pebbles squid letplay peach suburbs will [SEP]']
[Init] best rec loss: 1.694551944732666 for ['[CLS] moment fits encourage law koppenuch specifically [SEP]']
[Init] best rec loss: 1.6742746829986572 for ['[CLS]sar regatta fortunes roller nor commuted an [SEP]']
[Init] best perm rec loss: 1.6713130474090576 for ['[CLS] an commuted regatta nor roller fortunessar [SEP]']
[Init] best perm rec loss: 1.6709792613983154 for ['[CLS] commuted roller nor fortunes regattasar an [SEP]']
[Init] best perm rec loss: 1.6706624031066895 for ['[CLS] an commuted nor fortunes regatta rollersar [SEP]']
[Init] best perm rec loss: 1.669133186340332 for ['[CLS] an commuted roller nor fortunes regattasar [SEP]']
[Init] best perm rec loss: 1.669002890586853 for ['[CLS] an commuted fortunes nor regatta rollersar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.121 (perp=13.039, rec=0.414, cos=0.099), tot_loss_proj:4.402 [t=0.22s]
prediction: ['[CLS] jess middleweight text vuelta offer roller singer [SEP]']
[ 100/2000] tot_loss=2.561 (perp=11.688, rec=0.200, cos=0.023), tot_loss_proj:4.325 [t=0.19s]
prediction: ['[CLS] jess losslaze jessica sprayed sprayed paint [SEP]']
[ 150/2000] tot_loss=2.324 (perp=10.735, rec=0.162, cos=0.016), tot_loss_proj:4.206 [t=0.23s]
prediction: ['[CLS]. abalaze jessica sprayed paint paint [SEP]']
[ 200/2000] tot_loss=2.369 (perp=11.110, rec=0.135, cos=0.012), tot_loss_proj:4.268 [t=0.18s]
prediction: ['[CLS]. idealaze jessica sprayed table paint [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.800 (perp=12.623, rec=0.236, cos=0.040), tot_loss_proj:4.318 [t=0.18s]
prediction: ['[CLS] heaven slam jessica sprayed under paintnge [SEP]']
[ 300/2000] tot_loss=2.465 (perp=11.443, rec=0.159, cos=0.017), tot_loss_proj:4.365 [t=0.22s]
prediction: ['[CLS] theme theme jessica sprayed under paintnge [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.270 (perp=10.463, rec=0.162, cos=0.016), tot_loss_proj:4.125 [t=0.27s]
prediction: ['[CLS] theme theme jessicange sprayed under paint [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.266 (perp=10.528, rec=0.143, cos=0.017), tot_loss_proj:4.201 [t=0.21s]
prediction: ['[CLS] draft theme jessicange under sprayed paint [SEP]']
[ 450/2000] tot_loss=2.367 (perp=11.080, rec=0.137, cos=0.014), tot_loss_proj:4.246 [t=0.21s]
prediction: ['[CLS] draft slam jessicange under sprayed paint [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.355 (perp=10.985, rec=0.144, cos=0.014), tot_loss_proj:4.119 [t=0.21s]
prediction: ['[CLS] draft sprayed jessicange under theme paint [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.148 (perp=10.082, rec=0.119, cos=0.013), tot_loss_proj:3.934 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica. under slam paint [SEP]']
[ 600/2000] tot_loss=2.154 (perp=10.082, rec=0.125, cos=0.013), tot_loss_proj:3.938 [t=0.28s]
prediction: ['[CLS] draft sprayed jessica. under slam paint [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.789 (perp=8.242, rec=0.128, cos=0.013), tot_loss_proj:3.659 [t=0.25s]
prediction: ['[CLS] draft sprayed jessica under slam paint. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.914 (perp=8.865, rec=0.130, cos=0.012), tot_loss_proj:3.727 [t=0.29s]
prediction: ['[CLS] draft sprayed jessica under break paint. [SEP]']
[ 750/2000] tot_loss=1.891 (perp=8.762, rec=0.127, cos=0.011), tot_loss_proj:3.554 [t=0.20s]
prediction: ['[CLS] draft sprayed jessica under : paint. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.810 (perp=8.393, rec=0.121, cos=0.010), tot_loss_proj:3.733 [t=0.25s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.815 (perp=8.393, rec=0.127, cos=0.010), tot_loss_proj:3.727 [t=0.22s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
[ 900/2000] tot_loss=1.797 (perp=8.393, rec=0.109, cos=0.009), tot_loss_proj:3.726 [t=0.21s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.807 (perp=8.393, rec=0.120, cos=0.009), tot_loss_proj:3.725 [t=0.25s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.804 (perp=8.393, rec=0.117, cos=0.008), tot_loss_proj:3.726 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
[1050/2000] tot_loss=1.794 (perp=8.393, rec=0.107, cos=0.008), tot_loss_proj:3.729 [t=0.23s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.792 (perp=8.393, rec=0.106, cos=0.008), tot_loss_proj:3.723 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.796 (perp=8.393, rec=0.110, cos=0.007), tot_loss_proj:3.730 [t=0.19s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
[1200/2000] tot_loss=1.797 (perp=8.393, rec=0.112, cos=0.007), tot_loss_proj:3.725 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.795 (perp=8.393, rec=0.110, cos=0.007), tot_loss_proj:3.727 [t=0.20s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.785 (perp=8.393, rec=0.099, cos=0.007), tot_loss_proj:3.727 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
[1350/2000] tot_loss=1.784 (perp=8.393, rec=0.099, cos=0.007), tot_loss_proj:3.726 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.787 (perp=8.393, rec=0.102, cos=0.007), tot_loss_proj:3.727 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.775 (perp=8.393, rec=0.089, cos=0.007), tot_loss_proj:3.725 [t=0.19s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
[1500/2000] tot_loss=1.783 (perp=8.393, rec=0.098, cos=0.007), tot_loss_proj:3.725 [t=0.23s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.781 (perp=8.393, rec=0.096, cos=0.007), tot_loss_proj:3.730 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.782 (perp=8.393, rec=0.096, cos=0.007), tot_loss_proj:3.725 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
[1650/2000] tot_loss=1.780 (perp=8.393, rec=0.095, cos=0.007), tot_loss_proj:3.728 [t=0.28s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.779 (perp=8.393, rec=0.094, cos=0.006), tot_loss_proj:3.732 [t=0.19s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.787 (perp=8.393, rec=0.102, cos=0.006), tot_loss_proj:3.724 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
[1800/2000] tot_loss=1.781 (perp=8.393, rec=0.096, cos=0.006), tot_loss_proj:3.726 [t=0.21s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.775 (perp=8.393, rec=0.090, cos=0.006), tot_loss_proj:3.729 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.783 (perp=8.393, rec=0.098, cos=0.006), tot_loss_proj:3.722 [t=0.19s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
[1950/2000] tot_loss=1.777 (perp=8.393, rec=0.092, cos=0.006), tot_loss_proj:3.723 [t=0.19s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.780 (perp=8.393, rec=0.095, cos=0.006), tot_loss_proj:3.723 [t=0.18s]
prediction: ['[CLS] draft sprayed jessica under table paint. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] jessica sprayed paint under the table. [SEP]
========================
predicted: 
========================
[CLS] draft sprayed jessica under table paint. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 87.500

[Aggregate metrics]:
rouge1     | fm: 80.553 | p: 80.121 | r: 81.263
rouge2     | fm: 36.094 | p: 35.902 | r: 36.345
rougeL     | fm: 67.894 | p: 67.636 | r: 68.331
rougeLsum  | fm: 68.099 | p: 67.727 | r: 68.622
r1fm+r2fm = 116.648

input #34 time: 0:08:21 | total time: 4:55:17


Running input #35 of 100.
reference: 
========================
John is refused.
========================
average of cosine similarity 0.9992893523444286
highest_index [0]
highest [0.9992893523444286]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2198, 2003, 4188, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is refused. [SEP]']
[Init] best rec loss: 1.9772703647613525 for ['[CLS] hugo cruise than seconds [SEP]']
[Init] best rec loss: 1.9668530225753784 for ['[CLS] painful friendly reputation popularity [SEP]']
[Init] best rec loss: 1.8778486251831055 for ['[CLS] wings property warned wish [SEP]']
[Init] best rec loss: 1.7507518529891968 for ['[CLS] hypothesisphysics front closest [SEP]']
[Init] best rec loss: 1.6681959629058838 for ['[CLS] cass having many cy [SEP]']
[Init] best perm rec loss: 1.6646428108215332 for ['[CLS] cass cy many having [SEP]']
[Init] best perm rec loss: 1.661971926689148 for ['[CLS] cass having cy many [SEP]']
[Init] best perm rec loss: 1.6577669382095337 for ['[CLS] cass cy having many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.139 (perp=12.885, rec=0.632, cos=0.930), tot_loss_proj:4.443 [t=0.18s]
prediction: ['[CLS] refused fundlo fund [SEP]']
[ 100/2000] tot_loss=3.387 (perp=9.870, rec=0.530, cos=0.883), tot_loss_proj:3.792 [t=0.29s]
prediction: ['[CLS] is refused is williams [SEP]']
[ 150/2000] tot_loss=3.605 (perp=11.523, rec=0.453, cos=0.847), tot_loss_proj:4.148 [t=0.25s]
prediction: ['[CLS] is refused capt refused [SEP]']
[ 200/2000] tot_loss=3.584 (perp=11.523, rec=0.408, cos=0.871), tot_loss_proj:4.146 [t=0.26s]
prediction: ['[CLS] is refused capt refused [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.317 (perp=10.443, rec=0.372, cos=0.857), tot_loss_proj:3.913 [t=0.19s]
prediction: ['[CLS] refusediah is refused [SEP]']
[ 300/2000] tot_loss=3.752 (perp=12.781, rec=0.346, cos=0.849), tot_loss_proj:4.406 [t=0.23s]
prediction: ['[CLS] refusedriated is optical [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.359 (perp=10.823, rec=0.399, cos=0.795), tot_loss_proj:4.018 [t=0.18s]
prediction: ['[CLS] \\dable is refused [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.375 (perp=10.877, rec=0.383, cos=0.817), tot_loss_proj:4.048 [t=0.18s]
prediction: ['[CLS] grandpa antagonist is refused [SEP]']
[ 450/2000] tot_loss=3.237 (perp=10.289, rec=0.364, cos=0.815), tot_loss_proj:3.986 [t=0.18s]
prediction: ['[CLS] grandpa matthew is refused [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.226 (perp=10.289, rec=0.343, cos=0.825), tot_loss_proj:3.980 [t=0.18s]
prediction: ['[CLS] grandpa matthew is refused [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.499 (perp=11.499, rec=0.372, cos=0.828), tot_loss_proj:4.114 [t=0.23s]
prediction: ['[CLS] matthewceae is refused [SEP]']
[ 600/2000] tot_loss=3.285 (perp=10.619, rec=0.336, cos=0.825), tot_loss_proj:4.023 [t=0.18s]
prediction: ['[CLS] matthewvable is refused [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.289 (perp=10.619, rec=0.336, cos=0.829), tot_loss_proj:4.020 [t=0.20s]
prediction: ['[CLS] matthewvable is refused [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.926 (perp=8.751, rec=0.337, cos=0.839), tot_loss_proj:3.505 [t=0.19s]
prediction: ['[CLS] john matthew is refused [SEP]']
[ 750/2000] tot_loss=2.923 (perp=8.751, rec=0.341, cos=0.831), tot_loss_proj:3.524 [t=0.18s]
prediction: ['[CLS] john matthew is refused [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.910 (perp=8.751, rec=0.325, cos=0.835), tot_loss_proj:3.534 [t=0.18s]
prediction: ['[CLS] john matthew is refused [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.824 (perp=8.320, rec=0.322, cos=0.837), tot_loss_proj:3.187 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
[ 900/2000] tot_loss=2.830 (perp=8.320, rec=0.327, cos=0.838), tot_loss_proj:3.197 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.824 (perp=8.320, rec=0.320, cos=0.840), tot_loss_proj:3.184 [t=0.21s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1000/2000] tot_loss=2.825 (perp=8.320, rec=0.319, cos=0.841), tot_loss_proj:3.187 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
[1050/2000] tot_loss=2.830 (perp=8.320, rec=0.324, cos=0.842), tot_loss_proj:3.184 [t=0.19s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1100/2000] tot_loss=2.826 (perp=8.320, rec=0.320, cos=0.843), tot_loss_proj:3.190 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1150/2000] tot_loss=2.829 (perp=8.320, rec=0.321, cos=0.844), tot_loss_proj:3.185 [t=0.23s]
prediction: ['[CLS] john stephen is refused [SEP]']
[1200/2000] tot_loss=2.832 (perp=8.320, rec=0.324, cos=0.844), tot_loss_proj:3.180 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1250/2000] tot_loss=2.833 (perp=8.320, rec=0.325, cos=0.845), tot_loss_proj:3.182 [t=0.20s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1300/2000] tot_loss=2.836 (perp=8.320, rec=0.327, cos=0.845), tot_loss_proj:3.181 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
[1350/2000] tot_loss=2.827 (perp=8.320, rec=0.317, cos=0.846), tot_loss_proj:3.187 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1400/2000] tot_loss=2.837 (perp=8.320, rec=0.327, cos=0.846), tot_loss_proj:3.179 [t=0.23s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1450/2000] tot_loss=2.820 (perp=8.320, rec=0.310, cos=0.846), tot_loss_proj:3.178 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
[1500/2000] tot_loss=2.834 (perp=8.320, rec=0.324, cos=0.846), tot_loss_proj:3.180 [t=0.23s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1550/2000] tot_loss=2.829 (perp=8.320, rec=0.318, cos=0.846), tot_loss_proj:3.182 [t=0.19s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1600/2000] tot_loss=2.827 (perp=8.320, rec=0.316, cos=0.847), tot_loss_proj:3.174 [t=0.25s]
prediction: ['[CLS] john stephen is refused [SEP]']
[1650/2000] tot_loss=2.833 (perp=8.320, rec=0.323, cos=0.847), tot_loss_proj:3.186 [t=0.23s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1700/2000] tot_loss=2.834 (perp=8.320, rec=0.323, cos=0.847), tot_loss_proj:3.173 [t=0.24s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1750/2000] tot_loss=2.840 (perp=8.320, rec=0.329, cos=0.847), tot_loss_proj:3.173 [t=0.27s]
prediction: ['[CLS] john stephen is refused [SEP]']
[1800/2000] tot_loss=2.838 (perp=8.320, rec=0.326, cos=0.847), tot_loss_proj:3.178 [t=0.21s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1850/2000] tot_loss=2.836 (perp=8.320, rec=0.325, cos=0.847), tot_loss_proj:3.175 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[1900/2000] tot_loss=2.820 (perp=8.320, rec=0.309, cos=0.847), tot_loss_proj:3.173 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
[1950/2000] tot_loss=2.834 (perp=8.320, rec=0.323, cos=0.847), tot_loss_proj:3.175 [t=0.18s]
prediction: ['[CLS] john stephen is refused [SEP]']
Attempt swap
[2000/2000] tot_loss=2.820 (perp=8.320, rec=0.309, cos=0.847), tot_loss_proj:3.178 [t=0.23s]
prediction: ['[CLS] john stephen is refused [SEP]']
Done with input #35 of 100.
reference: 
========================
[CLS] john is refused. [SEP]
========================
predicted: 
========================
[CLS] john stephen is refused [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 83.333 | r: 100.000
rouge2     | fm: 66.667 | p: 60.000 | r: 75.000
rougeL     | fm: 90.909 | p: 83.333 | r: 100.000
rougeLsum  | fm: 90.909 | p: 83.333 | r: 100.000
r1fm+r2fm = 157.576

[Aggregate metrics]:
rouge1     | fm: 80.715 | p: 80.215 | r: 81.755
rouge2     | fm: 37.103 | p: 36.741 | r: 37.593
rougeL     | fm: 68.516 | p: 68.033 | r: 69.285
rougeLsum  | fm: 68.788 | p: 68.324 | r: 69.508
r1fm+r2fm = 117.818

input #35 time: 0:08:17 | total time: 5:03:34


Running input #36 of 100.
reference: 
========================
This information could have been released by Gorbachev, but he chose not to.
========================
average of cosine similarity 0.999461896585002
highest_index [0]
highest [0.999461896585002]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[  101,  2023,  2592,  2071,  2031,  2042,  2207,  2011,  2175, 28483,
         16179,  1010,  2021,  2002,  4900,  2025,  2000,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]']
[Init] best rec loss: 1.8711620569229126 for ['[CLS] actually joseph sofia sas colt late sketch sensefixed skate shaved clerical period huis powers news [SEP]']
[Init] best rec loss: 1.8475557565689087 for ['[CLS] enlarged like france fey lower updated left zimbabwe drove reserved ss era patrick klein ca collection painted [SEP]']
[Init] best rec loss: 1.8081066608428955 for ['[CLS] whenpressed pain must battled spyvu kilometres 10 term & enough bell each bandwidthdly design [SEP]']
[Init] best rec loss: 1.7946637868881226 for ['[CLS] im b year medici nobility struggling ) tempted poly objects equilibrium nora cam passing dorsey harlem shirt [SEP]']
[Init] best rec loss: 1.749609351158142 for ['[CLS]fect receiver underwear prizes gifford slaves vale hello sienna lights earl fried mason baronetitis stadium highway [SEP]']
[Init] best perm rec loss: 1.7446297407150269 for ['[CLS] lights gifford stadium masonitisfect hello sienna highway baronet vale earl receiver prizes slaves underwear fried [SEP]']
[Init] best perm rec loss: 1.7438631057739258 for ['[CLS] lights receiveritis baronet stadiumfect underwear vale hello earl prizes gifford mason sienna fried highway slaves [SEP]']
[Init] best perm rec loss: 1.7428724765777588 for ['[CLS] mason lights slaves baronet underwear helloitis fried receiver highway prizes sienna vale earl stadiumfect gifford [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.095 (perp=12.437, rec=0.608, cos=1.000), tot_loss_proj:4.360 [t=0.19s]
prediction: ['[CLS] system engines pension write unless & last chest limo colleagueservedplify prison.link favor caused [SEP]']
[ 100/2000] tot_loss=4.339 (perp=14.153, rec=0.508, cos=1.000), tot_loss_proj:4.703 [t=0.21s]
prediction: ['[CLS] information looked hesitationbr unless withoutinge janataeem mei ←⁺ cartel.link far rated [SEP]']
[ 150/2000] tot_loss=3.979 (perp=12.618, rec=0.456, cos=0.999), tot_loss_proj:4.360 [t=0.18s]
prediction: ['[CLS] information looked amnestychev could withoutingechevchev 成 agenda⁺chev. policy far category [SEP]']
[ 200/2000] tot_loss=3.973 (perp=12.341, rec=0.506, cos=0.999), tot_loss_proj:4.274 [t=0.18s]
prediction: ['[CLS] information looked amnesty attempt could withoutjchevchev 成 agenda asbestoschev. policy. effectively [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.723 (perp=11.590, rec=0.408, cos=0.997), tot_loss_proj:4.132 [t=0.19s]
prediction: ['[CLS] information could amnesty attempt could withoutwskichevchev 成sions beenchev. officials blew. [SEP]']
[ 300/2000] tot_loss=3.924 (perp=12.685, rec=0.394, cos=0.993), tot_loss_proj:4.320 [t=0.23s]
prediction: ['[CLS] information couldtya attempt could withoutwskichevchevclusivesions beenchev. initially ops. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.794 (perp=12.068, rec=0.387, cos=0.994), tot_loss_proj:4.198 [t=0.19s]
prediction: ['[CLS] information couldtya attempt could withoutwskichevchevpipesions beenchev. initiallyclusive. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.870 (perp=12.489, rec=0.377, cos=0.995), tot_loss_proj:4.317 [t=0.24s]
prediction: ['[CLS] information couldtya attempt couldrba etatchevchevchevsions beenpipe.chev revolves. [SEP]']
[ 450/2000] tot_loss=3.864 (perp=12.489, rec=0.369, cos=0.997), tot_loss_proj:4.321 [t=0.24s]
prediction: ['[CLS] information couldtya attempt couldrba etatchevchevchevsions beenpipe.chev revolves. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=3.878 (perp=12.366, rec=0.412, cos=0.993), tot_loss_proj:4.230 [t=0.18s]
prediction: ['[CLS] information couldtyarba outcome attempt chosechevchev legislationsions been handling ( initially 帝 to [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.730 (perp=11.840, rec=0.369, cos=0.993), tot_loss_proj:4.074 [t=0.21s]
prediction: ['[CLS] information couldtyarbachev attempt chose outcomechev legislationsions been handle. initially ultimately to [SEP]']
[ 600/2000] tot_loss=3.699 (perp=11.765, rec=0.352, cos=0.993), tot_loss_proj:4.097 [t=0.23s]
prediction: ['[CLS] information couldtyarbachev attempt chose outcomechevoroughesian been handle. released ultimately. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.583 (perp=11.214, rec=0.346, cos=0.994), tot_loss_proj:3.981 [t=0.19s]
prediction: ['[CLS] information couldtyarbachev attempt chose beenchevnsor claudius outcome executive. released ultimately. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.704 (perp=11.808, rec=0.348, cos=0.994), tot_loss_proj:4.176 [t=0.19s]
prediction: ['[CLS] information could unnecessaryrbachev attempt claudius chose beenchevnsor outcome executive. released ultimately. [SEP]']
[ 750/2000] tot_loss=3.688 (perp=11.810, rec=0.332, cos=0.994), tot_loss_proj:4.110 [t=0.19s]
prediction: ['[CLS] information could unnecessaryrbachev attempt never chose beenchevnsor outcome executive released released ultimately. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.643 (perp=11.573, rec=0.334, cos=0.994), tot_loss_proj:4.017 [t=0.19s]
prediction: ['[CLS] information could unnecessaryrbachev attempt certainly chose executivechevnsor outcome been released released ultimately. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.538 (perp=10.997, rec=0.344, cos=0.994), tot_loss_proj:3.926 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev unnecessary certainly chose executivechevnsor outcome been released released ultimately. [SEP]']
[ 900/2000] tot_loss=3.517 (perp=10.997, rec=0.323, cos=0.994), tot_loss_proj:3.927 [t=0.22s]
prediction: ['[CLS] information could attemptrbachev unnecessary certainly chose executivechevnsor outcome been released released ultimately. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=3.434 (perp=10.553, rec=0.330, cos=0.994), tot_loss_proj:3.825 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released released ultimately. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.426 (perp=10.553, rec=0.322, cos=0.994), tot_loss_proj:3.827 [t=0.18s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released released ultimately. [SEP]']
[1050/2000] tot_loss=3.543 (perp=11.146, rec=0.320, cos=0.994), tot_loss_proj:3.948 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.538 (perp=11.146, rec=0.314, cos=0.995), tot_loss_proj:3.944 [t=0.25s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.536 (perp=11.146, rec=0.312, cos=0.995), tot_loss_proj:3.945 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
[1200/2000] tot_loss=3.537 (perp=11.146, rec=0.312, cos=0.995), tot_loss_proj:3.942 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.531 (perp=11.146, rec=0.307, cos=0.995), tot_loss_proj:3.951 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.525 (perp=11.146, rec=0.300, cos=0.995), tot_loss_proj:3.947 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
[1350/2000] tot_loss=3.529 (perp=11.146, rec=0.305, cos=0.995), tot_loss_proj:3.945 [t=0.24s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.537 (perp=11.146, rec=0.312, cos=0.996), tot_loss_proj:3.943 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.523 (perp=11.146, rec=0.298, cos=0.996), tot_loss_proj:3.943 [t=0.25s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
[1500/2000] tot_loss=3.523 (perp=11.146, rec=0.298, cos=0.996), tot_loss_proj:3.943 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.525 (perp=11.146, rec=0.300, cos=0.996), tot_loss_proj:3.947 [t=0.18s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.539 (perp=11.146, rec=0.314, cos=0.996), tot_loss_proj:3.942 [t=0.23s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
[1650/2000] tot_loss=3.522 (perp=11.146, rec=0.297, cos=0.996), tot_loss_proj:3.943 [t=0.18s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.523 (perp=11.146, rec=0.297, cos=0.996), tot_loss_proj:3.944 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.530 (perp=11.146, rec=0.304, cos=0.996), tot_loss_proj:3.943 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]']
[1800/2000] tot_loss=3.501 (perp=11.025, rec=0.300, cos=0.996), tot_loss_proj:3.917 [t=0.18s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevorough outcome been released react ultimately. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.496 (perp=11.025, rec=0.294, cos=0.996), tot_loss_proj:3.917 [t=0.22s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevorough outcome been released react ultimately. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.488 (perp=11.025, rec=0.287, cos=0.996), tot_loss_proj:3.915 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevorough outcome been released react ultimately. [SEP]']
[1950/2000] tot_loss=3.490 (perp=11.025, rec=0.288, cos=0.996), tot_loss_proj:3.914 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevorough outcome been released react ultimately. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.502 (perp=11.025, rec=0.301, cos=0.997), tot_loss_proj:3.918 [t=0.19s]
prediction: ['[CLS] information could attemptrbachev certainly chose unnecessary executivechevorough outcome been released react ultimately. [SEP]']
Done with input #36 of 100.
reference: 
========================
[CLS] this information could have been released by gorbachev, but he chose not to. [SEP]
========================
predicted: 
========================
[CLS] information could attemptrbachev certainly chose unnecessary executivechevnsor outcome been released react ultimately. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.276 | p: 50.000 | r: 46.667
rouge2     | fm: 14.815 | p: 15.385 | r: 14.286
rougeL     | fm: 41.379 | p: 42.857 | r: 40.000
rougeLsum  | fm: 41.379 | p: 42.857 | r: 40.000
r1fm+r2fm = 63.091

[Aggregate metrics]:
rouge1     | fm: 79.933 | p: 79.438 | r: 80.776
rouge2     | fm: 36.360 | p: 36.028 | r: 36.865
rougeL     | fm: 67.986 | p: 67.422 | r: 68.693
rougeLsum  | fm: 67.915 | p: 67.529 | r: 68.621
r1fm+r2fm = 116.293

input #36 time: 0:08:19 | total time: 5:11:53


Running input #37 of 100.
reference: 
========================
Kevin ate spaghetti with a spoon and Geordie did so too.
========================
average of cosine similarity 0.9993304804986536
highest_index [0]
highest [0.9993304804986536]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  4901,  8823, 26666,  2007,  1037, 15642,  1998, 20248, 17080,
          2063,  2106,  2061,  2205,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]']
[Init] best rec loss: 1.911374568939209 for ['[CLS] grace extent first over maritime walked aria intake axis catcher dickinson twice tires serve [SEP]']
[Init] best rec loss: 1.8831528425216675 for ['[CLS] sayingl last the mate effect centralɛ titled from career winners stake etc [SEP]']
[Init] best rec loss: 1.8805214166641235 for ['[CLS] firingih bark programme powell colt angeles iangina warrant intention natural torontokind [SEP]']
[Init] best rec loss: 1.870123267173767 for ['[CLS] total kitchen sho has loving flora mongolia supreme majesty american herald world division reflection [SEP]']
[Init] best rec loss: 1.8675720691680908 for ['[CLS] nun backing gershwin greetedties though goes tied lindsay value shotgun breathe pauline called [SEP]']
[Init] best rec loss: 1.8648192882537842 for ['[CLS] templeeca walking ballads runs allow format → echo dedicatedwine kingdom awarded stars [SEP]']
[Init] best rec loss: 1.8569958209991455 for ['[CLS] agesee sourhart pathato consciousness /kel less tale trail origins races [SEP]']
[Init] best rec loss: 1.8513355255126953 for ['[CLS] ward millieael matter court universal tanner afterward chloe thirty scoring jack grey treat [SEP]']
[Init] best rec loss: 1.8329858779907227 for ['[CLS] id lille lightning produced y samecraft radio multiple there shortly nano lunch judge [SEP]']
[Init] best rec loss: 1.8249486684799194 for ['[CLS] your force surge like delludedthesis command angeles emblem locked propulsion skirt knocks [SEP]']
[Init] best perm rec loss: 1.82296884059906 for ['[CLS] your like surge emblem locked angeles force dell propulsion knocks commandthesisuded skirt [SEP]']
[Init] best perm rec loss: 1.8213392496109009 for ['[CLS] dell emblem commandthesis skirt angeles likeuded locked surge knocks propulsion your force [SEP]']
[Init] best perm rec loss: 1.8211369514465332 for ['[CLS] emblem force knocksuded dell command angeles surge locked propulsion likethesis your skirt [SEP]']
[Init] best perm rec loss: 1.8208014965057373 for ['[CLS] locked your command emblem like forceuded propulsion skirt angeles surgethesis dell knocks [SEP]']
[Init] best perm rec loss: 1.8201420307159424 for ['[CLS] dell your force skirt command emblemthesis locked surgeuded propulsion knocks angeles like [SEP]']
[Init] best perm rec loss: 1.8200104236602783 for ['[CLS] emblem dell angeles your like force surge skirt locked command propulsionudedthesis knocks [SEP]']
[Init] best perm rec loss: 1.8193992376327515 for ['[CLS] your emblem knocks angeles skirt surge forcethesis locked command propulsion dell likeuded [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.356 (perp=13.537, rec=0.651, cos=0.998), tot_loss_proj:4.547 [t=0.23s]
prediction: ['[CLS] inflammatorydor beforeald near surge wilame. us gazedtens toilet bavaria [SEP]']
[ 100/2000] tot_loss=4.555 (perp=14.998, rec=0.558, cos=0.998), tot_loss_proj:4.843 [t=0.24s]
prediction: ['[CLS] inflammatory! behindte aquarize geo geouti effort gazed geo toilet noah [SEP]']
[ 150/2000] tot_loss=4.083 (perp=12.991, rec=0.485, cos=1.000), tot_loss_proj:4.463 [t=0.31s]
prediction: ['[CLS] inflammatory! behind. versardi geordi. commentedetti geo toilete [SEP]']
[ 200/2000] tot_loss=3.651 (perp=11.149, rec=0.422, cos=0.998), tot_loss_proj:4.069 [t=0.18s]
prediction: ['[CLS] ¿ did was. throughrdi geordies sounded makes geo toilete [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.455 (perp=10.287, rec=0.400, cos=0.998), tot_loss_proj:3.975 [t=0.18s]
prediction: ['[CLS] ¿ did did. through spaghetti geordie non spoon geo soundede [SEP]']
[ 300/2000] tot_loss=3.557 (perp=10.304, rec=0.502, cos=0.995), tot_loss_proj:4.004 [t=0.18s]
prediction: ['[CLS] ¿ did (. through spaghetti geordie non spoon geo definee [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.504 (perp=10.704, rec=0.365, cos=0.999), tot_loss_proj:4.020 [t=0.18s]
prediction: ['[CLS] kevin dide. through spaghetti geordiesachal spoon geo embarrassed ( [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.346 (perp=10.045, rec=0.339, cos=0.998), tot_loss_proj:4.000 [t=0.18s]
prediction: ['[CLS] kevin dide - through spaghetti geordie innocent spoon geo ( define [SEP]']
[ 450/2000] tot_loss=3.663 (perp=11.665, rec=0.332, cos=0.998), tot_loss_proj:4.297 [t=0.18s]
prediction: ['[CLS] kevin dide - through spaghetti geordiesh innocent spoon geo shelf did [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.353 (perp=10.137, rec=0.328, cos=0.998), tot_loss_proj:4.017 [t=0.18s]
prediction: ['[CLS] kevin dide - through spaghetti geordie innocent spoon geo shelf did [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.334 (perp=10.066, rec=0.322, cos=0.998), tot_loss_proj:3.860 [t=0.18s]
prediction: ['[CLS] kevinesh did - so spaghetti geordie innocent ate geo shelf did [SEP]']
[ 600/2000] tot_loss=3.384 (perp=10.364, rec=0.313, cos=0.998), tot_loss_proj:3.925 [t=0.18s]
prediction: ['[CLS] kevinesh did. so spaghetti geordie innocent ate geo shelf did [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.386 (perp=10.364, rec=0.315, cos=0.998), tot_loss_proj:3.929 [t=0.18s]
prediction: ['[CLS] kevinesh did. so spaghetti geordie innocent ate geo shelf did [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.384 (perp=10.364, rec=0.312, cos=0.999), tot_loss_proj:3.927 [t=0.28s]
prediction: ['[CLS] kevinesh did. so spaghetti geordie innocent ate geo shelf did [SEP]']
[ 750/2000] tot_loss=3.367 (perp=10.364, rec=0.296, cos=0.999), tot_loss_proj:3.926 [t=0.27s]
prediction: ['[CLS] kevinesh did. so spaghetti geordie innocent ate geo shelf did [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.363 (perp=10.364, rec=0.292, cos=0.999), tot_loss_proj:3.928 [t=0.21s]
prediction: ['[CLS] kevinesh did. so spaghetti geordie innocent ate geo shelf did [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.376 (perp=10.364, rec=0.304, cos=0.999), tot_loss_proj:3.928 [t=0.27s]
prediction: ['[CLS] kevinesh did. so spaghetti geordie innocent ate geo shelf did [SEP]']
[ 900/2000] tot_loss=3.366 (perp=10.364, rec=0.294, cos=0.999), tot_loss_proj:3.924 [t=0.19s]
prediction: ['[CLS] kevinesh did. so spaghetti geordie innocent ate geo shelf did [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.370 (perp=10.364, rec=0.298, cos=0.999), tot_loss_proj:3.928 [t=0.21s]
prediction: ['[CLS] kevinesh did. so spaghetti geordie innocent ate geo shelf did [SEP]']
Attempt swap
[1000/2000] tot_loss=3.325 (perp=10.165, rec=0.293, cos=0.999), tot_loss_proj:3.870 [t=0.23s]
prediction: ['[CLS] kevinesh did. so spaghetti geordie innocent did geo shelf did [SEP]']
[1050/2000] tot_loss=3.540 (perp=11.230, rec=0.295, cos=0.999), tot_loss_proj:4.117 [t=0.21s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie innocent did geo shelf did [SEP]']
Attempt swap
[1100/2000] tot_loss=3.533 (perp=11.230, rec=0.288, cos=0.999), tot_loss_proj:4.122 [t=0.19s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie innocent did geo shelf did [SEP]']
Attempt swap
[1150/2000] tot_loss=3.474 (perp=10.960, rec=0.282, cos=0.999), tot_loss_proj:4.007 [t=0.18s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
[1200/2000] tot_loss=3.477 (perp=10.960, rec=0.286, cos=0.999), tot_loss_proj:4.006 [t=0.18s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
Attempt swap
[1250/2000] tot_loss=3.473 (perp=10.960, rec=0.282, cos=0.999), tot_loss_proj:4.007 [t=0.20s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
Attempt swap
[1300/2000] tot_loss=3.483 (perp=10.960, rec=0.292, cos=0.999), tot_loss_proj:4.014 [t=0.25s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
[1350/2000] tot_loss=3.476 (perp=10.960, rec=0.285, cos=0.999), tot_loss_proj:4.009 [t=0.18s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
Attempt swap
[1400/2000] tot_loss=3.473 (perp=10.960, rec=0.282, cos=0.999), tot_loss_proj:4.014 [t=0.24s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
Attempt swap
[1450/2000] tot_loss=3.467 (perp=10.960, rec=0.276, cos=0.999), tot_loss_proj:4.010 [t=0.21s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
[1500/2000] tot_loss=3.472 (perp=10.960, rec=0.280, cos=0.999), tot_loss_proj:4.010 [t=0.22s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
Attempt swap
[1550/2000] tot_loss=3.476 (perp=10.960, rec=0.285, cos=0.999), tot_loss_proj:4.011 [t=0.19s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
Attempt swap
[1600/2000] tot_loss=3.465 (perp=10.960, rec=0.274, cos=0.999), tot_loss_proj:4.010 [t=0.18s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
[1650/2000] tot_loss=3.472 (perp=10.960, rec=0.281, cos=0.999), tot_loss_proj:4.007 [t=0.25s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
Attempt swap
[1700/2000] tot_loss=3.468 (perp=10.960, rec=0.276, cos=0.999), tot_loss_proj:4.010 [t=0.18s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo shelf did [SEP]']
Attempt swap
[1750/2000] tot_loss=3.294 (perp=10.060, rec=0.282, cos=0.999), tot_loss_proj:3.858 [t=0.26s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo does did [SEP]']
[1800/2000] tot_loss=3.282 (perp=10.060, rec=0.270, cos=0.999), tot_loss_proj:3.860 [t=0.26s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo does did [SEP]']
Attempt swap
[1850/2000] tot_loss=3.293 (perp=10.060, rec=0.282, cos=0.999), tot_loss_proj:3.859 [t=0.22s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo does did [SEP]']
Attempt swap
[1900/2000] tot_loss=3.293 (perp=10.060, rec=0.282, cos=0.999), tot_loss_proj:3.858 [t=0.18s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo does did [SEP]']
[1950/2000] tot_loss=3.291 (perp=10.060, rec=0.280, cos=0.999), tot_loss_proj:3.860 [t=0.21s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo does did [SEP]']
Attempt swap
[2000/2000] tot_loss=3.403 (perp=10.632, rec=0.278, cos=0.999), tot_loss_proj:3.949 [t=0.20s]
prediction: ['[CLS] kevinesh did. so spaghetti withrdie genus did geo happened did [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] kevin ate spaghetti with a spoon and geordie did so too. [SEP]
========================
predicted: 
========================
[CLS] kevinesh did. so spaghetti withrdie genus did geo does did [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 41.667 | r: 38.462
rouge2     | fm: 8.696 | p: 9.091 | r: 8.333
rougeL     | fm: 32.000 | p: 33.333 | r: 30.769
rougeLsum  | fm: 32.000 | p: 33.333 | r: 30.769
r1fm+r2fm = 48.696

[Aggregate metrics]:
rouge1     | fm: 78.830 | p: 78.268 | r: 79.590
rouge2     | fm: 35.843 | p: 35.494 | r: 36.356
rougeL     | fm: 66.859 | p: 66.415 | r: 67.562
rougeLsum  | fm: 67.149 | p: 66.745 | r: 67.728
r1fm+r2fm = 114.674

input #37 time: 0:08:35 | total time: 5:20:29


Running input #38 of 100.
reference: 
========================
John is the kind of fool that I told you about.
========================
average of cosine similarity 0.9995113299775283
highest_index [0]
highest [0.9995113299775283]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[ 101, 2198, 2003, 1996, 2785, 1997, 7966, 2008, 1045, 2409, 2017, 2055,
         1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john is the kind of fool that i told you about. [SEP]']
[Init] best rec loss: 1.8025213479995728 for ['[CLS] medicine horns clear john splash treaties samson com credited birthplace ago managing [SEP]']
[Init] best rec loss: 1.7636878490447998 for ['[CLS] helped craft skip t blowcap shared balthazarmara refer wc expressions [SEP]']
[Init] best rec loss: 1.7544242143630981 for ['[CLS] nobility fail chapter pace distinctionburn khorasan down scoredcured direct rite [SEP]']
[Init] best rec loss: 1.7477167844772339 for ['[CLS]bang marine plain chapter srnsloadzh smart want humor ribbon [SEP]']
[Init] best rec loss: 1.7291399240493774 for ['[CLS] minute offᵒnte reputed automotive ed indian bored quest with studios [SEP]']
[Init] best rec loss: 1.719730019569397 for ['[CLS] discussionsdden chartersrter geometridae proofgio burgundy obe phone field translit [SEP]']
[Init] best rec loss: 1.7099213600158691 for ['[CLS] faint massacre circuit further difficulty utility block gr commissioned its city peck [SEP]']
[Init] best perm rec loss: 1.7072371244430542 for ['[CLS] circuit further gr difficulty peck massacre block faint its utility city commissioned [SEP]']
[Init] best perm rec loss: 1.7041339874267578 for ['[CLS] city massacre utility block commissioned its further circuit difficulty peck gr faint [SEP]']
[Init] best perm rec loss: 1.7033239603042603 for ['[CLS] difficulty circuit block further gr massacre faint city its peck utility commissioned [SEP]']
[Init] best perm rec loss: 1.7028989791870117 for ['[CLS] utility peck difficulty circuit block massacre commissioned gr faint its further city [SEP]']
[Init] best perm rec loss: 1.702406406402588 for ['[CLS] difficulty utility faint circuit gr commissioned its block city further massacre peck [SEP]']
[Init] best perm rec loss: 1.7016339302062988 for ['[CLS] difficulty utility block peck commissioned massacre city circuit further gr faint its [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.633 (perp=9.847, rec=0.699, cos=0.964), tot_loss_proj:3.757 [t=0.20s]
prediction: ['[CLS] jolly book did praised shown. blow. was this episode ensure [SEP]']
[ 100/2000] tot_loss=1.908 (perp=7.848, rec=0.305, cos=0.033), tot_loss_proj:3.378 [t=0.24s]
prediction: ['[CLS] a john is told ] fool you ; i you if? [SEP]']
[ 150/2000] tot_loss=1.968 (perp=8.613, rec=0.231, cos=0.014), tot_loss_proj:3.501 [t=0.27s]
prediction: ['[CLS] a john is told kind fool john. i you of? [SEP]']
[ 200/2000] tot_loss=1.953 (perp=8.922, rec=0.160, cos=0.009), tot_loss_proj:3.533 [t=0.18s]
prediction: ['[CLS] is john is told kind fool john that i you of? [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.926 (perp=8.922, rec=0.135, cos=0.006), tot_loss_proj:3.534 [t=0.31s]
prediction: ['[CLS] is john is told kind fool john that i you of? [SEP]']
[ 300/2000] tot_loss=2.101 (perp=9.818, rec=0.132, cos=0.005), tot_loss_proj:3.733 [t=0.19s]
prediction: ['[CLS] is the is told kind fool john that i you. about [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.152 (perp=9.957, rec=0.151, cos=0.009), tot_loss_proj:3.714 [t=0.18s]
prediction: ['[CLS] is of than told kind fool that i john you. suppose [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.821 (perp=8.202, rec=0.171, cos=0.010), tot_loss_proj:3.485 [t=0.18s]
prediction: ['[CLS] is of! kind fool that i john told you. about [SEP]']
[ 450/2000] tot_loss=1.787 (perp=8.202, rec=0.140, cos=0.007), tot_loss_proj:3.490 [t=0.18s]
prediction: ['[CLS] is of! kind fool that i john told you. about [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.657 (perp=7.577, rec=0.136, cos=0.006), tot_loss_proj:3.383 [t=0.20s]
prediction: ['[CLS] is of fool kind of that i john told you. about [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.697 (perp=7.435, rec=0.197, cos=0.013), tot_loss_proj:3.239 [t=0.22s]
prediction: ['[CLS] is of fool kind of that i john told you planet. [SEP]']
[ 600/2000] tot_loss=1.731 (perp=7.893, rec=0.145, cos=0.006), tot_loss_proj:3.311 [t=0.18s]
prediction: ['[CLS] is was fool kind of that i john told you planet. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.585 (perp=7.236, rec=0.132, cos=0.006), tot_loss_proj:3.179 [t=0.25s]
prediction: ['[CLS] is was fool kind of john i that told you planet. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.550 (perp=7.061, rec=0.133, cos=0.005), tot_loss_proj:3.151 [t=0.19s]
prediction: ['[CLS] is was fool kind of john that i told you planet. [SEP]']
[ 750/2000] tot_loss=1.423 (perp=6.447, rec=0.129, cos=0.005), tot_loss_proj:3.253 [t=0.18s]
prediction: ['[CLS] is was fool kind of john that i told you about. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.365 (perp=6.180, rec=0.124, cos=0.005), tot_loss_proj:3.206 [t=0.25s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.373 (perp=6.180, rec=0.132, cos=0.005), tot_loss_proj:3.203 [t=0.18s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
[ 900/2000] tot_loss=1.356 (perp=6.180, rec=0.115, cos=0.005), tot_loss_proj:3.201 [t=0.18s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.371 (perp=6.180, rec=0.130, cos=0.004), tot_loss_proj:3.203 [t=0.19s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.356 (perp=6.180, rec=0.115, cos=0.004), tot_loss_proj:3.201 [t=0.21s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
[1050/2000] tot_loss=1.366 (perp=6.180, rec=0.126, cos=0.004), tot_loss_proj:3.207 [t=0.18s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.367 (perp=6.180, rec=0.127, cos=0.004), tot_loss_proj:3.203 [t=0.18s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.364 (perp=6.180, rec=0.123, cos=0.004), tot_loss_proj:3.206 [t=0.18s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
[1200/2000] tot_loss=1.353 (perp=6.180, rec=0.113, cos=0.004), tot_loss_proj:3.204 [t=0.22s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.363 (perp=6.180, rec=0.123, cos=0.004), tot_loss_proj:3.205 [t=0.27s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.358 (perp=6.180, rec=0.118, cos=0.004), tot_loss_proj:3.205 [t=0.24s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
[1350/2000] tot_loss=1.354 (perp=6.180, rec=0.114, cos=0.004), tot_loss_proj:3.219 [t=0.22s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.365 (perp=6.180, rec=0.124, cos=0.004), tot_loss_proj:3.205 [t=0.18s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.357 (perp=6.180, rec=0.117, cos=0.004), tot_loss_proj:3.222 [t=0.22s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
[1500/2000] tot_loss=1.348 (perp=6.180, rec=0.107, cos=0.004), tot_loss_proj:3.217 [t=0.18s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.355 (perp=6.180, rec=0.115, cos=0.004), tot_loss_proj:3.213 [t=0.18s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.358 (perp=6.180, rec=0.118, cos=0.004), tot_loss_proj:3.217 [t=0.23s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
[1650/2000] tot_loss=1.353 (perp=6.180, rec=0.113, cos=0.004), tot_loss_proj:3.218 [t=0.20s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.350 (perp=6.180, rec=0.110, cos=0.004), tot_loss_proj:3.224 [t=0.18s]
prediction: ['[CLS] was is fool kind of john that i told you about. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.324 (perp=6.048, rec=0.111, cos=0.004), tot_loss_proj:3.280 [t=0.21s]
prediction: ['[CLS] about is fool kind of john that i told you about. [SEP]']
[1800/2000] tot_loss=1.320 (perp=6.048, rec=0.106, cos=0.004), tot_loss_proj:3.279 [t=0.23s]
prediction: ['[CLS] about is fool kind of john that i told you about. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.329 (perp=6.048, rec=0.115, cos=0.004), tot_loss_proj:3.279 [t=0.18s]
prediction: ['[CLS] about is fool kind of john that i told you about. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.336 (perp=6.048, rec=0.123, cos=0.004), tot_loss_proj:3.277 [t=0.18s]
prediction: ['[CLS] about is fool kind of john that i told you about. [SEP]']
[1950/2000] tot_loss=1.323 (perp=6.048, rec=0.109, cos=0.004), tot_loss_proj:3.282 [t=0.26s]
prediction: ['[CLS] about is fool kind of john that i told you about. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.331 (perp=6.048, rec=0.117, cos=0.004), tot_loss_proj:3.279 [t=0.20s]
prediction: ['[CLS] about is fool kind of john that i told you about. [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] john is the kind of fool that i told you about. [SEP]
========================
predicted: 
========================
[CLS] about is fool kind of john that i told you about. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 76.923 | p: 76.923 | r: 76.923
rougeLsum  | fm: 76.923 | p: 76.923 | r: 76.923
r1fm+r2fm = 142.308

[Aggregate metrics]:
rouge1     | fm: 79.137 | p: 78.699 | r: 79.883
rouge2     | fm: 36.170 | p: 35.806 | r: 36.669
rougeL     | fm: 67.202 | p: 66.737 | r: 67.797
rougeLsum  | fm: 67.476 | p: 67.076 | r: 68.080
r1fm+r2fm = 115.307

input #38 time: 0:08:19 | total time: 5:28:48


Running input #39 of 100.
reference: 
========================
I doubt if you can help me in understanding this.
========================
average of cosine similarity 0.99941311323763
highest_index [0]
highest [0.99941311323763]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 1045, 4797, 2065, 2017, 2064, 2393, 2033, 1999, 4824, 2023, 1012,
          102]], device='cuda:0')
Debug: ref = ['[CLS] i doubt if you can help me in understanding this. [SEP]']
[Init] best rec loss: 1.834570050239563 for ['[CLS] probably issue jade aren circumstances day old mayohum asian belonging [SEP]']
[Init] best rec loss: 1.8201663494110107 for ['[CLS] ethan jan shapezed supreme near areasert patrol passed gunpowder [SEP]']
[Init] best rec loss: 1.8190677165985107 for ['[CLS] character pen grace i coin fbi species big on hiking quick [SEP]']
[Init] best rec loss: 1.8169355392456055 for ['[CLS] ke radio n metal light full composition alreadyfia lucappy [SEP]']
[Init] best rec loss: 1.7915723323822021 for ['[CLS] medalulent holiday months through spoke dimension col sc specialsulf [SEP]']
[Init] best rec loss: 1.7448594570159912 for ['[CLS] mention reports leftdinapping overhead prix ko rule arrival boot [SEP]']
[Init] best rec loss: 1.7321523427963257 for ['[CLS] arch bid bar pa than pont clubs each year dorsal logos [SEP]']
[Init] best perm rec loss: 1.7307525873184204 for ['[CLS] dorsal clubs arch bid logos each than year bar pa pont [SEP]']
[Init] best perm rec loss: 1.7303093671798706 for ['[CLS] logos arch pa dorsal pont year each bar clubs than bid [SEP]']
[Init] best perm rec loss: 1.7285956144332886 for ['[CLS] clubs arch pa year each dorsal pont bid than bar logos [SEP]']
[Init] best perm rec loss: 1.7279905080795288 for ['[CLS] clubs bar pa arch year bid pont logos than each dorsal [SEP]']
[Init] best perm rec loss: 1.7262135744094849 for ['[CLS] arch bar logos clubs year dorsal bid than each pont pa [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.088 (perp=10.476, rec=0.510, cos=0.483), tot_loss_proj:3.893 [t=0.25s]
prediction: ['[CLS] use hope prophecy fruit might about?. °ciman. [SEP]']
[ 100/2000] tot_loss=1.817 (perp=7.463, rec=0.286, cos=0.039), tot_loss_proj:3.255 [t=0.19s]
prediction: ['[CLS] you doubt if know help if.? i mind. [SEP]']
[ 150/2000] tot_loss=1.680 (perp=7.329, rec=0.197, cos=0.017), tot_loss_proj:3.220 [t=0.28s]
prediction: ['[CLS] you doubt if know help if you understanding i mind. [SEP]']
[ 200/2000] tot_loss=1.570 (perp=7.151, rec=0.134, cos=0.006), tot_loss_proj:3.198 [t=0.26s]
prediction: ['[CLS] you doubt if could help in this understanding me mind. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.538 (perp=6.704, rec=0.178, cos=0.019), tot_loss_proj:3.472 [t=0.21s]
prediction: ['[CLS] you doubt if this can help in understanding metrust. [SEP]']
[ 300/2000] tot_loss=1.455 (perp=6.704, rec=0.110, cos=0.004), tot_loss_proj:3.420 [t=0.23s]
prediction: ['[CLS] you doubt if this can help in understanding metrust. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.440 (perp=6.704, rec=0.096, cos=0.003), tot_loss_proj:3.425 [t=0.19s]
prediction: ['[CLS] you doubt if this can help in understanding metrust. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.432 (perp=6.704, rec=0.089, cos=0.003), tot_loss_proj:3.424 [t=0.29s]
prediction: ['[CLS] you doubt if this can help in understanding metrust. [SEP]']
[ 450/2000] tot_loss=1.429 (perp=6.704, rec=0.086, cos=0.003), tot_loss_proj:3.427 [t=0.26s]
prediction: ['[CLS] you doubt if this can help in understanding metrust. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.408 (perp=6.538, rec=0.098, cos=0.003), tot_loss_proj:3.049 [t=0.19s]
prediction: ['[CLS] you doubt if this can help me in understandingtrust. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.346 (perp=6.313, rec=0.081, cos=0.003), tot_loss_proj:3.076 [t=0.18s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
[ 600/2000] tot_loss=1.341 (perp=6.313, rec=0.076, cos=0.003), tot_loss_proj:3.054 [t=0.21s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.341 (perp=6.313, rec=0.076, cos=0.002), tot_loss_proj:3.059 [t=0.18s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.344 (perp=6.313, rec=0.079, cos=0.002), tot_loss_proj:3.065 [t=0.22s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
[ 750/2000] tot_loss=1.339 (perp=6.313, rec=0.074, cos=0.002), tot_loss_proj:3.065 [t=0.23s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.348 (perp=6.313, rec=0.083, cos=0.002), tot_loss_proj:3.073 [t=0.18s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.332 (perp=6.313, rec=0.067, cos=0.002), tot_loss_proj:3.077 [t=0.18s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
[ 900/2000] tot_loss=1.341 (perp=6.313, rec=0.076, cos=0.002), tot_loss_proj:3.074 [t=0.25s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.345 (perp=6.313, rec=0.080, cos=0.002), tot_loss_proj:3.076 [t=0.19s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.347 (perp=6.313, rec=0.083, cos=0.002), tot_loss_proj:3.087 [t=0.19s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
[1050/2000] tot_loss=1.340 (perp=6.313, rec=0.075, cos=0.002), tot_loss_proj:3.082 [t=0.23s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.346 (perp=6.313, rec=0.081, cos=0.002), tot_loss_proj:3.085 [t=0.18s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.338 (perp=6.313, rec=0.073, cos=0.002), tot_loss_proj:3.076 [t=0.20s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
[1200/2000] tot_loss=1.330 (perp=6.313, rec=0.065, cos=0.002), tot_loss_proj:3.083 [t=0.22s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.353 (perp=6.313, rec=0.088, cos=0.002), tot_loss_proj:3.092 [t=0.22s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.342 (perp=6.313, rec=0.077, cos=0.002), tot_loss_proj:3.091 [t=0.18s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
[1350/2000] tot_loss=1.338 (perp=6.313, rec=0.073, cos=0.002), tot_loss_proj:3.095 [t=0.18s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.356 (perp=6.313, rec=0.092, cos=0.002), tot_loss_proj:3.088 [t=0.18s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.341 (perp=6.313, rec=0.076, cos=0.002), tot_loss_proj:3.092 [t=0.20s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
[1500/2000] tot_loss=1.344 (perp=6.313, rec=0.079, cos=0.002), tot_loss_proj:3.088 [t=0.19s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.329 (perp=6.313, rec=0.065, cos=0.002), tot_loss_proj:3.091 [t=0.19s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.340 (perp=6.313, rec=0.075, cos=0.002), tot_loss_proj:3.099 [t=0.20s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
[1650/2000] tot_loss=1.340 (perp=6.313, rec=0.075, cos=0.002), tot_loss_proj:3.098 [t=0.26s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.343 (perp=6.313, rec=0.078, cos=0.002), tot_loss_proj:3.096 [t=0.19s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.342 (perp=6.313, rec=0.077, cos=0.002), tot_loss_proj:3.091 [t=0.20s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
[1800/2000] tot_loss=1.339 (perp=6.313, rec=0.074, cos=0.002), tot_loss_proj:3.094 [t=0.22s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.347 (perp=6.313, rec=0.083, cos=0.002), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.340 (perp=6.313, rec=0.075, cos=0.002), tot_loss_proj:3.099 [t=0.19s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
[1950/2000] tot_loss=1.342 (perp=6.313, rec=0.077, cos=0.002), tot_loss_proj:3.100 [t=0.18s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.340 (perp=6.313, rec=0.075, cos=0.002), tot_loss_proj:3.093 [t=0.18s]
prediction: ['[CLS] you doubt iftrust can help me in understanding this. [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] i doubt if you can help me in understanding this. [SEP]
========================
predicted: 
========================
[CLS] you doubt iftrust can help me in understanding this. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 90.909 | r: 83.333
rouge2     | fm: 57.143 | p: 60.000 | r: 54.545
rougeL     | fm: 78.261 | p: 81.818 | r: 75.000
rougeLsum  | fm: 78.261 | p: 81.818 | r: 75.000
r1fm+r2fm = 144.099

[Aggregate metrics]:
rouge1     | fm: 79.381 | p: 78.864 | r: 80.082
rouge2     | fm: 36.769 | p: 36.559 | r: 37.113
rougeL     | fm: 67.394 | p: 67.045 | r: 67.896
rougeLsum  | fm: 67.580 | p: 67.327 | r: 68.111
r1fm+r2fm = 116.150

input #39 time: 0:08:33 | total time: 5:37:22


Running input #40 of 100.
reference: 
========================
Was the child running to the car?
========================
average of cosine similarity 0.9994376310826198
highest_index [0]
highest [0.9994376310826198]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2001, 1996, 2775, 2770, 2000, 1996, 2482, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] was the child running to the car? [SEP]']
[Init] best rec loss: 1.884344220161438 for ['[CLS]chfield only loan mast lust nape " nearly [SEP]']
[Init] best rec loss: 1.7391606569290161 for ['[CLS]typic races investigation singular haven boreay libby [SEP]']
[Init] best rec loss: 1.7371854782104492 for ['[CLS] private spot labor veil expect ar charity hum [SEP]']
[Init] best perm rec loss: 1.732835292816162 for ['[CLS] charity expect veil spot ar private hum labor [SEP]']
[Init] best perm rec loss: 1.7327277660369873 for ['[CLS] charity expect labor hum spot veil ar private [SEP]']
[Init] best perm rec loss: 1.732262372970581 for ['[CLS] veil expect private charity labor spot ar hum [SEP]']
[Init] best perm rec loss: 1.7288391590118408 for ['[CLS] spot labor hum charity private ar veil expect [SEP]']
[Init] best perm rec loss: 1.7281644344329834 for ['[CLS] spot ar expect private hum veil charity labor [SEP]']
[Init] best perm rec loss: 1.7272783517837524 for ['[CLS] spot expect hum private charity veil labor ar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.795 (perp=10.089, rec=0.526, cos=0.251), tot_loss_proj:3.881 [t=0.29s]
prediction: ['[CLS], daddy the within revival contains launch you [SEP]']
[ 100/2000] tot_loss=2.512 (perp=10.095, rec=0.409, cos=0.084), tot_loss_proj:3.893 [t=0.25s]
prediction: ['[CLS] to daddy reacher within children concluded. you [SEP]']
[ 150/2000] tot_loss=2.577 (perp=10.851, rec=0.359, cos=0.047), tot_loss_proj:4.040 [t=0.25s]
prediction: ['[CLS], child reacher within children concluded mad you [SEP]']
[ 200/2000] tot_loss=2.566 (perp=11.153, rec=0.306, cos=0.029), tot_loss_proj:4.059 [t=0.18s]
prediction: ['[CLS], child reacher child children concluded launch you [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.171 (perp=9.148, rec=0.305, cos=0.037), tot_loss_proj:3.643 [t=0.21s]
prediction: ['[CLS] if child whatever the child children running and [SEP]']
[ 300/2000] tot_loss=2.386 (perp=10.582, rec=0.250, cos=0.020), tot_loss_proj:3.924 [t=0.18s]
prediction: ['[CLS] was car mallory the child children running and [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.900 (perp=8.373, rec=0.215, cos=0.011), tot_loss_proj:3.544 [t=0.18s]
prediction: ['[CLS] was? the and the child car running [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.704 (perp=7.736, rec=0.149, cos=0.007), tot_loss_proj:3.447 [t=0.18s]
prediction: ['[CLS] was? the car the child and running [SEP]']
[ 450/2000] tot_loss=1.680 (perp=7.736, rec=0.128, cos=0.005), tot_loss_proj:3.442 [t=0.19s]
prediction: ['[CLS] was? the car the child and running [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.538 (perp=7.102, rec=0.114, cos=0.003), tot_loss_proj:3.368 [t=0.18s]
prediction: ['[CLS] was running the car the child and? [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.409 (perp=6.471, rec=0.111, cos=0.004), tot_loss_proj:3.393 [t=0.22s]
prediction: ['[CLS] was running the car and the child? [SEP]']
[ 600/2000] tot_loss=1.565 (perp=7.340, rec=0.095, cos=0.003), tot_loss_proj:3.309 [t=0.23s]
prediction: ['[CLS] was running the car the the child? [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.475 (perp=6.945, rec=0.083, cos=0.003), tot_loss_proj:3.221 [t=0.19s]
prediction: ['[CLS] was the running the car the child? [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.483 (perp=6.984, rec=0.084, cos=0.003), tot_loss_proj:3.332 [t=0.28s]
prediction: ['[CLS] was the running the car to child? [SEP]']
[ 750/2000] tot_loss=1.488 (perp=6.984, rec=0.088, cos=0.002), tot_loss_proj:3.333 [t=0.21s]
prediction: ['[CLS] was the running the car to child? [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.385 (perp=6.484, rec=0.086, cos=0.002), tot_loss_proj:3.188 [t=0.20s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.373 (perp=6.484, rec=0.074, cos=0.002), tot_loss_proj:3.182 [t=0.23s]
prediction: ['[CLS] was running the car to the child? [SEP]']
[ 900/2000] tot_loss=1.384 (perp=6.484, rec=0.085, cos=0.002), tot_loss_proj:3.183 [t=0.18s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.388 (perp=6.484, rec=0.089, cos=0.002), tot_loss_proj:3.187 [t=0.18s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1000/2000] tot_loss=1.385 (perp=6.484, rec=0.086, cos=0.002), tot_loss_proj:3.192 [t=0.24s]
prediction: ['[CLS] was running the car to the child? [SEP]']
[1050/2000] tot_loss=1.374 (perp=6.484, rec=0.075, cos=0.002), tot_loss_proj:3.185 [t=0.23s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1100/2000] tot_loss=1.371 (perp=6.484, rec=0.072, cos=0.002), tot_loss_proj:3.190 [t=0.18s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1150/2000] tot_loss=1.373 (perp=6.484, rec=0.074, cos=0.002), tot_loss_proj:3.192 [t=0.27s]
prediction: ['[CLS] was running the car to the child? [SEP]']
[1200/2000] tot_loss=1.380 (perp=6.484, rec=0.081, cos=0.002), tot_loss_proj:3.183 [t=0.27s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1250/2000] tot_loss=1.379 (perp=6.484, rec=0.080, cos=0.002), tot_loss_proj:3.183 [t=0.27s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1300/2000] tot_loss=1.378 (perp=6.484, rec=0.079, cos=0.002), tot_loss_proj:3.186 [t=0.22s]
prediction: ['[CLS] was running the car to the child? [SEP]']
[1350/2000] tot_loss=1.373 (perp=6.484, rec=0.074, cos=0.002), tot_loss_proj:3.191 [t=0.20s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1400/2000] tot_loss=1.375 (perp=6.484, rec=0.076, cos=0.002), tot_loss_proj:3.185 [t=0.18s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1450/2000] tot_loss=1.376 (perp=6.484, rec=0.077, cos=0.002), tot_loss_proj:3.184 [t=0.27s]
prediction: ['[CLS] was running the car to the child? [SEP]']
[1500/2000] tot_loss=1.375 (perp=6.484, rec=0.076, cos=0.002), tot_loss_proj:3.191 [t=0.28s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1550/2000] tot_loss=1.376 (perp=6.484, rec=0.077, cos=0.002), tot_loss_proj:3.193 [t=0.18s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1600/2000] tot_loss=1.373 (perp=6.484, rec=0.074, cos=0.002), tot_loss_proj:3.181 [t=0.18s]
prediction: ['[CLS] was running the car to the child? [SEP]']
[1650/2000] tot_loss=1.374 (perp=6.484, rec=0.075, cos=0.002), tot_loss_proj:3.188 [t=0.24s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1700/2000] tot_loss=1.376 (perp=6.484, rec=0.077, cos=0.002), tot_loss_proj:3.184 [t=0.24s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1750/2000] tot_loss=1.368 (perp=6.484, rec=0.069, cos=0.002), tot_loss_proj:3.183 [t=0.19s]
prediction: ['[CLS] was running the car to the child? [SEP]']
[1800/2000] tot_loss=1.376 (perp=6.484, rec=0.077, cos=0.002), tot_loss_proj:3.179 [t=0.21s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1850/2000] tot_loss=1.373 (perp=6.484, rec=0.074, cos=0.002), tot_loss_proj:3.189 [t=0.18s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[1900/2000] tot_loss=1.379 (perp=6.484, rec=0.080, cos=0.002), tot_loss_proj:3.189 [t=0.24s]
prediction: ['[CLS] was running the car to the child? [SEP]']
[1950/2000] tot_loss=1.377 (perp=6.484, rec=0.078, cos=0.002), tot_loss_proj:3.185 [t=0.22s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Attempt swap
[2000/2000] tot_loss=1.376 (perp=6.484, rec=0.077, cos=0.002), tot_loss_proj:3.188 [t=0.23s]
prediction: ['[CLS] was running the car to the child? [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] was the child running to the car? [SEP]
========================
predicted: 
========================
[CLS] was running the car to the child? [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 79.906 | p: 79.475 | r: 80.496
rouge2     | fm: 36.908 | p: 36.708 | r: 37.249
rougeL     | fm: 67.391 | p: 67.133 | r: 67.943
rougeLsum  | fm: 67.733 | p: 67.395 | r: 68.268
r1fm+r2fm = 116.815

input #40 time: 0:08:35 | total time: 5:45:58


Running input #41 of 100.
reference: 
========================
Mary is shorter than five feet.
========================
average of cosine similarity 0.9993780592173414
highest_index [0]
highest [0.9993780592173414]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2984, 2003, 7820, 2084, 2274, 2519, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] mary is shorter than five feet. [SEP]']
[Init] best rec loss: 1.9796572923660278 for ['[CLS] try formerly doneicz gmina away originals [SEP]']
[Init] best rec loss: 1.9712311029434204 for ['[CLS] pro district thomas pitch motion phases scott [SEP]']
[Init] best rec loss: 1.9328045845031738 for ['[CLS] whilst cards loud jacksonon ladies bounded [SEP]']
[Init] best rec loss: 1.9142910242080688 for ['[CLS] states tools about -rily we consulting [SEP]']
[Init] best rec loss: 1.8729884624481201 for ['[CLS] she motto nerve five patsy unable deeper [SEP]']
[Init] best rec loss: 1.8615933656692505 for ['[CLS] cheng suite dowry yet underwent summeruz [SEP]']
[Init] best rec loss: 1.8478217124938965 for ['[CLS] rae landing affect ) soldier corrections weekends [SEP]']
[Init] best rec loss: 1.8417134284973145 for ['[CLS] including * area theoretical agreement amy justin [SEP]']
[Init] best rec loss: 1.8393054008483887 for ['[CLS] vin metallic pilecede ropes use condemned [SEP]']
[Init] best rec loss: 1.8362576961517334 for ['[CLS] various world true worried gray measured stream [SEP]']
[Init] best rec loss: 1.8212026357650757 for ['[CLS] neck san cook heritage factory series ham [SEP]']
[Init] best rec loss: 1.7928014993667603 for ['[CLS]riated off shin neutral today winter hours [SEP]']
[Init] best rec loss: 1.7688794136047363 for ['[CLS] friend b⁄ strain decorated battery latino [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.307 (perp=8.684, rec=0.638, cos=0.932), tot_loss_proj:3.699 [t=0.18s]
prediction: ['[CLS].. thrusting someone starring ss. [SEP]']
[ 100/2000] tot_loss=3.658 (perp=10.344, rec=0.637, cos=0.952), tot_loss_proj:3.937 [t=0.20s]
prediction: ['[CLS] from? celebration tallest furlongs foot. [SEP]']
[ 150/2000] tot_loss=2.745 (perp=10.927, rec=0.386, cos=0.173), tot_loss_proj:4.010 [t=0.20s]
prediction: ['[CLS] genetically. celebrating ten ft than. [SEP]']
[ 200/2000] tot_loss=2.114 (perp=9.260, rec=0.227, cos=0.035), tot_loss_proj:3.725 [t=0.22s]
prediction: ['[CLS] sounding mary completing shorter shorter feet. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.180 (perp=9.735, rec=0.206, cos=0.028), tot_loss_proj:3.781 [t=0.18s]
prediction: ['[CLS] sounding mary # is shorter feet shorter [SEP]']
[ 300/2000] tot_loss=2.014 (perp=9.219, rec=0.154, cos=0.016), tot_loss_proj:3.767 [t=0.21s]
prediction: ['[CLS] five mary johnnie is shorter feet shorter [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.763 (perp=8.023, rec=0.146, cos=0.012), tot_loss_proj:3.509 [t=0.19s]
prediction: ['[CLS] mary johnnie is shorter five feet shorter [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.735 (perp=7.944, rec=0.135, cos=0.011), tot_loss_proj:3.446 [t=0.23s]
prediction: ['[CLS] mary johnnie shorter is five feet shorter [SEP]']
[ 450/2000] tot_loss=1.740 (perp=7.944, rec=0.141, cos=0.011), tot_loss_proj:3.446 [t=0.30s]
prediction: ['[CLS] mary johnnie shorter is five feet shorter [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.730 (perp=7.944, rec=0.131, cos=0.010), tot_loss_proj:3.443 [t=0.24s]
prediction: ['[CLS] mary johnnie shorter is five feet shorter [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.731 (perp=7.944, rec=0.133, cos=0.010), tot_loss_proj:3.450 [t=0.18s]
prediction: ['[CLS] mary johnnie shorter is five feet shorter [SEP]']
[ 600/2000] tot_loss=1.723 (perp=7.944, rec=0.125, cos=0.009), tot_loss_proj:3.449 [t=0.30s]
prediction: ['[CLS] mary johnnie shorter is five feet shorter [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.710 (perp=7.944, rec=0.113, cos=0.008), tot_loss_proj:3.448 [t=0.19s]
prediction: ['[CLS] mary johnnie shorter is five feet shorter [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.708 (perp=7.944, rec=0.113, cos=0.007), tot_loss_proj:3.450 [t=0.24s]
prediction: ['[CLS] mary johnnie shorter is five feet shorter [SEP]']
[ 750/2000] tot_loss=1.698 (perp=7.944, rec=0.103, cos=0.006), tot_loss_proj:3.443 [t=0.24s]
prediction: ['[CLS] mary johnnie shorter is five feet shorter [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.878 (perp=8.818, rec=0.109, cos=0.006), tot_loss_proj:3.649 [t=0.18s]
prediction: ['[CLS] mary johnnie than is five feet shorter [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.659 (perp=7.784, rec=0.097, cos=0.006), tot_loss_proj:3.495 [t=0.22s]
prediction: ['[CLS] mary johnnie is than five feet shorter [SEP]']
[ 900/2000] tot_loss=1.657 (perp=7.784, rec=0.095, cos=0.005), tot_loss_proj:3.493 [t=0.18s]
prediction: ['[CLS] mary johnnie is than five feet shorter [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.490 (perp=6.952, rec=0.094, cos=0.005), tot_loss_proj:3.333 [t=0.24s]
prediction: ['[CLS] mary johnnie is shorter than five feet [SEP]']
Attempt swap
[1000/2000] tot_loss=1.488 (perp=6.952, rec=0.092, cos=0.005), tot_loss_proj:3.335 [t=0.18s]
prediction: ['[CLS] mary johnnie is shorter than five feet [SEP]']
[1050/2000] tot_loss=1.486 (perp=6.952, rec=0.091, cos=0.005), tot_loss_proj:3.337 [t=0.23s]
prediction: ['[CLS] mary johnnie is shorter than five feet [SEP]']
Attempt swap
[1100/2000] tot_loss=1.488 (perp=6.952, rec=0.092, cos=0.005), tot_loss_proj:3.335 [t=0.19s]
prediction: ['[CLS] mary johnnie is shorter than five feet [SEP]']
Attempt swap
[1150/2000] tot_loss=1.512 (perp=7.116, rec=0.084, cos=0.005), tot_loss_proj:3.213 [t=0.27s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
[1200/2000] tot_loss=1.518 (perp=7.116, rec=0.090, cos=0.005), tot_loss_proj:3.210 [t=0.23s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[1250/2000] tot_loss=1.509 (perp=7.116, rec=0.081, cos=0.005), tot_loss_proj:3.206 [t=0.19s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[1300/2000] tot_loss=1.519 (perp=7.116, rec=0.091, cos=0.005), tot_loss_proj:3.203 [t=0.22s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
[1350/2000] tot_loss=1.512 (perp=7.116, rec=0.084, cos=0.005), tot_loss_proj:3.201 [t=0.19s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[1400/2000] tot_loss=1.516 (perp=7.116, rec=0.088, cos=0.005), tot_loss_proj:3.205 [t=0.20s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[1450/2000] tot_loss=1.520 (perp=7.116, rec=0.092, cos=0.005), tot_loss_proj:3.200 [t=0.20s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
[1500/2000] tot_loss=1.504 (perp=7.116, rec=0.076, cos=0.005), tot_loss_proj:3.199 [t=0.19s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[1550/2000] tot_loss=1.515 (perp=7.116, rec=0.087, cos=0.005), tot_loss_proj:3.198 [t=0.19s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[1600/2000] tot_loss=1.503 (perp=7.116, rec=0.075, cos=0.005), tot_loss_proj:3.194 [t=0.18s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
[1650/2000] tot_loss=1.515 (perp=7.116, rec=0.087, cos=0.005), tot_loss_proj:3.194 [t=0.18s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[1700/2000] tot_loss=1.506 (perp=7.116, rec=0.078, cos=0.005), tot_loss_proj:3.197 [t=0.18s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[1750/2000] tot_loss=1.512 (perp=7.116, rec=0.084, cos=0.005), tot_loss_proj:3.193 [t=0.29s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
[1800/2000] tot_loss=1.523 (perp=7.116, rec=0.095, cos=0.005), tot_loss_proj:3.191 [t=0.25s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[1850/2000] tot_loss=1.510 (perp=7.116, rec=0.082, cos=0.005), tot_loss_proj:3.193 [t=0.18s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[1900/2000] tot_loss=1.510 (perp=7.116, rec=0.082, cos=0.005), tot_loss_proj:3.191 [t=0.18s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
[1950/2000] tot_loss=1.509 (perp=7.116, rec=0.081, cos=0.005), tot_loss_proj:3.192 [t=0.18s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Attempt swap
[2000/2000] tot_loss=1.516 (perp=7.116, rec=0.088, cos=0.005), tot_loss_proj:3.191 [t=0.18s]
prediction: ['[CLS] marywhile is shorter than five feet [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] mary is shorter than five feet. [SEP]
========================
predicted: 
========================
[CLS] marywhile is shorter than five feet [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 71.429 | p: 71.429 | r: 71.429
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 158.929

[Aggregate metrics]:
rouge1     | fm: 79.981 | p: 79.595 | r: 80.691
rouge2     | fm: 37.729 | p: 37.489 | r: 38.068
rougeL     | fm: 67.927 | p: 67.658 | r: 68.482
rougeLsum  | fm: 68.200 | p: 67.953 | r: 68.637
r1fm+r2fm = 117.711

input #41 time: 0:08:31 | total time: 5:54:29


Running input #42 of 100.
reference: 
========================
She has enough of a problem as it is.
========================
average of cosine similarity 0.9992277228604687
highest_index [0]
highest [0.9992277228604687]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2016, 2038, 2438, 1997, 1037, 3291, 2004, 2009, 2003, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] she has enough of a problem as it is. [SEP]']
[Init] best rec loss: 1.7672672271728516 for ['[CLS] only shooter /press como solid togetherando ‑堂 [SEP]']
[Init] best rec loss: 1.7523273229599 for ['[CLS] violence trees closed much multimament mall freedoms separated squeezed [SEP]']
[Init] best rec loss: 1.6818212270736694 for ['[CLS] screenings former would headarty methyl saint bennett glenn ki [SEP]']
[Init] best rec loss: 1.6141703128814697 for ['[CLS] systems wear concertroids chanhyl since system rights because [SEP]']
[Init] best rec loss: 1.5239694118499756 for ['[CLS] boys # troy bel welcome honey sui application opera lark [SEP]']
[Init] best rec loss: 1.5051805973052979 for ['[CLS] ventures relief lana ann leadership teamsby from inheritance iron [SEP]']
[Init] best rec loss: 1.498190999031067 for ['[CLS] veil largereter urgency dynasty consistedrmedography wendyadt [SEP]']
[Init] best perm rec loss: 1.4919373989105225 for ['[CLS]ography veil urgencyeterrmed consisted dynasty largeradt wendy [SEP]']
[Init] best perm rec loss: 1.4781466722488403 for ['[CLS] dynastyography urgency veil wendy largeradteterrmed consisted [SEP]']
[Init] best perm rec loss: 1.4747443199157715 for ['[CLS]ographyadt largereter urgency veil wendyrmed consisted dynasty [SEP]']
[Init] best perm rec loss: 1.4660546779632568 for ['[CLS]rmedographyadt consisted dynasty wendyeter larger veil urgency [SEP]']
[Init] best perm rec loss: 1.4625591039657593 for ['[CLS] largerographyadt urgency dynasty wendyeter veil consistedrmed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.449 (perp=13.933, rec=0.484, cos=0.179), tot_loss_proj:4.604 [t=0.18s]
prediction: ['[CLS] new placed ii she basin issue registered violins special without [SEP]']
[ 100/2000] tot_loss=2.420 (perp=9.839, rec=0.384, cos=0.068), tot_loss_proj:3.793 [t=0.18s]
prediction: ['[CLS] new placed ii shendra as quite success or. [SEP]']
[ 150/2000] tot_loss=2.137 (perp=8.180, rec=0.435, cos=0.066), tot_loss_proj:3.679 [t=0.18s]
prediction: ['[CLS] apart its name has enough as enough success special. [SEP]']
[ 200/2000] tot_loss=1.897 (perp=7.608, rec=0.336, cos=0.040), tot_loss_proj:3.324 [t=0.18s]
prediction: ['[CLS] she has has, enough as enough problems as. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.186 (perp=9.057, rec=0.338, cos=0.037), tot_loss_proj:3.867 [t=0.19s]
prediction: ['[CLS] she enough has have enough as enough as problems as [SEP]']
[ 300/2000] tot_loss=1.772 (perp=7.447, rec=0.258, cos=0.025), tot_loss_proj:3.551 [t=0.26s]
prediction: ['[CLS] she has has has enough as enough a problem. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.955 (perp=8.506, rec=0.234, cos=0.020), tot_loss_proj:3.756 [t=0.18s]
prediction: ['[CLS] she is has have enough enough as of problem. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.993 (perp=8.599, rec=0.248, cos=0.025), tot_loss_proj:3.741 [t=0.19s]
prediction: ['[CLS] she of has enough has enough as a problemcera [SEP]']
[ 450/2000] tot_loss=2.044 (perp=9.153, rec=0.199, cos=0.014), tot_loss_proj:3.780 [t=0.18s]
prediction: ['[CLS] she of has has has enough as a problem a [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.715 (perp=7.595, rec=0.183, cos=0.013), tot_loss_proj:3.559 [t=0.18s]
prediction: ['[CLS] she has of problem has enough as a problem a [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.872 (perp=8.186, rec=0.197, cos=0.038), tot_loss_proj:3.601 [t=0.19s]
prediction: ['[CLS] she problem of green problem has enough as a problem [SEP]']
[ 600/2000] tot_loss=1.729 (perp=7.780, rec=0.161, cos=0.012), tot_loss_proj:3.509 [t=0.19s]
prediction: ['[CLS] she problem of white problem has enough as a problem [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.631 (perp=7.304, rec=0.158, cos=0.013), tot_loss_proj:3.444 [t=0.23s]
prediction: ['[CLS] she problem of white has enough problem as a problem [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.696 (perp=7.679, rec=0.147, cos=0.013), tot_loss_proj:3.542 [t=0.18s]
prediction: ['[CLS] she problem of born has enough problem as a problem [SEP]']
[ 750/2000] tot_loss=1.682 (perp=7.679, rec=0.134, cos=0.013), tot_loss_proj:3.547 [t=0.20s]
prediction: ['[CLS] she problem of born has enough problem as a problem [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.597 (perp=7.220, rec=0.141, cos=0.013), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS] she problem of problem born has enough as a problem [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.596 (perp=7.220, rec=0.140, cos=0.013), tot_loss_proj:3.415 [t=0.31s]
prediction: ['[CLS] she problem of problem born has enough as a problem [SEP]']
[ 900/2000] tot_loss=1.591 (perp=7.220, rec=0.134, cos=0.012), tot_loss_proj:3.414 [t=0.28s]
prediction: ['[CLS] she problem of problem born has enough as a problem [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.575 (perp=7.220, rec=0.120, cos=0.011), tot_loss_proj:3.415 [t=0.31s]
prediction: ['[CLS] she problem of problem born has enough as a problem [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.573 (perp=7.249, rec=0.112, cos=0.011), tot_loss_proj:3.425 [t=0.19s]
prediction: ['[CLS] she problem of if has enough problem as a problem [SEP]']
[1050/2000] tot_loss=1.559 (perp=7.249, rec=0.099, cos=0.010), tot_loss_proj:3.423 [t=0.19s]
prediction: ['[CLS] she problem of if has enough problem as a problem [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.537 (perp=7.108, rec=0.106, cos=0.010), tot_loss_proj:3.381 [t=0.20s]
prediction: ['[CLS] she problem of if enough has problem as a problem [SEP]']
Attempt swap
[1150/2000] tot_loss=1.541 (perp=7.108, rec=0.110, cos=0.010), tot_loss_proj:3.375 [t=0.22s]
prediction: ['[CLS] she problem of if enough has problem as a problem [SEP]']
[1200/2000] tot_loss=1.664 (perp=7.742, rec=0.106, cos=0.010), tot_loss_proj:3.485 [t=0.20s]
prediction: ['[CLS] she problem of if enough has problem as a is [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.518 (perp=7.012, rec=0.106, cos=0.010), tot_loss_proj:3.267 [t=0.19s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.497 (perp=7.012, rec=0.084, cos=0.010), tot_loss_proj:3.266 [t=0.19s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
[1350/2000] tot_loss=1.516 (perp=7.012, rec=0.104, cos=0.010), tot_loss_proj:3.268 [t=0.18s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.510 (perp=7.012, rec=0.098, cos=0.010), tot_loss_proj:3.269 [t=0.20s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.514 (perp=7.012, rec=0.102, cos=0.010), tot_loss_proj:3.270 [t=0.18s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
[1500/2000] tot_loss=1.514 (perp=7.012, rec=0.102, cos=0.010), tot_loss_proj:3.271 [t=0.18s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.510 (perp=7.012, rec=0.098, cos=0.010), tot_loss_proj:3.271 [t=0.18s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.515 (perp=7.012, rec=0.104, cos=0.010), tot_loss_proj:3.271 [t=0.21s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
[1650/2000] tot_loss=1.501 (perp=7.012, rec=0.089, cos=0.010), tot_loss_proj:3.267 [t=0.20s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.509 (perp=7.012, rec=0.097, cos=0.010), tot_loss_proj:3.271 [t=0.26s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.509 (perp=7.012, rec=0.097, cos=0.010), tot_loss_proj:3.264 [t=0.23s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
[1800/2000] tot_loss=1.504 (perp=7.012, rec=0.092, cos=0.010), tot_loss_proj:3.270 [t=0.18s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.500 (perp=7.012, rec=0.088, cos=0.010), tot_loss_proj:3.262 [t=0.20s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.511 (perp=7.012, rec=0.099, cos=0.010), tot_loss_proj:3.267 [t=0.18s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
[1950/2000] tot_loss=1.505 (perp=7.012, rec=0.093, cos=0.010), tot_loss_proj:3.263 [t=0.18s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.510 (perp=7.012, rec=0.098, cos=0.010), tot_loss_proj:3.270 [t=0.19s]
prediction: ['[CLS] she problem of if enough has a problem as is [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] she has enough of a problem as it is. [SEP]
========================
predicted: 
========================
[CLS] she problem of if enough has a problem as is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 69.565 | p: 66.667 | r: 72.727
rougeLsum  | fm: 69.565 | p: 66.667 | r: 72.727
r1fm+r2fm = 125.052

[Aggregate metrics]:
rouge1     | fm: 80.224 | p: 79.739 | r: 80.933
rouge2     | fm: 37.753 | p: 37.480 | r: 38.081
rougeL     | fm: 67.867 | p: 67.536 | r: 68.468
rougeLsum  | fm: 68.100 | p: 67.701 | r: 68.681
r1fm+r2fm = 117.977

input #42 time: 0:08:32 | total time: 6:03:02


Running input #43 of 100.
reference: 
========================
Every student has to come up with three arguments that show that some condition proposed by Bill is wrong.
========================
average of cosine similarity 0.9993892958061774
highest_index [0]
highest [0.9993892958061774]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[ 101, 2296, 3076, 2038, 2000, 2272, 2039, 2007, 2093, 9918, 2008, 2265,
         2008, 2070, 4650, 3818, 2011, 3021, 2003, 3308, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]']
[Init] best rec loss: 1.9250867366790771 for ['[CLS] unaffected peter interval sporting campaign singular relieved start shooting club helleche date operative either meredith occupied lamagee metals [SEP]']
[Init] best rec loss: 1.907796859741211 for ['[CLS] warlock picks portland briefly gardiner farther argued...mo received fi falls juliette betweenrate elderetachal zach carl [SEP]']
[Init] best rec loss: 1.8918366432189941 for ['[CLS] some budge really ugandacing part -aver aria foldedfly heart with enrollment inactivated starr goth action purely four [SEP]']
[Init] best rec loss: 1.8860535621643066 for ['[CLS] rule blind third sheen a xu snarl brainific storm median head you gathering mono operational hard patti nba coach [SEP]']
[Init] best rec loss: 1.859165072441101 for ['[CLS] situated states confidence invited country wr english himself originallyurity method heavily must room vic snapped may grants surprises expressed [SEP]']
[Init] best rec loss: 1.8591244220733643 for ['[CLS] straight being friendship spoke railway when nbc graph episode spur hem waterfeit leopold fitch ; hitch bank ridingtort [SEP]']
[Init] best perm rec loss: 1.8580060005187988 for ['[CLS]feit spur riding ; hem nbc graph railway being water when spoketort episode friendship fitch bank straight hitch leopold [SEP]']
[Init] best perm rec loss: 1.8578943014144897 for ['[CLS] nbc when graph railway bank waterfeit straight episode leopold ; hem fitch hitch spur spoke being friendship ridingtort [SEP]']
[Init] best perm rec loss: 1.8564634323120117 for ['[CLS] straight spur being railway hem water friendship when fitch bank nbc graph spoke hitchfeit episode ; leopoldtort riding [SEP]']
[Init] best perm rec loss: 1.8563454151153564 for ['[CLS] ;tort fitch leopold being riding episode graph straight spokefeit bank railway hitch friendship hem nbc water spur when [SEP]']
[Init] best perm rec loss: 1.855215072631836 for ['[CLS] fitch spurfeit ; episode bank being hem railway when leopold hitchtort straight spoke friendship riding nbc water graph [SEP]']
[Init] best perm rec loss: 1.8548758029937744 for ['[CLS] friendship leopold hem water spur riding spoke straighttort whenfeit episode ; bank railway nbc graph hitch fitch being [SEP]']
[Init] best perm rec loss: 1.8542321920394897 for ['[CLS] fitch spur graph ridingtort bank when leopold spoke straight railway ; beingfeit episode friendship nbc water hem hitch [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.235 (perp=13.569, rec=0.458, cos=0.064), tot_loss_proj:4.622 [t=0.23s]
prediction: ['[CLS] premium friedrich every arguments seesextherazation evenbiotic different discretion monopoly each devotion club water saxon gr [SEP]']
[ 100/2000] tot_loss=3.067 (perp=12.589, rec=0.420, cos=0.129), tot_loss_proj:4.359 [t=0.26s]
prediction: ['[CLS] develop nigerian every argument studenttoores has spoke dark proposed whetheraciesllary every curriculum stock hyper junior. [SEP]']
[ 150/2000] tot_loss=2.690 (perp=11.870, rec=0.289, cos=0.027), tot_loss_proj:4.248 [t=0.19s]
prediction: ['[CLS] developing racial every argument student ex bill has proposes some proposed whether irish oath student revival festival hyper morgan. [SEP]']
[ 200/2000] tot_loss=2.641 (perp=11.870, rec=0.250, cos=0.017), tot_loss_proj:4.232 [t=0.19s]
prediction: ['[CLS] is racial every arguments student ex bill / arguments some proposed thatbid condition student revival up show will. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.498 (perp=11.194, rec=0.240, cos=0.019), tot_loss_proj:4.060 [t=0.19s]
prediction: ['[CLS] is four every arguments student she bill / racial some arguments when whose condition student revival up show will. [SEP]']
[ 300/2000] tot_loss=2.476 (perp=10.838, rec=0.277, cos=0.032), tot_loss_proj:3.971 [t=0.19s]
prediction: ['[CLS] thinking four every argument student she bill has racial some argument opposed whose condition relation adding oil show will. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.356 (perp=10.408, rec=0.249, cos=0.025), tot_loss_proj:3.944 [t=0.19s]
prediction: ['[CLS] thinking arguments every arguments student out adding has how some argument two whose condition student bill spread show will. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.161 (perp=9.534, rec=0.233, cos=0.021), tot_loss_proj:3.715 [t=0.18s]
prediction: ['[CLS] thinking spread every arguments student that adding has representative some argument opposed whose condition those bill arguments show will. [SEP]']
[ 450/2000] tot_loss=2.143 (perp=9.623, rec=0.207, cos=0.011), tot_loss_proj:3.755 [t=0.27s]
prediction: ['[CLS] thinking spread every arguments student that showing has how three arguments opposed whose condition those bill arguments show will. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.980 (perp=8.927, rec=0.187, cos=0.008), tot_loss_proj:3.668 [t=0.27s]
prediction: ['[CLS] thinking by every student arguments that showing has how three arguments opposed whose condition those bill arguments show will. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.752 (perp=7.869, rec=0.171, cos=0.007), tot_loss_proj:3.390 [t=0.19s]
prediction: ['[CLS] thinking by every student arguments that show has how three arguments which bill condition those whose arguments show up. [SEP]']
[ 600/2000] tot_loss=1.721 (perp=7.712, rec=0.173, cos=0.006), tot_loss_proj:3.364 [t=0.19s]
prediction: ['[CLS] thinking by every student arguments that show in that three arguments which bill condition those whose arguments show up. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.851 (perp=8.413, rec=0.162, cos=0.006), tot_loss_proj:3.518 [t=0.28s]
prediction: ['[CLS] conditions by every student arguments that that has show three arguments which bill condition those whose arguments show is. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.879 (perp=8.519, rec=0.169, cos=0.006), tot_loss_proj:3.532 [t=0.18s]
prediction: ['[CLS] letting by every student arguments that has that show three arguments that bill condition some whose arguments show is. [SEP]']
[ 750/2000] tot_loss=1.869 (perp=8.519, rec=0.160, cos=0.005), tot_loss_proj:3.531 [t=0.18s]
prediction: ['[CLS] letting by every student arguments that has that show three arguments that bill condition some whose arguments show is. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.842 (perp=8.427, rec=0.150, cos=0.006), tot_loss_proj:3.517 [t=0.20s]
prediction: ['[CLS] letting that every student arguments that has by show three arguments that bill condition some ; arguments show is. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.756 (perp=7.984, rec=0.154, cos=0.005), tot_loss_proj:3.440 [t=0.22s]
prediction: ['[CLS] letting that every student arguments that has by show three arguments that bill ; condition some arguments show is. [SEP]']
[ 900/2000] tot_loss=1.746 (perp=7.984, rec=0.144, cos=0.005), tot_loss_proj:3.433 [t=0.20s]
prediction: ['[CLS] letting that every student arguments that has by show three arguments that bill ; condition some arguments show is. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.724 (perp=7.823, rec=0.154, cos=0.005), tot_loss_proj:3.406 [t=0.18s]
prediction: ['[CLS] letting that every student arguments that has by show three arguments that bill some condition some arguments is show. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.663 (perp=7.549, rec=0.148, cos=0.005), tot_loss_proj:3.404 [t=0.19s]
prediction: ['[CLS] letting that every student arguments that has bill show three arguments that by some condition some arguments is show. [SEP]']
[1050/2000] tot_loss=1.583 (perp=7.179, rec=0.142, cos=0.005), tot_loss_proj:3.332 [t=0.18s]
prediction: ['[CLS] letting that every student arguments that by bill show three arguments where by some condition some arguments is show. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.594 (perp=7.225, rec=0.145, cos=0.005), tot_loss_proj:3.350 [t=0.19s]
prediction: ['[CLS] letting that every student argument that by bill show three arguments where by some condition some arguments is show. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.589 (perp=7.225, rec=0.140, cos=0.005), tot_loss_proj:3.351 [t=0.18s]
prediction: ['[CLS] letting that every student argument that by bill show three arguments where by some condition some arguments is show. [SEP]']
[1200/2000] tot_loss=1.679 (perp=7.703, rec=0.134, cos=0.005), tot_loss_proj:3.460 [t=0.18s]
prediction: ['[CLS] letting that every student argument that by bill show three that with by some condition some arguments is show. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.619 (perp=7.391, rec=0.137, cos=0.005), tot_loss_proj:3.372 [t=0.19s]
prediction: ['[CLS] letting that every student argument that by bill with show three that by some condition some arguments is show. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.586 (perp=7.253, rec=0.131, cos=0.005), tot_loss_proj:3.365 [t=0.25s]
prediction: ['[CLS] letting that every student argument that by bill with three show that by some condition some arguments is show. [SEP]']
[1350/2000] tot_loss=1.587 (perp=7.253, rec=0.132, cos=0.004), tot_loss_proj:3.369 [t=0.19s]
prediction: ['[CLS] letting that every student argument that by bill with three show that by some condition some arguments is show. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.692 (perp=7.775, rec=0.133, cos=0.005), tot_loss_proj:3.384 [t=0.22s]
prediction: ['[CLS] turning that every student must that by bill with three show that by some condition is arguments some show. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.655 (perp=7.612, rec=0.128, cos=0.004), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] letting that every student must that by bill with three show that by some condition is arguments some show. [SEP]']
[1500/2000] tot_loss=1.662 (perp=7.612, rec=0.135, cos=0.004), tot_loss_proj:3.386 [t=0.19s]
prediction: ['[CLS] letting that every student must that by bill with three show that by some condition is arguments some show. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.564 (perp=7.130, rec=0.133, cos=0.005), tot_loss_proj:3.303 [t=0.21s]
prediction: ['[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.571 (perp=7.130, rec=0.140, cos=0.005), tot_loss_proj:3.299 [t=0.18s]
prediction: ['[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]']
[1650/2000] tot_loss=1.561 (perp=7.130, rec=0.130, cos=0.005), tot_loss_proj:3.301 [t=0.25s]
prediction: ['[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.561 (perp=7.130, rec=0.131, cos=0.004), tot_loss_proj:3.302 [t=0.18s]
prediction: ['[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.560 (perp=7.130, rec=0.129, cos=0.004), tot_loss_proj:3.304 [t=0.26s]
prediction: ['[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]']
[1800/2000] tot_loss=1.555 (perp=7.130, rec=0.124, cos=0.004), tot_loss_proj:3.300 [t=0.19s]
prediction: ['[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.555 (perp=7.130, rec=0.124, cos=0.004), tot_loss_proj:3.303 [t=0.18s]
prediction: ['[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.563 (perp=7.130, rec=0.133, cos=0.004), tot_loss_proj:3.297 [t=0.27s]
prediction: ['[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]']
[1950/2000] tot_loss=1.555 (perp=7.130, rec=0.124, cos=0.004), tot_loss_proj:3.302 [t=0.20s]
prediction: ['[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.556 (perp=7.130, rec=0.126, cos=0.004), tot_loss_proj:3.302 [t=0.19s]
prediction: ['[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] every student has to come up with three arguments that show that some condition proposed by bill is wrong. [SEP]
========================
predicted: 
========================
[CLS] letting that every student must show by bill with three that that by some condition is arguments some show. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 52.381 | p: 52.381 | r: 52.381
rougeLsum  | fm: 52.381 | p: 52.381 | r: 52.381
r1fm+r2fm = 91.429

[Aggregate metrics]:
rouge1     | fm: 80.076 | p: 79.592 | r: 80.722
rouge2     | fm: 37.250 | p: 37.026 | r: 37.703
rougeL     | fm: 67.590 | p: 67.130 | r: 68.162
rougeLsum  | fm: 67.802 | p: 67.422 | r: 68.326
r1fm+r2fm = 117.326

input #43 time: 0:08:23 | total time: 6:11:25


Running input #44 of 100.
reference: 
========================
Kim alienates cats and beat his dog.
========================
average of cosine similarity 0.9993126822858673
highest_index [0]
highest [0.9993126822858673]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 5035, 7344, 8520, 8870, 1998, 3786, 2010, 3899, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] kim alienates cats and beat his dog. [SEP]']
[Init] best rec loss: 2.013742446899414 for ['[CLS] vineyard sterling michigan bat hot boltedpati cannot matter [SEP]']
[Init] best rec loss: 1.9602761268615723 for ['[CLS] jihad much complex marshall deadline [SEP] terminus volume japan [SEP]']
[Init] best rec loss: 1.94943368434906 for ['[CLS] conventional commentary at better mutuallylaise film protein proton [SEP]']
[Init] best rec loss: 1.9049277305603027 for ['[CLS] attempt ll foreign suck off spy gain app promoted [SEP]']
[Init] best rec loss: 1.9042507410049438 for ['[CLS] hat soup western loyal jelly > such surface mythology [SEP]']
[Init] best rec loss: 1.8555396795272827 for ['[CLS] glacial examlip eat condition von wonder channel junk [SEP]']
[Init] best rec loss: 1.8509269952774048 for ['[CLS]⁄ lance assigns edmund missouri other. started dan [SEP]']
[Init] best perm rec loss: 1.8490761518478394 for ['[CLS] lance other dan edmund started assigns missouri⁄. [SEP]']
[Init] best perm rec loss: 1.84701406955719 for ['[CLS] other edmund assigns lance. missouri dan started⁄ [SEP]']
[Init] best perm rec loss: 1.843433141708374 for ['[CLS] dan other. lance started edmund assigns missouri⁄ [SEP]']
[Init] best perm rec loss: 1.8343827724456787 for ['[CLS] dan missouri lance assigns⁄. started edmund other [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.834 (perp=11.716, rec=0.404, cos=0.087), tot_loss_proj:4.309 [t=0.26s]
prediction: ['[CLS] voters cats beat. dog £10 samulate client [SEP]']
[ 100/2000] tot_loss=2.409 (perp=10.403, rec=0.293, cos=0.035), tot_loss_proj:4.042 [t=0.18s]
prediction: ['[CLS] cats kim beat. dog beat sam native. [SEP]']
[ 150/2000] tot_loss=2.666 (perp=10.746, rec=0.403, cos=0.113), tot_loss_proj:4.157 [t=0.20s]
prediction: ['[CLS] cats kim beat. dog beat his his. [SEP]']
[ 200/2000] tot_loss=2.463 (perp=11.009, rec=0.236, cos=0.026), tot_loss_proj:4.207 [t=0.18s]
prediction: ['[CLS] cats kim beat and dog beat cats his and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.191 (perp=9.757, rec=0.216, cos=0.024), tot_loss_proj:3.938 [t=0.25s]
prediction: ['[CLS] cats kimate and his beat his dog and [SEP]']
[ 300/2000] tot_loss=1.809 (perp=8.224, rec=0.151, cos=0.014), tot_loss_proj:3.639 [t=0.18s]
prediction: ['[CLS] cats kimates and his beat his dog. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.777 (perp=8.224, rec=0.126, cos=0.007), tot_loss_proj:3.643 [t=0.24s]
prediction: ['[CLS] cats kimates and his beat his dog. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.775 (perp=8.224, rec=0.124, cos=0.006), tot_loss_proj:3.649 [t=0.18s]
prediction: ['[CLS] cats kimates and his beat his dog. [SEP]']
[ 450/2000] tot_loss=1.929 (perp=8.762, rec=0.165, cos=0.012), tot_loss_proj:3.778 [t=0.18s]
prediction: ['[CLS] cats kimates and his beat his dog, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.032 (perp=9.402, rec=0.141, cos=0.011), tot_loss_proj:3.686 [t=0.23s]
prediction: ['[CLS] kim catsates and his beat. dog, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.779 (perp=8.176, rec=0.135, cos=0.009), tot_loss_proj:3.315 [t=0.23s]
prediction: ['[CLS] kim.ates and his beat cats dog, [SEP]']
[ 600/2000] tot_loss=1.768 (perp=8.176, rec=0.126, cos=0.007), tot_loss_proj:3.308 [t=0.26s]
prediction: ['[CLS] kim.ates and his beat cats dog, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.693 (perp=7.801, rec=0.127, cos=0.007), tot_loss_proj:3.514 [t=0.20s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.685 (perp=7.801, rec=0.118, cos=0.006), tot_loss_proj:3.515 [t=0.19s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
[ 750/2000] tot_loss=1.680 (perp=7.801, rec=0.114, cos=0.006), tot_loss_proj:3.515 [t=0.18s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.675 (perp=7.801, rec=0.109, cos=0.005), tot_loss_proj:3.513 [t=0.19s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.664 (perp=7.801, rec=0.098, cos=0.005), tot_loss_proj:3.509 [t=0.26s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
[ 900/2000] tot_loss=1.672 (perp=7.801, rec=0.106, cos=0.005), tot_loss_proj:3.517 [t=0.28s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.674 (perp=7.801, rec=0.109, cos=0.005), tot_loss_proj:3.514 [t=0.18s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.671 (perp=7.801, rec=0.106, cos=0.005), tot_loss_proj:3.508 [t=0.19s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
[1050/2000] tot_loss=1.671 (perp=7.801, rec=0.106, cos=0.005), tot_loss_proj:3.513 [t=0.23s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.670 (perp=7.801, rec=0.105, cos=0.005), tot_loss_proj:3.514 [t=0.26s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.676 (perp=7.801, rec=0.111, cos=0.005), tot_loss_proj:3.512 [t=0.21s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
[1200/2000] tot_loss=1.665 (perp=7.801, rec=0.100, cos=0.005), tot_loss_proj:3.514 [t=0.19s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.667 (perp=7.801, rec=0.102, cos=0.005), tot_loss_proj:3.510 [t=0.33s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.669 (perp=7.801, rec=0.104, cos=0.005), tot_loss_proj:3.512 [t=0.18s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
[1350/2000] tot_loss=1.676 (perp=7.801, rec=0.111, cos=0.005), tot_loss_proj:3.511 [t=0.18s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.665 (perp=7.801, rec=0.100, cos=0.005), tot_loss_proj:3.513 [t=0.18s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.658 (perp=7.801, rec=0.093, cos=0.005), tot_loss_proj:3.513 [t=0.18s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
[1500/2000] tot_loss=1.660 (perp=7.801, rec=0.095, cos=0.005), tot_loss_proj:3.519 [t=0.25s]
prediction: ['[CLS] kim.ates and beat his cats dog, [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.484 (perp=6.858, rec=0.108, cos=0.005), tot_loss_proj:3.242 [t=0.22s]
prediction: ['[CLS] kim,ates and beat his cats dog. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.484 (perp=6.858, rec=0.108, cos=0.005), tot_loss_proj:3.241 [t=0.23s]
prediction: ['[CLS] kim,ates and beat his cats dog. [SEP]']
[1650/2000] tot_loss=1.474 (perp=6.858, rec=0.098, cos=0.005), tot_loss_proj:3.248 [t=0.19s]
prediction: ['[CLS] kim,ates and beat his cats dog. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.477 (perp=6.858, rec=0.100, cos=0.005), tot_loss_proj:3.245 [t=0.28s]
prediction: ['[CLS] kim,ates and beat his cats dog. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.473 (perp=6.858, rec=0.097, cos=0.005), tot_loss_proj:3.243 [t=0.19s]
prediction: ['[CLS] kim,ates and beat his cats dog. [SEP]']
[1800/2000] tot_loss=1.483 (perp=6.858, rec=0.106, cos=0.005), tot_loss_proj:3.244 [t=0.21s]
prediction: ['[CLS] kim,ates and beat his cats dog. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.479 (perp=6.858, rec=0.103, cos=0.005), tot_loss_proj:3.243 [t=0.19s]
prediction: ['[CLS] kim,ates and beat his cats dog. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.483 (perp=6.858, rec=0.107, cos=0.005), tot_loss_proj:3.246 [t=0.23s]
prediction: ['[CLS] kim,ates and beat his cats dog. [SEP]']
[1950/2000] tot_loss=1.478 (perp=6.858, rec=0.102, cos=0.005), tot_loss_proj:3.241 [t=0.23s]
prediction: ['[CLS] kim,ates and beat his cats dog. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.474 (perp=6.858, rec=0.098, cos=0.005), tot_loss_proj:3.239 [t=0.22s]
prediction: ['[CLS] kim,ates and beat his cats dog. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] kim alienates cats and beat his dog. [SEP]
========================
predicted: 
========================
[CLS] kim,ates and beat his cats dog. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 138.889

[Aggregate metrics]:
rouge1     | fm: 80.240 | p: 79.786 | r: 80.961
rouge2     | fm: 37.701 | p: 37.432 | r: 38.108
rougeL     | fm: 67.873 | p: 67.567 | r: 68.390
rougeLsum  | fm: 68.024 | p: 67.681 | r: 68.560
r1fm+r2fm = 117.941

input #44 time: 0:08:26 | total time: 6:19:52


Running input #45 of 100.
reference: 
========================
John's I stole bike.
========================
average of cosine similarity 0.999353611080195
highest_index [0]
highest [0.999353611080195]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2198,  1005,  1055,  1045, 10312,  7997,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] john's i stole bike. [SEP]"]
[Init] best rec loss: 1.837700366973877 for ['[CLS] outskirts came too yourtered occupy tradition [SEP]']
[Init] best rec loss: 1.2024728059768677 for ['[CLS] and general driving weak [SEP]akcede [SEP]']
[Init] best rec loss: 1.074352502822876 for ['[CLS] video date prime tall lifeless grape person [SEP]']
[Init] best rec loss: 1.0035285949707031 for ['[CLS] evening lose high design bankrupt caucus landscape [SEP]']
[Init] best rec loss: 0.9194190502166748 for ['[CLS] hadn quite about sit exit rugby mc [SEP]']
[Init] best perm rec loss: 0.9141555428504944 for ['[CLS] about hadn quite exit sit rugby mc [SEP]']
[Init] best perm rec loss: 0.9138169884681702 for ['[CLS] quite sit exit about hadn rugby mc [SEP]']
[Init] best perm rec loss: 0.9108389019966125 for ['[CLS] rugby about quite exit sit hadn mc [SEP]']
[Init] best perm rec loss: 0.910693883895874 for ['[CLS] about exit hadn quite sit rugby mc [SEP]']
[Init] best perm rec loss: 0.9087426066398621 for ['[CLS] about exit rugby sit quite hadn mc [SEP]']
[Init] best perm rec loss: 0.9075803160667419 for ['[CLS] about rugby exit hadn sit quite mc [SEP]']
[Init] best perm rec loss: 0.9051599502563477 for ['[CLS] rugby about sit hadn exit quite mc [SEP]']
[Init] best perm rec loss: 0.9035841226577759 for ['[CLS] exit about sit rugby hadn quite mc [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.335 (perp=10.172, rec=0.290, cos=0.011), tot_loss_proj:2.986 [t=0.20s]
prediction: ['[CLS] australian s he & bike was. [SEP]']
[ 100/2000] tot_loss=2.610 (perp=10.906, rec=0.395, cos=0.034), tot_loss_proj:3.968 [t=0.26s]
prediction: ['[CLS] john s iriver bike returned. [SEP]']
[ 150/2000] tot_loss=2.293 (perp=9.939, rec=0.292, cos=0.014), tot_loss_proj:2.606 [t=0.27s]
prediction: ['[CLS] john s i heavily bike disappeared. [SEP]']
[ 200/2000] tot_loss=2.338 (perp=10.427, rec=0.244, cos=0.009), tot_loss_proj:3.144 [t=0.21s]
prediction: ['[CLS] john s i weekend bike disappeared. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.090 (perp=9.118, rec=0.257, cos=0.009), tot_loss_proj:2.449 [t=0.18s]
prediction: ['[CLS] i s john weekend bike stole. [SEP]']
[ 300/2000] tot_loss=1.937 (perp=8.611, rec=0.208, cos=0.006), tot_loss_proj:2.783 [t=0.18s]
prediction: ['[CLS] i s john stole bike stole. [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.881 (perp=8.371, rec=0.202, cos=0.005), tot_loss_proj:2.671 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.861 (perp=8.371, rec=0.182, cos=0.005), tot_loss_proj:2.679 [t=0.25s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[ 450/2000] tot_loss=1.854 (perp=8.371, rec=0.174, cos=0.005), tot_loss_proj:2.683 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.851 (perp=8.371, rec=0.171, cos=0.005), tot_loss_proj:2.698 [t=0.20s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.836 (perp=8.371, rec=0.156, cos=0.005), tot_loss_proj:2.699 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[ 600/2000] tot_loss=1.839 (perp=8.371, rec=0.160, cos=0.005), tot_loss_proj:2.717 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.838 (perp=8.371, rec=0.159, cos=0.005), tot_loss_proj:2.720 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.829 (perp=8.371, rec=0.150, cos=0.005), tot_loss_proj:2.727 [t=0.25s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[ 750/2000] tot_loss=1.834 (perp=8.371, rec=0.155, cos=0.005), tot_loss_proj:2.730 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.827 (perp=8.371, rec=0.148, cos=0.005), tot_loss_proj:2.736 [t=0.21s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.824 (perp=8.371, rec=0.145, cos=0.005), tot_loss_proj:2.737 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[ 900/2000] tot_loss=1.827 (perp=8.371, rec=0.148, cos=0.005), tot_loss_proj:2.740 [t=0.19s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.818 (perp=8.371, rec=0.138, cos=0.005), tot_loss_proj:2.744 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.827 (perp=8.371, rec=0.147, cos=0.005), tot_loss_proj:2.743 [t=0.19s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[1050/2000] tot_loss=1.824 (perp=8.371, rec=0.144, cos=0.005), tot_loss_proj:2.746 [t=0.24s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.822 (perp=8.371, rec=0.143, cos=0.005), tot_loss_proj:2.749 [t=0.21s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.823 (perp=8.371, rec=0.144, cos=0.005), tot_loss_proj:2.749 [t=0.19s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[1200/2000] tot_loss=1.821 (perp=8.371, rec=0.142, cos=0.005), tot_loss_proj:2.750 [t=0.19s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.820 (perp=8.371, rec=0.140, cos=0.005), tot_loss_proj:2.749 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.826 (perp=8.371, rec=0.147, cos=0.005), tot_loss_proj:2.747 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[1350/2000] tot_loss=1.816 (perp=8.371, rec=0.137, cos=0.005), tot_loss_proj:2.746 [t=0.19s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.818 (perp=8.371, rec=0.139, cos=0.005), tot_loss_proj:2.756 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.808 (perp=8.371, rec=0.129, cos=0.005), tot_loss_proj:2.749 [t=0.21s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[1500/2000] tot_loss=1.828 (perp=8.371, rec=0.149, cos=0.005), tot_loss_proj:2.751 [t=0.28s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.811 (perp=8.371, rec=0.132, cos=0.005), tot_loss_proj:2.748 [t=0.23s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.814 (perp=8.371, rec=0.135, cos=0.005), tot_loss_proj:2.747 [t=0.24s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[1650/2000] tot_loss=1.814 (perp=8.371, rec=0.135, cos=0.005), tot_loss_proj:2.748 [t=0.22s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.813 (perp=8.371, rec=0.134, cos=0.005), tot_loss_proj:2.753 [t=0.25s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.825 (perp=8.371, rec=0.146, cos=0.005), tot_loss_proj:2.751 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[1800/2000] tot_loss=1.818 (perp=8.371, rec=0.139, cos=0.005), tot_loss_proj:2.753 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.815 (perp=8.371, rec=0.136, cos=0.005), tot_loss_proj:2.751 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.810 (perp=8.371, rec=0.131, cos=0.005), tot_loss_proj:2.756 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
[1950/2000] tot_loss=1.814 (perp=8.371, rec=0.135, cos=0.005), tot_loss_proj:2.754 [t=0.18s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.814 (perp=8.371, rec=0.135, cos=0.005), tot_loss_proj:2.751 [t=0.25s]
prediction: ['[CLS] i s john stole stole bike. [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] john's i stole bike. [SEP]
========================
predicted: 
========================
[CLS] i s john stole stole bike. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 30.769 | p: 28.571 | r: 33.333
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 124.103

[Aggregate metrics]:
rouge1     | fm: 80.452 | p: 79.843 | r: 81.308
rouge2     | fm: 37.519 | p: 37.175 | r: 37.906
rougeL     | fm: 67.750 | p: 67.304 | r: 68.430
rougeLsum  | fm: 67.973 | p: 67.617 | r: 68.529
r1fm+r2fm = 117.971

input #45 time: 0:08:13 | total time: 6:28:05


Running input #46 of 100.
reference: 
========================
The witch went into the forest by vanishing.
========================
average of cosine similarity 0.9993622173126959
highest_index [0]
highest [0.9993622173126959]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1996,  6965,  2253,  2046,  1996,  3224,  2011, 24866,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] the witch went into the forest by vanishing. [SEP]']
[Init] best rec loss: 1.030975103378296 for ['[CLS] tripume mackenzie enterprise crunch threshold engine free down [SEP]']
[Init] best rec loss: 1.0264226198196411 for ['[CLS] efforts tonru drunk prove airfield yourself wineing [SEP]']
[Init] best rec loss: 0.9959819912910461 for ['[CLS] sounds money marvel sy stylistic your campus brigade scope [SEP]']
[Init] best rec loss: 0.9843336343765259 for ['[CLS]led feed noah hung baydding blog house gate [SEP]']
[Init] best rec loss: 0.9808626174926758 for ['[CLS] khan fig wish while now dragon recent what fool [SEP]']
[Init] best perm rec loss: 0.9805728197097778 for ['[CLS] wish khan now dragon fool what while recent fig [SEP]']
[Init] best perm rec loss: 0.9772886633872986 for ['[CLS] while fool khan now recent fig dragon what wish [SEP]']
[Init] best perm rec loss: 0.9652673602104187 for ['[CLS] dragon khan while recent now what wish fool fig [SEP]']
[Init] best perm rec loss: 0.9587528705596924 for ['[CLS] fool khan recent dragon fig while wish now what [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.609 (perp=11.426, rec=0.271, cos=0.053), tot_loss_proj:3.185 [t=0.18s]
prediction: ['[CLS] those healed disappeared appeared by vanishing disappeared † producer [SEP]']
[ 100/2000] tot_loss=2.379 (perp=10.717, rec=0.207, cos=0.029), tot_loss_proj:3.146 [t=0.22s]
prediction: ['[CLS] she the civilization went by vanishing invisible como base [SEP]']
[ 150/2000] tot_loss=2.149 (perp=9.895, rec=0.156, cos=0.014), tot_loss_proj:2.993 [t=0.25s]
prediction: ['[CLS] the the witch went by vanishing vanishing hiding forest [SEP]']
[ 200/2000] tot_loss=1.754 (perp=8.062, rec=0.132, cos=0.009), tot_loss_proj:2.444 [t=0.22s]
prediction: ['[CLS] the the witch went by vanishing intoch forest [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.726 (perp=8.062, rec=0.106, cos=0.007), tot_loss_proj:2.443 [t=0.18s]
prediction: ['[CLS] the the witch went by vanishing intoch forest [SEP]']
[ 300/2000] tot_loss=1.718 (perp=8.062, rec=0.098, cos=0.007), tot_loss_proj:2.443 [t=0.18s]
prediction: ['[CLS] the the witch went by vanishing intoch forest [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.383 (perp=9.401, rec=0.429, cos=0.073), tot_loss_proj:2.518 [t=0.19s]
prediction: ['[CLS] the witch went by vanishing in dancing hiding forest [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.249 (perp=9.500, rec=0.312, cos=0.036), tot_loss_proj:3.028 [t=0.27s]
prediction: ['[CLS] the witch went by vanishing by forest into witch [SEP]']
[ 450/2000] tot_loss=2.341 (perp=10.448, rec=0.225, cos=0.027), tot_loss_proj:2.935 [t=0.18s]
prediction: ['[CLS] witch witch went by vanishing by forest dancing witch [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.314 (perp=10.511, rec=0.189, cos=0.022), tot_loss_proj:2.975 [t=0.25s]
prediction: ['[CLS] witch went by witch vanishing by forest training witch [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.254 (perp=10.315, rec=0.171, cos=0.020), tot_loss_proj:2.983 [t=0.23s]
prediction: ['[CLS] witch went by witch vanishing by training witch forest [SEP]']
[ 600/2000] tot_loss=2.224 (perp=10.140, rec=0.179, cos=0.016), tot_loss_proj:2.965 [t=0.20s]
prediction: ['[CLS] witch went by witch vanishing by disappearing vanishing forest [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.076 (perp=9.559, rec=0.149, cos=0.015), tot_loss_proj:2.725 [t=0.23s]
prediction: ['[CLS] witch went by witch vanishing by vanishing forest disappearing [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.078 (perp=9.559, rec=0.152, cos=0.014), tot_loss_proj:2.727 [t=0.25s]
prediction: ['[CLS] witch went by witch vanishing by vanishing forest disappearing [SEP]']
[ 750/2000] tot_loss=2.066 (perp=9.559, rec=0.141, cos=0.014), tot_loss_proj:2.720 [t=0.26s]
prediction: ['[CLS] witch went by witch vanishing by vanishing forest disappearing [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.087 (perp=9.623, rec=0.150, cos=0.013), tot_loss_proj:2.765 [t=0.19s]
prediction: ['[CLS] witch went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.072 (perp=9.623, rec=0.135, cos=0.012), tot_loss_proj:2.764 [t=0.27s]
prediction: ['[CLS] witch went by witch vanishing by vanishing forest vanishing [SEP]']
[ 900/2000] tot_loss=2.067 (perp=9.623, rec=0.130, cos=0.012), tot_loss_proj:2.767 [t=0.27s]
prediction: ['[CLS] witch went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.094 (perp=9.809, rec=0.121, cos=0.011), tot_loss_proj:2.836 [t=0.18s]
prediction: ['[CLS] witch went by the vanishing by vanishing forest vanishing [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.981 (perp=9.139, rec=0.139, cos=0.014), tot_loss_proj:2.614 [t=0.19s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
[1050/2000] tot_loss=1.960 (perp=9.139, rec=0.121, cos=0.012), tot_loss_proj:2.609 [t=0.18s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1100/2000] tot_loss=1.957 (perp=9.139, rec=0.117, cos=0.012), tot_loss_proj:2.609 [t=0.18s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1150/2000] tot_loss=1.966 (perp=9.139, rec=0.127, cos=0.011), tot_loss_proj:2.624 [t=0.27s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
[1200/2000] tot_loss=1.947 (perp=9.139, rec=0.108, cos=0.011), tot_loss_proj:2.610 [t=0.21s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1250/2000] tot_loss=1.956 (perp=9.139, rec=0.117, cos=0.011), tot_loss_proj:2.611 [t=0.23s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1300/2000] tot_loss=1.962 (perp=9.139, rec=0.123, cos=0.011), tot_loss_proj:2.613 [t=0.27s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
[1350/2000] tot_loss=1.948 (perp=9.139, rec=0.109, cos=0.011), tot_loss_proj:2.608 [t=0.18s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1400/2000] tot_loss=1.946 (perp=9.139, rec=0.108, cos=0.011), tot_loss_proj:2.607 [t=0.18s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1450/2000] tot_loss=1.967 (perp=9.139, rec=0.128, cos=0.011), tot_loss_proj:2.618 [t=0.18s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
[1500/2000] tot_loss=1.960 (perp=9.139, rec=0.122, cos=0.010), tot_loss_proj:2.611 [t=0.18s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1550/2000] tot_loss=1.945 (perp=9.139, rec=0.107, cos=0.010), tot_loss_proj:2.613 [t=0.18s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1600/2000] tot_loss=1.961 (perp=9.139, rec=0.123, cos=0.010), tot_loss_proj:2.614 [t=0.18s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
[1650/2000] tot_loss=1.953 (perp=9.139, rec=0.115, cos=0.010), tot_loss_proj:2.615 [t=0.18s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1700/2000] tot_loss=1.957 (perp=9.139, rec=0.119, cos=0.010), tot_loss_proj:2.615 [t=0.22s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1750/2000] tot_loss=1.954 (perp=9.139, rec=0.116, cos=0.010), tot_loss_proj:2.614 [t=0.22s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
[1800/2000] tot_loss=1.943 (perp=9.139, rec=0.105, cos=0.010), tot_loss_proj:2.616 [t=0.29s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1850/2000] tot_loss=1.957 (perp=9.139, rec=0.119, cos=0.010), tot_loss_proj:2.613 [t=0.19s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[1900/2000] tot_loss=1.948 (perp=9.139, rec=0.110, cos=0.010), tot_loss_proj:2.616 [t=0.24s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
[1950/2000] tot_loss=1.954 (perp=9.139, rec=0.116, cos=0.010), tot_loss_proj:2.614 [t=0.19s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Attempt swap
[2000/2000] tot_loss=1.945 (perp=9.139, rec=0.107, cos=0.010), tot_loss_proj:2.617 [t=0.26s]
prediction: ['[CLS] the went by witch vanishing by vanishing forest vanishing [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] the witch went into the forest by vanishing. [SEP]
========================
predicted: 
========================
[CLS] the the witch went by vanishing intoch forest [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 44.444 | p: 44.444 | r: 44.444
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 134.444

[Aggregate metrics]:
rouge1     | fm: 80.696 | p: 80.106 | r: 81.493
rouge2     | fm: 37.732 | p: 37.414 | r: 38.142
rougeL     | fm: 67.813 | p: 67.379 | r: 68.502
rougeLsum  | fm: 67.992 | p: 67.539 | r: 68.682
r1fm+r2fm = 118.427

input #46 time: 0:08:33 | total time: 6:36:39


Running input #47 of 100.
reference: 
========================
Mary noticed John's excessive appreciation of himself.
========================
average of cosine similarity 0.9992399581895643
highest_index [0]
highest [0.9992399581895643]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2984,  4384,  2198,  1005,  1055, 11664, 12284,  1997,  2370,
          1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] mary noticed john's excessive appreciation of himself. [SEP]"]
[Init] best rec loss: 1.9367190599441528 for ['[CLS] negotiationsris deemedtment prohibition wine holdingyn divorced within [SEP]']
[Init] best rec loss: 1.9317290782928467 for ['[CLS] apart nearly twinotho point onceient overcome beck hong [SEP]']
[Init] best rec loss: 1.8879913091659546 for ['[CLS] less pain enters silk mktiv doesn thighs replde [SEP]']
[Init] best rec loss: 1.8620554208755493 for ['[CLS]tte off race indoor account fitz combine everysfield nominations [SEP]']
[Init] best rec loss: 1.8293923139572144 for ['[CLS] hill gentle blossoms descent oro continuum chapelster set [UNK] [SEP]']
[Init] best rec loss: 1.8264297246932983 for ['[CLS] mediterranean stranded burnett mindto captain couplingioril partnered [SEP]']
[Init] best rec loss: 1.8211188316345215 for ['[CLS] ⁱ og acres squire boo consensusauaz batman spin [SEP]']
[Init] best rec loss: 1.8200160264968872 for ['[CLS] late second earlier samson transfer toss begant styleelia [SEP]']
[Init] best rec loss: 1.8189520835876465 for ['[CLS] takes performing tammy eventually parallel side children formeren pilot [SEP]']
[Init] best rec loss: 1.8098407983779907 for ['[CLS] adult formation randy grass room generalmissive use hitchnche [SEP]']
[Init] best perm rec loss: 1.8089566230773926 for ['[CLS]nche formation adult general use room grass hitch randymissive [SEP]']
[Init] best perm rec loss: 1.8087513446807861 for ['[CLS] usenche generalmissive hitch adult room grass randy formation [SEP]']
[Init] best perm rec loss: 1.80751371383667 for ['[CLS] adultnche formation general room use randy grassmissive hitch [SEP]']
[Init] best perm rec loss: 1.8069231510162354 for ['[CLS]missive adult formation general grass room usenche hitch randy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.568 (perp=9.309, rec=0.706, cos=1.000), tot_loss_proj:3.811 [t=0.24s]
prediction: ["[CLS] during'recent lordship. shifters,. exchange loud [SEP]"]
[ 100/2000] tot_loss=3.626 (perp=9.900, rec=0.700, cos=0.947), tot_loss_proj:3.794 [t=0.18s]
prediction: ['[CLS] personally noticed arabian alex. by,ignant references. [SEP]']
[ 150/2000] tot_loss=2.663 (perp=11.121, rec=0.362, cos=0.077), tot_loss_proj:3.994 [t=0.19s]
prediction: ['[CLS] noticed noticed japanese champion. crazy,uring appointment lord [SEP]']
[ 200/2000] tot_loss=2.489 (perp=10.824, rec=0.288, cos=0.036), tot_loss_proj:3.986 [t=0.21s]
prediction: ['[CLS] noticed noticed interest excessive..,uring issue mary [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.382 (perp=10.734, rec=0.215, cos=0.020), tot_loss_proj:4.058 [t=0.18s]
prediction: ['[CLS] john noticed excessive interest excessive.,uring issue mary [SEP]']
[ 300/2000] tot_loss=2.157 (perp=9.831, rec=0.176, cos=0.014), tot_loss_proj:3.868 [t=0.22s]
prediction: ['[CLS] john noticed his excessive excessive., via issue mary [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.553 (perp=11.728, rec=0.191, cos=0.017), tot_loss_proj:4.156 [t=0.18s]
prediction: ['[CLS] john noticed s excessive excessive accepted mary excessive message, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.468 (perp=11.450, rec=0.166, cos=0.012), tot_loss_proj:4.334 [t=0.24s]
prediction: ['[CLS] john noticed s excessive excuse... mary excessive appreciation, [SEP]']
[ 450/2000] tot_loss=2.499 (perp=11.666, rec=0.155, cos=0.011), tot_loss_proj:4.340 [t=0.18s]
prediction: ['[CLS] john noticed s excessive appreciation... mary excessive appreciation, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.302 (perp=10.799, rec=0.134, cos=0.009), tot_loss_proj:4.151 [t=0.18s]
prediction: ['[CLS] john noticed s excessive appreciation, mary excessive appreciation... [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.227 (perp=10.469, rec=0.125, cos=0.009), tot_loss_proj:4.015 [t=0.19s]
prediction: ['[CLS] john noticed s excessive appreciation mary, excessive appreciation... [SEP]']
[ 600/2000] tot_loss=2.222 (perp=10.469, rec=0.121, cos=0.008), tot_loss_proj:4.012 [t=0.18s]
prediction: ['[CLS] john noticed s excessive appreciation mary, excessive appreciation... [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.408 (perp=11.457, rec=0.110, cos=0.007), tot_loss_proj:4.142 [t=0.21s]
prediction: ['[CLS] john noticed s excessive himself mary, excessive appreciation... [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.360 (perp=11.201, rec=0.112, cos=0.007), tot_loss_proj:4.022 [t=0.18s]
prediction: ['[CLS] john noticed s excessive excessive mary, himself appreciation... [SEP]']
[ 750/2000] tot_loss=2.362 (perp=11.201, rec=0.115, cos=0.006), tot_loss_proj:4.016 [t=0.18s]
prediction: ['[CLS] john noticed s excessive excessive mary, himself appreciation... [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.351 (perp=11.201, rec=0.105, cos=0.006), tot_loss_proj:4.018 [t=0.23s]
prediction: ['[CLS] john noticed s excessive excessive mary, himself appreciation... [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.345 (perp=11.201, rec=0.099, cos=0.006), tot_loss_proj:4.015 [t=0.26s]
prediction: ['[CLS] john noticed s excessive excessive mary, himself appreciation... [SEP]']
[ 900/2000] tot_loss=2.348 (perp=11.201, rec=0.102, cos=0.005), tot_loss_proj:4.023 [t=0.22s]
prediction: ['[CLS] john noticed s excessive excessive mary, himself appreciation... [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.197 (perp=10.470, rec=0.097, cos=0.006), tot_loss_proj:3.872 [t=0.25s]
prediction: ['[CLS] john noticed s excessive excessive appreciation mary, himself... [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.183 (perp=10.470, rec=0.083, cos=0.006), tot_loss_proj:3.862 [t=0.18s]
prediction: ['[CLS] john noticed s excessive excessive appreciation mary, himself... [SEP]']
[1050/2000] tot_loss=2.190 (perp=10.470, rec=0.091, cos=0.005), tot_loss_proj:3.869 [t=0.18s]
prediction: ['[CLS] john noticed s excessive excessive appreciation mary, himself... [SEP]']
Attempt swap
[1100/2000] tot_loss=2.195 (perp=10.470, rec=0.096, cos=0.005), tot_loss_proj:3.867 [t=0.20s]
prediction: ['[CLS] john noticed s excessive excessive appreciation mary, himself... [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.154 (perp=10.235, rec=0.101, cos=0.006), tot_loss_proj:3.872 [t=0.23s]
prediction: ['[CLS] john noticed... s excessive excessive appreciation mary, himself [SEP]']
[1200/2000] tot_loss=2.149 (perp=10.235, rec=0.097, cos=0.005), tot_loss_proj:3.869 [t=0.22s]
prediction: ['[CLS] john noticed... s excessive excessive appreciation mary, himself [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.005 (perp=9.536, rec=0.093, cos=0.005), tot_loss_proj:3.735 [t=0.29s]
prediction: ['[CLS] john noticed. mary s excessive excessive appreciation, himself [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.770 (perp=8.355, rec=0.093, cos=0.005), tot_loss_proj:3.542 [t=0.24s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
[1350/2000] tot_loss=1.763 (perp=8.355, rec=0.087, cos=0.005), tot_loss_proj:3.545 [t=0.29s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.764 (perp=8.355, rec=0.088, cos=0.005), tot_loss_proj:3.541 [t=0.25s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.758 (perp=8.355, rec=0.082, cos=0.005), tot_loss_proj:3.539 [t=0.26s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
[1500/2000] tot_loss=1.760 (perp=8.355, rec=0.084, cos=0.005), tot_loss_proj:3.539 [t=0.18s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.767 (perp=8.355, rec=0.091, cos=0.005), tot_loss_proj:3.544 [t=0.20s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.761 (perp=8.355, rec=0.085, cos=0.005), tot_loss_proj:3.540 [t=0.18s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
[1650/2000] tot_loss=1.765 (perp=8.355, rec=0.089, cos=0.005), tot_loss_proj:3.543 [t=0.18s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.768 (perp=8.355, rec=0.092, cos=0.005), tot_loss_proj:3.540 [t=0.21s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.764 (perp=8.355, rec=0.088, cos=0.005), tot_loss_proj:3.540 [t=0.26s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
[1800/2000] tot_loss=1.760 (perp=8.355, rec=0.084, cos=0.005), tot_loss_proj:3.541 [t=0.24s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.767 (perp=8.355, rec=0.091, cos=0.005), tot_loss_proj:3.541 [t=0.19s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.766 (perp=8.355, rec=0.091, cos=0.005), tot_loss_proj:3.545 [t=0.20s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
[1950/2000] tot_loss=1.766 (perp=8.355, rec=0.091, cos=0.005), tot_loss_proj:3.541 [t=0.19s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.772 (perp=8.355, rec=0.096, cos=0.005), tot_loss_proj:3.545 [t=0.18s]
prediction: ['[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] mary noticed john's excessive appreciation of himself. [SEP]
========================
predicted: 
========================
[CLS] john noticed mary s excessive excessive appreciation, himself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 123.333

[Aggregate metrics]:
rouge1     | fm: 80.890 | p: 80.303 | r: 81.691
rouge2     | fm: 37.604 | p: 37.354 | r: 37.973
rougeL     | fm: 67.865 | p: 67.425 | r: 68.568
rougeLsum  | fm: 68.074 | p: 67.653 | r: 68.715
r1fm+r2fm = 118.494

input #47 time: 0:08:28 | total time: 6:45:07


Running input #48 of 100.
reference: 
========================
John tagged Lewis with a regulation baseball on Tuesday.
========================
average of cosine similarity 0.9992913220295516
highest_index [0]
highest [0.9992913220295516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198, 26610,  4572,  2007,  1037,  7816,  3598,  2006,  9857,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]']
[Init] best rec loss: 1.9643326997756958 for ['[CLS]... spit opening tolerant lie officer 3rd wiener true li [SEP]']
[Init] best rec loss: 1.933288812637329 for ['[CLS] stunt exclusively since bear toss temple calings whispers claimed [SEP]']
[Init] best rec loss: 1.916601300239563 for ['[CLS] battery burnham canada hai spirit kirk themselves lostthal citizen [SEP]']
[Init] best rec loss: 1.854809284210205 for ['[CLS] (rag recognition i tissues xvi computer curious toward palm [SEP]']
[Init] best rec loss: 1.8279812335968018 for ['[CLS]hot prime found whiteline mostly also times as lennon [SEP]']
[Init] best perm rec loss: 1.8257287740707397 for ['[CLS] lennonline whitehot as also prime times mostly found [SEP]']
[Init] best perm rec loss: 1.8257275819778442 for ['[CLS] lennon timeshot as white mostlyline also prime found [SEP]']
[Init] best perm rec loss: 1.8230698108673096 for ['[CLS] also as times whitehot prime mostlyline found lennon [SEP]']
[Init] best perm rec loss: 1.8230035305023193 for ['[CLS] prime white alsoline lennon found ashot times mostly [SEP]']
[Init] best perm rec loss: 1.8205037117004395 for ['[CLS] also found mostly as prime lennon timeslinehot white [SEP]']
[Init] best perm rec loss: 1.8197555541992188 for ['[CLS]hot also mostly as white found lennon timesline prime [SEP]']
[Init] best perm rec loss: 1.81847083568573 for ['[CLS] also found as whiteline times lennon mostlyhot prime [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.847 (perp=11.114, rec=0.497, cos=0.128), tot_loss_proj:4.168 [t=0.22s]
prediction: ['[CLS] douglas june when super night sheriff pizza baseball activated. [SEP]']
[ 100/2000] tot_loss=2.940 (perp=12.784, rec=0.342, cos=0.040), tot_loss_proj:4.431 [t=0.20s]
prediction: ['[CLS] lewis sabbath tagged converted night matt baseball baseball activated. [SEP]']
[ 150/2000] tot_loss=2.994 (perp=12.570, rec=0.401, cos=0.078), tot_loss_proj:4.425 [t=0.18s]
prediction: ['[CLS] lewis, tagged late friday lewis baseball baseball florida helmut [SEP]']
[ 200/2000] tot_loss=2.829 (perp=12.636, rec=0.279, cos=0.023), tot_loss_proj:4.449 [t=0.18s]
prediction: ['[CLS] lewis, tagged a tuesday lewis baseball fined baseball helmut [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.442 (perp=10.908, rec=0.246, cos=0.014), tot_loss_proj:4.112 [t=0.22s]
prediction: ['[CLS] lewis. tagged on tuesday baseball baseball lewis baseball baseball [SEP]']
[ 300/2000] tot_loss=2.319 (perp=10.557, rec=0.196, cos=0.011), tot_loss_proj:4.019 [t=0.21s]
prediction: ['[CLS] lewis. tagged on tuesday baseball baseball lewis baseball with [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.023 (perp=9.286, rec=0.156, cos=0.010), tot_loss_proj:3.855 [t=0.18s]
prediction: ['[CLS] lewis. tagged on tuesday baseball. lewis regulation with [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.886 (perp=8.780, rec=0.122, cos=0.008), tot_loss_proj:3.736 [t=0.19s]
prediction: ['[CLS] john tagged. on tuesday baseball. lewis regulation with [SEP]']
[ 450/2000] tot_loss=1.884 (perp=8.780, rec=0.121, cos=0.007), tot_loss_proj:3.739 [t=0.19s]
prediction: ['[CLS] john tagged. on tuesday baseball. lewis regulation with [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.802 (perp=8.334, rec=0.128, cos=0.007), tot_loss_proj:3.665 [t=0.18s]
prediction: ['[CLS] john tagged. on tuesday with baseball. lewis regulation [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.783 (perp=8.334, rec=0.111, cos=0.005), tot_loss_proj:3.666 [t=0.18s]
prediction: ['[CLS] john tagged. on tuesday with baseball. lewis regulation [SEP]']
[ 600/2000] tot_loss=1.772 (perp=8.334, rec=0.100, cos=0.005), tot_loss_proj:3.668 [t=0.25s]
prediction: ['[CLS] john tagged. on tuesday with baseball. lewis regulation [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.653 (perp=7.736, rec=0.101, cos=0.005), tot_loss_proj:3.527 [t=0.25s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.644 (perp=7.736, rec=0.092, cos=0.005), tot_loss_proj:3.534 [t=0.25s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
[ 750/2000] tot_loss=1.647 (perp=7.736, rec=0.095, cos=0.005), tot_loss_proj:3.537 [t=0.23s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.647 (perp=7.736, rec=0.095, cos=0.005), tot_loss_proj:3.537 [t=0.20s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.649 (perp=7.736, rec=0.097, cos=0.005), tot_loss_proj:3.535 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
[ 900/2000] tot_loss=1.650 (perp=7.736, rec=0.098, cos=0.005), tot_loss_proj:3.539 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.643 (perp=7.736, rec=0.091, cos=0.005), tot_loss_proj:3.533 [t=0.21s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.641 (perp=7.736, rec=0.089, cos=0.005), tot_loss_proj:3.528 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
[1050/2000] tot_loss=1.632 (perp=7.736, rec=0.080, cos=0.005), tot_loss_proj:3.537 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.646 (perp=7.736, rec=0.094, cos=0.005), tot_loss_proj:3.533 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.636 (perp=7.736, rec=0.084, cos=0.005), tot_loss_proj:3.537 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
[1200/2000] tot_loss=1.641 (perp=7.736, rec=0.089, cos=0.005), tot_loss_proj:3.535 [t=0.21s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.635 (perp=7.736, rec=0.084, cos=0.005), tot_loss_proj:3.526 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.644 (perp=7.736, rec=0.092, cos=0.004), tot_loss_proj:3.529 [t=0.30s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
[1350/2000] tot_loss=1.638 (perp=7.736, rec=0.087, cos=0.004), tot_loss_proj:3.533 [t=0.22s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.633 (perp=7.736, rec=0.081, cos=0.004), tot_loss_proj:3.532 [t=0.19s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.635 (perp=7.736, rec=0.083, cos=0.004), tot_loss_proj:3.536 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
[1500/2000] tot_loss=1.635 (perp=7.736, rec=0.083, cos=0.004), tot_loss_proj:3.532 [t=0.19s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.646 (perp=7.736, rec=0.094, cos=0.004), tot_loss_proj:3.528 [t=0.25s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.635 (perp=7.736, rec=0.083, cos=0.004), tot_loss_proj:3.535 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
[1650/2000] tot_loss=1.640 (perp=7.736, rec=0.088, cos=0.004), tot_loss_proj:3.530 [t=0.21s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.630 (perp=7.736, rec=0.078, cos=0.004), tot_loss_proj:3.532 [t=0.20s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.633 (perp=7.736, rec=0.082, cos=0.004), tot_loss_proj:3.533 [t=0.26s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
[1800/2000] tot_loss=1.625 (perp=7.736, rec=0.073, cos=0.004), tot_loss_proj:3.528 [t=0.30s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.626 (perp=7.736, rec=0.074, cos=0.004), tot_loss_proj:3.533 [t=0.19s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.634 (perp=7.736, rec=0.082, cos=0.004), tot_loss_proj:3.527 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
[1950/2000] tot_loss=1.639 (perp=7.736, rec=0.088, cos=0.004), tot_loss_proj:3.534 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.641 (perp=7.736, rec=0.090, cos=0.004), tot_loss_proj:3.534 [t=0.18s]
prediction: ['[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] john tagged lewis with a regulation baseball on tuesday. [SEP]
========================
predicted: 
========================
[CLS] john tagged on tuesday with baseball. lewis regulation. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 100.000 | r: 90.909
rouge2     | fm: 31.579 | p: 33.333 | r: 30.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 126.817

[Aggregate metrics]:
rouge1     | fm: 81.248 | p: 80.766 | r: 81.954
rouge2     | fm: 37.495 | p: 37.215 | r: 37.909
rougeL     | fm: 67.612 | p: 67.272 | r: 68.257
rougeLsum  | fm: 67.853 | p: 67.474 | r: 68.319
r1fm+r2fm = 118.743

input #48 time: 0:08:20 | total time: 6:53:28


Running input #49 of 100.
reference: 
========================
We all thought him to be unhappy
========================
average of cosine similarity 0.9993920717359353
highest_index [0]
highest [0.9993920717359353]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2057,  2035,  2245,  2032,  2000,  2022, 12511,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] we all thought him to be unhappy [SEP]']
[Init] best rec loss: 1.9410984516143799 for ['[CLS] mattermei visibly port brandenburgmissive le [SEP]']
[Init] best rec loss: 1.9149824380874634 for ['[CLS] smoke starary pmid feather consider line [SEP]']
[Init] best rec loss: 1.908936619758606 for ['[CLS] untilnea happened egg confirmation final resonance [SEP]']
[Init] best rec loss: 1.9010589122772217 for ['[CLS] studies brig numbered logan tour percent rex [SEP]']
[Init] best rec loss: 1.8928929567337036 for ['[CLS]vy threatened fragments straight long piper sign [SEP]']
[Init] best rec loss: 1.871233582496643 for ['[CLS] springs society military deliver part holocaustuch [SEP]']
[Init] best rec loss: 1.8096837997436523 for ['[CLS] cominglett than carrier holiday exposed long [SEP]']
[Init] best perm rec loss: 1.7992626428604126 for ['[CLS] longlett carrier than holiday exposed coming [SEP]']
[Init] best perm rec loss: 1.7933979034423828 for ['[CLS] coming holiday exposed long carrierlett than [SEP]']
[Init] best perm rec loss: 1.7922755479812622 for ['[CLS] coming holidaylett long carrier exposed than [SEP]']
[Init] best perm rec loss: 1.78428316116333 for ['[CLS] carrier holiday coming exposedlett long than [SEP]']
[Init] best perm rec loss: 1.7797585725784302 for ['[CLS] holiday exposed carrier cominglett long than [SEP]']
[Init] best perm rec loss: 1.7774438858032227 for ['[CLS] holiday coming carrierlett exposed long than [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.628 (perp=10.575, rec=0.557, cos=0.956), tot_loss_proj:4.021 [t=0.18s]
prediction: ['[CLS] sure had sir thisː least come [SEP]']
[ 100/2000] tot_loss=3.574 (perp=11.274, rec=0.467, cos=0.852), tot_loss_proj:4.149 [t=0.18s]
prediction: ['[CLS] we to sir allct least him [SEP]']
[ 150/2000] tot_loss=2.640 (perp=10.503, rec=0.402, cos=0.138), tot_loss_proj:3.998 [t=0.18s]
prediction: ['[CLS] we had s justin unhappy much angry [SEP]']
[ 200/2000] tot_loss=2.285 (perp=9.783, rec=0.294, cos=0.034), tot_loss_proj:3.913 [t=0.28s]
prediction: ['[CLS] we had thought wilson eldest him unhappy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.116 (perp=8.920, rec=0.293, cos=0.039), tot_loss_proj:3.665 [t=0.19s]
prediction: ['[CLS] we thought him della thought him unhappy [SEP]']
[ 300/2000] tot_loss=1.980 (perp=8.920, rec=0.185, cos=0.011), tot_loss_proj:3.666 [t=0.18s]
prediction: ['[CLS] we thought him della thought him unhappy [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.619 (perp=11.040, rec=0.342, cos=0.069), tot_loss_proj:4.119 [t=0.18s]
prediction: ['[CLS] we thought himetched thoughtciful unhappy [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.203 (perp=9.499, rec=0.276, cos=0.027), tot_loss_proj:3.460 [t=0.18s]
prediction: ['[CLS] we thought unhappy respects thought him unhappy [SEP]']
[ 450/2000] tot_loss=2.108 (perp=9.300, rec=0.230, cos=0.017), tot_loss_proj:3.765 [t=0.22s]
prediction: ['[CLS] we thought unhappy unhappy thought him unhappy [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.080 (perp=9.300, rec=0.207, cos=0.013), tot_loss_proj:3.763 [t=0.18s]
prediction: ['[CLS] we thought unhappy unhappy thought him unhappy [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.066 (perp=9.300, rec=0.194, cos=0.012), tot_loss_proj:3.766 [t=0.23s]
prediction: ['[CLS] we thought unhappy unhappy thought him unhappy [SEP]']
[ 600/2000] tot_loss=2.583 (perp=11.063, rec=0.312, cos=0.059), tot_loss_proj:4.092 [t=0.18s]
prediction: ['[CLS] we thought useful stick thought him unhappy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.360 (perp=10.291, rec=0.266, cos=0.036), tot_loss_proj:3.892 [t=0.19s]
prediction: ['[CLS] we thought useful unhappy thought him bearer [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.528 (perp=11.203, rec=0.261, cos=0.026), tot_loss_proj:4.145 [t=0.18s]
prediction: ['[CLS] we thoughtencies thought him facebook unhappy [SEP]']
[ 750/2000] tot_loss=2.388 (perp=10.674, rec=0.233, cos=0.020), tot_loss_proj:4.011 [t=0.20s]
prediction: ['[CLS] we thought unhappy thought him facebook unhappy [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.184 (perp=9.728, rec=0.222, cos=0.016), tot_loss_proj:3.880 [t=0.19s]
prediction: ['[CLS] we thought facebook thought him unhappy unhappy [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.019 (perp=8.912, rec=0.221, cos=0.015), tot_loss_proj:3.822 [t=0.21s]
prediction: ['[CLS] we thought facebook thought him be unhappy [SEP]']
[ 900/2000] tot_loss=2.014 (perp=8.912, rec=0.218, cos=0.013), tot_loss_proj:3.825 [t=0.20s]
prediction: ['[CLS] we thought facebook thought him be unhappy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.962 (perp=8.706, rec=0.209, cos=0.012), tot_loss_proj:3.817 [t=0.19s]
prediction: ['[CLS] we thought dr thought him be unhappy [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.930 (perp=8.542, rec=0.209, cos=0.012), tot_loss_proj:3.797 [t=0.24s]
prediction: ['[CLS] dr thought we thought him be unhappy [SEP]']
[1050/2000] tot_loss=2.067 (perp=9.245, rec=0.207, cos=0.010), tot_loss_proj:3.864 [t=0.25s]
prediction: ['[CLS] disposed thought we thought him be unhappy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.913 (perp=8.542, rec=0.195, cos=0.010), tot_loss_proj:3.794 [t=0.24s]
prediction: ['[CLS] dr thought we thought him be unhappy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.904 (perp=8.542, rec=0.187, cos=0.009), tot_loss_proj:3.802 [t=0.19s]
prediction: ['[CLS] dr thought we thought him be unhappy [SEP]']
[1200/2000] tot_loss=1.911 (perp=8.542, rec=0.194, cos=0.008), tot_loss_proj:3.797 [t=0.22s]
prediction: ['[CLS] dr thought we thought him be unhappy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.907 (perp=8.542, rec=0.190, cos=0.008), tot_loss_proj:3.803 [t=0.26s]
prediction: ['[CLS] dr thought we thought him be unhappy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.908 (perp=8.542, rec=0.192, cos=0.008), tot_loss_proj:3.796 [t=0.18s]
prediction: ['[CLS] dr thought we thought him be unhappy [SEP]']
[1350/2000] tot_loss=1.905 (perp=8.542, rec=0.189, cos=0.008), tot_loss_proj:3.797 [t=0.21s]
prediction: ['[CLS] dr thought we thought him be unhappy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.899 (perp=8.542, rec=0.183, cos=0.007), tot_loss_proj:3.794 [t=0.23s]
prediction: ['[CLS] dr thought we thought him be unhappy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.904 (perp=8.542, rec=0.188, cos=0.007), tot_loss_proj:3.799 [t=0.25s]
prediction: ['[CLS] dr thought we thought him be unhappy [SEP]']
[1500/2000] tot_loss=2.040 (perp=9.245, rec=0.184, cos=0.007), tot_loss_proj:3.866 [t=0.25s]
prediction: ['[CLS] disposed thought we thought him be unhappy [SEP]']
Attempt swap
[1550/2000] tot_loss=2.035 (perp=9.245, rec=0.179, cos=0.007), tot_loss_proj:3.860 [t=0.25s]
prediction: ['[CLS] disposed thought we thought him be unhappy [SEP]']
Attempt swap
[1600/2000] tot_loss=2.031 (perp=9.245, rec=0.176, cos=0.007), tot_loss_proj:3.865 [t=0.26s]
prediction: ['[CLS] disposed thought we thought him be unhappy [SEP]']
[1650/2000] tot_loss=2.031 (perp=9.245, rec=0.176, cos=0.007), tot_loss_proj:3.863 [t=0.19s]
prediction: ['[CLS] disposed thought we thought him be unhappy [SEP]']
Attempt swap
[1700/2000] tot_loss=2.040 (perp=9.245, rec=0.185, cos=0.006), tot_loss_proj:3.857 [t=0.18s]
prediction: ['[CLS] disposed thought we thought him be unhappy [SEP]']
Attempt swap
[1750/2000] tot_loss=2.025 (perp=9.245, rec=0.170, cos=0.006), tot_loss_proj:3.867 [t=0.27s]
prediction: ['[CLS] disposed thought we thought him be unhappy [SEP]']
[1800/2000] tot_loss=2.032 (perp=9.245, rec=0.176, cos=0.006), tot_loss_proj:3.861 [t=0.21s]
prediction: ['[CLS] disposed thought we thought him be unhappy [SEP]']
Attempt swap
[1850/2000] tot_loss=2.027 (perp=9.245, rec=0.172, cos=0.006), tot_loss_proj:3.861 [t=0.18s]
prediction: ['[CLS] disposed thought we thought him be unhappy [SEP]']
Attempt swap
[1900/2000] tot_loss=2.028 (perp=9.245, rec=0.173, cos=0.006), tot_loss_proj:3.863 [t=0.19s]
prediction: ['[CLS] disposed thought we thought him be unhappy [SEP]']
[1950/2000] tot_loss=2.008 (perp=9.184, rec=0.166, cos=0.006), tot_loss_proj:3.645 [t=0.26s]
prediction: ['[CLS] thought thought we thought him be unhappy [SEP]']
Attempt swap
[2000/2000] tot_loss=2.016 (perp=9.184, rec=0.173, cos=0.006), tot_loss_proj:3.645 [t=0.23s]
prediction: ['[CLS] thought thought we thought him be unhappy [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] we all thought him to be unhappy [SEP]
========================
predicted: 
========================
[CLS] thought thought we thought him be unhappy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 115.278

[Aggregate metrics]:
rouge1     | fm: 81.081 | p: 80.669 | r: 81.790
rouge2     | fm: 37.471 | p: 37.268 | r: 37.874
rougeL     | fm: 67.842 | p: 67.537 | r: 68.342
rougeLsum  | fm: 67.975 | p: 67.694 | r: 68.547
r1fm+r2fm = 118.553

input #49 time: 0:08:18 | total time: 7:01:47


Running input #50 of 100.
reference: 
========================
Book is available in most countries.
========================
average of cosine similarity 0.999341484458915
highest_index [0]
highest [0.999341484458915]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2338, 2003, 2800, 1999, 2087, 3032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] book is available in most countries. [SEP]']
[Init] best rec loss: 1.2598944902420044 for ['[CLS] keyxy neither jenksuka chow administration [SEP]']
[Init] best rec loss: 1.1662899255752563 for ['[CLS]ers quality thereafter small conversations gaius sven [SEP]']
[Init] best rec loss: 1.1023132801055908 for ['[CLS] bang indira represented insideinator 15 twice [SEP]']
[Init] best perm rec loss: 1.1018016338348389 for ['[CLS] represented twice 15 insideinator indira bang [SEP]']
[Init] best perm rec loss: 1.099618911743164 for ['[CLS] represented insideinator 15 bang twice indira [SEP]']
[Init] best perm rec loss: 1.0970897674560547 for ['[CLS] represented twiceinator inside indira 15 bang [SEP]']
[Init] best perm rec loss: 1.0954992771148682 for ['[CLS]inator represented inside bang 15 indira twice [SEP]']
[Init] best perm rec loss: 1.0941078662872314 for ['[CLS] 15inator inside represented twice indira bang [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.710 (perp=11.400, rec=0.372, cos=0.058), tot_loss_proj:3.348 [t=0.20s]
prediction: ['[CLS] dump if book received app in tree [SEP]']
[ 100/2000] tot_loss=2.159 (perp=9.428, rec=0.251, cos=0.023), tot_loss_proj:2.940 [t=0.22s]
prediction: ['[CLS] college if book has book on available [SEP]']
[ 150/2000] tot_loss=1.739 (perp=7.708, rec=0.184, cos=0.013), tot_loss_proj:2.640 [t=0.18s]
prediction: ['[CLS] available. book is book available available [SEP]']
[ 200/2000] tot_loss=1.869 (perp=8.541, rec=0.153, cos=0.008), tot_loss_proj:2.804 [t=0.20s]
prediction: ['[CLS] available countries book is available available available [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.990 (perp=9.253, rec=0.133, cos=0.006), tot_loss_proj:2.892 [t=0.23s]
prediction: ['[CLS] countries countries book available is available available [SEP]']
[ 300/2000] tot_loss=1.911 (perp=8.915, rec=0.122, cos=0.006), tot_loss_proj:2.900 [t=0.18s]
prediction: ['[CLS] countries countries book available is in. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.653 (perp=7.669, rec=0.113, cos=0.006), tot_loss_proj:2.626 [t=0.20s]
prediction: ['[CLS] in countries book available is countries. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.755 (perp=7.239, rec=0.272, cos=0.035), tot_loss_proj:2.477 [t=0.22s]
prediction: ['[CLS] in book available countries is countries. [SEP]']
[ 450/2000] tot_loss=1.644 (perp=7.436, rec=0.148, cos=0.009), tot_loss_proj:2.472 [t=0.24s]
prediction: ['[CLS] in book available countries is most. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.162 (perp=5.199, rec=0.116, cos=0.006), tot_loss_proj:2.022 [t=0.19s]
prediction: ['[CLS] in book most countries is available. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.023 (perp=4.527, rec=0.113, cos=0.005), tot_loss_proj:1.607 [t=0.20s]
prediction: ['[CLS] in most countries book is available. [SEP]']
[ 600/2000] tot_loss=1.002 (perp=4.527, rec=0.093, cos=0.003), tot_loss_proj:1.611 [t=0.19s]
prediction: ['[CLS] in most countries book is available. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.006 (perp=4.527, rec=0.098, cos=0.003), tot_loss_proj:1.604 [t=0.21s]
prediction: ['[CLS] in most countries book is available. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.007 (perp=4.527, rec=0.099, cos=0.003), tot_loss_proj:1.606 [t=0.21s]
prediction: ['[CLS] in most countries book is available. [SEP]']
[ 750/2000] tot_loss=0.997 (perp=4.527, rec=0.089, cos=0.002), tot_loss_proj:1.613 [t=0.24s]
prediction: ['[CLS] in most countries book is available. [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.999 (perp=4.527, rec=0.091, cos=0.002), tot_loss_proj:1.608 [t=0.25s]
prediction: ['[CLS] in most countries book is available. [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.987 (perp=4.527, rec=0.080, cos=0.002), tot_loss_proj:1.600 [t=0.19s]
prediction: ['[CLS] in most countries book is available. [SEP]']
[ 900/2000] tot_loss=0.985 (perp=4.527, rec=0.078, cos=0.002), tot_loss_proj:1.600 [t=0.18s]
prediction: ['[CLS] in most countries book is available. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.991 (perp=4.527, rec=0.084, cos=0.002), tot_loss_proj:1.606 [t=0.20s]
prediction: ['[CLS] in most countries book is available. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.983 (perp=4.527, rec=0.076, cos=0.002), tot_loss_proj:1.603 [t=0.19s]
prediction: ['[CLS] in most countries book is available. [SEP]']
[1050/2000] tot_loss=0.988 (perp=4.527, rec=0.081, cos=0.002), tot_loss_proj:1.603 [t=0.19s]
prediction: ['[CLS] in most countries book is available. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=0.861 (perp=3.887, rec=0.082, cos=0.002), tot_loss_proj:0.948 [t=0.18s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.852 (perp=3.887, rec=0.072, cos=0.002), tot_loss_proj:0.952 [t=0.18s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1200/2000] tot_loss=0.850 (perp=3.887, rec=0.071, cos=0.002), tot_loss_proj:0.941 [t=0.22s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.859 (perp=3.887, rec=0.080, cos=0.002), tot_loss_proj:0.931 [t=0.21s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.845 (perp=3.887, rec=0.066, cos=0.002), tot_loss_proj:0.942 [t=0.18s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1350/2000] tot_loss=0.855 (perp=3.887, rec=0.076, cos=0.002), tot_loss_proj:0.948 [t=0.28s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.845 (perp=3.887, rec=0.066, cos=0.002), tot_loss_proj:0.935 [t=0.18s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.849 (perp=3.887, rec=0.070, cos=0.002), tot_loss_proj:0.936 [t=0.29s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1500/2000] tot_loss=0.854 (perp=3.887, rec=0.075, cos=0.002), tot_loss_proj:0.945 [t=0.22s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.856 (perp=3.887, rec=0.077, cos=0.002), tot_loss_proj:0.945 [t=0.22s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.838 (perp=3.887, rec=0.059, cos=0.002), tot_loss_proj:0.936 [t=0.19s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1650/2000] tot_loss=0.846 (perp=3.887, rec=0.067, cos=0.002), tot_loss_proj:0.939 [t=0.18s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.838 (perp=3.887, rec=0.059, cos=0.002), tot_loss_proj:0.950 [t=0.18s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.847 (perp=3.887, rec=0.068, cos=0.002), tot_loss_proj:0.935 [t=0.19s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1800/2000] tot_loss=0.859 (perp=3.887, rec=0.080, cos=0.002), tot_loss_proj:0.944 [t=0.18s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.857 (perp=3.887, rec=0.078, cos=0.002), tot_loss_proj:0.941 [t=0.18s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.849 (perp=3.887, rec=0.070, cos=0.002), tot_loss_proj:0.942 [t=0.18s]
prediction: ['[CLS] book is available in most countries. [SEP]']
[1950/2000] tot_loss=0.855 (perp=3.887, rec=0.076, cos=0.002), tot_loss_proj:0.948 [t=0.18s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.843 (perp=3.887, rec=0.064, cos=0.002), tot_loss_proj:0.946 [t=0.21s]
prediction: ['[CLS] book is available in most countries. [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] book is available in most countries. [SEP]
========================
predicted: 
========================
[CLS] book is available in most countries. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.570 | p: 81.123 | r: 82.116
rouge2     | fm: 38.701 | p: 38.417 | r: 39.036
rougeL     | fm: 68.513 | p: 68.154 | r: 69.013
rougeLsum  | fm: 68.721 | p: 68.399 | r: 69.218
r1fm+r2fm = 120.271

input #50 time: 0:08:20 | total time: 7:10:07


Running input #51 of 100.
reference: 
========================
I could have little known that more trouble was just around the corner.
========================
average of cosine similarity 0.9993932192875968
highest_index [0]
highest [0.9993932192875968]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 1045, 2071, 2031, 2210, 2124, 2008, 2062, 4390, 2001, 2074, 2105,
         1996, 3420, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i could have little known that more trouble was just around the corner. [SEP]']
[Init] best rec loss: 1.8910044431686401 for ['[CLS] missing coincidence ten ideas gas need status singleton silver considered demolished tale convert grumbled [SEP]']
[Init] best rec loss: 1.855173110961914 for ['[CLS] clshfalls chicago walled steps turn photos tell covers yet letter xx table [SEP]']
[Init] best rec loss: 1.7965996265411377 for ['[CLS] temperatures ruth krishna metre cultural samurai acceleration visual oscar premiere hitter priest jo ps [SEP]']
[Init] best perm rec loss: 1.7948894500732422 for ['[CLS] ps temperatures samurai metre priest cultural premiere jo krishna oscar visual ruth hitter acceleration [SEP]']
[Init] best perm rec loss: 1.7847721576690674 for ['[CLS] metre hitter priest samurai ps acceleration premiere krishna visual cultural temperatures jo oscar ruth [SEP]']
[Init] best perm rec loss: 1.7755775451660156 for ['[CLS] ps cultural priest oscar premiere visual temperatures ruth samurai krishna hitter jo metre acceleration [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.284 (perp=10.284, rec=0.547, cos=0.680), tot_loss_proj:3.974 [t=0.19s]
prediction: ['[CLS] has within that.. :?typical wise energy biological madrid technique scent [SEP]']
[ 100/2000] tot_loss=2.192 (perp=9.113, rec=0.318, cos=0.052), tot_loss_proj:3.888 [t=0.18s]
prediction: ['[CLS] could they and.. known that girls trouble more little bright issues jealous [SEP]']
[ 150/2000] tot_loss=2.163 (perp=9.402, rec=0.252, cos=0.030), tot_loss_proj:3.741 [t=0.20s]
prediction: ['[CLS] could known that. trouble was that considered more more little trouble trouble jealous [SEP]']
[ 200/2000] tot_loss=2.022 (perp=8.998, rec=0.198, cos=0.024), tot_loss_proj:3.707 [t=0.18s]
prediction: ['[CLS] could known somewhere. trouble was that considered more more more trouble trouble was [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.891 (perp=8.472, rec=0.181, cos=0.016), tot_loss_proj:3.620 [t=0.18s]
prediction: ['[CLS] little known somewhere that trouble was. boys more more little trouble trouble was [SEP]']
[ 300/2000] tot_loss=1.841 (perp=8.445, rec=0.144, cos=0.008), tot_loss_proj:3.682 [t=0.18s]
prediction: ['[CLS] little known corner that trouble was. little more more little trouble i just [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.781 (perp=8.171, rec=0.139, cos=0.008), tot_loss_proj:3.602 [t=0.18s]
prediction: ['[CLS] little known corner that more trouble was. little more corner trouble i just [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.796 (perp=8.322, rec=0.125, cos=0.007), tot_loss_proj:3.657 [t=0.22s]
prediction: ['[CLS] little known corner that most trouble was. little more trouble corner i just [SEP]']
[ 450/2000] tot_loss=1.779 (perp=8.322, rec=0.109, cos=0.006), tot_loss_proj:3.662 [t=0.18s]
prediction: ['[CLS] little known corner that most trouble was. little more trouble corner i just [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.760 (perp=7.925, rec=0.164, cos=0.011), tot_loss_proj:3.444 [t=0.18s]
prediction: ['[CLS] little known was that with. corner. little more trouble corner i around [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.715 (perp=7.841, rec=0.140, cos=0.008), tot_loss_proj:3.499 [t=0.19s]
prediction: ['[CLS] little known was that. earthquake corner. little more trouble corner i around [SEP]']
[ 600/2000] tot_loss=1.710 (perp=7.906, rec=0.122, cos=0.007), tot_loss_proj:3.492 [t=0.26s]
prediction: ['[CLS] little known was that just earthquake corner. little more trouble corner i around [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.652 (perp=7.596, rec=0.127, cos=0.006), tot_loss_proj:3.442 [t=0.18s]
prediction: ['[CLS] little known was that just earthquake corner. little more trouble around i corner [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.579 (perp=7.224, rec=0.128, cos=0.007), tot_loss_proj:3.354 [t=0.18s]
prediction: ['[CLS] little known was just that little corner. little more trouble around i corner [SEP]']
[ 750/2000] tot_loss=1.569 (perp=7.224, rec=0.119, cos=0.006), tot_loss_proj:3.361 [t=0.18s]
prediction: ['[CLS] little known was just that little corner. little more trouble around i corner [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.558 (perp=7.224, rec=0.108, cos=0.005), tot_loss_proj:3.365 [t=0.23s]
prediction: ['[CLS] little known was just that little corner. little more trouble around i corner [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.475 (perp=6.718, rec=0.124, cos=0.007), tot_loss_proj:3.227 [t=0.20s]
prediction: ['[CLS] little known was just that little corner. i more trouble around little corner [SEP]']
[ 900/2000] tot_loss=1.462 (perp=6.718, rec=0.113, cos=0.006), tot_loss_proj:3.232 [t=0.18s]
prediction: ['[CLS] little known was just that little corner. i more trouble around little corner [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.466 (perp=6.718, rec=0.116, cos=0.006), tot_loss_proj:3.228 [t=0.23s]
prediction: ['[CLS] little known was just that little corner. i more trouble around little corner [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.423 (perp=6.533, rec=0.110, cos=0.006), tot_loss_proj:3.193 [t=0.20s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
[1050/2000] tot_loss=1.416 (perp=6.533, rec=0.104, cos=0.006), tot_loss_proj:3.198 [t=0.23s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
Attempt swap
[1100/2000] tot_loss=1.428 (perp=6.533, rec=0.116, cos=0.006), tot_loss_proj:3.194 [t=0.19s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
Attempt swap
[1150/2000] tot_loss=1.421 (perp=6.533, rec=0.109, cos=0.005), tot_loss_proj:3.194 [t=0.23s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
[1200/2000] tot_loss=1.418 (perp=6.533, rec=0.106, cos=0.005), tot_loss_proj:3.195 [t=0.19s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
Attempt swap
[1250/2000] tot_loss=1.427 (perp=6.533, rec=0.115, cos=0.005), tot_loss_proj:3.192 [t=0.19s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
Attempt swap
[1300/2000] tot_loss=1.414 (perp=6.533, rec=0.102, cos=0.005), tot_loss_proj:3.192 [t=0.18s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
[1350/2000] tot_loss=1.424 (perp=6.533, rec=0.112, cos=0.005), tot_loss_proj:3.194 [t=0.25s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
Attempt swap
[1400/2000] tot_loss=1.415 (perp=6.533, rec=0.103, cos=0.005), tot_loss_proj:3.191 [t=0.24s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
Attempt swap
[1450/2000] tot_loss=1.415 (perp=6.533, rec=0.103, cos=0.005), tot_loss_proj:3.190 [t=0.26s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
[1500/2000] tot_loss=1.423 (perp=6.533, rec=0.111, cos=0.005), tot_loss_proj:3.189 [t=0.18s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
Attempt swap
[1550/2000] tot_loss=1.419 (perp=6.533, rec=0.107, cos=0.005), tot_loss_proj:3.190 [t=0.18s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
Attempt swap
[1600/2000] tot_loss=1.404 (perp=6.533, rec=0.093, cos=0.005), tot_loss_proj:3.190 [t=0.18s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
[1650/2000] tot_loss=1.415 (perp=6.533, rec=0.103, cos=0.005), tot_loss_proj:3.195 [t=0.19s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
Attempt swap
[1700/2000] tot_loss=1.410 (perp=6.533, rec=0.099, cos=0.005), tot_loss_proj:3.193 [t=0.18s]
prediction: ['[CLS] little known was just that little corner i. more trouble around little corner [SEP]']
Attempt swap
[1750/2000] tot_loss=1.470 (perp=6.803, rec=0.104, cos=0.005), tot_loss_proj:3.260 [t=0.23s]
prediction: ['[CLS] little known was just that little corner have. more trouble around little corner [SEP]']
[1800/2000] tot_loss=1.462 (perp=6.803, rec=0.096, cos=0.005), tot_loss_proj:3.259 [t=0.26s]
prediction: ['[CLS] little known was just that little corner have. more trouble around little corner [SEP]']
Attempt swap
[1850/2000] tot_loss=1.465 (perp=6.803, rec=0.100, cos=0.005), tot_loss_proj:3.254 [t=0.23s]
prediction: ['[CLS] little known was just that little corner have. more trouble around little corner [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.452 (perp=6.718, rec=0.104, cos=0.005), tot_loss_proj:3.229 [t=0.19s]
prediction: ['[CLS] little known was just that little corner. i more trouble around little corner [SEP]']
[1950/2000] tot_loss=1.447 (perp=6.715, rec=0.099, cos=0.005), tot_loss_proj:3.223 [t=0.19s]
prediction: ['[CLS] little known was just that little corner. have more trouble around little corner [SEP]']
Attempt swap
[2000/2000] tot_loss=1.455 (perp=6.715, rec=0.107, cos=0.005), tot_loss_proj:3.227 [t=0.19s]
prediction: ['[CLS] little known was just that little corner. have more trouble around little corner [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] i could have little known that more trouble was just around the corner. [SEP]
========================
predicted: 
========================
[CLS] little known was just that little corner i. more trouble around little corner [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 108.571

[Aggregate metrics]:
rouge1     | fm: 81.503 | p: 81.104 | r: 82.117
rouge2     | fm: 38.507 | p: 38.207 | r: 38.833
rougeL     | fm: 68.208 | p: 67.866 | r: 68.733
rougeLsum  | fm: 68.445 | p: 68.225 | r: 68.973
r1fm+r2fm = 120.010

input #51 time: 0:08:19 | total time: 7:18:27


Running input #52 of 100.
reference: 
========================
John gave the books to Mary at Christmas, and the records to Sue for her birthday.
========================
average of cosine similarity 0.9992993920902845
highest_index [0]
highest [0.9992993920902845]
Debug: ids_shape = 20, pads = [20]
Debug: input ids = tensor([[ 101, 2198, 2435, 1996, 2808, 2000, 2984, 2012, 4234, 1010, 1998, 1996,
         2636, 2000, 9790, 2005, 2014, 5798, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]']
[Init] best rec loss: 1.9253661632537842 for ['[CLS] drama establishments wicket vocal willem presence arm australia dashed guineaturn hand converse sparrow mastof hueymined [SEP]']
[Init] best rec loss: 1.9105561971664429 for ['[CLS] graves handel reflects westfall meaning particles dogs involving spoke fake total fair sc llti distribution myself [SEP]']
[Init] best rec loss: 1.9051728248596191 for ['[CLS] miller balancelined crawl net ramsay frost platform moved eachcial report lay reflecting # gray army contributed [SEP]']
[Init] best rec loss: 1.876082181930542 for ['[CLS] feathersת walk lack mole dad medical chapel ox blow onlogy60 partedu afghanistan ideal book [SEP]']
[Init] best rec loss: 1.8627393245697021 for ['[CLS] ta references under saved alarmailed boards velvet anything patriotic fed invisible issue mytor pointed britney someone [SEP]']
[Init] best rec loss: 1.8265786170959473 for ['[CLS] for thomas razor visitor standing artifact allergic independent scheduled looksflies amulet romance appear k drink italian gardens [SEP]']
[Init] best perm rec loss: 1.8260023593902588 for ['[CLS] visitor artifact amulet k for italian appear drink razor gardens looks independent scheduled allergic thomas standing romanceflies [SEP]']
[Init] best perm rec loss: 1.8248193264007568 for ['[CLS] amulet gardens standing drink for scheduled romance allergic italian appear k independent razor artifact visitorflies thomas looks [SEP]']
[Init] best perm rec loss: 1.824573040008545 for ['[CLS] for scheduled artifactflies visitor appear amulet gardens standing drink thomas independent razor looks allergic italian romance k [SEP]']
[Init] best perm rec loss: 1.8230516910552979 for ['[CLS] appear for looks drink italian scheduled amulet artifact independent k gardensflies standing thomas romance visitor razor allergic [SEP]']
[Init] best perm rec loss: 1.8220263719558716 for ['[CLS] razor italian independent amulet for allergic thomas gardens drinkflies scheduled romance k standing visitor looks artifact appear [SEP]']
[Init] best perm rec loss: 1.821516752243042 for ['[CLS] artifact looks for independent romance amulet drink razor scheduled appear standing gardens visitor thomasflies italian k allergic [SEP]']
[Init] best perm rec loss: 1.820723295211792 for ['[CLS] standing scheduled looksflies for visitor drink appear artifact k independent allergic amulet gardens italian thomas romance razor [SEP]']
[Init] best perm rec loss: 1.8203189373016357 for ['[CLS] scheduled for appear thomas artifact looks independent k razor amulet gardens allergic drink visitorflies italian romance standing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.803 (perp=10.944, rec=0.470, cos=0.144), tot_loss_proj:4.084 [t=0.19s]
prediction: ['[CLS] ‘ exchange payment boy to little happiness mary! mary judaism evaluation volunteer [SEP] stepping surf drama my [SEP]']
[ 100/2000] tot_loss=2.792 (perp=11.938, rec=0.341, cos=0.063), tot_loss_proj:4.256 [t=0.19s]
prediction: ['[CLS] consciousness armenian john go to suelence john from records giving records officer. liner adjective the old [SEP]']
[ 150/2000] tot_loss=2.413 (perp=10.683, rec=0.254, cos=0.022), tot_loss_proj:4.107 [t=0.19s]
prediction: ['[CLS] consciousness sue john go for christmas books sue from records christmas records collected the sue records the old [SEP]']
[ 200/2000] tot_loss=2.145 (perp=9.469, rec=0.234, cos=0.017), tot_loss_proj:3.853 [t=0.19s]
prediction: ['[CLS] developed sue mary at for christmas books sue from records christmas records records the sue records the : [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.317 (perp=9.709, rec=0.822, cos=0.553), tot_loss_proj:3.830 [t=0.23s]
prediction: ['[CLS] arranged sue mary christmas from to the records sue records christmas books his the christmas records and table [SEP]']
[ 300/2000] tot_loss=2.482 (perp=10.617, rec=0.309, cos=0.049), tot_loss_proj:3.925 [t=0.18s]
prediction: ['[CLS] arranged sue mary she from to john records sue gave with books their the album records and hi [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.363 (perp=10.493, rec=0.241, cos=0.023), tot_loss_proj:3.945 [t=0.19s]
prediction: ['[CLS] for sue mary apples arranged to john records sue gave ( books their the album records and hi [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.327 (perp=10.498, rec=0.211, cos=0.017), tot_loss_proj:3.968 [t=0.28s]
prediction: ['[CLS] for sue books apples arranged to john records sue gave ( mary their the album records and hi [SEP]']
[ 450/2000] tot_loss=2.187 (perp=9.945, rec=0.186, cos=0.012), tot_loss_proj:3.848 [t=0.21s]
prediction: ['[CLS] for sue books christmas arranged to john records sue gave to mary their the records records and hi [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.038 (perp=9.301, rec=0.168, cos=0.009), tot_loss_proj:3.816 [t=0.27s]
prediction: ['[CLS] for hi books christmas the to john records sue gave to mary their the records records and sue [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.792 (perp=8.110, rec=0.162, cos=0.009), tot_loss_proj:3.564 [t=0.18s]
prediction: ['[CLS] for hi books to christmas the john records john gave to mary their the records records and sue [SEP]']
[ 600/2000] tot_loss=1.917 (perp=8.721, rec=0.165, cos=0.008), tot_loss_proj:3.615 [t=0.19s]
prediction: ['[CLS] sue hi books to christmas the birthday records john gave to mary at the records records and sue [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.679 (perp=7.595, rec=0.152, cos=0.008), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS] sue records books to christmas the mary records john gave to mary at the hi records and sue [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.596 (perp=7.221, rec=0.144, cos=0.008), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] mary records books to christmas the birthday records john gave to sue at the hi records and sue [SEP]']
[ 750/2000] tot_loss=1.595 (perp=7.221, rec=0.144, cos=0.007), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] mary records books to christmas the birthday records john gave to sue at the hi records and sue [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.563 (perp=7.088, rec=0.138, cos=0.007), tot_loss_proj:3.361 [t=0.18s]
prediction: ['[CLS] mary records books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.563 (perp=7.088, rec=0.139, cos=0.007), tot_loss_proj:3.362 [t=0.18s]
prediction: ['[CLS] mary records books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
[ 900/2000] tot_loss=1.556 (perp=7.088, rec=0.132, cos=0.006), tot_loss_proj:3.361 [t=0.18s]
prediction: ['[CLS] mary records books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.550 (perp=7.088, rec=0.126, cos=0.006), tot_loss_proj:3.363 [t=0.25s]
prediction: ['[CLS] mary records books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
[1000/2000] tot_loss=1.555 (perp=7.088, rec=0.131, cos=0.006), tot_loss_proj:3.361 [t=0.18s]
prediction: ['[CLS] mary records books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
[1050/2000] tot_loss=1.548 (perp=7.088, rec=0.124, cos=0.006), tot_loss_proj:3.364 [t=0.18s]
prediction: ['[CLS] mary records books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
[1100/2000] tot_loss=1.544 (perp=7.088, rec=0.120, cos=0.006), tot_loss_proj:3.365 [t=0.18s]
prediction: ['[CLS] mary records books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
[1150/2000] tot_loss=1.551 (perp=7.088, rec=0.127, cos=0.006), tot_loss_proj:3.360 [t=0.19s]
prediction: ['[CLS] mary records books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
[1200/2000] tot_loss=1.540 (perp=7.088, rec=0.117, cos=0.006), tot_loss_proj:3.360 [t=0.19s]
prediction: ['[CLS] mary records books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
[1250/2000] tot_loss=1.544 (perp=7.088, rec=0.121, cos=0.006), tot_loss_proj:3.362 [t=0.22s]
prediction: ['[CLS] mary records books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.584 (perp=7.301, rec=0.118, cos=0.006), tot_loss_proj:3.387 [t=0.27s]
prediction: ['[CLS] birthday mary books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
[1350/2000] tot_loss=1.573 (perp=7.301, rec=0.106, cos=0.006), tot_loss_proj:3.390 [t=0.20s]
prediction: ['[CLS] birthday mary books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
[1400/2000] tot_loss=1.586 (perp=7.301, rec=0.119, cos=0.006), tot_loss_proj:3.388 [t=0.18s]
prediction: ['[CLS] birthday mary books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
[1450/2000] tot_loss=1.580 (perp=7.301, rec=0.113, cos=0.006), tot_loss_proj:3.390 [t=0.19s]
prediction: ['[CLS] birthday mary books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
[1500/2000] tot_loss=1.583 (perp=7.301, rec=0.117, cos=0.006), tot_loss_proj:3.386 [t=0.20s]
prediction: ['[CLS] birthday mary books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
[1550/2000] tot_loss=1.583 (perp=7.301, rec=0.116, cos=0.006), tot_loss_proj:3.389 [t=0.19s]
prediction: ['[CLS] birthday mary books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
Attempt swap
[1600/2000] tot_loss=1.601 (perp=7.381, rec=0.118, cos=0.007), tot_loss_proj:3.425 [t=0.19s]
prediction: ['[CLS] birthday john books records to christmas the birthday john gave to sue at the hi records and sue [SEP]']
[1650/2000] tot_loss=1.633 (perp=7.577, rec=0.111, cos=0.007), tot_loss_proj:3.456 [t=0.23s]
prediction: ['[CLS] birthday john books records to christmas the birthday john gave to mary at the hi records and sue [SEP]']
Attempt swap
[1700/2000] tot_loss=1.641 (perp=7.577, rec=0.119, cos=0.007), tot_loss_proj:3.455 [t=0.19s]
prediction: ['[CLS] birthday john books records to christmas the birthday john gave to mary at the hi records and sue [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.569 (perp=7.215, rec=0.118, cos=0.007), tot_loss_proj:3.352 [t=0.19s]
prediction: ['[CLS] birthday mary books records to christmas the birthday john gave to john at the hi records and sue [SEP]']
[1800/2000] tot_loss=1.576 (perp=7.287, rec=0.112, cos=0.007), tot_loss_proj:3.374 [t=0.19s]
prediction: ['[CLS] birthday mary books records to christmas the birthday john gave to mary at the hi records and sue [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.555 (perp=7.176, rec=0.113, cos=0.007), tot_loss_proj:3.363 [t=0.18s]
prediction: ['[CLS] birthday mary records books to christmas the birthday john gave to mary at the hi records and sue [SEP]']
Attempt swap
[1900/2000] tot_loss=1.535 (perp=7.103, rec=0.108, cos=0.007), tot_loss_proj:3.336 [t=0.19s]
prediction: ['[CLS] birthday mary records books to christmas the birthday john gave to john at the hi records and sue [SEP]']
[1950/2000] tot_loss=1.539 (perp=7.103, rec=0.112, cos=0.007), tot_loss_proj:3.335 [t=0.24s]
prediction: ['[CLS] birthday mary records books to christmas the birthday john gave to john at the hi records and sue [SEP]']
Attempt swap
[2000/2000] tot_loss=1.542 (perp=7.103, rec=0.115, cos=0.007), tot_loss_proj:3.336 [t=0.27s]
prediction: ['[CLS] birthday mary records books to christmas the birthday john gave to john at the hi records and sue [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] john gave the books to mary at christmas, and the records to sue for her birthday. [SEP]
========================
predicted: 
========================
[CLS] birthday mary records books to christmas the birthday john gave to john at the hi records and sue [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 11.111 | p: 10.526 | r: 11.765
rougeL     | fm: 47.368 | p: 45.000 | r: 50.000
rougeLsum  | fm: 47.368 | p: 45.000 | r: 50.000
r1fm+r2fm = 95.322

[Aggregate metrics]:
rouge1     | fm: 81.479 | p: 80.986 | r: 82.253
rouge2     | fm: 38.015 | p: 37.804 | r: 38.370
rougeL     | fm: 67.834 | p: 67.425 | r: 68.386
rougeLsum  | fm: 68.078 | p: 67.660 | r: 68.642
r1fm+r2fm = 119.494

input #52 time: 0:08:12 | total time: 7:26:40


Running input #53 of 100.
reference: 
========================
He said that himself was hungry.
========================
average of cosine similarity 0.9993481863787018
highest_index [0]
highest [0.9993481863787018]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2056, 2008, 2370, 2001, 7501, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he said that himself was hungry. [SEP]']
[Init] best rec loss: 1.6381171941757202 for ['[CLS] syncoc youth also returning jaguar flower [SEP]']
[Init] best rec loss: 1.4328124523162842 for ['[CLS] terms expireditanupt racing everuating [SEP]']
[Init] best rec loss: 1.3335953950881958 for ['[CLS] these once ofents intensive course vu [SEP]']
[Init] best rec loss: 1.1913394927978516 for ['[CLS] maha proof off experience occupation award advance [SEP]']
[Init] best rec loss: 1.096117377281189 for ['[CLS] house chi browningchia himalayan audience appeal [SEP]']
[Init] best rec loss: 1.047861099243164 for ['[CLS] program flowers abs havingting cost script [SEP]']
[Init] best rec loss: 0.9650077819824219 for ['[CLS] gravel shooter promotion rios press eve voyage [SEP]']
[Init] best perm rec loss: 0.9645376801490784 for ['[CLS] gravel eve promotion voyage press rios shooter [SEP]']
[Init] best perm rec loss: 0.9610859155654907 for ['[CLS] gravel eve rios voyage promotion press shooter [SEP]']
[Init] best perm rec loss: 0.9600293040275574 for ['[CLS] gravel eve press rios promotion shooter voyage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.058 (perp=8.817, rec=0.285, cos=0.010), tot_loss_proj:2.735 [t=0.19s]
prediction: ['[CLS] duke, himself was i hungry was [SEP]']
[ 100/2000] tot_loss=1.802 (perp=8.000, rec=0.195, cos=0.006), tot_loss_proj:2.147 [t=0.19s]
prediction: ['[CLS] said. himself was said hungry himself [SEP]']
[ 150/2000] tot_loss=1.356 (perp=6.233, rec=0.104, cos=0.005), tot_loss_proj:1.685 [t=0.18s]
prediction: ['[CLS] said that himself was said hungry. [SEP]']
[ 200/2000] tot_loss=1.347 (perp=6.233, rec=0.096, cos=0.004), tot_loss_proj:1.680 [t=0.19s]
prediction: ['[CLS] said that himself was said hungry. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.006 (perp=4.646, rec=0.073, cos=0.004), tot_loss_proj:1.032 [t=0.24s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 300/2000] tot_loss=1.010 (perp=4.646, rec=0.077, cos=0.004), tot_loss_proj:1.040 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.007 (perp=4.646, rec=0.074, cos=0.004), tot_loss_proj:1.035 [t=0.19s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.004 (perp=4.646, rec=0.071, cos=0.004), tot_loss_proj:1.044 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 450/2000] tot_loss=1.005 (perp=4.646, rec=0.072, cos=0.003), tot_loss_proj:1.023 [t=0.22s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 500/2000] tot_loss=0.987 (perp=4.646, rec=0.054, cos=0.003), tot_loss_proj:1.026 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.009 (perp=4.646, rec=0.077, cos=0.003), tot_loss_proj:1.035 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 600/2000] tot_loss=1.005 (perp=4.646, rec=0.072, cos=0.003), tot_loss_proj:1.039 [t=0.19s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.002 (perp=4.646, rec=0.070, cos=0.003), tot_loss_proj:1.022 [t=0.28s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.995 (perp=4.646, rec=0.062, cos=0.003), tot_loss_proj:1.033 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 750/2000] tot_loss=1.011 (perp=4.646, rec=0.078, cos=0.003), tot_loss_proj:1.043 [t=0.27s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.999 (perp=4.646, rec=0.067, cos=0.003), tot_loss_proj:1.037 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.006 (perp=4.646, rec=0.073, cos=0.003), tot_loss_proj:1.034 [t=0.26s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[ 900/2000] tot_loss=0.998 (perp=4.646, rec=0.066, cos=0.003), tot_loss_proj:1.035 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.008 (perp=4.646, rec=0.075, cos=0.003), tot_loss_proj:1.040 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.987 (perp=4.646, rec=0.054, cos=0.003), tot_loss_proj:1.039 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1050/2000] tot_loss=1.007 (perp=4.646, rec=0.074, cos=0.003), tot_loss_proj:1.046 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.015 (perp=4.646, rec=0.083, cos=0.003), tot_loss_proj:1.036 [t=0.25s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.010 (perp=4.646, rec=0.077, cos=0.003), tot_loss_proj:1.038 [t=0.19s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1200/2000] tot_loss=0.994 (perp=4.646, rec=0.062, cos=0.003), tot_loss_proj:1.037 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.998 (perp=4.646, rec=0.065, cos=0.003), tot_loss_proj:1.029 [t=0.26s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.993 (perp=4.646, rec=0.060, cos=0.003), tot_loss_proj:1.030 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1350/2000] tot_loss=0.988 (perp=4.646, rec=0.056, cos=0.003), tot_loss_proj:1.033 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.993 (perp=4.646, rec=0.060, cos=0.003), tot_loss_proj:1.036 [t=0.19s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.002 (perp=4.646, rec=0.069, cos=0.003), tot_loss_proj:1.027 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1500/2000] tot_loss=0.994 (perp=4.646, rec=0.062, cos=0.003), tot_loss_proj:1.041 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.000 (perp=4.646, rec=0.068, cos=0.003), tot_loss_proj:1.041 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.008 (perp=4.646, rec=0.075, cos=0.003), tot_loss_proj:1.039 [t=0.21s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1650/2000] tot_loss=0.994 (perp=4.646, rec=0.061, cos=0.003), tot_loss_proj:1.040 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.002 (perp=4.646, rec=0.070, cos=0.003), tot_loss_proj:1.036 [t=0.22s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.992 (perp=4.646, rec=0.059, cos=0.003), tot_loss_proj:1.037 [t=0.21s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1800/2000] tot_loss=0.993 (perp=4.646, rec=0.061, cos=0.003), tot_loss_proj:1.035 [t=0.21s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.998 (perp=4.646, rec=0.066, cos=0.003), tot_loss_proj:1.037 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.999 (perp=4.646, rec=0.067, cos=0.003), tot_loss_proj:1.031 [t=0.20s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
[1950/2000] tot_loss=1.007 (perp=4.646, rec=0.075, cos=0.003), tot_loss_proj:1.031 [t=0.28s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.004 (perp=4.646, rec=0.071, cos=0.003), tot_loss_proj:1.039 [t=0.18s]
prediction: ['[CLS] he said that himself was hungry. [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] he said that himself was hungry. [SEP]
========================
predicted: 
========================
[CLS] he said that himself was hungry. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.857 | p: 81.385 | r: 82.602
rouge2     | fm: 39.075 | p: 38.826 | r: 39.456
rougeL     | fm: 68.529 | p: 68.170 | r: 69.055
rougeLsum  | fm: 68.682 | p: 68.355 | r: 69.159
r1fm+r2fm = 120.931

input #53 time: 0:08:08 | total time: 7:34:49


Running input #54 of 100.
reference: 
========================
After reading the pamphlet, Judy threw them into the garbage can.
========================
average of cosine similarity 0.9993882826053118
highest_index [0]
highest [0.9993882826053118]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  2044,  3752,  1996, 19899,  1010, 12120,  4711,  2068,  2046,
          1996, 13044,  2064,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]']
[Init] best rec loss: 1.884690761566162 for ['[CLS]position unavailable reporter wink zero do leaning double declared temple swift 2012 fine [SEP]']
[Init] best rec loss: 1.8572546243667603 for ['[CLS] surgeons working district horatio pot rt small an paleframe festival veteran past [SEP]']
[Init] best rec loss: 1.8414102792739868 for ['[CLS] edward gwen daily ever consideredards erminafar quad river given why [SEP]']
[Init] best rec loss: 1.8387538194656372 for ['[CLS] fightjetboard men cody snorted yorkergraphy with 2010ize lucas hannah [SEP]']
[Init] best rec loss: 1.8383187055587769 for ['[CLS] planeiculate republican millie last dates plates up emissions conversion rags vice carry [SEP]']
[Init] best rec loss: 1.8293144702911377 for ['[CLS] soldier brute editorial sharing avant perspective heard classicate each tor has meant [SEP]']
[Init] best rec loss: 1.8210548162460327 for ['[CLS] imagery departed meanwhile trackswig threatimated worthfer balfour because compound reader [SEP]']
[Init] best perm rec loss: 1.8207454681396484 for ['[CLS] compound departed reader threat balfour trackswig worthferimated because imagery meanwhile [SEP]']
[Init] best perm rec loss: 1.8187906742095947 for ['[CLS] compoundimated departed tracks imagery becausewig balfourfer worth threat meanwhile reader [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.275 (perp=13.514, rec=0.605, cos=0.967), tot_loss_proj:4.731 [t=0.18s]
prediction: ['[CLS] lacey defined surface eps strategy hits became added socket indices houston barbie trans [SEP]']
[ 100/2000] tot_loss=2.833 (perp=12.096, rec=0.348, cos=0.066), tot_loss_proj:4.318 [t=0.18s]
prediction: ['[CLS] they opera of shortlisted them garbage them them : midtown caused beans reading [SEP]']
[ 150/2000] tot_loss=2.684 (perp=12.114, rec=0.232, cos=0.029), tot_loss_proj:4.318 [t=0.22s]
prediction: ['[CLS] merely opera judy reading pamphlet pamphlet them them : underway blew eggs reading [SEP]']
[ 200/2000] tot_loss=2.785 (perp=13.046, rec=0.164, cos=0.012), tot_loss_proj:4.468 [t=0.19s]
prediction: ['[CLS] after coward judy reading pamphlet pamphlet them them in into threw garbage pamphlet [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=4.187 (perp=12.281, rec=0.858, cos=0.873), tot_loss_proj:4.365 [t=0.20s]
prediction: ['[CLS] jenks them [SEP] reading temeraire pamphlet coward them sparsely quotes threw. the [SEP]']
[ 300/2000] tot_loss=3.774 (perp=10.662, rec=0.710, cos=0.932), tot_loss_proj:3.977 [t=0.18s]
prediction: ['[CLS] dipped them had reading gossip pamphlet week them sparsely drinking gave. the [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.794 (perp=11.218, rec=0.554, cos=0.997), tot_loss_proj:4.133 [t=0.18s]
prediction: ['[CLS] quiet them guild reading tonight pamphlet the engineering them retirement drinking gave. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.566 (perp=10.004, rec=0.567, cos=0.998), tot_loss_proj:3.868 [t=0.25s]
prediction: ['[CLS] dipped them pamphlet reading tonight glancing the heart them retirement onto gave. [SEP]']
[ 450/2000] tot_loss=3.780 (perp=11.561, rec=0.467, cos=1.000), tot_loss_proj:4.241 [t=0.18s]
prediction: ['[CLS] delaney them pamphlet reading tonightwo the heart them display onto gave. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.472 (perp=10.126, rec=0.448, cos=0.999), tot_loss_proj:3.941 [t=0.26s]
prediction: ['[CLS] once them pamphlet reading greedwo the heart them display onto delaney. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.506 (perp=10.420, rec=0.425, cos=0.997), tot_loss_proj:4.035 [t=0.18s]
prediction: ['[CLS] turned them pamphlet reading greedwo the heart them display onto delaney. [SEP]']
[ 600/2000] tot_loss=3.486 (perp=10.420, rec=0.405, cos=0.997), tot_loss_proj:4.041 [t=0.18s]
prediction: ['[CLS] turned them pamphlet reading greedwo the heart them display onto delaney. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.480 (perp=10.420, rec=0.400, cos=0.997), tot_loss_proj:4.039 [t=0.19s]
prediction: ['[CLS] turned them pamphlet reading greedwo the heart them display onto delaney. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.569 (perp=10.379, rec=0.493, cos=1.000), tot_loss_proj:3.985 [t=0.21s]
prediction: ['[CLS]naire them pamphlet ᵘ reading perfume the heart them display into delaney. [SEP]']
[ 750/2000] tot_loss=3.529 (perp=10.589, rec=0.413, cos=0.998), tot_loss_proj:4.010 [t=0.24s]
prediction: ['[CLS] published them pamphlet ᵘ reading cynthia the chart them display into delaney. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.522 (perp=10.570, rec=0.411, cos=0.997), tot_loss_proj:4.015 [t=0.21s]
prediction: ['[CLS] turned them pamphlet ᵘ reading. the chart them display into delaney perfume [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.317 (perp=9.683, rec=0.385, cos=0.996), tot_loss_proj:3.931 [t=0.18s]
prediction: ['[CLS] turned them pamphlet ᵘ reading. the chart marlon them into narrow greed [SEP]']
[ 900/2000] tot_loss=3.329 (perp=9.749, rec=0.385, cos=0.995), tot_loss_proj:3.824 [t=0.18s]
prediction: ['[CLS] turned them pamphlet threw reading. the chart marlon them into narrow greed [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.245 (perp=9.385, rec=0.374, cos=0.993), tot_loss_proj:3.766 [t=0.32s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1000/2000] tot_loss=3.240 (perp=9.385, rec=0.370, cos=0.993), tot_loss_proj:3.764 [t=0.19s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
[1050/2000] tot_loss=3.231 (perp=9.385, rec=0.362, cos=0.992), tot_loss_proj:3.765 [t=0.30s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1100/2000] tot_loss=3.231 (perp=9.385, rec=0.362, cos=0.991), tot_loss_proj:3.765 [t=0.18s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1150/2000] tot_loss=3.230 (perp=9.385, rec=0.362, cos=0.991), tot_loss_proj:3.761 [t=0.24s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
[1200/2000] tot_loss=3.221 (perp=9.385, rec=0.353, cos=0.990), tot_loss_proj:3.765 [t=0.26s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1250/2000] tot_loss=3.219 (perp=9.385, rec=0.351, cos=0.990), tot_loss_proj:3.763 [t=0.19s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1300/2000] tot_loss=3.217 (perp=9.385, rec=0.351, cos=0.990), tot_loss_proj:3.768 [t=0.28s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
[1350/2000] tot_loss=3.215 (perp=9.385, rec=0.348, cos=0.989), tot_loss_proj:3.762 [t=0.29s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1400/2000] tot_loss=3.210 (perp=9.385, rec=0.344, cos=0.989), tot_loss_proj:3.762 [t=0.18s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1450/2000] tot_loss=3.205 (perp=9.385, rec=0.339, cos=0.989), tot_loss_proj:3.762 [t=0.19s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
[1500/2000] tot_loss=3.213 (perp=9.385, rec=0.347, cos=0.989), tot_loss_proj:3.763 [t=0.23s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1550/2000] tot_loss=3.210 (perp=9.385, rec=0.344, cos=0.989), tot_loss_proj:3.764 [t=0.18s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1600/2000] tot_loss=3.204 (perp=9.385, rec=0.338, cos=0.989), tot_loss_proj:3.764 [t=0.25s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
[1650/2000] tot_loss=3.206 (perp=9.385, rec=0.340, cos=0.988), tot_loss_proj:3.768 [t=0.18s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1700/2000] tot_loss=3.212 (perp=9.385, rec=0.346, cos=0.988), tot_loss_proj:3.764 [t=0.19s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1750/2000] tot_loss=3.202 (perp=9.385, rec=0.337, cos=0.988), tot_loss_proj:3.762 [t=0.18s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
[1800/2000] tot_loss=3.202 (perp=9.385, rec=0.337, cos=0.988), tot_loss_proj:3.766 [t=0.18s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1850/2000] tot_loss=3.214 (perp=9.385, rec=0.349, cos=0.988), tot_loss_proj:3.768 [t=0.21s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow greed [SEP]']
Attempt swap
[1900/2000] tot_loss=3.271 (perp=9.710, rec=0.341, cos=0.988), tot_loss_proj:3.819 [t=0.19s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow randolph [SEP]']
[1950/2000] tot_loss=3.262 (perp=9.710, rec=0.331, cos=0.988), tot_loss_proj:3.821 [t=0.25s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow randolph [SEP]']
Attempt swap
[2000/2000] tot_loss=3.266 (perp=9.710, rec=0.336, cos=0.988), tot_loss_proj:3.822 [t=0.21s]
prediction: ['[CLS] turned them pamphlet. reading threw the chart marlon them into narrow randolph [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] after reading the pamphlet, judy threw them into the garbage can. [SEP]
========================
predicted: 
========================
[CLS] after coward judy reading pamphlet pamphlet them them in into threw garbage reading [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 66.667 | r: 76.923
rouge2     | fm: 7.692 | p: 7.143 | r: 8.333
rougeL     | fm: 57.143 | p: 53.333 | r: 61.538
rougeLsum  | fm: 57.143 | p: 53.333 | r: 61.538
r1fm+r2fm = 79.121

[Aggregate metrics]:
rouge1     | fm: 81.715 | p: 81.212 | r: 82.507
rouge2     | fm: 38.661 | p: 38.297 | r: 39.054
rougeL     | fm: 68.256 | p: 67.849 | r: 68.853
rougeLsum  | fm: 68.491 | p: 68.111 | r: 69.119
r1fm+r2fm = 120.376

input #54 time: 0:08:18 | total time: 7:43:08


Running input #55 of 100.
reference: 
========================
Collapsed Harry.
========================
average of cosine similarity 0.9993911323857784
highest_index [0]
highest [0.9993911323857784]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 7798, 4302, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] collapsed harry. [SEP]']
[Init] best rec loss: 1.7179925441741943 for ['[CLS] taken dana once [SEP]']
[Init] best rec loss: 1.1426339149475098 for ['[CLS] lowest black therefore [SEP]']
[Init] best rec loss: 1.0830011367797852 for ['[CLS] these how conditioning [SEP]']
[Init] best rec loss: 0.9772200584411621 for ['[CLS] assistantmymg [SEP]']
[Init] best perm rec loss: 0.9742582440376282 for ['[CLS]my assistantmg [SEP]']
[Init] best perm rec loss: 0.9694965481758118 for ['[CLS]mgmy assistant [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.763 (perp=11.840, rec=0.319, cos=0.077), tot_loss_proj:3.293 [t=0.17s]
prediction: ['[CLS] collapsed crazy season [SEP]']
[ 100/2000] tot_loss=2.637 (perp=12.011, rec=0.205, cos=0.029), tot_loss_proj:3.084 [t=0.18s]
prediction: ['[CLS] collapsed harry ghost [SEP]']
[ 150/2000] tot_loss=2.617 (perp=12.011, rec=0.173, cos=0.042), tot_loss_proj:3.085 [t=0.18s]
prediction: ['[CLS] collapsed harry ghost [SEP]']
[ 200/2000] tot_loss=2.604 (perp=12.011, rec=0.159, cos=0.043), tot_loss_proj:3.059 [t=0.18s]
prediction: ['[CLS] collapsed harry ghost [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.528 (perp=12.011, rec=0.113, cos=0.012), tot_loss_proj:3.054 [t=0.18s]
prediction: ['[CLS] collapsed harry ghost [SEP]']
[ 300/2000] tot_loss=2.778 (perp=13.327, rec=0.103, cos=0.010), tot_loss_proj:3.426 [t=0.20s]
prediction: ['[CLS] collapsed harry rat [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.849 (perp=8.635, rec=0.111, cos=0.011), tot_loss_proj:3.490 [t=0.18s]
prediction: ['[CLS] collapsed, harry [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.002 (perp=9.472, rec=0.100, cos=0.008), tot_loss_proj:3.907 [t=0.25s]
prediction: ['[CLS] collapsed. harry [SEP]']
[ 450/2000] tot_loss=1.990 (perp=9.472, rec=0.088, cos=0.008), tot_loss_proj:3.913 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.983 (perp=9.472, rec=0.082, cos=0.007), tot_loss_proj:3.911 [t=0.21s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.993 (perp=9.472, rec=0.092, cos=0.007), tot_loss_proj:3.912 [t=0.22s]
prediction: ['[CLS] collapsed. harry [SEP]']
[ 600/2000] tot_loss=1.991 (perp=9.472, rec=0.090, cos=0.007), tot_loss_proj:3.905 [t=0.21s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.992 (perp=9.472, rec=0.091, cos=0.006), tot_loss_proj:3.909 [t=0.19s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.992 (perp=9.472, rec=0.091, cos=0.006), tot_loss_proj:3.911 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
[ 750/2000] tot_loss=2.001 (perp=9.472, rec=0.100, cos=0.006), tot_loss_proj:3.905 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.993 (perp=9.472, rec=0.093, cos=0.006), tot_loss_proj:3.910 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.996 (perp=9.472, rec=0.095, cos=0.006), tot_loss_proj:3.904 [t=0.21s]
prediction: ['[CLS] collapsed. harry [SEP]']
[ 900/2000] tot_loss=1.978 (perp=9.472, rec=0.078, cos=0.006), tot_loss_proj:3.903 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.984 (perp=9.472, rec=0.084, cos=0.006), tot_loss_proj:3.907 [t=0.20s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1000/2000] tot_loss=1.988 (perp=9.472, rec=0.088, cos=0.006), tot_loss_proj:3.909 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
[1050/2000] tot_loss=1.997 (perp=9.472, rec=0.096, cos=0.006), tot_loss_proj:3.898 [t=0.24s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1100/2000] tot_loss=1.994 (perp=9.472, rec=0.094, cos=0.006), tot_loss_proj:3.902 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1150/2000] tot_loss=1.983 (perp=9.472, rec=0.082, cos=0.006), tot_loss_proj:3.901 [t=0.19s]
prediction: ['[CLS] collapsed. harry [SEP]']
[1200/2000] tot_loss=1.983 (perp=9.472, rec=0.084, cos=0.005), tot_loss_proj:3.899 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1250/2000] tot_loss=1.965 (perp=9.472, rec=0.068, cos=0.003), tot_loss_proj:3.894 [t=0.25s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1300/2000] tot_loss=1.971 (perp=9.472, rec=0.075, cos=0.002), tot_loss_proj:3.901 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
[1350/2000] tot_loss=1.961 (perp=9.472, rec=0.065, cos=0.002), tot_loss_proj:3.899 [t=0.20s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1400/2000] tot_loss=1.957 (perp=9.472, rec=0.061, cos=0.002), tot_loss_proj:3.898 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1450/2000] tot_loss=1.961 (perp=9.472, rec=0.065, cos=0.001), tot_loss_proj:3.889 [t=0.29s]
prediction: ['[CLS] collapsed. harry [SEP]']
[1500/2000] tot_loss=1.963 (perp=9.472, rec=0.067, cos=0.001), tot_loss_proj:3.897 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1550/2000] tot_loss=1.957 (perp=9.472, rec=0.061, cos=0.001), tot_loss_proj:3.901 [t=0.19s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1600/2000] tot_loss=1.966 (perp=9.472, rec=0.070, cos=0.001), tot_loss_proj:3.896 [t=0.23s]
prediction: ['[CLS] collapsed. harry [SEP]']
[1650/2000] tot_loss=1.964 (perp=9.472, rec=0.068, cos=0.001), tot_loss_proj:3.899 [t=0.20s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1700/2000] tot_loss=1.963 (perp=9.472, rec=0.067, cos=0.001), tot_loss_proj:3.894 [t=0.25s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1750/2000] tot_loss=1.962 (perp=9.472, rec=0.067, cos=0.001), tot_loss_proj:3.895 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
[1800/2000] tot_loss=1.965 (perp=9.472, rec=0.069, cos=0.001), tot_loss_proj:3.892 [t=0.20s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1850/2000] tot_loss=1.969 (perp=9.472, rec=0.074, cos=0.001), tot_loss_proj:3.890 [t=0.23s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[1900/2000] tot_loss=1.950 (perp=9.472, rec=0.054, cos=0.001), tot_loss_proj:3.893 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
[1950/2000] tot_loss=1.967 (perp=9.472, rec=0.071, cos=0.001), tot_loss_proj:3.895 [t=0.19s]
prediction: ['[CLS] collapsed. harry [SEP]']
Attempt swap
[2000/2000] tot_loss=1.971 (perp=9.472, rec=0.076, cos=0.001), tot_loss_proj:3.884 [t=0.18s]
prediction: ['[CLS] collapsed. harry [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] collapsed harry. [SEP]
========================
predicted: 
========================
[CLS] collapsed. harry [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.939 | p: 81.488 | r: 82.731
rouge2     | fm: 39.675 | p: 39.514 | r: 39.965
rougeL     | fm: 68.976 | p: 68.493 | r: 69.563
rougeLsum  | fm: 69.128 | p: 68.735 | r: 69.741
r1fm+r2fm = 121.613

input #55 time: 0:08:02 | total time: 7:51:10


Running input #56 of 100.
reference: 
========================
John was seeing his children.
========================
average of cosine similarity 0.9993522822859877
highest_index [0]
highest [0.9993522822859877]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2198, 2001, 3773, 2010, 2336, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] john was seeing his children. [SEP]']
[Init] best rec loss: 1.9047337770462036 for ['[CLS] vampire artists at like edge into [SEP]']
[Init] best rec loss: 1.7605843544006348 for ['[CLS] served show stood prof fellowsvocation [SEP]']
[Init] best rec loss: 1.7472879886627197 for ['[CLS] bracket fellow or wake32 shouldn [SEP]']
[Init] best rec loss: 1.7388708591461182 for ['[CLS] rest hair gettingtime motion found [SEP]']
[Init] best rec loss: 1.7322293519973755 for ['[CLS] anton effectity once wildlifeidae [SEP]']
[Init] best rec loss: 1.730926513671875 for ['[CLS] sense critically sphinx fear rugby accusing [SEP]']
[Init] best rec loss: 1.7122794389724731 for ['[CLS] dependentfarse hey claire sons [SEP]']
[Init] best rec loss: 1.683539628982544 for ['[CLS] jagger base foreign alaska congregation hobbs [SEP]']
[Init] best rec loss: 1.661874771118164 for ['[CLS]q promised everything watched hottest self [SEP]']
[Init] best perm rec loss: 1.6607229709625244 for ['[CLS]q hottest everything promised watched self [SEP]']
[Init] best perm rec loss: 1.6581897735595703 for ['[CLS] self everything promised hottestq watched [SEP]']
[Init] best perm rec loss: 1.6559139490127563 for ['[CLS] promised selfq watched hottest everything [SEP]']
[Init] best perm rec loss: 1.6554776430130005 for ['[CLS] hottest self promised watchedq everything [SEP]']
[Init] best perm rec loss: 1.6550865173339844 for ['[CLS] self promised watched hottestq everything [SEP]']
[Init] best perm rec loss: 1.654630422592163 for ['[CLS] self promised everything watchedq hottest [SEP]']
[Init] best perm rec loss: 1.6537848711013794 for ['[CLS] self promised hottest everythingq watched [SEP]']
[Init] best perm rec loss: 1.6531888246536255 for ['[CLS] hottest promised self everything watchedq [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.258 (perp=13.432, rec=0.463, cos=0.108), tot_loss_proj:4.548 [t=0.19s]
prediction: ['[CLS] paul kissed tyson jane abraham seeing [SEP]']
[ 100/2000] tot_loss=2.088 (perp=8.594, rec=0.338, cos=0.031), tot_loss_proj:3.422 [t=0.22s]
prediction: ['[CLS] john saw john john got. [SEP]']
[ 150/2000] tot_loss=2.010 (perp=8.594, rec=0.274, cos=0.017), tot_loss_proj:3.415 [t=0.19s]
prediction: ['[CLS] john saw john john got. [SEP]']
[ 200/2000] tot_loss=2.064 (perp=9.341, rec=0.185, cos=0.010), tot_loss_proj:3.582 [t=0.26s]
prediction: ['[CLS] john saw john children was seeing [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.928 (perp=7.788, rec=0.330, cos=0.041), tot_loss_proj:3.381 [t=0.18s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
[ 300/2000] tot_loss=1.776 (perp=7.788, rec=0.207, cos=0.012), tot_loss_proj:3.408 [t=0.19s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.729 (perp=7.788, rec=0.163, cos=0.008), tot_loss_proj:3.416 [t=0.19s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.716 (perp=7.788, rec=0.151, cos=0.008), tot_loss_proj:3.413 [t=0.18s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
[ 450/2000] tot_loss=1.714 (perp=7.788, rec=0.149, cos=0.007), tot_loss_proj:3.417 [t=0.19s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.696 (perp=7.788, rec=0.131, cos=0.007), tot_loss_proj:3.422 [t=0.18s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.700 (perp=7.788, rec=0.136, cos=0.007), tot_loss_proj:3.419 [t=0.18s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
[ 600/2000] tot_loss=1.701 (perp=7.788, rec=0.136, cos=0.007), tot_loss_proj:3.428 [t=0.21s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.687 (perp=7.788, rec=0.123, cos=0.007), tot_loss_proj:3.427 [t=0.20s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.680 (perp=7.788, rec=0.116, cos=0.007), tot_loss_proj:3.425 [t=0.19s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
[ 750/2000] tot_loss=1.684 (perp=7.788, rec=0.120, cos=0.006), tot_loss_proj:3.427 [t=0.18s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.664 (perp=7.788, rec=0.100, cos=0.006), tot_loss_proj:3.427 [t=0.19s]
prediction: ['[CLS] john seeing children was john seeing [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.950 (perp=9.165, rec=0.111, cos=0.006), tot_loss_proj:3.627 [t=0.19s]
prediction: ['[CLS] john seeing children was his seeing [SEP]']
[ 900/2000] tot_loss=1.951 (perp=9.165, rec=0.112, cos=0.006), tot_loss_proj:3.621 [t=0.20s]
prediction: ['[CLS] john seeing children was his seeing [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.592 (perp=7.376, rec=0.111, cos=0.005), tot_loss_proj:3.410 [t=0.29s]
prediction: ['[CLS] john seeing his children was seeing [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.525 (perp=7.061, rec=0.107, cos=0.006), tot_loss_proj:3.212 [t=0.19s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
[1050/2000] tot_loss=1.522 (perp=7.061, rec=0.104, cos=0.005), tot_loss_proj:3.208 [t=0.18s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1100/2000] tot_loss=1.508 (perp=7.061, rec=0.091, cos=0.005), tot_loss_proj:3.210 [t=0.26s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1150/2000] tot_loss=1.516 (perp=7.061, rec=0.098, cos=0.005), tot_loss_proj:3.206 [t=0.21s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
[1200/2000] tot_loss=1.504 (perp=7.061, rec=0.087, cos=0.005), tot_loss_proj:3.210 [t=0.18s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1250/2000] tot_loss=1.523 (perp=7.061, rec=0.106, cos=0.005), tot_loss_proj:3.210 [t=0.19s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1300/2000] tot_loss=1.517 (perp=7.061, rec=0.100, cos=0.005), tot_loss_proj:3.206 [t=0.18s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
[1350/2000] tot_loss=1.524 (perp=7.061, rec=0.107, cos=0.005), tot_loss_proj:3.211 [t=0.22s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1400/2000] tot_loss=1.509 (perp=7.061, rec=0.091, cos=0.005), tot_loss_proj:3.209 [t=0.20s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1450/2000] tot_loss=1.519 (perp=7.061, rec=0.101, cos=0.005), tot_loss_proj:3.205 [t=0.18s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
[1500/2000] tot_loss=1.521 (perp=7.061, rec=0.103, cos=0.005), tot_loss_proj:3.212 [t=0.21s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1550/2000] tot_loss=1.516 (perp=7.061, rec=0.098, cos=0.005), tot_loss_proj:3.208 [t=0.19s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1600/2000] tot_loss=1.515 (perp=7.061, rec=0.097, cos=0.005), tot_loss_proj:3.214 [t=0.19s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
[1650/2000] tot_loss=1.505 (perp=7.061, rec=0.088, cos=0.005), tot_loss_proj:3.205 [t=0.18s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1700/2000] tot_loss=1.519 (perp=7.061, rec=0.101, cos=0.005), tot_loss_proj:3.209 [t=0.19s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1750/2000] tot_loss=1.521 (perp=7.061, rec=0.104, cos=0.005), tot_loss_proj:3.207 [t=0.24s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
[1800/2000] tot_loss=1.499 (perp=7.061, rec=0.082, cos=0.005), tot_loss_proj:3.210 [t=0.18s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1850/2000] tot_loss=1.514 (perp=7.061, rec=0.097, cos=0.005), tot_loss_proj:3.208 [t=0.19s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[1900/2000] tot_loss=1.513 (perp=7.061, rec=0.096, cos=0.005), tot_loss_proj:3.208 [t=0.20s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
[1950/2000] tot_loss=1.512 (perp=7.061, rec=0.094, cos=0.005), tot_loss_proj:3.211 [t=0.19s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Attempt swap
[2000/2000] tot_loss=1.511 (perp=7.061, rec=0.093, cos=0.005), tot_loss_proj:3.204 [t=0.18s]
prediction: ['[CLS] john seeing his children seeing was [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] john was seeing his children. [SEP]
========================
predicted: 
========================
[CLS] john seeing his children seeing was [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 46.154 | p: 42.857 | r: 50.000
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 139.487

[Aggregate metrics]:
rouge1     | fm: 82.161 | p: 81.563 | r: 83.108
rouge2     | fm: 39.889 | p: 39.589 | r: 40.321
rougeL     | fm: 69.052 | p: 68.470 | r: 69.717
rougeLsum  | fm: 69.283 | p: 68.761 | r: 69.999
r1fm+r2fm = 122.050

input #56 time: 0:08:14 | total time: 7:59:25


Running input #57 of 100.
reference: 
========================
Carla mopped the floor under the furniture.
========================
average of cosine similarity 0.999410832505384
highest_index [0]
highest [0.999410832505384]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 17081,  9587, 11469,  1996,  2723,  2104,  1996,  7390,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] carla mopped the floor under the furniture. [SEP]']
[Init] best rec loss: 1.937060832977295 for ['[CLS]ne gathering do their health retirement go enforce things [SEP]']
[Init] best rec loss: 1.9333020448684692 for ['[CLS]je eight passedstand fit hospital watering ring hate [SEP]']
[Init] best rec loss: 1.8778849840164185 for ['[CLS]kes second loose late west allied creation utility evelyn [SEP]']
[Init] best rec loss: 1.8692553043365479 for ['[CLS] answer clinton fall meat test silk si job moving [SEP]']
[Init] best rec loss: 1.841779351234436 for ['[CLS] foot leave whatiidae togies hunt night lead [SEP]']
[Init] best rec loss: 1.8365228176116943 for ['[CLS] mark peak bowedbuilding kamhip shifterge evie [SEP]']
[Init] best perm rec loss: 1.835045337677002 for ['[CLS] kambuilding bowed markge peak evie shifterhip [SEP]']
[Init] best perm rec loss: 1.8349871635437012 for ['[CLS]building peakhip evie bowed mark shifterge kam [SEP]']
[Init] best perm rec loss: 1.8347430229187012 for ['[CLS] eviege shifterbuilding peak kamhip bowed mark [SEP]']
[Init] best perm rec loss: 1.8329956531524658 for ['[CLS]building kam evie shifter bowedge peakhip mark [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.115 (perp=12.203, rec=0.466, cos=0.209), tot_loss_proj:4.325 [t=0.18s]
prediction: ['[CLS] clean?▪ moose? walt jobsbright wolf [SEP]']
[ 100/2000] tot_loss=3.147 (perp=13.380, rec=0.385, cos=0.086), tot_loss_proj:4.555 [t=0.27s]
prediction: ['[CLS] clean begins carla lock truce jerryta brushed floor [SEP]']
[ 150/2000] tot_loss=2.897 (perp=12.301, rec=0.370, cos=0.067), tot_loss_proj:4.316 [t=0.23s]
prediction: ['[CLS] toe 2 carlaum upon glasstapped floor [SEP]']
[ 200/2000] tot_loss=2.626 (perp=11.754, rec=0.246, cos=0.029), tot_loss_proj:4.251 [t=0.21s]
prediction: ['[CLS] thee carla carla scotia×..pped floor [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.732 (perp=12.260, rec=0.250, cos=0.030), tot_loss_proj:4.287 [t=0.30s]
prediction: ['[CLS] tribe beside carla 2 dead ve.pped floor [SEP]']
[ 300/2000] tot_loss=3.008 (perp=13.814, rec=0.223, cos=0.022), tot_loss_proj:4.559 [t=0.19s]
prediction: ['[CLS] tallest beside carla carla mo ve.pped floor [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.944 (perp=13.208, rec=0.265, cos=0.038), tot_loss_proj:4.481 [t=0.18s]
prediction: ['[CLS] uncle beside carla inspectorberg hum vepped floor [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.907 (perp=12.358, rec=0.350, cos=0.085), tot_loss_proj:4.314 [t=0.18s]
prediction: ['[CLS] beside chamber carla inspector humberg tintedpped floor [SEP]']
[ 450/2000] tot_loss=2.905 (perp=13.083, rec=0.251, cos=0.038), tot_loss_proj:4.435 [t=0.18s]
prediction: ['[CLS] danny chamber carla inspector− jr drylypped floor [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.826 (perp=12.816, rec=0.233, cos=0.029), tot_loss_proj:4.441 [t=0.24s]
prediction: ['[CLS] inspector chamber carla danny− jr↔pped floor [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.987 (perp=13.413, rec=0.260, cos=0.045), tot_loss_proj:4.517 [t=0.26s]
prediction: ['[CLS] inspector beside carla multipped danny floor jr floor [SEP]']
[ 600/2000] tot_loss=2.754 (perp=12.589, rec=0.212, cos=0.025), tot_loss_proj:4.394 [t=0.23s]
prediction: ['[CLS] inspector beside carla mopped danny floor jr floor [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.563 (perp=11.645, rec=0.210, cos=0.024), tot_loss_proj:4.144 [t=0.18s]
prediction: ['[CLS] inspector beside carla floor mopped at jr floor [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.400 (perp=10.853, rec=0.207, cos=0.022), tot_loss_proj:3.973 [t=0.19s]
prediction: ['[CLS] inspector beside carla at mopped floor jr floor [SEP]']
[ 750/2000] tot_loss=2.393 (perp=10.853, rec=0.202, cos=0.021), tot_loss_proj:3.971 [t=0.18s]
prediction: ['[CLS] inspector beside carla at mopped floor jr floor [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.392 (perp=10.853, rec=0.202, cos=0.020), tot_loss_proj:3.972 [t=0.18s]
prediction: ['[CLS] inspector beside carla at mopped floor jr floor [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.376 (perp=10.560, rec=0.229, cos=0.034), tot_loss_proj:3.968 [t=0.21s]
prediction: ['[CLS] blue beside carla floor at mopped floor jr [SEP]']
[ 900/2000] tot_loss=2.501 (perp=11.382, rec=0.202, cos=0.022), tot_loss_proj:4.137 [t=0.20s]
prediction: ['[CLS] 00 beside carla floor at mopped floor jr [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.517 (perp=11.516, rec=0.193, cos=0.020), tot_loss_proj:4.142 [t=0.25s]
prediction: ['[CLS] carla under initially floor at mopped floor jr [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.320 (perp=10.532, rec=0.194, cos=0.020), tot_loss_proj:3.948 [t=0.18s]
prediction: ['[CLS] carla under floor initially at mopped floor jr [SEP]']
[1050/2000] tot_loss=2.310 (perp=10.532, rec=0.186, cos=0.018), tot_loss_proj:3.942 [t=0.18s]
prediction: ['[CLS] carla under floor initially at mopped floor jr [SEP]']
Attempt swap
[1100/2000] tot_loss=2.314 (perp=10.532, rec=0.191, cos=0.017), tot_loss_proj:3.946 [t=0.18s]
prediction: ['[CLS] carla under floor initially at mopped floor jr [SEP]']
Attempt swap
[1150/2000] tot_loss=2.309 (perp=10.528, rec=0.188, cos=0.016), tot_loss_proj:3.927 [t=0.23s]
prediction: ['[CLS] carla under floor chuck at mopped floor jr [SEP]']
[1200/2000] tot_loss=2.303 (perp=10.528, rec=0.182, cos=0.015), tot_loss_proj:3.922 [t=0.20s]
prediction: ['[CLS] carla under floor chuck at mopped floor jr [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.346 (perp=10.745, rec=0.181, cos=0.016), tot_loss_proj:3.948 [t=0.28s]
prediction: ['[CLS] carla under inspector floor at mopped floor furniture [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.309 (perp=10.521, rec=0.188, cos=0.017), tot_loss_proj:3.900 [t=0.19s]
prediction: ['[CLS] carla under inspector floor at furniture mopped floor [SEP]']
[1350/2000] tot_loss=2.288 (perp=10.521, rec=0.170, cos=0.015), tot_loss_proj:3.896 [t=0.18s]
prediction: ['[CLS] carla under inspector floor at furniture mopped floor [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.364 (perp=10.865, rec=0.177, cos=0.015), tot_loss_proj:3.979 [t=0.19s]
prediction: ['[CLS] carla under floor at furniture mopped 000 floor [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.262 (perp=10.343, rec=0.179, cos=0.014), tot_loss_proj:3.869 [t=0.24s]
prediction: ['[CLS] carla under floor at furniture mopped floor 000 [SEP]']
[1500/2000] tot_loss=2.259 (perp=10.343, rec=0.177, cos=0.013), tot_loss_proj:3.874 [t=0.25s]
prediction: ['[CLS] carla under floor at furniture mopped floor 000 [SEP]']
Attempt swap
[1550/2000] tot_loss=2.250 (perp=10.343, rec=0.169, cos=0.013), tot_loss_proj:3.869 [t=0.18s]
prediction: ['[CLS] carla under floor at furniture mopped floor 000 [SEP]']
Attempt swap
[1600/2000] tot_loss=2.208 (perp=10.097, rec=0.176, cos=0.012), tot_loss_proj:3.835 [t=0.18s]
prediction: ['[CLS] carla under floor at furniture mopped floor cox [SEP]']
[1650/2000] tot_loss=2.196 (perp=10.097, rec=0.165, cos=0.012), tot_loss_proj:3.841 [t=0.18s]
prediction: ['[CLS] carla under floor at furniture mopped floor cox [SEP]']
Attempt swap
[1700/2000] tot_loss=2.194 (perp=10.097, rec=0.163, cos=0.012), tot_loss_proj:3.838 [t=0.20s]
prediction: ['[CLS] carla under floor at furniture mopped floor cox [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.359 (perp=10.894, rec=0.167, cos=0.014), tot_loss_proj:3.986 [t=0.26s]
prediction: ['[CLS] carla under sheet floor at furniture mopped floor [SEP]']
[1800/2000] tot_loss=2.348 (perp=10.894, rec=0.157, cos=0.012), tot_loss_proj:3.982 [t=0.19s]
prediction: ['[CLS] carla under sheet floor at furniture mopped floor [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.110 (perp=9.655, rec=0.165, cos=0.014), tot_loss_proj:3.782 [t=0.18s]
prediction: ['[CLS] carla under floor at furniture sheet mopped floor [SEP]']
Attempt swap
[1900/2000] tot_loss=2.106 (perp=9.655, rec=0.162, cos=0.013), tot_loss_proj:3.786 [t=0.18s]
prediction: ['[CLS] carla under floor at furniture sheet mopped floor [SEP]']
[1950/2000] tot_loss=2.103 (perp=9.655, rec=0.159, cos=0.012), tot_loss_proj:3.780 [t=0.23s]
prediction: ['[CLS] carla under floor at furniture sheet mopped floor [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.051 (perp=9.380, rec=0.163, cos=0.013), tot_loss_proj:3.706 [t=0.18s]
prediction: ['[CLS] carla under floor sheet at furniture mopped floor [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] carla mopped the floor under the furniture. [SEP]
========================
predicted: 
========================
[CLS] carla under floor at furniture sheet mopped floor [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 70.000 | r: 77.778
rouge2     | fm: 11.765 | p: 11.111 | r: 12.500
rougeL     | fm: 52.632 | p: 50.000 | r: 55.556
rougeLsum  | fm: 52.632 | p: 50.000 | r: 55.556
r1fm+r2fm = 85.449

[Aggregate metrics]:
rouge1     | fm: 82.080 | p: 81.394 | r: 83.066
rouge2     | fm: 39.287 | p: 38.884 | r: 39.703
rougeL     | fm: 68.806 | p: 68.188 | r: 69.571
rougeLsum  | fm: 69.070 | p: 68.490 | r: 69.781
r1fm+r2fm = 121.367

input #57 time: 0:08:37 | total time: 8:08:02


Running input #58 of 100.
reference: 
========================
They expected us to should leave him.
========================
average of cosine similarity 0.9993178527703294
highest_index [0]
highest [0.9993178527703294]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2027, 3517, 2149, 2000, 2323, 2681, 2032, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] they expected us to should leave him. [SEP]']
[Init] best rec loss: 1.6914236545562744 for ['[CLS] like cal hazard far indiangence pair rolled [SEP]']
[Init] best rec loss: 1.5860739946365356 for ['[CLS] suit agent special small crack still try cases [SEP]']
[Init] best rec loss: 1.1096516847610474 for ['[CLS] michellevable moved lottery fold °f ask collectively [SEP]']
[Init] best rec loss: 1.0537365674972534 for ['[CLS] cartoon bastionional pulitzer implant camp assistance away [SEP]']
[Init] best rec loss: 1.048184871673584 for ['[CLS] around glinttangle recital purchase purchase pops says [SEP]']
[Init] best rec loss: 1.0459486246109009 for ['[CLS] foundation fame testament hell street talk [CLS] so [SEP]']
[Init] best rec loss: 1.0116829872131348 for ['[CLS] temporary gus belly sort detroit thansseword [SEP]']
[Init] best rec loss: 0.9972408413887024 for ['[CLS] mai institute sum allie apostolic redwoodrian corp [SEP]']
[Init] best perm rec loss: 0.9926648139953613 for ['[CLS] sum redwood corp apostolic allie mai instituterian [SEP]']
[Init] best perm rec loss: 0.9889511466026306 for ['[CLS] allierian institute mai redwood corp sum apostolic [SEP]']
[Init] best perm rec loss: 0.9864234924316406 for ['[CLS] redwood mai institute allie sumrian corp apostolic [SEP]']
[Init] best perm rec loss: 0.9856820702552795 for ['[CLS] sumrian redwood institute corp allie apostolic mai [SEP]']
[Init] best perm rec loss: 0.9853854775428772 for ['[CLS] redwoodrian mai allie corp institute sum apostolic [SEP]']
[Init] best perm rec loss: 0.9848899841308594 for ['[CLS] redwoodrian allie mai corp sum institute apostolic [SEP]']
[Init] best perm rec loss: 0.9844132661819458 for ['[CLS] redwood sum apostolic corp allie mai instituterian [SEP]']
[Init] best perm rec loss: 0.9831454753875732 for ['[CLS] redwoodrian sum allie mai institute corp apostolic [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.505 (perp=10.269, rec=0.377, cos=0.074), tot_loss_proj:3.447 [t=0.18s]
prediction: ['[CLS] ronald actually a bigger museum should should should [SEP]']
[ 100/2000] tot_loss=3.050 (perp=11.966, rec=0.525, cos=0.132), tot_loss_proj:3.325 [t=0.18s]
prediction: ['[CLS] prayers sisters gave arrow center should should should [SEP]']
[ 150/2000] tot_loss=2.501 (perp=10.214, rec=0.383, cos=0.075), tot_loss_proj:2.917 [t=0.21s]
prediction: ['[CLS] them arabian shouldus center should should to [SEP]']
[ 200/2000] tot_loss=2.186 (perp=9.023, rec=0.324, cos=0.057), tot_loss_proj:2.713 [t=0.22s]
prediction: ['[CLS] they should shouldus center should should to [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.125 (perp=8.846, rec=0.304, cos=0.052), tot_loss_proj:2.631 [t=0.18s]
prediction: ['[CLS] they should shouldus should should least to [SEP]']
[ 300/2000] tot_loss=1.869 (perp=7.776, rec=0.275, cos=0.039), tot_loss_proj:2.615 [t=0.18s]
prediction: ['[CLS] they should shouldus should should us to [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.996 (perp=8.561, rec=0.249, cos=0.035), tot_loss_proj:3.171 [t=0.18s]
prediction: ['[CLS] leave they should him should should us to [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.850 (perp=7.777, rec=0.255, cos=0.040), tot_loss_proj:2.439 [t=0.18s]
prediction: ['[CLS] should they should to leave shouldzation to [SEP]']
[ 450/2000] tot_loss=1.738 (perp=7.487, rec=0.213, cos=0.028), tot_loss_proj:2.757 [t=0.18s]
prediction: ['[CLS] should they should him leave should leave to [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.922 (perp=8.369, rec=0.220, cos=0.029), tot_loss_proj:2.850 [t=0.18s]
prediction: ['[CLS] should expected should should leave him leave to [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.536 (perp=6.557, rec=0.200, cos=0.024), tot_loss_proj:2.548 [t=0.18s]
prediction: ['[CLS] should expected should should leave to us. [SEP]']
[ 600/2000] tot_loss=1.545 (perp=6.694, rec=0.187, cos=0.019), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] should expected should to leave to us. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.379 (perp=5.857, rec=0.189, cos=0.019), tot_loss_proj:2.502 [t=0.18s]
prediction: ['[CLS] should should expected to leave to us. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.361 (perp=5.857, rec=0.171, cos=0.019), tot_loss_proj:2.501 [t=0.18s]
prediction: ['[CLS] should should expected to leave to us. [SEP]']
[ 750/2000] tot_loss=1.353 (perp=5.857, rec=0.165, cos=0.017), tot_loss_proj:2.500 [t=0.21s]
prediction: ['[CLS] should should expected to leave to us. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.340 (perp=5.857, rec=0.154, cos=0.015), tot_loss_proj:2.489 [t=0.19s]
prediction: ['[CLS] should should expected to leave to us. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.531 (perp=6.853, rec=0.145, cos=0.016), tot_loss_proj:2.602 [t=0.20s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
[ 900/2000] tot_loss=1.526 (perp=6.853, rec=0.141, cos=0.014), tot_loss_proj:2.595 [t=0.18s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.520 (perp=6.853, rec=0.135, cos=0.015), tot_loss_proj:2.594 [t=0.30s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.529 (perp=6.853, rec=0.145, cos=0.014), tot_loss_proj:2.592 [t=0.25s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
[1050/2000] tot_loss=1.520 (perp=6.853, rec=0.136, cos=0.014), tot_loss_proj:2.595 [t=0.19s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.515 (perp=6.853, rec=0.131, cos=0.013), tot_loss_proj:2.589 [t=0.26s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.514 (perp=6.853, rec=0.129, cos=0.014), tot_loss_proj:2.597 [t=0.22s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
[1200/2000] tot_loss=1.514 (perp=6.853, rec=0.130, cos=0.013), tot_loss_proj:2.593 [t=0.18s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.517 (perp=6.853, rec=0.133, cos=0.013), tot_loss_proj:2.589 [t=0.18s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.509 (perp=6.853, rec=0.125, cos=0.013), tot_loss_proj:2.594 [t=0.19s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
[1350/2000] tot_loss=1.515 (perp=6.853, rec=0.132, cos=0.013), tot_loss_proj:2.591 [t=0.23s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.512 (perp=6.853, rec=0.128, cos=0.013), tot_loss_proj:2.593 [t=0.18s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.508 (perp=6.853, rec=0.125, cos=0.013), tot_loss_proj:2.595 [t=0.23s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
[1500/2000] tot_loss=1.512 (perp=6.853, rec=0.128, cos=0.013), tot_loss_proj:2.589 [t=0.25s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.502 (perp=6.853, rec=0.119, cos=0.013), tot_loss_proj:2.587 [t=0.24s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.508 (perp=6.853, rec=0.125, cos=0.013), tot_loss_proj:2.585 [t=0.18s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
[1650/2000] tot_loss=1.501 (perp=6.853, rec=0.118, cos=0.013), tot_loss_proj:2.593 [t=0.18s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.512 (perp=6.853, rec=0.129, cos=0.012), tot_loss_proj:2.595 [t=0.19s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.503 (perp=6.853, rec=0.119, cos=0.013), tot_loss_proj:2.591 [t=0.24s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
[1800/2000] tot_loss=1.504 (perp=6.853, rec=0.121, cos=0.012), tot_loss_proj:2.591 [t=0.18s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.505 (perp=6.853, rec=0.122, cos=0.012), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.508 (perp=6.853, rec=0.125, cos=0.012), tot_loss_proj:2.587 [t=0.22s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
[1950/2000] tot_loss=1.505 (perp=6.853, rec=0.122, cos=0.012), tot_loss_proj:2.593 [t=0.18s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.506 (perp=6.853, rec=0.123, cos=0.012), tot_loss_proj:2.594 [t=0.19s]
prediction: ['[CLS] should expected expected to leave to us. [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] they expected us to should leave him. [SEP]
========================
predicted: 
========================
[CLS] should expected expected to leave to us. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 77.778

[Aggregate metrics]:
rouge1     | fm: 81.977 | p: 81.266 | r: 82.809
rouge2     | fm: 38.609 | p: 38.285 | r: 39.107
rougeL     | fm: 68.507 | p: 67.971 | r: 69.240
rougeLsum  | fm: 68.644 | p: 68.117 | r: 69.420
r1fm+r2fm = 120.586

input #58 time: 0:08:14 | total time: 8:16:16


Running input #59 of 100.
reference: 
========================
Mr Woodhouse sat in an armchair.
========================
average of cosine similarity 0.999401123526773
highest_index [0]
highest [0.999401123526773]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2720,  3536,  4580,  2938,  1999,  2019, 29372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] mr woodhouse sat in an armchair. [SEP]']
[Init] best rec loss: 1.8855668306350708 for ['[CLS] zero treasurer kennedy vet when le bronze plans [SEP]']
[Init] best rec loss: 1.8280147314071655 for ['[CLS] geraldine draft side everythingion lack hamlet react [SEP]']
[Init] best rec loss: 1.812221884727478 for ['[CLS] prize wait sex ste front coach downs list [SEP]']
[Init] best rec loss: 1.8113956451416016 for ['[CLS] national h sprawling lies wolf regular republicans meeting [SEP]']
[Init] best rec loss: 1.7937743663787842 for ['[CLS] provided cart untiluri apostolic cricket prevented stories [SEP]']
[Init] best rec loss: 1.7596840858459473 for ['[CLS] right cheat focus geographic rhodes awarded difference greater [SEP]']
[Init] best perm rec loss: 1.7577424049377441 for ['[CLS] rhodes greater focus awarded difference right geographic cheat [SEP]']
[Init] best perm rec loss: 1.7501940727233887 for ['[CLS] focus cheat awarded geographic difference rhodes greater right [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.209 (perp=12.327, rec=0.537, cos=0.207), tot_loss_proj:4.464 [t=0.17s]
prediction: ['[CLS] mister original jug castle mr democracy chicago chair [SEP]']
[ 100/2000] tot_loss=2.724 (perp=11.715, rec=0.340, cos=0.041), tot_loss_proj:4.257 [t=0.26s]
prediction: ['[CLS] : disorder jug divided mr supreme michigan chair [SEP]']
[ 150/2000] tot_loss=2.576 (perp=11.638, rec=0.232, cos=0.017), tot_loss_proj:4.098 [t=0.23s]
prediction: ['[CLS] he disorder jug armchair mr sat window sat [SEP]']
[ 200/2000] tot_loss=2.449 (perp=11.284, rec=0.182, cos=0.011), tot_loss_proj:4.062 [t=0.24s]
prediction: ['[CLS] he manuscript jug armchair mr sat wood sat [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.086 (perp=9.426, rec=0.186, cos=0.014), tot_loss_proj:3.718 [t=0.18s]
prediction: ['[CLS] harsh responses armchair. mr in wood sat [SEP]']
[ 300/2000] tot_loss=2.161 (perp=10.090, rec=0.135, cos=0.009), tot_loss_proj:3.934 [t=0.19s]
prediction: ['[CLS] harshhouse armchair. mr in wood sat [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.961 (perp=9.100, rec=0.133, cos=0.008), tot_loss_proj:3.598 [t=0.18s]
prediction: ['[CLS]crhouse armchair in mr. wood sat [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.767 (perp=8.119, rec=0.135, cos=0.008), tot_loss_proj:3.413 [t=0.21s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[ 450/2000] tot_loss=1.754 (perp=8.119, rec=0.124, cos=0.007), tot_loss_proj:3.418 [t=0.25s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.742 (perp=8.119, rec=0.112, cos=0.006), tot_loss_proj:3.414 [t=0.22s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.724 (perp=8.119, rec=0.095, cos=0.005), tot_loss_proj:3.418 [t=0.21s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[ 600/2000] tot_loss=1.733 (perp=8.119, rec=0.104, cos=0.006), tot_loss_proj:3.416 [t=0.19s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.722 (perp=8.119, rec=0.092, cos=0.005), tot_loss_proj:3.414 [t=0.18s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.731 (perp=8.119, rec=0.102, cos=0.005), tot_loss_proj:3.414 [t=0.19s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[ 750/2000] tot_loss=1.722 (perp=8.119, rec=0.093, cos=0.005), tot_loss_proj:3.419 [t=0.19s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.708 (perp=8.119, rec=0.079, cos=0.005), tot_loss_proj:3.420 [t=0.23s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.730 (perp=8.119, rec=0.101, cos=0.005), tot_loss_proj:3.415 [t=0.18s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[ 900/2000] tot_loss=1.728 (perp=8.119, rec=0.099, cos=0.005), tot_loss_proj:3.416 [t=0.18s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.712 (perp=8.119, rec=0.083, cos=0.005), tot_loss_proj:3.414 [t=0.19s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1000/2000] tot_loss=1.714 (perp=8.119, rec=0.086, cos=0.005), tot_loss_proj:3.418 [t=0.20s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[1050/2000] tot_loss=1.712 (perp=8.119, rec=0.083, cos=0.005), tot_loss_proj:3.414 [t=0.19s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1100/2000] tot_loss=1.720 (perp=8.119, rec=0.091, cos=0.005), tot_loss_proj:3.414 [t=0.18s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1150/2000] tot_loss=1.722 (perp=8.119, rec=0.094, cos=0.005), tot_loss_proj:3.414 [t=0.28s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[1200/2000] tot_loss=1.712 (perp=8.119, rec=0.083, cos=0.005), tot_loss_proj:3.416 [t=0.29s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1250/2000] tot_loss=1.709 (perp=8.119, rec=0.081, cos=0.005), tot_loss_proj:3.416 [t=0.19s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1300/2000] tot_loss=1.717 (perp=8.119, rec=0.089, cos=0.005), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[1350/2000] tot_loss=1.722 (perp=8.119, rec=0.094, cos=0.005), tot_loss_proj:3.416 [t=0.18s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1400/2000] tot_loss=1.725 (perp=8.119, rec=0.097, cos=0.004), tot_loss_proj:3.415 [t=0.19s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1450/2000] tot_loss=1.717 (perp=8.119, rec=0.089, cos=0.004), tot_loss_proj:3.410 [t=0.21s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[1500/2000] tot_loss=1.719 (perp=8.119, rec=0.091, cos=0.004), tot_loss_proj:3.412 [t=0.25s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1550/2000] tot_loss=1.717 (perp=8.119, rec=0.089, cos=0.004), tot_loss_proj:3.412 [t=0.19s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1600/2000] tot_loss=1.720 (perp=8.119, rec=0.092, cos=0.004), tot_loss_proj:3.413 [t=0.18s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[1650/2000] tot_loss=1.711 (perp=8.119, rec=0.082, cos=0.004), tot_loss_proj:3.416 [t=0.18s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1700/2000] tot_loss=1.722 (perp=8.119, rec=0.094, cos=0.004), tot_loss_proj:3.412 [t=0.24s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1750/2000] tot_loss=1.714 (perp=8.119, rec=0.085, cos=0.004), tot_loss_proj:3.410 [t=0.23s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[1800/2000] tot_loss=1.719 (perp=8.119, rec=0.091, cos=0.004), tot_loss_proj:3.417 [t=0.21s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1850/2000] tot_loss=1.718 (perp=8.119, rec=0.090, cos=0.004), tot_loss_proj:3.415 [t=0.25s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[1900/2000] tot_loss=1.725 (perp=8.119, rec=0.096, cos=0.004), tot_loss_proj:3.411 [t=0.22s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
[1950/2000] tot_loss=1.728 (perp=8.119, rec=0.100, cos=0.004), tot_loss_proj:3.415 [t=0.26s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Attempt swap
[2000/2000] tot_loss=1.714 (perp=8.119, rec=0.086, cos=0.004), tot_loss_proj:3.419 [t=0.18s]
prediction: ['[CLS]cr armchair in mr. woodhouse sat [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] mr woodhouse sat in an armchair. [SEP]
========================
predicted: 
========================
[CLS]cr armchair in mr. woodhouse sat [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 116.071

[Aggregate metrics]:
rouge1     | fm: 82.028 | p: 81.348 | r: 83.001
rouge2     | fm: 38.471 | p: 38.185 | r: 38.885
rougeL     | fm: 68.431 | p: 67.898 | r: 69.155
rougeLsum  | fm: 68.540 | p: 68.134 | r: 69.285
r1fm+r2fm = 120.499

input #59 time: 0:08:32 | total time: 8:24:49


Running input #60 of 100.
reference: 
========================
It is likely that Jean left.
========================
average of cosine similarity 0.9994653435805758
highest_index [0]
highest [0.9994653435805758]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2009, 2003, 3497, 2008, 3744, 2187, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] it is likely that jean left. [SEP]']
[Init] best rec loss: 2.0293774604797363 for ['[CLS]ach called vision sea age include wren [SEP]']
[Init] best rec loss: 1.8009871244430542 for ['[CLS] blue returnedisen within zur immediateores [SEP]']
[Init] best rec loss: 1.7729538679122925 for ['[CLS] pine bay silent nectar sister specific dog [SEP]']
[Init] best rec loss: 1.6898661851882935 for ['[CLS] immortality - time will crosses correct close [SEP]']
[Init] best rec loss: 1.685006022453308 for ['[CLS] recall men surveyclaim masks convention but [SEP]']
[Init] best rec loss: 1.641244649887085 for ['[CLS]ior explains maiden stage between mile oh [SEP]']
[Init] best perm rec loss: 1.6392616033554077 for ['[CLS]ior oh explains between mile stage maiden [SEP]']
[Init] best perm rec loss: 1.6385456323623657 for ['[CLS] stage between explainsior maiden mile oh [SEP]']
[Init] best perm rec loss: 1.6381484270095825 for ['[CLS] between maiden mile stage explains ohior [SEP]']
[Init] best perm rec loss: 1.6371288299560547 for ['[CLS] oh maiden mile explains stageior between [SEP]']
[Init] best perm rec loss: 1.6364763975143433 for ['[CLS] between maiden explains stage mileior oh [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.609 (perp=10.290, rec=0.650, cos=0.901), tot_loss_proj:3.895 [t=0.17s]
prediction: ['[CLS] photographic news k possibly ignored about. [SEP]']
[ 100/2000] tot_loss=4.079 (perp=12.188, rec=0.647, cos=0.995), tot_loss_proj:4.172 [t=0.18s]
prediction: ['[CLS]eux supposelings possibly leaves trailing that [SEP]']
[ 150/2000] tot_loss=2.691 (perp=11.205, rec=0.375, cos=0.075), tot_loss_proj:3.964 [t=0.19s]
prediction: ['[CLS] john poked jean possibly left seems that [SEP]']
[ 200/2000] tot_loss=2.435 (perp=10.894, rec=0.235, cos=0.020), tot_loss_proj:4.148 [t=0.18s]
prediction: ['[CLS] likely jean jean likely left whether that [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.303 (perp=10.529, rec=0.182, cos=0.015), tot_loss_proj:3.905 [t=0.19s]
prediction: ['[CLS] likely jean jean whether left likely that [SEP]']
[ 300/2000] tot_loss=2.229 (perp=10.472, rec=0.127, cos=0.008), tot_loss_proj:3.897 [t=0.19s]
prediction: ['[CLS] is jean jean whether left likely that [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.060 (perp=9.688, rec=0.115, cos=0.007), tot_loss_proj:3.709 [t=0.18s]
prediction: ['[CLS] jean jean is whether left likely that [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.920 (perp=8.987, rec=0.116, cos=0.006), tot_loss_proj:3.546 [t=0.18s]
prediction: ['[CLS] jean jean whether is left likely that [SEP]']
[ 450/2000] tot_loss=2.093 (perp=9.912, rec=0.105, cos=0.006), tot_loss_proj:3.731 [t=0.18s]
prediction: ['[CLS] jean jean if is left likely that [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.984 (perp=9.421, rec=0.094, cos=0.006), tot_loss_proj:3.609 [t=0.19s]
prediction: ['[CLS] if likely jean is left likely that [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.903 (perp=8.973, rec=0.103, cos=0.006), tot_loss_proj:3.591 [t=0.18s]
prediction: ['[CLS] if likely jean is left that likely [SEP]']
[ 600/2000] tot_loss=1.736 (perp=8.145, rec=0.102, cos=0.006), tot_loss_proj:3.480 [t=0.18s]
prediction: ['[CLS] if jean jean is left that likely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.736 (perp=8.145, rec=0.102, cos=0.006), tot_loss_proj:3.481 [t=0.18s]
prediction: ['[CLS] if jean jean is left that likely [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.925 (perp=9.056, rec=0.107, cos=0.006), tot_loss_proj:3.661 [t=0.27s]
prediction: ['[CLS] jean if jean is left that likely [SEP]']
[ 750/2000] tot_loss=1.911 (perp=9.056, rec=0.094, cos=0.006), tot_loss_proj:3.652 [t=0.18s]
prediction: ['[CLS] jean if jean is left that likely [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.726 (perp=8.145, rec=0.092, cos=0.006), tot_loss_proj:3.465 [t=0.23s]
prediction: ['[CLS] if jean jean is left that likely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.728 (perp=8.145, rec=0.094, cos=0.006), tot_loss_proj:3.461 [t=0.18s]
prediction: ['[CLS] if jean jean is left that likely [SEP]']
[ 900/2000] tot_loss=1.728 (perp=8.145, rec=0.093, cos=0.006), tot_loss_proj:3.462 [t=0.18s]
prediction: ['[CLS] if jean jean is left that likely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.723 (perp=8.145, rec=0.088, cos=0.006), tot_loss_proj:3.464 [t=0.18s]
prediction: ['[CLS] if jean jean is left that likely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.755 (perp=8.244, rec=0.101, cos=0.006), tot_loss_proj:3.448 [t=0.18s]
prediction: ['[CLS] if ; jean is left that likely [SEP]']
[1050/2000] tot_loss=1.706 (perp=8.035, rec=0.093, cos=0.006), tot_loss_proj:3.457 [t=0.20s]
prediction: ['[CLS] if. jean is left that likely [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.705 (perp=8.021, rec=0.095, cos=0.006), tot_loss_proj:3.634 [t=0.18s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.711 (perp=8.035, rec=0.099, cos=0.005), tot_loss_proj:3.456 [t=0.18s]
prediction: ['[CLS] if. jean is left that likely [SEP]']
[1200/2000] tot_loss=1.711 (perp=8.035, rec=0.098, cos=0.005), tot_loss_proj:3.455 [t=0.18s]
prediction: ['[CLS] if. jean is left that likely [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.706 (perp=8.021, rec=0.097, cos=0.005), tot_loss_proj:3.638 [t=0.23s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.706 (perp=8.021, rec=0.096, cos=0.005), tot_loss_proj:3.637 [t=0.18s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
[1350/2000] tot_loss=1.696 (perp=8.021, rec=0.086, cos=0.005), tot_loss_proj:3.628 [t=0.19s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.714 (perp=8.021, rec=0.105, cos=0.005), tot_loss_proj:3.631 [t=0.18s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.707 (perp=8.035, rec=0.095, cos=0.005), tot_loss_proj:3.458 [t=0.18s]
prediction: ['[CLS] if. jean is left that likely [SEP]']
[1500/2000] tot_loss=1.708 (perp=8.035, rec=0.095, cos=0.005), tot_loss_proj:3.457 [t=0.18s]
prediction: ['[CLS] if. jean is left that likely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.706 (perp=8.035, rec=0.093, cos=0.005), tot_loss_proj:3.454 [t=0.26s]
prediction: ['[CLS] if. jean is left that likely [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.712 (perp=8.021, rec=0.102, cos=0.005), tot_loss_proj:3.633 [t=0.18s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
[1650/2000] tot_loss=1.705 (perp=8.021, rec=0.096, cos=0.005), tot_loss_proj:3.633 [t=0.18s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.693 (perp=8.021, rec=0.083, cos=0.005), tot_loss_proj:3.633 [t=0.20s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.701 (perp=8.021, rec=0.092, cos=0.005), tot_loss_proj:3.629 [t=0.27s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
[1800/2000] tot_loss=1.705 (perp=8.021, rec=0.095, cos=0.005), tot_loss_proj:3.631 [t=0.22s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.700 (perp=8.021, rec=0.090, cos=0.005), tot_loss_proj:3.635 [t=0.23s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.705 (perp=8.035, rec=0.093, cos=0.005), tot_loss_proj:3.453 [t=0.18s]
prediction: ['[CLS] if. jean is left that likely [SEP]']
[1950/2000] tot_loss=1.702 (perp=8.035, rec=0.090, cos=0.005), tot_loss_proj:3.456 [t=0.22s]
prediction: ['[CLS] if. jean is left that likely [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.707 (perp=8.021, rec=0.098, cos=0.005), tot_loss_proj:3.634 [t=0.35s]
prediction: ['[CLS]. if jean is left that likely [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] it is likely that jean left. [SEP]
========================
predicted: 
========================
[CLS]. if jean is left that likely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 87.500

[Aggregate metrics]:
rouge1     | fm: 82.179 | p: 81.572 | r: 83.032
rouge2     | fm: 37.937 | p: 37.624 | r: 38.302
rougeL     | fm: 68.033 | p: 67.524 | r: 68.817
rougeLsum  | fm: 68.284 | p: 67.777 | r: 68.997
r1fm+r2fm = 120.116

input #60 time: 0:08:13 | total time: 8:33:03


Running input #61 of 100.
reference: 
========================
Physicists like yourself are a godsend.
========================
average of cosine similarity 0.9993168200569027
highest_index [0]
highest [0.9993168200569027]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 13702,  2015,  2066,  4426,  2024,  1037,  5932, 10497,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] physicists like yourself are a godsend. [SEP]']
[Init] best rec loss: 1.9368295669555664 for ['[CLS]serromatic rescue object morning which viable for seeking [SEP]']
[Init] best rec loss: 1.9124888181686401 for ['[CLS] finds type ad cerambycidae motionter holland epithet caught [SEP]']
[Init] best rec loss: 1.86813223361969 for ['[CLS] bombardment symptoms ul memorial were worked gray haiti know [SEP]']
[Init] best rec loss: 1.857263207435608 for ['[CLS] first parental bill julius orthodox thank orson what knock [SEP]']
[Init] best rec loss: 1.8566629886627197 for ['[CLS] nearly especially scored memory your fa town choose joined [SEP]']
[Init] best perm rec loss: 1.851499080657959 for ['[CLS] scored your choose fa town especially memory joined nearly [SEP]']
[Init] best perm rec loss: 1.8493272066116333 for ['[CLS] scored choose especially fa town memory your joined nearly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.892 (perp=11.157, rec=0.516, cos=0.144), tot_loss_proj:4.201 [t=0.18s]
prediction: ['[CLS] nations olympics curriculum values littleward and mali so [SEP]']
[ 100/2000] tot_loss=2.828 (perp=11.989, rec=0.382, cos=0.048), tot_loss_proj:4.324 [t=0.18s]
prediction: ['[CLS] nations yourself physicistsm yourless professory so [SEP]']
[ 150/2000] tot_loss=2.177 (perp=8.162, rec=0.456, cos=0.089), tot_loss_proj:3.594 [t=0.18s]
prediction: ['[CLS] your like! theorem your reality.ard. [SEP]']
[ 200/2000] tot_loss=2.619 (perp=9.324, rec=0.540, cos=0.214), tot_loss_proj:3.761 [t=0.18s]
prediction: ['[CLS] your like physics physicist your reality physicistend. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.020 (perp=8.274, rec=0.331, cos=0.034), tot_loss_proj:3.653 [t=0.21s]
prediction: ['[CLS] your physicist physicist like your successful physicistend. [SEP]']
[ 300/2000] tot_loss=2.123 (perp=9.183, rec=0.258, cos=0.028), tot_loss_proj:3.796 [t=0.18s]
prediction: ['[CLS] your physicist physicist like yourself successful physicistend. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.970 (perp=12.254, rec=0.431, cos=0.089), tot_loss_proj:4.349 [t=0.24s]
prediction: ['[CLS] anime physicist naturally your like parallel physicistek. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.823 (perp=11.576, rec=0.440, cos=0.069), tot_loss_proj:4.227 [t=0.27s]
prediction: ['[CLS] jedi physicist naturally like your yourself physicistend. [SEP]']
[ 450/2000] tot_loss=2.678 (perp=11.576, rec=0.330, cos=0.033), tot_loss_proj:4.221 [t=0.28s]
prediction: ['[CLS] jedi physicist naturally like your yourself physicistend. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.350 (perp=9.555, rec=0.388, cos=0.051), tot_loss_proj:3.826 [t=0.18s]
prediction: ['[CLS] anime physicist know like your physicist millsend. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.184 (perp=9.053, rec=0.340, cos=0.032), tot_loss_proj:3.745 [t=0.20s]
prediction: ['[CLS] physicist physicist know yourself like physicist universeend. [SEP]']
[ 600/2000] tot_loss=2.121 (perp=9.053, rec=0.284, cos=0.026), tot_loss_proj:3.745 [t=0.24s]
prediction: ['[CLS] physicist physicist know yourself like physicist universeend. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.976 (perp=8.433, rec=0.269, cos=0.020), tot_loss_proj:3.609 [t=0.27s]
prediction: ['[CLS] physicist physicist yourself are like physicist millsend. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.094 (perp=9.149, rec=0.246, cos=0.017), tot_loss_proj:3.761 [t=0.24s]
prediction: ['[CLS] physicist physicist yourself are like physicist somewhereend. [SEP]']
[ 750/2000] tot_loss=2.058 (perp=9.149, rec=0.215, cos=0.013), tot_loss_proj:3.762 [t=0.22s]
prediction: ['[CLS] physicist physicist yourself are like physicist somewhereend. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.000 (perp=8.633, rec=0.241, cos=0.032), tot_loss_proj:3.659 [t=0.18s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.938 (perp=8.633, rec=0.198, cos=0.013), tot_loss_proj:3.656 [t=0.25s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
[ 900/2000] tot_loss=1.927 (perp=8.633, rec=0.191, cos=0.010), tot_loss_proj:3.656 [t=0.22s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.919 (perp=8.633, rec=0.184, cos=0.008), tot_loss_proj:3.654 [t=0.18s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.907 (perp=8.633, rec=0.173, cos=0.007), tot_loss_proj:3.658 [t=0.24s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
[1050/2000] tot_loss=1.909 (perp=8.633, rec=0.175, cos=0.007), tot_loss_proj:3.657 [t=0.18s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.904 (perp=8.633, rec=0.171, cos=0.006), tot_loss_proj:3.651 [t=0.21s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.906 (perp=8.633, rec=0.173, cos=0.006), tot_loss_proj:3.656 [t=0.25s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
[1200/2000] tot_loss=1.898 (perp=8.633, rec=0.165, cos=0.006), tot_loss_proj:3.655 [t=0.19s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.888 (perp=8.633, rec=0.156, cos=0.006), tot_loss_proj:3.657 [t=0.18s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.897 (perp=8.633, rec=0.165, cos=0.005), tot_loss_proj:3.654 [t=0.23s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
[1350/2000] tot_loss=1.898 (perp=8.633, rec=0.166, cos=0.005), tot_loss_proj:3.654 [t=0.19s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.891 (perp=8.633, rec=0.160, cos=0.005), tot_loss_proj:3.661 [t=0.18s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.899 (perp=8.633, rec=0.168, cos=0.005), tot_loss_proj:3.662 [t=0.22s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
[1500/2000] tot_loss=1.893 (perp=8.633, rec=0.162, cos=0.005), tot_loss_proj:3.657 [t=0.25s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.893 (perp=8.633, rec=0.161, cos=0.005), tot_loss_proj:3.661 [t=0.19s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.890 (perp=8.633, rec=0.159, cos=0.005), tot_loss_proj:3.662 [t=0.19s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
[1650/2000] tot_loss=1.882 (perp=8.633, rec=0.150, cos=0.005), tot_loss_proj:3.656 [t=0.18s]
prediction: ['[CLS] physicist physicist yourself are like physicist universeend. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.721 (perp=7.812, rec=0.153, cos=0.005), tot_loss_proj:3.498 [t=0.18s]
prediction: ['[CLS] physicist physicist yourself are like physicist godsend. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.723 (perp=7.812, rec=0.156, cos=0.005), tot_loss_proj:3.505 [t=0.20s]
prediction: ['[CLS] physicist physicist yourself are like physicist godsend. [SEP]']
[1800/2000] tot_loss=1.721 (perp=7.812, rec=0.154, cos=0.005), tot_loss_proj:3.501 [t=0.21s]
prediction: ['[CLS] physicist physicist yourself are like physicist godsend. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.719 (perp=7.812, rec=0.152, cos=0.005), tot_loss_proj:3.496 [t=0.21s]
prediction: ['[CLS] physicist physicist yourself are like physicist godsend. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.724 (perp=7.812, rec=0.157, cos=0.005), tot_loss_proj:3.505 [t=0.19s]
prediction: ['[CLS] physicist physicist yourself are like physicist godsend. [SEP]']
[1950/2000] tot_loss=1.722 (perp=7.812, rec=0.155, cos=0.005), tot_loss_proj:3.503 [t=0.20s]
prediction: ['[CLS] physicist physicist yourself are like physicist godsend. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.721 (perp=7.812, rec=0.154, cos=0.005), tot_loss_proj:3.496 [t=0.18s]
prediction: ['[CLS] physicist physicist yourself are like physicist godsend. [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS] physicists like yourself are a godsend. [SEP]
========================
predicted: 
========================
[CLS] physicist physicist yourself are like physicist godsend. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 66.667 | r: 75.000
rouge2     | fm: 26.667 | p: 25.000 | r: 28.571
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 97.255

[Aggregate metrics]:
rouge1     | fm: 81.981 | p: 81.329 | r: 82.912
rouge2     | fm: 37.792 | p: 37.480 | r: 38.213
rougeL     | fm: 67.937 | p: 67.425 | r: 68.727
rougeLsum  | fm: 68.167 | p: 67.590 | r: 68.896
r1fm+r2fm = 119.773

input #61 time: 0:08:19 | total time: 8:41:23


Running input #62 of 100.
reference: 
========================
Any pilot could be flying this plane.
========================
average of cosine similarity 0.9994980007326446
highest_index [0]
highest [0.9994980007326446]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2151, 4405, 2071, 2022, 3909, 2023, 4946, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] any pilot could be flying this plane. [SEP]']
[Init] best rec loss: 1.9839799404144287 for ['[CLS] events heat names cole issue. 505 regina [SEP]']
[Init] best rec loss: 1.9153730869293213 for ['[CLS] from actress le testament sooner pit confederacy oct [SEP]']
[Init] best rec loss: 1.8920799493789673 for ['[CLS]liest into holding complained discovery sutherland coast fork [SEP]']
[Init] best rec loss: 1.881668210029602 for ['[CLS] permissionoun congregation tales eternity wilde memory format [SEP]']
[Init] best rec loss: 1.8768709897994995 for ['[CLS] rogers proogan palmsrm conference pitchfork aw [SEP]']
[Init] best rec loss: 1.8328007459640503 for ['[CLS] reader leagues english our place guestfire mad [SEP]']
[Init] best perm rec loss: 1.8269000053405762 for ['[CLS] mad place englishfire our guest leagues reader [SEP]']
[Init] best perm rec loss: 1.821074366569519 for ['[CLS] guest reader english place mad leagues ourfire [SEP]']
[Init] best perm rec loss: 1.819869041442871 for ['[CLS]fire guest english leagues mad our reader place [SEP]']
[Init] best perm rec loss: 1.8185937404632568 for ['[CLS] mad guestfire leagues reader our english place [SEP]']
[Init] best perm rec loss: 1.8181970119476318 for ['[CLS] our readerfire mad guest leagues place english [SEP]']
[Init] best perm rec loss: 1.8171947002410889 for ['[CLS] readerfire leagues guest place our english mad [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.389 (perp=9.581, rec=0.364, cos=0.109), tot_loss_proj:3.829 [t=0.17s]
prediction: ['[CLS] jet. ; flying jesus alex disney villain [SEP]']
[ 100/2000] tot_loss=2.560 (perp=10.850, rec=0.316, cos=0.075), tot_loss_proj:4.104 [t=0.18s]
prediction: ['[CLS] this anything ; flying jesus alex disney confirmed [SEP]']
[ 150/2000] tot_loss=2.517 (perp=11.159, rec=0.248, cos=0.038), tot_loss_proj:4.194 [t=0.18s]
prediction: ['[CLS] this any could plane jesus could skater surely [SEP]']
[ 200/2000] tot_loss=2.447 (perp=10.824, rec=0.246, cos=0.036), tot_loss_proj:4.093 [t=0.20s]
prediction: ['[CLS] this any could pilotout could flying surely [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.695 (perp=12.408, rec=0.191, cos=0.022), tot_loss_proj:4.403 [t=0.18s]
prediction: ['[CLS] this any could pilot » derek anyone cerambycidae [SEP]']
[ 300/2000] tot_loss=1.990 (perp=9.125, rec=0.149, cos=0.015), tot_loss_proj:3.700 [t=0.18s]
prediction: ['[CLS] this any could pilot plane. anyone plane [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.677 (perp=7.573, rec=0.148, cos=0.014), tot_loss_proj:3.443 [t=0.18s]
prediction: ['[CLS] this any plane pilot could. anyone plane [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.592 (perp=7.024, rec=0.169, cos=0.018), tot_loss_proj:3.383 [t=0.18s]
prediction: ['[CLS] this any plane pilot could plane anyone. [SEP]']
[ 450/2000] tot_loss=1.548 (perp=7.024, rec=0.130, cos=0.013), tot_loss_proj:3.374 [t=0.18s]
prediction: ['[CLS] this any plane pilot could plane anyone. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.526 (perp=6.935, rec=0.127, cos=0.011), tot_loss_proj:3.344 [t=0.19s]
prediction: ['[CLS] this any pilot pilot could plane anyone. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.389 (perp=6.261, rec=0.125, cos=0.012), tot_loss_proj:3.089 [t=0.18s]
prediction: ['[CLS] this any pilot pilot could be plane. [SEP]']
[ 600/2000] tot_loss=1.395 (perp=6.261, rec=0.133, cos=0.010), tot_loss_proj:3.095 [t=0.18s]
prediction: ['[CLS] this any pilot pilot could be plane. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.367 (perp=6.261, rec=0.106, cos=0.009), tot_loss_proj:3.090 [t=0.18s]
prediction: ['[CLS] this any pilot pilot could be plane. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.364 (perp=6.261, rec=0.104, cos=0.009), tot_loss_proj:3.092 [t=0.17s]
prediction: ['[CLS] this any pilot pilot could be plane. [SEP]']
[ 750/2000] tot_loss=1.450 (perp=6.621, rec=0.118, cos=0.008), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.437 (perp=6.621, rec=0.104, cos=0.008), tot_loss_proj:3.170 [t=0.20s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.434 (perp=6.621, rec=0.102, cos=0.008), tot_loss_proj:3.175 [t=0.22s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
[ 900/2000] tot_loss=1.452 (perp=6.621, rec=0.119, cos=0.008), tot_loss_proj:3.168 [t=0.18s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.438 (perp=6.621, rec=0.106, cos=0.008), tot_loss_proj:3.171 [t=0.18s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.430 (perp=6.621, rec=0.098, cos=0.008), tot_loss_proj:3.173 [t=0.23s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
[1050/2000] tot_loss=1.439 (perp=6.621, rec=0.107, cos=0.008), tot_loss_proj:3.171 [t=0.20s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.442 (perp=6.621, rec=0.110, cos=0.008), tot_loss_proj:3.172 [t=0.21s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.439 (perp=6.621, rec=0.107, cos=0.008), tot_loss_proj:3.172 [t=0.18s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
[1200/2000] tot_loss=1.426 (perp=6.621, rec=0.095, cos=0.008), tot_loss_proj:3.172 [t=0.18s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.446 (perp=6.621, rec=0.114, cos=0.007), tot_loss_proj:3.171 [t=0.18s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.434 (perp=6.621, rec=0.103, cos=0.007), tot_loss_proj:3.169 [t=0.18s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
[1350/2000] tot_loss=1.427 (perp=6.621, rec=0.096, cos=0.007), tot_loss_proj:3.175 [t=0.18s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.441 (perp=6.621, rec=0.111, cos=0.006), tot_loss_proj:3.167 [t=0.18s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.436 (perp=6.621, rec=0.106, cos=0.006), tot_loss_proj:3.169 [t=0.19s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
[1500/2000] tot_loss=1.437 (perp=6.621, rec=0.107, cos=0.006), tot_loss_proj:3.173 [t=0.20s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.426 (perp=6.621, rec=0.096, cos=0.006), tot_loss_proj:3.175 [t=0.19s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.417 (perp=6.621, rec=0.087, cos=0.006), tot_loss_proj:3.173 [t=0.18s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
[1650/2000] tot_loss=1.409 (perp=6.621, rec=0.079, cos=0.005), tot_loss_proj:3.172 [t=0.17s]
prediction: ['[CLS] this any flying pilot could be plane. [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.248 (perp=5.770, rec=0.090, cos=0.004), tot_loss_proj:3.171 [t=0.18s]
prediction: ['[CLS] any flying pilot could be this plane. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.053 (perp=4.831, rec=0.083, cos=0.004), tot_loss_proj:1.115 [t=0.18s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
[1800/2000] tot_loss=1.053 (perp=4.831, rec=0.084, cos=0.003), tot_loss_proj:1.111 [t=0.18s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.045 (perp=4.831, rec=0.077, cos=0.003), tot_loss_proj:1.115 [t=0.18s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.038 (perp=4.831, rec=0.069, cos=0.002), tot_loss_proj:1.108 [t=0.19s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
[1950/2000] tot_loss=1.051 (perp=4.831, rec=0.082, cos=0.002), tot_loss_proj:1.117 [t=0.18s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.037 (perp=4.831, rec=0.068, cos=0.002), tot_loss_proj:1.109 [t=0.19s]
prediction: ['[CLS] any pilot could be flying this plane. [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] any pilot could be flying this plane. [SEP]
========================
predicted: 
========================
[CLS] any pilot could be flying this plane. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.281 | p: 81.636 | r: 83.220
rouge2     | fm: 38.666 | p: 38.351 | r: 39.107
rougeL     | fm: 68.465 | p: 67.871 | r: 69.233
rougeLsum  | fm: 68.627 | p: 68.078 | r: 69.349
r1fm+r2fm = 120.947

input #62 time: 0:07:40 | total time: 8:49:03


Running input #63 of 100.
reference: 
========================
We wonder if Bill left.
========================
average of cosine similarity 0.9993481792856471
highest_index [0]
highest [0.9993481792856471]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2057, 4687, 2065, 3021, 2187, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] we wonder if bill left. [SEP]']
[Init] best rec loss: 1.9156413078308105 for ['[CLS] affected maine effect streets studies its [SEP]']
[Init] best rec loss: 1.830747127532959 for ['[CLS] concerned code victoria located steel korea [SEP]']
[Init] best rec loss: 1.7906625270843506 for ['[CLS] helen leads her design cas family [SEP]']
[Init] best rec loss: 1.7879899740219116 for ['[CLS]mise damn former door sachs ruler [SEP]']
[Init] best rec loss: 1.784172773361206 for ['[CLS] became terms disputeerland stands league [SEP]']
[Init] best rec loss: 1.7771904468536377 for ['[CLS] newcastle cannons readingfold mated dim [SEP]']
[Init] best rec loss: 1.7446740865707397 for ['[CLS] clear factific courthouseallymann [SEP]']
[Init] best rec loss: 1.7185769081115723 for ['[CLS] arrival techniques child mean iqbal inside [SEP]']
[Init] best perm rec loss: 1.7145167589187622 for ['[CLS] mean iqbal arrival child inside techniques [SEP]']
[Init] best perm rec loss: 1.713699460029602 for ['[CLS] mean inside arrival child iqbal techniques [SEP]']
[Init] best perm rec loss: 1.709486722946167 for ['[CLS] mean techniques child iqbal inside arrival [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.418 (perp=12.716, rec=0.536, cos=0.340), tot_loss_proj:4.537 [t=0.17s]
prediction: ['[CLS] medicinal texas joy rye... officially [SEP]']
[ 100/2000] tot_loss=2.999 (perp=11.666, rec=0.457, cos=0.209), tot_loss_proj:4.242 [t=0.18s]
prediction: ['[CLS] ain variable joy guiana. because [SEP]']
[ 150/2000] tot_loss=2.657 (perp=10.624, rec=0.395, cos=0.137), tot_loss_proj:4.061 [t=0.18s]
prediction: ['[CLS] hardly variable billworth. afterwards [SEP]']
[ 200/2000] tot_loss=2.626 (perp=10.568, rec=0.392, cos=0.121), tot_loss_proj:3.925 [t=0.18s]
prediction: ['[CLS] hardly denomination billcating. we [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.764 (perp=11.449, rec=0.379, cos=0.095), tot_loss_proj:4.116 [t=0.22s]
prediction: ['[CLS] bill denomination bill macquarie. wonder [SEP]']
[ 300/2000] tot_loss=2.803 (perp=11.838, rec=0.364, cos=0.071), tot_loss_proj:4.186 [t=0.23s]
prediction: ['[CLS] bill denomination bill♠. wonder [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.962 (perp=12.556, rec=0.369, cos=0.081), tot_loss_proj:4.414 [t=0.18s]
prediction: ['[CLS] bill denomination bill @ wela [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.636 (perp=10.501, rec=0.417, cos=0.119), tot_loss_proj:3.988 [t=0.18s]
prediction: ['[CLS] if we henry bill hailey i [SEP]']
[ 450/2000] tot_loss=2.520 (perp=10.196, rec=0.421, cos=0.060), tot_loss_proj:3.847 [t=0.19s]
prediction: ['[CLS] bill we assume bill wondered i [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.571 (perp=10.990, rec=0.319, cos=0.054), tot_loss_proj:4.102 [t=0.18s]
prediction: ['[CLS] bill we liam bill i wondered [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.382 (perp=10.223, rec=0.295, cos=0.043), tot_loss_proj:3.884 [t=0.21s]
prediction: ['[CLS] bill we wondered bill i liam [SEP]']
[ 600/2000] tot_loss=2.085 (perp=8.838, rec=0.279, cos=0.038), tot_loss_proj:3.609 [t=0.20s]
prediction: ['[CLS] bill we wondered bill. assume [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.624 (perp=6.596, rec=0.269, cos=0.036), tot_loss_proj:3.172 [t=0.18s]
prediction: ['[CLS] bill we wondered bill.. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.925 (perp=8.215, rec=0.250, cos=0.032), tot_loss_proj:3.465 [t=0.18s]
prediction: ['[CLS] bills we wondered bill.. [SEP]']
[ 750/2000] tot_loss=1.875 (perp=8.035, rec=0.240, cos=0.029), tot_loss_proj:3.452 [t=0.18s]
prediction: ['[CLS] bills we wonder bill.. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.085 (perp=8.913, rec=0.266, cos=0.037), tot_loss_proj:3.538 [t=0.18s]
prediction: ['[CLS] we bill wonder bill assume. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.729 (perp=7.289, rec=0.239, cos=0.033), tot_loss_proj:3.285 [t=0.18s]
prediction: ['[CLS] we bill wonder if bill. [SEP]']
[ 900/2000] tot_loss=1.709 (perp=7.289, rec=0.222, cos=0.029), tot_loss_proj:3.292 [t=0.20s]
prediction: ['[CLS] we bill wonder if bill. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.564 (perp=6.526, rec=0.231, cos=0.028), tot_loss_proj:3.138 [t=0.19s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.540 (perp=6.526, rec=0.209, cos=0.027), tot_loss_proj:3.137 [t=0.20s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
[1050/2000] tot_loss=1.544 (perp=6.526, rec=0.213, cos=0.026), tot_loss_proj:3.133 [t=0.20s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.537 (perp=6.526, rec=0.206, cos=0.025), tot_loss_proj:3.133 [t=0.21s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.543 (perp=6.526, rec=0.213, cos=0.025), tot_loss_proj:3.134 [t=0.20s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
[1200/2000] tot_loss=1.528 (perp=6.526, rec=0.198, cos=0.025), tot_loss_proj:3.135 [t=0.22s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.539 (perp=6.526, rec=0.209, cos=0.024), tot_loss_proj:3.134 [t=0.19s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.535 (perp=6.526, rec=0.206, cos=0.024), tot_loss_proj:3.136 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
[1350/2000] tot_loss=1.535 (perp=6.526, rec=0.206, cos=0.024), tot_loss_proj:3.134 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.523 (perp=6.526, rec=0.194, cos=0.024), tot_loss_proj:3.136 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.516 (perp=6.526, rec=0.187, cos=0.024), tot_loss_proj:3.136 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
[1500/2000] tot_loss=1.526 (perp=6.526, rec=0.197, cos=0.023), tot_loss_proj:3.135 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.524 (perp=6.526, rec=0.195, cos=0.023), tot_loss_proj:3.137 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.510 (perp=6.526, rec=0.182, cos=0.023), tot_loss_proj:3.139 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
[1650/2000] tot_loss=1.526 (perp=6.526, rec=0.197, cos=0.023), tot_loss_proj:3.135 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.522 (perp=6.526, rec=0.194, cos=0.023), tot_loss_proj:3.132 [t=0.19s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.521 (perp=6.526, rec=0.193, cos=0.023), tot_loss_proj:3.135 [t=0.19s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
[1800/2000] tot_loss=1.527 (perp=6.526, rec=0.199, cos=0.023), tot_loss_proj:3.137 [t=0.19s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.516 (perp=6.526, rec=0.188, cos=0.023), tot_loss_proj:3.135 [t=0.19s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.528 (perp=6.526, rec=0.200, cos=0.023), tot_loss_proj:3.134 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
[1950/2000] tot_loss=1.531 (perp=6.526, rec=0.203, cos=0.023), tot_loss_proj:3.136 [t=0.19s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.513 (perp=6.526, rec=0.186, cos=0.023), tot_loss_proj:3.131 [t=0.18s]
prediction: ['[CLS] we wonder if bill bill. [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] we wonder if bill left. [SEP]
========================
predicted: 
========================
[CLS] we wonder if bill bill. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 152.381

[Aggregate metrics]:
rouge1     | fm: 82.266 | p: 81.633 | r: 83.180
rouge2     | fm: 39.230 | p: 38.966 | r: 39.608
rougeL     | fm: 68.709 | p: 68.237 | r: 69.383
rougeLsum  | fm: 68.899 | p: 68.404 | r: 69.551
r1fm+r2fm = 121.495

input #63 time: 0:07:47 | total time: 8:56:51


Running input #64 of 100.
reference: 
========================
Ellen talked with Helen about the problem.
========================
average of cosine similarity 0.9993768579649704
highest_index [0]
highest [0.9993768579649704]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9155, 5720, 2007, 6330, 2055, 1996, 3291, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] ellen talked with helen about the problem. [SEP]']
[Init] best rec loss: 1.8212698698043823 for ['[CLS] states gmina auction monument worthy than kennedy urban [SEP]']
[Init] best rec loss: 1.763874888420105 for ['[CLS] operator letter bookmposes latin sides substituted [SEP]']
[Init] best rec loss: 1.729110836982727 for ['[CLS]una scouting lee racialaniannne behind plus [SEP]']
[Init] best rec loss: 1.718116044998169 for ['[CLS] it stamp again acquired truth lea pictureted [SEP]']
[Init] best rec loss: 1.7067344188690186 for ['[CLS] costume go men bi bellamy midnightvating asia [SEP]']
[Init] best rec loss: 1.6890567541122437 for ['[CLS]path intended dreweng cbs janeirograd bis [SEP]']
[Init] best perm rec loss: 1.6882743835449219 for ['[CLS] bispath intended cbsgradeng janeiro drew [SEP]']
[Init] best perm rec loss: 1.683711051940918 for ['[CLS] bisgradpath intended drew janeiro cbseng [SEP]']
[Init] best perm rec loss: 1.680848479270935 for ['[CLS]eng bisgrad drewpath cbs janeiro intended [SEP]']
[Init] best perm rec loss: 1.6805613040924072 for ['[CLS]pathgrad janeiro drew biseng intended cbs [SEP]']
[Init] best perm rec loss: 1.6792283058166504 for ['[CLS] janeiroenggrad intended cbs bispath drew [SEP]']
[Init] best perm rec loss: 1.67889404296875 for ['[CLS]eng janeiro drew cbs bispath intendedgrad [SEP]']
[Init] best perm rec loss: 1.6768978834152222 for ['[CLS] janeirograd cbs drewpath biseng intended [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.160 (perp=12.701, rec=0.623, cos=0.997), tot_loss_proj:4.401 [t=0.18s]
prediction: ['[CLS] connected puzzle nedra july after investigation " mosquito [SEP]']
[ 100/2000] tot_loss=4.306 (perp=14.019, rec=0.507, cos=0.995), tot_loss_proj:4.637 [t=0.18s]
prediction: ['[CLS] ellen ellen helen talked called investigationhof screwed [SEP]']
[ 150/2000] tot_loss=3.905 (perp=12.172, rec=0.484, cos=0.987), tot_loss_proj:4.311 [t=0.18s]
prediction: ['[CLS] ellen ellen helen talked about investigation folder everybody [SEP]']
[ 200/2000] tot_loss=4.223 (perp=13.753, rec=0.485, cos=0.987), tot_loss_proj:4.436 [t=0.18s]
prediction: ['[CLS] ellen talked helen talked anymore problemgoing dissertation [SEP]']
Attempt swap
[ 250/2000] tot_loss=4.211 (perp=13.399, rec=0.536, cos=0.996), tot_loss_proj:4.464 [t=0.18s]
prediction: ['[CLS] ellen talked helen talked talking problemgoing everybody [SEP]']
[ 300/2000] tot_loss=3.898 (perp=12.509, rec=0.426, cos=0.971), tot_loss_proj:4.291 [t=0.18s]
prediction: ['[CLS] ellen talked helen talked talking problem file everybody [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.888 (perp=12.509, rec=0.418, cos=0.968), tot_loss_proj:4.288 [t=0.18s]
prediction: ['[CLS] ellen talked helen talked talking problem file everybody [SEP]']
Attempt swap
[ 400/2000] tot_loss=4.067 (perp=13.399, rec=0.417, cos=0.970), tot_loss_proj:4.469 [t=0.18s]
prediction: ['[CLS] ellen talked helen talked talking problemgoing everybody [SEP]']
[ 450/2000] tot_loss=4.045 (perp=13.399, rec=0.394, cos=0.971), tot_loss_proj:4.467 [t=0.19s]
prediction: ['[CLS] ellen talked helen talked talking problemgoing everybody [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=4.027 (perp=12.960, rec=0.481, cos=0.954), tot_loss_proj:4.293 [t=0.19s]
prediction: ['[CLS] ellen talked helen talked everybody oxygengoing talking [SEP]']
Attempt swap
[ 550/2000] tot_loss=4.014 (perp=13.168, rec=0.429, cos=0.951), tot_loss_proj:4.362 [t=0.19s]
prediction: ['[CLS] ellen talked helen talked. oxygendown talking [SEP]']
[ 600/2000] tot_loss=3.758 (perp=11.985, rec=0.410, cos=0.951), tot_loss_proj:4.202 [t=0.19s]
prediction: ['[CLS] ellen talked helen talked. helendown talking [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.955 (perp=12.935, rec=0.418, cos=0.950), tot_loss_proj:4.391 [t=0.19s]
prediction: ['[CLS] ellen talked helen talked. excuse talkeddown [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=4.141 (perp=13.467, rec=0.496, cos=0.952), tot_loss_proj:4.430 [t=0.19s]
prediction: ['[CLS] excuse talked helen talked tonight ellen talkinggoing [SEP]']
[ 750/2000] tot_loss=3.941 (perp=12.774, rec=0.431, cos=0.954), tot_loss_proj:4.280 [t=0.21s]
prediction: ['[CLS] excuse talked helen talked jen ellen talking chuckle [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.729 (perp=11.833, rec=0.412, cos=0.951), tot_loss_proj:4.184 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen talked jen talked aback [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.911 (perp=12.750, rec=0.410, cos=0.951), tot_loss_proj:4.334 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen talked station talked aback [SEP]']
[ 900/2000] tot_loss=4.010 (perp=13.333, rec=0.394, cos=0.950), tot_loss_proj:4.468 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen talked station talkedosomal [SEP]']
Attempt swap
[ 950/2000] tot_loss=4.006 (perp=13.333, rec=0.391, cos=0.949), tot_loss_proj:4.474 [t=0.19s]
prediction: ['[CLS] excuse ellen talked helen talked station talkedosomal [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.904 (perp=12.815, rec=0.393, cos=0.949), tot_loss_proj:4.359 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen talked stationosomal talked [SEP]']
[1050/2000] tot_loss=3.898 (perp=12.815, rec=0.387, cos=0.948), tot_loss_proj:4.361 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen talked stationosomal talked [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=3.847 (perp=12.581, rec=0.382, cos=0.949), tot_loss_proj:4.307 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1150/2000] tot_loss=3.849 (perp=12.581, rec=0.384, cos=0.948), tot_loss_proj:4.303 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
[1200/2000] tot_loss=3.848 (perp=12.581, rec=0.383, cos=0.948), tot_loss_proj:4.310 [t=0.20s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1250/2000] tot_loss=3.843 (perp=12.581, rec=0.378, cos=0.949), tot_loss_proj:4.307 [t=0.20s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1300/2000] tot_loss=3.838 (perp=12.581, rec=0.373, cos=0.948), tot_loss_proj:4.302 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
[1350/2000] tot_loss=3.837 (perp=12.581, rec=0.373, cos=0.948), tot_loss_proj:4.306 [t=0.19s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1400/2000] tot_loss=3.845 (perp=12.581, rec=0.381, cos=0.948), tot_loss_proj:4.305 [t=0.24s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1450/2000] tot_loss=3.842 (perp=12.581, rec=0.378, cos=0.948), tot_loss_proj:4.307 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
[1500/2000] tot_loss=3.836 (perp=12.581, rec=0.372, cos=0.948), tot_loss_proj:4.308 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1550/2000] tot_loss=3.835 (perp=12.581, rec=0.372, cos=0.948), tot_loss_proj:4.309 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1600/2000] tot_loss=3.843 (perp=12.581, rec=0.379, cos=0.947), tot_loss_proj:4.306 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
[1650/2000] tot_loss=3.832 (perp=12.581, rec=0.369, cos=0.947), tot_loss_proj:4.309 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1700/2000] tot_loss=3.838 (perp=12.581, rec=0.375, cos=0.947), tot_loss_proj:4.302 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1750/2000] tot_loss=3.842 (perp=12.581, rec=0.378, cos=0.947), tot_loss_proj:4.310 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
[1800/2000] tot_loss=3.832 (perp=12.581, rec=0.369, cos=0.947), tot_loss_proj:4.306 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1850/2000] tot_loss=3.838 (perp=12.581, rec=0.375, cos=0.947), tot_loss_proj:4.305 [t=0.18s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[1900/2000] tot_loss=3.838 (perp=12.581, rec=0.375, cos=0.946), tot_loss_proj:4.304 [t=0.20s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
[1950/2000] tot_loss=3.830 (perp=12.581, rec=0.368, cos=0.946), tot_loss_proj:4.308 [t=0.23s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Attempt swap
[2000/2000] tot_loss=3.839 (perp=12.581, rec=0.376, cos=0.947), tot_loss_proj:4.303 [t=0.19s]
prediction: ['[CLS] excuse ellen talked helen stationosomal talked talked [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] ellen talked with helen about the problem. [SEP]
========================
predicted: 
========================
[CLS] excuse ellen talked helen stationosomal talked talked [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.556 | p: 55.556 | r: 55.556
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 68.056

[Aggregate metrics]:
rouge1     | fm: 82.002 | p: 81.317 | r: 82.847
rouge2     | fm: 38.494 | p: 38.210 | r: 38.966
rougeL     | fm: 68.640 | p: 68.196 | r: 69.294
rougeLsum  | fm: 68.636 | p: 68.125 | r: 69.307
r1fm+r2fm = 120.497

input #64 time: 0:07:40 | total time: 9:04:31


Running input #65 of 100.
reference: 
========================
Mag Wildwood came to introduce the bartender but I came precisely not to.
========================
average of cosine similarity 0.999347258517335
highest_index [0]
highest [0.999347258517335]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101, 23848,  3748,  3702,  2234,  2000,  8970,  1996, 15812,  2021,
          1045,  2234, 10785,  2025,  2000,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]']
[Init] best rec loss: 1.9084722995758057 for ['[CLS] old shaw mcgill standminated chapter publication legal non penny cheekatics contemporary story fleet [SEP]']
[Init] best rec loss: 1.9074466228485107 for ['[CLS] spot retires etinskywood alexandra [MASK] filetwined ka bryant hitlertein roared [SEP]']
[Init] best rec loss: 1.8851876258850098 for ['[CLS] mail shooting legends capture gen attention cpud graders democratic but lips suspicious suppressed out [SEP]']
[Init] best rec loss: 1.8839342594146729 for ['[CLS] groom ownership hd mellon field house of [SEP]zed lisa iranbreaker bypass short [SEP]']
[Init] best rec loss: 1.883246898651123 for ['[CLS] over pulse mirror steering travel meter : travelbed nosed opportunity obligations depends splitting notes [SEP]']
[Init] best rec loss: 1.8684508800506592 for ['[CLS]ines organ salesmanisen sectionoise people ideal succession single humanunt shown monk black [SEP]']
[Init] best rec loss: 1.8654247522354126 for ['[CLS] white ronin found weapon junction portion learnedsky warfare eager townland stakes pads homeland or [SEP]']
[Init] best rec loss: 1.8624204397201538 for ['[CLS] wrestlemania application south heritage just er announcement perfect disregard under → bonus through making catholic [SEP]']
[Init] best rec loss: 1.8123862743377686 for ['[CLS] question ibn calledevich gulfcting due instead mist end banks half mef butch [SEP]']
[Init] best rec loss: 1.8047677278518677 for ['[CLS] merit climbed going following ukyya panzzi sir policing voiceiente sabha asia jade [SEP]']
[Init] best perm rec loss: 1.8022180795669556 for ['[CLS]yya climbed asiazzi merit following pan uk policingiente voice going jade sabha sir [SEP]']
[Init] best perm rec loss: 1.8003294467926025 for ['[CLS] sir following policing jadeyya asia merit ukzziiente going pan voice sabha climbed [SEP]']
[Init] best perm rec loss: 1.7955282926559448 for ['[CLS] sabha policing voice climbedzzi merit jade uk going following asia panyyaiente sir [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.418 (perp=12.684, rec=0.564, cos=0.317), tot_loss_proj:4.425 [t=0.17s]
prediction: ['[CLS] salvador briefcase sitcom scenesoy feature dion ( go follow jeff additionally went possession captain [SEP]']
[ 100/2000] tot_loss=3.338 (perp=13.906, rec=0.432, cos=0.125), tot_loss_proj:4.639 [t=0.17s]
prediction: ['[CLS] вisation sitcom poly decide strip affects la run 2007 came additionally went papyrus played [SEP]']
[ 150/2000] tot_loss=3.092 (perp=12.726, rec=0.421, cos=0.126), tot_loss_proj:4.388 [t=0.17s]
prediction: ['[CLS] portrayal consultant episode³ interrupted page tabitha da dq 2004 came also went papyrus played [SEP]']
[ 200/2000] tot_loss=2.808 (perp=11.989, rec=0.349, cos=0.062), tot_loss_proj:4.274 [t=0.17s]
prediction: ['[CLS] portrayal psychiatric episode³ decide by tabitha partial commentary 2004 came also wentducted again [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.048 (perp=12.518, rec=0.412, cos=0.133), tot_loss_proj:4.334 [t=0.17s]
prediction: ['[CLS]aran portrayal protestant episode politely by tabitha partial commentary follow came because sloane comment again [SEP]']
[ 300/2000] tot_loss=2.823 (perp=12.337, rec=0.323, cos=0.033), tot_loss_proj:4.307 [t=0.17s]
prediction: ['[CLS] mere portrayal cocktail episode politely by tabitha la commentary follow came because replaced precisely again [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.705 (perp=11.614, rec=0.324, cos=0.057), tot_loss_proj:4.176 [t=0.17s]
prediction: ['[CLS]³ portrayal respectively episode politely by tabitha should indeed came bartender precisely because not again [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.738 (perp=11.943, rec=0.316, cos=0.034), tot_loss_proj:4.206 [t=0.17s]
prediction: ['[CLS] politely portrayal respectively episode mere by denote came indeed came bartender precisely because not again [SEP]']
[ 450/2000] tot_loss=2.628 (perp=11.610, rec=0.279, cos=0.027), tot_loss_proj:4.150 [t=0.17s]
prediction: ['[CLS] politely portrayal respectively introduce mere by denote came indeed came bartender precisely because not to [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.648 (perp=11.696, rec=0.281, cos=0.028), tot_loss_proj:4.156 [t=0.17s]
prediction: ['[CLS] politely show came introduce mere portrayal denote exactly indeed came bartender precisely because not to [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.624 (perp=11.667, rec=0.264, cos=0.027), tot_loss_proj:4.195 [t=0.17s]
prediction: ['[CLS] came show came introduce portrayal³ denote exactly shall came bartender precisely came not to [SEP]']
[ 600/2000] tot_loss=2.618 (perp=11.667, rec=0.259, cos=0.026), tot_loss_proj:4.188 [t=0.17s]
prediction: ['[CLS] came show came introduce portrayal³ denote exactly shall came bartender precisely came not to [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.638 (perp=11.801, rec=0.249, cos=0.029), tot_loss_proj:4.211 [t=0.17s]
prediction: ['[CLS] came show came introduce portrayal³ bartender exactly shall came bartender precisely came not to [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.481 (perp=11.060, rec=0.242, cos=0.027), tot_loss_proj:4.071 [t=0.17s]
prediction: ['[CLS] came to came introduce³ bartender murphy exactly shall came bartender precisely came not to [SEP]']
[ 750/2000] tot_loss=2.676 (perp=12.142, rec=0.227, cos=0.020), tot_loss_proj:4.285 [t=0.17s]
prediction: ['[CLS] came mag came introduce rune bartender murphy exactly shall came bartender precisely came not to [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.674 (perp=12.142, rec=0.227, cos=0.018), tot_loss_proj:4.279 [t=0.17s]
prediction: ['[CLS] came mag came introduce rune bartender murphy exactly shall came bartender precisely came not to [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.704 (perp=12.208, rec=0.238, cos=0.025), tot_loss_proj:4.297 [t=0.17s]
prediction: ['[CLS] came mag came introduce rune bartender exactly shall murphy came bartender precisely came not to [SEP]']
[ 900/2000] tot_loss=2.682 (perp=12.208, rec=0.222, cos=0.018), tot_loss_proj:4.298 [t=0.17s]
prediction: ['[CLS] came mag came introduce rune bartender exactly shall murphy came bartender precisely came not to [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.490 (perp=11.313, rec=0.209, cos=0.018), tot_loss_proj:4.096 [t=0.17s]
prediction: ['[CLS] came rune mag came introduce bartender exactly shallwood came bartender precisely came not to [SEP]']
Attempt swap
[1000/2000] tot_loss=2.544 (perp=11.597, rec=0.209, cos=0.015), tot_loss_proj:4.148 [t=0.17s]
prediction: ['[CLS] came mag mag came introduce bartender exactly shallwood came bartender precisely came not to [SEP]']
[1050/2000] tot_loss=2.549 (perp=11.597, rec=0.212, cos=0.018), tot_loss_proj:4.148 [t=0.17s]
prediction: ['[CLS] came mag mag came introduce bartender exactly shallwood came bartender precisely came not to [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.470 (perp=11.227, rec=0.209, cos=0.015), tot_loss_proj:4.092 [t=0.17s]
prediction: ['[CLS] came introduce mag came mag bartender exactly shallwood came bartender precisely came not to [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.494 (perp=11.322, rec=0.211, cos=0.019), tot_loss_proj:4.133 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly cannotwood mag came bartender precisely came not to [SEP]']
[1200/2000] tot_loss=2.354 (perp=10.700, rec=0.200, cos=0.015), tot_loss_proj:3.976 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly becausewood mag came bartender precisely came not to [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.310 (perp=10.529, rec=0.190, cos=0.014), tot_loss_proj:3.935 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactlywood because mag came bartender precisely came not to [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=2.191 (perp=9.752, rec=0.217, cos=0.024), tot_loss_proj:3.793 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely came not towood [SEP]']
[1350/2000] tot_loss=2.162 (perp=9.752, rec=0.196, cos=0.016), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely came not towood [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.141 (perp=9.659, rec=0.194, cos=0.015), tot_loss_proj:3.787 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
Attempt swap
[1450/2000] tot_loss=2.147 (perp=9.659, rec=0.201, cos=0.014), tot_loss_proj:3.790 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
[1500/2000] tot_loss=2.129 (perp=9.659, rec=0.184, cos=0.013), tot_loss_proj:3.789 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
Attempt swap
[1550/2000] tot_loss=2.129 (perp=9.659, rec=0.185, cos=0.013), tot_loss_proj:3.788 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
Attempt swap
[1600/2000] tot_loss=2.141 (perp=9.659, rec=0.197, cos=0.012), tot_loss_proj:3.791 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
[1650/2000] tot_loss=2.125 (perp=9.659, rec=0.181, cos=0.012), tot_loss_proj:3.789 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
Attempt swap
[1700/2000] tot_loss=2.131 (perp=9.659, rec=0.187, cos=0.012), tot_loss_proj:3.792 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
Attempt swap
[1750/2000] tot_loss=2.128 (perp=9.659, rec=0.184, cos=0.012), tot_loss_proj:3.790 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
[1800/2000] tot_loss=2.129 (perp=9.659, rec=0.186, cos=0.012), tot_loss_proj:3.786 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
Attempt swap
[1850/2000] tot_loss=2.130 (perp=9.659, rec=0.187, cos=0.011), tot_loss_proj:3.785 [t=0.17s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
Attempt swap
[1900/2000] tot_loss=2.124 (perp=9.659, rec=0.181, cos=0.011), tot_loss_proj:3.784 [t=0.20s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
[1950/2000] tot_loss=2.119 (perp=9.659, rec=0.176, cos=0.011), tot_loss_proj:3.791 [t=0.21s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
Attempt swap
[2000/2000] tot_loss=2.127 (perp=9.659, rec=0.184, cos=0.011), tot_loss_proj:3.786 [t=0.19s]
prediction: ['[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS] mag wildwood came to introduce the bartender but i came precisely not to. [SEP]
========================
predicted: 
========================
[CLS] came introduce mag came bartender exactly because mag came bartender precisely not came towood [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.065 | p: 56.250 | r: 60.000
rouge2     | fm: 6.897 | p: 6.667 | r: 7.143
rougeL     | fm: 51.613 | p: 50.000 | r: 53.333
rougeLsum  | fm: 51.613 | p: 50.000 | r: 53.333
r1fm+r2fm = 64.961

[Aggregate metrics]:
rouge1     | fm: 81.681 | p: 80.948 | r: 82.604
rouge2     | fm: 38.033 | p: 37.726 | r: 38.383
rougeL     | fm: 68.389 | p: 67.870 | r: 69.074
rougeLsum  | fm: 68.323 | p: 67.793 | r: 69.038
r1fm+r2fm = 119.714

input #65 time: 0:07:05 | total time: 9:11:37


Running input #66 of 100.
reference: 
========================
There tried to be riots in Seoul.
========================
average of cosine similarity 0.9993414821455255
highest_index [0]
highest [0.9993414821455255]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2045,  2699,  2000,  2022, 12925,  1999, 10884,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] there tried to be riots in seoul. [SEP]']
[Init] best rec loss: 1.4793832302093506 for ['[CLS] mcdonnell mount activities death today game medal ng [SEP]']
[Init] best rec loss: 1.1335169076919556 for ['[CLS] vamp kada devil kent lizard home angels [SEP]']
[Init] best rec loss: 1.1278619766235352 for ['[CLS] hanging damn landedbation fund justice category masonic [SEP]']
[Init] best rec loss: 1.095625400543213 for ['[CLS] variance airing bank whotro master newspaper wrote [SEP]']
[Init] best rec loss: 1.0252448320388794 for ['[CLS] brought their war lava message won contactedtures [SEP]']
[Init] best rec loss: 0.9582986235618591 for ['[CLS] mainger soil music means numbers this left [SEP]']
[Init] best rec loss: 0.9003497958183289 for ['[CLS]craft headed lineuplster lds farrellcellular handed [SEP]']
[Init] best rec loss: 0.8715320825576782 for ['[CLS] book web fablecing and this during benefit [SEP]']
[Init] best perm rec loss: 0.868614673614502 for ['[CLS] and benefit fable webcing during this book [SEP]']
[Init] best perm rec loss: 0.8468784689903259 for ['[CLS]cing during benefit fable book this web and [SEP]']
[Init] best perm rec loss: 0.8463841080665588 for ['[CLS]cing during web fable benefit this book and [SEP]']
[Init] best perm rec loss: 0.8429945111274719 for ['[CLS]cing this fable web during and book benefit [SEP]']
[Init] best perm rec loss: 0.8386707901954651 for ['[CLS]cing fable and during web book benefit this [SEP]']
[Init] best perm rec loss: 0.83627849817276 for ['[CLS]cing benefit and fable book during web this [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.817 (perp=12.123, rec=0.357, cos=0.035), tot_loss_proj:3.149 [t=0.17s]
prediction: ['[CLS] riots bacterium died tried have duringiculate that [SEP]']
[ 100/2000] tot_loss=2.848 (perp=12.631, rec=0.300, cos=0.022), tot_loss_proj:3.994 [t=0.17s]
prediction: ['[CLS] riots riots tried tried try at fail be [SEP]']
[ 150/2000] tot_loss=2.339 (perp=10.333, rec=0.248, cos=0.024), tot_loss_proj:2.722 [t=0.17s]
prediction: ['[CLS] there riots tried tried tried to riots be [SEP]']
[ 200/2000] tot_loss=2.238 (perp=10.372, rec=0.153, cos=0.011), tot_loss_proj:2.739 [t=0.17s]
prediction: ['[CLS] there riots tried riots tried to riots be [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.465 (perp=10.716, rec=0.295, cos=0.026), tot_loss_proj:2.808 [t=0.17s]
prediction: ['[CLS] there seoul riots tried be riots be tried [SEP]']
[ 300/2000] tot_loss=2.331 (perp=10.716, rec=0.175, cos=0.013), tot_loss_proj:2.798 [t=0.17s]
prediction: ['[CLS] there seoul riots tried be riots be tried [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.150 (perp=9.983, rec=0.144, cos=0.009), tot_loss_proj:2.704 [t=0.17s]
prediction: ['[CLS] there seoul riots be tried riots be tried [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.005 (perp=9.310, rec=0.135, cos=0.008), tot_loss_proj:2.662 [t=0.17s]
prediction: ['[CLS] there riots seoul to tried riots be tried [SEP]']
[ 450/2000] tot_loss=1.986 (perp=9.310, rec=0.116, cos=0.007), tot_loss_proj:2.665 [t=0.17s]
prediction: ['[CLS] there riots seoul to tried riots be tried [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.879 (perp=8.835, rec=0.106, cos=0.007), tot_loss_proj:2.494 [t=0.17s]
prediction: ['[CLS] there riots seoul tried to riots be tried [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.874 (perp=8.835, rec=0.101, cos=0.006), tot_loss_proj:2.503 [t=0.17s]
prediction: ['[CLS] there riots seoul tried to riots be tried [SEP]']
[ 600/2000] tot_loss=1.869 (perp=8.835, rec=0.095, cos=0.006), tot_loss_proj:2.494 [t=0.17s]
prediction: ['[CLS] there riots seoul tried to riots be tried [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.857 (perp=8.835, rec=0.084, cos=0.006), tot_loss_proj:2.498 [t=0.17s]
prediction: ['[CLS] there riots seoul tried to riots be tried [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.641 (perp=7.677, rec=0.100, cos=0.006), tot_loss_proj:2.283 [t=0.17s]
prediction: ['[CLS] there riots seoul tried to be riots. [SEP]']
[ 750/2000] tot_loss=1.632 (perp=7.677, rec=0.091, cos=0.006), tot_loss_proj:2.274 [t=0.17s]
prediction: ['[CLS] there riots seoul tried to be riots. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.477 (perp=6.886, rec=0.094, cos=0.006), tot_loss_proj:1.883 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.472 (perp=6.886, rec=0.089, cos=0.006), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
[ 900/2000] tot_loss=1.470 (perp=6.886, rec=0.087, cos=0.006), tot_loss_proj:1.884 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.459 (perp=6.886, rec=0.077, cos=0.005), tot_loss_proj:1.880 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.471 (perp=6.886, rec=0.088, cos=0.005), tot_loss_proj:1.878 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
[1050/2000] tot_loss=1.471 (perp=6.886, rec=0.089, cos=0.005), tot_loss_proj:1.880 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.462 (perp=6.886, rec=0.080, cos=0.005), tot_loss_proj:1.881 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.465 (perp=6.886, rec=0.083, cos=0.005), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
[1200/2000] tot_loss=1.460 (perp=6.886, rec=0.078, cos=0.005), tot_loss_proj:1.883 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.464 (perp=6.886, rec=0.082, cos=0.005), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.474 (perp=6.886, rec=0.093, cos=0.005), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
[1350/2000] tot_loss=1.462 (perp=6.886, rec=0.081, cos=0.004), tot_loss_proj:1.877 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.458 (perp=6.886, rec=0.076, cos=0.004), tot_loss_proj:1.883 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.467 (perp=6.886, rec=0.085, cos=0.004), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
[1500/2000] tot_loss=1.457 (perp=6.886, rec=0.076, cos=0.004), tot_loss_proj:1.884 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.447 (perp=6.886, rec=0.066, cos=0.004), tot_loss_proj:1.875 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.464 (perp=6.886, rec=0.084, cos=0.004), tot_loss_proj:1.886 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
[1650/2000] tot_loss=1.462 (perp=6.886, rec=0.081, cos=0.004), tot_loss_proj:1.878 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.456 (perp=6.886, rec=0.075, cos=0.004), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.461 (perp=6.886, rec=0.080, cos=0.004), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
[1800/2000] tot_loss=1.457 (perp=6.886, rec=0.076, cos=0.004), tot_loss_proj:1.886 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.454 (perp=6.886, rec=0.074, cos=0.003), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.459 (perp=6.886, rec=0.079, cos=0.003), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
[1950/2000] tot_loss=1.449 (perp=6.886, rec=0.069, cos=0.003), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.458 (perp=6.886, rec=0.077, cos=0.003), tot_loss_proj:1.889 [t=0.18s]
prediction: ['[CLS] seoul riots there tried to be riots. [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] there tried to be riots in seoul. [SEP]
========================
predicted: 
========================
[CLS] seoul riots there tried to be riots. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 138.889

[Aggregate metrics]:
rouge1     | fm: 81.825 | p: 81.153 | r: 82.748
rouge2     | fm: 38.164 | p: 37.897 | r: 38.536
rougeL     | fm: 68.446 | p: 67.933 | r: 69.179
rougeLsum  | fm: 68.453 | p: 67.901 | r: 69.186
r1fm+r2fm = 119.989

input #66 time: 0:06:51 | total time: 9:18:28


Running input #67 of 100.
reference: 
========================
Fido is the smarter dog than Spot.
========================
average of cosine similarity 0.9991866915016882
highest_index [0]
highest [0.9991866915016882]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 10882,  3527,  2003,  1996, 25670,  3899,  2084,  3962,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] fido is the smarter dog than spot. [SEP]']
[Init] best rec loss: 1.8722443580627441 for ['[CLS] spec legend currently boarding reasons chapel assistance accomplish through [SEP]']
[Init] best rec loss: 1.7424272298812866 for ['[CLS] bi ride driveway° student " life representative bomb [SEP]']
[Init] best rec loss: 1.6970099210739136 for ['[CLS] silkrting relating break cigarette bail finger charts do [SEP]']
[Init] best rec loss: 1.6280936002731323 for ['[CLS] word cab healthychenifying ruled mills flat prison [SEP]']
[Init] best rec loss: 1.611700415611267 for ['[CLS] qing englandmatic prix danarus abby higher remote [SEP]']
[Init] best rec loss: 1.4345662593841553 for ['[CLS] canberra mountain terms first transit ladder rats running naval [SEP]']
[Init] best perm rec loss: 1.4325761795043945 for ['[CLS] canberra running mountain transit ladder rats naval terms first [SEP]']
[Init] best perm rec loss: 1.4218223094940186 for ['[CLS] transit ladder running first mountain rats terms canberra naval [SEP]']
[Init] best perm rec loss: 1.4156819581985474 for ['[CLS] terms running canberra first rats mountain ladder transit naval [SEP]']
[Init] best perm rec loss: 1.4074838161468506 for ['[CLS] naval running first terms rats mountain ladder transit canberra [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.921 (perp=11.604, rec=0.439, cos=0.160), tot_loss_proj:4.161 [t=0.17s]
prediction: ['[CLS], scheme brought chicago dog dog travis stay hugh [SEP]']
[ 100/2000] tot_loss=2.771 (perp=11.586, rec=0.368, cos=0.086), tot_loss_proj:3.935 [t=0.17s]
prediction: ['[CLS] is smarter betterworld dog dog cho spot gemma [SEP]']
[ 150/2000] tot_loss=2.671 (perp=10.209, rec=0.460, cos=0.170), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] the smarter less than dog dog jake dex catherine [SEP]']
[ 200/2000] tot_loss=2.100 (perp=8.757, rec=0.292, cos=0.056), tot_loss_proj:3.045 [t=0.17s]
prediction: ['[CLS] the smarter less than dog dog matched popele [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.038 (perp=8.868, rec=0.219, cos=0.046), tot_loss_proj:3.379 [t=0.17s]
prediction: ['[CLS] the smarter less than dog dog spot spotle [SEP]']
[ 300/2000] tot_loss=1.982 (perp=8.868, rec=0.181, cos=0.028), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] the smarter less than dog dog spot spotle [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.228 (perp=10.261, rec=0.153, cos=0.022), tot_loss_proj:3.835 [t=0.17s]
prediction: ['[CLS] the than smarter than dog dog spot spoted [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.030 (perp=8.256, rec=0.276, cos=0.103), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] less the smarter than dog dog is spot the [SEP]']
[ 450/2000] tot_loss=1.590 (perp=7.021, rec=0.164, cos=0.022), tot_loss_proj:3.361 [t=0.17s]
prediction: ['[CLS] less the smarter than dog dog is spot. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.535 (perp=6.901, rec=0.138, cos=0.017), tot_loss_proj:3.127 [t=0.17s]
prediction: ['[CLS] less dog smarter than is dog is spot. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.449 (perp=6.549, rec=0.125, cos=0.014), tot_loss_proj:2.890 [t=0.17s]
prediction: ['[CLS] is dog smarter than does dog is spot. [SEP]']
[ 600/2000] tot_loss=1.435 (perp=6.549, rec=0.113, cos=0.012), tot_loss_proj:2.898 [t=0.17s]
prediction: ['[CLS] is dog smarter than does dog is spot. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.423 (perp=6.469, rec=0.117, cos=0.012), tot_loss_proj:2.929 [t=0.17s]
prediction: ['[CLS] dog is smarter than does dog is spot. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.405 (perp=6.469, rec=0.100, cos=0.011), tot_loss_proj:2.929 [t=0.17s]
prediction: ['[CLS] dog is smarter than does dog is spot. [SEP]']
[ 750/2000] tot_loss=1.418 (perp=6.469, rec=0.114, cos=0.011), tot_loss_proj:2.928 [t=0.17s]
prediction: ['[CLS] dog is smarter than does dog is spot. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.414 (perp=6.469, rec=0.110, cos=0.010), tot_loss_proj:2.926 [t=0.19s]
prediction: ['[CLS] dog is smarter than does dog is spot. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.448 (perp=6.748, rec=0.089, cos=0.010), tot_loss_proj:3.107 [t=0.17s]
prediction: ['[CLS] dog is smarter than is dog is spot. [SEP]']
[ 900/2000] tot_loss=1.478 (perp=6.748, rec=0.119, cos=0.010), tot_loss_proj:3.103 [t=0.17s]
prediction: ['[CLS] dog is smarter than is dog is spot. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.589 (perp=7.368, rec=0.102, cos=0.013), tot_loss_proj:2.722 [t=0.17s]
prediction: ['[CLS] is dog smarter than is dogdo spot. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.514 (perp=7.014, rec=0.100, cos=0.012), tot_loss_proj:2.868 [t=0.17s]
prediction: ['[CLS] is dog smarter than dogdo is spot. [SEP]']
[1050/2000] tot_loss=1.505 (perp=7.014, rec=0.093, cos=0.009), tot_loss_proj:2.871 [t=0.17s]
prediction: ['[CLS] is dog smarter than dogdo is spot. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.477 (perp=6.780, rec=0.113, cos=0.009), tot_loss_proj:3.178 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.454 (perp=6.780, rec=0.090, cos=0.008), tot_loss_proj:3.183 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
[1200/2000] tot_loss=1.456 (perp=6.780, rec=0.091, cos=0.008), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.443 (perp=6.780, rec=0.079, cos=0.008), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.458 (perp=6.780, rec=0.094, cos=0.008), tot_loss_proj:3.180 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
[1350/2000] tot_loss=1.460 (perp=6.780, rec=0.096, cos=0.008), tot_loss_proj:3.185 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.454 (perp=6.780, rec=0.090, cos=0.008), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.453 (perp=6.780, rec=0.089, cos=0.008), tot_loss_proj:3.183 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
[1500/2000] tot_loss=1.453 (perp=6.780, rec=0.090, cos=0.007), tot_loss_proj:3.184 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.441 (perp=6.780, rec=0.078, cos=0.007), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.446 (perp=6.780, rec=0.083, cos=0.007), tot_loss_proj:3.178 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
[1650/2000] tot_loss=1.462 (perp=6.780, rec=0.099, cos=0.007), tot_loss_proj:3.184 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.456 (perp=6.780, rec=0.093, cos=0.007), tot_loss_proj:3.184 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.446 (perp=6.780, rec=0.083, cos=0.007), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
[1800/2000] tot_loss=1.451 (perp=6.780, rec=0.088, cos=0.007), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.452 (perp=6.780, rec=0.089, cos=0.007), tot_loss_proj:3.183 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.458 (perp=6.780, rec=0.095, cos=0.007), tot_loss_proj:3.180 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
[1950/2000] tot_loss=1.463 (perp=6.780, rec=0.100, cos=0.007), tot_loss_proj:3.178 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.444 (perp=6.780, rec=0.081, cos=0.007), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] isdo smarter than dog dog is spot. [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] fido is the smarter dog than spot. [SEP]
========================
predicted: 
========================
[CLS] isdo smarter than dog dog is spot. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 90.278

[Aggregate metrics]:
rouge1     | fm: 81.692 | p: 81.030 | r: 82.640
rouge2     | fm: 37.731 | p: 37.512 | r: 38.138
rougeL     | fm: 68.228 | p: 67.721 | r: 68.969
rougeLsum  | fm: 68.248 | p: 67.766 | r: 68.953
r1fm+r2fm = 119.422

input #67 time: 0:06:53 | total time: 9:25:22


Running input #68 of 100.
reference: 
========================
John convinced the rice to be cooked by Bill.
========================
average of cosine similarity 0.9992469253349906
highest_index [0]
highest [0.9992469253349906]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2198,  6427,  1996,  5785,  2000,  2022, 12984,  2011,  3021,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] john convinced the rice to be cooked by bill. [SEP]']
[Init] best rec loss: 1.309221625328064 for ['[CLS] rich plant ticket has an boat favorite malaysia showing procedures [SEP]']
[Init] best rec loss: 1.144270658493042 for ['[CLS] ago participants bo charlie across formula alone fisheries core constantine [SEP]']
[Init] best rec loss: 1.1258279085159302 for ['[CLS] uncommon counsel national short cell mrs timing upside leyte justified [SEP]']
[Init] best rec loss: 1.1193957328796387 for ['[CLS] frozen now danhel ellie given without translatedhen reflecting [SEP]']
[Init] best rec loss: 1.0536203384399414 for ['[CLS] maintenance fr respectively sports alive turnoured acquisition barrow body [SEP]']
[Init] best rec loss: 1.0476313829421997 for ['[CLS] measures toolswell stocked arab sea ink striking capacity probation [SEP]']
[Init] best rec loss: 1.010743498802185 for ['[CLS] buy miles figureider okay hit springs loving todd contract [SEP]']
[Init] best perm rec loss: 1.0091407299041748 for ['[CLS] springs figure hit miles buy contractider okay loving todd [SEP]']
[Init] best perm rec loss: 1.0086064338684082 for ['[CLS] buy springs miles todd figureider loving contract hit okay [SEP]']
[Init] best perm rec loss: 1.0057224035263062 for ['[CLS] springs miles buy hit todd contract lovingider figure okay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.044 (perp=13.140, rec=0.348, cos=0.068), tot_loss_proj:3.634 [t=0.17s]
prediction: ['[CLS] skip to cerealrie john convinced full full players tennis [SEP]']
[ 100/2000] tot_loss=2.550 (perp=11.271, rec=0.256, cos=0.040), tot_loss_proj:3.068 [t=0.17s]
prediction: ['[CLS] joint to soupanne john convinced the board rice protein [SEP]']
[ 150/2000] tot_loss=2.217 (perp=10.065, rec=0.181, cos=0.023), tot_loss_proj:2.951 [t=0.17s]
prediction: ['[CLS] versions to rice to john convinced the rice rice rice [SEP]']
[ 200/2000] tot_loss=2.593 (perp=12.073, rec=0.144, cos=0.034), tot_loss_proj:3.639 [t=0.17s]
prediction: ['[CLS]ford to rice to john convinced the be rice rice [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.485 (perp=9.917, rec=0.411, cos=0.090), tot_loss_proj:3.353 [t=0.17s]
prediction: ['[CLS]ias in rice to be john convinced the cooked been [SEP]']
[ 300/2000] tot_loss=1.906 (perp=7.975, rec=0.270, cos=0.040), tot_loss_proj:2.832 [t=0.17s]
prediction: ['[CLS] told to rice to be john convinced the rice be [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.951 (perp=8.544, rec=0.217, cos=0.025), tot_loss_proj:2.895 [t=0.17s]
prediction: ['[CLS] convinced to rice to be john convinced the rice be [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.542 (perp=11.299, rec=0.241, cos=0.041), tot_loss_proj:3.299 [t=0.17s]
prediction: ['[CLS] john convinced rice to na convinced convinced the nicholas be [SEP]']
[ 450/2000] tot_loss=2.274 (perp=10.423, rec=0.167, cos=0.023), tot_loss_proj:3.003 [t=0.17s]
prediction: ['[CLS] john convinced rice to the convinced convinced the forewings be [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.185 (perp=10.034, rec=0.159, cos=0.019), tot_loss_proj:3.021 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the convinced thechrome be [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.986 (perp=9.158, rec=0.137, cos=0.017), tot_loss_proj:2.749 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced the °f convinced [SEP]']
[ 600/2000] tot_loss=2.004 (perp=9.301, rec=0.129, cos=0.015), tot_loss_proj:2.777 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced the to convinced [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.807 (perp=8.319, rec=0.128, cos=0.015), tot_loss_proj:2.533 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced to the convinced [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.789 (perp=8.319, rec=0.111, cos=0.014), tot_loss_proj:2.538 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced to the convinced [SEP]']
[ 750/2000] tot_loss=1.796 (perp=8.319, rec=0.119, cos=0.013), tot_loss_proj:2.534 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced to the convinced [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.846 (perp=8.645, rec=0.104, cos=0.013), tot_loss_proj:2.546 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced be the convinced [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.855 (perp=8.645, rec=0.113, cos=0.012), tot_loss_proj:2.551 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced be the convinced [SEP]']
[ 900/2000] tot_loss=1.844 (perp=8.645, rec=0.103, cos=0.012), tot_loss_proj:2.551 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced be the convinced [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.845 (perp=8.645, rec=0.105, cos=0.011), tot_loss_proj:2.551 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced be the convinced [SEP]']
Attempt swap
[1000/2000] tot_loss=1.845 (perp=8.645, rec=0.106, cos=0.011), tot_loss_proj:2.560 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced be the convinced [SEP]']
[1050/2000] tot_loss=1.850 (perp=8.645, rec=0.111, cos=0.010), tot_loss_proj:2.558 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced be the convinced [SEP]']
Attempt swap
[1100/2000] tot_loss=1.842 (perp=8.645, rec=0.103, cos=0.010), tot_loss_proj:2.557 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced be the convinced [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.839 (perp=8.645, rec=0.100, cos=0.011), tot_loss_proj:2.595 [t=0.17s]
prediction: ['[CLS] john convinced rice to be the convinced be the convinced [SEP]']
[1200/2000] tot_loss=2.016 (perp=9.517, rec=0.103, cos=0.010), tot_loss_proj:3.140 [t=0.17s]
prediction: ['[CLS] john convinced rice to cooked the convinced be the convinced [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.917 (perp=8.987, rec=0.109, cos=0.010), tot_loss_proj:2.988 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
Attempt swap
[1300/2000] tot_loss=1.894 (perp=8.987, rec=0.087, cos=0.010), tot_loss_proj:2.996 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
[1350/2000] tot_loss=1.910 (perp=8.987, rec=0.103, cos=0.010), tot_loss_proj:2.992 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.890 (perp=8.987, rec=0.084, cos=0.009), tot_loss_proj:2.942 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
Attempt swap
[1450/2000] tot_loss=1.905 (perp=8.987, rec=0.099, cos=0.009), tot_loss_proj:2.947 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
[1500/2000] tot_loss=1.914 (perp=8.987, rec=0.108, cos=0.009), tot_loss_proj:2.944 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
Attempt swap
[1550/2000] tot_loss=1.892 (perp=8.987, rec=0.086, cos=0.009), tot_loss_proj:2.947 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
Attempt swap
[1600/2000] tot_loss=1.898 (perp=8.987, rec=0.092, cos=0.009), tot_loss_proj:2.944 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
[1650/2000] tot_loss=1.894 (perp=8.987, rec=0.088, cos=0.009), tot_loss_proj:2.945 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
Attempt swap
[1700/2000] tot_loss=1.891 (perp=8.987, rec=0.085, cos=0.009), tot_loss_proj:2.953 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.894 (perp=8.987, rec=0.087, cos=0.010), tot_loss_proj:2.991 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
[1800/2000] tot_loss=1.900 (perp=8.987, rec=0.093, cos=0.010), tot_loss_proj:2.998 [t=0.17s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
Attempt swap
[1850/2000] tot_loss=1.895 (perp=8.987, rec=0.088, cos=0.010), tot_loss_proj:2.990 [t=0.19s]
prediction: ['[CLS] john convinced rice to convinced the cooked be the convinced [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.760 (perp=8.179, rec=0.110, cos=0.014), tot_loss_proj:2.614 [t=0.17s]
prediction: ['[CLS] john convinced convinced the cooked rice to be the convinced [SEP]']
[1950/2000] tot_loss=1.745 (perp=8.179, rec=0.099, cos=0.010), tot_loss_proj:2.616 [t=0.17s]
prediction: ['[CLS] john convinced convinced the cooked rice to be the convinced [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.663 (perp=7.777, rec=0.098, cos=0.009), tot_loss_proj:2.627 [t=0.17s]
prediction: ['[CLS] john convinced convinced the cooked rice to be convinced the [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] john convinced the rice to be cooked by bill. [SEP]
========================
predicted: 
========================
[CLS] john convinced rice to convinced the cooked be the convinced [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 75.000 | r: 81.818
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 60.870 | p: 58.333 | r: 63.636
rougeLsum  | fm: 60.870 | p: 58.333 | r: 63.636
r1fm+r2fm = 116.356

[Aggregate metrics]:
rouge1     | fm: 81.687 | p: 80.968 | r: 82.579
rouge2     | fm: 37.875 | p: 37.576 | r: 38.280
rougeL     | fm: 68.140 | p: 67.655 | r: 68.880
rougeLsum  | fm: 68.185 | p: 67.644 | r: 68.911
r1fm+r2fm = 119.562

input #68 time: 0:06:52 | total time: 9:32:15


Running input #69 of 100.
reference: 
========================
The squirrel ran straight quickly.
========================
average of cosine similarity 0.9993800710871901
highest_index [0]
highest [0.9993800710871901]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 18197,  2743,  3442,  2855,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the squirrel ran straight quickly. [SEP]']
[Init] best rec loss: 1.1452172994613647 for ['[CLS] theme skin alive won reach one [SEP]']
[Init] best rec loss: 0.9454455375671387 for ['[CLS] action ou defenceiom unto violence [SEP]']
[Init] best rec loss: 0.8561535477638245 for ['[CLS] brief forgetlyhawks husbandch [SEP]']
[Init] best perm rec loss: 0.8506807684898376 for ['[CLS] brieftlyhawks husband forgech [SEP]']
[Init] best perm rec loss: 0.8461862802505493 for ['[CLS] brieftlyhawksch husband forge [SEP]']
[Init] best perm rec loss: 0.8444114327430725 for ['[CLS] brieftly forgehawks husbandch [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.456 (perp=10.216, rec=0.330, cos=0.083), tot_loss_proj:2.863 [t=0.18s]
prediction: ['[CLS] went straight during guard had straight [SEP]']
[ 100/2000] tot_loss=2.426 (perp=8.980, rec=0.533, cos=0.096), tot_loss_proj:2.634 [t=0.19s]
prediction: ['[CLS] followed quickly was and then straight [SEP]']
[ 150/2000] tot_loss=2.391 (perp=9.946, rec=0.347, cos=0.055), tot_loss_proj:3.025 [t=0.19s]
prediction: ['[CLS] quickly quickly ran ( followed straight [SEP]']
[ 200/2000] tot_loss=1.980 (perp=8.537, rec=0.239, cos=0.033), tot_loss_proj:2.541 [t=0.19s]
prediction: ['[CLS] straight quickly ran quickly either straight [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.890 (perp=8.384, rec=0.189, cos=0.023), tot_loss_proj:2.597 [t=0.19s]
prediction: ['[CLS] quickly ran straight quickly straight straight [SEP]']
[ 300/2000] tot_loss=1.829 (perp=8.304, rec=0.149, cos=0.019), tot_loss_proj:2.524 [t=0.19s]
prediction: ['[CLS] quickly ran straight quickly ran straight [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.819 (perp=8.304, rec=0.144, cos=0.014), tot_loss_proj:2.516 [t=0.19s]
prediction: ['[CLS] quickly ran straight quickly ran straight [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.093 (perp=9.795, rec=0.122, cos=0.013), tot_loss_proj:2.873 [t=0.17s]
prediction: ['[CLS] squirrel quickly straight quickly ran straight [SEP]']
[ 450/2000] tot_loss=2.094 (perp=9.795, rec=0.126, cos=0.009), tot_loss_proj:2.879 [t=0.17s]
prediction: ['[CLS] squirrel quickly straight quickly ran straight [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.950 (perp=9.174, rec=0.106, cos=0.008), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.953 (perp=9.174, rec=0.111, cos=0.007), tot_loss_proj:2.483 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
[ 600/2000] tot_loss=1.956 (perp=9.174, rec=0.115, cos=0.007), tot_loss_proj:2.491 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.938 (perp=9.174, rec=0.097, cos=0.006), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.954 (perp=9.174, rec=0.113, cos=0.006), tot_loss_proj:2.503 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
[ 750/2000] tot_loss=1.934 (perp=9.174, rec=0.093, cos=0.006), tot_loss_proj:2.503 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.940 (perp=9.174, rec=0.099, cos=0.006), tot_loss_proj:2.497 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.936 (perp=9.174, rec=0.095, cos=0.006), tot_loss_proj:2.504 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
[ 900/2000] tot_loss=1.941 (perp=9.174, rec=0.100, cos=0.006), tot_loss_proj:2.511 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.942 (perp=9.174, rec=0.101, cos=0.006), tot_loss_proj:2.505 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly straight [SEP]']
Attempt swap
[1000/2000] tot_loss=2.131 (perp=10.082, rec=0.109, cos=0.006), tot_loss_proj:2.843 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1050/2000] tot_loss=2.115 (perp=10.082, rec=0.092, cos=0.006), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1100/2000] tot_loss=2.116 (perp=10.082, rec=0.093, cos=0.006), tot_loss_proj:2.850 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1150/2000] tot_loss=2.119 (perp=10.082, rec=0.096, cos=0.006), tot_loss_proj:2.842 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1200/2000] tot_loss=2.124 (perp=10.082, rec=0.101, cos=0.006), tot_loss_proj:2.854 [t=0.21s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1250/2000] tot_loss=2.116 (perp=10.082, rec=0.094, cos=0.006), tot_loss_proj:2.845 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1300/2000] tot_loss=2.117 (perp=10.082, rec=0.095, cos=0.006), tot_loss_proj:2.841 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1350/2000] tot_loss=2.112 (perp=10.082, rec=0.089, cos=0.006), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1400/2000] tot_loss=2.108 (perp=10.082, rec=0.085, cos=0.006), tot_loss_proj:2.845 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1450/2000] tot_loss=2.116 (perp=10.082, rec=0.094, cos=0.006), tot_loss_proj:2.850 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1500/2000] tot_loss=2.121 (perp=10.082, rec=0.098, cos=0.006), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1550/2000] tot_loss=2.101 (perp=10.082, rec=0.078, cos=0.006), tot_loss_proj:2.845 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1600/2000] tot_loss=2.124 (perp=10.082, rec=0.102, cos=0.006), tot_loss_proj:2.842 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1650/2000] tot_loss=2.112 (perp=10.082, rec=0.089, cos=0.006), tot_loss_proj:2.844 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1700/2000] tot_loss=2.128 (perp=10.082, rec=0.106, cos=0.006), tot_loss_proj:2.849 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1750/2000] tot_loss=2.113 (perp=10.082, rec=0.090, cos=0.006), tot_loss_proj:2.846 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1800/2000] tot_loss=2.113 (perp=10.082, rec=0.090, cos=0.006), tot_loss_proj:2.851 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1850/2000] tot_loss=2.109 (perp=10.082, rec=0.087, cos=0.006), tot_loss_proj:2.848 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[1900/2000] tot_loss=2.123 (perp=10.082, rec=0.100, cos=0.006), tot_loss_proj:2.853 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
[1950/2000] tot_loss=2.125 (perp=10.082, rec=0.103, cos=0.006), tot_loss_proj:2.849 [t=0.17s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Attempt swap
[2000/2000] tot_loss=2.117 (perp=10.082, rec=0.094, cos=0.006), tot_loss_proj:2.848 [t=0.19s]
prediction: ['[CLS] squirrel quickly ran straight quickly good [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] the squirrel ran straight quickly. [SEP]
========================
predicted: 
========================
[CLS] squirrel quickly ran straight quickly good [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 30.769 | p: 28.571 | r: 33.333
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 110.769

[Aggregate metrics]:
rouge1     | fm: 81.672 | p: 80.924 | r: 82.659
rouge2     | fm: 37.662 | p: 37.376 | r: 38.073
rougeL     | fm: 68.360 | p: 67.804 | r: 69.142
rougeLsum  | fm: 68.316 | p: 67.704 | r: 69.122
r1fm+r2fm = 119.334

input #69 time: 0:07:03 | total time: 9:39:18


Running input #70 of 100.
reference: 
========================
I assumed to be innocent
========================
average of cosine similarity 0.9993176562362933
highest_index [0]
highest [0.9993176562362933]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 5071, 2000, 2022, 7036,  102]], device='cuda:0')
Debug: ref = ['[CLS] i assumed to be innocent [SEP]']
[Init] best rec loss: 1.3912060260772705 for ['[CLS] down op epithet medicine sick [SEP]']
[Init] best rec loss: 1.23323392868042 for ['[CLS] small beings equation flightfall [SEP]']
[Init] best rec loss: 1.1429134607315063 for ['[CLS] can else king closed code [SEP]']
[Init] best rec loss: 1.1128222942352295 for ['[CLS] brother coordinator rough mind investments [SEP]']
[Init] best rec loss: 1.0194593667984009 for ['[CLS] [ across not inside stuff [SEP]']
[Init] best rec loss: 1.015527367591858 for ['[CLS]werk guest many ranchothed [SEP]']
[Init] best rec loss: 0.9733350872993469 for ['[CLS] oh kept middle pen opener [SEP]']
[Init] best perm rec loss: 0.9714557528495789 for ['[CLS] opener kept pen oh middle [SEP]']
[Init] best perm rec loss: 0.9684093594551086 for ['[CLS] middle opener kept oh pen [SEP]']
[Init] best perm rec loss: 0.9677919149398804 for ['[CLS] middle kept opener oh pen [SEP]']
[Init] best perm rec loss: 0.9656559824943542 for ['[CLS] pen kept opener oh middle [SEP]']
[Init] best perm rec loss: 0.9649540781974792 for ['[CLS] pen kept oh opener middle [SEP]']
[Init] best perm rec loss: 0.9645490646362305 for ['[CLS] pen opener oh kept middle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.784 (perp=11.636, rec=0.403, cos=0.053), tot_loss_proj:3.640 [t=0.17s]
prediction: ["[CLS] proof assumed'descendants red [SEP]"]
[ 100/2000] tot_loss=2.266 (perp=9.021, rec=0.406, cos=0.056), tot_loss_proj:2.547 [t=0.17s]
prediction: ['[CLS] certificate assumed and was genuine [SEP]']
[ 150/2000] tot_loss=2.171 (perp=9.688, rec=0.212, cos=0.022), tot_loss_proj:3.039 [t=0.17s]
prediction: ['[CLS] assumed assumed, be innocent [SEP]']
[ 200/2000] tot_loss=1.417 (perp=6.470, rec=0.119, cos=0.005), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.381 (perp=6.470, rec=0.086, cos=0.002), tot_loss_proj:1.500 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 300/2000] tot_loss=1.365 (perp=6.470, rec=0.069, cos=0.001), tot_loss_proj:1.501 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.365 (perp=6.470, rec=0.070, cos=0.001), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.359 (perp=6.470, rec=0.064, cos=0.001), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 450/2000] tot_loss=1.356 (perp=6.470, rec=0.061, cos=0.001), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.359 (perp=6.470, rec=0.063, cos=0.001), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.365 (perp=6.470, rec=0.069, cos=0.001), tot_loss_proj:1.492 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 600/2000] tot_loss=1.373 (perp=6.470, rec=0.078, cos=0.001), tot_loss_proj:1.483 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.348 (perp=6.470, rec=0.053, cos=0.001), tot_loss_proj:1.492 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.358 (perp=6.470, rec=0.063, cos=0.001), tot_loss_proj:1.487 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 750/2000] tot_loss=1.359 (perp=6.470, rec=0.063, cos=0.001), tot_loss_proj:1.489 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.354 (perp=6.470, rec=0.059, cos=0.001), tot_loss_proj:1.488 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.359 (perp=6.470, rec=0.063, cos=0.001), tot_loss_proj:1.481 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[ 900/2000] tot_loss=1.347 (perp=6.470, rec=0.052, cos=0.001), tot_loss_proj:1.479 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.345 (perp=6.470, rec=0.050, cos=0.001), tot_loss_proj:1.481 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.363 (perp=6.470, rec=0.068, cos=0.001), tot_loss_proj:1.475 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1050/2000] tot_loss=1.366 (perp=6.470, rec=0.071, cos=0.001), tot_loss_proj:1.478 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.359 (perp=6.470, rec=0.064, cos=0.001), tot_loss_proj:1.473 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.354 (perp=6.470, rec=0.059, cos=0.001), tot_loss_proj:1.471 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1200/2000] tot_loss=1.356 (perp=6.470, rec=0.061, cos=0.001), tot_loss_proj:1.472 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.346 (perp=6.470, rec=0.051, cos=0.001), tot_loss_proj:1.480 [t=0.18s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.356 (perp=6.470, rec=0.061, cos=0.001), tot_loss_proj:1.478 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1350/2000] tot_loss=1.366 (perp=6.470, rec=0.071, cos=0.001), tot_loss_proj:1.478 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.361 (perp=6.470, rec=0.066, cos=0.001), tot_loss_proj:1.474 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.349 (perp=6.470, rec=0.053, cos=0.001), tot_loss_proj:1.482 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1500/2000] tot_loss=1.359 (perp=6.470, rec=0.064, cos=0.001), tot_loss_proj:1.471 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.363 (perp=6.470, rec=0.068, cos=0.001), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.356 (perp=6.470, rec=0.060, cos=0.001), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1650/2000] tot_loss=1.357 (perp=6.470, rec=0.062, cos=0.001), tot_loss_proj:1.472 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.360 (perp=6.470, rec=0.064, cos=0.001), tot_loss_proj:1.482 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.360 (perp=6.470, rec=0.065, cos=0.001), tot_loss_proj:1.473 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1800/2000] tot_loss=1.340 (perp=6.470, rec=0.045, cos=0.001), tot_loss_proj:1.471 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.353 (perp=6.470, rec=0.057, cos=0.001), tot_loss_proj:1.455 [t=0.17s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.359 (perp=6.470, rec=0.063, cos=0.001), tot_loss_proj:1.476 [t=0.20s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
[1950/2000] tot_loss=1.351 (perp=6.470, rec=0.056, cos=0.001), tot_loss_proj:1.484 [t=0.19s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.359 (perp=6.470, rec=0.064, cos=0.001), tot_loss_proj:1.471 [t=0.19s]
prediction: ['[CLS] i assumed to be innocent [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] i assumed to be innocent [SEP]
========================
predicted: 
========================
[CLS] i assumed to be innocent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 81.967 | p: 81.190 | r: 82.929
rouge2     | fm: 38.536 | p: 38.201 | r: 38.969
rougeL     | fm: 68.751 | p: 68.192 | r: 69.512
rougeLsum  | fm: 68.829 | p: 68.259 | r: 69.613
r1fm+r2fm = 120.503

input #70 time: 0:06:58 | total time: 9:46:16


Running input #71 of 100.
reference: 
========================
He could not have been working.
========================
average of cosine similarity 0.9994072032581219
highest_index [0]
highest [0.9994072032581219]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 2071, 2025, 2031, 2042, 2551, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he could not have been working. [SEP]']
[Init] best rec loss: 1.8963830471038818 for ['[CLS] winston q officer obedience maize creamkha [SEP]']
[Init] best rec loss: 1.8867857456207275 for ['[CLS] deposit on twinned shadow layout and shining [SEP]']
[Init] best rec loss: 1.8768842220306396 for ['[CLS] [CLS] holt mls urgent we hey following [SEP]']
[Init] best rec loss: 1.8182096481323242 for ['[CLS] got red moment free zane van distinguish [SEP]']
[Init] best rec loss: 1.8042283058166504 for ['[CLS] armstrong may film subsidiary listed bridge sad [SEP]']
[Init] best rec loss: 1.8012009859085083 for ['[CLS]tine up heraldic customary particularholding raven [SEP]']
[Init] best rec loss: 1.7897928953170776 for ['[CLS] reproduced doorbell constantheater doctors melted scouts [SEP]']
[Init] best rec loss: 1.751822590827942 for ['[CLS] already film throatowed quite couple ist [SEP]']
[Init] best perm rec loss: 1.7514115571975708 for ['[CLS]owed quite film throat already couple ist [SEP]']
[Init] best perm rec loss: 1.7379438877105713 for ['[CLS] throat quiteowed already couple film ist [SEP]']
[Init] best perm rec loss: 1.7322558164596558 for ['[CLS] alreadyowed throat quite couple film ist [SEP]']
[Init] best perm rec loss: 1.730366587638855 for ['[CLS] already throat quiteowed couple film ist [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.706 (perp=10.653, rec=0.576, cos=0.999), tot_loss_proj:3.962 [t=0.17s]
prediction: ['[CLS] never along. including and across wyatt [SEP]']
[ 100/2000] tot_loss=2.071 (perp=7.939, rec=0.354, cos=0.129), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] they would.. had crossed been [SEP]']
[ 150/2000] tot_loss=2.199 (perp=9.596, rec=0.241, cos=0.039), tot_loss_proj:3.778 [t=0.17s]
prediction: ['[CLS] at cannot working. worked been working [SEP]']
[ 200/2000] tot_loss=2.237 (perp=10.156, rec=0.185, cos=0.021), tot_loss_proj:3.847 [t=0.17s]
prediction: ['[CLS] could could working. had working working [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.070 (perp=9.582, rec=0.139, cos=0.014), tot_loss_proj:3.837 [t=0.17s]
prediction: ['[CLS] could could working. have working been [SEP]']
[ 300/2000] tot_loss=1.887 (perp=8.747, rec=0.125, cos=0.013), tot_loss_proj:3.575 [t=0.17s]
prediction: ['[CLS] could he working. have been been [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.710 (perp=7.899, rec=0.118, cos=0.012), tot_loss_proj:3.565 [t=0.17s]
prediction: ['[CLS] he could working. have been been [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.605 (perp=7.386, rec=0.118, cos=0.010), tot_loss_proj:3.648 [t=0.17s]
prediction: ['[CLS] he could working. have been not [SEP]']
[ 450/2000] tot_loss=1.603 (perp=7.386, rec=0.113, cos=0.012), tot_loss_proj:3.628 [t=0.17s]
prediction: ['[CLS] he could working. have been not [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.286 (perp=5.748, rec=0.124, cos=0.012), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.269 (perp=5.748, rec=0.109, cos=0.011), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
[ 600/2000] tot_loss=1.264 (perp=5.748, rec=0.106, cos=0.009), tot_loss_proj:1.881 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.267 (perp=5.748, rec=0.110, cos=0.008), tot_loss_proj:1.882 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.260 (perp=5.748, rec=0.102, cos=0.008), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
[ 750/2000] tot_loss=1.268 (perp=5.748, rec=0.111, cos=0.007), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.267 (perp=5.748, rec=0.111, cos=0.006), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.266 (perp=5.748, rec=0.110, cos=0.007), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
[ 900/2000] tot_loss=1.261 (perp=5.748, rec=0.106, cos=0.005), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.246 (perp=5.748, rec=0.091, cos=0.005), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
Attempt swap
[1000/2000] tot_loss=1.255 (perp=5.748, rec=0.100, cos=0.005), tot_loss_proj:1.882 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
[1050/2000] tot_loss=1.253 (perp=5.748, rec=0.098, cos=0.005), tot_loss_proj:1.883 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
Attempt swap
[1100/2000] tot_loss=1.277 (perp=5.748, rec=0.117, cos=0.011), tot_loss_proj:1.873 [t=0.17s]
prediction: ['[CLS] he could not. have been working [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=0.919 (perp=4.026, rec=0.107, cos=0.007), tot_loss_proj:0.919 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1200/2000] tot_loss=0.909 (perp=4.026, rec=0.098, cos=0.006), tot_loss_proj:0.923 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.908 (perp=4.026, rec=0.097, cos=0.005), tot_loss_proj:0.923 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.907 (perp=4.026, rec=0.096, cos=0.005), tot_loss_proj:0.921 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1350/2000] tot_loss=0.903 (perp=4.026, rec=0.093, cos=0.005), tot_loss_proj:0.919 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.902 (perp=4.026, rec=0.092, cos=0.005), tot_loss_proj:0.912 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.912 (perp=4.026, rec=0.101, cos=0.005), tot_loss_proj:0.914 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1500/2000] tot_loss=0.901 (perp=4.026, rec=0.091, cos=0.005), tot_loss_proj:0.921 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.902 (perp=4.026, rec=0.090, cos=0.006), tot_loss_proj:0.923 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.898 (perp=4.026, rec=0.088, cos=0.005), tot_loss_proj:0.926 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1650/2000] tot_loss=0.893 (perp=4.026, rec=0.083, cos=0.005), tot_loss_proj:0.919 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.893 (perp=4.026, rec=0.082, cos=0.005), tot_loss_proj:0.923 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.908 (perp=4.026, rec=0.098, cos=0.005), tot_loss_proj:0.916 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1800/2000] tot_loss=0.892 (perp=4.026, rec=0.082, cos=0.005), tot_loss_proj:0.921 [t=0.19s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.907 (perp=4.026, rec=0.097, cos=0.005), tot_loss_proj:0.918 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.885 (perp=4.026, rec=0.075, cos=0.005), tot_loss_proj:0.915 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
[1950/2000] tot_loss=0.906 (perp=4.026, rec=0.095, cos=0.005), tot_loss_proj:0.915 [t=0.17s]
prediction: ['[CLS] he could not have been working. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.895 (perp=4.026, rec=0.085, cos=0.005), tot_loss_proj:0.917 [t=0.19s]
prediction: ['[CLS] he could not have been working. [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] he could not have been working. [SEP]
========================
predicted: 
========================
[CLS] he could not have been working. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.289 | p: 81.463 | r: 83.268
rouge2     | fm: 39.428 | p: 39.111 | r: 39.919
rougeL     | fm: 69.224 | p: 68.704 | r: 70.026
rougeLsum  | fm: 69.227 | p: 68.600 | r: 70.000
r1fm+r2fm = 121.716

input #71 time: 0:06:51 | total time: 9:53:08


Running input #72 of 100.
reference: 
========================
He goes.
========================
average of cosine similarity 0.9991964877569263
highest_index [0]
highest [0.9991964877569263]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 2002, 3632, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] he goes. [SEP]']
[Init] best rec loss: 1.9226821660995483 for ['[CLS] prior keynes latter [SEP]']
[Init] best rec loss: 1.9134042263031006 for ['[CLS] workshopgaard drift [SEP]']
[Init] best rec loss: 1.8578845262527466 for ['[CLS] diver prism theme [SEP]']
[Init] best rec loss: 1.824508786201477 for ['[CLS]ppet classic immune [SEP]']
[Init] best rec loss: 1.807704210281372 for ['[CLS] seller preventing crowley [SEP]']
[Init] best rec loss: 1.8056634664535522 for ['[CLS] metro mir center [SEP]']
[Init] best rec loss: 1.7470712661743164 for ['[CLS] thus trouble blocking [SEP]']
[Init] best rec loss: 1.6147851943969727 for ['[CLS] shouldn might wight [SEP]']
[Init] best perm rec loss: 1.6102136373519897 for ['[CLS] shouldn wight might [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.772 (perp=12.190, rec=0.286, cos=0.048), tot_loss_proj:4.301 [t=0.17s]
prediction: ['[CLS] went went might [SEP]']
[ 100/2000] tot_loss=1.170 (perp=5.241, rec=0.110, cos=0.012), tot_loss_proj:1.228 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 150/2000] tot_loss=1.148 (perp=5.241, rec=0.092, cos=0.009), tot_loss_proj:1.238 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 200/2000] tot_loss=1.150 (perp=5.241, rec=0.092, cos=0.010), tot_loss_proj:1.233 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.151 (perp=5.241, rec=0.096, cos=0.007), tot_loss_proj:1.219 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 300/2000] tot_loss=1.144 (perp=5.241, rec=0.090, cos=0.006), tot_loss_proj:1.225 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.141 (perp=5.241, rec=0.087, cos=0.006), tot_loss_proj:1.221 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.139 (perp=5.241, rec=0.085, cos=0.006), tot_loss_proj:1.219 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 450/2000] tot_loss=1.122 (perp=5.241, rec=0.068, cos=0.006), tot_loss_proj:1.224 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.122 (perp=5.241, rec=0.068, cos=0.006), tot_loss_proj:1.223 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.115 (perp=5.241, rec=0.061, cos=0.006), tot_loss_proj:1.223 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 600/2000] tot_loss=1.125 (perp=5.241, rec=0.071, cos=0.006), tot_loss_proj:1.222 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.135 (perp=5.241, rec=0.080, cos=0.006), tot_loss_proj:1.229 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.127 (perp=5.241, rec=0.073, cos=0.006), tot_loss_proj:1.218 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 750/2000] tot_loss=1.121 (perp=5.241, rec=0.067, cos=0.006), tot_loss_proj:1.215 [t=0.22s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.130 (perp=5.241, rec=0.076, cos=0.006), tot_loss_proj:1.227 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.133 (perp=5.241, rec=0.079, cos=0.006), tot_loss_proj:1.228 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[ 900/2000] tot_loss=1.130 (perp=5.241, rec=0.075, cos=0.006), tot_loss_proj:1.223 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.136 (perp=5.241, rec=0.082, cos=0.006), tot_loss_proj:1.233 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.124 (perp=5.241, rec=0.070, cos=0.006), tot_loss_proj:1.228 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1050/2000] tot_loss=1.134 (perp=5.241, rec=0.080, cos=0.006), tot_loss_proj:1.233 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.123 (perp=5.241, rec=0.069, cos=0.006), tot_loss_proj:1.225 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.131 (perp=5.241, rec=0.077, cos=0.006), tot_loss_proj:1.218 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1200/2000] tot_loss=1.127 (perp=5.241, rec=0.073, cos=0.006), tot_loss_proj:1.233 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.132 (perp=5.241, rec=0.078, cos=0.006), tot_loss_proj:1.227 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.132 (perp=5.241, rec=0.078, cos=0.006), tot_loss_proj:1.240 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1350/2000] tot_loss=1.133 (perp=5.241, rec=0.078, cos=0.006), tot_loss_proj:1.230 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.122 (perp=5.241, rec=0.068, cos=0.006), tot_loss_proj:1.231 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.131 (perp=5.241, rec=0.076, cos=0.006), tot_loss_proj:1.224 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1500/2000] tot_loss=1.135 (perp=5.241, rec=0.081, cos=0.006), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.131 (perp=5.241, rec=0.077, cos=0.006), tot_loss_proj:1.228 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.128 (perp=5.241, rec=0.074, cos=0.006), tot_loss_proj:1.235 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1650/2000] tot_loss=1.133 (perp=5.241, rec=0.079, cos=0.006), tot_loss_proj:1.233 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.129 (perp=5.241, rec=0.075, cos=0.006), tot_loss_proj:1.238 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.131 (perp=5.241, rec=0.077, cos=0.006), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
[1800/2000] tot_loss=1.118 (perp=5.241, rec=0.064, cos=0.006), tot_loss_proj:1.231 [t=0.17s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.130 (perp=5.241, rec=0.076, cos=0.006), tot_loss_proj:1.226 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.131 (perp=5.241, rec=0.076, cos=0.006), tot_loss_proj:1.232 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
[1950/2000] tot_loss=1.138 (perp=5.241, rec=0.083, cos=0.006), tot_loss_proj:1.241 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.127 (perp=5.241, rec=0.073, cos=0.006), tot_loss_proj:1.230 [t=0.19s]
prediction: ['[CLS] he goes. [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] he goes. [SEP]
========================
predicted: 
========================
[CLS] he goes. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.444 | p: 81.664 | r: 83.332
rouge2     | fm: 40.269 | p: 39.957 | r: 40.737
rougeL     | fm: 69.634 | p: 69.063 | r: 70.371
rougeLsum  | fm: 69.646 | p: 69.089 | r: 70.444
r1fm+r2fm = 122.712

input #72 time: 0:06:50 | total time: 9:59:59


Running input #73 of 100.
reference: 
========================
This machine records well.
========================
average of cosine similarity 0.9994617040871804
highest_index [0]
highest [0.9994617040871804]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2023, 3698, 2636, 2092, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] this machine records well. [SEP]']
[Init] best rec loss: 1.8811092376708984 for ['[CLS] miss violet chord parole tempo [SEP]']
[Init] best rec loss: 1.8533735275268555 for ['[CLS]dilly records fortune instituteberry [SEP]']
[Init] best rec loss: 1.833971381187439 for ['[CLS] guest brushed news pursuing church [SEP]']
[Init] best rec loss: 1.7970069646835327 for ['[CLS] pursuit pas heroic because attitude [SEP]']
[Init] best rec loss: 1.774659276008606 for ['[CLS]ft day ninja maynard calculation [SEP]']
[Init] best rec loss: 1.7528139352798462 for ['[CLS] beyonce orders suit passing iron [SEP]']
[Init] best rec loss: 1.7495248317718506 for ['[CLS] melody norfolk ibn headsels [SEP]']
[Init] best rec loss: 1.6856272220611572 for ['[CLS] referee temple cincinnati m² conversation [SEP]']
[Init] best perm rec loss: 1.6621443033218384 for ['[CLS] m² cincinnati temple conversation referee [SEP]']
[Init] best perm rec loss: 1.6546549797058105 for ['[CLS] cincinnati m² conversation temple referee [SEP]']
[Init] best perm rec loss: 1.6463290452957153 for ['[CLS] conversation referee m² cincinnati temple [SEP]']
[Init] best perm rec loss: 1.6216455698013306 for ['[CLS] m² cincinnati conversation referee temple [SEP]']
[Init] best perm rec loss: 1.6163352727890015 for ['[CLS] cincinnati m² conversation referee temple [SEP]']
[Init] best perm rec loss: 1.6162760257720947 for ['[CLS] cincinnati m² referee conversation temple [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.771 (perp=10.178, rec=0.488, cos=0.247), tot_loss_proj:3.835 [t=0.17s]
prediction: ['[CLS] matter anderson for fishing from [SEP]']
[ 100/2000] tot_loss=2.675 (perp=11.265, rec=0.357, cos=0.065), tot_loss_proj:4.249 [t=0.17s]
prediction: ['[CLS] collections machines really feature from [SEP]']
[ 150/2000] tot_loss=2.084 (perp=8.756, rec=0.298, cos=0.034), tot_loss_proj:3.740 [t=0.17s]
prediction: ['[CLS] records records records feature, [SEP]']
[ 200/2000] tot_loss=2.148 (perp=8.966, rec=0.304, cos=0.051), tot_loss_proj:3.868 [t=0.17s]
prediction: ['[CLS] records machine records well, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.868 (perp=7.926, rec=0.258, cos=0.025), tot_loss_proj:3.603 [t=0.17s]
prediction: ['[CLS] machine records records well, [SEP]']
[ 300/2000] tot_loss=1.831 (perp=7.926, rec=0.224, cos=0.022), tot_loss_proj:3.607 [t=0.17s]
prediction: ['[CLS] machine records records well, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.800 (perp=7.926, rec=0.199, cos=0.017), tot_loss_proj:3.600 [t=0.17s]
prediction: ['[CLS] machine records records well, [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.801 (perp=10.911, rec=0.479, cos=0.140), tot_loss_proj:4.188 [t=0.17s]
prediction: ['[CLS] machine creepy. computer from [SEP]']
[ 450/2000] tot_loss=2.569 (perp=10.238, rec=0.410, cos=0.111), tot_loss_proj:3.941 [t=0.17s]
prediction: ['[CLS] this creepy. computer from [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.726 (perp=11.277, rec=0.379, cos=0.092), tot_loss_proj:4.210 [t=0.17s]
prediction: ['[CLS] this creepy computer this from [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.145 (perp=8.530, rec=0.358, cos=0.081), tot_loss_proj:3.001 [t=0.17s]
prediction: ['[CLS] this creepy machine machine, [SEP]']
[ 600/2000] tot_loss=2.291 (perp=9.396, rec=0.341, cos=0.070), tot_loss_proj:3.868 [t=0.17s]
prediction: ['[CLS]. creepy machine machine, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.074 (perp=8.422, rec=0.326, cos=0.064), tot_loss_proj:3.546 [t=0.17s]
prediction: ['[CLS] machine. creepy machine, [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.222 (perp=9.266, rec=0.313, cos=0.056), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS] machine records machine creepy, [SEP]']
[ 750/2000] tot_loss=2.209 (perp=9.266, rec=0.303, cos=0.052), tot_loss_proj:3.865 [t=0.17s]
prediction: ['[CLS] machine records machine creepy, [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.082 (perp=8.682, rec=0.301, cos=0.044), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS] machine machine records creepy, [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.100 (perp=8.831, rec=0.294, cos=0.040), tot_loss_proj:3.590 [t=0.17s]
prediction: ['[CLS] this machine records creepy, [SEP]']
[ 900/2000] tot_loss=1.825 (perp=7.565, rec=0.276, cos=0.036), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.820 (perp=7.565, rec=0.273, cos=0.034), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.814 (perp=7.565, rec=0.269, cos=0.032), tot_loss_proj:3.420 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
[1050/2000] tot_loss=1.803 (perp=7.565, rec=0.260, cos=0.030), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.807 (perp=7.565, rec=0.265, cos=0.029), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.798 (perp=7.565, rec=0.258, cos=0.027), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
[1200/2000] tot_loss=1.789 (perp=7.565, rec=0.250, cos=0.026), tot_loss_proj:3.426 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.788 (perp=7.565, rec=0.250, cos=0.025), tot_loss_proj:3.425 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.770 (perp=7.565, rec=0.232, cos=0.025), tot_loss_proj:3.425 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
[1350/2000] tot_loss=1.764 (perp=7.565, rec=0.227, cos=0.024), tot_loss_proj:3.419 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.778 (perp=7.565, rec=0.241, cos=0.023), tot_loss_proj:3.421 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.757 (perp=7.565, rec=0.222, cos=0.023), tot_loss_proj:3.426 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
[1500/2000] tot_loss=1.754 (perp=7.565, rec=0.219, cos=0.022), tot_loss_proj:3.420 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.774 (perp=7.565, rec=0.240, cos=0.022), tot_loss_proj:3.420 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.758 (perp=7.565, rec=0.224, cos=0.021), tot_loss_proj:3.421 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
[1650/2000] tot_loss=1.760 (perp=7.565, rec=0.226, cos=0.021), tot_loss_proj:3.426 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.762 (perp=7.565, rec=0.229, cos=0.021), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.763 (perp=7.565, rec=0.229, cos=0.020), tot_loss_proj:3.429 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
[1800/2000] tot_loss=1.742 (perp=7.565, rec=0.209, cos=0.020), tot_loss_proj:3.420 [t=0.19s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.761 (perp=7.565, rec=0.228, cos=0.020), tot_loss_proj:3.425 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.742 (perp=7.565, rec=0.209, cos=0.019), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
[1950/2000] tot_loss=1.757 (perp=7.565, rec=0.225, cos=0.019), tot_loss_proj:3.427 [t=0.17s]
prediction: ['[CLS] this machine records an, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.746 (perp=7.565, rec=0.213, cos=0.019), tot_loss_proj:3.422 [t=0.22s]
prediction: ['[CLS] this machine records an, [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] this machine records well. [SEP]
========================
predicted: 
========================
[CLS] machine records records well, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 143.333

[Aggregate metrics]:
rouge1     | fm: 82.452 | p: 81.671 | r: 83.401
rouge2     | fm: 40.552 | p: 40.272 | r: 40.966
rougeL     | fm: 69.805 | p: 69.270 | r: 70.598
rougeLsum  | fm: 69.794 | p: 69.247 | r: 70.512
r1fm+r2fm = 123.004

input #73 time: 0:06:57 | total time: 10:06:56


Running input #74 of 100.
reference: 
========================
Love her though I may, that won't affect the grade.
========================
average of cosine similarity 0.9993168384864592
highest_index [0]
highest [0.9993168384864592]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2293, 2014, 2295, 1045, 2089, 1010, 2008, 2180, 1005, 1056, 7461,
         1996, 3694, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] love her though i may, that won't affect the grade. [SEP]"]
[Init] best rec loss: 1.9842681884765625 for ['[CLS] charm joke classification lemon vhs d （ alzheimer minogueify gunslinger part used club [SEP]']
[Init] best rec loss: 1.901560664176941 for ['[CLS] blast health charliebase can through letterns door alternatives attenditatedatin competed [SEP]']
[Init] best rec loss: 1.9014475345611572 for ['[CLS] passed eva with two history outward box cai shuffleeritt wonders temple aware [SEP]']
[Init] best rec loss: 1.892398476600647 for ['[CLS] orient conner dresser canada came belly sing sri front jacobdate pharaoh? devon [SEP]']
[Init] best rec loss: 1.8654320240020752 for ['[CLS] conqueror deficit killinglessfeit questions top ne texasry ministernge fear man [SEP]']
[Init] best rec loss: 1.854601263999939 for ['[CLS] inflation frowned knew clapped rosalie executed affecteda wild blue keptrcle za rafe [SEP]']
[Init] best rec loss: 1.8442292213439941 for ['[CLS] dot topic strip investigation kg facing chang mani causedond have millie bank divided [SEP]']
[Init] best rec loss: 1.8334152698516846 for ['[CLS] par animals gavin hokkaido fisherman gttwined yetrgy sexual thank sophia aim gag [SEP]']
[Init] best rec loss: 1.8195847272872925 for ['[CLS] bonnie brothers reed plague florida hezbollah fulbright " contrast seedsnist since him debates [SEP]']
[Init] best rec loss: 1.807897686958313 for ['[CLS] length dressantawa via merlin watch kerr drivenulating sprang map [SEP] organ [SEP]']
[Init] best perm rec loss: 1.8066086769104004 for ['[CLS]awa merlin sprang length map watch driven [SEP] kerrant via organ dressulating [SEP]']
[Init] best perm rec loss: 1.8017948865890503 for ['[CLS]awa driven map viaant length merlin sprang dress kerrulating organ watch [SEP] [SEP]']
[Init] best perm rec loss: 1.7998075485229492 for ['[CLS] [SEP]ulating organ watch mapant sprang length dress kerr driven merlinawa via [SEP]']
[Init] best perm rec loss: 1.7969026565551758 for ['[CLS] driven kerr sprang map dressantulating watch [SEP] via merlinawa organ length [SEP]']
[Init] best perm rec loss: 1.7951469421386719 for ['[CLS] sprang driven watch organ [SEP] dress viaant kerr merlin map lengthawaulating [SEP]']
[Init] best perm rec loss: 1.7944726943969727 for ['[CLS] drivenulating sprang map [SEP] kerrawaant dress via merlin watch organ length [SEP]']
[Init] best perm rec loss: 1.7938226461410522 for ['[CLS] kerr map lengthant dress via sprangawaulating merlin organ watch [SEP] driven [SEP]']
[Init] best perm rec loss: 1.793677568435669 for ['[CLS]awa watch dressulating [SEP] merlin sprang organ kerrant map driven via length [SEP]']
[Init] best perm rec loss: 1.7930742502212524 for ['[CLS] kerrulating watch via [SEP] dress drivenant mapawa sprang organ merlin length [SEP]']
[Init] best perm rec loss: 1.7919877767562866 for ['[CLS] kerr dress watch length viaulating merlin sprang organ [SEP]antawa driven map [SEP]']
[Init] best perm rec loss: 1.7916275262832642 for ['[CLS] kerrant driven map watchulating organ [SEP] length merlinawa dress via sprang [SEP]']
[Init] best perm rec loss: 1.7886393070220947 for ['[CLS] kerr merlinulating via drivenant watch [SEP]awa dress organ map sprang length [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.699 (perp=11.346, rec=0.671, cos=0.759), tot_loss_proj:4.141 [t=0.19s]
prediction: ['[CLS] throughout son peter a down her suggest [SEP] with $ bmg zoo about − [SEP]']
[ 100/2000] tot_loss=2.983 (perp=11.322, rec=0.478, cos=0.240), tot_loss_proj:4.163 [t=0.19s]
prediction: ['[CLS] loved sebastian love olivia du thoughth [SEP], late love sister ; mit [SEP]']
[ 150/2000] tot_loss=2.308 (perp=9.127, rec=0.378, cos=0.104), tot_loss_proj:3.783 [t=0.19s]
prediction: ['[CLS] love this love da mother john i love from present love! as seminary [SEP]']
[ 200/2000] tot_loss=2.463 (perp=10.510, rec=0.300, cos=0.061), tot_loss_proj:3.994 [t=0.19s]
prediction: ['[CLS] lovevoking love da mother when i students, may love fi as adoptive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.538 (perp=10.318, rec=0.362, cos=0.113), tot_loss_proj:3.983 [t=0.17s]
prediction: ['[CLS] lovevoking love da her when i students a may love affect, adoptive [SEP]']
[ 300/2000] tot_loss=2.241 (perp=9.691, rec=0.261, cos=0.042), tot_loss_proj:3.867 [t=0.17s]
prediction: ['[CLS] love. love da her when i 2008 theting loved.. adoptive [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.447 (perp=10.803, rec=0.254, cos=0.032), tot_loss_proj:4.032 [t=0.17s]
prediction: ['[CLS] da. love love her though applies grade the short loved difference, consideration [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.101 (perp=9.188, rec=0.238, cos=0.026), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] jar. love love her though, grade the great loved. applies consideration [SEP]']
[ 450/2000] tot_loss=2.077 (perp=9.188, rec=0.219, cos=0.021), tot_loss_proj:3.711 [t=0.17s]
prediction: ['[CLS] jar. love love her though, grade the great loved. applies consideration [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.009 (perp=8.852, rec=0.219, cos=0.019), tot_loss_proj:3.676 [t=0.17s]
prediction: ['[CLS] jar. love love her though, grade the lesser loved consideration applies. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.876 (perp=8.244, rec=0.214, cos=0.014), tot_loss_proj:3.552 [t=0.17s]
prediction: ['[CLS] we though love love her though, grade the lesser loved consideration thorns. [SEP]']
[ 600/2000] tot_loss=1.838 (perp=8.204, rec=0.184, cos=0.012), tot_loss_proj:3.560 [t=0.17s]
prediction: ['[CLS] we though love love her though that grade the lesser loved consideration thorns. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.856 (perp=7.749, rec=0.262, cos=0.044), tot_loss_proj:3.460 [t=0.17s]
prediction: ['[CLS] we though love love her though that grade the lesser loved should thorns. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.747 (perp=7.749, rec=0.184, cos=0.013), tot_loss_proj:3.460 [t=0.17s]
prediction: ['[CLS] we though love love her though that grade the lesser loved should thorns. [SEP]']
[ 750/2000] tot_loss=1.726 (perp=7.663, rec=0.182, cos=0.011), tot_loss_proj:3.451 [t=0.17s]
prediction: ['[CLS] we though love love her though that grade the lesser loved should should. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.765 (perp=7.898, rec=0.174, cos=0.010), tot_loss_proj:3.539 [t=0.17s]
prediction: ['[CLS] we, love love her though that grade the lesser loved should would. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.957 (perp=8.462, rec=0.228, cos=0.037), tot_loss_proj:3.625 [t=0.17s]
prediction: ['[CLS] i we love love her though that grade from not loved should would affect [SEP]']
[ 900/2000] tot_loss=1.917 (perp=8.547, rec=0.190, cos=0.018), tot_loss_proj:3.623 [t=0.17s]
prediction: ['[CLS] i we love love her though that grade the not my should would affect [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.731 (perp=7.673, rec=0.182, cos=0.014), tot_loss_proj:3.446 [t=0.17s]
prediction: ['[CLS] i we love love her though that should the not my grade would affect [SEP]']
Attempt swap
[1000/2000] tot_loss=1.727 (perp=7.673, rec=0.179, cos=0.013), tot_loss_proj:3.444 [t=0.17s]
prediction: ['[CLS] i we love love her though that should the not my grade would affect [SEP]']
[1050/2000] tot_loss=1.714 (perp=7.673, rec=0.168, cos=0.012), tot_loss_proj:3.447 [t=0.17s]
prediction: ['[CLS] i we love love her though that should the not my grade would affect [SEP]']
Attempt swap
[1100/2000] tot_loss=1.757 (perp=7.673, rec=0.199, cos=0.023), tot_loss_proj:3.449 [t=0.17s]
prediction: ['[CLS] i we love love her though that should the not my grade would affect [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.695 (perp=7.604, rec=0.163, cos=0.011), tot_loss_proj:3.456 [t=0.17s]
prediction: ['[CLS] i we love love her though that should not the my grade would affect [SEP]']
[1200/2000] tot_loss=1.641 (perp=7.351, rec=0.160, cos=0.011), tot_loss_proj:3.431 [t=0.17s]
prediction: ['[CLS] i. love love her though that should not the my grade would affect [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.635 (perp=7.272, rec=0.169, cos=0.012), tot_loss_proj:3.362 [t=0.17s]
prediction: ['[CLS] i should love love her though that we not the my grade would affect [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.524 (perp=6.680, rec=0.172, cos=0.016), tot_loss_proj:3.296 [t=0.19s]
prediction: ['[CLS] i should love her though that we not the love my grade would affect [SEP]']
[1350/2000] tot_loss=1.396 (perp=6.090, rec=0.166, cos=0.012), tot_loss_proj:3.184 [t=0.19s]
prediction: ['[CLS] i should love her though that. not the love my grade would affect [SEP]']
Attempt swap
[1400/2000] tot_loss=1.387 (perp=6.090, rec=0.158, cos=0.011), tot_loss_proj:3.184 [t=0.19s]
prediction: ['[CLS] i should love her though that. not the love my grade would affect [SEP]']
Attempt swap
[1450/2000] tot_loss=1.386 (perp=6.090, rec=0.158, cos=0.011), tot_loss_proj:3.186 [t=0.19s]
prediction: ['[CLS] i should love her though that. not the love my grade would affect [SEP]']
[1500/2000] tot_loss=1.393 (perp=6.123, rec=0.158, cos=0.011), tot_loss_proj:3.166 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
Attempt swap
[1550/2000] tot_loss=1.396 (perp=6.123, rec=0.160, cos=0.011), tot_loss_proj:3.167 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
Attempt swap
[1600/2000] tot_loss=1.389 (perp=6.123, rec=0.154, cos=0.010), tot_loss_proj:3.165 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
[1650/2000] tot_loss=1.392 (perp=6.123, rec=0.157, cos=0.010), tot_loss_proj:3.169 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
Attempt swap
[1700/2000] tot_loss=1.397 (perp=6.123, rec=0.162, cos=0.010), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
Attempt swap
[1750/2000] tot_loss=1.385 (perp=6.123, rec=0.151, cos=0.010), tot_loss_proj:3.165 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
[1800/2000] tot_loss=1.388 (perp=6.123, rec=0.153, cos=0.010), tot_loss_proj:3.166 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
Attempt swap
[1850/2000] tot_loss=1.396 (perp=6.123, rec=0.161, cos=0.010), tot_loss_proj:3.166 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
Attempt swap
[1900/2000] tot_loss=1.384 (perp=6.123, rec=0.149, cos=0.010), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
[1950/2000] tot_loss=1.381 (perp=6.123, rec=0.146, cos=0.010), tot_loss_proj:3.168 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
Attempt swap
[2000/2000] tot_loss=1.385 (perp=6.123, rec=0.151, cos=0.010), tot_loss_proj:3.165 [t=0.17s]
prediction: ['[CLS] i should love her though that. not the love my grade will affect [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] love her though i may, that won't affect the grade. [SEP]
========================
predicted: 
========================
[CLS] i should love her though that. not the love my grade will affect [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 66.667 | r: 76.923
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 57.143 | p: 53.333 | r: 61.538
rougeLsum  | fm: 57.143 | p: 53.333 | r: 61.538
r1fm+r2fm = 86.813

[Aggregate metrics]:
rouge1     | fm: 82.267 | p: 81.462 | r: 83.267
rouge2     | fm: 40.114 | p: 39.847 | r: 40.591
rougeL     | fm: 69.669 | p: 69.094 | r: 70.471
rougeLsum  | fm: 69.676 | p: 69.049 | r: 70.509
r1fm+r2fm = 122.381

input #74 time: 0:07:02 | total time: 10:13:58


Running input #75 of 100.
reference: 
========================
I have been flying helicopters for years.
========================
average of cosine similarity 0.9993561168596996
highest_index [0]
highest [0.9993561168596996]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1045,  2031,  2042,  3909, 12400,  2005,  2086,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] i have been flying helicopters for years. [SEP]']
[Init] best rec loss: 1.8857710361480713 for ['[CLS] lindsey exposed gov recreation touch approaching lack troubles [SEP]']
[Init] best rec loss: 1.8836071491241455 for ['[CLS] deer german mechanism fin row sucking from lake [SEP]']
[Init] best rec loss: 1.8356610536575317 for ['[CLS] maggie same villa right per key otherwise recording [SEP]']
[Init] best rec loss: 1.7775722742080688 for ['[CLS] sheridanance 寺 done names chance time continued [SEP]']
[Init] best rec loss: 1.7576189041137695 for ['[CLS]ı tang scored rex 2010 called please sy [SEP]']
[Init] best perm rec loss: 1.7546701431274414 for ['[CLS]ı rex 2010 scored sy tang please called [SEP]']
[Init] best perm rec loss: 1.7546687126159668 for ['[CLS] tang rex please scored sy called 2010ı [SEP]']
[Init] best perm rec loss: 1.753705620765686 for ['[CLS] tang called sy rexı please scored 2010 [SEP]']
[Init] best perm rec loss: 1.7529798746109009 for ['[CLS] rex tang 2010 scored sy pleaseı called [SEP]']
[Init] best perm rec loss: 1.7527025938034058 for ['[CLS] rex tang calledı please scored sy 2010 [SEP]']
[Init] best perm rec loss: 1.751526117324829 for ['[CLS] scored rex called tang pleaseı 2010 sy [SEP]']
[Init] best perm rec loss: 1.7506109476089478 for ['[CLS] tang scored 2010 pleaseı rex sy called [SEP]']
[Init] best perm rec loss: 1.748780369758606 for ['[CLS] scored rex please tang syı called 2010 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.702 (perp=11.313, rec=0.373, cos=0.066), tot_loss_proj:4.251 [t=0.17s]
prediction: ['[CLS] connor ; walking chuck helicopter flying days vacation [SEP]']
[ 100/2000] tot_loss=2.649 (perp=12.051, rec=0.222, cos=0.017), tot_loss_proj:4.203 [t=0.17s]
prediction: ['[CLS] infinitely i flying gonna helicopters helicopters years. [SEP]']
[ 150/2000] tot_loss=1.915 (perp=8.811, rec=0.145, cos=0.008), tot_loss_proj:3.654 [t=0.17s]
prediction: ['[CLS]zhou i been flying helicopters decades years. [SEP]']
[ 200/2000] tot_loss=1.169 (perp=5.229, rec=0.117, cos=0.006), tot_loss_proj:2.958 [t=0.17s]
prediction: ['[CLS] have i been flying helicopters for years. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=0.986 (perp=4.434, rec=0.093, cos=0.005), tot_loss_proj:0.996 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
[ 300/2000] tot_loss=1.130 (perp=5.185, rec=0.088, cos=0.006), tot_loss_proj:1.923 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[ 350/2000] tot_loss=0.972 (perp=4.434, rec=0.080, cos=0.006), tot_loss_proj:1.001 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[ 400/2000] tot_loss=0.980 (perp=4.434, rec=0.088, cos=0.006), tot_loss_proj:0.999 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
[ 450/2000] tot_loss=0.981 (perp=4.434, rec=0.089, cos=0.005), tot_loss_proj:1.001 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[ 500/2000] tot_loss=0.967 (perp=4.434, rec=0.075, cos=0.005), tot_loss_proj:0.993 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[ 550/2000] tot_loss=0.978 (perp=4.434, rec=0.086, cos=0.006), tot_loss_proj:0.989 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
[ 600/2000] tot_loss=0.970 (perp=4.434, rec=0.078, cos=0.005), tot_loss_proj:1.000 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.967 (perp=4.434, rec=0.075, cos=0.005), tot_loss_proj:0.994 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.978 (perp=4.434, rec=0.086, cos=0.005), tot_loss_proj:1.004 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
[ 750/2000] tot_loss=0.972 (perp=4.434, rec=0.080, cos=0.005), tot_loss_proj:0.999 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.220 (perp=4.434, rec=0.300, cos=0.034), tot_loss_proj:1.028 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.286 (perp=5.185, rec=0.228, cos=0.021), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
[ 900/2000] tot_loss=1.255 (perp=5.185, rec=0.203, cos=0.015), tot_loss_proj:1.989 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.230 (perp=5.185, rec=0.181, cos=0.012), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1000/2000] tot_loss=1.225 (perp=5.185, rec=0.177, cos=0.011), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
[1050/2000] tot_loss=1.222 (perp=5.185, rec=0.175, cos=0.010), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1100/2000] tot_loss=1.217 (perp=5.185, rec=0.170, cos=0.009), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1150/2000] tot_loss=1.208 (perp=5.185, rec=0.162, cos=0.009), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
[1200/2000] tot_loss=1.202 (perp=5.185, rec=0.156, cos=0.009), tot_loss_proj:1.962 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1250/2000] tot_loss=1.201 (perp=5.185, rec=0.156, cos=0.009), tot_loss_proj:1.956 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1300/2000] tot_loss=1.189 (perp=5.185, rec=0.144, cos=0.008), tot_loss_proj:1.962 [t=0.19s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
[1350/2000] tot_loss=1.182 (perp=5.185, rec=0.137, cos=0.008), tot_loss_proj:1.953 [t=0.19s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1400/2000] tot_loss=1.191 (perp=5.185, rec=0.146, cos=0.008), tot_loss_proj:1.956 [t=0.19s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1450/2000] tot_loss=1.190 (perp=5.185, rec=0.145, cos=0.008), tot_loss_proj:1.949 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
[1500/2000] tot_loss=1.196 (perp=5.185, rec=0.151, cos=0.008), tot_loss_proj:1.951 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1550/2000] tot_loss=1.190 (perp=5.185, rec=0.145, cos=0.008), tot_loss_proj:1.954 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1600/2000] tot_loss=1.181 (perp=5.185, rec=0.136, cos=0.008), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
[1650/2000] tot_loss=1.187 (perp=5.185, rec=0.142, cos=0.008), tot_loss_proj:1.936 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1700/2000] tot_loss=1.180 (perp=5.185, rec=0.135, cos=0.008), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1750/2000] tot_loss=1.183 (perp=5.185, rec=0.138, cos=0.008), tot_loss_proj:1.945 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
[1800/2000] tot_loss=1.182 (perp=5.185, rec=0.138, cos=0.008), tot_loss_proj:1.943 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1850/2000] tot_loss=1.186 (perp=5.185, rec=0.141, cos=0.008), tot_loss_proj:1.944 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[1900/2000] tot_loss=1.180 (perp=5.185, rec=0.136, cos=0.008), tot_loss_proj:1.947 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
[1950/2000] tot_loss=1.186 (perp=5.185, rec=0.142, cos=0.008), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Attempt swap
[2000/2000] tot_loss=1.182 (perp=5.185, rec=0.137, cos=0.008), tot_loss_proj:1.938 [t=0.17s]
prediction: ['[CLS] i have been flying helicopters for years ; [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] i have been flying helicopters for years. [SEP]
========================
predicted: 
========================
[CLS] i have been flying helicopters for years. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.524 | p: 81.733 | r: 83.497
rouge2     | fm: 41.038 | p: 40.682 | r: 41.487
rougeL     | fm: 70.122 | p: 69.512 | r: 70.900
rougeLsum  | fm: 70.037 | p: 69.448 | r: 70.904
r1fm+r2fm = 123.562

input #75 time: 0:06:50 | total time: 10:20:49


Running input #76 of 100.
reference: 
========================
the person stand on my foot is heavy.
========================
average of cosine similarity 0.9993156362431244
highest_index [0]
highest [0.9993156362431244]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2711, 3233, 2006, 2026, 3329, 2003, 3082, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the person stand on my foot is heavy. [SEP]']
[Init] best rec loss: 1.380448341369629 for ['[CLS] yes motorway has entering lin trust d dante without [SEP]']
[Init] best rec loss: 1.2697889804840088 for ['[CLS] how cindy thousands yeah gram chudocknsed widow [SEP]']
[Init] best rec loss: 1.192774772644043 for ['[CLS] right atgang connecting naturalistpy half use feud [SEP]']
[Init] best rec loss: 1.1534500122070312 for ['[CLS] speech largest endemicner flow stateism decenttrust [SEP]']
[Init] best rec loss: 0.9870676398277283 for ['[CLS]ya bird bottledped range figure two serial astro [SEP]']
[Init] best rec loss: 0.9826367497444153 for ['[CLS] solid tolkien been plant 1770 thus resident our fish [SEP]']
[Init] best rec loss: 0.8757468461990356 for ['[CLS] landfall day resulted kenton institute kate holland learning recorder [SEP]']
[Init] best perm rec loss: 0.8750126361846924 for ['[CLS] learning resulted holland day kate institute recorder landfall kenton [SEP]']
[Init] best perm rec loss: 0.8744537234306335 for ['[CLS] learning landfall holland day kenton institute recorder resulted kate [SEP]']
[Init] best perm rec loss: 0.8660425543785095 for ['[CLS] institute landfall day recorder learning holland kenton resulted kate [SEP]']
[Init] best perm rec loss: 0.8651455044746399 for ['[CLS] kenton resulted holland day institute landfall learning recorder kate [SEP]']
[Init] best perm rec loss: 0.8605121970176697 for ['[CLS] day resulted landfall holland kenton institute learning kate recorder [SEP]']
[Init] best perm rec loss: 0.8598467707633972 for ['[CLS] recorder day holland kenton institute landfall resulted learning kate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.892 (perp=12.476, rec=0.375, cos=0.022), tot_loss_proj:3.189 [t=0.17s]
prediction: ['[CLS] beatingleaderlman mons cells person combat jacob, [SEP]']
[ 100/2000] tot_loss=2.816 (perp=12.347, rec=0.332, cos=0.015), tot_loss_proj:3.237 [t=0.17s]
prediction: ['[CLS] facing you meak person person footita heavy [SEP]']
[ 150/2000] tot_loss=2.517 (perp=10.997, rec=0.305, cos=0.012), tot_loss_proj:3.322 [t=0.17s]
prediction: ['[CLS] on you me person person person foot _ heavy [SEP]']
[ 200/2000] tot_loss=2.429 (perp=10.751, rec=0.270, cos=0.009), tot_loss_proj:3.490 [t=0.17s]
prediction: ['[CLS] on person stand person person person foot _ heavy [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.066 (perp=8.805, rec=0.293, cos=0.012), tot_loss_proj:2.844 [t=0.17s]
prediction: ['[CLS] on foot. stand the stand person _ heavy [SEP]']
[ 300/2000] tot_loss=2.065 (perp=9.126, rec=0.231, cos=0.008), tot_loss_proj:2.861 [t=0.17s]
prediction: ['[CLS] on foot. stand the is person _ heavy [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.725 (perp=7.652, rec=0.188, cos=0.006), tot_loss_proj:2.205 [t=0.17s]
prediction: ['[CLS] on foot is on stand the person _ heavy [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.772 (perp=7.989, rec=0.167, cos=0.007), tot_loss_proj:2.402 [t=0.17s]
prediction: ['[CLS] the foot. stand the person faber is heavy [SEP]']
[ 450/2000] tot_loss=1.669 (perp=7.552, rec=0.153, cos=0.006), tot_loss_proj:2.157 [t=0.17s]
prediction: ['[CLS] the foot on stand the person heel is heavy [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.883 (perp=8.646, rec=0.148, cos=0.006), tot_loss_proj:2.381 [t=0.17s]
prediction: ['[CLS] the foot on stand his sandals person is heavy [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.816 (perp=8.189, rec=0.172, cos=0.007), tot_loss_proj:2.286 [t=0.17s]
prediction: ['[CLS] the foot. his sandals stand person is heavy [SEP]']
[ 600/2000] tot_loss=2.051 (perp=9.525, rec=0.142, cos=0.004), tot_loss_proj:2.708 [t=0.17s]
prediction: ['[CLS] the foot my his sandals stand person is heavy [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.808 (perp=8.365, rec=0.132, cos=0.004), tot_loss_proj:2.474 [t=0.17s]
prediction: ['[CLS] the foot my sandals stand his person is heavy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.812 (perp=8.365, rec=0.135, cos=0.004), tot_loss_proj:2.470 [t=0.17s]
prediction: ['[CLS] the foot my sandals stand his person is heavy [SEP]']
[ 750/2000] tot_loss=1.807 (perp=8.365, rec=0.130, cos=0.004), tot_loss_proj:2.469 [t=0.17s]
prediction: ['[CLS] the foot my sandals stand his person is heavy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.870 (perp=8.719, rec=0.122, cos=0.004), tot_loss_proj:2.398 [t=0.17s]
prediction: ['[CLS] the on my sandals stand his person is heavy [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.647 (perp=7.618, rec=0.119, cos=0.004), tot_loss_proj:2.157 [t=0.17s]
prediction: ['[CLS] the stand my sandals on the person is heavy [SEP]']
[ 900/2000] tot_loss=1.488 (perp=6.861, rec=0.112, cos=0.004), tot_loss_proj:2.003 [t=0.17s]
prediction: ['[CLS] the stand my foot on his person is heavy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.494 (perp=6.861, rec=0.119, cos=0.003), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] the stand my foot on his person is heavy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.518 (perp=6.976, rec=0.120, cos=0.003), tot_loss_proj:1.999 [t=0.17s]
prediction: ['[CLS] the stand my foot on the person is heavy [SEP]']
[1050/2000] tot_loss=1.503 (perp=6.976, rec=0.105, cos=0.003), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] the stand my foot on the person is heavy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.501 (perp=6.976, rec=0.102, cos=0.003), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS] the stand my foot on the person is heavy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.506 (perp=6.976, rec=0.107, cos=0.003), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] the stand my foot on the person is heavy [SEP]']
[1200/2000] tot_loss=1.501 (perp=6.976, rec=0.103, cos=0.003), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS] the stand my foot on the person is heavy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.501 (perp=6.976, rec=0.102, cos=0.003), tot_loss_proj:2.003 [t=0.17s]
prediction: ['[CLS] the stand my foot on the person is heavy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.493 (perp=6.976, rec=0.095, cos=0.003), tot_loss_proj:1.994 [t=0.17s]
prediction: ['[CLS] the stand my foot on the person is heavy [SEP]']
[1350/2000] tot_loss=1.502 (perp=6.976, rec=0.103, cos=0.003), tot_loss_proj:1.999 [t=0.17s]
prediction: ['[CLS] the stand my foot on the person is heavy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.643 (perp=7.659, rec=0.108, cos=0.003), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] the stand my foot on foot person is heavy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.639 (perp=7.659, rec=0.105, cos=0.003), tot_loss_proj:2.510 [t=0.17s]
prediction: ['[CLS] the stand my foot on foot person is heavy [SEP]']
[1500/2000] tot_loss=1.630 (perp=7.659, rec=0.095, cos=0.003), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] the stand my foot on foot person is heavy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.632 (perp=7.659, rec=0.098, cos=0.003), tot_loss_proj:2.507 [t=0.17s]
prediction: ['[CLS] the stand my foot on foot person is heavy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.627 (perp=7.659, rec=0.093, cos=0.003), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] the stand my foot on foot person is heavy [SEP]']
[1650/2000] tot_loss=1.633 (perp=7.659, rec=0.098, cos=0.003), tot_loss_proj:2.510 [t=0.17s]
prediction: ['[CLS] the stand my foot on foot person is heavy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.635 (perp=7.659, rec=0.100, cos=0.003), tot_loss_proj:2.508 [t=0.17s]
prediction: ['[CLS] the stand my foot on foot person is heavy [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.552 (perp=7.173, rec=0.114, cos=0.003), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] the stand foot foot on my person is heavy [SEP]']
[1800/2000] tot_loss=1.540 (perp=7.173, rec=0.103, cos=0.003), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] the stand foot foot on my person is heavy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.539 (perp=7.173, rec=0.101, cos=0.003), tot_loss_proj:2.486 [t=0.17s]
prediction: ['[CLS] the stand foot foot on my person is heavy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.532 (perp=7.173, rec=0.095, cos=0.003), tot_loss_proj:2.475 [t=0.17s]
prediction: ['[CLS] the stand foot foot on my person is heavy [SEP]']
[1950/2000] tot_loss=1.530 (perp=7.173, rec=0.093, cos=0.003), tot_loss_proj:2.486 [t=0.17s]
prediction: ['[CLS] the stand foot foot on my person is heavy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.533 (perp=7.173, rec=0.095, cos=0.003), tot_loss_proj:2.483 [t=0.17s]
prediction: ['[CLS] the stand foot foot on my person is heavy [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS] the person stand on my foot is heavy. [SEP]
========================
predicted: 
========================
[CLS] the stand my foot on foot person is heavy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 42.105 | p: 40.000 | r: 44.444
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 137.343

[Aggregate metrics]:
rouge1     | fm: 82.742 | p: 81.911 | r: 83.794
rouge2     | fm: 41.009 | p: 40.667 | r: 41.457
rougeL     | fm: 70.166 | p: 69.510 | r: 70.968
rougeLsum  | fm: 70.063 | p: 69.467 | r: 70.904
r1fm+r2fm = 123.751

input #76 time: 0:06:50 | total time: 10:27:40


Running input #77 of 100.
reference: 
========================
My mother baked a cake for me.
========================
average of cosine similarity 0.9994064498635338
highest_index [0]
highest [0.9994064498635338]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2026,  2388, 17776,  1037,  9850,  2005,  2033,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] my mother baked a cake for me. [SEP]']
[Init] best rec loss: 1.8614399433135986 for ['[CLS] mysterious statistical its owner soft bodo network posting [SEP]']
[Init] best rec loss: 1.8480610847473145 for ['[CLS] calitte bo ago [SEP] debut resolution allowed [SEP]']
[Init] best rec loss: 1.8252049684524536 for ['[CLS] mode impossible search by fertility nudged personal and [SEP]']
[Init] best rec loss: 1.8045706748962402 for ['[CLS] quarter crying tour specification period minds pub [MASK] [SEP]']
[Init] best rec loss: 1.7354665994644165 for ['[CLS] northern, orders approach auxthan british poll [SEP]']
[Init] best rec loss: 1.721542477607727 for ['[CLS] owl appointments hot tributary gauge final aghic [SEP]']
[Init] best rec loss: 1.6887249946594238 for ['[CLS] knife accused third as even weekly far honorable [SEP]']
[Init] best perm rec loss: 1.6870468854904175 for ['[CLS] even knife accused far honorable third as weekly [SEP]']
[Init] best perm rec loss: 1.683107614517212 for ['[CLS] accused far honorable knife as even weekly third [SEP]']
[Init] best perm rec loss: 1.6816920042037964 for ['[CLS] as far honorable third even knife accused weekly [SEP]']
[Init] best perm rec loss: 1.681456208229065 for ['[CLS] third as knife far honorable even accused weekly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.080 (perp=12.115, rec=0.657, cos=1.000), tot_loss_proj:4.262 [t=0.17s]
prediction: ['[CLS] sophie notion wryly. daddy your tony daisy [SEP]']
[ 100/2000] tot_loss=4.023 (perp=11.871, rec=0.655, cos=0.994), tot_loss_proj:4.323 [t=0.17s]
prediction: ['[CLS] sliding candles ©. daddy eating syndicateted [SEP]']
[ 150/2000] tot_loss=3.188 (perp=8.453, rec=0.519, cos=0.979), tot_loss_proj:3.588 [t=0.17s]
prediction: ['[CLS] cake cakeusly " daddy baked me. [SEP]']
[ 200/2000] tot_loss=3.727 (perp=10.806, rec=0.571, cos=0.996), tot_loss_proj:4.263 [t=0.17s]
prediction: ["[CLS]rigue fantasy cake'daddy baked pt? [SEP]"]
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.168 (perp=8.497, rec=0.506, cos=0.963), tot_loss_proj:3.649 [t=0.17s]
prediction: ["[CLS] cake baked'cake daddy baked bamboo. [SEP]"]
[ 300/2000] tot_loss=4.484 (perp=13.011, rec=0.907, cos=0.975), tot_loss_proj:4.449 [t=0.17s]
prediction: ['[CLS] uncle baked aspects cake bribes baked hamish pete [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.865 (perp=11.471, rec=0.574, cos=0.997), tot_loss_proj:4.038 [t=0.17s]
prediction: ['[CLS] repertory baked becky bread payment mother sarcasm ; [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.645 (perp=10.645, rec=0.519, cos=0.998), tot_loss_proj:3.865 [t=0.17s]
prediction: ['[CLS] repertory baked uncle mom bread payment baked ; [SEP]']
[ 450/2000] tot_loss=3.736 (perp=11.295, rec=0.482, cos=0.995), tot_loss_proj:4.004 [t=0.17s]
prediction: ['[CLS]vation bakedusly mom cake surgery baked. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.752 (perp=11.386, rec=0.480, cos=0.995), tot_loss_proj:4.032 [t=0.17s]
prediction: ['[CLS] tablet bakedvation mom sounded surgery baked. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.568 (perp=10.505, rec=0.474, cos=0.993), tot_loss_proj:3.890 [t=0.17s]
prediction: ['[CLS] tablet baked momvation baked surgery baked. [SEP]']
[ 600/2000] tot_loss=3.534 (perp=10.505, rec=0.443, cos=0.991), tot_loss_proj:3.891 [t=0.17s]
prediction: ['[CLS] tablet baked momvation baked surgery baked. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.491 (perp=10.353, rec=0.431, cos=0.989), tot_loss_proj:3.812 [t=0.17s]
prediction: ['[CLS] baked tablet mom tattoo baked surgery baked. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.354 (perp=9.708, rec=0.426, cos=0.987), tot_loss_proj:3.688 [t=0.17s]
prediction: ['[CLS] baked mom tablet tattoo baked surgery baked. [SEP]']
[ 750/2000] tot_loss=3.484 (perp=10.319, rec=0.434, cos=0.987), tot_loss_proj:3.818 [t=0.21s]
prediction: ['[CLS] baked mom tabletamericana baked surgery baked. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=3.431 (perp=10.159, rec=0.416, cos=0.983), tot_loss_proj:3.784 [t=0.17s]
prediction: ['[CLS] baked mom tattoo tablet baked surgery baked. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.246 (perp=9.281, rec=0.417, cos=0.972), tot_loss_proj:3.596 [t=0.19s]
prediction: ['[CLS] baked mom baked tablet tattoo surgery baked. [SEP]']
[ 900/2000] tot_loss=3.520 (perp=10.585, rec=0.421, cos=0.982), tot_loss_proj:3.877 [t=0.19s]
prediction: ['[CLS] baked mom baked tabletamericana surgery baked. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.324 (perp=9.666, rec=0.409, cos=0.982), tot_loss_proj:3.686 [t=0.19s]
prediction: ['[CLS] baked momamericana tablet baked surgery baked. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.379 (perp=9.942, rec=0.422, cos=0.969), tot_loss_proj:3.743 [t=0.19s]
prediction: ['[CLS] baked mom surgery tablet baked tattoo baked. [SEP]']
[1050/2000] tot_loss=3.441 (perp=10.287, rec=0.403, cos=0.980), tot_loss_proj:3.861 [t=0.19s]
prediction: ['[CLS] baked my surgery tablet baked tattoo baked. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.446 (perp=10.287, rec=0.407, cos=0.982), tot_loss_proj:3.864 [t=0.19s]
prediction: ['[CLS] baked my surgery tablet baked tattoo baked. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.528 (perp=10.694, rec=0.412, cos=0.978), tot_loss_proj:3.884 [t=0.19s]
prediction: ['[CLS] baked my surgery tablet cerambycidae baked baked. [SEP]']
[1200/2000] tot_loss=3.465 (perp=10.442, rec=0.396, cos=0.981), tot_loss_proj:3.856 [t=0.19s]
prediction: ['[CLS] baked my surgery tabletamericana baked baked. [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=3.411 (perp=10.094, rec=0.410, cos=0.983), tot_loss_proj:3.766 [t=0.19s]
prediction: ['[CLS] baked my surgeryamericana baked dinner baked. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.401 (perp=10.094, rec=0.400, cos=0.982), tot_loss_proj:3.765 [t=0.19s]
prediction: ['[CLS] baked my surgeryamericana baked dinner baked. [SEP]']
[1350/2000] tot_loss=3.432 (perp=10.258, rec=0.398, cos=0.982), tot_loss_proj:3.780 [t=0.17s]
prediction: ['[CLS] baked my surgery pregnant baked dinner baked. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=3.313 (perp=9.651, rec=0.403, cos=0.980), tot_loss_proj:3.659 [t=0.17s]
prediction: ['[CLS] baked surgery pregnant baked my dinner baked. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=3.218 (perp=9.218, rec=0.396, cos=0.978), tot_loss_proj:3.605 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
[1500/2000] tot_loss=3.220 (perp=9.218, rec=0.396, cos=0.981), tot_loss_proj:3.601 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.211 (perp=9.218, rec=0.386, cos=0.981), tot_loss_proj:3.609 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.214 (perp=9.218, rec=0.389, cos=0.981), tot_loss_proj:3.606 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
[1650/2000] tot_loss=3.213 (perp=9.218, rec=0.388, cos=0.982), tot_loss_proj:3.604 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.211 (perp=9.218, rec=0.386, cos=0.982), tot_loss_proj:3.606 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.211 (perp=9.218, rec=0.385, cos=0.982), tot_loss_proj:3.607 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
[1800/2000] tot_loss=3.216 (perp=9.218, rec=0.390, cos=0.982), tot_loss_proj:3.610 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.204 (perp=9.218, rec=0.378, cos=0.982), tot_loss_proj:3.606 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.223 (perp=9.218, rec=0.397, cos=0.982), tot_loss_proj:3.608 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
[1950/2000] tot_loss=3.215 (perp=9.218, rec=0.389, cos=0.982), tot_loss_proj:3.603 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.220 (perp=9.218, rec=0.394, cos=0.982), tot_loss_proj:3.607 [t=0.17s]
prediction: ['[CLS] baked pregnant surgery baked my dinner baked. [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] my mother baked a cake for me. [SEP]
========================
predicted: 
========================
[CLS] baked pregnant surgery baked my dinner baked. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 44.444 | p: 44.444 | r: 44.444
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 44.444

[Aggregate metrics]:
rouge1     | fm: 82.055 | p: 81.310 | r: 83.121
rouge2     | fm: 40.597 | p: 40.229 | r: 41.047
rougeL     | fm: 69.896 | p: 69.280 | r: 70.657
rougeLsum  | fm: 69.742 | p: 69.108 | r: 70.550
r1fm+r2fm = 122.651

input #77 time: 0:06:58 | total time: 10:34:38


Running input #78 of 100.
reference: 
========================
I read some book.
========================
average of cosine similarity 0.9993794737153854
highest_index [0]
highest [0.9993794737153854]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 1045, 3191, 2070, 2338, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] i read some book. [SEP]']
[Init] best rec loss: 1.5637524127960205 for ['[CLS]ys sponsored ni patience courts [SEP]']
[Init] best rec loss: 1.4623504877090454 for ['[CLS] kay escapedonale together tau [SEP]']
[Init] best rec loss: 1.284755825996399 for ['[CLS] am iv pregnant lagoon ample [SEP]']
[Init] best rec loss: 1.2820332050323486 for ['[CLS] gears seen persuasion tech galley [SEP]']
[Init] best rec loss: 1.277390480041504 for ['[CLS]lyverybo ago exempt [SEP]']
[Init] best rec loss: 1.2426445484161377 for ['[CLS] givenvers downtown band ban [SEP]']
[Init] best rec loss: 1.2316104173660278 for ['[CLS] see mal exact major curran [SEP]']
[Init] best rec loss: 1.1290827989578247 for ['[CLS] epidemic deceased accused flames zone [SEP]']
[Init] best perm rec loss: 1.1222310066223145 for ['[CLS] epidemic flames accused zone deceased [SEP]']
[Init] best perm rec loss: 1.1180310249328613 for ['[CLS] accused epidemic zone deceased flames [SEP]']
[Init] best perm rec loss: 1.1160284280776978 for ['[CLS] zone flames epidemic accused deceased [SEP]']
[Init] best perm rec loss: 1.1160205602645874 for ['[CLS] accused zone flames epidemic deceased [SEP]']
[Init] best perm rec loss: 1.1158640384674072 for ['[CLS] accused flames zone deceased epidemic [SEP]']
[Init] best perm rec loss: 1.1152188777923584 for ['[CLS] deceased accused flames epidemic zone [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.933 (perp=12.065, rec=0.654, cos=0.866), tot_loss_proj:3.867 [t=0.18s]
prediction: ['[CLS] percent beer someone when middle [SEP]']
[ 100/2000] tot_loss=3.947 (perp=12.546, rec=0.634, cos=0.803), tot_loss_proj:4.150 [t=0.18s]
prediction: ['[CLS] chapter vampires someone bag alpha [SEP]']
[ 150/2000] tot_loss=2.249 (perp=9.252, rec=0.353, cos=0.045), tot_loss_proj:2.880 [t=0.19s]
prediction: ['[CLS] read book some book cake [SEP]']
[ 200/2000] tot_loss=1.871 (perp=8.378, rec=0.181, cos=0.015), tot_loss_proj:2.598 [t=0.19s]
prediction: ['[CLS] i book some read book [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.513 (perp=6.792, rec=0.145, cos=0.009), tot_loss_proj:2.082 [t=0.19s]
prediction: ['[CLS] i read some book book [SEP]']
[ 300/2000] tot_loss=1.472 (perp=6.792, rec=0.107, cos=0.007), tot_loss_proj:2.043 [t=0.19s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.461 (perp=6.792, rec=0.096, cos=0.006), tot_loss_proj:2.057 [t=0.19s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.675 (perp=6.792, rec=0.272, cos=0.045), tot_loss_proj:2.090 [t=0.19s]
prediction: ['[CLS] i read some book book [SEP]']
[ 450/2000] tot_loss=1.479 (perp=6.792, rec=0.113, cos=0.007), tot_loss_proj:1.888 [t=0.19s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.469 (perp=6.792, rec=0.104, cos=0.006), tot_loss_proj:1.898 [t=0.19s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.455 (perp=6.792, rec=0.091, cos=0.006), tot_loss_proj:1.896 [t=0.19s]
prediction: ['[CLS] i read some book book [SEP]']
[ 600/2000] tot_loss=1.465 (perp=6.792, rec=0.101, cos=0.006), tot_loss_proj:1.898 [t=0.19s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.463 (perp=6.792, rec=0.098, cos=0.006), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.447 (perp=6.792, rec=0.083, cos=0.006), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
[ 750/2000] tot_loss=1.450 (perp=6.792, rec=0.086, cos=0.006), tot_loss_proj:1.897 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.439 (perp=6.792, rec=0.075, cos=0.006), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.450 (perp=6.792, rec=0.086, cos=0.006), tot_loss_proj:1.900 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
[ 900/2000] tot_loss=1.448 (perp=6.792, rec=0.084, cos=0.006), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.456 (perp=6.792, rec=0.092, cos=0.005), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1000/2000] tot_loss=1.456 (perp=6.792, rec=0.092, cos=0.005), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
[1050/2000] tot_loss=1.446 (perp=6.792, rec=0.082, cos=0.005), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1100/2000] tot_loss=1.449 (perp=6.792, rec=0.085, cos=0.005), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1150/2000] tot_loss=1.448 (perp=6.792, rec=0.084, cos=0.005), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
[1200/2000] tot_loss=1.452 (perp=6.792, rec=0.088, cos=0.005), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1250/2000] tot_loss=1.444 (perp=6.792, rec=0.080, cos=0.005), tot_loss_proj:1.886 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1300/2000] tot_loss=1.448 (perp=6.792, rec=0.085, cos=0.005), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
[1350/2000] tot_loss=1.444 (perp=6.792, rec=0.080, cos=0.005), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1400/2000] tot_loss=1.453 (perp=6.792, rec=0.089, cos=0.005), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1450/2000] tot_loss=1.440 (perp=6.792, rec=0.076, cos=0.005), tot_loss_proj:1.883 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
[1500/2000] tot_loss=1.447 (perp=6.792, rec=0.083, cos=0.005), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1550/2000] tot_loss=1.445 (perp=6.792, rec=0.081, cos=0.005), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1600/2000] tot_loss=1.449 (perp=6.792, rec=0.085, cos=0.005), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
[1650/2000] tot_loss=1.441 (perp=6.792, rec=0.078, cos=0.005), tot_loss_proj:1.886 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1700/2000] tot_loss=1.445 (perp=6.792, rec=0.081, cos=0.005), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1750/2000] tot_loss=1.446 (perp=6.792, rec=0.082, cos=0.005), tot_loss_proj:1.885 [t=0.18s]
prediction: ['[CLS] i read some book book [SEP]']
[1800/2000] tot_loss=1.445 (perp=6.792, rec=0.082, cos=0.005), tot_loss_proj:1.884 [t=0.19s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1850/2000] tot_loss=1.450 (perp=6.792, rec=0.086, cos=0.005), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[1900/2000] tot_loss=1.453 (perp=6.792, rec=0.090, cos=0.005), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
[1950/2000] tot_loss=1.448 (perp=6.792, rec=0.084, cos=0.005), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Attempt swap
[2000/2000] tot_loss=1.448 (perp=6.792, rec=0.085, cos=0.005), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] i read some book book [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] i read some book. [SEP]
========================
predicted: 
========================
[CLS] i read some book book [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 90.909 | p: 83.333 | r: 100.000
rougeL     | fm: 92.308 | p: 85.714 | r: 100.000
rougeLsum  | fm: 92.308 | p: 85.714 | r: 100.000
r1fm+r2fm = 183.217

[Aggregate metrics]:
rouge1     | fm: 82.194 | p: 81.339 | r: 83.331
rouge2     | fm: 41.260 | p: 40.850 | r: 41.813
rougeL     | fm: 70.197 | p: 69.453 | r: 71.060
rougeLsum  | fm: 70.096 | p: 69.322 | r: 71.069
r1fm+r2fm = 123.454

input #78 time: 0:06:59 | total time: 10:41:37


Running input #79 of 100.
reference: 
========================
The umpire called it of.
========================
average of cosine similarity 0.9993217640206553
highest_index [0]
highest [0.9993217640206553]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1996, 20887,  2170,  2009,  1997,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] the umpire called it of. [SEP]']
[Init] best rec loss: 1.9081144332885742 for ['[CLS]tlement gi professional julian reaching wingspan [SEP]']
[Init] best rec loss: 1.872009038925171 for ['[CLS]ncia welcometedphile vector copyright [SEP]']
[Init] best rec loss: 1.8346995115280151 for ['[CLS] ′ ears natural developed star quest [SEP]']
[Init] best rec loss: 1.8013540506362915 for ['[CLS] behind demanded habit west restored active [SEP]']
[Init] best rec loss: 1.77981436252594 for ['[CLS] genesisiolrayem should laid [SEP]']
[Init] best rec loss: 1.7765934467315674 for ['[CLS] newscasts behalf hiseimtercini [SEP]']
[Init] best rec loss: 1.7468129396438599 for ['[CLS] figurative lunch flipped outdated incoming cross [SEP]']
[Init] best perm rec loss: 1.7438634634017944 for ['[CLS] figurative lunch cross outdated flipped incoming [SEP]']
[Init] best perm rec loss: 1.7437344789505005 for ['[CLS] incoming lunch flipped figurative cross outdated [SEP]']
[Init] best perm rec loss: 1.733204960823059 for ['[CLS] outdated figurative lunch cross incoming flipped [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.162 (perp=12.880, rec=0.622, cos=0.964), tot_loss_proj:4.456 [t=0.18s]
prediction: ['[CLS] wasatable umpireª per look [SEP]']
[ 100/2000] tot_loss=3.727 (perp=11.312, rec=0.494, cos=0.971), tot_loss_proj:4.239 [t=0.18s]
prediction: ['[CLS] hydro umpire umpire umpire conclude umpire [SEP]']
[ 150/2000] tot_loss=3.948 (perp=12.806, rec=0.429, cos=0.958), tot_loss_proj:4.575 [t=0.19s]
prediction: ['[CLS] hydro umpire umpire umpire chatter° [SEP]']
[ 200/2000] tot_loss=3.819 (perp=12.374, rec=0.397, cos=0.947), tot_loss_proj:4.485 [t=0.19s]
prediction: ['[CLS]dicated umpire umpire umpire chatter productions [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.743 (perp=11.834, rec=0.511, cos=0.865), tot_loss_proj:4.205 [t=0.19s]
prediction: ['[CLS] ceased endellebilities umpire umpire. [SEP]']
[ 300/2000] tot_loss=3.140 (perp=9.505, rec=0.408, cos=0.831), tot_loss_proj:3.781 [t=0.18s]
prediction: ['[CLS] it withoutpu umpire umpire. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.068 (perp=9.492, rec=0.382, cos=0.787), tot_loss_proj:3.899 [t=0.19s]
prediction: ['[CLS] itpuorough umpire called. [SEP]']
Attempt swap
[ 400/2000] tot_loss=4.350 (perp=12.727, rec=0.816, cos=0.989), tot_loss_proj:4.341 [t=0.18s]
prediction: ['[CLS] archie mercenary candi umpire of. [SEP]']
[ 450/2000] tot_loss=3.412 (perp=8.785, rec=0.657, cos=0.998), tot_loss_proj:3.688 [t=0.19s]
prediction: ['[CLS]orf umpire & umpire of. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.075 (perp=7.432, rec=0.593, cos=0.995), tot_loss_proj:3.478 [t=0.19s]
prediction: ['[CLS] of umpire & umpireorf. [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.032 (perp=7.432, rec=0.552, cos=0.994), tot_loss_proj:3.465 [t=0.19s]
prediction: ['[CLS] of umpire & umpireorf. [SEP]']
[ 600/2000] tot_loss=3.211 (perp=8.365, rec=0.545, cos=0.993), tot_loss_proj:3.634 [t=0.18s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.190 (perp=8.365, rec=0.523, cos=0.994), tot_loss_proj:3.632 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.184 (perp=8.365, rec=0.516, cos=0.995), tot_loss_proj:3.638 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
[ 750/2000] tot_loss=3.160 (perp=8.365, rec=0.494, cos=0.993), tot_loss_proj:3.638 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.154 (perp=8.365, rec=0.487, cos=0.995), tot_loss_proj:3.635 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.150 (perp=8.365, rec=0.484, cos=0.993), tot_loss_proj:3.637 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
[ 900/2000] tot_loss=3.147 (perp=8.365, rec=0.482, cos=0.992), tot_loss_proj:3.638 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.130 (perp=8.365, rec=0.464, cos=0.993), tot_loss_proj:3.638 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[1000/2000] tot_loss=3.131 (perp=8.365, rec=0.465, cos=0.992), tot_loss_proj:3.640 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
[1050/2000] tot_loss=3.128 (perp=8.365, rec=0.463, cos=0.991), tot_loss_proj:3.641 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[1100/2000] tot_loss=3.126 (perp=8.365, rec=0.460, cos=0.992), tot_loss_proj:3.638 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[1150/2000] tot_loss=3.112 (perp=8.365, rec=0.449, cos=0.990), tot_loss_proj:3.635 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
[1200/2000] tot_loss=3.114 (perp=8.365, rec=0.451, cos=0.990), tot_loss_proj:3.638 [t=0.19s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[1250/2000] tot_loss=3.111 (perp=8.365, rec=0.448, cos=0.989), tot_loss_proj:3.636 [t=0.17s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[1300/2000] tot_loss=3.325 (perp=9.455, rec=0.445, cos=0.989), tot_loss_proj:3.901 [t=0.17s]
prediction: ['[CLS] they umpire umpire umpire gregory. [SEP]']
[1350/2000] tot_loss=3.323 (perp=9.455, rec=0.443, cos=0.989), tot_loss_proj:3.902 [t=0.17s]
prediction: ['[CLS] they umpire umpire umpire gregory. [SEP]']
Attempt swap
[1400/2000] tot_loss=3.326 (perp=9.455, rec=0.446, cos=0.989), tot_loss_proj:3.899 [t=0.18s]
prediction: ['[CLS] they umpire umpire umpire gregory. [SEP]']
Attempt swap
[1450/2000] tot_loss=3.322 (perp=9.455, rec=0.442, cos=0.989), tot_loss_proj:3.899 [t=0.18s]
prediction: ['[CLS] they umpire umpire umpire gregory. [SEP]']
[1500/2000] tot_loss=3.322 (perp=9.455, rec=0.442, cos=0.988), tot_loss_proj:3.902 [t=0.18s]
prediction: ['[CLS] they umpire umpire umpire gregory. [SEP]']
Attempt swap
[1550/2000] tot_loss=3.324 (perp=9.455, rec=0.445, cos=0.988), tot_loss_proj:3.902 [t=0.18s]
prediction: ['[CLS] they umpire umpire umpire gregory. [SEP]']
Attempt swap
[1600/2000] tot_loss=3.308 (perp=9.455, rec=0.429, cos=0.988), tot_loss_proj:3.901 [t=0.18s]
prediction: ['[CLS] they umpire umpire umpire gregory. [SEP]']
[1650/2000] tot_loss=3.094 (perp=8.365, rec=0.433, cos=0.988), tot_loss_proj:3.637 [t=0.18s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[1700/2000] tot_loss=3.103 (perp=8.365, rec=0.442, cos=0.988), tot_loss_proj:3.634 [t=0.17s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[1750/2000] tot_loss=3.092 (perp=8.365, rec=0.431, cos=0.988), tot_loss_proj:3.635 [t=0.17s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
[1800/2000] tot_loss=3.095 (perp=8.365, rec=0.434, cos=0.988), tot_loss_proj:3.634 [t=0.17s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[1850/2000] tot_loss=3.093 (perp=8.365, rec=0.432, cos=0.988), tot_loss_proj:3.635 [t=0.17s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[1900/2000] tot_loss=3.088 (perp=8.365, rec=0.427, cos=0.988), tot_loss_proj:3.638 [t=0.17s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
[1950/2000] tot_loss=3.100 (perp=8.365, rec=0.439, cos=0.988), tot_loss_proj:3.637 [t=0.17s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Attempt swap
[2000/2000] tot_loss=3.102 (perp=8.365, rec=0.441, cos=0.988), tot_loss_proj:3.636 [t=0.17s]
prediction: ['[CLS] of umpire umpire umpire gregory. [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] the umpire called it of. [SEP]
========================
predicted: 
========================
[CLS] itpuolis umpire called. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 80.000 | r: 57.143
rouge2     | fm: 20.000 | p: 25.000 | r: 16.667
rougeL     | fm: 66.667 | p: 80.000 | r: 57.143
rougeLsum  | fm: 66.667 | p: 80.000 | r: 57.143
r1fm+r2fm = 86.667

[Aggregate metrics]:
rouge1     | fm: 82.195 | p: 81.493 | r: 83.191
rouge2     | fm: 40.939 | p: 40.609 | r: 41.416
rougeL     | fm: 70.044 | p: 69.468 | r: 70.844
rougeLsum  | fm: 70.019 | p: 69.424 | r: 70.824
r1fm+r2fm = 123.134

input #79 time: 0:07:07 | total time: 10:48:44


Running input #80 of 100.
reference: 
========================
The rock placed the sky with the fork.
========================
average of cosine similarity 0.9993117236696568
highest_index [0]
highest [0.9993117236696568]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[ 101, 1996, 2600, 2872, 1996, 3712, 2007, 1996, 9292, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] the rock placed the sky with the fork. [SEP]']
[Init] best rec loss: 1.5755250453948975 for ['[CLS] female scared marcus humble ramp bracket hybrid marieeur [SEP]']
[Init] best rec loss: 1.392714023590088 for ['[CLS] janr afterward city necessary trans him raced fis [SEP]']
[Init] best rec loss: 1.3708689212799072 for ['[CLS] kind plan loft [MASK]?elin unincorporated beard points [SEP]']
[Init] best rec loss: 1.3612807989120483 for ['[CLS]own volunteers byte carr bold grace interchange chalk our [SEP]']
[Init] best rec loss: 1.1748619079589844 for ['[CLS] marchade bowie despite april example un de cassie [SEP]']
[Init] best rec loss: 1.1663693189620972 for ['[CLS] every actions climbingnotressed bun via [SEP] louder [SEP]']
[Init] best rec loss: 1.0659953355789185 for ['[CLS] carolina battle minor meredith care quantum beside demanded asked [SEP]']
[Init] best rec loss: 1.0313990116119385 for ['[CLS] duane av lungs forty currently bird. charge actors [SEP]']
[Init] best rec loss: 0.9735422134399414 for ['[CLS] crazy daughters plusg words sessions vent server hereditary [SEP]']
[Init] best perm rec loss: 0.9653320908546448 for ['[CLS] plusg vent words crazy sessions daughters server hereditary [SEP]']
[Init] best perm rec loss: 0.9612882733345032 for ['[CLS] hereditary plus words crazy server sessions ventg daughters [SEP]']
[Init] best perm rec loss: 0.9568877220153809 for ['[CLS] server daughters plus words crazy sessions hereditaryg vent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.924 (perp=12.679, rec=0.354, cos=0.034), tot_loss_proj:3.230 [t=0.17s]
prediction: ['[CLS] placed brother the veins using could largest put altar [SEP]']
[ 100/2000] tot_loss=2.790 (perp=12.757, rec=0.224, cos=0.014), tot_loss_proj:3.438 [t=0.17s]
prediction: ['[CLS] placed rock the fork with could larger placed sky [SEP]']
[ 150/2000] tot_loss=2.716 (perp=12.757, rec=0.156, cos=0.009), tot_loss_proj:3.458 [t=0.17s]
prediction: ['[CLS] placed rock the fork with could larger placed sky [SEP]']
[ 200/2000] tot_loss=2.398 (perp=11.391, rec=0.113, cos=0.006), tot_loss_proj:3.029 [t=0.17s]
prediction: ['[CLS] placed rock the fork with could other placed sky [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.878 (perp=8.773, rec=0.119, cos=0.005), tot_loss_proj:2.687 [t=0.17s]
prediction: ['[CLS] placed the rock the fork with the placed sky [SEP]']
[ 300/2000] tot_loss=1.863 (perp=8.773, rec=0.103, cos=0.005), tot_loss_proj:2.679 [t=0.17s]
prediction: ['[CLS] placed the rock the fork with the placed sky [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.601 (perp=7.552, rec=0.086, cos=0.004), tot_loss_proj:2.408 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.606 (perp=7.552, rec=0.091, cos=0.005), tot_loss_proj:2.401 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[ 450/2000] tot_loss=1.609 (perp=7.552, rec=0.094, cos=0.004), tot_loss_proj:2.412 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.593 (perp=7.552, rec=0.078, cos=0.004), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.603 (perp=7.552, rec=0.088, cos=0.004), tot_loss_proj:2.398 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[ 600/2000] tot_loss=1.594 (perp=7.552, rec=0.079, cos=0.004), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.608 (perp=7.552, rec=0.094, cos=0.004), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.595 (perp=7.552, rec=0.081, cos=0.004), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[ 750/2000] tot_loss=1.604 (perp=7.552, rec=0.089, cos=0.004), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.597 (perp=7.552, rec=0.082, cos=0.004), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.586 (perp=7.552, rec=0.072, cos=0.004), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[ 900/2000] tot_loss=1.612 (perp=7.552, rec=0.097, cos=0.004), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.595 (perp=7.552, rec=0.080, cos=0.004), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.583 (perp=7.552, rec=0.069, cos=0.004), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[1050/2000] tot_loss=1.596 (perp=7.552, rec=0.081, cos=0.004), tot_loss_proj:2.396 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.596 (perp=7.552, rec=0.082, cos=0.004), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.592 (perp=7.552, rec=0.078, cos=0.004), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[1200/2000] tot_loss=1.582 (perp=7.552, rec=0.068, cos=0.004), tot_loss_proj:2.387 [t=0.19s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.591 (perp=7.552, rec=0.077, cos=0.004), tot_loss_proj:2.384 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.592 (perp=7.552, rec=0.077, cos=0.004), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[1350/2000] tot_loss=1.584 (perp=7.552, rec=0.070, cos=0.004), tot_loss_proj:2.390 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.598 (perp=7.552, rec=0.084, cos=0.004), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.601 (perp=7.552, rec=0.087, cos=0.004), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[1500/2000] tot_loss=1.595 (perp=7.552, rec=0.081, cos=0.004), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.599 (perp=7.552, rec=0.085, cos=0.004), tot_loss_proj:2.396 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.593 (perp=7.552, rec=0.079, cos=0.004), tot_loss_proj:2.386 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[1650/2000] tot_loss=1.593 (perp=7.552, rec=0.079, cos=0.004), tot_loss_proj:2.390 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.552, rec=0.082, cos=0.004), tot_loss_proj:2.381 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.595 (perp=7.552, rec=0.081, cos=0.004), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[1800/2000] tot_loss=1.590 (perp=7.552, rec=0.075, cos=0.004), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.592 (perp=7.552, rec=0.078, cos=0.004), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.591 (perp=7.552, rec=0.077, cos=0.004), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
[1950/2000] tot_loss=1.590 (perp=7.552, rec=0.075, cos=0.004), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.590 (perp=7.552, rec=0.076, cos=0.004), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] placed the rock placed the fork with the sky [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] the rock placed the sky with the fork. [SEP]
========================
predicted: 
========================
[CLS] placed the rock placed the fork with the sky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 63.158 | p: 60.000 | r: 66.667
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 158.396

[Aggregate metrics]:
rouge1     | fm: 82.308 | p: 81.570 | r: 83.318
rouge2     | fm: 41.092 | p: 40.728 | r: 41.708
rougeL     | fm: 70.198 | p: 69.597 | r: 71.053
rougeLsum  | fm: 70.083 | p: 69.502 | r: 70.938
r1fm+r2fm = 123.400

input #80 time: 0:06:53 | total time: 10:55:38


Running input #81 of 100.
reference: 
========================
Tagalog is speaks in the Philippines.
========================
average of cosine similarity 0.999340695785271
highest_index [0]
highest [0.999340695785271]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  6415, 23067,  2290,  2003,  8847,  1999,  1996,  5137,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] tagalog is speaks in the philippines. [SEP]']
[Init] best rec loss: 1.1397817134857178 for ['[CLS]lch scotland uhf qualifying claude worse attempt faye costs [SEP]']
[Init] best rec loss: 0.978796124458313 for ['[CLS]ei understand turn infrastructure galley project tracks annual [SEP]']
[Init] best rec loss: 0.9372612237930298 for ['[CLS] has kowalski part case jericho money though stuck holy [SEP]']
[Init] best rec loss: 0.9342506527900696 for ['[CLS] / star mo wasn doubled trial pmid como problem [SEP]']
[Init] best rec loss: 0.8889713883399963 for ['[CLS]ee forcescence reach inherited / for work again [SEP]']
[Init] best rec loss: 0.8831915855407715 for ['[CLS]mba biggerusdock be named kill hit standards [SEP]']
[Init] best perm rec loss: 0.879248321056366 for ['[CLS] named standards be hit kill biggerusmbadock [SEP]']
[Init] best perm rec loss: 0.8737494945526123 for ['[CLS] hit standards bigger nameddockus kill bemba [SEP]']
[Init] best perm rec loss: 0.8724139332771301 for ['[CLS] standardsdock namedmba biggerus be hit kill [SEP]']
[Init] best perm rec loss: 0.869186520576477 for ['[CLS] killdockus named standards bigger hitmba be [SEP]']
[Init] best perm rec loss: 0.8687834143638611 for ['[CLS] standardsmba hit bigger named killdockus be [SEP]']
[Init] best perm rec loss: 0.86784827709198 for ['[CLS] hit standards kill nameddock biggermba beus [SEP]']
[Init] best perm rec loss: 0.8661229610443115 for ['[CLS] killdock namedusmba hit be bigger standards [SEP]']
[Init] best perm rec loss: 0.8646193146705627 for ['[CLS] standardsdock named hit bigger bemba killus [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.674 (perp=11.361, rec=0.356, cos=0.046), tot_loss_proj:3.141 [t=0.17s]
prediction: ['[CLS] tam had information was filipino was filipino number niche [SEP]']
[ 100/2000] tot_loss=2.303 (perp=9.898, rec=0.295, cos=0.029), tot_loss_proj:2.861 [t=0.17s]
prediction: ['[CLS] finn has word was philippines is philippines is is [SEP]']
[ 150/2000] tot_loss=2.239 (perp=9.898, rec=0.242, cos=0.018), tot_loss_proj:2.868 [t=0.17s]
prediction: ['[CLS] finn has word was philippines is philippines is is [SEP]']
[ 200/2000] tot_loss=2.203 (perp=9.845, rec=0.220, cos=0.014), tot_loss_proj:3.015 [t=0.17s]
prediction: ['[CLS] finn has word in philippines is philippines speaks is [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.651 (perp=11.945, rec=0.247, cos=0.015), tot_loss_proj:3.156 [t=0.17s]
prediction: ['[CLS] tagalo speaks word is tag is philippines in [SEP]']
[ 300/2000] tot_loss=2.606 (perp=11.930, rec=0.209, cos=0.010), tot_loss_proj:3.115 [t=0.17s]
prediction: ['[CLS] tagalo speaks tag inalo is philippines in [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.157 (perp=9.787, rec=0.190, cos=0.010), tot_loss_proj:2.665 [t=0.17s]
prediction: ['[CLS] tagalo speaks speaks tagalo is philippines in [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.208 (perp=10.201, rec=0.160, cos=0.007), tot_loss_proj:2.742 [t=0.17s]
prediction: ['[CLS] tagalo speaks speaks inalo is in philippines [SEP]']
[ 450/2000] tot_loss=2.199 (perp=10.201, rec=0.151, cos=0.007), tot_loss_proj:2.740 [t=0.17s]
prediction: ['[CLS] tagalo speaks speaks inalo is in philippines [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.782 (perp=8.243, rec=0.127, cos=0.006), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo in philippines [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.772 (perp=8.243, rec=0.118, cos=0.006), tot_loss_proj:2.458 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo in philippines [SEP]']
[ 600/2000] tot_loss=1.761 (perp=8.243, rec=0.107, cos=0.005), tot_loss_proj:2.454 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo in philippines [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.759 (perp=8.243, rec=0.105, cos=0.005), tot_loss_proj:2.454 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo in philippines [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.768 (perp=8.243, rec=0.114, cos=0.005), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo in philippines [SEP]']
[ 750/2000] tot_loss=1.754 (perp=8.243, rec=0.100, cos=0.005), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo in philippines [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.833 (perp=8.625, rec=0.103, cos=0.005), tot_loss_proj:2.754 [t=0.17s]
prediction: ['[CLS] tagalog speaks. isalo in philippines [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.800 (perp=8.440, rec=0.105, cos=0.007), tot_loss_proj:2.941 [t=0.17s]
prediction: ['[CLS] tagalog speaks. in isalo philippines [SEP]']
[ 900/2000] tot_loss=1.796 (perp=8.440, rec=0.103, cos=0.005), tot_loss_proj:2.945 [t=0.17s]
prediction: ['[CLS] tagalog speaks. in isalo philippines [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.564 (perp=7.301, rec=0.100, cos=0.004), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.565 (perp=7.301, rec=0.101, cos=0.004), tot_loss_proj:2.524 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
[1050/2000] tot_loss=1.562 (perp=7.301, rec=0.098, cos=0.004), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.579 (perp=7.301, rec=0.114, cos=0.004), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.560 (perp=7.301, rec=0.096, cos=0.003), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
[1200/2000] tot_loss=1.558 (perp=7.301, rec=0.094, cos=0.004), tot_loss_proj:2.520 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.557 (perp=7.301, rec=0.093, cos=0.004), tot_loss_proj:2.522 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.556 (perp=7.301, rec=0.092, cos=0.004), tot_loss_proj:2.517 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
[1350/2000] tot_loss=1.542 (perp=7.301, rec=0.078, cos=0.004), tot_loss_proj:2.520 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.554 (perp=7.301, rec=0.091, cos=0.004), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.550 (perp=7.301, rec=0.086, cos=0.004), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
[1500/2000] tot_loss=1.554 (perp=7.301, rec=0.090, cos=0.004), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.549 (perp=7.301, rec=0.085, cos=0.004), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.555 (perp=7.301, rec=0.091, cos=0.004), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
[1650/2000] tot_loss=1.550 (perp=7.301, rec=0.086, cos=0.004), tot_loss_proj:2.515 [t=0.19s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.545 (perp=7.301, rec=0.081, cos=0.003), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.544 (perp=7.301, rec=0.080, cos=0.003), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
[1800/2000] tot_loss=1.552 (perp=7.301, rec=0.089, cos=0.003), tot_loss_proj:2.520 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.549 (perp=7.301, rec=0.086, cos=0.003), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.558 (perp=7.301, rec=0.094, cos=0.003), tot_loss_proj:2.517 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
[1950/2000] tot_loss=1.553 (perp=7.301, rec=0.089, cos=0.003), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.553 (perp=7.301, rec=0.089, cos=0.003), tot_loss_proj:2.522 [t=0.17s]
prediction: ['[CLS] tagalog speaks in isalo philippines. [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] tagalog is speaks in the philippines. [SEP]
========================
predicted: 
========================
[CLS] tagalog speaks in isalo philippines. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 85.714 | r: 75.000
rouge2     | fm: 46.154 | p: 50.000 | r: 42.857
rougeL     | fm: 80.000 | p: 85.714 | r: 75.000
rougeLsum  | fm: 80.000 | p: 85.714 | r: 75.000
r1fm+r2fm = 126.154

[Aggregate metrics]:
rouge1     | fm: 82.222 | p: 81.504 | r: 83.199
rouge2     | fm: 41.167 | p: 40.863 | r: 41.623
rougeL     | fm: 70.302 | p: 69.774 | r: 71.080
rougeLsum  | fm: 70.239 | p: 69.730 | r: 71.037
r1fm+r2fm = 123.388

input #81 time: 0:06:49 | total time: 11:02:28


Running input #82 of 100.
reference: 
========================
He waltzed her across the floor.
========================
average of cosine similarity 0.9995051539996082
highest_index [0]
highest [0.9995051539996082]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2002, 17569,  2098,  2014,  2408,  1996,  2723,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] he waltzed her across the floor. [SEP]']
[Init] best rec loss: 1.9916000366210938 for ['[CLS] beverly womenboat [MASK] greatly waterfold bears [SEP]']
[Init] best rec loss: 1.9036943912506104 for ['[CLS] recruittropical flip lowolin rome as? [SEP]']
[Init] best rec loss: 1.8906415700912476 for ['[CLS] forced eyes promoted tessa dayton allied damon chalk [SEP]']
[Init] best rec loss: 1.886218547821045 for ['[CLS] understood both cluster sometimesnished private sharptive [SEP]']
[Init] best rec loss: 1.885218858718872 for ['[CLS] gulpntes state lives broken relatives achieved winter [SEP]']
[Init] best rec loss: 1.8678590059280396 for ['[CLS] surgery cup coe corn theyrainedorin moon [SEP]']
[Init] best rec loss: 1.858630657196045 for ['[CLS] among acquired mouthed don radar money blacks club [SEP]']
[Init] best rec loss: 1.852632999420166 for ['[CLS] can diamond jamie lieseu lisa find division [SEP]']
[Init] best perm rec loss: 1.8512533903121948 for ['[CLS] can lies lisa find divisioneu jamie diamond [SEP]']
[Init] best perm rec loss: 1.8505641222000122 for ['[CLS] can lisa divisioneu jamie lies find diamond [SEP]']
[Init] best perm rec loss: 1.8497194051742554 for ['[CLS] can division lieseu find diamond lisa jamie [SEP]']
[Init] best perm rec loss: 1.8495534658432007 for ['[CLS]eu division lies diamond find jamie lisa can [SEP]']
[Init] best perm rec loss: 1.847408413887024 for ['[CLS] lieseu can diamond find division lisa jamie [SEP]']
[Init] best perm rec loss: 1.8468546867370605 for ['[CLS] division caneu lisa jamie find lies diamond [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.720 (perp=11.147, rec=0.672, cos=0.819), tot_loss_proj:4.195 [t=0.17s]
prediction: ['[CLS] ♥bus tribe. : demand trader blockade [SEP]']
[ 100/2000] tot_loss=2.550 (perp=10.526, rec=0.389, cos=0.056), tot_loss_proj:4.080 [t=0.17s]
prediction: ['[CLS] waltz waltz teams. waltzenity brick laced [SEP]']
[ 150/2000] tot_loss=2.669 (perp=11.605, rec=0.319, cos=0.029), tot_loss_proj:4.244 [t=0.17s]
prediction: ['[CLS] waltz cocktail across. waltz waltz hered [SEP]']
[ 200/2000] tot_loss=2.637 (perp=11.820, rec=0.254, cos=0.019), tot_loss_proj:4.235 [t=0.17s]
prediction: ['[CLS] he waltz across. waltz waltz hered [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.251 (perp=10.103, rec=0.216, cos=0.015), tot_loss_proj:3.868 [t=0.17s]
prediction: ['[CLS] he waltzed across waltz waltz her across [SEP]']
[ 300/2000] tot_loss=2.075 (perp=9.537, rec=0.159, cos=0.008), tot_loss_proj:3.766 [t=0.17s]
prediction: ['[CLS] he waltzed floor waltz floor her across [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.931 (perp=8.939, rec=0.136, cos=0.007), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] he waltzed floor waltz floor across her [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.752 (perp=8.081, rec=0.129, cos=0.007), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] he waltzed floor waltz across her floor [SEP]']
[ 450/2000] tot_loss=2.095 (perp=9.851, rec=0.119, cos=0.006), tot_loss_proj:3.839 [t=0.17s]
prediction: ['[CLS] heeded floor waltz across her floor [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.009 (perp=9.517, rec=0.101, cos=0.005), tot_loss_proj:3.788 [t=0.17s]
prediction: ['[CLS] heeded waltz floor across her floor [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.679 (perp=7.855, rec=0.103, cos=0.005), tot_loss_proj:3.481 [t=0.17s]
prediction: ['[CLS] heed waltzed floor across her floor [SEP]']
[ 600/2000] tot_loss=1.663 (perp=7.855, rec=0.089, cos=0.004), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] heed waltzed floor across her floor [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.589 (perp=7.536, rec=0.079, cos=0.003), tot_loss_proj:3.489 [t=0.17s]
prediction: ['[CLS] he floored waltzed across her floor [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.599 (perp=7.536, rec=0.088, cos=0.003), tot_loss_proj:3.492 [t=0.17s]
prediction: ['[CLS] he floored waltzed across her floor [SEP]']
[ 750/2000] tot_loss=1.595 (perp=7.536, rec=0.085, cos=0.003), tot_loss_proj:3.490 [t=0.17s]
prediction: ['[CLS] he floored waltzed across her floor [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.803 (perp=8.587, rec=0.082, cos=0.003), tot_loss_proj:3.614 [t=0.17s]
prediction: ['[CLS] he waltz. floored across her floor [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.553 (perp=7.381, rec=0.074, cos=0.004), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] he waltzed floor. across her floor [SEP]']
[ 900/2000] tot_loss=1.554 (perp=7.381, rec=0.074, cos=0.003), tot_loss_proj:3.511 [t=0.17s]
prediction: ['[CLS] he waltzed floor. across her floor [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.357 (perp=6.351, rec=0.083, cos=0.003), tot_loss_proj:3.291 [t=0.17s]
prediction: ['[CLS] he waltzed floor across her floor. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.306 (perp=6.131, rec=0.076, cos=0.004), tot_loss_proj:2.326 [t=0.17s]
prediction: ['[CLS] he waltzed across her floor floor. [SEP]']
[1050/2000] tot_loss=1.306 (perp=6.131, rec=0.077, cos=0.003), tot_loss_proj:2.328 [t=0.17s]
prediction: ['[CLS] he waltzed across her floor floor. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.424 (perp=6.715, rec=0.077, cos=0.003), tot_loss_proj:3.298 [t=0.17s]
prediction: ['[CLS] he waltzed across her floor across. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.338 (perp=6.244, rec=0.086, cos=0.003), tot_loss_proj:2.638 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
[1200/2000] tot_loss=1.328 (perp=6.244, rec=0.075, cos=0.003), tot_loss_proj:2.624 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.325 (perp=6.244, rec=0.073, cos=0.003), tot_loss_proj:2.625 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.327 (perp=6.244, rec=0.075, cos=0.003), tot_loss_proj:2.618 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
[1350/2000] tot_loss=1.330 (perp=6.244, rec=0.078, cos=0.003), tot_loss_proj:2.618 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.324 (perp=6.244, rec=0.072, cos=0.003), tot_loss_proj:2.615 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.325 (perp=6.244, rec=0.073, cos=0.003), tot_loss_proj:2.611 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
[1500/2000] tot_loss=1.325 (perp=6.244, rec=0.073, cos=0.003), tot_loss_proj:2.605 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.329 (perp=6.244, rec=0.077, cos=0.003), tot_loss_proj:2.599 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.323 (perp=6.244, rec=0.071, cos=0.003), tot_loss_proj:2.599 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
[1650/2000] tot_loss=1.324 (perp=6.244, rec=0.072, cos=0.003), tot_loss_proj:2.601 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.319 (perp=6.244, rec=0.067, cos=0.003), tot_loss_proj:2.598 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.323 (perp=6.244, rec=0.071, cos=0.003), tot_loss_proj:2.598 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
[1800/2000] tot_loss=1.331 (perp=6.244, rec=0.079, cos=0.003), tot_loss_proj:2.587 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.318 (perp=6.244, rec=0.066, cos=0.003), tot_loss_proj:2.588 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.321 (perp=6.244, rec=0.069, cos=0.003), tot_loss_proj:2.590 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
[1950/2000] tot_loss=1.328 (perp=6.244, rec=0.076, cos=0.003), tot_loss_proj:2.584 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.323 (perp=6.244, rec=0.071, cos=0.003), tot_loss_proj:2.596 [t=0.17s]
prediction: ['[CLS] he waltzed across across her floor. [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] he waltzed her across the floor. [SEP]
========================
predicted: 
========================
[CLS] he waltzed across across her floor. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 130.357

[Aggregate metrics]:
rouge1     | fm: 82.239 | p: 81.591 | r: 83.202
rouge2     | fm: 41.117 | p: 40.739 | r: 41.664
rougeL     | fm: 70.361 | p: 69.887 | r: 71.113
rougeLsum  | fm: 70.310 | p: 69.813 | r: 71.041
r1fm+r2fm = 123.356

input #82 time: 0:06:50 | total time: 11:09:19


Running input #83 of 100.
reference: 
========================
How easy to please John is it?
========================
average of cosine similarity 0.9991972001687286
highest_index [0]
highest [0.9991972001687286]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 2129, 3733, 2000, 3531, 2198, 2003, 2009, 1029,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] how easy to please john is it? [SEP]']
[Init] best rec loss: 1.6630487442016602 for ['[CLS] blacksmith straight heart comprises works right wa would [SEP]']
[Init] best rec loss: 1.3179535865783691 for ['[CLS] god bay hungarianaround dad pony medal i [SEP]']
[Init] best rec loss: 1.2576791048049927 for ['[CLS] trevorntsgni midway coup eye denied disputed [SEP]']
[Init] best rec loss: 1.1287204027175903 for ['[CLS] lead addressed cruz irish nice motion | father [SEP]']
[Init] best rec loss: 1.0780028104782104 for ['[CLS] bonnie teller elevation min cafe superior involvedthest [SEP]']
[Init] best perm rec loss: 1.0713708400726318 for ['[CLS] cafethest involved superior min elevation teller bonnie [SEP]']
[Init] best perm rec loss: 1.0632133483886719 for ['[CLS] superior elevation minthest teller cafe involved bonnie [SEP]']
[Init] best perm rec loss: 1.0489915609359741 for ['[CLS] superior involved min elevation bonnie cafe tellerthest [SEP]']
[Init] best perm rec loss: 1.0469294786453247 for ['[CLS] min bonnie elevation superior involved teller cafethest [SEP]']
[Init] best perm rec loss: 1.0460975170135498 for ['[CLS] superior cafe elevation bonnie teller involved minthest [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.958 (perp=12.613, rec=0.374, cos=0.062), tot_loss_proj:3.506 [t=0.17s]
prediction: ['[CLS] please info please danger now what faster haste [SEP]']
[ 100/2000] tot_loss=2.016 (perp=8.301, rec=0.318, cos=0.038), tot_loss_proj:2.520 [t=0.17s]
prediction: ['[CLS] how easy easy is is what please john [SEP]']
[ 150/2000] tot_loss=1.749 (perp=7.442, rec=0.238, cos=0.023), tot_loss_proj:3.275 [t=0.17s]
prediction: ['[CLS] how easy easy is? to please john [SEP]']
[ 200/2000] tot_loss=1.697 (perp=7.442, rec=0.190, cos=0.019), tot_loss_proj:3.280 [t=0.17s]
prediction: ['[CLS] how easy easy is? to please john [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.444 (perp=6.460, rec=0.141, cos=0.011), tot_loss_proj:2.967 [t=0.17s]
prediction: ['[CLS] how easy easy is to please? john [SEP]']
[ 300/2000] tot_loss=1.412 (perp=6.460, rec=0.111, cos=0.008), tot_loss_proj:2.961 [t=0.17s]
prediction: ['[CLS] how easy easy is to please? john [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.396 (perp=5.854, rec=0.210, cos=0.015), tot_loss_proj:3.184 [t=0.17s]
prediction: ['[CLS] how easy is easy to please? john [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.332 (perp=5.854, rec=0.151, cos=0.010), tot_loss_proj:3.178 [t=0.17s]
prediction: ['[CLS] how easy is easy to please? john [SEP]']
[ 450/2000] tot_loss=1.298 (perp=5.854, rec=0.119, cos=0.008), tot_loss_proj:3.182 [t=0.17s]
prediction: ['[CLS] how easy is easy to please? john [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.287 (perp=5.854, rec=0.108, cos=0.008), tot_loss_proj:3.182 [t=0.17s]
prediction: ['[CLS] how easy is easy to please? john [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.286 (perp=5.854, rec=0.107, cos=0.007), tot_loss_proj:3.185 [t=0.17s]
prediction: ['[CLS] how easy is easy to please? john [SEP]']
[ 600/2000] tot_loss=1.284 (perp=5.854, rec=0.106, cos=0.007), tot_loss_proj:3.184 [t=0.17s]
prediction: ['[CLS] how easy is easy to please? john [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.277 (perp=5.854, rec=0.099, cos=0.007), tot_loss_proj:3.184 [t=0.17s]
prediction: ['[CLS] how easy is easy to please? john [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.167 (perp=5.309, rec=0.099, cos=0.007), tot_loss_proj:3.084 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
[ 750/2000] tot_loss=1.170 (perp=5.309, rec=0.102, cos=0.006), tot_loss_proj:3.083 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.149 (perp=5.309, rec=0.084, cos=0.003), tot_loss_proj:3.084 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.138 (perp=5.309, rec=0.074, cos=0.002), tot_loss_proj:3.083 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
[ 900/2000] tot_loss=1.145 (perp=5.309, rec=0.081, cos=0.002), tot_loss_proj:3.084 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.127 (perp=5.309, rec=0.064, cos=0.002), tot_loss_proj:3.087 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1000/2000] tot_loss=1.131 (perp=5.309, rec=0.067, cos=0.002), tot_loss_proj:3.086 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
[1050/2000] tot_loss=1.127 (perp=5.309, rec=0.064, cos=0.002), tot_loss_proj:3.086 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1100/2000] tot_loss=1.129 (perp=5.309, rec=0.066, cos=0.002), tot_loss_proj:3.090 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1150/2000] tot_loss=1.130 (perp=5.309, rec=0.066, cos=0.002), tot_loss_proj:3.080 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
[1200/2000] tot_loss=1.128 (perp=5.309, rec=0.065, cos=0.002), tot_loss_proj:3.086 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1250/2000] tot_loss=1.130 (perp=5.309, rec=0.067, cos=0.002), tot_loss_proj:3.086 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1300/2000] tot_loss=1.125 (perp=5.309, rec=0.062, cos=0.002), tot_loss_proj:3.085 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
[1350/2000] tot_loss=1.130 (perp=5.309, rec=0.066, cos=0.002), tot_loss_proj:3.083 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1400/2000] tot_loss=1.124 (perp=5.309, rec=0.060, cos=0.002), tot_loss_proj:3.083 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1450/2000] tot_loss=1.136 (perp=5.309, rec=0.073, cos=0.002), tot_loss_proj:3.086 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
[1500/2000] tot_loss=1.133 (perp=5.309, rec=0.069, cos=0.002), tot_loss_proj:3.089 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1550/2000] tot_loss=1.139 (perp=5.309, rec=0.075, cos=0.002), tot_loss_proj:3.088 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1600/2000] tot_loss=1.133 (perp=5.309, rec=0.070, cos=0.002), tot_loss_proj:3.085 [t=0.22s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
[1650/2000] tot_loss=1.135 (perp=5.309, rec=0.071, cos=0.002), tot_loss_proj:3.088 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1700/2000] tot_loss=1.126 (perp=5.309, rec=0.062, cos=0.002), tot_loss_proj:3.087 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1750/2000] tot_loss=1.133 (perp=5.309, rec=0.070, cos=0.002), tot_loss_proj:3.085 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
[1800/2000] tot_loss=1.133 (perp=5.309, rec=0.070, cos=0.002), tot_loss_proj:3.087 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1850/2000] tot_loss=1.143 (perp=5.309, rec=0.080, cos=0.002), tot_loss_proj:3.089 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[1900/2000] tot_loss=1.130 (perp=5.309, rec=0.066, cos=0.002), tot_loss_proj:3.088 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
[1950/2000] tot_loss=1.138 (perp=5.309, rec=0.075, cos=0.002), tot_loss_proj:3.080 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Attempt swap
[2000/2000] tot_loss=1.138 (perp=5.309, rec=0.074, cos=0.002), tot_loss_proj:3.087 [t=0.17s]
prediction: ['[CLS] how it is easy to please? john [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] how easy to please john is it? [SEP]
========================
predicted: 
========================
[CLS] how it is easy to please? john [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 82.636 | p: 81.939 | r: 83.551
rouge2     | fm: 41.364 | p: 41.003 | r: 41.846
rougeL     | fm: 70.440 | p: 70.007 | r: 71.187
rougeLsum  | fm: 70.434 | p: 69.896 | r: 71.126
r1fm+r2fm = 124.000

input #83 time: 0:06:51 | total time: 11:16:10


Running input #84 of 100.
reference: 
========================
That the king or queen be present is a requirement on all Royal weddings.
========================
average of cosine similarity 0.9993769048273349
highest_index [0]
highest [0.9993769048273349]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2008,  1996,  2332,  2030,  3035,  2022,  2556,  2003,  1037,
          9095,  2006,  2035,  2548, 20429,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]']
[Init] best rec loss: 1.843615174293518 for ['[CLS] y during udnsorlot shed art closed described power na seriously guild le grinding [SEP]']
[Init] best rec loss: 1.8412238359451294 for ['[CLS] bali equal ncaa blew roosevelt bell > prior arab bye mach led technologicaltage clicked [SEP]']
[Init] best rec loss: 1.8388968706130981 for ['[CLS] gia studiedgingly forget robin give nationally character harvey wilkes cullen pulled n designated zealand [SEP]']
[Init] best rec loss: 1.8314876556396484 for ['[CLS] pictures finished christian concerned press breath historyarat wish everything malta later offeriki repeated [SEP]']
[Init] best rec loss: 1.82575261592865 for ['[CLS] slip broken muchtonesx datejured physical sorry key hit cruising taxi tug tate [SEP]']
[Init] best perm rec loss: 1.8220531940460205 for ['[CLS] slip sorry tug cruising taxixjured brokentones hit tate physical much date key [SEP]']
[Init] best perm rec loss: 1.8206307888031006 for ['[CLS] broken date slip tugtones tate taxi physicaljured sorry cruisingx much hit key [SEP]']
[Init] best perm rec loss: 1.8188068866729736 for ['[CLS] hit taxi sorry tug slip broken physicalx keyjured cruisingtones tate much date [SEP]']
[Init] best perm rec loss: 1.818703055381775 for ['[CLS] cruising date key tug much broken physical sliptones hitxjured sorry taxi tate [SEP]']
[Init] best perm rec loss: 1.816228985786438 for ['[CLS] taxi much hit sorry tate physical sliptones tug brokenx datejured key cruising [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.011 (perp=12.554, rec=0.412, cos=0.088), tot_loss_proj:4.395 [t=0.17s]
prediction: ['[CLS]. timing indian township bad royal pushedox cheer throne. properly voted northernly [SEP]']
[ 100/2000] tot_loss=2.272 (perp=9.810, rec=0.282, cos=0.029), tot_loss_proj:3.843 [t=0.17s]
prediction: ['[CLS]. timing that weddings a royal cannot wedding relation royal. properly weddings north of [SEP]']
[ 150/2000] tot_loss=2.126 (perp=9.461, rec=0.218, cos=0.016), tot_loss_proj:3.720 [t=0.17s]
prediction: ['[CLS]. be is weddings that king on weddingsgoing royal. requirement weddings queen. [SEP]']
[ 200/2000] tot_loss=1.868 (perp=8.357, rec=0.187, cos=0.010), tot_loss_proj:3.492 [t=0.17s]
prediction: ['[CLS] that be isquisite a king on royal requirement royal. on weddings queen. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.759 (perp=7.665, rec=0.208, cos=0.018), tot_loss_proj:3.406 [t=0.17s]
prediction: ['[CLS] that be is royal requirement the king was present king. on weddings royal, [SEP]']
[ 300/2000] tot_loss=1.601 (perp=7.277, rec=0.139, cos=0.006), tot_loss_proj:3.309 [t=0.17s]
prediction: ['[CLS] that be is royal requirement the king be present king or on weddings royal. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.474 (perp=6.773, rec=0.114, cos=0.005), tot_loss_proj:3.227 [t=0.17s]
prediction: ['[CLS] that be is royal requirement the king be king present or on weddings royal. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.567 (perp=6.853, rec=0.185, cos=0.012), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] that is royal requirement the king be king be present or on weddings royal, [SEP]']
[ 450/2000] tot_loss=1.569 (perp=7.183, rec=0.127, cos=0.005), tot_loss_proj:3.324 [t=0.17s]
prediction: ['[CLS] that is royal requirement the queen be king that present or on weddings royal, [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.391 (perp=6.384, rec=0.110, cos=0.004), tot_loss_proj:3.218 [t=0.17s]
prediction: ['[CLS] that is royal requirement that the queen be king present or on weddings all, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.347 (perp=6.129, rec=0.117, cos=0.005), tot_loss_proj:3.194 [t=0.17s]
prediction: ['[CLS] that is royal requirement that the queen be king present or on weddings, royal [SEP]']
[ 600/2000] tot_loss=1.340 (perp=6.129, rec=0.109, cos=0.005), tot_loss_proj:3.192 [t=0.17s]
prediction: ['[CLS] that is royal requirement that the queen be king present or on weddings, royal [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.334 (perp=6.089, rec=0.112, cos=0.004), tot_loss_proj:3.190 [t=0.17s]
prediction: ['[CLS] that is royal requirement that the queen be king present or on weddings royal, [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.201 (perp=5.486, rec=0.100, cos=0.004), tot_loss_proj:3.046 [t=0.17s]
prediction: ['[CLS] that is royal requirement that the queen be king present or on royal weddings, [SEP]']
[ 750/2000] tot_loss=1.276 (perp=5.813, rec=0.109, cos=0.004), tot_loss_proj:3.140 [t=0.17s]
prediction: ['[CLS] that is royal requirement that the queen be king present or on queen weddings, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.262 (perp=5.813, rec=0.095, cos=0.004), tot_loss_proj:3.139 [t=0.17s]
prediction: ['[CLS] that is royal requirement that the queen be king present or on queen weddings, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.230 (perp=5.575, rec=0.109, cos=0.005), tot_loss_proj:3.084 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen be king present or on queen weddings. [SEP]']
[ 900/2000] tot_loss=1.211 (perp=5.575, rec=0.093, cos=0.003), tot_loss_proj:3.093 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen be king present or on queen weddings. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.159 (perp=5.311, rec=0.094, cos=0.003), tot_loss_proj:3.113 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen be king present or queen on weddings. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.104 (perp=5.057, rec=0.090, cos=0.003), tot_loss_proj:3.012 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen be present king or queen on weddings. [SEP]']
[1050/2000] tot_loss=1.104 (perp=5.057, rec=0.090, cos=0.003), tot_loss_proj:3.015 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen be present king or queen on weddings. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.083 (perp=4.979, rec=0.085, cos=0.003), tot_loss_proj:3.061 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.083 (perp=4.979, rec=0.084, cos=0.003), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
[1200/2000] tot_loss=1.076 (perp=4.979, rec=0.078, cos=0.003), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.089 (perp=4.979, rec=0.091, cos=0.003), tot_loss_proj:3.053 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.083 (perp=4.979, rec=0.085, cos=0.003), tot_loss_proj:3.060 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
[1350/2000] tot_loss=1.081 (perp=4.979, rec=0.083, cos=0.003), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.080 (perp=4.979, rec=0.082, cos=0.003), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.074 (perp=4.979, rec=0.076, cos=0.003), tot_loss_proj:3.052 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
[1500/2000] tot_loss=1.082 (perp=4.979, rec=0.084, cos=0.003), tot_loss_proj:3.056 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.078 (perp=4.979, rec=0.080, cos=0.003), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.094 (perp=4.979, rec=0.096, cos=0.003), tot_loss_proj:3.061 [t=0.21s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
[1650/2000] tot_loss=1.084 (perp=4.979, rec=0.085, cos=0.003), tot_loss_proj:3.058 [t=0.20s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.081 (perp=4.979, rec=0.082, cos=0.003), tot_loss_proj:3.058 [t=0.21s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.088 (perp=4.979, rec=0.090, cos=0.003), tot_loss_proj:3.059 [t=0.19s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
[1800/2000] tot_loss=1.086 (perp=4.979, rec=0.087, cos=0.003), tot_loss_proj:3.062 [t=0.19s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.081 (perp=4.979, rec=0.083, cos=0.003), tot_loss_proj:3.056 [t=0.19s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.075 (perp=4.979, rec=0.077, cos=0.003), tot_loss_proj:3.062 [t=0.19s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
[1950/2000] tot_loss=1.079 (perp=4.979, rec=0.081, cos=0.003), tot_loss_proj:3.054 [t=0.19s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.078 (perp=4.979, rec=0.080, cos=0.003), tot_loss_proj:3.057 [t=0.19s]
prediction: ['[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] that the king or queen be present is a requirement on all royal weddings. [SEP]
========================
predicted: 
========================
[CLS] all is royal requirement that the queen present be king or queen on weddings. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.750 | p: 93.750 | r: 93.750
rouge2     | fm: 26.667 | p: 26.667 | r: 26.667
rougeL     | fm: 56.250 | p: 56.250 | r: 56.250
rougeLsum  | fm: 56.250 | p: 56.250 | r: 56.250
r1fm+r2fm = 120.417

[Aggregate metrics]:
rouge1     | fm: 82.681 | p: 82.032 | r: 83.618
rouge2     | fm: 41.169 | p: 40.844 | r: 41.635
rougeL     | fm: 70.329 | p: 69.893 | r: 70.998
rougeLsum  | fm: 70.225 | p: 69.758 | r: 70.944
r1fm+r2fm = 123.850

input #84 time: 0:07:04 | total time: 11:23:15


Running input #85 of 100.
reference: 
========================
Aphrodite stinks to be omnipotent.
========================
average of cosine similarity 0.9992293766306254
highest_index [0]
highest [0.9992293766306254]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  9706,  8093,  7716,  4221, 27136,  2015,  2000,  2022, 18168,
          3490, 11008,  4765,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] aphrodite stinks to be omnipotent. [SEP]']
[Init] best rec loss: 1.8772838115692139 for ['[CLS] grandchildren ghosts course [SEP]et chief view matt single ko pass rural entered [SEP]']
[Init] best rec loss: 1.5649994611740112 for ['[CLS] glancedュ lowell anna bathtana range focus deafules ball look shortened [SEP]']
[Init] best rec loss: 1.547109842300415 for ['[CLS] bang hd people essential cell [UNK]ckweight wonder origin unique joshua pick [SEP]']
[Init] best rec loss: 1.4954006671905518 for ['[CLS] march mayoralloadsman greatuled coverskieox monuments res bree thomas [SEP]']
[Init] best rec loss: 1.4837992191314697 for ['[CLS] horatio score clenched traffic numerous certain drained ontohend heart mystery roger burgundy [SEP]']
[Init] best rec loss: 1.4634904861450195 for ['[CLS] davy prime lace therefore grown destruction scales card spaceyp bennett hung whispered [SEP]']
[Init] best rec loss: 1.4442527294158936 for ['[CLS] flyer plain abruptly respectivelybase stan didndara trialseconomic may know card [SEP]']
[Init] best rec loss: 1.398227572441101 for ['[CLS] beneath asked string wrath chief premiere general kneltabas expected minute taiwanese careful [SEP]']
[Init] best rec loss: 1.3146623373031616 for ['[CLS] wounded se try electronic bei emi than 2000s federer in somebody script minute [SEP]']
[Init] best rec loss: 1.290819525718689 for ['[CLS] go legged camille song xavier greg corinne most minus fever formation pair se [SEP]']
[Init] best rec loss: 1.2818083763122559 for ['[CLS] dana weather grandmaster first checked youngereration gliding catalogue as profile block to [SEP]']
[Init] best rec loss: 1.2302075624465942 for ['[CLS] siennapage off expanded well chair now greaves curse infantry legionstra communicate [SEP]']
[Init] best perm rec loss: 1.223167896270752 for ['[CLS] expanded curse well greaves infantry now legions chairpage sienna offtra communicate [SEP]']
[Init] best perm rec loss: 1.216576337814331 for ['[CLS] communicatepage expanded chair now welltra sienna off curse infantry greaves legions [SEP]']
[Init] best perm rec loss: 1.2147618532180786 for ['[CLS] expanded chair communicate legionspage well greaves infantry offtra curse sienna now [SEP]']
[Init] best perm rec loss: 1.201157808303833 for ['[CLS] now expanded well sienna offtra curse chair greaves communicatepage legions infantry [SEP]']
[Init] best perm rec loss: 1.1978189945220947 for ['[CLS] communicate greaves now infantry off well expanded chair siennatrapage curse legions [SEP]']
[Init] best perm rec loss: 1.188220500946045 for ['[CLS] expanded curse legions well greavespage communicate off infantry chair now siennatra [SEP]']
[Init] best perm rec loss: 1.1869001388549805 for ['[CLS] communicate now off greaves infantry curse legions expanded welltrapage chair sienna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.586 (perp=14.108, rec=0.500, cos=0.264), tot_loss_proj:4.080 [t=0.17s]
prediction: ['[CLS] recorded expo solid0fest imperial sounds plane cleveland pressure taken humans oricon [SEP]']
[ 100/2000] tot_loss=3.100 (perp=13.304, rec=0.354, cos=0.085), tot_loss_proj:3.863 [t=0.17s]
prediction: ['[CLS]odite gtpot stink stink tours constantly blackpro acclaimed smelling be [SEP]']
[ 150/2000] tot_loss=3.126 (perp=13.784, rec=0.308, cos=0.062), tot_loss_proj:4.110 [t=0.17s]
prediction: ['[CLS]oditepoteria stink stink stinkizeditepro portray smelling be [SEP]']
[ 200/2000] tot_loss=2.822 (perp=12.665, rec=0.248, cos=0.040), tot_loss_proj:3.873 [t=0.17s]
prediction: ['[CLS]oditepotite stink stink stinknitepro portray stink be [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.836 (perp=12.848, rec=0.233, cos=0.034), tot_loss_proj:4.207 [t=0.17s]
prediction: ['[CLS]odite ominus stink stink stinknpotite portray qualify to [SEP]']
[ 300/2000] tot_loss=2.646 (perp=12.061, rec=0.206, cos=0.028), tot_loss_proj:3.652 [t=0.17s]
prediction: ['[CLS]odite omic stink stink stinknpotite beent to [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.329 (perp=10.484, rec=0.209, cos=0.023), tot_loss_proj:3.760 [t=0.17s]
prediction: ['[CLS]odite to omics stink stink.potite beent [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.488 (perp=11.505, rec=0.171, cos=0.016), tot_loss_proj:3.737 [t=0.17s]
prediction: ['[CLS]odite to omics stink stinkanialpotentite be [SEP]']
[ 450/2000] tot_loss=2.463 (perp=11.505, rec=0.147, cos=0.014), tot_loss_proj:3.744 [t=0.17s]
prediction: ['[CLS]odite to omics stink stinkanialpotentite be [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.489 (perp=11.702, rec=0.137, cos=0.011), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS]odite to omods ap stink stinkpotentite be [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.393 (perp=11.237, rec=0.134, cos=0.012), tot_loss_proj:3.610 [t=0.17s]
prediction: ['[CLS]odite to omods ap stinkite stinkpotent be [SEP]']
[ 600/2000] tot_loss=2.386 (perp=11.237, rec=0.131, cos=0.008), tot_loss_proj:3.603 [t=0.17s]
prediction: ['[CLS]odite to omods ap stinkite stinkpotent be [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.410 (perp=11.349, rec=0.127, cos=0.013), tot_loss_proj:3.543 [t=0.17s]
prediction: ['[CLS]odite to om stinks apicite stinkpotent be [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.151 (perp=9.990, rec=0.138, cos=0.016), tot_loss_proj:3.351 [t=0.17s]
prediction: ['[CLS]odite om stinks apicite stinkpotent to be [SEP]']
[ 750/2000] tot_loss=2.126 (perp=9.990, rec=0.120, cos=0.008), tot_loss_proj:3.349 [t=0.17s]
prediction: ['[CLS]odite om stinks apicite stinkpotent to be [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.100 (perp=9.921, rec=0.109, cos=0.007), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS]odite om stinks ap stinkicchemicalpotent to be [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.896 (perp=8.912, rec=0.106, cos=0.007), tot_loss_proj:3.218 [t=0.17s]
prediction: ['[CLS]odite om stinks ap stinkchemicalnipotent to be [SEP]']
[ 900/2000] tot_loss=1.898 (perp=8.912, rec=0.109, cos=0.006), tot_loss_proj:3.215 [t=0.17s]
prediction: ['[CLS]odite om stinks ap stinkchemicalnipotent to be [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.076 (perp=9.791, rec=0.110, cos=0.008), tot_loss_proj:3.454 [t=0.17s]
prediction: ['[CLS]odite om stinks stink apchemicalodpotent to be [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.939 (perp=9.118, rec=0.108, cos=0.007), tot_loss_proj:3.311 [t=0.17s]
prediction: ['[CLS]odite om stinks stink apodchemicalpotent to be [SEP]']
[1050/2000] tot_loss=1.940 (perp=9.118, rec=0.109, cos=0.007), tot_loss_proj:3.316 [t=0.17s]
prediction: ['[CLS]odite om stinks stink apodchemicalpotent to be [SEP]']
Attempt swap
[1100/2000] tot_loss=1.948 (perp=9.118, rec=0.118, cos=0.006), tot_loss_proj:3.315 [t=0.17s]
prediction: ['[CLS]odite om stinks stink apodchemicalpotent to be [SEP]']
Attempt swap
[1150/2000] tot_loss=1.942 (perp=9.118, rec=0.112, cos=0.006), tot_loss_proj:3.312 [t=0.17s]
prediction: ['[CLS]odite om stinks stink apodchemicalpotent to be [SEP]']
[1200/2000] tot_loss=1.930 (perp=9.118, rec=0.100, cos=0.006), tot_loss_proj:3.314 [t=0.17s]
prediction: ['[CLS]odite om stinks stink apodchemicalpotent to be [SEP]']
Attempt swap
[1250/2000] tot_loss=1.942 (perp=9.118, rec=0.112, cos=0.006), tot_loss_proj:3.310 [t=0.17s]
prediction: ['[CLS]odite om stinks stink apodchemicalpotent to be [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.844 (perp=8.678, rec=0.102, cos=0.006), tot_loss_proj:3.280 [t=0.17s]
prediction: ['[CLS]odite om stinks stink apchemicalnipotent to be [SEP]']
[1350/2000] tot_loss=1.843 (perp=8.678, rec=0.101, cos=0.006), tot_loss_proj:3.277 [t=0.18s]
prediction: ['[CLS]odite om stinks stink apchemicalnipotent to be [SEP]']
Attempt swap
[1400/2000] tot_loss=1.842 (perp=8.678, rec=0.100, cos=0.006), tot_loss_proj:3.275 [t=0.17s]
prediction: ['[CLS]odite om stinks stink apchemicalnipotent to be [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.652 (perp=7.707, rec=0.105, cos=0.006), tot_loss_proj:3.060 [t=0.17s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
[1500/2000] tot_loss=1.649 (perp=7.707, rec=0.101, cos=0.007), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
Attempt swap
[1550/2000] tot_loss=1.647 (perp=7.707, rec=0.099, cos=0.007), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
Attempt swap
[1600/2000] tot_loss=1.661 (perp=7.707, rec=0.113, cos=0.007), tot_loss_proj:3.060 [t=0.19s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
[1650/2000] tot_loss=1.648 (perp=7.707, rec=0.100, cos=0.007), tot_loss_proj:3.065 [t=0.19s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
Attempt swap
[1700/2000] tot_loss=1.645 (perp=7.707, rec=0.097, cos=0.007), tot_loss_proj:3.067 [t=0.19s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
Attempt swap
[1750/2000] tot_loss=1.650 (perp=7.707, rec=0.102, cos=0.007), tot_loss_proj:3.068 [t=0.19s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
[1800/2000] tot_loss=1.654 (perp=7.707, rec=0.106, cos=0.007), tot_loss_proj:3.064 [t=0.19s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
Attempt swap
[1850/2000] tot_loss=1.651 (perp=7.707, rec=0.103, cos=0.007), tot_loss_proj:3.065 [t=0.19s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
Attempt swap
[1900/2000] tot_loss=1.652 (perp=7.707, rec=0.104, cos=0.007), tot_loss_proj:3.073 [t=0.19s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
[1950/2000] tot_loss=1.645 (perp=7.707, rec=0.097, cos=0.007), tot_loss_proj:3.065 [t=0.19s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
Attempt swap
[2000/2000] tot_loss=1.648 (perp=7.707, rec=0.100, cos=0.007), tot_loss_proj:3.064 [t=0.19s]
prediction: ['[CLS]oditechemical stinks stink ap omnipotent to be [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] aphrodite stinks to be omnipotent. [SEP]
========================
predicted: 
========================
[CLS]oditechemical stinks stink ap omnipotent to be [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 66.667 | r: 85.714
rouge2     | fm: 14.286 | p: 12.500 | r: 16.667
rougeL     | fm: 62.500 | p: 55.556 | r: 71.429
rougeLsum  | fm: 62.500 | p: 55.556 | r: 71.429
r1fm+r2fm = 89.286

[Aggregate metrics]:
rouge1     | fm: 82.613 | p: 81.886 | r: 83.616
rouge2     | fm: 40.978 | p: 40.671 | r: 41.383
rougeL     | fm: 70.208 | p: 69.686 | r: 71.009
rougeLsum  | fm: 70.069 | p: 69.559 | r: 70.893
r1fm+r2fm = 123.591

input #85 time: 0:06:59 | total time: 11:30:15


Running input #86 of 100.
reference: 
========================
I lifted him up the books.
========================
average of cosine similarity 0.9993153968093855
highest_index [0]
highest [0.9993153968093855]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1045, 4196, 2032, 2039, 1996, 2808, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i lifted him up the books. [SEP]']
[Init] best rec loss: 1.611572027206421 for ['[CLS] associates kill blockade musica [SEP] bees... [SEP]']
[Init] best rec loss: 1.416754961013794 for ['[CLS] grey features civil emotions cheek villain could [SEP]']
[Init] best rec loss: 1.3640830516815186 for ["[CLS] 'ry full winston postwright what [SEP]"]
[Init] best rec loss: 1.3453989028930664 for ['[CLS] geekping converted order early franchise pressing [SEP]']
[Init] best rec loss: 1.329918384552002 for ['[CLS] hope police shelters applicant war chris not [SEP]']
[Init] best rec loss: 1.2267729043960571 for ['[CLS] schools team legal lateents laird each [SEP]']
[Init] best rec loss: 1.1739482879638672 for ['[CLS] cara jar orchard wolf walking this negative [SEP]']
[Init] best rec loss: 1.0476857423782349 for ['[CLS] did chin rearن spray davyologist [SEP]']
[Init] best rec loss: 1.0341604948043823 for ['[CLS] put minutes brest week renamed wilson fields [SEP]']
[Init] best rec loss: 1.0213634967803955 for ['[CLS] growing vocals unlike clan t actually next [SEP]']
[Init] best rec loss: 0.9557203054428101 for ['[CLS]tonic based coveren booth novels infrared [SEP]']
[Init] best rec loss: 0.9362522959709167 for ['[CLS] made par letters imp carrier obviouss [SEP]']
[Init] best rec loss: 0.8857644200325012 for ['[CLS]arus bank groups bare primetime rub reviewer [SEP]']
[Init] best perm rec loss: 0.8790813684463501 for ['[CLS] primetime bank groups reviewer rubarus bare [SEP]']
[Init] best perm rec loss: 0.8781758546829224 for ['[CLS] bare primetime rub bank reviewer groupsarus [SEP]']
[Init] best perm rec loss: 0.8770923614501953 for ['[CLS] reviewer bare bank groupsarus rub primetime [SEP]']
[Init] best perm rec loss: 0.868222177028656 for ['[CLS] groupsarus primetime bank reviewer rub bare [SEP]']
[Init] best perm rec loss: 0.865603506565094 for ['[CLS] rub primetime bare bank reviewer groupsarus [SEP]']
[Init] best perm rec loss: 0.8654381036758423 for ['[CLS] groups primetime reviewer bankarus rub bare [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.871 (perp=11.737, rec=0.477, cos=0.046), tot_loss_proj:3.656 [t=0.18s]
prediction: ['[CLS] is construction scale systemrium model rec [SEP]']
[ 100/2000] tot_loss=2.254 (perp=9.375, rec=0.353, cos=0.026), tot_loss_proj:3.045 [t=0.19s]
prediction: ['[CLS] is ranks lifted upr up and [SEP]']
[ 150/2000] tot_loss=2.186 (perp=9.500, rec=0.271, cos=0.016), tot_loss_proj:2.716 [t=0.19s]
prediction: ['[CLS] was lifted books up metal lifted : [SEP]']
[ 200/2000] tot_loss=2.251 (perp=10.192, rec=0.204, cos=0.009), tot_loss_proj:2.889 [t=0.19s]
prediction: ['[CLS] was him books up book lifted books [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.030 (perp=9.103, rec=0.196, cos=0.014), tot_loss_proj:2.375 [t=0.19s]
prediction: ['[CLS] i lifted him the up books books [SEP]']
[ 300/2000] tot_loss=1.954 (perp=9.103, rec=0.127, cos=0.006), tot_loss_proj:2.384 [t=0.19s]
prediction: ['[CLS] i lifted him the up books books [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.570 (perp=7.301, rec=0.106, cos=0.004), tot_loss_proj:1.996 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.582 (perp=7.301, rec=0.113, cos=0.009), tot_loss_proj:1.994 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[ 450/2000] tot_loss=1.538 (perp=7.301, rec=0.074, cos=0.003), tot_loss_proj:1.980 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.556 (perp=7.301, rec=0.093, cos=0.003), tot_loss_proj:1.983 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.547 (perp=7.301, rec=0.084, cos=0.003), tot_loss_proj:1.978 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[ 600/2000] tot_loss=1.544 (perp=7.301, rec=0.081, cos=0.003), tot_loss_proj:1.974 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.542 (perp=7.301, rec=0.079, cos=0.003), tot_loss_proj:1.961 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.542 (perp=7.301, rec=0.079, cos=0.003), tot_loss_proj:1.965 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[ 750/2000] tot_loss=1.541 (perp=7.301, rec=0.078, cos=0.003), tot_loss_proj:1.959 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.536 (perp=7.301, rec=0.072, cos=0.003), tot_loss_proj:1.951 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.550 (perp=7.301, rec=0.087, cos=0.003), tot_loss_proj:1.955 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[ 900/2000] tot_loss=1.541 (perp=7.301, rec=0.078, cos=0.003), tot_loss_proj:1.936 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.535 (perp=7.301, rec=0.072, cos=0.003), tot_loss_proj:1.942 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1000/2000] tot_loss=1.541 (perp=7.301, rec=0.078, cos=0.003), tot_loss_proj:1.943 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[1050/2000] tot_loss=1.540 (perp=7.301, rec=0.077, cos=0.003), tot_loss_proj:1.938 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1100/2000] tot_loss=1.534 (perp=7.301, rec=0.071, cos=0.003), tot_loss_proj:1.938 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1150/2000] tot_loss=1.544 (perp=7.301, rec=0.081, cos=0.003), tot_loss_proj:1.940 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[1200/2000] tot_loss=1.546 (perp=7.301, rec=0.083, cos=0.003), tot_loss_proj:1.932 [t=0.19s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1250/2000] tot_loss=1.534 (perp=7.301, rec=0.071, cos=0.003), tot_loss_proj:1.929 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1300/2000] tot_loss=1.549 (perp=7.301, rec=0.086, cos=0.003), tot_loss_proj:1.934 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[1350/2000] tot_loss=1.546 (perp=7.301, rec=0.083, cos=0.003), tot_loss_proj:1.932 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1400/2000] tot_loss=1.535 (perp=7.301, rec=0.072, cos=0.003), tot_loss_proj:1.930 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1450/2000] tot_loss=1.534 (perp=7.301, rec=0.071, cos=0.003), tot_loss_proj:1.928 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[1500/2000] tot_loss=1.542 (perp=7.301, rec=0.079, cos=0.003), tot_loss_proj:1.937 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1550/2000] tot_loss=1.529 (perp=7.301, rec=0.066, cos=0.003), tot_loss_proj:1.930 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1600/2000] tot_loss=1.542 (perp=7.301, rec=0.079, cos=0.003), tot_loss_proj:1.922 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[1650/2000] tot_loss=1.534 (perp=7.301, rec=0.070, cos=0.003), tot_loss_proj:1.921 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1700/2000] tot_loss=1.533 (perp=7.301, rec=0.070, cos=0.003), tot_loss_proj:1.923 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1750/2000] tot_loss=1.534 (perp=7.301, rec=0.071, cos=0.003), tot_loss_proj:1.923 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[1800/2000] tot_loss=1.537 (perp=7.301, rec=0.074, cos=0.003), tot_loss_proj:1.918 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1850/2000] tot_loss=1.544 (perp=7.301, rec=0.081, cos=0.003), tot_loss_proj:1.919 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[1900/2000] tot_loss=1.543 (perp=7.301, rec=0.079, cos=0.003), tot_loss_proj:1.928 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
[1950/2000] tot_loss=1.536 (perp=7.301, rec=0.073, cos=0.003), tot_loss_proj:1.922 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Attempt swap
[2000/2000] tot_loss=1.539 (perp=7.301, rec=0.076, cos=0.003), tot_loss_proj:1.926 [t=0.17s]
prediction: ['[CLS] i lifted him up the books books [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] i lifted him up the books. [SEP]
========================
predicted: 
========================
[CLS] i lifted him up the books books [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 93.333 | p: 87.500 | r: 100.000
rougeL     | fm: 94.118 | p: 88.889 | r: 100.000
rougeLsum  | fm: 94.118 | p: 88.889 | r: 100.000
r1fm+r2fm = 187.451

[Aggregate metrics]:
rouge1     | fm: 82.690 | p: 81.861 | r: 83.806
rouge2     | fm: 41.505 | p: 41.062 | r: 42.051
rougeL     | fm: 70.467 | p: 69.848 | r: 71.328
rougeLsum  | fm: 70.419 | p: 69.862 | r: 71.335
r1fm+r2fm = 124.195

input #86 time: 0:07:13 | total time: 11:37:28


Running input #87 of 100.
reference: 
========================
Heidi thinks that Andy has eaten salmon flavored candy bars.
========================
average of cosine similarity 0.9993324758205361
highest_index [0]
highest [0.9993324758205361]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101, 21372,  6732,  2008,  5557,  2038,  8828, 11840, 14894,  2098,
          9485,  6963,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]']
[Init] best rec loss: 1.9233328104019165 for ['[CLS] flood but! means roe vietnam after partial owe cult novel question [SEP]']
[Init] best rec loss: 1.803200602531433 for ['[CLS] remained rates made glacier beginning gift pianoril department springsuratie [SEP]']
[Init] best rec loss: 1.7936533689498901 for ['[CLS] news hatch group doing grandpa suppose sanity shadows calls unlike matters sits [SEP]']
[Init] best rec loss: 1.7917555570602417 for ['[CLS] read political mcbride career near booti gemma fix swayed understood english [SEP]']
[Init] best rec loss: 1.7558246850967407 for ['[CLS] lookenciesbad against lost quality often warner called engineers reece downed [SEP]']
[Init] best rec loss: 1.7485740184783936 for ['[CLS] noted slavery surfer none article or deeper precinct hannah purchaseab steel [SEP]']
[Init] best perm rec loss: 1.7434015274047852 for ['[CLS] articleab precinct none steel hannah slavery purchase or noted deeper surfer [SEP]']
[Init] best perm rec loss: 1.7432234287261963 for ['[CLS] none noted hannah purchase precinctab surfer article deeper slavery or steel [SEP]']
[Init] best perm rec loss: 1.7422431707382202 for ['[CLS] precinct purchase none notedab surfer hannah article steel slavery or deeper [SEP]']
[Init] best perm rec loss: 1.741007924079895 for ['[CLS]ab none or precinct noted steel hannah purchase surfer article slavery deeper [SEP]']
[Init] best perm rec loss: 1.7391886711120605 for ['[CLS] purchase none deeper or noted article precinctab surfer hannah steel slavery [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.120 (perp=12.960, rec=0.559, cos=0.969), tot_loss_proj:4.453 [t=0.17s]
prediction: ['[CLS] attempting besidesberry - eyebrows harry precinct lips reeling disease kid headquartered [SEP]']
[ 100/2000] tot_loss=2.978 (perp=13.407, rec=0.266, cos=0.030), tot_loss_proj:4.540 [t=0.17s]
prediction: ['[CLS] noticed sweet heidi found facial andy wants heidi flavor advertisement andy eat [SEP]']
[ 150/2000] tot_loss=2.666 (perp=12.297, rec=0.194, cos=0.013), tot_loss_proj:4.247 [t=0.17s]
prediction: ['[CLS] eaten sweet andy has flavor heidi thinks heidi think liquor andy eat [SEP]']
[ 200/2000] tot_loss=2.670 (perp=12.628, rec=0.137, cos=0.007), tot_loss_proj:4.352 [t=0.17s]
prediction: ['[CLS] eaten otherwise andy has candy heidi thinks heidi thinks liquor andy candy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=4.075 (perp=11.465, rec=0.797, cos=0.985), tot_loss_proj:4.176 [t=0.17s]
prediction: ['[CLS] eaten that andy has candy heidi outbreak heidi thinks. food candy [SEP]']
[ 300/2000] tot_loss=2.858 (perp=11.803, rec=0.425, cos=0.072), tot_loss_proj:4.152 [t=0.17s]
prediction: ['[CLS] eaten that andy has cervical heidi salmon heidi thinks. variety bars [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.639 (perp=11.618, rec=0.293, cos=0.022), tot_loss_proj:4.234 [t=0.17s]
prediction: ['[CLS] thinks that andy has litre heidi salmon heidi eaten. ⟨ foods [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.199 (perp=9.765, rec=0.230, cos=0.016), tot_loss_proj:3.869 [t=0.17s]
prediction: ['[CLS] thinks that andy has eaten eating heidi salmon heidi. ⟨ candy [SEP]']
[ 450/2000] tot_loss=2.148 (perp=9.709, rec=0.195, cos=0.012), tot_loss_proj:3.784 [t=0.17s]
prediction: ['[CLS] thinks that andy has eaten eaten heidi salmon heidi. flavor candy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.154 (perp=9.837, rec=0.178, cos=0.009), tot_loss_proj:3.886 [t=0.17s]
prediction: ['[CLS] thinks that andy has eaten heidi salmon eaten heidi ; flavor candy [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.551 (perp=11.089, rec=0.301, cos=0.031), tot_loss_proj:4.068 [t=0.17s]
prediction: ['[CLS] thinks that andy has eaten heidi heidi eaten flavor eaten inwardly cents [SEP]']
[ 600/2000] tot_loss=2.451 (perp=11.043, rec=0.227, cos=0.015), tot_loss_proj:4.056 [t=0.22s]
prediction: ['[CLS] thinks that andy has eaten heidi heidi eaten flavor eaten inwardly candy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.211 (perp=9.933, rec=0.212, cos=0.012), tot_loss_proj:3.926 [t=0.17s]
prediction: ['[CLS] thinks that andy has eaten heidi heidi inwardly foods eaten eaten candy [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.149 (perp=9.688, rec=0.200, cos=0.012), tot_loss_proj:3.876 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
[ 750/2000] tot_loss=2.122 (perp=9.688, rec=0.174, cos=0.011), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.115 (perp=9.688, rec=0.168, cos=0.010), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.107 (perp=9.688, rec=0.160, cos=0.009), tot_loss_proj:3.875 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
[ 900/2000] tot_loss=2.102 (perp=9.688, rec=0.155, cos=0.009), tot_loss_proj:3.876 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.098 (perp=9.688, rec=0.151, cos=0.009), tot_loss_proj:3.869 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
Attempt swap
[1000/2000] tot_loss=2.096 (perp=9.688, rec=0.150, cos=0.008), tot_loss_proj:3.868 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
[1050/2000] tot_loss=2.095 (perp=9.688, rec=0.149, cos=0.008), tot_loss_proj:3.868 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
Attempt swap
[1100/2000] tot_loss=2.094 (perp=9.688, rec=0.148, cos=0.008), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
Attempt swap
[1150/2000] tot_loss=2.087 (perp=9.688, rec=0.141, cos=0.008), tot_loss_proj:3.873 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
[1200/2000] tot_loss=2.084 (perp=9.688, rec=0.139, cos=0.008), tot_loss_proj:3.871 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
Attempt swap
[1250/2000] tot_loss=2.085 (perp=9.688, rec=0.140, cos=0.008), tot_loss_proj:3.869 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
Attempt swap
[1300/2000] tot_loss=2.088 (perp=9.688, rec=0.143, cos=0.008), tot_loss_proj:3.875 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
[1350/2000] tot_loss=2.081 (perp=9.688, rec=0.136, cos=0.008), tot_loss_proj:3.870 [t=0.17s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
Attempt swap
[1400/2000] tot_loss=2.092 (perp=9.688, rec=0.147, cos=0.008), tot_loss_proj:3.870 [t=0.19s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly foods eaten eaten candy [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.095 (perp=9.727, rec=0.142, cos=0.008), tot_loss_proj:3.794 [t=0.19s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly eaten foods eaten candy [SEP]']
[1500/2000] tot_loss=2.093 (perp=9.724, rec=0.140, cos=0.008), tot_loss_proj:3.817 [t=0.19s]
prediction: ['[CLS] thinks that heidi has eaten heidi andy inwardly eaten candy eaten candy [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.032 (perp=9.440, rec=0.136, cos=0.008), tot_loss_proj:3.708 [t=0.19s]
prediction: ['[CLS] thinks that heidi eaten heidi has andy inwardly eaten candy eaten candy [SEP]']
Attempt swap
[1600/2000] tot_loss=2.095 (perp=9.711, rec=0.145, cos=0.008), tot_loss_proj:3.755 [t=0.19s]
prediction: ['[CLS] thinks that heidi eaten heidi has andy flavor eaten candy eaten candy [SEP]']
[1650/2000] tot_loss=2.088 (perp=9.711, rec=0.139, cos=0.008), tot_loss_proj:3.752 [t=0.19s]
prediction: ['[CLS] thinks that heidi eaten heidi has andy flavor eaten candy eaten candy [SEP]']
Attempt swap
[1700/2000] tot_loss=2.084 (perp=9.711, rec=0.134, cos=0.007), tot_loss_proj:3.752 [t=0.19s]
prediction: ['[CLS] thinks that heidi eaten heidi has andy flavor eaten candy eaten candy [SEP]']
Attempt swap
[1750/2000] tot_loss=2.088 (perp=9.711, rec=0.138, cos=0.007), tot_loss_proj:3.752 [t=0.19s]
prediction: ['[CLS] thinks that heidi eaten heidi has andy flavor eaten candy eaten candy [SEP]']
[1800/2000] tot_loss=2.087 (perp=9.711, rec=0.138, cos=0.007), tot_loss_proj:3.753 [t=0.19s]
prediction: ['[CLS] thinks that heidi eaten heidi has andy flavor eaten candy eaten candy [SEP]']
Attempt swap
[1850/2000] tot_loss=2.063 (perp=9.597, rec=0.137, cos=0.007), tot_loss_proj:3.737 [t=0.19s]
prediction: ['[CLS] thinks that heidi eaten heidi has andy protein eaten candy eaten candy [SEP]']
Attempt swap
[1900/2000] tot_loss=2.063 (perp=9.597, rec=0.136, cos=0.007), tot_loss_proj:3.744 [t=0.19s]
prediction: ['[CLS] thinks that heidi eaten heidi has andy protein eaten candy eaten candy [SEP]']
[1950/2000] tot_loss=2.067 (perp=9.597, rec=0.141, cos=0.007), tot_loss_proj:3.740 [t=0.19s]
prediction: ['[CLS] thinks that heidi eaten heidi has andy protein eaten candy eaten candy [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.027 (perp=9.416, rec=0.137, cos=0.007), tot_loss_proj:3.725 [t=0.19s]
prediction: ['[CLS] thinks that heidi has heidi eaten andy protein eaten candy eaten candy [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] heidi thinks that andy has eaten salmon flavored candy bars. [SEP]
========================
predicted: 
========================
[CLS] eaten that andy has candy heidi thinks heidi thinks tickets andy candy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.231 | p: 64.286 | r: 75.000
rouge2     | fm: 25.000 | p: 23.077 | r: 27.273
rougeL     | fm: 46.154 | p: 42.857 | r: 50.000
rougeLsum  | fm: 46.154 | p: 42.857 | r: 50.000
r1fm+r2fm = 94.231

[Aggregate metrics]:
rouge1     | fm: 82.519 | p: 81.642 | r: 83.731
rouge2     | fm: 41.183 | p: 40.748 | r: 41.724
rougeL     | fm: 70.179 | p: 69.562 | r: 71.067
rougeLsum  | fm: 70.136 | p: 69.504 | r: 71.040
r1fm+r2fm = 123.702

input #87 time: 0:07:01 | total time: 11:44:29


Running input #88 of 100.
reference: 
========================
He bought these flowers for Aaron.
========================
average of cosine similarity 0.9993928411345322
highest_index [0]
highest [0.9993928411345322]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2002, 4149, 2122, 4870, 2005, 7158, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] he bought these flowers for aaron. [SEP]']
[Init] best rec loss: 2.032292127609253 for ['[CLS] wi rio xx irving ou obligations tang [SEP]']
[Init] best rec loss: 1.9112935066223145 for ['[CLS]ing rahman medina volume!lyn put [SEP]']
[Init] best rec loss: 1.8924027681350708 for ['[CLS] monica making helmet think remains admitted queue [SEP]']
[Init] best rec loss: 1.7550089359283447 for ['[CLS] firm force beef parttion companions civil [SEP]']
[Init] best rec loss: 1.6916624307632446 for ['[CLS] jew between whitney its timing child architectural [SEP]']
[Init] best rec loss: 1.6840591430664062 for ['[CLS] disappointment her col observer responsible outbreakssel [SEP]']
[Init] best perm rec loss: 1.6792335510253906 for ['[CLS] her disappointment col observer outbreakssel responsible [SEP]']
[Init] best perm rec loss: 1.678680181503296 for ['[CLS] outbreak observer responsible her disappointmentssel col [SEP]']
[Init] best perm rec loss: 1.6719882488250732 for ['[CLS] disappointmentssel responsible outbreak her col observer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.517 (perp=9.458, rec=0.733, cos=0.893), tot_loss_proj:3.841 [t=0.18s]
prediction: ['[CLS] bill these windows, inyou pierce [SEP]']
[ 100/2000] tot_loss=2.922 (perp=12.397, rec=0.377, cos=0.066), tot_loss_proj:4.314 [t=0.19s]
prediction: ['[CLS] flowers they windows bought goodbye aaron these [SEP]']
[ 150/2000] tot_loss=2.514 (perp=11.415, rec=0.214, cos=0.016), tot_loss_proj:4.199 [t=0.19s]
prediction: ['[CLS] flowers flowers flowers bought mr aaron these [SEP]']
[ 200/2000] tot_loss=2.416 (perp=11.152, rec=0.173, cos=0.013), tot_loss_proj:4.159 [t=0.19s]
prediction: ['[CLS] flowers flowers flowers bought ms aaron these [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.280 (perp=10.629, rec=0.146, cos=0.009), tot_loss_proj:4.052 [t=0.19s]
prediction: ['[CLS] aaron flowers flowers bought ms flowers these [SEP]']
[ 300/2000] tot_loss=2.701 (perp=13.006, rec=0.094, cos=0.005), tot_loss_proj:4.401 [t=0.19s]
prediction: ['[CLS] aaron for flowers bought thank he these [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.251 (perp=10.756, rec=0.095, cos=0.005), tot_loss_proj:3.940 [t=0.19s]
prediction: ['[CLS] aaron for flowers bought these he thank [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.028 (perp=9.689, rec=0.085, cos=0.005), tot_loss_proj:3.778 [t=0.19s]
prediction: ['[CLS] aaron bought flowers for these he thank [SEP]']
[ 450/2000] tot_loss=2.018 (perp=9.689, rec=0.076, cos=0.005), tot_loss_proj:3.774 [t=0.19s]
prediction: ['[CLS] aaron bought flowers for these he thank [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.022 (perp=9.689, rec=0.080, cos=0.004), tot_loss_proj:3.776 [t=0.19s]
prediction: ['[CLS] aaron bought flowers for these he thank [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.030 (perp=9.689, rec=0.088, cos=0.004), tot_loss_proj:3.776 [t=0.19s]
prediction: ['[CLS] aaron bought flowers for these he thank [SEP]']
[ 600/2000] tot_loss=2.039 (perp=9.717, rec=0.091, cos=0.004), tot_loss_proj:4.116 [t=0.19s]
prediction: ['[CLS] aaron bought flowers for these he • [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.941 (perp=9.311, rec=0.074, cos=0.004), tot_loss_proj:3.801 [t=0.19s]
prediction: ['[CLS] aaron bought these flowers for he • [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.951 (perp=9.311, rec=0.085, cos=0.004), tot_loss_proj:3.796 [t=0.19s]
prediction: ['[CLS] aaron bought these flowers for he • [SEP]']
[ 750/2000] tot_loss=1.944 (perp=9.311, rec=0.077, cos=0.004), tot_loss_proj:3.803 [t=0.19s]
prediction: ['[CLS] aaron bought these flowers for he • [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.950 (perp=9.311, rec=0.084, cos=0.004), tot_loss_proj:3.797 [t=0.19s]
prediction: ['[CLS] aaron bought these flowers for he • [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.947 (perp=9.311, rec=0.081, cos=0.004), tot_loss_proj:3.797 [t=0.19s]
prediction: ['[CLS] aaron bought these flowers for he • [SEP]']
[ 900/2000] tot_loss=1.941 (perp=9.311, rec=0.075, cos=0.004), tot_loss_proj:3.796 [t=0.19s]
prediction: ['[CLS] aaron bought these flowers for he • [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.943 (perp=9.311, rec=0.077, cos=0.004), tot_loss_proj:3.796 [t=0.19s]
prediction: ['[CLS] aaron bought these flowers for he • [SEP]']
Attempt swap
[1000/2000] tot_loss=1.628 (perp=7.725, rec=0.079, cos=0.004), tot_loss_proj:3.427 [t=0.19s]
prediction: ['[CLS] aaron bought these flowers for he. [SEP]']
[1050/2000] tot_loss=1.941 (perp=9.311, rec=0.075, cos=0.004), tot_loss_proj:3.801 [t=0.19s]
prediction: ['[CLS] aaron bought these flowers for he • [SEP]']
Attempt swap
[1100/2000] tot_loss=1.628 (perp=7.725, rec=0.079, cos=0.004), tot_loss_proj:3.432 [t=0.17s]
prediction: ['[CLS] aaron bought these flowers for he. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.620 (perp=7.725, rec=0.071, cos=0.004), tot_loss_proj:3.431 [t=0.17s]
prediction: ['[CLS] aaron bought these flowers for he. [SEP]']
[1200/2000] tot_loss=1.623 (perp=7.725, rec=0.074, cos=0.004), tot_loss_proj:3.434 [t=0.17s]
prediction: ['[CLS] aaron bought these flowers for he. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.623 (perp=7.725, rec=0.075, cos=0.004), tot_loss_proj:3.434 [t=0.17s]
prediction: ['[CLS] aaron bought these flowers for he. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.908 (perp=9.033, rec=0.095, cos=0.006), tot_loss_proj:2.473 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron • [SEP]']
[1350/2000] tot_loss=1.890 (perp=9.033, rec=0.079, cos=0.004), tot_loss_proj:2.471 [t=0.17s]
prediction: ['[CLS] he bought these flowers for aaron • [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.806 (perp=8.574, rec=0.087, cos=0.004), tot_loss_proj:3.750 [t=0.17s]
prediction: ['[CLS] he • bought these flowers for aaron [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.763 (perp=8.367, rec=0.085, cos=0.005), tot_loss_proj:2.831 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
[1500/2000] tot_loss=1.771 (perp=8.367, rec=0.093, cos=0.005), tot_loss_proj:2.836 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
Attempt swap
[1550/2000] tot_loss=1.754 (perp=8.367, rec=0.077, cos=0.004), tot_loss_proj:2.822 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
Attempt swap
[1600/2000] tot_loss=1.760 (perp=8.367, rec=0.082, cos=0.004), tot_loss_proj:2.831 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
[1650/2000] tot_loss=1.756 (perp=8.367, rec=0.078, cos=0.004), tot_loss_proj:2.828 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
Attempt swap
[1700/2000] tot_loss=1.764 (perp=8.367, rec=0.087, cos=0.004), tot_loss_proj:2.830 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
Attempt swap
[1750/2000] tot_loss=1.767 (perp=8.367, rec=0.089, cos=0.004), tot_loss_proj:2.830 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
[1800/2000] tot_loss=1.763 (perp=8.367, rec=0.085, cos=0.004), tot_loss_proj:2.830 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
Attempt swap
[1850/2000] tot_loss=1.762 (perp=8.367, rec=0.085, cos=0.004), tot_loss_proj:2.832 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
Attempt swap
[1900/2000] tot_loss=1.760 (perp=8.367, rec=0.083, cos=0.004), tot_loss_proj:2.826 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
[1950/2000] tot_loss=1.757 (perp=8.367, rec=0.080, cos=0.004), tot_loss_proj:2.830 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.367, rec=0.082, cos=0.004), tot_loss_proj:2.828 [t=0.17s]
prediction: ['[CLS] • he bought these flowers for aaron [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] he bought these flowers for aaron. [SEP]
========================
predicted: 
========================
[CLS] aaron bought these flowers for he. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 142.857

[Aggregate metrics]:
rouge1     | fm: 82.715 | p: 81.844 | r: 83.877
rouge2     | fm: 41.115 | p: 40.681 | r: 41.711
rougeL     | fm: 70.252 | p: 69.599 | r: 71.085
rougeLsum  | fm: 70.213 | p: 69.556 | r: 71.122
r1fm+r2fm = 123.830

input #88 time: 0:07:05 | total time: 11:51:35


Running input #89 of 100.
reference: 
========================
Handsome though they told me that Tom is, I still won't date him.
========================
average of cosine similarity 0.9993499747712495
highest_index [0]
highest [0.9993499747712495]
Debug: ids_shape = 19, pads = [19]
Debug: input ids = tensor([[ 101, 8502, 2295, 2027, 2409, 2033, 2008, 3419, 2003, 1010, 1045, 2145,
         2180, 1005, 1056, 3058, 2032, 1012,  102]], device='cuda:0')
Debug: ref = ["[CLS] handsome though they told me that tom is, i still won't date him. [SEP]"]
[Init] best rec loss: 1.7645385265350342 for ['[CLS] save jersey myanmar walkedfkthic ˢ wife dealing tomorrow lola e bit ll show ˈ competitions [SEP]']
[Init] best rec loss: 1.7267464399337769 for ['[CLS] victim deficit will carrier glass participate fledopers green jin grim hasving littlelineplinbered [SEP]']
[Init] best rec loss: 1.6976786851882935 for ['[CLS] airports in generic root administrative capitol wisconsin blind municipality remainder prasad squirrelswise antioch programricted palmer [SEP]']
[Init] best rec loss: 1.6974705457687378 for ['[CLS] savannah circularcap adding faster ina mater ⟨weight ka teams things corporationgo mer constitution fox [SEP]']
[Init] best rec loss: 1.6904346942901611 for ['[CLS] cultural toll effective olive sci coordinates occurring celia antony above poundertinzing radio aquatics us nrhp [SEP]']
[Init] best rec loss: 1.6681127548217773 for ['[CLS]enedyn discovery knee ne pun described candles technologies juliet intersect dj apollo flowers flute penn incomplete [SEP]']
[Init] best rec loss: 1.550883412361145 for ["[CLS] sandractive hopeless get cambridge oppositionnch | centre'oddissa hellivndo minor offensive [SEP]"]
[Init] best rec loss: 1.5115399360656738 for ['[CLS] title wrists sami primary olympic vance da orthodox gmina reunionmindford z centereerssian seeing [SEP]']
[Init] best rec loss: 1.4009183645248413 for ['[CLS] hopes devicesrued iv governor swap that saskatchewan pup under ultimate section drugged voivodeship should morning 500 [SEP]']
[Init] best rec loss: 1.4000285863876343 for ['[CLS] avid tunnel canopy intimacy brussels crystals childrney inter lower maceosing bust likely eds second rounded [SEP]']
[Init] best perm rec loss: 1.3923972845077515 for ['[CLS] mace avid canopy brussels tunnel intimacy secondosing rounded inter likely bust eds crystalsrney child lower [SEP]']
[Init] best perm rec loss: 1.391045331954956 for ['[CLS] likely brussels avid mace child second roundedosingrney lower crystals canopy bust inter intimacy eds tunnel [SEP]']
[Init] best perm rec loss: 1.3883261680603027 for ['[CLS] avid eds mace crystals likely canopyosing second intimacy interrney child lower bust brussels rounded tunnel [SEP]']
[Init] best perm rec loss: 1.3861048221588135 for ['[CLS] second rounded mace bust tunnel crystalsosing intimacy canopy inter lower child avidrney brussels likely eds [SEP]']
[Init] best perm rec loss: 1.3845624923706055 for ['[CLS] rounded likely mace second eds intimacy canopy lower childosing avidrney tunnel brussels bust inter crystals [SEP]']
[Init] best perm rec loss: 1.3840968608856201 for ['[CLS] crystals inter avid mace lower eds second likely bustosing brusselsrney child intimacy canopy rounded tunnel [SEP]']
[Init] best perm rec loss: 1.3840606212615967 for ['[CLS] canopyrney child tunnel eds likelyosing intimacy avid bust lower rounded crystals brussels second inter mace [SEP]']
[Init] best perm rec loss: 1.3837217092514038 for ['[CLS] eds brussels rounded likely tunnel avid canopyosing crystalsrney child bust intimacy inter second lower mace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.390 (perp=9.471, rec=0.398, cos=0.098), tot_loss_proj:3.483 [t=0.17s]
prediction: ['[CLS] handsome hearted 3, widow though this of mps this especially is tom or william bread. [SEP]']
[ 100/2000] tot_loss=2.586 (perp=9.216, rec=0.540, cos=0.204), tot_loss_proj:3.570 [t=0.17s]
prediction: ['[CLS] handsome caused tom, tex though obviously., why obviously is tom across though sox. [SEP]']
[ 150/2000] tot_loss=2.465 (perp=10.158, rec=0.342, cos=0.091), tot_loss_proj:4.002 [t=0.17s]
prediction: ['[CLS] handsome would little very ke though obviously of f filling obviously is he greasy though he. [SEP]']
[ 200/2000] tot_loss=2.175 (perp=8.727, rec=0.289, cos=0.140), tot_loss_proj:3.613 [t=0.17s]
prediction: ['[CLS] handsome though little that ke though obviously of f, tom is tom greasy though he. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.325 (perp=9.357, rec=0.364, cos=0.090), tot_loss_proj:3.420 [t=0.17s]
prediction: ['[CLS] told handsome though little that though obviously, 20 nick obviously is tom handsome though i went [SEP]']
[ 300/2000] tot_loss=2.242 (perp=9.786, rec=0.231, cos=0.054), tot_loss_proj:3.702 [t=0.17s]
prediction: ['[CLS] told handsome though rock that though that,? tom already is tom handsome though i. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.817 (perp=7.941, rec=0.189, cos=0.039), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] that handsome though big told though that,? tom already is tom handsome though i. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.751 (perp=7.514, rec=0.166, cos=0.082), tot_loss_proj:3.270 [t=0.17s]
prediction: ['[CLS] that handsome though little told still that,? tom tom is already handsome though i. [SEP]']
[ 450/2000] tot_loss=1.670 (perp=7.428, rec=0.159, cos=0.025), tot_loss_proj:3.224 [t=0.17s]
prediction: ['[CLS] that handsome though little told still that,?, tom is already handsome though i. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.626 (perp=7.349, rec=0.138, cos=0.019), tot_loss_proj:3.219 [t=0.17s]
prediction: ['[CLS] that handsome though date told? that, still, tom is already handsome though i. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.551 (perp=6.993, rec=0.134, cos=0.018), tot_loss_proj:2.966 [t=0.17s]
prediction: ['[CLS] that handsome though? told date that, still, tom is already handsome though i. [SEP]']
[ 600/2000] tot_loss=1.570 (perp=7.121, rec=0.129, cos=0.017), tot_loss_proj:3.210 [t=0.17s]
prediction: ['[CLS] that handsome though? told date that, still, tom is him handsome though i. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.565 (perp=7.121, rec=0.126, cos=0.015), tot_loss_proj:3.210 [t=0.17s]
prediction: ['[CLS] that handsome though? told date that, still, tom is him handsome though i. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.695 (perp=7.823, rec=0.118, cos=0.012), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] that handsome though? told date that, still they tom is him they though i. [SEP]']
[ 750/2000] tot_loss=1.694 (perp=7.823, rec=0.118, cos=0.011), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] that handsome though? told date that, still they tom is him they though i. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.797 (perp=8.356, rec=0.116, cos=0.011), tot_loss_proj:3.526 [t=0.17s]
prediction: ['[CLS] that handsome though date told date that, still they tom is him they though i. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.794 (perp=8.356, rec=0.113, cos=0.010), tot_loss_proj:3.528 [t=0.17s]
prediction: ['[CLS] that handsome though date told date that, still they tom is him they though i. [SEP]']
[ 900/2000] tot_loss=1.785 (perp=8.356, rec=0.105, cos=0.009), tot_loss_proj:3.531 [t=0.17s]
prediction: ['[CLS] that handsome though date told date that, still they tom is him they though i. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.734 (perp=8.060, rec=0.113, cos=0.009), tot_loss_proj:3.511 [t=0.17s]
prediction: ['[CLS] that handsome though told date that date, still they tom is him they though i. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.693 (perp=7.868, rec=0.110, cos=0.010), tot_loss_proj:3.456 [t=0.17s]
prediction: ['[CLS] that handsome though told date that date, they still tom is him they though i. [SEP]']
[1050/2000] tot_loss=1.685 (perp=7.868, rec=0.103, cos=0.009), tot_loss_proj:3.454 [t=0.17s]
prediction: ['[CLS] that handsome though told date that date, they still tom is him they though i. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.646 (perp=7.634, rec=0.110, cos=0.010), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS] that handsome though told date that tom, they still date is him they though i. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.649 (perp=7.634, rec=0.113, cos=0.009), tot_loss_proj:3.427 [t=0.17s]
prediction: ['[CLS] that handsome though told date that tom, they still date is him they though i. [SEP]']
[1200/2000] tot_loss=1.633 (perp=7.634, rec=0.098, cos=0.008), tot_loss_proj:3.430 [t=0.17s]
prediction: ['[CLS] that handsome though told date that tom, they still date is him they though i. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.620 (perp=7.634, rec=0.085, cos=0.008), tot_loss_proj:3.431 [t=0.17s]
prediction: ['[CLS] that handsome though told date that tom, they still date is him they though i. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.635 (perp=7.634, rec=0.101, cos=0.008), tot_loss_proj:3.435 [t=0.17s]
prediction: ['[CLS] that handsome though told date that tom, they still date is him they though i. [SEP]']
[1350/2000] tot_loss=1.637 (perp=7.634, rec=0.102, cos=0.008), tot_loss_proj:3.432 [t=0.17s]
prediction: ['[CLS] that handsome though told date that tom, they still date is him they though i. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.629 (perp=7.624, rec=0.097, cos=0.008), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS] that handsome though told date that tom, they still date is him we though i. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.602 (perp=7.449, rec=0.104, cos=0.008), tot_loss_proj:3.341 [t=0.17s]
prediction: ['[CLS] that handsome though told date that tom, they still date is him i though i. [SEP]']
[1500/2000] tot_loss=1.593 (perp=7.449, rec=0.095, cos=0.008), tot_loss_proj:3.337 [t=0.17s]
prediction: ['[CLS] that handsome though told date that tom, they still date is him i though i. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.597 (perp=7.449, rec=0.100, cos=0.008), tot_loss_proj:3.338 [t=0.19s]
prediction: ['[CLS] that handsome though told date that tom, they still date is him i though i. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.534 (perp=7.060, rec=0.109, cos=0.013), tot_loss_proj:3.105 [t=0.17s]
prediction: ['[CLS] that handsome though told him that tom, they still date is date i though i. [SEP]']
[1650/2000] tot_loss=1.687 (perp=7.919, rec=0.095, cos=0.008), tot_loss_proj:3.442 [t=0.17s]
prediction: ['[CLS] still handsome though told him that tom, they still date is date i though i. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.620 (perp=7.561, rec=0.098, cos=0.009), tot_loss_proj:3.341 [t=0.17s]
prediction: ['[CLS] still handsome though told him that tom, they still date is though i date i. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.620 (perp=7.561, rec=0.099, cos=0.008), tot_loss_proj:3.345 [t=0.17s]
prediction: ['[CLS] still handsome though told him that tom, they still date is though i date i. [SEP]']
[1800/2000] tot_loss=1.620 (perp=7.561, rec=0.099, cos=0.008), tot_loss_proj:3.344 [t=0.17s]
prediction: ['[CLS] still handsome though told him that tom, they still date is though i date i. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.608 (perp=7.561, rec=0.087, cos=0.008), tot_loss_proj:3.335 [t=0.17s]
prediction: ['[CLS] still handsome though told him that tom, they still date is though i date i. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.624 (perp=7.561, rec=0.103, cos=0.008), tot_loss_proj:3.343 [t=0.17s]
prediction: ['[CLS] still handsome though told him that tom, they still date is though i date i. [SEP]']
[1950/2000] tot_loss=1.622 (perp=7.561, rec=0.102, cos=0.008), tot_loss_proj:3.345 [t=0.17s]
prediction: ['[CLS] still handsome though told him that tom, they still date is though i date i. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.556 (perp=7.263, rec=0.096, cos=0.008), tot_loss_proj:3.011 [t=0.17s]
prediction: ['[CLS] though handsome still told him that tom, they still date is though i date i. [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] handsome though they told me that tom is, i still won't date him. [SEP]
========================
predicted: 
========================
[CLS] that handsome though told date that tom, they still date is him i though i. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.788 | p: 76.471 | r: 81.250
rouge2     | fm: 12.903 | p: 12.500 | r: 13.333
rougeL     | fm: 60.606 | p: 58.824 | r: 62.500
rougeLsum  | fm: 60.606 | p: 58.824 | r: 62.500
r1fm+r2fm = 91.691

[Aggregate metrics]:
rouge1     | fm: 82.711 | p: 81.802 | r: 83.898
rouge2     | fm: 40.990 | p: 40.534 | r: 41.601
rougeL     | fm: 70.101 | p: 69.436 | r: 70.948
rougeLsum  | fm: 70.040 | p: 69.444 | r: 71.003
r1fm+r2fm = 123.702

input #89 time: 0:06:54 | total time: 11:58:30


Running input #90 of 100.
reference: 
========================
Moya's football team loved her
========================
average of cosine similarity 0.9993060410574175
highest_index [0]
highest [0.9993060410574175]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[ 101, 9587, 3148, 1005, 1055, 2374, 2136, 3866, 2014,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] moya's football team loved her [SEP]"]
[Init] best rec loss: 1.8151686191558838 for ['[CLS]rra person gasp shit rex become snow dunn [SEP]']
[Init] best rec loss: 1.797290563583374 for ['[CLS] company slightly describe eager izzy poetryneyox [SEP]']
[Init] best rec loss: 1.7044082880020142 for ['[CLS] roman oclc consultantjust countrieslic relief kam [SEP]']
[Init] best rec loss: 1.6683741807937622 for ['[CLS] quite [SEP]ttle producerersberries timedron [SEP]']
[Init] best rec loss: 1.5949440002441406 for ['[CLS] morgan creaked li debtlun fixed garcia sc [SEP]']
[Init] best rec loss: 1.5417226552963257 for ['[CLS] threshold big semiticatt pilot characterized nepal daughters [SEP]']
[Init] best perm rec loss: 1.5415534973144531 for ['[CLS] big threshold semitic pilot daughtersatt characterized nepal [SEP]']
[Init] best perm rec loss: 1.53763747215271 for ['[CLS] characterized nepal pilot daughters semiticatt big threshold [SEP]']
[Init] best perm rec loss: 1.535007119178772 for ['[CLS] semitic big daughters characterized nepalatt threshold pilot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.508 (perp=12.693, rec=0.553, cos=0.417), tot_loss_proj:4.337 [t=0.17s]
prediction: ['[CLS] freestyle word body houston guitar tooth christmas boom [SEP]']
[ 100/2000] tot_loss=2.720 (perp=11.392, rec=0.374, cos=0.068), tot_loss_proj:4.145 [t=0.17s]
prediction: ['[CLS] genet call twins footballred < loved [SEP]']
[ 150/2000] tot_loss=2.567 (perp=11.053, rec=0.319, cos=0.037), tot_loss_proj:4.071 [t=0.17s]
prediction: ['[CLS] mot scent twins football loved hours loved [SEP]']
[ 200/2000] tot_loss=2.600 (perp=11.547, rec=0.265, cos=0.025), tot_loss_proj:4.157 [t=0.17s]
prediction: ['[CLS] moya wifeendra football loved wonderful her [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.567 (perp=11.157, rec=0.302, cos=0.034), tot_loss_proj:4.158 [t=0.17s]
prediction: ['[CLS] moyaya differently football loved university her [SEP]']
[ 300/2000] tot_loss=2.416 (perp=10.628, rec=0.261, cos=0.029), tot_loss_proj:4.040 [t=0.17s]
prediction: ['[CLS] moyayaya football loved baseball her [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.087 (perp=9.309, rec=0.213, cos=0.012), tot_loss_proj:3.747 [t=0.17s]
prediction: ['[CLS] moyaya baseballya team loved her [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.381 (perp=10.354, rec=0.273, cos=0.037), tot_loss_proj:3.977 [t=0.17s]
prediction: ['[CLS]ya moyaya football football loved her [SEP]']
[ 450/2000] tot_loss=2.274 (perp=10.354, rec=0.192, cos=0.011), tot_loss_proj:3.966 [t=0.17s]
prediction: ['[CLS]ya moyaya football football loved her [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.800 (perp=8.124, rec=0.168, cos=0.007), tot_loss_proj:3.461 [t=0.17s]
prediction: ["[CLS] moya moya'football loved her [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.993 (perp=9.262, rec=0.135, cos=0.006), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] moya moya s football loved her [SEP]']
[ 600/2000] tot_loss=1.709 (perp=7.927, rec=0.118, cos=0.005), tot_loss_proj:3.230 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.710 (perp=7.927, rec=0.116, cos=0.009), tot_loss_proj:3.235 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.689 (perp=7.927, rec=0.099, cos=0.004), tot_loss_proj:3.228 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
[ 750/2000] tot_loss=1.684 (perp=7.927, rec=0.094, cos=0.004), tot_loss_proj:3.228 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.679 (perp=7.927, rec=0.090, cos=0.004), tot_loss_proj:3.226 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.684 (perp=7.927, rec=0.095, cos=0.004), tot_loss_proj:3.230 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
[ 900/2000] tot_loss=1.681 (perp=7.927, rec=0.092, cos=0.003), tot_loss_proj:3.233 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.680 (perp=7.927, rec=0.091, cos=0.003), tot_loss_proj:3.236 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1000/2000] tot_loss=1.679 (perp=7.927, rec=0.090, cos=0.003), tot_loss_proj:3.232 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
[1050/2000] tot_loss=1.676 (perp=7.927, rec=0.087, cos=0.003), tot_loss_proj:3.237 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1100/2000] tot_loss=1.681 (perp=7.927, rec=0.092, cos=0.003), tot_loss_proj:3.233 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1150/2000] tot_loss=1.672 (perp=7.927, rec=0.084, cos=0.003), tot_loss_proj:3.238 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
[1200/2000] tot_loss=1.680 (perp=7.927, rec=0.091, cos=0.003), tot_loss_proj:3.236 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1250/2000] tot_loss=1.684 (perp=7.927, rec=0.096, cos=0.003), tot_loss_proj:3.235 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1300/2000] tot_loss=1.675 (perp=7.927, rec=0.086, cos=0.003), tot_loss_proj:3.235 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
[1350/2000] tot_loss=1.677 (perp=7.927, rec=0.088, cos=0.003), tot_loss_proj:3.235 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1400/2000] tot_loss=1.667 (perp=7.927, rec=0.078, cos=0.003), tot_loss_proj:3.248 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1450/2000] tot_loss=1.678 (perp=7.927, rec=0.090, cos=0.003), tot_loss_proj:3.236 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
[1500/2000] tot_loss=1.670 (perp=7.927, rec=0.082, cos=0.003), tot_loss_proj:3.243 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1550/2000] tot_loss=1.672 (perp=7.927, rec=0.083, cos=0.003), tot_loss_proj:3.245 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1600/2000] tot_loss=1.673 (perp=7.927, rec=0.084, cos=0.003), tot_loss_proj:3.245 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
[1650/2000] tot_loss=1.670 (perp=7.927, rec=0.081, cos=0.003), tot_loss_proj:3.248 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1700/2000] tot_loss=1.671 (perp=7.927, rec=0.082, cos=0.003), tot_loss_proj:3.248 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1750/2000] tot_loss=1.672 (perp=7.927, rec=0.084, cos=0.003), tot_loss_proj:3.239 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
[1800/2000] tot_loss=1.672 (perp=7.927, rec=0.083, cos=0.003), tot_loss_proj:3.244 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1850/2000] tot_loss=1.663 (perp=7.927, rec=0.074, cos=0.003), tot_loss_proj:3.239 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[1900/2000] tot_loss=1.676 (perp=7.927, rec=0.088, cos=0.003), tot_loss_proj:3.236 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
[1950/2000] tot_loss=1.675 (perp=7.927, rec=0.086, cos=0.003), tot_loss_proj:3.243 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Attempt swap
[2000/2000] tot_loss=1.671 (perp=7.927, rec=0.083, cos=0.003), tot_loss_proj:3.241 [t=0.17s]
prediction: ['[CLS] moya moya s team loved her [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] moya's football team loved her [SEP]
========================
predicted: 
========================
[CLS] moya moya s team loved her [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 71.429 | p: 71.429 | r: 71.429
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 158.929

[Aggregate metrics]:
rouge1     | fm: 82.800 | p: 81.924 | r: 83.973
rouge2     | fm: 41.243 | p: 40.835 | r: 41.715
rougeL     | fm: 70.249 | p: 69.641 | r: 71.162
rougeLsum  | fm: 70.354 | p: 69.691 | r: 71.251
r1fm+r2fm = 124.043

input #90 time: 0:06:48 | total time: 12:05:18


Running input #91 of 100.
reference: 
========================
They investigated the problem.
========================
average of cosine similarity 0.9994048200497065
highest_index [0]
highest [0.9994048200497065]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2027, 10847,  1996,  3291,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] they investigated the problem. [SEP]']
[Init] best rec loss: 1.9986168146133423 for ['[CLS] non trap brackets opposite mbe [SEP]']
[Init] best rec loss: 1.9207534790039062 for ['[CLS] nope rare chief steveyon [SEP]']
[Init] best rec loss: 1.9067156314849854 for ['[CLS] dave premiocross. kilograms [SEP]']
[Init] best rec loss: 1.860822081565857 for ['[CLS] ale stay national off princess [SEP]']
[Init] best rec loss: 1.8529037237167358 for ['[CLS]uk greek age hands debris [SEP]']
[Init] best rec loss: 1.8050317764282227 for ['[CLS]brush charts steven to reservations [SEP]']
[Init] best rec loss: 1.7110785245895386 for ['[CLS]w czech real mrference [SEP]']
[Init] best perm rec loss: 1.7052041292190552 for ['[CLS]wference czech real mr [SEP]']
[Init] best perm rec loss: 1.6961934566497803 for ['[CLS] mrw czech realference [SEP]']
[Init] best perm rec loss: 1.6923887729644775 for ['[CLS] real mr czechferencew [SEP]']
[Init] best perm rec loss: 1.6909065246582031 for ['[CLS] mr czechferencew real [SEP]']
[Init] best perm rec loss: 1.6858993768692017 for ['[CLS] mrference czechw real [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.049 (perp=11.801, rec=0.689, cos=1.000), tot_loss_proj:4.314 [t=0.18s]
prediction: ['[CLS]rc record ; ) committed [SEP]']
[ 100/2000] tot_loss=3.653 (perp=10.063, rec=0.656, cos=0.984), tot_loss_proj:3.783 [t=0.19s]
prediction: ['[CLS] per examination. holds deemed [SEP]']
[ 150/2000] tot_loss=3.100 (perp=7.844, rec=0.542, cos=0.989), tot_loss_proj:3.489 [t=0.19s]
prediction: ['[CLS] the problem. holds investigated [SEP]']
[ 200/2000] tot_loss=3.220 (perp=8.828, rec=0.485, cos=0.970), tot_loss_proj:3.648 [t=0.19s]
prediction: ['[CLS] the problem they holds investigated [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.253 (perp=9.158, rec=0.456, cos=0.965), tot_loss_proj:3.754 [t=0.19s]
prediction: ['[CLS] the problem theyggles investigated [SEP]']
[ 300/2000] tot_loss=3.559 (perp=9.831, rec=0.602, cos=0.991), tot_loss_proj:3.751 [t=0.19s]
prediction: ['[CLS] the problem results offs investigated [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.061 (perp=7.894, rec=0.505, cos=0.976), tot_loss_proj:3.476 [t=0.19s]
prediction: ['[CLS] the problem results. investigated [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.446 (perp=9.414, rec=0.568, cos=0.996), tot_loss_proj:3.861 [t=0.19s]
prediction: ['[CLS] the problem. congratulations investigated [SEP]']
[ 450/2000] tot_loss=3.090 (perp=8.188, rec=0.481, cos=0.971), tot_loss_proj:3.484 [t=0.19s]
prediction: ['[CLS] their problem. results investigated [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.061 (perp=8.188, rec=0.460, cos=0.963), tot_loss_proj:3.483 [t=0.19s]
prediction: ['[CLS] their problem. results investigated [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.031 (perp=8.188, rec=0.439, cos=0.954), tot_loss_proj:3.480 [t=0.19s]
prediction: ['[CLS] their problem. results investigated [SEP]']
[ 600/2000] tot_loss=3.076 (perp=8.565, rec=0.421, cos=0.942), tot_loss_proj:3.478 [t=0.19s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.056 (perp=8.565, rec=0.409, cos=0.934), tot_loss_proj:3.483 [t=0.19s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.045 (perp=8.565, rec=0.401, cos=0.931), tot_loss_proj:3.483 [t=0.19s]
prediction: ['[CLS] they problem. results investigated [SEP]']
[ 750/2000] tot_loss=3.041 (perp=8.565, rec=0.402, cos=0.926), tot_loss_proj:3.475 [t=0.19s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.019 (perp=8.565, rec=0.394, cos=0.912), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.010 (perp=8.565, rec=0.391, cos=0.906), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
[ 900/2000] tot_loss=3.008 (perp=8.565, rec=0.399, cos=0.897), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.075 (perp=8.491, rec=0.448, cos=0.929), tot_loss_proj:3.441 [t=0.17s]
prediction: ['[CLS] these problem. results investigated [SEP]']
Attempt swap
[1000/2000] tot_loss=2.999 (perp=8.491, rec=0.403, cos=0.897), tot_loss_proj:3.439 [t=0.17s]
prediction: ['[CLS] these problem. results investigated [SEP]']
[1050/2000] tot_loss=2.996 (perp=8.565, rec=0.399, cos=0.884), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1100/2000] tot_loss=2.974 (perp=8.565, rec=0.387, cos=0.874), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1150/2000] tot_loss=2.986 (perp=8.565, rec=0.394, cos=0.879), tot_loss_proj:3.473 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
[1200/2000] tot_loss=2.938 (perp=8.565, rec=0.383, cos=0.842), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1250/2000] tot_loss=2.921 (perp=8.565, rec=0.376, cos=0.832), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1300/2000] tot_loss=2.906 (perp=8.565, rec=0.373, cos=0.819), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
[1350/2000] tot_loss=2.893 (perp=8.565, rec=0.376, cos=0.804), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1400/2000] tot_loss=2.871 (perp=8.565, rec=0.375, cos=0.782), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1450/2000] tot_loss=2.830 (perp=8.565, rec=0.372, cos=0.744), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
[1500/2000] tot_loss=2.734 (perp=8.565, rec=0.369, cos=0.652), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1550/2000] tot_loss=2.399 (perp=8.565, rec=0.350, cos=0.335), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1600/2000] tot_loss=2.056 (perp=8.565, rec=0.257, cos=0.086), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
[1650/2000] tot_loss=1.970 (perp=8.565, rec=0.210, cos=0.047), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1700/2000] tot_loss=1.930 (perp=8.565, rec=0.183, cos=0.034), tot_loss_proj:3.475 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1750/2000] tot_loss=1.914 (perp=8.565, rec=0.173, cos=0.028), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
[1800/2000] tot_loss=1.914 (perp=8.565, rec=0.175, cos=0.025), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1850/2000] tot_loss=1.908 (perp=8.565, rec=0.171, cos=0.024), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[1900/2000] tot_loss=1.915 (perp=8.565, rec=0.180, cos=0.022), tot_loss_proj:3.470 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
[1950/2000] tot_loss=1.895 (perp=8.565, rec=0.160, cos=0.021), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Attempt swap
[2000/2000] tot_loss=1.899 (perp=8.565, rec=0.165, cos=0.021), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] they problem. results investigated [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] they investigated the problem. [SEP]
========================
predicted: 
========================
[CLS] they problem. results investigated [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 103.333

[Aggregate metrics]:
rouge1     | fm: 82.747 | p: 81.857 | r: 83.905
rouge2     | fm: 41.012 | p: 40.631 | r: 41.576
rougeL     | fm: 70.222 | p: 69.587 | r: 71.120
rougeLsum  | fm: 70.263 | p: 69.680 | r: 71.147
r1fm+r2fm = 123.759

input #91 time: 0:07:02 | total time: 12:12:20


Running input #92 of 100.
reference: 
========================
Andy promised that we would go.
========================
average of cosine similarity 0.99925545607284
highest_index [0]
highest [0.99925545607284]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 5557, 5763, 2008, 2057, 2052, 2175, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] andy promised that we would go. [SEP]']
[Init] best rec loss: 2.0157506465911865 for ['[CLS] church shade features forwardlateral one ⟨ [SEP]']
[Init] best rec loss: 1.7693511247634888 for ['[CLS] parental expected chase years fighting ego in [SEP]']
[Init] best rec loss: 1.7607189416885376 for ['[CLS] these claire disorder ready dakota sap let [SEP]']
[Init] best rec loss: 1.7542598247528076 for ['[CLS]rdial aurora triple absolutely rumors count native [SEP]']
[Init] best rec loss: 1.75125253200531 for ['[CLS] scroll every rwanda everykers lgbt operative [SEP]']
[Init] best rec loss: 1.7347298860549927 for ['[CLS] temple peabody northern sara motions much eye [SEP]']
[Init] best perm rec loss: 1.7310349941253662 for ['[CLS] motions sara northern peabody temple much eye [SEP]']
[Init] best perm rec loss: 1.7297494411468506 for ['[CLS] peabody motions much northern eye temple sara [SEP]']
[Init] best perm rec loss: 1.7293593883514404 for ['[CLS] peabody eye motions much sara northern temple [SEP]']
[Init] best perm rec loss: 1.7285301685333252 for ['[CLS] eye motions peabody northern sara much temple [SEP]']
[Init] best perm rec loss: 1.728170394897461 for ['[CLS] motions temple eye much peabody northern sara [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.319 (perp=13.686, rec=0.583, cos=0.998), tot_loss_proj:4.579 [t=0.17s]
prediction: ['[CLS] uss that poker promised tea psi sip [SEP]']
[ 100/2000] tot_loss=4.217 (perp=13.668, rec=0.505, cos=0.979), tot_loss_proj:4.624 [t=0.17s]
prediction: ['[CLS] andy promisedpeed promised andy andy na [SEP]']
[ 150/2000] tot_loss=3.916 (perp=11.752, rec=0.578, cos=0.988), tot_loss_proj:4.141 [t=0.17s]
prediction: ['[CLS] [SEP] promised absolutely promised andy andy essence [SEP]']
[ 200/2000] tot_loss=3.980 (perp=12.583, rec=0.495, cos=0.968), tot_loss_proj:4.355 [t=0.17s]
prediction: ['[CLS] [SEP] promisedkyu promised andy andy nedra [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=4.007 (perp=12.775, rec=0.482, cos=0.969), tot_loss_proj:4.605 [t=0.17s]
prediction: ['[CLS] [SEP] promised freddy promised andy ª ⁱ [SEP]']
[ 300/2000] tot_loss=4.018 (perp=12.987, rec=0.455, cos=0.966), tot_loss_proj:4.667 [t=0.17s]
prediction: ['[CLS]. promised freddy promised andy ª infantry [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.973 (perp=7.885, rec=0.433, cos=0.963), tot_loss_proj:3.552 [t=0.17s]
prediction: ['[CLS] we promised andy promised andy andy. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.869 (perp=7.381, rec=0.427, cos=0.966), tot_loss_proj:2.875 [t=0.17s]
prediction: ['[CLS] we promised andy andy promised andy. [SEP]']
[ 450/2000] tot_loss=2.834 (perp=7.381, rec=0.413, cos=0.945), tot_loss_proj:2.881 [t=0.17s]
prediction: ['[CLS] we promised andy andy promised andy. [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.122 (perp=9.058, rec=0.401, cos=0.910), tot_loss_proj:3.903 [t=0.17s]
prediction: ['[CLS] we promised ， andy promised andy. [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.773 (perp=7.381, rec=0.395, cos=0.903), tot_loss_proj:2.900 [t=0.17s]
prediction: ['[CLS] we promised andy andy promised andy. [SEP]']
[ 600/2000] tot_loss=2.753 (perp=7.381, rec=0.389, cos=0.888), tot_loss_proj:2.896 [t=0.17s]
prediction: ['[CLS] we promised andy andy promised andy. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.736 (perp=7.381, rec=0.388, cos=0.872), tot_loss_proj:2.897 [t=0.17s]
prediction: ['[CLS] we promised andy andy promised andy. [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.729 (perp=7.381, rec=0.383, cos=0.870), tot_loss_proj:2.903 [t=0.17s]
prediction: ['[CLS] we promised andy andy promised andy. [SEP]']
[ 750/2000] tot_loss=2.772 (perp=7.691, rec=0.385, cos=0.849), tot_loss_proj:3.343 [t=0.17s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.746 (perp=7.691, rec=0.367, cos=0.840), tot_loss_proj:3.344 [t=0.17s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.739 (perp=7.691, rec=0.372, cos=0.829), tot_loss_proj:3.349 [t=0.17s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
[ 900/2000] tot_loss=2.716 (perp=7.691, rec=0.364, cos=0.814), tot_loss_proj:3.338 [t=0.17s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.718 (perp=7.691, rec=0.372, cos=0.808), tot_loss_proj:3.338 [t=0.17s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
Attempt swap
[1000/2000] tot_loss=2.693 (perp=7.691, rec=0.370, cos=0.785), tot_loss_proj:3.342 [t=0.17s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
[1050/2000] tot_loss=2.655 (perp=7.691, rec=0.363, cos=0.754), tot_loss_proj:3.344 [t=0.17s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
Attempt swap
[1100/2000] tot_loss=2.614 (perp=7.691, rec=0.370, cos=0.705), tot_loss_proj:3.341 [t=0.17s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
Attempt swap
[1150/2000] tot_loss=2.766 (perp=7.691, rec=0.412, cos=0.816), tot_loss_proj:3.345 [t=0.17s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
[1200/2000] tot_loss=2.533 (perp=7.691, rec=0.360, cos=0.635), tot_loss_proj:3.341 [t=0.17s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.035 (perp=7.691, rec=0.342, cos=0.155), tot_loss_proj:3.343 [t=0.19s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.839 (perp=7.691, rec=0.247, cos=0.054), tot_loss_proj:3.343 [t=0.19s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
[1350/2000] tot_loss=1.795 (perp=7.691, rec=0.220, cos=0.037), tot_loss_proj:3.341 [t=0.19s]
prediction: ['[CLS] we would declare andy promised andy. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.968 (perp=8.656, rec=0.206, cos=0.031), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] we would esteem andy promised andy. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.964 (perp=8.656, rec=0.205, cos=0.028), tot_loss_proj:3.692 [t=0.17s]
prediction: ['[CLS] we would esteem andy promised andy. [SEP]']
[1500/2000] tot_loss=1.947 (perp=8.656, rec=0.190, cos=0.026), tot_loss_proj:3.695 [t=0.17s]
prediction: ['[CLS] we would esteem andy promised andy. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.950 (perp=8.656, rec=0.195, cos=0.024), tot_loss_proj:3.694 [t=0.17s]
prediction: ['[CLS] we would esteem andy promised andy. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.950 (perp=8.656, rec=0.196, cos=0.023), tot_loss_proj:3.693 [t=0.17s]
prediction: ['[CLS] we would esteem andy promised andy. [SEP]']
[1650/2000] tot_loss=1.956 (perp=8.656, rec=0.203, cos=0.022), tot_loss_proj:3.692 [t=0.17s]
prediction: ['[CLS] we would esteem andy promised andy. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.945 (perp=8.656, rec=0.193, cos=0.021), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] we would esteem andy promised andy. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.039 (perp=9.139, rec=0.191, cos=0.020), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] would would esteem andy promised andy. [SEP]']
[1800/2000] tot_loss=2.033 (perp=9.139, rec=0.186, cos=0.019), tot_loss_proj:3.677 [t=0.17s]
prediction: ['[CLS] would would esteem andy promised andy. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.037 (perp=9.139, rec=0.190, cos=0.019), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] would would esteem andy promised andy. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.032 (perp=9.139, rec=0.186, cos=0.018), tot_loss_proj:3.676 [t=0.17s]
prediction: ['[CLS] would would esteem andy promised andy. [SEP]']
[1950/2000] tot_loss=2.150 (perp=9.790, rec=0.175, cos=0.017), tot_loss_proj:3.808 [t=0.17s]
prediction: ['[CLS] would would esteem andy promised we. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.150 (perp=9.790, rec=0.175, cos=0.017), tot_loss_proj:3.807 [t=0.17s]
prediction: ['[CLS] would would esteem andy promised we. [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] andy promised that we would go. [SEP]
========================
predicted: 
========================
[CLS] would would esteem andy promised andy. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.500 | p: 62.500 | r: 62.500
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 76.786

[Aggregate metrics]:
rouge1     | fm: 82.575 | p: 81.720 | r: 83.681
rouge2     | fm: 40.700 | p: 40.297 | r: 41.190
rougeL     | fm: 69.961 | p: 69.353 | r: 70.859
rougeLsum  | fm: 70.094 | p: 69.429 | r: 70.992
r1fm+r2fm = 123.275

input #92 time: 0:06:52 | total time: 12:19:13


Running input #93 of 100.
reference: 
========================
I saw these dancers and those musicians smoking something.
========================
average of cosine similarity 0.999405837791129
highest_index [0]
highest [0.999405837791129]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1045,  2387,  2122, 10487,  1998,  2216,  5389,  9422,  2242,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] i saw these dancers and those musicians smoking something. [SEP]']
[Init] best rec loss: 1.875568151473999 for ['[CLS] choir torque titled uttar 25 tell even hitch encounter choosing [SEP]']
[Init] best rec loss: 1.8066014051437378 for ['[CLS] version ltd blur ringinghs chip astro bandrized federal [SEP]']
[Init] best rec loss: 1.7918766736984253 for ['[CLS] married formora wrong [CLS] enoughoft unanimouscturing spring [SEP]']
[Init] best rec loss: 1.758913278579712 for ['[CLS] possible any untilblock review making indian conflict wicket smithsonian [SEP]']
[Init] best rec loss: 1.7446130514144897 for ['[CLS] scorer equality playing t zack sooner end scoreders discipline [SEP]']
[Init] best rec loss: 1.7426820993423462 for ['[CLS] features wishes scale amber works {eerroving ni thumb [SEP]']
[Init] best perm rec loss: 1.7416843175888062 for ['[CLS] thumbeer amberroving wishes features scale ni { works [SEP]']
[Init] best perm rec loss: 1.7401669025421143 for ['[CLS] thumbroving nieer wishes features amber scale works { [SEP]']
[Init] best perm rec loss: 1.7359980344772339 for ['[CLS] ambereer scale features niroving works thumb wishes { [SEP]']
[Init] best perm rec loss: 1.735305666923523 for ['[CLS] features scale amberroving ni works { wishes thumbeer [SEP]']
[Init] best perm rec loss: 1.7342665195465088 for ['[CLS] scaleeerroving wishes features thumb amber works ni { [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.100 (perp=11.879, rec=0.538, cos=0.186), tot_loss_proj:4.093 [t=0.17s]
prediction: ['[CLS] became create she concerns thoroughbred through andal kinds exercises [SEP]']
[ 100/2000] tot_loss=2.135 (perp=8.659, rec=0.359, cos=0.044), tot_loss_proj:3.552 [t=0.17s]
prediction: ['[CLS] taking. those ideas ladder they and these these fighters [SEP]']
[ 150/2000] tot_loss=1.961 (perp=8.456, rec=0.250, cos=0.019), tot_loss_proj:3.438 [t=0.17s]
prediction: ['[CLS] these. those something wine sounded and these these musicians [SEP]']
[ 200/2000] tot_loss=1.940 (perp=8.584, rec=0.206, cos=0.018), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS] these. those something wine smoking and these those musicians [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.983 (perp=9.054, rec=0.161, cos=0.012), tot_loss_proj:3.614 [t=0.17s]
prediction: ['[CLS] saw i these something those smoking and smoking those musicians [SEP]']
[ 300/2000] tot_loss=1.922 (perp=9.054, rec=0.105, cos=0.006), tot_loss_proj:3.618 [t=0.17s]
prediction: ['[CLS] saw i these something those smoking and smoking those musicians [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.736 (perp=8.140, rec=0.102, cos=0.006), tot_loss_proj:3.426 [t=0.17s]
prediction: ['[CLS] i saw these something those smoking and smoking those musicians [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.769 (perp=8.333, rec=0.097, cos=0.006), tot_loss_proj:3.465 [t=0.17s]
prediction: ['[CLS] i saw these something and smoking those musicians those dancers [SEP]']
[ 450/2000] tot_loss=1.769 (perp=8.333, rec=0.097, cos=0.005), tot_loss_proj:3.463 [t=0.17s]
prediction: ['[CLS] i saw these something and smoking those musicians those dancers [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.720 (perp=7.933, rec=0.125, cos=0.009), tot_loss_proj:3.510 [t=0.17s]
prediction: ['[CLS] i saw these smoking something and those musicians those dancers [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.639 (perp=7.650, rec=0.103, cos=0.007), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS] i saw these smoking dancers and those musicians those something [SEP]']
[ 600/2000] tot_loss=1.631 (perp=7.650, rec=0.095, cos=0.006), tot_loss_proj:3.382 [t=0.17s]
prediction: ['[CLS] i saw these smoking dancers and those musicians those something [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.418 (perp=6.605, rec=0.091, cos=0.006), tot_loss_proj:1.768 [t=0.17s]
prediction: ['[CLS] i saw these those dancers and those musicians smoking something [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.411 (perp=6.605, rec=0.084, cos=0.006), tot_loss_proj:1.783 [t=0.17s]
prediction: ['[CLS] i saw these those dancers and those musicians smoking something [SEP]']
[ 750/2000] tot_loss=1.556 (perp=7.295, rec=0.092, cos=0.006), tot_loss_proj:3.092 [t=0.17s]
prediction: ['[CLS] i saw these those dancers and heard musicians smoking something [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.555 (perp=7.295, rec=0.091, cos=0.005), tot_loss_proj:3.101 [t=0.17s]
prediction: ['[CLS] i saw these those dancers and heard musicians smoking something [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.498 (perp=7.029, rec=0.085, cos=0.007), tot_loss_proj:3.234 [t=0.17s]
prediction: ['[CLS] i saw heard those dancers and these musicians smoking something [SEP]']
[ 900/2000] tot_loss=1.454 (perp=6.837, rec=0.081, cos=0.006), tot_loss_proj:3.318 [t=0.17s]
prediction: ['[CLS] i saw some those dancers and these musicians smoking something [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.546 (perp=7.295, rec=0.081, cos=0.005), tot_loss_proj:3.101 [t=0.17s]
prediction: ['[CLS] i saw these those dancers and heard musicians smoking something [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.443 (perp=6.682, rec=0.098, cos=0.008), tot_loss_proj:3.273 [t=0.17s]
prediction: ['[CLS] i saw those dancers and some these musicians smoking something [SEP]']
[1050/2000] tot_loss=1.423 (perp=6.682, rec=0.080, cos=0.006), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS] i saw those dancers and some these musicians smoking something [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.376 (perp=6.466, rec=0.077, cos=0.006), tot_loss_proj:3.325 [t=0.17s]
prediction: ['[CLS] i saw those these dancers and some musicians smoking something [SEP]']
Attempt swap
[1150/2000] tot_loss=1.369 (perp=6.466, rec=0.070, cos=0.006), tot_loss_proj:3.317 [t=0.17s]
prediction: ['[CLS] i saw those these dancers and some musicians smoking something [SEP]']
[1200/2000] tot_loss=1.384 (perp=6.466, rec=0.086, cos=0.005), tot_loss_proj:3.312 [t=0.17s]
prediction: ['[CLS] i saw those these dancers and some musicians smoking something [SEP]']
Attempt swap
[1250/2000] tot_loss=1.379 (perp=6.466, rec=0.081, cos=0.005), tot_loss_proj:3.309 [t=0.17s]
prediction: ['[CLS] i saw those these dancers and some musicians smoking something [SEP]']
Attempt swap
[1300/2000] tot_loss=1.380 (perp=6.466, rec=0.082, cos=0.005), tot_loss_proj:3.306 [t=0.17s]
prediction: ['[CLS] i saw those these dancers and some musicians smoking something [SEP]']
[1350/2000] tot_loss=1.657 (perp=7.819, rec=0.088, cos=0.005), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS] i saw those these dancers and players musicians smoking something [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.433 (perp=6.691, rec=0.090, cos=0.005), tot_loss_proj:3.153 [t=0.17s]
prediction: ['[CLS] i saw those some dancers and these musicians smoking something [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.650 (perp=7.819, rec=0.082, cos=0.005), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS] i saw those these dancers and players musicians smoking something [SEP]']
[1500/2000] tot_loss=1.659 (perp=7.819, rec=0.091, cos=0.005), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS] i saw those these dancers and players musicians smoking something [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.474 (perp=6.963, rec=0.077, cos=0.005), tot_loss_proj:2.978 [t=0.17s]
prediction: ['[CLS] i saw those players dancers and these musicians smoking something [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.472 (perp=6.931, rec=0.081, cos=0.005), tot_loss_proj:3.229 [t=0.17s]
prediction: ['[CLS] i saw those dancers and these musicians some smoking something [SEP]']
[1650/2000] tot_loss=1.593 (perp=7.500, rec=0.088, cos=0.005), tot_loss_proj:3.625 [t=0.17s]
prediction: ['[CLS] i saw those dancers and these musicians colour smoking something [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.430 (perp=6.765, rec=0.072, cos=0.005), tot_loss_proj:3.155 [t=0.17s]
prediction: ['[CLS] i saw those dancers some and these musicians smoking something [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.402 (perp=6.579, rec=0.082, cos=0.005), tot_loss_proj:3.191 [t=0.17s]
prediction: ['[CLS] i saw those dancers and these some musicians smoking something [SEP]']
[1800/2000] tot_loss=1.483 (perp=7.029, rec=0.072, cos=0.005), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] i saw those dancers and these colour musicians smoking something [SEP]']
Attempt swap
[1850/2000] tot_loss=1.485 (perp=7.029, rec=0.075, cos=0.004), tot_loss_proj:2.434 [t=0.17s]
prediction: ['[CLS] i saw those dancers and these colour musicians smoking something [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.452 (perp=6.811, rec=0.084, cos=0.005), tot_loss_proj:3.498 [t=0.17s]
prediction: ['[CLS] i saw those dancers and these musicians smoking colour something [SEP]']
[1950/2000] tot_loss=1.433 (perp=6.811, rec=0.066, cos=0.005), tot_loss_proj:3.489 [t=0.17s]
prediction: ['[CLS] i saw those dancers and these musicians smoking colour something [SEP]']
Attempt swap
[2000/2000] tot_loss=1.441 (perp=6.811, rec=0.074, cos=0.005), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] i saw those dancers and these musicians smoking colour something [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] i saw these dancers and those musicians smoking something. [SEP]
========================
predicted: 
========================
[CLS] i saw those these dancers and some musicians smoking something [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 66.667 | p: 63.636 | r: 70.000
rougeL     | fm: 86.957 | p: 83.333 | r: 90.909
rougeLsum  | fm: 86.957 | p: 83.333 | r: 90.909
r1fm+r2fm = 162.319

[Aggregate metrics]:
rouge1     | fm: 82.725 | p: 81.860 | r: 83.901
rouge2     | fm: 41.039 | p: 40.585 | r: 41.614
rougeL     | fm: 70.199 | p: 69.517 | r: 71.090
rougeLsum  | fm: 70.168 | p: 69.517 | r: 71.040
r1fm+r2fm = 123.764

input #93 time: 0:06:49 | total time: 12:26:03


Running input #94 of 100.
reference: 
========================
Ayala sent back her cousin the diamond necklace.
========================
average of cosine similarity 0.9992840849473748
highest_index [0]
highest [0.9992840849473748]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  1037, 28617,  2741,  2067,  2014,  5542,  1996,  6323, 13016,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ayala sent back her cousin the diamond necklace. [SEP]']
[Init] best rec loss: 1.5740669965744019 for ['[CLS] universe car flight volume stem? fangs naturally port produced [SEP]']
[Init] best rec loss: 1.337361216545105 for ['[CLS] c2 guysament means tucker indicated corresponding likes instead shifters [SEP]']
[Init] best rec loss: 1.1773312091827393 for ['[CLS] nina weights micah economy ladyaciesffled feeling harbor mt [SEP]']
[Init] best rec loss: 1.170557975769043 for ['[CLS] consecutive [MASK] brother safe grows collect janeiroably e produced [SEP]']
[Init] best rec loss: 1.1697776317596436 for ['[CLS] commander system country ca young orleans facial yhaus boring [SEP]']
[Init] best rec loss: 1.063694953918457 for ['[CLS] chartered cult4chment boat six cinder bothered eminentacies [SEP]']
[Init] best rec loss: 1.0563299655914307 for ['[CLS] radio disc castle lilith confidentialmel torah effectively prompted once [SEP]']
[Init] best rec loss: 1.0179009437561035 for ['[CLS] may av connected onwards recorder hampson they struggled adaptation bunch [SEP]']
[Init] best perm rec loss: 1.0155069828033447 for ['[CLS] hampson they recorder av connected onwards may struggled adaptation bunch [SEP]']
[Init] best perm rec loss: 1.0147130489349365 for ['[CLS] hampson may av connected onwards recorder they struggled adaptation bunch [SEP]']
[Init] best perm rec loss: 1.01413893699646 for ['[CLS] struggled recorder onwards they connected adaptation bunch av hampson may [SEP]']
[Init] best perm rec loss: 1.01349675655365 for ['[CLS] may connected they onwards struggled recorder hampson adaptation bunch av [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.175 (perp=13.293, rec=0.420, cos=0.097), tot_loss_proj:3.924 [t=0.17s]
prediction: ['[CLS] swing brought jessie blonde sean democratic was money brant health [SEP]']
[ 100/2000] tot_loss=3.203 (perp=13.674, rec=0.405, cos=0.064), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] drake sent there jobs [SEP] gone thread neck chileanyle [SEP]']
[ 150/2000] tot_loss=2.569 (perp=11.241, rec=0.283, cos=0.038), tot_loss_proj:3.971 [t=0.17s]
prediction: ['[CLS] drake sent back property the sexual haggard her columbia jewelry [SEP]']
[ 200/2000] tot_loss=2.915 (perp=10.510, rec=0.440, cos=0.373), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS]yala sent back her the aunt diamond her ᶜ necklace [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.081 (perp=9.312, rec=0.194, cos=0.026), tot_loss_proj:3.072 [t=0.17s]
prediction: ['[CLS] likeyala sent back cousin the diamond necklace diamond necklace [SEP]']
[ 300/2000] tot_loss=2.030 (perp=9.312, rec=0.150, cos=0.018), tot_loss_proj:3.075 [t=0.17s]
prediction: ['[CLS] likeyala sent back cousin the diamond necklace diamond necklace [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.000 (perp=9.312, rec=0.125, cos=0.013), tot_loss_proj:3.073 [t=0.17s]
prediction: ['[CLS] likeyala sent back cousin the diamond necklace diamond necklace [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.796 (perp=8.324, rec=0.119, cos=0.013), tot_loss_proj:2.556 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace diamond necklace [SEP]']
[ 450/2000] tot_loss=1.788 (perp=8.324, rec=0.112, cos=0.011), tot_loss_proj:2.551 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace diamond necklace [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.789 (perp=8.324, rec=0.115, cos=0.009), tot_loss_proj:2.559 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace diamond necklace [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.784 (perp=8.324, rec=0.109, cos=0.010), tot_loss_proj:2.561 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace diamond necklace [SEP]']
[ 600/2000] tot_loss=1.782 (perp=8.324, rec=0.108, cos=0.009), tot_loss_proj:2.558 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace diamond necklace [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.772 (perp=8.324, rec=0.099, cos=0.008), tot_loss_proj:2.562 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace diamond necklace [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.770 (perp=8.324, rec=0.098, cos=0.008), tot_loss_proj:2.563 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace diamond necklace [SEP]']
[ 750/2000] tot_loss=1.776 (perp=8.324, rec=0.104, cos=0.008), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace diamond necklace [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.773 (perp=8.324, rec=0.101, cos=0.008), tot_loss_proj:2.568 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace diamond necklace [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.804 (perp=8.495, rec=0.097, cos=0.008), tot_loss_proj:2.687 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace. necklace [SEP]']
[ 900/2000] tot_loss=1.810 (perp=8.495, rec=0.102, cos=0.010), tot_loss_proj:2.695 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace. necklace [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.629 (perp=7.571, rec=0.107, cos=0.008), tot_loss_proj:2.415 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace necklace. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.625 (perp=7.571, rec=0.104, cos=0.008), tot_loss_proj:2.417 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace necklace. [SEP]']
[1050/2000] tot_loss=1.619 (perp=7.571, rec=0.097, cos=0.008), tot_loss_proj:2.417 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace necklace. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.614 (perp=7.571, rec=0.093, cos=0.008), tot_loss_proj:2.419 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace necklace. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.623 (perp=7.571, rec=0.101, cos=0.008), tot_loss_proj:2.417 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace necklace. [SEP]']
[1200/2000] tot_loss=1.619 (perp=7.571, rec=0.097, cos=0.008), tot_loss_proj:2.413 [t=0.17s]
prediction: ['[CLS] ayala sent back cousin the diamond necklace necklace. [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.498 (perp=6.996, rec=0.092, cos=0.007), tot_loss_proj:2.941 [t=0.17s]
prediction: ['[CLS] ayala cousin sent back the diamond necklace necklace. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.492 (perp=6.907, rec=0.103, cos=0.008), tot_loss_proj:3.262 [t=0.17s]
prediction: ['[CLS] a cousinyala sent back the diamond necklace necklace. [SEP]']
[1350/2000] tot_loss=1.472 (perp=6.835, rec=0.098, cos=0.007), tot_loss_proj:3.143 [t=0.19s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.475 (perp=6.835, rec=0.101, cos=0.007), tot_loss_proj:3.136 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.459 (perp=6.835, rec=0.085, cos=0.007), tot_loss_proj:3.133 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
[1500/2000] tot_loss=1.470 (perp=6.835, rec=0.096, cos=0.007), tot_loss_proj:3.145 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.464 (perp=6.835, rec=0.090, cos=0.007), tot_loss_proj:3.139 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.470 (perp=6.835, rec=0.096, cos=0.007), tot_loss_proj:3.137 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
[1650/2000] tot_loss=1.467 (perp=6.835, rec=0.093, cos=0.007), tot_loss_proj:3.140 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.479 (perp=6.835, rec=0.105, cos=0.007), tot_loss_proj:3.142 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.470 (perp=6.835, rec=0.096, cos=0.007), tot_loss_proj:3.143 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
[1800/2000] tot_loss=1.463 (perp=6.835, rec=0.089, cos=0.007), tot_loss_proj:3.144 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.469 (perp=6.835, rec=0.095, cos=0.007), tot_loss_proj:3.145 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.472 (perp=6.835, rec=0.098, cos=0.007), tot_loss_proj:3.146 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
[1950/2000] tot_loss=1.466 (perp=6.835, rec=0.092, cos=0.007), tot_loss_proj:3.152 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.478 (perp=6.835, rec=0.104, cos=0.007), tot_loss_proj:3.149 [t=0.17s]
prediction: ['[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] ayala sent back her cousin the diamond necklace. [SEP]
========================
predicted: 
========================
[CLS] her cousinyala sent back the diamond necklace necklace. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 44.444 | p: 44.444 | r: 44.444
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 124.444

[Aggregate metrics]:
rouge1     | fm: 82.669 | p: 81.786 | r: 83.818
rouge2     | fm: 41.069 | p: 40.662 | r: 41.634
rougeL     | fm: 70.230 | p: 69.569 | r: 71.159
rougeLsum  | fm: 70.228 | p: 69.631 | r: 71.115
r1fm+r2fm = 123.738

input #94 time: 0:06:52 | total time: 12:32:55


Running input #95 of 100.
reference: 
========================
Brenda met.
========================
average of cosine similarity 0.9992582990211568
highest_index [0]
highest [0.9992582990211568]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15507,  2777,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] brenda met. [SEP]']
[Init] best rec loss: 1.9262616634368896 for ['[CLS]eptive day less [SEP]']
[Init] best rec loss: 1.294613003730774 for ['[CLS]fall few why [SEP]']
[Init] best rec loss: 1.288987159729004 for ['[CLS] si indefinite nixon [SEP]']
[Init] best rec loss: 1.182835578918457 for ['[CLS]ave recorded head [SEP]']
[Init] best rec loss: 0.9679192900657654 for ['[CLS] boss back michigan [SEP]']
[Init] best rec loss: 0.9314659237861633 for ['[CLS] pseudonym mill joyah [SEP]']
[Init] best rec loss: 0.9130374193191528 for ['[CLS] matituted kelsey [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.742 (perp=11.386, rec=0.418, cos=0.047), tot_loss_proj:3.129 [t=0.18s]
prediction: ['[CLS] rome encountered defeated [SEP]']
[ 100/2000] tot_loss=2.257 (perp=10.029, rec=0.230, cos=0.021), tot_loss_proj:2.794 [t=0.18s]
prediction: ['[CLS] brenda met met [SEP]']
[ 150/2000] tot_loss=2.198 (perp=10.029, rec=0.175, cos=0.017), tot_loss_proj:2.813 [t=0.19s]
prediction: ['[CLS] brenda met met [SEP]']
[ 200/2000] tot_loss=2.170 (perp=10.029, rec=0.151, cos=0.014), tot_loss_proj:2.819 [t=0.19s]
prediction: ['[CLS] brenda met met [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.013 (perp=9.191, rec=0.160, cos=0.015), tot_loss_proj:2.661 [t=0.18s]
prediction: ['[CLS] met brenda met [SEP]']
[ 300/2000] tot_loss=2.055 (perp=9.699, rec=0.110, cos=0.006), tot_loss_proj:3.705 [t=0.19s]
prediction: ['[CLS]. brenda met [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.572 (perp=7.451, rec=0.080, cos=0.002), tot_loss_proj:1.588 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.562 (perp=7.451, rec=0.070, cos=0.002), tot_loss_proj:1.592 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
[ 450/2000] tot_loss=1.559 (perp=7.451, rec=0.067, cos=0.002), tot_loss_proj:1.587 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.562 (perp=7.451, rec=0.070, cos=0.002), tot_loss_proj:1.588 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.551 (perp=7.451, rec=0.060, cos=0.002), tot_loss_proj:1.584 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
[ 600/2000] tot_loss=1.554 (perp=7.451, rec=0.063, cos=0.002), tot_loss_proj:1.587 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.560 (perp=7.451, rec=0.068, cos=0.002), tot_loss_proj:1.578 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.560 (perp=7.451, rec=0.068, cos=0.002), tot_loss_proj:1.591 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
[ 750/2000] tot_loss=1.559 (perp=7.451, rec=0.067, cos=0.002), tot_loss_proj:1.582 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.541 (perp=7.451, rec=0.050, cos=0.001), tot_loss_proj:1.575 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.550 (perp=7.451, rec=0.058, cos=0.001), tot_loss_proj:1.585 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
[ 900/2000] tot_loss=1.556 (perp=7.451, rec=0.065, cos=0.001), tot_loss_proj:1.591 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.561 (perp=7.451, rec=0.070, cos=0.001), tot_loss_proj:1.589 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.550 (perp=7.451, rec=0.058, cos=0.001), tot_loss_proj:1.589 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
[1050/2000] tot_loss=1.552 (perp=7.451, rec=0.061, cos=0.001), tot_loss_proj:1.579 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.554 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.587 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.557 (perp=7.451, rec=0.065, cos=0.001), tot_loss_proj:1.587 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
[1200/2000] tot_loss=1.554 (perp=7.451, rec=0.062, cos=0.001), tot_loss_proj:1.585 [t=0.19s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.451, rec=0.058, cos=0.001), tot_loss_proj:1.591 [t=0.18s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.554 (perp=7.451, rec=0.062, cos=0.001), tot_loss_proj:1.581 [t=0.23s]
prediction: ['[CLS] brenda met. [SEP]']
[1350/2000] tot_loss=1.557 (perp=7.451, rec=0.065, cos=0.001), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.577 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.562 (perp=7.451, rec=0.070, cos=0.001), tot_loss_proj:1.575 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1500/2000] tot_loss=1.551 (perp=7.451, rec=0.059, cos=0.002), tot_loss_proj:1.585 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.545 (perp=7.451, rec=0.054, cos=0.001), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1650/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.581 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.552 (perp=7.451, rec=0.060, cos=0.001), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.553 (perp=7.451, rec=0.061, cos=0.001), tot_loss_proj:1.574 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1800/2000] tot_loss=1.565 (perp=7.451, rec=0.073, cos=0.001), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.544 (perp=7.451, rec=0.053, cos=0.001), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.551 (perp=7.451, rec=0.059, cos=0.001), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
[1950/2000] tot_loss=1.562 (perp=7.451, rec=0.071, cos=0.001), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.555 (perp=7.451, rec=0.063, cos=0.001), tot_loss_proj:1.587 [t=0.17s]
prediction: ['[CLS] brenda met. [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] brenda met. [SEP]
========================
predicted: 
========================
[CLS] brenda met. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.803 | p: 81.947 | r: 84.013
rouge2     | fm: 41.693 | p: 41.246 | r: 42.327
rougeL     | fm: 70.568 | p: 69.932 | r: 71.434
rougeLsum  | fm: 70.533 | p: 69.887 | r: 71.466
r1fm+r2fm = 124.496

input #95 time: 0:07:06 | total time: 12:40:02


Running input #96 of 100.
reference: 
========================
Today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might.
========================
average of cosine similarity 0.9994474553270568
highest_index [0]
highest [0.9994474553270568]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  2651,  2045,  2003,  2210,  2030,  2053,  2880, 16011,  1997,
         11690,  2015,  1998,  5637,  2015,  2011,  1996,  2120,  2231,  1010,
          2348,  8392,  6867,  2453,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]']
[Init] best rec loss: 1.9129246473312378 for ['[CLS] typeilised exiary radha legislative spotlight latter jesse wonder passing opened church charm dropping santa authorities loan youth firm regarding 1930s border kirk [SEP]']
[Init] best rec loss: 1.8974169492721558 for ['[CLS] other tunnel un barking historical forth back monks $nction worthy boys happyhic vivian visitors murdering batonion useless main to july elected [SEP]']
[Init] best rec loss: 1.8726886510849 for ['[CLS]ly lucky daggerchenkont que lilith nails lips wingspan thai melting place roller companyumb orlando use even cycle basic steiner christ burning [SEP]']
[Init] best rec loss: 1.8713973760604858 for ['[CLS] glad princess working closing heel newspaperberman lately dai along foreigneur overwhelmingly coming learning garageowski tried filed integral co haven language anything [SEP]']
[Init] best rec loss: 1.868512511253357 for ['[CLS]ect caring vhf wright friends markers post call saturday right see possibility simplicity 5 perch signed voices2 much sports news managementdhi canada [SEP]']
[Init] best rec loss: 1.8436658382415771 for ['[CLS] distinguishing hit heavygrave treaty weeks adept staff principal from bare almost very road venus applied generally substitute understandois asked run marin ecological [SEP]']
[Init] best rec loss: 1.8353660106658936 for ['[CLS] exerciseʲntes interact imaginesta performing follows fat area advanced visual fearing eligible contractorude developments then potsdam wake about star register some [SEP]']
[Init] best rec loss: 1.826676845550537 for ["[CLS] woman still land mileworthcon later prevented help outstandingක stacy disappeared window namesake silence'canada everyone up boost tootti suppose [SEP]"]
[Init] best perm rec loss: 1.8241603374481201 for ["[CLS] silence to upworth suppose boost later outstanding woman everyone still mile disappeared prevented land stacyconක canada'namesake windowotti help [SEP]"]
[Init] best perm rec loss: 1.813383936882019 for ["[CLS] help land silenceකotti boost namesake stacy outstanding'later woman still supposecon to prevented canada window mile disappearedworth up everyone [SEP]"]
[Init] best perm rec loss: 1.8133798837661743 for ["[CLS]worth suppose window up land woman later disappeared namesake still tootti stacy help canadacon'mile outstanding everyone boost prevented silenceක [SEP]"]
[Init] best perm rec loss: 1.811353325843811 for ["[CLS]con still later mile up boost toක everyone canada disappearedotti prevented namesake silence helpworth land stacy outstanding window woman suppose'[SEP]"]
[Init] best perm rec loss: 1.8105039596557617 for ["[CLS] window everyone outstanding namesake stacy helpcon silenceworth canada disappeared prevented to supposeotti'womanක boost mile later still up land [SEP]"]
[Init] best perm rec loss: 1.808115839958191 for ["[CLS] land stacy namesake canada up still later boost everyone silenceක woman suppose disappeared outstandingworthcon'to mile help window preventedotti [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=3.725 (perp=11.112, rec=0.570, cos=0.933), tot_loss_proj:3.999 [t=0.17s]
prediction: ['[CLS] me in head died at iia defending so com advanced ms based there outstanding responsible government thus. motorcycle : weeks allowed historically [SEP]']
[ 100/2000] tot_loss=3.547 (perp=12.255, rec=0.694, cos=0.403), tot_loss_proj:4.281 [t=0.17s]
prediction: ['[CLS] lord in / frost down i reign national lgbt fred any dowager ground australia inspector lesbian dictatorship even. around to sees awarded phone [SEP]']
[ 150/2000] tot_loss=2.644 (perp=10.744, rec=0.415, cos=0.081), tot_loss_proj:3.967 [t=0.17s]
prediction: ['[CLS] fit therefore, eternal down john symphony currently clinical lesbian any southern presence government government feminist private even mines. and gay government government [SEP]']
[ 200/2000] tot_loss=2.193 (perp=9.567, rec=0.255, cos=0.024), tot_loss_proj:3.682 [t=0.17s]
prediction: ['[CLS] there officials, eternal harassment military lesbian today harassment lesbian any national industry government government regional government by mines. and gay government government [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.936 (perp=8.500, rec=0.219, cos=0.018), tot_loss_proj:3.538 [t=0.17s]
prediction: ['[CLS] there today, gay harassment male lesbian officials against lesbian any national business government government regional autonomous by mines. and large national government [SEP]']
[ 300/2000] tot_loss=1.937 (perp=8.641, rec=0.194, cos=0.015), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] there today, lesbian harassment male lesbian officials harassment lesbian any national business government government regional autonomous by mines. and large national government [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.828 (perp=8.155, rec=0.186, cos=0.011), tot_loss_proj:3.510 [t=0.17s]
prediction: ['[CLS] there today, lesbian harassment sexual harassment officials of lesbian any national autonomous government government regional business by mines. or harassment national government [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.123 (perp=9.223, rec=0.250, cos=0.028), tot_loss_proj:3.781 [t=0.17s]
prediction: ['[CLS] this today ( gay harassment or harassment officials overwhelming lesbian no regional autonomous government or government regional operational swinging forces. harassment national government [SEP]']
[ 450/2000] tot_loss=1.956 (perp=8.754, rec=0.194, cos=0.012), tot_loss_proj:3.631 [t=0.17s]
prediction: ['[CLS] this today ( lesbian harassment or harassment definitely of lesbian the the autonomous government or government regional operational alongside forces. harassment national government [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.071 (perp=9.347, rec=0.189, cos=0.013), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] this today or gay harassment sexual harassment definitely of lesbian regional the autonomous government or government the operational alongsides. harassment national government [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.989 (perp=8.579, rec=0.234, cos=0.039), tot_loss_proj:3.608 [t=0.17s]
prediction: ['[CLS] this today or alongside harassment gay harassment obligations of lesbian regional national autonomous government or government the no gays. exists national government [SEP]']
[ 600/2000] tot_loss=1.773 (perp=7.862, rec=0.187, cos=0.014), tot_loss_proj:3.479 [t=0.17s]
prediction: ['[CLS] there today or alongside harassment gay harassment obligations of lesbian regional national autonomous government or government the no gays. official national government [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.952 (perp=8.814, rec=0.179, cos=0.010), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] there today orsm harassment gay harassment obligations of lesbian regional national autonomous government or government the gays over no any national government [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.856 (perp=8.308, rec=0.177, cos=0.017), tot_loss_proj:3.527 [t=0.17s]
prediction: ['[CLS] there today nosm harassment gay harassment obligations of lesbian regional national autonomous government or government the gays. or no national government [SEP]']
[ 750/2000] tot_loss=1.607 (perp=7.208, rec=0.158, cos=0.007), tot_loss_proj:3.292 [t=0.17s]
prediction: ['[CLS] there today no or harassment gay harassment official of lesbian regional national autonomous government or government the gays. or no national government [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.559 (perp=6.956, rec=0.161, cos=0.006), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] there today no or harassment gay harassment official of lesbian government national autonomous government or regional the gays. or no national government [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.517 (perp=6.657, rec=0.174, cos=0.012), tot_loss_proj:3.207 [t=0.17s]
prediction: ['[CLS] there today no harassment or gay harassment official by lesbian government national autonomous government or autonomous the gays. or no national government [SEP]']
[ 900/2000] tot_loss=1.484 (perp=6.657, rec=0.146, cos=0.006), tot_loss_proj:3.203 [t=0.17s]
prediction: ['[CLS] there today no harassment or gay harassment official by lesbian government national autonomous government or autonomous the gays. or no national government [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.510 (perp=6.801, rec=0.144, cos=0.006), tot_loss_proj:3.261 [t=0.17s]
prediction: ['[CLS] there today no harassment or gay harassment official by lesbians national autonomous government or autonomous the gay government. might no national government [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.418 (perp=6.267, rec=0.154, cos=0.011), tot_loss_proj:3.163 [t=0.17s]
prediction: ['[CLS] there today no harassment or gay harassment official by lesbians autonomous national autonomous government or the gay government. might no national government [SEP]']
[1050/2000] tot_loss=1.402 (perp=6.267, rec=0.142, cos=0.006), tot_loss_proj:3.162 [t=0.17s]
prediction: ['[CLS] there today no harassment or gay harassment official by lesbians autonomous national autonomous government or the gay government. might no national government [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.355 (perp=6.006, rec=0.149, cos=0.005), tot_loss_proj:3.119 [t=0.17s]
prediction: ['[CLS] there today no harassment or gay harassment official by lesbians autonomous national autonomous government or the gay government might. no national government [SEP]']
Attempt swap
[1150/2000] tot_loss=1.351 (perp=6.006, rec=0.145, cos=0.005), tot_loss_proj:3.121 [t=0.17s]
prediction: ['[CLS] there today no harassment or gay harassment official by lesbians autonomous national autonomous government or the gay government might. no national government [SEP]']
[1200/2000] tot_loss=1.431 (perp=6.428, rec=0.140, cos=0.005), tot_loss_proj:3.127 [t=0.17s]
prediction: ['[CLS] there today nos or gay harassment official by lesbians autonomous national autonomous government or the gay government might. no national government [SEP]']
Attempt swap
[1250/2000] tot_loss=1.483 (perp=6.673, rec=0.143, cos=0.005), tot_loss_proj:3.202 [t=0.17s]
prediction: ['[CLS] there today nos or gay harassment official by lesbians autonomous of autonomous government or the gay government might. no national government [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.592 (perp=7.169, rec=0.153, cos=0.005), tot_loss_proj:3.341 [t=0.17s]
prediction: ['[CLS] there today no government or or harassment official by lesbians autonomous of autonomous should or the gays might. no national government [SEP]']
[1350/2000] tot_loss=1.584 (perp=7.169, rec=0.145, cos=0.005), tot_loss_proj:3.332 [t=0.17s]
prediction: ['[CLS] there today no government or or harassment official by lesbians autonomous of autonomous should or the gays might. no national government [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.483 (perp=6.649, rec=0.148, cos=0.005), tot_loss_proj:3.165 [t=0.17s]
prediction: ['[CLS] there today no government or or harassment should by lesbians autonomous of autonomous official or the gays might. no national government [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.462 (perp=6.546, rec=0.148, cos=0.005), tot_loss_proj:3.208 [t=0.17s]
prediction: ['[CLS] there today no government or or harassment might by lesbians autonomous of the official or autonomous gays might. no national government [SEP]']
[1500/2000] tot_loss=1.454 (perp=6.546, rec=0.140, cos=0.005), tot_loss_proj:3.207 [t=0.17s]
prediction: ['[CLS] there today no government or or harassment might by lesbians autonomous of the official or autonomous gays might. no national government [SEP]']
Attempt swap
[1550/2000] tot_loss=1.503 (perp=6.752, rec=0.148, cos=0.005), tot_loss_proj:3.270 [t=0.17s]
prediction: ['[CLS] there today no governments or harassment might by lesbians autonomous of the official or autonomous gays might. no national government [SEP]']
Attempt swap
[1600/2000] tot_loss=1.490 (perp=6.752, rec=0.135, cos=0.005), tot_loss_proj:3.270 [t=0.17s]
prediction: ['[CLS] there today no governments or harassment might by lesbians autonomous of the official or autonomous gays might. no national government [SEP]']
[1650/2000] tot_loss=1.488 (perp=6.752, rec=0.133, cos=0.005), tot_loss_proj:3.267 [t=0.17s]
prediction: ['[CLS] there today no governments or harassment might by lesbians autonomous of the official or autonomous gays might. no national government [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.455 (perp=6.535, rec=0.143, cos=0.005), tot_loss_proj:3.224 [t=0.17s]
prediction: ['[CLS] there today no governments or harassment might by lesbians autonomous of the national or autonomous gays might. no official government [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.394 (perp=6.246, rec=0.139, cos=0.005), tot_loss_proj:3.174 [t=0.17s]
prediction: ['[CLS] there today no nationals or harassment might by lesbians autonomous of the government or autonomous gays might. no official government [SEP]']
[1800/2000] tot_loss=1.392 (perp=6.246, rec=0.138, cos=0.005), tot_loss_proj:3.174 [t=0.17s]
prediction: ['[CLS] there today no nationals or harassment might by lesbians autonomous of the government or autonomous gays might. no official government [SEP]']
Attempt swap
[1850/2000] tot_loss=1.389 (perp=6.246, rec=0.135, cos=0.005), tot_loss_proj:3.169 [t=0.17s]
prediction: ['[CLS] there today no nationals or harassment might by lesbians autonomous of the government or autonomous gays might. no official government [SEP]']
Attempt swap
[1900/2000] tot_loss=1.391 (perp=6.246, rec=0.137, cos=0.005), tot_loss_proj:3.166 [t=0.17s]
prediction: ['[CLS] there today no nationals or harassment might by lesbians autonomous of the government or autonomous gays might. no official government [SEP]']
[1950/2000] tot_loss=1.388 (perp=6.246, rec=0.134, cos=0.004), tot_loss_proj:3.166 [t=0.17s]
prediction: ['[CLS] there today no nationals or harassment might by lesbians autonomous of the government or autonomous gays might. no official government [SEP]']
Attempt swap
[2000/2000] tot_loss=1.400 (perp=6.246, rec=0.147, cos=0.004), tot_loss_proj:3.164 [t=0.17s]
prediction: ['[CLS] there today no nationals or harassment might by lesbians autonomous of the government or autonomous gays might. no official government [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] today there is little or no official harassment of lesbians and gays by the national government, although autonomous governments might. [SEP]
========================
predicted: 
========================
[CLS] there today no nationals or harassment might by lesbians autonomous of the government or autonomous gays might. no official government [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 72.727 | r: 72.727
rouge2     | fm: 4.762 | p: 4.762 | r: 4.762
rougeL     | fm: 45.455 | p: 45.455 | r: 45.455
rougeLsum  | fm: 45.455 | p: 45.455 | r: 45.455
r1fm+r2fm = 77.489

[Aggregate metrics]:
rouge1     | fm: 82.696 | p: 81.892 | r: 83.822
rouge2     | fm: 41.314 | p: 40.893 | r: 41.909
rougeL     | fm: 70.246 | p: 69.619 | r: 71.129
rougeLsum  | fm: 70.295 | p: 69.651 | r: 71.133
r1fm+r2fm = 124.010

input #96 time: 0:06:50 | total time: 12:46:52


Running input #97 of 100.
reference: 
========================
This oven cooks well.
========================
average of cosine similarity 0.999361289301567
highest_index [0]
highest [0.999361289301567]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  2023, 17428, 26929,  2092,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] this oven cooks well. [SEP]']
[Init] best rec loss: 1.9729759693145752 for ['[CLS] representing savedm ft dynasty [SEP]']
[Init] best rec loss: 1.878318428993225 for ['[CLS] diagnosed timothy besides jump lab [SEP]']
[Init] best rec loss: 1.8273491859436035 for ['[CLS] beer unions a brain monica [SEP]']
[Init] best rec loss: 1.8268033266067505 for ['[CLS] balanced corinne numbered near coat [SEP]']
[Init] best rec loss: 1.8073146343231201 for ['[CLS] officer true hold certified volvo [SEP]']
[Init] best rec loss: 1.7961475849151611 for ['[CLS] transferred provoke freedom rivera muscles [SEP]']
[Init] best rec loss: 1.7746626138687134 for ['[CLS] won hundred especially ara wit [SEP]']
[Init] best rec loss: 1.7743667364120483 for ['[CLS] mont lau plane located but [SEP]']
[Init] best rec loss: 1.7604713439941406 for ['[CLS] nominate market one slope crocodile [SEP]']
[Init] best perm rec loss: 1.7583602666854858 for ['[CLS] market slope one crocodile nominate [SEP]']
[Init] best perm rec loss: 1.7544159889221191 for ['[CLS] market nominate slope crocodile one [SEP]']
[Init] best perm rec loss: 1.7521787881851196 for ['[CLS] one nominate slope market crocodile [SEP]']
[Init] best perm rec loss: 1.748634696006775 for ['[CLS] crocodile nominate slope market one [SEP]']
[Init] best perm rec loss: 1.747166633605957 for ['[CLS] one nominate slope crocodile market [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.337 (perp=9.281, rec=0.388, cos=0.092), tot_loss_proj:3.809 [t=0.18s]
prediction: ['[CLS] born forced electoral teachers. [SEP]']
[ 100/2000] tot_loss=1.764 (perp=7.983, rec=0.156, cos=0.012), tot_loss_proj:3.510 [t=0.18s]
prediction: ['[CLS] this oven cooks oven. [SEP]']
[ 150/2000] tot_loss=1.578 (perp=7.419, rec=0.091, cos=0.003), tot_loss_proj:1.570 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[ 200/2000] tot_loss=1.557 (perp=7.419, rec=0.071, cos=0.002), tot_loss_proj:1.566 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.545 (perp=7.419, rec=0.059, cos=0.001), tot_loss_proj:1.559 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[ 300/2000] tot_loss=1.539 (perp=7.419, rec=0.054, cos=0.001), tot_loss_proj:1.579 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.543 (perp=7.419, rec=0.058, cos=0.001), tot_loss_proj:1.571 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.550 (perp=7.419, rec=0.065, cos=0.001), tot_loss_proj:1.561 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[ 450/2000] tot_loss=1.552 (perp=7.419, rec=0.067, cos=0.001), tot_loss_proj:1.562 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.548 (perp=7.419, rec=0.063, cos=0.001), tot_loss_proj:1.567 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.542 (perp=7.419, rec=0.057, cos=0.001), tot_loss_proj:1.565 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[ 600/2000] tot_loss=1.544 (perp=7.419, rec=0.059, cos=0.001), tot_loss_proj:1.570 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.533 (perp=7.419, rec=0.048, cos=0.001), tot_loss_proj:1.564 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.546 (perp=7.419, rec=0.061, cos=0.001), tot_loss_proj:1.575 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[ 750/2000] tot_loss=1.545 (perp=7.419, rec=0.060, cos=0.001), tot_loss_proj:1.571 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.551 (perp=7.419, rec=0.066, cos=0.001), tot_loss_proj:1.563 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.555 (perp=7.419, rec=0.070, cos=0.001), tot_loss_proj:1.562 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[ 900/2000] tot_loss=1.550 (perp=7.419, rec=0.065, cos=0.001), tot_loss_proj:1.575 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.552 (perp=7.419, rec=0.067, cos=0.001), tot_loss_proj:1.566 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.548 (perp=7.419, rec=0.063, cos=0.001), tot_loss_proj:1.573 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1050/2000] tot_loss=1.554 (perp=7.419, rec=0.069, cos=0.001), tot_loss_proj:1.576 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.548 (perp=7.419, rec=0.063, cos=0.001), tot_loss_proj:1.562 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.549 (perp=7.419, rec=0.064, cos=0.001), tot_loss_proj:1.571 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1200/2000] tot_loss=1.551 (perp=7.419, rec=0.066, cos=0.001), tot_loss_proj:1.570 [t=0.21s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.538 (perp=7.419, rec=0.053, cos=0.001), tot_loss_proj:1.566 [t=0.23s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.546 (perp=7.419, rec=0.061, cos=0.001), tot_loss_proj:1.563 [t=0.19s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1350/2000] tot_loss=1.548 (perp=7.419, rec=0.063, cos=0.001), tot_loss_proj:1.567 [t=0.20s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.544 (perp=7.419, rec=0.058, cos=0.001), tot_loss_proj:1.571 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.546 (perp=7.419, rec=0.060, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1500/2000] tot_loss=1.548 (perp=7.419, rec=0.063, cos=0.001), tot_loss_proj:1.573 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.535 (perp=7.419, rec=0.050, cos=0.001), tot_loss_proj:1.562 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.551 (perp=7.419, rec=0.066, cos=0.001), tot_loss_proj:1.573 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1650/2000] tot_loss=1.554 (perp=7.419, rec=0.069, cos=0.001), tot_loss_proj:1.562 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.543 (perp=7.419, rec=0.058, cos=0.001), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.551 (perp=7.419, rec=0.066, cos=0.001), tot_loss_proj:1.573 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1800/2000] tot_loss=1.544 (perp=7.419, rec=0.059, cos=0.001), tot_loss_proj:1.571 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.556 (perp=7.419, rec=0.071, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.544 (perp=7.419, rec=0.058, cos=0.001), tot_loss_proj:1.559 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
[1950/2000] tot_loss=1.539 (perp=7.419, rec=0.054, cos=0.001), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.543 (perp=7.419, rec=0.058, cos=0.001), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] this oven cooks well. [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] this oven cooks well. [SEP]
========================
predicted: 
========================
[CLS] this oven cooks well. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 82.852 | p: 82.072 | r: 83.952
rouge2     | fm: 41.770 | p: 41.370 | r: 42.356
rougeL     | fm: 70.507 | p: 69.942 | r: 71.386
rougeLsum  | fm: 70.609 | p: 69.993 | r: 71.487
r1fm+r2fm = 124.622

input #97 time: 0:07:14 | total time: 12:54:07


Running input #98 of 100.
reference: 
========================
Sarah devoured the cakes in the kitchen last night.
========================
average of cosine similarity 0.9993452529147651
highest_index [0]
highest [0.9993452529147651]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  4532, 16475, 16777,  1996, 22619,  1999,  1996,  3829,  2197,
          2305,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sarah devoured the cakes in the kitchen last night. [SEP]']
[Init] best rec loss: 1.9618949890136719 for ['[CLS] socialced coordination umbrella louder require paper plank parallel hi dame [SEP]']
[Init] best rec loss: 1.8039392232894897 for ['[CLS] commonwealthdine una british native unix hit arch unknown in pga [SEP]']
[Init] best rec loss: 1.7542437314987183 for ['[CLS] kiss apple le type will standing ballet productions - unincorporated sovereignty [SEP]']
[Init] best rec loss: 1.7489780187606812 for ['[CLS] two cycle juliana time itself placesfa import priority graphic beauty [SEP]']
[Init] best rec loss: 1.741433024406433 for ['[CLS] minister chartinate premises within canrationere above gay studio [SEP]']
[Init] best perm rec loss: 1.7359075546264648 for ['[CLS] above chart within studioration can gay ministerinate premisesere [SEP]']
[Init] best perm rec loss: 1.7357803583145142 for ['[CLS] studio chart minister withininate canereration above premises gay [SEP]']
[Init] best perm rec loss: 1.7344977855682373 for ['[CLS] premises ministerration gay can aboveere chart studio withininate [SEP]']
[Init] best perm rec loss: 1.7341339588165283 for ['[CLS] minister above can chart within studiorationinateere premises gay [SEP]']
[Init] best perm rec loss: 1.733855128288269 for ['[CLS] can above studio gay chart ministerrationere within premisesinate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.027 (perp=12.837, rec=0.406, cos=0.054), tot_loss_proj:4.416 [t=0.18s]
prediction: ['[CLS] recipient species richard tutor sarah killed something languages genesisne seeks [SEP]']
[ 100/2000] tot_loss=2.946 (perp=13.269, rec=0.276, cos=0.016), tot_loss_proj:4.438 [t=0.19s]
prediction: ['[CLS] cakes creatures sarah dining sarah at downstairs languages judges with covent [SEP]']
[ 150/2000] tot_loss=2.719 (perp=12.420, rec=0.222, cos=0.012), tot_loss_proj:4.393 [t=0.19s]
prediction: ['[CLS] cakes creatures sarah today sarahoured cooking cakes likened with priest [SEP]']
[ 200/2000] tot_loss=2.679 (perp=12.313, rec=0.204, cos=0.013), tot_loss_proj:4.373 [t=0.19s]
prediction: ['[CLS] cakes creatures sarah last sarahoured the cakes 1997 atoured [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.250 (perp=10.412, rec=0.159, cos=0.009), tot_loss_proj:4.036 [t=0.19s]
prediction: ['[CLS] cakes creatures sarah last sarahoured the cakes 1997 night. [SEP]']
[ 300/2000] tot_loss=2.079 (perp=9.621, rec=0.146, cos=0.008), tot_loss_proj:3.812 [t=0.19s]
prediction: ['[CLS] cakes dev kitchen last sarahoured the cakes morning night. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.984 (perp=9.162, rec=0.143, cos=0.009), tot_loss_proj:3.687 [t=0.19s]
prediction: ['[CLS] kitchen dev cakes last sarahoured the cakes morning night. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.243 (perp=10.034, rec=0.219, cos=0.018), tot_loss_proj:3.816 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last ªoured the cakes the night bridge [SEP]']
[ 450/2000] tot_loss=1.832 (perp=8.328, rec=0.157, cos=0.009), tot_loss_proj:3.552 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured night cakes the night night [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.822 (perp=8.328, rec=0.148, cos=0.008), tot_loss_proj:3.557 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured night cakes the night night [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.801 (perp=8.328, rec=0.128, cos=0.008), tot_loss_proj:3.558 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured night cakes the night night [SEP]']
[ 600/2000] tot_loss=1.991 (perp=9.374, rec=0.110, cos=0.007), tot_loss_proj:3.729 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured night cakes the dev night [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.853 (perp=8.668, rec=0.113, cos=0.007), tot_loss_proj:3.530 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured the cakes the dev night [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.944 (perp=9.154, rec=0.106, cos=0.006), tot_loss_proj:3.627 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured in cakes the dev night [SEP]']
[ 750/2000] tot_loss=1.930 (perp=9.154, rec=0.093, cos=0.006), tot_loss_proj:3.625 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured in cakes the dev night [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.936 (perp=9.154, rec=0.099, cos=0.006), tot_loss_proj:3.627 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured in cakes the dev night [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.935 (perp=9.154, rec=0.098, cos=0.006), tot_loss_proj:3.627 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured in cakes the dev night [SEP]']
[ 900/2000] tot_loss=1.928 (perp=9.154, rec=0.091, cos=0.006), tot_loss_proj:3.627 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured in cakes the dev night [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.505 (perp=7.046, rec=0.093, cos=0.002), tot_loss_proj:3.199 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured in cakes the night. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.378 (perp=6.441, rec=0.087, cos=0.002), tot_loss_proj:3.286 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured cakes in the night. [SEP]']
[1050/2000] tot_loss=1.372 (perp=6.441, rec=0.082, cos=0.002), tot_loss_proj:3.289 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured cakes in the night. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.376 (perp=6.441, rec=0.085, cos=0.002), tot_loss_proj:3.287 [t=0.19s]
prediction: ['[CLS] kitchen sarah cakes last devoured cakes in the night. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.464 (perp=6.953, rec=0.071, cos=0.002), tot_loss_proj:3.403 [t=0.19s]
prediction: ['[CLS] kitchen dev sarah last devoured cakes in the night. [SEP]']
[1200/2000] tot_loss=1.481 (perp=6.953, rec=0.088, cos=0.002), tot_loss_proj:3.405 [t=0.19s]
prediction: ['[CLS] kitchen dev sarah last devoured cakes in the night. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.466 (perp=6.953, rec=0.073, cos=0.002), tot_loss_proj:3.407 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah last devoured cakes in the night. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.468 (perp=6.953, rec=0.075, cos=0.002), tot_loss_proj:3.404 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah last devoured cakes in the night. [SEP]']
[1350/2000] tot_loss=1.474 (perp=6.953, rec=0.081, cos=0.002), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah last devoured cakes in the night. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.467 (perp=6.953, rec=0.074, cos=0.002), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah last devoured cakes in the night. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.420 (perp=6.659, rec=0.086, cos=0.002), tot_loss_proj:3.197 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
[1500/2000] tot_loss=1.409 (perp=6.659, rec=0.075, cos=0.002), tot_loss_proj:3.203 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.414 (perp=6.659, rec=0.080, cos=0.002), tot_loss_proj:3.202 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.424 (perp=6.659, rec=0.090, cos=0.002), tot_loss_proj:3.208 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
[1650/2000] tot_loss=1.411 (perp=6.659, rec=0.077, cos=0.002), tot_loss_proj:3.201 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.403 (perp=6.659, rec=0.070, cos=0.002), tot_loss_proj:3.202 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.402 (perp=6.659, rec=0.068, cos=0.002), tot_loss_proj:3.202 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
[1800/2000] tot_loss=1.413 (perp=6.659, rec=0.080, cos=0.002), tot_loss_proj:3.200 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.409 (perp=6.659, rec=0.075, cos=0.002), tot_loss_proj:3.200 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.409 (perp=6.659, rec=0.075, cos=0.002), tot_loss_proj:3.203 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
[1950/2000] tot_loss=1.406 (perp=6.659, rec=0.072, cos=0.002), tot_loss_proj:3.207 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.409 (perp=6.659, rec=0.075, cos=0.002), tot_loss_proj:3.203 [t=0.17s]
prediction: ['[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] sarah devoured the cakes in the kitchen last night. [SEP]
========================
predicted: 
========================
[CLS] kitchen dev sarah cakes last devoured in the night. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 110.909

[Aggregate metrics]:
rouge1     | fm: 82.955 | p: 82.175 | r: 84.092
rouge2     | fm: 41.686 | p: 41.213 | r: 42.370
rougeL     | fm: 70.467 | p: 69.888 | r: 71.372
rougeLsum  | fm: 70.450 | p: 69.861 | r: 71.346
r1fm+r2fm = 124.641

input #98 time: 0:07:09 | total time: 13:01:16


Running input #99 of 100.
reference: 
========================
The box contains the ball.
========================
average of cosine similarity 0.999440902871247
highest_index [0]
highest [0.999440902871247]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 1996, 3482, 3397, 1996, 3608, 1012,  102]], device='cuda:0')
Debug: ref = ['[CLS] the box contains the ball. [SEP]']
[Init] best rec loss: 1.9640625715255737 for ['[CLS] point bono dry position nothing using [SEP]']
[Init] best rec loss: 1.9234081506729126 for ['[CLS] tense childhood port oman mo earl [SEP]']
[Init] best rec loss: 1.9050358533859253 for ['[CLS]ential op favouroliommer awful [SEP]']
[Init] best rec loss: 1.8736497163772583 for ['[CLS]atinhyl spartan for suspension claire [SEP]']
[Init] best rec loss: 1.8736212253570557 for ['[CLS]stic elena wholly cambridge grounds der [SEP]']
[Init] best rec loss: 1.8237512111663818 for ['[CLS] childrenhy knockout centered documentaries conduct [SEP]']
[Init] best rec loss: 1.8212569952011108 for ['[CLS] allowingsti keller french cannot instant [SEP]']
[Init] best rec loss: 1.8180299997329712 for ['[CLS] burton devon rock patchesholesbrates [SEP]']
[Init] best rec loss: 1.8153693675994873 for ['[CLS] player [MASK] bard 28 retired israel [SEP]']
[Init] best rec loss: 1.8077106475830078 for ['[CLS] loud ; flat jin project ally [SEP]']
[Init] best rec loss: 1.790271520614624 for ['[CLS] gauge today winding mixeroses 2012 [SEP]']
[Init] best perm rec loss: 1.7878056764602661 for ['[CLS] winding gauge 2012oses today mixer [SEP]']
[Init] best perm rec loss: 1.7870416641235352 for ['[CLS] 2012 today windingoses gauge mixer [SEP]']
[Init] best perm rec loss: 1.7846521139144897 for ['[CLS] 2012 today winding mixer gaugeoses [SEP]']
[Init] best perm rec loss: 1.7845295667648315 for ['[CLS] winding 2012 gaugeoses today mixer [SEP]']
[Init] best perm rec loss: 1.7835992574691772 for ['[CLS] winding 2012 today mixeroses gauge [SEP]']
[Init] best perm rec loss: 1.78352689743042 for ['[CLS] gauge winding 2012 mixer todayoses [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.430 (perp=9.855, rec=0.366, cos=0.094), tot_loss_proj:3.843 [t=0.17s]
prediction: ['[CLS] bat rode destroyed. album. [SEP]']
[ 100/2000] tot_loss=2.334 (perp=10.219, rec=0.242, cos=0.048), tot_loss_proj:3.886 [t=0.17s]
prediction: ['[CLS] ball ran contain box contains. [SEP]']
[ 150/2000] tot_loss=2.160 (perp=9.642, rec=0.206, cos=0.025), tot_loss_proj:3.790 [t=0.17s]
prediction: ['[CLS] ball became box box contains. [SEP]']
[ 200/2000] tot_loss=2.112 (perp=9.655, rec=0.162, cos=0.019), tot_loss_proj:3.760 [t=0.17s]
prediction: ['[CLS] ball wrapped box box contains. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.951 (perp=8.845, rec=0.164, cos=0.017), tot_loss_proj:3.758 [t=0.17s]
prediction: ['[CLS] contains blurred box box ball. [SEP]']
[ 300/2000] tot_loss=1.850 (perp=8.500, rec=0.135, cos=0.016), tot_loss_proj:3.653 [t=0.17s]
prediction: ['[CLS] contains km² box box ball. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.203 (perp=9.490, rec=0.264, cos=0.042), tot_loss_proj:3.933 [t=0.17s]
prediction: ['[CLS] contains car ball the box ball [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.910 (perp=7.662, rec=0.324, cos=0.054), tot_loss_proj:3.564 [t=0.17s]
prediction: ['[CLS] contains the ball conor le. [SEP]']
[ 450/2000] tot_loss=2.496 (perp=11.069, rec=0.246, cos=0.037), tot_loss_proj:4.273 [t=0.17s]
prediction: ['[CLS] contains the ball µ box ball [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.070 (perp=9.164, rec=0.211, cos=0.026), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.045 (perp=9.164, rec=0.191, cos=0.022), tot_loss_proj:3.786 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
[ 600/2000] tot_loss=2.016 (perp=9.164, rec=0.162, cos=0.021), tot_loss_proj:3.783 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.001 (perp=9.164, rec=0.148, cos=0.020), tot_loss_proj:3.782 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.999 (perp=9.164, rec=0.147, cos=0.019), tot_loss_proj:3.785 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
[ 750/2000] tot_loss=1.988 (perp=9.164, rec=0.138, cos=0.017), tot_loss_proj:3.776 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.973 (perp=9.164, rec=0.124, cos=0.016), tot_loss_proj:3.781 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.972 (perp=9.164, rec=0.123, cos=0.016), tot_loss_proj:3.781 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
[ 900/2000] tot_loss=1.972 (perp=9.164, rec=0.124, cos=0.016), tot_loss_proj:3.786 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.970 (perp=9.164, rec=0.122, cos=0.015), tot_loss_proj:3.788 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
Attempt swap
[1000/2000] tot_loss=1.973 (perp=9.164, rec=0.126, cos=0.015), tot_loss_proj:3.784 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
[1050/2000] tot_loss=1.965 (perp=9.164, rec=0.118, cos=0.015), tot_loss_proj:3.787 [t=0.17s]
prediction: ['[CLS] contains the µ box ball box [SEP]']
Attempt swap
[1100/2000] tot_loss=2.101 (perp=9.792, rec=0.128, cos=0.015), tot_loss_proj:3.824 [t=0.17s]
prediction: ['[CLS] contains the µ inner ball box [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.267 (perp=10.489, rec=0.150, cos=0.020), tot_loss_proj:4.092 [t=0.17s]
prediction: ['[CLS] contains the µ box le ball [SEP]']
[1200/2000] tot_loss=1.753 (perp=8.027, rec=0.131, cos=0.016), tot_loss_proj:3.599 [t=0.17s]
prediction: ['[CLS] contains the collect box. ball [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.469 (perp=6.624, rec=0.128, cos=0.016), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.468 (perp=6.624, rec=0.128, cos=0.015), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
[1350/2000] tot_loss=1.457 (perp=6.624, rec=0.118, cos=0.014), tot_loss_proj:3.387 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.460 (perp=6.624, rec=0.121, cos=0.014), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.466 (perp=6.624, rec=0.127, cos=0.014), tot_loss_proj:3.387 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
[1500/2000] tot_loss=1.465 (perp=6.624, rec=0.126, cos=0.014), tot_loss_proj:3.386 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.468 (perp=6.624, rec=0.129, cos=0.014), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.453 (perp=6.624, rec=0.114, cos=0.014), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
[1650/2000] tot_loss=1.455 (perp=6.624, rec=0.117, cos=0.014), tot_loss_proj:3.383 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.457 (perp=6.624, rec=0.118, cos=0.014), tot_loss_proj:3.389 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.460 (perp=6.624, rec=0.122, cos=0.014), tot_loss_proj:3.386 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
[1800/2000] tot_loss=1.453 (perp=6.624, rec=0.115, cos=0.014), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.460 (perp=6.624, rec=0.122, cos=0.014), tot_loss_proj:3.387 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.462 (perp=6.624, rec=0.123, cos=0.014), tot_loss_proj:3.388 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
[1950/2000] tot_loss=1.456 (perp=6.624, rec=0.118, cos=0.014), tot_loss_proj:3.386 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.464 (perp=6.624, rec=0.126, cos=0.014), tot_loss_proj:3.378 [t=0.17s]
prediction: ['[CLS] contains the collect ball box. [SEP]']
Done with input #99 of 100.
reference: 
========================
[CLS] the box contains the ball. [SEP]
========================
predicted: 
========================
[CLS] contains the collect ball box. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 82.977 | p: 82.154 | r: 84.070
rouge2     | fm: 41.453 | p: 41.059 | r: 41.949
rougeL     | fm: 70.488 | p: 69.884 | r: 71.326
rougeLsum  | fm: 70.580 | p: 69.971 | r: 71.398
r1fm+r2fm = 124.431

input #99 time: 0:06:51 | total time: 13:08:07


Average Cosine Similarity: 0.9993532828782739
Done with all.
