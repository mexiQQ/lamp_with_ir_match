


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.1 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 1534.13it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9992715259422633
highest_index [0]
highest [0.9992715259422633]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.0055351257324219 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9447663426399231 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9361805319786072 for ['[CLS] ronnie huff [SEP]']
[Init] best rec loss: 0.9271856546401978 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9249287247657776 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8513282537460327 for ['[CLS] panel officer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.263 (perp=10.251, rec=0.197, cos=0.017), tot_loss_proj:2.130 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 100/2000] tot_loss=2.194 (perp=10.251, rec=0.134, cos=0.010), tot_loss_proj:2.122 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.136 (perp=10.251, rec=0.084, cos=0.002), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.115 (perp=10.251, rec=0.063, cos=0.001), tot_loss_proj:2.129 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.111 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.114 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.100 (perp=10.251, rec=0.048, cos=0.001), tot_loss_proj:2.129 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.108 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.124 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.105 (perp=10.251, rec=0.053, cos=0.001), tot_loss_proj:2.108 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.115 (perp=10.251, rec=0.063, cos=0.001), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.099 (perp=10.251, rec=0.047, cos=0.001), tot_loss_proj:2.112 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.123 (perp=10.251, rec=0.071, cos=0.001), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.119 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.118 (perp=10.251, rec=0.067, cos=0.001), tot_loss_proj:2.119 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.116 (perp=10.251, rec=0.064, cos=0.001), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.101 (perp=10.251, rec=0.050, cos=0.001), tot_loss_proj:2.119 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.111 (perp=10.251, rec=0.059, cos=0.001), tot_loss_proj:2.127 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.116 (perp=10.251, rec=0.064, cos=0.001), tot_loss_proj:2.121 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.119 (perp=10.251, rec=0.068, cos=0.001), tot_loss_proj:2.124 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.123 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.114 (perp=10.251, rec=0.062, cos=0.001), tot_loss_proj:2.121 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.105 (perp=10.251, rec=0.053, cos=0.001), tot_loss_proj:2.120 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.111 (perp=10.251, rec=0.059, cos=0.001), tot_loss_proj:2.122 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.115 (perp=10.251, rec=0.064, cos=0.001), tot_loss_proj:2.117 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.104 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.122 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.115 (perp=10.251, rec=0.063, cos=0.001), tot_loss_proj:2.120 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.111 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.115 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.103 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.107 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.130 (perp=10.251, rec=0.079, cos=0.001), tot_loss_proj:2.126 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.111 (perp=10.251, rec=0.059, cos=0.001), tot_loss_proj:2.116 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.098 (perp=10.251, rec=0.046, cos=0.001), tot_loss_proj:2.122 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.114 (perp=10.251, rec=0.063, cos=0.001), tot_loss_proj:2.126 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.118 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.120 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.116 (perp=10.251, rec=0.064, cos=0.001), tot_loss_proj:2.122 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.109 (perp=10.251, rec=0.058, cos=0.001), tot_loss_proj:2.129 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.127 (perp=10.251, rec=0.075, cos=0.001), tot_loss_proj:2.123 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.110 (perp=10.251, rec=0.058, cos=0.001), tot_loss_proj:2.113 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.107 (perp=10.251, rec=0.055, cos=0.001), tot_loss_proj:2.123 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.102 (perp=10.251, rec=0.050, cos=0.001), tot_loss_proj:2.123 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.119 (perp=10.251, rec=0.067, cos=0.001), tot_loss_proj:2.125 [t=0.28s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:08:32 | total time: 0:08:32


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9993548278348494
highest_index [0]
highest [0.9993548278348494]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.0210397243499756 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9793888926506042 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.8951830267906189 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 0.864271879196167 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8217445015907288 for ['[CLS] passage erupted [SEP]']
[Init] best rec loss: 0.8215807676315308 for ['[CLS] siam presidents [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.393 (perp=10.892, rec=0.212, cos=0.003), tot_loss_proj:2.543 [t=0.18s]
prediction: ['[CLS] wonderful splendid [SEP]']
[ 100/2000] tot_loss=2.193 (perp=10.288, rec=0.134, cos=0.001), tot_loss_proj:2.351 [t=0.19s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.133 (perp=10.288, rec=0.074, cos=0.001), tot_loss_proj:2.353 [t=0.18s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.115 (perp=10.288, rec=0.056, cos=0.001), tot_loss_proj:2.345 [t=0.18s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.902 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.906 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.894 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.894 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.898 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.890 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.899 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.887 (perp=9.171, rec=0.052, cos=0.001), tot_loss_proj:1.888 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.897 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.885 (perp=9.171, rec=0.049, cos=0.001), tot_loss_proj:1.897 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.892 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.905 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.889 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.897 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.891 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.900 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.893 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.903 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.891 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.908 (perp=9.171, rec=0.073, cos=0.001), tot_loss_proj:1.897 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.902 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.888 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.917 (perp=9.171, rec=0.081, cos=0.001), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.888 [t=0.28s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.877 (perp=9.171, rec=0.041, cos=0.001), tot_loss_proj:1.904 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.906 (perp=9.171, rec=0.071, cos=0.001), tot_loss_proj:1.913 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.891 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.895 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.904 (perp=9.171, rec=0.068, cos=0.001), tot_loss_proj:1.889 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.892 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.892 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.903 (perp=9.171, rec=0.068, cos=0.001), tot_loss_proj:1.890 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.908 (perp=9.171, rec=0.072, cos=0.001), tot_loss_proj:1.894 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.903 (perp=9.171, rec=0.068, cos=0.001), tot_loss_proj:1.894 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.906 (perp=9.171, rec=0.071, cos=0.001), tot_loss_proj:1.902 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.884 (perp=9.171, rec=0.048, cos=0.001), tot_loss_proj:1.898 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.878 (perp=9.171, rec=0.043, cos=0.001), tot_loss_proj:1.892 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.906 (perp=9.171, rec=0.071, cos=0.001), tot_loss_proj:1.901 [t=0.21s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.894 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.901 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.887 (perp=9.171, rec=0.051, cos=0.001), tot_loss_proj:1.898 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.908 (perp=9.171, rec=0.073, cos=0.001), tot_loss_proj:1.907 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.892 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.905 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:08:20 | total time: 0:16:53


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9994340582458305
highest_index [0]
highest [0.9994340582458305]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.8397367596626282 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.8254684805870056 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best rec loss: 0.8126578330993652 for ['[CLS] dailypol food [SEP]']
[Init] best rec loss: 0.805020809173584 for ['[CLS] just percussion universal [SEP]']
[Init] best rec loss: 0.7947117686271667 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 0.7828556895256042 for ['[CLS] we would working [SEP]']
[Init] best perm rec loss: 0.7795121073722839 for ['[CLS] would we working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.783 (perp=12.018, rec=0.344, cos=0.035), tot_loss_proj:3.070 [t=0.18s]
prediction: ['[CLS] style momentum gaining [SEP]']
[ 100/2000] tot_loss=2.459 (perp=11.212, rec=0.208, cos=0.009), tot_loss_proj:2.969 [t=0.24s]
prediction: ['[CLS] process momentum gaining [SEP]']
[ 150/2000] tot_loss=2.356 (perp=10.888, rec=0.172, cos=0.006), tot_loss_proj:2.705 [t=0.19s]
prediction: ['[CLS] much momentum gaining [SEP]']
[ 200/2000] tot_loss=2.336 (perp=10.888, rec=0.153, cos=0.005), tot_loss_proj:2.708 [t=0.25s]
prediction: ['[CLS] much momentum gaining [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.816 (perp=8.515, rec=0.111, cos=0.003), tot_loss_proj:1.797 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.787 (perp=8.515, rec=0.082, cos=0.002), tot_loss_proj:1.791 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.795 (perp=8.515, rec=0.091, cos=0.001), tot_loss_proj:1.793 [t=0.21s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.781 (perp=8.515, rec=0.076, cos=0.001), tot_loss_proj:1.805 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.801 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.790 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.796 [t=0.20s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.784 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.787 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.786 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.777 (perp=8.515, rec=0.073, cos=0.001), tot_loss_proj:1.788 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.789 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.753 (perp=8.515, rec=0.049, cos=0.001), tot_loss_proj:1.798 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.780 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.756 (perp=8.515, rec=0.051, cos=0.001), tot_loss_proj:1.791 [t=0.20s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.789 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.788 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.797 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.757 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.796 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.762 (perp=8.515, rec=0.058, cos=0.001), tot_loss_proj:1.787 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.792 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.785 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.796 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.773 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.792 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.797 [t=0.21s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.755 (perp=8.515, rec=0.051, cos=0.001), tot_loss_proj:1.786 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.773 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.793 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.753 (perp=8.515, rec=0.049, cos=0.001), tot_loss_proj:1.794 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.793 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.785 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.791 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.791 [t=0.20s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.800 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.798 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.787 [t=0.29s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:08:34 | total time: 0:25:28


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.9993001481006445
highest_index [0]
highest [0.9993001481006445]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.0116136074066162 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9035081267356873 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8794226050376892 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8757002949714661 for ['[CLS] role bart [SEP]']
[Init] best rec loss: 0.8483982086181641 for ['[CLS] gallons professor [SEP]']
[Init] best rec loss: 0.8467844724655151 for ['[CLS] canterbury havoc [SEP]']
[Init] best rec loss: 0.8355522155761719 for ['[CLS] anthony robin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.338 (perp=10.476, rec=0.238, cos=0.005), tot_loss_proj:2.436 [t=0.18s]
prediction: ['[CLS] flawless flawless [SEP]']
[ 100/2000] tot_loss=2.139 (perp=10.224, rec=0.093, cos=0.001), tot_loss_proj:2.367 [t=0.19s]
prediction: ['[CLS] film flawless [SEP]']
[ 150/2000] tot_loss=2.119 (perp=10.224, rec=0.072, cos=0.001), tot_loss_proj:2.373 [t=0.18s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.110 (perp=10.224, rec=0.063, cos=0.001), tot_loss_proj:2.377 [t=0.18s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.788 (perp=8.385, rec=0.109, cos=0.002), tot_loss_proj:1.760 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.757 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.739 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.760 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.741 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.759 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.743 (perp=8.385, rec=0.065, cos=0.001), tot_loss_proj:1.747 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.728 (perp=8.385, rec=0.050, cos=0.001), tot_loss_proj:1.753 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.758 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.743 (perp=8.385, rec=0.065, cos=0.001), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.744 (perp=8.385, rec=0.066, cos=0.001), tot_loss_proj:1.753 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.751 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.741 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.758 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.756 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.747 (perp=8.385, rec=0.069, cos=0.001), tot_loss_proj:1.753 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.756 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.751 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.738 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.743 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.733 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.755 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.750 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.733 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.755 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.740 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.752 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.742 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.740 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.743 (perp=8.385, rec=0.065, cos=0.001), tot_loss_proj:1.746 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.755 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.747 (perp=8.385, rec=0.069, cos=0.001), tot_loss_proj:1.760 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.749 (perp=8.385, rec=0.071, cos=0.001), tot_loss_proj:1.756 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.743 (perp=8.385, rec=0.065, cos=0.001), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.736 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.750 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.755 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.741 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.757 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.745 (perp=8.385, rec=0.066, cos=0.001), tot_loss_proj:1.749 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.744 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.748 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.730 (perp=8.385, rec=0.051, cos=0.001), tot_loss_proj:1.767 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.754 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.733 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.753 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.750 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:08:14 | total time: 0:33:43


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.9992301171062454
highest_index [0]
highest [0.9992301171062454]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.0361230373382568 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9819928407669067 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.963243842124939 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9556242823600769 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 0.9394267797470093 for ['[CLS] who table christ [SEP]']
[Init] best rec loss: 0.9341257810592651 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.9212238788604736 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.9182291030883789 for ['[CLS] troupe stopped clayton [SEP]']
[Init] best rec loss: 0.8931007385253906 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.133 (perp=9.706, rec=0.184, cos=0.007), tot_loss_proj:2.152 [t=0.32s]
prediction: ['[CLS] tiresomently [SEP]']
[ 100/2000] tot_loss=1.599 (perp=7.516, rec=0.093, cos=0.002), tot_loss_proj:1.576 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.578 (perp=7.516, rec=0.073, cos=0.002), tot_loss_proj:1.576 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.576 (perp=7.516, rec=0.071, cos=0.002), tot_loss_proj:1.570 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.001), tot_loss_proj:1.573 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.576 (perp=7.516, rec=0.072, cos=0.001), tot_loss_proj:1.562 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.570 (perp=7.516, rec=0.065, cos=0.001), tot_loss_proj:1.564 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.567 (perp=7.516, rec=0.062, cos=0.001), tot_loss_proj:1.572 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.572 (perp=7.516, rec=0.067, cos=0.001), tot_loss_proj:1.565 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.566 (perp=7.516, rec=0.062, cos=0.001), tot_loss_proj:1.579 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.565 (perp=7.516, rec=0.060, cos=0.001), tot_loss_proj:1.568 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.567 (perp=7.516, rec=0.062, cos=0.001), tot_loss_proj:1.569 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.567 (perp=7.516, rec=0.063, cos=0.001), tot_loss_proj:1.571 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.569 (perp=7.516, rec=0.064, cos=0.002), tot_loss_proj:1.562 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.562 (perp=7.516, rec=0.058, cos=0.002), tot_loss_proj:1.576 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.563 (perp=7.516, rec=0.058, cos=0.002), tot_loss_proj:1.561 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.573 (perp=7.516, rec=0.069, cos=0.002), tot_loss_proj:1.561 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.561 (perp=7.516, rec=0.056, cos=0.002), tot_loss_proj:1.567 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.573 (perp=7.516, rec=0.069, cos=0.001), tot_loss_proj:1.566 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.564 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.576 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.575 (perp=7.516, rec=0.071, cos=0.002), tot_loss_proj:1.563 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.548 (perp=7.516, rec=0.044, cos=0.002), tot_loss_proj:1.568 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.564 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.556 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.577 (perp=7.516, rec=0.072, cos=0.002), tot_loss_proj:1.575 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.555 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.559 (perp=7.516, rec=0.054, cos=0.002), tot_loss_proj:1.564 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.570 (perp=7.516, rec=0.065, cos=0.002), tot_loss_proj:1.569 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.562 (perp=7.516, rec=0.057, cos=0.002), tot_loss_proj:1.567 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.555 (perp=7.516, rec=0.050, cos=0.002), tot_loss_proj:1.568 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.572 (perp=7.516, rec=0.067, cos=0.002), tot_loss_proj:1.564 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.562 (perp=7.516, rec=0.057, cos=0.002), tot_loss_proj:1.562 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.567 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.573 (perp=7.516, rec=0.069, cos=0.002), tot_loss_proj:1.568 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.563 (perp=7.516, rec=0.058, cos=0.002), tot_loss_proj:1.563 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.565 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.565 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.552 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.563 (perp=7.516, rec=0.058, cos=0.002), tot_loss_proj:1.567 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.558 (perp=7.516, rec=0.054, cos=0.002), tot_loss_proj:1.558 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.556 (perp=7.516, rec=0.051, cos=0.002), tot_loss_proj:1.553 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:08:32 | total time: 0:42:15


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9993649146105028
highest_index [0]
highest [0.9993649146105028]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9572856426239014 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9517245292663574 for ['[CLS] stay orgasm [SEP]']
[Init] best rec loss: 0.9491873979568481 for ['[CLS] territorial half [SEP]']
[Init] best rec loss: 0.9308651685714722 for ['[CLS] pleasant favorable [SEP]']
[Init] best rec loss: 0.927051305770874 for ['[CLS]iv fl [SEP]']
[Init] best rec loss: 0.9123218059539795 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 0.8898680210113525 for ['[CLS] quiet. [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.593 (perp=12.316, rec=0.128, cos=0.002), tot_loss_proj:2.530 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 100/2000] tot_loss=2.544 (perp=12.316, rec=0.079, cos=0.001), tot_loss_proj:2.510 [t=0.21s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 150/2000] tot_loss=2.534 (perp=12.316, rec=0.070, cos=0.001), tot_loss_proj:2.526 [t=0.21s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 200/2000] tot_loss=2.525 (perp=12.316, rec=0.060, cos=0.001), tot_loss_proj:2.523 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.520 (perp=12.316, rec=0.055, cos=0.001), tot_loss_proj:2.523 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 300/2000] tot_loss=2.528 (perp=12.316, rec=0.063, cos=0.001), tot_loss_proj:2.539 [t=0.22s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.529 (perp=12.316, rec=0.065, cos=0.001), tot_loss_proj:2.520 [t=0.21s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.515 (perp=12.316, rec=0.051, cos=0.001), tot_loss_proj:2.534 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 450/2000] tot_loss=2.519 (perp=12.316, rec=0.054, cos=0.001), tot_loss_proj:2.536 [t=0.29s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.514 (perp=12.316, rec=0.050, cos=0.001), tot_loss_proj:2.522 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.526 (perp=12.316, rec=0.061, cos=0.001), tot_loss_proj:2.514 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 600/2000] tot_loss=2.526 (perp=12.316, rec=0.062, cos=0.001), tot_loss_proj:2.533 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.527 (perp=12.316, rec=0.062, cos=0.001), tot_loss_proj:2.526 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.523 (perp=12.316, rec=0.059, cos=0.001), tot_loss_proj:2.516 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 750/2000] tot_loss=2.521 (perp=12.316, rec=0.056, cos=0.001), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.529 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.523 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.523 (perp=12.316, rec=0.059, cos=0.001), tot_loss_proj:2.535 [t=0.22s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 900/2000] tot_loss=2.526 (perp=12.316, rec=0.061, cos=0.001), tot_loss_proj:2.513 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.529 (perp=12.316, rec=0.065, cos=0.001), tot_loss_proj:2.520 [t=0.24s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1000/2000] tot_loss=2.529 (perp=12.316, rec=0.065, cos=0.001), tot_loss_proj:2.516 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1050/2000] tot_loss=2.528 (perp=12.316, rec=0.063, cos=0.001), tot_loss_proj:2.524 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1100/2000] tot_loss=2.524 (perp=12.316, rec=0.059, cos=0.001), tot_loss_proj:2.533 [t=0.22s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1150/2000] tot_loss=2.530 (perp=12.316, rec=0.066, cos=0.001), tot_loss_proj:2.526 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1200/2000] tot_loss=2.538 (perp=12.316, rec=0.074, cos=0.001), tot_loss_proj:2.526 [t=0.24s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1250/2000] tot_loss=2.528 (perp=12.316, rec=0.063, cos=0.001), tot_loss_proj:2.516 [t=0.22s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1300/2000] tot_loss=2.517 (perp=12.316, rec=0.053, cos=0.001), tot_loss_proj:2.520 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1350/2000] tot_loss=2.524 (perp=12.316, rec=0.060, cos=0.001), tot_loss_proj:2.525 [t=0.22s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1400/2000] tot_loss=2.533 (perp=12.316, rec=0.069, cos=0.001), tot_loss_proj:2.524 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1450/2000] tot_loss=2.528 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.521 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1500/2000] tot_loss=2.525 (perp=12.316, rec=0.060, cos=0.001), tot_loss_proj:2.517 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1550/2000] tot_loss=2.517 (perp=12.316, rec=0.053, cos=0.001), tot_loss_proj:2.526 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1600/2000] tot_loss=2.522 (perp=12.316, rec=0.058, cos=0.001), tot_loss_proj:2.530 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1650/2000] tot_loss=2.531 (perp=12.316, rec=0.067, cos=0.001), tot_loss_proj:2.530 [t=0.22s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1700/2000] tot_loss=2.517 (perp=12.316, rec=0.053, cos=0.001), tot_loss_proj:2.527 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1750/2000] tot_loss=2.525 (perp=12.316, rec=0.061, cos=0.001), tot_loss_proj:2.519 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1800/2000] tot_loss=2.530 (perp=12.316, rec=0.066, cos=0.001), tot_loss_proj:2.537 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1850/2000] tot_loss=2.526 (perp=12.316, rec=0.061, cos=0.001), tot_loss_proj:2.529 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1900/2000] tot_loss=2.527 (perp=12.316, rec=0.063, cos=0.001), tot_loss_proj:2.517 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1950/2000] tot_loss=2.540 (perp=12.316, rec=0.076, cos=0.001), tot_loss_proj:2.530 [t=0.25s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[2000/2000] tot_loss=2.512 (perp=12.316, rec=0.047, cos=0.001), tot_loss_proj:2.524 [t=0.29s]
prediction: ['[CLS] enjoyable ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] enjoyable ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #5 time: 0:08:30 | total time: 0:50:46


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.999250469444722
highest_index [0]
highest [0.999250469444722]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9556694626808167 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9542555809020996 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9281026721000671 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.870527982711792 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.8636731505393982 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.8084701895713806 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7869214415550232 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.7772212028503418 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.7523331046104431 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 0.7494601011276245 for ['[CLS] too u2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.604 (perp=6.813, rec=0.227, cos=0.014), tot_loss_proj:2.723 [t=0.22s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.725 (perp=8.089, rec=0.104, cos=0.003), tot_loss_proj:1.710 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.700 (perp=8.089, rec=0.081, cos=0.002), tot_loss_proj:1.693 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.670 (perp=8.089, rec=0.051, cos=0.002), tot_loss_proj:1.694 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.685 (perp=8.089, rec=0.066, cos=0.002), tot_loss_proj:1.691 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.676 (perp=8.089, rec=0.057, cos=0.001), tot_loss_proj:1.697 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.664 (perp=8.089, rec=0.045, cos=0.001), tot_loss_proj:1.685 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.684 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.689 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.688 (perp=8.089, rec=0.069, cos=0.001), tot_loss_proj:1.690 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.677 (perp=8.089, rec=0.058, cos=0.001), tot_loss_proj:1.686 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.684 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.696 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.685 (perp=8.089, rec=0.066, cos=0.001), tot_loss_proj:1.701 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.001), tot_loss_proj:1.679 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.689 (perp=8.089, rec=0.070, cos=0.001), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.001), tot_loss_proj:1.700 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.001), tot_loss_proj:1.688 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.678 (perp=8.089, rec=0.059, cos=0.001), tot_loss_proj:1.693 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.669 (perp=8.089, rec=0.050, cos=0.001), tot_loss_proj:1.696 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.688 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.666 (perp=8.089, rec=0.047, cos=0.001), tot_loss_proj:1.700 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.684 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.001), tot_loss_proj:1.709 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.684 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.001), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.684 (perp=8.089, rec=0.065, cos=0.001), tot_loss_proj:1.695 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.687 (perp=8.089, rec=0.067, cos=0.001), tot_loss_proj:1.698 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.682 (perp=8.089, rec=0.062, cos=0.001), tot_loss_proj:1.696 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.001), tot_loss_proj:1.687 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.687 (perp=8.089, rec=0.068, cos=0.001), tot_loss_proj:1.679 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.691 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.001), tot_loss_proj:1.693 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.686 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.663 (perp=8.089, rec=0.044, cos=0.001), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.685 (perp=8.089, rec=0.066, cos=0.001), tot_loss_proj:1.693 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.681 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.673 (perp=8.089, rec=0.054, cos=0.001), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.696 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.672 (perp=8.089, rec=0.053, cos=0.001), tot_loss_proj:1.684 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.682 (perp=8.089, rec=0.062, cos=0.001), tot_loss_proj:1.680 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.669 (perp=8.089, rec=0.050, cos=0.001), tot_loss_proj:1.688 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #6 time: 0:08:26 | total time: 0:59:12


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9991768686555793
highest_index [0]
highest [0.9991768686555793]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9112632274627686 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8373158574104309 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8293389678001404 for ['[CLS] minor bonnetmme near routine cluster confirmed pray mail guy smooth us empty bleeding interior [CLS] relegated seen tapes in beast risk contributingds addedores [SEP]']
[Init] best rec loss: 0.7947319149971008 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best perm rec loss: 0.7944874167442322 for ['[CLS] manual main disease mukherjee pacific animal battalion classics careernies gold 17th none ranide on blow depending sony alec madagascar tourismzed moffat consisting life [SEP]']
[Init] best perm rec loss: 0.7915330529212952 for ['[CLS] blow animal disease manual consistingzedidenies battalion main pacific on career gold madagascar 17th mukherjee sony alec none depending classics ran life tourism moffat [SEP]']
[Init] best perm rec loss: 0.7903832793235779 for ['[CLS] ran tourism career 17th consisting battalionzed classics madagascar depending manual none gold blowide disease life mainnies animal alec pacific sony mukherjee moffat on [SEP]']
[Init] best perm rec loss: 0.790372371673584 for ['[CLS] none consistingnies depending tourism main moffat classics 17th animal blow alec battalion life ran manual on sony madagascar career goldzed diseaseide mukherjee pacific [SEP]']
[Init] best perm rec loss: 0.790019154548645 for ['[CLS] tourism aleczedidenies depending moffat blow 17th none ran pacific sony main gold madagascar mukherjee manual life classics consisting on disease battalion career animal [SEP]']
[Init] best perm rec loss: 0.7886852025985718 for ['[CLS] tourism disease mainide battalionnies 17th moffat on animal madagascar consistingzed life career sony ran pacific gold alec depending mukherjee manual blow none classics [SEP]']
[Init] best perm rec loss: 0.7882210612297058 for ['[CLS] gold 17th on classics sony blow career pacific battalionzed depending tourismnies ran mukherjee animal consisting diseaseide main madagascar life manual moffat alec none [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.548 (perp=10.925, rec=0.350, cos=0.012), tot_loss_proj:3.316 [t=0.30s]
prediction: ['[CLS] problem worst keating neither incapable an problem was wrong abandoned issue or problem. bwf badly drug national standard ordinary. - jesus no ugly. [SEP]']
[ 100/2000] tot_loss=2.337 (perp=10.357, rec=0.259, cos=0.006), tot_loss_proj:3.518 [t=0.18s]
prediction: ['[CLS] problem problemleader no gregory an problem was problem little problem has no ; °c badly is no government character.ity he no ugly. [SEP]']
[ 150/2000] tot_loss=2.250 (perp=9.751, rec=0.287, cos=0.013), tot_loss_proj:3.505 [t=0.20s]
prediction: ['[CLS] problem problemwork no rules not ugly it problem no issue we no. because no was out system character character favors he no ugly lack [SEP]']
[ 200/2000] tot_loss=2.219 (perp=9.938, rec=0.224, cos=0.007), tot_loss_proj:2.848 [t=0.25s]
prediction: ['[CLS] problem problemwork no not has ugly not problem electricity i we no. is no - not system love character important he has ugly lack [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.330 (perp=10.423, rec=0.238, cos=0.008), tot_loss_proj:3.135 [t=0.24s]
prediction: ['[CLS] problem problembed no character has ugly mind problem electricity or we no ; is not. either system love plenty important he the ugly lack [SEP]']
[ 300/2000] tot_loss=2.112 (perp=9.582, rec=0.192, cos=0.004), tot_loss_proj:3.037 [t=0.22s]
prediction: ['[CLS] problem themebed no character has ugly mind problem? or ; no. is no.. system love perfect exciting he the ugly lack [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.924 (perp=8.759, rec=0.169, cos=0.003), tot_loss_proj:2.813 [t=0.19s]
prediction: ['[CLS] problem problem. no character has problem mind problem? or ; no. is no. fails system love perfect dozens he the ugly lack [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.782 (perp=8.085, rec=0.162, cos=0.003), tot_loss_proj:2.711 [t=0.19s]
prediction: ['[CLS] problem problem. no character has problem mind problem? or ; no. is not.. involved love perfect literally lack the ugly he [SEP]']
[ 450/2000] tot_loss=1.877 (perp=8.579, rec=0.159, cos=0.002), tot_loss_proj:2.909 [t=0.24s]
prediction: ['[CLS] problem factor. no character has cute mind problem ; or ; no. is not.. involved love perfect literally lack the ugly he [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.769 (perp=8.085, rec=0.149, cos=0.003), tot_loss_proj:3.090 [t=0.27s]
prediction: ['[CLS] problem cute. no character has factor mind problem. or ; no. is not.. involved love perfect literally lack the ugly he [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.726 (perp=7.938, rec=0.136, cos=0.002), tot_loss_proj:3.164 [t=0.24s]
prediction: ['[CLS] problem cute. no character has factor mind problem. or ; no. is not. system. love perfectriders lack the ugly he [SEP]']
[ 600/2000] tot_loss=1.769 (perp=8.129, rec=0.141, cos=0.002), tot_loss_proj:2.932 [t=0.27s]
prediction: ['[CLS] problem cute. no character has factor mind mind. or ; no. is not. system. love negativeriders lack the ugly he [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.698 (perp=7.799, rec=0.136, cos=0.002), tot_loss_proj:2.870 [t=0.19s]
prediction: ['[CLS] problem cute. no character has mind factor mind. or ; no. is not. system. love negativeriders lack the ugly he [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.780 (perp=8.187, rec=0.141, cos=0.002), tot_loss_proj:2.710 [t=0.20s]
prediction: ['[CLS] problem cute otherwise no character has mind or mind. here ; no. is not. system. love negativeriders lack the ugly he [SEP]']
[ 750/2000] tot_loss=1.732 (perp=7.956, rec=0.139, cos=0.002), tot_loss_proj:2.761 [t=0.24s]
prediction: ['[CLS] problem cute otherwise. character has mind or mind. here ; no. is not. system. love negativeriders lack the ugly he [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.625 (perp=7.476, rec=0.128, cos=0.002), tot_loss_proj:2.660 [t=0.19s]
prediction: ['[CLS] not cute otherwise. character has mind or mind. here ; no. is problem. system. love negativeriders lack the ugly he [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.610 (perp=7.403, rec=0.128, cos=0.002), tot_loss_proj:2.650 [t=0.23s]
prediction: ['[CLS] not cute otherwise. character has mind or mind. here ; no. problem is. system. love negativeriders lack the ugly he [SEP]']
[ 900/2000] tot_loss=1.605 (perp=7.403, rec=0.122, cos=0.002), tot_loss_proj:2.647 [t=0.19s]
prediction: ['[CLS] not cute otherwise. character has mind or mind. here ; no. problem is. system. love negativeriders lack the ugly he [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.546 (perp=7.102, rec=0.124, cos=0.002), tot_loss_proj:2.468 [t=0.18s]
prediction: ['[CLS] not cute otherwise. character has mind or mind. here ; no. problem is negative. system. loveriders lack the ugly he [SEP]']
Attempt swap
[1000/2000] tot_loss=1.547 (perp=7.102, rec=0.124, cos=0.002), tot_loss_proj:2.477 [t=0.23s]
prediction: ['[CLS] not cute otherwise. character has mind or mind. here ; no. problem is negative. system. loveriders lack the ugly he [SEP]']
[1050/2000] tot_loss=1.542 (perp=7.102, rec=0.120, cos=0.002), tot_loss_proj:2.473 [t=0.23s]
prediction: ['[CLS] not cute otherwise. character has mind or mind. here ; no. problem is negative. system. loveriders lack the ugly he [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.513 (perp=6.999, rec=0.112, cos=0.002), tot_loss_proj:2.295 [t=0.19s]
prediction: ['[CLS] not cute otherwise. character has mind or mind. here ; no. problem is. not system. loveriders lack the ugly he [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.488 (perp=6.864, rec=0.113, cos=0.002), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] not cute otherwise. character has mind or mind lack here ; no. problem is. not system. loveriders. the ugly he [SEP]']
[1200/2000] tot_loss=1.496 (perp=6.864, rec=0.121, cos=0.002), tot_loss_proj:2.224 [t=0.23s]
prediction: ['[CLS] not cute otherwise. character has mind or mind lack here ; no. problem is. not system. loveriders. the ugly he [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.484 (perp=6.788, rec=0.124, cos=0.002), tot_loss_proj:2.215 [t=0.27s]
prediction: ['[CLS] not cute otherwise. character has mind or mind lack here ; no. problem is. not system. love anything the ugly. he [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.482 (perp=6.780, rec=0.124, cos=0.002), tot_loss_proj:2.355 [t=0.19s]
prediction: ['[CLS] not cute otherwise. character has mind or mind lack here ; no. problem is or system not. love anything the ugly. he [SEP]']
[1350/2000] tot_loss=1.497 (perp=6.890, rec=0.117, cos=0.002), tot_loss_proj:2.377 [t=0.26s]
prediction: ['[CLS] not cuteable. character has mind or mind lack here ; no. problem is or system not. love anything the ugly. he [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.364 (perp=6.241, rec=0.114, cos=0.002), tot_loss_proj:2.292 [t=0.26s]
prediction: ['[CLS] not cuteable. character has mind or mind lack here ; no problem is. or system not. love not the ugly. he [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.363 (perp=6.187, rec=0.122, cos=0.003), tot_loss_proj:2.329 [t=0.25s]
prediction: ['[CLS] not cuteable. character has mind or mind lack here ; no problem is he.. system not. love not the ugly. [SEP]']
[1500/2000] tot_loss=1.336 (perp=6.062, rec=0.121, cos=0.002), tot_loss_proj:2.058 [t=0.19s]
prediction: ['[CLS] not cuteable. character has mind or mind lack here ; no problem is he. or would not. loveriders the ugly. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.333 (perp=6.062, rec=0.119, cos=0.002), tot_loss_proj:2.058 [t=0.19s]
prediction: ['[CLS] not cuteable. character has mind or mind lack here ; no problem is he. or would not. loveriders the ugly. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.363 (perp=6.256, rec=0.110, cos=0.002), tot_loss_proj:2.115 [t=0.25s]
prediction: ['[CLS] not cuteable. character has mind i, lack here ; no problem is he. or would not. loveriders the ugly. [SEP]']
[1650/2000] tot_loss=1.403 (perp=6.440, rec=0.113, cos=0.002), tot_loss_proj:2.174 [t=0.28s]
prediction: ['[CLS] not cuteable. character has mind i, lack here ; no problem is he. or would not of loveriders the ugly. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.390 (perp=6.368, rec=0.115, cos=0.002), tot_loss_proj:2.125 [t=0.23s]
prediction: ['[CLS] not cuteable character. has mind i, lack here ; no problem is he. or system not of love anything the ugly. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.314 (perp=5.986, rec=0.115, cos=0.002), tot_loss_proj:2.049 [t=0.22s]
prediction: ['[CLS] not cuteable character. has mind or i lack here ; no problem is he. or would not of love anything the ugly. [SEP]']
[1800/2000] tot_loss=1.312 (perp=5.986, rec=0.114, cos=0.002), tot_loss_proj:2.049 [t=0.25s]
prediction: ['[CLS] not cuteable character. has mind or i lack here ; no problem is he. or would not of love anything the ugly. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.289 (perp=5.848, rec=0.117, cos=0.002), tot_loss_proj:1.934 [t=0.21s]
prediction: ['[CLS] not cuteable character. has mind or i lack here ; no problem is he. or would not of anything love the ugly. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.285 (perp=5.848, rec=0.114, cos=0.002), tot_loss_proj:1.930 [t=0.19s]
prediction: ['[CLS] not cuteable character. has mind or i lack here ; no problem is he. or would not of anything love the ugly. [SEP]']
[1950/2000] tot_loss=1.287 (perp=5.848, rec=0.115, cos=0.002), tot_loss_proj:1.930 [t=0.26s]
prediction: ['[CLS] not cuteable character. has mind or i lack here ; no problem is he. or would not of anything love the ugly. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.282 (perp=5.848, rec=0.111, cos=0.002), tot_loss_proj:1.931 [t=0.18s]
prediction: ['[CLS] not cuteable character. has mind or i lack here ; no problem is he. or would not of anything love the ugly. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] not cute otherwise. character has mind or mind lack here ; no. problem is or system not. love not the ugly. he [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 69.565 | r: 76.190
rouge2     | fm: 4.762 | p: 4.545 | r: 5.000
rougeL     | fm: 31.818 | p: 30.435 | r: 33.333
rougeLsum  | fm: 31.818 | p: 30.435 | r: 33.333
r1fm+r2fm = 77.489

[Aggregate metrics]:
rouge1     | fm: 96.591 | p: 96.196 | r: 97.024
rouge2     | fm: 88.095 | p: 88.068 | r: 88.125
rougeL     | fm: 91.477 | p: 91.304 | r: 91.667
rougeLsum  | fm: 91.477 | p: 91.304 | r: 91.667
r1fm+r2fm = 184.686

input #7 time: 0:08:50 | total time: 1:08:03


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9994032830483026
highest_index [0]
highest [0.9994032830483026]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.7545608878135681 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7099087834358215 for ['[CLS] assassins able a bowled palace times drive camequal happens silver only foreign shelley pumping nbc camp easy payyo bigutounded meaning [SEP]']
[Init] best rec loss: 0.6953709125518799 for ['[CLS]dry pace hash mike parker guard defence disease relief studentquest steiner downdin dance domain briefly crystal beech reason newcastle kai prenostic [SEP]']
[Init] best rec loss: 0.6868163347244263 for ['[CLS] air namely fourjun nkend neitherdf rich ; bit healthcare formula noon abdul drill parks pr daylight longitude tent milo usaas [SEP]']
[Init] best rec loss: 0.6856463551521301 for ['[CLS] shouts guards germany space establishments sometimes flags dead rear protestant floyd breed article gut id occupational development institute loss joint hull meat mode required [SEP]']
[Init] best rec loss: 0.6826488375663757 for ['[CLS] normal bo set supreme something justified brahms mmmering age forward deafting wins backchen growth frozeere romney fighting crawl popularity copy [SEP]']
[Init] best rec loss: 0.6799412369728088 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.6793580651283264 for ['[CLS] sense bc dani actually ceased look thunder launch old doin translated ordainedrk case legal privately vatican pilot language sqldine turing midnight guard [SEP]']
[Init] best rec loss: 0.6682642102241516 for ['[CLS] eisenhower plaque arkansas screens sweat adventuremei wanda productey dna prison canontta tail franchise facts res si february season sociallydent badminton [SEP]']
[Init] best perm rec loss: 0.6651372313499451 for ['[CLS]dentey simei sweat franchise arkansas plaque facts canon february product res badminton screens adventuretta socially wanda prison eisenhower season tail dna [SEP]']
[Init] best perm rec loss: 0.6647960543632507 for ['[CLS] si socially tail dna wanda res arkansas february eisenhower screens sweat season franchiseey prison adventure product canonmeitta facts badminton plaquedent [SEP]']
[Init] best perm rec loss: 0.6633939146995544 for ['[CLS] dna sweat factsttadent sociallymei arkansas eisenhower si franchise canon adventure plaque season product tail res prison screens badminton wanda februaryey [SEP]']
[Init] best perm rec loss: 0.6628186106681824 for ['[CLS]mei si franchise wanda sweat product dna adventure eisenhowertta arkansas seasoney canon plaquedent tail february facts screens badminton res prison socially [SEP]']
[Init] best perm rec loss: 0.6616048216819763 for ['[CLS] res product socially badminton tail arkansas february facts sweat wandameident prison plaque eisenhower franchise adventure sitta dna seasoney screens canon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.894 (perp=12.467, rec=0.367, cos=0.033), tot_loss_proj:3.911 [t=0.22s]
prediction: ["[CLS]usion sense'nothing game lucienering owed its turn sox millie vanity reelection film legitimate debt million redding fulfilling owed wish suburban sovereign [SEP]"]
[ 100/2000] tot_loss=3.134 (perp=13.773, rec=0.340, cos=0.039), tot_loss_proj:4.059 [t=0.19s]
prediction: ['[CLS] grant albumed paid brightlike horror vanity us fox reserve doubt vanity vanity film crime debt paying redding pay pay find renegade vampire [SEP]']
[ 150/2000] tot_loss=2.780 (perp=12.552, rec=0.253, cos=0.017), tot_loss_proj:3.906 [t=0.19s]
prediction: ['[CLS] vanity vanity that everything a fright horror vanity us relaxisance doubt vanity vanity film film debt paid what pays owed what vanity vampire [SEP]']
[ 200/2000] tot_loss=2.597 (perp=11.915, rec=0.197, cos=0.016), tot_loss_proj:3.924 [t=0.19s]
prediction: ['[CLS] vanity film that everything a fright terror vanity off movieisance doubt vanity vanity film film debt gives what pays owed what vanity vampire [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.541 (perp=11.766, rec=0.178, cos=0.010), tot_loss_proj:3.842 [t=0.26s]
prediction: ['[CLS] vanity film that everything a fright vampire vanity off movie sustaining doubt vanity vanity film film debt pakistan what pays owed what vanity fright [SEP]']
[ 300/2000] tot_loss=2.555 (perp=11.996, rec=0.152, cos=0.004), tot_loss_proj:3.891 [t=0.19s]
prediction: ['[CLS] vanity s that owed a fright vampire vanity off movie benign doubt vanity vanity film film debt pakistan what pays owed what no fright [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.460 (perp=11.592, rec=0.139, cos=0.003), tot_loss_proj:3.771 [t=0.19s]
prediction: ['[CLS] s vanity that owed a fright vanity vanity off movie benign doubt vanity vanity film film debt s what pays owed what no fright [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.191 (perp=10.276, rec=0.133, cos=0.003), tot_loss_proj:3.466 [t=0.21s]
prediction: ['[CLS] s vanity that owed a frightful vanity, movie benign doubt vanity vanity film film debt off what pays owed what noda [SEP]']
[ 450/2000] tot_loss=2.225 (perp=10.453, rec=0.122, cos=0.012), tot_loss_proj:3.391 [t=0.19s]
prediction: ['[CLS] s vanity that owed a frightful vanity, movie benign doubt vanity vanity film film debt off felt pays owed what noda [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.089 (perp=9.862, rec=0.115, cos=0.002), tot_loss_proj:3.172 [t=0.19s]
prediction: ['[CLS] s film that owed a frightful vanity, movie benign doubt vanity vanity vanity film debt off felt pays owed what noda [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.141 (perp=10.047, rec=0.126, cos=0.006), tot_loss_proj:3.410 [t=0.19s]
prediction: ['[CLS] s film that felt a frightful vanity, movie benign doubt vanity vanity vanity film debt off owed pays owed what no volta [SEP]']
[ 600/2000] tot_loss=2.181 (perp=10.356, rec=0.107, cos=0.002), tot_loss_proj:3.533 [t=0.28s]
prediction: ['[CLS] s film that felt a frightful vanity, movie benign doubt vanity vanity vanitymax debt off owed pays owed what no volta [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.974 (perp=9.375, rec=0.097, cos=0.002), tot_loss_proj:3.182 [t=0.22s]
prediction: ['[CLS] s film that felt a frightful vanity, movie benign doubt vanity vanity vanitymax pays off owed debt owed what no - [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.002 (perp=9.512, rec=0.097, cos=0.002), tot_loss_proj:3.217 [t=0.20s]
prediction: ['[CLS] s film that felt a frightful vanity, - benign doubt vanity vanity vanitymax pays off owed debt owed what no circuit [SEP]']
[ 750/2000] tot_loss=1.995 (perp=9.512, rec=0.092, cos=0.001), tot_loss_proj:3.217 [t=0.19s]
prediction: ['[CLS] s film that felt a frightful vanity, - benign doubt vanity vanity vanitymax pays off owed debt owed what no circuit [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.935 (perp=9.190, rec=0.096, cos=0.001), tot_loss_proj:2.961 [t=0.19s]
prediction: ['[CLS] s owed that felt a frightful vanity, - benign doubt vanity vanity vanitymax pays off film debt owed what no circuit [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.898 (perp=9.001, rec=0.096, cos=0.001), tot_loss_proj:3.128 [t=0.25s]
prediction: ['[CLS] s, that felt a frightful vanity owed - benign doubt vanity vanity vanitymax pays off film debt owed what no circuit [SEP]']
[ 900/2000] tot_loss=1.891 (perp=9.001, rec=0.090, cos=0.001), tot_loss_proj:3.126 [t=0.19s]
prediction: ['[CLS] s, that felt a frightful vanity owed - benign doubt vanity vanity vanitymax pays off film debt owed what no circuit [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.937 (perp=9.213, rec=0.094, cos=0.001), tot_loss_proj:3.281 [t=0.19s]
prediction: ['[CLS] s, that felt a frightful ( owed - benign vanity doubt vanity vanitymax pays off film debt owed what no circuit [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.000 (perp=9.542, rec=0.089, cos=0.003), tot_loss_proj:3.350 [t=0.19s]
prediction: ['[CLS] s, that felt a frightful, benign vanity doubt vanity owedla vanitymax pays off film debt owed what no circuit [SEP]']
[1050/2000] tot_loss=2.000 (perp=9.542, rec=0.091, cos=0.001), tot_loss_proj:3.349 [t=0.18s]
prediction: ['[CLS] s, that felt a frightful, benign vanity doubt vanity owedla vanitymax pays off film debt owed what no circuit [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.864 (perp=8.886, rec=0.085, cos=0.001), tot_loss_proj:3.186 [t=0.19s]
prediction: ['[CLS] s, that felt a frightful, benign no doubt vanity owedla vanitymax pays off film debt owed what vanity circuit [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.744 (perp=8.264, rec=0.087, cos=0.004), tot_loss_proj:2.887 [t=0.20s]
prediction: ['[CLS] s, that felt a frightful, benign no doubt vanity owed -max pays off film vanity debt owed what vanity circuit [SEP]']
[1200/2000] tot_loss=1.740 (perp=8.264, rec=0.086, cos=0.001), tot_loss_proj:2.890 [t=0.19s]
prediction: ['[CLS] s, that felt a frightful, benign no doubt vanity owed -max pays off film vanity debt owed what vanity circuit [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.712 (perp=8.130, rec=0.085, cos=0.001), tot_loss_proj:2.912 [t=0.22s]
prediction: ['[CLS] s, that felt a frightful, benign no doubt vanity owed -max pays off film vanity debt owed vanity what circuit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.711 (perp=8.130, rec=0.084, cos=0.001), tot_loss_proj:2.919 [t=0.19s]
prediction: ['[CLS] s, that felt a frightful, benign no doubt vanity owed -max pays off film vanity debt owed vanity what circuit [SEP]']
[1350/2000] tot_loss=1.707 (perp=8.130, rec=0.080, cos=0.001), tot_loss_proj:2.916 [t=0.25s]
prediction: ['[CLS] s, that felt a frightful, benign no doubt vanity owed -max pays off film vanity debt owed vanity what circuit [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.760 (perp=8.373, rec=0.084, cos=0.001), tot_loss_proj:3.109 [t=0.19s]
prediction: ['[CLS] s, that felt a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.759 (perp=8.373, rec=0.083, cos=0.001), tot_loss_proj:3.109 [t=0.19s]
prediction: ['[CLS] s, that felt a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
[1500/2000] tot_loss=1.763 (perp=8.373, rec=0.087, cos=0.001), tot_loss_proj:3.112 [t=0.18s]
prediction: ['[CLS] s, that felt a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.767 (perp=8.373, rec=0.091, cos=0.001), tot_loss_proj:3.112 [t=0.30s]
prediction: ['[CLS] s, that felt a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.753 (perp=8.332, rec=0.086, cos=0.001), tot_loss_proj:3.002 [t=0.25s]
prediction: ['[CLS] s, felt that a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
[1650/2000] tot_loss=1.747 (perp=8.332, rec=0.080, cos=0.001), tot_loss_proj:3.005 [t=0.19s]
prediction: ['[CLS] s, felt that a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.760 (perp=8.332, rec=0.093, cos=0.001), tot_loss_proj:3.000 [t=0.19s]
prediction: ['[CLS] s, felt that a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.746 (perp=8.332, rec=0.078, cos=0.001), tot_loss_proj:3.002 [t=0.23s]
prediction: ['[CLS] s, felt that a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
[1800/2000] tot_loss=1.749 (perp=8.332, rec=0.082, cos=0.001), tot_loss_proj:3.001 [t=0.21s]
prediction: ['[CLS] s, felt that a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.754 (perp=8.332, rec=0.086, cos=0.001), tot_loss_proj:2.999 [t=0.19s]
prediction: ['[CLS] s, felt that a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.748 (perp=8.332, rec=0.080, cos=0.001), tot_loss_proj:3.001 [t=0.20s]
prediction: ['[CLS] s, felt that a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
[1950/2000] tot_loss=1.759 (perp=8.332, rec=0.092, cos=0.001), tot_loss_proj:3.002 [t=0.23s]
prediction: ['[CLS] s, felt that a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.750 (perp=8.332, rec=0.083, cos=0.001), tot_loss_proj:3.004 [t=0.19s]
prediction: ['[CLS] s, felt that a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] s, felt that a frightful, benign no doubt vanity owedlamax pays off film vanity vanity debt owed what circuit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.049 | p: 76.190 | r: 80.000
rouge2     | fm: 20.513 | p: 20.000 | r: 21.053
rougeL     | fm: 53.659 | p: 52.381 | r: 55.000
rougeLsum  | fm: 53.659 | p: 52.381 | r: 55.000
r1fm+r2fm = 98.562

[Aggregate metrics]:
rouge1     | fm: 94.531 | p: 93.973 | r: 95.132
rouge2     | fm: 80.586 | p: 80.505 | r: 80.673
rougeL     | fm: 87.275 | p: 86.980 | r: 87.593
rougeLsum  | fm: 87.275 | p: 86.980 | r: 87.593
r1fm+r2fm = 175.117

input #8 time: 0:08:38 | total time: 1:16:41


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9993981275486599
highest_index [0]
highest [0.9993981275486599]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.8187081217765808 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.7782889604568481 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7333240509033203 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.7192718386650085 for ['[CLS] owners pad there arena da rico weekly family [SEP]']
[Init] best rec loss: 0.6858556866645813 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6808661222457886 for ['[CLS] red sh dipped in outstretched hour go imagine [SEP]']
[Init] best rec loss: 0.6510923504829407 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6500662565231323 for ['[CLS] cody luck deaths outlaw decca arsenaldden edward [SEP]']
[Init] best perm rec loss: 0.6491195559501648 for ['[CLS]dden deaths arsenal luck decca outlaw cody edward [SEP]']
[Init] best perm rec loss: 0.648005485534668 for ['[CLS] outlaw deaths luckdden cody edward arsenal decca [SEP]']
[Init] best perm rec loss: 0.6462655663490295 for ['[CLS] decca cody luck edward deaths outlawdden arsenal [SEP]']
[Init] best perm rec loss: 0.6440391540527344 for ['[CLS] cody decca deaths arsenal luck edwarddden outlaw [SEP]']
[Init] best perm rec loss: 0.6436610221862793 for ['[CLS] cody decca outlaw luck arsenal edwarddden deaths [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.201 (perp=14.279, rec=0.296, cos=0.049), tot_loss_proj:3.739 [t=0.26s]
prediction: ['[CLS]melet garageheaddown metaphysicalcon drop [SEP]']
[ 100/2000] tot_loss=2.860 (perp=13.231, rec=0.200, cos=0.013), tot_loss_proj:3.323 [t=0.25s]
prediction: ['[CLS] of soft clapheadhead metaphysicaltratra [SEP]']
[ 150/2000] tot_loss=2.475 (perp=11.717, rec=0.120, cos=0.012), tot_loss_proj:2.876 [t=0.18s]
prediction: ['[CLS] of soft clapheadp metaphysicaltrap [SEP]']
[ 200/2000] tot_loss=2.145 (perp=10.300, rec=0.084, cos=0.001), tot_loss_proj:2.556 [t=0.18s]
prediction: ['[CLS] of soft clapheaded metaphysicaltrap [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.640 (perp=7.643, rec=0.106, cos=0.006), tot_loss_proj:1.620 [t=0.18s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
[ 300/2000] tot_loss=1.601 (perp=7.643, rec=0.071, cos=0.001), tot_loss_proj:1.616 [t=0.18s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.602 (perp=7.643, rec=0.072, cos=0.001), tot_loss_proj:1.615 [t=0.21s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.595 (perp=7.643, rec=0.065, cos=0.001), tot_loss_proj:1.604 [t=0.25s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
[ 450/2000] tot_loss=1.582 (perp=7.643, rec=0.052, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.593 (perp=7.643, rec=0.063, cos=0.001), tot_loss_proj:1.610 [t=0.19s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.548 (perp=7.384, rec=0.069, cos=0.002), tot_loss_proj:1.651 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 600/2000] tot_loss=1.542 (perp=7.384, rec=0.064, cos=0.001), tot_loss_proj:1.649 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.539 (perp=7.384, rec=0.061, cos=0.001), tot_loss_proj:1.656 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.536 (perp=7.384, rec=0.058, cos=0.001), tot_loss_proj:1.664 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 750/2000] tot_loss=1.528 (perp=7.384, rec=0.050, cos=0.001), tot_loss_proj:1.659 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.543 (perp=7.384, rec=0.065, cos=0.001), tot_loss_proj:1.657 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.534 (perp=7.384, rec=0.056, cos=0.001), tot_loss_proj:1.651 [t=0.26s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 900/2000] tot_loss=1.534 (perp=7.384, rec=0.056, cos=0.001), tot_loss_proj:1.663 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.547 (perp=7.384, rec=0.069, cos=0.001), tot_loss_proj:1.655 [t=0.20s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.536 (perp=7.384, rec=0.058, cos=0.001), tot_loss_proj:1.660 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1050/2000] tot_loss=1.541 (perp=7.384, rec=0.063, cos=0.001), tot_loss_proj:1.665 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.543 (perp=7.384, rec=0.065, cos=0.001), tot_loss_proj:1.649 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.541 (perp=7.384, rec=0.063, cos=0.001), tot_loss_proj:1.645 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1200/2000] tot_loss=1.545 (perp=7.384, rec=0.067, cos=0.001), tot_loss_proj:1.656 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.543 (perp=7.384, rec=0.065, cos=0.001), tot_loss_proj:1.654 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.532 (perp=7.384, rec=0.054, cos=0.001), tot_loss_proj:1.659 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1350/2000] tot_loss=1.555 (perp=7.384, rec=0.077, cos=0.001), tot_loss_proj:1.651 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.533 (perp=7.384, rec=0.055, cos=0.001), tot_loss_proj:1.656 [t=0.26s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.533 (perp=7.384, rec=0.055, cos=0.001), tot_loss_proj:1.657 [t=0.24s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1500/2000] tot_loss=1.548 (perp=7.384, rec=0.070, cos=0.001), tot_loss_proj:1.650 [t=0.21s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.546 (perp=7.384, rec=0.068, cos=0.001), tot_loss_proj:1.656 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.539 (perp=7.384, rec=0.061, cos=0.001), tot_loss_proj:1.654 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1650/2000] tot_loss=1.539 (perp=7.384, rec=0.061, cos=0.001), tot_loss_proj:1.660 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.542 (perp=7.384, rec=0.064, cos=0.001), tot_loss_proj:1.653 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.529 (perp=7.384, rec=0.051, cos=0.001), tot_loss_proj:1.646 [t=0.21s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1800/2000] tot_loss=1.539 (perp=7.384, rec=0.061, cos=0.001), tot_loss_proj:1.656 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.546 (perp=7.384, rec=0.068, cos=0.001), tot_loss_proj:1.649 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.542 (perp=7.384, rec=0.064, cos=0.001), tot_loss_proj:1.658 [t=0.24s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1950/2000] tot_loss=1.543 (perp=7.384, rec=0.065, cos=0.001), tot_loss_proj:1.654 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.538 (perp=7.384, rec=0.060, cos=0.001), tot_loss_proj:1.651 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical softheaded claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 95.078 | p: 94.576 | r: 95.619
rouge2     | fm: 76.527 | p: 76.455 | r: 76.605
rougeL     | fm: 87.398 | p: 87.143 | r: 87.667
rougeLsum  | fm: 87.398 | p: 87.143 | r: 87.667
r1fm+r2fm = 171.605

input #9 time: 0:08:08 | total time: 1:24:50


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9991472052153934
highest_index [0]
highest [0.9991472052153934]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8814778923988342 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8704736828804016 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8242684602737427 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 0.8198046684265137 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.8065224885940552 for ['[CLS] hidelin swing reacher immediately championship nervous accompaniedcar eva pounded besides help [SEP]']
[Init] best perm rec loss: 0.8059665560722351 for ['[CLS] help reachercar hid championship immediately besideselin accompanied eva nervous pounded swing [SEP]']
[Init] best perm rec loss: 0.8049544095993042 for ['[CLS] help nervouscarelin besides reacher championship swing pounded hid immediately accompanied eva [SEP]']
[Init] best perm rec loss: 0.8048099279403687 for ['[CLS] hid helpcar pounded eva immediately besideselin swing reacher championship accompanied nervous [SEP]']
[Init] best perm rec loss: 0.8033286333084106 for ['[CLS] besides nervous immediately eva hid swing pounded reacherelincar accompanied help championship [SEP]']
[Init] best perm rec loss: 0.8032909035682678 for ['[CLS]car championship hid accompanied reacher swing evaelin immediately nervous help pounded besides [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.802 (perp=12.314, rec=0.326, cos=0.014), tot_loss_proj:4.293 [t=0.18s]
prediction: ['[CLS] sleep solo about. dianawoman iv jean characteristics taylor balance. purposely [SEP]']
[ 100/2000] tot_loss=2.639 (perp=11.967, rec=0.237, cos=0.009), tot_loss_proj:3.848 [t=0.21s]
prediction: ['[CLS] ab solo based. cycleswoman eva day rhythms taylor balance.ly [SEP]']
[ 150/2000] tot_loss=2.302 (perp=10.498, rec=0.198, cos=0.005), tot_loss_proj:3.399 [t=0.26s]
prediction: ['[CLS] ably based. period incidentious day rhythms - balance. ab [SEP]']
[ 200/2000] tot_loss=2.161 (perp=9.983, rec=0.159, cos=0.006), tot_loss_proj:3.125 [t=0.22s]
prediction: ['[CLS] ably baseds period incident with day rhythms ; balance. ab [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.246 (perp=10.206, rec=0.197, cos=0.008), tot_loss_proj:3.390 [t=0.20s]
prediction: ['[CLS] ably based. ab perspective incident with? rhythms ; balanceulsive [SEP]']
[ 300/2000] tot_loss=2.330 (perp=10.908, rec=0.144, cos=0.004), tot_loss_proj:3.800 [t=0.24s]
prediction: ['[CLS]lyly based. ab real incident with day rhythms incident balance incident [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.488 (perp=11.349, rec=0.212, cos=0.006), tot_loss_proj:3.272 [t=0.19s]
prediction: ['[CLS]lylyulsive aurora ab real occurring with shots rhythms. balance. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.051 (perp=9.393, rec=0.167, cos=0.005), tot_loss_proj:2.656 [t=0.20s]
prediction: ['[CLS]lyly aurora abulsive real time withulsive rhythms. balance. [SEP]']
[ 450/2000] tot_loss=1.849 (perp=8.504, rec=0.145, cos=0.003), tot_loss_proj:2.473 [t=0.19s]
prediction: ['[CLS]lyly. abulsive real time with incident rhythms. balance. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.672 (perp=7.650, rec=0.138, cos=0.004), tot_loss_proj:2.220 [t=0.18s]
prediction: ['[CLS]lyly balance abulsive real time with incident rhythms... [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.622 (perp=7.403, rec=0.137, cos=0.003), tot_loss_proj:2.023 [t=0.19s]
prediction: ['[CLS]ly ably balanceulsive real time with incident rhythms... [SEP]']
[ 600/2000] tot_loss=1.612 (perp=7.403, rec=0.128, cos=0.003), tot_loss_proj:2.023 [t=0.18s]
prediction: ['[CLS]ly ably balanceulsive real time with incident rhythms... [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.523 (perp=7.014, rec=0.117, cos=0.003), tot_loss_proj:1.942 [t=0.19s]
prediction: ['[CLS] ably balanceulsively real time with incident rhythms... [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.463 (perp=6.692, rec=0.122, cos=0.003), tot_loss_proj:1.937 [t=0.18s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
[ 750/2000] tot_loss=1.454 (perp=6.692, rec=0.113, cos=0.003), tot_loss_proj:1.941 [t=0.27s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.461 (perp=6.692, rec=0.120, cos=0.003), tot_loss_proj:1.938 [t=0.25s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.463 (perp=6.692, rec=0.121, cos=0.003), tot_loss_proj:1.939 [t=0.24s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
[ 900/2000] tot_loss=1.458 (perp=6.692, rec=0.117, cos=0.003), tot_loss_proj:1.940 [t=0.19s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.452 (perp=6.692, rec=0.111, cos=0.003), tot_loss_proj:1.949 [t=0.18s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
[1000/2000] tot_loss=1.441 (perp=6.692, rec=0.100, cos=0.003), tot_loss_proj:1.949 [t=0.18s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
[1050/2000] tot_loss=1.457 (perp=6.692, rec=0.116, cos=0.003), tot_loss_proj:1.960 [t=0.19s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
[1100/2000] tot_loss=1.450 (perp=6.692, rec=0.110, cos=0.003), tot_loss_proj:1.943 [t=0.19s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.432 (perp=6.692, rec=0.092, cos=0.003), tot_loss_proj:1.943 [t=0.25s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
[1200/2000] tot_loss=1.448 (perp=6.692, rec=0.107, cos=0.002), tot_loss_proj:1.939 [t=0.20s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
[1250/2000] tot_loss=1.453 (perp=6.692, rec=0.112, cos=0.002), tot_loss_proj:1.947 [t=0.23s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.439 (perp=6.692, rec=0.099, cos=0.003), tot_loss_proj:1.943 [t=0.27s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
[1350/2000] tot_loss=1.448 (perp=6.692, rec=0.107, cos=0.002), tot_loss_proj:1.946 [t=0.18s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.447 (perp=6.692, rec=0.107, cos=0.002), tot_loss_proj:1.934 [t=0.19s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
[1450/2000] tot_loss=1.439 (perp=6.692, rec=0.098, cos=0.002), tot_loss_proj:1.929 [t=0.24s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
[1500/2000] tot_loss=1.445 (perp=6.692, rec=0.105, cos=0.002), tot_loss_proj:1.946 [t=0.19s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
[1550/2000] tot_loss=1.440 (perp=6.692, rec=0.100, cos=0.002), tot_loss_proj:1.943 [t=0.18s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
[1600/2000] tot_loss=1.455 (perp=6.692, rec=0.114, cos=0.002), tot_loss_proj:1.941 [t=0.19s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
[1650/2000] tot_loss=1.433 (perp=6.692, rec=0.092, cos=0.002), tot_loss_proj:1.935 [t=0.18s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.448 (perp=6.692, rec=0.107, cos=0.002), tot_loss_proj:1.941 [t=0.22s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
[1750/2000] tot_loss=1.441 (perp=6.692, rec=0.100, cos=0.003), tot_loss_proj:1.950 [t=0.19s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
[1800/2000] tot_loss=1.441 (perp=6.692, rec=0.101, cos=0.003), tot_loss_proj:1.941 [t=0.20s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.439 (perp=6.692, rec=0.098, cos=0.003), tot_loss_proj:1.936 [t=0.20s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
[1900/2000] tot_loss=1.435 (perp=6.692, rec=0.094, cos=0.003), tot_loss_proj:1.932 [t=0.20s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
[1950/2000] tot_loss=1.437 (perp=6.692, rec=0.096, cos=0.003), tot_loss_proj:1.942 [t=0.19s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.441 (perp=6.692, rec=0.100, cos=0.003), tot_loss_proj:1.953 [t=0.22s]
prediction: ['[CLS] balance ablyulsively real time with incident rhythms... [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] balance ablyulsively real time with incident rhythms... [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 77.778 | r: 70.000
rouge2     | fm: 11.765 | p: 12.500 | r: 11.111
rougeL     | fm: 63.158 | p: 66.667 | r: 60.000
rougeLsum  | fm: 63.158 | p: 66.667 | r: 60.000
r1fm+r2fm = 85.449

[Aggregate metrics]:
rouge1     | fm: 93.133 | p: 93.193 | r: 93.290
rouge2     | fm: 71.277 | p: 71.322 | r: 71.207
rougeL     | fm: 85.043 | p: 85.018 | r: 84.697
rougeLsum  | fm: 85.195 | p: 85.173 | r: 85.000
r1fm+r2fm = 164.409

input #10 time: 0:08:14 | total time: 1:33:05


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9992849825911105
highest_index [0]
highest [0.9992849825911105]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.9119930863380432 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.9002856016159058 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.8241632580757141 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.8143832683563232 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.8102236986160278 for ['[CLS]ture inlandvd tal me platform drawngu mile familiar [SEP]']
[Init] best perm rec loss: 0.8092162609100342 for ['[CLS] inlandture drawngu platform tal familiar mevd mile [SEP]']
[Init] best perm rec loss: 0.8080193400382996 for ['[CLS] inland mevdgu mile tal drawn familiarture platform [SEP]']
[Init] best perm rec loss: 0.8064080476760864 for ['[CLS] inland me milevd platformture familiar talgu drawn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.486 (perp=10.735, rec=0.322, cos=0.017), tot_loss_proj:3.503 [t=0.18s]
prediction: ['[CLS] that attempted gel that pop refused refused gel opinion refused [SEP]']
[ 100/2000] tot_loss=2.610 (perp=11.878, rec=0.223, cos=0.012), tot_loss_proj:3.698 [t=0.18s]
prediction: ['[CLS] was attempted gelly stubborn refused refused gel stubborn refused [SEP]']
[ 150/2000] tot_loss=2.066 (perp=9.680, rec=0.127, cos=0.002), tot_loss_proj:2.948 [t=0.18s]
prediction: ['[CLS] was attempted gel that stubbornly refused gel here refused [SEP]']
[ 200/2000] tot_loss=2.045 (perp=9.680, rec=0.106, cos=0.003), tot_loss_proj:2.946 [t=0.18s]
prediction: ['[CLS] was attempted gel that stubbornly refused gel here refused [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.951 (perp=9.283, rec=0.093, cos=0.002), tot_loss_proj:2.941 [t=0.19s]
prediction: ['[CLS] was attempted gel that stubbornly refused gel refused here [SEP]']
[ 300/2000] tot_loss=1.733 (perp=8.254, rec=0.081, cos=0.001), tot_loss_proj:2.423 [t=0.19s]
prediction: ['[CLS] was attempted gel that stubbornly refused gel to here [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.684 (perp=8.034, rec=0.076, cos=0.001), tot_loss_proj:2.475 [t=0.25s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.690 (perp=8.034, rec=0.081, cos=0.001), tot_loss_proj:2.473 [t=0.19s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
[ 450/2000] tot_loss=1.682 (perp=8.034, rec=0.074, cos=0.001), tot_loss_proj:2.466 [t=0.23s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.676 (perp=8.034, rec=0.068, cos=0.001), tot_loss_proj:2.466 [t=0.18s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.690 (perp=8.034, rec=0.082, cos=0.001), tot_loss_proj:2.471 [t=0.24s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
[ 600/2000] tot_loss=1.688 (perp=8.034, rec=0.080, cos=0.001), tot_loss_proj:2.473 [t=0.18s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.689 (perp=8.034, rec=0.081, cos=0.001), tot_loss_proj:2.474 [t=0.18s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.686 (perp=8.034, rec=0.077, cos=0.001), tot_loss_proj:2.478 [t=0.18s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
[ 750/2000] tot_loss=1.688 (perp=8.034, rec=0.080, cos=0.001), tot_loss_proj:2.476 [t=0.19s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.682 (perp=8.034, rec=0.074, cos=0.001), tot_loss_proj:2.475 [t=0.25s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.693 (perp=8.034, rec=0.085, cos=0.001), tot_loss_proj:2.475 [t=0.19s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
[ 900/2000] tot_loss=1.685 (perp=8.034, rec=0.076, cos=0.001), tot_loss_proj:2.482 [t=0.19s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.682 (perp=8.034, rec=0.074, cos=0.001), tot_loss_proj:2.472 [t=0.19s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
Attempt swap
[1000/2000] tot_loss=1.687 (perp=8.034, rec=0.079, cos=0.001), tot_loss_proj:2.479 [t=0.24s]
prediction: ['[CLS] attempted was gel that stubbornly refused gel to here [SEP]']
[1050/2000] tot_loss=1.828 (perp=8.774, rec=0.072, cos=0.001), tot_loss_proj:2.475 [t=0.19s]
prediction: ['[CLS] attempted was being that stubbornly refused gel to here [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.576 (perp=7.461, rec=0.083, cos=0.001), tot_loss_proj:2.123 [t=0.19s]
prediction: ['[CLS] that attempted was being stubbornly refused gel to here [SEP]']
Attempt swap
[1150/2000] tot_loss=1.569 (perp=7.461, rec=0.075, cos=0.001), tot_loss_proj:2.121 [t=0.19s]
prediction: ['[CLS] that attempted was being stubbornly refused gel to here [SEP]']
[1200/2000] tot_loss=1.569 (perp=7.461, rec=0.076, cos=0.001), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] that attempted was being stubbornly refused gel to here [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.471 (perp=6.981, rec=0.073, cos=0.001), tot_loss_proj:1.800 [t=0.21s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Attempt swap
[1300/2000] tot_loss=1.469 (perp=6.981, rec=0.071, cos=0.001), tot_loss_proj:1.803 [t=0.21s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
[1350/2000] tot_loss=1.468 (perp=6.981, rec=0.071, cos=0.001), tot_loss_proj:1.802 [t=0.18s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Attempt swap
[1400/2000] tot_loss=1.470 (perp=6.981, rec=0.073, cos=0.001), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Attempt swap
[1450/2000] tot_loss=1.471 (perp=6.981, rec=0.074, cos=0.001), tot_loss_proj:1.803 [t=0.19s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
[1500/2000] tot_loss=1.468 (perp=6.981, rec=0.071, cos=0.001), tot_loss_proj:1.798 [t=0.19s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Attempt swap
[1550/2000] tot_loss=1.469 (perp=6.981, rec=0.072, cos=0.001), tot_loss_proj:1.811 [t=0.19s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Attempt swap
[1600/2000] tot_loss=1.459 (perp=6.981, rec=0.062, cos=0.001), tot_loss_proj:1.804 [t=0.18s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
[1650/2000] tot_loss=1.477 (perp=6.981, rec=0.080, cos=0.001), tot_loss_proj:1.800 [t=0.23s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Attempt swap
[1700/2000] tot_loss=1.459 (perp=6.981, rec=0.062, cos=0.001), tot_loss_proj:1.800 [t=0.20s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Attempt swap
[1750/2000] tot_loss=1.468 (perp=6.981, rec=0.070, cos=0.001), tot_loss_proj:1.806 [t=0.19s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
[1800/2000] tot_loss=1.464 (perp=6.981, rec=0.066, cos=0.001), tot_loss_proj:1.809 [t=0.21s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Attempt swap
[1850/2000] tot_loss=1.469 (perp=6.981, rec=0.071, cos=0.001), tot_loss_proj:1.802 [t=0.22s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Attempt swap
[1900/2000] tot_loss=1.459 (perp=6.981, rec=0.061, cos=0.001), tot_loss_proj:1.794 [t=0.19s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
[1950/2000] tot_loss=1.463 (perp=6.981, rec=0.066, cos=0.001), tot_loss_proj:1.806 [t=0.18s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Attempt swap
[2000/2000] tot_loss=1.468 (perp=6.981, rec=0.071, cos=0.001), tot_loss_proj:1.806 [t=0.20s]
prediction: ['[CLS] that attempted was being stubbornly refused to gel here [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] that attempted was being stubbornly refused to gel here [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 93.705 | p: 93.760 | r: 94.048
rouge2     | fm: 68.670 | p: 68.712 | r: 68.606
rougeL     | fm: 83.725 | p: 83.795 | r: 83.750
rougeLsum  | fm: 84.316 | p: 84.239 | r: 84.167
r1fm+r2fm = 162.375

input #11 time: 0:08:06 | total time: 1:41:11


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.99934391763152
highest_index [0]
highest [0.99934391763152]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.867132842540741 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.861339807510376 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 0.799628496170044 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7725229263305664 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7675877213478088 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.743887186050415 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best perm rec loss: 0.7403388023376465 for ['[CLS] ha guess shades margin office series bethitasyn few victor laynction translate [SEP]']
[Init] best perm rec loss: 0.7387611269950867 for ['[CLS] guess beth ha few series shadesitas translate office marginnction layyn victor [SEP]']
[Init] best perm rec loss: 0.7375137805938721 for ['[CLS]nction translate few victor beth office margin series shades haitas guessyn lay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.245 (perp=9.694, rec=0.282, cos=0.024), tot_loss_proj:2.846 [t=0.23s]
prediction: ['[CLS] cable cable barely better for better advantage off passed no cable theory no worse [SEP]']
[ 100/2000] tot_loss=2.171 (perp=9.841, rec=0.191, cos=0.011), tot_loss_proj:2.798 [t=0.25s]
prediction: ['[CLS] cable cable barely better is seen advantage on considering barely cable barely no advantage [SEP]']
[ 150/2000] tot_loss=1.889 (perp=8.731, rec=0.139, cos=0.004), tot_loss_proj:2.725 [t=0.19s]
prediction: ['[CLS] cable seen barely better will seen advantage on considering its cable barely barely better [SEP]']
[ 200/2000] tot_loss=2.097 (perp=9.866, rec=0.121, cos=0.003), tot_loss_proj:3.161 [t=0.23s]
prediction: ['[CLS] cable considering that better will seen advantage on considering its cable although barely barely [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.895 (perp=8.885, rec=0.114, cos=0.003), tot_loss_proj:2.616 [t=0.19s]
prediction: ['[CLS] although considering that better will seen advantage on considering its cable cable barely barely [SEP]']
[ 300/2000] tot_loss=2.056 (perp=9.754, rec=0.103, cos=0.002), tot_loss_proj:2.928 [t=0.19s]
prediction: ['[CLS] although especially that better will seen advantage on considering its cable cable barely especially [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.974 (perp=9.379, rec=0.096, cos=0.002), tot_loss_proj:2.670 [t=0.23s]
prediction: ['[CLS] although especially that seen will better advantage on considering its cable cable barely especially [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.871 (perp=8.909, rec=0.087, cos=0.002), tot_loss_proj:2.579 [t=0.20s]
prediction: ['[CLS] although that especially seen will better advantage on considering its cable cable barely especially [SEP]']
[ 450/2000] tot_loss=1.872 (perp=8.909, rec=0.088, cos=0.002), tot_loss_proj:2.573 [t=0.22s]
prediction: ['[CLS] although that especially seen will better advantage on considering its cable cable barely especially [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.862 (perp=8.909, rec=0.078, cos=0.002), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS] although that especially seen will better advantage on considering its cable cable barely especially [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.879 (perp=8.777, rec=0.118, cos=0.006), tot_loss_proj:2.481 [t=0.19s]
prediction: ['[CLS] estimate that especially seen will better advantage on considering its cable cable barely even [SEP]']
[ 600/2000] tot_loss=1.826 (perp=8.631, rec=0.097, cos=0.002), tot_loss_proj:2.588 [t=0.19s]
prediction: ['[CLS] estimate that especially seen will better advantage on considering its cable cable barely, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.840 (perp=8.699, rec=0.097, cos=0.002), tot_loss_proj:2.522 [t=0.19s]
prediction: ['[CLS] especially that especially seen will better advantage on considering its cable cable the barely [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.751 (perp=8.276, rec=0.094, cos=0.003), tot_loss_proj:2.304 [t=0.19s]
prediction: ['[CLS] especially that especially seen will better advantage on cable cable, considering its barely [SEP]']
[ 750/2000] tot_loss=1.751 (perp=8.276, rec=0.094, cos=0.002), tot_loss_proj:2.307 [t=0.24s]
prediction: ['[CLS] especially that especially seen will better advantage on cable cable, considering its barely [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.694 (perp=7.984, rec=0.095, cos=0.002), tot_loss_proj:2.180 [t=0.23s]
prediction: ['[CLS] by that seen will better advantage on cable cable, especially considering its barely [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.553 (perp=7.276, rec=0.096, cos=0.002), tot_loss_proj:2.038 [t=0.23s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
[ 900/2000] tot_loss=1.540 (perp=7.276, rec=0.083, cos=0.002), tot_loss_proj:2.027 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.547 (perp=7.276, rec=0.090, cos=0.002), tot_loss_proj:2.028 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.544 (perp=7.276, rec=0.087, cos=0.002), tot_loss_proj:2.026 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
[1050/2000] tot_loss=1.547 (perp=7.276, rec=0.090, cos=0.002), tot_loss_proj:2.027 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.545 (perp=7.276, rec=0.088, cos=0.002), tot_loss_proj:2.028 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.540 (perp=7.276, rec=0.083, cos=0.002), tot_loss_proj:2.030 [t=0.22s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
[1200/2000] tot_loss=1.544 (perp=7.276, rec=0.087, cos=0.002), tot_loss_proj:2.025 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.542 (perp=7.276, rec=0.085, cos=0.002), tot_loss_proj:2.020 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.546 (perp=7.276, rec=0.089, cos=0.002), tot_loss_proj:2.026 [t=0.24s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
[1350/2000] tot_loss=1.543 (perp=7.276, rec=0.086, cos=0.002), tot_loss_proj:2.030 [t=0.18s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.543 (perp=7.276, rec=0.086, cos=0.002), tot_loss_proj:2.022 [t=0.25s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.547 (perp=7.276, rec=0.090, cos=0.002), tot_loss_proj:2.027 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
[1500/2000] tot_loss=1.543 (perp=7.276, rec=0.086, cos=0.002), tot_loss_proj:2.029 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.549 (perp=7.276, rec=0.092, cos=0.002), tot_loss_proj:2.027 [t=0.24s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.545 (perp=7.276, rec=0.088, cos=0.002), tot_loss_proj:2.025 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
[1650/2000] tot_loss=1.538 (perp=7.276, rec=0.081, cos=0.002), tot_loss_proj:2.021 [t=0.26s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.530 (perp=7.276, rec=0.073, cos=0.002), tot_loss_proj:2.026 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.538 (perp=7.276, rec=0.081, cos=0.002), tot_loss_proj:2.021 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
[1800/2000] tot_loss=1.535 (perp=7.276, rec=0.078, cos=0.002), tot_loss_proj:2.024 [t=0.19s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.546 (perp=7.276, rec=0.089, cos=0.002), tot_loss_proj:2.026 [t=0.23s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.543 (perp=7.276, rec=0.086, cos=0.002), tot_loss_proj:2.027 [t=0.18s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
[1950/2000] tot_loss=1.539 (perp=7.276, rec=0.082, cos=0.002), tot_loss_proj:2.020 [t=0.22s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.545 (perp=7.276, rec=0.088, cos=0.002), tot_loss_proj:2.031 [t=0.23s]
prediction: ['[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] by that seen cable will better advantage on cable, especially considering its barely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.667 | p: 86.667 | r: 86.667
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 143.810

[Aggregate metrics]:
rouge1     | fm: 93.164 | p: 93.092 | r: 93.333
rouge2     | fm: 67.797 | p: 67.822 | r: 67.794
rougeL     | fm: 83.764 | p: 83.849 | r: 83.671
rougeLsum  | fm: 83.604 | p: 83.700 | r: 83.607
r1fm+r2fm = 160.961

input #12 time: 0:08:12 | total time: 1:49:24


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9992538394516878
highest_index [0]
highest [0.9992538394516878]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8887738585472107 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8844950199127197 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.8545551896095276 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7818396091461182 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7813502550125122 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 0.7700784802436829 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 0.7579190731048584 for ['[CLS]typic malice avenue andy rightart brought [SEP]']
[Init] best rec loss: 0.7517123222351074 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best rec loss: 0.7473309636116028 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best perm rec loss: 0.7472784519195557 for ['[CLS] permanent defeat arm cardinal roweional precision [SEP]']
[Init] best perm rec loss: 0.7453463077545166 for ['[CLS] cardinal arm defeat rowe permanent precisionional [SEP]']
[Init] best perm rec loss: 0.7436425089836121 for ['[CLS]ional precision arm cardinal permanent rowe defeat [SEP]']
[Init] best perm rec loss: 0.7426804900169373 for ['[CLS] rowe cardinal defeat armional permanent precision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.005 (perp=8.566, rec=0.266, cos=0.026), tot_loss_proj:3.015 [t=0.21s]
prediction: ['[CLS] to explosion flame flame at fires point [SEP]']
[ 100/2000] tot_loss=2.325 (perp=10.733, rec=0.169, cos=0.009), tot_loss_proj:3.355 [t=0.19s]
prediction: ['[CLS] at explode flame things into fires point [SEP]']
[ 150/2000] tot_loss=2.272 (perp=10.733, rec=0.121, cos=0.005), tot_loss_proj:3.339 [t=0.18s]
prediction: ['[CLS] at explode flame things into fires point [SEP]']
[ 200/2000] tot_loss=2.152 (perp=10.276, rec=0.094, cos=0.003), tot_loss_proj:3.024 [t=0.19s]
prediction: ['[CLS] at explode flame things into flame point [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.963 (perp=9.183, rec=0.120, cos=0.006), tot_loss_proj:2.648 [t=0.19s]
prediction: ['[CLS] at point flame things into these explode [SEP]']
[ 300/2000] tot_loss=1.995 (perp=9.468, rec=0.099, cos=0.002), tot_loss_proj:2.724 [t=0.21s]
prediction: ['[CLS] at point flame things into thing explode [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.889 (perp=9.005, rec=0.086, cos=0.002), tot_loss_proj:2.735 [t=0.25s]
prediction: ['[CLS] at point flame things explode into code [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.883 (perp=8.927, rec=0.094, cos=0.003), tot_loss_proj:2.537 [t=0.24s]
prediction: ['[CLS] at point things things explode into flame [SEP]']
[ 450/2000] tot_loss=1.876 (perp=8.927, rec=0.089, cos=0.002), tot_loss_proj:2.529 [t=0.19s]
prediction: ['[CLS] at point things things explode into flame [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.735 (perp=8.257, rec=0.082, cos=0.002), tot_loss_proj:2.505 [t=0.19s]
prediction: ['[CLS] at things point things explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.726 (perp=8.257, rec=0.073, cos=0.002), tot_loss_proj:2.499 [t=0.19s]
prediction: ['[CLS] at things point things explode into flame [SEP]']
[ 600/2000] tot_loss=1.741 (perp=8.307, rec=0.077, cos=0.002), tot_loss_proj:2.502 [t=0.19s]
prediction: ['[CLS] at thing point things explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.742 (perp=8.307, rec=0.079, cos=0.002), tot_loss_proj:2.499 [t=0.18s]
prediction: ['[CLS] at thing point things explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.736 (perp=8.307, rec=0.073, cos=0.002), tot_loss_proj:2.499 [t=0.23s]
prediction: ['[CLS] at thing point things explode into flame [SEP]']
[ 750/2000] tot_loss=1.741 (perp=8.307, rec=0.077, cos=0.002), tot_loss_proj:2.498 [t=0.19s]
prediction: ['[CLS] at thing point things explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.736 (perp=8.307, rec=0.072, cos=0.002), tot_loss_proj:2.498 [t=0.18s]
prediction: ['[CLS] at thing point things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.752 (perp=8.307, rec=0.089, cos=0.002), tot_loss_proj:2.496 [t=0.19s]
prediction: ['[CLS] at thing point things explode into flame [SEP]']
[ 900/2000] tot_loss=1.740 (perp=8.307, rec=0.077, cos=0.002), tot_loss_proj:2.499 [t=0.18s]
prediction: ['[CLS] at thing point things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.737 (perp=8.307, rec=0.073, cos=0.002), tot_loss_proj:2.493 [t=0.18s]
prediction: ['[CLS] at thing point things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.742 (perp=8.307, rec=0.078, cos=0.002), tot_loss_proj:2.490 [t=0.19s]
prediction: ['[CLS] at thing point things explode into flame [SEP]']
[1050/2000] tot_loss=1.371 (perp=6.423, rec=0.084, cos=0.002), tot_loss_proj:2.105 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.369 (perp=6.423, rec=0.083, cos=0.002), tot_loss_proj:2.114 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.370 (perp=6.423, rec=0.083, cos=0.002), tot_loss_proj:2.114 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1200/2000] tot_loss=1.360 (perp=6.423, rec=0.074, cos=0.002), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.373 (perp=6.423, rec=0.087, cos=0.002), tot_loss_proj:2.111 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.373 (perp=6.423, rec=0.086, cos=0.002), tot_loss_proj:2.109 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1350/2000] tot_loss=1.373 (perp=6.423, rec=0.086, cos=0.002), tot_loss_proj:2.119 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.352 (perp=6.423, rec=0.066, cos=0.002), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.372 (perp=6.423, rec=0.086, cos=0.002), tot_loss_proj:2.114 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1500/2000] tot_loss=1.366 (perp=6.423, rec=0.080, cos=0.002), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.369 (perp=6.423, rec=0.083, cos=0.002), tot_loss_proj:2.112 [t=0.23s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.365 (perp=6.423, rec=0.079, cos=0.002), tot_loss_proj:2.116 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1650/2000] tot_loss=1.367 (perp=6.423, rec=0.080, cos=0.002), tot_loss_proj:2.121 [t=0.20s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.365 (perp=6.423, rec=0.079, cos=0.002), tot_loss_proj:2.112 [t=0.23s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.368 (perp=6.423, rec=0.081, cos=0.002), tot_loss_proj:2.119 [t=0.18s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1800/2000] tot_loss=1.360 (perp=6.423, rec=0.074, cos=0.002), tot_loss_proj:2.107 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.366 (perp=6.423, rec=0.079, cos=0.002), tot_loss_proj:2.111 [t=0.29s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.369 (perp=6.423, rec=0.082, cos=0.002), tot_loss_proj:2.110 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1950/2000] tot_loss=1.364 (perp=6.423, rec=0.077, cos=0.002), tot_loss_proj:2.112 [t=0.26s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.369 (perp=6.423, rec=0.083, cos=0.002), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at that point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 93.674 | p: 93.699 | r: 93.810
rouge2     | fm: 65.195 | p: 65.188 | r: 65.208
rougeL     | fm: 83.283 | p: 83.271 | r: 83.171
rougeLsum  | fm: 83.294 | p: 83.459 | r: 83.313
r1fm+r2fm = 158.869

input #13 time: 0:08:20 | total time: 1:57:44


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9993219682705545
highest_index [0]
highest [0.9993219682705545]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9556125998497009 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9368494749069214 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9233089089393616 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9153460264205933 for ['[CLS] bar these catch arms state [SEP]']
[Init] best rec loss: 0.9128281474113464 for ['[CLS] models cordytness gun [SEP]']
[Init] best rec loss: 0.8928517699241638 for ['[CLS] return him always kolkata frame [SEP]']
[Init] best rec loss: 0.8734212517738342 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8720963597297668 for ['[CLS] myers sprayed harold [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8720387816429138 for ['[CLS] [MASK] harold sprayed tom myers [SEP]']
[Init] best perm rec loss: 0.8698037266731262 for ['[CLS] tom [MASK] harold myers sprayed [SEP]']
[Init] best perm rec loss: 0.8688009977340698 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.287 (perp=10.237, rec=0.236, cos=0.004), tot_loss_proj:2.414 [t=0.21s]
prediction: ['[CLS] interestingbly intriguing film intriguing [SEP]']
[ 100/2000] tot_loss=3.084 (perp=14.666, rec=0.148, cos=0.002), tot_loss_proj:3.714 [t=0.18s]
prediction: ['[CLS] intriguingblyenia film intriguing [SEP]']
[ 150/2000] tot_loss=3.064 (perp=14.666, rec=0.129, cos=0.002), tot_loss_proj:3.725 [t=0.20s]
prediction: ['[CLS] intriguingblyenia film intriguing [SEP]']
[ 200/2000] tot_loss=3.037 (perp=14.666, rec=0.102, cos=0.002), tot_loss_proj:3.744 [t=0.20s]
prediction: ['[CLS] intriguingblyenia film intriguing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.960 (perp=9.271, rec=0.104, cos=0.002), tot_loss_proj:2.144 [t=0.26s]
prediction: ['[CLS] intriguing filmeniably intriguing [SEP]']
[ 300/2000] tot_loss=1.947 (perp=9.271, rec=0.091, cos=0.002), tot_loss_proj:2.133 [t=0.20s]
prediction: ['[CLS] intriguing filmeniably intriguing [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.439 (perp=6.728, rec=0.092, cos=0.002), tot_loss_proj:1.404 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.421 (perp=6.728, rec=0.074, cos=0.001), tot_loss_proj:1.404 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.408 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.406 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.420 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.402 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.396 (perp=6.728, rec=0.049, cos=0.001), tot_loss_proj:1.414 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.415 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.416 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.410 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.398 (perp=6.728, rec=0.051, cos=0.001), tot_loss_proj:1.409 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.404 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.416 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.402 (perp=6.728, rec=0.055, cos=0.001), tot_loss_proj:1.413 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.406 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.407 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.412 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.412 [t=0.21s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.411 [t=0.21s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.409 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.412 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.418 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.404 [t=0.21s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.407 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.406 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.392 (perp=6.728, rec=0.045, cos=0.001), tot_loss_proj:1.412 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.407 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.412 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.402 (perp=6.728, rec=0.055, cos=0.001), tot_loss_proj:1.407 [t=0.21s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.413 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.404 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.409 [t=0.26s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.412 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.406 [t=0.21s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.366 | p: 94.355 | r: 94.413
rouge2     | fm: 67.959 | p: 67.958 | r: 67.889
rougeL     | fm: 84.341 | p: 84.397 | r: 84.313
rougeLsum  | fm: 84.407 | p: 84.488 | r: 84.293
r1fm+r2fm = 162.325

input #14 time: 0:08:20 | total time: 2:06:04


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9992724874303516
highest_index [0]
highest [0.9992724874303516]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9709395170211792 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.9276955127716064 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 0.9179652333259583 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.9067785143852234 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.9063056707382202 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8998844623565674 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8911759257316589 for ['[CLS]che carolezard multi zone rhythmic watervating [SEP]']
[Init] best rec loss: 0.8846814036369324 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8817172050476074 for ['[CLS] 0 humanities metaphor olivia easily fetch first sweden [SEP]']
[Init] best perm rec loss: 0.8800804018974304 for ['[CLS] easily first olivia metaphor fetch 0 humanities sweden [SEP]']
[Init] best perm rec loss: 0.879218578338623 for ['[CLS] easily sweden humanities first olivia 0 fetch metaphor [SEP]']
[Init] best perm rec loss: 0.879126250743866 for ['[CLS] easily sweden humanities 0 olivia first fetch metaphor [SEP]']
[Init] best perm rec loss: 0.8768956065177917 for ['[CLS] fetch humanities first 0 sweden olivia easily metaphor [SEP]']
[Init] best perm rec loss: 0.8764843344688416 for ['[CLS] 0 first humanities sweden olivia metaphor easily fetch [SEP]']
[Init] best perm rec loss: 0.8753165006637573 for ['[CLS] 0 sweden fetch metaphor humanities olivia first easily [SEP]']
[Init] best perm rec loss: 0.8751561641693115 for ['[CLS] metaphor 0 first humanities sweden olivia easily fetch [SEP]']
[Init] best perm rec loss: 0.8732092976570129 for ['[CLS] metaphor first sweden fetch 0 easily olivia humanities [SEP]']
[Init] best perm rec loss: 0.8722246885299683 for ['[CLS] first easily 0 sweden metaphor olivia humanities fetch [SEP]']
[Init] best perm rec loss: 0.8716493844985962 for ['[CLS] metaphor humanities first sweden olivia fetch easily 0 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.758 (perp=12.464, rec=0.255, cos=0.010), tot_loss_proj:3.043 [t=0.20s]
prediction: ['[CLS] efficient hip efficientably efficient chill creative suit [SEP]']
[ 100/2000] tot_loss=2.692 (perp=12.504, rec=0.187, cos=0.005), tot_loss_proj:3.266 [t=0.19s]
prediction: ['[CLS] efficient hipablyably efficient chill efficienter [SEP]']
[ 150/2000] tot_loss=2.654 (perp=12.504, rec=0.150, cos=0.004), tot_loss_proj:3.272 [t=0.20s]
prediction: ['[CLS] efficient hipablyably efficient chill efficienter [SEP]']
[ 200/2000] tot_loss=2.579 (perp=12.281, rec=0.119, cos=0.003), tot_loss_proj:2.957 [t=0.18s]
prediction: ['[CLS]. hipably suit efficient chill anonymouser [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.215 (perp=10.600, rec=0.093, cos=0.002), tot_loss_proj:2.541 [t=0.18s]
prediction: ['[CLS], suitably anonymous efficient chill anonymouser [SEP]']
[ 300/2000] tot_loss=2.210 (perp=10.600, rec=0.089, cos=0.002), tot_loss_proj:2.552 [t=0.19s]
prediction: ['[CLS], suitably anonymous efficient chill anonymouser [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.797 (perp=8.549, rec=0.086, cos=0.002), tot_loss_proj:2.210 [t=0.18s]
prediction: ['[CLS], anonymous suitably anonymous efficient chiller [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.745 (perp=8.332, rec=0.077, cos=0.002), tot_loss_proj:1.925 [t=0.18s]
prediction: ['[CLS] anonymous, suitably anonymous efficient chiller [SEP]']
[ 450/2000] tot_loss=1.745 (perp=8.332, rec=0.077, cos=0.002), tot_loss_proj:1.921 [t=0.19s]
prediction: ['[CLS] anonymous, suitably anonymous efficient chiller [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.672 (perp=7.984, rec=0.074, cos=0.002), tot_loss_proj:1.754 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chiller [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.670 (perp=7.984, rec=0.072, cos=0.001), tot_loss_proj:1.756 [t=0.27s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chiller [SEP]']
[ 600/2000] tot_loss=1.678 (perp=7.984, rec=0.079, cos=0.001), tot_loss_proj:1.748 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chiller [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.673 (perp=7.984, rec=0.075, cos=0.001), tot_loss_proj:1.754 [t=0.19s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chiller [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.668 (perp=7.984, rec=0.070, cos=0.001), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous anonymous chiller [SEP]']
[ 750/2000] tot_loss=1.611 (perp=7.664, rec=0.077, cos=0.001), tot_loss_proj:1.800 [t=0.18s]
prediction: ['[CLS] efficient, suitably. anonymous chiller [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.608 (perp=7.664, rec=0.074, cos=0.001), tot_loss_proj:1.803 [t=0.28s]
prediction: ['[CLS] efficient, suitably. anonymous chiller [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.616 (perp=7.664, rec=0.082, cos=0.001), tot_loss_proj:1.791 [t=0.19s]
prediction: ['[CLS] efficient, suitably. anonymous chiller [SEP]']
[ 900/2000] tot_loss=1.608 (perp=7.664, rec=0.073, cos=0.001), tot_loss_proj:1.800 [t=0.19s]
prediction: ['[CLS] efficient, suitably. anonymous chiller [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.400 (perp=6.615, rec=0.076, cos=0.002), tot_loss_proj:1.406 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.392 (perp=6.615, rec=0.068, cos=0.001), tot_loss_proj:1.406 [t=0.19s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.392 (perp=6.615, rec=0.068, cos=0.002), tot_loss_proj:1.401 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.400 (perp=6.615, rec=0.076, cos=0.002), tot_loss_proj:1.398 [t=0.19s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.395 (perp=6.615, rec=0.070, cos=0.002), tot_loss_proj:1.407 [t=0.19s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.388 (perp=6.615, rec=0.063, cos=0.002), tot_loss_proj:1.403 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.400 (perp=6.615, rec=0.076, cos=0.002), tot_loss_proj:1.401 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.398 (perp=6.615, rec=0.074, cos=0.002), tot_loss_proj:1.404 [t=0.27s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.392 (perp=6.615, rec=0.068, cos=0.002), tot_loss_proj:1.409 [t=0.20s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.394 (perp=6.615, rec=0.070, cos=0.001), tot_loss_proj:1.400 [t=0.26s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.393 (perp=6.615, rec=0.068, cos=0.001), tot_loss_proj:1.416 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.391 (perp=6.615, rec=0.066, cos=0.001), tot_loss_proj:1.408 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.391 (perp=6.615, rec=0.067, cos=0.001), tot_loss_proj:1.417 [t=0.24s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.382 (perp=6.615, rec=0.057, cos=0.001), tot_loss_proj:1.406 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.389 (perp=6.615, rec=0.064, cos=0.001), tot_loss_proj:1.407 [t=0.26s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.396 (perp=6.615, rec=0.071, cos=0.001), tot_loss_proj:1.408 [t=0.30s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.385 (perp=6.615, rec=0.061, cos=0.001), tot_loss_proj:1.405 [t=0.19s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.390 (perp=6.615, rec=0.066, cos=0.001), tot_loss_proj:1.403 [t=0.19s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.388 (perp=6.615, rec=0.063, cos=0.001), tot_loss_proj:1.405 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.386 (perp=6.615, rec=0.062, cos=0.001), tot_loss_proj:1.400 [t=0.19s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.383 (perp=6.615, rec=0.059, cos=0.001), tot_loss_proj:1.404 [t=0.19s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.384 (perp=6.615, rec=0.059, cos=0.001), tot_loss_proj:1.396 [t=0.19s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.778 | p: 94.708 | r: 94.792
rouge2     | fm: 69.675 | p: 69.634 | r: 69.733
rougeL     | fm: 85.357 | p: 85.456 | r: 85.259
rougeLsum  | fm: 85.029 | p: 85.227 | r: 84.995
r1fm+r2fm = 164.453

input #15 time: 0:08:16 | total time: 2:14:21


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9993411698074052
highest_index [0]
highest [0.9993411698074052]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.018147349357605 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.9020346403121948 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7366529107093811 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.7362502217292786 for ['[CLS]athi alta lord film slowly various [SEP]']
[Init] best perm rec loss: 0.7362011075019836 for ['[CLS] lord slowly film variousathi alta [SEP]']
[Init] best perm rec loss: 0.7361390590667725 for ['[CLS] various slowly film lordathi alta [SEP]']
[Init] best perm rec loss: 0.7351789474487305 for ['[CLS]athi alta lord slowly various film [SEP]']
[Init] best perm rec loss: 0.7351776957511902 for ['[CLS] various film lord slowlyathi alta [SEP]']
[Init] best perm rec loss: 0.7336527705192566 for ['[CLS] various film lord slowly altaathi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.176 (perp=8.344, rec=0.434, cos=0.074), tot_loss_proj:2.926 [t=0.18s]
prediction: ['[CLS] three as information and more everything [SEP]']
[ 100/2000] tot_loss=1.737 (perp=7.155, rec=0.283, cos=0.023), tot_loss_proj:2.509 [t=0.18s]
prediction: ['[CLS] more of main and all this [SEP]']
[ 150/2000] tot_loss=1.697 (perp=7.225, rec=0.227, cos=0.025), tot_loss_proj:2.459 [t=0.22s]
prediction: ['[CLS] all of making and more this [SEP]']
[ 200/2000] tot_loss=1.556 (perp=7.005, rec=0.147, cos=0.008), tot_loss_proj:2.197 [t=0.18s]
prediction: ['[CLS] all of all and more this [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.218 (perp=5.539, rec=0.106, cos=0.005), tot_loss_proj:1.622 [t=0.19s]
prediction: ['[CLS] all of this and more all [SEP]']
[ 300/2000] tot_loss=1.415 (perp=6.558, rec=0.099, cos=0.004), tot_loss_proj:2.599 [t=0.26s]
prediction: ['[CLS] all of this and more mighty [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.410 (perp=6.558, rec=0.095, cos=0.003), tot_loss_proj:2.596 [t=0.20s]
prediction: ['[CLS] all of this and more mighty [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.517 (perp=7.150, rec=0.084, cos=0.003), tot_loss_proj:2.085 [t=0.19s]
prediction: ['[CLS] all of this and mighty more [SEP]']
[ 450/2000] tot_loss=1.519 (perp=7.150, rec=0.086, cos=0.003), tot_loss_proj:2.084 [t=0.19s]
prediction: ['[CLS] all of this and mighty more [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.199 (perp=5.539, rec=0.088, cos=0.003), tot_loss_proj:1.620 [t=0.19s]
prediction: ['[CLS] all of this and more all [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.131 (perp=5.191, rec=0.090, cos=0.003), tot_loss_proj:1.578 [t=0.19s]
prediction: ['[CLS] all of this and all more [SEP]']
[ 600/2000] tot_loss=1.129 (perp=5.191, rec=0.088, cos=0.003), tot_loss_proj:1.583 [t=0.19s]
prediction: ['[CLS] all of this and all more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.197 (perp=5.545, rec=0.085, cos=0.003), tot_loss_proj:1.613 [t=0.27s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.196 (perp=5.545, rec=0.085, cos=0.003), tot_loss_proj:1.613 [t=0.19s]
prediction: ['[CLS] all of this and that more [SEP]']
[ 750/2000] tot_loss=1.193 (perp=5.545, rec=0.081, cos=0.003), tot_loss_proj:1.612 [t=0.18s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.195 (perp=5.545, rec=0.083, cos=0.003), tot_loss_proj:1.610 [t=0.19s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.200 (perp=5.545, rec=0.089, cos=0.003), tot_loss_proj:1.615 [t=0.18s]
prediction: ['[CLS] all of this and that more [SEP]']
[ 900/2000] tot_loss=1.182 (perp=5.545, rec=0.070, cos=0.003), tot_loss_proj:1.607 [t=0.18s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.191 (perp=5.545, rec=0.079, cos=0.003), tot_loss_proj:1.611 [t=0.19s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.192 (perp=5.545, rec=0.080, cos=0.003), tot_loss_proj:1.612 [t=0.21s]
prediction: ['[CLS] all of this and that more [SEP]']
[1050/2000] tot_loss=1.187 (perp=5.545, rec=0.076, cos=0.003), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.197 (perp=5.545, rec=0.086, cos=0.002), tot_loss_proj:1.611 [t=0.18s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.187 (perp=5.545, rec=0.075, cos=0.002), tot_loss_proj:1.616 [t=0.19s]
prediction: ['[CLS] all of this and that more [SEP]']
[1200/2000] tot_loss=1.181 (perp=5.545, rec=0.069, cos=0.002), tot_loss_proj:1.610 [t=0.19s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.187 (perp=5.545, rec=0.075, cos=0.002), tot_loss_proj:1.609 [t=0.21s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.189 (perp=5.545, rec=0.078, cos=0.002), tot_loss_proj:1.611 [t=0.18s]
prediction: ['[CLS] all of this and that more [SEP]']
[1350/2000] tot_loss=1.192 (perp=5.545, rec=0.081, cos=0.002), tot_loss_proj:1.611 [t=0.21s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.184 (perp=5.545, rec=0.073, cos=0.002), tot_loss_proj:1.609 [t=0.18s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.193 (perp=5.545, rec=0.081, cos=0.002), tot_loss_proj:1.611 [t=0.26s]
prediction: ['[CLS] all of this and that more [SEP]']
[1500/2000] tot_loss=1.184 (perp=5.545, rec=0.073, cos=0.002), tot_loss_proj:1.609 [t=0.19s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.189 (perp=5.545, rec=0.078, cos=0.002), tot_loss_proj:1.609 [t=0.18s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.192 (perp=5.545, rec=0.080, cos=0.002), tot_loss_proj:1.610 [t=0.19s]
prediction: ['[CLS] all of this and that more [SEP]']
[1650/2000] tot_loss=1.193 (perp=5.545, rec=0.081, cos=0.002), tot_loss_proj:1.607 [t=0.19s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.186 (perp=5.545, rec=0.074, cos=0.002), tot_loss_proj:1.611 [t=0.19s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.197 (perp=5.545, rec=0.086, cos=0.002), tot_loss_proj:1.602 [t=0.21s]
prediction: ['[CLS] all of this and that more [SEP]']
[1800/2000] tot_loss=1.189 (perp=5.545, rec=0.078, cos=0.002), tot_loss_proj:1.612 [t=0.18s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.187 (perp=5.545, rec=0.076, cos=0.002), tot_loss_proj:1.606 [t=0.19s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.189 (perp=5.545, rec=0.078, cos=0.002), tot_loss_proj:1.611 [t=0.28s]
prediction: ['[CLS] all of this and that more [SEP]']
[1950/2000] tot_loss=1.187 (perp=5.545, rec=0.075, cos=0.002), tot_loss_proj:1.614 [t=0.28s]
prediction: ['[CLS] all of this and that more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.195 (perp=5.545, rec=0.084, cos=0.002), tot_loss_proj:1.611 [t=0.23s]
prediction: ['[CLS] all of this and that more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this and that more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 94.459 | p: 94.076 | r: 94.902
rouge2     | fm: 70.115 | p: 69.798 | r: 70.476
rougeL     | fm: 85.967 | p: 85.671 | r: 86.338
rougeLsum  | fm: 85.698 | p: 85.424 | r: 86.159
r1fm+r2fm = 164.574

input #16 time: 0:08:17 | total time: 2:22:39


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9992301552937229
highest_index [0]
highest [0.9992301552937229]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8486641645431519 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8205068111419678 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.8189647197723389 for ['[CLS] santa bourneity church jacence move nativeburnub early [SEP]']
[Init] best rec loss: 0.8072818517684937 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7922393679618835 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 0.7693865895271301 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 0.7615459561347961 for ['[CLS] lieutenant magazineuin miss grey marius honestly pressure saved meeting i [SEP]']
[Init] best perm rec loss: 0.7598406076431274 for ['[CLS] meeting marius miss pressure greyuin i magazine saved lieutenant honestly [SEP]']
[Init] best perm rec loss: 0.7584831714630127 for ['[CLS] marius missuin lieutenant grey magazine honestly i saved meeting pressure [SEP]']
[Init] best perm rec loss: 0.7562015652656555 for ['[CLS] pressure marius honestly magazine saved meeting grey lieutenant iuin miss [SEP]']
[Init] best perm rec loss: 0.7561701536178589 for ['[CLS] i pressure marius lieutenant magazine miss greyuin meeting saved honestly [SEP]']
[Init] best perm rec loss: 0.7556576132774353 for ['[CLS]uin lieutenant honestly i pressure marius miss meeting grey saved magazine [SEP]']
[Init] best perm rec loss: 0.7535409927368164 for ['[CLS] i meetinguin pressure honestly magazine grey lieutenant marius saved miss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.685 (perp=11.170, rec=0.404, cos=0.047), tot_loss_proj:3.527 [t=0.19s]
prediction: ["[CLS] too 会 hitter case with deputies fu'about enough investigation [SEP]"]
[ 100/2000] tot_loss=2.150 (perp=9.542, rec=0.226, cos=0.016), tot_loss_proj:2.859 [t=0.19s]
prediction: ['[CLS] too worried really early much about what what want much going [SEP]']
[ 150/2000] tot_loss=2.103 (perp=9.848, rec=0.127, cos=0.007), tot_loss_proj:3.002 [t=0.19s]
prediction: ['[CLS] too much really s much going what about want much think [SEP]']
[ 200/2000] tot_loss=1.698 (perp=7.989, rec=0.098, cos=0.003), tot_loss_proj:2.536 [t=0.18s]
prediction: ['[CLS] too much about s much going what about want to think [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.716 (perp=8.144, rec=0.084, cos=0.002), tot_loss_proj:2.549 [t=0.27s]
prediction: ['[CLS] s too much much much going what about want to think [SEP]']
[ 300/2000] tot_loss=1.712 (perp=8.144, rec=0.082, cos=0.002), tot_loss_proj:2.540 [t=0.25s]
prediction: ['[CLS] s too much much much going what about want to think [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.615 (perp=7.738, rec=0.066, cos=0.002), tot_loss_proj:2.454 [t=0.22s]
prediction: ['[CLS] s much too obviously much going what about want to think [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.507 (perp=7.195, rec=0.067, cos=0.002), tot_loss_proj:2.384 [t=0.20s]
prediction: ['[CLS] s much too much much going about what want to think [SEP]']
[ 450/2000] tot_loss=1.511 (perp=7.195, rec=0.071, cos=0.002), tot_loss_proj:2.389 [t=0.25s]
prediction: ['[CLS] s much too much much going about what want to think [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.562 (perp=7.428, rec=0.075, cos=0.002), tot_loss_proj:2.340 [t=0.19s]
prediction: ['[CLS] s a too much going much about what want to think [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.452 (perp=6.822, rec=0.085, cos=0.002), tot_loss_proj:2.264 [t=0.19s]
prediction: ['[CLS] s a much too much going about what want to think [SEP]']
[ 600/2000] tot_loss=1.443 (perp=6.822, rec=0.076, cos=0.002), tot_loss_proj:2.256 [t=0.19s]
prediction: ['[CLS] s a much too much going about what want to think [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.353 (perp=6.463, rec=0.059, cos=0.001), tot_loss_proj:2.276 [t=0.18s]
prediction: ['[CLS] s much too much going about what really want to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.359 (perp=6.463, rec=0.064, cos=0.002), tot_loss_proj:2.269 [t=0.19s]
prediction: ['[CLS] s much too much going about what really want to think [SEP]']
[ 750/2000] tot_loss=1.364 (perp=6.463, rec=0.069, cos=0.002), tot_loss_proj:2.281 [t=0.19s]
prediction: ['[CLS] s much too much going about what really want to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.302 (perp=6.158, rec=0.068, cos=0.002), tot_loss_proj:2.234 [t=0.19s]
prediction: ['[CLS] s much too much going about what a want to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.312 (perp=6.158, rec=0.079, cos=0.002), tot_loss_proj:2.237 [t=0.21s]
prediction: ['[CLS] s much too much going about what a want to think [SEP]']
[ 900/2000] tot_loss=1.296 (perp=6.158, rec=0.063, cos=0.002), tot_loss_proj:2.231 [t=0.18s]
prediction: ['[CLS] s much too much going about what a want to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.300 (perp=6.158, rec=0.067, cos=0.002), tot_loss_proj:2.234 [t=0.19s]
prediction: ['[CLS] s much too much going about what a want to think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.310 (perp=6.158, rec=0.076, cos=0.002), tot_loss_proj:2.228 [t=0.27s]
prediction: ['[CLS] s much too much going about what a want to think [SEP]']
[1050/2000] tot_loss=1.450 (perp=6.914, rec=0.065, cos=0.002), tot_loss_proj:2.263 [t=0.18s]
prediction: ['[CLS] s much too much going about what on want to think [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.471 (perp=7.046, rec=0.060, cos=0.002), tot_loss_proj:2.381 [t=0.27s]
prediction: ['[CLS] s much too much about what going a want to think [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.319 (perp=6.203, rec=0.077, cos=0.002), tot_loss_proj:2.110 [t=0.22s]
prediction: ['[CLS] s much too much going a want to think about what [SEP]']
[1200/2000] tot_loss=1.309 (perp=6.203, rec=0.066, cos=0.002), tot_loss_proj:2.128 [t=0.19s]
prediction: ['[CLS] s much too much going a want to think about what [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.457 (perp=6.914, rec=0.073, cos=0.002), tot_loss_proj:2.244 [t=0.19s]
prediction: ['[CLS] s much too much going about what on want to think [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.571 (perp=7.471, rec=0.075, cos=0.002), tot_loss_proj:2.433 [t=0.22s]
prediction: ['[CLS] s much too really going about a want to think what [SEP]']
[1350/2000] tot_loss=1.394 (perp=6.629, rec=0.067, cos=0.001), tot_loss_proj:2.173 [t=0.19s]
prediction: ['[CLS] s much too much going about a want to think what [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.438 (perp=6.801, rec=0.076, cos=0.002), tot_loss_proj:2.399 [t=0.19s]
prediction: ['[CLS] s much too really going about what a want to think [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.326 (perp=6.284, rec=0.068, cos=0.002), tot_loss_proj:2.318 [t=0.28s]
prediction: ['[CLS] s too much really going about what a want to think [SEP]']
[1500/2000] tot_loss=1.330 (perp=6.284, rec=0.072, cos=0.002), tot_loss_proj:2.313 [t=0.18s]
prediction: ['[CLS] s too much really going about what a want to think [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.371 (perp=6.498, rec=0.070, cos=0.001), tot_loss_proj:2.166 [t=0.28s]
prediction: ['[CLS] s too much really going want to think about what on [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.179 (perp=5.549, rec=0.068, cos=0.001), tot_loss_proj:1.863 [t=0.27s]
prediction: ['[CLS] s too much really want to think about what going on [SEP]']
[1650/2000] tot_loss=1.165 (perp=5.549, rec=0.053, cos=0.002), tot_loss_proj:1.867 [t=0.18s]
prediction: ['[CLS] s too much really want to think about what going on [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.048 (perp=4.843, rec=0.078, cos=0.002), tot_loss_proj:1.647 [t=0.21s]
prediction: ['[CLS] too much really want to think about what s going on [SEP]']
Attempt swap
[1750/2000] tot_loss=1.041 (perp=4.843, rec=0.071, cos=0.002), tot_loss_proj:1.646 [t=0.20s]
prediction: ['[CLS] too much really want to think about what s going on [SEP]']
[1800/2000] tot_loss=1.041 (perp=4.843, rec=0.071, cos=0.002), tot_loss_proj:1.640 [t=0.25s]
prediction: ['[CLS] too much really want to think about what s going on [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.006 (perp=4.658, rec=0.073, cos=0.002), tot_loss_proj:1.649 [t=0.26s]
prediction: ['[CLS] too much want to think about what s really going on [SEP]']
Attempt swap
[1900/2000] tot_loss=0.996 (perp=4.658, rec=0.063, cos=0.002), tot_loss_proj:1.651 [t=0.20s]
prediction: ['[CLS] too much want to think about what s really going on [SEP]']
[1950/2000] tot_loss=1.000 (perp=4.658, rec=0.067, cos=0.002), tot_loss_proj:1.647 [t=0.18s]
prediction: ['[CLS] too much want to think about what s really going on [SEP]']
Attempt swap
[2000/2000] tot_loss=1.128 (perp=5.291, rec=0.068, cos=0.002), tot_loss_proj:1.785 [t=0.26s]
prediction: ['[CLS] too much want to think about what s much going on [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] too much really want to think about what s going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 69.565 | p: 66.667 | r: 72.727
rougeL     | fm: 80.000 | p: 76.923 | r: 83.333
rougeLsum  | fm: 80.000 | p: 76.923 | r: 83.333
r1fm+r2fm = 165.565

[Aggregate metrics]:
rouge1     | fm: 94.545 | p: 94.042 | r: 95.159
rouge2     | fm: 70.115 | p: 69.627 | r: 70.573
rougeL     | fm: 85.556 | p: 85.146 | r: 86.061
rougeLsum  | fm: 85.423 | p: 84.937 | r: 86.002
r1fm+r2fm = 164.660

input #17 time: 0:08:20 | total time: 2:31:00


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9993194147820215
highest_index [0]
highest [0.9993194147820215]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9796279072761536 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9423751831054688 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9344695806503296 for ['[CLS] deportivo suspect usual aston [SEP]']
[Init] best rec loss: 0.9258310198783875 for ['[CLS] water global accreditation originally [SEP]']
[Init] best rec loss: 0.8895648717880249 for ['[CLS] press lose hunger tracks [SEP]']
[Init] best rec loss: 0.8812242150306702 for ['[CLS] affectionately character hundreds team [SEP]']
[Init] best rec loss: 0.869970977306366 for ['[CLS] oniest α department [SEP]']
[Init] best rec loss: 0.8667334318161011 for ['[CLS] middle away mc reserves [SEP]']
[Init] best rec loss: 0.8235080242156982 for ['[CLS] dual circle duodle [SEP]']
[Init] best perm rec loss: 0.8209102153778076 for ['[CLS]odle circle du dual [SEP]']
[Init] best perm rec loss: 0.8185354471206665 for ['[CLS] dual duodle circle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.600 (perp=11.535, rec=0.289, cos=0.004), tot_loss_proj:3.600 [t=0.24s]
prediction: ['[CLS] large reachingable vampires [SEP]']
[ 100/2000] tot_loss=3.464 (perp=16.222, rec=0.216, cos=0.003), tot_loss_proj:5.027 [t=0.27s]
prediction: ['[CLS]vigorgorgor [SEP]']
[ 150/2000] tot_loss=3.507 (perp=16.736, rec=0.157, cos=0.003), tot_loss_proj:5.241 [t=0.25s]
prediction: ['[CLS]viatinggorgor [SEP]']
[ 200/2000] tot_loss=2.292 (perp=10.916, rec=0.107, cos=0.002), tot_loss_proj:3.515 [t=0.26s]
prediction: ['[CLS]viatinggorating [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.197 (perp=5.588, rec=0.077, cos=0.002), tot_loss_proj:1.187 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.183 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.190 [t=0.21s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.187 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.183 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.190 (perp=5.588, rec=0.071, cos=0.001), tot_loss_proj:1.189 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.176 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.175 (perp=5.588, rec=0.056, cos=0.001), tot_loss_proj:1.187 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.182 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.180 [t=0.21s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.190 (perp=5.588, rec=0.071, cos=0.001), tot_loss_proj:1.195 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.188 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.192 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.185 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.184 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.181 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.171 (perp=5.588, rec=0.052, cos=0.001), tot_loss_proj:1.179 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.182 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.195 (perp=5.588, rec=0.076, cos=0.001), tot_loss_proj:1.185 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.188 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.190 (perp=5.588, rec=0.071, cos=0.001), tot_loss_proj:1.184 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.184 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.183 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.181 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.191 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.175 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.171 (perp=5.588, rec=0.052, cos=0.001), tot_loss_proj:1.174 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.194 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.176 [t=0.30s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.185 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.187 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.183 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.175 (perp=5.588, rec=0.056, cos=0.001), tot_loss_proj:1.184 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.169 (perp=5.588, rec=0.050, cos=0.001), tot_loss_proj:1.187 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.184 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.184 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.792 | p: 94.238 | r: 95.439
rouge2     | fm: 71.867 | p: 71.457 | r: 72.350
rougeL     | fm: 86.227 | p: 85.785 | r: 86.781
rougeLsum  | fm: 86.161 | p: 85.736 | r: 86.704
r1fm+r2fm = 166.659

input #18 time: 0:08:32 | total time: 2:39:32


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9993635209107408
highest_index [0]
highest [0.9993635209107408]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7703872323036194 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7632964253425598 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.7431591749191284 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7254143357276917 for ['[CLS] target jessica episode ling [SEP]']
[Init] best rec loss: 0.7071809768676758 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.7017049789428711 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.688244640827179 for ['[CLS] centers recordtion difficult [SEP]']
[Init] best rec loss: 0.680355966091156 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.6743445992469788 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 0.6420117020606995 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6395600438117981 for ['[CLS] reaching pin orderyna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.253 (perp=13.982, rec=0.391, cos=0.065), tot_loss_proj:3.926 [t=0.23s]
prediction: ['[CLS] candy arte violent in [SEP]']
[ 100/2000] tot_loss=2.331 (perp=10.293, rec=0.250, cos=0.023), tot_loss_proj:3.470 [t=0.18s]
prediction: ['[CLS]famy to in [SEP]']
[ 150/2000] tot_loss=2.208 (perp=10.293, rec=0.133, cos=0.016), tot_loss_proj:3.464 [t=0.26s]
prediction: ['[CLS]famy to in [SEP]']
[ 200/2000] tot_loss=2.156 (perp=10.293, rec=0.094, cos=0.003), tot_loss_proj:3.455 [t=0.27s]
prediction: ['[CLS]famy to in [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.302 (perp=6.110, rec=0.076, cos=0.004), tot_loss_proj:1.306 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.294 (perp=6.110, rec=0.071, cos=0.001), tot_loss_proj:1.297 [t=0.30s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.274 (perp=6.110, rec=0.050, cos=0.001), tot_loss_proj:1.304 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.291 (perp=6.110, rec=0.068, cos=0.001), tot_loss_proj:1.300 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.308 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.289 (perp=6.110, rec=0.066, cos=0.001), tot_loss_proj:1.307 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.286 (perp=6.110, rec=0.063, cos=0.001), tot_loss_proj:1.311 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.301 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.285 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.311 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.286 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.307 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.287 (perp=6.110, rec=0.064, cos=0.001), tot_loss_proj:1.307 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.300 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.310 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.286 (perp=6.110, rec=0.063, cos=0.001), tot_loss_proj:1.302 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.312 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.305 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.306 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.289 (perp=6.110, rec=0.066, cos=0.001), tot_loss_proj:1.300 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.273 (perp=6.110, rec=0.049, cos=0.001), tot_loss_proj:1.304 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.279 (perp=6.110, rec=0.056, cos=0.001), tot_loss_proj:1.304 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.290 (perp=6.110, rec=0.066, cos=0.001), tot_loss_proj:1.310 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.285 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.301 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.272 (perp=6.110, rec=0.049, cos=0.001), tot_loss_proj:1.298 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.286 (perp=6.110, rec=0.063, cos=0.001), tot_loss_proj:1.292 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.276 (perp=6.110, rec=0.053, cos=0.001), tot_loss_proj:1.309 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.279 (perp=6.110, rec=0.056, cos=0.001), tot_loss_proj:1.306 [t=0.27s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.291 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.307 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.289 (perp=6.110, rec=0.066, cos=0.001), tot_loss_proj:1.303 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.287 (perp=6.110, rec=0.063, cos=0.001), tot_loss_proj:1.308 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.309 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.290 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.305 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.286 (perp=6.110, rec=0.063, cos=0.001), tot_loss_proj:1.310 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.273 (perp=6.110, rec=0.050, cos=0.001), tot_loss_proj:1.303 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.279 (perp=6.110, rec=0.056, cos=0.001), tot_loss_proj:1.302 [t=0.28s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.288 (perp=6.110, rec=0.065, cos=0.001), tot_loss_proj:1.302 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.289 (perp=6.110, rec=0.065, cos=0.001), tot_loss_proj:1.317 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.138 | p: 94.625 | r: 95.762
rouge2     | fm: 73.479 | p: 72.926 | r: 73.928
rougeL     | fm: 87.351 | p: 86.841 | r: 87.691
rougeLsum  | fm: 86.961 | p: 86.506 | r: 87.581
r1fm+r2fm = 168.617

input #19 time: 0:08:25 | total time: 2:47:58


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9992466071766843
highest_index [0]
highest [0.9992466071766843]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.813522219657898 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8018914461135864 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7928059697151184 for ['[CLS] york match causearu [SEP]']
[Init] best rec loss: 0.7927916049957275 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.7916965484619141 for ['[CLS] glad home gentlemanboard [SEP]']
[Init] best rec loss: 0.765182614326477 for ['[CLS] poorpid african forming [SEP]']
[Init] best perm rec loss: 0.7627440690994263 for ['[CLS]pid poor forming african [SEP]']
[Init] best perm rec loss: 0.7611280083656311 for ['[CLS] african poor formingpid [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.350 (perp=9.791, rec=0.354, cos=0.037), tot_loss_proj:3.487 [t=0.19s]
prediction: ['[CLS] menverse pleasureverse [SEP]']
[ 100/2000] tot_loss=2.367 (perp=10.658, rec=0.218, cos=0.017), tot_loss_proj:3.432 [t=0.19s]
prediction: ['[CLS]verseverse pleasureverse [SEP]']
[ 150/2000] tot_loss=2.536 (perp=11.911, rec=0.144, cos=0.010), tot_loss_proj:3.091 [t=0.19s]
prediction: ['[CLS]verseverse pleasure the [SEP]']
[ 200/2000] tot_loss=1.838 (perp=8.633, rec=0.109, cos=0.003), tot_loss_proj:2.302 [t=0.21s]
prediction: ['[CLS] perverse pleasure the [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.742 (perp=7.535, rec=0.212, cos=0.023), tot_loss_proj:2.238 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 300/2000] tot_loss=1.632 (perp=7.535, rec=0.122, cos=0.003), tot_loss_proj:2.108 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.599 (perp=7.535, rec=0.090, cos=0.002), tot_loss_proj:2.117 [t=0.26s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.577 (perp=7.535, rec=0.068, cos=0.002), tot_loss_proj:2.119 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 450/2000] tot_loss=1.590 (perp=7.535, rec=0.081, cos=0.001), tot_loss_proj:2.114 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.578 (perp=7.535, rec=0.069, cos=0.002), tot_loss_proj:2.109 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.578 (perp=7.535, rec=0.070, cos=0.001), tot_loss_proj:2.117 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 600/2000] tot_loss=1.593 (perp=7.535, rec=0.085, cos=0.001), tot_loss_proj:2.110 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.578 (perp=7.535, rec=0.070, cos=0.001), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.581 (perp=7.535, rec=0.072, cos=0.001), tot_loss_proj:2.116 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 750/2000] tot_loss=1.579 (perp=7.535, rec=0.071, cos=0.001), tot_loss_proj:2.109 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.564 (perp=7.535, rec=0.056, cos=0.001), tot_loss_proj:2.119 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.576 (perp=7.535, rec=0.067, cos=0.001), tot_loss_proj:2.115 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 900/2000] tot_loss=1.575 (perp=7.535, rec=0.067, cos=0.001), tot_loss_proj:2.115 [t=0.24s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.576 (perp=7.535, rec=0.068, cos=0.001), tot_loss_proj:2.109 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1000/2000] tot_loss=1.566 (perp=7.535, rec=0.057, cos=0.001), tot_loss_proj:2.108 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1050/2000] tot_loss=1.579 (perp=7.535, rec=0.070, cos=0.001), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1100/2000] tot_loss=1.584 (perp=7.535, rec=0.076, cos=0.002), tot_loss_proj:2.113 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1150/2000] tot_loss=1.579 (perp=7.535, rec=0.070, cos=0.001), tot_loss_proj:2.116 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1200/2000] tot_loss=1.572 (perp=7.535, rec=0.063, cos=0.001), tot_loss_proj:2.109 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1250/2000] tot_loss=1.572 (perp=7.535, rec=0.064, cos=0.001), tot_loss_proj:2.124 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1300/2000] tot_loss=1.582 (perp=7.535, rec=0.074, cos=0.001), tot_loss_proj:2.111 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.535, rec=0.078, cos=0.001), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1400/2000] tot_loss=1.566 (perp=7.535, rec=0.058, cos=0.002), tot_loss_proj:2.117 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1450/2000] tot_loss=1.577 (perp=7.535, rec=0.068, cos=0.001), tot_loss_proj:2.114 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1500/2000] tot_loss=1.579 (perp=7.535, rec=0.070, cos=0.001), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1550/2000] tot_loss=1.576 (perp=7.535, rec=0.067, cos=0.002), tot_loss_proj:2.119 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1600/2000] tot_loss=1.574 (perp=7.535, rec=0.066, cos=0.001), tot_loss_proj:2.108 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1650/2000] tot_loss=1.584 (perp=7.535, rec=0.076, cos=0.001), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1700/2000] tot_loss=1.571 (perp=7.535, rec=0.063, cos=0.002), tot_loss_proj:2.125 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1750/2000] tot_loss=1.581 (perp=7.535, rec=0.072, cos=0.001), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1800/2000] tot_loss=1.581 (perp=7.535, rec=0.072, cos=0.001), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1850/2000] tot_loss=1.576 (perp=7.535, rec=0.067, cos=0.002), tot_loss_proj:2.110 [t=0.23s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1900/2000] tot_loss=1.574 (perp=7.535, rec=0.065, cos=0.001), tot_loss_proj:2.121 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1950/2000] tot_loss=1.581 (perp=7.535, rec=0.072, cos=0.001), tot_loss_proj:2.111 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[2000/2000] tot_loss=1.575 (perp=7.535, rec=0.066, cos=0.001), tot_loss_proj:2.114 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] pleasure the perverse [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 95.266 | p: 94.777 | r: 95.873
rouge2     | fm: 71.171 | p: 70.726 | r: 71.708
rougeL     | fm: 86.804 | p: 86.424 | r: 87.221
rougeLsum  | fm: 86.775 | p: 86.307 | r: 87.195
r1fm+r2fm = 166.437

input #20 time: 0:08:25 | total time: 2:56:23


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.999323347023505
highest_index [0]
highest [0.999323347023505]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9415550231933594 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.881145179271698 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.8719595670700073 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 0.8715744018554688 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.8490786552429199 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.8239164352416992 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best rec loss: 0.820530891418457 for ['[CLS]westock displays lock [MASK] peg potatoes precious sarajevo tomorrow gingerhis offers extension recently part lake pena comedy punjabhraors hardware alabama chemical [SEP]']
[Init] best rec loss: 0.8185598850250244 for ['[CLS] chamber firm returnfying evidence commission clear sq extra above episodeoom [SEP] brows ashland odd viva range surgical waters village right daddy speed jin [SEP]']
[Init] best perm rec loss: 0.8150901794433594 for ['[CLS] jin [SEP] brows return clear firm ashland evidence villageoom daddy speed extra sq chamberfying above odd episode viva surgical commission right range waters [SEP]']
[Init] best perm rec loss: 0.8130291700363159 for ['[CLS] daddy odd range surgical firm chamber jinoom [SEP] above viva extra brows speed ashland clear episode evidence returnfying sq village waters right commission [SEP]']
[Init] best perm rec loss: 0.8112152814865112 for ['[CLS] extra brows odd speedoom commission daddy range clear surgical evidence firm episode [SEP] viva waters above returnfying village jin ashland right chamber sq [SEP]']
[Init] best perm rec loss: 0.8100186586380005 for ['[CLS] right evidence ashland extra range speed return odd surgical episodeoom commissionfying viva [SEP] daddy brows jin waters sq village above firm chamber clear [SEP]']
[Init] best perm rec loss: 0.8091968297958374 for ['[CLS] speed evidenceoom extra commission return ashland chamber firm daddy episodefying right jin brows [SEP] above village clear viva sq surgical odd range waters [SEP]']
[Init] best perm rec loss: 0.8089424967765808 for ['[CLS] surgical sq odd return vivafying browsoom village [SEP] jin chamber firm clear daddy range ashland waters extra above commission evidence speed right episode [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.586 (perp=11.030, rec=0.364, cos=0.015), tot_loss_proj:3.499 [t=0.18s]
prediction: ['[CLS] government another least reversed supply areas than caretaker really employees organization systemus moral. on restroom continue problems. told. even lookout system [SEP]']
[ 100/2000] tot_loss=2.705 (perp=11.943, rec=0.296, cos=0.020), tot_loss_proj:3.422 [t=0.25s]
prediction: ['[CLS] women makesmain complicated treatments athletes lo caretaker look individuals seriesp out ladies. jan instead continued problems. its. looking lookout helmet [SEP]']
[ 150/2000] tot_loss=2.342 (perp=10.412, rec=0.248, cos=0.012), tot_loss_proj:3.579 [t=0.19s]
prediction: ['[CLS] women makes different works look athletes the caretaker look teachers look work out woman.ys instead instead moral how that. looking religiousmen [SEP]']
[ 200/2000] tot_loss=2.186 (perp=9.887, rec=0.204, cos=0.005), tot_loss_proj:3.021 [t=0.18s]
prediction: ['[CLS] women makes this more look athletes lookstypical look teachers teams work out woman.ys instead instead athletes how that works looking stereotype [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.075 (perp=9.434, rec=0.182, cos=0.006), tot_loss_proj:2.788 [t=0.19s]
prediction: ['[CLS] women makes this all look athletes looktypical look teachers works out woman teams.ys instead continue athletes way this works looking stereotypical [SEP]']
[ 300/2000] tot_loss=2.063 (perp=9.527, rec=0.153, cos=0.004), tot_loss_proj:2.638 [t=0.23s]
prediction: ['[CLS] women makes this all look athletes looktypical more caretaker works out woman athletes.ys instead continue athletes way this works look stereotypical [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.891 (perp=8.728, rec=0.141, cos=0.004), tot_loss_proj:2.482 [t=0.27s]
prediction: ['[CLS] women makes this all look athletes the more caretaker works out woman athletes.al instead caretakertypical athletes way this works look stereotypical [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.818 (perp=8.386, rec=0.137, cos=0.004), tot_loss_proj:2.407 [t=0.26s]
prediction: ['[CLS] women makes this all look athletes the more caretaker works outal instead serious woman athletes.typical athletes way this works look stereotypical [SEP]']
[ 450/2000] tot_loss=1.753 (perp=8.167, rec=0.116, cos=0.003), tot_loss_proj:2.311 [t=0.21s]
prediction: ['[CLS] women makes this all look athletes like more caretaker works out of instead serious woman athletes.typical athletes way this works look stereotypical [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.790 (perp=8.328, rec=0.121, cos=0.004), tot_loss_proj:2.309 [t=0.32s]
prediction: ['[CLS] this makes this all look athletes like more caretaker works out of instead serious woman athletes.typical moral way women works look stereotypical [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.805 (perp=8.433, rec=0.114, cos=0.004), tot_loss_proj:2.382 [t=0.28s]
prediction: ['[CLS] this makes this all look athletes like more caretaker works out moral instead serious woman athletes.typical moral works way women look stereotypical [SEP]']
[ 600/2000] tot_loss=1.833 (perp=8.661, rec=0.097, cos=0.003), tot_loss_proj:2.475 [t=0.25s]
prediction: ['[CLS] this makes this all look athletes like more caretaker works out moral instead serious woman athletes.typical teachers works way women look stereotypical [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.757 (perp=8.217, rec=0.111, cos=0.003), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] this makes this all look athletes like more of caretaker works out instead serious womans,typical teachers works way women look stereotypical [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.742 (perp=8.139, rec=0.111, cos=0.004), tot_loss_proj:2.281 [t=0.23s]
prediction: ['[CLS] this makes this all athletes look like more moral caretaker works out instead serious womans,typical teachers works way women look stereotypical [SEP]']
[ 750/2000] tot_loss=1.765 (perp=8.311, rec=0.100, cos=0.003), tot_loss_proj:2.313 [t=0.18s]
prediction: ['[CLS] this makes this all athletes look like more moral caretaker works out instead serious nunss,typical teachers works way women look stereotypical [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.769 (perp=8.311, rec=0.104, cos=0.003), tot_loss_proj:2.318 [t=0.26s]
prediction: ['[CLS] this makes this all athletes look like more moral caretaker works out instead serious nunss,typical teachers works way women look stereotypical [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.726 (perp=8.127, rec=0.098, cos=0.003), tot_loss_proj:2.353 [t=0.25s]
prediction: ['[CLS] works makes this all athletes look like more moral caretaker works out instead serious nunss,typical teachers the way women look stereotypical [SEP]']
[ 900/2000] tot_loss=1.809 (perp=8.543, rec=0.097, cos=0.003), tot_loss_proj:3.155 [t=0.29s]
prediction: ['[CLS] works makes this all athletes moral like more moral caretaker works out instead serious nunss,typical teachers the way women look stereotypical [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.764 (perp=8.368, rec=0.088, cos=0.003), tot_loss_proj:2.658 [t=0.25s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out instead serious nunss,typical teachers the way women look stereotypical [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.739 (perp=8.156, rec=0.105, cos=0.003), tot_loss_proj:2.988 [t=0.19s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out, serious nunss insteadtypical teachers the way women look stereotypical [SEP]']
[1050/2000] tot_loss=1.741 (perp=8.156, rec=0.108, cos=0.003), tot_loss_proj:2.990 [t=0.18s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out, serious nunss insteadtypical teachers the way women look stereotypical [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.707 (perp=8.028, rec=0.099, cos=0.002), tot_loss_proj:2.781 [t=0.19s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
[1150/2000] tot_loss=1.705 (perp=8.028, rec=0.097, cos=0.002), tot_loss_proj:2.781 [t=0.24s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
[1200/2000] tot_loss=1.696 (perp=8.028, rec=0.088, cos=0.002), tot_loss_proj:2.783 [t=0.18s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
[1250/2000] tot_loss=1.701 (perp=8.028, rec=0.093, cos=0.002), tot_loss_proj:2.781 [t=0.20s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
[1300/2000] tot_loss=1.702 (perp=8.028, rec=0.094, cos=0.002), tot_loss_proj:2.779 [t=0.19s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
[1350/2000] tot_loss=1.703 (perp=8.028, rec=0.095, cos=0.002), tot_loss_proj:2.782 [t=0.25s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
[1400/2000] tot_loss=1.698 (perp=8.028, rec=0.090, cos=0.002), tot_loss_proj:2.782 [t=0.19s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.709 (perp=8.028, rec=0.101, cos=0.002), tot_loss_proj:2.772 [t=0.19s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
[1500/2000] tot_loss=1.698 (perp=8.028, rec=0.091, cos=0.002), tot_loss_proj:2.772 [t=0.26s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
[1550/2000] tot_loss=1.696 (perp=8.028, rec=0.088, cos=0.002), tot_loss_proj:2.774 [t=0.19s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.693 (perp=8.028, rec=0.085, cos=0.003), tot_loss_proj:2.777 [t=0.19s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
[1650/2000] tot_loss=1.700 (perp=8.028, rec=0.092, cos=0.002), tot_loss_proj:2.781 [t=0.28s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.639 (perp=7.690, rec=0.098, cos=0.003), tot_loss_proj:2.675 [t=0.19s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretakers works out,typical nuns instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
[1750/2000] tot_loss=1.632 (perp=7.690, rec=0.091, cos=0.002), tot_loss_proj:2.678 [t=0.28s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretakers works out,typical nuns instead serious teachers the way women look stereotypical [SEP]']
[1800/2000] tot_loss=1.632 (perp=7.690, rec=0.092, cos=0.002), tot_loss_proj:2.684 [t=0.22s]
prediction: ['[CLS] works makes this all athletes moral more like moral caretakers works out,typical nuns instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
[1850/2000] tot_loss=1.687 (perp=7.948, rec=0.095, cos=0.002), tot_loss_proj:2.749 [t=0.20s]
prediction: ['[CLS] works makes this all athletes moral more like of caretakers works out,typical nuns instead serious teachers the way women look stereotypical [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.618 (perp=7.558, rec=0.104, cos=0.002), tot_loss_proj:2.920 [t=0.24s]
prediction: ['[CLS] works makes this all athletes moral more like serious caretakers works out,typical nuns instead of teachers the way women look stereotypical [SEP]']
[1950/2000] tot_loss=1.607 (perp=7.558, rec=0.093, cos=0.002), tot_loss_proj:2.922 [t=0.27s]
prediction: ['[CLS] works makes this all athletes moral more like serious caretakers works out,typical nuns instead of teachers the way women look stereotypical [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.547 (perp=7.239, rec=0.097, cos=0.003), tot_loss_proj:3.177 [t=0.21s]
prediction: ['[CLS] works makes this all athletes moral more like serious caretakers works out,typical nuns instead of stereotypical teachers the way women look [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] works makes this all athletes moral more like moral caretaker works out,typical nunss instead serious teachers the way women look stereotypical [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.851 | p: 79.167 | r: 82.609
rouge2     | fm: 22.222 | p: 21.739 | r: 22.727
rougeL     | fm: 42.553 | p: 41.667 | r: 43.478
rougeLsum  | fm: 42.553 | p: 41.667 | r: 43.478
r1fm+r2fm = 103.073

[Aggregate metrics]:
rouge1     | fm: 94.685 | p: 94.163 | r: 95.248
rouge2     | fm: 68.777 | p: 68.494 | r: 69.186
rougeL     | fm: 84.744 | p: 84.312 | r: 85.159
rougeLsum  | fm: 84.537 | p: 84.120 | r: 85.096
r1fm+r2fm = 163.462

input #21 time: 0:08:48 | total time: 3:05:12


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9993366894184397
highest_index [0]
highest [0.9993366894184397]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9641942381858826 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9582980871200562 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 0.9533578157424927 for ['[CLS] so saddle bronze dimension was hal code throughout semester static paced [SEP]']
[Init] best rec loss: 0.9530670642852783 for ['[CLS] husband figures individual merge gdp planongriders beat your nur [SEP]']
[Init] best rec loss: 0.936561644077301 for ['[CLS] along amount clear garden isn crime jockey gillespiecies dorian same [SEP]']
[Init] best rec loss: 0.9236189723014832 for ['[CLS] immunity manufacture poor vested access another dir $ resemblance i wrote [SEP]']
[Init] best perm rec loss: 0.9202683568000793 for ['[CLS] resemblance manufacture another immunity poor wrote access $ vested dir i [SEP]']
[Init] best perm rec loss: 0.9199215769767761 for ['[CLS] poor resemblance wrote $ manufacture i vested another dir immunity access [SEP]']
[Init] best perm rec loss: 0.9190679788589478 for ['[CLS] $ wrote poor vested dir immunity resemblance manufacture i another access [SEP]']
[Init] best perm rec loss: 0.917163074016571 for ['[CLS] dir manufacture i $ another poor access immunity wrote vested resemblance [SEP]']
[Init] best perm rec loss: 0.9159475564956665 for ['[CLS] $ i another manufacture resemblance immunity vested access poor wrote dir [SEP]']
[Init] best perm rec loss: 0.9134272336959839 for ['[CLS] dir wrote i vested manufacture immunity access $ another poor resemblance [SEP]']
[Init] best perm rec loss: 0.9125464558601379 for ['[CLS] manufacture $ immunity vested resemblance wrote i dir another access poor [SEP]']
[Init] best perm rec loss: 0.9117497801780701 for ['[CLS] manufacture vested access immunity poor another resemblance i $ wrote dir [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.312 (perp=10.503, rec=0.208, cos=0.004), tot_loss_proj:2.710 [t=0.18s]
prediction: ['[CLS] successful successful successful film successful a successful adaptationmanship considered seasonal [SEP]']
[ 100/2000] tot_loss=2.036 (perp=9.420, rec=0.150, cos=0.002), tot_loss_proj:2.346 [t=0.18s]
prediction: ['[CLS] successful successful enjoyable film enjoyable a successful adaptation its own an [SEP]']
[ 150/2000] tot_loss=2.095 (perp=9.876, rec=0.117, cos=0.002), tot_loss_proj:2.565 [t=0.18s]
prediction: ['[CLS] successful successful⁄₄ film enjoyable a successful adaptation its and right [SEP]']
[ 200/2000] tot_loss=2.083 (perp=9.839, rec=0.113, cos=0.002), tot_loss_proj:2.497 [t=0.18s]
prediction: ['[CLS] successful successfulising film enjoyable a successful adaptation its and right [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.888 (perp=8.694, rec=0.146, cos=0.002), tot_loss_proj:2.258 [t=0.19s]
prediction: ['[CLS] successful successful yours film enjoyable and a successful adaptation its right [SEP]']
[ 300/2000] tot_loss=2.023 (perp=9.636, rec=0.094, cos=0.001), tot_loss_proj:2.381 [t=0.21s]
prediction: ['[CLS] an successfulcial film enjoyable and a successful adaptation its right [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.779 (perp=8.398, rec=0.098, cos=0.001), tot_loss_proj:2.103 [t=0.19s]
prediction: ['[CLS] an enjoyable successful an film and a successful adaptation its right [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.607 (perp=7.557, rec=0.094, cos=0.001), tot_loss_proj:1.889 [t=0.19s]
prediction: ['[CLS] an enjoyable successful film and an a successful adaptation its right [SEP]']
[ 450/2000] tot_loss=1.633 (perp=7.805, rec=0.071, cos=0.001), tot_loss_proj:1.986 [t=0.27s]
prediction: ['[CLS] an enjoyable successful film and own a successful adaptation its right [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.473 (perp=6.957, rec=0.080, cos=0.001), tot_loss_proj:1.691 [t=0.18s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation own its right [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.473 (perp=6.957, rec=0.080, cos=0.001), tot_loss_proj:1.698 [t=0.22s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation own its right [SEP]']
[ 600/2000] tot_loss=1.469 (perp=6.957, rec=0.076, cos=0.001), tot_loss_proj:1.688 [t=0.23s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation own its right [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.681 (perp=7.987, rec=0.083, cos=0.001), tot_loss_proj:1.922 [t=0.22s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right own own [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.557 (perp=7.358, rec=0.084, cos=0.001), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation own own right [SEP]']
[ 750/2000] tot_loss=1.555 (perp=7.358, rec=0.082, cos=0.001), tot_loss_proj:1.761 [t=0.19s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation own own right [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.507 (perp=7.086, rec=0.088, cos=0.001), tot_loss_proj:1.719 [t=0.19s]
prediction: ['[CLS] an enjoyable successful film and a successful own adaptation own right [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.578 (perp=7.472, rec=0.082, cos=0.001), tot_loss_proj:1.811 [t=0.23s]
prediction: ['[CLS] an enjoyable successful film and a successful its right own adaptation [SEP]']
[ 900/2000] tot_loss=1.576 (perp=7.472, rec=0.081, cos=0.001), tot_loss_proj:1.820 [t=0.18s]
prediction: ['[CLS] an enjoyable successful film and a successful its right own adaptation [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.408 (perp=6.607, rec=0.085, cos=0.001), tot_loss_proj:1.658 [t=0.19s]
prediction: ['[CLS] an enjoyable successful film and a successful right its own adaptation [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.341 (perp=6.243, rec=0.092, cos=0.001), tot_loss_proj:1.583 [t=0.23s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
[1050/2000] tot_loss=1.331 (perp=6.243, rec=0.081, cos=0.001), tot_loss_proj:1.582 [t=0.19s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
Attempt swap
[1100/2000] tot_loss=1.321 (perp=6.243, rec=0.071, cos=0.001), tot_loss_proj:1.583 [t=0.19s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
Attempt swap
[1150/2000] tot_loss=1.319 (perp=6.243, rec=0.069, cos=0.001), tot_loss_proj:1.587 [t=0.18s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
[1200/2000] tot_loss=1.318 (perp=6.243, rec=0.068, cos=0.001), tot_loss_proj:1.586 [t=0.18s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
Attempt swap
[1250/2000] tot_loss=1.319 (perp=6.243, rec=0.069, cos=0.001), tot_loss_proj:1.591 [t=0.28s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
Attempt swap
[1300/2000] tot_loss=1.329 (perp=6.243, rec=0.080, cos=0.001), tot_loss_proj:1.584 [t=0.27s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
[1350/2000] tot_loss=1.324 (perp=6.243, rec=0.074, cos=0.001), tot_loss_proj:1.580 [t=0.22s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
Attempt swap
[1400/2000] tot_loss=1.326 (perp=6.243, rec=0.076, cos=0.001), tot_loss_proj:1.585 [t=0.19s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
Attempt swap
[1450/2000] tot_loss=1.316 (perp=6.243, rec=0.066, cos=0.001), tot_loss_proj:1.573 [t=0.18s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
[1500/2000] tot_loss=1.333 (perp=6.243, rec=0.083, cos=0.001), tot_loss_proj:1.589 [t=0.25s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
Attempt swap
[1550/2000] tot_loss=1.322 (perp=6.243, rec=0.072, cos=0.001), tot_loss_proj:1.579 [t=0.21s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
Attempt swap
[1600/2000] tot_loss=1.324 (perp=6.243, rec=0.075, cos=0.001), tot_loss_proj:1.585 [t=0.29s]
prediction: ['[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]']
[1650/2000] tot_loss=1.463 (perp=6.986, rec=0.064, cos=0.001), tot_loss_proj:1.776 [t=0.20s]
prediction: ['[CLS] an enjoyable successful film and a its adaptation right its own [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.324 (perp=6.268, rec=0.069, cos=0.001), tot_loss_proj:1.641 [t=0.18s]
prediction: ['[CLS] an enjoyable film and a successful its adaptation right its own [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.316 (perp=6.185, rec=0.078, cos=0.001), tot_loss_proj:1.578 [t=0.23s]
prediction: ['[CLS] an enjoyable film and a successful adaptation its right its own [SEP]']
[1800/2000] tot_loss=1.311 (perp=6.185, rec=0.073, cos=0.001), tot_loss_proj:1.575 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation its right its own [SEP]']
Attempt swap
[1850/2000] tot_loss=1.315 (perp=6.185, rec=0.077, cos=0.001), tot_loss_proj:1.584 [t=0.25s]
prediction: ['[CLS] an enjoyable film and a successful adaptation its right its own [SEP]']
Attempt swap
[1900/2000] tot_loss=1.312 (perp=6.185, rec=0.074, cos=0.001), tot_loss_proj:1.581 [t=0.23s]
prediction: ['[CLS] an enjoyable film and a successful adaptation its right its own [SEP]']
[1950/2000] tot_loss=1.311 (perp=6.185, rec=0.073, cos=0.001), tot_loss_proj:1.574 [t=0.19s]
prediction: ['[CLS] an enjoyable film and a successful adaptation its right its own [SEP]']
Attempt swap
[2000/2000] tot_loss=1.307 (perp=6.185, rec=0.068, cos=0.001), tot_loss_proj:1.586 [t=0.26s]
prediction: ['[CLS] an enjoyable film and a successful adaptation its right its own [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] an enjoyable successful film and a successful adaptation right its own [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 53.846 | p: 53.846 | r: 53.846
rougeLsum  | fm: 53.846 | p: 53.846 | r: 53.846
r1fm+r2fm = 125.641

[Aggregate metrics]:
rouge1     | fm: 94.565 | p: 94.060 | r: 95.126
rouge2     | fm: 67.109 | p: 66.784 | r: 67.491
rougeL     | fm: 83.305 | p: 82.963 | r: 83.780
rougeLsum  | fm: 83.411 | p: 83.011 | r: 83.864
r1fm+r2fm = 161.674

input #22 time: 0:08:24 | total time: 3:13:37


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.999235259621351
highest_index [0]
highest [0.999235259621351]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.8047433495521545 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7619422078132629 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.7616995573043823 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell re書amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7562028169631958 for ['[CLS] catching directita antibiotics portrait omeza billy together nile skirtly rovers \\ aw remarks [CLS] soothing nonprofit attitude maybetag amar article tattooll camp [SEP] iii toe been ouaine var outrina " wild addition barry faced travelled rocket leigh engine ribbon abbreviation orders [SEP]']
[Init] best rec loss: 0.7405182719230652 for ['[CLS] ricky chief judas hai north hasiating machinery fathers next shown twitter industry guilty eye media possession grandª variety room cover administrativevere earlier del min fee becomeszzlingap matter trial fact boone pitch arranged saying gutime independence viola battle mentioning motorway song2 belgian [SEP]']
[Init] best rec loss: 0.7381587028503418 for ['[CLS] compiling ears eponymous education carlo debutrk area guᵈ yeah spare span hugolene belowtile draft housing trade box grace these head engineback ter depend likelihood previous meantime steam imagery extra fond those reissued 2 form privatepromising roads schools search maximti gazeshold [SEP]']
[Init] best rec loss: 0.7374657392501831 for ['[CLS] florence heck vineyard breachpping spider hoptive mp ware property exploitation drew genre producer vic 5 alien straw becoming todder cut lackdity takgles queen warner una cloak orientation relations mouth copmed integer dd pearson jessie exterioristic abbreviated extra home round responded facts [SEP]']
[Init] best rec loss: 0.7275494337081909 for ['[CLS]tat erica asleep mayo test bullshit fine air sensation host rockeront into tracks. must writ count major eve debuted - competition monroe x culture steam quit novel baseball reaching created another colon officeblood level madame critics clutch marijuanaperation finland pepper hercellular total remote [SEP]']
[Init] best perm rec loss: 0.7270619869232178 for ['[CLS] baseball remote finlandperation tracks. erica another air her created must total madame marijuana mayo steam quit test monroe clutch fine reaching sensation into writ colon asleeptat eve level office rocker x debuted competitionblood pepper bullshitcellular culture - critics countont host major novel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.874 (perp=11.572, rec=0.434, cos=0.126), tot_loss_proj:3.590 [t=0.24s]
prediction: ['[CLS] achieve archive value plan classic. greater her nhs [SEP] its gwen resource islam offers portion am [SEP] value gt help needs clutching and polish an depth nurse where saving population action exposed geschichte hasduced energy −. solutions. us le command objective goal major hamilton [SEP]']
[ 100/2000] tot_loss=2.785 (perp=12.054, rec=0.329, cos=0.045), tot_loss_proj:3.683 [t=0.20s]
prediction: ['[CLS] provides constitution objectives objectives historical. idea command focuses africa its lacked + escape offers overthrow is with system of puppyrine edition. historical an ultimatelyv revolution save decades conquest objective developments couldm voter the ; solution but investigative battalions pga objective object several its [SEP]']
[ 150/2000] tot_loss=2.336 (perp=10.362, rec=0.255, cos=0.009), tot_loss_proj:3.052 [t=0.19s]
prediction: ['[CLS] initially soldiers objectives strategic historical. idea caused mainicia its grandfather of achieving toneroving is to : ofilly picture edition, historical their ultimately its revolution generation of objective objective : involvingp constituency the ; endemic but investigative soldiers its objective object various : [SEP]']
[ 200/2000] tot_loss=2.320 (perp=10.636, rec=0.188, cos=0.005), tot_loss_proj:3.056 [t=0.19s]
prediction: ['[CLS] initially patriotic strategic strategic historical : idea caused main [SEP] its ultimately the hays whileroving are attain picture of patriotic picture edition, retail its achieve its ultimately generation million objective objective : involvingx constituencygroup ; including but journalist soldiers is objective object various : [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.253 (perp=10.425, rec=0.163, cos=0.005), tot_loss_proj:3.031 [t=0.20s]
prediction: ['[CLS] initially patriotic strategic strategic strategic its picture caused mainizing, ultimately the idea couldroving while achieve room of patriotic picture activity, shortly its achieve its ultimately generation assassinated objective objective :zing the eventually the ; carmine? emotional soldiers eventually objective achieve various the [SEP]']
[ 300/2000] tot_loss=2.312 (perp=10.816, rec=0.146, cos=0.003), tot_loss_proj:3.182 [t=0.19s]
prediction: ['[CLS] initially patriotic strategic strategic strategic its picture caused main [SEP], ultimately the idea couldroving while to room of patriotic picture concept. shortly its achieves ultimately generation assassinated objective objective :zingti generation the ; carmine, journalist soldiers eventually objective achieve various a [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.082 (perp=9.744, rec=0.130, cos=0.004), tot_loss_proj:3.124 [t=0.19s]
prediction: ['[CLS] proposal patriotic strategic strategic strategic a picture drama mainzing, ultimately the idea willroving while to drama of patriotic tone tone. shortly its achieves ultimately generation killed objective objective :zingti generation the ultimately shi, journalist soldiers ultimately ; ultimately vietnam the [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.032 (perp=9.524, rec=0.125, cos=0.003), tot_loss_proj:2.935 [t=0.27s]
prediction: ['[CLS] idea a strategic strategic strategic patriotic picture drama mainzing, ultimately the idea willroving while to drama of patriotic tone tone. while its achieves ultimately generation guggenheim objective objective :zingti generation the ultimately ar, journalist soldiers ultimately ; ultimately vietnam the [SEP]']
[ 450/2000] tot_loss=2.027 (perp=9.542, rec=0.116, cos=0.003), tot_loss_proj:3.019 [t=0.19s]
prediction: ['[CLS] idea a strategic strategic strategic patriotic picture drama mainzing, supporters the idea willroving while to drama of patriotic tone tone. while its achieves ultimately generationzing tone objective :zingti generation the ultimatelyh, journalist soldiers ultimately ; ultimately vietnam the [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.892 (perp=8.875, rec=0.115, cos=0.002), tot_loss_proj:2.763 [t=0.19s]
prediction: ['[CLS] idea a strategic strategic strategic patriotic picture drama ultimatelyzing, supporters the idea will object while with drama of patriotic tone tone. while its achieves ultimately generationzing tone objective : dramati generation the main ra, reporter soldiers ultimately ; ultimately vietnam the [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.093 (perp=9.335, rec=0.205, cos=0.021), tot_loss_proj:3.031 [t=0.20s]
prediction: ['[CLS] idea a strategic strategic strategic vietnam picture generation ultimatelyad, supporters - theory will deny while with drama a patriotic tone tone ; when its achieves ultimately ra minus tone objective : dramati generation as main generation, reporter soldiers ultimately ; achieve near the [SEP]']
[ 600/2000] tot_loss=2.053 (perp=9.559, rec=0.138, cos=0.004), tot_loss_proj:3.110 [t=0.26s]
prediction: ['[CLS] idea a strategic strategic strategic vietnam picture period ultimately draw, supporters - scheme will deny while with drama a patriotic tone tone ; when its achieves ultimately ra minus tone objective : dramati generation as main generation, reporter soldiers ultimately ; achieve near the [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.036 (perp=9.513, rec=0.131, cos=0.003), tot_loss_proj:2.823 [t=0.24s]
prediction: ['[CLS] idea a strategic strategic strategic vietnam picture minus ultimatelyzing, supporters - theory will object while with drama a patriotic tone tone ; when its achieves ultimately ra period tone objective : dramati generation as main generation, reporter soldiers ultimately ; achieve near the [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.015 (perp=9.459, rec=0.121, cos=0.002), tot_loss_proj:2.741 [t=0.25s]
prediction: ['[CLS] idea a strategic strategic strategic vietnam picture minus ultimatelyzing, supporters - theory will object while with drama a patriotic tone tone ; eventually its achieves ultimately ra period tone objective : dramati generation as main generation, ultimately soldiers ultimately ; reporter near the [SEP]']
[ 750/2000] tot_loss=2.041 (perp=9.615, rec=0.117, cos=0.002), tot_loss_proj:2.775 [t=0.19s]
prediction: ['[CLS] idea a strategic strategic strategic vietnam picture minus ultimatelyzing, supporters - theory will object while with dramati patriotic tone tone, eventually its achieves ultimately ra period tone objective : dramati generation as main generation, ultimately soldiers ultimately ; reporter generation the [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.025 (perp=9.557, rec=0.112, cos=0.002), tot_loss_proj:2.837 [t=0.20s]
prediction: ['[CLS] idea a strategic strategic strategic vietnam picture future ultimatelyzing, supporters - ra will object while with dramati patriotic tone tone, eventually its achieves ultimately ra generation tone objective : dramati generation as the main generation, ultimately soldiers ultimately ; reporter generation [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.026 (perp=9.573, rec=0.110, cos=0.002), tot_loss_proj:2.803 [t=0.26s]
prediction: ['[CLS] idea a strategic strategic patriotic vietnam picture consume ultimatelyzing, supporters - ra will object while with dramati patriotic tone tone, eventually ra achieves ultimately its generation tone objective : dramati generation as the main generation, ultimately soldiers ultimately ; reporter generation [SEP]']
[ 900/2000] tot_loss=2.022 (perp=9.573, rec=0.105, cos=0.002), tot_loss_proj:2.795 [t=0.19s]
prediction: ['[CLS] idea a strategic strategic patriotic vietnam picture consume ultimatelyzing, supporters - ra will object while with dramati patriotic tone tone, eventually ra achieves ultimately its generation tone objective : dramati generation as the main generation, ultimately soldiers ultimately ; reporter generation [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.916 (perp=9.034, rec=0.108, cos=0.002), tot_loss_proj:2.643 [t=0.19s]
prediction: ['[CLS] idea a strategic strategic cost vietnam picture when ultimatelyzing, supporters - ra will object while with dramati patriotic tone tone, eventually ra achieves ultimately its patriotic tone objective : dramati generation as the main generation, ultimately soldiers ultimately ; reporter generation [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.904 (perp=8.974, rec=0.107, cos=0.002), tot_loss_proj:2.669 [t=0.19s]
prediction: ['[CLS] idea a strategic strategic picture cost vietnam when ultimatelyzing, supporters - ra will object while with dramati patriotic tone tone, expanded ra achieves ultimately its patriotic tone objective : dramati generation as the main generation, ultimately soldiers ultimately ; reporter generation [SEP]']
[1050/2000] tot_loss=1.898 (perp=8.974, rec=0.102, cos=0.002), tot_loss_proj:2.668 [t=0.24s]
prediction: ['[CLS] idea a strategic strategic picture cost vietnam when ultimatelyzing, supporters - ra will object while with dramati patriotic tone tone, expanded ra achieves ultimately its patriotic tone objective : dramati generation as the main generation, ultimately soldiers ultimately ; reporter generation [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.881 (perp=8.885, rec=0.102, cos=0.002), tot_loss_proj:2.629 [t=0.19s]
prediction: ['[CLS] idea a strategic strategic picture cost vietnam when ultimatelyzing, supporters, ra will object while with dramati patriotic tone tone, expanded ra achieves ultimately its patriotic tone objective : dramati generation as the main generation - ultimately soldiers ultimately ; reporter generation [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.864 (perp=8.795, rec=0.104, cos=0.002), tot_loss_proj:2.606 [t=0.19s]
prediction: ['[CLS] idea a strategic strategic picture cost vietnam when supporterszing, ultimately, ra will object while with dramati patriotic tone tone, expanded ra achieves ultimately its patriotic tone objective : dramati generation as the main generation - ultimately soldiers ultimately ; reporter generation [SEP]']
[1200/2000] tot_loss=1.863 (perp=8.795, rec=0.102, cos=0.002), tot_loss_proj:2.605 [t=0.19s]
prediction: ['[CLS] idea a strategic strategic picture cost vietnam when supporterszing, ultimately, ra will object while with dramati patriotic tone tone, expanded ra achieves ultimately its patriotic tone objective : dramati generation as the main generation - ultimately soldiers ultimately ; reporter generation [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.820 (perp=8.588, rec=0.101, cos=0.002), tot_loss_proj:2.592 [t=0.23s]
prediction: ['[CLS] tone a strategic strategic picture cost vietnam when supporterszing, ultimately, ra will object while with dramati patriotic tone idea, expanded ra achieves ultimately its patriotic tone objective : dramati generation as the main generation - ultimately soldiers ultimately ; reporter generation [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.761 (perp=8.269, rec=0.105, cos=0.002), tot_loss_proj:2.605 [t=0.26s]
prediction: ['[CLS] tone a strategic strategic picture cost vietnam with supporters, ultimately, ra will object while with dramatizing patriotic tone idea, expanded ra achieves ultimately its patriotic tone objective : dramati generation as the main generation - ultimately soldiers ultimately ; reporter generation [SEP]']
[1350/2000] tot_loss=1.845 (perp=8.687, rec=0.106, cos=0.001), tot_loss_proj:2.640 [t=0.21s]
prediction: ['[CLS] tone a strategic strategic picture cost vietnam with supporters, ultimately, ra will object while with ratizing patriotic tone idea, expanded ra achieves ultimately its patriotic tone objective : dramati generation as the main that - ultimately soldiers ultimately ; reporter generation [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.794 (perp=8.456, rec=0.101, cos=0.002), tot_loss_proj:2.616 [t=0.25s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters, ultimately, vietnam will object while with ratizing patriotic tone idea, expanded ra achieves ultimately its patriotic tone objective : dramati generation as the main that the ultimately soldiers ultimately ; reporter + [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.765 (perp=8.306, rec=0.101, cos=0.002), tot_loss_proj:2.533 [t=0.20s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; ultimately, vietnam will object while with ratizing patriotic tone idea, expanded ra achieves ultimately its patriotic tone objective : dramati generation as the main that the ultimately soldiers ultimately, reporter + [SEP]']
[1500/2000] tot_loss=1.774 (perp=8.351, rec=0.102, cos=0.001), tot_loss_proj:2.549 [t=0.20s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; ultimately, vietnam will object while with ratizing patriotic tone idea, expanded ra achieves ultimately its patriotic tone objective : dramati generation. the main that the ultimately soldiers ultimately, reporter + [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.801 (perp=8.483, rec=0.102, cos=0.002), tot_loss_proj:2.617 [t=0.26s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; ultimately, vietnam will object while with ratizing patriotic tone idea, expanded ra achieves ultimately its patriotic tone objective : dramati generation generation the main that the ultimately soldiers ultimately, reporter as [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.769 (perp=8.356, rec=0.096, cos=0.002), tot_loss_proj:2.615 [t=0.20s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; ultimately, ra will object while with ratizing patriotic tone idea, expanded vietnam achieves ultimately its patriotic tone objective : dramati generation generation the main that the ultimately soldiers ultimately, reporter as [SEP]']
[1650/2000] tot_loss=1.786 (perp=8.398, rec=0.104, cos=0.002), tot_loss_proj:2.669 [t=0.26s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; ultimately, ra will object while with ratizing patriotic tone idea, expanded vietnam achieves ultimately its patriotic tone objective : dramati generation generation the main that the ultimately soldiers ultimately, emotional as [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.746 (perp=8.233, rec=0.098, cos=0.002), tot_loss_proj:2.591 [t=0.18s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; ultimately, ra will object while with reportertizing patriotic tone idea, expanded vietnam achieves ultimately its patriotic tone objective : dramati generation generation the main that the ultimately soldiers ultimately, ra as [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.697 (perp=7.996, rec=0.096, cos=0.002), tot_loss_proj:2.513 [t=0.24s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; ultimately, ra will object while with reportertizing patriotic tone idea, expanded vietnam achieves ultimately its patriotic tone objective : dramati generation at the main that the soldiers ultimately ultimately, ra as [SEP]']
[1800/2000] tot_loss=1.701 (perp=7.996, rec=0.101, cos=0.001), tot_loss_proj:2.512 [t=0.26s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; ultimately, ra will object while with reportertizing patriotic tone idea, expanded vietnam achieves ultimately its patriotic tone objective : dramati generation at the main that the soldiers ultimately ultimately, ra as [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.696 (perp=7.953, rec=0.104, cos=0.002), tot_loss_proj:2.512 [t=0.19s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; ultimately, ra will object while with reportertizing patriotic tone idea, expanded vietnam achieves ultimately its patriotic tone objective : dramati generation at the main that the soldiers, ultimately ultimately ra as [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.677 (perp=7.876, rec=0.100, cos=0.002), tot_loss_proj:2.661 [t=0.19s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; main, ra will object that with reportertizing patriotic tone idea, expanded vietnam achieves ultimately its patriotic tone objective : dramati generation at the main while the soldiers, ultimately ultimately ra as [SEP]']
[1950/2000] tot_loss=1.678 (perp=7.876, rec=0.101, cos=0.001), tot_loss_proj:2.665 [t=0.19s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; main, ra will object that with reportertizing patriotic tone idea, expanded vietnam achieves ultimately its patriotic tone objective : dramati generation at the main while the soldiers, ultimately ultimately ra as [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.631 (perp=7.644, rec=0.100, cos=0.002), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] tone a strategic strategic picture cost ra with supporters ; main, ra will object that while reportertizing patriotic tone idea, expanded vietnam achieves ultimately its patriotic tone objective : dramati generation at the main with the soldiers, ultimately ultimately ra as [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] tone a strategic strategic picture cost ra with supporters ; main, ra will object while with reportertizing patriotic tone idea, expanded vietnam achieves ultimately its patriotic tone objective : dramati generation at the main that the soldiers, ultimately ultimately ra as [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 59.259 | p: 58.537 | r: 60.000
rouge2     | fm: 7.595 | p: 7.500 | r: 7.692
rougeL     | fm: 29.630 | p: 29.268 | r: 30.000
rougeLsum  | fm: 29.630 | p: 29.268 | r: 30.000
r1fm+r2fm = 66.854

[Aggregate metrics]:
rouge1     | fm: 93.129 | p: 92.627 | r: 93.792
rouge2     | fm: 64.984 | p: 64.658 | r: 65.312
rougeL     | fm: 81.182 | p: 80.830 | r: 81.633
rougeLsum  | fm: 81.045 | p: 80.668 | r: 81.498
r1fm+r2fm = 158.114

input #23 time: 0:08:44 | total time: 3:22:22


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9993537840940762
highest_index [0]
highest [0.9993537840940762]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.894450843334198 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.867894172668457 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8559075593948364 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.8252934217453003 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.822307825088501 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.8148989677429199 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 0.7632057666778564 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7629173994064331 for ['[CLS]aneous county port play em bond mid damned snow village bush ryuwyl suffer arms attack happy unless younger no [SEP]']
[Init] best perm rec loss: 0.7620291113853455 for ['[CLS] em village damned suffer snow county mid bush attackaneous happy port bond younger unless armswyl no play ryu [SEP]']
[Init] best perm rec loss: 0.7610010504722595 for ['[CLS] em snow no bond suffer villagewyl play bush unlessaneous ryu mid arms port attack damned happy county younger [SEP]']
[Init] best perm rec loss: 0.7564561367034912 for ['[CLS] portaneouswyl em arms attack damned play ryu happy younger bond mid suffer county unless no village bush snow [SEP]']
[Init] best perm rec loss: 0.7562641501426697 for ['[CLS] county damned play sufferaneouswyl younger unless snow no mid happy arms em ryu attack village bush port bond [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.582 (perp=11.092, rec=0.348, cos=0.016), tot_loss_proj:3.092 [t=0.21s]
prediction: ['[CLS] ( evil the political terrorists d activity taken taken terrorists threat market across evil! rigged tony against did! [SEP]']
[ 100/2000] tot_loss=2.308 (perp=10.217, rec=0.257, cos=0.008), tot_loss_proj:3.081 [t=0.22s]
prediction: ['[CLS] ( evil the political indeed under conspiracy taken taken political threat context outside evil! evil situ )! outside [SEP]']
[ 150/2000] tot_loss=2.318 (perp=10.543, rec=0.204, cos=0.006), tot_loss_proj:3.137 [t=0.22s]
prediction: ['[CLS] ( evil the context indeed under conspiracy taken taken political ) context outside evil! terrorists deeply than! outside [SEP]']
[ 200/2000] tot_loss=2.166 (perp=9.980, rec=0.166, cos=0.003), tot_loss_proj:2.890 [t=0.23s]
prediction: ['[CLS] ( evil the context indeed ( circumstances taken taken political climate context outside evil! terrorists less than! outside [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.126 (perp=9.753, rec=0.171, cos=0.004), tot_loss_proj:2.763 [t=0.18s]
prediction: ['[CLS] ( outside the context indeed ( subfamily taken taken political climate context outside evil! terrorists less than! terrorists [SEP]']
[ 300/2000] tot_loss=2.038 (perp=9.463, rec=0.142, cos=0.003), tot_loss_proj:2.856 [t=0.26s]
prediction: ['[CLS] see outside the context indeed ( situation taken taken political climate context outside evil : terrorists than than! terrorists [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.916 (perp=8.865, rec=0.140, cos=0.003), tot_loss_proj:2.695 [t=0.18s]
prediction: ['[CLS] see outside the context! ( situation taken taken political climate context outside evil : terrorists than than terrorists! [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.061 (perp=9.571, rec=0.142, cos=0.005), tot_loss_proj:2.933 [t=0.28s]
prediction: ['[CLS] in see outside are context! situation taken taken political climate context outside evil : terrorists r than terrorists! [SEP]']
[ 450/2000] tot_loss=2.191 (perp=10.293, rec=0.129, cos=0.003), tot_loss_proj:3.204 [t=0.31s]
prediction: ['[CLS] in see outside are context!vial taken taken political climate context outside evil : terrorists deeply than terrorists! [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.108 (perp=9.851, rec=0.135, cos=0.003), tot_loss_proj:3.141 [t=0.19s]
prediction: ['[CLS] are see outside in context!vial taken taken political climate context outside evil : terrorists deeply than terrorists! [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.936 (perp=8.972, rec=0.139, cos=0.003), tot_loss_proj:2.658 [t=0.22s]
prediction: ['[CLS] are see outside of context! : taken taken political climate context outside evil : terrorists ever than which! [SEP]']
[ 600/2000] tot_loss=1.923 (perp=8.972, rec=0.126, cos=0.003), tot_loss_proj:2.665 [t=0.21s]
prediction: ['[CLS] are see outside of context! : taken taken political climate context outside evil : terrorists ever than which! [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.085 (perp=9.751, rec=0.133, cos=0.002), tot_loss_proj:2.984 [t=0.19s]
prediction: ['[CLS] are see outside of political more : taken taken current climate context outside evil : than terrorists ever which! [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.911 (perp=8.904, rec=0.128, cos=0.002), tot_loss_proj:2.790 [t=0.28s]
prediction: ['[CLS] are see outside of political taken : taken more current climate context outside evil : than terrorists ever which! [SEP]']
[ 750/2000] tot_loss=1.905 (perp=8.904, rec=0.123, cos=0.002), tot_loss_proj:2.786 [t=0.21s]
prediction: ['[CLS] are see outside of political taken : taken more current climate context outside evil : than terrorists ever which! [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.887 (perp=8.850, rec=0.115, cos=0.002), tot_loss_proj:2.859 [t=0.19s]
prediction: ['[CLS] are see outside of political taken : more taken current climate context outside evil : than terrorists ever which! [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.831 (perp=8.536, rec=0.123, cos=0.002), tot_loss_proj:2.861 [t=0.19s]
prediction: ['[CLS] are see outside of political taken : more taken current climate context outside evil : terrorists than ever which! [SEP]']
[ 900/2000] tot_loss=1.882 (perp=8.856, rec=0.110, cos=0.002), tot_loss_proj:2.848 [t=0.21s]
prediction: ['[CLS] are see outside of political taken ( more taken current climate context outside evil : terrorists than ever which! [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.811 (perp=8.487, rec=0.111, cos=0.002), tot_loss_proj:2.756 [t=0.19s]
prediction: ['[CLS] are ( see outside of political taken more taken current climate context outside evil : terrorists than ever which! [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.783 (perp=8.308, rec=0.119, cos=0.002), tot_loss_proj:2.709 [t=0.19s]
prediction: ['[CLS] are ( see outside of political taken more taken current climate context outside evil : terrorists than ever! which [SEP]']
[1050/2000] tot_loss=1.772 (perp=8.308, rec=0.108, cos=0.002), tot_loss_proj:2.704 [t=0.19s]
prediction: ['[CLS] are ( see outside of political taken more taken current climate context outside evil : terrorists than ever! which [SEP]']
Attempt swap
[1100/2000] tot_loss=1.781 (perp=8.308, rec=0.118, cos=0.002), tot_loss_proj:2.709 [t=0.28s]
prediction: ['[CLS] are ( see outside of political taken more taken current climate context outside evil : terrorists than ever! which [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.754 (perp=8.205, rec=0.111, cos=0.002), tot_loss_proj:2.671 [t=0.24s]
prediction: ['[CLS] are ( see outside of political taken more current taken climate context outside evil : terrorists than ever! which [SEP]']
[1200/2000] tot_loss=1.749 (perp=8.205, rec=0.107, cos=0.002), tot_loss_proj:2.675 [t=0.21s]
prediction: ['[CLS] are ( see outside of political taken more current taken climate context outside evil : terrorists than ever! which [SEP]']
Attempt swap
[1250/2000] tot_loss=1.760 (perp=8.205, rec=0.117, cos=0.002), tot_loss_proj:2.674 [t=0.19s]
prediction: ['[CLS] are ( see outside of political taken more current taken climate context outside evil : terrorists than ever! which [SEP]']
Attempt swap
[1300/2000] tot_loss=1.754 (perp=8.205, rec=0.111, cos=0.002), tot_loss_proj:2.671 [t=0.20s]
prediction: ['[CLS] are ( see outside of political taken more current taken climate context outside evil : terrorists than ever! which [SEP]']
[1350/2000] tot_loss=1.756 (perp=8.205, rec=0.113, cos=0.002), tot_loss_proj:2.670 [t=0.19s]
prediction: ['[CLS] are ( see outside of political taken more current taken climate context outside evil : terrorists than ever! which [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.674 (perp=7.804, rec=0.111, cos=0.002), tot_loss_proj:2.650 [t=0.19s]
prediction: ['[CLS] are taken ( see outside of political taken more current climate context outside evil : terrorists than ever! which [SEP]']
Attempt swap
[1450/2000] tot_loss=1.676 (perp=7.804, rec=0.113, cos=0.002), tot_loss_proj:2.650 [t=0.19s]
prediction: ['[CLS] are taken ( see outside of political taken more current climate context outside evil : terrorists than ever! which [SEP]']
[1500/2000] tot_loss=1.671 (perp=7.804, rec=0.109, cos=0.002), tot_loss_proj:2.647 [t=0.19s]
prediction: ['[CLS] are taken ( see outside of political taken more current climate context outside evil : terrorists than ever! which [SEP]']
Attempt swap
[1550/2000] tot_loss=1.672 (perp=7.804, rec=0.109, cos=0.002), tot_loss_proj:2.652 [t=0.19s]
prediction: ['[CLS] are taken ( see outside of political taken more current climate context outside evil : terrorists than ever! which [SEP]']
Attempt swap
[1600/2000] tot_loss=1.667 (perp=7.804, rec=0.104, cos=0.002), tot_loss_proj:2.651 [t=0.19s]
prediction: ['[CLS] are taken ( see outside of political taken more current climate context outside evil : terrorists than ever! which [SEP]']
[1650/2000] tot_loss=1.675 (perp=7.804, rec=0.112, cos=0.002), tot_loss_proj:2.651 [t=0.26s]
prediction: ['[CLS] are taken ( see outside of political taken more current climate context outside evil : terrorists than ever! which [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.636 (perp=7.633, rec=0.107, cos=0.002), tot_loss_proj:2.428 [t=0.19s]
prediction: ['[CLS] are taken ( see outside of political taken more context outside current climate evil : terrorists than ever! which [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.589 (perp=7.362, rec=0.115, cos=0.002), tot_loss_proj:2.352 [t=0.26s]
prediction: ['[CLS] are taken ( see outside of political context more taken outside current climate evil : terrorists than ever! which [SEP]']
[1800/2000] tot_loss=1.586 (perp=7.362, rec=0.111, cos=0.002), tot_loss_proj:2.352 [t=0.19s]
prediction: ['[CLS] are taken ( see outside of political context more taken outside current climate evil : terrorists than ever! which [SEP]']
Attempt swap
[1850/2000] tot_loss=1.588 (perp=7.362, rec=0.113, cos=0.002), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] are taken ( see outside of political context more taken outside current climate evil : terrorists than ever! which [SEP]']
Attempt swap
[1900/2000] tot_loss=1.586 (perp=7.362, rec=0.111, cos=0.002), tot_loss_proj:2.348 [t=0.27s]
prediction: ['[CLS] are taken ( see outside of political context more taken outside current climate evil : terrorists than ever! which [SEP]']
[1950/2000] tot_loss=1.581 (perp=7.362, rec=0.106, cos=0.002), tot_loss_proj:2.349 [t=0.19s]
prediction: ['[CLS] are taken ( see outside of political context more taken outside current climate evil : terrorists than ever! which [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.362, rec=0.113, cos=0.002), tot_loss_proj:2.348 [t=0.24s]
prediction: ['[CLS] are taken ( see outside of political context more taken outside current climate evil : terrorists than ever! which [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] are taken ( see outside of political context more taken outside current climate evil : terrorists than ever! which [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.486 | p: 84.211 | r: 88.889
rouge2     | fm: 11.429 | p: 11.111 | r: 11.765
rougeL     | fm: 54.054 | p: 52.632 | r: 55.556
rougeLsum  | fm: 54.054 | p: 52.632 | r: 55.556
r1fm+r2fm = 97.915

[Aggregate metrics]:
rouge1     | fm: 92.969 | p: 92.289 | r: 93.617
rouge2     | fm: 62.623 | p: 62.216 | r: 63.045
rougeL     | fm: 80.166 | p: 79.694 | r: 80.585
rougeLsum  | fm: 79.919 | p: 79.445 | r: 80.477
r1fm+r2fm = 155.593

input #24 time: 0:08:47 | total time: 3:31:09


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9993176191193096
highest_index [0]
highest [0.9993176191193096]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.002394437789917 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9406914114952087 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 0.9302701950073242 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.9185459613800049 for ['[CLS] cigarettes happy before makers [SEP]']
[Init] best rec loss: 0.9134899973869324 for ['[CLS] each envoy socialist achieving [SEP]']
[Init] best rec loss: 0.9054555296897888 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best rec loss: 0.876388669013977 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best perm rec loss: 0.875738263130188 for ['[CLS] cycle oblast jury mouth [SEP]']
[Init] best perm rec loss: 0.8756436705589294 for ['[CLS] oblast cycle jury mouth [SEP]']
[Init] best perm rec loss: 0.8743534088134766 for ['[CLS] oblast jury mouth cycle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.351 (perp=10.560, rec=0.235, cos=0.005), tot_loss_proj:2.782 [t=0.18s]
prediction: ['[CLS] beautiful film strange strange [SEP]']
[ 100/2000] tot_loss=2.229 (perp=10.560, rec=0.115, cos=0.002), tot_loss_proj:2.788 [t=0.24s]
prediction: ['[CLS] beautiful film strange strange [SEP]']
[ 150/2000] tot_loss=2.209 (perp=10.560, rec=0.096, cos=0.002), tot_loss_proj:2.812 [t=0.26s]
prediction: ['[CLS] beautiful film strange strange [SEP]']
[ 200/2000] tot_loss=1.921 (perp=9.132, rec=0.093, cos=0.002), tot_loss_proj:2.098 [t=0.19s]
prediction: ['[CLS] beautiful film and strange [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.764 (perp=8.257, rec=0.110, cos=0.002), tot_loss_proj:1.929 [t=0.22s]
prediction: ['[CLS] beautiful & strange film [SEP]']
[ 300/2000] tot_loss=1.521 (perp=7.104, rec=0.098, cos=0.002), tot_loss_proj:1.619 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.700 (perp=8.039, rec=0.091, cos=0.002), tot_loss_proj:2.223 [t=0.20s]
prediction: ['[CLS] beautiful or strange film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.512 (perp=7.104, rec=0.089, cos=0.002), tot_loss_proj:1.624 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[ 450/2000] tot_loss=1.522 (perp=7.104, rec=0.099, cos=0.002), tot_loss_proj:1.620 [t=0.23s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.408 (perp=6.646, rec=0.077, cos=0.002), tot_loss_proj:1.439 [t=0.21s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.439 [t=0.21s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.433 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.421 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.444 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.393 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.442 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.388 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.437 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.436 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.441 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.390 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.427 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.388 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.436 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.399 (perp=6.646, rec=0.069, cos=0.001), tot_loss_proj:1.438 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.444 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.428 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.432 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.431 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.436 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.384 (perp=6.646, rec=0.054, cos=0.001), tot_loss_proj:1.434 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.400 (perp=6.646, rec=0.070, cos=0.001), tot_loss_proj:1.425 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.439 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.387 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.437 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.429 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.390 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.428 [t=0.20s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.384 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.436 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.386 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.430 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.427 [t=0.27s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.387 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.427 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.398 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.435 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.387 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.445 [t=0.25s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.388 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.430 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.396 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.437 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.175 | p: 92.536 | r: 93.815
rouge2     | fm: 64.176 | p: 63.774 | r: 64.631
rougeL     | fm: 80.884 | p: 80.439 | r: 81.387
rougeLsum  | fm: 80.658 | p: 80.213 | r: 81.096
r1fm+r2fm = 157.351

input #25 time: 0:08:30 | total time: 3:39:40


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9992061826546763
highest_index [0]
highest [0.9992061826546763]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.9740388989448547 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.9654331803321838 for ['[CLS] arthur senior green europa out reach o approaching beck saga phone kimball range tel alain pointing spoil during people na tanggram bucket [SEP]']
[Init] best rec loss: 0.959073543548584 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 0.9550803303718567 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 0.9425822496414185 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.9396986365318298 for ['[CLS] own aren solelyval hull shoot [CLS] letter four t gore plan when how marsh recently assessment throughout hiv bequeathed administrative liberty branch [SEP]']
[Init] best rec loss: 0.9339746832847595 for ['[CLS] frozen peru embarrassed not one farimus sole australian clearance ladder | heir stevie covert dollars hunter allmusic post remain depending⁺ isolation [SEP]']
[Init] best rec loss: 0.8896158337593079 for ['[CLS] also space add ao intent bat intentם should huge charity family timeline rectangular whom failed list supposed boat deputyness teaches hair [SEP]']
[Init] best perm rec loss: 0.8848931789398193 for ['[CLS] ao also supposed failed bat rectangular space huge teaches deputy familyם add intentness hair boat whom intent should list timeline charity [SEP]']
[Init] best perm rec loss: 0.8846459984779358 for ['[CLS] boat huge supposed hair teaches ao rectangular deputy should bat family also addם whomness space timeline charity intent failed intent list [SEP]']
[Init] best perm rec loss: 0.8816198706626892 for ['[CLS] add also failed timeline whom list bat space hairness teaches ao familyם boat charity intent huge deputy intent supposed should rectangular [SEP]']
[Init] best perm rec loss: 0.8793452978134155 for ['[CLS] also family list supposed teaches ao bat hair space failed intentness whom huge intent add boat should rectangular deputy charityם timeline [SEP]']
[Init] best perm rec loss: 0.878869354724884 for ['[CLS] space hairם intent also timeline supposed boatness teaches should family huge whom ao list rectangular charity add failed intent bat deputy [SEP]']
[Init] best perm rec loss: 0.8787726163864136 for ['[CLS] bat rectangular intent should space timeline family alsoם failed teaches charity add boatness ao deputy supposed huge intent whom list hair [SEP]']
[Init] best perm rec loss: 0.8780877590179443 for ['[CLS] huge list add spaceם bat also family hair failed teaches boat should deputy intent supposed intent aoness charity whom timeline rectangular [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.789 (perp=12.504, rec=0.279, cos=0.009), tot_loss_proj:3.167 [t=0.18s]
prediction: ['[CLS] pointless bound circumstances expand else spanish import accompanying pointless incident, pointless increasingly ) dowager with latin pointless import extra authority import card [SEP]']
[ 100/2000] tot_loss=2.442 (perp=11.163, rec=0.204, cos=0.006), tot_loss_proj:2.808 [t=0.26s]
prediction: ['[CLS] pointless - aloudtropical from french import including pointless for ) pointless increasingly french anne - coming on import age owner import - [SEP]']
[ 150/2000] tot_loss=2.201 (perp=10.125, rec=0.173, cos=0.003), tot_loss_proj:2.581 [t=0.27s]
prediction: ['[CLS] pointless - director sophie from french import this pointless client ) pointless - french anne - coming - import age director import - [SEP]']
[ 200/2000] tot_loss=2.118 (perp=9.896, rec=0.136, cos=0.002), tot_loss_proj:2.560 [t=0.19s]
prediction: ['[CLS] pointless - director anne from french import this mean client ) pointless age french anne - coming - from age director mean - [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.936 (perp=9.059, rec=0.122, cos=0.002), tot_loss_proj:2.358 [t=0.22s]
prediction: ['[CLS] pointless -der anne from french import this and : ) pointless - french mean - coming - from age director anne - [SEP]']
[ 300/2000] tot_loss=1.970 (perp=8.776, rec=0.205, cos=0.009), tot_loss_proj:2.344 [t=0.25s]
prediction: ['[CLS] pointless - and anne season french import this and - ) pointless - french mean - coming - from age director anne - [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.935 (perp=8.807, rec=0.169, cos=0.004), tot_loss_proj:2.313 [t=0.22s]
prediction: ['[CLS] pointless - and anne and french import this season writer ) pointless age and mean - coming - from age director sophie - [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.818 (perp=8.390, rec=0.138, cos=0.002), tot_loss_proj:2.235 [t=0.25s]
prediction: ['[CLS] pointless - - anne and french import this season writer ) pointless age and mean - coming - from age director sophie - [SEP]']
[ 450/2000] tot_loss=1.806 (perp=8.390, rec=0.126, cos=0.002), tot_loss_proj:2.228 [t=0.19s]
prediction: ['[CLS] pointless - - anne and french import this season writer ) pointless age and mean - coming - from age director sophie - [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.913 (perp=9.001, rec=0.111, cos=0.002), tot_loss_proj:2.325 [t=0.23s]
prediction: ['[CLS] - -ing anne and french import this pointless writer ) pointless age and mean - coming - from age director sophie - [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.815 (perp=8.556, rec=0.102, cos=0.002), tot_loss_proj:2.236 [t=0.18s]
prediction: ['[CLS]ing - - anne and french import this pointless writer ) pointless age and mean - coming - from age director sophie - [SEP]']
[ 600/2000] tot_loss=1.809 (perp=8.556, rec=0.096, cos=0.002), tot_loss_proj:2.234 [t=0.18s]
prediction: ['[CLS]ing - - anne and french import this pointless writer ) pointless age and mean - coming - from age director sophie - [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.771 (perp=8.291, rec=0.111, cos=0.002), tot_loss_proj:2.207 [t=0.19s]
prediction: ['[CLS]ing - - anne and french import this pointless writer ) pointless age and mean - - coming from age director sophie - [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.726 (perp=8.073, rec=0.109, cos=0.002), tot_loss_proj:2.172 [t=0.21s]
prediction: ['[CLS] thising - - anne and french import pointless writer ) pointless age and mean - - coming from age director sophie - [SEP]']
[ 750/2000] tot_loss=1.716 (perp=8.073, rec=0.100, cos=0.002), tot_loss_proj:2.163 [t=0.19s]
prediction: ['[CLS] thising - - anne and french import pointless writer ) pointless age and mean - - coming from age director sophie - [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.613 (perp=7.617, rec=0.088, cos=0.002), tot_loss_proj:2.107 [t=0.19s]
prediction: ['[CLS] thising - - - and french import pointless writer ) pointless age and mean - - coming from age director sophie anne [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.608 (perp=7.565, rec=0.093, cos=0.002), tot_loss_proj:2.209 [t=0.20s]
prediction: ['[CLS] thising - - - and french import pointless writer pointless age ) and mean - - coming from age director sophie anne [SEP]']
[ 900/2000] tot_loss=1.607 (perp=7.565, rec=0.092, cos=0.002), tot_loss_proj:2.209 [t=0.22s]
prediction: ['[CLS] thising - - - and french import pointless writer pointless age ) and mean - - coming from age director sophie anne [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.702 (perp=8.019, rec=0.096, cos=0.002), tot_loss_proj:2.338 [t=0.27s]
prediction: ['[CLS] thising - - of and french import pointless writer pointless age ) and - - mean coming from age director sophie anne [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.613 (perp=7.593, rec=0.093, cos=0.002), tot_loss_proj:2.349 [t=0.19s]
prediction: ['[CLS] thising - - and of french import pointless writer pointless age ) and - - mean coming from age director sophie anne [SEP]']
[1050/2000] tot_loss=1.744 (perp=8.283, rec=0.086, cos=0.002), tot_loss_proj:2.581 [t=0.21s]
prediction: ['[CLS] thisingder - and of french import pointless writer pointless age ) and - - mean coming from age director sophie anne [SEP]']
Attempt swap
[1100/2000] tot_loss=1.744 (perp=8.283, rec=0.086, cos=0.002), tot_loss_proj:2.574 [t=0.25s]
prediction: ['[CLS] thisingder - and of french import pointless writer pointless age ) and - - mean coming from age director sophie anne [SEP]']
Attempt swap
[1150/2000] tot_loss=1.745 (perp=8.283, rec=0.086, cos=0.002), tot_loss_proj:2.578 [t=0.19s]
prediction: ['[CLS] thisingder - and of french import pointless writer pointless age ) and - - mean coming from age director sophie anne [SEP]']
[1200/2000] tot_loss=1.751 (perp=8.283, rec=0.093, cos=0.002), tot_loss_proj:2.579 [t=0.25s]
prediction: ['[CLS] thisingder - and of french import pointless writer pointless age ) and - - mean coming from age director sophie anne [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.807 (perp=8.593, rec=0.087, cos=0.002), tot_loss_proj:2.512 [t=0.29s]
prediction: ['[CLS] thisderingder and of french import pointless writer pointless age ) and - - mean coming from age director sophie anne [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.727 (perp=8.005, rec=0.121, cos=0.004), tot_loss_proj:2.545 [t=0.21s]
prediction: ['[CLS] meanderingder and of french import pointless writer pointless age ) and - - this coming from age director sophie anne [SEP]']
[1350/2000] tot_loss=1.699 (perp=8.005, rec=0.096, cos=0.002), tot_loss_proj:2.547 [t=0.20s]
prediction: ['[CLS] meanderingder and of french import pointless writer pointless age ) and - - this coming from age director sophie anne [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.621 (perp=7.650, rec=0.089, cos=0.002), tot_loss_proj:2.432 [t=0.19s]
prediction: ['[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director sophie anne [SEP]']
Attempt swap
[1450/2000] tot_loss=1.618 (perp=7.650, rec=0.087, cos=0.002), tot_loss_proj:2.427 [t=0.24s]
prediction: ['[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director sophie anne [SEP]']
[1500/2000] tot_loss=1.613 (perp=7.650, rec=0.081, cos=0.002), tot_loss_proj:2.428 [t=0.28s]
prediction: ['[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director sophie anne [SEP]']
Attempt swap
[1550/2000] tot_loss=1.610 (perp=7.650, rec=0.078, cos=0.002), tot_loss_proj:2.434 [t=0.19s]
prediction: ['[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director sophie anne [SEP]']
Attempt swap
[1600/2000] tot_loss=1.619 (perp=7.650, rec=0.087, cos=0.002), tot_loss_proj:2.431 [t=0.26s]
prediction: ['[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director sophie anne [SEP]']
[1650/2000] tot_loss=1.611 (perp=7.650, rec=0.079, cos=0.002), tot_loss_proj:2.428 [t=0.19s]
prediction: ['[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director sophie anne [SEP]']
Attempt swap
[1700/2000] tot_loss=1.613 (perp=7.650, rec=0.082, cos=0.002), tot_loss_proj:2.431 [t=0.21s]
prediction: ['[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director sophie anne [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.636 (perp=7.707, rec=0.093, cos=0.002), tot_loss_proj:2.671 [t=0.19s]
prediction: ['[CLS] meanderingder and french import writer pointless pointless age ) and - - this coming from age of director sophie anne [SEP]']
[1800/2000] tot_loss=1.621 (perp=7.707, rec=0.078, cos=0.002), tot_loss_proj:2.671 [t=0.19s]
prediction: ['[CLS] meanderingder and french import writer pointless pointless age ) and - - this coming from age of director sophie anne [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.635 (perp=7.726, rec=0.088, cos=0.002), tot_loss_proj:2.685 [t=0.30s]
prediction: ['[CLS] meanderingder and french import writer pointless pointless age ) and - - this coming from age of director anne sophie [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.620 (perp=7.672, rec=0.084, cos=0.002), tot_loss_proj:2.430 [t=0.19s]
prediction: ['[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director anne sophie [SEP]']
[1950/2000] tot_loss=1.614 (perp=7.672, rec=0.078, cos=0.002), tot_loss_proj:2.437 [t=0.21s]
prediction: ['[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director anne sophie [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.617 (perp=7.650, rec=0.086, cos=0.002), tot_loss_proj:2.428 [t=0.19s]
prediction: ['[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director sophie anne [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] meanderingder and french import pointless writer pointless age ) and - - this coming from age of director sophie anne [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 78.947 | r: 88.235
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 42.105 | r: 47.059
rougeLsum  | fm: 44.444 | p: 42.105 | r: 47.059
r1fm+r2fm = 83.333

[Aggregate metrics]:
rouge1     | fm: 92.801 | p: 92.086 | r: 93.671
rouge2     | fm: 61.634 | p: 61.334 | r: 62.040
rougeL     | fm: 79.544 | p: 79.133 | r: 80.097
rougeLsum  | fm: 79.364 | p: 78.873 | r: 79.892
r1fm+r2fm = 154.435

input #26 time: 0:08:41 | total time: 3:48:21


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.999345236003067
highest_index [0]
highest [0.999345236003067]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9609618782997131 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9331122636795044 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9077965617179871 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.8589619994163513 for ['[CLS] landing imposed distant [SEP]']
[Init] best rec loss: 0.8030321598052979 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.8014320135116577 for ['[CLS] transit givenwine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.756 (perp=13.068, rec=0.726, cos=0.416), tot_loss_proj:3.238 [t=0.19s]
prediction: ['[CLS] em delivered generic [SEP]']
[ 100/2000] tot_loss=3.272 (perp=11.753, rec=0.639, cos=0.283), tot_loss_proj:2.819 [t=0.23s]
prediction: ['[CLS] generic looked generic [SEP]']
[ 150/2000] tot_loss=2.795 (perp=9.693, rec=0.610, cos=0.247), tot_loss_proj:2.521 [t=0.30s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 200/2000] tot_loss=3.227 (perp=11.128, rec=0.682, cos=0.319), tot_loss_proj:2.856 [t=0.19s]
prediction: ['[CLS] generic generic iris [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.057 (perp=11.128, rec=0.589, cos=0.242), tot_loss_proj:2.858 [t=0.18s]
prediction: ['[CLS] generic generic iris [SEP]']
[ 300/2000] tot_loss=3.024 (perp=11.182, rec=0.572, cos=0.216), tot_loss_proj:2.819 [t=0.25s]
prediction: ['[CLS] generic generic carmen [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.708 (perp=9.693, rec=0.570, cos=0.200), tot_loss_proj:2.516 [t=0.23s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.640 (perp=9.693, rec=0.544, cos=0.158), tot_loss_proj:2.519 [t=0.19s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 450/2000] tot_loss=2.596 (perp=9.693, rec=0.528, cos=0.130), tot_loss_proj:2.529 [t=0.21s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.616 (perp=9.693, rec=0.529, cos=0.149), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.551 (perp=9.693, rec=0.513, cos=0.099), tot_loss_proj:2.521 [t=0.22s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 600/2000] tot_loss=2.793 (perp=10.851, rec=0.499, cos=0.124), tot_loss_proj:2.686 [t=0.19s]
prediction: ['[CLS] generic generic simply [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.974 (perp=11.947, rec=0.490, cos=0.095), tot_loss_proj:3.028 [t=0.19s]
prediction: ['[CLS] generic generic medieval [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.971 (perp=11.947, rec=0.493, cos=0.089), tot_loss_proj:3.021 [t=0.19s]
prediction: ['[CLS] generic generic medieval [SEP]']
[ 750/2000] tot_loss=2.740 (perp=10.851, rec=0.491, cos=0.079), tot_loss_proj:2.693 [t=0.23s]
prediction: ['[CLS] generic generic simply [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.748 (perp=10.851, rec=0.483, cos=0.095), tot_loss_proj:2.696 [t=0.25s]
prediction: ['[CLS] generic generic simply [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.801 (perp=11.227, rec=0.479, cos=0.077), tot_loss_proj:2.814 [t=0.21s]
prediction: ['[CLS] generic generic drawer [SEP]']
[ 900/2000] tot_loss=3.052 (perp=11.227, rec=0.560, cos=0.246), tot_loss_proj:2.809 [t=0.19s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.800 (perp=11.227, rec=0.469, cos=0.086), tot_loss_proj:2.808 [t=0.20s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1000/2000] tot_loss=2.786 (perp=11.227, rec=0.467, cos=0.073), tot_loss_proj:2.808 [t=0.18s]
prediction: ['[CLS] generic generic drawer [SEP]']
[1050/2000] tot_loss=2.780 (perp=11.227, rec=0.466, cos=0.069), tot_loss_proj:2.813 [t=0.18s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1100/2000] tot_loss=2.766 (perp=11.227, rec=0.458, cos=0.062), tot_loss_proj:2.817 [t=0.19s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1150/2000] tot_loss=2.767 (perp=11.227, rec=0.462, cos=0.061), tot_loss_proj:2.807 [t=0.19s]
prediction: ['[CLS] generic generic drawer [SEP]']
[1200/2000] tot_loss=2.759 (perp=11.227, rec=0.458, cos=0.056), tot_loss_proj:2.813 [t=0.21s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1250/2000] tot_loss=2.759 (perp=11.227, rec=0.462, cos=0.052), tot_loss_proj:2.808 [t=0.19s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1300/2000] tot_loss=2.752 (perp=11.227, rec=0.456, cos=0.050), tot_loss_proj:2.812 [t=0.19s]
prediction: ['[CLS] generic generic drawer [SEP]']
[1350/2000] tot_loss=2.747 (perp=11.227, rec=0.453, cos=0.048), tot_loss_proj:2.810 [t=0.23s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1400/2000] tot_loss=2.747 (perp=11.227, rec=0.455, cos=0.046), tot_loss_proj:2.806 [t=0.19s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1450/2000] tot_loss=2.742 (perp=11.227, rec=0.453, cos=0.043), tot_loss_proj:2.804 [t=0.18s]
prediction: ['[CLS] generic generic drawer [SEP]']
[1500/2000] tot_loss=2.739 (perp=11.227, rec=0.452, cos=0.042), tot_loss_proj:2.814 [t=0.26s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1550/2000] tot_loss=2.730 (perp=11.227, rec=0.447, cos=0.038), tot_loss_proj:2.816 [t=0.18s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1600/2000] tot_loss=2.746 (perp=11.227, rec=0.463, cos=0.037), tot_loss_proj:2.814 [t=0.22s]
prediction: ['[CLS] generic generic drawer [SEP]']
[1650/2000] tot_loss=2.728 (perp=11.227, rec=0.447, cos=0.036), tot_loss_proj:2.810 [t=0.20s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1700/2000] tot_loss=2.724 (perp=11.227, rec=0.446, cos=0.033), tot_loss_proj:2.818 [t=0.26s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1750/2000] tot_loss=2.728 (perp=11.227, rec=0.450, cos=0.032), tot_loss_proj:2.817 [t=0.25s]
prediction: ['[CLS] generic generic drawer [SEP]']
[1800/2000] tot_loss=2.727 (perp=11.227, rec=0.451, cos=0.030), tot_loss_proj:2.805 [t=0.21s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1850/2000] tot_loss=2.718 (perp=11.227, rec=0.443, cos=0.029), tot_loss_proj:2.811 [t=0.19s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[1900/2000] tot_loss=2.731 (perp=11.227, rec=0.459, cos=0.027), tot_loss_proj:2.812 [t=0.27s]
prediction: ['[CLS] generic generic drawer [SEP]']
[1950/2000] tot_loss=2.721 (perp=11.227, rec=0.451, cos=0.025), tot_loss_proj:2.812 [t=0.19s]
prediction: ['[CLS] generic generic drawer [SEP]']
Attempt swap
[2000/2000] tot_loss=2.715 (perp=11.227, rec=0.445, cos=0.024), tot_loss_proj:2.810 [t=0.22s]
prediction: ['[CLS] generic generic drawer [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] generic generic drawer [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 60.000

[Aggregate metrics]:
rouge1     | fm: 91.613 | p: 90.982 | r: 92.373
rouge2     | fm: 59.113 | p: 58.771 | r: 59.513
rougeL     | fm: 78.696 | p: 78.196 | r: 79.187
rougeLsum  | fm: 78.441 | p: 77.972 | r: 79.026
r1fm+r2fm = 150.725

input #27 time: 0:08:26 | total time: 3:56:47


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.9993345319062628
highest_index [0]
highest [0.9993345319062628]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8165134787559509 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.7931988835334778 for ['[CLS] guests mackenzie voyager reader [SEP]']
[Init] best rec loss: 0.7827070355415344 for ['[CLS] james facilitieslty ¨ [SEP]']
[Init] best rec loss: 0.7524273991584778 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best rec loss: 0.7502107620239258 for ['[CLS]vron sex guessed morgan [SEP]']
[Init] best perm rec loss: 0.7490264177322388 for ['[CLS] guessed morganvron sex [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.105 (perp=9.007, rec=0.283, cos=0.020), tot_loss_proj:3.014 [t=0.18s]
prediction: ['[CLS] delay for minutes holding [SEP]']
[ 100/2000] tot_loss=1.934 (perp=8.954, rec=0.131, cos=0.013), tot_loss_proj:2.912 [t=0.19s]
prediction: ['[CLS] minutes for minutes 71 [SEP]']
[ 150/2000] tot_loss=1.622 (perp=7.564, rec=0.100, cos=0.009), tot_loss_proj:2.502 [t=0.19s]
prediction: ['[CLS] minutes for minutes only [SEP]']
[ 200/2000] tot_loss=1.625 (perp=7.564, rec=0.105, cos=0.007), tot_loss_proj:2.520 [t=0.28s]
prediction: ['[CLS] minutes for minutes only [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.618 (perp=7.564, rec=0.099, cos=0.006), tot_loss_proj:2.510 [t=0.23s]
prediction: ['[CLS] minutes for minutes only [SEP]']
[ 300/2000] tot_loss=1.604 (perp=7.564, rec=0.087, cos=0.005), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] minutes for minutes only [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.959 (perp=9.252, rec=0.106, cos=0.002), tot_loss_proj:2.798 [t=0.21s]
prediction: ['[CLS] 71 for minutes only [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.566 (perp=7.445, rec=0.075, cos=0.002), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=1.563 (perp=7.445, rec=0.073, cos=0.001), tot_loss_proj:1.837 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.559 (perp=7.445, rec=0.069, cos=0.001), tot_loss_proj:1.842 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.554 (perp=7.445, rec=0.064, cos=0.001), tot_loss_proj:1.845 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=1.555 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.843 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.553 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.838 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.542 (perp=7.445, rec=0.051, cos=0.001), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=1.560 (perp=7.445, rec=0.070, cos=0.001), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.562 (perp=7.445, rec=0.072, cos=0.001), tot_loss_proj:1.835 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.559 (perp=7.445, rec=0.069, cos=0.001), tot_loss_proj:1.841 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=1.558 (perp=7.445, rec=0.068, cos=0.001), tot_loss_proj:1.850 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.556 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.837 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=1.545 (perp=7.445, rec=0.055, cos=0.001), tot_loss_proj:1.845 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=1.552 (perp=7.445, rec=0.062, cos=0.001), tot_loss_proj:1.839 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=1.550 (perp=7.445, rec=0.060, cos=0.001), tot_loss_proj:1.839 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=1.555 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.840 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.845 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=1.565 (perp=7.445, rec=0.075, cos=0.001), tot_loss_proj:1.841 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=1.542 (perp=7.445, rec=0.052, cos=0.001), tot_loss_proj:1.845 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.843 [t=0.26s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=1.545 (perp=7.445, rec=0.054, cos=0.001), tot_loss_proj:1.847 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=1.540 (perp=7.445, rec=0.049, cos=0.001), tot_loss_proj:1.841 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=1.557 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.838 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=1.560 (perp=7.445, rec=0.070, cos=0.001), tot_loss_proj:1.843 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=1.542 (perp=7.445, rec=0.051, cos=0.001), tot_loss_proj:1.852 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=1.562 (perp=7.445, rec=0.071, cos=0.001), tot_loss_proj:1.841 [t=0.28s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=1.559 (perp=7.445, rec=0.068, cos=0.001), tot_loss_proj:1.850 [t=0.29s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.840 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=1.554 (perp=7.445, rec=0.064, cos=0.001), tot_loss_proj:1.844 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=1.558 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.843 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=1.559 (perp=7.445, rec=0.069, cos=0.001), tot_loss_proj:1.844 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.837 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=1.555 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.843 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 91.862 | p: 91.215 | r: 92.589
rouge2     | fm: 58.350 | p: 58.110 | r: 58.710
rougeL     | fm: 78.745 | p: 78.253 | r: 79.295
rougeLsum  | fm: 78.790 | p: 78.242 | r: 79.346
r1fm+r2fm = 150.212

input #28 time: 0:08:30 | total time: 4:05:18


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9992943703711437
highest_index [0]
highest [0.9992943703711437]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.9436143040657043 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.9236282706260681 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.9098904132843018 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.8565943837165833 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8468968868255615 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 0.8464521765708923 for ['[CLS] lordship buckingham rather postsbor we home wildlife valleygan [SEP]']
[Init] best rec loss: 0.844285249710083 for ['[CLS] downke his heir wantedø degree opposition march head [SEP]']
[Init] best rec loss: 0.8212891221046448 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 0.8188213109970093 for ['[CLS] type attack www estate ambulance + chelsealand out todd [SEP]']
[Init] best rec loss: 0.8150292038917542 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 0.8131462931632996 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 0.8110625147819519 for ['[CLS] tv oil envelope administration taste this engagementuted runs landed [SEP]']
[Init] best perm rec loss: 0.8109373450279236 for ['[CLS] runs administration tv oil this taste landed engagement envelopeuted [SEP]']
[Init] best perm rec loss: 0.8048712015151978 for ['[CLS] taste landed tv this engagementuted runs oil administration envelope [SEP]']
[Init] best perm rec loss: 0.8036940097808838 for ['[CLS] runs taste engagementuted envelope oil this tv landed administration [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.641 (perp=11.389, rec=0.334, cos=0.030), tot_loss_proj:3.350 [t=0.25s]
prediction: ['[CLS] which believe murder believe. officials violent his cop null [SEP]']
[ 100/2000] tot_loss=1.945 (perp=8.487, rec=0.232, cos=0.016), tot_loss_proj:3.043 [t=0.18s]
prediction: ['[CLS] also believe resident witch. believe is that evil not [SEP]']
[ 150/2000] tot_loss=1.849 (perp=8.208, rec=0.194, cos=0.013), tot_loss_proj:3.090 [t=0.19s]
prediction: ['[CLS] also believe resident witch. also is that evil not [SEP]']
[ 200/2000] tot_loss=1.575 (perp=7.119, rec=0.144, cos=0.007), tot_loss_proj:2.776 [t=0.19s]
prediction: ['[CLS] also believe resident evil. also is that it not [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.248 (perp=5.397, rec=0.159, cos=0.010), tot_loss_proj:1.956 [t=0.19s]
prediction: ['[CLS] i believe resident evil. also that it is not [SEP]']
[ 300/2000] tot_loss=1.187 (perp=5.397, rec=0.104, cos=0.004), tot_loss_proj:1.960 [t=0.18s]
prediction: ['[CLS] i believe resident evil. also that it is not [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.460 (perp=5.397, rec=0.320, cos=0.061), tot_loss_proj:1.911 [t=0.19s]
prediction: ['[CLS] i believe resident evil. also that it is not [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.219 (perp=5.058, rec=0.195, cos=0.012), tot_loss_proj:2.180 [t=0.18s]
prediction: ['[CLS] i believe also that resident evil. it is not [SEP]']
[ 450/2000] tot_loss=1.185 (perp=5.058, rec=0.166, cos=0.007), tot_loss_proj:2.177 [t=0.20s]
prediction: ['[CLS] i believe also that resident evil. it is not [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.129 (perp=4.884, rec=0.147, cos=0.006), tot_loss_proj:2.190 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.110 (perp=4.884, rec=0.128, cos=0.005), tot_loss_proj:2.183 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[ 600/2000] tot_loss=1.101 (perp=4.884, rec=0.120, cos=0.004), tot_loss_proj:2.182 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.095 (perp=4.884, rec=0.115, cos=0.004), tot_loss_proj:2.186 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.098 (perp=4.884, rec=0.117, cos=0.005), tot_loss_proj:2.189 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[ 750/2000] tot_loss=1.095 (perp=4.884, rec=0.115, cos=0.004), tot_loss_proj:2.179 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.085 (perp=4.884, rec=0.104, cos=0.004), tot_loss_proj:2.183 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.069 (perp=4.884, rec=0.089, cos=0.003), tot_loss_proj:2.178 [t=0.23s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[ 900/2000] tot_loss=1.077 (perp=4.884, rec=0.097, cos=0.003), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.078 (perp=4.884, rec=0.098, cos=0.003), tot_loss_proj:2.174 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1000/2000] tot_loss=1.075 (perp=4.884, rec=0.095, cos=0.003), tot_loss_proj:2.177 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1050/2000] tot_loss=1.074 (perp=4.884, rec=0.094, cos=0.003), tot_loss_proj:2.175 [t=0.21s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1100/2000] tot_loss=1.069 (perp=4.884, rec=0.089, cos=0.003), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1150/2000] tot_loss=1.074 (perp=4.884, rec=0.094, cos=0.003), tot_loss_proj:2.169 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1200/2000] tot_loss=1.078 (perp=4.884, rec=0.098, cos=0.003), tot_loss_proj:2.182 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1250/2000] tot_loss=1.070 (perp=4.884, rec=0.090, cos=0.003), tot_loss_proj:2.169 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1300/2000] tot_loss=1.074 (perp=4.884, rec=0.094, cos=0.003), tot_loss_proj:2.170 [t=0.21s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1350/2000] tot_loss=1.070 (perp=4.884, rec=0.090, cos=0.003), tot_loss_proj:2.162 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1400/2000] tot_loss=1.073 (perp=4.884, rec=0.093, cos=0.003), tot_loss_proj:2.177 [t=0.23s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1450/2000] tot_loss=1.070 (perp=4.884, rec=0.090, cos=0.003), tot_loss_proj:2.173 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1500/2000] tot_loss=1.077 (perp=4.884, rec=0.097, cos=0.003), tot_loss_proj:2.163 [t=0.21s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1550/2000] tot_loss=1.075 (perp=4.884, rec=0.095, cos=0.003), tot_loss_proj:2.165 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1600/2000] tot_loss=1.076 (perp=4.884, rec=0.096, cos=0.003), tot_loss_proj:2.167 [t=0.21s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1650/2000] tot_loss=1.059 (perp=4.884, rec=0.079, cos=0.003), tot_loss_proj:2.173 [t=0.20s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1700/2000] tot_loss=1.068 (perp=4.884, rec=0.088, cos=0.003), tot_loss_proj:2.171 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1750/2000] tot_loss=1.068 (perp=4.884, rec=0.088, cos=0.003), tot_loss_proj:2.166 [t=0.23s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1800/2000] tot_loss=1.070 (perp=4.884, rec=0.091, cos=0.003), tot_loss_proj:2.169 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1850/2000] tot_loss=1.066 (perp=4.884, rec=0.086, cos=0.003), tot_loss_proj:2.167 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1900/2000] tot_loss=1.066 (perp=4.884, rec=0.086, cos=0.003), tot_loss_proj:2.173 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1950/2000] tot_loss=1.069 (perp=4.884, rec=0.090, cos=0.003), tot_loss_proj:2.173 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[2000/2000] tot_loss=1.069 (perp=4.884, rec=0.089, cos=0.003), tot_loss_proj:2.166 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil. it is not [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 92.116 | p: 91.454 | r: 92.795
rouge2     | fm: 58.961 | p: 58.669 | r: 59.274
rougeL     | fm: 79.396 | p: 78.942 | r: 79.851
rougeLsum  | fm: 79.212 | p: 78.801 | r: 79.751
r1fm+r2fm = 151.077

input #29 time: 0:08:15 | total time: 4:13:33


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.999272099459075
highest_index [0]
highest [0.999272099459075]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.9139088988304138 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8701140880584717 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.8681485652923584 for ['[CLS] superior vary lynne [SEP]']
[Init] best rec loss: 0.8041428923606873 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7869581580162048 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7338038682937622 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.7189111113548279 for ['[CLS] acceleration council lizard [SEP]']
[Init] best perm rec loss: 0.7150062918663025 for ['[CLS] lizard acceleration council [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.623 (perp=11.807, rec=0.254, cos=0.008), tot_loss_proj:3.735 [t=0.23s]
prediction: ['[CLS]zzability check [SEP]']
[ 100/2000] tot_loss=2.651 (perp=12.475, rec=0.151, cos=0.005), tot_loss_proj:3.583 [t=0.28s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 150/2000] tot_loss=2.703 (perp=12.949, rec=0.110, cos=0.003), tot_loss_proj:3.699 [t=0.18s]
prediction: ['[CLS]zzability fi [SEP]']
[ 200/2000] tot_loss=2.675 (perp=12.949, rec=0.084, cos=0.002), tot_loss_proj:3.709 [t=0.18s]
prediction: ['[CLS]zzability fi [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.001 (perp=9.540, rec=0.089, cos=0.004), tot_loss_proj:1.981 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.971 (perp=9.540, rec=0.062, cos=0.001), tot_loss_proj:1.973 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.968 (perp=9.540, rec=0.058, cos=0.002), tot_loss_proj:1.973 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.962 (perp=9.540, rec=0.052, cos=0.002), tot_loss_proj:1.981 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.974 (perp=9.540, rec=0.065, cos=0.001), tot_loss_proj:1.973 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.972 (perp=9.540, rec=0.062, cos=0.002), tot_loss_proj:1.970 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.980 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.966 (perp=9.540, rec=0.057, cos=0.001), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.973 (perp=9.540, rec=0.064, cos=0.001), tot_loss_proj:1.976 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.973 (perp=9.540, rec=0.064, cos=0.001), tot_loss_proj:1.966 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.978 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.972 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.963 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.972 (perp=9.540, rec=0.062, cos=0.001), tot_loss_proj:1.978 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.960 (perp=9.540, rec=0.050, cos=0.001), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.977 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.969 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.968 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.978 (perp=9.540, rec=0.069, cos=0.001), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.972 (perp=9.540, rec=0.062, cos=0.001), tot_loss_proj:1.984 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.971 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.964 (perp=9.540, rec=0.055, cos=0.001), tot_loss_proj:1.985 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.967 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.973 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.966 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.967 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.978 (perp=9.540, rec=0.069, cos=0.001), tot_loss_proj:1.980 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.962 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.959 (perp=9.540, rec=0.050, cos=0.001), tot_loss_proj:1.973 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.962 (perp=9.540, rec=0.052, cos=0.001), tot_loss_proj:1.986 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.972 (perp=9.540, rec=0.063, cos=0.001), tot_loss_proj:1.973 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.981 (perp=9.540, rec=0.072, cos=0.001), tot_loss_proj:1.964 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.954 (perp=9.540, rec=0.045, cos=0.001), tot_loss_proj:1.978 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.965 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.971 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.983 (perp=9.540, rec=0.074, cos=0.001), tot_loss_proj:1.975 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.957 (perp=9.540, rec=0.047, cos=0.001), tot_loss_proj:1.977 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.966 (perp=9.540, rec=0.057, cos=0.001), tot_loss_proj:1.966 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.972 (perp=9.540, rec=0.063, cos=0.001), tot_loss_proj:1.968 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.975 (perp=9.540, rec=0.065, cos=0.001), tot_loss_proj:1.973 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.335 | p: 91.683 | r: 93.110
rouge2     | fm: 60.371 | p: 60.130 | r: 60.615
rougeL     | fm: 79.933 | p: 79.568 | r: 80.409
rougeLsum  | fm: 79.729 | p: 79.288 | r: 80.136
r1fm+r2fm = 152.706

input #30 time: 0:08:35 | total time: 4:22:08


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.999339325216174
highest_index [0]
highest [0.999339325216174]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9432398676872253 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.920174777507782 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8837398290634155 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.8651828765869141 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.8041785955429077 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 0.8038828372955322 for ['[CLS] robin running artwork [SEP]']
[Init] best perm rec loss: 0.8038730621337891 for ['[CLS] artwork running robin [SEP]']
[Init] best perm rec loss: 0.7982505559921265 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.335 (perp=10.166, rec=0.274, cos=0.028), tot_loss_proj:2.720 [t=0.23s]
prediction: ['[CLS] better instrument vehicle [SEP]']
[ 100/2000] tot_loss=2.103 (perp=9.658, rec=0.156, cos=0.016), tot_loss_proj:2.406 [t=0.18s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=2.281 (perp=10.656, rec=0.137, cos=0.013), tot_loss_proj:2.770 [t=0.18s]
prediction: ['[CLS] better easier vehicle [SEP]']
[ 200/2000] tot_loss=1.916 (perp=8.742, rec=0.150, cos=0.018), tot_loss_proj:3.280 [t=0.18s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.856 (perp=8.742, rec=0.104, cos=0.004), tot_loss_proj:3.266 [t=0.25s]
prediction: ['[CLS] better a vehicle [SEP]']
[ 300/2000] tot_loss=1.809 (perp=8.742, rec=0.060, cos=0.001), tot_loss_proj:3.265 [t=0.18s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.675 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.673 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.672 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.679 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.676 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.672 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.671 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.680 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.672 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.590 (perp=7.603, rec=0.068, cos=0.001), tot_loss_proj:1.673 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.590 (perp=7.603, rec=0.068, cos=0.001), tot_loss_proj:1.681 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.580 (perp=7.603, rec=0.058, cos=0.001), tot_loss_proj:1.669 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.676 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.669 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.572 (perp=7.603, rec=0.050, cos=0.001), tot_loss_proj:1.683 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.673 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.595 (perp=7.603, rec=0.073, cos=0.001), tot_loss_proj:1.679 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.670 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.675 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.580 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.670 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.576 (perp=7.603, rec=0.054, cos=0.001), tot_loss_proj:1.677 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.581 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.665 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.580 (perp=7.603, rec=0.058, cos=0.001), tot_loss_proj:1.669 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.681 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.670 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.584 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.668 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.673 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.680 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.684 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.581 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.688 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.667 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.673 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.674 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.704 | p: 92.130 | r: 93.397
rouge2     | fm: 61.613 | p: 61.341 | r: 62.001
rougeL     | fm: 80.626 | p: 80.144 | r: 81.060
rougeLsum  | fm: 80.585 | p: 80.249 | r: 81.083
r1fm+r2fm = 154.317

input #31 time: 0:08:22 | total time: 4:30:30


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9992521630934186
highest_index [0]
highest [0.9992521630934186]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.0409706830978394 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9490888714790344 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 0.8853940367698669 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.8810258507728577 for ['[CLS]le force cheers discarded replicateباد clash lighthouse direct remarried narrative words [SEP]']
[Init] best rec loss: 0.8623101115226746 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.8531050086021423 for ['[CLS]ono harlem auckland hanna organization rex force riot back decker mud tune [SEP]']
[Init] best rec loss: 0.8450931906700134 for ['[CLS] palaceshire athletic th funds lilith bio circlecting thomas cake natalie [SEP]']
[Init] best perm rec loss: 0.8438608646392822 for ['[CLS] athletic palace th thomasshire bio cake circle lilith fundscting natalie [SEP]']
[Init] best perm rec loss: 0.842842161655426 for ['[CLS] cake funds lilith athletic thshire biocting natalie palace circle thomas [SEP]']
[Init] best perm rec loss: 0.8413686156272888 for ['[CLS] th natalie circlecting thomas funds bio lilith palace cakeshire athletic [SEP]']
[Init] best perm rec loss: 0.8397578001022339 for ['[CLS]cting lilith thomas cake bio athleticshire natalie th circle palace funds [SEP]']
[Init] best perm rec loss: 0.8387935161590576 for ['[CLS] cakecting natalie bio lilith athletic th thomas circle palaceshire funds [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.768 (perp=12.449, rec=0.271, cos=0.007), tot_loss_proj:4.321 [t=0.18s]
prediction: ['[CLS] reliance story up available rooms in liturgical connections invited palace shouldonate [SEP]']
[ 100/2000] tot_loss=2.791 (perp=12.893, rec=0.209, cos=0.004), tot_loss_proj:3.550 [t=0.18s]
prediction: ['[CLS] easily fiction accessible accessibleity easilyonate stories especially battalion easilyonate [SEP]']
[ 150/2000] tot_loss=2.425 (perp=11.288, rec=0.165, cos=0.002), tot_loss_proj:4.169 [t=0.18s]
prediction: ['[CLS] easily mythology accessible accessible with easilyonate stories res below should pull [SEP]']
[ 200/2000] tot_loss=2.546 (perp=11.974, rec=0.149, cos=0.002), tot_loss_proj:3.647 [t=0.19s]
prediction: ['[CLS]onate mythology accessible accessible with easilyonate stories resities pulls pull [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.537 (perp=11.958, rec=0.143, cos=0.002), tot_loss_proj:4.335 [t=0.25s]
prediction: ['[CLS]unditive accessible with easily accessibleonate stories res below pulls pull [SEP]']
[ 300/2000] tot_loss=2.494 (perp=11.847, rec=0.122, cos=0.002), tot_loss_proj:4.091 [t=0.27s]
prediction: ['[CLS]undity accessible with easily accessibleonate stories resrouted committing pull [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.199 (perp=10.425, rec=0.112, cos=0.002), tot_loss_proj:3.401 [t=0.19s]
prediction: ['[CLS]undity accessible with easily accessiblerouted stories resonate [SEP] pull [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.306 (perp=10.934, rec=0.117, cos=0.002), tot_loss_proj:3.181 [t=0.18s]
prediction: ['[CLS]undity accessible that easily accessible stories react resonate [SEP] pull [SEP]']
[ 450/2000] tot_loss=2.238 (perp=10.584, rec=0.119, cos=0.002), tot_loss_proj:2.734 [t=0.18s]
prediction: ['[CLS]undity accessible that easily accessible stories together resonateity pull [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.141 (perp=10.158, rec=0.107, cos=0.002), tot_loss_proj:2.849 [t=0.19s]
prediction: ['[CLS]undity accessible that easily accessible stories pull together resonateity [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.143 (perp=10.158, rec=0.109, cos=0.002), tot_loss_proj:2.840 [t=0.27s]
prediction: ['[CLS]undity accessible that easily accessible stories pull together resonateity [SEP]']
[ 600/2000] tot_loss=2.338 (perp=11.199, rec=0.096, cos=0.002), tot_loss_proj:3.026 [t=0.19s]
prediction: ['[CLS]und prof accessible that easily accessible stories pull together resonateity [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.098 (perp=9.945, rec=0.106, cos=0.003), tot_loss_proj:2.648 [t=0.21s]
prediction: ['[CLS] profund accessible that easily accessible stories pull together resonateity [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.303 (perp=11.041, rec=0.093, cos=0.002), tot_loss_proj:2.874 [t=0.24s]
prediction: ['[CLS] profund accessible that easilyonate stories pull together resonateity [SEP]']
[ 750/2000] tot_loss=2.288 (perp=11.041, rec=0.078, cos=0.002), tot_loss_proj:2.873 [t=0.23s]
prediction: ['[CLS] profund accessible that easilyonate stories pull together resonateity [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.831 (perp=8.589, rec=0.111, cos=0.002), tot_loss_proj:2.204 [t=0.18s]
prediction: ['[CLS] profundity that easily accessible stories pull together resonate accessible [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.807 (perp=8.589, rec=0.088, cos=0.002), tot_loss_proj:2.201 [t=0.22s]
prediction: ['[CLS] profundity that easily accessible stories pull together resonate accessible [SEP]']
[ 900/2000] tot_loss=1.811 (perp=8.589, rec=0.092, cos=0.001), tot_loss_proj:2.200 [t=0.19s]
prediction: ['[CLS] profundity that easily accessible stories pull together resonate accessible [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.802 (perp=8.589, rec=0.083, cos=0.001), tot_loss_proj:2.203 [t=0.23s]
prediction: ['[CLS] profundity that easily accessible stories pull together resonate accessible [SEP]']
Attempt swap
[1000/2000] tot_loss=1.793 (perp=8.589, rec=0.074, cos=0.001), tot_loss_proj:2.207 [t=0.18s]
prediction: ['[CLS] profundity that easily accessible stories pull together resonate accessible [SEP]']
[1050/2000] tot_loss=1.804 (perp=8.589, rec=0.085, cos=0.001), tot_loss_proj:2.207 [t=0.18s]
prediction: ['[CLS] profundity that easily accessible stories pull together resonate accessible [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.783 (perp=8.516, rec=0.078, cos=0.002), tot_loss_proj:2.280 [t=0.21s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
[1150/2000] tot_loss=1.792 (perp=8.516, rec=0.088, cos=0.001), tot_loss_proj:2.291 [t=0.18s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
[1200/2000] tot_loss=1.792 (perp=8.516, rec=0.087, cos=0.001), tot_loss_proj:2.285 [t=0.18s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
[1250/2000] tot_loss=1.781 (perp=8.516, rec=0.076, cos=0.001), tot_loss_proj:2.286 [t=0.18s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
[1300/2000] tot_loss=1.790 (perp=8.516, rec=0.086, cos=0.001), tot_loss_proj:2.289 [t=0.20s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
[1350/2000] tot_loss=1.778 (perp=8.516, rec=0.073, cos=0.001), tot_loss_proj:2.279 [t=0.20s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
[1400/2000] tot_loss=1.787 (perp=8.516, rec=0.082, cos=0.002), tot_loss_proj:2.284 [t=0.18s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
[1450/2000] tot_loss=1.778 (perp=8.516, rec=0.074, cos=0.001), tot_loss_proj:2.283 [t=0.19s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
[1500/2000] tot_loss=1.784 (perp=8.516, rec=0.079, cos=0.001), tot_loss_proj:2.286 [t=0.19s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
[1550/2000] tot_loss=1.776 (perp=8.516, rec=0.072, cos=0.001), tot_loss_proj:2.285 [t=0.27s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
[1600/2000] tot_loss=1.792 (perp=8.516, rec=0.087, cos=0.001), tot_loss_proj:2.286 [t=0.24s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
[1650/2000] tot_loss=1.777 (perp=8.516, rec=0.072, cos=0.001), tot_loss_proj:2.292 [t=0.25s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
[1700/2000] tot_loss=1.784 (perp=8.516, rec=0.079, cos=0.002), tot_loss_proj:2.289 [t=0.23s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.795 (perp=8.568, rec=0.080, cos=0.002), tot_loss_proj:2.277 [t=0.18s]
prediction: ['[CLS] profundity that easily accessible pull stories together accessible resonate [SEP]']
[1800/2000] tot_loss=1.789 (perp=8.568, rec=0.074, cos=0.001), tot_loss_proj:2.273 [t=0.30s]
prediction: ['[CLS] profundity that easily accessible pull stories together accessible resonate [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.784 (perp=8.516, rec=0.079, cos=0.001), tot_loss_proj:2.278 [t=0.25s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
[1900/2000] tot_loss=1.774 (perp=8.516, rec=0.070, cos=0.001), tot_loss_proj:2.284 [t=0.18s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
[1950/2000] tot_loss=1.782 (perp=8.516, rec=0.077, cos=0.001), tot_loss_proj:2.287 [t=0.19s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Attempt swap
[2000/2000] tot_loss=1.786 (perp=8.516, rec=0.081, cos=0.001), tot_loss_proj:2.280 [t=0.25s]
prediction: ['[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] profundity that easily accessible stories pull together accessible resonate [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 120.909

[Aggregate metrics]:
rouge1     | fm: 92.527 | p: 91.897 | r: 93.215
rouge2     | fm: 60.523 | p: 60.251 | r: 60.894
rougeL     | fm: 79.805 | p: 79.335 | r: 80.226
rougeLsum  | fm: 79.687 | p: 79.308 | r: 80.149
r1fm+r2fm = 153.050

input #32 time: 0:08:33 | total time: 4:39:04


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9992763851579931
highest_index [0]
highest [0.9992763851579931]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9998520612716675 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9732957482337952 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.9511236548423767 for ['[CLS] parent [SEP]']
[Init] best rec loss: 0.9041293859481812 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8212264180183411 for ['[CLS] attributed [SEP]']
[Init] best rec loss: 0.7986159920692444 for ['[CLS] showing [SEP]']
[Init] best rec loss: 0.7904055118560791 for ['[CLS] manifold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.434 (perp=11.231, rec=0.179, cos=0.009), tot_loss_proj:3.005 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.316 (perp=11.231, rec=0.068, cos=0.002), tot_loss_proj:2.427 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.296 (perp=11.231, rec=0.048, cos=0.002), tot_loss_proj:2.415 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.320 (perp=11.231, rec=0.072, cos=0.001), tot_loss_proj:2.380 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.300 (perp=11.231, rec=0.052, cos=0.002), tot_loss_proj:2.398 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.302 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.398 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.388 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.393 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.313 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.398 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.301 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.391 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.316 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.393 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.315 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.396 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.315 (perp=11.231, rec=0.068, cos=0.001), tot_loss_proj:2.395 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.303 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.390 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.303 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.386 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.321 (perp=11.231, rec=0.074, cos=0.001), tot_loss_proj:2.402 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.311 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.405 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.295 (perp=11.231, rec=0.047, cos=0.001), tot_loss_proj:2.397 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.320 (perp=11.231, rec=0.072, cos=0.001), tot_loss_proj:2.398 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.396 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.299 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.392 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.315 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.389 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.391 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.314 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.402 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.317 (perp=11.231, rec=0.070, cos=0.001), tot_loss_proj:2.401 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.314 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.399 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.310 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.399 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.403 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.312 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.395 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.302 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.397 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.299 (perp=11.231, rec=0.051, cos=0.001), tot_loss_proj:2.401 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.402 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.404 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.296 (perp=11.231, rec=0.048, cos=0.001), tot_loss_proj:2.389 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.406 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.405 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.294 (perp=11.231, rec=0.046, cos=0.001), tot_loss_proj:2.396 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.311 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.394 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.303 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.405 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.314 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.406 [t=0.20s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.798 | p: 92.227 | r: 93.422
rouge2     | fm: 61.327 | p: 61.027 | r: 61.725
rougeL     | fm: 80.395 | p: 79.980 | r: 80.867
rougeLsum  | fm: 80.191 | p: 79.886 | r: 80.691
r1fm+r2fm = 154.126

input #33 time: 0:08:24 | total time: 4:47:28


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9992091879502123
highest_index [0]
highest [0.9992091879502123]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8935192823410034 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8888072967529297 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8439813256263733 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8383127450942993 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.813098132610321 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.8127062320709229 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.8103282451629639 for ['[CLS] who slightask founderibe field lissa along ship drivers statue worth okay [SEP]']
[Init] best perm rec loss: 0.8098567128181458 for ['[CLS] field slight who statueibe founder lissa shipask drivers okay along worth [SEP]']
[Init] best perm rec loss: 0.808777928352356 for ['[CLS] okayibe statueask slight founder along drivers field worth ship who lissa [SEP]']
[Init] best perm rec loss: 0.8087007999420166 for ['[CLS] okay field ship slight alongask statue lissa founder worth driversibe who [SEP]']
[Init] best perm rec loss: 0.8083059787750244 for ['[CLS] who along lissa ship statue okay slight field driversibe worth founderask [SEP]']
[Init] best perm rec loss: 0.8071286082267761 for ['[CLS] worth founder drivers okay along ship lissa field whoask statueibe slight [SEP]']
[Init] best perm rec loss: 0.8067096471786499 for ['[CLS] founder worth okayaskibe lissa who statue along drivers ship slight field [SEP]']
[Init] best perm rec loss: 0.8060021996498108 for ['[CLS] slight founder fieldaskibe okay lissa ship statue who worth along drivers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.822 (perp=12.442, rec=0.315, cos=0.019), tot_loss_proj:3.702 [t=0.25s]
prediction: ['[CLS] tempest orchestra power adelaide overlap events viewer capture having eclipse urgency the intense [SEP]']
[ 100/2000] tot_loss=2.510 (perp=11.472, rec=0.204, cos=0.012), tot_loss_proj:3.923 [t=0.24s]
prediction: ['[CLS] gloria / engine adelaide viewer urgency viewer build on take urgency. extreme [SEP]']
[ 150/2000] tot_loss=2.300 (perp=10.761, rec=0.143, cos=0.004), tot_loss_proj:3.622 [t=0.20s]
prediction: ['[CLS] nelson. engine adelaide viewer mind viewer build on take urgency. extreme [SEP]']
[ 200/2000] tot_loss=2.179 (perp=10.237, rec=0.128, cos=0.004), tot_loss_proj:3.244 [t=0.19s]
prediction: ['[CLS] john. mind mary viewer mind viewer build in take urgency. extreme [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.217 (perp=10.440, rec=0.125, cos=0.004), tot_loss_proj:3.233 [t=0.27s]
prediction: ['[CLS] kylie. charlotte viewer mind viewer mind build in take urgency. extreme [SEP]']
[ 300/2000] tot_loss=2.218 (perp=10.497, rec=0.116, cos=0.003), tot_loss_proj:3.311 [t=0.25s]
prediction: ['[CLS] kylie. luther viewer mind viewer mind build in take urgency. extreme [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.060 (perp=9.780, rec=0.101, cos=0.003), tot_loss_proj:3.235 [t=0.29s]
prediction: ['[CLS] kylie. luther viewer mind viewer mind build in extreme take urgency. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.949 (perp=9.150, rec=0.115, cos=0.004), tot_loss_proj:2.965 [t=0.19s]
prediction: ['[CLS] walter and bible viewer mind build viewer mind in extreme take urgency. [SEP]']
[ 450/2000] tot_loss=1.919 (perp=9.031, rec=0.110, cos=0.003), tot_loss_proj:2.934 [t=0.19s]
prediction: ['[CLS] john and bible viewer mind build viewer mind in extreme take urgency. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.744 (perp=8.236, rec=0.094, cos=0.003), tot_loss_proj:2.678 [t=0.18s]
prediction: ['[CLS] john take bible viewer mind build viewer mind in extreme and urgency. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.665 (perp=7.807, rec=0.101, cos=0.003), tot_loss_proj:2.378 [t=0.22s]
prediction: ['[CLS] john take bible viewer mind and build viewer and in extreme urgency. [SEP]']
[ 600/2000] tot_loss=1.647 (perp=7.807, rec=0.084, cos=0.002), tot_loss_proj:2.387 [t=0.18s]
prediction: ['[CLS] john take bible viewer mind and build viewer and in extreme urgency. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.584 (perp=7.499, rec=0.083, cos=0.002), tot_loss_proj:2.269 [t=0.19s]
prediction: ['[CLS] john take bible viewer viewer mind and build and in extreme urgency. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.590 (perp=7.499, rec=0.088, cos=0.002), tot_loss_proj:2.272 [t=0.22s]
prediction: ['[CLS] john take bible viewer viewer mind and build and in extreme urgency. [SEP]']
[ 750/2000] tot_loss=1.599 (perp=7.499, rec=0.097, cos=0.002), tot_loss_proj:2.271 [t=0.19s]
prediction: ['[CLS] john take bible viewer viewer mind and build and in extreme urgency. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.585 (perp=7.499, rec=0.083, cos=0.002), tot_loss_proj:2.274 [t=0.19s]
prediction: ['[CLS] john take bible viewer viewer mind and build and in extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.597 (perp=7.499, rec=0.095, cos=0.002), tot_loss_proj:2.282 [t=0.27s]
prediction: ['[CLS] john take bible viewer viewer mind and build and in extreme urgency. [SEP]']
[ 900/2000] tot_loss=1.584 (perp=7.499, rec=0.083, cos=0.002), tot_loss_proj:2.281 [t=0.24s]
prediction: ['[CLS] john take bible viewer viewer mind and build and in extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.685 (perp=7.941, rec=0.095, cos=0.002), tot_loss_proj:2.280 [t=0.18s]
prediction: ['[CLS] of take bible viewer viewer mind and build and in extreme urgency. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.584 (perp=7.522, rec=0.077, cos=0.002), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] take bible viewer viewer of mind and build and in extreme urgency. [SEP]']
[1050/2000] tot_loss=1.581 (perp=7.522, rec=0.076, cos=0.002), tot_loss_proj:2.228 [t=0.24s]
prediction: ['[CLS] take bible viewer viewer of mind and build and in extreme urgency. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.543 (perp=7.304, rec=0.081, cos=0.002), tot_loss_proj:2.365 [t=0.19s]
prediction: ['[CLS] bible viewer viewer take of mind and build and in extreme urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.545 (perp=7.304, rec=0.083, cos=0.002), tot_loss_proj:2.373 [t=0.22s]
prediction: ['[CLS] bible viewer viewer take of mind and build and in extreme urgency. [SEP]']
[1200/2000] tot_loss=1.555 (perp=7.304, rec=0.092, cos=0.002), tot_loss_proj:2.368 [t=0.23s]
prediction: ['[CLS] bible viewer viewer take of mind and build and in extreme urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.548 (perp=7.304, rec=0.086, cos=0.002), tot_loss_proj:2.367 [t=0.19s]
prediction: ['[CLS] bible viewer viewer take of mind and build and in extreme urgency. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.413 (perp=6.502, rec=0.108, cos=0.005), tot_loss_proj:2.214 [t=0.24s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
[1350/2000] tot_loss=1.399 (perp=6.502, rec=0.096, cos=0.002), tot_loss_proj:2.210 [t=0.23s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.388 (perp=6.502, rec=0.085, cos=0.002), tot_loss_proj:2.210 [t=0.19s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.377 (perp=6.502, rec=0.075, cos=0.002), tot_loss_proj:2.214 [t=0.20s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
[1500/2000] tot_loss=1.379 (perp=6.502, rec=0.077, cos=0.002), tot_loss_proj:2.211 [t=0.18s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.386 (perp=6.502, rec=0.084, cos=0.002), tot_loss_proj:2.211 [t=0.26s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.394 (perp=6.502, rec=0.092, cos=0.002), tot_loss_proj:2.206 [t=0.19s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
[1650/2000] tot_loss=1.382 (perp=6.502, rec=0.080, cos=0.002), tot_loss_proj:2.215 [t=0.23s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.382 (perp=6.502, rec=0.081, cos=0.002), tot_loss_proj:2.217 [t=0.24s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.386 (perp=6.502, rec=0.084, cos=0.002), tot_loss_proj:2.210 [t=0.21s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
[1800/2000] tot_loss=1.383 (perp=6.502, rec=0.081, cos=0.002), tot_loss_proj:2.216 [t=0.26s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.378 (perp=6.502, rec=0.077, cos=0.002), tot_loss_proj:2.216 [t=0.21s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.384 (perp=6.502, rec=0.082, cos=0.001), tot_loss_proj:2.209 [t=0.18s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
[1950/2000] tot_loss=1.374 (perp=6.502, rec=0.072, cos=0.002), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.373 (perp=6.502, rec=0.071, cos=0.002), tot_loss_proj:2.209 [t=0.19s]
prediction: ['[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] bible viewer and viewer take of mind and build in extreme urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 78.571 | r: 78.571
rouge2     | fm: 30.769 | p: 30.769 | r: 30.769
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 109.341

[Aggregate metrics]:
rouge1     | fm: 92.378 | p: 91.820 | r: 93.034
rouge2     | fm: 60.914 | p: 60.594 | r: 61.269
rougeL     | fm: 79.543 | p: 79.152 | r: 80.031
rougeLsum  | fm: 79.297 | p: 78.964 | r: 79.728
r1fm+r2fm = 153.291

input #34 time: 0:08:40 | total time: 4:56:08


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9993278544896083
highest_index [0]
highest [0.9993278544896083]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9250960350036621 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.9220249056816101 for ['[CLS] nightstand locality shall shifted pdfish migrated reason features happy statisticsbant medium singled anti but least [SEP] contemptness second mia architecture nonsense departments order deserved ا guardian [MASK] hospitaluts itsried direction soc christmas merely sodiummeral score because [SEP]']
[Init] best rec loss: 0.9155790209770203 for ['[CLS] thousand lack alternative energy fae deservevil denied field outside pages province beauty fade actsar dynamic sole one organized folk ms primary appointment devicedran part zion nightmaresdrive isabellaght intervals singer published sleeper signs lynch, somehow position flow [SEP]']
[Init] best perm rec loss: 0.9139524698257446 for ['[CLS] field thousand published nightmares alternative organized position primary energy one appointment act sole device flow,sardrive somehow lack intervals outside denied sleeper singerght beauty isabella signs fae part lynch zion pages provincevil ms folk fadedran deserve dynamic [SEP]']
[Init] best perm rec loss: 0.9106967449188232 for ['[CLS] province nightmares deserve energy act fae ms singer device field alternative folk denied signs flow thousand outsidedrive beauty intervals somehow published isabella part organized lack primaryght sleeper position lynch,dran solesar zion pages appointment dynamicvil one fade [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.724 (perp=11.538, rec=0.398, cos=0.019), tot_loss_proj:3.885 [t=0.25s]
prediction: ['[CLS] a crazy damien elimination source ballet ph natural since german from : very traditions into amount of gill the antiquityurg is religious ability wonderful today there lucinda great al reliableel of d chorale patents. outsider. [SEP]farlane concept [SEP]']
[ 100/2000] tot_loss=2.114 (perp=9.049, rec=0.299, cos=0.005), tot_loss_proj:3.180 [t=0.19s]
prediction: ["[CLS] the similar they previous'before y the founder german is,. glory human amount of gill the afterwards is of science installation great today has mcmahon with how this, after danger father before and however. [SEP] summons include [SEP]"]
[ 150/2000] tot_loss=2.321 (perp=10.188, rec=0.279, cos=0.005), tot_loss_proj:4.019 [t=0.24s]
prediction: ["[CLS] our seen we prior'beforenation the director despite is before praise we'' but across the who as 'gration care great cares 'tten ve how of, afternation choice before and but, [SEP] this \\ [SEP]"]
[ 200/2000] tot_loss=2.160 (perp=9.635, rec=0.229, cos=0.003), tot_loss_proj:3.798 [t=0.19s]
prediction: ["[CLS] we seen we before'beforenationonte director they is before including help'' but at the who into and band care great care'comes ve seen of, afternation teacher (. however, [SEP] this \\ [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.052 (perp=9.039, rec=0.240, cos=0.003), tot_loss_proj:3.380 [t=0.19s]
prediction: ["[CLS] we seen we before'seennation the director jews is before including the'' but director help we with'olivia care great care'us ve seen of, afternation teacher (. au, [SEP] this. [SEP]"]
[ 300/2000] tot_loss=2.793 (perp=10.097, rec=0.698, cos=0.076), tot_loss_proj:3.846 [t=0.20s]
prediction: ["[CLS] we ve they before'itnation [SEP] director they is before in the'' but director help everyone. ; everyone care great care 'bie ve they ve'fromnation teacher ( of, aboutnation reissued from [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.666 (perp=10.256, rec=0.555, cos=0.060), tot_loss_proj:3.998 [t=0.19s]
prediction: ["[CLS] we ve they speed'programming it [SEP]. '. before central the'' and david brave shared. ; her care island wanted jews gaze ve way the'fromnation teacher university isi about location implemented from [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.509 (perp=9.787, rec=0.509, cos=0.042), tot_loss_proj:3.954 [t=0.19s]
prediction: ["[CLS] we ve ve speed'it you [SEP].'is before central the'' and david piloted estate. ; her care island wanted jews gaze they way the'fromnation teacher [SEP] wasi will location implemented from [SEP]"]
[ 450/2000] tot_loss=2.440 (perp=9.652, rec=0.479, cos=0.031), tot_loss_proj:3.853 [t=0.19s]
prediction: ["[CLS] we ve ve speed'it you [SEP].'is before central the'' and davidlai estate. ; her care island wanted jews gaze they way the'from asked teacher [SEP] was. about location implemented from [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.304 (perp=9.113, rec=0.458, cos=0.024), tot_loss_proj:3.757 [t=0.27s]
prediction: ["[CLS] we ve ve speed'it you [SEP].'is before central the'' and davidlai estate. ; her care island wanted jews gaze they way the'from. teacher university when asked about location leaders from [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.218 (perp=8.797, rec=0.439, cos=0.019), tot_loss_proj:3.679 [t=0.18s]
prediction: ["[CLS] we ve ve speed'it you [SEP].'is before central the'' and davidlai '. ; her care island wanted jews gaze they way s estate from. teacher ( when asked about location leaders from [SEP]"]
[ 600/2000] tot_loss=2.193 (perp=8.797, rec=0.418, cos=0.016), tot_loss_proj:3.682 [t=0.25s]
prediction: ["[CLS] we ve ve speed'it you [SEP].'is before central the'' and davidlai '. ; her care island wanted jews gaze they way s estate from. teacher ( when asked about location leaders from [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.211 (perp=8.935, rec=0.409, cos=0.015), tot_loss_proj:3.597 [t=0.20s]
prediction: ["[CLS] we ve ve speed'it friendship [SEP].'is before central the'her and david appointment '. ;'care island wanted jews gaze they way s estate from. teacher ( when asked about location muslim from [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.187 (perp=8.883, rec=0.397, cos=0.014), tot_loss_proj:3.524 [t=0.19s]
prediction: ['[CLS] we ve ve speed\'it. [SEP] friendship\'is before central the " her and david appointment \'. ;\'care island wanted jews gaze they way s estate from. teacher and when asked about chef muslim from [SEP]']
[ 750/2000] tot_loss=2.186 (perp=8.947, rec=0.384, cos=0.012), tot_loss_proj:3.559 [t=0.19s]
prediction: ['[CLS] we ve ve speed\'it. [SEP] friendship\'is before central the " her and david appointment \'. ;\'care island wanted jews gaze they way s estate after. teacher and when asked about chef muslim from [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.071 (perp=8.415, rec=0.377, cos=0.011), tot_loss_proj:3.481 [t=0.19s]
prediction: ["[CLS] we ve ve wanted'it. [SEP] friendship'is before central the'her and david appointment '. ;'care island speed jews gaze they way s estate after. teacher and when asked about chef muslim from [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.055 (perp=8.323, rec=0.380, cos=0.011), tot_loss_proj:3.174 [t=0.30s]
prediction: ["[CLS] we ve ve wanted'it. [SEP] friendship'is the central before'her and david appointment '. ;'care island watching jews gaze they way s estate from. teacher and when helped about chef teacher from [SEP]"]
[ 900/2000] tot_loss=2.029 (perp=8.323, rec=0.355, cos=0.010), tot_loss_proj:3.167 [t=0.28s]
prediction: ["[CLS] we ve ve wanted'it. [SEP] friendship'is the central before'her and david appointment '. ;'care island watching jews gaze they way s estate from. teacher and when helped about chef teacher from [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.993 (perp=8.150, rec=0.354, cos=0.009), tot_loss_proj:3.308 [t=0.19s]
prediction: ["[CLS] we ve ve wanted'it. [SEP] friendship'is the central before'her and david appointment '. ;'care island watching jewsn they way s estate from. teacher and teacher helped about chef when from [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.963 (perp=8.007, rec=0.353, cos=0.009), tot_loss_proj:3.303 [t=0.19s]
prediction: ["[CLS] we've wanted'it. [SEP] friendship'is the central before'her and david appointment '. ; ve care island watching jewsn they way s estate from. teacher and teacher helped about location when from [SEP]"]
[1050/2000] tot_loss=1.961 (perp=8.007, rec=0.351, cos=0.009), tot_loss_proj:3.309 [t=0.25s]
prediction: ["[CLS] we've wanted'it. [SEP] friendship'is the central before'her and david appointment '. ; ve care island watching jewsn they way s estate from. teacher and teacher helped about location when from [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.918 (perp=7.854, rec=0.339, cos=0.008), tot_loss_proj:3.262 [t=0.21s]
prediction: ["[CLS] we've wanted'it. [SEP] friendship'is the central before'her and david appointment '.n ve care island watching jews ; they way s estate from. teacher and teacher helped about location when from [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.902 (perp=7.738, rec=0.346, cos=0.008), tot_loss_proj:3.282 [t=0.26s]
prediction: ["[CLS] we've wanted'it. [SEP] friendship'is the central before'her and david appointment '. ven care island watching jews ; they way s estate from. teacher and teacher helped about location of from [SEP]"]
[1200/2000] tot_loss=1.895 (perp=7.738, rec=0.340, cos=0.008), tot_loss_proj:3.284 [t=0.27s]
prediction: ["[CLS] we've wanted'it. [SEP] friendship'is the central before'her and david appointment '. ven care island watching jews ; they way s estate from. teacher and teacher helped about location of from [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.859 (perp=7.575, rec=0.336, cos=0.007), tot_loss_proj:3.241 [t=0.30s]
prediction: ["[CLS] we've wanted'it. [SEP] friendship'is the central before'her and david appointment '. ven care island watching jews ; they way from s estate. teacher and teacher helped about location of from [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.855 (perp=7.568, rec=0.334, cos=0.008), tot_loss_proj:3.418 [t=0.25s]
prediction: ["[CLS] we've wanted'it. [SEP] friendship'is the central before's and david appointment '. ven care island watching jews ; they way from her estate. teacher and teachernation about location of from [SEP]"]
[1350/2000] tot_loss=1.817 (perp=7.396, rec=0.331, cos=0.007), tot_loss_proj:3.166 [t=0.22s]
prediction: ["[CLS] we've wanted'it. [SEP] friendship'is the central before's and david appointment '. ven care island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.815 (perp=7.396, rec=0.329, cos=0.006), tot_loss_proj:3.168 [t=0.19s]
prediction: ["[CLS] we've wanted'it. [SEP] friendship'is the central before's and david appointment '. ven care island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.812 (perp=7.397, rec=0.326, cos=0.007), tot_loss_proj:3.313 [t=0.19s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central before's david and appointment '. ven care island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
[1500/2000] tot_loss=1.812 (perp=7.397, rec=0.327, cos=0.006), tot_loss_proj:3.312 [t=0.19s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central before's david and appointment '. ven care island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.805 (perp=7.397, rec=0.320, cos=0.006), tot_loss_proj:3.310 [t=0.19s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central before's david and appointment '. ven care island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.806 (perp=7.397, rec=0.321, cos=0.006), tot_loss_proj:3.309 [t=0.25s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central before's david and appointment '. ven care island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
[1650/2000] tot_loss=1.803 (perp=7.397, rec=0.318, cos=0.006), tot_loss_proj:3.313 [t=0.26s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central before's david and appointment '. ven care island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.808 (perp=7.397, rec=0.323, cos=0.006), tot_loss_proj:3.311 [t=0.25s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central before's david and appointment '. ven care island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.779 (perp=7.275, rec=0.318, cos=0.006), tot_loss_proj:3.258 [t=0.21s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central before's david and appointment '. ve caren island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
[1800/2000] tot_loss=1.779 (perp=7.275, rec=0.318, cos=0.006), tot_loss_proj:3.255 [t=0.20s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central before's david and appointment '. ve caren island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.763 (perp=7.189, rec=0.319, cos=0.005), tot_loss_proj:3.302 [t=0.23s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central and's david before appointment '. ve caren island watching jews ; they way from her estate. teacher and teacher helped about location of from [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.749 (perp=7.092, rec=0.325, cos=0.006), tot_loss_proj:3.332 [t=0.19s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central and's david before appointment '. ve caren island of jews ; they way from her estate. teacher and teacher helped about location watching from [SEP]"]
[1950/2000] tot_loss=1.743 (perp=7.092, rec=0.319, cos=0.006), tot_loss_proj:3.332 [t=0.19s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central and's david before appointment '. ve caren island of jews ; they way from her estate. teacher and teacher helped about location watching from [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.739 (perp=7.092, rec=0.315, cos=0.005), tot_loss_proj:3.333 [t=0.19s]
prediction: ["[CLS] we've wanted'it. [SEP]plify'is the central and's david before appointment '. ve caren island of jews ; they way from her estate. teacher and teacher helped about location watching from [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] we ve they before'seennation the director jews is before or the'' but director help of with. vaccine care great care'us ve seen ve, afternation teacher (, but, [SEP] latest about [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 55.882 | p: 57.576 | r: 54.286
rouge2     | fm: 12.121 | p: 12.500 | r: 11.765
rougeL     | fm: 35.294 | p: 36.364 | r: 34.286
rougeLsum  | fm: 35.294 | p: 36.364 | r: 34.286
r1fm+r2fm = 68.004

[Aggregate metrics]:
rouge1     | fm: 91.285 | p: 90.803 | r: 91.883
rouge2     | fm: 59.370 | p: 59.115 | r: 59.691
rougeL     | fm: 78.305 | p: 77.988 | r: 78.738
rougeLsum  | fm: 78.128 | p: 77.757 | r: 78.590
r1fm+r2fm = 150.655

input #35 time: 0:08:51 | total time: 5:05:00


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.9992842743865827
highest_index [0]
highest [0.9992842743865827]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9986883401870728 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9958099126815796 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9545882940292358 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9252082705497742 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9223971962928772 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.9177457690238953 for ['[CLS] papa sinclairevsky perhaps [SEP]']
[Init] best rec loss: 0.8233659863471985 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8216447234153748 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 0.8213571906089783 for ['[CLS] bates harassment ramsey cornelius [SEP]']
[Init] best perm rec loss: 0.8175345659255981 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.960 (perp=9.086, rec=0.137, cos=0.006), tot_loss_proj:2.112 [t=0.22s]
prediction: ['[CLS] is horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=1.903 (perp=9.148, rec=0.072, cos=0.002), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=1.907 (perp=9.148, rec=0.076, cos=0.002), tot_loss_proj:2.106 [t=0.19s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=1.903 (perp=9.148, rec=0.072, cos=0.002), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.900 (perp=9.148, rec=0.068, cos=0.002), tot_loss_proj:2.119 [t=0.19s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 300/2000] tot_loss=1.909 (perp=9.148, rec=0.078, cos=0.002), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.891 (perp=9.148, rec=0.060, cos=0.002), tot_loss_proj:2.126 [t=0.19s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.896 (perp=9.148, rec=0.064, cos=0.002), tot_loss_proj:2.121 [t=0.19s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 450/2000] tot_loss=1.786 (perp=8.607, rec=0.063, cos=0.002), tot_loss_proj:1.920 [t=0.19s]
prediction: ["[CLS] s horribly wrong'[SEP]"]
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.521 (perp=7.159, rec=0.088, cos=0.002), tot_loss_proj:1.850 [t=0.20s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.502 (perp=7.159, rec=0.069, cos=0.002), tot_loss_proj:1.853 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 600/2000] tot_loss=1.497 (perp=7.159, rec=0.063, cos=0.002), tot_loss_proj:1.849 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.489 (perp=7.159, rec=0.056, cos=0.001), tot_loss_proj:1.846 [t=0.29s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.853 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 750/2000] tot_loss=1.487 (perp=7.159, rec=0.054, cos=0.001), tot_loss_proj:1.851 [t=0.27s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.505 (perp=7.159, rec=0.072, cos=0.001), tot_loss_proj:1.848 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.849 [t=0.30s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 900/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.857 [t=0.29s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.496 (perp=7.159, rec=0.063, cos=0.001), tot_loss_proj:1.839 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.488 (perp=7.159, rec=0.055, cos=0.001), tot_loss_proj:1.851 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1050/2000] tot_loss=1.494 (perp=7.159, rec=0.061, cos=0.001), tot_loss_proj:1.851 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.502 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.840 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.496 (perp=7.159, rec=0.063, cos=0.001), tot_loss_proj:1.850 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1200/2000] tot_loss=1.502 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.842 [t=0.27s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.832 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.500 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.843 [t=0.23s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1350/2000] tot_loss=1.496 (perp=7.159, rec=0.063, cos=0.001), tot_loss_proj:1.840 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.496 (perp=7.159, rec=0.062, cos=0.001), tot_loss_proj:1.840 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.490 (perp=7.159, rec=0.057, cos=0.001), tot_loss_proj:1.840 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1500/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.843 [t=0.23s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.498 (perp=7.159, rec=0.065, cos=0.001), tot_loss_proj:1.844 [t=0.26s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.846 [t=0.30s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1650/2000] tot_loss=1.490 (perp=7.159, rec=0.057, cos=0.001), tot_loss_proj:1.840 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.844 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.493 (perp=7.159, rec=0.059, cos=0.001), tot_loss_proj:1.844 [t=0.30s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1800/2000] tot_loss=1.513 (perp=7.159, rec=0.079, cos=0.001), tot_loss_proj:1.841 [t=0.27s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.500 (perp=7.159, rec=0.067, cos=0.001), tot_loss_proj:1.851 [t=0.23s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.506 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.841 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1950/2000] tot_loss=1.494 (perp=7.159, rec=0.061, cos=0.001), tot_loss_proj:1.832 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.001), tot_loss_proj:1.841 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] horribly wrong's [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.565 | p: 91.071 | r: 92.118
rouge2     | fm: 58.602 | p: 58.317 | r: 58.892
rougeL     | fm: 78.475 | p: 78.147 | r: 78.919
rougeLsum  | fm: 78.280 | p: 77.911 | r: 78.618
r1fm+r2fm = 150.167

input #36 time: 0:08:46 | total time: 5:13:47


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9993688501312639
highest_index [0]
highest [0.9993688501312639]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.9638330340385437 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.9471154808998108 for ['[CLS]quest medical [SEP]']
[Init] best rec loss: 0.8868577480316162 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.809199333190918 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.8002374172210693 for ['[CLS] living metacritic [SEP]']
[Init] best rec loss: 0.7850696444511414 for ['[CLS] housemple [SEP]']
[Init] best rec loss: 0.7521161437034607 for ['[CLS] year clarissa [SEP]']
[Init] best rec loss: 0.7474158406257629 for ['[CLS]atal purpose [SEP]']
[Init] best rec loss: 0.7218530774116516 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.7020721435546875 for ['[CLS] cousin many [SEP]']
[Init] best rec loss: 0.6827971339225769 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6734248399734497 for ['[CLS] cassidystream [SEP]']
[Init] best rec loss: 0.6440885663032532 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6402079463005066 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.901 (perp=12.495, rec=0.320, cos=0.082), tot_loss_proj:3.305 [t=0.19s]
prediction: ['[CLS] eccentric newly [SEP]']
[ 100/2000] tot_loss=2.084 (perp=9.583, rec=0.130, cos=0.037), tot_loss_proj:2.024 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
[ 150/2000] tot_loss=1.997 (perp=9.583, rec=0.079, cos=0.002), tot_loss_proj:2.003 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.967 (perp=9.583, rec=0.049, cos=0.001), tot_loss_proj:2.006 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.986 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.011 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
[ 300/2000] tot_loss=1.994 (perp=9.583, rec=0.076, cos=0.001), tot_loss_proj:2.021 [t=0.25s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.975 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.018 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.021 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[ 450/2000] tot_loss=1.981 (perp=9.583, rec=0.063, cos=0.001), tot_loss_proj:2.013 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.993 (perp=9.583, rec=0.075, cos=0.001), tot_loss_proj:2.022 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.013 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
[ 600/2000] tot_loss=1.966 (perp=9.583, rec=0.049, cos=0.001), tot_loss_proj:2.017 [t=0.26s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.990 (perp=9.583, rec=0.072, cos=0.001), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.981 (perp=9.583, rec=0.063, cos=0.001), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
[ 750/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.005 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.011 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.988 (perp=9.583, rec=0.070, cos=0.001), tot_loss_proj:2.009 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.983 (perp=9.583, rec=0.066, cos=0.001), tot_loss_proj:2.016 [t=0.23s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.986 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.014 [t=0.21s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.991 (perp=9.583, rec=0.073, cos=0.001), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.003 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.970 (perp=9.583, rec=0.052, cos=0.001), tot_loss_proj:2.005 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.971 (perp=9.583, rec=0.053, cos=0.001), tot_loss_proj:2.019 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.011 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.971 (perp=9.583, rec=0.053, cos=0.001), tot_loss_proj:2.009 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.987 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.974 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.988 (perp=9.583, rec=0.070, cos=0.001), tot_loss_proj:2.006 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.983 (perp=9.583, rec=0.066, cos=0.001), tot_loss_proj:2.014 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.019 [t=0.21s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.015 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.011 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.012 [t=0.27s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:1.998 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.968 (perp=9.583, rec=0.051, cos=0.001), tot_loss_proj:2.009 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.011 [t=0.20s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.014 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.986 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.810 | p: 91.357 | r: 92.464
rouge2     | fm: 59.373 | p: 59.162 | r: 59.675
rougeL     | fm: 78.930 | p: 78.646 | r: 79.335
rougeLsum  | fm: 78.859 | p: 78.605 | r: 79.173
r1fm+r2fm = 151.183

input #37 time: 0:08:25 | total time: 5:22:12


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9992650714710192
highest_index [0]
highest [0.9992650714710192]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8147767186164856 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8102814555168152 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.8013331294059753 for ['[CLS] federation [SEP]']
[Init] best rec loss: 0.767846405506134 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7035160064697266 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6697532534599304 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6317602396011353 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.908 (perp=14.069, rec=0.088, cos=0.007), tot_loss_proj:2.887 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.889 (perp=14.069, rec=0.070, cos=0.004), tot_loss_proj:2.876 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.887 (perp=14.069, rec=0.072, cos=0.001), tot_loss_proj:2.884 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.880 (perp=14.069, rec=0.064, cos=0.002), tot_loss_proj:2.875 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.879 (perp=14.069, rec=0.064, cos=0.001), tot_loss_proj:2.883 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.896 (perp=14.069, rec=0.079, cos=0.003), tot_loss_proj:2.878 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.862 (perp=14.069, rec=0.047, cos=0.001), tot_loss_proj:2.877 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.870 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.865 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.882 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.868 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.870 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.878 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.878 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.877 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.877 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.887 (perp=14.069, rec=0.072, cos=0.001), tot_loss_proj:2.868 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.861 (perp=14.069, rec=0.046, cos=0.001), tot_loss_proj:2.861 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.861 (perp=14.069, rec=0.046, cos=0.001), tot_loss_proj:2.877 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.865 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.873 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.874 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.865 (perp=14.069, rec=0.050, cos=0.001), tot_loss_proj:2.868 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.868 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.873 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.882 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.877 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.862 (perp=14.069, rec=0.047, cos=0.001), tot_loss_proj:2.876 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.874 (perp=14.069, rec=0.058, cos=0.001), tot_loss_proj:2.878 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.857 (perp=14.069, rec=0.042, cos=0.001), tot_loss_proj:2.868 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.865 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.885 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.888 (perp=14.069, rec=0.072, cos=0.001), tot_loss_proj:2.869 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.863 (perp=14.069, rec=0.048, cos=0.001), tot_loss_proj:2.878 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.868 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.887 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.870 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.877 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.866 (perp=14.069, rec=0.051, cos=0.001), tot_loss_proj:2.886 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.875 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.890 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.875 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.874 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.877 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.868 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.878 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.873 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.873 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.973 | p: 91.571 | r: 92.528
rouge2     | fm: 60.385 | p: 60.167 | r: 60.704
rougeL     | fm: 79.576 | p: 79.259 | r: 80.016
rougeLsum  | fm: 79.356 | p: 79.108 | r: 79.772
r1fm+r2fm = 152.358

input #38 time: 0:08:22 | total time: 5:30:34


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9992526747729698
highest_index [0]
highest [0.9992526747729698]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.0125712156295776 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.0075626373291016 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9883815050125122 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.9328680038452148 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.9286262392997742 for ['[CLS] ira estimate rabbi relegationbiotic request veronica his baby firedusia property management spring gone dub related location cd age eastern drove than kelly parking [SEP]']
[Init] best rec loss: 0.9213950037956238 for ['[CLS] mutual peopleュ stone intimate reeve templeming freak shores over they sprinterous pro dedication harbour along ll minority [CLS] class raise issue need [SEP]']
[Init] best rec loss: 0.9183960556983948 for ['[CLS] will press caseztty never crimson bohemia journal search band relations behind formula cells main commissioner quick palmer present bible backs duty sogh [SEP]']
[Init] best rec loss: 0.9107301235198975 for ['[CLS] townwind hurt main thenney cassidyowa position jury southpher wash sailhy gordon lab happened bepettive in etc sometimes event [SEP]']
[Init] best perm rec loss: 0.9091352820396423 for ['[CLS]pher happened sailowa jury cassidy gordon main etcwind thentivehy event south sometimes positionney lab be hurtpet wash town in [SEP]']
[Init] best perm rec loss: 0.9068863391876221 for ['[CLS]hy jurypet wash then townney sometimestive hurt eventpher position main happened etc south bewind gordon cassidy labowa sail in [SEP]']
[Init] best perm rec loss: 0.9056861400604248 for ['[CLS] cassidypher eventneypet southowa in gordonwind position sail town thentive wash sometimeshy etc be happened jury lab main hurt [SEP]']
[Init] best perm rec loss: 0.9048677086830139 for ['[CLS] happened event hurt lab be gordonwind in sometimeshy south wash thenney etc cassidy position sailpetpherowa main towntive jury [SEP]']
[Init] best perm rec loss: 0.9048073887825012 for ['[CLS]owa south sailpetneytive main hurt sometimes cassidy town in gordon etc happened be labhy then positionwind jury washpher event [SEP]']
[Init] best perm rec loss: 0.902324914932251 for ['[CLS] be jurypher etc wash position gordon cassidy happened southney sometimesowa in mainhytive lab then eventpet sailwind hurt town [SEP]']
[Init] best perm rec loss: 0.9018852710723877 for ['[CLS] position labney gordon happened mainpher wash thenowa south sail jury inpet cassidy etctive eventwind be hurt sometimes townhy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.763 (perp=12.096, rec=0.333, cos=0.011), tot_loss_proj:4.170 [t=0.18s]
prediction: ['[CLS] along has ben.pledtlan kang aspect [SEP] stitch kelly dating democratic find. drugs charted some autumn, strange each [SEP] find [SEP] [SEP]']
[ 100/2000] tot_loss=2.712 (perp=12.223, rec=0.251, cos=0.016), tot_loss_proj:3.939 [t=0.25s]
prediction: ['[CLS] along has jon. conservativetlan secretbound [SEP] conservative finds dating democratic finds. drugsography pretty texture, new texture [SEP] find [SEP] [SEP]']
[ 150/2000] tot_loss=2.604 (perp=11.667, rec=0.253, cos=0.018), tot_loss_proj:4.355 [t=0.19s]
prediction: ['[CLS] hide figure martin. conservativetlan hidebound [SEP] this demise cook tradition gives. drugs realm theirstones, new texture invasion finds conservative [SEP]']
[ 200/2000] tot_loss=2.457 (perp=11.348, rec=0.183, cos=0.004), tot_loss_proj:4.289 [t=0.21s]
prediction: ['[CLS] hide % martin and conservative giant hidebound [SEP] it broadway reality tradition gives. drugs producing most texture, new texture movie finds conservative [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.151 (perp=9.921, rec=0.163, cos=0.004), tot_loss_proj:3.895 [t=0.22s]
prediction: ['[CLS] hide somehow conservative and conservative giant hidebound [SEP] it movie reality tradition gives. drugs movie most texture, new texture movie finds martin [SEP]']
[ 300/2000] tot_loss=2.107 (perp=9.732, rec=0.155, cos=0.006), tot_loss_proj:3.793 [t=0.25s]
prediction: ['[CLS] hide somehow conservative and conservative giant hidebound [SEP] it movie movie traditions gives of drugs movie most texture, new texture movie finds martin [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.015 (perp=9.370, rec=0.137, cos=0.004), tot_loss_proj:3.787 [t=0.25s]
prediction: ['[CLS] hide somehow conservative and conservative giant hidebound [SEP] of movie movie traditions gives it drugs movie most texture, new texture movie finds martin [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.117 (perp=9.918, rec=0.131, cos=0.003), tot_loss_proj:2.886 [t=0.19s]
prediction: ['[CLS] hide somehow conservative and conservative [SEP]boundbound giant one movie movie traditions gives it treasure movie most texture, new texture whole finds specialist [SEP]']
[ 450/2000] tot_loss=2.139 (perp=10.076, rec=0.121, cos=0.003), tot_loss_proj:3.628 [t=0.24s]
prediction: ['[CLS] hide because conservative and conservative [SEP]boundbound giant one movie making traditions gives it making movie most texture, new texture new finds specialist [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.094 (perp=9.916, rec=0.109, cos=0.002), tot_loss_proj:3.564 [t=0.19s]
prediction: ['[CLS] hide maybe conservative and conservative [SEP]boundbound giant was movie making traditions gives it making soundtrack most texture, new texture new finds one [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.987 (perp=9.340, rec=0.114, cos=0.004), tot_loss_proj:3.345 [t=0.24s]
prediction: ['[CLS] making. conservative and conservative [SEP]boundbound giant was movie making traditions gives it hide soundtrack most relevance, new texture new finds one [SEP]']
[ 600/2000] tot_loss=1.981 (perp=9.340, rec=0.111, cos=0.002), tot_loss_proj:3.349 [t=0.19s]
prediction: ['[CLS] making. conservative and conservative [SEP]boundbound giant was movie making traditions gives it hide soundtrack most relevance, new texture new finds one [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.945 (perp=9.201, rec=0.103, cos=0.002), tot_loss_proj:3.364 [t=0.18s]
prediction: ['[CLS] making. conservative and conservative [SEP]boundbound was giant movie making traditions gives it hide soundtrack most relevance, new texture new finds one [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.896 (perp=8.929, rec=0.109, cos=0.002), tot_loss_proj:3.473 [t=0.19s]
prediction: ['[CLS] making. conservative and conservative [SEP]boundbound was giant movie making traditions gives it hide soundtrack new relevance, new texture most finds one [SEP]']
[ 750/2000] tot_loss=1.922 (perp=9.080, rec=0.104, cos=0.002), tot_loss_proj:3.546 [t=0.18s]
prediction: ['[CLS] making. conservative and conservative [SEP]boundbound was giant movie making traditions gives it hide reality new relevance, new texture most finds one [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.843 (perp=8.724, rec=0.096, cos=0.002), tot_loss_proj:3.520 [t=0.23s]
prediction: ['[CLS] making conservative and conservative. [SEP]boundbound was giant movie making traditions gives it hide reality new relevance, new texture most finds one [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.839 (perp=8.724, rec=0.092, cos=0.002), tot_loss_proj:3.518 [t=0.19s]
prediction: ['[CLS] making conservative and conservative. [SEP]boundbound was giant movie making traditions gives it hide reality new relevance, new texture most finds one [SEP]']
[ 900/2000] tot_loss=1.845 (perp=8.724, rec=0.099, cos=0.002), tot_loss_proj:3.519 [t=0.22s]
prediction: ['[CLS] making conservative and conservative. [SEP]boundbound was giant movie making traditions gives it hide reality new relevance, new texture most finds one [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.837 (perp=8.724, rec=0.091, cos=0.002), tot_loss_proj:3.514 [t=0.19s]
prediction: ['[CLS] making conservative and conservative. [SEP]boundbound was giant movie making traditions gives it hide reality new relevance, new texture most finds one [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.770 (perp=8.353, rec=0.097, cos=0.002), tot_loss_proj:2.768 [t=0.18s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound filmed was giant movie making traditions gives it hidebound new relevance, new texture most finds one [SEP]']
[1050/2000] tot_loss=1.702 (perp=8.002, rec=0.100, cos=0.002), tot_loss_proj:2.960 [t=0.28s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture most finds one [SEP]']
Attempt swap
[1100/2000] tot_loss=1.703 (perp=8.002, rec=0.101, cos=0.002), tot_loss_proj:2.962 [t=0.19s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture most finds one [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.672 (perp=7.900, rec=0.091, cos=0.002), tot_loss_proj:2.840 [t=0.27s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture most one finds [SEP]']
[1200/2000] tot_loss=1.680 (perp=7.900, rec=0.098, cos=0.002), tot_loss_proj:2.836 [t=0.24s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture most one finds [SEP]']
Attempt swap
[1250/2000] tot_loss=1.678 (perp=7.900, rec=0.096, cos=0.002), tot_loss_proj:2.846 [t=0.19s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture most one finds [SEP]']
Attempt swap
[1300/2000] tot_loss=1.676 (perp=7.900, rec=0.094, cos=0.002), tot_loss_proj:2.840 [t=0.26s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture most one finds [SEP]']
[1350/2000] tot_loss=1.711 (perp=8.073, rec=0.094, cos=0.002), tot_loss_proj:2.698 [t=0.27s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture our one finds [SEP]']
Attempt swap
[1400/2000] tot_loss=1.710 (perp=8.073, rec=0.094, cos=0.002), tot_loss_proj:2.699 [t=0.22s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture our one finds [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.687 (perp=7.941, rec=0.097, cos=0.002), tot_loss_proj:2.774 [t=0.19s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture finds our one [SEP]']
[1500/2000] tot_loss=1.684 (perp=7.941, rec=0.094, cos=0.002), tot_loss_proj:2.767 [t=0.20s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture finds our one [SEP]']
Attempt swap
[1550/2000] tot_loss=1.680 (perp=7.941, rec=0.090, cos=0.002), tot_loss_proj:2.773 [t=0.19s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture finds our one [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.597 (perp=7.525, rec=0.090, cos=0.002), tot_loss_proj:2.498 [t=0.26s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions hidebound gives it new relevance, new texture finds our one [SEP]']
[1650/2000] tot_loss=1.593 (perp=7.525, rec=0.086, cos=0.002), tot_loss_proj:2.503 [t=0.19s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions hidebound gives it new relevance, new texture finds our one [SEP]']
Attempt swap
[1700/2000] tot_loss=1.636 (perp=7.680, rec=0.098, cos=0.002), tot_loss_proj:2.507 [t=0.28s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was season movie making traditions hidebound gives it new relevance, new texture finds our one [SEP]']
Attempt swap
[1750/2000] tot_loss=1.555 (perp=7.272, rec=0.099, cos=0.002), tot_loss_proj:2.296 [t=0.20s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was and movie making traditions hidebound gives it new relevance, new texture finds our one [SEP]']
[1800/2000] tot_loss=1.545 (perp=7.272, rec=0.089, cos=0.002), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was and movie making traditions hidebound gives it new relevance, new texture finds our one [SEP]']
Attempt swap
[1850/2000] tot_loss=1.552 (perp=7.272, rec=0.095, cos=0.002), tot_loss_proj:2.296 [t=0.19s]
prediction: ['[CLS] making conservative and conservative. [SEP]bound reality was and movie making traditions hidebound gives it new relevance, new texture finds our one [SEP]']
Attempt swap
[1900/2000] tot_loss=1.598 (perp=7.510, rec=0.095, cos=0.002), tot_loss_proj:2.287 [t=0.19s]
prediction: ['[CLS] of conservative and conservative. [SEP]bound reality was and movie making traditions hidebound gives it new relevance, new texture finds our one [SEP]']
[1950/2000] tot_loss=1.591 (perp=7.510, rec=0.087, cos=0.002), tot_loss_proj:2.279 [t=0.18s]
prediction: ['[CLS] of conservative and conservative. [SEP]bound reality was and movie making traditions hidebound gives it new relevance, new texture finds our one [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.556 (perp=7.350, rec=0.084, cos=0.002), tot_loss_proj:2.324 [t=0.19s]
prediction: ['[CLS] of conservative and conservative. [SEP]bound reality was movie making and traditions hidebound gives it new relevance, new texture finds our one [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] making conservative and conservative. [SEP]bound reality was giant movie making traditions gives it hidebound new relevance, new texture our one finds [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 75.000 | r: 81.818
rouge2     | fm: 31.818 | p: 30.435 | r: 33.333
rougeL     | fm: 52.174 | p: 50.000 | r: 54.545
rougeLsum  | fm: 52.174 | p: 50.000 | r: 54.545
r1fm+r2fm = 110.079

[Aggregate metrics]:
rouge1     | fm: 91.635 | p: 91.133 | r: 92.273
rouge2     | fm: 59.753 | p: 59.506 | r: 59.997
rougeL     | fm: 78.833 | p: 78.472 | r: 79.214
rougeLsum  | fm: 78.458 | p: 78.093 | r: 78.863
r1fm+r2fm = 151.388

input #39 time: 0:08:45 | total time: 5:39:20


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9993178197074233
highest_index [0]
highest [0.9993178197074233]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9942196607589722 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9584137797355652 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9366960525512695 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 0.935725748538971 for ['[CLS] alive represents adelaide cinder majestymersfordthes s [SEP]']
[Init] best rec loss: 0.9297330379486084 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 0.9249941110610962 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 0.9139153957366943 for ['[CLS] formula expression groundsoft written used ⇒ution murray [SEP]']
[Init] best rec loss: 0.9052402973175049 for ['[CLS] alloid courtesy [MASK]blood mean gownrarm [SEP]']
[Init] best rec loss: 0.8458519577980042 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8345496654510498 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8326913118362427 for ['[CLS] but already lady° georgian kent deciding abd many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.791 (perp=12.440, rec=0.294, cos=0.009), tot_loss_proj:3.536 [t=0.18s]
prediction: ["[CLS] linnaeusmmelony typeony until evidence'ridiculous [SEP]"]
[ 100/2000] tot_loss=2.461 (perp=11.344, rec=0.186, cos=0.006), tot_loss_proj:3.654 [t=0.22s]
prediction: ['[CLS] pummelony usony with imagery musicony [SEP]']
[ 150/2000] tot_loss=2.352 (perp=11.058, rec=0.135, cos=0.005), tot_loss_proj:3.516 [t=0.30s]
prediction: ['[CLS] pummelony us ph with imagery musicony [SEP]']
[ 200/2000] tot_loss=2.329 (perp=11.058, rec=0.114, cos=0.003), tot_loss_proj:3.523 [t=0.31s]
prediction: ['[CLS] pummelony us ph with imagery musicony [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.856 (perp=8.787, rec=0.097, cos=0.002), tot_loss_proj:2.238 [t=0.28s]
prediction: ['[CLS] pummelony us with imagery or phony [SEP]']
[ 300/2000] tot_loss=1.840 (perp=8.787, rec=0.081, cos=0.002), tot_loss_proj:2.241 [t=0.22s]
prediction: ['[CLS] pummelony us with imagery or phony [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.833 (perp=8.787, rec=0.074, cos=0.002), tot_loss_proj:2.238 [t=0.19s]
prediction: ['[CLS] pummelony us with imagery or phony [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.711 (perp=8.045, rec=0.100, cos=0.002), tot_loss_proj:2.048 [t=0.18s]
prediction: ['[CLS]ony pummel us with imagery or phony [SEP]']
[ 450/2000] tot_loss=1.683 (perp=8.045, rec=0.072, cos=0.002), tot_loss_proj:2.040 [t=0.18s]
prediction: ['[CLS]ony pummel us with imagery or phony [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.686 (perp=8.045, rec=0.076, cos=0.002), tot_loss_proj:2.036 [t=0.19s]
prediction: ['[CLS]ony pummel us with imagery or phony [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.686 (perp=8.045, rec=0.076, cos=0.002), tot_loss_proj:2.050 [t=0.18s]
prediction: ['[CLS]ony pummel us with imagery or phony [SEP]']
[ 600/2000] tot_loss=1.682 (perp=8.045, rec=0.071, cos=0.002), tot_loss_proj:2.042 [t=0.21s]
prediction: ['[CLS]ony pummel us with imagery or phony [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.679 (perp=8.045, rec=0.069, cos=0.002), tot_loss_proj:2.040 [t=0.18s]
prediction: ['[CLS]ony pummel us with imagery or phony [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.674 (perp=8.045, rec=0.063, cos=0.002), tot_loss_proj:2.037 [t=0.18s]
prediction: ['[CLS]ony pummel us with imagery or phony [SEP]']
[ 750/2000] tot_loss=1.982 (perp=9.490, rec=0.082, cos=0.002), tot_loss_proj:3.188 [t=0.24s]
prediction: ['[CLS]ony pummel us with imagery or ph music [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.679 (perp=8.045, rec=0.068, cos=0.002), tot_loss_proj:2.061 [t=0.19s]
prediction: ['[CLS]ony pummel us with imagery or phony [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.686 (perp=8.045, rec=0.075, cos=0.002), tot_loss_proj:2.056 [t=0.26s]
prediction: ['[CLS]ony pummel us with imagery or phony [SEP]']
[ 900/2000] tot_loss=1.540 (perp=7.347, rec=0.069, cos=0.002), tot_loss_proj:1.958 [t=0.23s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.542 (perp=7.347, rec=0.071, cos=0.002), tot_loss_proj:1.961 [t=0.19s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1000/2000] tot_loss=1.549 (perp=7.347, rec=0.078, cos=0.002), tot_loss_proj:1.962 [t=0.18s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
[1050/2000] tot_loss=1.545 (perp=7.347, rec=0.074, cos=0.002), tot_loss_proj:1.960 [t=0.18s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1100/2000] tot_loss=1.553 (perp=7.347, rec=0.082, cos=0.002), tot_loss_proj:1.963 [t=0.19s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1150/2000] tot_loss=1.550 (perp=7.347, rec=0.079, cos=0.002), tot_loss_proj:1.968 [t=0.19s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
[1200/2000] tot_loss=1.538 (perp=7.347, rec=0.067, cos=0.002), tot_loss_proj:1.963 [t=0.19s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1250/2000] tot_loss=1.549 (perp=7.347, rec=0.078, cos=0.002), tot_loss_proj:1.960 [t=0.18s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1300/2000] tot_loss=1.531 (perp=7.347, rec=0.060, cos=0.002), tot_loss_proj:1.961 [t=0.19s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
[1350/2000] tot_loss=1.528 (perp=7.347, rec=0.057, cos=0.001), tot_loss_proj:1.959 [t=0.22s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1400/2000] tot_loss=1.534 (perp=7.347, rec=0.064, cos=0.001), tot_loss_proj:1.960 [t=0.24s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1450/2000] tot_loss=1.543 (perp=7.347, rec=0.072, cos=0.001), tot_loss_proj:1.967 [t=0.20s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
[1500/2000] tot_loss=1.537 (perp=7.347, rec=0.066, cos=0.001), tot_loss_proj:1.964 [t=0.21s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1550/2000] tot_loss=1.533 (perp=7.347, rec=0.063, cos=0.001), tot_loss_proj:1.953 [t=0.19s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1600/2000] tot_loss=1.538 (perp=7.347, rec=0.067, cos=0.001), tot_loss_proj:1.957 [t=0.18s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
[1650/2000] tot_loss=1.524 (perp=7.347, rec=0.054, cos=0.001), tot_loss_proj:1.956 [t=0.19s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1700/2000] tot_loss=1.541 (perp=7.347, rec=0.070, cos=0.001), tot_loss_proj:1.957 [t=0.18s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1750/2000] tot_loss=1.533 (perp=7.347, rec=0.062, cos=0.001), tot_loss_proj:1.956 [t=0.18s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
[1800/2000] tot_loss=1.534 (perp=7.347, rec=0.063, cos=0.001), tot_loss_proj:1.960 [t=0.19s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1850/2000] tot_loss=1.537 (perp=7.347, rec=0.066, cos=0.001), tot_loss_proj:1.955 [t=0.18s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[1900/2000] tot_loss=1.536 (perp=7.347, rec=0.065, cos=0.001), tot_loss_proj:1.963 [t=0.19s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
[1950/2000] tot_loss=1.542 (perp=7.347, rec=0.071, cos=0.001), tot_loss_proj:1.955 [t=0.19s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Attempt swap
[2000/2000] tot_loss=1.531 (perp=7.347, rec=0.060, cos=0.001), tot_loss_proj:1.965 [t=0.24s]
prediction: ['[CLS] music pummel us with imagery or phony [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] music pummel us with imagery or phony [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 91.865 | p: 91.371 | r: 92.482
rouge2     | fm: 58.996 | p: 58.787 | r: 59.407
rougeL     | fm: 78.862 | p: 78.452 | r: 79.251
rougeLsum  | fm: 78.712 | p: 78.333 | r: 79.099
r1fm+r2fm = 150.861

input #40 time: 0:08:35 | total time: 5:47:56


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.999304507364323
highest_index [0]
highest [0.999304507364323]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9788511395454407 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9516528844833374 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 0.9389455914497375 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 0.9341390132904053 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.928720235824585 for ['[CLS]grapher pr [SEP]']
[Init] best rec loss: 0.924547553062439 for ['[CLS]mler previously [SEP]']
[Init] best rec loss: 0.9216023683547974 for ['[CLS] style tomorrow [SEP]']
[Init] best rec loss: 0.9001919627189636 for ['[CLS] electors mediterranean [SEP]']
[Init] best rec loss: 0.8952876925468445 for ['[CLS] meetswr [SEP]']
[Init] best rec loss: 0.8542567491531372 for ['[CLS] bolivar satisfied [SEP]']
[Init] best rec loss: 0.8272965550422668 for ['[CLS] ways whether [SEP]']
[Init] best perm rec loss: 0.8260568976402283 for ['[CLS] whether ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.150 (perp=10.212, rec=0.106, cos=0.002), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.114 (perp=10.212, rec=0.070, cos=0.002), tot_loss_proj:2.109 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.102 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.114 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.093 (perp=10.212, rec=0.049, cos=0.001), tot_loss_proj:2.128 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.113 (perp=10.212, rec=0.070, cos=0.001), tot_loss_proj:2.103 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.106 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.099 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.121 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.111 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.109 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.107 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.095 (perp=10.212, rec=0.051, cos=0.001), tot_loss_proj:2.107 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.114 (perp=10.212, rec=0.070, cos=0.001), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.096 (perp=10.212, rec=0.052, cos=0.001), tot_loss_proj:2.107 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.121 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.096 (perp=10.212, rec=0.052, cos=0.001), tot_loss_proj:2.108 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.113 (perp=10.212, rec=0.069, cos=0.001), tot_loss_proj:2.107 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.115 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.096 [t=0.20s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.103 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.105 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.100 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.098 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.105 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.121 [t=0.31s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.092 (perp=10.212, rec=0.048, cos=0.001), tot_loss_proj:2.109 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.107 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.125 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.121 (perp=10.212, rec=0.078, cos=0.001), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.116 (perp=10.212, rec=0.072, cos=0.001), tot_loss_proj:2.118 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.106 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.108 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.104 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.113 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.095 (perp=10.212, rec=0.051, cos=0.001), tot_loss_proj:2.113 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.101 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.112 [t=0.20s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.101 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.088 | p: 91.569 | r: 92.697
rouge2     | fm: 60.111 | p: 59.835 | r: 60.403
rougeL     | fm: 79.415 | p: 79.050 | r: 79.790
rougeLsum  | fm: 79.176 | p: 78.891 | r: 79.584
r1fm+r2fm = 152.199

input #41 time: 0:08:30 | total time: 5:56:26


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9993257960966828
highest_index [0]
highest [0.9993257960966828]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9041017889976501 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8518991470336914 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8484532237052917 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8162120580673218 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.8055222630500793 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.8025503158569336 for ['[CLS] liftedures ever dare kitchenrs attracted scale enough ran cut mapletaking bandabe treatygible international wishpling superseded stages larger assignmentctric offended [SEP]']
[Init] best perm rec loss: 0.7999148368835449 for ['[CLS] wishtakingctric enoughurespling dare maple supersededbe stages ran offended larger treaty scale assignment bandagiblers international kitchen attracted lifted cut ever [SEP]']
[Init] best perm rec loss: 0.7986771464347839 for ['[CLS]be assignment lifted stages largerrs attracted maplepling enough banda offended daretaking treaty ever ran cutures international wish kitchen scalectric supersededgible [SEP]']
[Init] best perm rec loss: 0.7972655892372131 for ['[CLS] wish ran larger kitchen treaty assignmentpling maple offendedures attracted supersededctrictaking ever stages scale bandabe cut enough lifted darersgible international [SEP]']
[Init] best perm rec loss: 0.7947720885276794 for ['[CLS]ctric dare wish treaty stages superseded international scalebegible largerpling banda offendedures kitchen ever cut liftedtakingrs maple ran attracted enough assignment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.840 (perp=12.659, rec=0.298, cos=0.010), tot_loss_proj:3.336 [t=0.20s]
prediction: ['[CLS] twain expecting forgot funds the bram running more.git department alleged mom poorly after police shell military corpse shirt programming loyalist presidential flood jail scenario [SEP]']
[ 100/2000] tot_loss=2.601 (perp=11.898, rec=0.213, cos=0.008), tot_loss_proj:3.096 [t=0.24s]
prediction: ['[CLS] stanford boring forgot toed equilibrium winner a. carlo department attributed poorly poorly as re subspecies exhibitco identification programming loyalist school cliff ruin project [SEP]']
[ 150/2000] tot_loss=2.487 (perp=11.525, rec=0.179, cos=0.003), tot_loss_proj:2.944 [t=0.21s]
prediction: ['[CLS] stanford include forgot to the equilibrium into a.gible school fatal poorly poorly as regger filmmaker attack playing programming sis school nightclub anything project [SEP]']
[ 200/2000] tot_loss=2.405 (perp=11.237, rec=0.150, cos=0.007), tot_loss_proj:3.003 [t=0.24s]
prediction: ['[CLS] stanford include forgot to the halfway into include.gger school attraction they poorly as regger filmmaker attackgger anything scary school setting anything project [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.169 (perp=10.189, rec=0.129, cos=0.002), tot_loss_proj:2.926 [t=0.19s]
prediction: ['[CLS] runs include forgot to the halfway into include anything scary school attraction they poorly as regger scary deathgger anything scary school setting. project [SEP]']
[ 300/2000] tot_loss=2.330 (perp=11.067, rec=0.115, cos=0.002), tot_loss_proj:3.014 [t=0.19s]
prediction: ['[CLS] runs include forgot to the halfway into include of scary school attraction they poorly as regger scary fatalgger anything halfway school setting. filmmakers [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.136 (perp=10.162, rec=0.102, cos=0.002), tot_loss_proj:2.895 [t=0.22s]
prediction: ['[CLS] attraction include forgot to the halfway into include of scary school runs they poorly as regger scary fatal attraction anything halfway school setting. filmmakers [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.061 (perp=9.853, rec=0.089, cos=0.002), tot_loss_proj:2.931 [t=0.30s]
prediction: ['[CLS] attraction include forgot to the halfway into include anything scary school runs they poorly asjigger scary fatal attraction of halfway school setting. filmmakers [SEP]']
[ 450/2000] tot_loss=2.109 (perp=10.086, rec=0.091, cos=0.001), tot_loss_proj:3.095 [t=0.21s]
prediction: ['[CLS] attraction include forgot to the halfway into include anything scary school runs they poorly asjigger scary fatal attraction a halfway high setting. filmmakers [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.153 (perp=10.289, rec=0.093, cos=0.002), tot_loss_proj:2.996 [t=0.22s]
prediction: ['[CLS] the attraction include forgot to even into filmmakers anything scary school runs they poorly asjigger scary fatal attraction a halfway high setting. filmmakers [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.044 (perp=9.742, rec=0.094, cos=0.002), tot_loss_proj:2.617 [t=0.26s]
prediction: ['[CLS] the attraction include forgot to even into filmmakers anything scary school as they poorly runsjigger scary fatal attraction a halfway high setting. filmmakers [SEP]']
[ 600/2000] tot_loss=2.288 (perp=10.993, rec=0.088, cos=0.002), tot_loss_proj:2.824 [t=0.29s]
prediction: ['[CLS] the attraction include forgot to even into filmmakers anything scary school as they poorly runsjigger scary fatalji a halfway high setting. filmmakers [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.225 (perp=10.729, rec=0.078, cos=0.001), tot_loss_proj:2.939 [t=0.26s]
prediction: ['[CLS] the attraction scary forgot to even into filmmakers anything scary school as they poorly runsjigger include fatalji a halfway high setting. project [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.106 (perp=10.074, rec=0.090, cos=0.001), tot_loss_proj:3.011 [t=0.25s]
prediction: ['[CLS] the attraction scary forgot to school into filmmakers anything scary even as they poorly runsjigger include fatalji a halfway high setting. project [SEP]']
[ 750/2000] tot_loss=2.101 (perp=10.074, rec=0.084, cos=0.001), tot_loss_proj:3.012 [t=0.25s]
prediction: ['[CLS] the attraction scary forgot to school into filmmakers anything scary even as they poorly runsjigger include fatalji a halfway high setting. project [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.926 (perp=9.195, rec=0.085, cos=0.001), tot_loss_proj:2.788 [t=0.25s]
prediction: ['[CLS] the attraction scary forgot to schoolji filmmakers anything scary even as they poorly runsjigger include fatal into a halfway high setting. project [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.770 (perp=8.403, rec=0.088, cos=0.002), tot_loss_proj:2.460 [t=0.24s]
prediction: ['[CLS] the attraction scary forgot to school a filmmakers anything scary even as they include runsjigger poorly fatal into a halfway high setting. project [SEP]']
[ 900/2000] tot_loss=1.758 (perp=8.403, rec=0.076, cos=0.001), tot_loss_proj:2.455 [t=0.24s]
prediction: ['[CLS] the attraction scary forgot to school a filmmakers anything scary even as they include runsjigger poorly fatal into a halfway high setting. project [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.722 (perp=8.223, rec=0.076, cos=0.001), tot_loss_proj:2.356 [t=0.27s]
prediction: ['[CLS] the attraction runs forgot to school a filmmakers anything scary even as they include scaryjigger poorly fatal into a halfway high setting. project [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.704 (perp=8.116, rec=0.079, cos=0.001), tot_loss_proj:2.363 [t=0.29s]
prediction: ['[CLS] the attraction runs forgot to a school filmmakers anything scary even as they include scaryjigger poorly fatal into a halfway high setting. project [SEP]']
[1050/2000] tot_loss=1.706 (perp=8.116, rec=0.081, cos=0.001), tot_loss_proj:2.375 [t=0.28s]
prediction: ['[CLS] the attraction runs forgot to a school filmmakers anything scary even as they include scaryjigger poorly fatal into a halfway high setting. project [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.625 (perp=7.736, rec=0.076, cos=0.001), tot_loss_proj:2.233 [t=0.19s]
prediction: ['[CLS] the attraction runs forgot to a school filmmakers anything scary even as they include scaryjigger poorly project fatal into a halfway high setting. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.631 (perp=7.736, rec=0.082, cos=0.001), tot_loss_proj:2.235 [t=0.19s]
prediction: ['[CLS] the attraction runs forgot to a school filmmakers anything scary even as they include scaryjigger poorly project fatal into a halfway high setting. [SEP]']
[1200/2000] tot_loss=1.780 (perp=8.533, rec=0.072, cos=0.001), tot_loss_proj:2.425 [t=0.30s]
prediction: ['[CLS] the attraction runs forgot toji school filmmakers anything scary even as they include scaryjigger poorly project fatal into a halfway high setting. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.761 (perp=8.408, rec=0.078, cos=0.001), tot_loss_proj:2.414 [t=0.22s]
prediction: ['[CLS] the attraction runs forgot toji filmmakers school anything scary even as they include scaryjigger poorly project fatal into a halfway high setting. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.709 (perp=8.147, rec=0.078, cos=0.002), tot_loss_proj:2.344 [t=0.19s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers school anything even as they include scaryjigger poorly project fatal into a halfway high setting. [SEP]']
[1350/2000] tot_loss=1.703 (perp=8.147, rec=0.072, cos=0.001), tot_loss_proj:2.341 [t=0.21s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers school anything even as they include scaryjigger poorly project fatal into a halfway high setting. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.706 (perp=8.147, rec=0.075, cos=0.001), tot_loss_proj:2.342 [t=0.19s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers school anything even as they include scaryjigger poorly project fatal into a halfway high setting. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.703 (perp=8.147, rec=0.072, cos=0.001), tot_loss_proj:2.338 [t=0.23s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers school anything even as they include scaryjigger poorly project fatal into a halfway high setting. [SEP]']
[1500/2000] tot_loss=1.705 (perp=8.147, rec=0.074, cos=0.001), tot_loss_proj:2.344 [t=0.19s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers school anything even as they include scaryjigger poorly project fatal into a halfway high setting. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.631 (perp=7.752, rec=0.079, cos=0.001), tot_loss_proj:2.206 [t=0.19s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers anything even as they include scaryjigger poorly project fatal into a halfway high school setting. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.629 (perp=7.752, rec=0.077, cos=0.001), tot_loss_proj:2.211 [t=0.19s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers anything even as they include scaryjigger poorly project fatal into a halfway high school setting. [SEP]']
[1650/2000] tot_loss=1.623 (perp=7.752, rec=0.071, cos=0.001), tot_loss_proj:2.213 [t=0.21s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers anything even as they include scaryjigger poorly project fatal into a halfway high school setting. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.630 (perp=7.752, rec=0.078, cos=0.001), tot_loss_proj:2.212 [t=0.23s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers anything even as they include scaryjigger poorly project fatal into a halfway high school setting. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.620 (perp=7.752, rec=0.068, cos=0.001), tot_loss_proj:2.206 [t=0.18s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers anything even as they include scaryjigger poorly project fatal into a halfway high school setting. [SEP]']
[1800/2000] tot_loss=1.630 (perp=7.752, rec=0.078, cos=0.001), tot_loss_proj:2.207 [t=0.20s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers anything even as they include scaryjigger poorly project fatal into a halfway high school setting. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.629 (perp=7.752, rec=0.078, cos=0.001), tot_loss_proj:2.209 [t=0.23s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers anything even as they include scaryjigger poorly project fatal into a halfway high school setting. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.627 (perp=7.752, rec=0.075, cos=0.001), tot_loss_proj:2.206 [t=0.19s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers anything even as they include scaryjigger poorly project fatal into a halfway high school setting. [SEP]']
[1950/2000] tot_loss=1.622 (perp=7.752, rec=0.071, cos=0.001), tot_loss_proj:2.207 [t=0.20s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers anything even as they include scaryjigger poorly project fatal into a halfway high school setting. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.622 (perp=7.752, rec=0.070, cos=0.001), tot_loss_proj:2.210 [t=0.18s]
prediction: ['[CLS] the attraction runs forgot to scaryji filmmakers anything even as they include scaryjigger poorly project fatal into a halfway high school setting. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] the attraction runs forgot toji school filmmakers anything scary even as they include scaryjigger poorly project fatal into a halfway high setting. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 17.391 | p: 17.391 | r: 17.391
rougeL     | fm: 58.333 | p: 58.333 | r: 58.333
rougeLsum  | fm: 58.333 | p: 58.333 | r: 58.333
r1fm+r2fm = 104.891

[Aggregate metrics]:
rouge1     | fm: 92.001 | p: 91.492 | r: 92.549
rouge2     | fm: 59.225 | p: 58.935 | r: 59.511
rougeL     | fm: 78.841 | p: 78.565 | r: 79.208
rougeLsum  | fm: 78.567 | p: 78.256 | r: 78.921
r1fm+r2fm = 151.226

input #42 time: 0:08:58 | total time: 6:05:24


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9992732655805339
highest_index [0]
highest [0.9992732655805339]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9607493281364441 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9227121472358704 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8925204873085022 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8689665198326111 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.8586649298667908 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.846950888633728 for ['[CLS] carested royals erica [SEP]']
[Init] best rec loss: 0.8364328742027283 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 0.7888320684432983 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7853228449821472 for ['[CLS] secondck climbbus [SEP]']
[Init] best rec loss: 0.7806761264801025 for ['[CLS] deserved oxidation council enrollment [SEP]']
[Init] best perm rec loss: 0.7801570892333984 for ['[CLS] oxidation enrollment deserved council [SEP]']
[Init] best perm rec loss: 0.7796530723571777 for ['[CLS] oxidation council enrollment deserved [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.048 (perp=8.970, rec=0.248, cos=0.006), tot_loss_proj:2.807 [t=0.23s]
prediction: ['[CLS] offrcissistic [SEP]']
[ 100/2000] tot_loss=1.141 (perp=5.048, rec=0.128, cos=0.003), tot_loss_proj:1.085 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 150/2000] tot_loss=1.097 (perp=5.048, rec=0.085, cos=0.003), tot_loss_proj:1.091 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
[ 200/2000] tot_loss=1.084 (perp=5.048, rec=0.073, cos=0.002), tot_loss_proj:1.084 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.081 (perp=5.048, rec=0.070, cos=0.002), tot_loss_proj:1.086 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.002), tot_loss_proj:1.090 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.065 (perp=5.048, rec=0.053, cos=0.002), tot_loss_proj:1.090 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.063 (perp=5.048, rec=0.052, cos=0.001), tot_loss_proj:1.086 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.002), tot_loss_proj:1.082 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.081 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.065 (perp=5.048, rec=0.054, cos=0.001), tot_loss_proj:1.085 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.074 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.080 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.092 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.086 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.080 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.087 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.082 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.081 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.077 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.082 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.076 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.081 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.081 (perp=5.048, rec=0.070, cos=0.001), tot_loss_proj:1.071 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.080 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.063 (perp=5.048, rec=0.052, cos=0.001), tot_loss_proj:1.089 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.095 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.081 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.081 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.078 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.064 (perp=5.048, rec=0.053, cos=0.001), tot_loss_proj:1.078 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.090 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.064 (perp=5.048, rec=0.053, cos=0.001), tot_loss_proj:1.089 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.084 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.070 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.079 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.081 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.063 (perp=5.048, rec=0.052, cos=0.001), tot_loss_proj:1.075 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.056 (perp=5.048, rec=0.045, cos=0.001), tot_loss_proj:1.080 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.088 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.091 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.195 | p: 91.746 | r: 92.740
rouge2     | fm: 60.161 | p: 59.967 | r: 60.456
rougeL     | fm: 79.165 | p: 78.849 | r: 79.476
rougeLsum  | fm: 79.233 | p: 78.891 | r: 79.570
r1fm+r2fm = 152.355

input #43 time: 0:08:19 | total time: 6:13:44


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9992417534706349
highest_index [0]
highest [0.9992417534706349]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9856536388397217 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9538675546646118 for ['[CLS] photo led breath sound coin day opponents allies joycevel move throne doin head huge guest perhaps ; his gaze saddle decide willise new great ¡wark grand [SEP]']
[Init] best rec loss: 0.9338456988334656 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.9291354417800903 for ['[CLS]hat since shotsisance morning her wound ji living appealing fifapis aus braun filmed james saved ian service person alias motion inclination age storage hyper heard wind any [SEP]']
[Init] best rec loss: 0.9056149125099182 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best perm rec loss: 0.904999852180481 for ['[CLS] fatty formerly haley ltd raceway nation brow harbor slavehair intent contact hello ; contains contestants heeosi data graphic capacity settled landon blue comedy rock s co illustrated [SEP]']
[Init] best perm rec loss: 0.9043598175048828 for ['[CLS] s comedyosi slave ltd co contestants contains hello graphic settled capacity hee intent ; contact formerly brow landon blue data illustrated rock nationhair harbor haley fatty raceway [SEP]']
[Init] best perm rec loss: 0.903514564037323 for ['[CLS] comedyhair settled intent contestants capacity contact contains hello rock data nation brow formerly ; hee co blueosi graphic fatty illustrated raceway ltd slave s landon haley harbor [SEP]']
[Init] best perm rec loss: 0.90308678150177 for ['[CLS] graphic contains comedy settled raceway ; intent hee hello slave contact fatty brow ltd s capacityosi formerly rock co data illustratedhair harbor contestants landon haley blue nation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.383 (perp=10.739, rec=0.230, cos=0.006), tot_loss_proj:3.180 [t=0.18s]
prediction: ['[CLS] tibet the translation. translation translation lost that lost the cdp routine ; another losttory collaborator default lost killing execution of loses routine jesus iccity hollywood translation [SEP]']
[ 100/2000] tot_loss=2.322 (perp=10.930, rec=0.133, cos=0.003), tot_loss_proj:3.046 [t=0.19s]
prediction: ['[CLS]nesian in the. translation translation lost another ( the revolves routine has been lostled executed slack lost execution execution. slack routine currency areity hollywoodstorm [SEP]']
[ 150/2000] tot_loss=2.121 (perp=10.057, rec=0.108, cos=0.002), tot_loss_proj:2.652 [t=0.18s]
prediction: ['[CLS]alic in the. translation translation. another. thealic routine has been lost in which slack slack execution fright. slack routineimus areity hollywoodfest [SEP]']
[ 200/2000] tot_loss=2.117 (perp=10.120, rec=0.091, cos=0.002), tot_loss_proj:2.651 [t=0.18s]
prediction: ['[CLS]alic in the. translation translation. another. thealic routine has been lost during which slack slack execution fright.izes routineimus in wherein hollywoodfest [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.046 (perp=9.774, rec=0.090, cos=0.002), tot_loss_proj:2.433 [t=0.24s]
prediction: ['[CLS]alic in the. translation translation. another. thealic routine has been lost. which slackalic execution frightationizes routine absurd in which hollywoodfest [SEP]']
[ 300/2000] tot_loss=1.933 (perp=9.311, rec=0.069, cos=0.001), tot_loss_proj:2.308 [t=0.27s]
prediction: ['[CLS]alic in the. translation translation. another. thealic routine has been lost. the slackalic execution premiseityizes routine absurd in which hollywoodfest [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.815 (perp=8.670, rec=0.080, cos=0.001), tot_loss_proj:2.217 [t=0.28s]
prediction: ['[CLS]s in the. translation translation. another. thealic fright has been lost. the slack absurd execution premisealicizes routine absurd in which hollywoodfest [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.714 (perp=8.157, rec=0.081, cos=0.001), tot_loss_proj:2.113 [t=0.19s]
prediction: ['[CLS]s in the.. translation. another translation thealic fright has been lost. the slack absurd execution premisealicizes routine absurd in which hollywoodfest [SEP]']
[ 450/2000] tot_loss=1.837 (perp=8.859, rec=0.064, cos=0.001), tot_loss_proj:2.256 [t=0.19s]
prediction: ['[CLS]s in the. it translation. anotherity thealic fright has been lost. the slack absurd execution premisealicizes routine absurd in which hollywoodfest [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.782 (perp=8.095, rec=0.159, cos=0.004), tot_loss_proj:2.087 [t=0.27s]
prediction: ['[CLS]ed in the absurd.. translation. anotherity thealic fright has been lost. the slack absurd execution premisealicizes routine in which hollywoodfest [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.746 (perp=7.965, rec=0.149, cos=0.004), tot_loss_proj:2.141 [t=0.21s]
prediction: ['[CLS]ed in the absurd.. translation. another scottish thealic which has been lost. the slack absurd execution premisealicizes routine in fright hollywoodfest [SEP]']
[ 600/2000] tot_loss=1.708 (perp=7.895, rec=0.127, cos=0.003), tot_loss_proj:2.077 [t=0.22s]
prediction: ['[CLS]ed in thescript.. translation. another translation thealic which has been lost. the slack absurd execution premisealicizes routine in fright hollywoodfest [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.683 (perp=7.908, rec=0.099, cos=0.002), tot_loss_proj:2.085 [t=0.22s]
prediction: ['[CLS]ed in the gameplay.. translation. another translation frightalic which has been lost. the slack absurd execution premisealicizes routine in the hollywoodfest [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.675 (perp=7.757, rec=0.120, cos=0.003), tot_loss_proj:2.049 [t=0.19s]
prediction: ['[CLS]ed in the gameplay.. translation. another translation frightalic which has been lost. the absurd slack execution premisealicizes routine in the hollywoodfest [SEP]']
[ 750/2000] tot_loss=1.637 (perp=7.671, rec=0.101, cos=0.002), tot_loss_proj:1.994 [t=0.19s]
prediction: ['[CLS]ed in thescript.. translation. another translation frightalic which has been lost. the absurd slack execution premisealicizes routine in the hollywoodfest [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.725 (perp=8.100, rec=0.103, cos=0.002), tot_loss_proj:2.235 [t=0.28s]
prediction: ['[CLS]ed in thezziness.. translation. another hollywood frightalic which has been lost. the absurd slack execution premisealicizes routine it the hollywoodfest [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.725 (perp=8.100, rec=0.104, cos=0.002), tot_loss_proj:2.232 [t=0.19s]
prediction: ['[CLS]ed in thezziness.. translation. another hollywood frightalic which has been lost. the absurd slack execution premisealicizes routine it the hollywoodfest [SEP]']
[ 900/2000] tot_loss=1.721 (perp=8.100, rec=0.100, cos=0.002), tot_loss_proj:2.233 [t=0.19s]
prediction: ['[CLS]ed in thezziness.. translation. another hollywood frightalic which has been lost. the absurd slack execution premisealicizes routine it the hollywoodfest [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.649 (perp=7.762, rec=0.094, cos=0.002), tot_loss_proj:2.145 [t=0.20s]
prediction: ['[CLS]ity in the translationzziness... another hollywood frightalic which has been lost. the absurd slack execution premisealicizes routine it the hollywoodfest [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.597 (perp=7.485, rec=0.098, cos=0.002), tot_loss_proj:2.077 [t=0.20s]
prediction: ['[CLS]ity in the translationzziness... another hollywood frightalic which has been lost. the absurd slack execution in premisealicizes routine the hollywoodfest [SEP]']
[1050/2000] tot_loss=1.595 (perp=7.485, rec=0.096, cos=0.002), tot_loss_proj:2.078 [t=0.19s]
prediction: ['[CLS]ity in the translationzziness... another hollywood frightalic which has been lost. the absurd slack execution in premisealicizes routine the hollywoodfest [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.538 (perp=7.235, rec=0.089, cos=0.002), tot_loss_proj:2.081 [t=0.21s]
prediction: ['[CLS]ity in the translationzziness... another hollywood frightalic which has been lost. the absurd slack execution routine premisealicizes in the hollywoodfest [SEP]']
Attempt swap
[1150/2000] tot_loss=1.602 (perp=7.529, rec=0.094, cos=0.002), tot_loss_proj:2.110 [t=0.19s]
prediction: ['[CLS]ity in the translationzziness... another hollywood frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
[1200/2000] tot_loss=1.605 (perp=7.529, rec=0.098, cos=0.002), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS]ity in the translationzziness... another hollywood frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
[1250/2000] tot_loss=1.602 (perp=7.565, rec=0.088, cos=0.002), tot_loss_proj:2.103 [t=0.19s]
prediction: ['[CLS]ity in the translationzziness... another execution frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
[1300/2000] tot_loss=1.598 (perp=7.565, rec=0.084, cos=0.002), tot_loss_proj:2.095 [t=0.19s]
prediction: ['[CLS]ity in the translationzziness... another execution frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
[1350/2000] tot_loss=1.596 (perp=7.565, rec=0.081, cos=0.002), tot_loss_proj:2.098 [t=0.24s]
prediction: ['[CLS]ity in the translationzziness... another execution frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
[1400/2000] tot_loss=1.608 (perp=7.602, rec=0.086, cos=0.002), tot_loss_proj:2.044 [t=0.22s]
prediction: ['[CLS]ity in the translation the... another execution frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.591 (perp=7.500, rec=0.089, cos=0.002), tot_loss_proj:2.097 [t=0.18s]
prediction: ['[CLS] inity the translation the... another execution frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
[1500/2000] tot_loss=1.593 (perp=7.500, rec=0.091, cos=0.002), tot_loss_proj:2.100 [t=0.24s]
prediction: ['[CLS] inity the translation the... another execution frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
[1550/2000] tot_loss=1.590 (perp=7.500, rec=0.088, cos=0.002), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] inity the translation the... another execution frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.562 (perp=7.364, rec=0.088, cos=0.002), tot_loss_proj:2.160 [t=0.24s]
prediction: ['[CLS] inity the translation the... execution another frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
[1650/2000] tot_loss=1.556 (perp=7.364, rec=0.081, cos=0.002), tot_loss_proj:2.159 [t=0.20s]
prediction: ['[CLS] inity the translation the... execution another frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
[1700/2000] tot_loss=1.557 (perp=7.364, rec=0.082, cos=0.002), tot_loss_proj:2.161 [t=0.19s]
prediction: ['[CLS] inity the translation the... execution another frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
[1750/2000] tot_loss=1.553 (perp=7.364, rec=0.078, cos=0.002), tot_loss_proj:2.158 [t=0.21s]
prediction: ['[CLS] inity the translation the... execution another frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
[1800/2000] tot_loss=1.556 (perp=7.364, rec=0.082, cos=0.002), tot_loss_proj:2.154 [t=0.23s]
prediction: ['[CLS] inity the translation the... execution another frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
[1850/2000] tot_loss=1.558 (perp=7.364, rec=0.084, cos=0.002), tot_loss_proj:2.158 [t=0.25s]
prediction: ['[CLS] inity the translation the... execution another frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
[1900/2000] tot_loss=1.557 (perp=7.364, rec=0.082, cos=0.002), tot_loss_proj:2.161 [t=0.23s]
prediction: ['[CLS] inity the translation the... execution another frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
[1950/2000] tot_loss=1.554 (perp=7.364, rec=0.080, cos=0.002), tot_loss_proj:2.156 [t=0.19s]
prediction: ['[CLS] inity the translation the... execution another frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Attempt swap
[2000/2000] tot_loss=1.551 (perp=7.364, rec=0.077, cos=0.002), tot_loss_proj:2.156 [t=0.19s]
prediction: ['[CLS] inity the translation the... execution another frightalic which has been lost. the absurd slack execution routine premisealicizes it the hollywoodfest [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS]s in the. it translation. anotherity thealic fright has been lost. the slack absurd execution premisealicizes routine absurd in which hollywoodfest [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.870 | p: 60.870 | r: 60.870
rouge2     | fm: 22.727 | p: 22.727 | r: 22.727
rougeL     | fm: 39.130 | p: 39.130 | r: 39.130
rougeLsum  | fm: 39.130 | p: 39.130 | r: 39.130
r1fm+r2fm = 83.597

[Aggregate metrics]:
rouge1     | fm: 91.402 | p: 90.939 | r: 91.939
rouge2     | fm: 59.310 | p: 59.072 | r: 59.569
rougeL     | fm: 78.390 | p: 78.041 | r: 78.783
rougeLsum  | fm: 78.238 | p: 77.892 | r: 78.642
r1fm+r2fm = 150.713

input #44 time: 0:08:47 | total time: 6:22:31


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9993986811377396
highest_index [0]
highest [0.9993986811377396]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.9825860261917114 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.9404022693634033 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.9185224771499634 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.9133827090263367 for ['[CLS] look greater applications still decay line learning reagan ata alley fact isn starboard thorne portion stepped women5 bee defense producing ł wingtlestation hold net festival [SEP]']
[Init] best rec loss: 0.903794527053833 for ['[CLS] need invitation small cross hot no sk cello deep leader motions harry slide guest pity ash nepal rather ashleyinsman previous walt mclean prix van zoneition [SEP]']
[Init] best rec loss: 0.9032831192016602 for ['[CLS] circussome nj lodge photoᅵ bioome kg morning. have interviewrcus account winfield letofan shy broken man floor sunday sack tuneenter station ll [SEP]']
[Init] best rec loss: 0.8698243498802185 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.8686729073524475 for ['[CLS] skinlanda ( whoa tree ku entrance special five bore2 via curtis operated murmured v status letter few enclosed gentry joan around military single taste footballtiv [SEP]']
[Init] best perm rec loss: 0.8660717606544495 for ['[CLS] single (tiv tree around v entrance letter bore ku operated football enclosed curtislanda five military taste joan status murmured skin2 via few special gentry whoa [SEP]']
[Init] best perm rec loss: 0.8620867133140564 for ['[CLS] five footballtiv2 taste military ku via single skin status few enclosed special curtis murmured whoa entrancelanda ( tree joan around bore letter v gentry operated [SEP]']
[Init] best perm rec loss: 0.861274242401123 for ['[CLS] murmured2 single taste via skintiv curtis whoa tree v football entrancelanda ku joan five status bore letter few around ( enclosed special operated military gentry [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.497 (perp=10.894, rec=0.309, cos=0.009), tot_loss_proj:3.468 [t=0.23s]
prediction: ['[CLS] than mouth florida much thaned reasons - guard exercise than shottone - try na then attached equipment of than action thatel -. - birds [SEP]']
[ 100/2000] tot_loss=2.251 (perp=10.072, rec=0.232, cos=0.004), tot_loss_proj:3.100 [t=0.19s]
prediction: ['[CLS] - upper question much than bow movements - number exercise chick -ove - shelf - this gi shelf - - fitted bowmm - - shoot movements [SEP]']
[ 150/2000] tot_loss=2.045 (perp=9.376, rec=0.167, cos=0.002), tot_loss_proj:2.928 [t=0.27s]
prediction: ['[CLS] - upper single north than bow movements -el exercise bow - shelf - shelf - this gi shelf - - exercise bowmmick - shoot exercises [SEP]']
[ 200/2000] tot_loss=2.034 (perp=9.495, rec=0.133, cos=0.003), tot_loss_proj:2.889 [t=0.19s]
prediction: ['[CLS] - upper long - than bow movements -el exercise long on shelf - shelf in this gi shelf - - exercise bowmmick - shoot exercises [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.909 (perp=9.007, rec=0.106, cos=0.002), tot_loss_proj:2.742 [t=0.19s]
prediction: ['[CLS] - upper long - than bow movements -el exercise - on shelf long shelf in this gi shelf - - exercise bowmmick - crime shoot [SEP]']
[ 300/2000] tot_loss=1.882 (perp=8.929, rec=0.095, cos=0.001), tot_loss_proj:2.792 [t=0.19s]
prediction: ['[CLS] - upper long - than bow movements -el exercise - on shelf long shelf in this gi shelf -, drama bowmmick - crime shoot [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.791 (perp=8.496, rec=0.091, cos=0.001), tot_loss_proj:2.611 [t=0.18s]
prediction: ['[CLS] - this long - than bow movements -el exercise - on shelf long shelf in upper gi shelf -, drama bowmmick - crime shoot [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.778 (perp=8.445, rec=0.088, cos=0.001), tot_loss_proj:2.525 [t=0.19s]
prediction: ['[CLS] - this long - than bow movements -el exercise - on shelf long shelf in shelf gi - -, drama bowmmick - crime shoot [SEP]']
[ 450/2000] tot_loss=1.771 (perp=8.445, rec=0.081, cos=0.001), tot_loss_proj:2.524 [t=0.19s]
prediction: ['[CLS] - this long - than bow movements -el exercise - on shelf long shelf in shelf gi - -, drama bowmmick - crime shoot [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.769 (perp=8.460, rec=0.076, cos=0.001), tot_loss_proj:2.569 [t=0.19s]
prediction: ['[CLS] - this long bow - than movements -el exercise - on shelf long shelf in point gi - -, drama bowmmicky crime shoot [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.736 (perp=8.233, rec=0.088, cos=0.001), tot_loss_proj:2.596 [t=0.19s]
prediction: ['[CLS] - this long the - than movements - long exercise - on shootel shelf in point gi - -, drama bowmmicky crime shoot [SEP]']
[ 600/2000] tot_loss=1.775 (perp=8.473, rec=0.079, cos=0.001), tot_loss_proj:2.649 [t=0.19s]
prediction: ['[CLS] - this long the - than movements - long exercise - on shootel shelf in shoot gi - -, drama bowmmicky crime shoot [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.688 (perp=8.038, rec=0.079, cos=0.001), tot_loss_proj:2.323 [t=0.19s]
prediction: ['[CLS] - this long the - than movements - long exercise - on shootel shelf in shoot - -, drama bow gimmicky crime shoot [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.630 (perp=7.743, rec=0.080, cos=0.001), tot_loss_proj:2.260 [t=0.19s]
prediction: ['[CLS] - this long the - than movements - long exercise - on shootel shelf in shoot - - bow drama, gimmicky crime shoot [SEP]']
[ 750/2000] tot_loss=1.630 (perp=7.743, rec=0.080, cos=0.001), tot_loss_proj:2.265 [t=0.19s]
prediction: ['[CLS] - this long the - than movements - long exercise - on shootel shelf in shoot - - bow drama, gimmicky crime shoot [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.504 (perp=7.176, rec=0.067, cos=0.001), tot_loss_proj:2.100 [t=0.25s]
prediction: ['[CLS] - this long the - than movements - long exercise - on bowel shelf in shoot - - shoot drama, gimmicky crime shoot [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.484 (perp=7.078, rec=0.068, cos=0.001), tot_loss_proj:2.062 [t=0.19s]
prediction: ['[CLS] - this long - the than movements - long exercise - on bowel shelf in shoot - - shoot drama, gimmicky crime shoot [SEP]']
[ 900/2000] tot_loss=1.530 (perp=7.312, rec=0.067, cos=0.001), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] - this long - the than movements - long exercise - on bowel shelf in point - - shoot drama, gimmicky crime shoot [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.552 (perp=7.344, rec=0.082, cos=0.001), tot_loss_proj:2.045 [t=0.24s]
prediction: ['[CLS] - this and - the than movements - long exercise - on bowel shelf in point long - shoot drama, gimmicky crime shoot [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.484 (perp=7.048, rec=0.073, cos=0.001), tot_loss_proj:2.263 [t=0.21s]
prediction: ['[CLS] - this shoot - the than movements - long exercise - on bowel shelf in point long - shoot drama, gimmicky crime and [SEP]']
[1050/2000] tot_loss=1.481 (perp=7.043, rec=0.071, cos=0.001), tot_loss_proj:2.342 [t=0.19s]
prediction: ['[CLS] - this shoot - the than movements - long exercise - on bowel shelf in point - - shoot drama, gimmicky crime and [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.478 (perp=7.043, rec=0.068, cos=0.001), tot_loss_proj:2.353 [t=0.19s]
prediction: ['[CLS] - this shoot - the than movements - long exercise - on bowel shelf in point - - shoot drama, gimmicky crime and [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.457 (perp=6.957, rec=0.065, cos=0.001), tot_loss_proj:2.211 [t=0.20s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf in point the - shoot drama, gimmicky crime and [SEP]']
[1200/2000] tot_loss=1.472 (perp=6.957, rec=0.080, cos=0.001), tot_loss_proj:2.214 [t=0.23s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf in point the - shoot drama, gimmicky crime and [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.391 (perp=6.576, rec=0.075, cos=0.001), tot_loss_proj:2.071 [t=0.19s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf in point the crime shoot drama, gimmicky - and [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.361 (perp=6.432, rec=0.073, cos=0.001), tot_loss_proj:2.074 [t=0.25s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf shoot in point the crime drama, gimmicky - and [SEP]']
[1350/2000] tot_loss=1.355 (perp=6.432, rec=0.067, cos=0.001), tot_loss_proj:2.077 [t=0.25s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf shoot in point the crime drama, gimmicky - and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.354 (perp=6.432, rec=0.067, cos=0.001), tot_loss_proj:2.077 [t=0.23s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf shoot in point the crime drama, gimmicky - and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.350 (perp=6.432, rec=0.063, cos=0.001), tot_loss_proj:2.077 [t=0.19s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf shoot in point the crime drama, gimmicky - and [SEP]']
[1500/2000] tot_loss=1.367 (perp=6.432, rec=0.079, cos=0.001), tot_loss_proj:2.079 [t=0.19s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf shoot in point the crime drama, gimmicky - and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.357 (perp=6.432, rec=0.069, cos=0.001), tot_loss_proj:2.073 [t=0.22s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf shoot in point the crime drama, gimmicky - and [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.341 (perp=6.360, rec=0.068, cos=0.001), tot_loss_proj:2.096 [t=0.19s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf shoot point in the crime drama, gimmicky - and [SEP]']
[1650/2000] tot_loss=1.295 (perp=6.112, rec=0.071, cos=0.001), tot_loss_proj:2.029 [t=0.19s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf - point in the crime drama, gimmicky - and [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.274 (perp=6.042, rec=0.065, cos=0.001), tot_loss_proj:2.080 [t=0.21s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf point - in the crime drama, gimmicky - and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.281 (perp=6.042, rec=0.071, cos=0.001), tot_loss_proj:2.078 [t=0.25s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf point - in the crime drama, gimmicky - and [SEP]']
[1800/2000] tot_loss=1.271 (perp=6.042, rec=0.061, cos=0.001), tot_loss_proj:2.076 [t=0.19s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf point - in the crime drama, gimmicky - and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.279 (perp=6.042, rec=0.069, cos=0.001), tot_loss_proj:2.075 [t=0.19s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf point - in the crime drama, gimmicky - and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.282 (perp=6.042, rec=0.072, cos=0.001), tot_loss_proj:2.077 [t=0.18s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf point - in the crime drama, gimmicky - and [SEP]']
[1950/2000] tot_loss=1.276 (perp=6.042, rec=0.067, cos=0.001), tot_loss_proj:2.078 [t=0.19s]
prediction: ['[CLS] - this shoot - - than movements - long exercise - on bowel shelf point - in the crime drama, gimmicky - and [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.275 (perp=6.030, rec=0.068, cos=0.001), tot_loss_proj:1.987 [t=0.24s]
prediction: ['[CLS] - - this shoot - than movements - long exercise - on bowel shelf point - in the crime drama, gimmicky - and [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] - this shoot - - than movements - long exercise - on bowel shelf in point the - shoot drama, gimmicky crime and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 97.297 | p: 94.737 | r: 100.000
rouge2     | fm: 5.714 | p: 5.556 | r: 5.882
rougeL     | fm: 54.054 | p: 52.632 | r: 55.556
rougeLsum  | fm: 54.054 | p: 52.632 | r: 55.556
r1fm+r2fm = 103.012

[Aggregate metrics]:
rouge1     | fm: 91.511 | p: 91.039 | r: 92.116
rouge2     | fm: 58.097 | p: 57.841 | r: 58.270
rougeL     | fm: 77.888 | p: 77.525 | r: 78.267
rougeLsum  | fm: 77.688 | p: 77.301 | r: 78.106
r1fm+r2fm = 149.608

input #45 time: 0:08:40 | total time: 6:31:12


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9992703548035418
highest_index [0]
highest [0.9992703548035418]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9911298155784607 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9792498350143433 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 0.9472112059593201 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9385618567466736 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9372692704200745 for ['[CLS] political m act paperrton fitz [SEP]']
[Init] best rec loss: 0.9318523406982422 for ['[CLS]tyn tillquisite inside chair fixed [SEP]']
[Init] best rec loss: 0.9173271059989929 for ['[CLS] four no and canada reed donald [SEP]']
[Init] best perm rec loss: 0.9158892631530762 for ['[CLS] four donald canada reed and no [SEP]']
[Init] best perm rec loss: 0.9147517085075378 for ['[CLS] donald and four reed no canada [SEP]']
[Init] best perm rec loss: 0.9115938544273376 for ['[CLS] four reed canada and donald no [SEP]']
[Init] best perm rec loss: 0.9111836552619934 for ['[CLS] donald reed canada four no and [SEP]']
[Init] best perm rec loss: 0.9108540415763855 for ['[CLS] and reed donald four no canada [SEP]']
[Init] best perm rec loss: 0.9107707142829895 for ['[CLS] donald and canada no four reed [SEP]']
[Init] best perm rec loss: 0.9106481671333313 for ['[CLS] four reed no donald canada and [SEP]']
[Init] best perm rec loss: 0.9093884825706482 for ['[CLS] and reed no donald canada four [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.617 (perp=12.114, rec=0.191, cos=0.003), tot_loss_proj:2.961 [t=0.19s]
prediction: ['[CLS] striking visual striking slick staged slick [SEP]']
[ 100/2000] tot_loss=1.656 (perp=7.711, rec=0.112, cos=0.003), tot_loss_proj:1.775 [t=0.24s]
prediction: ['[CLS] striking visually striking slickly staged [SEP]']
[ 150/2000] tot_loss=1.625 (perp=7.711, rec=0.081, cos=0.002), tot_loss_proj:1.784 [t=0.18s]
prediction: ['[CLS] striking visually striking slickly staged [SEP]']
[ 200/2000] tot_loss=1.630 (perp=7.711, rec=0.086, cos=0.002), tot_loss_proj:1.779 [t=0.18s]
prediction: ['[CLS] striking visually striking slickly staged [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.621 (perp=7.711, rec=0.077, cos=0.002), tot_loss_proj:1.779 [t=0.20s]
prediction: ['[CLS] striking visually striking slickly staged [SEP]']
[ 300/2000] tot_loss=1.636 (perp=7.888, rec=0.057, cos=0.001), tot_loss_proj:1.739 [t=0.19s]
prediction: ['[CLS] striking visually and slickly staged [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.254 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.248 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.238 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 450/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.259 [t=0.27s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.254 (perp=5.916, rec=0.069, cos=0.001), tot_loss_proj:1.248 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.238 (perp=5.916, rec=0.054, cos=0.001), tot_loss_proj:1.247 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 600/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.251 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.258 (perp=5.916, rec=0.073, cos=0.001), tot_loss_proj:1.253 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.240 (perp=5.916, rec=0.055, cos=0.001), tot_loss_proj:1.258 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 750/2000] tot_loss=1.245 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.243 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.248 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.249 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.245 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.245 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.245 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.253 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.252 (perp=5.916, rec=0.068, cos=0.001), tot_loss_proj:1.250 [t=0.27s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.226 (perp=5.916, rec=0.042, cos=0.001), tot_loss_proj:1.250 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.236 (perp=5.916, rec=0.051, cos=0.001), tot_loss_proj:1.250 [t=0.20s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.252 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.258 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.235 (perp=5.916, rec=0.050, cos=0.001), tot_loss_proj:1.256 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.246 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.242 [t=0.27s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.245 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.247 [t=0.25s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.239 (perp=5.916, rec=0.054, cos=0.001), tot_loss_proj:1.250 [t=0.20s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.250 (perp=5.916, rec=0.066, cos=0.001), tot_loss_proj:1.246 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.237 (perp=5.916, rec=0.052, cos=0.001), tot_loss_proj:1.259 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.254 (perp=5.916, rec=0.070, cos=0.001), tot_loss_proj:1.246 [t=0.23s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.234 (perp=5.916, rec=0.049, cos=0.001), tot_loss_proj:1.252 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.243 (perp=5.916, rec=0.059, cos=0.001), tot_loss_proj:1.242 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.251 (perp=5.916, rec=0.066, cos=0.001), tot_loss_proj:1.249 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.242 (perp=5.916, rec=0.057, cos=0.001), tot_loss_proj:1.251 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.252 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.247 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.250 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.249 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.251 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.241 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.252 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.250 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.253 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.739 | p: 91.257 | r: 92.310
rouge2     | fm: 59.334 | p: 59.118 | r: 59.561
rougeL     | fm: 78.357 | p: 77.997 | r: 78.729
rougeLsum  | fm: 78.097 | p: 77.734 | r: 78.506
r1fm+r2fm = 151.073

input #46 time: 0:08:27 | total time: 6:39:39


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9992059059142622
highest_index [0]
highest [0.9992059059142622]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6953830718994141 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6925281286239624 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6903731226921082 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6853982210159302 for ['[CLS] purse divine rush [SEP]']
[Init] best rec loss: 0.6800500154495239 for ['[CLS] network biceps truth [SEP]']
[Init] best rec loss: 0.6800178289413452 for ['[CLS] circles hand school [SEP]']
[Init] best rec loss: 0.67453533411026 for ['[CLS] sky next sailed [SEP]']
[Init] best rec loss: 0.6720250844955444 for ['[CLS] salt reality poles [SEP]']
[Init] best perm rec loss: 0.668911337852478 for ['[CLS] poles salt reality [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.643 (perp=11.373, rec=0.317, cos=0.052), tot_loss_proj:3.392 [t=0.18s]
prediction: ['[CLS] transparent transparent commando [SEP]']
[ 100/2000] tot_loss=2.670 (perp=12.131, rec=0.223, cos=0.021), tot_loss_proj:3.498 [t=0.26s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 150/2000] tot_loss=2.598 (perp=12.131, rec=0.157, cos=0.015), tot_loss_proj:3.515 [t=0.18s]
prediction: ['[CLS] transparent transparentright [SEP]']
[ 200/2000] tot_loss=2.646 (perp=12.414, rec=0.105, cos=0.058), tot_loss_proj:3.265 [t=0.30s]
prediction: ['[CLS] down transparentright [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.841 (perp=8.803, rec=0.076, cos=0.005), tot_loss_proj:1.908 [t=0.29s]
prediction: ['[CLS] downright transparent [SEP]']
[ 300/2000] tot_loss=1.836 (perp=8.803, rec=0.064, cos=0.011), tot_loss_proj:1.898 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.832 (perp=8.803, rec=0.064, cos=0.007), tot_loss_proj:1.923 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.838 (perp=8.803, rec=0.066, cos=0.011), tot_loss_proj:1.922 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=1.844 (perp=8.803, rec=0.075, cos=0.009), tot_loss_proj:1.921 [t=0.32s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.825 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.918 [t=0.20s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.823 (perp=8.803, rec=0.058, cos=0.004), tot_loss_proj:1.919 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.838 (perp=8.803, rec=0.076, cos=0.002), tot_loss_proj:1.915 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.828 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.919 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.826 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.922 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.834 (perp=8.803, rec=0.071, cos=0.002), tot_loss_proj:1.931 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.914 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.838 (perp=8.803, rec=0.076, cos=0.001), tot_loss_proj:1.911 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.833 (perp=8.803, rec=0.071, cos=0.002), tot_loss_proj:1.911 [t=0.20s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.001), tot_loss_proj:1.917 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.817 (perp=8.803, rec=0.054, cos=0.002), tot_loss_proj:1.910 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.001), tot_loss_proj:1.911 [t=0.20s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.833 (perp=8.803, rec=0.071, cos=0.002), tot_loss_proj:1.918 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.823 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.921 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.822 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.901 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.828 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.907 [t=0.20s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.825 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.902 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.918 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.828 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.901 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.814 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.918 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.819 (perp=8.803, rec=0.057, cos=0.002), tot_loss_proj:1.912 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.814 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.915 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.910 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.902 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.812 (perp=8.803, rec=0.050, cos=0.002), tot_loss_proj:1.904 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.912 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.815 (perp=8.803, rec=0.053, cos=0.002), tot_loss_proj:1.905 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.911 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.825 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.924 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.816 (perp=8.803, rec=0.053, cos=0.002), tot_loss_proj:1.908 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.915 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.877 | p: 91.413 | r: 92.466
rouge2     | fm: 59.914 | p: 59.714 | r: 60.214
rougeL     | fm: 78.806 | p: 78.487 | r: 79.151
rougeLsum  | fm: 78.574 | p: 78.223 | r: 78.929
r1fm+r2fm = 151.791

input #47 time: 0:08:33 | total time: 6:48:12


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9993046234064709
highest_index [0]
highest [0.9993046234064709]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.9481353759765625 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.9344632625579834 for ['[CLS] general deathstle air [SEP]']
[Init] best rec loss: 0.9107456207275391 for ['[CLS] indians * progress elevator [SEP]']
[Init] best rec loss: 0.893878161907196 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 0.8840940594673157 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.8556822538375854 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8369787931442261 for ['[CLS]lu natural horizontal work [SEP]']
[Init] best rec loss: 0.796784520149231 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7961894869804382 for ['[CLS] runsdinetute graveyard [SEP]']
[Init] best perm rec loss: 0.7949187159538269 for ['[CLS]tutedine runs graveyard [SEP]']
[Init] best perm rec loss: 0.7926889657974243 for ['[CLS] graveyard runstutedine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.585 (perp=12.047, rec=0.170, cos=0.005), tot_loss_proj:2.841 [t=0.27s]
prediction: ['[CLS] rotting rotting under rotting [SEP]']
[ 100/2000] tot_loss=2.518 (perp=12.071, rec=0.102, cos=0.003), tot_loss_proj:2.702 [t=0.28s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 150/2000] tot_loss=2.506 (perp=12.071, rec=0.090, cos=0.002), tot_loss_proj:2.697 [t=0.26s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 200/2000] tot_loss=2.500 (perp=12.071, rec=0.085, cos=0.002), tot_loss_proj:2.695 [t=0.28s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.497 (perp=7.028, rec=0.090, cos=0.002), tot_loss_proj:1.734 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 300/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.736 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.740 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.478 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 450/2000] tot_loss=1.481 (perp=7.028, rec=0.074, cos=0.001), tot_loss_proj:1.737 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.478 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.734 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.481 (perp=7.028, rec=0.074, cos=0.001), tot_loss_proj:1.741 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.742 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.466 (perp=7.028, rec=0.059, cos=0.001), tot_loss_proj:1.742 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.466 (perp=7.028, rec=0.059, cos=0.001), tot_loss_proj:1.734 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.740 [t=0.20s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.476 (perp=7.028, rec=0.069, cos=0.001), tot_loss_proj:1.742 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.463 (perp=7.028, rec=0.056, cos=0.001), tot_loss_proj:1.735 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.478 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.744 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.740 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.744 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.732 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.485 (perp=7.028, rec=0.078, cos=0.001), tot_loss_proj:1.748 [t=0.20s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.459 (perp=7.028, rec=0.052, cos=0.001), tot_loss_proj:1.735 [t=0.20s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.736 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.730 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.734 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.478 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.739 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.729 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.740 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.476 (perp=7.028, rec=0.069, cos=0.001), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.736 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.740 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.739 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.750 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.463 (perp=7.028, rec=0.056, cos=0.001), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.481 (perp=7.028, rec=0.074, cos=0.001), tot_loss_proj:1.725 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.737 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.072 | p: 91.534 | r: 92.604
rouge2     | fm: 58.944 | p: 58.724 | r: 59.189
rougeL     | fm: 78.641 | p: 78.326 | r: 78.938
rougeLsum  | fm: 78.606 | p: 78.281 | r: 78.959
r1fm+r2fm = 151.016

input #48 time: 0:08:45 | total time: 6:56:58


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9992285770800434
highest_index [0]
highest [0.9992285770800434]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8349988460540771 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7890780568122864 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7884876728057861 for ['[CLS] evolved [SEP] armed desert silence rugby peering officers down did society quarter [SEP]']
[Init] best rec loss: 0.7864314913749695 for ['[CLS] saline rang market aspects senate brothersona situation trafficking health follows tel [SEP]']
[Init] best rec loss: 0.7806379795074463 for ['[CLS] painted exactly tips haunt unknown going wrong matches until tamillaw ambulance [SEP]']
[Init] best rec loss: 0.7647554874420166 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best rec loss: 0.7542374730110168 for ['[CLS] trick jose college legs jockey baby tongue processiza during gmina patrick [SEP]']
[Init] best perm rec loss: 0.7533898949623108 for ['[CLS] legs jose trick tongue gmina collegeiza during jockey patrick process baby [SEP]']
[Init] best perm rec loss: 0.7522913813591003 for ['[CLS] tongue during process gmina patrick baby legsiza jose trick college jockey [SEP]']
[Init] best perm rec loss: 0.7503772377967834 for ['[CLS]iza process gmina jose college tongue baby patrick jockey during trick legs [SEP]']
[Init] best perm rec loss: 0.7501202821731567 for ['[CLS] legs college patrick gmina jockey trick baby during jose processiza tongue [SEP]']
[Init] best perm rec loss: 0.74857497215271 for ['[CLS] tongue jose trick jockey legs gmina patrick college babyiza during process [SEP]']
[Init] best perm rec loss: 0.7482708692550659 for ['[CLS] college process legs during trick patrick jockeyiza jose tongue gmina baby [SEP]']
[Init] best perm rec loss: 0.7479612827301025 for ['[CLS] jose baby legs during patrick tongue college process gmina trickiza jockey [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.516 (perp=10.830, rec=0.324, cos=0.026), tot_loss_proj:3.432 [t=0.22s]
prediction: ['[CLS] false mug blame. female contempt woman than of int least could [SEP]']
[ 100/2000] tot_loss=2.204 (perp=10.029, rec=0.192, cos=0.006), tot_loss_proj:3.128 [t=0.22s]
prediction: ['[CLS] population internal contempt. female contempt more could of intuous could [SEP]']
[ 150/2000] tot_loss=2.244 (perp=10.412, rec=0.155, cos=0.007), tot_loss_proj:3.296 [t=0.23s]
prediction: ['[CLS] population wire contempt. female contempt more unless of intuous could [SEP]']
[ 200/2000] tot_loss=2.235 (perp=10.567, rec=0.118, cos=0.004), tot_loss_proj:3.198 [t=0.18s]
prediction: ['[CLS] population internal contempt single female contempt more possibly of beuous could [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.157 (perp=10.216, rec=0.110, cos=0.003), tot_loss_proj:2.979 [t=0.27s]
prediction: ['[CLS] population wire more single female contempt could possibly of beuous could [SEP]']
[ 300/2000] tot_loss=2.210 (perp=10.541, rec=0.098, cos=0.003), tot_loss_proj:3.263 [t=0.19s]
prediction: ['[CLS] population timer more single female contempt could possibly of beuous could [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.092 (perp=9.955, rec=0.098, cos=0.003), tot_loss_proj:2.995 [t=0.19s]
prediction: ['[CLS] population more single female contempt could possibly of timer beuous could [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.048 (perp=9.732, rec=0.099, cos=0.003), tot_loss_proj:2.945 [t=0.27s]
prediction: ['[CLS] population more single female contempt could possibly of beuous could chain [SEP]']
[ 450/2000] tot_loss=2.048 (perp=9.732, rec=0.098, cos=0.003), tot_loss_proj:2.946 [t=0.24s]
prediction: ['[CLS] population more single female contempt could possibly of beuous could chain [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.932 (perp=9.197, rec=0.090, cos=0.003), tot_loss_proj:2.761 [t=0.18s]
prediction: ['[CLS] population more single female contempt could possibly of axisuous could be [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.949 (perp=9.284, rec=0.089, cos=0.003), tot_loss_proj:2.959 [t=0.21s]
prediction: ['[CLS] population more single female contempt could possibly ofuous blockade could be [SEP]']
[ 600/2000] tot_loss=2.031 (perp=9.721, rec=0.085, cos=0.003), tot_loss_proj:2.898 [t=0.19s]
prediction: ['[CLS] population more single female contempt could possibly ofuous axis could be [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.939 (perp=9.245, rec=0.087, cos=0.003), tot_loss_proj:2.772 [t=0.20s]
prediction: ['[CLS] more single female population contempt could possibly ofuous → could be [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.859 (perp=8.845, rec=0.086, cos=0.004), tot_loss_proj:2.642 [t=0.26s]
prediction: ['[CLS] more single female population contemptuous could possibly of → could be [SEP]']
[ 750/2000] tot_loss=1.796 (perp=8.552, rec=0.083, cos=0.003), tot_loss_proj:2.645 [t=0.18s]
prediction: ['[CLS] more single female population contemptuous. possibly of → could be [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.654 (perp=7.885, rec=0.075, cos=0.003), tot_loss_proj:2.594 [t=0.18s]
prediction: ['[CLS] more. possibly single female population contemptuous of dual could be [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.634 (perp=7.725, rec=0.086, cos=0.003), tot_loss_proj:2.633 [t=0.22s]
prediction: ['[CLS] more. possibly single female contemptuous of blockade population could be [SEP]']
[ 900/2000] tot_loss=1.637 (perp=7.725, rec=0.090, cos=0.002), tot_loss_proj:2.626 [t=0.24s]
prediction: ['[CLS] more. possibly single female contemptuous of blockade population could be [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.624 (perp=7.725, rec=0.076, cos=0.002), tot_loss_proj:2.629 [t=0.19s]
prediction: ['[CLS] more. possibly single female contemptuous of blockade population could be [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.574 (perp=7.432, rec=0.085, cos=0.003), tot_loss_proj:2.663 [t=0.18s]
prediction: ['[CLS] possibly more. single female contemptuous of blockade population could be [SEP]']
[1050/2000] tot_loss=1.574 (perp=7.432, rec=0.085, cos=0.002), tot_loss_proj:2.658 [t=0.19s]
prediction: ['[CLS] possibly more. single female contemptuous of blockade population could be [SEP]']
Attempt swap
[1100/2000] tot_loss=1.563 (perp=7.432, rec=0.074, cos=0.002), tot_loss_proj:2.661 [t=0.24s]
prediction: ['[CLS] possibly more. single female contemptuous of blockade population could be [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.560 (perp=7.409, rec=0.076, cos=0.003), tot_loss_proj:2.508 [t=0.18s]
prediction: ['[CLS] possibly more single female. contemptuous of blockade population could be [SEP]']
[1200/2000] tot_loss=1.541 (perp=7.289, rec=0.081, cos=0.002), tot_loss_proj:2.401 [t=0.24s]
prediction: ['[CLS] possibly more single female. contemptuous ofiating population could be [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.469 (perp=6.963, rec=0.073, cos=0.003), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Attempt swap
[1300/2000] tot_loss=1.468 (perp=6.963, rec=0.073, cos=0.002), tot_loss_proj:2.152 [t=0.30s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
[1350/2000] tot_loss=1.481 (perp=6.963, rec=0.086, cos=0.002), tot_loss_proj:2.151 [t=0.29s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Attempt swap
[1400/2000] tot_loss=1.479 (perp=6.963, rec=0.084, cos=0.002), tot_loss_proj:2.150 [t=0.28s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Attempt swap
[1450/2000] tot_loss=1.467 (perp=6.963, rec=0.072, cos=0.002), tot_loss_proj:2.152 [t=0.19s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
[1500/2000] tot_loss=1.472 (perp=6.963, rec=0.077, cos=0.002), tot_loss_proj:2.151 [t=0.25s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Attempt swap
[1550/2000] tot_loss=1.477 (perp=6.963, rec=0.082, cos=0.002), tot_loss_proj:2.155 [t=0.27s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Attempt swap
[1600/2000] tot_loss=1.480 (perp=6.963, rec=0.085, cos=0.002), tot_loss_proj:2.148 [t=0.22s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
[1650/2000] tot_loss=1.487 (perp=6.963, rec=0.093, cos=0.002), tot_loss_proj:2.154 [t=0.26s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Attempt swap
[1700/2000] tot_loss=1.478 (perp=6.963, rec=0.083, cos=0.002), tot_loss_proj:2.154 [t=0.24s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Attempt swap
[1750/2000] tot_loss=1.480 (perp=6.963, rec=0.086, cos=0.002), tot_loss_proj:2.154 [t=0.21s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
[1800/2000] tot_loss=1.480 (perp=6.963, rec=0.086, cos=0.002), tot_loss_proj:2.151 [t=0.22s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Attempt swap
[1850/2000] tot_loss=1.481 (perp=6.963, rec=0.086, cos=0.002), tot_loss_proj:2.152 [t=0.22s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Attempt swap
[1900/2000] tot_loss=1.477 (perp=6.963, rec=0.082, cos=0.002), tot_loss_proj:2.155 [t=0.25s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
[1950/2000] tot_loss=1.470 (perp=6.963, rec=0.076, cos=0.002), tot_loss_proj:2.152 [t=0.20s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Attempt swap
[2000/2000] tot_loss=1.473 (perp=6.963, rec=0.078, cos=0.002), tot_loss_proj:2.148 [t=0.25s]
prediction: ['[CLS] possibly more singleiating. contemptuous of female population could be [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] possibly more singleiating. contemptuous of female population could be [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 90.909 | r: 83.333
rouge2     | fm: 19.048 | p: 20.000 | r: 18.182
rougeL     | fm: 69.565 | p: 72.727 | r: 66.667
rougeLsum  | fm: 69.565 | p: 72.727 | r: 66.667
r1fm+r2fm = 106.004

[Aggregate metrics]:
rouge1     | fm: 91.982 | p: 91.567 | r: 92.448
rouge2     | fm: 58.070 | p: 57.851 | r: 58.298
rougeL     | fm: 78.526 | p: 78.280 | r: 78.785
rougeLsum  | fm: 78.411 | p: 78.155 | r: 78.738
r1fm+r2fm = 150.053

input #49 time: 0:08:55 | total time: 7:05:53


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.9992840964591766
highest_index [0]
highest [0.9992840964591766]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.9206792116165161 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8376301527023315 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.7573332786560059 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7526006698608398 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best perm rec loss: 0.7520577311515808 for ['[CLS]ieving night byhamlent bridget accordance red crisis [SEP]']
[Init] best perm rec loss: 0.7493540644645691 for ['[CLS]lent accordance bridgethamieving by night crisis red [SEP]']
[Init] best perm rec loss: 0.7488336563110352 for ['[CLS]lent accordance redieving crisis night by bridgetham [SEP]']
[Init] best perm rec loss: 0.7483512163162231 for ['[CLS]hamievinglent accordance by red night bridget crisis [SEP]']
[Init] best perm rec loss: 0.7482115030288696 for ['[CLS] red accordance bridgetlent nightham byieving crisis [SEP]']
[Init] best perm rec loss: 0.7472875714302063 for ['[CLS]lentham accordance bridgetieving by night red crisis [SEP]']
[Init] best perm rec loss: 0.7451678514480591 for ['[CLS]lent crisis red by accordanceham nightieving bridget [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.039 (perp=12.799, rec=0.432, cos=0.047), tot_loss_proj:3.731 [t=0.26s]
prediction: ['[CLS] mack indeed classics byious what why careless sexy [SEP]']
[ 100/2000] tot_loss=2.780 (perp=11.717, rec=0.401, cos=0.035), tot_loss_proj:4.087 [t=0.18s]
prediction: ['[CLS] english indeed classics by clever what | clever greater [SEP]']
[ 150/2000] tot_loss=2.421 (perp=10.416, rec=0.323, cos=0.015), tot_loss_proj:3.131 [t=0.26s]
prediction: ['[CLS] english when clever by clever what hardly clever as [SEP]']
[ 200/2000] tot_loss=2.376 (perp=10.017, rec=0.349, cos=0.023), tot_loss_proj:3.449 [t=0.18s]
prediction: ['[CLS] english " clever by clever what hardly clever as [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.740 (perp=11.681, rec=0.372, cos=0.032), tot_loss_proj:3.255 [t=0.22s]
prediction: ["[CLS] claimsville half clever what english half clever'[SEP]"]
[ 300/2000] tot_loss=2.599 (perp=11.425, rec=0.301, cos=0.013), tot_loss_proj:3.338 [t=0.18s]
prediction: ['[CLS] claimsclass by clever what english half clever half [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.572 (perp=11.070, rec=0.319, cos=0.039), tot_loss_proj:3.955 [t=0.18s]
prediction: ['[CLS] claims finish without clever what english too what half [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.285 (perp=9.888, rec=0.292, cos=0.016), tot_loss_proj:3.367 [t=0.30s]
prediction: ['[CLS] claims finish too clever what english by what half [SEP]']
[ 450/2000] tot_loss=2.323 (perp=10.205, rec=0.268, cos=0.014), tot_loss_proj:2.956 [t=0.24s]
prediction: ['[CLS] claims england too clever what english call what half [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.366 (perp=10.635, rec=0.233, cos=0.006), tot_loss_proj:2.885 [t=0.26s]
prediction: ['[CLS]hun claims too clever what english call what half [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.092 (perp=9.321, rec=0.218, cos=0.010), tot_loss_proj:2.623 [t=0.22s]
prediction: ['[CLS] england claims too clever what english call what half [SEP]']
[ 600/2000] tot_loss=2.077 (perp=9.321, rec=0.206, cos=0.007), tot_loss_proj:2.629 [t=0.18s]
prediction: ['[CLS] england claims too clever what english call what half [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.066 (perp=9.321, rec=0.197, cos=0.005), tot_loss_proj:2.627 [t=0.22s]
prediction: ['[CLS] england claims too clever what english call what half [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.055 (perp=9.321, rec=0.186, cos=0.004), tot_loss_proj:2.634 [t=0.19s]
prediction: ['[CLS] england claims too clever what english call what half [SEP]']
[ 750/2000] tot_loss=2.053 (perp=9.321, rec=0.185, cos=0.005), tot_loss_proj:2.629 [t=0.18s]
prediction: ['[CLS] england claims too clever what english call what half [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.042 (perp=9.321, rec=0.173, cos=0.004), tot_loss_proj:2.634 [t=0.25s]
prediction: ['[CLS] england claims too clever what english call what half [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.037 (perp=9.321, rec=0.169, cos=0.004), tot_loss_proj:2.635 [t=0.19s]
prediction: ['[CLS] england claims too clever what english call what half [SEP]']
[ 900/2000] tot_loss=2.035 (perp=9.321, rec=0.167, cos=0.004), tot_loss_proj:2.638 [t=0.22s]
prediction: ['[CLS] england claims too clever what english call what half [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.145 (perp=9.858, rec=0.170, cos=0.003), tot_loss_proj:2.928 [t=0.24s]
prediction: ['[CLS] version claims too clever what english call what half [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.359 (perp=10.916, rec=0.172, cos=0.004), tot_loss_proj:3.232 [t=0.19s]
prediction: ['[CLS] claims england too clever ` english call what half [SEP]']
[1050/2000] tot_loss=2.344 (perp=10.916, rec=0.158, cos=0.003), tot_loss_proj:3.232 [t=0.23s]
prediction: ['[CLS] claims england too clever ` english call what half [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.239 (perp=10.411, rec=0.153, cos=0.003), tot_loss_proj:3.094 [t=0.23s]
prediction: ['[CLS] england claims too clever ` english call what half [SEP]']
Attempt swap
[1150/2000] tot_loss=2.235 (perp=10.411, rec=0.150, cos=0.003), tot_loss_proj:3.094 [t=0.22s]
prediction: ['[CLS] england claims too clever ` english call what half [SEP]']
[1200/2000] tot_loss=2.230 (perp=10.411, rec=0.145, cos=0.003), tot_loss_proj:3.101 [t=0.25s]
prediction: ['[CLS] england claims too clever ` english call what half [SEP]']
Attempt swap
[1250/2000] tot_loss=2.236 (perp=10.411, rec=0.151, cos=0.003), tot_loss_proj:3.100 [t=0.20s]
prediction: ['[CLS] england claims too clever ` english call what half [SEP]']
Attempt swap
[1300/2000] tot_loss=2.230 (perp=10.411, rec=0.145, cos=0.003), tot_loss_proj:3.103 [t=0.19s]
prediction: ['[CLS] england claims too clever ` english call what half [SEP]']
[1350/2000] tot_loss=2.223 (perp=10.411, rec=0.138, cos=0.003), tot_loss_proj:3.104 [t=0.18s]
prediction: ['[CLS] england claims too clever ` english call what half [SEP]']
Attempt swap
[1400/2000] tot_loss=2.220 (perp=10.411, rec=0.135, cos=0.003), tot_loss_proj:3.103 [t=0.19s]
prediction: ['[CLS] england claims too clever ` english call what half [SEP]']
Attempt swap
[1450/2000] tot_loss=2.428 (perp=11.438, rec=0.137, cos=0.003), tot_loss_proj:3.279 [t=0.19s]
prediction: ['[CLS] england the too clever ` english call what half [SEP]']
[1500/2000] tot_loss=2.422 (perp=11.438, rec=0.132, cos=0.003), tot_loss_proj:3.278 [t=0.25s]
prediction: ['[CLS] england the too clever ` english call what half [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=2.181 (perp=10.204, rec=0.137, cos=0.003), tot_loss_proj:2.898 [t=0.24s]
prediction: ['[CLS] the too clever england ` english call what half [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.054 (perp=9.530, rec=0.142, cos=0.006), tot_loss_proj:2.767 [t=0.18s]
prediction: ['[CLS] the too clever england ` call what english half [SEP]']
[1650/2000] tot_loss=2.047 (perp=9.530, rec=0.138, cos=0.003), tot_loss_proj:2.770 [t=0.19s]
prediction: ['[CLS] the too clever england ` call what english half [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.996 (perp=9.295, rec=0.134, cos=0.003), tot_loss_proj:2.821 [t=0.20s]
prediction: ['[CLS] the too clever england call ` what english half [SEP]']
Attempt swap
[1750/2000] tot_loss=2.003 (perp=9.295, rec=0.141, cos=0.003), tot_loss_proj:2.823 [t=0.19s]
prediction: ['[CLS] the too clever england call ` what english half [SEP]']
[1800/2000] tot_loss=1.999 (perp=9.295, rec=0.137, cos=0.003), tot_loss_proj:2.826 [t=0.22s]
prediction: ['[CLS] the too clever england call ` what english half [SEP]']
Attempt swap
[1850/2000] tot_loss=2.000 (perp=9.295, rec=0.138, cos=0.003), tot_loss_proj:2.825 [t=0.21s]
prediction: ['[CLS] the too clever england call ` what english half [SEP]']
Attempt swap
[1900/2000] tot_loss=1.993 (perp=9.295, rec=0.131, cos=0.003), tot_loss_proj:2.826 [t=0.19s]
prediction: ['[CLS] the too clever england call ` what english half [SEP]']
[1950/2000] tot_loss=1.998 (perp=9.295, rec=0.136, cos=0.003), tot_loss_proj:2.822 [t=0.25s]
prediction: ['[CLS] the too clever england call ` what english half [SEP]']
Attempt swap
[2000/2000] tot_loss=1.993 (perp=9.295, rec=0.131, cos=0.003), tot_loss_proj:2.829 [t=0.25s]
prediction: ['[CLS] the too clever england call ` what english half [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] the too clever england call ` what english half [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 22.222 | p: 22.222 | r: 22.222
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 112.222

[Aggregate metrics]:
rouge1     | fm: 91.934 | p: 91.541 | r: 92.378
rouge2     | fm: 57.598 | p: 57.381 | r: 57.833
rougeL     | fm: 78.137 | p: 77.888 | r: 78.417
rougeLsum  | fm: 78.154 | p: 77.906 | r: 78.362
r1fm+r2fm = 149.532

input #50 time: 0:08:44 | total time: 7:14:37


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9992548315433463
highest_index [0]
highest [0.9992548315433463]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.826704740524292 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7897737622261047 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7381834387779236 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7270974516868591 for ['[CLS] join paying nonsense thought secret mine sans fields sara stench [SEP]']
[Init] best rec loss: 0.7253291010856628 for ['[CLS] lying acceptance [MASK] longer fence hotel rocking view knocked iaaf [SEP]']
[Init] best rec loss: 0.7200135588645935 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7114751935005188 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 0.7108536958694458 for ['[CLS] symbol blanc australian civil front compact foundation doubt 2018 fitness [SEP]']
[Init] best rec loss: 0.7055902481079102 for ['[CLS] disappointed market in toured literary watching once renamedrak medium [SEP]']
[Init] best perm rec loss: 0.7039530873298645 for ['[CLS] in toured once renamed medium watching market disappointed literaryrak [SEP]']
[Init] best perm rec loss: 0.7036332488059998 for ['[CLS]rak once watching literary renamed medium toured disappointed in market [SEP]']
[Init] best perm rec loss: 0.7021721601486206 for ['[CLS] disappointed toured renamed mediumrak once in watching market literary [SEP]']
[Init] best perm rec loss: 0.7017951011657715 for ['[CLS] toured disappointed in once medium renamed market literary watchingrak [SEP]']
[Init] best perm rec loss: 0.7002806663513184 for ['[CLS] medium market watching toured disappointedrak renamed in once literary [SEP]']
[Init] best perm rec loss: 0.7000938057899475 for ['[CLS] literary renamed toured watching disappointed medium market inrak once [SEP]']
[Init] best perm rec loss: 0.6998263597488403 for ['[CLS] medium toured disappointed once watching renamed marketrak literary in [SEP]']
[Init] best perm rec loss: 0.6994193196296692 for ['[CLS] medium in market watchingrak literary renamed toured disappointed once [SEP]']
[Init] best perm rec loss: 0.6993638277053833 for ['[CLS]rak renamed once watching medium toured disappointed in market literary [SEP]']
[Init] best perm rec loss: 0.6992019414901733 for ['[CLS] watching medium disappointed renamed marketrak in literary once toured [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.973 (perp=12.809, rec=0.374, cos=0.037), tot_loss_proj:3.505 [t=0.21s]
prediction: ['[CLS] sideways exists trent [SEP] sucks limited period s funny sucks [SEP]']
[ 100/2000] tot_loss=2.633 (perp=11.645, rec=0.291, cos=0.014), tot_loss_proj:3.419 [t=0.18s]
prediction: ['[CLS] six anyway john [SEP] sucks maybe sucks has funny sucks [SEP]']
[ 150/2000] tot_loss=2.394 (perp=10.752, rec=0.228, cos=0.015), tot_loss_proj:3.105 [t=0.18s]
prediction: ['[CLS] six anyway john [SEP] sucks or sucks has funny sucks [SEP]']
[ 200/2000] tot_loss=2.214 (perp=10.127, rec=0.172, cos=0.017), tot_loss_proj:2.788 [t=0.20s]
prediction: ['[CLS] moment but. [SEP] sucks or but has funny sucks [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.996 (perp=9.281, rec=0.133, cos=0.006), tot_loss_proj:2.601 [t=0.18s]
prediction: ['[CLS] moment but sucks. [SEP] or but has funny sucks [SEP]']
[ 300/2000] tot_loss=1.974 (perp=9.281, rec=0.113, cos=0.005), tot_loss_proj:2.603 [t=0.21s]
prediction: ['[CLS] moment but sucks. [SEP] or but has funny sucks [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.977 (perp=9.281, rec=0.115, cos=0.006), tot_loss_proj:2.598 [t=0.23s]
prediction: ['[CLS] moment but sucks. [SEP] or but has funny sucks [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.240 (perp=10.609, rec=0.113, cos=0.005), tot_loss_proj:3.060 [t=0.19s]
prediction: ['[CLS] moment but sucks. didn or but has funny sucks [SEP]']
[ 450/2000] tot_loss=2.165 (perp=10.263, rec=0.108, cos=0.004), tot_loss_proj:3.035 [t=0.18s]
prediction: ['[CLS] moment but sucks. didn or, has funny sucks [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.988 (perp=9.414, rec=0.102, cos=0.003), tot_loss_proj:2.850 [t=0.19s]
prediction: ['[CLS] moment but sucks. or didn, has funny sucks [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.909 (perp=9.002, rec=0.105, cos=0.004), tot_loss_proj:2.810 [t=0.22s]
prediction: ['[CLS] moment but sucks. or has didn, funny sucks [SEP]']
[ 600/2000] tot_loss=1.897 (perp=9.002, rec=0.094, cos=0.003), tot_loss_proj:2.805 [t=0.18s]
prediction: ['[CLS] moment but sucks. or has didn, funny sucks [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.841 (perp=8.661, rec=0.106, cos=0.003), tot_loss_proj:2.859 [t=0.21s]
prediction: ['[CLS], but sucks. or has didn moment funny sucks [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.735 (perp=8.129, rec=0.105, cos=0.004), tot_loss_proj:2.374 [t=0.19s]
prediction: ['[CLS], but sucks or has didn moment. funny sucks [SEP]']
[ 750/2000] tot_loss=1.730 (perp=8.129, rec=0.101, cos=0.003), tot_loss_proj:2.376 [t=0.19s]
prediction: ['[CLS], but sucks or has didn moment. funny sucks [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.688 (perp=7.946, rec=0.095, cos=0.004), tot_loss_proj:2.566 [t=0.27s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.686 (perp=7.946, rec=0.093, cos=0.003), tot_loss_proj:2.562 [t=0.22s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
[ 900/2000] tot_loss=1.680 (perp=7.946, rec=0.088, cos=0.003), tot_loss_proj:2.564 [t=0.19s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.681 (perp=7.946, rec=0.089, cos=0.003), tot_loss_proj:2.566 [t=0.20s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.681 (perp=7.946, rec=0.089, cos=0.003), tot_loss_proj:2.564 [t=0.18s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
[1050/2000] tot_loss=1.684 (perp=7.946, rec=0.092, cos=0.003), tot_loss_proj:2.567 [t=0.19s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.679 (perp=7.946, rec=0.087, cos=0.003), tot_loss_proj:2.563 [t=0.19s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.683 (perp=7.946, rec=0.091, cos=0.003), tot_loss_proj:2.569 [t=0.23s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
[1200/2000] tot_loss=1.685 (perp=7.946, rec=0.093, cos=0.003), tot_loss_proj:2.564 [t=0.25s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.680 (perp=7.946, rec=0.088, cos=0.003), tot_loss_proj:2.566 [t=0.19s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.678 (perp=7.946, rec=0.086, cos=0.003), tot_loss_proj:2.566 [t=0.18s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
[1350/2000] tot_loss=1.689 (perp=7.946, rec=0.097, cos=0.003), tot_loss_proj:2.558 [t=0.19s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.686 (perp=7.946, rec=0.094, cos=0.003), tot_loss_proj:2.560 [t=0.22s]
prediction: ['[CLS], but sucks or has didn moment funny sucks. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.664 (perp=7.856, rec=0.090, cos=0.003), tot_loss_proj:2.398 [t=0.18s]
prediction: ['[CLS], but sucks or has five moment funny sucks. [SEP]']
[1500/2000] tot_loss=1.667 (perp=7.856, rec=0.093, cos=0.003), tot_loss_proj:2.400 [t=0.21s]
prediction: ['[CLS], but sucks or has five moment funny sucks. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.661 (perp=7.856, rec=0.087, cos=0.003), tot_loss_proj:2.403 [t=0.21s]
prediction: ['[CLS], but sucks or has five moment funny sucks. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.665 (perp=7.856, rec=0.091, cos=0.003), tot_loss_proj:2.402 [t=0.18s]
prediction: ['[CLS], but sucks or has five moment funny sucks. [SEP]']
[1650/2000] tot_loss=1.662 (perp=7.856, rec=0.088, cos=0.003), tot_loss_proj:2.404 [t=0.19s]
prediction: ['[CLS], but sucks or has five moment funny sucks. [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.509 (perp=7.072, rec=0.092, cos=0.003), tot_loss_proj:2.228 [t=0.18s]
prediction: ['[CLS], but has five sucks or moment funny sucks. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.503 (perp=7.072, rec=0.086, cos=0.003), tot_loss_proj:2.231 [t=0.18s]
prediction: ['[CLS], but has five sucks or moment funny sucks. [SEP]']
[1800/2000] tot_loss=1.511 (perp=7.072, rec=0.094, cos=0.003), tot_loss_proj:2.225 [t=0.18s]
prediction: ['[CLS], but has five sucks or moment funny sucks. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.512 (perp=7.072, rec=0.095, cos=0.003), tot_loss_proj:2.226 [t=0.19s]
prediction: ['[CLS], but has five sucks or moment funny sucks. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.511 (perp=7.072, rec=0.094, cos=0.003), tot_loss_proj:2.226 [t=0.28s]
prediction: ['[CLS], but has five sucks or moment funny sucks. [SEP]']
[1950/2000] tot_loss=1.507 (perp=7.072, rec=0.090, cos=0.003), tot_loss_proj:2.226 [t=0.18s]
prediction: ['[CLS], but has five sucks or moment funny sucks. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.506 (perp=7.072, rec=0.089, cos=0.003), tot_loss_proj:2.224 [t=0.22s]
prediction: ['[CLS], but has five sucks or moment funny sucks. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS], but sucks or has five moment funny sucks. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 80.000

[Aggregate metrics]:
rouge1     | fm: 91.717 | p: 91.356 | r: 92.183
rouge2     | fm: 56.217 | p: 56.027 | r: 56.482
rougeL     | fm: 77.670 | p: 77.419 | r: 77.955
rougeLsum  | fm: 77.507 | p: 77.287 | r: 77.817
r1fm+r2fm = 147.935

input #51 time: 0:08:24 | total time: 7:23:02


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9992769471396806
highest_index [0]
highest [0.9992769471396806]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9633553624153137 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9276461005210876 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8949947357177734 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 0.8681666254997253 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.7894576191902161 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7760429382324219 for ['[CLS] confession commentator die [SEP]']
[Init] best rec loss: 0.7046040296554565 for ['[CLS] vocabulary football expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.496 (perp=11.737, rec=0.144, cos=0.004), tot_loss_proj:2.668 [t=0.18s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.448 (perp=11.737, rec=0.098, cos=0.003), tot_loss_proj:2.667 [t=0.26s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.446 (perp=11.737, rec=0.096, cos=0.002), tot_loss_proj:2.654 [t=0.19s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 200/2000] tot_loss=2.183 (perp=10.528, rec=0.074, cos=0.003), tot_loss_proj:2.213 [t=0.26s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.791 (perp=8.482, rec=0.091, cos=0.004), tot_loss_proj:2.131 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.774 (perp=8.482, rec=0.076, cos=0.001), tot_loss_proj:2.137 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.764 (perp=8.482, rec=0.066, cos=0.001), tot_loss_proj:2.137 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.133 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.131 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.767 (perp=8.482, rec=0.069, cos=0.001), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.133 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.757 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.118 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.124 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.764 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.133 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.757 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.754 (perp=8.482, rec=0.057, cos=0.001), tot_loss_proj:2.123 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.120 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.756 (perp=8.482, rec=0.058, cos=0.001), tot_loss_proj:2.129 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.127 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.753 (perp=8.482, rec=0.055, cos=0.001), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.128 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.748 (perp=8.482, rec=0.050, cos=0.001), tot_loss_proj:2.129 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.767 (perp=8.482, rec=0.069, cos=0.001), tot_loss_proj:2.131 [t=0.33s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.769 (perp=8.482, rec=0.071, cos=0.001), tot_loss_proj:2.123 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.132 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.764 (perp=8.482, rec=0.066, cos=0.001), tot_loss_proj:2.117 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.754 (perp=8.482, rec=0.056, cos=0.001), tot_loss_proj:2.125 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.770 (perp=8.482, rec=0.072, cos=0.001), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.122 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.748 (perp=8.482, rec=0.050, cos=0.001), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.127 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.117 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.765 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.131 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.127 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.769 (perp=8.482, rec=0.071, cos=0.001), tot_loss_proj:2.118 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.766 (perp=8.482, rec=0.069, cos=0.001), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.749 (perp=8.482, rec=0.051, cos=0.001), tot_loss_proj:2.121 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.126 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 91.849 | p: 91.482 | r: 92.302
rouge2     | fm: 55.147 | p: 54.955 | r: 55.376
rougeL     | fm: 77.617 | p: 77.340 | r: 77.902
rougeLsum  | fm: 77.351 | p: 77.199 | r: 77.669
r1fm+r2fm = 146.996

input #52 time: 0:08:34 | total time: 7:31:36


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9993462296030828
highest_index [0]
highest [0.9993462296030828]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.9457181096076965 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.862006664276123 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 0.8316056728363037 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 0.7958467602729797 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 0.7199336886405945 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.6997024416923523 for ['[CLS] lake highlands [SEP]']
[Init] best rec loss: 0.6986270546913147 for ['[CLS] towerbal [SEP]']
[Init] best rec loss: 0.6915310621261597 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6842321157455444 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6748745441436768 for ['[CLS] el peace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.752 (perp=12.492, rec=0.226, cos=0.027), tot_loss_proj:3.329 [t=0.18s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=2.655 (perp=12.492, rec=0.143, cos=0.014), tot_loss_proj:3.334 [t=0.18s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=1.702 (perp=8.090, rec=0.080, cos=0.004), tot_loss_proj:1.699 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
[ 200/2000] tot_loss=1.696 (perp=8.090, rec=0.076, cos=0.001), tot_loss_proj:1.695 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.691 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.692 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.685 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.704 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.690 (perp=8.090, rec=0.070, cos=0.001), tot_loss_proj:1.690 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.687 (perp=8.090, rec=0.068, cos=0.001), tot_loss_proj:1.704 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.683 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.669 (perp=8.090, rec=0.050, cos=0.001), tot_loss_proj:1.706 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.678 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.693 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.678 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.697 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.686 (perp=8.090, rec=0.067, cos=0.001), tot_loss_proj:1.707 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.698 (perp=8.090, rec=0.079, cos=0.001), tot_loss_proj:1.699 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.673 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.680 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.672 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.694 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.695 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.682 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.689 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.662 (perp=8.090, rec=0.043, cos=0.001), tot_loss_proj:1.689 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.691 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.691 (perp=8.090, rec=0.072, cos=0.001), tot_loss_proj:1.689 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.671 (perp=8.090, rec=0.052, cos=0.001), tot_loss_proj:1.687 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.689 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.699 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.687 (perp=8.090, rec=0.068, cos=0.001), tot_loss_proj:1.687 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.690 [t=0.31s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.681 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.707 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.697 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.697 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.686 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.689 (perp=8.090, rec=0.070, cos=0.001), tot_loss_proj:1.702 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.697 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.691 [t=0.20s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.672 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.688 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.060 | p: 91.702 | r: 92.466
rouge2     | fm: 56.080 | p: 55.877 | r: 56.243
rougeL     | fm: 77.954 | p: 77.717 | r: 78.213
rougeLsum  | fm: 77.836 | p: 77.565 | r: 78.145
r1fm+r2fm = 148.140

input #53 time: 0:08:28 | total time: 7:40:05


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9991885466091153
highest_index [0]
highest [0.9991885466091153]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.9532368183135986 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.8024941086769104 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7537968754768372 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.7135902047157288 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.7061654329299927 for ['[CLS] deployment bro [SEP]']
[Init] best perm rec loss: 0.7006915807723999 for ['[CLS] bro deployment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.127 (perp=13.693, rec=0.351, cos=0.038), tot_loss_proj:3.698 [t=0.18s]
prediction: ['[CLS] topics plenty [SEP]']
[ 100/2000] tot_loss=2.501 (perp=11.553, rec=0.183, cos=0.008), tot_loss_proj:2.852 [t=0.19s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.419 (perp=11.553, rec=0.104, cos=0.004), tot_loss_proj:2.884 [t=0.19s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.402 (perp=11.553, rec=0.089, cos=0.003), tot_loss_proj:2.878 [t=0.18s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.730 (perp=8.198, rec=0.086, cos=0.004), tot_loss_proj:1.742 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.707 (perp=8.198, rec=0.064, cos=0.003), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.708 (perp=8.198, rec=0.065, cos=0.003), tot_loss_proj:1.746 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.749 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.748 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.743 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.760 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.698 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.742 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.756 [t=0.29s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.708 (perp=8.198, rec=0.067, cos=0.002), tot_loss_proj:1.732 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.704 (perp=8.198, rec=0.063, cos=0.002), tot_loss_proj:1.758 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.697 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.742 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.744 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.708 (perp=8.198, rec=0.067, cos=0.002), tot_loss_proj:1.749 [t=0.32s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.712 (perp=8.198, rec=0.071, cos=0.002), tot_loss_proj:1.745 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.747 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.704 (perp=8.198, rec=0.063, cos=0.002), tot_loss_proj:1.741 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.735 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.734 [t=0.29s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.709 (perp=8.198, rec=0.068, cos=0.002), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.693 (perp=8.198, rec=0.052, cos=0.002), tot_loss_proj:1.748 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.705 (perp=8.198, rec=0.063, cos=0.002), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.698 (perp=8.198, rec=0.057, cos=0.002), tot_loss_proj:1.745 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.706 (perp=8.198, rec=0.065, cos=0.002), tot_loss_proj:1.745 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.693 (perp=8.198, rec=0.052, cos=0.002), tot_loss_proj:1.746 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.750 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.736 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.718 (perp=8.198, rec=0.077, cos=0.002), tot_loss_proj:1.744 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.685 (perp=8.198, rec=0.044, cos=0.002), tot_loss_proj:1.754 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.715 (perp=8.198, rec=0.074, cos=0.002), tot_loss_proj:1.756 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.738 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.696 (perp=8.198, rec=0.055, cos=0.002), tot_loss_proj:1.745 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.725 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.756 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.189 | p: 91.832 | r: 92.629
rouge2     | fm: 57.078 | p: 56.895 | r: 57.247
rougeL     | fm: 78.266 | p: 78.068 | r: 78.588
rougeLsum  | fm: 78.144 | p: 77.961 | r: 78.450
r1fm+r2fm = 149.268

input #54 time: 0:08:24 | total time: 7:48:29


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9991205863745829
highest_index [0]
highest [0.9991205863745829]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.9149343371391296 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.8663113713264465 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7905805706977844 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 0.7703065872192383 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7634938359260559 for ['[CLS] kirk door regional [SEP]']
[Init] best rec loss: 0.7582106590270996 for ['[CLS] single argentine patent [SEP]']
[Init] best rec loss: 0.7517237663269043 for ['[CLS] plantesthesia pr [SEP]']
[Init] best rec loss: 0.712469220161438 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.703285276889801 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7019903659820557 for ['[CLS] post holly stride [SEP]']
[Init] best perm rec loss: 0.7008416652679443 for ['[CLS] stride post holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.714 (perp=11.287, rec=0.381, cos=0.076), tot_loss_proj:4.088 [t=0.18s]
prediction: ['[CLS] easy settled easily [SEP]']
[ 100/2000] tot_loss=2.123 (perp=9.485, rec=0.208, cos=0.018), tot_loss_proj:3.795 [t=0.18s]
prediction: ['[CLS] easily settles easily [SEP]']
[ 150/2000] tot_loss=2.002 (perp=9.583, rec=0.083, cos=0.003), tot_loss_proj:2.330 [t=0.19s]
prediction: ['[CLS] too settles easily [SEP]']
[ 200/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.002), tot_loss_proj:2.325 [t=0.18s]
prediction: ['[CLS] too settles easily [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.828 (perp=8.687, rec=0.083, cos=0.008), tot_loss_proj:2.230 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
[ 300/2000] tot_loss=1.806 (perp=8.687, rec=0.067, cos=0.002), tot_loss_proj:2.256 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.806 (perp=8.687, rec=0.067, cos=0.002), tot_loss_proj:2.265 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.805 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.257 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.805 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.269 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.792 (perp=8.687, rec=0.053, cos=0.002), tot_loss_proj:2.259 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.801 (perp=8.687, rec=0.062, cos=0.002), tot_loss_proj:2.252 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.792 (perp=8.687, rec=0.053, cos=0.002), tot_loss_proj:2.267 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.800 (perp=8.687, rec=0.061, cos=0.002), tot_loss_proj:2.259 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.805 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.261 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.805 (perp=8.687, rec=0.065, cos=0.002), tot_loss_proj:2.269 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.797 (perp=8.687, rec=0.057, cos=0.002), tot_loss_proj:2.262 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.810 (perp=8.687, rec=0.071, cos=0.002), tot_loss_proj:2.252 [t=0.22s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.799 (perp=8.687, rec=0.060, cos=0.002), tot_loss_proj:2.265 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.805 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.269 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.810 (perp=8.687, rec=0.071, cos=0.002), tot_loss_proj:2.262 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.803 (perp=8.687, rec=0.064, cos=0.002), tot_loss_proj:2.267 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.806 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.263 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.802 (perp=8.687, rec=0.063, cos=0.002), tot_loss_proj:2.256 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.803 (perp=8.687, rec=0.064, cos=0.002), tot_loss_proj:2.263 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.812 (perp=8.687, rec=0.073, cos=0.002), tot_loss_proj:2.247 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.798 (perp=8.687, rec=0.059, cos=0.002), tot_loss_proj:2.255 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.806 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.270 [t=0.22s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.812 (perp=8.687, rec=0.073, cos=0.002), tot_loss_proj:2.265 [t=0.22s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.802 (perp=8.687, rec=0.063, cos=0.002), tot_loss_proj:2.257 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.804 (perp=8.687, rec=0.065, cos=0.002), tot_loss_proj:2.266 [t=0.22s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.802 (perp=8.687, rec=0.063, cos=0.002), tot_loss_proj:2.266 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.808 (perp=8.687, rec=0.069, cos=0.002), tot_loss_proj:2.259 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.793 (perp=8.687, rec=0.053, cos=0.002), tot_loss_proj:2.257 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.803 (perp=8.687, rec=0.064, cos=0.002), tot_loss_proj:2.260 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.803 (perp=8.687, rec=0.064, cos=0.002), tot_loss_proj:2.263 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.803 (perp=8.687, rec=0.063, cos=0.002), tot_loss_proj:2.260 [t=0.22s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.797 (perp=8.687, rec=0.057, cos=0.002), tot_loss_proj:2.263 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.802 (perp=8.687, rec=0.063, cos=0.002), tot_loss_proj:2.266 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.807 (perp=8.687, rec=0.068, cos=0.002), tot_loss_proj:2.265 [t=0.29s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.804 (perp=8.687, rec=0.064, cos=0.002), tot_loss_proj:2.263 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.267 | p: 91.928 | r: 92.708
rouge2     | fm: 56.416 | p: 56.228 | r: 56.650
rougeL     | fm: 78.397 | p: 78.197 | r: 78.697
rougeLsum  | fm: 78.320 | p: 78.118 | r: 78.559
r1fm+r2fm = 148.684

input #55 time: 0:08:28 | total time: 7:56:58


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.9992743912224646
highest_index [0]
highest [0.9992743912224646]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.932321310043335 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.9175447821617126 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.9035267233848572 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 0.8958414793014526 for ['[CLS] sergeant atlanticrted further enough face za sincedah had bringing experience claus stereo tour novelmler trails worn korean armed [SEP]']
[Init] best rec loss: 0.8944609761238098 for ['[CLS] direction casual pl constitution orange storm beardction norris polo reaches accmity bladetlingus mayer hatch novels chinese ore [SEP]']
[Init] best rec loss: 0.8827247619628906 for ['[CLS] handed almost with leadership emotional obsidian wall households consolation potential spectroscopy defeated been existing organization variables up acquainted cas dive realm [SEP]']
[Init] best perm rec loss: 0.8799951076507568 for ['[CLS] almost wall up emotional defeated leadership acquainted variables spectroscopy dive realm with consolation households cas potential obsidian handed existing been organization [SEP]']
[Init] best perm rec loss: 0.8781517744064331 for ['[CLS] organization almost been emotional consolation defeated existing obsidian households acquainted with spectroscopy dive wall leadership up cas handed potential realm variables [SEP]']
[Init] best perm rec loss: 0.8778687119483948 for ['[CLS] cas variables wall emotional potential dive spectroscopy leadership organization obsidian existing consolation with almost defeated realm handed up been acquainted households [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.491 (perp=10.997, rec=0.284, cos=0.008), tot_loss_proj:3.222 [t=0.26s]
prediction: ['[CLS] fullnished with costly analysis films damaged huge dangerous spending zhou repair films until costly of road that films damage damage [SEP]']
[ 100/2000] tot_loss=2.184 (perp=9.960, rec=0.189, cos=0.004), tot_loss_proj:2.666 [t=0.18s]
prediction: ['[CLS] which causes with costly analysis films damage potentially loads having decades analysis programs now costly of never which films fix damage [SEP]']
[ 150/2000] tot_loss=2.525 (perp=11.106, rec=0.291, cos=0.012), tot_loss_proj:2.986 [t=0.19s]
prediction: ['[CLS] which cause with costly analysis films damage potentially loads that years analysis iceland to costly of never would films fix damage [SEP]']
[ 200/2000] tot_loss=2.309 (perp=10.685, rec=0.169, cos=0.003), tot_loss_proj:3.237 [t=0.19s]
prediction: ['[CLS] which cause with costly of films damage be loads that years analysis mini could costly of could would films fix damage [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.138 (perp=10.047, rec=0.126, cos=0.003), tot_loss_proj:2.917 [t=0.22s]
prediction: ['[CLS] which cause of costly of years damage will loads that could analysis mini years costly of never would films fix damage [SEP]']
[ 300/2000] tot_loss=2.149 (perp=10.150, rec=0.117, cos=0.002), tot_loss_proj:2.944 [t=0.25s]
prediction: ['[CLS] which cause of costly cause years damage will loads that could analysis very years costly of never would films fix damage [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.233 (perp=10.596, rec=0.112, cos=0.002), tot_loss_proj:2.902 [t=0.19s]
prediction: ['[CLS] which cause of costlypara of damage will loads that could analysis very years costly years never will films fix damage [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.083 (perp=9.816, rec=0.118, cos=0.002), tot_loss_proj:2.653 [t=0.19s]
prediction: ['[CLS] which loads of costlypara of damage will cause that could analysis very years costly years never would films fix damage [SEP]']
[ 450/2000] tot_loss=2.073 (perp=9.816, rec=0.108, cos=0.002), tot_loss_proj:2.662 [t=0.20s]
prediction: ['[CLS] which loads of costlypara of damage will cause that could analysis very years costly years never would films fix damage [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.000 (perp=9.530, rec=0.093, cos=0.001), tot_loss_proj:2.604 [t=0.18s]
prediction: ['[CLS] which loads of costlypara costly damage will cause that could analysis would years of years never would films fix damage [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.886 (perp=8.895, rec=0.106, cos=0.002), tot_loss_proj:2.435 [t=0.20s]
prediction: ['[CLS] which loads of costly films costly damage will cause that could analysis would years of years never wouldpara fix damage [SEP]']
[ 600/2000] tot_loss=1.831 (perp=8.685, rec=0.092, cos=0.001), tot_loss_proj:2.377 [t=0.30s]
prediction: ['[CLS] which loads of costly films costly damage will cause that could analysis would years and years never wouldpara fix damage [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.826 (perp=8.685, rec=0.087, cos=0.001), tot_loss_proj:2.377 [t=0.19s]
prediction: ['[CLS] which loads of costly films costly damage will cause that could analysis would years and years never wouldpara fix damage [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.846 (perp=8.721, rec=0.100, cos=0.002), tot_loss_proj:2.561 [t=0.25s]
prediction: ['[CLS] which loads of costly filmsparable will cause that could analysis would years and years never would costly fix damage [SEP]']
[ 750/2000] tot_loss=1.779 (perp=8.458, rec=0.086, cos=0.001), tot_loss_proj:2.535 [t=0.19s]
prediction: ['[CLS] which loads of costly filmsparable will cause that could analysis very years and years never would costly fix damage [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.761 (perp=8.402, rec=0.079, cos=0.001), tot_loss_proj:2.459 [t=0.18s]
prediction: ['[CLS] which loads of costly films couldparable will cause that analysis would years and years never would costly fix damage [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.765 (perp=8.327, rec=0.098, cos=0.002), tot_loss_proj:2.323 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause that analysis would years and years never could fix costly damage [SEP]']
[ 900/2000] tot_loss=1.756 (perp=8.327, rec=0.089, cos=0.001), tot_loss_proj:2.332 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause that analysis would years and years never could fix costly damage [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.701 (perp=8.100, rec=0.080, cos=0.001), tot_loss_proj:2.240 [t=0.26s]
prediction: ['[CLS] which loads of costly films couldparable will cause analysis that would years and years never could fix costly damage [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.677 (perp=7.977, rec=0.081, cos=0.002), tot_loss_proj:2.271 [t=0.18s]
prediction: ['[CLS] which loads of costly films couldparable will cause analysis that would years and years could never fix costly damage [SEP]']
[1050/2000] tot_loss=1.664 (perp=7.901, rec=0.083, cos=0.001), tot_loss_proj:2.210 [t=0.20s]
prediction: ['[CLS] which loads of costly films couldparable will cause analysis that would years and years would never fix costly damage [SEP]']
Attempt swap
[1100/2000] tot_loss=1.664 (perp=7.901, rec=0.082, cos=0.001), tot_loss_proj:2.208 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause analysis that would years and years would never fix costly damage [SEP]']
Attempt swap
[1150/2000] tot_loss=1.657 (perp=7.901, rec=0.075, cos=0.001), tot_loss_proj:2.211 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause analysis that would years and years would never fix costly damage [SEP]']
[1200/2000] tot_loss=1.654 (perp=7.901, rec=0.072, cos=0.001), tot_loss_proj:2.209 [t=0.21s]
prediction: ['[CLS] which loads of costly films couldparable will cause analysis that would years and years would never fix costly damage [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.616 (perp=7.663, rec=0.082, cos=0.002), tot_loss_proj:2.053 [t=0.25s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that would years and years would never fix damage [SEP]']
Attempt swap
[1300/2000] tot_loss=1.575 (perp=7.520, rec=0.069, cos=0.001), tot_loss_proj:2.057 [t=0.18s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years would never fix damage [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.543, rec=0.076, cos=0.001), tot_loss_proj:2.087 [t=0.22s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
Attempt swap
[1400/2000] tot_loss=1.584 (perp=7.543, rec=0.074, cos=0.001), tot_loss_proj:2.088 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
Attempt swap
[1450/2000] tot_loss=1.590 (perp=7.543, rec=0.080, cos=0.001), tot_loss_proj:2.092 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
[1500/2000] tot_loss=1.585 (perp=7.543, rec=0.075, cos=0.001), tot_loss_proj:2.091 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
Attempt swap
[1550/2000] tot_loss=1.586 (perp=7.543, rec=0.076, cos=0.001), tot_loss_proj:2.085 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
Attempt swap
[1600/2000] tot_loss=1.583 (perp=7.543, rec=0.073, cos=0.001), tot_loss_proj:2.089 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
[1650/2000] tot_loss=1.588 (perp=7.543, rec=0.077, cos=0.001), tot_loss_proj:2.087 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
Attempt swap
[1700/2000] tot_loss=1.585 (perp=7.543, rec=0.075, cos=0.001), tot_loss_proj:2.097 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
Attempt swap
[1750/2000] tot_loss=1.583 (perp=7.543, rec=0.073, cos=0.001), tot_loss_proj:2.091 [t=0.30s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
[1800/2000] tot_loss=1.584 (perp=7.543, rec=0.073, cos=0.001), tot_loss_proj:2.094 [t=0.20s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
Attempt swap
[1850/2000] tot_loss=1.591 (perp=7.543, rec=0.081, cos=0.001), tot_loss_proj:2.091 [t=0.19s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
Attempt swap
[1900/2000] tot_loss=1.585 (perp=7.543, rec=0.075, cos=0.001), tot_loss_proj:2.091 [t=0.27s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
[1950/2000] tot_loss=1.584 (perp=7.543, rec=0.074, cos=0.001), tot_loss_proj:2.090 [t=0.29s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
Attempt swap
[2000/2000] tot_loss=1.588 (perp=7.543, rec=0.078, cos=0.001), tot_loss_proj:2.087 [t=0.18s]
prediction: ['[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] which loads of costly films couldparable will cause costly analysis that of years and years could never fix damage [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.683 | p: 90.476 | r: 95.000
rouge2     | fm: 41.026 | p: 40.000 | r: 42.105
rougeL     | fm: 58.537 | p: 57.143 | r: 60.000
rougeLsum  | fm: 58.537 | p: 57.143 | r: 60.000
r1fm+r2fm = 133.709

[Aggregate metrics]:
rouge1     | fm: 92.364 | p: 91.979 | r: 92.821
rouge2     | fm: 56.126 | p: 55.916 | r: 56.334
rougeL     | fm: 78.065 | p: 77.835 | r: 78.398
rougeLsum  | fm: 77.961 | p: 77.760 | r: 78.272
r1fm+r2fm = 148.490

input #56 time: 0:08:37 | total time: 8:05:35


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9993815950585874
highest_index [0]
highest [0.9993815950585874]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8631657361984253 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.7994511723518372 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.705524206161499 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6581541299819946 for ['[CLS] expressed [SEP]']
[Init] best rec loss: 0.643149733543396 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.634 (perp=12.282, rec=0.155, cos=0.022), tot_loss_proj:2.519 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.527 (perp=12.282, rec=0.068, cos=0.002), tot_loss_proj:2.512 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.513 (perp=12.282, rec=0.054, cos=0.002), tot_loss_proj:2.531 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.510 (perp=12.282, rec=0.052, cos=0.002), tot_loss_proj:2.517 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.518 (perp=12.282, rec=0.059, cos=0.002), tot_loss_proj:2.524 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.524 (perp=12.282, rec=0.065, cos=0.003), tot_loss_proj:2.519 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.511 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.513 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.525 (perp=12.282, rec=0.068, cos=0.001), tot_loss_proj:2.511 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.510 (perp=12.282, rec=0.053, cos=0.001), tot_loss_proj:2.517 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.508 (perp=12.282, rec=0.051, cos=0.001), tot_loss_proj:2.514 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.535 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.524 (perp=12.282, rec=0.067, cos=0.001), tot_loss_proj:2.508 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.526 (perp=12.282, rec=0.068, cos=0.001), tot_loss_proj:2.527 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.507 (perp=12.282, rec=0.049, cos=0.001), tot_loss_proj:2.512 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.509 (perp=12.282, rec=0.051, cos=0.001), tot_loss_proj:2.516 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.511 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.513 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.522 (perp=12.282, rec=0.065, cos=0.001), tot_loss_proj:2.536 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.536 (perp=12.282, rec=0.078, cos=0.001), tot_loss_proj:2.515 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.518 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.517 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.531 (perp=12.282, rec=0.073, cos=0.001), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.519 (perp=12.282, rec=0.061, cos=0.001), tot_loss_proj:2.531 [t=0.29s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.514 (perp=12.282, rec=0.057, cos=0.001), tot_loss_proj:2.513 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.507 (perp=12.282, rec=0.049, cos=0.001), tot_loss_proj:2.513 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.508 (perp=12.282, rec=0.050, cos=0.001), tot_loss_proj:2.506 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.512 (perp=12.282, rec=0.055, cos=0.001), tot_loss_proj:2.530 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.528 (perp=12.282, rec=0.070, cos=0.001), tot_loss_proj:2.517 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.519 (perp=12.282, rec=0.061, cos=0.001), tot_loss_proj:2.522 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.524 (perp=12.282, rec=0.066, cos=0.001), tot_loss_proj:2.515 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.511 (perp=12.282, rec=0.053, cos=0.001), tot_loss_proj:2.522 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.514 (perp=12.282, rec=0.056, cos=0.001), tot_loss_proj:2.527 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.524 (perp=12.282, rec=0.066, cos=0.001), tot_loss_proj:2.510 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.520 (perp=12.282, rec=0.062, cos=0.001), tot_loss_proj:2.521 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.521 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.523 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.520 (perp=12.282, rec=0.062, cos=0.001), tot_loss_proj:2.509 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.525 (perp=12.282, rec=0.067, cos=0.001), tot_loss_proj:2.525 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.510 (perp=12.282, rec=0.052, cos=0.001), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.509 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.520 (perp=12.282, rec=0.062, cos=0.001), tot_loss_proj:2.519 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.505 (perp=12.282, rec=0.047, cos=0.001), tot_loss_proj:2.533 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.521 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.511 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.542 | p: 92.118 | r: 92.988
rouge2     | fm: 56.903 | p: 56.752 | r: 57.090
rougeL     | fm: 78.501 | p: 78.256 | r: 78.796
rougeLsum  | fm: 78.274 | p: 78.009 | r: 78.611
r1fm+r2fm = 149.445

input #57 time: 0:08:01 | total time: 8:13:37


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9992685151622416
highest_index [0]
highest [0.9992685151622416]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.9649522304534912 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9525012969970703 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9179250597953796 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9173662066459656 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 0.9167462587356567 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army £100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.8904667496681213 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.8734395503997803 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.872577428817749 for ['[CLS] down trade zack serious verde thighsager finishedtyle chiefuration apart beautyitical est herself [SEP]']
[Init] best perm rec loss: 0.872272789478302 for ['[CLS] verde finishedager thighs beauty estitical trade zack herselfuration apart chieftyle down serious [SEP]']
[Init] best perm rec loss: 0.8679993748664856 for ['[CLS] down herselfitical verde zack finished apart serious chiefuration thighs tradetyle beauty estager [SEP]']
[Init] best perm rec loss: 0.8665047287940979 for ['[CLS]itical est trade zack serioustyle herself down thighs finished beauty apart chiefageruration verde [SEP]']
[Init] best perm rec loss: 0.8653094172477722 for ['[CLS] beauty aparturation thighs trade verde zack down chief finished herself serioustyle estiticalager [SEP]']
[Init] best perm rec loss: 0.8635257482528687 for ['[CLS] est chief beauty down zack serious tradetyle verde thighsurationitical apartager herself finished [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.642 (perp=11.891, rec=0.255, cos=0.008), tot_loss_proj:3.036 [t=0.25s]
prediction: ['[CLS] sharp - good quality raj adventure against innovative entertainment good compulsion story innocence adventure inspirational sweet [SEP]']
[ 100/2000] tot_loss=2.313 (perp=10.698, rec=0.170, cos=0.003), tot_loss_proj:3.642 [t=0.26s]
prediction: ['[CLS] is love educational story raj giggled against inspirational entertainment an, story encounter story inspirational inspirational [SEP]']
[ 150/2000] tot_loss=2.168 (perp=10.190, rec=0.128, cos=0.002), tot_loss_proj:3.395 [t=0.24s]
prediction: ['[CLS] is love inspirational the an innocence against capturing innocence an, encounter encounter story inspirational inspirational [SEP]']
[ 200/2000] tot_loss=2.302 (perp=10.988, rec=0.103, cos=0.002), tot_loss_proj:3.518 [t=0.24s]
prediction: ['[CLS] is love inspirational a an innocence against capturing innocence an and encounter encounter story inspirational inspirational [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.886 (perp=8.937, rec=0.097, cos=0.002), tot_loss_proj:2.926 [t=0.20s]
prediction: ['[CLS] is love inspirational the, innocence against capturing innocence an encounter encounter and story an inspirational [SEP]']
[ 300/2000] tot_loss=1.921 (perp=9.151, rec=0.089, cos=0.002), tot_loss_proj:3.055 [t=0.18s]
prediction: ['[CLS] is love inspirational the, innocence against capturing innocence an encounter first and story an inspirational [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.906 (perp=9.114, rec=0.082, cos=0.002), tot_loss_proj:2.446 [t=0.22s]
prediction: ['[CLS] is love inspirational, the innocence against capturingism that encounter first and story an inspirational [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.744 (perp=8.302, rec=0.082, cos=0.001), tot_loss_proj:2.555 [t=0.18s]
prediction: ['[CLS] is love inspirational, the first against capturingism that encounter innocence and story an inspirational [SEP]']
[ 450/2000] tot_loss=1.816 (perp=8.725, rec=0.069, cos=0.001), tot_loss_proj:2.669 [t=0.24s]
prediction: ['[CLS] is love ideal, the first against capturingism that encounter innocence and story an inspirational [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.707 (perp=8.173, rec=0.071, cos=0.001), tot_loss_proj:2.837 [t=0.19s]
prediction: ['[CLS] is love ideal, the first against capturingism that an encounter innocence and story inspirational [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.560 (perp=7.446, rec=0.070, cos=0.001), tot_loss_proj:2.227 [t=0.20s]
prediction: ['[CLS] is love idealism, the first of capturing that an encounter innocence and story inspirational [SEP]']
[ 600/2000] tot_loss=1.572 (perp=7.446, rec=0.081, cos=0.001), tot_loss_proj:2.237 [t=0.24s]
prediction: ['[CLS] is love idealism, the first of capturing that an encounter innocence and story inspirational [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.516 (perp=7.208, rec=0.073, cos=0.001), tot_loss_proj:2.168 [t=0.27s]
prediction: ['[CLS] is love idealism, the first of capturing that an encounter innocence and inspirational story [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.454 (perp=6.908, rec=0.070, cos=0.001), tot_loss_proj:1.843 [t=0.18s]
prediction: ['[CLS] is inspirational idealism, the first of capturing that an encounter innocence and love story [SEP]']
[ 750/2000] tot_loss=1.453 (perp=6.908, rec=0.070, cos=0.001), tot_loss_proj:1.837 [t=0.19s]
prediction: ['[CLS] is inspirational idealism, the first of capturing that an encounter innocence and love story [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.419 (perp=6.715, rec=0.075, cos=0.001), tot_loss_proj:1.713 [t=0.23s]
prediction: ['[CLS] is inspirational idealism, the first story capturing that an encounter innocence and love of [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.326 (perp=6.302, rec=0.064, cos=0.001), tot_loss_proj:1.629 [t=0.21s]
prediction: ['[CLS] is inspirational idealism, the first story capturing of an encounter innocence and love that [SEP]']
[ 900/2000] tot_loss=1.327 (perp=6.302, rec=0.065, cos=0.001), tot_loss_proj:1.625 [t=0.19s]
prediction: ['[CLS] is inspirational idealism, the first story capturing of an encounter innocence and love that [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.273 (perp=6.021, rec=0.067, cos=0.001), tot_loss_proj:1.518 [t=0.19s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing innocence and love that [SEP]']
Attempt swap
[1000/2000] tot_loss=1.277 (perp=6.021, rec=0.071, cos=0.001), tot_loss_proj:1.515 [t=0.26s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing innocence and love that [SEP]']
[1050/2000] tot_loss=1.265 (perp=6.021, rec=0.059, cos=0.001), tot_loss_proj:1.521 [t=0.19s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing innocence and love that [SEP]']
Attempt swap
[1100/2000] tot_loss=1.283 (perp=6.021, rec=0.078, cos=0.001), tot_loss_proj:1.521 [t=0.19s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing innocence and love that [SEP]']
Attempt swap
[1150/2000] tot_loss=1.275 (perp=6.021, rec=0.069, cos=0.001), tot_loss_proj:1.518 [t=0.24s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing innocence and love that [SEP]']
[1200/2000] tot_loss=1.274 (perp=6.021, rec=0.068, cos=0.001), tot_loss_proj:1.520 [t=0.20s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing innocence and love that [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.264 (perp=5.968, rec=0.069, cos=0.001), tot_loss_proj:1.518 [t=0.19s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing love and innocence that [SEP]']
Attempt swap
[1300/2000] tot_loss=1.261 (perp=5.968, rec=0.066, cos=0.001), tot_loss_proj:1.509 [t=0.19s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing love and innocence that [SEP]']
[1350/2000] tot_loss=1.263 (perp=5.968, rec=0.068, cos=0.001), tot_loss_proj:1.516 [t=0.25s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing love and innocence that [SEP]']
Attempt swap
[1400/2000] tot_loss=1.265 (perp=5.968, rec=0.070, cos=0.001), tot_loss_proj:1.508 [t=0.19s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing love and innocence that [SEP]']
Attempt swap
[1450/2000] tot_loss=1.261 (perp=5.968, rec=0.066, cos=0.001), tot_loss_proj:1.517 [t=0.27s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing love and innocence that [SEP]']
[1500/2000] tot_loss=1.260 (perp=5.968, rec=0.065, cos=0.001), tot_loss_proj:1.518 [t=0.25s]
prediction: ['[CLS] is inspirational idealism, the first story of an encounter capturing love and innocence that [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.239 (perp=5.832, rec=0.071, cos=0.001), tot_loss_proj:1.479 [t=0.19s]
prediction: ['[CLS] is inspirational idealism, the first story capturing love and innocence of an encounter that [SEP]']
Attempt swap
[1600/2000] tot_loss=1.238 (perp=5.832, rec=0.070, cos=0.001), tot_loss_proj:1.480 [t=0.18s]
prediction: ['[CLS] is inspirational idealism, the first story capturing love and innocence of an encounter that [SEP]']
[1650/2000] tot_loss=1.230 (perp=5.832, rec=0.062, cos=0.001), tot_loss_proj:1.478 [t=0.22s]
prediction: ['[CLS] is inspirational idealism, the first story capturing love and innocence of an encounter that [SEP]']
Attempt swap
[1700/2000] tot_loss=1.239 (perp=5.832, rec=0.071, cos=0.001), tot_loss_proj:1.486 [t=0.18s]
prediction: ['[CLS] is inspirational idealism, the first story capturing love and innocence of an encounter that [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.221 (perp=5.790, rec=0.062, cos=0.001), tot_loss_proj:1.458 [t=0.24s]
prediction: ['[CLS] is inspirational idealism, first story capturing the love and innocence of an encounter that [SEP]']
[1800/2000] tot_loss=1.230 (perp=5.790, rec=0.070, cos=0.001), tot_loss_proj:1.463 [t=0.18s]
prediction: ['[CLS] is inspirational idealism, first story capturing the love and innocence of an encounter that [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.195 (perp=5.658, rec=0.062, cos=0.001), tot_loss_proj:1.460 [t=0.18s]
prediction: ['[CLS] is inspirational idealism, story first capturing the love and innocence of an encounter that [SEP]']
Attempt swap
[1900/2000] tot_loss=1.197 (perp=5.658, rec=0.064, cos=0.001), tot_loss_proj:1.456 [t=0.26s]
prediction: ['[CLS] is inspirational idealism, story first capturing the love and innocence of an encounter that [SEP]']
[1950/2000] tot_loss=1.198 (perp=5.658, rec=0.065, cos=0.001), tot_loss_proj:1.461 [t=0.26s]
prediction: ['[CLS] is inspirational idealism, story first capturing the love and innocence of an encounter that [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.174 (perp=5.573, rec=0.058, cos=0.001), tot_loss_proj:1.458 [t=0.19s]
prediction: ['[CLS] is inspirational, idealism story first capturing the love and innocence of an encounter that [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] is inspirational idealism, the first story of an encounter capturing love and innocence that [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 6.667 | p: 6.667 | r: 6.667
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 106.667

[Aggregate metrics]:
rouge1     | fm: 92.602 | p: 92.230 | r: 93.057
rouge2     | fm: 55.920 | p: 55.745 | r: 56.124
rougeL     | fm: 78.042 | p: 77.775 | r: 78.320
rougeLsum  | fm: 77.746 | p: 77.544 | r: 78.026
r1fm+r2fm = 148.522

input #58 time: 0:08:32 | total time: 8:22:09


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9992224669689527
highest_index [0]
highest [0.9992224669689527]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.9151541590690613 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.9016127586364746 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 0.8955602645874023 for ['[CLS] clutch sports meridian placed weekly dixonwords up⁄ faerie rugby been towards resist programming infantry [SEP]']
[Init] best rec loss: 0.865580677986145 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.857191801071167 for ['[CLS]ition wandering wearing right wore kent hemisphere purple strict we gas dark deserve tonnes did letterman [SEP]']
[Init] best rec loss: 0.8294965028762817 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best perm rec loss: 0.8291977643966675 for ['[CLS] wasby temperament awhile noah information bologna 1993 fleet thus pump bobo races tunnel stuffak [SEP]']
[Init] best perm rec loss: 0.8291869163513184 for ['[CLS] awhile pump bobo tunnel fleet thus was temperamentak races stuff noah 1993by bologna information [SEP]']
[Init] best perm rec loss: 0.8275994658470154 for ['[CLS] thus information pump temperament awhile bobo races stuff fleetby was 1993 noah tunnelak bologna [SEP]']
[Init] best perm rec loss: 0.8272705078125 for ['[CLS] fleet temperament pumpak information noah bologna races tunnelby awhile thus stuff bobo 1993 was [SEP]']
[Init] best perm rec loss: 0.8271450400352478 for ['[CLS] bologna tunnel pump thus noah races information bobo stuff fleet 1993 temperament wasakby awhile [SEP]']
[Init] best perm rec loss: 0.8269852995872498 for ['[CLS] bologna pump 1993 information awhile stuffbyak bobo fleet races temperament thus was noah tunnel [SEP]']
[Init] best perm rec loss: 0.8267932534217834 for ['[CLS] thus 1993 bologna stuff pump temperament fleet tunnel was awhile noahakby races bobo information [SEP]']
[Init] best perm rec loss: 0.8258228898048401 for ['[CLS] bobo stuff temperamentby tunnel 1993 informationak thus races awhile noah bologna pump was fleet [SEP]']
[Init] best perm rec loss: 0.8244286775588989 for ['[CLS]by fleet thus information bologna tunnel temperament races awhile stuff pump noah bobo was 1993ak [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.773 (perp=11.819, rec=0.394, cos=0.015), tot_loss_proj:3.185 [t=0.28s]
prediction: ['[CLS] naturenologytical theif young the thing with region an brilliantlike amount the subject [SEP]']
[ 100/2000] tot_loss=2.448 (perp=10.965, rec=0.252, cos=0.004), tot_loss_proj:3.951 [t=0.27s]
prediction: ['[CLS] work suppliestical hasism youngism thing woman woman an experiencedlike woman the screen [SEP]']
[ 150/2000] tot_loss=2.493 (perp=11.532, rec=0.185, cos=0.002), tot_loss_proj:3.907 [t=0.19s]
prediction: ['[CLS] screen suppliesism hasism young char of woman woman a howlike screen what screen [SEP]']
[ 200/2000] tot_loss=2.693 (perp=12.648, rec=0.160, cos=0.003), tot_loss_proj:3.979 [t=0.19s]
prediction: ['[CLS] hold has holds hasism young char of woman woman a howism screen who screen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.546 (perp=11.947, rec=0.153, cos=0.003), tot_loss_proj:3.941 [t=0.19s]
prediction: ['[CLS] young has hold hasism young char of woman woman a holdism how who screen [SEP]']
[ 300/2000] tot_loss=2.541 (perp=12.139, rec=0.110, cos=0.003), tot_loss_proj:4.067 [t=0.21s]
prediction: ['[CLS] young velocity hold hasism young char of woman woman a hold char how who screen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.304 (perp=10.963, rec=0.110, cos=0.002), tot_loss_proj:3.838 [t=0.24s]
prediction: ['[CLS] the velocity woman hasism young char of hold woman a hold char how who screen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.152 (perp=10.038, rec=0.142, cos=0.003), tot_loss_proj:3.447 [t=0.19s]
prediction: ['[CLS] who vernacular woman hasism young char of hold woman a hold char how the screen [SEP]']
[ 450/2000] tot_loss=2.129 (perp=10.021, rec=0.123, cos=0.002), tot_loss_proj:3.451 [t=0.19s]
prediction: ['[CLS] who velocity woman hasism young char of hold woman a screen char how the screen [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.975 (perp=9.301, rec=0.113, cos=0.002), tot_loss_proj:3.231 [t=0.20s]
prediction: ['[CLS] who velocity woman hasism young char of a who hold hold char how the screen [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.071 (perp=9.884, rec=0.092, cos=0.002), tot_loss_proj:3.345 [t=0.19s]
prediction: ['[CLS] young society woman hasism knows char of a who hold holda how the screen [SEP]']
[ 600/2000] tot_loss=2.066 (perp=9.853, rec=0.093, cos=0.002), tot_loss_proj:3.155 [t=0.25s]
prediction: ['[CLS] young wisdom woman hasism knows char of a who hold toa how the screen [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.845 (perp=8.783, rec=0.087, cos=0.002), tot_loss_proj:2.397 [t=0.19s]
prediction: ['[CLS] young the woman hasisma char of a who hold to knows how the screen [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.676 (perp=7.946, rec=0.086, cos=0.002), tot_loss_proj:2.171 [t=0.19s]
prediction: ['[CLS] the young woman hasisma char of a who hold to knows how the screen [SEP]']
[ 750/2000] tot_loss=1.669 (perp=7.946, rec=0.078, cos=0.002), tot_loss_proj:2.180 [t=0.18s]
prediction: ['[CLS] the young woman hasisma char of a who hold to knows how the screen [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.404 (perp=6.639, rec=0.075, cos=0.002), tot_loss_proj:1.823 [t=0.29s]
prediction: ['[CLS] the young woman has charisma of a who hold to knows how the screen [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.332 (perp=6.263, rec=0.078, cos=0.002), tot_loss_proj:1.711 [t=0.23s]
prediction: ['[CLS] the young woman has the charisma of a who hold to knows how screen [SEP]']
[ 900/2000] tot_loss=1.317 (perp=6.263, rec=0.063, cos=0.002), tot_loss_proj:1.715 [t=0.19s]
prediction: ['[CLS] the young woman has the charisma of a who hold to knows how screen [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.346 (perp=6.324, rec=0.079, cos=0.002), tot_loss_proj:1.821 [t=0.19s]
prediction: ['[CLS] the young woman has the charisma of a who knows hold the how screen [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.233 (perp=5.801, rec=0.071, cos=0.002), tot_loss_proj:1.635 [t=0.20s]
prediction: ['[CLS] the young woman has the charisma of a who knows hold how the screen [SEP]']
[1050/2000] tot_loss=1.231 (perp=5.801, rec=0.070, cos=0.002), tot_loss_proj:1.633 [t=0.19s]
prediction: ['[CLS] the young woman has the charisma of a who knows hold how the screen [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.190 (perp=5.591, rec=0.070, cos=0.001), tot_loss_proj:1.518 [t=0.19s]
prediction: ['[CLS] the young has the charisma of a woman who knows hold how the screen [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.103 (perp=5.121, rec=0.077, cos=0.002), tot_loss_proj:1.387 [t=0.18s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
[1200/2000] tot_loss=1.103 (perp=5.121, rec=0.077, cos=0.002), tot_loss_proj:1.390 [t=0.19s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.087 (perp=5.121, rec=0.061, cos=0.002), tot_loss_proj:1.393 [t=0.21s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.092 (perp=5.121, rec=0.066, cos=0.002), tot_loss_proj:1.392 [t=0.27s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
[1350/2000] tot_loss=1.097 (perp=5.121, rec=0.071, cos=0.002), tot_loss_proj:1.385 [t=0.25s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.093 (perp=5.121, rec=0.067, cos=0.002), tot_loss_proj:1.391 [t=0.18s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.079 (perp=5.121, rec=0.054, cos=0.002), tot_loss_proj:1.384 [t=0.18s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
[1500/2000] tot_loss=1.101 (perp=5.121, rec=0.076, cos=0.002), tot_loss_proj:1.386 [t=0.19s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.098 (perp=5.121, rec=0.072, cos=0.002), tot_loss_proj:1.392 [t=0.24s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.095 (perp=5.121, rec=0.070, cos=0.002), tot_loss_proj:1.388 [t=0.19s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
[1650/2000] tot_loss=1.098 (perp=5.121, rec=0.072, cos=0.002), tot_loss_proj:1.388 [t=0.19s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.098 (perp=5.121, rec=0.072, cos=0.002), tot_loss_proj:1.375 [t=0.21s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.102 (perp=5.121, rec=0.077, cos=0.002), tot_loss_proj:1.384 [t=0.19s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
[1800/2000] tot_loss=1.094 (perp=5.121, rec=0.068, cos=0.002), tot_loss_proj:1.391 [t=0.23s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.105 (perp=5.121, rec=0.080, cos=0.002), tot_loss_proj:1.388 [t=0.24s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.084 (perp=5.121, rec=0.059, cos=0.002), tot_loss_proj:1.396 [t=0.21s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
[1950/2000] tot_loss=1.087 (perp=5.121, rec=0.061, cos=0.002), tot_loss_proj:1.379 [t=0.29s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.104 (perp=5.121, rec=0.078, cos=0.002), tot_loss_proj:1.384 [t=0.19s]
prediction: ['[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] the young has the charisma of a woman who knows how hold the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.750 | p: 93.750 | r: 93.750
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 160.417

[Aggregate metrics]:
rouge1     | fm: 92.643 | p: 92.286 | r: 93.091
rouge2     | fm: 56.203 | p: 55.970 | r: 56.392
rougeL     | fm: 78.218 | p: 77.985 | r: 78.518
rougeLsum  | fm: 77.987 | p: 77.746 | r: 78.257
r1fm+r2fm = 148.846

input #59 time: 0:08:38 | total time: 8:30:47


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.999371813039142
highest_index [0]
highest [0.999371813039142]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9299472570419312 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9130843281745911 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8701856732368469 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8695709109306335 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8544469475746155 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 0.842263400554657 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 0.8397374749183655 for ['[CLS] constitutionitude upsetshaw coverlby strungouring majority plenty / through [SEP]']
[Init] best perm rec loss: 0.8392449617385864 for ['[CLS] majorityitudelby upsetouring plentyshaw constitution cover strung through / [SEP]']
[Init] best perm rec loss: 0.8391808867454529 for ['[CLS]itude coverouring majoritylbyshaw through / plenty upset strung constitution [SEP]']
[Init] best perm rec loss: 0.8388378024101257 for ['[CLS]lby / upsetouring constitutionshaw cover strung majorityitude through plenty [SEP]']
[Init] best perm rec loss: 0.838720440864563 for ['[CLS] throughlby / majority upset strungitude constitutionshaw plentyouring cover [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.802 (perp=12.667, rec=0.263, cos=0.005), tot_loss_proj:3.308 [t=0.24s]
prediction: ['[CLS] is opera worriedes circuit story awkwardly close bomb drama circuit awkwardly [SEP]']
[ 100/2000] tot_loss=2.363 (perp=10.911, rec=0.176, cos=0.004), tot_loss_proj:2.818 [t=0.23s]
prediction: ['[CLS] is opera paced : story is awkwardly soap sitcom story circuit awkwardly [SEP]']
[ 150/2000] tot_loss=2.155 (perp=9.926, rec=0.160, cos=0.009), tot_loss_proj:2.750 [t=0.21s]
prediction: ['[CLS] is opera paced : story is awkwardly soap opera story circuit awkwardly [SEP]']
[ 200/2000] tot_loss=2.146 (perp=10.182, rec=0.107, cos=0.002), tot_loss_proj:2.547 [t=0.23s]
prediction: ['[CLS] the opera pacedh story is awkwardly soap opera story circuit awkwardly [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.978 (perp=9.351, rec=0.105, cos=0.003), tot_loss_proj:2.359 [t=0.18s]
prediction: ['[CLS] the awkwardly pacedh story is opera soap opera story circuit awkwardly [SEP]']
[ 300/2000] tot_loss=1.971 (perp=9.351, rec=0.098, cos=0.002), tot_loss_proj:2.364 [t=0.18s]
prediction: ['[CLS] the awkwardly pacedh story is opera soap opera story circuit awkwardly [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.927 (perp=9.181, rec=0.089, cos=0.002), tot_loss_proj:2.318 [t=0.19s]
prediction: ['[CLS] the awkwardly paced storyh is opera soap opera story circuit awkwardly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.920 (perp=9.181, rec=0.082, cos=0.002), tot_loss_proj:2.322 [t=0.18s]
prediction: ['[CLS] the awkwardly paced storyh is opera soap opera story circuit awkwardly [SEP]']
[ 450/2000] tot_loss=1.835 (perp=8.773, rec=0.079, cos=0.002), tot_loss_proj:2.166 [t=0.19s]
prediction: ['[CLS] the awkwardly paced storyh is opera soap opera - circuit is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.824 (perp=8.773, rec=0.068, cos=0.002), tot_loss_proj:2.167 [t=0.18s]
prediction: ['[CLS] the awkwardly paced storyh is opera soap opera - circuit is [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.802 (perp=8.611, rec=0.078, cos=0.002), tot_loss_proj:2.141 [t=0.19s]
prediction: ['[CLS] the awkwardly paced storyh is circuit soap opera - opera is [SEP]']
[ 600/2000] tot_loss=1.797 (perp=8.611, rec=0.073, cos=0.002), tot_loss_proj:2.140 [t=0.18s]
prediction: ['[CLS] the awkwardly paced storyh is circuit soap opera - opera is [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.752 (perp=8.415, rec=0.068, cos=0.002), tot_loss_proj:2.167 [t=0.18s]
prediction: ['[CLS] the awkwardly paced storyh circuit is soap opera - opera is [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.694 (perp=8.131, rec=0.066, cos=0.002), tot_loss_proj:2.059 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuith is soap opera - opera is [SEP]']
[ 750/2000] tot_loss=1.696 (perp=8.131, rec=0.068, cos=0.002), tot_loss_proj:2.056 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuith is soap opera - opera is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.700 (perp=8.131, rec=0.072, cos=0.002), tot_loss_proj:2.065 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuith is soap opera - opera is [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.655 (perp=7.924, rec=0.069, cos=0.001), tot_loss_proj:2.037 [t=0.26s]
prediction: ['[CLS] the awkwardly paced story circuith is soap opera - is. [SEP]']
[ 900/2000] tot_loss=1.652 (perp=7.924, rec=0.066, cos=0.001), tot_loss_proj:2.036 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuith is soap opera - is. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.612 (perp=7.648, rec=0.081, cos=0.001), tot_loss_proj:2.106 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuith is - soap opera is. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.602 (perp=7.648, rec=0.071, cos=0.001), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuith is - soap opera is. [SEP]']
[1050/2000] tot_loss=1.596 (perp=7.648, rec=0.065, cos=0.001), tot_loss_proj:2.106 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuith is - soap opera is. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.541 (perp=7.397, rec=0.061, cos=0.001), tot_loss_proj:2.019 [t=0.20s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.552 (perp=7.397, rec=0.072, cos=0.001), tot_loss_proj:2.023 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
[1200/2000] tot_loss=1.535 (perp=7.397, rec=0.054, cos=0.001), tot_loss_proj:2.023 [t=0.23s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.547 (perp=7.397, rec=0.067, cos=0.001), tot_loss_proj:2.019 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.547 (perp=7.397, rec=0.066, cos=0.001), tot_loss_proj:2.021 [t=0.19s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
[1350/2000] tot_loss=1.554 (perp=7.397, rec=0.073, cos=0.001), tot_loss_proj:2.027 [t=0.26s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.551 (perp=7.397, rec=0.070, cos=0.001), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.539 (perp=7.397, rec=0.059, cos=0.001), tot_loss_proj:2.018 [t=0.19s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
[1500/2000] tot_loss=1.545 (perp=7.397, rec=0.064, cos=0.001), tot_loss_proj:2.022 [t=0.20s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.543 (perp=7.397, rec=0.062, cos=0.001), tot_loss_proj:2.019 [t=0.21s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.547 (perp=7.397, rec=0.067, cos=0.001), tot_loss_proj:2.021 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
[1650/2000] tot_loss=1.552 (perp=7.397, rec=0.071, cos=0.001), tot_loss_proj:2.022 [t=0.27s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.551 (perp=7.397, rec=0.070, cos=0.001), tot_loss_proj:2.020 [t=0.27s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.554 (perp=7.397, rec=0.074, cos=0.001), tot_loss_proj:2.022 [t=0.19s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
[1800/2000] tot_loss=1.543 (perp=7.397, rec=0.063, cos=0.001), tot_loss_proj:2.021 [t=0.26s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.547 (perp=7.397, rec=0.066, cos=0.001), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.538 (perp=7.397, rec=0.057, cos=0.001), tot_loss_proj:2.012 [t=0.19s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
[1950/2000] tot_loss=1.549 (perp=7.397, rec=0.068, cos=0.001), tot_loss_proj:2.020 [t=0.19s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.548 (perp=7.397, rec=0.067, cos=0.001), tot_loss_proj:2.022 [t=0.19s]
prediction: ['[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] the awkwardly paced story circuit is - soap operah is. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 111.818

[Aggregate metrics]:
rouge1     | fm: 92.341 | p: 91.989 | r: 92.785
rouge2     | fm: 55.793 | p: 55.589 | r: 55.991
rougeL     | fm: 77.659 | p: 77.433 | r: 77.942
rougeLsum  | fm: 77.638 | p: 77.351 | r: 77.892
r1fm+r2fm = 148.135

input #60 time: 0:08:20 | total time: 8:39:07


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.999284746941759
highest_index [0]
highest [0.999284746941759]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9795893430709839 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9741564989089966 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9512136578559875 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9470409154891968 for ['[CLS] paths whose bar [SEP]']
[Init] best rec loss: 0.9432965517044067 for ['[CLS] conscious baptizedness [SEP]']
[Init] best rec loss: 0.9347224831581116 for ['[CLS] crested tend prize [SEP]']
[Init] best rec loss: 0.9169871807098389 for ['[CLS] bologna nails steps [SEP]']
[Init] best rec loss: 0.9168724417686462 for ['[CLS] joint flamingual [SEP]']
[Init] best rec loss: 0.9121196269989014 for ['[CLS] you wedding velvet [SEP]']
[Init] best rec loss: 0.9106317162513733 for ['[CLS] installed equipped unlike [SEP]']
[Init] best rec loss: 0.8808217644691467 for ['[CLS] respect thrill butterfly [SEP]']
[Init] best rec loss: 0.8280910849571228 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 0.8269730806350708 for ['[CLS] lets mini request [SEP]']
[Init] best perm rec loss: 0.8244650959968567 for ['[CLS] mini request lets [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.163 (perp=9.683, rec=0.216, cos=0.011), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 100/2000] tot_loss=2.085 (perp=9.683, rec=0.141, cos=0.008), tot_loss_proj:2.395 [t=0.27s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 150/2000] tot_loss=2.080 (perp=9.683, rec=0.136, cos=0.007), tot_loss_proj:2.389 [t=0.29s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 200/2000] tot_loss=2.070 (perp=9.683, rec=0.128, cos=0.006), tot_loss_proj:2.397 [t=0.18s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.498 (perp=7.101, rec=0.077, cos=0.001), tot_loss_proj:1.617 [t=0.20s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 300/2000] tot_loss=1.489 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.630 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.624 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.478 (perp=7.101, rec=0.056, cos=0.001), tot_loss_proj:1.628 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.623 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.482 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.621 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.475 (perp=7.101, rec=0.053, cos=0.001), tot_loss_proj:1.620 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.624 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.495 (perp=7.101, rec=0.074, cos=0.001), tot_loss_proj:1.627 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.491 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.622 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.491 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.617 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.494 (perp=7.101, rec=0.073, cos=0.001), tot_loss_proj:1.617 [t=0.20s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.488 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.625 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.608 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.616 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.621 [t=0.26s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.482 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.615 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.482 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.623 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.489 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.627 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.481 (perp=7.101, rec=0.059, cos=0.001), tot_loss_proj:1.623 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.481 (perp=7.101, rec=0.059, cos=0.001), tot_loss_proj:1.626 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.479 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.610 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.474 (perp=7.101, rec=0.052, cos=0.001), tot_loss_proj:1.617 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.473 (perp=7.101, rec=0.052, cos=0.001), tot_loss_proj:1.621 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.473 (perp=7.101, rec=0.051, cos=0.001), tot_loss_proj:1.620 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.479 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.615 [t=0.20s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.484 (perp=7.101, rec=0.062, cos=0.001), tot_loss_proj:1.629 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.616 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.483 (perp=7.101, rec=0.061, cos=0.001), tot_loss_proj:1.613 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.487 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.625 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.490 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.617 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.477 (perp=7.101, rec=0.056, cos=0.001), tot_loss_proj:1.624 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.479 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.620 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.628 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.619 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.491 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.625 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.546 | p: 92.162 | r: 92.958
rouge2     | fm: 56.583 | p: 56.443 | r: 56.754
rougeL     | fm: 78.225 | p: 78.018 | r: 78.489
rougeLsum  | fm: 77.963 | p: 77.698 | r: 78.196
r1fm+r2fm = 149.129

input #61 time: 0:08:19 | total time: 8:47:27


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.999255650346929
highest_index [0]
highest [0.999255650346929]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9540637731552124 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9288767576217651 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.927240788936615 for ['[CLS] gem longer congregationiq commemorate members police later pm drawing [MASK]ly onwards drops team senator access head wrath miss shane [SEP]']
[Init] best rec loss: 0.9213613867759705 for ['[CLS] percentage trap danzinghur shapeee sacred persianlon record theater freestylegold cards dance sacks pits dreadmund existed [SEP]']
[Init] best rec loss: 0.9167788624763489 for ['[CLS] girl plain followedion recalls間 by spread fight sioux 2002 test origins humanitarian peck reed forumnce tooth closely mccarthy [SEP]']
[Init] best perm rec loss: 0.9164981842041016 for ['[CLS]nce followed mccarthy sioux by forum fight closely origins peckion humanitarian 2002 recalls reed spread tooth plain test girl間 [SEP]']
[Init] best perm rec loss: 0.914860188961029 for ['[CLS] girl by tooth forum followednce test reed sioux plain fight 2002 origins spread recalls closely humanitarian mccarthy間 peckion [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.526 (perp=10.902, rec=0.339, cos=0.007), tot_loss_proj:4.052 [t=0.22s]
prediction: ["[CLS] grace by from credited not outstanding saw on pmid best for film prevention grace recording being'deeplyable asset its [SEP]"]
[ 100/2000] tot_loss=2.745 (perp=12.404, rec=0.260, cos=0.004), tot_loss_proj:4.070 [t=0.20s]
prediction: ['[CLS] grace to from montgomery films best best prevention federal best best movies prevention grace prevention being layer highly best effort their [SEP]']
[ 150/2000] tot_loss=2.264 (perp=10.287, rec=0.203, cos=0.003), tot_loss_proj:3.823 [t=0.19s]
prediction: ['[CLS] grace to from know movies best best prevention to best any movies prevention grace prevention being its easily best most making [SEP]']
[ 200/2000] tot_loss=2.087 (perp=9.620, rec=0.161, cos=0.002), tot_loss_proj:3.793 [t=0.19s]
prediction: ['[CLS] grace to rather say movies call call prevention to best any movies war grace prevention in one ever best one making [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.054 (perp=9.498, rec=0.152, cos=0.002), tot_loss_proj:3.881 [t=0.18s]
prediction: ['[CLS] grace to from say movies call war prevention to best having movies call grace rather of one ever best one making [SEP]']
[ 300/2000] tot_loss=1.938 (perp=9.077, rec=0.121, cos=0.002), tot_loss_proj:3.776 [t=0.25s]
prediction: ['[CLS] grace to for blame movies call war prevention to best those movies call grace rather of one ever best it making [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.945 (perp=9.172, rec=0.109, cos=0.002), tot_loss_proj:3.812 [t=0.19s]
prediction: ['[CLS] grace to for blame movies call war prevention to best those movies for grace rather of one ever best it making [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.943 (perp=9.161, rec=0.109, cos=0.002), tot_loss_proj:3.820 [t=0.21s]
prediction: ['[CLS] grace to for blame for call it prevention to best those movies for grace rather of one ever best war making [SEP]']
[ 450/2000] tot_loss=1.926 (perp=9.142, rec=0.096, cos=0.002), tot_loss_proj:3.783 [t=0.23s]
prediction: ['[CLS] grace to for blame for call it prevention to best those movies for grace rather of one ever made war making [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.730 (perp=8.160, rec=0.096, cos=0.002), tot_loss_proj:3.602 [t=0.19s]
prediction: ['[CLS] grace to prevention to blame than call it to best the movies for grace rather of one ever made war making [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.664 (perp=7.861, rec=0.091, cos=0.002), tot_loss_proj:3.549 [t=0.19s]
prediction: ['[CLS] grace to prevention to blame than call it to the best movies for grace rather of one ever made war making [SEP]']
[ 600/2000] tot_loss=1.664 (perp=7.861, rec=0.090, cos=0.002), tot_loss_proj:3.551 [t=0.18s]
prediction: ['[CLS] grace to prevention to blame than call it to the best movies for grace rather of one ever made war making [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.647 (perp=7.784, rec=0.089, cos=0.002), tot_loss_proj:3.497 [t=0.30s]
prediction: ['[CLS] grace to prevention it to blame than call to the best movies for grace rather of one ever made war making [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.601 (perp=7.541, rec=0.092, cos=0.002), tot_loss_proj:3.346 [t=0.24s]
prediction: ['[CLS] grace to prevention it to blame than call to the best of movies for grace rather one ever made war making [SEP]']
[ 750/2000] tot_loss=1.594 (perp=7.541, rec=0.085, cos=0.002), tot_loss_proj:3.344 [t=0.24s]
prediction: ['[CLS] grace to prevention it to blame than call to the best of movies for grace rather one ever made war making [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.571 (perp=7.447, rec=0.081, cos=0.001), tot_loss_proj:3.399 [t=0.18s]
prediction: ['[CLS] grace to prevention it to blame than to call the best of movies for grace rather one ever made war making [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.522 (perp=7.177, rec=0.085, cos=0.002), tot_loss_proj:3.433 [t=0.18s]
prediction: ['[CLS] grace to prevention it to blame than to call the best for grace rather one of movies ever made war making [SEP]']
[ 900/2000] tot_loss=1.499 (perp=7.080, rec=0.081, cos=0.002), tot_loss_proj:3.324 [t=0.19s]
prediction: ['[CLS] grace to prevention it to blame than to call the best for, rather one of movies ever made war making [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.507 (perp=7.128, rec=0.080, cos=0.001), tot_loss_proj:3.318 [t=0.26s]
prediction: ['[CLS] grace to prevention it to blame rather than, call the best for grace one of movies ever made war making [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.466 (perp=6.932, rec=0.079, cos=0.001), tot_loss_proj:3.337 [t=0.23s]
prediction: ['[CLS] grace to prevention it to blame rather than, call the best grace one of movies ever made for war making [SEP]']
[1050/2000] tot_loss=1.461 (perp=6.932, rec=0.073, cos=0.001), tot_loss_proj:3.343 [t=0.23s]
prediction: ['[CLS] grace to prevention it to blame rather than, call the best grace one of movies ever made for war making [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.373 (perp=6.519, rec=0.067, cos=0.001), tot_loss_proj:3.270 [t=0.19s]
prediction: ['[CLS] grace to prevention it to blame, rather than call the best grace one of movies ever made for war making [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.329 (perp=6.281, rec=0.072, cos=0.001), tot_loss_proj:3.238 [t=0.19s]
prediction: ['[CLS] grace to prevention it to blame, rather than call the best grace one of war movies ever made for making [SEP]']
[1200/2000] tot_loss=1.332 (perp=6.281, rec=0.074, cos=0.001), tot_loss_proj:3.236 [t=0.19s]
prediction: ['[CLS] grace to prevention it to blame, rather than call the best grace one of war movies ever made for making [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.267 (perp=5.965, rec=0.073, cos=0.001), tot_loss_proj:3.126 [t=0.18s]
prediction: ['[CLS] grace to prevention it to blame, rather than call the best one of war movies ever made for making grace [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.183 (perp=5.536, rec=0.075, cos=0.002), tot_loss_proj:3.027 [t=0.20s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
[1350/2000] tot_loss=1.182 (perp=5.536, rec=0.073, cos=0.001), tot_loss_proj:3.025 [t=0.25s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.181 (perp=5.536, rec=0.072, cos=0.001), tot_loss_proj:3.024 [t=0.19s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.185 (perp=5.536, rec=0.077, cos=0.001), tot_loss_proj:3.020 [t=0.18s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
[1500/2000] tot_loss=1.182 (perp=5.536, rec=0.073, cos=0.001), tot_loss_proj:3.023 [t=0.19s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.182 (perp=5.536, rec=0.073, cos=0.001), tot_loss_proj:3.018 [t=0.21s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.192 (perp=5.536, rec=0.083, cos=0.001), tot_loss_proj:3.023 [t=0.19s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
[1650/2000] tot_loss=1.186 (perp=5.536, rec=0.077, cos=0.001), tot_loss_proj:3.021 [t=0.18s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.183 (perp=5.536, rec=0.075, cos=0.001), tot_loss_proj:3.020 [t=0.27s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.186 (perp=5.536, rec=0.077, cos=0.001), tot_loss_proj:3.021 [t=0.18s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
[1800/2000] tot_loss=1.184 (perp=5.536, rec=0.075, cos=0.001), tot_loss_proj:3.021 [t=0.18s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.179 (perp=5.536, rec=0.071, cos=0.001), tot_loss_proj:3.022 [t=0.19s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.180 (perp=5.536, rec=0.071, cos=0.001), tot_loss_proj:3.016 [t=0.20s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
[1950/2000] tot_loss=1.174 (perp=5.536, rec=0.066, cos=0.001), tot_loss_proj:3.022 [t=0.18s]
prediction: ['[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.176 (perp=5.494, rec=0.075, cos=0.001), tot_loss_proj:3.049 [t=0.19s]
prediction: ['[CLS] grace to blame it to prevention, rather than call one the best of war movies ever made for making, [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] grace to blame it to prevention, rather than call the best one of war movies ever made for making, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 97.674 | p: 100.000 | r: 95.455
rouge2     | fm: 43.902 | p: 45.000 | r: 42.857
rougeL     | fm: 60.465 | p: 61.905 | r: 59.091
rougeLsum  | fm: 60.465 | p: 61.905 | r: 59.091
r1fm+r2fm = 141.577

[Aggregate metrics]:
rouge1     | fm: 92.580 | p: 92.290 | r: 93.011
rouge2     | fm: 56.043 | p: 55.927 | r: 56.226
rougeL     | fm: 77.795 | p: 77.620 | r: 78.016
rougeLsum  | fm: 77.531 | p: 77.357 | r: 77.798
r1fm+r2fm = 148.624

input #62 time: 0:08:27 | total time: 8:55:54


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9992646432214791
highest_index [0]
highest [0.9992646432214791]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.9565043449401855 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.9048953652381897 for ['[CLS] touch alternative glacier bentry [SEP]']
[Init] best rec loss: 0.7484632730484009 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7433376908302307 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 0.739037811756134 for ['[CLS] diploma catalogue honors knee skirt [SEP]']
[Init] best rec loss: 0.7285273671150208 for ['[CLS] forces solutions... offense civil [SEP]']
[Init] best perm rec loss: 0.7276551127433777 for ['[CLS] solutions forces offense... civil [SEP]']
[Init] best perm rec loss: 0.7259407639503479 for ['[CLS] solutions civil forces... offense [SEP]']
[Init] best perm rec loss: 0.7244595885276794 for ['[CLS] forces... offense solutions civil [SEP]']
[Init] best perm rec loss: 0.7240341901779175 for ['[CLS] forces solutions... civil offense [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.518 (perp=10.331, rec=0.393, cos=0.058), tot_loss_proj:3.270 [t=0.23s]
prediction: ['[CLS] limited rejected off ticket ticket [SEP]']
[ 100/2000] tot_loss=2.234 (perp=10.156, rec=0.194, cos=0.009), tot_loss_proj:3.102 [t=0.18s]
prediction: ['[CLS] return looking off ticket ticket [SEP]']
[ 150/2000] tot_loss=1.847 (perp=8.568, rec=0.129, cos=0.005), tot_loss_proj:2.616 [t=0.22s]
prediction: ['[CLS] return looking for ticket ticket [SEP]']
[ 200/2000] tot_loss=1.862 (perp=8.818, rec=0.095, cos=0.003), tot_loss_proj:2.549 [t=0.18s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.851 (perp=8.818, rec=0.084, cos=0.003), tot_loss_proj:2.549 [t=0.27s]
prediction: ['[CLS] return looking for return ticket [SEP]']
[ 300/2000] tot_loss=1.840 (perp=8.818, rec=0.074, cos=0.003), tot_loss_proj:2.551 [t=0.25s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.850 (perp=8.818, rec=0.084, cos=0.003), tot_loss_proj:2.550 [t=0.28s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.852 (perp=8.818, rec=0.085, cos=0.003), tot_loss_proj:2.541 [t=0.20s]
prediction: ['[CLS] return looking for return ticket [SEP]']
[ 450/2000] tot_loss=1.842 (perp=8.818, rec=0.076, cos=0.003), tot_loss_proj:2.556 [t=0.24s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.838 (perp=8.818, rec=0.072, cos=0.003), tot_loss_proj:2.553 [t=0.18s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.837 (perp=8.818, rec=0.071, cos=0.003), tot_loss_proj:2.555 [t=0.19s]
prediction: ['[CLS] return looking for return ticket [SEP]']
[ 600/2000] tot_loss=1.851 (perp=8.818, rec=0.085, cos=0.003), tot_loss_proj:2.550 [t=0.24s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.833 (perp=8.818, rec=0.067, cos=0.002), tot_loss_proj:2.554 [t=0.18s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.844 (perp=8.818, rec=0.078, cos=0.002), tot_loss_proj:2.549 [t=0.18s]
prediction: ['[CLS] return looking for return ticket [SEP]']
[ 750/2000] tot_loss=1.830 (perp=8.818, rec=0.064, cos=0.002), tot_loss_proj:2.550 [t=0.22s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.835 (perp=8.818, rec=0.070, cos=0.002), tot_loss_proj:2.550 [t=0.25s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.836 (perp=8.818, rec=0.070, cos=0.002), tot_loss_proj:2.549 [t=0.19s]
prediction: ['[CLS] return looking for return ticket [SEP]']
[ 900/2000] tot_loss=1.838 (perp=8.818, rec=0.073, cos=0.002), tot_loss_proj:2.553 [t=0.22s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.841 (perp=8.818, rec=0.075, cos=0.002), tot_loss_proj:2.556 [t=0.19s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.836 (perp=8.818, rec=0.071, cos=0.001), tot_loss_proj:2.553 [t=0.19s]
prediction: ['[CLS] return looking for return ticket [SEP]']
[1050/2000] tot_loss=1.834 (perp=8.818, rec=0.069, cos=0.001), tot_loss_proj:2.555 [t=0.20s]
prediction: ['[CLS] return looking for return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.743 (perp=8.350, rec=0.072, cos=0.001), tot_loss_proj:2.120 [t=0.24s]
prediction: ['[CLS] a looking for return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.741 (perp=8.350, rec=0.069, cos=0.001), tot_loss_proj:2.120 [t=0.23s]
prediction: ['[CLS] a looking for return ticket [SEP]']
[1200/2000] tot_loss=1.745 (perp=8.350, rec=0.074, cos=0.001), tot_loss_proj:2.125 [t=0.18s]
prediction: ['[CLS] a looking for return ticket [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.291 (perp=6.111, rec=0.067, cos=0.001), tot_loss_proj:1.323 [t=0.26s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.285 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.317 [t=0.19s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.286 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.316 [t=0.26s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.287 (perp=6.111, rec=0.063, cos=0.001), tot_loss_proj:1.321 [t=0.18s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.001), tot_loss_proj:1.326 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.001), tot_loss_proj:1.327 [t=0.18s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.290 (perp=6.111, rec=0.067, cos=0.001), tot_loss_proj:1.314 [t=0.19s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.298 (perp=6.111, rec=0.075, cos=0.001), tot_loss_proj:1.322 [t=0.19s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.295 (perp=6.111, rec=0.071, cos=0.001), tot_loss_proj:1.314 [t=0.18s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.289 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.310 [t=0.19s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.290 (perp=6.111, rec=0.067, cos=0.001), tot_loss_proj:1.313 [t=0.20s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.001), tot_loss_proj:1.312 [t=0.25s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.284 (perp=6.111, rec=0.060, cos=0.001), tot_loss_proj:1.313 [t=0.22s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.320 [t=0.25s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.282 (perp=6.111, rec=0.059, cos=0.001), tot_loss_proj:1.314 [t=0.24s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.292 (perp=6.111, rec=0.068, cos=0.001), tot_loss_proj:1.313 [t=0.23s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.795 | p: 92.474 | r: 93.128
rouge2     | fm: 56.925 | p: 56.793 | r: 57.098
rougeL     | fm: 78.123 | p: 77.925 | r: 78.330
rougeLsum  | fm: 77.994 | p: 77.796 | r: 78.249
r1fm+r2fm = 149.720

input #63 time: 0:08:26 | total time: 9:04:21


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.999160846219472
highest_index [0]
highest [0.999160846219472]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8796932697296143 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8693087697029114 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 0.728920042514801 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.675671398639679 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6740126609802246 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 0.6711879372596741 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.972 (perp=8.653, rec=0.213, cos=0.028), tot_loss_proj:2.060 [t=0.18s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.893 (perp=8.653, rec=0.143, cos=0.020), tot_loss_proj:2.061 [t=0.19s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.874 (perp=8.653, rec=0.131, cos=0.012), tot_loss_proj:2.062 [t=0.25s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=1.876 (perp=8.653, rec=0.133, cos=0.013), tot_loss_proj:2.055 [t=0.18s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.864 (perp=8.653, rec=0.122, cos=0.012), tot_loss_proj:2.065 [t=0.19s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 300/2000] tot_loss=1.862 (perp=8.653, rec=0.121, cos=0.010), tot_loss_proj:2.054 [t=0.18s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.879 (perp=8.653, rec=0.139, cos=0.009), tot_loss_proj:2.061 [t=0.26s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.880 (perp=8.653, rec=0.139, cos=0.010), tot_loss_proj:2.061 [t=0.22s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 450/2000] tot_loss=1.863 (perp=8.653, rec=0.124, cos=0.009), tot_loss_proj:2.062 [t=0.19s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.873 (perp=8.653, rec=0.134, cos=0.009), tot_loss_proj:2.070 [t=0.19s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.858 (perp=8.653, rec=0.119, cos=0.009), tot_loss_proj:2.066 [t=0.19s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 600/2000] tot_loss=1.870 (perp=8.653, rec=0.128, cos=0.011), tot_loss_proj:2.067 [t=0.19s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.864 (perp=8.653, rec=0.126, cos=0.007), tot_loss_proj:2.070 [t=0.19s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.949 (perp=9.190, rec=0.105, cos=0.005), tot_loss_proj:2.231 [t=0.18s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 750/2000] tot_loss=1.912 (perp=9.190, rec=0.072, cos=0.002), tot_loss_proj:2.213 [t=0.19s]
prediction: ['[CLS] strange strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.907 (perp=9.190, rec=0.067, cos=0.002), tot_loss_proj:2.213 [t=0.18s]
prediction: ['[CLS] strange strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.686 (perp=8.065, rec=0.071, cos=0.002), tot_loss_proj:1.713 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.661 (perp=8.065, rec=0.047, cos=0.002), tot_loss_proj:1.715 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.668 (perp=8.065, rec=0.054, cos=0.002), tot_loss_proj:1.709 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.715 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.702 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.711 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.673 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.700 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.695 (perp=8.065, rec=0.080, cos=0.002), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.677 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.706 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.665 (perp=8.065, rec=0.050, cos=0.002), tot_loss_proj:1.720 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.721 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.671 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.703 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.718 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.666 (perp=8.065, rec=0.051, cos=0.002), tot_loss_proj:1.712 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.712 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.705 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.686 (perp=8.065, rec=0.072, cos=0.002), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.680 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.711 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.670 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.670 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.708 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.685 (perp=8.065, rec=0.070, cos=0.002), tot_loss_proj:1.711 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.677 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.716 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.937 | p: 92.611 | r: 93.265
rouge2     | fm: 57.554 | p: 57.441 | r: 57.675
rougeL     | fm: 78.462 | p: 78.267 | r: 78.688
rougeLsum  | fm: 78.460 | p: 78.285 | r: 78.692
r1fm+r2fm = 150.491

input #64 time: 0:07:56 | total time: 9:12:17


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9992260466615117
highest_index [0]
highest [0.9992260466615117]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.0258606672286987 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9586822390556335 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9518215656280518 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.9477682113647461 for ['[CLS]blpf bce med stride plot skip honest what [SEP]']
[Init] best rec loss: 0.8876939415931702 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8789583444595337 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8788501620292664 for ['[CLS] evenhoff overs pu newsmament general fun someday [SEP]']
[Init] best perm rec loss: 0.875924289226532 for ['[CLS]hoff someday general even pumament news fun overs [SEP]']
[Init] best perm rec loss: 0.8755142688751221 for ['[CLS] general news evenmament puhoff overs fun someday [SEP]']
[Init] best perm rec loss: 0.8745706081390381 for ['[CLS] even general news pumament somedayhoff fun overs [SEP]']
[Init] best perm rec loss: 0.8732827305793762 for ['[CLS] somedaymamenthoff general overs pu news even fun [SEP]']
[Init] best perm rec loss: 0.8718383312225342 for ['[CLS]mament news general even pu overs fun somedayhoff [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.663 (perp=11.721, rec=0.305, cos=0.014), tot_loss_proj:2.979 [t=0.20s]
prediction: ['[CLS] joyousous everything associate area joy investigation joy [SEP]']
[ 100/2000] tot_loss=2.170 (perp=9.922, rec=0.183, cos=0.003), tot_loss_proj:2.461 [t=0.19s]
prediction: ['[CLS] joyous,,. film of - joy [SEP]']
[ 150/2000] tot_loss=1.705 (perp=7.838, rec=0.135, cos=0.002), tot_loss_proj:2.001 [t=0.20s]
prediction: ['[CLS] joyous, aura. film of - film [SEP]']
[ 200/2000] tot_loss=2.032 (perp=9.573, rec=0.114, cos=0.003), tot_loss_proj:2.859 [t=0.19s]
prediction: ['[CLS] joyous, of. rom ofous film [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.740 (perp=8.108, rec=0.116, cos=0.002), tot_loss_proj:2.629 [t=0.20s]
prediction: ['[CLS] joyous. rom, of of - film [SEP]']
[ 300/2000] tot_loss=1.905 (perp=9.055, rec=0.092, cos=0.002), tot_loss_proj:2.746 [t=0.18s]
prediction: ['[CLS] joyous. rom, of ofp film [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.510 (perp=7.106, rec=0.087, cos=0.002), tot_loss_proj:1.969 [t=0.18s]
prediction: ['[CLS] joyous. romp, of of film [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.394 (perp=6.542, rec=0.084, cos=0.002), tot_loss_proj:1.692 [t=0.19s]
prediction: ['[CLS]. joyous romp, of of film [SEP]']
[ 450/2000] tot_loss=1.387 (perp=6.542, rec=0.077, cos=0.002), tot_loss_proj:1.681 [t=0.18s]
prediction: ['[CLS]. joyous romp, of of film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.388 (perp=6.542, rec=0.078, cos=0.002), tot_loss_proj:1.687 [t=0.18s]
prediction: ['[CLS]. joyous romp, of of film [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.324 (perp=6.198, rec=0.082, cos=0.002), tot_loss_proj:1.527 [t=0.18s]
prediction: ['[CLS]. joyous romp of film,, [SEP]']
[ 600/2000] tot_loss=1.302 (perp=6.198, rec=0.061, cos=0.002), tot_loss_proj:1.523 [t=0.18s]
prediction: ['[CLS]. joyous romp of film,, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.193 (perp=5.492, rec=0.093, cos=0.002), tot_loss_proj:1.371 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.166 (perp=5.492, rec=0.066, cos=0.002), tot_loss_proj:1.372 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
[ 750/2000] tot_loss=1.182 (perp=5.492, rec=0.082, cos=0.002), tot_loss_proj:1.376 [t=0.19s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.175 (perp=5.492, rec=0.075, cos=0.002), tot_loss_proj:1.375 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.183 (perp=5.492, rec=0.083, cos=0.002), tot_loss_proj:1.378 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
[ 900/2000] tot_loss=1.178 (perp=5.492, rec=0.078, cos=0.002), tot_loss_proj:1.370 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.171 (perp=5.492, rec=0.071, cos=0.002), tot_loss_proj:1.390 [t=0.21s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.179 (perp=5.492, rec=0.079, cos=0.002), tot_loss_proj:1.372 [t=0.21s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
[1050/2000] tot_loss=1.183 (perp=5.492, rec=0.083, cos=0.002), tot_loss_proj:1.381 [t=0.20s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.166 (perp=5.492, rec=0.066, cos=0.002), tot_loss_proj:1.375 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.176 (perp=5.492, rec=0.076, cos=0.002), tot_loss_proj:1.377 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
[1200/2000] tot_loss=1.179 (perp=5.492, rec=0.079, cos=0.002), tot_loss_proj:1.373 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.171 (perp=5.492, rec=0.071, cos=0.002), tot_loss_proj:1.367 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.174 (perp=5.492, rec=0.073, cos=0.002), tot_loss_proj:1.371 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
[1350/2000] tot_loss=1.163 (perp=5.492, rec=0.063, cos=0.002), tot_loss_proj:1.374 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.175 (perp=5.492, rec=0.075, cos=0.002), tot_loss_proj:1.369 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.176 (perp=5.492, rec=0.076, cos=0.002), tot_loss_proj:1.374 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
[1500/2000] tot_loss=1.170 (perp=5.492, rec=0.070, cos=0.002), tot_loss_proj:1.369 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.171 (perp=5.492, rec=0.071, cos=0.002), tot_loss_proj:1.378 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.177 (perp=5.492, rec=0.076, cos=0.002), tot_loss_proj:1.375 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
[1650/2000] tot_loss=1.181 (perp=5.492, rec=0.081, cos=0.002), tot_loss_proj:1.379 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.171 (perp=5.492, rec=0.070, cos=0.002), tot_loss_proj:1.375 [t=0.19s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.182 (perp=5.492, rec=0.082, cos=0.002), tot_loss_proj:1.377 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
[1800/2000] tot_loss=1.185 (perp=5.492, rec=0.085, cos=0.002), tot_loss_proj:1.372 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.164 (perp=5.492, rec=0.064, cos=0.002), tot_loss_proj:1.377 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.178 (perp=5.492, rec=0.078, cos=0.002), tot_loss_proj:1.369 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
[1950/2000] tot_loss=1.176 (perp=5.492, rec=0.076, cos=0.002), tot_loss_proj:1.370 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.175 (perp=5.492, rec=0.075, cos=0.002), tot_loss_proj:1.375 [t=0.18s]
prediction: ['[CLS]., joyous romp of film, [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS]., joyous romp of film, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 100.000 | r: 85.714
rouge2     | fm: 72.727 | p: 80.000 | r: 66.667
rougeL     | fm: 92.308 | p: 100.000 | r: 85.714
rougeLsum  | fm: 92.308 | p: 100.000 | r: 85.714
r1fm+r2fm = 165.035

[Aggregate metrics]:
rouge1     | fm: 92.898 | p: 92.720 | r: 93.153
rouge2     | fm: 58.055 | p: 58.050 | r: 58.090
rougeL     | fm: 78.665 | p: 78.569 | r: 78.804
rougeLsum  | fm: 78.640 | p: 78.514 | r: 78.768
r1fm+r2fm = 150.953

input #65 time: 0:07:30 | total time: 9:19:48


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9992330092949469
highest_index [0]
highest [0.9992330092949469]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.973792552947998 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.9307570457458496 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.9160336256027222 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8862890601158142 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.8742782473564148 for ['[CLS]beersa bryce two [SEP]']
[Init] best perm rec loss: 0.8719822764396667 for ['[CLS]beersa two bryce [SEP]']
[Init] best perm rec loss: 0.8696925640106201 for ['[CLS]rsa two brycebee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.051 (perp=9.012, rec=0.237, cos=0.012), tot_loss_proj:2.500 [t=0.18s]
prediction: ['[CLS] fan fan tolkien fan [SEP]']
[ 100/2000] tot_loss=1.955 (perp=9.181, rec=0.114, cos=0.005), tot_loss_proj:2.347 [t=0.18s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 150/2000] tot_loss=1.857 (perp=8.772, rec=0.100, cos=0.003), tot_loss_proj:1.990 [t=0.21s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
[ 200/2000] tot_loss=1.815 (perp=8.772, rec=0.059, cos=0.002), tot_loss_proj:1.989 [t=0.19s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.593 (perp=7.673, rec=0.057, cos=0.002), tot_loss_proj:1.608 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.591 (perp=7.673, rec=0.055, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.597 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.608 (perp=7.673, rec=0.072, cos=0.001), tot_loss_proj:1.608 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.586 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.603 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.619 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.609 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.619 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.597 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.589 (perp=7.673, rec=0.053, cos=0.002), tot_loss_proj:1.607 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.586 (perp=7.673, rec=0.050, cos=0.002), tot_loss_proj:1.606 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.617 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.609 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.599 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.606 (perp=7.673, rec=0.070, cos=0.002), tot_loss_proj:1.607 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.608 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.582 (perp=7.673, rec=0.046, cos=0.002), tot_loss_proj:1.594 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.599 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.596 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.606 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.002), tot_loss_proj:1.601 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.607 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.603 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.605 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.612 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.586 (perp=7.673, rec=0.050, cos=0.002), tot_loss_proj:1.601 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.590 (perp=7.673, rec=0.054, cos=0.002), tot_loss_proj:1.600 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.604 (perp=7.673, rec=0.068, cos=0.002), tot_loss_proj:1.604 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.608 (perp=7.673, rec=0.072, cos=0.002), tot_loss_proj:1.609 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.605 (perp=7.673, rec=0.068, cos=0.002), tot_loss_proj:1.604 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.002), tot_loss_proj:1.612 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.607 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.608 (perp=7.673, rec=0.072, cos=0.002), tot_loss_proj:1.606 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.603 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.606 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.016 | p: 92.816 | r: 93.250
rouge2     | fm: 58.406 | p: 58.389 | r: 58.493
rougeL     | fm: 78.959 | p: 78.896 | r: 79.107
rougeLsum  | fm: 78.949 | p: 78.898 | r: 79.103
r1fm+r2fm = 151.422

input #66 time: 0:07:21 | total time: 9:27:09


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.999292690019056
highest_index [0]
highest [0.999292690019056]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.005807638168335 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9567444324493408 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.9554714560508728 for ['[CLS] repeat well rv strikes combined leaned written itself welsh bunch [SEP]']
[Init] best rec loss: 0.9473316669464111 for ['[CLS] position citationliga carriage demands source administered leancode pope [SEP]']
[Init] best rec loss: 0.9436708688735962 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 0.9336733222007751 for ['[CLS] investment parker mostly radical national snow nearly baltimore contact are [SEP]']
[Init] best rec loss: 0.9325234889984131 for ['[CLS]ible ultimately season mainly swifthood abby source price need [SEP]']
[Init] best rec loss: 0.9268360137939453 for ['[CLS] wild tribes upon cone home enough promotion mural courtney ） [SEP]']
[Init] best perm rec loss: 0.9241943955421448 for ['[CLS] ） cone home mural courtney promotion upon enough wild tribes [SEP]']
[Init] best perm rec loss: 0.9226720929145813 for ['[CLS] promotion tribes home cone enough ） wild courtney upon mural [SEP]']
[Init] best perm rec loss: 0.9221352934837341 for ['[CLS] upon home tribes courtney cone mural ） wild promotion enough [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.569 (perp=11.544, rec=0.255, cos=0.005), tot_loss_proj:3.358 [t=0.17s]
prediction: ['[CLS] surwar god imaging feel - - touchingomorphic kind [SEP]']
[ 100/2000] tot_loss=2.606 (perp=12.273, rec=0.148, cos=0.002), tot_loss_proj:3.837 [t=0.18s]
prediction: ['[CLS] nonwar godental heart, -minggm kind [SEP]']
[ 150/2000] tot_loss=2.707 (perp=13.019, rec=0.101, cos=0.002), tot_loss_proj:3.916 [t=0.18s]
prediction: ['[CLS] nonwar heartental heart, -minggm kind [SEP]']
[ 200/2000] tot_loss=2.862 (perp=13.862, rec=0.088, cos=0.002), tot_loss_proj:4.099 [t=0.18s]
prediction: ['[CLS] nonwar heartental heart,dminggm kind [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.648 (perp=12.571, rec=0.131, cos=0.003), tot_loss_proj:3.791 [t=0.18s]
prediction: ['[CLS] nonwar, originatingental heartjuminggm kind [SEP]']
[ 300/2000] tot_loss=2.550 (perp=12.292, rec=0.090, cos=0.002), tot_loss_proj:3.679 [t=0.18s]
prediction: ['[CLS] nonwar, birthental heartjuminggm kind [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.432 (perp=11.715, rec=0.087, cos=0.002), tot_loss_proj:3.373 [t=0.18s]
prediction: ['[CLS] nonwar,gmental heartjuming collect kind [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.273 (perp=10.702, rec=0.131, cos=0.002), tot_loss_proj:3.740 [t=0.18s]
prediction: ['[CLS] nonwarming,gmental heartjuety kind [SEP]']
[ 450/2000] tot_loss=2.161 (perp=10.364, rec=0.087, cos=0.002), tot_loss_proj:3.640 [t=0.18s]
prediction: ['[CLS] nonwarming,gmental heartju inward kind [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.701 (perp=8.074, rec=0.084, cos=0.002), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] heartwarming,gmental nonjunent kind [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.607 (perp=7.668, rec=0.072, cos=0.001), tot_loss_proj:2.094 [t=0.18s]
prediction: ['[CLS] heartwarming,gmental nonjuensis kind [SEP]']
[ 600/2000] tot_loss=1.613 (perp=7.668, rec=0.078, cos=0.001), tot_loss_proj:2.086 [t=0.18s]
prediction: ['[CLS] heartwarming,gmental nonjuensis kind [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.613 (perp=7.668, rec=0.078, cos=0.001), tot_loss_proj:2.087 [t=0.18s]
prediction: ['[CLS] heartwarming,gmental nonjuensis kind [SEP]']
Attempt swap
Put prefix at the end
[ 700/2000] tot_loss=1.547 (perp=7.214, rec=0.102, cos=0.002), tot_loss_proj:2.016 [t=0.18s]
prediction: ['[CLS] kind heartwarming,gmental nonjumorphic [SEP]']
[ 750/2000] tot_loss=1.528 (perp=7.214, rec=0.083, cos=0.002), tot_loss_proj:2.015 [t=0.18s]
prediction: ['[CLS] kind heartwarming,gmental nonjumorphic [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.469 (perp=6.954, rec=0.077, cos=0.001), tot_loss_proj:1.713 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjumorphicgmental [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.470 (perp=6.954, rec=0.078, cos=0.001), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjumorphicgmental [SEP]']
[ 900/2000] tot_loss=1.468 (perp=6.954, rec=0.075, cos=0.001), tot_loss_proj:1.714 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjumorphicgmental [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.471 (perp=6.954, rec=0.079, cos=0.001), tot_loss_proj:1.716 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjumorphicgmental [SEP]']
Attempt swap
[1000/2000] tot_loss=1.461 (perp=6.954, rec=0.068, cos=0.001), tot_loss_proj:1.707 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjumorphicgmental [SEP]']
[1050/2000] tot_loss=1.462 (perp=6.954, rec=0.070, cos=0.001), tot_loss_proj:1.706 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjumorphicgmental [SEP]']
Attempt swap
[1100/2000] tot_loss=1.500 (perp=7.088, rec=0.081, cos=0.001), tot_loss_proj:1.823 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjuensisgmental [SEP]']
Attempt swap
[1150/2000] tot_loss=1.491 (perp=7.088, rec=0.072, cos=0.001), tot_loss_proj:1.823 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjuensisgmental [SEP]']
[1200/2000] tot_loss=1.563 (perp=7.379, rec=0.086, cos=0.001), tot_loss_proj:1.840 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjuwilgmental [SEP]']
Attempt swap
[1250/2000] tot_loss=1.551 (perp=7.379, rec=0.074, cos=0.001), tot_loss_proj:1.833 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjuwilgmental [SEP]']
Attempt swap
[1300/2000] tot_loss=1.552 (perp=7.379, rec=0.075, cos=0.001), tot_loss_proj:1.826 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjuwilgmental [SEP]']
[1350/2000] tot_loss=1.547 (perp=7.379, rec=0.070, cos=0.001), tot_loss_proj:1.831 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjuwilgmental [SEP]']
Attempt swap
[1400/2000] tot_loss=1.549 (perp=7.379, rec=0.072, cos=0.001), tot_loss_proj:1.833 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjuwilgmental [SEP]']
Attempt swap
[1450/2000] tot_loss=1.552 (perp=7.379, rec=0.075, cos=0.001), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] kind heartwarming, nonjuwilgmental [SEP]']
[1500/2000] tot_loss=1.511 (perp=7.180, rec=0.074, cos=0.001), tot_loss_proj:1.750 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjuntgmental [SEP]']
Attempt swap
[1550/2000] tot_loss=1.511 (perp=7.180, rec=0.074, cos=0.001), tot_loss_proj:1.746 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjuntgmental [SEP]']
Attempt swap
[1600/2000] tot_loss=1.514 (perp=7.180, rec=0.076, cos=0.001), tot_loss_proj:1.749 [t=0.19s]
prediction: ['[CLS] kind heartwarming, nonjuntgmental [SEP]']
[1650/2000] tot_loss=1.134 (perp=5.308, rec=0.071, cos=0.001), tot_loss_proj:1.331 [t=0.20s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1700/2000] tot_loss=1.123 (perp=5.308, rec=0.060, cos=0.001), tot_loss_proj:1.337 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1750/2000] tot_loss=1.138 (perp=5.308, rec=0.075, cos=0.001), tot_loss_proj:1.335 [t=0.18s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
[1800/2000] tot_loss=1.129 (perp=5.308, rec=0.066, cos=0.001), tot_loss_proj:1.335 [t=0.19s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1850/2000] tot_loss=1.137 (perp=5.308, rec=0.074, cos=0.001), tot_loss_proj:1.332 [t=0.20s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[1900/2000] tot_loss=1.126 (perp=5.308, rec=0.063, cos=0.001), tot_loss_proj:1.336 [t=0.20s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
[1950/2000] tot_loss=1.127 (perp=5.308, rec=0.064, cos=0.001), tot_loss_proj:1.338 [t=0.20s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Attempt swap
[2000/2000] tot_loss=1.135 (perp=5.308, rec=0.073, cos=0.001), tot_loss_proj:1.330 [t=0.20s]
prediction: ['[CLS] kind heartwarming, nonjudgmental [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind heartwarming, nonjudgmental [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 93.052 | p: 92.859 | r: 93.315
rouge2     | fm: 58.222 | p: 58.111 | r: 58.329
rougeL     | fm: 79.001 | p: 78.909 | r: 79.104
rougeLsum  | fm: 78.990 | p: 78.908 | r: 79.116
r1fm+r2fm = 151.273

input #67 time: 0:07:29 | total time: 9:34:38


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9992789242841313
highest_index [0]
highest [0.9992789242841313]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.989619255065918 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9645585417747498 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.9424722194671631 for ['[CLS] raise describedwehrwork witch rom can bray fictional elton here sex pilots [SEP]']
[Init] best rec loss: 0.9253563284873962 for ['[CLS] neutron acrosswas 2005 security tip fa— identity david entitled readers letters [SEP]']
[Init] best rec loss: 0.8706526756286621 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8648829460144043 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8608188629150391 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8541148900985718 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8531020283699036 for ['[CLS]iferous comfortyn form medal died floor. beth possibly riding view councils [SEP]']
[Init] best perm rec loss: 0.8519254326820374 for ['[CLS] possibly councils comfortiferousyn floor died form view beth. medal riding [SEP]']
[Init] best perm rec loss: 0.8488271236419678 for ['[CLS]iferous flooryn form possibly medal riding view beth councils. died comfort [SEP]']
[Init] best perm rec loss: 0.8450530767440796 for ['[CLS] beth comfortyn died form riding councils possibly medal floor. viewiferous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.056 (perp=9.301, rec=0.186, cos=0.010), tot_loss_proj:3.168 [t=0.18s]
prediction: ['[CLS] santos,berg absurdsible, shy and absurd vicious and absurd un [SEP]']
[ 100/2000] tot_loss=1.756 (perp=8.165, rec=0.121, cos=0.002), tot_loss_proj:1.986 [t=0.18s]
prediction: ['[CLS] uncouthsiblesible, vicious, absurd vicious and absurdco [SEP]']
[ 150/2000] tot_loss=2.277 (perp=10.954, rec=0.085, cos=0.002), tot_loss_proj:2.560 [t=0.18s]
prediction: ['[CLS] uncohenuthsible,omp, absurd vicious and absurdco [SEP]']
[ 200/2000] tot_loss=2.297 (perp=11.101, rec=0.075, cos=0.002), tot_loss_proj:2.584 [t=0.18s]
prediction: ['[CLS] uncohenuthsible,omp, absurd vicious and absurd inc [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.921 (perp=9.272, rec=0.066, cos=0.001), tot_loss_proj:2.224 [t=0.20s]
prediction: ['[CLS] unhencouthsible,omp, absurd vicious and absurd inc [SEP]']
[ 300/2000] tot_loss=1.924 (perp=9.272, rec=0.069, cos=0.001), tot_loss_proj:2.223 [t=0.18s]
prediction: ['[CLS] unhencouthsible,omp, absurd vicious and absurd inc [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.739 (perp=8.332, rec=0.072, cos=0.001), tot_loss_proj:2.007 [t=0.18s]
prediction: ['[CLS] uncouthhensible,omp, absurd vicious and absurd inc [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.426 (perp=6.749, rec=0.075, cos=0.002), tot_loss_proj:1.666 [t=0.18s]
prediction: ['[CLS] uncouthhensible, incomp, un vicious and absurd [SEP]']
[ 450/2000] tot_loss=1.420 (perp=6.749, rec=0.069, cos=0.001), tot_loss_proj:1.658 [t=0.18s]
prediction: ['[CLS] uncouthhensible, incomp, un vicious and absurd [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.219 (perp=5.767, rec=0.064, cos=0.001), tot_loss_proj:1.302 [t=0.17s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.217 (perp=5.767, rec=0.062, cos=0.001), tot_loss_proj:1.308 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
[ 600/2000] tot_loss=1.207 (perp=5.767, rec=0.053, cos=0.001), tot_loss_proj:1.306 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.217 (perp=5.767, rec=0.062, cos=0.001), tot_loss_proj:1.305 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.220 (perp=5.767, rec=0.065, cos=0.001), tot_loss_proj:1.301 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
[ 750/2000] tot_loss=1.205 (perp=5.767, rec=0.050, cos=0.001), tot_loss_proj:1.299 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.219 (perp=5.767, rec=0.064, cos=0.001), tot_loss_proj:1.304 [t=0.21s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.221 (perp=5.767, rec=0.066, cos=0.001), tot_loss_proj:1.296 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
[ 900/2000] tot_loss=1.220 (perp=5.767, rec=0.066, cos=0.001), tot_loss_proj:1.298 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.218 (perp=5.767, rec=0.063, cos=0.001), tot_loss_proj:1.295 [t=0.21s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1000/2000] tot_loss=1.220 (perp=5.767, rec=0.065, cos=0.001), tot_loss_proj:1.305 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
[1050/2000] tot_loss=1.221 (perp=5.767, rec=0.066, cos=0.001), tot_loss_proj:1.306 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1100/2000] tot_loss=1.216 (perp=5.767, rec=0.061, cos=0.001), tot_loss_proj:1.309 [t=0.19s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1150/2000] tot_loss=1.221 (perp=5.767, rec=0.066, cos=0.001), tot_loss_proj:1.303 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
[1200/2000] tot_loss=1.225 (perp=5.767, rec=0.071, cos=0.001), tot_loss_proj:1.300 [t=0.19s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1250/2000] tot_loss=1.222 (perp=5.767, rec=0.067, cos=0.001), tot_loss_proj:1.311 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1300/2000] tot_loss=1.211 (perp=5.767, rec=0.056, cos=0.001), tot_loss_proj:1.310 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
[1350/2000] tot_loss=1.220 (perp=5.767, rec=0.066, cos=0.001), tot_loss_proj:1.311 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1400/2000] tot_loss=1.227 (perp=5.767, rec=0.072, cos=0.001), tot_loss_proj:1.296 [t=0.19s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1450/2000] tot_loss=1.219 (perp=5.767, rec=0.065, cos=0.001), tot_loss_proj:1.308 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
[1500/2000] tot_loss=1.221 (perp=5.767, rec=0.066, cos=0.001), tot_loss_proj:1.304 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=1.217 (perp=5.767, rec=0.063, cos=0.001), tot_loss_proj:1.295 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1600/2000] tot_loss=1.220 (perp=5.767, rec=0.066, cos=0.001), tot_loss_proj:1.299 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
[1650/2000] tot_loss=1.222 (perp=5.767, rec=0.067, cos=0.001), tot_loss_proj:1.303 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=1.215 (perp=5.767, rec=0.060, cos=0.001), tot_loss_proj:1.305 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=1.224 (perp=5.767, rec=0.069, cos=0.001), tot_loss_proj:1.306 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
[1800/2000] tot_loss=1.210 (perp=5.767, rec=0.055, cos=0.001), tot_loss_proj:1.298 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=1.214 (perp=5.767, rec=0.059, cos=0.001), tot_loss_proj:1.307 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=1.214 (perp=5.767, rec=0.059, cos=0.001), tot_loss_proj:1.309 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
[1950/2000] tot_loss=1.217 (perp=5.767, rec=0.062, cos=0.001), tot_loss_proj:1.299 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=1.212 (perp=5.767, rec=0.057, cos=0.001), tot_loss_proj:1.303 [t=0.18s]
prediction: ['[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouth, unhensible, incomp vicious and absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 61.538 | p: 57.143 | r: 66.667
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 141.538

[Aggregate metrics]:
rouge1     | fm: 92.907 | p: 92.654 | r: 93.267
rouge2     | fm: 58.207 | p: 58.068 | r: 58.392
rougeL     | fm: 78.957 | p: 78.810 | r: 79.173
rougeLsum  | fm: 78.975 | p: 78.826 | r: 79.162
r1fm+r2fm = 151.113

input #68 time: 0:07:23 | total time: 9:42:02


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9992908222867736
highest_index [0]
highest [0.9992908222867736]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.086551547050476 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9466122388839722 for ['[CLS] cade atoms especially suddenly schneider commanded noble retirement causescap meant grin immortals fai act paternal [SEP]']
[Init] best rec loss: 0.925304114818573 for ['[CLS] meetings bells mountain bloody technical script⁄ sarah rebound fare they br hospital christmas value turkmenistan [SEP]']
[Init] best rec loss: 0.9242345690727234 for ['[CLS] et roughly christian cinema angela zoo commanded determinedpine treatcraft said being amountigo ; [SEP]']
[Init] best rec loss: 0.9170600771903992 for ['[CLS] operation tactics toes collective valley stitches drop criticism insteadivequitable francis surnamezer san zone [SEP]']
[Init] best rec loss: 0.9078761339187622 for ['[CLS] mans border mormon vocational be doubt recordseft outcomes same humor spring chi ears other ling [SEP]']
[Init] best rec loss: 0.8832088112831116 for ['[CLS] tract havinggated libraries himself odd magna courtney jonah tempted miller stunning spit opened french now [SEP]']
[Init] best rec loss: 0.8760436773300171 for ['[CLS]mission down unopposedacio tray adelaide african platform burnham ferrisest port case [MASK] gross main [SEP]']
[Init] best perm rec loss: 0.8714134693145752 for ['[CLS] ferris main case african gross tray adelaide burnham port unopposedest [MASK] platformmission downacio [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.810 (perp=12.382, rec=0.327, cos=0.006), tot_loss_proj:4.043 [t=0.18s]
prediction: ['[CLS] telling co case graduatemont and buildingssarhire schools gesture.fast comic australian al [SEP]']
[ 100/2000] tot_loss=2.191 (perp=9.758, rec=0.237, cos=0.003), tot_loss_proj:2.643 [t=0.18s]
prediction: ['[CLS] smart camera case winner _. smart - real and gesture. successful comic australian lloyd [SEP]']
[ 150/2000] tot_loss=2.150 (perp=9.764, rec=0.194, cos=0.002), tot_loss_proj:2.606 [t=0.18s]
prediction: ['[CLS] smart co case winner _ - funny, real and subtle. winner comic antarctic lloyd [SEP]']
[ 200/2000] tot_loss=2.129 (perp=9.761, rec=0.175, cos=0.002), tot_loss_proj:2.678 [t=0.18s]
prediction: ['[CLS] smart co a winner -, funny points real and subtle. winner comic sydney real [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.053 (perp=9.239, rec=0.202, cos=0.003), tot_loss_proj:2.350 [t=0.18s]
prediction: ['[CLS] co a winner -, funny percussion real and funny smart. real comic sydney real [SEP]']
[ 300/2000] tot_loss=1.989 (perp=9.150, rec=0.157, cos=0.002), tot_loss_proj:2.474 [t=0.18s]
prediction: ['[CLS] hunter a winner -, funnyona real, funny smart.ona metre sydney real [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.017 (perp=9.348, rec=0.145, cos=0.002), tot_loss_proj:2.578 [t=0.18s]
prediction: ['[CLS] case a winner -, funnyona real, funny. smartona quinlan canadian muhammad [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.860 (perp=8.625, rec=0.133, cos=0.002), tot_loss_proj:2.504 [t=0.18s]
prediction: ['[CLS] case a winner - funnyona, real, funny. smartona curl alaska ins [SEP]']
[ 450/2000] tot_loss=1.887 (perp=8.769, rec=0.132, cos=0.002), tot_loss_proj:2.484 [t=0.20s]
prediction: ['[CLS] case a winner - funnyona, real, funny. smartona curl boxing ins [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.924 (perp=9.003, rec=0.122, cos=0.002), tot_loss_proj:2.537 [t=0.20s]
prediction: ['[CLS] case a winner - funnyona, real, subtleona smart. curl boxing - [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.112 (perp=9.836, rec=0.143, cos=0.002), tot_loss_proj:2.521 [t=0.20s]
prediction: ['[CLS] developed a winner -ona funny, real, subtleona smart. curl sydney background [SEP]']
[ 600/2000] tot_loss=1.993 (perp=9.357, rec=0.120, cos=0.002), tot_loss_proj:2.506 [t=0.20s]
prediction: ['[CLS] developed a winner -ona funny, real, subtleona smart. metre boxing - [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.031 (perp=9.520, rec=0.126, cos=0.002), tot_loss_proj:2.484 [t=0.20s]
prediction: ['[CLS]. a winner -ona funny, real, subtleona smart developed metre boxing subtle [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.875 (perp=8.718, rec=0.130, cos=0.002), tot_loss_proj:2.415 [t=0.18s]
prediction: ['[CLS]. a winner -ona smart, real, subtleona smart developed boxing subtle metre [SEP]']
[ 750/2000] tot_loss=1.901 (perp=8.911, rec=0.118, cos=0.002), tot_loss_proj:2.485 [t=0.19s]
prediction: ['[CLS]. a winner -ona smart, real, subtleona smart developed boxing subtle puts [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.854 (perp=8.705, rec=0.111, cos=0.002), tot_loss_proj:2.339 [t=0.19s]
prediction: ['[CLS]. a winner -ona smart, real, subtle subtlent smart developed boxing puts [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.687 (perp=7.887, rec=0.108, cos=0.002), tot_loss_proj:2.145 [t=0.18s]
prediction: ['[CLS]. a winner -ona smart, real, subtle and subtlent smart boxing puts [SEP]']
[ 900/2000] tot_loss=1.746 (perp=8.174, rec=0.110, cos=0.002), tot_loss_proj:2.149 [t=0.19s]
prediction: ['[CLS]. a winner -ona smart, real, subtle and subtlent smart liner puts [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.652 (perp=7.668, rec=0.117, cos=0.002), tot_loss_proj:1.959 [t=0.19s]
prediction: ['[CLS]. a winner - smart, real, subtle and subtleonant smart liner puts [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.574 (perp=7.260, rec=0.120, cos=0.002), tot_loss_proj:1.943 [t=0.18s]
prediction: ['[CLS]. a winner - smart, real, subtle and subtleonant smart boxing puts [SEP]']
[1050/2000] tot_loss=1.723 (perp=8.059, rec=0.109, cos=0.002), tot_loss_proj:2.073 [t=0.19s]
prediction: ['[CLS]. a winner - subtle, real, subtle and subtleonant smart liner puts [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.729 (perp=8.059, rec=0.116, cos=0.002), tot_loss_proj:2.073 [t=0.19s]
prediction: ['[CLS]. a winner - subtle, real, subtle and subtleonant smart liner puts [SEP]']
Attempt swap
[1150/2000] tot_loss=1.722 (perp=8.059, rec=0.109, cos=0.002), tot_loss_proj:2.076 [t=0.18s]
prediction: ['[CLS]. a winner - subtle, real, subtle and subtleonant smart liner puts [SEP]']
[1200/2000] tot_loss=1.726 (perp=8.059, rec=0.113, cos=0.002), tot_loss_proj:2.063 [t=0.19s]
prediction: ['[CLS]. a winner - subtle, real, subtle and subtleonant smart liner puts [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.730 (perp=8.059, rec=0.116, cos=0.002), tot_loss_proj:2.071 [t=0.18s]
prediction: ['[CLS]. a winner - subtle, real, subtle and subtleonant smart liner puts [SEP]']
Attempt swap
[1300/2000] tot_loss=1.721 (perp=8.059, rec=0.107, cos=0.002), tot_loss_proj:2.069 [t=0.18s]
prediction: ['[CLS]. a winner - subtle, real, subtle and subtleonant smart liner puts [SEP]']
[1350/2000] tot_loss=1.723 (perp=8.059, rec=0.110, cos=0.002), tot_loss_proj:2.063 [t=0.19s]
prediction: ['[CLS]. a winner - subtle, real, subtle and subtleonant smart liner puts [SEP]']
Attempt swap
[1400/2000] tot_loss=1.711 (perp=8.009, rec=0.107, cos=0.002), tot_loss_proj:2.148 [t=0.18s]
prediction: ['[CLS]. a winner - subtle, real, subtle and subtleonant smart comment puts [SEP]']
Attempt swap
[1450/2000] tot_loss=1.718 (perp=8.009, rec=0.114, cos=0.002), tot_loss_proj:2.137 [t=0.18s]
prediction: ['[CLS]. a winner - subtle, real, subtle and subtleonant smart comment puts [SEP]']
[1500/2000] tot_loss=1.718 (perp=8.009, rec=0.114, cos=0.002), tot_loss_proj:2.150 [t=0.19s]
prediction: ['[CLS]. a winner - subtle, real, subtle and subtleonant smart comment puts [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.684 (perp=7.897, rec=0.103, cos=0.002), tot_loss_proj:2.193 [t=0.19s]
prediction: ['[CLS]. a winner - subtle, real, subtle and smartonant subtle comment puts [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.599 (perp=7.429, rec=0.111, cos=0.002), tot_loss_proj:2.208 [t=0.18s]
prediction: ['[CLS] puts a winner - subtle, real, subtle and smartonant subtle isbn. [SEP]']
[1650/2000] tot_loss=1.595 (perp=7.429, rec=0.108, cos=0.002), tot_loss_proj:2.214 [t=0.19s]
prediction: ['[CLS] puts a winner - subtle, real, subtle and smartonant subtle isbn. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.576 (perp=7.348, rec=0.105, cos=0.002), tot_loss_proj:2.123 [t=0.19s]
prediction: ['[CLS] puts a winner - subtle, real, subtle and smart isbnonant subtle. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.537 (perp=7.104, rec=0.114, cos=0.002), tot_loss_proj:2.060 [t=0.18s]
prediction: ['[CLS] puts a winner - subtle, real, subtle and smart subtle isbnonant. [SEP]']
[1800/2000] tot_loss=1.540 (perp=7.104, rec=0.118, cos=0.002), tot_loss_proj:2.060 [t=0.19s]
prediction: ['[CLS] puts a winner - subtle, real, subtle and smart subtle isbnonant. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.597 (perp=7.403, rec=0.115, cos=0.002), tot_loss_proj:2.058 [t=0.19s]
prediction: ['[CLS] puts a winner - subtle, real, subtle and smart subtle lineronant. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.586 (perp=7.403, rec=0.104, cos=0.002), tot_loss_proj:2.067 [t=0.18s]
prediction: ['[CLS] puts a winner - subtle, real, subtle and smart subtle lineronant. [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.403, rec=0.105, cos=0.002), tot_loss_proj:2.070 [t=0.19s]
prediction: ['[CLS] puts a winner - subtle, real, subtle and smart subtle lineronant. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.546 (perp=7.173, rec=0.110, cos=0.002), tot_loss_proj:2.067 [t=0.19s]
prediction: ['[CLS] puts a winner - subtle, real, subtle and subtle smart lineronant. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] puts a winner - subtle, real, subtle and smart subtle lineronant. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 66.667 | r: 80.000
rouge2     | fm: 10.000 | p: 9.091 | r: 11.111
rougeL     | fm: 54.545 | p: 50.000 | r: 60.000
rougeLsum  | fm: 54.545 | p: 50.000 | r: 60.000
r1fm+r2fm = 82.727

[Aggregate metrics]:
rouge1     | fm: 92.599 | p: 92.287 | r: 93.014
rouge2     | fm: 57.342 | p: 57.208 | r: 57.571
rougeL     | fm: 78.674 | p: 78.437 | r: 78.958
rougeLsum  | fm: 78.702 | p: 78.487 | r: 79.017
r1fm+r2fm = 149.941

input #69 time: 0:07:32 | total time: 9:49:35


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9993748902467187
highest_index [0]
highest [0.9993748902467187]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8451830148696899 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.81871098279953 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7903928160667419 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7371676564216614 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best perm rec loss: 0.7334622144699097 for ['[CLS] detention technological sharma herself blood mark effects [SEP]']
[Init] best perm rec loss: 0.7315616607666016 for ['[CLS] blood sharma herself effects mark detention technological [SEP]']
[Init] best perm rec loss: 0.7313181161880493 for ['[CLS] detention sharma effects mark herself blood technological [SEP]']
[Init] best perm rec loss: 0.7305154204368591 for ['[CLS] sharma blood herself detention technological effects mark [SEP]']
[Init] best perm rec loss: 0.730158805847168 for ['[CLS] mark blood herself effects technological detention sharma [SEP]']
[Init] best perm rec loss: 0.7293766736984253 for ['[CLS] detention blood effects sharma herself technological mark [SEP]']
[Init] best perm rec loss: 0.7282413840293884 for ['[CLS] detention herself mark sharma technological effects blood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.653 (perp=11.351, rec=0.348, cos=0.035), tot_loss_proj:3.079 [t=0.18s]
prediction: ['[CLS] blewy jammed around overunk gets [SEP]']
[ 100/2000] tot_loss=2.392 (perp=10.947, rec=0.189, cos=0.014), tot_loss_proj:3.063 [t=0.19s]
prediction: ['[CLS] clyunk screen clunk gets [SEP]']
[ 150/2000] tot_loss=2.367 (perp=10.947, rec=0.162, cos=0.016), tot_loss_proj:3.067 [t=0.24s]
prediction: ['[CLS] clyunk screen clunk gets [SEP]']
[ 200/2000] tot_loss=2.297 (perp=10.947, rec=0.103, cos=0.004), tot_loss_proj:3.071 [t=0.19s]
prediction: ['[CLS] clyunk screen clunk gets [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.785 (perp=8.441, rec=0.092, cos=0.006), tot_loss_proj:2.229 [t=0.20s]
prediction: ['[CLS] on screenunky clunk gets [SEP]']
[ 300/2000] tot_loss=1.762 (perp=8.441, rec=0.072, cos=0.002), tot_loss_proj:2.229 [t=0.19s]
prediction: ['[CLS] on screenunky clunk gets [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.771 (perp=8.441, rec=0.081, cos=0.002), tot_loss_proj:2.232 [t=0.18s]
prediction: ['[CLS] on screenunky clunk gets [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.830 (perp=8.753, rec=0.077, cos=0.002), tot_loss_proj:2.549 [t=0.23s]
prediction: ['[CLS] on screenunky the cl gets [SEP]']
[ 450/2000] tot_loss=1.817 (perp=8.753, rec=0.065, cos=0.001), tot_loss_proj:2.548 [t=0.20s]
prediction: ['[CLS] on screenunky the cl gets [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.386 (perp=6.560, rec=0.072, cos=0.002), tot_loss_proj:1.840 [t=0.18s]
prediction: ['[CLS] on screen the clunky gets [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.370 (perp=6.484, rec=0.072, cos=0.001), tot_loss_proj:1.760 [t=0.18s]
prediction: ['[CLS] on the screen clunky gets [SEP]']
[ 600/2000] tot_loss=1.368 (perp=6.484, rec=0.070, cos=0.001), tot_loss_proj:1.747 [t=0.18s]
prediction: ['[CLS] on the screen clunky gets [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.369 (perp=6.484, rec=0.071, cos=0.001), tot_loss_proj:1.749 [t=0.18s]
prediction: ['[CLS] on the screen clunky gets [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.218 (perp=5.690, rec=0.078, cos=0.002), tot_loss_proj:1.645 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 750/2000] tot_loss=1.210 (perp=5.690, rec=0.071, cos=0.001), tot_loss_proj:1.652 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.210 (perp=5.690, rec=0.071, cos=0.001), tot_loss_proj:1.646 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.207 (perp=5.690, rec=0.068, cos=0.001), tot_loss_proj:1.651 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[ 900/2000] tot_loss=1.208 (perp=5.690, rec=0.069, cos=0.001), tot_loss_proj:1.643 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.211 (perp=5.690, rec=0.072, cos=0.001), tot_loss_proj:1.648 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.200 (perp=5.690, rec=0.061, cos=0.001), tot_loss_proj:1.636 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1050/2000] tot_loss=1.207 (perp=5.690, rec=0.068, cos=0.001), tot_loss_proj:1.644 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.215 (perp=5.690, rec=0.076, cos=0.001), tot_loss_proj:1.646 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.208 (perp=5.690, rec=0.069, cos=0.001), tot_loss_proj:1.647 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1200/2000] tot_loss=1.201 (perp=5.690, rec=0.062, cos=0.001), tot_loss_proj:1.647 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.200 (perp=5.690, rec=0.061, cos=0.001), tot_loss_proj:1.644 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.202 (perp=5.690, rec=0.063, cos=0.001), tot_loss_proj:1.647 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1350/2000] tot_loss=1.208 (perp=5.690, rec=0.069, cos=0.001), tot_loss_proj:1.650 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.211 (perp=5.690, rec=0.072, cos=0.001), tot_loss_proj:1.644 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.203 (perp=5.690, rec=0.063, cos=0.001), tot_loss_proj:1.643 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1500/2000] tot_loss=1.208 (perp=5.690, rec=0.069, cos=0.001), tot_loss_proj:1.648 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.196 (perp=5.690, rec=0.057, cos=0.001), tot_loss_proj:1.642 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.207 (perp=5.690, rec=0.067, cos=0.001), tot_loss_proj:1.642 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1650/2000] tot_loss=1.212 (perp=5.690, rec=0.073, cos=0.001), tot_loss_proj:1.642 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.208 (perp=5.690, rec=0.068, cos=0.001), tot_loss_proj:1.635 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.211 (perp=5.690, rec=0.072, cos=0.001), tot_loss_proj:1.639 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1800/2000] tot_loss=1.206 (perp=5.690, rec=0.067, cos=0.001), tot_loss_proj:1.637 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.191 (perp=5.690, rec=0.052, cos=0.001), tot_loss_proj:1.641 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.195 (perp=5.690, rec=0.056, cos=0.001), tot_loss_proj:1.645 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
[1950/2000] tot_loss=1.209 (perp=5.690, rec=0.070, cos=0.001), tot_loss_proj:1.636 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.211 (perp=5.690, rec=0.072, cos=0.001), tot_loss_proj:1.637 [t=0.18s]
prediction: ['[CLS] on the screen gets clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] on the screen gets clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 92.691 | p: 92.401 | r: 93.128
rouge2     | fm: 57.326 | p: 57.214 | r: 57.488
rougeL     | fm: 78.554 | p: 78.344 | r: 78.773
rougeLsum  | fm: 78.515 | p: 78.327 | r: 78.832
r1fm+r2fm = 150.017

input #70 time: 0:07:26 | total time: 9:57:01


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9993403548184047
highest_index [0]
highest [0.9993403548184047]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8840630650520325 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.847382128238678 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8406677842140198 for ['[CLS] fed to radar county sun gunshot parchment waiting regional wallacewo dia [CLS] smiles fantasy [SEP]']
[Init] best rec loss: 0.8305583596229553 for ['[CLS] shoulders protocol powerfulfication sash jonas obligatory definition box thorough whole except visit flanked dated [SEP]']
[Init] best rec loss: 0.8247600197792053 for ['[CLS] cidloubridge living blues republicfl projections transition rally mere torpedo spellingcio espn [SEP]']
[Init] best rec loss: 0.8176411986351013 for ['[CLS] mutual internal travel grief with album careful item serious european either warp spoil waived every [SEP]']
[Init] best rec loss: 0.813213050365448 for ['[CLS] knock lily combinedzh times soundfinger assist chains kylie most asha? industryico [SEP]']
[Init] best rec loss: 0.8101482391357422 for ['[CLS]. coursearth acids south gogh beyond stage reservoir until little tombathlontered wright [SEP]']
[Init] best perm rec loss: 0.8090407252311707 for ['[CLS] tomb gogharth acids course beyond littletered wright until south. reservoir stageathlon [SEP]']
[Init] best perm rec loss: 0.8082916736602783 for ['[CLS] beyond gogh southarth wright stage course acidstered. little until tombathlon reservoir [SEP]']
[Init] best perm rec loss: 0.8073354363441467 for ['[CLS] reservoir beyond.athlon little acids tombarth wright south course stage until goghtered [SEP]']
[Init] best perm rec loss: 0.8070156574249268 for ['[CLS]. reservoir wright beyondathlon tombarth stage acids south gogh course littletered until [SEP]']
[Init] best perm rec loss: 0.8070120215415955 for ['[CLS]athlon. reservoir southarth stagetered tomb beyond wright until little gogh acids course [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.525 (perp=11.020, rec=0.302, cos=0.019), tot_loss_proj:3.521 [t=0.18s]
prediction: ["[CLS] bingo ever kingdom number any single'jump event is'seats not moment moment [SEP]"]
[ 100/2000] tot_loss=1.943 (perp=8.729, rec=0.186, cos=0.011), tot_loss_proj:3.026 [t=0.18s]
prediction: ['[CLS] jump you jump not a single jump jump moment there - seat not moment moment [SEP]']
[ 150/2000] tot_loss=1.765 (perp=8.129, rec=0.133, cos=0.007), tot_loss_proj:2.514 [t=0.18s]
prediction: ['[CLS] jump - jump not a single - jump moment there - seat not moment and [SEP]']
[ 200/2000] tot_loss=1.722 (perp=8.113, rec=0.097, cos=0.002), tot_loss_proj:3.109 [t=0.19s]
prediction: ['[CLS] there - jump - a single - jump moment there your seat not moment and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.692 (perp=7.989, rec=0.092, cos=0.002), tot_loss_proj:3.071 [t=0.18s]
prediction: ['[CLS] there - jump s a single jump - moment there your seat not moment and [SEP]']
[ 300/2000] tot_loss=1.754 (perp=8.372, rec=0.078, cos=0.002), tot_loss_proj:3.154 [t=0.18s]
prediction: ['[CLS] here - jump s a single jump - moment there your seat not moment and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.548 (perp=7.326, rec=0.081, cos=0.001), tot_loss_proj:2.931 [t=0.18s]
prediction: ['[CLS] there s jump - a single jump - moment there your seat not - and [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.493 (perp=7.114, rec=0.069, cos=0.001), tot_loss_proj:2.584 [t=0.18s]
prediction: ['[CLS] there s your not a single jump - moment there your seat - - and [SEP]']
[ 450/2000] tot_loss=1.497 (perp=7.114, rec=0.073, cos=0.001), tot_loss_proj:2.586 [t=0.18s]
prediction: ['[CLS] there s your not a single jump - moment there your seat - - and [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.388 (perp=6.540, rec=0.078, cos=0.001), tot_loss_proj:2.274 [t=0.19s]
prediction: ['[CLS] there your s not a single jump - moment there your seat - - and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.411 (perp=6.668, rec=0.076, cos=0.001), tot_loss_proj:2.203 [t=0.18s]
prediction: ['[CLS] there your s not a single jump in moment there your seat - - and [SEP]']
[ 600/2000] tot_loss=1.405 (perp=6.668, rec=0.070, cos=0.001), tot_loss_proj:2.205 [t=0.18s]
prediction: ['[CLS] there your s not a single jump in moment there your seat - - and [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.402 (perp=6.668, rec=0.067, cos=0.001), tot_loss_proj:2.189 [t=0.18s]
prediction: ['[CLS] there your s not a single jump in moment there your seat - - and [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.316 (perp=6.202, rec=0.074, cos=0.002), tot_loss_proj:2.737 [t=0.18s]
prediction: ['[CLS] - your moment there s not a single jump in your seat - - and [SEP]']
[ 750/2000] tot_loss=1.308 (perp=6.202, rec=0.066, cos=0.001), tot_loss_proj:2.744 [t=0.18s]
prediction: ['[CLS] - your moment there s not a single jump in your seat - - and [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.240 (perp=5.842, rec=0.070, cos=0.001), tot_loss_proj:2.507 [t=0.18s]
prediction: ['[CLS] your moment there - s not a single jump in your seat - - and [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.233 (perp=5.827, rec=0.066, cos=0.001), tot_loss_proj:2.947 [t=0.18s]
prediction: ['[CLS] in moment - there s not a single jump in your seat - - and [SEP]']
[ 900/2000] tot_loss=1.240 (perp=5.827, rec=0.074, cos=0.001), tot_loss_proj:2.943 [t=0.18s]
prediction: ['[CLS] in moment - there s not a single jump in your seat - - and [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.164 (perp=5.457, rec=0.071, cos=0.001), tot_loss_proj:2.795 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.163 (perp=5.457, rec=0.070, cos=0.001), tot_loss_proj:2.790 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
[1050/2000] tot_loss=1.163 (perp=5.457, rec=0.071, cos=0.001), tot_loss_proj:2.790 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.170 (perp=5.457, rec=0.077, cos=0.001), tot_loss_proj:2.788 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.158 (perp=5.457, rec=0.066, cos=0.001), tot_loss_proj:2.791 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
[1200/2000] tot_loss=1.158 (perp=5.457, rec=0.066, cos=0.001), tot_loss_proj:2.800 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.164 (perp=5.457, rec=0.071, cos=0.001), tot_loss_proj:2.795 [t=0.17s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.154 (perp=5.457, rec=0.061, cos=0.001), tot_loss_proj:2.795 [t=0.19s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
[1350/2000] tot_loss=1.166 (perp=5.457, rec=0.073, cos=0.001), tot_loss_proj:2.799 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.154 (perp=5.457, rec=0.062, cos=0.001), tot_loss_proj:2.804 [t=0.21s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.159 (perp=5.457, rec=0.067, cos=0.001), tot_loss_proj:2.799 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
[1500/2000] tot_loss=1.150 (perp=5.457, rec=0.057, cos=0.001), tot_loss_proj:2.801 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.160 (perp=5.457, rec=0.067, cos=0.001), tot_loss_proj:2.801 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.162 (perp=5.457, rec=0.069, cos=0.001), tot_loss_proj:2.846 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
[1650/2000] tot_loss=1.159 (perp=5.457, rec=0.066, cos=0.001), tot_loss_proj:2.853 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.158 (perp=5.457, rec=0.065, cos=0.001), tot_loss_proj:2.849 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.155 (perp=5.457, rec=0.062, cos=0.001), tot_loss_proj:2.854 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
[1800/2000] tot_loss=1.168 (perp=5.457, rec=0.075, cos=0.001), tot_loss_proj:2.851 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.155 (perp=5.457, rec=0.062, cos=0.001), tot_loss_proj:2.850 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.154 (perp=5.457, rec=0.061, cos=0.001), tot_loss_proj:2.850 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
[1950/2000] tot_loss=1.159 (perp=5.457, rec=0.067, cos=0.001), tot_loss_proj:2.858 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.159 (perp=5.457, rec=0.067, cos=0.001), tot_loss_proj:2.850 [t=0.18s]
prediction: ['[CLS] moment in - there s not a single jump in your seat - - and [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] there your s not a single jump in moment there your seat - - and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.857 | p: 86.667 | r: 100.000
rouge2     | fm: 61.538 | p: 57.143 | r: 66.667
rougeL     | fm: 85.714 | p: 80.000 | r: 92.308
rougeLsum  | fm: 85.714 | p: 80.000 | r: 92.308
r1fm+r2fm = 154.396

[Aggregate metrics]:
rouge1     | fm: 92.702 | p: 92.278 | r: 93.205
rouge2     | fm: 57.313 | p: 57.119 | r: 57.534
rougeL     | fm: 78.687 | p: 78.394 | r: 79.014
rougeLsum  | fm: 78.577 | p: 78.281 | r: 78.992
r1fm+r2fm = 150.015

input #71 time: 0:07:28 | total time: 10:04:30


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9992329827199963
highest_index [0]
highest [0.9992329827199963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7871954441070557 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.756220817565918 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7524415254592896 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7376322150230408 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.736792266368866 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7195456624031067 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7185581922531128 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.7164209485054016 for ['[CLS] except orbitalungen lifeboat dna walking nonetheless support van! pork zone ta reserve accidentally [SEP]']
[Init] best perm rec loss: 0.713283896446228 for ['[CLS] except pork zone! lifeboat nonetheless accidentally ta orbital support walking dnaungen reserve van [SEP]']
[Init] best perm rec loss: 0.7122484445571899 for ['[CLS] porkungen lifeboat support accidentally nonetheless except walking dna reserve ta! zone orbital van [SEP]']
[Init] best perm rec loss: 0.7111414074897766 for ['[CLS] orbital except pork lifeboat! accidentally support reserve walkingungen ta van dna zone nonetheless [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.819 (perp=12.330, rec=0.338, cos=0.016), tot_loss_proj:3.558 [t=0.18s]
prediction: ['[CLS] bad faced homo tough cardbloodman styleism intervened time - fist your an [SEP]']
[ 100/2000] tot_loss=2.293 (perp=10.255, rec=0.233, cos=0.010), tot_loss_proj:3.727 [t=0.18s]
prediction: ['[CLS] has balancing a tough its toughman philosophy off if time its tough philosophy an [SEP]']
[ 150/2000] tot_loss=2.305 (perp=10.208, rec=0.223, cos=0.041), tot_loss_proj:3.711 [t=0.18s]
prediction: ['[CLS] has balancing its tough its tougher philosophy alone bonus time its tough philosophyer [SEP]']
[ 200/2000] tot_loss=2.170 (perp=10.197, rec=0.127, cos=0.003), tot_loss_proj:3.589 [t=0.19s]
prediction: ['[CLS] has balancing its tough its toughfeld philosophy alone if time its violence violenceer [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.017 (perp=9.528, rec=0.108, cos=0.003), tot_loss_proj:3.177 [t=0.18s]
prediction: ['[CLS] has balancing its tough its balancinga philosophy with if its violence violenceer time [SEP]']
[ 300/2000] tot_loss=2.169 (perp=10.381, rec=0.090, cos=0.003), tot_loss_proj:3.592 [t=0.18s]
prediction: ['[CLS] has balancing its tough its balancingfk inspired with if its violence philosophyer time [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.964 (perp=9.380, rec=0.086, cos=0.002), tot_loss_proj:3.190 [t=0.18s]
prediction: ['[CLS] has balancing its tougher balancingfk inspired with if its violence philosophy its time [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.824 (perp=8.652, rec=0.091, cos=0.002), tot_loss_proj:3.346 [t=0.18s]
prediction: ['[CLS] has balancing a tougher balancingfk philosophy with progress its violence inspired its time [SEP]']
[ 450/2000] tot_loss=1.827 (perp=8.652, rec=0.095, cos=0.001), tot_loss_proj:3.355 [t=0.18s]
prediction: ['[CLS] has balancing a tougher balancingfk philosophy with progress its violence inspired its time [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.768 (perp=8.396, rec=0.087, cos=0.002), tot_loss_proj:3.193 [t=0.19s]
prediction: ['[CLS] has balancing a tougher balancingfk philosophy if with its violence inspired its time [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.780 (perp=8.545, rec=0.070, cos=0.002), tot_loss_proj:3.238 [t=0.18s]
prediction: ['[CLS] has balancing a tougherer philosophyfk if with its violence inspired its time [SEP]']
[ 600/2000] tot_loss=1.792 (perp=8.545, rec=0.082, cos=0.001), tot_loss_proj:3.240 [t=0.18s]
prediction: ['[CLS] has balancing a tougherer philosophyfk if with its violence inspired its time [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.727 (perp=8.256, rec=0.075, cos=0.001), tot_loss_proj:2.792 [t=0.18s]
prediction: ['[CLS] has balancing a tougherer philosophyfk with if its violence inspired its time [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.741 (perp=8.315, rec=0.076, cos=0.001), tot_loss_proj:3.047 [t=0.19s]
prediction: ['[CLS] has balancing a tougherer philosophyfk with violence if its inspired its time [SEP]']
[ 750/2000] tot_loss=1.729 (perp=8.315, rec=0.064, cos=0.001), tot_loss_proj:3.050 [t=0.18s]
prediction: ['[CLS] has balancing a tougherer philosophyfk with violence if its inspired its time [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.740 (perp=8.315, rec=0.076, cos=0.001), tot_loss_proj:3.049 [t=0.19s]
prediction: ['[CLS] has balancing a tougherer philosophyfk with violence if its inspired its time [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.624 (perp=7.786, rec=0.065, cos=0.002), tot_loss_proj:2.932 [t=0.19s]
prediction: ['[CLS] hasfk balancing a tougherer philosophy with violence if its inspired its time [SEP]']
[ 900/2000] tot_loss=1.625 (perp=7.786, rec=0.066, cos=0.001), tot_loss_proj:2.934 [t=0.18s]
prediction: ['[CLS] hasfk balancing a tougherer philosophy with violence if its inspired its time [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.631 (perp=7.786, rec=0.073, cos=0.001), tot_loss_proj:2.920 [t=0.19s]
prediction: ['[CLS] hasfk balancing a tougherer philosophy with violence if its inspired its time [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.589 (perp=7.584, rec=0.070, cos=0.002), tot_loss_proj:3.056 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence if its inspired its time [SEP]']
[1050/2000] tot_loss=1.595 (perp=7.584, rec=0.077, cos=0.001), tot_loss_proj:3.057 [t=0.18s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence if its inspired its time [SEP]']
Attempt swap
[1100/2000] tot_loss=1.630 (perp=7.790, rec=0.070, cos=0.001), tot_loss_proj:3.325 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence ( its inspired its time [SEP]']
Attempt swap
[1150/2000] tot_loss=1.719 (perp=8.235, rec=0.071, cos=0.001), tot_loss_proj:3.276 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence ( its inspiredfk time [SEP]']
[1200/2000] tot_loss=1.715 (perp=8.235, rec=0.067, cos=0.001), tot_loss_proj:3.276 [t=0.18s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence ( its inspiredfk time [SEP]']
Attempt swap
[1250/2000] tot_loss=1.726 (perp=8.235, rec=0.077, cos=0.001), tot_loss_proj:3.271 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence ( its inspiredfk time [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.654 (perp=7.910, rec=0.070, cos=0.002), tot_loss_proj:3.159 [t=0.21s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence ( its timefk inspired [SEP]']
[1350/2000] tot_loss=1.660 (perp=7.910, rec=0.077, cos=0.001), tot_loss_proj:3.160 [t=0.18s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence ( its timefk inspired [SEP]']
Attempt swap
[1400/2000] tot_loss=1.657 (perp=7.910, rec=0.074, cos=0.001), tot_loss_proj:3.160 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence ( its timefk inspired [SEP]']
Attempt swap
[1450/2000] tot_loss=1.662 (perp=7.910, rec=0.078, cos=0.001), tot_loss_proj:3.158 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence ( its timefk inspired [SEP]']
[1500/2000] tot_loss=1.652 (perp=7.910, rec=0.068, cos=0.002), tot_loss_proj:3.162 [t=0.20s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with violence ( its timefk inspired [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.647 (perp=7.892, rec=0.067, cos=0.001), tot_loss_proj:3.052 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with its violence ( timefk inspired [SEP]']
Attempt swap
[1600/2000] tot_loss=1.651 (perp=7.892, rec=0.071, cos=0.001), tot_loss_proj:3.051 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with its violence ( timefk inspired [SEP]']
[1650/2000] tot_loss=1.655 (perp=7.892, rec=0.075, cos=0.001), tot_loss_proj:3.053 [t=0.22s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with its violence ( timefk inspired [SEP]']
Attempt swap
[1700/2000] tot_loss=1.650 (perp=7.892, rec=0.070, cos=0.001), tot_loss_proj:3.050 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with its violence ( timefk inspired [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.653 (perp=7.892, rec=0.073, cos=0.002), tot_loss_proj:3.055 [t=0.18s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with its violence ( timefk inspired [SEP]']
[1800/2000] tot_loss=1.766 (perp=8.496, rec=0.065, cos=0.001), tot_loss_proj:3.193 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougha philosophy with its violence ( timefk inspired [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.646 (perp=7.892, rec=0.067, cos=0.001), tot_loss_proj:3.052 [t=0.18s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with its violence ( timefk inspired [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.655 (perp=7.892, rec=0.075, cos=0.002), tot_loss_proj:3.052 [t=0.18s]
prediction: ['[CLS] hasfker balancing a tougher philosophy with its violence ( timefk inspired [SEP]']
[1950/2000] tot_loss=1.774 (perp=8.496, rec=0.073, cos=0.001), tot_loss_proj:3.201 [t=0.19s]
prediction: ['[CLS] hasfker balancing a tougha philosophy with its violence ( timefk inspired [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.656 (perp=7.911, rec=0.073, cos=0.001), tot_loss_proj:2.962 [t=0.18s]
prediction: ['[CLS] hasfka balancing a tougher philosophy with its violence ( timefk inspired [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] hasfker balancing a tougher philosophy with violence ( its inspiredfk time [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 83.333 | r: 76.923
rouge2     | fm: 8.696 | p: 9.091 | r: 8.333
rougeL     | fm: 40.000 | p: 41.667 | r: 38.462
rougeLsum  | fm: 40.000 | p: 41.667 | r: 38.462
r1fm+r2fm = 88.696

[Aggregate metrics]:
rouge1     | fm: 92.552 | p: 92.181 | r: 92.987
rouge2     | fm: 56.630 | p: 56.495 | r: 56.870
rougeL     | fm: 78.075 | p: 77.843 | r: 78.437
rougeLsum  | fm: 78.134 | p: 77.880 | r: 78.520
r1fm+r2fm = 149.181

input #72 time: 0:07:31 | total time: 10:12:01


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9991746597716884
highest_index [0]
highest [0.9991746597716884]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9928975701332092 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9657580256462097 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9560467600822449 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9083574414253235 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.8474614024162292 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 0.8438819646835327 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.115 (perp=9.723, rec=0.165, cos=0.006), tot_loss_proj:2.032 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.013 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.015 (perp=9.723, rec=0.069, cos=0.002), tot_loss_proj:2.015 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.003 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.017 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.022 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.012 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.004 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.016 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=1.999 (perp=9.723, rec=0.053, cos=0.002), tot_loss_proj:1.999 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.011 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.008 [t=0.20s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.007 [t=0.21s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.012 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.004 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=1.997 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:2.018 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.008 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.011 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.003 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.014 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.004 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.996 (perp=9.723, rec=0.050, cos=0.002), tot_loss_proj:2.015 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.001 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.013 (perp=9.723, rec=0.067, cos=0.002), tot_loss_proj:2.011 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.021 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.002 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.011 (perp=9.723, rec=0.065, cos=0.002), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.003 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=1.998 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:2.022 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.015 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.002 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.998 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:2.009 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.017 (perp=9.723, rec=0.070, cos=0.002), tot_loss_proj:1.994 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.014 (perp=9.723, rec=0.068, cos=0.002), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.015 (perp=9.723, rec=0.069, cos=0.002), tot_loss_proj:2.014 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.002 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.016 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.013 (perp=9.723, rec=0.067, cos=0.002), tot_loss_proj:2.007 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.604 | p: 92.256 | r: 93.094
rouge2     | fm: 57.372 | p: 57.237 | r: 57.591
rougeL     | fm: 78.435 | p: 78.188 | r: 78.783
rougeLsum  | fm: 78.393 | p: 78.163 | r: 78.814
r1fm+r2fm = 149.976

input #73 time: 0:07:22 | total time: 10:19:23


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9992591939462341
highest_index [0]
highest [0.9992591939462341]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.0006722211837769 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6869400143623352 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6835439205169678 for ['[CLS] answering [SEP]']
[Init] best rec loss: 0.6572129726409912 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.968 (perp=8.178, rec=0.286, cos=0.047), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.708 (perp=8.178, rec=0.071, cos=0.002), tot_loss_proj:1.793 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.002), tot_loss_proj:1.749 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.710 (perp=8.178, rec=0.073, cos=0.001), tot_loss_proj:1.737 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.710 (perp=8.178, rec=0.072, cos=0.002), tot_loss_proj:1.737 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.681 (perp=8.178, rec=0.044, cos=0.001), tot_loss_proj:1.747 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.714 (perp=8.178, rec=0.077, cos=0.002), tot_loss_proj:1.732 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.684 (perp=8.178, rec=0.047, cos=0.001), tot_loss_proj:1.727 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.692 (perp=8.178, rec=0.055, cos=0.001), tot_loss_proj:1.735 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.737 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.739 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.719 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.717 (perp=8.178, rec=0.080, cos=0.001), tot_loss_proj:1.740 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.733 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.701 (perp=8.178, rec=0.064, cos=0.001), tot_loss_proj:1.743 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.734 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.689 (perp=8.178, rec=0.052, cos=0.001), tot_loss_proj:1.726 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.727 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.730 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.729 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.676 (perp=8.178, rec=0.039, cos=0.001), tot_loss_proj:1.736 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.742 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.733 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.001), tot_loss_proj:1.731 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.688 (perp=8.178, rec=0.051, cos=0.001), tot_loss_proj:1.743 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.702 (perp=8.178, rec=0.065, cos=0.001), tot_loss_proj:1.749 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.001), tot_loss_proj:1.730 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.744 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.706 (perp=8.178, rec=0.069, cos=0.001), tot_loss_proj:1.743 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.705 (perp=8.178, rec=0.068, cos=0.001), tot_loss_proj:1.739 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.736 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.711 (perp=8.178, rec=0.074, cos=0.001), tot_loss_proj:1.744 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.751 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.737 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.705 (perp=8.178, rec=0.068, cos=0.001), tot_loss_proj:1.738 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.001), tot_loss_proj:1.742 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.691 (perp=8.178, rec=0.054, cos=0.001), tot_loss_proj:1.731 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.690 (perp=8.178, rec=0.053, cos=0.001), tot_loss_proj:1.741 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.001), tot_loss_proj:1.739 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.736 | p: 92.379 | r: 93.178
rouge2     | fm: 57.902 | p: 57.709 | r: 58.119
rougeL     | fm: 78.751 | p: 78.459 | r: 79.074
rougeLsum  | fm: 78.764 | p: 78.483 | r: 79.129
r1fm+r2fm = 150.638

input #74 time: 0:07:15 | total time: 10:26:39


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9993458403755586
highest_index [0]
highest [0.9993458403755586]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9583500623703003 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.9476472735404968 for ['[CLS] changed door covert obviously tone sinclair final hard eventdrome apps nick tempo nations diveiii willem nodded rolled [SEP]']
[Init] best rec loss: 0.9449086785316467 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.904586672782898 for ['[CLS] years public during cup months du sources community ind baseman viz together clinton est frog gum firing points prick [SEP]']
[Init] best rec loss: 0.8991710543632507 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 0.8988634347915649 for ['[CLS] gas harbour jobs primarily indy starts smile colorado spirit mach [MASK] academy breakingmetonic ling readerimum millennium [SEP]']
[Init] best rec loss: 0.8913002014160156 for ['[CLS]orin rearview bore nicky yang dynasty confidence hockey preaching mangrove meanllet ventureix resistance constitution sun nicholas piece [SEP]']
[Init] best rec loss: 0.8875274658203125 for ['[CLS] stir will case bills blocked hand miniseries electricchen words tha batting shed az happen women known gen tourist [SEP]']
[Init] best rec loss: 0.8863378167152405 for ['[CLS]thermal howbara single free better coats younger which against goddess portion 2018 octopus managed hu honoraryom compares [SEP]']
[Init] best rec loss: 0.8637418150901794 for ['[CLS]ception resultedrate left fact crown skill apollo auxiliary regardedcl magic to eachmmel viewed stood loop royalties [SEP]']
[Init] best perm rec loss: 0.8630682826042175 for ['[CLS] magic eachrate apollo stood royalties resultedmmel loopcl skill crown fact viewed auxiliary left regardedception to [SEP]']
[Init] best perm rec loss: 0.8622175455093384 for ['[CLS] stood loop crownrate auxiliarymmel left apollo each royalties to magic viewedcl skillception resulted fact regarded [SEP]']
[Init] best perm rec loss: 0.8622075319290161 for ['[CLS]mmel loop royalties regarded fact magic to left apollo stoodcl skill resultedception viewedrate each crown auxiliary [SEP]']
[Init] best perm rec loss: 0.8609483242034912 for ['[CLS]ceptionmmel auxiliary stood fact apollo regarded viewed eachclrate royalties skill magic crown resulted loop to left [SEP]']
[Init] best perm rec loss: 0.8605997562408447 for ['[CLS] resulted skill apollocl to crown stood auxiliary fact each regardedmmelception loop magic royalties viewed leftrate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.115 (perp=13.292, rec=0.425, cos=0.031), tot_loss_proj:4.498 [t=0.18s]
prediction: ['[CLS] whenylusberg the as. mythical reinforced potentialinklesgrants passes reeceano your genuine literarybreak zealand [SEP]']
[ 100/2000] tot_loss=2.620 (perp=11.499, rec=0.307, cos=0.013), tot_loss_proj:4.212 [t=0.18s]
prediction: ['[CLS] whenylusdale the to. instability this focal easily forgotten passes irritation rarely is unnoticed cannot forgotten zealand [SEP]']
[ 150/2000] tot_loss=2.550 (perp=11.547, rec=0.229, cos=0.012), tot_loss_proj:4.217 [t=0.18s]
prediction: ['[CLS] eventually portraits reaper the avoided. instability thisrating not easily dismissed irritation not statement easily or forgottenpersonal [SEP]']
[ 200/2000] tot_loss=2.070 (perp=9.469, rec=0.170, cos=0.006), tot_loss_proj:3.652 [t=0.18s]
prediction: ['[CLS] this dismiss$ theicative. instability this into not easily dismissed irritation is excursion excursion or forgotten. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.079 (perp=9.700, rec=0.135, cos=0.004), tot_loss_proj:3.259 [t=0.18s]
prediction: ['[CLS] this disappear instability epic thisicative instability israting not easily dismissed is not excursion excursion or forgotten. [SEP]']
[ 300/2000] tot_loss=2.178 (perp=10.302, rec=0.115, cos=0.003), tot_loss_proj:3.462 [t=0.18s]
prediction: ['[CLS] this disappear instability epic this efforts instability israting not easily dismissed is not excursion excursion or forgotten, [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.018 (perp=9.568, rec=0.102, cos=0.003), tot_loss_proj:3.442 [t=0.18s]
prediction: ['[CLS] this dismiss into epic this efforts instability this$ not easily dismissed is not excursion excursion or forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.942 (perp=9.176, rec=0.105, cos=0.002), tot_loss_proj:3.616 [t=0.18s]
prediction: ['[CLS] this dismiss excursionenter this efforts instability this mental not easily dismissed is not excursion into or forgotten. [SEP]']
[ 450/2000] tot_loss=1.862 (perp=8.834, rec=0.093, cos=0.002), tot_loss_proj:3.612 [t=0.18s]
prediction: ['[CLS] this dismiss excursionenter this excursion instability this mental not easily dismissed is not excursion into or forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.862 (perp=8.786, rec=0.103, cos=0.002), tot_loss_proj:3.078 [t=0.18s]
prediction: ['[CLS] thistate excursionenter this opportunity not this mental instability easily dismissed is not excursion into or forgotten, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.893 (perp=8.957, rec=0.099, cos=0.002), tot_loss_proj:3.205 [t=0.19s]
prediction: ['[CLS] thesetate excursionenter this opportunity not this mental instability easily dismissed is not excursion into or forgotten, [SEP]']
[ 600/2000] tot_loss=1.987 (perp=9.413, rec=0.102, cos=0.002), tot_loss_proj:3.374 [t=0.19s]
prediction: ['[CLS] thesetate excursionenter this efforts not this mental instability easily dismissed is not excursion into or forgotten, [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.970 (perp=9.359, rec=0.096, cos=0.002), tot_loss_proj:3.723 [t=0.19s]
prediction: ['[CLS] these epictate excursionenter this not into mental instability easily dismissed is. excursion into or forgotten, [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.849 (perp=8.769, rec=0.093, cos=0.002), tot_loss_proj:3.578 [t=0.19s]
prediction: ['[CLS] excursion into epictateenter this not into mental instability easily dismissed is. excursion into or forgotten, [SEP]']
[ 750/2000] tot_loss=1.854 (perp=8.769, rec=0.099, cos=0.002), tot_loss_proj:3.576 [t=0.18s]
prediction: ['[CLS] excursion into epictateenter this not into mental instability easily dismissed is. excursion into or forgotten, [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.778 (perp=8.436, rec=0.089, cos=0.002), tot_loss_proj:3.449 [t=0.19s]
prediction: ['[CLS] excursion into epicenter this not into mental instabilitytate easily dismissed is. excursion into or forgotten, [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.700 (perp=8.011, rec=0.096, cos=0.002), tot_loss_proj:3.386 [t=0.19s]
prediction: ['[CLS] excursion into epicenter this not into mental instability easily dismissed istate. excursion into or forgotten, [SEP]']
[ 900/2000] tot_loss=1.699 (perp=8.011, rec=0.096, cos=0.002), tot_loss_proj:3.384 [t=0.18s]
prediction: ['[CLS] excursion into epicenter this not into mental instability easily dismissed istate. excursion into or forgotten, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.843 (perp=8.786, rec=0.085, cos=0.002), tot_loss_proj:3.601 [t=0.19s]
prediction: ['[CLS]enter into epicenter this not into mental instability easily dismissed istate. excursion into or forgotten, [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.757 (perp=8.380, rec=0.079, cos=0.002), tot_loss_proj:3.491 [t=0.19s]
prediction: ['[CLS]enter into epicenter, not into mental instability easily dismissed istate. excursion into or forgotten this [SEP]']
[1050/2000] tot_loss=1.769 (perp=8.380, rec=0.091, cos=0.002), tot_loss_proj:3.492 [t=0.18s]
prediction: ['[CLS]enter into epicenter, not into mental instability easily dismissed istate. excursion into or forgotten this [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.969 (perp=9.384, rec=0.091, cos=0.002), tot_loss_proj:3.770 [t=0.19s]
prediction: ['[CLS]. dioxide epicenter, not into mental instability easily dismissed isenter. excursion into or forgotten this [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.854 (perp=8.837, rec=0.084, cos=0.002), tot_loss_proj:3.596 [t=0.19s]
prediction: ['[CLS].enter epicenter, not into mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
[1200/2000] tot_loss=1.859 (perp=8.837, rec=0.090, cos=0.002), tot_loss_proj:3.595 [t=0.18s]
prediction: ['[CLS].enter epicenter, not into mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.831 (perp=8.720, rec=0.085, cos=0.002), tot_loss_proj:3.612 [t=0.19s]
prediction: ['[CLS],enter epicenter. not into mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.003 (perp=9.531, rec=0.095, cos=0.002), tot_loss_proj:3.748 [t=0.19s]
prediction: ['[CLS]enter, epicenter wrist not into mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
[1350/2000] tot_loss=1.939 (perp=9.276, rec=0.083, cos=0.002), tot_loss_proj:3.729 [t=0.18s]
prediction: ['[CLS] epic, epicenter wrist not into mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.822 (perp=8.656, rec=0.089, cos=0.002), tot_loss_proj:3.534 [t=0.19s]
prediction: ['[CLS] epic, epicenter not into wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
[1450/2000] tot_loss=1.826 (perp=8.656, rec=0.093, cos=0.002), tot_loss_proj:3.537 [t=0.19s]
prediction: ['[CLS] epic, epicenter not into wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
[1500/2000] tot_loss=1.817 (perp=8.656, rec=0.084, cos=0.002), tot_loss_proj:3.536 [t=0.18s]
prediction: ['[CLS] epic, epicenter not into wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
[1550/2000] tot_loss=1.816 (perp=8.656, rec=0.083, cos=0.002), tot_loss_proj:3.538 [t=0.19s]
prediction: ['[CLS] epic, epicenter not into wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
[1600/2000] tot_loss=1.824 (perp=8.656, rec=0.092, cos=0.002), tot_loss_proj:3.539 [t=0.19s]
prediction: ['[CLS] epic, epicenter not into wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
[1650/2000] tot_loss=1.816 (perp=8.656, rec=0.083, cos=0.002), tot_loss_proj:3.537 [t=0.18s]
prediction: ['[CLS] epic, epicenter not into wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
[1700/2000] tot_loss=1.810 (perp=8.656, rec=0.077, cos=0.002), tot_loss_proj:3.538 [t=0.19s]
prediction: ['[CLS] epic, epicenter not into wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
[1750/2000] tot_loss=1.811 (perp=8.656, rec=0.078, cos=0.002), tot_loss_proj:3.536 [t=0.19s]
prediction: ['[CLS] epic, epicenter not into wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
[1800/2000] tot_loss=1.808 (perp=8.656, rec=0.075, cos=0.002), tot_loss_proj:3.534 [t=0.18s]
prediction: ['[CLS] epic, epicenter not into wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.793 (perp=8.550, rec=0.081, cos=0.002), tot_loss_proj:3.548 [t=0.19s]
prediction: ['[CLS] epic, epicenter into not wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
[1900/2000] tot_loss=1.802 (perp=8.550, rec=0.091, cos=0.002), tot_loss_proj:3.544 [t=0.19s]
prediction: ['[CLS] epic, epicenter into not wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
[1950/2000] tot_loss=1.797 (perp=8.550, rec=0.086, cos=0.002), tot_loss_proj:3.544 [t=0.18s]
prediction: ['[CLS] epic, epicenter into not wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Attempt swap
[2000/2000] tot_loss=1.811 (perp=8.550, rec=0.099, cos=0.002), tot_loss_proj:3.544 [t=0.18s]
prediction: ['[CLS] epic, epicenter into not wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] epic, epicenter into not wrist mental instability easily dismissed is dioxide. excursion into or forgotten this [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 77.778 | r: 82.353
rouge2     | fm: 24.242 | p: 23.529 | r: 25.000
rougeL     | fm: 51.429 | p: 50.000 | r: 52.941
rougeLsum  | fm: 51.429 | p: 50.000 | r: 52.941
r1fm+r2fm = 104.242

[Aggregate metrics]:
rouge1     | fm: 92.568 | p: 92.193 | r: 93.029
rouge2     | fm: 57.393 | p: 57.243 | r: 57.607
rougeL     | fm: 78.308 | p: 78.038 | r: 78.654
rougeLsum  | fm: 78.378 | p: 78.071 | r: 78.767
r1fm+r2fm = 149.962

input #75 time: 0:07:31 | total time: 10:34:10


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9991386602126575
highest_index [0]
highest [0.9991386602126575]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9212543964385986 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.9036272764205933 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 0.8987579345703125 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 0.892052412033081 for ['[CLS] carrie word 38 saying subject window rican disc anatomy awardscles cf past resisted [SEP]']
[Init] best rec loss: 0.8654380440711975 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 0.8489521741867065 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 0.8485825657844543 for ['[CLS] surreal onwardsoning hard ab tauthaw mangoˣ purse left ( pushed backward [SEP]']
[Init] best perm rec loss: 0.8479114174842834 for ['[CLS] purse left hard abˣ backward mango ( surreal tautoning pushed onwardshaw [SEP]']
[Init] best perm rec loss: 0.8466055393218994 for ['[CLS] left mango onwards ( ab hard surreal taut backwardoning purse pushedˣhaw [SEP]']
[Init] best perm rec loss: 0.8464253544807434 for ['[CLS] (haw surreal purse onwards backward hardˣ taut pushedoning mango ab left [SEP]']
[Init] best perm rec loss: 0.846075177192688 for ['[CLS]oning onwards purse left ( taut pushedhaw hard mango backward abˣ surreal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.884 (perp=12.858, rec=0.295, cos=0.017), tot_loss_proj:3.887 [t=0.17s]
prediction: ['[CLS], lloyd presence raw 33 becauselle seems stopped. ¶ stoppedides concluded [SEP]']
[ 100/2000] tot_loss=2.228 (perp=10.118, rec=0.196, cos=0.008), tot_loss_proj:3.365 [t=0.18s]
prediction: ['[CLS], though than allen 18 challengelle has stopped if has stopped challenging as [SEP]']
[ 150/2000] tot_loss=2.248 (perp=10.453, rec=0.153, cos=0.005), tot_loss_proj:3.636 [t=0.18s]
prediction: ['[CLS]. if than allen 66 bachlle has stopped if has stopped challenging into [SEP]']
[ 200/2000] tot_loss=2.072 (perp=9.705, rec=0.128, cos=0.004), tot_loss_proj:3.244 [t=0.18s]
prediction: ['[CLS]. if? allen 66 atlle has stopped if himself stopped challenging into [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.990 (perp=9.333, rec=0.120, cos=0.004), tot_loss_proj:3.087 [t=0.18s]
prediction: ['[CLS]. as allen 66? at allen has stopped if himself stopped challenging 66 [SEP]']
[ 300/2000] tot_loss=1.982 (perp=9.333, rec=0.113, cos=0.003), tot_loss_proj:3.096 [t=0.18s]
prediction: ['[CLS]. as allen 66? at allen has stopped if himself stopped challenging 66 [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.869 (perp=8.823, rec=0.101, cos=0.003), tot_loss_proj:3.062 [t=0.18s]
prediction: ['[CLS]. as allen 66? at has stopped if himself stopped challenging allen 66 [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.781 (perp=8.402, rec=0.098, cos=0.003), tot_loss_proj:2.677 [t=0.19s]
prediction: ['[CLS]. as allen 66 if at has stopped? himself stopped challenging allen 66 [SEP]']
[ 450/2000] tot_loss=1.773 (perp=8.402, rec=0.091, cos=0.002), tot_loss_proj:2.672 [t=0.20s]
prediction: ['[CLS]. as allen 66 if at has stopped? himself stopped challenging allen 66 [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.750 (perp=8.303, rec=0.087, cos=0.002), tot_loss_proj:2.631 [t=0.20s]
prediction: ['[CLS] s as allen 66 if at has stopped. himself stopped challenging allen 66 [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.750 (perp=8.303, rec=0.087, cos=0.002), tot_loss_proj:2.620 [t=0.18s]
prediction: ['[CLS] s as allen 66 if at has stopped. himself stopped challenging allen 66 [SEP]']
[ 600/2000] tot_loss=1.749 (perp=8.303, rec=0.086, cos=0.002), tot_loss_proj:2.619 [t=0.18s]
prediction: ['[CLS] s as allen 66 if at has stopped. himself stopped challenging allen 66 [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.727 (perp=8.211, rec=0.082, cos=0.002), tot_loss_proj:2.592 [t=0.18s]
prediction: ['[CLS] s as allen 66 if at stopped. himself has stopped challenging allen 66 [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.725 (perp=8.211, rec=0.081, cos=0.002), tot_loss_proj:2.591 [t=0.18s]
prediction: ['[CLS] s as allen 66 if at stopped. himself has stopped challenging allen 66 [SEP]']
[ 750/2000] tot_loss=1.736 (perp=8.211, rec=0.092, cos=0.002), tot_loss_proj:2.596 [t=0.18s]
prediction: ['[CLS] s as allen 66 if at stopped. himself has stopped challenging allen 66 [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.733 (perp=8.211, rec=0.089, cos=0.002), tot_loss_proj:2.590 [t=0.18s]
prediction: ['[CLS] s as allen 66 if at stopped. himself has stopped challenging allen 66 [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.725 (perp=8.211, rec=0.081, cos=0.002), tot_loss_proj:2.594 [t=0.18s]
prediction: ['[CLS] s as allen 66 if at stopped. himself has stopped challenging allen 66 [SEP]']
[ 900/2000] tot_loss=1.724 (perp=8.211, rec=0.080, cos=0.002), tot_loss_proj:2.596 [t=0.18s]
prediction: ['[CLS] s as allen 66 if at stopped. himself has stopped challenging allen 66 [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.726 (perp=8.211, rec=0.082, cos=0.002), tot_loss_proj:2.588 [t=0.18s]
prediction: ['[CLS] s as allen 66 if at stopped. himself has stopped challenging allen 66 [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.849 (perp=8.257, rec=0.185, cos=0.013), tot_loss_proj:2.482 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped. himself has stopped challenging allen 66 [SEP]']
[1050/2000] tot_loss=1.780 (perp=8.257, rec=0.124, cos=0.004), tot_loss_proj:2.475 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped. himself has stopped challenging allen 66 [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.742 (perp=8.101, rec=0.119, cos=0.003), tot_loss_proj:2.435 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen himself has stopped challenging. 66 [SEP]']
Attempt swap
[1150/2000] tot_loss=1.722 (perp=8.101, rec=0.099, cos=0.002), tot_loss_proj:2.438 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen himself has stopped challenging. 66 [SEP]']
[1200/2000] tot_loss=1.723 (perp=8.101, rec=0.100, cos=0.002), tot_loss_proj:2.432 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen himself has stopped challenging. 66 [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.677 (perp=7.900, rec=0.095, cos=0.002), tot_loss_proj:2.427 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen himself has stopped challenging 66. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.588 (perp=7.461, rec=0.093, cos=0.002), tot_loss_proj:2.187 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
[1350/2000] tot_loss=1.590 (perp=7.461, rec=0.096, cos=0.002), tot_loss_proj:2.186 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.584 (perp=7.461, rec=0.090, cos=0.002), tot_loss_proj:2.195 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.576 (perp=7.461, rec=0.082, cos=0.002), tot_loss_proj:2.187 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
[1500/2000] tot_loss=1.575 (perp=7.461, rec=0.081, cos=0.002), tot_loss_proj:2.190 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.570 (perp=7.461, rec=0.076, cos=0.002), tot_loss_proj:2.195 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.582 (perp=7.461, rec=0.088, cos=0.002), tot_loss_proj:2.186 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
[1650/2000] tot_loss=1.587 (perp=7.461, rec=0.093, cos=0.002), tot_loss_proj:2.186 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.573 (perp=7.461, rec=0.079, cos=0.002), tot_loss_proj:2.187 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.576 (perp=7.461, rec=0.082, cos=0.002), tot_loss_proj:2.187 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
[1800/2000] tot_loss=1.581 (perp=7.461, rec=0.087, cos=0.002), tot_loss_proj:2.189 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.567 (perp=7.461, rec=0.073, cos=0.002), tot_loss_proj:2.186 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.581 (perp=7.461, rec=0.087, cos=0.002), tot_loss_proj:2.186 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
[1950/2000] tot_loss=1.584 (perp=7.461, rec=0.090, cos=0.002), tot_loss_proj:2.191 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.580 (perp=7.461, rec=0.086, cos=0.002), tot_loss_proj:2.186 [t=0.18s]
prediction: ['[CLS] s 66, as if at stopped allen 66 has stopped challenging himself. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] s as, 66 if at stopped. himself has stopped challenging allen 66 [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 33.333 | p: 30.769 | r: 36.364
rougeL     | fm: 69.231 | p: 64.286 | r: 75.000
rougeLsum  | fm: 69.231 | p: 64.286 | r: 75.000
r1fm+r2fm = 125.641

[Aggregate metrics]:
rouge1     | fm: 92.579 | p: 92.096 | r: 93.165
rouge2     | fm: 57.063 | p: 56.876 | r: 57.305
rougeL     | fm: 78.233 | p: 77.947 | r: 78.621
rougeLsum  | fm: 78.144 | p: 77.832 | r: 78.590
r1fm+r2fm = 149.642

input #76 time: 0:07:26 | total time: 10:41:37


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9992013460879874
highest_index [0]
highest [0.9992013460879874]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.9127402305603027 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8795410990715027 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.8759706020355225 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.8712755441665649 for ['[CLS]yana daylight matthewlson blacksmithdrop county endless rural tel gallery pencil poet something yugoslav [SEP]']
[Init] best perm rec loss: 0.8703407049179077 for ['[CLS] ruraldrop endless yugoslavlson countyyana pencil tel poet something daylight gallery blacksmith matthew [SEP]']
[Init] best perm rec loss: 0.8697276711463928 for ['[CLS] county somethingdropyana gallery rural daylight tellson matthew blacksmith pencil yugoslav endless poet [SEP]']
[Init] best perm rec loss: 0.8681926727294922 for ['[CLS] gallerydrop endless tel matthewyana countylson blacksmith yugoslav rural poet something daylight pencil [SEP]']
[Init] best perm rec loss: 0.8674351572990417 for ['[CLS] pencildrop yugoslav endless something matthew gallery tel ruralyanalson daylight county blacksmith poet [SEP]']
[Init] best perm rec loss: 0.8671553730964661 for ['[CLS] blacksmith countyyana daylight endless yugoslav gallerydrop matthew pencil rural poetlson tel something [SEP]']
[Init] best perm rec loss: 0.8659143447875977 for ['[CLS] poet yugoslav county daylight matthewyanadrop something pencil gallery tel blacksmith endlesslson rural [SEP]']
[Init] best perm rec loss: 0.8652167916297913 for ['[CLS]lson gallery matthewdrop pencil something daylight yugoslav county endless tel rural blacksmith poetyana [SEP]']
[Init] best perm rec loss: 0.8632962107658386 for ['[CLS]yana poet county something matthew blacksmithdrop endless rural pencil tel daylightlson gallery yugoslav [SEP]']
[Init] best perm rec loss: 0.863000750541687 for ['[CLS] poet daylightdrop county something gallery blacksmithlson rural pencil tel yugoslav matthewyana endless [SEP]']
[Init] best perm rec loss: 0.862393856048584 for ['[CLS] poet matthewdrop yugoslav endless galleryyana something countylson tel blacksmith rural pencil daylight [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.855 (perp=12.569, rec=0.325, cos=0.016), tot_loss_proj:3.750 [t=0.18s]
prediction: ['[CLS] bro appeal its heightslad avenue you heavenly beings concept what snake of believe hiding [SEP]']
[ 100/2000] tot_loss=2.104 (perp=9.259, rec=0.243, cos=0.009), tot_loss_proj:2.790 [t=0.19s]
prediction: ['[CLS] bra promise is above make nature that above itself of material promise of believe the [SEP]']
[ 150/2000] tot_loss=2.063 (perp=9.297, rec=0.198, cos=0.006), tot_loss_proj:2.892 [t=0.18s]
prediction: ['[CLS] bra promise is above make promise that above itself of material promise of believe realm [SEP]']
[ 200/2000] tot_loss=2.214 (perp=10.214, rec=0.168, cos=0.004), tot_loss_proj:3.056 [t=0.18s]
prediction: ['[CLS] realm promise is above make life thatars thing of material promise of believe realm [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.124 (perp=9.736, rec=0.171, cos=0.005), tot_loss_proj:2.908 [t=0.18s]
prediction: ['[CLS] realm promise is itself make life thatars above of material promise of believe realm [SEP]']
[ 300/2000] tot_loss=2.102 (perp=9.736, rec=0.150, cos=0.004), tot_loss_proj:2.883 [t=0.18s]
prediction: ['[CLS] realm promise is itself make life thatars above of material promise of believe realm [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.921 (perp=8.791, rec=0.159, cos=0.003), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] promise is its make life thatars above realm of material promise the believe realm [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.755 (perp=8.065, rec=0.138, cos=0.004), tot_loss_proj:2.451 [t=0.18s]
prediction: ['[CLS] promise is its make believe life thatars above realm of material promise the realm [SEP]']
[ 450/2000] tot_loss=1.809 (perp=8.361, rec=0.132, cos=0.005), tot_loss_proj:2.503 [t=0.18s]
prediction: ['[CLS] promise is its make believe life thatars above realm of material promise - realm [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.702 (perp=7.926, rec=0.115, cos=0.002), tot_loss_proj:2.377 [t=0.18s]
prediction: ['[CLS] promise is its make believe life thatars above realm of material realm promise - [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.631 (perp=7.459, rec=0.136, cos=0.004), tot_loss_proj:2.128 [t=0.19s]
prediction: ['[CLS] make promise - is its make believe life thatars above realm of material realm [SEP]']
[ 600/2000] tot_loss=1.595 (perp=7.459, rec=0.101, cos=0.002), tot_loss_proj:2.106 [t=0.19s]
prediction: ['[CLS] make promise - is its make believe life thatars above realm of material realm [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.531 (perp=7.154, rec=0.098, cos=0.002), tot_loss_proj:2.040 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.527 (perp=7.154, rec=0.095, cos=0.002), tot_loss_proj:2.037 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
[ 750/2000] tot_loss=1.531 (perp=7.154, rec=0.098, cos=0.002), tot_loss_proj:2.043 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.519 (perp=7.154, rec=0.086, cos=0.002), tot_loss_proj:2.044 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.528 (perp=7.154, rec=0.095, cos=0.002), tot_loss_proj:2.035 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
[ 900/2000] tot_loss=1.528 (perp=7.154, rec=0.096, cos=0.002), tot_loss_proj:2.034 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.532 (perp=7.154, rec=0.099, cos=0.002), tot_loss_proj:2.002 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.533 (perp=7.154, rec=0.100, cos=0.002), tot_loss_proj:2.035 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
[1050/2000] tot_loss=1.525 (perp=7.154, rec=0.093, cos=0.002), tot_loss_proj:2.031 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.523 (perp=7.154, rec=0.091, cos=0.002), tot_loss_proj:2.024 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.524 (perp=7.154, rec=0.091, cos=0.002), tot_loss_proj:2.038 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
[1200/2000] tot_loss=1.532 (perp=7.154, rec=0.100, cos=0.002), tot_loss_proj:2.032 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.525 (perp=7.154, rec=0.092, cos=0.002), tot_loss_proj:2.034 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.526 (perp=7.154, rec=0.094, cos=0.002), tot_loss_proj:1.997 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
[1350/2000] tot_loss=1.527 (perp=7.154, rec=0.095, cos=0.002), tot_loss_proj:2.000 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.525 (perp=7.154, rec=0.093, cos=0.002), tot_loss_proj:2.009 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.523 (perp=7.154, rec=0.090, cos=0.002), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
[1500/2000] tot_loss=1.528 (perp=7.154, rec=0.095, cos=0.002), tot_loss_proj:2.001 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.518 (perp=7.154, rec=0.085, cos=0.002), tot_loss_proj:2.001 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.513 (perp=7.154, rec=0.081, cos=0.002), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
[1650/2000] tot_loss=1.518 (perp=7.154, rec=0.086, cos=0.002), tot_loss_proj:2.006 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.515 (perp=7.154, rec=0.082, cos=0.002), tot_loss_proj:2.002 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.518 (perp=7.154, rec=0.086, cos=0.002), tot_loss_proj:2.000 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
[1800/2000] tot_loss=1.513 (perp=7.154, rec=0.080, cos=0.002), tot_loss_proj:2.001 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.527 (perp=7.154, rec=0.094, cos=0.002), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.520 (perp=7.154, rec=0.088, cos=0.002), tot_loss_proj:2.009 [t=0.18s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
[1950/2000] tot_loss=1.520 (perp=7.154, rec=0.088, cos=0.002), tot_loss_proj:2.002 [t=0.19s]
prediction: ['[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.508 (perp=7.061, rec=0.094, cos=0.002), tot_loss_proj:2.141 [t=0.18s]
prediction: ['[CLS] make promise is its make believe lifears above that realm of material realm - [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] make promise is its make believe life thatars above realm of material realm - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 35.714 | p: 35.714 | r: 35.714
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 115.714

[Aggregate metrics]:
rouge1     | fm: 92.446 | p: 91.988 | r: 92.991
rouge2     | fm: 56.874 | p: 56.714 | r: 57.100
rougeL     | fm: 78.020 | p: 77.668 | r: 78.439
rougeLsum  | fm: 78.007 | p: 77.669 | r: 78.450
r1fm+r2fm = 149.320

input #77 time: 0:07:42 | total time: 10:49:19


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9992696483604169
highest_index [0]
highest [0.9992696483604169]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9868218302726746 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9798540472984314 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8532800674438477 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8239110112190247 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.8230682015419006 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.039 (perp=8.972, rec=0.233, cos=0.011), tot_loss_proj:2.715 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 100/2000] tot_loss=1.901 (perp=8.972, rec=0.102, cos=0.005), tot_loss_proj:2.726 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 150/2000] tot_loss=1.885 (perp=8.972, rec=0.087, cos=0.004), tot_loss_proj:2.717 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 200/2000] tot_loss=1.890 (perp=8.972, rec=0.091, cos=0.004), tot_loss_proj:2.727 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.898 (perp=8.972, rec=0.099, cos=0.005), tot_loss_proj:2.722 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 300/2000] tot_loss=1.894 (perp=8.972, rec=0.096, cos=0.004), tot_loss_proj:2.725 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.892 (perp=8.972, rec=0.094, cos=0.003), tot_loss_proj:2.724 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.886 (perp=8.972, rec=0.087, cos=0.004), tot_loss_proj:2.726 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 450/2000] tot_loss=1.888 (perp=8.972, rec=0.090, cos=0.004), tot_loss_proj:2.732 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.885 (perp=8.972, rec=0.088, cos=0.003), tot_loss_proj:2.729 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.880 (perp=8.972, rec=0.083, cos=0.002), tot_loss_proj:2.721 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 600/2000] tot_loss=2.222 (perp=10.782, rec=0.064, cos=0.001), tot_loss_proj:2.977 [t=0.18s]
prediction: ['[CLS] exit theater the [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.645 (perp=7.958, rec=0.052, cos=0.001), tot_loss_proj:1.689 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.685 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.685 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.696 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.690 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.684 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.665 (perp=7.958, rec=0.072, cos=0.001), tot_loss_proj:1.695 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.636 (perp=7.958, rec=0.043, cos=0.001), tot_loss_proj:1.688 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.641 (perp=7.958, rec=0.048, cos=0.001), tot_loss_proj:1.677 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.669 (perp=7.958, rec=0.076, cos=0.001), tot_loss_proj:1.684 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.656 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.672 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.646 (perp=7.958, rec=0.053, cos=0.001), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.687 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.655 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.684 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.677 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.667 (perp=7.958, rec=0.074, cos=0.001), tot_loss_proj:1.696 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.655 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.689 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.646 (perp=7.958, rec=0.053, cos=0.001), tot_loss_proj:1.690 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.681 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.646 (perp=7.958, rec=0.053, cos=0.001), tot_loss_proj:1.694 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.645 (perp=7.958, rec=0.052, cos=0.001), tot_loss_proj:1.684 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.674 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.670 (perp=7.958, rec=0.077, cos=0.001), tot_loss_proj:1.677 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.685 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.651 (perp=7.958, rec=0.058, cos=0.001), tot_loss_proj:1.685 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.666 (perp=7.958, rec=0.073, cos=0.001), tot_loss_proj:1.689 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.642 (perp=7.958, rec=0.049, cos=0.001), tot_loss_proj:1.692 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.477 | p: 92.041 | r: 93.049
rouge2     | fm: 57.391 | p: 57.199 | r: 57.677
rougeL     | fm: 78.379 | p: 78.063 | r: 78.804
rougeLsum  | fm: 78.446 | p: 78.123 | r: 78.843
r1fm+r2fm = 149.868

input #78 time: 0:07:17 | total time: 10:56:37


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.9993343381444821
highest_index [0]
highest [0.9993343381444821]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.97676020860672 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.8503931164741516 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.8493977189064026 for ['[CLS]rna into [SEP]']
[Init] best rec loss: 0.8459595441818237 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.8386962413787842 for ['[CLS] funslow [SEP]']
[Init] best rec loss: 0.8356737494468689 for ['[CLS] gray should [SEP]']
[Init] best rec loss: 0.8324992060661316 for ['[CLS] comte sculptor [SEP]']
[Init] best perm rec loss: 0.8268929123878479 for ['[CLS] sculptor comte [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.480 (perp=11.428, rec=0.191, cos=0.004), tot_loss_proj:2.629 [t=0.18s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.444 (perp=11.428, rec=0.155, cos=0.004), tot_loss_proj:2.616 [t=0.18s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=1.817 (perp=8.695, rec=0.077, cos=0.001), tot_loss_proj:1.969 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[ 200/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.967 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.970 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.972 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.795 (perp=8.695, rec=0.054, cos=0.001), tot_loss_proj:1.967 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.972 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.802 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.974 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.803 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.969 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.972 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.967 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.966 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.814 (perp=8.695, rec=0.074, cos=0.001), tot_loss_proj:1.965 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.957 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.956 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.802 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.969 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.964 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.816 (perp=8.695, rec=0.076, cos=0.001), tot_loss_proj:1.963 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.955 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.814 (perp=8.695, rec=0.074, cos=0.001), tot_loss_proj:1.964 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.812 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.967 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.959 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.808 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.964 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.799 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.959 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.812 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.962 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.968 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.812 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.961 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.787 (perp=8.695, rec=0.047, cos=0.001), tot_loss_proj:1.954 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.954 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.808 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.952 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.797 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.968 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.971 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.961 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.950 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.811 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.961 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.799 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.957 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.794 (perp=8.695, rec=0.054, cos=0.001), tot_loss_proj:1.961 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.809 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.958 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.964 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.552 | p: 92.135 | r: 93.102
rouge2     | fm: 56.763 | p: 56.590 | r: 56.990
rougeL     | fm: 78.328 | p: 78.056 | r: 78.698
rougeLsum  | fm: 78.324 | p: 77.980 | r: 78.722
r1fm+r2fm = 149.314

input #79 time: 0:07:23 | total time: 11:04:00


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9992812106805644
highest_index [0]
highest [0.9992812106805644]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9617707133293152 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9375922083854675 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.9287824034690857 for ['[CLS]down frasercake court beta [SEP]']
[Init] best rec loss: 0.9259979724884033 for ['[CLS] western area whilepres took [SEP]']
[Init] best rec loss: 0.9242680668830872 for ['[CLS] close blonde form parks pussy [SEP]']
[Init] best rec loss: 0.9182730913162231 for ["[CLS]'incense kraft it jubilee [SEP]"]
[Init] best perm rec loss: 0.9177989959716797 for ["[CLS] jubilee incense'kraft it [SEP]"]
[Init] best perm rec loss: 0.9138138294219971 for ["[CLS] jubilee'kraft it incense [SEP]"]
[Init] best perm rec loss: 0.913648784160614 for ["[CLS] incense it'jubilee kraft [SEP]"]
[Init] best perm rec loss: 0.9132492542266846 for ["[CLS] kraft jubilee it incense'[SEP]"]
[Init] best perm rec loss: 0.9125822186470032 for ["[CLS] it incense kraft jubilee'[SEP]"]
[Init] best perm rec loss: 0.9123266935348511 for ["[CLS] kraft it'incense jubilee [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=3.292 (perp=14.953, rec=0.294, cos=0.008), tot_loss_proj:4.175 [t=0.22s]
prediction: ['[CLS] practical able truezed inward [SEP]']
[ 100/2000] tot_loss=2.115 (perp=9.607, rec=0.190, cos=0.004), tot_loss_proj:3.311 [t=0.18s]
prediction: ['[CLS] wisezenzenzenzen [SEP]']
[ 150/2000] tot_loss=1.851 (perp=8.513, rec=0.146, cos=0.002), tot_loss_proj:2.553 [t=0.18s]
prediction: ['[CLS] wisezen wiedzen [SEP]']
[ 200/2000] tot_loss=2.291 (perp=11.018, rec=0.085, cos=0.002), tot_loss_proj:3.270 [t=0.18s]
prediction: ['[CLS] wisezen wieded [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.392 (perp=6.600, rec=0.071, cos=0.001), tot_loss_proj:1.385 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 300/2000] tot_loss=1.387 (perp=6.600, rec=0.065, cos=0.001), tot_loss_proj:1.385 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.387 (perp=6.600, rec=0.065, cos=0.001), tot_loss_proj:1.387 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.378 (perp=6.600, rec=0.057, cos=0.001), tot_loss_proj:1.390 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 450/2000] tot_loss=1.382 (perp=6.600, rec=0.061, cos=0.001), tot_loss_proj:1.383 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.378 (perp=6.600, rec=0.057, cos=0.001), tot_loss_proj:1.390 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.391 (perp=6.600, rec=0.069, cos=0.001), tot_loss_proj:1.387 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 600/2000] tot_loss=1.386 (perp=6.600, rec=0.065, cos=0.001), tot_loss_proj:1.392 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.386 (perp=6.600, rec=0.065, cos=0.001), tot_loss_proj:1.391 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.389 (perp=6.600, rec=0.067, cos=0.001), tot_loss_proj:1.387 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 750/2000] tot_loss=1.385 (perp=6.600, rec=0.064, cos=0.001), tot_loss_proj:1.376 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.387 (perp=6.600, rec=0.066, cos=0.001), tot_loss_proj:1.394 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.377 (perp=6.600, rec=0.055, cos=0.001), tot_loss_proj:1.380 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 900/2000] tot_loss=1.388 (perp=6.600, rec=0.067, cos=0.001), tot_loss_proj:1.401 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.372 (perp=6.600, rec=0.050, cos=0.001), tot_loss_proj:1.382 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1000/2000] tot_loss=1.380 (perp=6.600, rec=0.058, cos=0.001), tot_loss_proj:1.399 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[1050/2000] tot_loss=1.381 (perp=6.600, rec=0.060, cos=0.001), tot_loss_proj:1.386 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1100/2000] tot_loss=1.378 (perp=6.600, rec=0.057, cos=0.001), tot_loss_proj:1.387 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1150/2000] tot_loss=1.386 (perp=6.600, rec=0.065, cos=0.001), tot_loss_proj:1.397 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[1200/2000] tot_loss=1.378 (perp=6.600, rec=0.057, cos=0.001), tot_loss_proj:1.386 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1250/2000] tot_loss=1.379 (perp=6.600, rec=0.057, cos=0.001), tot_loss_proj:1.383 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1300/2000] tot_loss=1.388 (perp=6.600, rec=0.066, cos=0.001), tot_loss_proj:1.387 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[1350/2000] tot_loss=1.385 (perp=6.600, rec=0.063, cos=0.001), tot_loss_proj:1.382 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1400/2000] tot_loss=1.385 (perp=6.600, rec=0.064, cos=0.001), tot_loss_proj:1.387 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1450/2000] tot_loss=1.390 (perp=6.600, rec=0.068, cos=0.001), tot_loss_proj:1.386 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[1500/2000] tot_loss=1.380 (perp=6.600, rec=0.059, cos=0.001), tot_loss_proj:1.394 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1550/2000] tot_loss=1.378 (perp=6.600, rec=0.057, cos=0.001), tot_loss_proj:1.387 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1600/2000] tot_loss=1.381 (perp=6.600, rec=0.060, cos=0.001), tot_loss_proj:1.383 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[1650/2000] tot_loss=1.378 (perp=6.600, rec=0.057, cos=0.001), tot_loss_proj:1.392 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1700/2000] tot_loss=1.376 (perp=6.600, rec=0.054, cos=0.001), tot_loss_proj:1.386 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1750/2000] tot_loss=1.377 (perp=6.600, rec=0.056, cos=0.001), tot_loss_proj:1.388 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[1800/2000] tot_loss=1.389 (perp=6.600, rec=0.067, cos=0.001), tot_loss_proj:1.390 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1850/2000] tot_loss=1.388 (perp=6.600, rec=0.066, cos=0.001), tot_loss_proj:1.390 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1900/2000] tot_loss=1.392 (perp=6.600, rec=0.071, cos=0.001), tot_loss_proj:1.384 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[1950/2000] tot_loss=1.387 (perp=6.600, rec=0.066, cos=0.001), tot_loss_proj:1.387 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[2000/2000] tot_loss=1.384 (perp=6.600, rec=0.063, cos=0.001), tot_loss_proj:1.390 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise, wizened [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.662 | p: 92.238 | r: 93.197
rouge2     | fm: 57.154 | p: 56.997 | r: 57.420
rougeL     | fm: 78.603 | p: 78.296 | r: 79.008
rougeLsum  | fm: 78.459 | p: 78.116 | r: 78.867
r1fm+r2fm = 149.816

input #80 time: 0:07:25 | total time: 11:11:25


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9992879299948307
highest_index [0]
highest [0.9992879299948307]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9063941836357117 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.85554039478302 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8432484865188599 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8243643641471863 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8131975531578064 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8085715174674988 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 0.794321596622467 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 0.790020227432251 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 0.7895707488059998 for ['[CLS] ivy proceededplate donaldsondownvik [SEP]']
[Init] best perm rec loss: 0.7880122065544128 for ['[CLS]down ivyvik proceeded donaldsonplate [SEP]']
[Init] best perm rec loss: 0.786943256855011 for ['[CLS] ivy donaldson proceededvikplatedown [SEP]']
[Init] best perm rec loss: 0.7865198850631714 for ['[CLS]vik ivy donaldsondown proceededplate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.778 (perp=11.891, rec=0.370, cos=0.030), tot_loss_proj:4.031 [t=0.18s]
prediction: ['[CLS] is impressive poor impressive narrowed not [SEP]']
[ 100/2000] tot_loss=2.385 (perp=10.592, rec=0.251, cos=0.016), tot_loss_proj:3.394 [t=0.18s]
prediction: ['[CLS] developed is not impressive least not [SEP]']
[ 150/2000] tot_loss=2.237 (perp=10.290, rec=0.172, cos=0.007), tot_loss_proj:2.804 [t=0.18s]
prediction: ['[CLS] developed is not impressive most player [SEP]']
[ 200/2000] tot_loss=1.974 (perp=9.168, rec=0.135, cos=0.005), tot_loss_proj:2.564 [t=0.18s]
prediction: ['[CLS] simply is not impressive most player [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.377 (perp=11.194, rec=0.131, cos=0.007), tot_loss_proj:2.916 [t=0.18s]
prediction: ['[CLS] scheduled is not most impressive player [SEP]']
[ 300/2000] tot_loss=2.340 (perp=11.194, rec=0.096, cos=0.004), tot_loss_proj:2.907 [t=0.18s]
prediction: ['[CLS] scheduled is not most impressive player [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.804 (perp=8.505, rec=0.099, cos=0.004), tot_loss_proj:2.306 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.791 (perp=8.505, rec=0.087, cos=0.004), tot_loss_proj:2.300 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
[ 450/2000] tot_loss=1.800 (perp=8.505, rec=0.096, cos=0.004), tot_loss_proj:2.316 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.799 (perp=8.505, rec=0.095, cos=0.004), tot_loss_proj:2.306 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.807 (perp=8.505, rec=0.103, cos=0.004), tot_loss_proj:2.304 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
[ 600/2000] tot_loss=1.796 (perp=8.505, rec=0.091, cos=0.004), tot_loss_proj:2.304 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.791 (perp=8.505, rec=0.087, cos=0.004), tot_loss_proj:2.311 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.797 (perp=8.505, rec=0.093, cos=0.003), tot_loss_proj:2.303 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
[ 750/2000] tot_loss=1.791 (perp=8.505, rec=0.086, cos=0.003), tot_loss_proj:2.309 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.793 (perp=8.505, rec=0.089, cos=0.003), tot_loss_proj:2.310 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.797 (perp=8.505, rec=0.092, cos=0.003), tot_loss_proj:2.304 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
[ 900/2000] tot_loss=1.791 (perp=8.505, rec=0.086, cos=0.003), tot_loss_proj:2.303 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.793 (perp=8.505, rec=0.089, cos=0.003), tot_loss_proj:2.306 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.794 (perp=8.505, rec=0.090, cos=0.003), tot_loss_proj:2.311 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
[1050/2000] tot_loss=1.794 (perp=8.505, rec=0.089, cos=0.003), tot_loss_proj:2.309 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.791 (perp=8.505, rec=0.087, cos=0.003), tot_loss_proj:2.306 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.789 (perp=8.505, rec=0.084, cos=0.003), tot_loss_proj:2.307 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
[1200/2000] tot_loss=1.789 (perp=8.505, rec=0.085, cos=0.003), tot_loss_proj:2.313 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.783 (perp=8.505, rec=0.079, cos=0.003), tot_loss_proj:2.311 [t=0.18s]
prediction: ['[CLS] is not most impressive scheduled player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.755 (perp=8.305, rec=0.091, cos=0.003), tot_loss_proj:2.379 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
[1350/2000] tot_loss=1.750 (perp=8.305, rec=0.085, cos=0.003), tot_loss_proj:2.373 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.744 (perp=8.305, rec=0.079, cos=0.003), tot_loss_proj:2.370 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.755 (perp=8.305, rec=0.090, cos=0.003), tot_loss_proj:2.383 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
[1500/2000] tot_loss=1.751 (perp=8.305, rec=0.087, cos=0.003), tot_loss_proj:2.374 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.756 (perp=8.305, rec=0.091, cos=0.003), tot_loss_proj:2.368 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.751 (perp=8.305, rec=0.086, cos=0.003), tot_loss_proj:2.374 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
[1650/2000] tot_loss=1.742 (perp=8.305, rec=0.078, cos=0.003), tot_loss_proj:2.373 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.753 (perp=8.305, rec=0.089, cos=0.003), tot_loss_proj:2.373 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.747 (perp=8.305, rec=0.083, cos=0.003), tot_loss_proj:2.376 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
[1800/2000] tot_loss=1.755 (perp=8.305, rec=0.090, cos=0.003), tot_loss_proj:2.372 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.754 (perp=8.305, rec=0.090, cos=0.003), tot_loss_proj:2.371 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.741 (perp=8.305, rec=0.077, cos=0.003), tot_loss_proj:2.371 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
[1950/2000] tot_loss=1.756 (perp=8.305, rec=0.091, cos=0.003), tot_loss_proj:2.370 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.751 (perp=8.305, rec=0.087, cos=0.003), tot_loss_proj:2.371 [t=0.18s]
prediction: ['[CLS] is not most impressive proceedings player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not most impressive scheduled player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 144.643

[Aggregate metrics]:
rouge1     | fm: 92.632 | p: 92.221 | r: 93.169
rouge2     | fm: 57.342 | p: 57.164 | r: 57.608
rougeL     | fm: 78.698 | p: 78.372 | r: 79.071
rougeLsum  | fm: 78.619 | p: 78.298 | r: 79.031
r1fm+r2fm = 149.974

input #81 time: 0:07:18 | total time: 11:18:44


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.9992801011451229
highest_index [0]
highest [0.9992801011451229]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.98771733045578 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9761659502983093 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9474851489067078 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9335925579071045 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9326500296592712 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 0.8672366738319397 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.8271898627281189 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8216337561607361 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8212171196937561 for ['[CLS]basket plumage whoeverach respective role recordfur [SEP]']
[Init] best perm rec loss: 0.8198072910308838 for ['[CLS] respectivebasket record plumagefurach role whoever [SEP]']
[Init] best perm rec loss: 0.819161593914032 for ['[CLS] respectiveach whoeverfur role record plumagebasket [SEP]']
[Init] best perm rec loss: 0.81831294298172 for ['[CLS]fur respective rolebasketach plumage whoever record [SEP]']
[Init] best perm rec loss: 0.8175076842308044 for ['[CLS] whoeverbasket role respective plumagefurach record [SEP]']
[Init] best perm rec loss: 0.8163747787475586 for ['[CLS]furbasket respective roleach plumage record whoever [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.543 (perp=11.548, rec=0.227, cos=0.006), tot_loss_proj:3.030 [t=0.18s]
prediction: ['[CLS] sloppy undone ary by undone script unanimous [SEP]']
[ 100/2000] tot_loss=2.290 (perp=10.927, rec=0.103, cos=0.002), tot_loss_proj:2.698 [t=0.18s]
prediction: ["[CLS] sloppy undone s'by sloppy script it [SEP]"]
[ 150/2000] tot_loss=2.269 (perp=10.927, rec=0.082, cos=0.002), tot_loss_proj:2.694 [t=0.18s]
prediction: ["[CLS] sloppy undone s'by sloppy script it [SEP]"]
[ 200/2000] tot_loss=2.266 (perp=10.927, rec=0.079, cos=0.002), tot_loss_proj:2.699 [t=0.18s]
prediction: ["[CLS] sloppy undone s'by sloppy script it [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.988 (perp=9.595, rec=0.067, cos=0.002), tot_loss_proj:2.343 [t=0.18s]
prediction: ['[CLS] sloppy a s undone by sloppy script it [SEP]']
[ 300/2000] tot_loss=1.991 (perp=9.595, rec=0.071, cos=0.001), tot_loss_proj:2.346 [t=0.18s]
prediction: ['[CLS] sloppy a s undone by sloppy script it [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.798 (perp=8.639, rec=0.069, cos=0.001), tot_loss_proj:2.119 [t=0.18s]
prediction: ['[CLS] it sloppy a s undone by sloppy script [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.622 (perp=7.783, rec=0.064, cos=0.002), tot_loss_proj:1.795 [t=0.18s]
prediction: ['[CLS] it sloppy s undone by a sloppy script [SEP]']
[ 450/2000] tot_loss=1.625 (perp=7.783, rec=0.067, cos=0.001), tot_loss_proj:1.800 [t=0.18s]
prediction: ['[CLS] it sloppy s undone by a sloppy script [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.624 (perp=7.783, rec=0.066, cos=0.001), tot_loss_proj:1.805 [t=0.18s]
prediction: ['[CLS] it sloppy s undone by a sloppy script [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.562 (perp=7.465, rec=0.068, cos=0.001), tot_loss_proj:1.636 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 600/2000] tot_loss=1.564 (perp=7.465, rec=0.070, cos=0.001), tot_loss_proj:1.645 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.554 (perp=7.465, rec=0.059, cos=0.001), tot_loss_proj:1.636 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.566 (perp=7.465, rec=0.071, cos=0.001), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 750/2000] tot_loss=1.561 (perp=7.465, rec=0.067, cos=0.001), tot_loss_proj:1.644 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.562 (perp=7.465, rec=0.067, cos=0.001), tot_loss_proj:1.639 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.551 (perp=7.465, rec=0.056, cos=0.001), tot_loss_proj:1.642 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 900/2000] tot_loss=1.555 (perp=7.465, rec=0.060, cos=0.001), tot_loss_proj:1.648 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.558 (perp=7.465, rec=0.064, cos=0.001), tot_loss_proj:1.644 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1000/2000] tot_loss=1.553 (perp=7.465, rec=0.058, cos=0.001), tot_loss_proj:1.643 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1050/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.001), tot_loss_proj:1.647 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1100/2000] tot_loss=1.560 (perp=7.465, rec=0.066, cos=0.001), tot_loss_proj:1.640 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1150/2000] tot_loss=1.563 (perp=7.465, rec=0.068, cos=0.001), tot_loss_proj:1.649 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1200/2000] tot_loss=1.559 (perp=7.465, rec=0.065, cos=0.001), tot_loss_proj:1.638 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1250/2000] tot_loss=1.562 (perp=7.465, rec=0.067, cos=0.001), tot_loss_proj:1.642 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1300/2000] tot_loss=1.561 (perp=7.465, rec=0.066, cos=0.001), tot_loss_proj:1.642 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1350/2000] tot_loss=1.553 (perp=7.465, rec=0.059, cos=0.001), tot_loss_proj:1.637 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1400/2000] tot_loss=1.560 (perp=7.465, rec=0.066, cos=0.001), tot_loss_proj:1.646 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1450/2000] tot_loss=1.559 (perp=7.465, rec=0.065, cos=0.001), tot_loss_proj:1.644 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1500/2000] tot_loss=1.556 (perp=7.465, rec=0.062, cos=0.001), tot_loss_proj:1.646 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1550/2000] tot_loss=1.547 (perp=7.465, rec=0.052, cos=0.001), tot_loss_proj:1.646 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1600/2000] tot_loss=1.558 (perp=7.465, rec=0.063, cos=0.001), tot_loss_proj:1.642 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1650/2000] tot_loss=1.552 (perp=7.465, rec=0.057, cos=0.001), tot_loss_proj:1.648 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1700/2000] tot_loss=1.560 (perp=7.465, rec=0.065, cos=0.001), tot_loss_proj:1.647 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1750/2000] tot_loss=1.559 (perp=7.465, rec=0.065, cos=0.001), tot_loss_proj:1.647 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1800/2000] tot_loss=1.554 (perp=7.465, rec=0.059, cos=0.001), tot_loss_proj:1.649 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1850/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.001), tot_loss_proj:1.637 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1900/2000] tot_loss=1.556 (perp=7.465, rec=0.062, cos=0.001), tot_loss_proj:1.639 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1950/2000] tot_loss=1.555 (perp=7.465, rec=0.061, cos=0.001), tot_loss_proj:1.650 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[2000/2000] tot_loss=1.558 (perp=7.465, rec=0.064, cos=0.001), tot_loss_proj:1.643 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s undone by a sloppy sloppy script [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 94.118 | p: 88.889 | r: 100.000
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 188.854

[Aggregate metrics]:
rouge1     | fm: 92.656 | p: 92.161 | r: 93.269
rouge2     | fm: 57.812 | p: 57.574 | r: 58.088
rougeL     | fm: 78.905 | p: 78.532 | r: 79.365
rougeLsum  | fm: 78.854 | p: 78.507 | r: 79.287
r1fm+r2fm = 150.468

input #82 time: 0:07:19 | total time: 11:26:03


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9992427003793516
highest_index [0]
highest [0.9992427003793516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.9601501822471619 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.9566210508346558 for ['[CLS] consisting hartley lives champions forgotten johnson account integeronal merge [SEP]']
[Init] best rec loss: 0.9550451636314392 for ['[CLS] ben tawork position naked map because sort been season [SEP]']
[Init] best rec loss: 0.9463936686515808 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.887312650680542 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 0.8696892261505127 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8692896366119385 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.8648756146430969 for ['[CLS] original review giggled field floor arid read beckett cecil i [SEP]']
[Init] best rec loss: 0.8604941964149475 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.8593842387199402 for ['[CLS] ut sighed another tex predicted hooper alsoов toes personally [SEP]']
[Init] best rec loss: 0.8368008732795715 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best rec loss: 0.8151112198829651 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.8039038181304932 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
[Init] best perm rec loss: 0.8021044135093689 for ['[CLS] vice neck pitch comprehensive stew follows boys nearly residence envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.607 (perp=11.324, rec=0.315, cos=0.028), tot_loss_proj:3.854 [t=0.18s]
prediction: ['[CLS] consider around growing it first became version grows learn tomorrow [SEP]']
[ 100/2000] tot_loss=2.283 (perp=10.145, rec=0.242, cos=0.013), tot_loss_proj:2.769 [t=0.18s]
prediction: ['[CLS] know understand growing it when gets what grows learn for [SEP]']
[ 150/2000] tot_loss=2.081 (perp=9.536, rec=0.170, cos=0.004), tot_loss_proj:2.842 [t=0.18s]
prediction: ['[CLS] know be when it grows wants what grows learn to [SEP]']
[ 200/2000] tot_loss=1.995 (perp=9.491, rec=0.095, cos=0.002), tot_loss_proj:2.722 [t=0.18s]
prediction: ['[CLS] know be when it grows wants what up grow to [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.674 (perp=7.774, rec=0.116, cos=0.003), tot_loss_proj:2.135 [t=0.18s]
prediction: ['[CLS] know when it grows wants what up grow to be [SEP]']
[ 300/2000] tot_loss=1.647 (perp=7.774, rec=0.090, cos=0.002), tot_loss_proj:2.136 [t=0.18s]
prediction: ['[CLS] know when it grows wants what up grow to be [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.466 (perp=6.905, rec=0.083, cos=0.002), tot_loss_proj:2.001 [t=0.18s]
prediction: ['[CLS] know when it wants what grows up grow to be [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.346 (perp=6.308, rec=0.082, cos=0.002), tot_loss_proj:1.879 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up grow [SEP]']
[ 450/2000] tot_loss=1.342 (perp=6.308, rec=0.079, cos=0.002), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up grow [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.336 (perp=6.281, rec=0.078, cos=0.002), tot_loss_proj:1.884 [t=0.18s]
prediction: ['[CLS] know when it wants to be grow what grows up [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.331 (perp=6.281, rec=0.073, cos=0.002), tot_loss_proj:1.880 [t=0.18s]
prediction: ['[CLS] know when it wants to be grow what grows up [SEP]']
[ 600/2000] tot_loss=1.337 (perp=6.281, rec=0.079, cos=0.002), tot_loss_proj:1.884 [t=0.18s]
prediction: ['[CLS] know when it wants to be grow what grows up [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.334 (perp=6.281, rec=0.076, cos=0.002), tot_loss_proj:1.876 [t=0.18s]
prediction: ['[CLS] know when it wants to be grow what grows up [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.327 (perp=6.281, rec=0.069, cos=0.002), tot_loss_proj:1.879 [t=0.18s]
prediction: ['[CLS] know when it wants to be grow what grows up [SEP]']
[ 750/2000] tot_loss=1.333 (perp=6.281, rec=0.075, cos=0.002), tot_loss_proj:1.870 [t=0.18s]
prediction: ['[CLS] know when it wants to be grow what grows up [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.325 (perp=6.281, rec=0.068, cos=0.002), tot_loss_proj:1.875 [t=0.18s]
prediction: ['[CLS] know when it wants to be grow what grows up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.319 (perp=6.281, rec=0.061, cos=0.002), tot_loss_proj:1.880 [t=0.18s]
prediction: ['[CLS] know when it wants to be grow what grows up [SEP]']
[ 900/2000] tot_loss=1.242 (perp=5.854, rec=0.070, cos=0.002), tot_loss_proj:1.923 [t=0.18s]
prediction: ['[CLS] know when it wants to be getting what grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.235 (perp=5.854, rec=0.062, cos=0.002), tot_loss_proj:1.925 [t=0.18s]
prediction: ['[CLS] know when it wants to be getting what grows up [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.221 (perp=5.750, rec=0.069, cos=0.002), tot_loss_proj:1.879 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
[1050/2000] tot_loss=1.218 (perp=5.750, rec=0.067, cos=0.002), tot_loss_proj:1.883 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.218 (perp=5.750, rec=0.067, cos=0.002), tot_loss_proj:1.877 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.227 (perp=5.750, rec=0.075, cos=0.002), tot_loss_proj:1.876 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
[1200/2000] tot_loss=1.225 (perp=5.750, rec=0.073, cos=0.002), tot_loss_proj:1.876 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.225 (perp=5.750, rec=0.073, cos=0.002), tot_loss_proj:1.878 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.222 (perp=5.750, rec=0.071, cos=0.002), tot_loss_proj:1.886 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
[1350/2000] tot_loss=1.220 (perp=5.750, rec=0.068, cos=0.002), tot_loss_proj:1.875 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.224 (perp=5.750, rec=0.073, cos=0.002), tot_loss_proj:1.872 [t=0.17s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.216 (perp=5.750, rec=0.065, cos=0.002), tot_loss_proj:1.879 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
[1500/2000] tot_loss=1.224 (perp=5.750, rec=0.073, cos=0.002), tot_loss_proj:1.869 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.225 (perp=5.750, rec=0.074, cos=0.002), tot_loss_proj:1.874 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.222 (perp=5.750, rec=0.070, cos=0.002), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
[1650/2000] tot_loss=1.216 (perp=5.750, rec=0.065, cos=0.002), tot_loss_proj:1.880 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.213 (perp=5.750, rec=0.062, cos=0.002), tot_loss_proj:1.870 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.224 (perp=5.750, rec=0.073, cos=0.002), tot_loss_proj:1.876 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
[1800/2000] tot_loss=1.219 (perp=5.750, rec=0.068, cos=0.002), tot_loss_proj:1.873 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.226 (perp=5.750, rec=0.074, cos=0.002), tot_loss_proj:1.869 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.225 (perp=5.750, rec=0.073, cos=0.002), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
[1950/2000] tot_loss=1.219 (perp=5.750, rec=0.068, cos=0.002), tot_loss_proj:1.870 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.218 (perp=5.750, rec=0.066, cos=0.002), tot_loss_proj:1.868 [t=0.18s]
prediction: ['[CLS] know when it wants to be what grows up getting [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know when it wants to be what grows up getting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 54.545 | p: 54.545 | r: 54.545
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 146.212

[Aggregate metrics]:
rouge1     | fm: 92.627 | p: 92.137 | r: 93.250
rouge2     | fm: 57.657 | p: 57.385 | r: 57.997
rougeL     | fm: 78.959 | p: 78.565 | r: 79.345
rougeLsum  | fm: 78.887 | p: 78.506 | r: 79.341
r1fm+r2fm = 150.284

input #83 time: 0:07:17 | total time: 11:33:21


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9991125724774641
highest_index [0]
highest [0.9991125724774641]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9286046624183655 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.9211990833282471 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 0.8995694518089294 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8926138281822205 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 0.8923629522323608 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.8866891264915466 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8839888572692871 for ['[CLS]oglaise catholicur prototype issues cheered [SEP]']
[Init] best rec loss: 0.8611317276954651 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best perm rec loss: 0.8604739904403687 for ['[CLS] sar block is whetherness project dark [SEP]']
[Init] best perm rec loss: 0.8604679703712463 for ['[CLS] block dark sar whether isness project [SEP]']
[Init] best perm rec loss: 0.85843825340271 for ['[CLS] whether sar project block is darkness [SEP]']
[Init] best perm rec loss: 0.8576532006263733 for ['[CLS] whether is block projectness dark sar [SEP]']
[Init] best perm rec loss: 0.8570180535316467 for ['[CLS] sar block project dark is whetherness [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.544 (perp=11.218, rec=0.283, cos=0.017), tot_loss_proj:3.351 [t=0.18s]
prediction: ['[CLS] been lost impossible think think losing people [SEP]']
[ 100/2000] tot_loss=2.076 (perp=9.675, rec=0.135, cos=0.005), tot_loss_proj:2.448 [t=0.18s]
prediction: ['[CLS] have lost people ability think the think [SEP]']
[ 150/2000] tot_loss=1.930 (perp=9.294, rec=0.070, cos=0.002), tot_loss_proj:2.387 [t=0.18s]
prediction: ['[CLS] have lost people ability think the to [SEP]']
[ 200/2000] tot_loss=1.927 (perp=9.294, rec=0.067, cos=0.002), tot_loss_proj:2.393 [t=0.18s]
prediction: ['[CLS] have lost people ability think the to [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.551 (perp=7.383, rec=0.073, cos=0.002), tot_loss_proj:2.075 [t=0.18s]
prediction: ['[CLS] have lost people think the ability to [SEP]']
[ 300/2000] tot_loss=1.554 (perp=7.383, rec=0.076, cos=0.002), tot_loss_proj:2.066 [t=0.18s]
prediction: ['[CLS] have lost people think the ability to [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.281 (perp=6.083, rec=0.063, cos=0.002), tot_loss_proj:1.653 [t=0.18s]
prediction: ['[CLS] have lost people the ability to think [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.010 (perp=4.681, rec=0.072, cos=0.002), tot_loss_proj:1.048 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 450/2000] tot_loss=1.003 (perp=4.681, rec=0.065, cos=0.002), tot_loss_proj:1.045 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 500/2000] tot_loss=0.998 (perp=4.681, rec=0.060, cos=0.002), tot_loss_proj:1.039 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.003 (perp=4.681, rec=0.065, cos=0.002), tot_loss_proj:1.030 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 600/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.040 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.999 (perp=4.681, rec=0.061, cos=0.002), tot_loss_proj:1.032 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.034 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.038 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.043 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.993 (perp=4.681, rec=0.055, cos=0.002), tot_loss_proj:1.048 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.029 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.039 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.004 (perp=4.681, rec=0.066, cos=0.002), tot_loss_proj:1.040 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.049 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.011 (perp=4.681, rec=0.073, cos=0.002), tot_loss_proj:1.049 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=0.998 (perp=4.681, rec=0.060, cos=0.002), tot_loss_proj:1.037 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=0.999 (perp=4.681, rec=0.061, cos=0.002), tot_loss_proj:1.031 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.042 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.006 (perp=4.681, rec=0.068, cos=0.002), tot_loss_proj:1.027 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.041 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=0.996 (perp=4.681, rec=0.058, cos=0.002), tot_loss_proj:1.048 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.003 (perp=4.681, rec=0.065, cos=0.002), tot_loss_proj:1.048 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.050 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=0.992 (perp=4.681, rec=0.054, cos=0.002), tot_loss_proj:1.037 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=0.992 (perp=4.681, rec=0.054, cos=0.002), tot_loss_proj:1.032 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=1.007 (perp=4.681, rec=0.069, cos=0.002), tot_loss_proj:1.040 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.047 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.040 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.047 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=0.991 (perp=4.681, rec=0.053, cos=0.002), tot_loss_proj:1.045 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.011 (perp=4.681, rec=0.073, cos=0.002), tot_loss_proj:1.043 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=1.011 (perp=4.681, rec=0.073, cos=0.002), tot_loss_proj:1.044 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=0.998 (perp=4.681, rec=0.060, cos=0.002), tot_loss_proj:1.046 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.721 | p: 92.271 | r: 93.282
rouge2     | fm: 58.144 | p: 57.903 | r: 58.483
rougeL     | fm: 79.063 | p: 78.744 | r: 79.502
rougeLsum  | fm: 79.091 | p: 78.690 | r: 79.608
r1fm+r2fm = 150.865

input #84 time: 0:07:22 | total time: 11:40:43


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9992374406339235
highest_index [0]
highest [0.9992374406339235]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9699996709823608 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9557927250862122 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.933201789855957 for ['[CLS] creek i instrumental bottomifnotes kensington military kowalski smoky [SEP]']
[Init] best rec loss: 0.8898030519485474 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8735714554786682 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best perm rec loss: 0.8669417500495911 for ['[CLS] indies backgroundleinthing road laps indianrman fallen defender [SEP]']
[Init] best perm rec loss: 0.8647000193595886 for ['[CLS]lein laps roadrman indian background indiesthing defender fallen [SEP]']
[Init] best perm rec loss: 0.8642165064811707 for ['[CLS]rmanlein indies lapsthing fallen defender background road indian [SEP]']
[Init] best perm rec loss: 0.8628117442131042 for ['[CLS] indiesleinthing lapsrman indian defender background fallen road [SEP]']
[Init] best perm rec loss: 0.8601159453392029 for ['[CLS] indieslein fallen road background laps indianthing defenderrman [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.132 (perp=9.073, rec=0.305, cos=0.012), tot_loss_proj:3.285 [t=0.18s]
prediction: ['[CLS] unfortunately not extremely unfortunately unfortunately unfortunately good, good unfortunately [SEP]']
[ 100/2000] tot_loss=1.840 (perp=8.398, rec=0.155, cos=0.006), tot_loss_proj:2.788 [t=0.18s]
prediction: ['[CLS] unfortunately not very unfortunately not also very. good unfortunately [SEP]']
[ 150/2000] tot_loss=1.902 (perp=8.885, rec=0.121, cos=0.004), tot_loss_proj:2.311 [t=0.18s]
prediction: ['[CLS] unfortunately s very unfortunately not also very it good unfortunately [SEP]']
[ 200/2000] tot_loss=1.867 (perp=8.885, rec=0.088, cos=0.002), tot_loss_proj:2.343 [t=0.18s]
prediction: ['[CLS] unfortunately s very unfortunately not also very it good unfortunately [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.591 (perp=7.336, rec=0.120, cos=0.003), tot_loss_proj:2.026 [t=0.18s]
prediction: ["[CLS] unfortunately's unfortunately not also very it good unfortunately [SEP]"]
[ 300/2000] tot_loss=1.574 (perp=7.440, rec=0.084, cos=0.002), tot_loss_proj:2.173 [t=0.18s]
prediction: ["[CLS],'s'not also very it good unfortunately [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.711 (perp=8.062, rec=0.096, cos=0.002), tot_loss_proj:2.220 [t=0.18s]
prediction: ["[CLS] unfortunately,'slike not also very it good [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.489 (perp=7.024, rec=0.082, cos=0.002), tot_loss_proj:2.062 [t=0.18s]
prediction: ["[CLS] unfortunately,'s not also very itlike good [SEP]"]
[ 450/2000] tot_loss=1.495 (perp=7.024, rec=0.088, cos=0.002), tot_loss_proj:2.065 [t=0.17s]
prediction: ["[CLS] unfortunately,'s not also very itlike good [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.342 (perp=6.332, rec=0.073, cos=0.002), tot_loss_proj:1.912 [t=0.19s]
prediction: ["[CLS] unfortunately,'s not also very good itlike [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.304 (perp=6.096, rec=0.083, cos=0.002), tot_loss_proj:1.831 [t=0.19s]
prediction: ["[CLS] unfortunately,'s it not also very goodlike [SEP]"]
[ 600/2000] tot_loss=1.532 (perp=7.228, rec=0.085, cos=0.002), tot_loss_proj:1.982 [t=0.20s]
prediction: ['[CLS] unfortunately,. s it not also very goodlike [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.393 (perp=6.594, rec=0.073, cos=0.002), tot_loss_proj:1.756 [t=0.19s]
prediction: ['[CLS] unfortunately,. it s not also very goodlike [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.186 (perp=5.528, rec=0.078, cos=0.002), tot_loss_proj:1.546 [t=0.18s]
prediction: ['[CLS] unfortunately, it s not also very goodlike. [SEP]']
[ 750/2000] tot_loss=1.185 (perp=5.528, rec=0.077, cos=0.002), tot_loss_proj:1.531 [t=0.19s]
prediction: ['[CLS] unfortunately, it s not also very goodlike. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.164 (perp=5.426, rec=0.077, cos=0.002), tot_loss_proj:1.370 [t=0.19s]
prediction: ['[CLS] unfortunately, it s also not very goodlike. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.156 (perp=5.426, rec=0.069, cos=0.002), tot_loss_proj:1.368 [t=0.17s]
prediction: ['[CLS] unfortunately, it s also not very goodlike. [SEP]']
[ 900/2000] tot_loss=1.157 (perp=5.426, rec=0.070, cos=0.002), tot_loss_proj:1.365 [t=0.19s]
prediction: ['[CLS] unfortunately, it s also not very goodlike. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.176 (perp=5.478, rec=0.078, cos=0.002), tot_loss_proj:1.450 [t=0.19s]
prediction: ['[CLS] unfortunately, it also s not very goodʳ. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.170 (perp=5.478, rec=0.073, cos=0.002), tot_loss_proj:1.453 [t=0.19s]
prediction: ['[CLS] unfortunately, it also s not very goodʳ. [SEP]']
[1050/2000] tot_loss=1.119 (perp=5.309, rec=0.055, cos=0.002), tot_loss_proj:1.413 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.129 (perp=5.309, rec=0.065, cos=0.002), tot_loss_proj:1.415 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.133 (perp=5.309, rec=0.069, cos=0.002), tot_loss_proj:1.420 [t=0.19s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
[1200/2000] tot_loss=1.131 (perp=5.309, rec=0.067, cos=0.002), tot_loss_proj:1.413 [t=0.19s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.129 (perp=5.309, rec=0.065, cos=0.002), tot_loss_proj:1.416 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.119 (perp=5.309, rec=0.055, cos=0.002), tot_loss_proj:1.416 [t=0.20s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
[1350/2000] tot_loss=1.139 (perp=5.309, rec=0.076, cos=0.002), tot_loss_proj:1.421 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.123 (perp=5.309, rec=0.059, cos=0.002), tot_loss_proj:1.415 [t=0.19s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.131 (perp=5.309, rec=0.067, cos=0.002), tot_loss_proj:1.421 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
[1500/2000] tot_loss=1.133 (perp=5.309, rec=0.070, cos=0.002), tot_loss_proj:1.416 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.130 (perp=5.309, rec=0.066, cos=0.002), tot_loss_proj:1.405 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.131 (perp=5.309, rec=0.067, cos=0.002), tot_loss_proj:1.414 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
[1650/2000] tot_loss=1.128 (perp=5.309, rec=0.064, cos=0.002), tot_loss_proj:1.421 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.135 (perp=5.309, rec=0.071, cos=0.002), tot_loss_proj:1.410 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.141 (perp=5.309, rec=0.077, cos=0.002), tot_loss_proj:1.420 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
[1800/2000] tot_loss=1.129 (perp=5.309, rec=0.065, cos=0.002), tot_loss_proj:1.422 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.125 (perp=5.309, rec=0.062, cos=0.002), tot_loss_proj:1.411 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.138 (perp=5.309, rec=0.074, cos=0.002), tot_loss_proj:1.416 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
[1950/2000] tot_loss=1.126 (perp=5.309, rec=0.063, cos=0.002), tot_loss_proj:1.408 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.122 (perp=5.309, rec=0.058, cos=0.002), tot_loss_proj:1.411 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s not very good ®. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, it also s not very good ®. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 162.500

[Aggregate metrics]:
rouge1     | fm: 92.814 | p: 92.355 | r: 93.361
rouge2     | fm: 58.220 | p: 57.969 | r: 58.500
rougeL     | fm: 79.121 | p: 78.803 | r: 79.568
rougeLsum  | fm: 79.202 | p: 78.844 | r: 79.616
r1fm+r2fm = 151.034

input #85 time: 0:07:23 | total time: 11:48:07


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9993327117168653
highest_index [0]
highest [0.9993327117168653]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9209051132202148 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9168149828910828 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 0.8586238026618958 for ['[CLS] len tin signals [SEP]']
[Init] best rec loss: 0.7911268472671509 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.7695991396903992 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.7565065622329712 for ['[CLS] liberated round alright [SEP]']
[Init] best perm rec loss: 0.7532469630241394 for ['[CLS] alright round liberated [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.303 (perp=9.833, rec=0.324, cos=0.013), tot_loss_proj:3.225 [t=0.19s]
prediction: ['[CLS] [SEP] clarity championship [SEP]']
[ 100/2000] tot_loss=2.398 (perp=11.045, rec=0.185, cos=0.004), tot_loss_proj:3.605 [t=0.18s]
prediction: ['[CLS] explosive clarity examinations [SEP]']
[ 150/2000] tot_loss=2.061 (perp=9.574, rec=0.144, cos=0.002), tot_loss_proj:2.261 [t=0.19s]
prediction: ['[CLS] and clarity emotional [SEP]']
[ 200/2000] tot_loss=2.040 (perp=9.574, rec=0.123, cos=0.002), tot_loss_proj:2.252 [t=0.19s]
prediction: ['[CLS] and clarity emotional [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.748 (perp=8.211, rec=0.104, cos=0.002), tot_loss_proj:1.885 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 300/2000] tot_loss=1.735 (perp=8.211, rec=0.091, cos=0.001), tot_loss_proj:1.881 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.725 (perp=8.211, rec=0.081, cos=0.001), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.722 (perp=8.211, rec=0.079, cos=0.001), tot_loss_proj:1.888 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 450/2000] tot_loss=1.717 (perp=8.211, rec=0.073, cos=0.001), tot_loss_proj:1.881 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.713 (perp=8.211, rec=0.069, cos=0.001), tot_loss_proj:1.879 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.707 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.879 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 600/2000] tot_loss=1.707 (perp=8.211, rec=0.064, cos=0.001), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.709 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.873 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.698 (perp=8.211, rec=0.054, cos=0.001), tot_loss_proj:1.881 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=1.714 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.711 (perp=8.211, rec=0.068, cos=0.001), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.711 (perp=8.211, rec=0.067, cos=0.001), tot_loss_proj:1.870 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=1.721 (perp=8.211, rec=0.078, cos=0.001), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.708 (perp=8.211, rec=0.064, cos=0.001), tot_loss_proj:1.882 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.700 (perp=8.211, rec=0.056, cos=0.001), tot_loss_proj:1.882 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=1.696 (perp=8.211, rec=0.053, cos=0.001), tot_loss_proj:1.877 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.701 (perp=8.211, rec=0.057, cos=0.001), tot_loss_proj:1.873 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.702 (perp=8.211, rec=0.059, cos=0.001), tot_loss_proj:1.874 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=1.700 (perp=8.211, rec=0.057, cos=0.001), tot_loss_proj:1.875 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.712 (perp=8.211, rec=0.069, cos=0.001), tot_loss_proj:1.873 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.713 (perp=8.211, rec=0.069, cos=0.001), tot_loss_proj:1.877 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=1.716 (perp=8.211, rec=0.073, cos=0.001), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.712 (perp=8.211, rec=0.068, cos=0.001), tot_loss_proj:1.881 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.707 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.875 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=1.700 (perp=8.211, rec=0.056, cos=0.001), tot_loss_proj:1.873 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.702 (perp=8.211, rec=0.058, cos=0.001), tot_loss_proj:1.878 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.715 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.881 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=1.714 (perp=8.211, rec=0.070, cos=0.001), tot_loss_proj:1.885 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.701 (perp=8.211, rec=0.058, cos=0.001), tot_loss_proj:1.879 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.696 (perp=8.211, rec=0.052, cos=0.001), tot_loss_proj:1.880 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=1.704 (perp=8.211, rec=0.060, cos=0.001), tot_loss_proj:1.877 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.720 (perp=8.211, rec=0.076, cos=0.001), tot_loss_proj:1.871 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.705 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.882 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=1.699 (perp=8.211, rec=0.055, cos=0.001), tot_loss_proj:1.873 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.704 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.880 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.853 | p: 92.363 | r: 93.427
rouge2     | fm: 57.683 | p: 57.442 | r: 57.966
rougeL     | fm: 79.180 | p: 78.838 | r: 79.602
rougeLsum  | fm: 79.171 | p: 78.826 | r: 79.603
r1fm+r2fm = 150.535

input #86 time: 0:07:19 | total time: 11:55:26


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.9992553760665845
highest_index [0]
highest [0.9992553760665845]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.8846666812896729 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7553390860557556 for ['[CLS]minate force [SEP]']
[Init] best rec loss: 0.7130892872810364 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.7034943103790283 for ['[CLS] officer yorker [SEP]']
[Init] best rec loss: 0.6935102939605713 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6770039796829224 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6745697855949402 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.729 (perp=7.258, rec=0.246, cos=0.031), tot_loss_proj:1.523 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 100/2000] tot_loss=1.746 (perp=7.258, rec=0.274, cos=0.020), tot_loss_proj:1.526 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.596 (perp=7.258, rec=0.139, cos=0.005), tot_loss_proj:1.513 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.551 (perp=7.258, rec=0.097, cos=0.002), tot_loss_proj:1.543 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.539 (perp=7.258, rec=0.086, cos=0.002), tot_loss_proj:1.541 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.002), tot_loss_proj:1.542 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.700 (perp=7.258, rec=0.219, cos=0.029), tot_loss_proj:1.540 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.538 (perp=7.258, rec=0.083, cos=0.004), tot_loss_proj:1.531 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.532 (perp=7.258, rec=0.079, cos=0.001), tot_loss_proj:1.541 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.522 (perp=7.258, rec=0.069, cos=0.001), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.533 (perp=7.258, rec=0.080, cos=0.001), tot_loss_proj:1.542 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.526 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.535 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.522 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.537 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.527 (perp=7.258, rec=0.074, cos=0.001), tot_loss_proj:1.528 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.530 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.499 (perp=7.258, rec=0.046, cos=0.001), tot_loss_proj:1.528 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.524 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.527 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.544 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.529 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.536 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.504 (perp=7.258, rec=0.051, cos=0.001), tot_loss_proj:1.539 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.548 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.524 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.509 (perp=7.258, rec=0.056, cos=0.001), tot_loss_proj:1.532 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.527 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.539 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.524 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.497 (perp=7.258, rec=0.044, cos=0.001), tot_loss_proj:1.537 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.509 (perp=7.258, rec=0.056, cos=0.001), tot_loss_proj:1.536 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.527 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.537 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.536 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.514 (perp=7.258, rec=0.061, cos=0.001), tot_loss_proj:1.534 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.530 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.524 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.522 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.526 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.999 | p: 92.557 | r: 93.547
rouge2     | fm: 58.336 | p: 58.050 | r: 58.656
rougeL     | fm: 79.449 | p: 79.148 | r: 79.852
rougeLsum  | fm: 79.468 | p: 79.078 | r: 79.896
r1fm+r2fm = 151.335

input #87 time: 0:07:18 | total time: 12:02:44


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.9992358071326222
highest_index [0]
highest [0.9992358071326222]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9809058904647827 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.944068431854248 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9212347269058228 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.917607307434082 for ['[CLS] signing architectural miss of? tension popbreaker covered versus planning bean single field advanced a lipstickingdon tab shorter dos down luther ki t directors wounded drink people ps animals administrativeari tone geologic international above 18 free dam way software clay [SEP]']
[Init] best rec loss: 0.9161702394485474 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.9086971879005432 for ['[CLS] assistants isbag mighty ll shortagekou subject central printian contract separated eight tick twenties ball how orange victor help fund council key morris lace weight vacancy hungick equipment her goran dvd business gould sidou rector us g moment freud [SEP]']
[Init] best rec loss: 0.9049574136734009 for ['[CLS] towards scene too tram beetle vice updated being west grips above.olaignment golden gloss hot boundaries slave satellite warm reasons meant chord antagonist now trick migration part pennsylvania julius following embraced center rebound miss together hero bail museum days four rash [SEP]']
[Init] best rec loss: 0.9017528891563416 for ["[CLS]⁺'ship socialist knightlines trapped golden vital rail soil or accepted seasonal behind mall tickets american fallon https word appearedminated break people familiar bornllie serious once wealth are ll protector caterizedest trade masspina berlin flavortine [SEP]"]
[Init] best rec loss: 0.8954169154167175 for ['[CLS] designated engine never pondered harmon programs? mandarin according employees legitimate exchanged as elevated piston exodus won machine aunt hadnbbed insanity allowed home landing [UNK] starting ki! signed close today force immortality nets where reform baronet ) network demi observation spanning [SEP]']
[Init] best perm rec loss: 0.8942180275917053 for ['[CLS] pondered allowed where! aunt never designated starting demi as programs home hadn piston spanning legitimate engine exodusbbed? insanity machine immortality [UNK] reform harmon network elevated nets today according baronet ki exchanged ) signed employees mandarin force close won landing observation [SEP]']
[Init] best perm rec loss: 0.8933555483818054 for ['[CLS] landing signed? ki legitimate network harmon starting demi observation! exchanged where aunt programs exodus insanity ) never today nets pistonbbed mandarin allowed baronet close won [UNK] reform force pondered employees home engine designated as spanning according elevated machine hadn immortality [SEP]']
[Init] best perm rec loss: 0.8925676345825195 for ['[CLS] machine? never immortality exodus landing exchanged! harmon force spanning according as reform [UNK] won where programs auntbbed home employees pondered insanity observation piston today network allowed close ) starting hadn mandarin nets demi elevated legitimate signed engine baronet designated ki [SEP]']
[Init] best perm rec loss: 0.8924002051353455 for ['[CLS] harmon today piston? [UNK] won legitimate machine designated where landing starting allowed demibbed close engine elevated baronet nets ) hadn aunt exchanged never! according employees spanning mandarin insanity exodus immortality signed reform observation as force pondered programs network ki home [SEP]']
[Init] best perm rec loss: 0.8921587467193604 for ['[CLS] allowed hadn legitimate signed piston mandarin exodus reform pondered as observation ) ki engine never network insanitybbed aunt? immortality force demi starting today! where nets machine landing [UNK] home close spanning exchanged designated won employees baronet programs elevated according harmon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.681 (perp=11.812, rec=0.312, cos=0.007), tot_loss_proj:3.489 [t=0.18s]
prediction: ['[CLS] stairs understood appreciate owen marriage joyness love about " its historical love joy [SEP] parlor our smile,! this heritage energy mer need : laws non released understands [UNK]. wonderful payton inner positive wonderful globalpowering emotions pain completely highness [SEP]']
[ 100/2000] tot_loss=2.490 (perp=11.065, rec=0.273, cos=0.005), tot_loss_proj:3.295 [t=0.18s]
prediction: ['[CLS] lovers how understands [SEP] romance thrillness love how the our historical loved [SEP] parlor our endurance [CLS] your our ী things mer ill. silver non we understands informal. wonderful payton the sometimes great andivating thoughts solution completely. [SEP]']
[ 150/2000] tot_loss=2.348 (perp=10.389, rec=0.266, cos=0.004), tot_loss_proj:3.200 [t=0.18s]
prediction: ['[CLS] lovers in understands p romance joyness love how the ourual love n anderson yesterday our history of our ourgical that every ill. black non we understands ways. grand ェ. sometimes grand and driving thoughts inspiration still is [SEP]']
[ 200/2000] tot_loss=2.275 (perp=10.042, rec=0.263, cos=0.004), tot_loss_proj:3.617 [t=0.19s]
prediction: ["[CLS] romancelistic calm p romance joyness romance how and their. wu. anderson raw our romance of our ouricative that daily calm.'t our understands our. grand ェ the daily great those ェ thoughts courage also. [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.934 (perp=8.509, rec=0.230, cos=0.002), tot_loss_proj:3.220 [t=0.18s]
prediction: ['[CLS] romance and calm p romance joys romance how and their. p. anderson days our love. life our of that daily ill.. bearer our understands nothing. grand． the daily grand that ェ thoughts power out. [SEP]']
[ 300/2000] tot_loss=1.988 (perp=8.922, rec=0.202, cos=0.002), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] romance and calm p romance illness romance how and their. p. anderson days our love. living our of that daily ill.. non our understands money of grand． the daily grand that hidden thoughts power own. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.063 (perp=9.302, rec=0.200, cos=0.002), tot_loss_proj:3.467 [t=0.18s]
prediction: ['[CLS] romance your calmness p romance joy romance how and their. p. anderson days our love. living our © that daily ill.. non our understands money. grand． the daily grand thating thoughts might personal. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.983 (perp=8.942, rec=0.193, cos=0.002), tot_loss_proj:3.208 [t=0.18s]
prediction: ['[CLS] ill and calmness p romance joy romance how and their. p. anderson years power love. living our © that everyday ill.. forms our understands space. grand． the daily grand thating lives our personal. [SEP]']
[ 450/2000] tot_loss=1.988 (perp=9.012, rec=0.183, cos=0.002), tot_loss_proj:3.647 [t=0.18s]
prediction: ['[CLS] ill of calmness p romance joy romance how and their and p. anderson fires power history. lives our © that daily ill.. un our understands space. grand ェ the daily grand thating lives our sometimes. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.929 (perp=8.811, rec=0.165, cos=0.002), tot_loss_proj:3.590 [t=0.17s]
prediction: ['[CLS] ill of calmness p romance joy romance how and their and p. anderson face power history. lives ourness that. daily ill. un our understands space. grand ェ the daily grand thating lives our sometimes. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.888 (perp=8.653, rec=0.155, cos=0.002), tot_loss_proj:3.493 [t=0.18s]
prediction: ['[CLS] ill. calmness p romance joy romance how and. and p. anderson room might history. lives ourness that their daily ill. un our understands space. grand ェ the daily grand thating lives ours. [SEP]']
[ 600/2000] tot_loss=1.888 (perp=8.656, rec=0.155, cos=0.002), tot_loss_proj:3.562 [t=0.18s]
prediction: ['[CLS] ill of calmness p romance joy romance how and. and p. anderson room might history. lives ourness that their daily ill. un our understands space. grand ェ the daily grand thating lives ours. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.910 (perp=8.717, rec=0.165, cos=0.002), tot_loss_proj:3.427 [t=0.18s]
prediction: ['[CLS] ill. calmness p romance joy romance how and. and p. andersonness might history. lives our room that their daily ill. un our understandsin. grand ェ the daily grand thating lives our personal. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.872 (perp=8.566, rec=0.157, cos=0.002), tot_loss_proj:3.361 [t=0.19s]
prediction: ['[CLS] ill. calmness p romance joy love how and. and p. andersonness might history. ouring that their daily ill. un lives our understandsin. grand ェ the daily grand thats lives our still. [SEP]']
[ 750/2000] tot_loss=1.853 (perp=8.481, rec=0.155, cos=0.002), tot_loss_proj:3.433 [t=0.19s]
prediction: ['[CLS] ill of calmness p romance joy love how and. and p. andersonness might history. ouring that their daily ill. un lives our understandsin. grand ェ the daily grand thats lives our still. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.827 (perp=8.397, rec=0.147, cos=0.002), tot_loss_proj:3.316 [t=0.18s]
prediction: ['[CLS] ill. calmness p romance un love how and. and p. anderson of might with. ouring that their daily ill. joy lives us understandsin. grand ェ the daily grand thats lives our still. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.757 (perp=8.059, rec=0.144, cos=0.002), tot_loss_proj:3.297 [t=0.18s]
prediction: ['[CLS] ill. calmness p. un love how and romance and p. andersonness might with. ouring that their daily ill. joy lives us understandsin. grand ェ the daily grand thats lives our still. [SEP]']
[ 900/2000] tot_loss=1.831 (perp=8.444, rec=0.141, cos=0.002), tot_loss_proj:3.234 [t=0.19s]
prediction: ['[CLS] ill. calmness p. states love how and romance and p. andersonness might with. our of that of daily ill. joy lives us understandsin. grand ェ the daily grand thats lives our still. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.769 (perp=8.122, rec=0.143, cos=0.002), tot_loss_proj:3.242 [t=0.18s]
prediction: ['[CLS] ill. calmness p. how states love and romance and p. andersonness might with. our of that of daily ill. joy lives us understandsin. grand ェ the daily grand weres lives our still. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.719 (perp=7.883, rec=0.141, cos=0.002), tot_loss_proj:3.203 [t=0.18s]
prediction: ['[CLS] ill. calmness states p. how love and romance and p. anderson of might with. our of that of daily ill. joy lives us understandsin. grand ェ the daily grand weres lives our still. [SEP]']
[1050/2000] tot_loss=1.719 (perp=7.883, rec=0.140, cos=0.002), tot_loss_proj:3.203 [t=0.19s]
prediction: ['[CLS] ill. calmness states p. how love and romance and p. anderson of might with. our of that of daily ill. joy lives us understandsin. grand ェ the daily grand weres lives our still. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.676 (perp=7.676, rec=0.140, cos=0.002), tot_loss_proj:3.210 [t=0.18s]
prediction: ['[CLS] ill. calmness states p. how love and romance and p. anderson of might with. our of that lives daily ill. joy lives us understandsin. grand ェ the daily grand weres of our still. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.689 (perp=7.740, rec=0.139, cos=0.002), tot_loss_proj:3.158 [t=0.18s]
prediction: ['[CLS] ill. calmness states p. how love and romance is p. anderson of might. the of that lives daily ill and joy lives with us understandsin. grand ェ the daily grand weres of our still. [SEP]']
[1200/2000] tot_loss=1.677 (perp=7.704, rec=0.135, cos=0.002), tot_loss_proj:3.129 [t=0.19s]
prediction: ['[CLS] ill. calmness states p. how love and romance is t. anderson of might. the of that lives daily ill. joy lives with us understandsin. grand ェ the daily grand weres of our still. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.642 (perp=7.525, rec=0.135, cos=0.002), tot_loss_proj:3.108 [t=0.18s]
prediction: ['[CLS] ill. calmness states p. how love and romance of t. anderson is might. the of that lives daily ill. joy lives with us understandsin. grand ェ the daily grand weres of our still. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.658 (perp=7.638, rec=0.129, cos=0.002), tot_loss_proj:3.159 [t=0.18s]
prediction: ['[CLS] ill. calmness states p. how love and romance of t. anderson is might. the daily that lives of ill and joy lives with us understandsin. grand ェ the daily grand weres of our [SEP]. [SEP]']
[1350/2000] tot_loss=1.729 (perp=7.945, rec=0.138, cos=0.002), tot_loss_proj:3.213 [t=0.19s]
prediction: ['[CLS] ill. calmness states p. how love and romance of t. anderson is might. the daily that lives limit ill and joy lives with us understandsin. grand ェ the daily grand weres of our [SEP]. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.666 (perp=7.669, rec=0.130, cos=0.002), tot_loss_proj:3.393 [t=0.18s]
prediction: ['[CLS] ill. calmness states p. how love and romance of t. anderson is might. the daily that lives limitin and joy lives with us understands ill. grand ェ the daily grand weres of our [SEP]. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.637 (perp=7.499, rec=0.135, cos=0.002), tot_loss_proj:3.297 [t=0.18s]
prediction: ['[CLS] ill. calmness states p. how love and romance of t. anderson is might. the daily that [SEP]ing ( and joy lives with us understands ill. grand ェ the daily grand weres of our lives. [SEP]']
[1500/2000] tot_loss=1.583 (perp=7.248, rec=0.131, cos=0.002), tot_loss_proj:3.369 [t=0.19s]
prediction: ['[CLS] ill. calmness states p. how love and romance of t. anderson is could. the daily that [SEP]ing ( and joy lives with us understands ill. grand even the daily grand weres of our lives. [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.628 (perp=7.445, rec=0.137, cos=0.002), tot_loss_proj:3.388 [t=0.18s]
prediction: ['[CLS] ill your calmness states p. how love and romance of t. anderson is could. our daily joy us with that [SEP]ing ( and us understands ill. grand even the daily grand weres of our lives. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.544 (perp=7.070, rec=0.128, cos=0.002), tot_loss_proj:3.353 [t=0.18s]
prediction: ['[CLS] ill. calmness states p. how love and romance of t. anderson is could. our daily joy us with that [SEP]ing ( and us understands ill. even the daily grand grand weres of our lives. [SEP]']
[1650/2000] tot_loss=1.607 (perp=7.354, rec=0.134, cos=0.002), tot_loss_proj:3.405 [t=0.19s]
prediction: ['[CLS] ill your calmness un p. how love and romance of t. anderson is could. our daily joy us with that [SEP]ing ( and us understands ill. even the daily grand grand weres of our lives. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.569 (perp=7.165, rec=0.134, cos=0.002), tot_loss_proj:3.403 [t=0.18s]
prediction: ['[CLS] ill your calmness states p. how love and romance of t. anderson that is. our daily joy us with is [SEP]ing ( and us understands ill. even the daily grand grand weres of our lives. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.507 (perp=6.871, rec=0.132, cos=0.002), tot_loss_proj:3.314 [t=0.18s]
prediction: ['[CLS] ill your calmness states p. how love and romance of t. anderson that is. our daily joy is with us [SEP]ing ( and us understands ill. even the daily grand grand weres of our lives. [SEP]']
[1800/2000] tot_loss=1.491 (perp=6.824, rec=0.125, cos=0.001), tot_loss_proj:3.294 [t=0.19s]
prediction: ['[CLS] ill your calmness states p. how love and romance of t. anderson that is. our daily joy is with us stilling ( and us understands ill. even the daily grand grand weres of our lives. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.473 (perp=6.716, rec=0.129, cos=0.002), tot_loss_proj:3.159 [t=0.18s]
prediction: ['[CLS] ill your calmness states p. how love and romance of t. anderson is. our daily joy is with us [SEP]ing ( and us understands that ill. even the daily grand grand weres of our lives. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.487 (perp=6.784, rec=0.129, cos=0.001), tot_loss_proj:3.259 [t=0.18s]
prediction: ['[CLS] ill your calmness states p. how love and romance of t. anderson is. our daily joy is with us [SEP] limit ( and us understands that ill. even the daily grand were grands of our lives. [SEP]']
[1950/2000] tot_loss=1.484 (perp=6.784, rec=0.126, cos=0.001), tot_loss_proj:3.259 [t=0.19s]
prediction: ['[CLS] ill your calmness states p. how love and romance of t. anderson is. our daily joy is with us [SEP] limit ( and us understands that ill. even the daily grand were grands of our lives. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.486 (perp=6.784, rec=0.128, cos=0.002), tot_loss_proj:3.259 [t=0.18s]
prediction: ['[CLS] ill your calmness states p. how love and romance of t. anderson is. our daily joy is with us [SEP] limit ( and us understands that ill. even the daily grand were grands of our lives. [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] ill your calmness states p. how love and romance of t. anderson that is. our daily joy is with us stilling ( and us understands ill. even the daily grand grand weres of our lives. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.757 | p: 58.333 | r: 55.263
rouge2     | fm: 13.889 | p: 14.286 | r: 13.514
rougeL     | fm: 29.730 | p: 30.556 | r: 28.947
rougeLsum  | fm: 29.730 | p: 30.556 | r: 28.947
r1fm+r2fm = 70.646

[Aggregate metrics]:
rouge1     | fm: 92.600 | p: 92.146 | r: 93.130
rouge2     | fm: 57.642 | p: 57.422 | r: 57.988
rougeL     | fm: 78.821 | p: 78.516 | r: 79.249
rougeLsum  | fm: 78.876 | p: 78.538 | r: 79.287
r1fm+r2fm = 150.242

input #88 time: 0:07:33 | total time: 12:10:18


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.9993426143386362
highest_index [0]
highest [0.9993426143386362]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9663888216018677 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9524359107017517 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.9456372857093811 for ['[CLS] lucraction ditch vin vehicle nights filing wholeierusion above myself capacity easter just bowlpath silver campaign urging draw huntersky operation himself plant bolt gin won ours only object [SEP]']
[Init] best rec loss: 0.9341058135032654 for ['[CLS] watt trustingats promisepate weight eight blood happened photograph deaths credited jp wish practicing boysfulfootuded donttemedia broken atomic muttereduating gps leon relatively atari document cutler [SEP]']
[Init] best perm rec loss: 0.933344841003418 for ['[CLS] trusting weight blood boysmediafultte donfoot muttered happenedats atari document practicing photograph eight leon watt cutler gps jp brokenuded credited wish relatively promisepateuating deaths atomic [SEP]']
[Init] best perm rec loss: 0.9307798743247986 for ['[CLS] happenedtte atari promiseats gps leon relatively blood broken weight deathsfootmedia jp wish atomic cutleruating eight watt boys practicing muttereduded document creditedpate donful photograph trusting [SEP]']
[Init] best perm rec loss: 0.9285004734992981 for ['[CLS]ats jp practicing blood trustingmediauating donfulpate promise boysfoot broken happened document relatively weight muttered atomic wish deaths credited photographtte atariuded leon cutler gps watt eight [SEP]']
[Init] best perm rec loss: 0.9245237708091736 for ['[CLS]pate watt weight gpsats eight boys document cutler jptte deathsuating blood trusting atari atomic credited wish donuded mutteredfoot happenedful photograph broken practicingmedia promise relatively leon [SEP]']
[Init] best perm rec loss: 0.9240761399269104 for ['[CLS]foot credited blooduded document atomic promise cutler boysats relatively photographmedia ataripate broken watt gps jp deathsful trustinguating weight don happenedtte practicing eight wish leon muttered [SEP]']
[Init] best perm rec loss: 0.9212810397148132 for ['[CLS] eight documentpateuating deaths blood boys muttered donuded photographfoot relatively broken cutler atomic practicing atari watt jpats happened trusting wish weight credited gpsmedia leonfultte promise [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.649 (perp=11.681, rec=0.301, cos=0.012), tot_loss_proj:3.127 [t=0.18s]
prediction: ['[CLS] none dim base bacteriamaster tactic become vi department fake cover. photo through - - bad specificge cu besides hired device - hiring technical - ) concept behind worse technology [SEP]']
[ 100/2000] tot_loss=2.168 (perp=9.700, rec=0.224, cos=0.005), tot_loss_proj:2.802 [t=0.19s]
prediction: ['[CLS] worse dim worse valuemaster tactic or remix fact tactic cover that picture through it - work talk adept or worse matters constructed - psychology alleged - - ideas of worse ideas [SEP]']
[ 150/2000] tot_loss=2.160 (perp=9.841, rec=0.188, cos=0.005), tot_loss_proj:2.768 [t=0.17s]
prediction: ["[CLS] worsepipe nonexmaster tactic or'fact tactic cover fact picture and additional -imsy yet or worse they constructed - decision active - - ideas of none ideas [SEP]"]
[ 200/2000] tot_loss=2.292 (perp=10.394, rec=0.203, cos=0.010), tot_loss_proj:2.930 [t=0.18s]
prediction: ['[CLS] worsepipe nonexi opener tactic orgre fact to cover fact picture a - theimsy yet or worse yet constructed - constructed coresy - ideas of none ideas [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.059 (perp=9.268, rec=0.202, cos=0.004), tot_loss_proj:2.776 [t=0.19s]
prediction: ['[CLS] worse the nonexi build tactic or thety to cover fact picture the ( aimsy yet or and yet constructed is goal core fact - ideas of none ideas [SEP]']
[ 300/2000] tot_loss=1.975 (perp=9.077, rec=0.157, cos=0.003), tot_loss_proj:2.729 [t=0.18s]
prediction: ['[CLS] worse the nonexi runs tactic or the, to cover fact picture, that aimsy yet or and yet constructed around constructed core where - ideas of none ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.909 (perp=8.839, rec=0.138, cos=0.002), tot_loss_proj:2.735 [t=0.18s]
prediction: ['[CLS] worse the nonexi runs tactic - the, to cover fact picture, that aimsy yet or - yet constructed around constructed core s of ideas - none ideas [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.770 (perp=8.169, rec=0.134, cos=0.002), tot_loss_proj:2.668 [t=0.18s]
prediction: ['[CLS] worse the nonexi core tactic - the - to cover fact picture, that aimsy around or and yet constructed yet constructed core - of ideas - none ideas [SEP]']
[ 450/2000] tot_loss=1.774 (perp=8.239, rec=0.125, cos=0.002), tot_loss_proj:2.631 [t=0.18s]
prediction: ['[CLS] worse the nonexi core tactic - - - to cover fact picture, that aimsy around or - yet core yet constructed core - of ideas - none ideas [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.742 (perp=8.083, rec=0.123, cos=0.002), tot_loss_proj:2.640 [t=0.17s]
prediction: ['[CLS] worse the nonexi is tactic - - - to cover fact picture, that aimsy around or - yet core yet constructed of core - ideas - none ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.634 (perp=7.572, rec=0.117, cos=0.003), tot_loss_proj:2.740 [t=0.18s]
prediction: ['[CLS] worse the nonexi that tactic - - - to cover fact picture, is aimsy around or - yet core yet constructed of core - ideas - - ideas [SEP]']
[ 600/2000] tot_loss=1.542 (perp=7.124, rec=0.115, cos=0.002), tot_loss_proj:2.656 [t=0.18s]
prediction: ['[CLS] worse the nonexi that tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core - ideas - - ideas [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.471 (perp=6.799, rec=0.109, cos=0.002), tot_loss_proj:2.595 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to cover that fact picture - is aimsy around or, yet core, constructed of core - ideas - - ideas [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.470 (perp=6.799, rec=0.108, cos=0.002), tot_loss_proj:2.604 [t=0.19s]
prediction: ['[CLS] worse the nonexi tactic - - - to cover that fact picture - is aimsy around or, yet core, constructed of core - ideas - - ideas [SEP]']
[ 750/2000] tot_loss=1.528 (perp=7.091, rec=0.108, cos=0.002), tot_loss_proj:2.604 [t=0.19s]
prediction: ['[CLS] worse the nonexi tactic - - - to cover that fact picture - is aimsy around or, yet core, constructed of core - ideast - ideas [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.609 (perp=7.508, rec=0.106, cos=0.002), tot_loss_proj:2.560 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to cover that fact picture - is aimsy around or, yet core, constructed of core ideast - nonesten [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.613 (perp=7.508, rec=0.110, cos=0.002), tot_loss_proj:2.557 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to cover that fact picture - is aimsy around or, yet core, constructed of core ideast - nonesten [SEP]']
[ 900/2000] tot_loss=1.590 (perp=7.433, rec=0.102, cos=0.002), tot_loss_proj:2.674 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to cover - fact picture - is aimsy around or, yet core, constructed of core ideast - -sten [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.604 (perp=7.502, rec=0.101, cos=0.002), tot_loss_proj:2.824 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to covert fact picture - is aimsy around or, yet core, constructed of core ideas - -stensten [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.567 (perp=7.285, rec=0.108, cos=0.002), tot_loss_proj:2.632 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to coversten fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
[1050/2000] tot_loss=1.562 (perp=7.285, rec=0.104, cos=0.002), tot_loss_proj:2.635 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to coversten fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.558 (perp=7.285, rec=0.100, cos=0.002), tot_loss_proj:2.634 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to coversten fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.559 (perp=7.285, rec=0.100, cos=0.002), tot_loss_proj:2.631 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to coversten fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
[1200/2000] tot_loss=1.557 (perp=7.285, rec=0.098, cos=0.002), tot_loss_proj:2.636 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to coversten fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.554 (perp=7.285, rec=0.095, cos=0.002), tot_loss_proj:2.632 [t=0.19s]
prediction: ['[CLS] worse the nonexi tactic - - - to coversten fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.556 (perp=7.285, rec=0.098, cos=0.002), tot_loss_proj:2.638 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to coversten fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
[1350/2000] tot_loss=1.554 (perp=7.285, rec=0.096, cos=0.002), tot_loss_proj:2.635 [t=0.19s]
prediction: ['[CLS] worse the nonexi tactic - - - to coversten fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.548 (perp=7.285, rec=0.089, cos=0.002), tot_loss_proj:2.636 [t=0.18s]
prediction: ['[CLS] worse the nonexi tactic - - - to coversten fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.503 (perp=7.001, rec=0.100, cos=0.002), tot_loss_proj:2.407 [t=0.18s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
[1500/2000] tot_loss=1.498 (perp=7.001, rec=0.096, cos=0.002), tot_loss_proj:2.407 [t=0.19s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.498 (perp=7.001, rec=0.096, cos=0.002), tot_loss_proj:2.408 [t=0.19s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.497 (perp=7.001, rec=0.095, cos=0.002), tot_loss_proj:2.407 [t=0.18s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
[1650/2000] tot_loss=1.492 (perp=7.001, rec=0.090, cos=0.002), tot_loss_proj:2.409 [t=0.19s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.494 (perp=7.001, rec=0.092, cos=0.002), tot_loss_proj:2.403 [t=0.18s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.496 (perp=7.001, rec=0.095, cos=0.002), tot_loss_proj:2.405 [t=0.18s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
[1800/2000] tot_loss=1.495 (perp=7.001, rec=0.094, cos=0.002), tot_loss_proj:2.403 [t=0.19s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.494 (perp=7.001, rec=0.092, cos=0.002), tot_loss_proj:2.403 [t=0.19s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.499 (perp=7.001, rec=0.097, cos=0.002), tot_loss_proj:2.408 [t=0.18s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
[1950/2000] tot_loss=1.496 (perp=7.001, rec=0.094, cos=0.002), tot_loss_proj:2.406 [t=0.19s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.498 (perp=7.001, rec=0.096, cos=0.002), tot_loss_proj:2.409 [t=0.19s]
prediction: ['[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] worse the nonexisten tactic - - - to cover fact picture - is aimsy around or, yet core, constructed of core ideas - -stent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.273 | p: 80.952 | r: 73.913
rouge2     | fm: 14.286 | p: 15.000 | r: 13.636
rougeL     | fm: 54.545 | p: 57.143 | r: 52.174
rougeLsum  | fm: 54.545 | p: 57.143 | r: 52.174
r1fm+r2fm = 91.558

[Aggregate metrics]:
rouge1     | fm: 92.419 | p: 92.034 | r: 92.934
rouge2     | fm: 57.361 | p: 57.176 | r: 57.609
rougeL     | fm: 78.640 | p: 78.351 | r: 79.045
rougeLsum  | fm: 78.574 | p: 78.269 | r: 78.951
r1fm+r2fm = 149.781

input #89 time: 0:07:29 | total time: 12:17:48


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9993650968600143
highest_index [0]
highest [0.9993650968600143]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9487876892089844 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9457016587257385 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.9307820200920105 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 0.9131976962089539 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8914667963981628 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.8844628930091858 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.874426543712616 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8734989166259766 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.8714959025382996 for ['[CLS] when entourage spirited male released cannot [SEP]']
[Init] best perm rec loss: 0.8705925345420837 for ['[CLS] cannot male spirited entourage released when [SEP]']
[Init] best perm rec loss: 0.8705049157142639 for ['[CLS] cannot entourage spirited male released when [SEP]']
[Init] best perm rec loss: 0.8698896765708923 for ['[CLS] male cannot when spirited released entourage [SEP]']
[Init] best perm rec loss: 0.8698087334632874 for ['[CLS] entourage released spirited male cannot when [SEP]']
[Init] best perm rec loss: 0.8679990172386169 for ['[CLS] cannot released male spirited when entourage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.347 (perp=10.356, rec=0.260, cos=0.016), tot_loss_proj:2.815 [t=0.18s]
prediction: ['[CLS] ridiculous ridiculous - question money how [SEP]']
[ 100/2000] tot_loss=2.222 (perp=10.324, rec=0.152, cos=0.005), tot_loss_proj:2.910 [t=0.18s]
prediction: ['[CLS] ridiculous ridiculous oriented and money how [SEP]']
[ 150/2000] tot_loss=2.377 (perp=10.962, rec=0.165, cos=0.020), tot_loss_proj:3.364 [t=0.18s]
prediction: ['[CLS] crazy ridiculous oriented and money how [SEP]']
[ 200/2000] tot_loss=2.273 (perp=10.962, rec=0.079, cos=0.002), tot_loss_proj:3.351 [t=0.18s]
prediction: ['[CLS] crazy ridiculous oriented and money how [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.848 (perp=8.896, rec=0.067, cos=0.002), tot_loss_proj:2.513 [t=0.18s]
prediction: ['[CLS] how ridiculous oriented and money - [SEP]']
[ 300/2000] tot_loss=1.849 (perp=8.896, rec=0.068, cos=0.001), tot_loss_proj:2.521 [t=0.18s]
prediction: ['[CLS] how ridiculous oriented and money - [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.693 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.441 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.711 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.700 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.706 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.446 (perp=6.870, rec=0.071, cos=0.001), tot_loss_proj:1.714 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.712 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.440 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.724 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.712 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.725 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.441 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.714 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.720 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.445 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.715 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.717 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.720 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.719 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.440 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.722 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.446 (perp=6.870, rec=0.071, cos=0.001), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.432 (perp=6.870, rec=0.057, cos=0.001), tot_loss_proj:1.710 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.442 (perp=6.870, rec=0.067, cos=0.001), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.719 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.444 (perp=6.870, rec=0.069, cos=0.001), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.720 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.445 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.723 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.431 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.717 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.715 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.441 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.718 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.730 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.438 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.725 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.724 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.497 | p: 92.081 | r: 93.001
rouge2     | fm: 57.690 | p: 57.463 | r: 57.987
rougeL     | fm: 78.805 | p: 78.517 | r: 79.181
rougeLsum  | fm: 78.913 | p: 78.621 | r: 79.297
r1fm+r2fm = 150.187

input #90 time: 0:07:17 | total time: 12:25:05


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9993538374859834
highest_index [0]
highest [0.9993538374859834]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.9367198944091797 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.8268771767616272 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.8143160343170166 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.77603679895401 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.7621927261352539 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.7398632168769836 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 0.7303189039230347 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 0.7301856279373169 for ['[CLS]dern pony revolutionpment unknownlip hard shelter [SEP]']
[Init] best perm rec loss: 0.7299460172653198 for ['[CLS]lippment hard unknown pony shelterdern revolution [SEP]']
[Init] best perm rec loss: 0.7278955578804016 for ['[CLS] hard unknown revolutiondernlip shelter ponypment [SEP]']
[Init] best perm rec loss: 0.7267093658447266 for ['[CLS] pony hard shelterpmentlip unknowndern revolution [SEP]']
[Init] best perm rec loss: 0.7247644662857056 for ['[CLS] hard unknown revolutionpmentlipdern shelter pony [SEP]']
[Init] best perm rec loss: 0.7247127890586853 for ['[CLS] hard shelterpmentlip revolution unknowndern pony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.749 (perp=12.131, rec=0.304, cos=0.019), tot_loss_proj:3.239 [t=0.18s]
prediction: ['[CLS] yellow crazy no worse ridiculous no sox ridiculous [SEP]']
[ 100/2000] tot_loss=2.258 (perp=10.298, rec=0.192, cos=0.006), tot_loss_proj:2.597 [t=0.18s]
prediction: ['[CLS]y loco no more ridiculous no vietnamese loco [SEP]']
[ 150/2000] tot_loss=2.332 (perp=10.871, rec=0.153, cos=0.005), tot_loss_proj:2.701 [t=0.18s]
prediction: ['[CLS]y loco no more ridiculous no mu loco [SEP]']
[ 200/2000] tot_loss=2.267 (perp=10.824, rec=0.100, cos=0.003), tot_loss_proj:2.945 [t=0.18s]
prediction: ['[CLS]y loco but more ridiculous no mu loco [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.145 (perp=10.255, rec=0.091, cos=0.003), tot_loss_proj:2.683 [t=0.18s]
prediction: ['[CLS] but locoy more ridiculous no mu loco [SEP]']
[ 300/2000] tot_loss=2.135 (perp=10.255, rec=0.083, cos=0.002), tot_loss_proj:2.688 [t=0.18s]
prediction: ['[CLS] but locoy more ridiculous no mu loco [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.988 (perp=9.410, rec=0.104, cos=0.003), tot_loss_proj:2.415 [t=0.18s]
prediction: ['[CLS] but loco more ridiculous no muy loco [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.919 (perp=9.150, rec=0.086, cos=0.003), tot_loss_proj:2.451 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[ 450/2000] tot_loss=1.913 (perp=9.150, rec=0.082, cos=0.002), tot_loss_proj:2.451 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.914 (perp=9.150, rec=0.082, cos=0.002), tot_loss_proj:2.442 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.922 (perp=9.150, rec=0.090, cos=0.001), tot_loss_proj:2.454 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[ 600/2000] tot_loss=1.903 (perp=9.150, rec=0.072, cos=0.001), tot_loss_proj:2.455 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.912 (perp=9.150, rec=0.081, cos=0.002), tot_loss_proj:2.451 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.900 (perp=9.150, rec=0.068, cos=0.002), tot_loss_proj:2.452 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[ 750/2000] tot_loss=1.907 (perp=9.150, rec=0.075, cos=0.001), tot_loss_proj:2.446 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.902 (perp=9.150, rec=0.070, cos=0.002), tot_loss_proj:2.460 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.916 (perp=9.150, rec=0.085, cos=0.001), tot_loss_proj:2.456 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[ 900/2000] tot_loss=1.904 (perp=9.150, rec=0.073, cos=0.001), tot_loss_proj:2.456 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.898 (perp=9.150, rec=0.066, cos=0.001), tot_loss_proj:2.456 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.918 (perp=9.150, rec=0.086, cos=0.002), tot_loss_proj:2.449 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[1050/2000] tot_loss=1.908 (perp=9.150, rec=0.077, cos=0.001), tot_loss_proj:2.441 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.915 (perp=9.150, rec=0.084, cos=0.001), tot_loss_proj:2.457 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.903 (perp=9.150, rec=0.071, cos=0.001), tot_loss_proj:2.447 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[1200/2000] tot_loss=1.907 (perp=9.150, rec=0.076, cos=0.001), tot_loss_proj:2.451 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.912 (perp=9.150, rec=0.080, cos=0.001), tot_loss_proj:2.451 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.906 (perp=9.150, rec=0.075, cos=0.001), tot_loss_proj:2.449 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[1350/2000] tot_loss=1.897 (perp=9.150, rec=0.065, cos=0.001), tot_loss_proj:2.448 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.897 (perp=9.150, rec=0.066, cos=0.001), tot_loss_proj:2.449 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.912 (perp=9.150, rec=0.080, cos=0.001), tot_loss_proj:2.448 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[1500/2000] tot_loss=1.905 (perp=9.150, rec=0.073, cos=0.001), tot_loss_proj:2.446 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.902 (perp=9.150, rec=0.070, cos=0.001), tot_loss_proj:2.450 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.902 (perp=9.150, rec=0.071, cos=0.001), tot_loss_proj:2.450 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[1650/2000] tot_loss=1.913 (perp=9.150, rec=0.082, cos=0.001), tot_loss_proj:2.456 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.901 (perp=9.150, rec=0.070, cos=0.001), tot_loss_proj:2.454 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.905 (perp=9.150, rec=0.074, cos=0.001), tot_loss_proj:2.448 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[1800/2000] tot_loss=1.906 (perp=9.150, rec=0.075, cos=0.001), tot_loss_proj:2.440 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.897 (perp=9.150, rec=0.066, cos=0.001), tot_loss_proj:2.453 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.899 (perp=9.150, rec=0.067, cos=0.001), tot_loss_proj:2.453 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
[1950/2000] tot_loss=1.907 (perp=9.150, rec=0.076, cos=0.001), tot_loss_proj:2.454 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.912 (perp=9.150, rec=0.080, cos=0.001), tot_loss_proj:2.446 [t=0.18s]
prediction: ['[CLS] but loco loco ridiculous no muy more [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] but loco loco ridiculous no muy more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 94.118

[Aggregate metrics]:
rouge1     | fm: 92.516 | p: 92.082 | r: 93.081
rouge2     | fm: 57.026 | p: 56.846 | r: 57.333
rougeL     | fm: 78.651 | p: 78.338 | r: 79.037
rougeLsum  | fm: 78.646 | p: 78.314 | r: 79.071
r1fm+r2fm = 149.542

input #91 time: 0:07:19 | total time: 12:32:25


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9993137310302476
highest_index [0]
highest [0.9993137310302476]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8797468543052673 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8783625364303589 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8693297505378723 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.8594153523445129 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 0.8578515648841858 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.8554595112800598 for ['[CLS] edge island [SEP]']
[Init] best rec loss: 0.7936431765556335 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7916328310966492 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.634 (perp=12.265, rec=0.176, cos=0.005), tot_loss_proj:3.203 [t=0.18s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=1.598 (perp=7.646, rec=0.068, cos=0.002), tot_loss_proj:1.598 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.597 (perp=7.646, rec=0.066, cos=0.001), tot_loss_proj:1.592 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.601 (perp=7.646, rec=0.071, cos=0.001), tot_loss_proj:1.595 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.600 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.579 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.572 (perp=7.646, rec=0.041, cos=0.002), tot_loss_proj:1.608 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.596 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.599 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.600 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.589 (perp=7.646, rec=0.058, cos=0.001), tot_loss_proj:1.608 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.605 (perp=7.646, rec=0.075, cos=0.001), tot_loss_proj:1.597 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.600 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.594 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.600 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.586 (perp=7.646, rec=0.056, cos=0.001), tot_loss_proj:1.601 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.587 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.578 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.586 (perp=7.646, rec=0.055, cos=0.001), tot_loss_proj:1.602 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.595 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.591 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.579 (perp=7.646, rec=0.049, cos=0.001), tot_loss_proj:1.581 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.591 (perp=7.646, rec=0.061, cos=0.001), tot_loss_proj:1.596 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.596 (perp=7.646, rec=0.066, cos=0.001), tot_loss_proj:1.596 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.596 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.601 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.597 (perp=7.646, rec=0.067, cos=0.001), tot_loss_proj:1.593 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.600 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.599 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.595 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.596 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.584 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.595 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.598 (perp=7.646, rec=0.067, cos=0.001), tot_loss_proj:1.583 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.602 (perp=7.646, rec=0.071, cos=0.001), tot_loss_proj:1.585 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.578 (perp=7.646, rec=0.048, cos=0.001), tot_loss_proj:1.606 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.607 (perp=7.646, rec=0.077, cos=0.001), tot_loss_proj:1.596 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.596 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.595 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.592 (perp=7.646, rec=0.061, cos=0.001), tot_loss_proj:1.607 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.606 (perp=7.646, rec=0.076, cos=0.001), tot_loss_proj:1.602 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.581 (perp=7.646, rec=0.051, cos=0.001), tot_loss_proj:1.603 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.591 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.593 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.602 (perp=7.646, rec=0.071, cos=0.001), tot_loss_proj:1.596 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.599 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.594 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.586 (perp=7.646, rec=0.056, cos=0.001), tot_loss_proj:1.588 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.586 (perp=7.646, rec=0.056, cos=0.001), tot_loss_proj:1.603 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.598 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.589 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.596 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.602 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.625 | p: 92.203 | r: 93.149
rouge2     | fm: 57.661 | p: 57.432 | r: 57.911
rougeL     | fm: 78.891 | p: 78.594 | r: 79.242
rougeLsum  | fm: 78.866 | p: 78.533 | r: 79.325
r1fm+r2fm = 150.286

input #92 time: 0:07:21 | total time: 12:39:46


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9993323263895038
highest_index [0]
highest [0.9993323263895038]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.0078084468841553 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8302108645439148 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.8220402598381042 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 0.8074820637702942 for ['[CLS] solo specificball shrinking lad 1970s judicial [SEP]']
[Init] best perm rec loss: 0.8070929646492004 for ['[CLS]ball lad specific shrinking judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.807031512260437 for ['[CLS] lad specific shrinkingball judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.806305468082428 for ['[CLS] lad shrinkingball solo 1970s judicial specific [SEP]']
[Init] best perm rec loss: 0.8061965107917786 for ['[CLS] solo 1970s shrinkingball lad judicial specific [SEP]']
[Init] best perm rec loss: 0.8059419989585876 for ['[CLS] 1970s specificball shrinking judicial lad solo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.754 (perp=12.101, rec=0.321, cos=0.013), tot_loss_proj:3.516 [t=0.18s]
prediction: ['[CLS] disease song duo funny understanding understanding influence [SEP]']
[ 100/2000] tot_loss=2.235 (perp=10.033, rec=0.224, cos=0.005), tot_loss_proj:3.136 [t=0.18s]
prediction: ['[CLS] disease ( understanding funny understanding its way [SEP]']
[ 150/2000] tot_loss=2.185 (perp=10.074, rec=0.167, cos=0.003), tot_loss_proj:3.435 [t=0.18s]
prediction: ['[CLS] disease ( understanding understanding funny its way [SEP]']
[ 200/2000] tot_loss=2.127 (perp=9.860, rec=0.151, cos=0.004), tot_loss_proj:3.854 [t=0.18s]
prediction: ['[CLS] disease ( often understanding funny its way [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.877 (perp=8.745, rec=0.125, cos=0.003), tot_loss_proj:3.112 [t=0.18s]
prediction: ['[CLS] understanding tuberculosis ( often funny its way [SEP]']
[ 300/2000] tot_loss=1.801 (perp=8.433, rec=0.112, cos=0.003), tot_loss_proj:2.419 [t=0.18s]
prediction: ['[CLS] understanding developed, often funny its way [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.808 (perp=8.433, rec=0.119, cos=0.002), tot_loss_proj:2.423 [t=0.18s]
prediction: ['[CLS] understanding developed, often funny its way [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.715 (perp=7.988, rec=0.114, cos=0.002), tot_loss_proj:2.055 [t=0.18s]
prediction: ['[CLS] understanding, often funny often its way [SEP]']
[ 450/2000] tot_loss=1.703 (perp=7.988, rec=0.103, cos=0.002), tot_loss_proj:2.057 [t=0.18s]
prediction: ['[CLS] understanding, often funny often its way [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.692 (perp=7.988, rec=0.092, cos=0.002), tot_loss_proj:2.040 [t=0.18s]
prediction: ['[CLS] understanding, often funny often its way [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.692 (perp=7.988, rec=0.092, cos=0.002), tot_loss_proj:2.048 [t=0.18s]
prediction: ['[CLS] understanding, often funny often its way [SEP]']
[ 600/2000] tot_loss=1.687 (perp=7.988, rec=0.087, cos=0.002), tot_loss_proj:2.048 [t=0.18s]
prediction: ['[CLS] understanding, often funny often its way [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.693 (perp=7.988, rec=0.093, cos=0.002), tot_loss_proj:2.045 [t=0.17s]
prediction: ['[CLS] understanding, often funny often its way [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.695 (perp=7.988, rec=0.096, cos=0.002), tot_loss_proj:2.039 [t=0.18s]
prediction: ['[CLS] understanding, often funny often its way [SEP]']
[ 750/2000] tot_loss=1.685 (perp=7.988, rec=0.085, cos=0.002), tot_loss_proj:2.048 [t=0.18s]
prediction: ['[CLS] understanding, often funny often its way [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.774 (perp=8.425, rec=0.087, cos=0.002), tot_loss_proj:2.148 [t=0.18s]
prediction: ['[CLS] understanding, often funny its its way [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.982 (perp=7.978, rec=0.369, cos=0.017), tot_loss_proj:2.064 [t=0.18s]
prediction: ['[CLS] understanding in, often funny its way [SEP]']
[ 900/2000] tot_loss=1.874 (perp=7.978, rec=0.268, cos=0.010), tot_loss_proj:2.061 [t=0.18s]
prediction: ['[CLS] understanding in, often funny its way [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.617 (perp=6.947, rec=0.220, cos=0.007), tot_loss_proj:1.799 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1000/2000] tot_loss=1.601 (perp=6.947, rec=0.206, cos=0.006), tot_loss_proj:1.790 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
[1050/2000] tot_loss=1.578 (perp=6.947, rec=0.183, cos=0.005), tot_loss_proj:1.789 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1100/2000] tot_loss=1.576 (perp=6.947, rec=0.182, cos=0.005), tot_loss_proj:1.788 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1150/2000] tot_loss=1.565 (perp=6.947, rec=0.171, cos=0.005), tot_loss_proj:1.783 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
[1200/2000] tot_loss=1.556 (perp=6.947, rec=0.162, cos=0.004), tot_loss_proj:1.779 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1250/2000] tot_loss=1.554 (perp=6.947, rec=0.160, cos=0.004), tot_loss_proj:1.787 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1300/2000] tot_loss=1.556 (perp=6.947, rec=0.162, cos=0.004), tot_loss_proj:1.785 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
[1350/2000] tot_loss=1.545 (perp=6.947, rec=0.151, cos=0.004), tot_loss_proj:1.779 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1400/2000] tot_loss=1.555 (perp=6.947, rec=0.161, cos=0.004), tot_loss_proj:1.780 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1450/2000] tot_loss=1.545 (perp=6.947, rec=0.152, cos=0.004), tot_loss_proj:1.781 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
[1500/2000] tot_loss=1.539 (perp=6.947, rec=0.146, cos=0.004), tot_loss_proj:1.781 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1550/2000] tot_loss=1.548 (perp=6.947, rec=0.155, cos=0.004), tot_loss_proj:1.781 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1600/2000] tot_loss=1.547 (perp=6.947, rec=0.154, cos=0.004), tot_loss_proj:1.778 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
[1650/2000] tot_loss=1.541 (perp=6.947, rec=0.148, cos=0.004), tot_loss_proj:1.778 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1700/2000] tot_loss=1.541 (perp=6.947, rec=0.148, cos=0.004), tot_loss_proj:1.780 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1750/2000] tot_loss=1.544 (perp=6.947, rec=0.151, cos=0.004), tot_loss_proj:1.775 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
[1800/2000] tot_loss=1.535 (perp=6.947, rec=0.142, cos=0.004), tot_loss_proj:1.782 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1850/2000] tot_loss=1.533 (perp=6.947, rec=0.140, cos=0.004), tot_loss_proj:1.782 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[1900/2000] tot_loss=1.543 (perp=6.947, rec=0.151, cos=0.003), tot_loss_proj:1.769 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
[1950/2000] tot_loss=1.535 (perp=6.947, rec=0.142, cos=0.003), tot_loss_proj:1.785 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Attempt swap
[2000/2000] tot_loss=1.537 (perp=6.947, rec=0.144, cos=0.003), tot_loss_proj:1.777 [t=0.18s]
prediction: ['[CLS] understanding, often funny in its way [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding, often funny often its way [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 130.357

[Aggregate metrics]:
rouge1     | fm: 92.577 | p: 92.121 | r: 93.106
rouge2     | fm: 57.368 | p: 57.183 | r: 57.680
rougeL     | fm: 78.732 | p: 78.459 | r: 79.153
rougeLsum  | fm: 78.818 | p: 78.502 | r: 79.260
r1fm+r2fm = 149.944

input #93 time: 0:07:23 | total time: 12:47:09


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9993168061064917
highest_index [0]
highest [0.9993168061064917]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9727807641029358 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9545496106147766 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9148076176643372 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9085803627967834 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.8869084715843201 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.8795130848884583 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 0.879210889339447 for ['[CLS] internal plum rockwell expedition crushed flowering shocks territorialventing chronic centre [SEP]']
[Init] best perm rec loss: 0.8783528804779053 for ['[CLS] internalventing territorial shocks expedition centre crushed plum flowering chronic rockwell [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.870 (perp=12.436, rec=0.367, cos=0.016), tot_loss_proj:3.284 [t=0.18s]
prediction: ['[CLS] worst. na aywood internal transport neither vinnie none funny [SEP]']
[ 100/2000] tot_loss=2.663 (perp=12.111, rec=0.235, cos=0.006), tot_loss_proj:3.123 [t=0.18s]
prediction: ['[CLS] any nor zombie a cape internal wb nor terribly neither funny [SEP]']
[ 150/2000] tot_loss=1.854 (perp=8.453, rec=0.159, cos=0.004), tot_loss_proj:2.241 [t=0.18s]
prediction: ['[CLS] a nor neither a cape caper nor original neither funny [SEP]']
[ 200/2000] tot_loss=2.300 (perp=10.853, rec=0.127, cos=0.002), tot_loss_proj:2.641 [t=0.18s]
prediction: ['[CLS] a who insane a cape caper nor original neither funny [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.045 (perp=9.650, rec=0.112, cos=0.003), tot_loss_proj:2.387 [t=0.18s]
prediction: ['[CLS] a who neither s cape caper nor original very funny [SEP]']
[ 300/2000] tot_loss=1.838 (perp=8.758, rec=0.084, cos=0.002), tot_loss_proj:2.185 [t=0.18s]
prediction: ['[CLS] a who neither s terribly caper nor original terribly funny [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.061 (perp=9.892, rec=0.081, cos=0.002), tot_loss_proj:2.493 [t=0.18s]
prediction: ['[CLS]tur neither s a cape caper nor original terribly funny [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.888 (perp=9.043, rec=0.077, cos=0.002), tot_loss_proj:2.290 [t=0.18s]
prediction: ['[CLS] s neithertur a cape caper nor original terribly funny [SEP]']
[ 450/2000] tot_loss=1.947 (perp=9.350, rec=0.076, cos=0.002), tot_loss_proj:2.431 [t=0.18s]
prediction: ['[CLS] s neithertur a came caper nor original terribly funny [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.949 (perp=9.367, rec=0.074, cos=0.002), tot_loss_proj:2.391 [t=0.19s]
prediction: ['[CLS] s neither½tur a caper nor original terribly funny [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.127 (perp=10.229, rec=0.079, cos=0.002), tot_loss_proj:2.515 [t=0.18s]
prediction: ['[CLS] neither diagonaltur s a caper nor original terribly funny [SEP]']
[ 600/2000] tot_loss=1.607 (perp=7.615, rec=0.082, cos=0.002), tot_loss_proj:2.023 [t=0.18s]
prediction: ["[CLS] neither came's a caper nor original terribly funny [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.720 (perp=8.204, rec=0.078, cos=0.002), tot_loss_proj:2.182 [t=0.18s]
prediction: ["[CLS] neither's a overall caper nor original terribly funny [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.563 (perp=7.376, rec=0.086, cos=0.002), tot_loss_proj:2.064 [t=0.18s]
prediction: ["[CLS] neither's a which original caper nor terribly funny [SEP]"]
[ 750/2000] tot_loss=1.564 (perp=7.376, rec=0.087, cos=0.002), tot_loss_proj:2.047 [t=0.18s]
prediction: ["[CLS] neither's a which original caper nor terribly funny [SEP]"]
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.431 (perp=6.789, rec=0.072, cos=0.002), tot_loss_proj:2.010 [t=0.18s]
prediction: ["[CLS] neither's which original a caper nor terribly funny [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.199 (perp=5.641, rec=0.070, cos=0.002), tot_loss_proj:1.424 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
[ 900/2000] tot_loss=1.202 (perp=5.641, rec=0.072, cos=0.002), tot_loss_proj:1.427 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.207 (perp=5.641, rec=0.077, cos=0.002), tot_loss_proj:1.438 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.211 (perp=5.641, rec=0.081, cos=0.002), tot_loss_proj:1.440 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
[1050/2000] tot_loss=1.113 (perp=5.193, rec=0.072, cos=0.002), tot_loss_proj:1.334 [t=0.17s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.112 (perp=5.193, rec=0.072, cos=0.002), tot_loss_proj:1.340 [t=0.18s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.124 (perp=5.193, rec=0.083, cos=0.002), tot_loss_proj:1.343 [t=0.18s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1200/2000] tot_loss=1.106 (perp=5.193, rec=0.065, cos=0.002), tot_loss_proj:1.336 [t=0.18s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.116 (perp=5.193, rec=0.076, cos=0.001), tot_loss_proj:1.346 [t=0.18s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.122 (perp=5.193, rec=0.082, cos=0.001), tot_loss_proj:1.337 [t=0.18s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1350/2000] tot_loss=1.118 (perp=5.193, rec=0.078, cos=0.001), tot_loss_proj:1.350 [t=0.18s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.112 (perp=5.193, rec=0.072, cos=0.001), tot_loss_proj:1.344 [t=0.18s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.116 (perp=5.193, rec=0.075, cos=0.001), tot_loss_proj:1.333 [t=0.18s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
[1500/2000] tot_loss=1.109 (perp=5.193, rec=0.069, cos=0.001), tot_loss_proj:1.337 [t=0.18s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.106 (perp=5.193, rec=0.066, cos=0.001), tot_loss_proj:1.341 [t=0.18s]
prediction: ["[CLS] that's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.195 (perp=5.641, rec=0.065, cos=0.001), tot_loss_proj:1.431 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
[1650/2000] tot_loss=1.197 (perp=5.641, rec=0.067, cos=0.001), tot_loss_proj:1.432 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.204 (perp=5.641, rec=0.074, cos=0.001), tot_loss_proj:1.434 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.198 (perp=5.641, rec=0.069, cos=0.001), tot_loss_proj:1.429 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
[1800/2000] tot_loss=1.203 (perp=5.641, rec=0.074, cos=0.001), tot_loss_proj:1.433 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.202 (perp=5.641, rec=0.072, cos=0.001), tot_loss_proj:1.428 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.201 (perp=5.641, rec=0.072, cos=0.001), tot_loss_proj:1.431 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
[1950/2000] tot_loss=1.207 (perp=5.641, rec=0.077, cos=0.001), tot_loss_proj:1.432 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.200 (perp=5.641, rec=0.071, cos=0.001), tot_loss_proj:1.428 [t=0.18s]
prediction: ["[CLS] which's neither original a caper nor terribly funny [SEP]"]
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] which's neither original a caper nor terribly funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 150.909

[Aggregate metrics]:
rouge1     | fm: 92.496 | p: 92.075 | r: 93.035
rouge2     | fm: 57.376 | p: 57.165 | r: 57.630
rougeL     | fm: 78.755 | p: 78.478 | r: 79.213
rougeLsum  | fm: 78.846 | p: 78.567 | r: 79.215
r1fm+r2fm = 149.872

input #94 time: 0:07:23 | total time: 12:54:33


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9991574288984811
highest_index [0]
highest [0.9991574288984811]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9695915579795837 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9447000622749329 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 0.9425680041313171 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9293648600578308 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 0.9289979338645935 for ['[CLS] oval foster welfarecu range turk partly support turret familiesumatic helping inclinedsteredling [SEP]']
[Init] best rec loss: 0.9244387745857239 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 0.8965775966644287 for ['[CLS] plenty heroes kit operating aim ouby fa physics pinco victim playing cisco feeling [SEP]']
[Init] best rec loss: 0.8573101758956909 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8477544188499451 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 0.8469237089157104 for ['[CLS] cut pressure ]ے wire complete sister block monty hanging damp tech trailer privatenne [SEP]']
[Init] best perm rec loss: 0.8467367887496948 for ['[CLS] wireے pressure ] damp trailer cut private block sister complete hanging tech montynne [SEP]']
[Init] best perm rec loss: 0.8459979295730591 for ['[CLS] complete trailer pressure private damp sister hanging wire block monty cutnneے ] tech [SEP]']
[Init] best perm rec loss: 0.8446309566497803 for ['[CLS] sister damp trailer cut private monty complete pressure tech wire hangingے ] blocknne [SEP]']
[Init] best perm rec loss: 0.8437495231628418 for ['[CLS]ے ] wire tech private pressure trailer monty completenne cut block damp sister hanging [SEP]']
[Init] best perm rec loss: 0.8430407643318176 for ['[CLS] trailer sister wire monty blockے hanging private cut complete pressure damp ] technne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.645 (perp=11.983, rec=0.243, cos=0.006), tot_loss_proj:2.933 [t=0.17s]
prediction: ['[CLS] is collapse packet hopeless story became hopeless avoiding hopeless 10 an hopeless hopeless, hopeless [SEP]']
[ 100/2000] tot_loss=2.533 (perp=11.879, rec=0.153, cos=0.004), tot_loss_proj:2.968 [t=0.18s]
prediction: ["[CLS]'mud protein hopeless story becomes hopelesssatdle mohammad anfying hopeless, coincided [SEP]"]
[ 150/2000] tot_loss=2.128 (perp=10.021, rec=0.121, cos=0.003), tot_loss_proj:2.513 [t=0.18s]
prediction: ["[CLS]'mud lbs hopeless story becomes a muddlesat unfying hopeless, coincided [SEP]"]
[ 200/2000] tot_loss=1.822 (perp=8.549, rec=0.109, cos=0.002), tot_loss_proj:2.134 [t=0.18s]
prediction: ["[CLS]'mud ) hopeless story becomes a muddlesatisfying hopeless,fying [SEP]"]
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.642 (perp=7.536, rec=0.132, cos=0.004), tot_loss_proj:1.893 [t=0.17s]
prediction: ["[CLS]'mud ) ) story becomes asatisfying hopeless muddle, un [SEP]"]
[ 300/2000] tot_loss=1.610 (perp=7.536, rec=0.100, cos=0.002), tot_loss_proj:1.895 [t=0.18s]
prediction: ["[CLS]'mud ) ) story becomes asatisfying hopeless muddle, un [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=1.479 (perp=6.850, rec=0.107, cos=0.002), tot_loss_proj:1.659 [t=0.18s]
prediction: ["[CLS]'mud denis ) story becomes a unsatisfying hopeless muddle, [SEP]"]
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.430 (perp=6.661, rec=0.096, cos=0.002), tot_loss_proj:1.584 [t=0.18s]
prediction: ['[CLS] ( mud denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[ 450/2000] tot_loss=1.422 (perp=6.661, rec=0.088, cos=0.002), tot_loss_proj:1.594 [t=0.18s]
prediction: ['[CLS] ( mud denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.418 (perp=6.661, rec=0.084, cos=0.002), tot_loss_proj:1.589 [t=0.18s]
prediction: ['[CLS] ( mud denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.399 (perp=6.661, rec=0.065, cos=0.002), tot_loss_proj:1.584 [t=0.18s]
prediction: ['[CLS] ( mud denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[ 600/2000] tot_loss=1.404 (perp=6.661, rec=0.070, cos=0.002), tot_loss_proj:1.594 [t=0.18s]
prediction: ['[CLS] ( mud denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.396 (perp=6.593, rec=0.075, cos=0.002), tot_loss_proj:1.567 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.402 (perp=6.593, rec=0.082, cos=0.002), tot_loss_proj:1.564 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[ 750/2000] tot_loss=1.406 (perp=6.593, rec=0.086, cos=0.002), tot_loss_proj:1.566 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.397 (perp=6.593, rec=0.077, cos=0.002), tot_loss_proj:1.563 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.399 (perp=6.593, rec=0.079, cos=0.002), tot_loss_proj:1.570 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[ 900/2000] tot_loss=1.400 (perp=6.593, rec=0.080, cos=0.002), tot_loss_proj:1.568 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.391 (perp=6.593, rec=0.071, cos=0.002), tot_loss_proj:1.564 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.386 (perp=6.593, rec=0.066, cos=0.002), tot_loss_proj:1.571 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[1050/2000] tot_loss=1.394 (perp=6.593, rec=0.073, cos=0.002), tot_loss_proj:1.568 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.395 (perp=6.593, rec=0.075, cos=0.002), tot_loss_proj:1.571 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.401 (perp=6.593, rec=0.081, cos=0.002), tot_loss_proj:1.567 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[1200/2000] tot_loss=1.393 (perp=6.593, rec=0.073, cos=0.002), tot_loss_proj:1.575 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.395 (perp=6.593, rec=0.075, cos=0.002), tot_loss_proj:1.569 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.398 (perp=6.593, rec=0.077, cos=0.002), tot_loss_proj:1.566 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[1350/2000] tot_loss=1.393 (perp=6.593, rec=0.073, cos=0.002), tot_loss_proj:1.561 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.402 (perp=6.593, rec=0.081, cos=0.002), tot_loss_proj:1.559 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.395 (perp=6.593, rec=0.074, cos=0.002), tot_loss_proj:1.561 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[1500/2000] tot_loss=1.397 (perp=6.593, rec=0.076, cos=0.002), tot_loss_proj:1.562 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.392 (perp=6.593, rec=0.072, cos=0.002), tot_loss_proj:1.560 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.388 (perp=6.593, rec=0.067, cos=0.002), tot_loss_proj:1.567 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[1650/2000] tot_loss=1.399 (perp=6.593, rec=0.078, cos=0.002), tot_loss_proj:1.565 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.392 (perp=6.593, rec=0.072, cos=0.002), tot_loss_proj:1.561 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.390 (perp=6.593, rec=0.070, cos=0.002), tot_loss_proj:1.562 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[1800/2000] tot_loss=1.402 (perp=6.593, rec=0.082, cos=0.002), tot_loss_proj:1.566 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.387 (perp=6.593, rec=0.066, cos=0.002), tot_loss_proj:1.567 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.389 (perp=6.593, rec=0.068, cos=0.002), tot_loss_proj:1.567 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
[1950/2000] tot_loss=1.400 (perp=6.593, rec=0.079, cos=0.002), tot_loss_proj:1.570 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.393 (perp=6.593, rec=0.073, cos=0.002), tot_loss_proj:1.565 [t=0.18s]
prediction: ['[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] mud ( denis ) story becomes a unsatisfying, hopeless muddle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 141.796

[Aggregate metrics]:
rouge1     | fm: 92.548 | p: 92.096 | r: 93.144
rouge2     | fm: 57.378 | p: 57.117 | r: 57.667
rougeL     | fm: 78.714 | p: 78.391 | r: 79.189
rougeLsum  | fm: 78.800 | p: 78.431 | r: 79.238
r1fm+r2fm = 149.925

input #95 time: 0:07:30 | total time: 13:02:03


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9992866562400882
highest_index [0]
highest [0.9992866562400882]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8909018635749817 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8791100382804871 for ['[CLS] regrets emotionsoit purpose superior loop released given higher careini speechply springs assist [SEP]']
[Init] best rec loss: 0.8585579991340637 for ['[CLS] all nova resolution which assault domestic look mandy headquarteredtated thanlus completion stillboards [SEP]']
[Init] best rec loss: 0.8257309794425964 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 0.8243802189826965 for ['[CLS] lighter dunbar y itself phantom gen pickflowerled record margaret failed living giles stake [SEP]']
[Init] best rec loss: 0.8242563605308533 for ['[CLS] flex thought considerationlin kylie ste in gasped somewherese top close christian raised us [SEP]']
[Init] best rec loss: 0.8184889554977417 for ['[CLS] lea corps cellrily smashed unconscious garcia broke intensity baseball urban who reins brigade β [SEP]']
[Init] best rec loss: 0.8130791187286377 for ['[CLS]culus teacher robson colonies now world over enables who obsidianrlerving peacehwa contract [SEP]']
[Init] best rec loss: 0.7910962700843811 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.7895482182502747 for ['[CLS] wig memoir pondered save august typical smashwords statue sounding projectile spent era livinggn time [SEP]']
[Init] best perm rec loss: 0.7892841100692749 for ['[CLS] living statue sounding eragn pondered smashwords typical projectile time spent save august memoir wig [SEP]']
[Init] best perm rec loss: 0.7874389290809631 for ['[CLS] typical living save sounding wig smashwords august statue time spent projectile era ponderedgn memoir [SEP]']
[Init] best perm rec loss: 0.7851721048355103 for ['[CLS] typical era spent statue smashwords memoir wig sounding august timegn save living pondered projectile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.921 (perp=12.952, rec=0.312, cos=0.018), tot_loss_proj:4.401 [t=0.18s]
prediction: ['[CLS] community sized high james without paulnosar transport jace better people commission palms individuals [SEP]']
[ 100/2000] tot_loss=2.661 (perp=12.019, rec=0.248, cos=0.009), tot_loss_proj:3.628 [t=0.18s]
prediction: ['[CLS] himself into forces james into betternos for forceman lesser people male with people [SEP]']
[ 150/2000] tot_loss=2.219 (perp=9.979, rec=0.214, cos=0.009), tot_loss_proj:3.404 [t=0.18s]
prediction: ['[CLS] himself into might james in betterations for force man lesser people lesser into people [SEP]']
[ 200/2000] tot_loss=2.177 (perp=10.014, rec=0.169, cos=0.005), tot_loss_proj:3.319 [t=0.18s]
prediction: ['[CLS] himself on situations people people lesser lesser for force would lesser people lesser into men [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.422 (perp=11.034, rec=0.207, cos=0.009), tot_loss_proj:3.752 [t=0.19s]
prediction: ['[CLS] himself on situations hands people walked lesser cover for force lesser situations lesser panzer men [SEP]']
[ 300/2000] tot_loss=2.026 (perp=9.337, rec=0.154, cos=0.004), tot_loss_proj:3.538 [t=0.18s]
prediction: ['[CLS] himself on conditions men people into would cover for force lesser situations lesser to men [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.197 (perp=10.068, rec=0.176, cos=0.007), tot_loss_proj:3.311 [t=0.18s]
prediction: ['[CLS] himself on situations force people men would cover for himself lesser situations lesser into men [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.886 (perp=8.719, rec=0.138, cos=0.004), tot_loss_proj:2.848 [t=0.18s]
prediction: ['[CLS] himself on into force people men would cover for would lesser situations into lesser men [SEP]']
[ 450/2000] tot_loss=1.789 (perp=8.315, rec=0.124, cos=0.003), tot_loss_proj:2.865 [t=0.18s]
prediction: ['[CLS] himself on into force people men would cover for would make situations into lesser men [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.789 (perp=8.387, rec=0.109, cos=0.002), tot_loss_proj:2.316 [t=0.18s]
prediction: ['[CLS] himself on and force people situations would cover for would make man into lesser men [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.536 (perp=7.120, rec=0.109, cos=0.003), tot_loss_proj:2.338 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would cover for and make man into lesser men [SEP]']
[ 600/2000] tot_loss=1.732 (perp=8.175, rec=0.095, cos=0.002), tot_loss_proj:2.844 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would cover run in make man into lesser men [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.683 (perp=7.927, rec=0.096, cos=0.002), tot_loss_proj:2.985 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run cover in make man into lesser men [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.642 (perp=7.737, rec=0.092, cos=0.002), tot_loss_proj:3.138 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run in make man cover into lesser men [SEP]']
[ 750/2000] tot_loss=1.646 (perp=7.768, rec=0.090, cos=0.002), tot_loss_proj:3.266 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run for make man cover into lesser men [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.649 (perp=7.768, rec=0.093, cos=0.002), tot_loss_proj:3.263 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run for make man cover into lesser men [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.641 (perp=7.768, rec=0.086, cos=0.002), tot_loss_proj:3.260 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run for make man cover into lesser men [SEP]']
[ 900/2000] tot_loss=1.638 (perp=7.768, rec=0.083, cos=0.002), tot_loss_proj:3.265 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run for make man cover into lesser men [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.643 (perp=7.768, rec=0.087, cos=0.002), tot_loss_proj:3.265 [t=0.19s]
prediction: ['[CLS] himself on people force and situations would run for make man cover into lesser men [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.559 (perp=7.377, rec=0.082, cos=0.002), tot_loss_proj:3.139 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
[1050/2000] tot_loss=1.557 (perp=7.377, rec=0.079, cos=0.002), tot_loss_proj:3.137 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1100/2000] tot_loss=1.554 (perp=7.377, rec=0.076, cos=0.002), tot_loss_proj:3.139 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1150/2000] tot_loss=1.560 (perp=7.377, rec=0.083, cos=0.002), tot_loss_proj:3.141 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
[1200/2000] tot_loss=1.547 (perp=7.377, rec=0.070, cos=0.002), tot_loss_proj:3.139 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1250/2000] tot_loss=1.549 (perp=7.377, rec=0.072, cos=0.002), tot_loss_proj:3.139 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1300/2000] tot_loss=1.550 (perp=7.377, rec=0.073, cos=0.002), tot_loss_proj:3.142 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
[1350/2000] tot_loss=1.555 (perp=7.377, rec=0.078, cos=0.002), tot_loss_proj:3.135 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1400/2000] tot_loss=1.544 (perp=7.377, rec=0.067, cos=0.002), tot_loss_proj:3.140 [t=0.19s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1450/2000] tot_loss=1.559 (perp=7.377, rec=0.082, cos=0.002), tot_loss_proj:3.142 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
[1500/2000] tot_loss=1.562 (perp=7.377, rec=0.085, cos=0.002), tot_loss_proj:3.143 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1550/2000] tot_loss=1.550 (perp=7.377, rec=0.073, cos=0.002), tot_loss_proj:3.138 [t=0.19s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1600/2000] tot_loss=1.551 (perp=7.377, rec=0.074, cos=0.002), tot_loss_proj:3.137 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
[1650/2000] tot_loss=1.550 (perp=7.377, rec=0.073, cos=0.002), tot_loss_proj:3.140 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1700/2000] tot_loss=1.556 (perp=7.377, rec=0.079, cos=0.002), tot_loss_proj:3.138 [t=0.17s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1750/2000] tot_loss=1.559 (perp=7.377, rec=0.082, cos=0.002), tot_loss_proj:3.139 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
[1800/2000] tot_loss=1.543 (perp=7.377, rec=0.066, cos=0.002), tot_loss_proj:3.140 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1850/2000] tot_loss=1.550 (perp=7.377, rec=0.073, cos=0.002), tot_loss_proj:3.137 [t=0.19s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[1900/2000] tot_loss=1.551 (perp=7.377, rec=0.074, cos=0.002), tot_loss_proj:3.138 [t=0.18s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
[1950/2000] tot_loss=1.549 (perp=7.377, rec=0.072, cos=0.002), tot_loss_proj:3.134 [t=0.19s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Attempt swap
[2000/2000] tot_loss=1.556 (perp=7.377, rec=0.079, cos=0.002), tot_loss_proj:3.142 [t=0.19s]
prediction: ['[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] himself on people force and situations would run into make man cover for lesser men [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 18.750 | p: 18.750 | r: 18.750
rougeL     | fm: 64.706 | p: 64.706 | r: 64.706
rougeLsum  | fm: 64.706 | p: 64.706 | r: 64.706
r1fm+r2fm = 112.868

[Aggregate metrics]:
rouge1     | fm: 92.582 | p: 92.135 | r: 93.144
rouge2     | fm: 56.982 | p: 56.756 | r: 57.272
rougeL     | fm: 78.648 | p: 78.319 | r: 79.073
rougeLsum  | fm: 78.662 | p: 78.327 | r: 79.145
r1fm+r2fm = 149.564

input #96 time: 0:07:40 | total time: 13:09:43


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9991660915875735
highest_index [0]
highest [0.9991660915875735]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8396337628364563 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.8173046708106995 for ['[CLS] [SEP] crates margarita trip decisionsylus [SEP]']
[Init] best rec loss: 0.8006014823913574 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.7802342772483826 for ['[CLS] jealous glennm his = empire [SEP]']
[Init] best rec loss: 0.7502726316452026 for ['[CLS] perfect channel cam working 140et [SEP]']
[Init] best perm rec loss: 0.7448185682296753 for ['[CLS] working perfectet 140 cam channel [SEP]']
[Init] best perm rec loss: 0.7447396516799927 for ['[CLS] channel cam perfect working 140et [SEP]']
[Init] best perm rec loss: 0.7446287870407104 for ['[CLS] cam channel perfect workinget 140 [SEP]']
[Init] best perm rec loss: 0.7441828846931458 for ['[CLS] cam perfect working 140et channel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.677 (perp=11.561, rec=0.344, cos=0.020), tot_loss_proj:4.100 [t=0.17s]
prediction: ['[CLS] island activerogeforlish [SEP]']
[ 100/2000] tot_loss=2.727 (perp=12.494, rec=0.219, cos=0.010), tot_loss_proj:4.407 [t=0.18s]
prediction: ['[CLS] un unget charactersfortable [SEP]']
[ 150/2000] tot_loss=2.673 (perp=12.494, rec=0.163, cos=0.011), tot_loss_proj:4.412 [t=0.18s]
prediction: ['[CLS] un unget charactersfortable [SEP]']
[ 200/2000] tot_loss=2.633 (perp=12.494, rec=0.128, cos=0.006), tot_loss_proj:4.412 [t=0.18s]
prediction: ['[CLS] un unget charactersfortable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.976 (perp=9.197, rec=0.128, cos=0.008), tot_loss_proj:3.547 [t=0.18s]
prediction: ['[CLS] unforget characters untable [SEP]']
[ 300/2000] tot_loss=1.949 (perp=9.197, rec=0.106, cos=0.004), tot_loss_proj:3.559 [t=0.18s]
prediction: ['[CLS] unforget characters untable [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.481 (perp=6.911, rec=0.095, cos=0.004), tot_loss_proj:1.945 [t=0.18s]
prediction: ['[CLS] unforgettable un characters [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.276 (perp=5.782, rec=0.115, cos=0.004), tot_loss_proj:1.577 [t=0.18s]
prediction: ['[CLS] un characters unforgettable [SEP]']
[ 450/2000] tot_loss=1.271 (perp=5.782, rec=0.111, cos=0.003), tot_loss_proj:1.660 [t=0.18s]
prediction: ['[CLS] un characters unforgettable [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.275 (perp=5.782, rec=0.115, cos=0.003), tot_loss_proj:1.682 [t=0.18s]
prediction: ['[CLS] un characters unforgettable [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.261 (perp=5.782, rec=0.101, cos=0.003), tot_loss_proj:1.702 [t=0.18s]
prediction: ['[CLS] un characters unforgettable [SEP]']
[ 600/2000] tot_loss=1.261 (perp=5.782, rec=0.101, cos=0.003), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] un characters unforgettable [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.269 (perp=5.782, rec=0.110, cos=0.003), tot_loss_proj:1.712 [t=0.18s]
prediction: ['[CLS] un characters unforgettable [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.259 (perp=5.782, rec=0.100, cos=0.003), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] un characters unforgettable [SEP]']
[ 750/2000] tot_loss=1.252 (perp=5.782, rec=0.093, cos=0.003), tot_loss_proj:1.720 [t=0.18s]
prediction: ['[CLS] un characters unforgettable [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.218 (perp=5.572, rec=0.101, cos=0.003), tot_loss_proj:1.331 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.198 (perp=5.572, rec=0.082, cos=0.002), tot_loss_proj:1.337 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[ 900/2000] tot_loss=1.186 (perp=5.572, rec=0.070, cos=0.002), tot_loss_proj:1.346 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.186 (perp=5.572, rec=0.070, cos=0.002), tot_loss_proj:1.329 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1000/2000] tot_loss=1.181 (perp=5.572, rec=0.065, cos=0.002), tot_loss_proj:1.345 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1050/2000] tot_loss=1.182 (perp=5.572, rec=0.066, cos=0.002), tot_loss_proj:1.339 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1100/2000] tot_loss=1.185 (perp=5.572, rec=0.069, cos=0.002), tot_loss_proj:1.337 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1150/2000] tot_loss=1.188 (perp=5.572, rec=0.072, cos=0.002), tot_loss_proj:1.340 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1200/2000] tot_loss=1.175 (perp=5.572, rec=0.059, cos=0.002), tot_loss_proj:1.338 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1250/2000] tot_loss=1.171 (perp=5.572, rec=0.055, cos=0.002), tot_loss_proj:1.337 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1300/2000] tot_loss=1.179 (perp=5.572, rec=0.063, cos=0.002), tot_loss_proj:1.340 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1350/2000] tot_loss=1.183 (perp=5.572, rec=0.067, cos=0.002), tot_loss_proj:1.331 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1400/2000] tot_loss=1.181 (perp=5.572, rec=0.065, cos=0.002), tot_loss_proj:1.339 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1450/2000] tot_loss=1.188 (perp=5.572, rec=0.072, cos=0.002), tot_loss_proj:1.332 [t=0.17s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1500/2000] tot_loss=1.176 (perp=5.572, rec=0.060, cos=0.002), tot_loss_proj:1.342 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1550/2000] tot_loss=1.186 (perp=5.572, rec=0.070, cos=0.002), tot_loss_proj:1.341 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1600/2000] tot_loss=1.179 (perp=5.572, rec=0.063, cos=0.002), tot_loss_proj:1.344 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1650/2000] tot_loss=1.181 (perp=5.572, rec=0.065, cos=0.002), tot_loss_proj:1.343 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1700/2000] tot_loss=1.176 (perp=5.572, rec=0.060, cos=0.002), tot_loss_proj:1.343 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1750/2000] tot_loss=1.183 (perp=5.572, rec=0.067, cos=0.002), tot_loss_proj:1.332 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1800/2000] tot_loss=1.184 (perp=5.572, rec=0.068, cos=0.002), tot_loss_proj:1.333 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1850/2000] tot_loss=1.176 (perp=5.572, rec=0.060, cos=0.002), tot_loss_proj:1.340 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[1900/2000] tot_loss=1.176 (perp=5.572, rec=0.060, cos=0.002), tot_loss_proj:1.332 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
[1950/2000] tot_loss=1.183 (perp=5.572, rec=0.066, cos=0.002), tot_loss_proj:1.343 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Attempt swap
[2000/2000] tot_loss=1.183 (perp=5.572, rec=0.066, cos=0.002), tot_loss_proj:1.336 [t=0.18s]
prediction: ['[CLS] and characters unforgettable [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and characters unforgettable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.652 | p: 92.185 | r: 93.238
rouge2     | fm: 56.592 | p: 56.376 | r: 56.845
rougeL     | fm: 78.647 | p: 78.292 | r: 79.109
rougeLsum  | fm: 78.724 | p: 78.364 | r: 79.182
r1fm+r2fm = 149.244

input #97 time: 0:07:20 | total time: 13:17:03


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9991916976323436
highest_index [0]
highest [0.9991916976323436]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.7122125029563904 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.7120754718780518 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.709286630153656 for ['[CLS] jed ada nos prohibited [SEP]']
[Init] best perm rec loss: 0.7076743245124817 for ['[CLS] prohibited nos ada jed [SEP]']
[Init] best perm rec loss: 0.7051839828491211 for ['[CLS] nos ada jed prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.875 (perp=12.865, rec=0.282, cos=0.019), tot_loss_proj:3.325 [t=0.18s]
prediction: ['[CLS] unfulful construction [SEP]']
[ 100/2000] tot_loss=2.714 (perp=12.796, rec=0.146, cos=0.009), tot_loss_proj:4.100 [t=0.18s]
prediction: ['[CLS] unllingful reasonable [SEP]']
[ 150/2000] tot_loss=2.156 (perp=10.207, rec=0.112, cos=0.003), tot_loss_proj:2.740 [t=0.18s]
prediction: ['[CLS] unllingfulfi [SEP]']
[ 200/2000] tot_loss=2.153 (perp=10.207, rec=0.103, cos=0.009), tot_loss_proj:2.710 [t=0.18s]
prediction: ['[CLS] unllingfulfi [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.084 (perp=4.948, rec=0.091, cos=0.003), tot_loss_proj:1.069 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.062 (perp=4.948, rec=0.071, cos=0.002), tot_loss_proj:1.071 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.074 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.042 (perp=4.948, rec=0.050, cos=0.002), tot_loss_proj:1.069 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.067 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.048 (perp=4.948, rec=0.057, cos=0.002), tot_loss_proj:1.072 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.062 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.065 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.061 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.048 (perp=4.948, rec=0.057, cos=0.002), tot_loss_proj:1.072 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.066 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.064 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.063 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.072 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.065 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.043 (perp=4.948, rec=0.052, cos=0.002), tot_loss_proj:1.068 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.059 (perp=4.948, rec=0.068, cos=0.002), tot_loss_proj:1.071 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.076 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.050 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.058 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.059 (perp=4.948, rec=0.067, cos=0.002), tot_loss_proj:1.069 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.061 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.059 (perp=4.948, rec=0.068, cos=0.002), tot_loss_proj:1.061 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.045 (perp=4.948, rec=0.054, cos=0.002), tot_loss_proj:1.061 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.058 (perp=4.948, rec=0.067, cos=0.002), tot_loss_proj:1.064 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.064 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.064 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.060 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.048 (perp=4.948, rec=0.057, cos=0.002), tot_loss_proj:1.062 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.056 (perp=4.948, rec=0.065, cos=0.002), tot_loss_proj:1.056 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.048 (perp=4.948, rec=0.057, cos=0.002), tot_loss_proj:1.055 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.066 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.055 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.064 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.055 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.051 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.054 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.062 (perp=4.948, rec=0.071, cos=0.002), tot_loss_proj:1.064 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.039 (perp=4.948, rec=0.048, cos=0.002), tot_loss_proj:1.048 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.742 | p: 92.294 | r: 93.316
rouge2     | fm: 56.982 | p: 56.770 | r: 57.269
rougeL     | fm: 78.933 | p: 78.557 | r: 79.356
rougeLsum  | fm: 78.952 | p: 78.571 | r: 79.330
r1fm+r2fm = 149.724

input #98 time: 0:07:21 | total time: 13:24:25


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.9993095816453154
highest_index [0]
highest [0.9993095816453154]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8722755908966064 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8668547868728638 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8600996136665344 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.8582916855812073 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.8477660417556763 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 0.8349575400352478 for ['[CLS] sealed−1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 0.8292847275733948 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 0.823960542678833 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.8212921023368835 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.820878267288208 for ['[CLS]ˈ ferns opposedaging actually orient taste earliest claire slight thunder ratings currently temps bet te distance whente cushion services bearing re barbie knowledgets garcia synonym harper still screens [MASK] dental forced himself right [SEP]']
[Init] best perm rec loss: 0.8208308815956116 for ['[CLS] knowledge ratings re synonym slight currently taste ferns claire actuallyˈ forced garcia bet opposed screens right when orient himself thunder services temps earliest dental cushionts te still harperagingte distance barbie [MASK] bearing [SEP]']
[Init] best perm rec loss: 0.8205059766769409 for ['[CLS] cushionts garcia opposed distance ratings synonym thunder slight bearing ferns when services knowledge taste harper orient clairete forced bet [MASK] temps te currently actually re himself screensˈ rightaging still earliest barbie dental [SEP]']
[Init] best perm rec loss: 0.8195905089378357 for ['[CLS] distance cushion knowledge right services re screens still claire orient dentalaging [MASK] garcia thunder harper synonym taste fernsˈte forced barbie ratings tempsts bet actually when te bearing slight earliest opposed currently himself [SEP]']
[Init] best perm rec loss: 0.818151593208313 for ['[CLS] temps taste re fernsaging forced ratings dentalˈ cushion right claire te garcia slight earliest thunder knowledge actually services himself harper bet screens still orient when [MASK] opposed synonym currently barbiete distance bearingts [SEP]']
[Init] best perm rec loss: 0.8180760741233826 for ['[CLS] ratingsˈ claire thunder betts taste ferns temps garcia still re [MASK] himself slight cushion opposed actuallyte currently screensaging bearing te harper dental right orient services barbie forced distance earliest knowledge when synonym [SEP]']
[Init] best perm rec loss: 0.8174036741256714 for ['[CLS] opposed screens forcedagingts synonym earliest [MASK] garcia claire dental actually barbie orient currently harper thunder ferns slight bearing rete still right temps ratings when cushion te taste distance knowledge himself bet servicesˈ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.530 (perp=11.039, rec=0.313, cos=0.009), tot_loss_proj:2.995 [t=0.18s]
prediction: ["[CLS] non guys socialist'typical against waste. horrible lip ammunition mother ass behavior [ the unix got'drinking aedwyl his clause bathroom cart saying injury portals head, blinked airport violence [ [SEP]"]
[ 100/2000] tot_loss=2.557 (perp=11.586, rec=0.234, cos=0.006), tot_loss_proj:3.362 [t=0.18s]
prediction: ["[CLS] non guys fun'truly without idiots but ` dited terriblessing legs into the individuals got di fun di walkednation prize talked film gu saying clauses coming that'walked film anal film [SEP]"]
[ 150/2000] tot_loss=2.573 (perp=11.892, rec=0.189, cos=0.005), tot_loss_proj:3.068 [t=0.19s]
prediction: ["[CLS] mob aviator fun'truly into poorly but ` di angry terriblessing fantasy kept the them minded di fun di walkednation prize hindi ticket express saying horrible that that'walked filmssing [ [SEP]"]
[ 200/2000] tot_loss=2.384 (perp=11.098, rec=0.161, cos=0.004), tot_loss_proj:3.050 [t=0.18s]
prediction: ["[CLS] mob those fun'had into cost but ` di angry terriblessing when kept the the minded di fun out walked bible tickets out ticket own muttering should that that'walked filmssing [ [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.217 (perp=10.312, rec=0.149, cos=0.005), tot_loss_proj:2.879 [t=0.18s]
prediction: ["[CLS] mob should fun'so into cost but ` horrible named terriblessing when had the the mind di fun out walked bible tickets out ticket n muttering they that that'walked filmssing terrible [SEP]"]
[ 300/2000] tot_loss=2.219 (perp=10.472, rec=0.122, cos=0.003), tot_loss_proj:2.871 [t=0.18s]
prediction: ["[CLS] mob should fun'so of cost but ` horrible named terriblessing when had the the mind di fun out walked ` worst out ticket n muttering they that that did talked filmssing terrible [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.114 (perp=10.001, rec=0.112, cos=0.002), tot_loss_proj:2.701 [t=0.18s]
prediction: ["[CLS] mob should fun ` worst of cost but ` horrible'terriblessing'had the the mind di fun out walked ` so like ticket n muttering they that that did talked film labels terrible [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.039 (perp=9.648, rec=0.108, cos=0.002), tot_loss_proj:2.654 [t=0.18s]
prediction: ["[CLS] they should fun ` worst or cost but ` horrible'terriblessing'had the the mind di fun out walked ` so like ticket n muttering mob that you did talked film alarms terrible [SEP]"]
[ 450/2000] tot_loss=2.061 (perp=9.790, rec=0.102, cos=0.002), tot_loss_proj:2.700 [t=0.18s]
prediction: ["[CLS] they should fun ` worst like cost but ` horrible'terriblessing'had the the mind di fun out walked ` so like ticket n muttering mob that did t talked film ` terrible [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.931 (perp=9.184, rec=0.092, cos=0.002), tot_loss_proj:2.537 [t=0.17s]
prediction: ["[CLS] they should fun ` horrible like cost but ` horrible'terriblessing'had the talked mind di fun out walked'so like ticket n muttering mob that did t the film ` terrible [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.943 (perp=9.251, rec=0.091, cos=0.002), tot_loss_proj:2.554 [t=0.18s]
prediction: ["[CLS] they should fun ` worst like cost but ` horrible'terriblessing'had the talked mind di fun out walked'so like ticket n muttering mob that t the film did ` terrible [SEP]"]
[ 600/2000] tot_loss=1.925 (perp=9.144, rec=0.095, cos=0.002), tot_loss_proj:2.519 [t=0.18s]
prediction: ["[CLS] they should fun ` horrible like cost but ` horrible'terriblessing'had the talked mind di fun out walked'so like ticket n muttering mob that t the film did ` terrible [SEP]"]
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.860 (perp=8.876, rec=0.083, cos=0.001), tot_loss_proj:2.463 [t=0.18s]
prediction: ["[CLS] they should fun'horrible like cost but ` terrible'terriblessing'had the talked di fun mind out walked'so like ticket n muttering mob that t the film did ` terrible [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.810 (perp=8.629, rec=0.083, cos=0.002), tot_loss_proj:2.375 [t=0.19s]
prediction: ["[CLS] they should fun'horrible like cost but ` terrible'talkedssing, had the terrible di fun mind out walked'so like ticket n muttering mob that t the film did ` terrible [SEP]"]
[ 750/2000] tot_loss=1.808 (perp=8.590, rec=0.088, cos=0.002), tot_loss_proj:2.337 [t=0.19s]
prediction: ["[CLS] they'fun'horrible like cost but ` terrible'talkedssing, had the terrible di fun mind out walked'so like ticket n muttering mob that t the film did ` terrible [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.769 (perp=8.427, rec=0.082, cos=0.001), tot_loss_proj:2.304 [t=0.19s]
prediction: ["[CLS] they'fun like'horrible cost but ` terrible'talkedssing, had the terrible di fun mind out walked'so like ticket n muttering mob that t the film did ` terrible [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.750 (perp=8.330, rec=0.083, cos=0.001), tot_loss_proj:2.283 [t=0.18s]
prediction: ["[CLS] they'fun like'horrible cost but ` terrible'talkedssing, had the terrible di fun mind out walked'n like ticket so muttering mob that t the film did ` terrible [SEP]"]
[ 900/2000] tot_loss=1.821 (perp=8.659, rec=0.087, cos=0.001), tot_loss_proj:2.370 [t=0.19s]
prediction: ["[CLS] they'fun like'horrible cost but ` terrible words talkedssing, had the terrible di fun mind out walked'n like ticket so muttering mob that t the film did ` terrible [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.736 (perp=8.266, rec=0.081, cos=0.002), tot_loss_proj:2.317 [t=0.19s]
prediction: ["[CLS] they'fun like'horrible cost but ` terrible words dissing, had the terrible talked fun mind out walked'n like ticket so muttering strains that t the film did ` terrible [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.701 (perp=8.087, rec=0.082, cos=0.001), tot_loss_proj:2.284 [t=0.18s]
prediction: ["[CLS] they'out cost like'horrible but ` terrible words dissing, had the terrible talked fun mind out walked'n like ticket so muttering strains that t the film did ` terrible [SEP]"]
[1050/2000] tot_loss=1.702 (perp=8.087, rec=0.083, cos=0.001), tot_loss_proj:2.280 [t=0.19s]
prediction: ["[CLS] they'out cost like'horrible but ` terrible words dissing, had the terrible talked fun mind out walked'n like ticket so muttering strains that t the film did ` terrible [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.699 (perp=8.087, rec=0.080, cos=0.001), tot_loss_proj:2.276 [t=0.18s]
prediction: ["[CLS] they'out cost like'horrible but ` terrible words dissing, had the terrible talked fun mind out walked'n like ticket so muttering strains that t the film did ` terrible [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.738 (perp=8.308, rec=0.075, cos=0.001), tot_loss_proj:2.337 [t=0.18s]
prediction: ["[CLS] they'out cost like'very but ` horrible words dissing, had the terrible talked fun mind out walked'n like ticket so muttering strains that t the film ` did terrible [SEP]"]
[1200/2000] tot_loss=1.742 (perp=8.308, rec=0.079, cos=0.001), tot_loss_proj:2.339 [t=0.19s]
prediction: ["[CLS] they'out cost like'very but ` horrible words dissing, had the terrible talked fun mind out walked'n like ticket so muttering strains that t the film ` did terrible [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.718 (perp=8.144, rec=0.088, cos=0.002), tot_loss_proj:2.308 [t=0.19s]
prediction: ["[CLS] they'out cost like'very ` but horrible words dissing, had the terrible talked fun mind out walked'n like ticket so muttering strains that t the film ` did terrible [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.720 (perp=8.224, rec=0.073, cos=0.002), tot_loss_proj:2.304 [t=0.18s]
prediction: ["[CLS] they'out cost like'' ` but horrible words dissing, had the terrible talked fun mind out walked liken'ticket so muttering strains that t the film ` did terrible [SEP]"]
[1350/2000] tot_loss=1.743 (perp=8.306, rec=0.080, cos=0.002), tot_loss_proj:2.309 [t=0.19s]
prediction: ["[CLS] they'out cost like'' ` but horrible words dissing, had the terrible because fun mind out walked liken'ticket so muttering strains that t the film ` did terrible [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.714 (perp=8.161, rec=0.080, cos=0.002), tot_loss_proj:2.276 [t=0.19s]
prediction: ["[CLS] they'out cost like'' `, horrible words dissing but had the terrible because fun mind out walked liken'ticket so muttering strains that t the film ` did terrible [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.668 (perp=7.948, rec=0.077, cos=0.002), tot_loss_proj:2.201 [t=0.18s]
prediction: ["[CLS] they'out cost like'' `, horrible words dissing but had the terrible because fun mind walked out liken'ticket so muttering strains that t the film ` did terrible [SEP]"]
[1500/2000] tot_loss=1.673 (perp=7.948, rec=0.081, cos=0.002), tot_loss_proj:2.202 [t=0.19s]
prediction: ["[CLS] they'out cost like'' `, horrible words dissing but had the terrible because fun mind walked out liken'ticket so muttering strains that t the film ` did terrible [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.628 (perp=7.721, rec=0.082, cos=0.002), tot_loss_proj:2.155 [t=0.18s]
prediction: ["[CLS] they'out cost like,'`'horrible words dissing but had the terrible because fun mind walked out liken'ticket so muttering strains that t the film ` did terrible [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.602 (perp=7.598, rec=0.081, cos=0.001), tot_loss_proj:2.167 [t=0.18s]
prediction: ["[CLS] they'out cost like,'`'horrible words dissing because had the terrible but fun mind walked out liken'ticket so muttering strains that t the film ` did terrible [SEP]"]
[1650/2000] tot_loss=1.606 (perp=7.598, rec=0.085, cos=0.001), tot_loss_proj:2.173 [t=0.19s]
prediction: ["[CLS] they'out cost like,'`'horrible words dissing because had the terrible but fun mind walked out liken'ticket so muttering strains that t the film ` did terrible [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.598 (perp=7.571, rec=0.083, cos=0.002), tot_loss_proj:2.153 [t=0.18s]
prediction: ["[CLS] they'out cost like,'`'horrible words dissing because had the terrible but fun mind walked out liken'ticket strains muttering so that t the film ` did terrible [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.592 (perp=7.533, rec=0.084, cos=0.002), tot_loss_proj:2.163 [t=0.18s]
prediction: ["[CLS] they'out like,'cost `'horrible words dissing because had the terrible but fun mind walked out liken'ticket strains muttering so that t the film ` did terrible [SEP]"]
[1800/2000] tot_loss=1.583 (perp=7.533, rec=0.075, cos=0.001), tot_loss_proj:2.159 [t=0.18s]
prediction: ["[CLS] they'out like,'cost `'horrible words dissing because had the terrible but fun mind walked out liken'ticket strains muttering so that t the film ` did terrible [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.574 (perp=7.458, rec=0.081, cos=0.002), tot_loss_proj:2.230 [t=0.19s]
prediction: ["[CLS] they strains out like,'cost `'horrible words dissing because had the terrible but fun mind walked out liken'ticket'muttering so that t the film ` did terrible [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.562 (perp=7.442, rec=0.072, cos=0.001), tot_loss_proj:2.244 [t=0.18s]
prediction: ["[CLS] they strains out like,'cost `'horrible words dissing because had the terrible but fun mind walked out liken'ticket so muttering'that t the film ` did terrible [SEP]"]
[1950/2000] tot_loss=1.563 (perp=7.442, rec=0.074, cos=0.001), tot_loss_proj:2.249 [t=0.18s]
prediction: ["[CLS] they strains out like,'cost `'horrible words dissing because had the terrible but fun mind walked out liken'ticket so muttering'that t the film ` did terrible [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.571 (perp=7.442, rec=0.082, cos=0.001), tot_loss_proj:2.241 [t=0.18s]
prediction: ["[CLS] they strains out like,'cost `'horrible words dissing because had the terrible but fun mind walked out liken'ticket so muttering'that t the film ` did terrible [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] they'out cost like,'`'horrible words dissing but had the terrible because fun mind walked out liken'ticket so muttering strains that t the film ` did terrible [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.636 | p: 79.310 | r: 88.462
rouge2     | fm: 15.094 | p: 14.286 | r: 16.000
rougeL     | fm: 40.000 | p: 37.931 | r: 42.308
rougeLsum  | fm: 40.000 | p: 37.931 | r: 42.308
r1fm+r2fm = 98.731

[Aggregate metrics]:
rouge1     | fm: 92.614 | p: 92.126 | r: 93.253
rouge2     | fm: 56.578 | p: 56.325 | r: 56.861
rougeL     | fm: 78.480 | p: 78.135 | r: 78.941
rougeLsum  | fm: 78.511 | p: 78.129 | r: 79.024
r1fm+r2fm = 149.192

input #99 time: 0:07:34 | total time: 13:31:59


Average Cosine Similarity: 0.9992812683158312
Done with all.
