


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 1 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 1351.55it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.8816385521827378
highest_index [0]
highest [0.8816385521827378]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.950709342956543 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.8171788454055786 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.8099396824836731 for ['[CLS] tolerance receiving [SEP]']
[Init] best rec loss: 0.8099271059036255 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.7989488840103149 for ['[CLS] panel officer [SEP]']
[Init] best perm rec loss: 0.7954607009887695 for ['[CLS] officer panel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.349 (perp=9.554, rec=0.219, cos=0.219), tot_loss_proj:2.543 [t=0.18s]
prediction: ['[CLS] disappointed because [SEP]']
[ 100/2000] tot_loss=2.549 (perp=11.088, rec=0.113, cos=0.219), tot_loss_proj:2.796 [t=0.18s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 150/2000] tot_loss=2.524 (perp=11.088, rec=0.085, cos=0.221), tot_loss_proj:2.793 [t=0.22s]
prediction: ['[CLS] disappointed slightly [SEP]']
[ 200/2000] tot_loss=2.515 (perp=11.088, rec=0.077, cos=0.221), tot_loss_proj:2.794 [t=0.19s]
prediction: ['[CLS] disappointed slightly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.338 (perp=10.251, rec=0.068, cos=0.220), tot_loss_proj:2.345 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.346 (perp=10.251, rec=0.074, cos=0.222), tot_loss_proj:2.335 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.328 (perp=10.251, rec=0.056, cos=0.222), tot_loss_proj:2.346 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.318 (perp=10.251, rec=0.047, cos=0.221), tot_loss_proj:2.342 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.331 (perp=10.251, rec=0.058, cos=0.222), tot_loss_proj:2.337 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.319 (perp=10.251, rec=0.052, cos=0.218), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.339 (perp=10.251, rec=0.067, cos=0.222), tot_loss_proj:2.330 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.329 (perp=10.251, rec=0.056, cos=0.223), tot_loss_proj:2.350 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.334 (perp=10.251, rec=0.063, cos=0.221), tot_loss_proj:2.334 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.324 (perp=10.251, rec=0.052, cos=0.222), tot_loss_proj:2.340 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.341 (perp=10.251, rec=0.068, cos=0.222), tot_loss_proj:2.338 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.332 (perp=10.251, rec=0.059, cos=0.222), tot_loss_proj:2.336 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.325 (perp=10.251, rec=0.055, cos=0.221), tot_loss_proj:2.335 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.334 (perp=10.251, rec=0.061, cos=0.222), tot_loss_proj:2.325 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.334 (perp=10.251, rec=0.061, cos=0.222), tot_loss_proj:2.339 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.339 (perp=10.251, rec=0.066, cos=0.223), tot_loss_proj:2.346 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.334 (perp=10.251, rec=0.061, cos=0.223), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.336 (perp=10.251, rec=0.066, cos=0.220), tot_loss_proj:2.330 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.331 (perp=10.251, rec=0.059, cos=0.222), tot_loss_proj:2.344 [t=0.20s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.338 (perp=10.251, rec=0.065, cos=0.222), tot_loss_proj:2.343 [t=0.20s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.336 (perp=10.251, rec=0.064, cos=0.222), tot_loss_proj:2.339 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.339 (perp=10.251, rec=0.066, cos=0.223), tot_loss_proj:2.331 [t=0.20s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.325 (perp=10.251, rec=0.053, cos=0.223), tot_loss_proj:2.335 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.326 (perp=10.251, rec=0.053, cos=0.223), tot_loss_proj:2.346 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.349 (perp=10.251, rec=0.076, cos=0.223), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.331 (perp=10.251, rec=0.058, cos=0.223), tot_loss_proj:2.338 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.325 (perp=10.251, rec=0.054, cos=0.220), tot_loss_proj:2.334 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.333 (perp=10.251, rec=0.061, cos=0.222), tot_loss_proj:2.333 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.331 (perp=10.251, rec=0.058, cos=0.222), tot_loss_proj:2.342 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.327 (perp=10.251, rec=0.055, cos=0.222), tot_loss_proj:2.336 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.332 (perp=10.251, rec=0.060, cos=0.222), tot_loss_proj:2.336 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.336 (perp=10.251, rec=0.064, cos=0.223), tot_loss_proj:2.334 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.331 (perp=10.251, rec=0.059, cos=0.223), tot_loss_proj:2.351 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.340 (perp=10.251, rec=0.067, cos=0.223), tot_loss_proj:2.335 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.322 (perp=10.251, rec=0.049, cos=0.223), tot_loss_proj:2.329 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.337 (perp=10.251, rec=0.065, cos=0.223), tot_loss_proj:2.337 [t=0.31s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:08:20 | total time: 0:08:20


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.8183999970881315
highest_index [0]
highest [0.8183999970881315]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 0.9701926708221436 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9622064232826233 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.9542056322097778 for ['[CLS] consist waterloo [SEP]']
[Init] best rec loss: 0.9492364525794983 for ['[CLS] schedule sensors [SEP]']
[Init] best rec loss: 0.9453232884407043 for ['[CLS] vital conflict [SEP]']
[Init] best rec loss: 0.9444528818130493 for ['[CLS] } sex [SEP]']
[Init] best rec loss: 0.9375839829444885 for ['[CLS] received mountain [SEP]']
[Init] best rec loss: 0.8822393417358398 for ['[CLS] feeling play [SEP]']
[Init] best rec loss: 0.8447230458259583 for ["[CLS] giant'[SEP]"]
[Init] best perm rec loss: 0.8423231244087219 for ["[CLS]'giant [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=3.370 (perp=11.656, rec=0.737, cos=0.301), tot_loss_proj:4.285 [t=0.20s]
prediction: ['[CLS] catholics opposition [SEP]']
[ 100/2000] tot_loss=3.377 (perp=11.783, rec=0.707, cos=0.313), tot_loss_proj:4.035 [t=0.25s]
prediction: ['[CLS] burnt opposition [SEP]']
[ 150/2000] tot_loss=2.955 (perp=10.460, rec=0.619, cos=0.244), tot_loss_proj:3.735 [t=0.27s]
prediction: ['[CLS] burnt interception [SEP]']
[ 200/2000] tot_loss=2.707 (perp=9.171, rec=0.589, cos=0.283), tot_loss_proj:2.236 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.708 (perp=9.171, rec=0.558, cos=0.316), tot_loss_proj:2.220 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=2.666 (perp=9.171, rec=0.546, cos=0.286), tot_loss_proj:2.228 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.620 (perp=9.171, rec=0.535, cos=0.250), tot_loss_proj:2.232 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.652 (perp=9.171, rec=0.520, cos=0.298), tot_loss_proj:2.243 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=2.620 (perp=9.171, rec=0.517, cos=0.268), tot_loss_proj:2.229 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.666 (perp=9.171, rec=0.551, cos=0.281), tot_loss_proj:2.223 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.644 (perp=9.171, rec=0.499, cos=0.311), tot_loss_proj:2.227 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=2.575 (perp=9.171, rec=0.495, cos=0.246), tot_loss_proj:2.231 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.940 (perp=10.543, rec=0.509, cos=0.322), tot_loss_proj:2.744 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.872 (perp=10.543, rec=0.476, cos=0.288), tot_loss_proj:2.750 [t=0.19s]
prediction: ['[CLS] splendid splendid [SEP]']
[ 750/2000] tot_loss=2.921 (perp=10.543, rec=0.472, cos=0.340), tot_loss_proj:2.736 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.854 (perp=10.543, rec=0.477, cos=0.269), tot_loss_proj:2.738 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.860 (perp=10.543, rec=0.476, cos=0.275), tot_loss_proj:2.748 [t=0.25s]
prediction: ['[CLS] splendid splendid [SEP]']
[ 900/2000] tot_loss=2.861 (perp=10.543, rec=0.483, cos=0.269), tot_loss_proj:2.732 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.837 (perp=10.543, rec=0.462, cos=0.266), tot_loss_proj:2.751 [t=0.21s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1000/2000] tot_loss=2.848 (perp=10.543, rec=0.472, cos=0.267), tot_loss_proj:2.739 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
[1050/2000] tot_loss=2.876 (perp=10.543, rec=0.466, cos=0.301), tot_loss_proj:2.755 [t=0.25s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1100/2000] tot_loss=2.862 (perp=10.543, rec=0.466, cos=0.287), tot_loss_proj:2.736 [t=0.26s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1150/2000] tot_loss=2.878 (perp=10.543, rec=0.448, cos=0.321), tot_loss_proj:2.753 [t=0.24s]
prediction: ['[CLS] splendid splendid [SEP]']
[1200/2000] tot_loss=2.863 (perp=10.543, rec=0.454, cos=0.301), tot_loss_proj:2.753 [t=0.21s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1250/2000] tot_loss=2.849 (perp=10.543, rec=0.450, cos=0.291), tot_loss_proj:2.752 [t=0.24s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1300/2000] tot_loss=2.854 (perp=10.543, rec=0.461, cos=0.285), tot_loss_proj:2.754 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
[1350/2000] tot_loss=2.840 (perp=10.543, rec=0.451, cos=0.280), tot_loss_proj:2.733 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1400/2000] tot_loss=2.876 (perp=10.543, rec=0.455, cos=0.312), tot_loss_proj:2.740 [t=0.20s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1450/2000] tot_loss=2.869 (perp=10.543, rec=0.451, cos=0.310), tot_loss_proj:2.741 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
[1500/2000] tot_loss=2.862 (perp=10.543, rec=0.454, cos=0.300), tot_loss_proj:2.736 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1550/2000] tot_loss=2.857 (perp=10.543, rec=0.451, cos=0.297), tot_loss_proj:2.753 [t=0.19s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1600/2000] tot_loss=2.874 (perp=10.543, rec=0.444, cos=0.321), tot_loss_proj:2.741 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
[1650/2000] tot_loss=2.868 (perp=10.543, rec=0.453, cos=0.307), tot_loss_proj:2.735 [t=0.23s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1700/2000] tot_loss=2.859 (perp=10.543, rec=0.444, cos=0.306), tot_loss_proj:2.741 [t=0.27s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1750/2000] tot_loss=2.879 (perp=10.543, rec=0.449, cos=0.322), tot_loss_proj:2.745 [t=0.22s]
prediction: ['[CLS] splendid splendid [SEP]']
[1800/2000] tot_loss=2.858 (perp=10.543, rec=0.439, cos=0.310), tot_loss_proj:2.742 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1850/2000] tot_loss=2.865 (perp=10.543, rec=0.443, cos=0.313), tot_loss_proj:2.744 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[1900/2000] tot_loss=2.868 (perp=10.543, rec=0.436, cos=0.323), tot_loss_proj:2.737 [t=0.26s]
prediction: ['[CLS] splendid splendid [SEP]']
[1950/2000] tot_loss=2.867 (perp=10.543, rec=0.449, cos=0.309), tot_loss_proj:2.748 [t=0.18s]
prediction: ['[CLS] splendid splendid [SEP]']
Attempt swap
[2000/2000] tot_loss=2.882 (perp=10.543, rec=0.443, cos=0.330), tot_loss_proj:2.743 [t=0.26s]
prediction: ['[CLS] splendid splendid [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendid splendid [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 50.000 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 57.143 | p: 50.000 | r: 66.667
rougeLsum  | fm: 57.143 | p: 50.000 | r: 66.667
r1fm+r2fm = 57.143

[Aggregate metrics]:
rouge1     | fm: 78.571 | p: 75.000 | r: 83.333
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 78.571 | p: 75.000 | r: 83.333
rougeLsum  | fm: 78.571 | p: 75.000 | r: 83.333
r1fm+r2fm = 128.571

input #1 time: 0:08:26 | total time: 0:16:47


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.8601285920222788
highest_index [0]
highest [0.8601285920222788]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7175871729850769 for ['[CLS] wash〜 at [SEP]']
[Init] best perm rec loss: 0.7154011130332947 for ['[CLS]〜 at wash [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.579 (perp=10.108, rec=0.320, cos=0.238), tot_loss_proj:2.661 [t=0.21s]
prediction: ['[CLS] gaining power momentum [SEP]']
[ 100/2000] tot_loss=2.067 (perp=8.515, rec=0.108, cos=0.255), tot_loss_proj:2.037 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=2.028 (perp=8.515, rec=0.066, cos=0.259), tot_loss_proj:2.029 [t=0.28s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=2.028 (perp=8.515, rec=0.066, cos=0.259), tot_loss_proj:2.033 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.018 (perp=8.515, rec=0.056, cos=0.259), tot_loss_proj:2.024 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=2.020 (perp=8.515, rec=0.058, cos=0.259), tot_loss_proj:2.026 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.026 (perp=8.515, rec=0.064, cos=0.259), tot_loss_proj:2.029 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.025 (perp=8.515, rec=0.063, cos=0.259), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=2.010 (perp=8.515, rec=0.048, cos=0.259), tot_loss_proj:2.040 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.022 (perp=8.515, rec=0.060, cos=0.259), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.024 (perp=8.515, rec=0.061, cos=0.259), tot_loss_proj:2.038 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=2.025 (perp=8.515, rec=0.063, cos=0.259), tot_loss_proj:2.031 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.022 (perp=8.515, rec=0.060, cos=0.259), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.017 (perp=8.515, rec=0.055, cos=0.259), tot_loss_proj:2.044 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=2.019 (perp=8.515, rec=0.057, cos=0.259), tot_loss_proj:2.048 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.025 (perp=8.515, rec=0.062, cos=0.259), tot_loss_proj:2.022 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.014 (perp=8.515, rec=0.051, cos=0.259), tot_loss_proj:2.028 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=2.022 (perp=8.515, rec=0.060, cos=0.259), tot_loss_proj:2.037 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.024 (perp=8.515, rec=0.062, cos=0.260), tot_loss_proj:2.034 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=2.020 (perp=8.515, rec=0.057, cos=0.259), tot_loss_proj:2.038 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=2.027 (perp=8.515, rec=0.065, cos=0.259), tot_loss_proj:2.036 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=2.023 (perp=8.515, rec=0.061, cos=0.259), tot_loss_proj:2.044 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=2.020 (perp=8.515, rec=0.057, cos=0.259), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=2.025 (perp=8.515, rec=0.063, cos=0.259), tot_loss_proj:2.027 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=2.016 (perp=8.515, rec=0.054, cos=0.260), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=2.027 (perp=8.515, rec=0.065, cos=0.259), tot_loss_proj:2.034 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=2.019 (perp=8.515, rec=0.057, cos=0.259), tot_loss_proj:2.033 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=2.022 (perp=8.515, rec=0.059, cos=0.259), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=2.018 (perp=8.515, rec=0.056, cos=0.259), tot_loss_proj:2.030 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=2.020 (perp=8.515, rec=0.058, cos=0.259), tot_loss_proj:2.031 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=2.022 (perp=8.515, rec=0.060, cos=0.260), tot_loss_proj:2.036 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=2.027 (perp=8.515, rec=0.065, cos=0.259), tot_loss_proj:2.031 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=2.031 (perp=8.515, rec=0.068, cos=0.259), tot_loss_proj:2.044 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=2.017 (perp=8.515, rec=0.055, cos=0.259), tot_loss_proj:2.039 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=2.023 (perp=8.515, rec=0.061, cos=0.259), tot_loss_proj:2.043 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=2.016 (perp=8.515, rec=0.053, cos=0.260), tot_loss_proj:2.033 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=2.027 (perp=8.515, rec=0.064, cos=0.259), tot_loss_proj:2.027 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=2.025 (perp=8.515, rec=0.063, cos=0.259), tot_loss_proj:2.030 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=2.030 (perp=8.515, rec=0.067, cos=0.260), tot_loss_proj:2.023 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=2.018 (perp=8.515, rec=0.056, cos=0.259), tot_loss_proj:2.028 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 85.714 | p: 83.333 | r: 88.889
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 83.333 | r: 88.889
rougeLsum  | fm: 85.714 | p: 83.333 | r: 88.889
r1fm+r2fm = 152.381

input #2 time: 0:08:18 | total time: 0:25:06


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.8248615261381422
highest_index [0]
highest [0.8248615261381422]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9727191925048828 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.8335400223731995 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.828101396560669 for ['[CLS] lancashire isaac [SEP]']
[Init] best rec loss: 0.7918369770050049 for ['[CLS] end depart [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.832 (perp=11.076, rec=0.302, cos=0.315), tot_loss_proj:2.917 [t=0.17s]
prediction: ['[CLS] perfection flawless [SEP]']
[ 100/2000] tot_loss=2.104 (perp=8.385, rec=0.110, cos=0.317), tot_loss_proj:2.107 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/2000] tot_loss=2.066 (perp=8.385, rec=0.070, cos=0.319), tot_loss_proj:2.106 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
[ 200/2000] tot_loss=2.062 (perp=8.385, rec=0.066, cos=0.318), tot_loss_proj:2.104 [t=0.31s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.064 (perp=8.385, rec=0.070, cos=0.318), tot_loss_proj:2.082 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=2.065 (perp=8.385, rec=0.070, cos=0.319), tot_loss_proj:2.105 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.058 (perp=8.385, rec=0.062, cos=0.319), tot_loss_proj:2.106 [t=0.30s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.056 (perp=8.385, rec=0.060, cos=0.319), tot_loss_proj:2.106 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=2.062 (perp=8.385, rec=0.066, cos=0.319), tot_loss_proj:2.096 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.062 (perp=8.385, rec=0.066, cos=0.319), tot_loss_proj:2.100 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.053 (perp=8.385, rec=0.057, cos=0.319), tot_loss_proj:2.101 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=2.056 (perp=8.385, rec=0.060, cos=0.319), tot_loss_proj:2.090 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.059 (perp=8.385, rec=0.063, cos=0.319), tot_loss_proj:2.104 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.052 (perp=8.385, rec=0.056, cos=0.319), tot_loss_proj:2.112 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=2.040 (perp=8.385, rec=0.044, cos=0.319), tot_loss_proj:2.097 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.042 (perp=8.385, rec=0.046, cos=0.319), tot_loss_proj:2.088 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.053 (perp=8.385, rec=0.056, cos=0.319), tot_loss_proj:2.089 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=2.046 (perp=8.385, rec=0.050, cos=0.319), tot_loss_proj:2.103 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.060 (perp=8.385, rec=0.064, cos=0.319), tot_loss_proj:2.082 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=2.046 (perp=8.385, rec=0.049, cos=0.319), tot_loss_proj:2.107 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=2.064 (perp=8.385, rec=0.068, cos=0.319), tot_loss_proj:2.085 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=2.041 (perp=8.385, rec=0.045, cos=0.319), tot_loss_proj:2.097 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=2.054 (perp=8.385, rec=0.057, cos=0.319), tot_loss_proj:2.101 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=2.059 (perp=8.385, rec=0.062, cos=0.319), tot_loss_proj:2.090 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=2.053 (perp=8.385, rec=0.057, cos=0.319), tot_loss_proj:2.090 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=2.058 (perp=8.385, rec=0.062, cos=0.319), tot_loss_proj:2.107 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=2.053 (perp=8.385, rec=0.057, cos=0.319), tot_loss_proj:2.107 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=2.044 (perp=8.385, rec=0.048, cos=0.319), tot_loss_proj:2.094 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=2.063 (perp=8.385, rec=0.067, cos=0.319), tot_loss_proj:2.090 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=2.059 (perp=8.385, rec=0.063, cos=0.319), tot_loss_proj:2.085 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=2.047 (perp=8.385, rec=0.051, cos=0.319), tot_loss_proj:2.089 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=2.056 (perp=8.385, rec=0.060, cos=0.319), tot_loss_proj:2.096 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=2.056 (perp=8.385, rec=0.060, cos=0.319), tot_loss_proj:2.096 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=2.034 (perp=8.385, rec=0.038, cos=0.319), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=2.060 (perp=8.385, rec=0.064, cos=0.319), tot_loss_proj:2.088 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=2.051 (perp=8.385, rec=0.055, cos=0.319), tot_loss_proj:2.099 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=2.039 (perp=8.385, rec=0.042, cos=0.319), tot_loss_proj:2.093 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=2.052 (perp=8.385, rec=0.056, cos=0.319), tot_loss_proj:2.103 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=2.062 (perp=8.385, rec=0.066, cos=0.319), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=2.053 (perp=8.385, rec=0.057, cos=0.319), tot_loss_proj:2.102 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.286 | p: 87.500 | r: 91.667
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 89.286 | p: 87.500 | r: 91.667
rougeLsum  | fm: 89.286 | p: 87.500 | r: 91.667
r1fm+r2fm = 164.286

input #3 time: 0:08:11 | total time: 0:33:17


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.8769751520504598
highest_index [0]
highest [0.8769751520504598]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.96952885389328 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9338753819465637 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9239044785499573 for ['[CLS] rally entered worldwide [SEP]']
[Init] best rec loss: 0.9216598272323608 for ['[CLS]dge squareaway [SEP]']
[Init] best rec loss: 0.9211033582687378 for ['[CLS] paper under welsh [SEP]']
[Init] best rec loss: 0.8813302516937256 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.8700507879257202 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.865799605846405 for ['[CLS] could againstndra [SEP]']
[Init] best rec loss: 0.8620737195014954 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.246 (perp=13.949, rec=0.234, cos=0.222), tot_loss_proj:3.889 [t=0.25s]
prediction: ['[CLS] tires badlyrator [SEP]']
[ 100/2000] tot_loss=1.831 (perp=7.516, rec=0.101, cos=0.227), tot_loss_proj:1.811 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.809 (perp=7.516, rec=0.078, cos=0.228), tot_loss_proj:1.791 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.797 (perp=7.516, rec=0.065, cos=0.229), tot_loss_proj:1.801 [t=0.29s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.790 (perp=7.516, rec=0.058, cos=0.229), tot_loss_proj:1.799 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.819 (perp=7.516, rec=0.087, cos=0.229), tot_loss_proj:1.797 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.792 (perp=7.516, rec=0.060, cos=0.229), tot_loss_proj:1.793 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.798 (perp=7.516, rec=0.066, cos=0.229), tot_loss_proj:1.797 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.787 (perp=7.516, rec=0.054, cos=0.230), tot_loss_proj:1.801 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.796 (perp=7.516, rec=0.064, cos=0.229), tot_loss_proj:1.790 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.801 (perp=7.516, rec=0.069, cos=0.230), tot_loss_proj:1.808 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.800 (perp=7.516, rec=0.067, cos=0.230), tot_loss_proj:1.816 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.798 (perp=7.516, rec=0.066, cos=0.229), tot_loss_proj:1.793 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.797 (perp=7.516, rec=0.065, cos=0.229), tot_loss_proj:1.792 [t=0.28s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.788 (perp=7.516, rec=0.056, cos=0.230), tot_loss_proj:1.798 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.787 (perp=7.516, rec=0.054, cos=0.230), tot_loss_proj:1.796 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.793 (perp=7.516, rec=0.060, cos=0.230), tot_loss_proj:1.802 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.793 (perp=7.516, rec=0.060, cos=0.230), tot_loss_proj:1.806 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.782 (perp=7.516, rec=0.049, cos=0.230), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.808 (perp=7.516, rec=0.075, cos=0.230), tot_loss_proj:1.794 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.802 (perp=7.516, rec=0.069, cos=0.230), tot_loss_proj:1.809 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.801 (perp=7.516, rec=0.069, cos=0.230), tot_loss_proj:1.794 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.806 (perp=7.516, rec=0.073, cos=0.230), tot_loss_proj:1.803 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.792 (perp=7.516, rec=0.059, cos=0.230), tot_loss_proj:1.786 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.809 (perp=7.516, rec=0.077, cos=0.230), tot_loss_proj:1.803 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.808 (perp=7.516, rec=0.075, cos=0.230), tot_loss_proj:1.793 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.804 (perp=7.516, rec=0.071, cos=0.230), tot_loss_proj:1.806 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.785 (perp=7.516, rec=0.052, cos=0.230), tot_loss_proj:1.802 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.783 (perp=7.516, rec=0.050, cos=0.230), tot_loss_proj:1.802 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.795 (perp=7.516, rec=0.062, cos=0.230), tot_loss_proj:1.813 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.793 (perp=7.516, rec=0.060, cos=0.230), tot_loss_proj:1.792 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.802 (perp=7.516, rec=0.069, cos=0.230), tot_loss_proj:1.794 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.778 (perp=7.516, rec=0.045, cos=0.230), tot_loss_proj:1.782 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.783 (perp=7.516, rec=0.050, cos=0.230), tot_loss_proj:1.790 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.791 (perp=7.516, rec=0.058, cos=0.230), tot_loss_proj:1.794 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.797 (perp=7.516, rec=0.065, cos=0.230), tot_loss_proj:1.787 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.799 (perp=7.516, rec=0.066, cos=0.230), tot_loss_proj:1.793 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.800 (perp=7.516, rec=0.067, cos=0.230), tot_loss_proj:1.804 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.801 (perp=7.516, rec=0.068, cos=0.230), tot_loss_proj:1.798 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.782 (perp=7.516, rec=0.049, cos=0.230), tot_loss_proj:1.787 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.429 | p: 90.000 | r: 93.333
rouge2     | fm: 80.000 | p: 80.000 | r: 80.000
rougeL     | fm: 91.429 | p: 90.000 | r: 93.333
rougeLsum  | fm: 91.429 | p: 90.000 | r: 93.333
r1fm+r2fm = 171.429

input #4 time: 0:08:23 | total time: 0:41:40


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.8236732059681047
highest_index [0]
highest [0.8236732059681047]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9813829064369202 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9555556774139404 for ['[CLS] juathic [SEP]']
[Init] best rec loss: 0.9495815634727478 for ['[CLS] those legs [SEP]']
[Init] best rec loss: 0.9433021545410156 for ['[CLS] preservation notre [SEP]']
[Init] best rec loss: 0.9344522356987 for ['[CLS] institution wanting [SEP]']
[Init] best rec loss: 0.9313395619392395 for ['[CLS] reid supportive [SEP]']
[Init] best rec loss: 0.9143791794776917 for ['[CLS] baby face [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.550 (perp=12.621, rec=0.758, cos=0.267), tot_loss_proj:4.235 [t=0.22s]
prediction: ['[CLS] introductionsович [SEP]']
[ 100/2000] tot_loss=3.155 (perp=10.998, rec=0.657, cos=0.298), tot_loss_proj:4.229 [t=0.23s]
prediction: ['[CLS] categoryович [SEP]']
[ 150/2000] tot_loss=3.086 (perp=10.998, rec=0.670, cos=0.217), tot_loss_proj:4.228 [t=0.19s]
prediction: ['[CLS] categoryович [SEP]']
[ 200/2000] tot_loss=3.071 (perp=10.870, rec=0.584, cos=0.313), tot_loss_proj:3.790 [t=0.20s]
prediction: ['[CLS] timing ease [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.239 (perp=12.316, rec=0.564, cos=0.212), tot_loss_proj:2.839 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 300/2000] tot_loss=3.331 (perp=12.316, rec=0.542, cos=0.326), tot_loss_proj:2.845 [t=0.29s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.294 (perp=12.316, rec=0.532, cos=0.299), tot_loss_proj:2.841 [t=0.23s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.226 (perp=12.316, rec=0.529, cos=0.234), tot_loss_proj:2.850 [t=0.23s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 450/2000] tot_loss=3.235 (perp=12.316, rec=0.530, cos=0.242), tot_loss_proj:2.835 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.255 (perp=12.316, rec=0.497, cos=0.295), tot_loss_proj:2.842 [t=0.24s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.205 (perp=12.316, rec=0.510, cos=0.232), tot_loss_proj:2.839 [t=0.22s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 600/2000] tot_loss=3.262 (perp=12.316, rec=0.501, cos=0.298), tot_loss_proj:2.850 [t=0.21s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.247 (perp=12.316, rec=0.511, cos=0.273), tot_loss_proj:2.853 [t=0.23s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.214 (perp=12.316, rec=0.493, cos=0.257), tot_loss_proj:2.849 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 750/2000] tot_loss=3.195 (perp=12.316, rec=0.485, cos=0.247), tot_loss_proj:2.853 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.188 (perp=12.316, rec=0.485, cos=0.239), tot_loss_proj:2.843 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.208 (perp=12.316, rec=0.482, cos=0.263), tot_loss_proj:2.850 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 900/2000] tot_loss=3.205 (perp=12.316, rec=0.500, cos=0.241), tot_loss_proj:2.845 [t=0.26s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.240 (perp=12.316, rec=0.468, cos=0.309), tot_loss_proj:2.852 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1000/2000] tot_loss=3.245 (perp=12.316, rec=0.470, cos=0.312), tot_loss_proj:2.833 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1050/2000] tot_loss=3.207 (perp=12.316, rec=0.471, cos=0.272), tot_loss_proj:2.852 [t=0.23s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1100/2000] tot_loss=3.010 (perp=11.370, rec=0.461, cos=0.275), tot_loss_proj:3.961 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1150/2000] tot_loss=3.031 (perp=11.370, rec=0.464, cos=0.294), tot_loss_proj:3.956 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
[1200/2000] tot_loss=3.009 (perp=11.370, rec=0.453, cos=0.282), tot_loss_proj:3.950 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1250/2000] tot_loss=3.019 (perp=11.370, rec=0.462, cos=0.283), tot_loss_proj:3.962 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1300/2000] tot_loss=3.019 (perp=11.370, rec=0.455, cos=0.290), tot_loss_proj:3.950 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
[1350/2000] tot_loss=3.033 (perp=11.370, rec=0.464, cos=0.295), tot_loss_proj:3.954 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1400/2000] tot_loss=3.035 (perp=11.370, rec=0.461, cos=0.300), tot_loss_proj:3.953 [t=0.21s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1450/2000] tot_loss=3.031 (perp=11.370, rec=0.451, cos=0.306), tot_loss_proj:3.957 [t=0.21s]
prediction: ['[CLS] ease ease [SEP]']
[1500/2000] tot_loss=3.056 (perp=11.370, rec=0.458, cos=0.324), tot_loss_proj:3.960 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1550/2000] tot_loss=3.034 (perp=11.370, rec=0.450, cos=0.310), tot_loss_proj:3.956 [t=0.23s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1600/2000] tot_loss=3.045 (perp=11.370, rec=0.454, cos=0.317), tot_loss_proj:3.957 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
[1650/2000] tot_loss=3.045 (perp=11.370, rec=0.449, cos=0.321), tot_loss_proj:3.962 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1700/2000] tot_loss=3.040 (perp=11.370, rec=0.449, cos=0.317), tot_loss_proj:3.957 [t=0.23s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1750/2000] tot_loss=3.037 (perp=11.370, rec=0.449, cos=0.314), tot_loss_proj:3.951 [t=0.19s]
prediction: ['[CLS] ease ease [SEP]']
[1800/2000] tot_loss=3.030 (perp=11.370, rec=0.445, cos=0.311), tot_loss_proj:3.946 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1850/2000] tot_loss=3.038 (perp=11.370, rec=0.451, cos=0.313), tot_loss_proj:3.953 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1900/2000] tot_loss=3.027 (perp=11.370, rec=0.445, cos=0.307), tot_loss_proj:3.956 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
[1950/2000] tot_loss=3.040 (perp=11.370, rec=0.455, cos=0.311), tot_loss_proj:3.953 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[2000/2000] tot_loss=3.034 (perp=11.370, rec=0.447, cos=0.313), tot_loss_proj:3.958 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 88.690 | p: 87.500 | r: 90.278
rouge2     | fm: 72.222 | p: 72.222 | r: 72.222
rougeL     | fm: 88.690 | p: 87.500 | r: 90.278
rougeLsum  | fm: 88.690 | p: 87.500 | r: 90.278
r1fm+r2fm = 160.913

input #5 time: 0:08:10 | total time: 0:49:50


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.8918763305077556
highest_index [0]
highest [0.8918763305077556]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9211199879646301 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9203128814697266 for ['[CLS] main natural [SEP]']
[Init] best rec loss: 0.7890889644622803 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.7765814661979675 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.7562983632087708 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.7250957489013672 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7047967910766602 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.6881719827651978 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 0.6869768500328064 for ['[CLS] demolition tre [SEP]']
[Init] best rec loss: 0.6589066386222839 for ['[CLS] double deep [SEP]']
[Init] best perm rec loss: 0.6547788977622986 for ['[CLS] deep double [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.502 (perp=10.460, rec=0.209, cos=0.202), tot_loss_proj:2.721 [t=0.17s]
prediction: ['[CLS]ish gray [SEP]']
[ 100/2000] tot_loss=2.371 (perp=10.460, rec=0.079, cos=0.200), tot_loss_proj:2.713 [t=0.17s]
prediction: ['[CLS]ish gray [SEP]']
[ 150/2000] tot_loss=2.367 (perp=10.460, rec=0.072, cos=0.203), tot_loss_proj:2.721 [t=0.23s]
prediction: ['[CLS]ish gray [SEP]']
[ 200/2000] tot_loss=2.354 (perp=10.460, rec=0.058, cos=0.204), tot_loss_proj:2.725 [t=0.24s]
prediction: ['[CLS]ish gray [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.890 (perp=8.089, rec=0.073, cos=0.200), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.872 (perp=8.089, rec=0.051, cos=0.204), tot_loss_proj:1.900 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.882 (perp=8.089, rec=0.060, cos=0.204), tot_loss_proj:1.897 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.888 (perp=8.089, rec=0.066, cos=0.204), tot_loss_proj:1.907 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.885 (perp=8.089, rec=0.062, cos=0.204), tot_loss_proj:1.891 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.880 (perp=8.089, rec=0.059, cos=0.204), tot_loss_proj:1.899 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.877 (perp=8.089, rec=0.055, cos=0.204), tot_loss_proj:1.903 [t=0.29s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.896 (perp=8.089, rec=0.073, cos=0.205), tot_loss_proj:1.897 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.870 (perp=8.089, rec=0.048, cos=0.204), tot_loss_proj:1.894 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.876 (perp=8.089, rec=0.058, cos=0.200), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.873 (perp=8.089, rec=0.052, cos=0.203), tot_loss_proj:1.896 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.878 (perp=8.089, rec=0.056, cos=0.204), tot_loss_proj:1.892 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.876 (perp=8.089, rec=0.054, cos=0.204), tot_loss_proj:1.906 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.879 (perp=8.089, rec=0.057, cos=0.204), tot_loss_proj:1.890 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.892 (perp=8.089, rec=0.070, cos=0.204), tot_loss_proj:1.896 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.882 (perp=8.089, rec=0.063, cos=0.201), tot_loss_proj:1.896 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.886 (perp=8.089, rec=0.065, cos=0.204), tot_loss_proj:1.891 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.883 (perp=8.089, rec=0.061, cos=0.204), tot_loss_proj:1.897 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.883 (perp=8.089, rec=0.061, cos=0.204), tot_loss_proj:1.892 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.879 (perp=8.089, rec=0.057, cos=0.204), tot_loss_proj:1.876 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.886 (perp=8.089, rec=0.064, cos=0.204), tot_loss_proj:1.890 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.885 (perp=8.089, rec=0.063, cos=0.204), tot_loss_proj:1.882 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.876 (perp=8.089, rec=0.057, cos=0.202), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.886 (perp=8.089, rec=0.065, cos=0.204), tot_loss_proj:1.888 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.882 (perp=8.089, rec=0.060, cos=0.204), tot_loss_proj:1.892 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.885 (perp=8.089, rec=0.063, cos=0.204), tot_loss_proj:1.889 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.875 (perp=8.089, rec=0.053, cos=0.204), tot_loss_proj:1.887 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.888 (perp=8.089, rec=0.066, cos=0.204), tot_loss_proj:1.894 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.885 (perp=8.089, rec=0.063, cos=0.204), tot_loss_proj:1.887 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.877 (perp=8.089, rec=0.055, cos=0.204), tot_loss_proj:1.886 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.873 (perp=8.089, rec=0.051, cos=0.204), tot_loss_proj:1.887 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.888 (perp=8.089, rec=0.066, cos=0.204), tot_loss_proj:1.898 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.878 (perp=8.089, rec=0.055, cos=0.204), tot_loss_proj:1.899 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.894 (perp=8.089, rec=0.072, cos=0.204), tot_loss_proj:1.901 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.886 (perp=8.089, rec=0.064, cos=0.204), tot_loss_proj:1.896 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.880 (perp=8.089, rec=0.058, cos=0.204), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.306 | p: 89.286 | r: 91.667
rouge2     | fm: 76.190 | p: 76.190 | r: 76.190
rougeL     | fm: 90.306 | p: 89.286 | r: 91.667
rougeLsum  | fm: 90.306 | p: 89.286 | r: 91.667
r1fm+r2fm = 166.497

input #6 time: 0:08:12 | total time: 0:58:03


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9034098142743746
highest_index [0]
highest [0.9034098142743746]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.863567054271698 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8067464232444763 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8027425408363342 for ['[CLS] strengths kenton bond victimsmined absent se sides deed gavin making resides renewed magic antarctica clarebalance gaingnapressive need another easy fell race merged [SEP]']
[Init] best rec loss: 0.7935410737991333 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.7871045470237732 for ['[CLS] ni maintained micro aces echo all behind legal somethingelli stanley park d conspiracy medicine childbation jobtative hop rule fighting early twins sykes line [SEP]']
[Init] best rec loss: 0.7865518927574158 for ['[CLS] loss soup division sloane distress trailision stills jordan rain free⁄ the long o endallmbling live reader bat vaughn joint standing class minute [SEP]']
[Init] best perm rec loss: 0.7861496806144714 for ['[CLS] minute live trail sloaneision long⁄ end loss stills the jointmbling standing o division rain bat soup class free jordan vaughnall reader distress [SEP]']
[Init] best perm rec loss: 0.7852265238761902 for ['[CLS] class⁄ distressall sloane joint long rain jordan minute division the lossision stills end trail standing free bat vaughn soup livembling o reader [SEP]']
[Init] best perm rec loss: 0.7846407890319824 for ['[CLS]⁄ vaughn distress stills jordan minute the sloane joint class free division long loss liveall standingision o bat readermbling end soup trail rain [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.929 (perp=11.871, rec=0.385, cos=0.170), tot_loss_proj:3.452 [t=0.23s]
prediction: ['[CLS] problem clause equivalent or conesnarebber? it bullshit radio toiletsen records suspects ship problem expense deposit were va problem sure whistled problem [SEP]']
[ 100/2000] tot_loss=2.680 (perp=11.029, rec=0.308, cos=0.166), tot_loss_proj:3.203 [t=0.18s]
prediction: ['[CLS] problem word equivalent or u guy!?? it disappeared radio actual was any was blown problem department glare him gun problem sure exclusive problem [SEP]']
[ 150/2000] tot_loss=2.805 (perp=11.873, rec=0.251, cos=0.180), tot_loss_proj:3.481 [t=0.18s]
prediction: ['[CLS] copies least boyfriend no his guy.øy no it nothing phone less is it was is problem department puzzle him! problem sure unique problem [SEP]']
[ 200/2000] tot_loss=2.317 (perp=9.621, rec=0.222, cos=0.171), tot_loss_proj:2.957 [t=0.21s]
prediction: ['[CLS] except leaf virginity no his person. temper no or nothing off less is problem was is problem character characters him! problem no unique character [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.277 (perp=9.699, rec=0.194, cos=0.143), tot_loss_proj:3.341 [t=0.23s]
prediction: ['[CLS] cute leaf virginity no he characters. souls no! nothing jones not is problem was is problem character character, or problem no unique character [SEP]']
[ 300/2000] tot_loss=2.207 (perp=9.337, rec=0.161, cos=0.178), tot_loss_proj:3.007 [t=0.22s]
prediction: ['[CLS] ugly includes virginity here he characters.able no! nothing jones not is problem ; is problem character love, or problem no cute character [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.055 (perp=8.704, rec=0.148, cos=0.167), tot_loss_proj:3.419 [t=0.20s]
prediction: ['[CLS] or includes relatively here he factor. love no ugly nothing cute not the problem ; is problem character love, or problem no cute character [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.030 (perp=8.474, rec=0.152, cos=0.183), tot_loss_proj:3.300 [t=0.19s]
prediction: ['[CLS] or includes relatively here he factor.able no ugly no cute ; not the ugly is problem character love, or problem no cute character [SEP]']
[ 450/2000] tot_loss=1.918 (perp=8.199, rec=0.121, cos=0.157), tot_loss_proj:3.329 [t=0.19s]
prediction: ['[CLS]. is relatively here he factor.able no ugly no mind ; not the ugly is problem character love, or problem no cute character [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.938 (perp=8.214, rec=0.122, cos=0.173), tot_loss_proj:3.479 [t=0.23s]
prediction: ['[CLS].. relatively here he factor isable no ugly no mind ; not the ugly is problem character love, or problem i cute factor [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.809 (perp=7.655, rec=0.121, cos=0.158), tot_loss_proj:3.318 [t=0.19s]
prediction: ['[CLS].. relativelyable he factor is here no ugly no mind ; not the ugly is problem character love, or problem i cute factor [SEP]']
[ 600/2000] tot_loss=1.810 (perp=7.655, rec=0.108, cos=0.171), tot_loss_proj:3.319 [t=0.19s]
prediction: ['[CLS].. relativelyable he factor is here no ugly no mind ; not the ugly is problem character love, or problem i cute factor [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.825 (perp=7.724, rec=0.106, cos=0.174), tot_loss_proj:3.330 [t=0.30s]
prediction: ['[CLS].. relativelyable he factor here, no ugly no mind ; not the ugly is problem character love, or problem i cute factor [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.820 (perp=7.675, rec=0.107, cos=0.178), tot_loss_proj:3.218 [t=0.22s]
prediction: ['[CLS].. relativelyable he factor here, no ugly no mind ; not the ugly is character love problem, or problem i cute factor [SEP]']
[ 750/2000] tot_loss=1.812 (perp=7.675, rec=0.100, cos=0.177), tot_loss_proj:3.216 [t=0.24s]
prediction: ['[CLS].. relativelyable he factor here, no ugly no mind ; not the ugly is character love problem, or problem i cute factor [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.768 (perp=7.469, rec=0.096, cos=0.178), tot_loss_proj:3.399 [t=0.18s]
prediction: ['[CLS].. relativelyable he factor here, no ugly the mind ; not no ugly is character love problem, or problem i cute factor [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.715 (perp=7.338, rec=0.088, cos=0.159), tot_loss_proj:3.215 [t=0.27s]
prediction: ['[CLS].. relativelyable he factor here, no ugly cute mind ; not no ugly is character love problem, or problem i the factor [SEP]']
[ 900/2000] tot_loss=1.723 (perp=7.338, rec=0.085, cos=0.171), tot_loss_proj:3.212 [t=0.24s]
prediction: ['[CLS].. relativelyable he factor here, no ugly cute mind ; not no ugly is character love problem, or problem i the factor [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.712 (perp=7.221, rec=0.095, cos=0.173), tot_loss_proj:3.202 [t=0.26s]
prediction: ['[CLS].. relativelyable he factor here, no ugly cute mind ; not no ugly is character love problem, or problem the i factor [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.705 (perp=7.208, rec=0.089, cos=0.174), tot_loss_proj:3.264 [t=0.23s]
prediction: ['[CLS].. relatively heable factor here, no ugly cute mind ; not no ugly is character love problem, or problem the i factor [SEP]']
[1050/2000] tot_loss=1.699 (perp=7.208, rec=0.082, cos=0.175), tot_loss_proj:3.261 [t=0.25s]
prediction: ['[CLS].. relatively heable factor here, no ugly cute mind ; not no ugly is character love problem, or problem the i factor [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.677 (perp=7.075, rec=0.087, cos=0.175), tot_loss_proj:3.236 [t=0.20s]
prediction: ['[CLS].. relatively heable factor here. no ugly cute mind ; not ugly is no character love problem, or problem the i factor [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.704 (perp=7.174, rec=0.091, cos=0.178), tot_loss_proj:2.818 [t=0.24s]
prediction: ['[CLS].. not heable factor here has no ugly cute mind ; relatively ugly is no character love problem, or problem the i factor [SEP]']
[1200/2000] tot_loss=1.691 (perp=7.174, rec=0.081, cos=0.175), tot_loss_proj:2.816 [t=0.22s]
prediction: ['[CLS].. not heable factor here has no ugly cute mind ; relatively ugly is no character love problem, or problem the i factor [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.666 (perp=7.061, rec=0.079, cos=0.175), tot_loss_proj:2.702 [t=0.23s]
prediction: ['[CLS].. not heable factor here has no cute ugly mind ; relatively ugly is no character love problem, or problem the i factor [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.627 (perp=6.853, rec=0.081, cos=0.175), tot_loss_proj:2.455 [t=0.20s]
prediction: ['[CLS].. not heable factor here has no cute i mind ; relatively ugly is no character love problem, or problem the ugly factor [SEP]']
[1350/2000] tot_loss=1.626 (perp=6.853, rec=0.081, cos=0.175), tot_loss_proj:2.460 [t=0.18s]
prediction: ['[CLS].. not heable factor here has no cute i mind ; relatively ugly is no character love problem, or problem the ugly factor [SEP]']
Attempt swap
[1400/2000] tot_loss=1.640 (perp=6.853, rec=0.094, cos=0.175), tot_loss_proj:2.455 [t=0.19s]
prediction: ['[CLS].. not heable factor here has no cute i mind ; relatively ugly is no character love problem, or problem the ugly factor [SEP]']
Attempt swap
[1450/2000] tot_loss=1.623 (perp=6.853, rec=0.077, cos=0.176), tot_loss_proj:2.460 [t=0.20s]
prediction: ['[CLS].. not heable factor here has no cute i mind ; relatively ugly is no character love problem, or problem the ugly factor [SEP]']
[1500/2000] tot_loss=1.626 (perp=6.853, rec=0.080, cos=0.176), tot_loss_proj:2.456 [t=0.25s]
prediction: ['[CLS].. not heable factor here has no cute i mind ; relatively ugly is no character love problem, or problem the ugly factor [SEP]']
Attempt swap
[1550/2000] tot_loss=1.628 (perp=6.853, rec=0.081, cos=0.176), tot_loss_proj:2.456 [t=0.18s]
prediction: ['[CLS].. not heable factor here has no cute i mind ; relatively ugly is no character love problem, or problem the ugly factor [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.592 (perp=6.671, rec=0.082, cos=0.176), tot_loss_proj:2.380 [t=0.24s]
prediction: ['[CLS].. not heable factor here problem no cute i mind ; otherwise ugly is no character love problem, or has the ugly factor [SEP]']
[1650/2000] tot_loss=1.594 (perp=6.671, rec=0.084, cos=0.176), tot_loss_proj:2.383 [t=0.18s]
prediction: ['[CLS].. not heable factor here problem no cute i mind ; otherwise ugly is no character love problem, or has the ugly factor [SEP]']
Attempt swap
[1700/2000] tot_loss=1.589 (perp=6.671, rec=0.079, cos=0.176), tot_loss_proj:2.381 [t=0.24s]
prediction: ['[CLS].. not heable factor here problem no cute i mind ; otherwise ugly is no character love problem, or has the ugly factor [SEP]']
Attempt swap
[1750/2000] tot_loss=1.589 (perp=6.671, rec=0.078, cos=0.177), tot_loss_proj:2.378 [t=0.26s]
prediction: ['[CLS].. not heable factor here problem no cute i mind ; otherwise ugly is no character love problem, or has the ugly factor [SEP]']
[1800/2000] tot_loss=1.590 (perp=6.671, rec=0.080, cos=0.176), tot_loss_proj:2.379 [t=0.26s]
prediction: ['[CLS].. not heable factor here problem no cute i mind ; otherwise ugly is no character love problem, or has the ugly factor [SEP]']
Attempt swap
[1850/2000] tot_loss=1.594 (perp=6.671, rec=0.083, cos=0.176), tot_loss_proj:2.380 [t=0.19s]
prediction: ['[CLS].. not heable factor here problem no cute i mind ; otherwise ugly is no character love problem, or has the ugly factor [SEP]']
Attempt swap
[1900/2000] tot_loss=1.588 (perp=6.671, rec=0.077, cos=0.176), tot_loss_proj:2.380 [t=0.19s]
prediction: ['[CLS].. not heable factor here problem no cute i mind ; otherwise ugly is no character love problem, or has the ugly factor [SEP]']
[1950/2000] tot_loss=1.595 (perp=6.671, rec=0.084, cos=0.177), tot_loss_proj:2.385 [t=0.18s]
prediction: ['[CLS].. not heable factor here problem no cute i mind ; otherwise ugly is no character love problem, or has the ugly factor [SEP]']
Attempt swap
[2000/2000] tot_loss=1.594 (perp=6.671, rec=0.083, cos=0.177), tot_loss_proj:2.382 [t=0.25s]
prediction: ['[CLS].. not heable factor here problem no cute i mind ; otherwise ugly is no character love problem, or has the ugly factor [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS].. not heable factor here problem no cute i mind ; otherwise ugly is no character love problem, or has the ugly factor [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 78.261 | r: 85.714
rouge2     | fm: 19.048 | p: 18.182 | r: 20.000
rougeL     | fm: 50.000 | p: 47.826 | r: 52.381
rougeLsum  | fm: 50.000 | p: 47.826 | r: 52.381
r1fm+r2fm = 100.866

[Aggregate metrics]:
rouge1     | fm: 89.286 | p: 87.908 | r: 90.923
rouge2     | fm: 69.048 | p: 68.939 | r: 69.167
rougeL     | fm: 85.268 | p: 84.375 | r: 87.500
rougeLsum  | fm: 85.268 | p: 84.103 | r: 86.756
r1fm+r2fm = 158.333

input #7 time: 0:08:29 | total time: 1:06:32


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9068075592265654
highest_index [0]
highest [0.9068075592265654]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.6738892197608948 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.6710774898529053 for ['[CLS] intra selfir major model centraliard doesncy do strait everyonetes exactly respect fine [UNK] musical smallerton eagleump bet recent [SEP]']
[Init] best rec loss: 0.6709109544754028 for ['[CLS] proto palms traffic domesticd fee linkoot provincial peach karma watchflight corbin phone strategies mad impossible west morris shot shiny handball medical [SEP]']
[Init] best rec loss: 0.6580982208251953 for ['[CLS] breed app king jude rome am regal roman grown levi mine fitting peninsula cappella age bulldogs component founder macarthur unionist overturegible raysstock [SEP]']
[Init] best rec loss: 0.6495086550712585 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.6493655443191528 for ['[CLS] andhra basque richards surrounding rockwell gloss rodeo series balanced waived word line plan styx responsible wish procession than attentionrave retention past doe tv [SEP]']
[Init] best perm rec loss: 0.6464521884918213 for ['[CLS] surrounding responsible retention plan rodeo procession balanced wish richards doe attention gloss rockwell basque styx line waived word pastrave than tv andhra series [SEP]']
[Init] best perm rec loss: 0.6462417244911194 for ['[CLS] plan attention thanrave series responsible past balanced richards surrounding rockwell word line andhra gloss waived retention procession styx doe tv rodeo wish basque [SEP]']
[Init] best perm rec loss: 0.646196186542511 for ['[CLS] basque tv than surrounding balanced richards line styx responsiblerave series retention attention doe rockwell rodeo procession gloss past waived word wish plan andhra [SEP]']
[Init] best perm rec loss: 0.6435730457305908 for ['[CLS] responsible rodeo gloss balanced rockwellrave series tv waived wish richards doe attention past andhra than procession basque styx plan retention line word surrounding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.181 (perp=13.043, rec=0.464, cos=0.108), tot_loss_proj:4.217 [t=0.22s]
prediction: ['[CLS] income ‖ forgotten noble killed film cases murder british bail free sold because veterans off vanity inmates injustice fearing political trade lost hollywood serena [SEP]']
[ 100/2000] tot_loss=2.828 (perp=11.677, rec=0.385, cos=0.108), tot_loss_proj:3.879 [t=0.22s]
prediction: ['[CLS] income ‖ my vanity vanity filmsive murder might pay becauset what person off vanity paid debt vanity debt trade due vanity gambling [SEP]']
[ 150/2000] tot_loss=2.939 (perp=12.531, rec=0.254, cos=0.179), tot_loss_proj:3.979 [t=0.18s]
prediction: ["[CLS] income vanity'vanity vanity filmsive fright dollars pays becauset what person off vanity paid debt vanity debt trade owed vanity vanity [SEP]"]
[ 200/2000] tot_loss=2.946 (perp=12.746, rec=0.250, cos=0.147), tot_loss_proj:3.924 [t=0.20s]
prediction: ['[CLS] vanity vanity film vanity vanity film : fright though pays not what debt off vanity paid debt vanity financialve owed vanity likely [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.803 (perp=12.199, rec=0.207, cos=0.156), tot_loss_proj:3.852 [t=0.18s]
prediction: ["[CLS] vanity a'vanity vanity film vanity fright though pays not what debt off vanity pays debt vanity debti owed vanity doubt [SEP]"]
[ 300/2000] tot_loss=2.797 (perp=12.199, rec=0.178, cos=0.179), tot_loss_proj:3.845 [t=0.27s]
prediction: ["[CLS] vanity a'vanity vanity film vanity fright though pays not what debt off vanity pays debt vanity debti owed vanity doubt [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.865 (perp=12.567, rec=0.203, cos=0.148), tot_loss_proj:4.023 [t=0.19s]
prediction: ['[CLS] ai vanity vanity film vanity fright least pays [SEP]t what debt off vanity ariel paid debt vanity... they owed down doubt [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.437 (perp=10.460, rec=0.183, cos=0.161), tot_loss_proj:3.538 [t=0.20s]
prediction: ["[CLS] a arieli vanity vanity film vanity fright anyway pays no'what debt off vanity pays debt vanity. they owed benign doubt [SEP]"]
[ 450/2000] tot_loss=2.426 (perp=10.460, rec=0.164, cos=0.169), tot_loss_proj:3.540 [t=0.27s]
prediction: ["[CLS] a arieli vanity vanity film vanity fright anyway pays no'what debt off vanity pays debt vanity. they owed benign doubt [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.399 (perp=10.464, rec=0.158, cos=0.148), tot_loss_proj:3.393 [t=0.25s]
prediction: ['[CLS] a ariely vanity vanity film vanity fright anyway pays no where what debt. vanity pays debt vanity off they owed benign doubt [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.408 (perp=10.483, rec=0.150, cos=0.161), tot_loss_proj:3.491 [t=0.19s]
prediction: ['[CLS] ay ® vanity vanity film vanity fright anyway pays no where what debt, vanity pays debt vanity off they owed benign doubt [SEP]']
[ 600/2000] tot_loss=2.590 (perp=11.380, rec=0.144, cos=0.169), tot_loss_proj:3.614 [t=0.19s]
prediction: ['[CLS] ai juarezmax vanity film vanity fright anyway pays no where what debt, vanity pays debt vanity off they owed benign doubt [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.461 (perp=10.698, rec=0.183, cos=0.138), tot_loss_proj:3.624 [t=0.19s]
prediction: ['[CLS] a doubt gnumax vanity film vanity fright often pays not what feeling of vanity pays debt vanity off they owed benign resident [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.263 (perp=9.795, rec=0.154, cos=0.150), tot_loss_proj:3.281 [t=0.18s]
prediction: ['[CLS] a doubt gnumax vanity film vanity fright often pays not what feeling of vanity pays off vanity debt they owed benigni [SEP]']
[ 750/2000] tot_loss=2.265 (perp=9.795, rec=0.149, cos=0.157), tot_loss_proj:3.273 [t=0.21s]
prediction: ['[CLS] a doubt gnumax vanity film vanity fright often pays not what feeling of vanity pays off vanity debt they owed benigni [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.163 (perp=9.378, rec=0.141, cos=0.146), tot_loss_proj:3.239 [t=0.27s]
prediction: ['[CLS] a doubtmax vanity film vanity fright often pays not what debt of vanity pays off vanity debt they owed gnu benigni [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.091 (perp=8.977, rec=0.141, cos=0.155), tot_loss_proj:3.009 [t=0.23s]
prediction: ['[CLS] a doubtmax vanity film vanity fright often pays not debt of vanity pays off what vanity debt they owed gnu benigni [SEP]']
[ 900/2000] tot_loss=2.101 (perp=9.057, rec=0.133, cos=0.157), tot_loss_proj:2.983 [t=0.19s]
prediction: ['[CLS] a doubtmax vanity film vanity fright often pays not debt, vanity pays off what vanity debt they owed gnu benigni [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.112 (perp=9.273, rec=0.130, cos=0.127), tot_loss_proj:3.365 [t=0.18s]
prediction: ['[CLS] a doubtmaxful film vanity fright often pays off no, feeling, vanity pays what vanity debt they owed gnu benigni [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.084 (perp=9.102, rec=0.125, cos=0.138), tot_loss_proj:2.886 [t=0.18s]
prediction: ['[CLS] a doubtfulmax film vanity fright often pays off noy feeling, vanity pays what vanity debt they owed gnu benigni [SEP]']
[1050/2000] tot_loss=2.098 (perp=9.102, rec=0.133, cos=0.145), tot_loss_proj:2.878 [t=0.26s]
prediction: ['[CLS] a doubtfulmax film vanity fright often pays off noy feeling, vanity pays what vanity debt they owed gnu benigni [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=2.047 (perp=8.861, rec=0.127, cos=0.148), tot_loss_proj:3.003 [t=0.22s]
prediction: ['[CLS] a doubtfulmax film vanity fright often pays off feeling noi, vanity pays what vanity debt they owed gnu benigni [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.019 (perp=8.719, rec=0.123, cos=0.153), tot_loss_proj:3.016 [t=0.19s]
prediction: ['[CLS] a doubtfulmax film often vanity fright pays off feeling noi, vanity pays what vanity debt they owed gnu benigni [SEP]']
[1200/2000] tot_loss=2.018 (perp=8.719, rec=0.117, cos=0.157), tot_loss_proj:3.017 [t=0.19s]
prediction: ['[CLS] a doubtfulmax film often vanity fright pays off feeling noi, vanity pays what vanity debt they owed gnu benigni [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.012 (perp=8.648, rec=0.121, cos=0.160), tot_loss_proj:3.011 [t=0.22s]
prediction: ['[CLS] a doubtfulmax film often vanity fright pays off feeling noi, vanity pays what debt they owed vanity gnu benigni [SEP]']
Attempt swap
[1300/2000] tot_loss=2.151 (perp=9.321, rec=0.125, cos=0.162), tot_loss_proj:3.178 [t=0.22s]
prediction: ['[CLS] a doubtfulmax film oftenmax fright pays off feeling noi, vanity pays what debt they owed vanity gnu benigni [SEP]']
[1350/2000] tot_loss=2.201 (perp=9.612, rec=0.115, cos=0.164), tot_loss_proj:3.174 [t=0.19s]
prediction: ['[CLS] a doubtfulmax film oftenmax fright pays off felt noi, vanity pays what debt they owed vanity gnu benigni [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.142 (perp=9.309, rec=0.116, cos=0.165), tot_loss_proj:3.022 [t=0.18s]
prediction: ['[CLS] a doubtfulmax film oftenmax fright pays off felt no vanityi, pays what debt they owed vanity gnu benigni [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.118 (perp=9.174, rec=0.116, cos=0.167), tot_loss_proj:2.998 [t=0.22s]
prediction: ['[CLS] a doubtfulmax film oftenmax fright felt pays off no vanityi, pays what debt they owed vanity gnu benigni [SEP]']
[1500/2000] tot_loss=2.119 (perp=9.174, rec=0.117, cos=0.167), tot_loss_proj:3.008 [t=0.23s]
prediction: ['[CLS] a doubtfulmax film oftenmax fright felt pays off no vanityi, pays what debt they owed vanity gnu benigni [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.078 (perp=8.962, rec=0.117, cos=0.169), tot_loss_proj:3.008 [t=0.19s]
prediction: ['[CLS] a doubtfulmax film oftenmax felt pays off no vanity frighti, pays what debt they owed vanity gnu benigni [SEP]']
Attempt swap
[1600/2000] tot_loss=2.078 (perp=8.962, rec=0.117, cos=0.168), tot_loss_proj:3.011 [t=0.26s]
prediction: ['[CLS] a doubtfulmax film oftenmax felt pays off no vanity frighti, pays what debt they owed vanity gnu benigni [SEP]']
[1650/2000] tot_loss=2.079 (perp=8.962, rec=0.118, cos=0.169), tot_loss_proj:3.013 [t=0.22s]
prediction: ['[CLS] a doubtfulmax film oftenmax felt pays off no vanity frighti, pays what debt they owed vanity gnu benigni [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.068 (perp=8.945, rec=0.115, cos=0.164), tot_loss_proj:3.221 [t=0.18s]
prediction: ['[CLS] a doubtful gnumax film oftenmax felt pays off no vanity frighti to pays what debt they owed vanity benigni [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.990 (perp=8.527, rec=0.119, cos=0.166), tot_loss_proj:3.231 [t=0.21s]
prediction: ['[CLS] a doubtful gnumax film oftenmax felt pays off no vanity frighti pays what debt they owed to vanity benigni [SEP]']
[1800/2000] tot_loss=1.987 (perp=8.527, rec=0.114, cos=0.167), tot_loss_proj:3.233 [t=0.18s]
prediction: ['[CLS] a doubtful gnumax film oftenmax felt pays off no vanity frighti pays what debt they owed to vanity benigni [SEP]']
Attempt swap
[1850/2000] tot_loss=1.987 (perp=8.527, rec=0.113, cos=0.168), tot_loss_proj:3.234 [t=0.21s]
prediction: ['[CLS] a doubtful gnumax film oftenmax felt pays off no vanity frighti pays what debt they owed to vanity benigni [SEP]']
Attempt swap
[1900/2000] tot_loss=1.981 (perp=8.527, rec=0.107, cos=0.169), tot_loss_proj:3.231 [t=0.21s]
prediction: ['[CLS] a doubtful gnumax film oftenmax felt pays off no vanity frighti pays what debt they owed to vanity benigni [SEP]']
[1950/2000] tot_loss=1.986 (perp=8.527, rec=0.111, cos=0.169), tot_loss_proj:3.228 [t=0.18s]
prediction: ['[CLS] a doubtful gnumax film oftenmax felt pays off no vanity frighti pays what debt they owed to vanity benigni [SEP]']
Attempt swap
[2000/2000] tot_loss=1.990 (perp=8.527, rec=0.115, cos=0.169), tot_loss_proj:3.233 [t=0.22s]
prediction: ['[CLS] a doubtful gnumax film oftenmax felt pays off no vanity frighti pays what debt they owed to vanity benigni [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] a doubtful gnumax film oftenmax felt pays off no vanity frighti pays what debt they owed to vanity benigni [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.171 | p: 71.429 | r: 75.000
rouge2     | fm: 25.641 | p: 25.000 | r: 26.316
rougeL     | fm: 58.537 | p: 57.143 | r: 60.000
rougeLsum  | fm: 58.537 | p: 57.143 | r: 60.000
r1fm+r2fm = 98.812

[Aggregate metrics]:
rouge1     | fm: 87.561 | p: 86.111 | r: 89.153
rouge2     | fm: 64.225 | p: 64.057 | r: 64.405
rougeL     | fm: 82.298 | p: 81.108 | r: 83.783
rougeLsum  | fm: 82.298 | p: 81.108 | r: 83.783
r1fm+r2fm = 151.785

input #8 time: 0:08:19 | total time: 1:14:52


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9140903852992303
highest_index [0]
highest [0.9140903852992303]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.772497832775116 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.6955122947692871 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.6761088371276855 for ['[CLS] military offered fragments gathered leaning sphere rom legs [SEP]']
[Init] best rec loss: 0.6559935808181763 for ['[CLS] ham ice command across see beatty anal tan [SEP]']
[Init] best rec loss: 0.6523060202598572 for ['[CLS] save california liquidstownabiing plain for [SEP]']
[Init] best perm rec loss: 0.6519339680671692 for ['[CLS]abi forstown plain save california liquiding [SEP]']
[Init] best perm rec loss: 0.6507493257522583 for ['[CLS] californiaabi save liquidstown foring plain [SEP]']
[Init] best perm rec loss: 0.6504753828048706 for ['[CLS] plainingstown liquidabi california for save [SEP]']
[Init] best perm rec loss: 0.6500648856163025 for ['[CLS]stownabi plain save liquid californiaing for [SEP]']
[Init] best perm rec loss: 0.6491062045097351 for ['[CLS]ingstown california plain for liquid saveabi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.357 (perp=14.301, rec=0.353, cos=0.144), tot_loss_proj:4.150 [t=0.22s]
prediction: ['[CLS] joining closed inner toilet corporate liquidph shut [SEP]']
[ 100/2000] tot_loss=2.309 (perp=9.435, rec=0.273, cos=0.149), tot_loss_proj:3.487 [t=0.26s]
prediction: ['[CLS] on clap soft clap metaphysical clapped. [SEP]']
[ 150/2000] tot_loss=2.664 (perp=11.513, rec=0.201, cos=0.160), tot_loss_proj:3.650 [t=0.25s]
prediction: ['[CLS] on soft soft clap metaphysical claptraed [SEP]']
[ 200/2000] tot_loss=2.636 (perp=11.563, rec=0.191, cos=0.132), tot_loss_proj:3.547 [t=0.18s]
prediction: ['[CLS] of soft soft clap metaphysical claptraed [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.557 (perp=11.212, rec=0.172, cos=0.142), tot_loss_proj:2.966 [t=0.26s]
prediction: ['[CLS] of softhead claped claptra metaphysical [SEP]']
[ 300/2000] tot_loss=2.516 (perp=11.212, rec=0.114, cos=0.160), tot_loss_proj:2.967 [t=0.26s]
prediction: ['[CLS] of softhead claped claptra metaphysical [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.256 (perp=9.912, rec=0.122, cos=0.152), tot_loss_proj:3.007 [t=0.19s]
prediction: ['[CLS] clap of softheaded claptra metaphysical [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.255 (perp=9.912, rec=0.108, cos=0.165), tot_loss_proj:3.016 [t=0.22s]
prediction: ['[CLS] clap of softheaded claptra metaphysical [SEP]']
[ 450/2000] tot_loss=2.227 (perp=9.912, rec=0.084, cos=0.161), tot_loss_proj:3.011 [t=0.26s]
prediction: ['[CLS] clap of softheaded claptra metaphysical [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.221 (perp=9.912, rec=0.095, cos=0.143), tot_loss_proj:3.014 [t=0.20s]
prediction: ['[CLS] clap of softheaded claptra metaphysical [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.100 (perp=9.292, rec=0.094, cos=0.148), tot_loss_proj:2.783 [t=0.24s]
prediction: ['[CLS] clapheaded of soft claptra metaphysical [SEP]']
[ 600/2000] tot_loss=2.116 (perp=9.292, rec=0.099, cos=0.159), tot_loss_proj:2.779 [t=0.18s]
prediction: ['[CLS] clapheaded of soft claptra metaphysical [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.833 (perp=7.985, rec=0.086, cos=0.151), tot_loss_proj:2.448 [t=0.21s]
prediction: ['[CLS] claphead metaphysical of soft claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.830 (perp=7.985, rec=0.075, cos=0.158), tot_loss_proj:2.446 [t=0.24s]
prediction: ['[CLS] claphead metaphysical of soft claptrap [SEP]']
[ 750/2000] tot_loss=1.839 (perp=7.985, rec=0.082, cos=0.160), tot_loss_proj:2.448 [t=0.19s]
prediction: ['[CLS] claphead metaphysical of soft claptrap [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.798 (perp=7.811, rec=0.081, cos=0.156), tot_loss_proj:2.405 [t=0.25s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.807 (perp=7.811, rec=0.085, cos=0.160), tot_loss_proj:2.413 [t=0.21s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
[ 900/2000] tot_loss=1.807 (perp=7.811, rec=0.084, cos=0.161), tot_loss_proj:2.411 [t=0.19s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.796 (perp=7.811, rec=0.072, cos=0.162), tot_loss_proj:2.405 [t=0.20s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.803 (perp=7.811, rec=0.078, cos=0.163), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
[1050/2000] tot_loss=1.801 (perp=7.811, rec=0.076, cos=0.163), tot_loss_proj:2.401 [t=0.24s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.801 (perp=7.811, rec=0.075, cos=0.163), tot_loss_proj:2.415 [t=0.24s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.795 (perp=7.811, rec=0.069, cos=0.164), tot_loss_proj:2.410 [t=0.32s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
[1200/2000] tot_loss=1.797 (perp=7.811, rec=0.070, cos=0.164), tot_loss_proj:2.407 [t=0.18s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.798 (perp=7.811, rec=0.071, cos=0.164), tot_loss_proj:2.403 [t=0.19s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.799 (perp=7.811, rec=0.072, cos=0.164), tot_loss_proj:2.407 [t=0.18s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
[1350/2000] tot_loss=1.796 (perp=7.811, rec=0.069, cos=0.164), tot_loss_proj:2.408 [t=0.23s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.792 (perp=7.811, rec=0.070, cos=0.159), tot_loss_proj:2.407 [t=0.29s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.802 (perp=7.811, rec=0.078, cos=0.162), tot_loss_proj:2.407 [t=0.19s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
[1500/2000] tot_loss=1.800 (perp=7.811, rec=0.075, cos=0.163), tot_loss_proj:2.414 [t=0.20s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.794 (perp=7.811, rec=0.069, cos=0.163), tot_loss_proj:2.405 [t=0.18s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.803 (perp=7.811, rec=0.078, cos=0.163), tot_loss_proj:2.409 [t=0.20s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
[1650/2000] tot_loss=1.804 (perp=7.811, rec=0.078, cos=0.164), tot_loss_proj:2.411 [t=0.21s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.792 (perp=7.811, rec=0.066, cos=0.164), tot_loss_proj:2.397 [t=0.23s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.799 (perp=7.811, rec=0.073, cos=0.164), tot_loss_proj:2.391 [t=0.22s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
[1800/2000] tot_loss=1.805 (perp=7.811, rec=0.078, cos=0.164), tot_loss_proj:2.407 [t=0.18s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.784 (perp=7.811, rec=0.058, cos=0.164), tot_loss_proj:2.411 [t=0.18s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.807 (perp=7.811, rec=0.080, cos=0.164), tot_loss_proj:2.403 [t=0.18s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
[1950/2000] tot_loss=1.790 (perp=7.811, rec=0.068, cos=0.160), tot_loss_proj:2.393 [t=0.20s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.800 (perp=7.811, rec=0.077, cos=0.161), tot_loss_proj:2.402 [t=0.25s]
prediction: ['[CLS] claphead of soft metaphysical claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] claphead of soft metaphysical claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 71.429 | r: 83.333
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 113.287

[Aggregate metrics]:
rouge1     | fm: 86.438 | p: 84.643 | r: 88.571
rouge2     | fm: 61.439 | p: 60.985 | r: 61.965
rougeL     | fm: 81.760 | p: 80.210 | r: 83.976
rougeLsum  | fm: 81.856 | p: 80.280 | r: 83.810
r1fm+r2fm = 147.877

input #9 time: 0:08:24 | total time: 1:23:16


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.8381428879035604
highest_index [0]
highest [0.8381428879035604]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.840921938419342 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8265045881271362 for ['[CLS] university mitaonaefa never existing gym backed ribs realmsund odd [SEP]']
[Init] best rec loss: 0.794999361038208 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.682347297668457 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 0.6774789094924927 for ['[CLS] themes up sheep blessedblood angel common orderoric places totally level sound [SEP]']
[Init] best perm rec loss: 0.6772818565368652 for ['[CLS] places level angel sheep totally order common up soundoric themes blessedblood [SEP]']
[Init] best perm rec loss: 0.676223874092102 for ['[CLS] sound order commonoric up sheep angel totallyblood places themes blessed level [SEP]']
[Init] best perm rec loss: 0.6761038303375244 for ['[CLS] order common uporic sound themes angel sheepblood places blessed level totally [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.323 (perp=12.872, rec=0.466, cos=0.282), tot_loss_proj:3.628 [t=0.31s]
prediction: ['[CLS] trim warrior roosevelt / anchorois passionate profound edge its ; embrace spirit [SEP]']
[ 100/2000] tot_loss=2.602 (perp=10.144, rec=0.305, cos=0.269), tot_loss_proj:3.330 [t=0.25s]
prediction: ['[CLS] balance something gravity, differently ab real robynently quo. ab values [SEP]']
[ 150/2000] tot_loss=2.785 (perp=11.250, rec=0.271, cos=0.264), tot_loss_proj:3.222 [t=0.25s]
prediction: ['[CLS] balancelyulsive franklin rhythms ab bornulsively love ;ly values [SEP]']
[ 200/2000] tot_loss=2.770 (perp=11.578, rec=0.176, cos=0.278), tot_loss_proj:3.360 [t=0.26s]
prediction: ['[CLS] balancelyulsiveraph rhythms ab bornulsively good really charges [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.323 (perp=9.480, rec=0.141, cos=0.286), tot_loss_proj:2.912 [t=0.18s]
prediction: ['[CLS] balancesulsivelyraph rhythms ab realulsively with real incident [SEP]']
[ 300/2000] tot_loss=2.091 (perp=8.412, rec=0.120, cos=0.288), tot_loss_proj:2.533 [t=0.22s]
prediction: ['[CLS] balances really ; rhythms ab realulsively with real incident [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.990 (perp=7.940, rec=0.112, cos=0.289), tot_loss_proj:2.452 [t=0.18s]
prediction: ['[CLS] balances really ; rhythms real abulsively with real incident [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.959 (perp=7.842, rec=0.100, cos=0.290), tot_loss_proj:2.463 [t=0.18s]
prediction: ['[CLS] balances really. real rhythms abulsively with real incident [SEP]']
[ 450/2000] tot_loss=2.127 (perp=8.696, rec=0.098, cos=0.290), tot_loss_proj:2.646 [t=0.18s]
prediction: ['[CLS] balances really. real rhythms abulsive time with real incident [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.014 (perp=8.168, rec=0.090, cos=0.291), tot_loss_proj:2.535 [t=0.18s]
prediction: ['[CLS] balances really. real rhythms abulsive with real time incident [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.928 (perp=7.682, rec=0.128, cos=0.263), tot_loss_proj:2.324 [t=0.18s]
prediction: ['[CLS] balances real ; real rhythms abulsively with real time incident [SEP]']
[ 600/2000] tot_loss=1.919 (perp=7.682, rec=0.100, cos=0.282), tot_loss_proj:2.330 [t=0.20s]
prediction: ['[CLS] balances real ; real rhythms abulsively with real time incident [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.934 (perp=7.810, rec=0.085, cos=0.286), tot_loss_proj:2.397 [t=0.27s]
prediction: ['[CLS] balances real. real rhythms abulsively with real time incident [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.912 (perp=7.705, rec=0.083, cos=0.288), tot_loss_proj:2.440 [t=0.18s]
prediction: ['[CLS] balances. real real rhythms abulsively with real time incident [SEP]']
[ 750/2000] tot_loss=2.207 (perp=9.167, rec=0.085, cos=0.288), tot_loss_proj:2.780 [t=0.19s]
prediction: ['[CLS] balances. real real rhythms abulsively with prop time incident [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.917 (perp=7.705, rec=0.087, cos=0.289), tot_loss_proj:2.437 [t=0.18s]
prediction: ['[CLS] balances. real real rhythms abulsively with real time incident [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.917 (perp=7.705, rec=0.086, cos=0.290), tot_loss_proj:2.441 [t=0.18s]
prediction: ['[CLS] balances. real real rhythms abulsively with real time incident [SEP]']
[ 900/2000] tot_loss=1.922 (perp=7.705, rec=0.090, cos=0.291), tot_loss_proj:2.447 [t=0.18s]
prediction: ['[CLS] balances. real real rhythms abulsively with real time incident [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.920 (perp=7.705, rec=0.085, cos=0.295), tot_loss_proj:2.441 [t=0.27s]
prediction: ['[CLS] balances. real real rhythms abulsively with real time incident [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.877 (perp=7.497, rec=0.098, cos=0.279), tot_loss_proj:2.267 [t=0.18s]
prediction: ['[CLS] balances incident real real rhythms abulsively with real time. [SEP]']
[1050/2000] tot_loss=1.993 (perp=8.096, rec=0.084, cos=0.289), tot_loss_proj:2.462 [t=0.25s]
prediction: ['[CLS] balances incident real prop rhythms abulsively with real time. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.828 (perp=7.269, rec=0.082, cos=0.292), tot_loss_proj:2.315 [t=0.18s]
prediction: ['[CLS] real balances incident real rhythms abulsively with real time. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.989 (perp=8.051, rec=0.084, cos=0.294), tot_loss_proj:2.639 [t=0.25s]
prediction: ['[CLS] prop balances real incident rhythms abulsively with prop time. [SEP]']
[1200/2000] tot_loss=1.980 (perp=8.051, rec=0.076, cos=0.294), tot_loss_proj:2.638 [t=0.19s]
prediction: ['[CLS] prop balances real incident rhythms abulsively with prop time. [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.977 (perp=8.033, rec=0.075, cos=0.295), tot_loss_proj:2.702 [t=0.18s]
prediction: ['[CLS] prop balances incident rhythms real abulsively with prop time. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.855 (perp=7.384, rec=0.091, cos=0.287), tot_loss_proj:2.524 [t=0.18s]
prediction: ['[CLS] prop balances incident rhythms real ab propulsively with time. [SEP]']
[1350/2000] tot_loss=1.849 (perp=7.384, rec=0.080, cos=0.292), tot_loss_proj:2.528 [t=0.21s]
prediction: ['[CLS] prop balances incident rhythms real ab propulsively with time. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.742 (perp=6.857, rec=0.077, cos=0.294), tot_loss_proj:2.585 [t=0.20s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.747 (perp=6.857, rec=0.082, cos=0.294), tot_loss_proj:2.579 [t=0.25s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
[1500/2000] tot_loss=1.744 (perp=6.857, rec=0.078, cos=0.294), tot_loss_proj:2.581 [t=0.25s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.750 (perp=6.857, rec=0.084, cos=0.295), tot_loss_proj:2.585 [t=0.18s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.749 (perp=6.857, rec=0.083, cos=0.295), tot_loss_proj:2.580 [t=0.18s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
[1650/2000] tot_loss=1.738 (perp=6.857, rec=0.071, cos=0.295), tot_loss_proj:2.583 [t=0.18s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.744 (perp=6.857, rec=0.077, cos=0.295), tot_loss_proj:2.581 [t=0.18s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.752 (perp=6.857, rec=0.085, cos=0.295), tot_loss_proj:2.583 [t=0.18s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
[1800/2000] tot_loss=1.739 (perp=6.857, rec=0.073, cos=0.295), tot_loss_proj:2.577 [t=0.18s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.738 (perp=6.857, rec=0.071, cos=0.295), tot_loss_proj:2.582 [t=0.24s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.743 (perp=6.857, rec=0.076, cos=0.295), tot_loss_proj:2.585 [t=0.25s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
[1950/2000] tot_loss=1.742 (perp=6.857, rec=0.075, cos=0.296), tot_loss_proj:2.584 [t=0.24s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.744 (perp=6.857, rec=0.077, cos=0.296), tot_loss_proj:2.581 [t=0.29s]
prediction: ['[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] prop balances incident rhythms ab real propulsively with time. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.190 | p: 72.727 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.619 | p: 45.455 | r: 50.000
rougeLsum  | fm: 47.619 | p: 45.455 | r: 50.000
r1fm+r2fm = 76.190

[Aggregate metrics]:
rouge1     | fm: 85.440 | p: 83.531 | r: 87.792
rouge2     | fm: 55.853 | p: 55.441 | r: 56.332
rougeL     | fm: 78.864 | p: 77.158 | r: 80.790
rougeLsum  | fm: 78.825 | p: 77.075 | r: 81.061
r1fm+r2fm = 141.293

input #10 time: 0:08:12 | total time: 1:31:29


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.8662994104042623
highest_index [0]
highest [0.8662994104042623]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8579704165458679 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8468865752220154 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.781200647354126 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.7786020636558533 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.775368332862854 for ['[CLS] drawnture tal platform inland mileguvd familiar me [SEP]']
[Init] best perm rec loss: 0.7747753262519836 for ['[CLS] familiarture drawn platform tal milegu inland mevd [SEP]']
[Init] best perm rec loss: 0.7745776772499084 for ['[CLS]ture tal inland mile megu drawn platform familiarvd [SEP]']
[Init] best perm rec loss: 0.7744993567466736 for ['[CLS]ture me tal platform drawn mileguvd familiar inland [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.956 (perp=11.662, rec=0.393, cos=0.230), tot_loss_proj:3.319 [t=0.25s]
prediction: ['[CLS]ested to denial road yet left muded it waiting [SEP]']
[ 100/2000] tot_loss=2.636 (perp=10.480, rec=0.303, cos=0.237), tot_loss_proj:3.682 [t=0.18s]
prediction: ['[CLS] caused that refused to unexpected that begted that refused [SEP]']
[ 150/2000] tot_loss=2.266 (perp=8.881, rec=0.247, cos=0.243), tot_loss_proj:2.872 [t=0.22s]
prediction: ['[CLS] wasly refused to gel that stubbornfully that refused [SEP]']
[ 200/2000] tot_loss=2.289 (perp=9.109, rec=0.225, cos=0.242), tot_loss_proj:3.257 [t=0.34s]
prediction: ['[CLS] was stubborn stubborn to gel that stubbornly refused refused [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.489 (perp=10.060, rec=0.246, cos=0.231), tot_loss_proj:3.194 [t=0.18s]
prediction: ['[CLS] tried attempted refused stubborn to gel that stubbornly refused [SEP]']
[ 300/2000] tot_loss=2.084 (perp=8.382, rec=0.169, cos=0.239), tot_loss_proj:2.933 [t=0.26s]
prediction: ['[CLS] was here refused stubborn to gel that stubbornly refused [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.963 (perp=7.880, rec=0.148, cos=0.239), tot_loss_proj:2.827 [t=0.20s]
prediction: ['[CLS] here was refused stubborn to gel that stubbornly refused [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.874 (perp=7.557, rec=0.126, cos=0.236), tot_loss_proj:2.420 [t=0.24s]
prediction: ['[CLS] here was stubborn refused to gel that stubbornly refused [SEP]']
[ 450/2000] tot_loss=1.888 (perp=7.637, rec=0.116, cos=0.245), tot_loss_proj:2.570 [t=0.19s]
prediction: ['[CLS] here was attempted refused to gel that stubbornly refused [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.819 (perp=7.358, rec=0.104, cos=0.243), tot_loss_proj:2.647 [t=0.20s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.805 (perp=7.358, rec=0.093, cos=0.241), tot_loss_proj:2.643 [t=0.23s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
[ 600/2000] tot_loss=1.810 (perp=7.358, rec=0.089, cos=0.250), tot_loss_proj:2.638 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.806 (perp=7.358, rec=0.087, cos=0.247), tot_loss_proj:2.642 [t=0.23s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.816 (perp=7.358, rec=0.097, cos=0.247), tot_loss_proj:2.640 [t=0.25s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
[ 750/2000] tot_loss=1.798 (perp=7.358, rec=0.083, cos=0.244), tot_loss_proj:2.642 [t=0.19s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.797 (perp=7.358, rec=0.080, cos=0.246), tot_loss_proj:2.635 [t=0.19s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.791 (perp=7.358, rec=0.077, cos=0.242), tot_loss_proj:2.643 [t=0.26s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
[ 900/2000] tot_loss=1.798 (perp=7.358, rec=0.078, cos=0.248), tot_loss_proj:2.639 [t=0.24s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.800 (perp=7.358, rec=0.079, cos=0.249), tot_loss_proj:2.648 [t=0.24s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1000/2000] tot_loss=1.796 (perp=7.358, rec=0.078, cos=0.246), tot_loss_proj:2.643 [t=0.23s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
[1050/2000] tot_loss=1.793 (perp=7.358, rec=0.073, cos=0.248), tot_loss_proj:2.635 [t=0.23s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1100/2000] tot_loss=1.795 (perp=7.358, rec=0.078, cos=0.245), tot_loss_proj:2.647 [t=0.21s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1150/2000] tot_loss=1.798 (perp=7.358, rec=0.078, cos=0.249), tot_loss_proj:2.642 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
[1200/2000] tot_loss=1.794 (perp=7.358, rec=0.076, cos=0.246), tot_loss_proj:2.644 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1250/2000] tot_loss=1.810 (perp=7.358, rec=0.090, cos=0.249), tot_loss_proj:2.639 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1300/2000] tot_loss=1.796 (perp=7.358, rec=0.075, cos=0.249), tot_loss_proj:2.646 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
[1350/2000] tot_loss=1.807 (perp=7.358, rec=0.089, cos=0.246), tot_loss_proj:2.640 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1400/2000] tot_loss=1.808 (perp=7.358, rec=0.089, cos=0.248), tot_loss_proj:2.645 [t=0.25s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1450/2000] tot_loss=1.804 (perp=7.358, rec=0.083, cos=0.249), tot_loss_proj:2.647 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
[1500/2000] tot_loss=1.797 (perp=7.358, rec=0.079, cos=0.247), tot_loss_proj:2.642 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1550/2000] tot_loss=1.794 (perp=7.358, rec=0.074, cos=0.249), tot_loss_proj:2.634 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1600/2000] tot_loss=1.793 (perp=7.358, rec=0.074, cos=0.247), tot_loss_proj:2.641 [t=0.21s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
[1650/2000] tot_loss=1.800 (perp=7.358, rec=0.080, cos=0.248), tot_loss_proj:2.642 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1700/2000] tot_loss=1.795 (perp=7.358, rec=0.075, cos=0.249), tot_loss_proj:2.641 [t=0.21s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1750/2000] tot_loss=1.800 (perp=7.358, rec=0.079, cos=0.249), tot_loss_proj:2.646 [t=0.22s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
[1800/2000] tot_loss=1.797 (perp=7.358, rec=0.078, cos=0.248), tot_loss_proj:2.641 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1850/2000] tot_loss=1.794 (perp=7.358, rec=0.073, cos=0.249), tot_loss_proj:2.641 [t=0.18s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[1900/2000] tot_loss=1.810 (perp=7.358, rec=0.089, cos=0.249), tot_loss_proj:2.643 [t=0.23s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
[1950/2000] tot_loss=1.793 (perp=7.358, rec=0.074, cos=0.248), tot_loss_proj:2.647 [t=0.19s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Attempt swap
[2000/2000] tot_loss=1.797 (perp=7.358, rec=0.076, cos=0.249), tot_loss_proj:2.640 [t=0.26s]
prediction: ['[CLS] here refused was attempted to gel that stubbornly refused [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here refused was attempted to gel that stubbornly refused [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 120.909

[Aggregate metrics]:
rouge1     | fm: 86.051 | p: 84.335 | r: 88.062
rouge2     | fm: 53.951 | p: 53.466 | r: 54.401
rougeL     | fm: 77.375 | p: 75.874 | r: 79.095
rougeLsum  | fm: 77.470 | p: 75.988 | r: 79.284
r1fm+r2fm = 140.002

input #11 time: 0:08:26 | total time: 1:39:55


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9283782023949543
highest_index [0]
highest [0.9283782023949543]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8323867321014404 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.7897476553916931 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7868282794952393 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7803595662117004 for ['[CLS] wolf rex usualli plant live painfully sqlamtpemi wallace du sort [SEP]']
[Init] best rec loss: 0.7779301404953003 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7615143656730652 for ['[CLS] this heart hot noise fixing trying system potential salt ifana defense ii alexandria [SEP]']
[Init] best rec loss: 0.7536682486534119 for ['[CLS] hear protocol heidi race strokes safety association transactions snail most place buried terror documentary [SEP]']
[Init] best rec loss: 0.7302504777908325 for ['[CLS] alive expression semiuid wise friend investigationthed beloved [MASK] got richards didnbank [SEP]']
[Init] best perm rec loss: 0.7288262248039246 for ['[CLS] gotbank wiseuid friend semi didn richards [MASK] alivethed expression beloved investigation [SEP]']
[Init] best perm rec loss: 0.728458821773529 for ['[CLS] didnbank gotthed wise semi expressionuid friend investigation beloved [MASK] richards alive [SEP]']
[Init] best perm rec loss: 0.7251093983650208 for ['[CLS]uid alive expressionbank [MASK]thed investigation wise got semi didn richards friend beloved [SEP]']
[Init] best perm rec loss: 0.7246637344360352 for ['[CLS] alive [MASK] richardsuid investigation gotthedbank expression friend beloved wise didn semi [SEP]']
[Init] best perm rec loss: 0.724576473236084 for ['[CLS] friend alive wise [MASK] expression belovedthed richardsuid investigation got semibank didn [SEP]']
[Init] best perm rec loss: 0.7229287028312683 for ['[CLS] [MASK]thed wise got beloved expressionbank semi friend richards didn alive investigationuid [SEP]']
[Init] best perm rec loss: 0.7221211791038513 for ['[CLS] friend belovedthed wiseuid richards investigation expression didn semi got alivebank [MASK] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.996 (perp=12.606, rec=0.374, cos=0.101), tot_loss_proj:3.626 [t=0.17s]
prediction: ['[CLS]las phone crown productsaround it cable better legal snakeative or penalty is [SEP]']
[ 100/2000] tot_loss=2.597 (perp=11.280, rec=0.259, cos=0.081), tot_loss_proj:3.425 [t=0.23s]
prediction: ['[CLS]tropical cable seen advantage advantage to cable better opinion government barely, [SEP] only [SEP]']
[ 150/2000] tot_loss=2.308 (perp=9.973, rec=0.180, cos=0.133), tot_loss_proj:3.048 [t=0.25s]
prediction: ['[CLS] its cable seen seen advantage to cable better seen cable barely, [SEP] especially [SEP]']
[ 200/2000] tot_loss=2.244 (perp=10.057, rec=0.128, cos=0.105), tot_loss_proj:2.952 [t=0.18s]
prediction: ['[CLS] its cable will seen advantage to cable better seen cable barely on [SEP] especially [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.182 (perp=9.756, rec=0.101, cos=0.130), tot_loss_proj:3.297 [t=0.18s]
prediction: ['[CLS] its cable will seen advantage to cable better that barely on cable [SEP] especially [SEP]']
[ 300/2000] tot_loss=2.151 (perp=9.756, rec=0.095, cos=0.104), tot_loss_proj:3.287 [t=0.21s]
prediction: ['[CLS] its cable will seen advantage to cable better that barely on cable [SEP] especially [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.014 (perp=8.996, rec=0.079, cos=0.135), tot_loss_proj:2.704 [t=0.27s]
prediction: ['[CLS] that cable will seen advantage to cable better its barely on considering its especially [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.011 (perp=9.047, rec=0.091, cos=0.111), tot_loss_proj:2.640 [t=0.18s]
prediction: ['[CLS] that cable will seen advantage to cable better its barely on considering its considering [SEP]']
[ 450/2000] tot_loss=2.120 (perp=9.482, rec=0.090, cos=0.133), tot_loss_proj:2.764 [t=0.18s]
prediction: ['[CLS] that cable will seen advantage to cable better its barely on considering especially considering [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.987 (perp=8.920, rec=0.086, cos=0.117), tot_loss_proj:3.014 [t=0.18s]
prediction: ['[CLS] that cable will seen advantage to its barely on cable better especially its considering [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.891 (perp=8.425, rec=0.080, cos=0.126), tot_loss_proj:2.664 [t=0.22s]
prediction: ['[CLS] that cable will seen to its advantage barely on cable better especially its considering [SEP]']
[ 600/2000] tot_loss=1.893 (perp=8.425, rec=0.076, cos=0.132), tot_loss_proj:2.663 [t=0.19s]
prediction: ['[CLS] that cable will seen to its advantage barely on cable better especially its considering [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.799 (perp=7.907, rec=0.082, cos=0.135), tot_loss_proj:2.491 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely on cable better especially considering its [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.720 (perp=7.626, rec=0.070, cos=0.125), tot_loss_proj:2.423 [t=0.22s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering its [SEP]']
[ 750/2000] tot_loss=1.726 (perp=7.626, rec=0.069, cos=0.133), tot_loss_proj:2.424 [t=0.24s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering its [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.738 (perp=7.626, rec=0.078, cos=0.134), tot_loss_proj:2.429 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering its [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.728 (perp=7.626, rec=0.067, cos=0.136), tot_loss_proj:2.428 [t=0.21s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering its [SEP]']
[ 900/2000] tot_loss=1.734 (perp=7.626, rec=0.072, cos=0.137), tot_loss_proj:2.420 [t=0.25s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering its [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.732 (perp=7.626, rec=0.070, cos=0.137), tot_loss_proj:2.424 [t=0.23s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering its [SEP]']
Attempt swap
[1000/2000] tot_loss=1.742 (perp=7.626, rec=0.080, cos=0.137), tot_loss_proj:2.420 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering its [SEP]']
[1050/2000] tot_loss=1.885 (perp=8.343, rec=0.079, cos=0.137), tot_loss_proj:2.619 [t=0.23s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering especially [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.669 (perp=7.315, rec=0.078, cos=0.128), tot_loss_proj:2.353 [t=0.26s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1150/2000] tot_loss=1.674 (perp=7.315, rec=0.078, cos=0.133), tot_loss_proj:2.347 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
[1200/2000] tot_loss=1.672 (perp=7.315, rec=0.074, cos=0.135), tot_loss_proj:2.355 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1250/2000] tot_loss=1.674 (perp=7.315, rec=0.075, cos=0.136), tot_loss_proj:2.353 [t=0.23s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1300/2000] tot_loss=1.678 (perp=7.315, rec=0.079, cos=0.136), tot_loss_proj:2.345 [t=0.24s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
[1350/2000] tot_loss=1.665 (perp=7.315, rec=0.066, cos=0.137), tot_loss_proj:2.349 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1400/2000] tot_loss=1.680 (perp=7.315, rec=0.080, cos=0.137), tot_loss_proj:2.350 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1450/2000] tot_loss=1.673 (perp=7.315, rec=0.073, cos=0.137), tot_loss_proj:2.350 [t=0.25s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
[1500/2000] tot_loss=1.674 (perp=7.315, rec=0.073, cos=0.137), tot_loss_proj:2.353 [t=0.21s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1550/2000] tot_loss=1.670 (perp=7.315, rec=0.070, cos=0.137), tot_loss_proj:2.352 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1600/2000] tot_loss=1.680 (perp=7.315, rec=0.079, cos=0.138), tot_loss_proj:2.345 [t=0.23s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
[1650/2000] tot_loss=1.675 (perp=7.315, rec=0.075, cos=0.138), tot_loss_proj:2.347 [t=0.23s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1700/2000] tot_loss=1.674 (perp=7.315, rec=0.073, cos=0.138), tot_loss_proj:2.345 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1750/2000] tot_loss=1.682 (perp=7.315, rec=0.081, cos=0.138), tot_loss_proj:2.344 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
[1800/2000] tot_loss=1.670 (perp=7.315, rec=0.069, cos=0.138), tot_loss_proj:2.349 [t=0.25s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1850/2000] tot_loss=1.670 (perp=7.315, rec=0.069, cos=0.138), tot_loss_proj:2.351 [t=0.25s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[1900/2000] tot_loss=1.677 (perp=7.315, rec=0.076, cos=0.138), tot_loss_proj:2.350 [t=0.18s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
[1950/2000] tot_loss=1.671 (perp=7.315, rec=0.073, cos=0.135), tot_loss_proj:2.349 [t=0.24s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Attempt swap
[2000/2000] tot_loss=1.685 (perp=7.315, rec=0.086, cos=0.136), tot_loss_proj:2.346 [t=0.19s]
prediction: ['[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] that cable will seen to its advantage barely better on cable especially considering that [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.323 | p: 87.500 | r: 93.333
rouge2     | fm: 34.483 | p: 33.333 | r: 35.714
rougeL     | fm: 70.968 | p: 68.750 | r: 73.333
rougeLsum  | fm: 70.968 | p: 68.750 | r: 73.333
r1fm+r2fm = 124.805

[Aggregate metrics]:
rouge1     | fm: 86.341 | p: 84.572 | r: 88.473
rouge2     | fm: 52.410 | p: 51.853 | r: 52.780
rougeL     | fm: 76.770 | p: 75.230 | r: 78.792
rougeLsum  | fm: 76.838 | p: 75.213 | r: 78.647
r1fm+r2fm = 138.751

input #12 time: 0:08:17 | total time: 1:48:13


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9020523730530327
highest_index [0]
highest [0.9020523730530327]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.6926698088645935 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.686700701713562 for ['[CLS] baccalaureate, black saunderstec armed much [SEP]']
[Init] best rec loss: 0.6862374544143677 for ['[CLS] todd travel time mountain relation territorial same [SEP]']
[Init] best rec loss: 0.6802213191986084 for ['[CLS] dressed fraternity colonial round et bahn heads [SEP]']
[Init] best perm rec loss: 0.6788508296012878 for ['[CLS] round colonial fraternity et dressed heads bahn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.580 (perp=10.331, rec=0.338, cos=0.175), tot_loss_proj:3.327 [t=0.18s]
prediction: ['[CLS] nuclear deaths flame into verity flame down [SEP]']
[ 100/2000] tot_loss=2.638 (perp=11.150, rec=0.231, cos=0.177), tot_loss_proj:3.985 [t=0.20s]
prediction: ['[CLS] ofum flame into those flame into [SEP]']
[ 150/2000] tot_loss=2.450 (perp=10.517, rec=0.170, cos=0.177), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] of ones point point things flame into [SEP]']
[ 200/2000] tot_loss=2.051 (perp=8.604, rec=0.147, cos=0.183), tot_loss_proj:2.975 [t=0.25s]
prediction: ['[CLS] at ones point point things flame into [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.009 (perp=8.604, rec=0.115, cos=0.173), tot_loss_proj:2.976 [t=0.24s]
prediction: ['[CLS] at ones point point things flame into [SEP]']
[ 300/2000] tot_loss=2.248 (perp=9.753, rec=0.120, cos=0.177), tot_loss_proj:3.089 [t=0.25s]
prediction: ['[CLS] at explode point point things flame into [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.033 (perp=8.764, rec=0.112, cos=0.168), tot_loss_proj:3.144 [t=0.27s]
prediction: ['[CLS] at point point events things flame into [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.109 (perp=9.102, rec=0.109, cos=0.180), tot_loss_proj:3.122 [t=0.18s]
prediction: ['[CLS] at point point things things flame into [SEP]']
[ 450/2000] tot_loss=2.103 (perp=9.102, rec=0.098, cos=0.185), tot_loss_proj:3.114 [t=0.29s]
prediction: ['[CLS] at point point things things flame into [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.088 (perp=8.968, rec=0.115, cos=0.179), tot_loss_proj:3.323 [t=0.24s]
prediction: ['[CLS] at things point at things flame into [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.022 (perp=8.741, rec=0.103, cos=0.171), tot_loss_proj:2.614 [t=0.18s]
prediction: ['[CLS] at things point explode things flame at [SEP]']
[ 600/2000] tot_loss=2.016 (perp=8.774, rec=0.079, cos=0.183), tot_loss_proj:2.761 [t=0.18s]
prediction: ['[CLS] at things point explode things flame into [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.964 (perp=8.519, rec=0.079, cos=0.181), tot_loss_proj:2.423 [t=0.28s]
prediction: ['[CLS] at things point explode things into flame [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.983 (perp=8.519, rec=0.127, cos=0.152), tot_loss_proj:2.437 [t=0.18s]
prediction: ['[CLS] at things point explode things into flame [SEP]']
[ 750/2000] tot_loss=1.964 (perp=8.519, rec=0.086, cos=0.174), tot_loss_proj:2.431 [t=0.30s]
prediction: ['[CLS] at things point explode things into flame [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.912 (perp=8.257, rec=0.082, cos=0.179), tot_loss_proj:2.512 [t=0.28s]
prediction: ['[CLS] at things point things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.540 (perp=6.423, rec=0.074, cos=0.182), tot_loss_proj:2.128 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 900/2000] tot_loss=1.526 (perp=6.423, rec=0.059, cos=0.182), tot_loss_proj:2.123 [t=0.24s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.532 (perp=6.423, rec=0.064, cos=0.183), tot_loss_proj:2.131 [t=0.18s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.525 (perp=6.423, rec=0.058, cos=0.183), tot_loss_proj:2.126 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1050/2000] tot_loss=1.537 (perp=6.423, rec=0.069, cos=0.183), tot_loss_proj:2.136 [t=0.26s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.543 (perp=6.423, rec=0.075, cos=0.184), tot_loss_proj:2.136 [t=0.18s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.521 (perp=6.423, rec=0.052, cos=0.184), tot_loss_proj:2.131 [t=0.18s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1200/2000] tot_loss=1.531 (perp=6.423, rec=0.063, cos=0.184), tot_loss_proj:2.134 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.542 (perp=6.423, rec=0.073, cos=0.184), tot_loss_proj:2.134 [t=0.18s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.532 (perp=6.423, rec=0.063, cos=0.184), tot_loss_proj:2.129 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1350/2000] tot_loss=1.539 (perp=6.423, rec=0.070, cos=0.184), tot_loss_proj:2.131 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.532 (perp=6.423, rec=0.063, cos=0.185), tot_loss_proj:2.137 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.542 (perp=6.423, rec=0.073, cos=0.185), tot_loss_proj:2.134 [t=0.18s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1500/2000] tot_loss=1.528 (perp=6.423, rec=0.059, cos=0.185), tot_loss_proj:2.136 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.536 (perp=6.423, rec=0.066, cos=0.185), tot_loss_proj:2.132 [t=0.21s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.531 (perp=6.423, rec=0.061, cos=0.185), tot_loss_proj:2.131 [t=0.26s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1650/2000] tot_loss=1.539 (perp=6.423, rec=0.070, cos=0.185), tot_loss_proj:2.135 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.536 (perp=6.423, rec=0.066, cos=0.185), tot_loss_proj:2.131 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.536 (perp=6.423, rec=0.067, cos=0.185), tot_loss_proj:2.135 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1800/2000] tot_loss=1.529 (perp=6.423, rec=0.060, cos=0.185), tot_loss_proj:2.132 [t=0.22s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.522 (perp=6.423, rec=0.053, cos=0.185), tot_loss_proj:2.123 [t=0.18s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.531 (perp=6.423, rec=0.061, cos=0.185), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1950/2000] tot_loss=1.543 (perp=6.423, rec=0.073, cos=0.185), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.531 (perp=6.423, rec=0.062, cos=0.185), tot_loss_proj:2.134 [t=0.23s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at that point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 87.310 | p: 85.599 | r: 89.320
rouge2     | fm: 50.866 | p: 50.471 | r: 51.399
rougeL     | fm: 76.784 | p: 75.427 | r: 78.502
rougeLsum  | fm: 76.921 | p: 75.451 | r: 78.733
r1fm+r2fm = 138.176

input #13 time: 0:08:39 | total time: 1:56:52


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.8221858527470765
highest_index [0]
highest [0.8221858527470765]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9944355487823486 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9809552431106567 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9740397334098816 for ['[CLS] green stepped one battle rear [SEP]']
[Init] best rec loss: 0.9641602635383606 for ['[CLS] gps war break stream carriage [SEP]']
[Init] best rec loss: 0.9588375687599182 for ['[CLS] female pants hard surely olympics [SEP]']
[Init] best rec loss: 0.9524041414260864 for ['[CLS]pace chicago is thrust youth [SEP]']
[Init] best rec loss: 0.950710654258728 for ['[CLS] baton channel along presided corners [SEP]']
[Init] best rec loss: 0.9373902082443237 for ['[CLS] strategy sigh hk automatically county [SEP]']
[Init] best rec loss: 0.9368411898612976 for ['[CLS] dirtig directionseous dealer [SEP]']
[Init] best perm rec loss: 0.9336022138595581 for ['[CLS]eous dealer directionsig dirt [SEP]']
[Init] best perm rec loss: 0.9334275126457214 for ['[CLS]eous directions dealerig dirt [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.705 (perp=13.586, rec=0.698, cos=0.289), tot_loss_proj:4.267 [t=0.26s]
prediction: ['[CLS] siegepressed nothing couch breathing [SEP]']
[ 100/2000] tot_loss=3.561 (perp=13.403, rec=0.593, cos=0.288), tot_loss_proj:4.501 [t=0.25s]
prediction: ['[CLS] beethoven peaceful nothingeger pretty [SEP]']
[ 150/2000] tot_loss=3.630 (perp=13.452, rec=0.605, cos=0.334), tot_loss_proj:4.271 [t=0.18s]
prediction: ['[CLS] relativityily wastedenia kylie [SEP]']
[ 200/2000] tot_loss=3.819 (perp=14.936, rec=0.528, cos=0.305), tot_loss_proj:4.979 [t=0.21s]
prediction: ['[CLS] relativityilyignantenia kylie [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.489 (perp=13.338, rec=0.570, cos=0.252), tot_loss_proj:4.641 [t=0.18s]
prediction: ['[CLS] relativityignantilypathic kylie [SEP]']
[ 300/2000] tot_loss=3.519 (perp=13.799, rec=0.513, cos=0.247), tot_loss_proj:4.107 [t=0.22s]
prediction: ['[CLS]asurableignantily intriguing kylie [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.476 (perp=12.750, rec=0.601, cos=0.324), tot_loss_proj:4.150 [t=0.18s]
prediction: ['[CLS]xious regression canoepathic kylie [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.499 (perp=13.480, rec=0.556, cos=0.246), tot_loss_proj:4.691 [t=0.18s]
prediction: ['[CLS]ignant kylie observations ᵍ record [SEP]']
[ 450/2000] tot_loss=3.396 (perp=13.265, rec=0.519, cos=0.225), tot_loss_proj:4.288 [t=0.18s]
prediction: ['[CLS]ignant messedasurableenia record [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.593 (perp=14.247, rec=0.504, cos=0.239), tot_loss_proj:4.773 [t=0.20s]
prediction: ['[CLS]ignant messed intriguingeniacased [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.250 (perp=12.462, rec=0.496, cos=0.261), tot_loss_proj:3.923 [t=0.18s]
prediction: ['[CLS]ignant film intriguingeniacased [SEP]']
[ 600/2000] tot_loss=3.318 (perp=12.620, rec=0.499, cos=0.296), tot_loss_proj:4.068 [t=0.25s]
prediction: ['[CLS]ignant film intriguingblycased [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=3.041 (perp=11.516, rec=0.507, cos=0.231), tot_loss_proj:3.173 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguingcased [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.062 (perp=11.516, rec=0.501, cos=0.257), tot_loss_proj:3.168 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguingcased [SEP]']
[ 750/2000] tot_loss=3.033 (perp=11.516, rec=0.506, cos=0.224), tot_loss_proj:3.169 [t=0.20s]
prediction: ['[CLS] intriguing filmbly intriguingcased [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.130 (perp=11.815, rec=0.529, cos=0.238), tot_loss_proj:3.634 [t=0.18s]
prediction: ['[CLS] intriguing kyliebly intriguingcased [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.002 (perp=11.154, rec=0.476, cos=0.295), tot_loss_proj:2.929 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing ′ [SEP]']
[ 900/2000] tot_loss=2.960 (perp=11.154, rec=0.460, cos=0.269), tot_loss_proj:2.933 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing ′ [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.976 (perp=11.154, rec=0.462, cos=0.282), tot_loss_proj:2.934 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing ′ [SEP]']
Attempt swap
[1000/2000] tot_loss=2.936 (perp=11.154, rec=0.459, cos=0.247), tot_loss_proj:2.928 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing ′ [SEP]']
[1050/2000] tot_loss=2.930 (perp=11.154, rec=0.462, cos=0.237), tot_loss_proj:2.925 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing ′ [SEP]']
Attempt swap
[1100/2000] tot_loss=2.943 (perp=11.154, rec=0.458, cos=0.254), tot_loss_proj:2.926 [t=0.23s]
prediction: ['[CLS] intriguing filmbly intriguing ′ [SEP]']
Attempt swap
[1150/2000] tot_loss=2.964 (perp=11.154, rec=0.465, cos=0.269), tot_loss_proj:2.926 [t=0.23s]
prediction: ['[CLS] intriguing filmbly intriguing ′ [SEP]']
[1200/2000] tot_loss=2.961 (perp=10.981, rec=0.449, cos=0.317), tot_loss_proj:2.861 [t=0.28s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[1250/2000] tot_loss=2.951 (perp=10.981, rec=0.452, cos=0.302), tot_loss_proj:2.859 [t=0.25s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[1300/2000] tot_loss=2.929 (perp=10.981, rec=0.450, cos=0.283), tot_loss_proj:2.860 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
[1350/2000] tot_loss=2.909 (perp=10.981, rec=0.454, cos=0.260), tot_loss_proj:2.876 [t=0.26s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[1400/2000] tot_loss=2.960 (perp=10.981, rec=0.455, cos=0.309), tot_loss_proj:2.866 [t=0.25s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[1450/2000] tot_loss=2.954 (perp=10.981, rec=0.448, cos=0.310), tot_loss_proj:2.878 [t=0.22s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
[1500/2000] tot_loss=2.936 (perp=10.981, rec=0.447, cos=0.293), tot_loss_proj:2.864 [t=0.21s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[1550/2000] tot_loss=2.937 (perp=10.981, rec=0.461, cos=0.280), tot_loss_proj:2.862 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[1600/2000] tot_loss=2.959 (perp=10.981, rec=0.445, cos=0.317), tot_loss_proj:2.870 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
[1650/2000] tot_loss=2.945 (perp=10.981, rec=0.446, cos=0.303), tot_loss_proj:2.875 [t=0.23s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[1700/2000] tot_loss=2.922 (perp=10.981, rec=0.440, cos=0.285), tot_loss_proj:2.869 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[1750/2000] tot_loss=2.967 (perp=10.981, rec=0.452, cos=0.319), tot_loss_proj:2.870 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
[1800/2000] tot_loss=2.954 (perp=10.981, rec=0.452, cos=0.305), tot_loss_proj:2.861 [t=0.20s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[1850/2000] tot_loss=2.940 (perp=10.981, rec=0.452, cos=0.292), tot_loss_proj:2.866 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[1900/2000] tot_loss=2.974 (perp=10.981, rec=0.461, cos=0.317), tot_loss_proj:2.858 [t=0.18s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
[1950/2000] tot_loss=2.944 (perp=10.981, rec=0.444, cos=0.304), tot_loss_proj:2.863 [t=0.20s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Attempt swap
[2000/2000] tot_loss=2.966 (perp=10.981, rec=0.446, cos=0.323), tot_loss_proj:2.855 [t=0.21s]
prediction: ['[CLS] intriguing filmbly intriguing frankly [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] intriguing filmbly intriguing frankly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.545 | p: 50.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 54.545 | p: 50.000 | r: 60.000
rougeLsum  | fm: 54.545 | p: 50.000 | r: 60.000
r1fm+r2fm = 54.545

[Aggregate metrics]:
rouge1     | fm: 85.036 | p: 83.131 | r: 87.283
rouge2     | fm: 47.942 | p: 47.568 | r: 48.263
rougeL     | fm: 75.395 | p: 73.653 | r: 77.387
rougeLsum  | fm: 75.363 | p: 73.803 | r: 77.329
r1fm+r2fm = 132.978

input #14 time: 0:08:19 | total time: 2:05:12


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.8063966403682521
highest_index [0]
highest [0.8063966403682521]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.8277201056480408 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.8197278380393982 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.8095610737800598 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.7977768778800964 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.7936840653419495 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.7927590608596802 for ['[CLS] massachusetts stomach qui beverlyrangle fleet strong driven [SEP]']
[Init] best perm rec loss: 0.7894755601882935 for ['[CLS] stomachrangle qui massachusetts strong fleet driven beverly [SEP]']
[Init] best perm rec loss: 0.788325309753418 for ['[CLS] stomachrangle qui fleet strong massachusetts driven beverly [SEP]']
[Init] best perm rec loss: 0.7881602048873901 for ['[CLS] driven qui stomach massachusetts fleetrangle beverly strong [SEP]']
[Init] best perm rec loss: 0.7874126434326172 for ['[CLS] fleet driven strong qui massachusetts beverly stomachrangle [SEP]']
[Init] best perm rec loss: 0.7873669266700745 for ['[CLS] massachusetts beverly qui fleet stomach strong drivenrangle [SEP]']
[Init] best perm rec loss: 0.7866385579109192 for ['[CLS] massachusetts beverlyrangle stomach qui strong fleet driven [SEP]']
[Init] best perm rec loss: 0.7845451235771179 for ['[CLS] qui beverly fleet stomachrangle strong driven massachusetts [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.471 (perp=9.292, rec=0.262, cos=0.351), tot_loss_proj:3.045 [t=0.27s]
prediction: ['[CLS] efficientably efficientable altitude model estimated. [SEP]']
[ 100/2000] tot_loss=2.716 (perp=10.947, rec=0.182, cos=0.345), tot_loss_proj:3.241 [t=0.20s]
prediction: ['[CLS] efficientably efficient suit chill chill estimated. [SEP]']
[ 150/2000] tot_loss=2.406 (perp=9.608, rec=0.140, cos=0.344), tot_loss_proj:3.192 [t=0.18s]
prediction: ['[CLS] efficientably anonymous suit chiller estimated. [SEP]']
[ 200/2000] tot_loss=2.414 (perp=9.820, rec=0.101, cos=0.349), tot_loss_proj:3.106 [t=0.26s]
prediction: ['[CLS] efficientably anonymous suit chillerible. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.389 (perp=9.660, rec=0.111, cos=0.346), tot_loss_proj:2.973 [t=0.21s]
prediction: ['[CLS] efficientably anonymous chiller suitod. [SEP]']
[ 300/2000] tot_loss=2.369 (perp=9.660, rec=0.093, cos=0.343), tot_loss_proj:2.969 [t=0.18s]
prediction: ['[CLS] efficientably anonymous chiller suitod. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.157 (perp=8.579, rec=0.095, cos=0.347), tot_loss_proj:2.542 [t=0.23s]
prediction: ['[CLS] efficient suitably anonymous chiller or. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.005 (perp=7.814, rec=0.095, cos=0.347), tot_loss_proj:2.204 [t=0.21s]
prediction: ['[CLS] efficient - suitably anonymous chiller. [SEP]']
[ 450/2000] tot_loss=1.986 (perp=7.814, rec=0.077, cos=0.346), tot_loss_proj:2.205 [t=0.18s]
prediction: ['[CLS] efficient - suitably anonymous chiller. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.994 (perp=7.814, rec=0.087, cos=0.344), tot_loss_proj:2.198 [t=0.25s]
prediction: ['[CLS] efficient - suitably anonymous chiller. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.992 (perp=7.814, rec=0.080, cos=0.349), tot_loss_proj:2.194 [t=0.18s]
prediction: ['[CLS] efficient - suitably anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.991 (perp=7.814, rec=0.079, cos=0.349), tot_loss_proj:2.205 [t=0.18s]
prediction: ['[CLS] efficient - suitably anonymous chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.988 (perp=7.814, rec=0.077, cos=0.348), tot_loss_proj:2.190 [t=0.20s]
prediction: ['[CLS] efficient - suitably anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.755 (perp=6.615, rec=0.082, cos=0.350), tot_loss_proj:1.744 [t=0.19s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.754 (perp=6.615, rec=0.082, cos=0.349), tot_loss_proj:1.749 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.753 (perp=6.615, rec=0.084, cos=0.345), tot_loss_proj:1.755 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.744 (perp=6.615, rec=0.072, cos=0.349), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.740 (perp=6.615, rec=0.069, cos=0.348), tot_loss_proj:1.748 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.738 (perp=6.615, rec=0.067, cos=0.349), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.736 (perp=6.615, rec=0.064, cos=0.349), tot_loss_proj:1.755 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.735 (perp=6.615, rec=0.063, cos=0.349), tot_loss_proj:1.752 [t=0.21s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.736 (perp=6.615, rec=0.063, cos=0.349), tot_loss_proj:1.748 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.740 (perp=6.615, rec=0.068, cos=0.349), tot_loss_proj:1.751 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.743 (perp=6.615, rec=0.071, cos=0.349), tot_loss_proj:1.756 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.740 (perp=6.615, rec=0.068, cos=0.349), tot_loss_proj:1.747 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.745 (perp=6.615, rec=0.072, cos=0.349), tot_loss_proj:1.752 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.733 (perp=6.615, rec=0.061, cos=0.349), tot_loss_proj:1.746 [t=0.21s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.727 (perp=6.615, rec=0.055, cos=0.349), tot_loss_proj:1.750 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.740 (perp=6.615, rec=0.067, cos=0.350), tot_loss_proj:1.744 [t=0.24s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.739 (perp=6.615, rec=0.066, cos=0.350), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.737 (perp=6.615, rec=0.065, cos=0.350), tot_loss_proj:1.750 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.737 (perp=6.615, rec=0.064, cos=0.350), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.738 (perp=6.615, rec=0.065, cos=0.350), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.730 (perp=6.615, rec=0.058, cos=0.349), tot_loss_proj:1.742 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.738 (perp=6.615, rec=0.066, cos=0.350), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.738 (perp=6.615, rec=0.065, cos=0.350), tot_loss_proj:1.747 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.737 (perp=6.615, rec=0.065, cos=0.350), tot_loss_proj:1.741 [t=0.23s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.744 (perp=6.615, rec=0.071, cos=0.350), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.735 (perp=6.615, rec=0.062, cos=0.350), tot_loss_proj:1.736 [t=0.18s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.735 (perp=6.615, rec=0.063, cos=0.350), tot_loss_proj:1.737 [t=0.27s]
prediction: ['[CLS] efficient, suitably anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.042 | p: 84.275 | r: 88.116
rouge2     | fm: 51.622 | p: 51.236 | r: 52.035
rougeL     | fm: 77.138 | p: 75.547 | r: 79.015
rougeLsum  | fm: 76.916 | p: 75.402 | r: 78.859
r1fm+r2fm = 137.665

input #15 time: 0:08:15 | total time: 2:13:27


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.8738477759274703
highest_index [0]
highest [0.8738477759274703]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.8535990715026855 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.8344760537147522 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.8333166837692261 for ['[CLS]sa base slave shadow irvingdale [SEP]']
[Init] best rec loss: 0.8291432857513428 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best rec loss: 0.7910189628601074 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 0.7821306586265564 for ['[CLS] south jefferson late guy e sophia [SEP]']
[Init] best rec loss: 0.751442015171051 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 0.7509915828704834 for ['[CLS]encia olgazy edit areas sounding [SEP]']
[Init] best rec loss: 0.7365742325782776 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 0.7222983241081238 for ['[CLS]worthy eat town normal court earth [SEP]']
[Init] best perm rec loss: 0.7217596173286438 for ['[CLS]worthy town eat court normal earth [SEP]']
[Init] best perm rec loss: 0.7216429710388184 for ['[CLS] court eat normalworthy earth town [SEP]']
[Init] best perm rec loss: 0.7205458879470825 for ['[CLS] courtworthy earth eat town normal [SEP]']
[Init] best perm rec loss: 0.7202786803245544 for ['[CLS] earth town court eatworthy normal [SEP]']
[Init] best perm rec loss: 0.7198666930198669 for ['[CLS]worthy normal eat town court earth [SEP]']
[Init] best perm rec loss: 0.7186505794525146 for ['[CLS]worthy court eat normal earth town [SEP]']
[Init] best perm rec loss: 0.7185974717140198 for ['[CLS] earth court normalworthy eat town [SEP]']
[Init] best perm rec loss: 0.7184571027755737 for ['[CLS]worthy normal town eat court earth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.255 (perp=8.196, rec=0.380, cos=0.236), tot_loss_proj:2.723 [t=0.27s]
prediction: ['[CLS] more - this more all day [SEP]']
[ 100/2000] tot_loss=2.103 (perp=8.258, rec=0.220, cos=0.231), tot_loss_proj:2.541 [t=0.24s]
prediction: ['[CLS] all - this more all and [SEP]']
[ 150/2000] tot_loss=1.772 (perp=7.060, rec=0.134, cos=0.226), tot_loss_proj:2.245 [t=0.37s]
prediction: ['[CLS] all of this more all and [SEP]']
[ 200/2000] tot_loss=1.419 (perp=5.493, rec=0.087, cos=0.234), tot_loss_proj:1.802 [t=0.29s]
prediction: ['[CLS] all of this more, and [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.277 (perp=4.891, rec=0.083, cos=0.216), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] all of this and more, [SEP]']
[ 300/2000] tot_loss=1.290 (perp=4.891, rec=0.080, cos=0.232), tot_loss_proj:1.459 [t=0.22s]
prediction: ['[CLS] all of this and more, [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.244 (perp=4.697, rec=0.073, cos=0.231), tot_loss_proj:1.316 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.249 (perp=4.697, rec=0.076, cos=0.233), tot_loss_proj:1.325 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.243 (perp=4.697, rec=0.069, cos=0.234), tot_loss_proj:1.314 [t=0.20s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.239 (perp=4.697, rec=0.065, cos=0.234), tot_loss_proj:1.319 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.231 (perp=4.697, rec=0.057, cos=0.235), tot_loss_proj:1.316 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=1.236 (perp=4.697, rec=0.062, cos=0.235), tot_loss_proj:1.317 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.240 (perp=4.697, rec=0.066, cos=0.235), tot_loss_proj:1.319 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.237 (perp=4.697, rec=0.062, cos=0.235), tot_loss_proj:1.317 [t=0.20s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=1.234 (perp=4.697, rec=0.059, cos=0.235), tot_loss_proj:1.315 [t=0.24s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.238 (perp=4.697, rec=0.064, cos=0.235), tot_loss_proj:1.312 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.229 (perp=4.697, rec=0.054, cos=0.235), tot_loss_proj:1.306 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.246 (perp=4.697, rec=0.071, cos=0.235), tot_loss_proj:1.312 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.233 (perp=4.697, rec=0.058, cos=0.235), tot_loss_proj:1.320 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.235 (perp=4.697, rec=0.060, cos=0.235), tot_loss_proj:1.307 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.228 (perp=4.697, rec=0.053, cos=0.235), tot_loss_proj:1.310 [t=0.24s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.247 (perp=4.697, rec=0.072, cos=0.235), tot_loss_proj:1.311 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.240 (perp=4.697, rec=0.066, cos=0.235), tot_loss_proj:1.320 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.236 (perp=4.697, rec=0.061, cos=0.235), tot_loss_proj:1.311 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.233 (perp=4.697, rec=0.058, cos=0.235), tot_loss_proj:1.309 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.246 (perp=4.697, rec=0.071, cos=0.236), tot_loss_proj:1.324 [t=0.20s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.236 (perp=4.697, rec=0.061, cos=0.236), tot_loss_proj:1.309 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.230 (perp=4.697, rec=0.055, cos=0.236), tot_loss_proj:1.310 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.243 (perp=4.697, rec=0.068, cos=0.236), tot_loss_proj:1.315 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.242 (perp=4.697, rec=0.067, cos=0.236), tot_loss_proj:1.313 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.236 (perp=4.697, rec=0.061, cos=0.236), tot_loss_proj:1.314 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.235 (perp=4.697, rec=0.060, cos=0.236), tot_loss_proj:1.319 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.235 (perp=4.697, rec=0.060, cos=0.236), tot_loss_proj:1.312 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.239 (perp=4.697, rec=0.064, cos=0.236), tot_loss_proj:1.309 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.237 (perp=4.697, rec=0.062, cos=0.236), tot_loss_proj:1.313 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.234 (perp=4.697, rec=0.059, cos=0.236), tot_loss_proj:1.311 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.237 (perp=4.697, rec=0.062, cos=0.236), tot_loss_proj:1.318 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.239 (perp=4.697, rec=0.064, cos=0.236), tot_loss_proj:1.313 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.243 (perp=4.697, rec=0.068, cos=0.236), tot_loss_proj:1.320 [t=0.26s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.241 (perp=4.697, rec=0.066, cos=0.236), tot_loss_proj:1.313 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.994 | p: 85.285 | r: 88.919
rouge2     | fm: 54.172 | p: 53.810 | r: 54.535
rougeL     | fm: 78.352 | p: 76.806 | r: 80.131
rougeLsum  | fm: 78.368 | p: 77.022 | r: 80.144
r1fm+r2fm = 141.166

input #16 time: 0:08:25 | total time: 2:21:52


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.897085274221656
highest_index [0]
highest [0.897085274221656]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8094595074653625 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8010927438735962 for ['[CLS] angle bond masonacle cabinachejord right is kiel woman [SEP]']
[Init] best rec loss: 0.7858012914657593 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.7790115475654602 for ['[CLS] staretha jack nur stone lied pointsmori richie sienna foot [SEP]']
[Init] best rec loss: 0.7773550748825073 for ['[CLS] forecast yeast jewels young food filed paralyzedggio easy thing beau [SEP]']
[Init] best rec loss: 0.7639809250831604 for ['[CLS] wild filing curls wandabuck day victor which judicial coach peyton [SEP]']
[Init] best perm rec loss: 0.7639490365982056 for ['[CLS] curls wild judicial wanda coach victorbuck peyton day which filing [SEP]']
[Init] best perm rec loss: 0.76322340965271 for ['[CLS] peyton wanda which wild curlsbuck coach day victor judicial filing [SEP]']
[Init] best perm rec loss: 0.7632054090499878 for ['[CLS] filing coach judicial victor wild day wanda which peyton curlsbuck [SEP]']
[Init] best perm rec loss: 0.7618324160575867 for ['[CLS] curls filing day peyton judicial coachbuck wanda which wild victor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.046 (perp=12.131, rec=0.413, cos=0.207), tot_loss_proj:3.905 [t=0.20s]
prediction: ['[CLS] los against drug dirty latin talkeding [ when more slightly [SEP]']
[ 100/2000] tot_loss=2.296 (perp=8.893, rec=0.345, cos=0.173), tot_loss_proj:2.756 [t=0.19s]
prediction: ['[CLS] want for mind too much much aboutgo feeling more much [SEP]']
[ 150/2000] tot_loss=2.166 (perp=9.025, rec=0.177, cos=0.185), tot_loss_proj:2.790 [t=0.21s]
prediction: ['[CLS] want to getting too much think much too pretty think much [SEP]']
[ 200/2000] tot_loss=2.229 (perp=9.644, rec=0.123, cos=0.177), tot_loss_proj:3.241 [t=0.18s]
prediction: ['[CLS] want to on too think think about too that think much [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.233 (perp=9.716, rec=0.100, cos=0.190), tot_loss_proj:3.149 [t=0.22s]
prediction: ['[CLS] want to think too on think aboutgo what think much [SEP]']
[ 300/2000] tot_loss=2.215 (perp=9.716, rec=0.090, cos=0.182), tot_loss_proj:3.159 [t=0.25s]
prediction: ['[CLS] want to think too on think aboutgo what think much [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.816 (perp=7.641, rec=0.097, cos=0.191), tot_loss_proj:2.446 [t=0.18s]
prediction: ['[CLS] want to think too much think about like what think on [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.732 (perp=7.278, rec=0.092, cos=0.184), tot_loss_proj:2.247 [t=0.27s]
prediction: ['[CLS] want to think too much about think like what think going [SEP]']
[ 450/2000] tot_loss=1.729 (perp=7.278, rec=0.079, cos=0.194), tot_loss_proj:2.259 [t=0.23s]
prediction: ['[CLS] want to think too much about think like what think going [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.707 (perp=7.186, rec=0.078, cos=0.192), tot_loss_proj:2.207 [t=0.21s]
prediction: ['[CLS] want to think too much about think like think what going [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.717 (perp=7.186, rec=0.085, cos=0.195), tot_loss_proj:2.211 [t=0.19s]
prediction: ['[CLS] want to think too much about think like think what going [SEP]']
[ 600/2000] tot_loss=1.933 (perp=8.341, rec=0.073, cos=0.192), tot_loss_proj:2.796 [t=0.22s]
prediction: ['[CLS] want to what too much about think like think what going [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.677 (perp=7.040, rec=0.079, cos=0.191), tot_loss_proj:2.174 [t=0.28s]
prediction: ['[CLS] want to think too much about think like what what going [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.597 (perp=6.595, rec=0.083, cos=0.195), tot_loss_proj:2.053 [t=0.21s]
prediction: ['[CLS] want to think too much about what think like what going [SEP]']
[ 750/2000] tot_loss=1.577 (perp=6.595, rec=0.064, cos=0.194), tot_loss_proj:2.055 [t=0.21s]
prediction: ['[CLS] want to think too much about what think like what going [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.578 (perp=6.595, rec=0.065, cos=0.194), tot_loss_proj:2.057 [t=0.22s]
prediction: ['[CLS] want to think too much about what think like what going [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.596 (perp=6.595, rec=0.082, cos=0.195), tot_loss_proj:2.058 [t=0.18s]
prediction: ['[CLS] want to think too much about what think like what going [SEP]']
[ 900/2000] tot_loss=1.676 (perp=7.042, rec=0.073, cos=0.195), tot_loss_proj:1.965 [t=0.23s]
prediction: ["[CLS] want to think too much about what think'what going [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.649 (perp=6.922, rec=0.074, cos=0.190), tot_loss_proj:2.043 [t=0.24s]
prediction: ["[CLS] want to think too much about think'what what going [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.563 (perp=6.519, rec=0.065, cos=0.194), tot_loss_proj:1.945 [t=0.26s]
prediction: ["[CLS] want to think too much about going'what what think [SEP]"]
[1050/2000] tot_loss=1.563 (perp=6.519, rec=0.066, cos=0.194), tot_loss_proj:1.942 [t=0.18s]
prediction: ["[CLS] want to think too much about going'what what think [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.572 (perp=6.519, rec=0.074, cos=0.194), tot_loss_proj:1.936 [t=0.19s]
prediction: ["[CLS] want to think too much about going'what what think [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.538 (perp=6.389, rec=0.074, cos=0.186), tot_loss_proj:1.988 [t=0.19s]
prediction: ["[CLS] want to think too much about going think'what what [SEP]"]
[1200/2000] tot_loss=1.539 (perp=6.389, rec=0.069, cos=0.192), tot_loss_proj:1.980 [t=0.18s]
prediction: ["[CLS] want to think too much about going think'what what [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.535 (perp=6.389, rec=0.065, cos=0.192), tot_loss_proj:1.988 [t=0.21s]
prediction: ["[CLS] want to think too much about going think'what what [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.538 (perp=6.401, rec=0.065, cos=0.193), tot_loss_proj:1.960 [t=0.29s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
[1350/2000] tot_loss=1.557 (perp=6.401, rec=0.083, cos=0.194), tot_loss_proj:1.952 [t=0.18s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.537 (perp=6.401, rec=0.063, cos=0.194), tot_loss_proj:1.962 [t=0.24s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.545 (perp=6.401, rec=0.070, cos=0.195), tot_loss_proj:1.954 [t=0.18s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
[1500/2000] tot_loss=1.557 (perp=6.401, rec=0.082, cos=0.195), tot_loss_proj:1.959 [t=0.20s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.543 (perp=6.401, rec=0.068, cos=0.194), tot_loss_proj:1.952 [t=0.23s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.542 (perp=6.401, rec=0.068, cos=0.194), tot_loss_proj:1.964 [t=0.23s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
[1650/2000] tot_loss=1.543 (perp=6.401, rec=0.069, cos=0.194), tot_loss_proj:1.953 [t=0.18s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.550 (perp=6.401, rec=0.077, cos=0.194), tot_loss_proj:1.958 [t=0.18s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.537 (perp=6.401, rec=0.067, cos=0.189), tot_loss_proj:1.949 [t=0.24s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
[1800/2000] tot_loss=1.542 (perp=6.401, rec=0.070, cos=0.192), tot_loss_proj:1.958 [t=0.22s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.535 (perp=6.401, rec=0.062, cos=0.193), tot_loss_proj:1.959 [t=0.19s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.549 (perp=6.401, rec=0.076, cos=0.193), tot_loss_proj:1.954 [t=0.22s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
[1950/2000] tot_loss=1.549 (perp=6.401, rec=0.076, cos=0.193), tot_loss_proj:1.962 [t=0.25s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.537 (perp=6.401, rec=0.063, cos=0.193), tot_loss_proj:1.963 [t=0.18s]
prediction: ["[CLS] want to think too much about going think going'what [SEP]"]
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want to think too much about going think going'what [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 54.545 | p: 54.545 | r: 54.545
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 137.879

[Aggregate metrics]:
rouge1     | fm: 86.917 | p: 85.412 | r: 88.743
rouge2     | fm: 54.108 | p: 53.801 | r: 54.479
rougeL     | fm: 78.294 | p: 76.928 | r: 80.040
rougeLsum  | fm: 78.434 | p: 77.103 | r: 80.015
r1fm+r2fm = 141.025

input #17 time: 0:08:17 | total time: 2:30:10


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.8149975381030587
highest_index [0]
highest [0.8149975381030587]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9726220965385437 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9121159315109253 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.8722646832466125 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.8684701323509216 for ['[CLS]cs finally long throat [SEP]']
[Init] best rec loss: 0.8538751006126404 for ['[CLS] master asteroidnagar fungi [SEP]']
[Init] best rec loss: 0.8324066996574402 for ['[CLS] alternativelastic garrett filed [SEP]']
[Init] best rec loss: 0.8318713903427124 for ['[CLS] picked motto squadron siam [SEP]']
[Init] best perm rec loss: 0.8266626596450806 for ['[CLS] squadron motto picked siam [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.408 (perp=13.714, rec=0.330, cos=0.335), tot_loss_proj:4.280 [t=0.23s]
prediction: ['[CLS] alivetting medaliststatic [SEP]']
[ 100/2000] tot_loss=2.859 (perp=11.529, rec=0.222, cos=0.331), tot_loss_proj:4.013 [t=0.18s]
prediction: ['[CLS]goratinggorgor [SEP]']
[ 150/2000] tot_loss=2.922 (perp=12.203, rec=0.149, cos=0.332), tot_loss_proj:3.869 [t=0.23s]
prediction: ['[CLS]goratingvigor [SEP]']
[ 200/2000] tot_loss=2.880 (perp=12.203, rec=0.109, cos=0.331), tot_loss_proj:3.864 [t=0.22s]
prediction: ['[CLS]goratingvigor [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.343 (perp=9.456, rec=0.118, cos=0.334), tot_loss_proj:2.903 [t=0.18s]
prediction: ['[CLS]gorvigorating [SEP]']
[ 300/2000] tot_loss=2.311 (perp=9.456, rec=0.084, cos=0.335), tot_loss_proj:2.903 [t=0.20s]
prediction: ['[CLS]gorvigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.320 (perp=9.456, rec=0.094, cos=0.335), tot_loss_proj:2.897 [t=0.17s]
prediction: ['[CLS]gorvigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.310 (perp=9.456, rec=0.084, cos=0.335), tot_loss_proj:2.893 [t=0.24s]
prediction: ['[CLS]gorvigorating [SEP]']
[ 450/2000] tot_loss=2.302 (perp=9.456, rec=0.077, cos=0.334), tot_loss_proj:2.894 [t=0.18s]
prediction: ['[CLS]gorvigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.842 (perp=12.165, rec=0.074, cos=0.335), tot_loss_proj:3.947 [t=0.18s]
prediction: ['[CLS]gorvi inating [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.529 (perp=5.588, rec=0.077, cos=0.334), tot_loss_proj:1.526 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.514 (perp=5.588, rec=0.062, cos=0.335), tot_loss_proj:1.512 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.517 (perp=5.588, rec=0.064, cos=0.335), tot_loss_proj:1.518 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.503 (perp=5.588, rec=0.050, cos=0.335), tot_loss_proj:1.523 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.513 (perp=5.588, rec=0.060, cos=0.335), tot_loss_proj:1.512 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.503 (perp=5.588, rec=0.050, cos=0.335), tot_loss_proj:1.520 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.512 (perp=5.588, rec=0.059, cos=0.335), tot_loss_proj:1.525 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.519 (perp=5.588, rec=0.066, cos=0.335), tot_loss_proj:1.519 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.509 (perp=5.588, rec=0.056, cos=0.335), tot_loss_proj:1.519 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.522 (perp=5.588, rec=0.069, cos=0.335), tot_loss_proj:1.526 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.501 (perp=5.588, rec=0.048, cos=0.335), tot_loss_proj:1.515 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.506 (perp=5.588, rec=0.053, cos=0.335), tot_loss_proj:1.515 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.513 (perp=5.588, rec=0.059, cos=0.335), tot_loss_proj:1.527 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.518 (perp=5.588, rec=0.065, cos=0.336), tot_loss_proj:1.529 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.515 (perp=5.588, rec=0.061, cos=0.336), tot_loss_proj:1.515 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.502 (perp=5.588, rec=0.049, cos=0.335), tot_loss_proj:1.526 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.511 (perp=5.588, rec=0.058, cos=0.336), tot_loss_proj:1.514 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.513 (perp=5.588, rec=0.059, cos=0.336), tot_loss_proj:1.519 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.514 (perp=5.588, rec=0.061, cos=0.336), tot_loss_proj:1.512 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.518 (perp=5.588, rec=0.064, cos=0.336), tot_loss_proj:1.521 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.510 (perp=5.588, rec=0.057, cos=0.336), tot_loss_proj:1.517 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.512 (perp=5.588, rec=0.059, cos=0.336), tot_loss_proj:1.525 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.504 (perp=5.588, rec=0.051, cos=0.336), tot_loss_proj:1.511 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.521 (perp=5.588, rec=0.067, cos=0.336), tot_loss_proj:1.511 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.520 (perp=5.588, rec=0.067, cos=0.336), tot_loss_proj:1.516 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.513 (perp=5.588, rec=0.060, cos=0.336), tot_loss_proj:1.525 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.521 (perp=5.588, rec=0.068, cos=0.336), tot_loss_proj:1.511 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.515 (perp=5.588, rec=0.062, cos=0.336), tot_loss_proj:1.516 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.511 (perp=5.588, rec=0.058, cos=0.336), tot_loss_proj:1.522 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.514 (perp=5.588, rec=0.061, cos=0.336), tot_loss_proj:1.521 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.512 | p: 85.993 | r: 89.256
rouge2     | fm: 56.422 | p: 56.192 | r: 56.845
rougeL     | fm: 79.261 | p: 77.878 | r: 80.833
rougeLsum  | fm: 79.573 | p: 78.374 | r: 81.119
r1fm+r2fm = 143.935

input #18 time: 0:08:17 | total time: 2:38:27


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9112053282415201
highest_index [0]
highest [0.9112053282415201]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7290459871292114 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7178984880447388 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7136286497116089 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.6794976592063904 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best perm rec loss: 0.6768947243690491 for ['[CLS]zuki selected symmetry interstate [SEP]']
[Init] best perm rec loss: 0.6763118505477905 for ['[CLS] selectedzuki interstate symmetry [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.614 (perp=9.714, rec=0.501, cos=0.171), tot_loss_proj:3.219 [t=0.21s]
prediction: ['[CLS] satan deity ( prison [SEP]']
[ 100/2000] tot_loss=2.633 (perp=10.159, rec=0.452, cos=0.149), tot_loss_proj:3.501 [t=0.28s]
prediction: ['[CLS] rat deity hitler severe [SEP]']
[ 150/2000] tot_loss=2.852 (perp=11.786, rec=0.344, cos=0.151), tot_loss_proj:4.054 [t=0.18s]
prediction: ['[CLS] yofa inmy [SEP]']
[ 200/2000] tot_loss=2.762 (perp=11.182, rec=0.366, cos=0.160), tot_loss_proj:3.727 [t=0.19s]
prediction: ['[CLS] bofammy [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.385 (perp=9.815, rec=0.280, cos=0.142), tot_loss_proj:3.223 [t=0.19s]
prediction: ['[CLS] youfamyfa [SEP]']
[ 300/2000] tot_loss=2.220 (perp=9.390, rec=0.178, cos=0.163), tot_loss_proj:3.157 [t=0.21s]
prediction: ['[CLS] tofamyfa [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.167 (perp=9.390, rec=0.125, cos=0.164), tot_loss_proj:3.148 [t=0.23s]
prediction: ['[CLS] tofamyfa [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.163 (perp=9.390, rec=0.117, cos=0.168), tot_loss_proj:3.152 [t=0.18s]
prediction: ['[CLS] tofamyfa [SEP]']
[ 450/2000] tot_loss=2.156 (perp=9.390, rec=0.109, cos=0.169), tot_loss_proj:3.148 [t=0.24s]
prediction: ['[CLS] tofamyfa [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.765 (perp=7.523, rec=0.104, cos=0.157), tot_loss_proj:2.425 [t=0.18s]
prediction: ['[CLS] infamyfa [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.773 (perp=7.523, rec=0.099, cos=0.169), tot_loss_proj:2.420 [t=0.24s]
prediction: ['[CLS] infamyfa [SEP]']
[ 600/2000] tot_loss=1.778 (perp=7.523, rec=0.106, cos=0.167), tot_loss_proj:2.424 [t=0.19s]
prediction: ['[CLS] infamyfa [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.756 (perp=7.523, rec=0.090, cos=0.161), tot_loss_proj:2.416 [t=0.18s]
prediction: ['[CLS] infamyfa [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.756 (perp=7.523, rec=0.097, cos=0.155), tot_loss_proj:2.416 [t=0.28s]
prediction: ['[CLS] infamyfa [SEP]']
[ 750/2000] tot_loss=1.766 (perp=7.523, rec=0.092, cos=0.169), tot_loss_proj:2.414 [t=0.18s]
prediction: ['[CLS] infamyfa [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.750 (perp=7.523, rec=0.079, cos=0.167), tot_loss_proj:2.418 [t=0.18s]
prediction: ['[CLS] infamyfa [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.758 (perp=7.523, rec=0.084, cos=0.169), tot_loss_proj:2.419 [t=0.19s]
prediction: ['[CLS] infamyfa [SEP]']
[ 900/2000] tot_loss=1.750 (perp=7.523, rec=0.078, cos=0.168), tot_loss_proj:2.422 [t=0.20s]
prediction: ['[CLS] infamyfa [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.748 (perp=7.523, rec=0.076, cos=0.168), tot_loss_proj:2.424 [t=0.19s]
prediction: ['[CLS] infamyfa [SEP]']
Attempt swap
[1000/2000] tot_loss=2.423 (perp=10.909, rec=0.073, cos=0.168), tot_loss_proj:3.653 [t=0.19s]
prediction: ['[CLS] in inmyfa [SEP]']
[1050/2000] tot_loss=2.414 (perp=10.909, rec=0.064, cos=0.168), tot_loss_proj:3.649 [t=0.18s]
prediction: ['[CLS] in inmyfa [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.522 (perp=6.548, rec=0.062, cos=0.151), tot_loss_proj:1.833 [t=0.25s]
prediction: ['[CLS] in infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.540 (perp=6.548, rec=0.071, cos=0.159), tot_loss_proj:1.838 [t=0.18s]
prediction: ['[CLS] in infamy [SEP]']
[1200/2000] tot_loss=1.558 (perp=6.548, rec=0.087, cos=0.162), tot_loss_proj:1.834 [t=0.18s]
prediction: ['[CLS] in infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.543 (perp=6.548, rec=0.070, cos=0.164), tot_loss_proj:1.842 [t=0.25s]
prediction: ['[CLS] in infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.538 (perp=6.548, rec=0.064, cos=0.165), tot_loss_proj:1.830 [t=0.18s]
prediction: ['[CLS] in infamy [SEP]']
[1350/2000] tot_loss=1.461 (perp=6.110, rec=0.073, cos=0.165), tot_loss_proj:1.496 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.458 (perp=6.110, rec=0.070, cos=0.166), tot_loss_proj:1.483 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.459 (perp=6.110, rec=0.071, cos=0.166), tot_loss_proj:1.498 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.446 (perp=6.110, rec=0.058, cos=0.167), tot_loss_proj:1.482 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.451 (perp=6.110, rec=0.062, cos=0.167), tot_loss_proj:1.493 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.446 (perp=6.110, rec=0.057, cos=0.167), tot_loss_proj:1.488 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.465 (perp=6.110, rec=0.076, cos=0.167), tot_loss_proj:1.481 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.450 (perp=6.110, rec=0.061, cos=0.167), tot_loss_proj:1.494 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.468 (perp=6.110, rec=0.078, cos=0.167), tot_loss_proj:1.490 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.451 (perp=6.110, rec=0.062, cos=0.168), tot_loss_proj:1.500 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.462 (perp=6.110, rec=0.072, cos=0.168), tot_loss_proj:1.466 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.462 (perp=6.110, rec=0.073, cos=0.168), tot_loss_proj:1.496 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.437 (perp=6.110, rec=0.047, cos=0.168), tot_loss_proj:1.504 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.465 (perp=6.110, rec=0.075, cos=0.168), tot_loss_proj:1.485 [t=0.29s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.122 | p: 86.773 | r: 89.812
rouge2     | fm: 58.585 | p: 58.347 | r: 58.927
rougeL     | fm: 80.495 | p: 79.201 | r: 82.023
rougeLsum  | fm: 80.397 | p: 79.205 | r: 81.952
r1fm+r2fm = 146.707

input #19 time: 0:08:13 | total time: 2:46:40


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.8493072236043971
highest_index [0]
highest [0.8493072236043971]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.861232340335846 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.7953866124153137 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 0.7832732200622559 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best rec loss: 0.7799745798110962 for ['[CLS] club provious microphone [SEP]']
[Init] best perm rec loss: 0.7778477072715759 for ['[CLS] pro club microphonevious [SEP]']
[Init] best perm rec loss: 0.7745069861412048 for ['[CLS] microphone pro clubvious [SEP]']
[Init] best perm rec loss: 0.774168074131012 for ['[CLS] pro microphonevious club [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.375 (perp=8.863, rec=0.343, cos=0.259), tot_loss_proj:2.891 [t=0.18s]
prediction: ['[CLS] the pleasureverse pleasure [SEP]']
[ 100/2000] tot_loss=2.174 (perp=8.863, rec=0.130, cos=0.271), tot_loss_proj:2.901 [t=0.25s]
prediction: ['[CLS] the pleasureverse pleasure [SEP]']
[ 150/2000] tot_loss=2.358 (perp=8.863, rec=0.244, cos=0.341), tot_loss_proj:2.899 [t=0.18s]
prediction: ['[CLS] the pleasureverse pleasure [SEP]']
[ 200/2000] tot_loss=1.902 (perp=7.610, rec=0.115, cos=0.265), tot_loss_proj:1.906 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.874 (perp=7.610, rec=0.081, cos=0.271), tot_loss_proj:1.906 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 300/2000] tot_loss=1.856 (perp=7.610, rec=0.060, cos=0.274), tot_loss_proj:1.900 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.869 (perp=7.610, rec=0.071, cos=0.276), tot_loss_proj:1.909 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.857 (perp=7.610, rec=0.057, cos=0.278), tot_loss_proj:1.900 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.863 (perp=7.610, rec=0.063, cos=0.278), tot_loss_proj:1.898 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.863 (perp=7.610, rec=0.063, cos=0.278), tot_loss_proj:1.896 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.853 (perp=7.610, rec=0.065, cos=0.266), tot_loss_proj:1.901 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.864 (perp=7.610, rec=0.066, cos=0.276), tot_loss_proj:1.905 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.869 (perp=7.610, rec=0.070, cos=0.277), tot_loss_proj:1.903 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.862 (perp=7.610, rec=0.062, cos=0.277), tot_loss_proj:1.896 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.853 (perp=7.610, rec=0.053, cos=0.278), tot_loss_proj:1.896 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.861 (perp=7.610, rec=0.060, cos=0.278), tot_loss_proj:1.898 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.867 (perp=7.610, rec=0.066, cos=0.278), tot_loss_proj:1.894 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.858 (perp=7.610, rec=0.058, cos=0.278), tot_loss_proj:1.897 [t=0.20s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.844 (perp=7.610, rec=0.055, cos=0.267), tot_loss_proj:1.899 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.863 (perp=7.610, rec=0.065, cos=0.276), tot_loss_proj:1.909 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.854 (perp=7.610, rec=0.055, cos=0.277), tot_loss_proj:1.895 [t=0.21s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.848 (perp=7.610, rec=0.048, cos=0.278), tot_loss_proj:1.904 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.858 (perp=7.610, rec=0.058, cos=0.278), tot_loss_proj:1.899 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.866 (perp=7.610, rec=0.066, cos=0.278), tot_loss_proj:1.907 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.854 (perp=7.610, rec=0.054, cos=0.278), tot_loss_proj:1.897 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.867 (perp=7.610, rec=0.067, cos=0.278), tot_loss_proj:1.897 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.870 (perp=7.610, rec=0.070, cos=0.278), tot_loss_proj:1.892 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.847 (perp=7.610, rec=0.046, cos=0.278), tot_loss_proj:1.909 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.856 (perp=7.610, rec=0.055, cos=0.278), tot_loss_proj:1.898 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.854 (perp=7.610, rec=0.054, cos=0.278), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.868 (perp=7.610, rec=0.068, cos=0.278), tot_loss_proj:1.902 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.860 (perp=7.610, rec=0.059, cos=0.278), tot_loss_proj:1.900 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.858 (perp=7.610, rec=0.058, cos=0.278), tot_loss_proj:1.902 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.866 (perp=7.610, rec=0.065, cos=0.278), tot_loss_proj:1.894 [t=0.21s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.855 (perp=7.610, rec=0.055, cos=0.278), tot_loss_proj:1.906 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.857 (perp=7.610, rec=0.057, cos=0.278), tot_loss_proj:1.900 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.866 (perp=7.610, rec=0.066, cos=0.278), tot_loss_proj:1.915 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.861 (perp=7.610, rec=0.060, cos=0.278), tot_loss_proj:1.909 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.862 (perp=7.610, rec=0.061, cos=0.278), tot_loss_proj:1.894 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.865 (perp=7.610, rec=0.064, cos=0.278), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.716 | p: 87.402 | r: 90.258
rouge2     | fm: 60.439 | p: 60.164 | r: 60.754
rougeL     | fm: 81.332 | p: 80.032 | r: 82.859
rougeLsum  | fm: 81.429 | p: 80.327 | r: 82.804
r1fm+r2fm = 149.154

input #20 time: 0:08:13 | total time: 2:54:54


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.8900996169074267
highest_index [0]
highest [0.8900996169074267]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.8414052128791809 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.807881772518158 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.7976624369621277 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.7944239377975464 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.7779096961021423 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.7635916471481323 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 0.7617754340171814 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 0.7614224553108215 for ['[CLS] side according [UNK] item vii she pose baby bent sizeback stony loan, general fauna labor situationstaking rights there golden dee connecticut especially [SEP]']
[Init] best perm rec loss: 0.7612538933753967 for ['[CLS] baby especially situations rightstaking, stony loan according connecticut there dee pose bent viiback she general size item fauna labor golden side [UNK] [SEP]']
[Init] best perm rec loss: 0.7612189054489136 for ['[CLS] connecticut size, side stony especially according there bent [UNK] labor vii rights generalback fauna golden pose shetaking item situations loan dee baby [SEP]']
[Init] best perm rec loss: 0.7608145475387573 for ['[CLS] golden connecticut, she stony situations dee pose fauna general especially according there baby size vii labor side itemback loan benttaking rights [UNK] [SEP]']
[Init] best perm rec loss: 0.7605355381965637 for ['[CLS] she bent side vii size [UNK] situationsback especially connecticut there rights according golden, loan labor general stony item baby posetaking dee fauna [SEP]']
[Init] best perm rec loss: 0.7600076198577881 for ['[CLS] labor loan size according item rightstaking golden baby stony dee there pose [UNK] fauna especially situations connecticut bent generalback she, side vii [SEP]']
[Init] best perm rec loss: 0.7597319483757019 for ['[CLS] general golden pose vii [UNK] she fauna connecticut especially according bentback size baby side loan there labor rightstaking situations item stony dee, [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.211 (perp=12.875, rec=0.484, cos=0.152), tot_loss_proj:3.722 [t=0.18s]
prediction: ['[CLS] training by racism saddam states notbed paid blind became badly swedisheta terrorist platform tax waste poorly unicef people officials. probablynction fitted [SEP]']
[ 100/2000] tot_loss=3.121 (perp=12.328, rec=0.480, cos=0.175), tot_loss_proj:3.557 [t=0.25s]
prediction: ['[CLS] mascot by treatmentitor bill are a that down slam lesseborg /lassified platform tax fault poorly victim progressive officials barrel apparently publicity built [SEP]']
[ 150/2000] tot_loss=3.040 (perp=12.623, rec=0.323, cos=0.193), tot_loss_proj:4.236 [t=0.21s]
prediction: ['[CLS]lia by representative off the are woman that under relegated badly dutch like seizure turnout tax fault instead sex progressive athletes barrel evidently seasons works [SEP]']
[ 200/2000] tot_loss=2.809 (perp=11.589, rec=0.315, cos=0.176), tot_loss_proj:3.519 [t=0.25s]
prediction: ['[CLS] way by representative death sexual both man that days across jaenelle carolina rather autism buren were political instead of military athletes barrel apparently seasons built [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.666 (perp=11.124, rec=0.268, cos=0.172), tot_loss_proj:3.637 [t=0.26s]
prediction: ['[CLS] man upside representative the u both way is up across jaenelle carolina considered autism buren any fault instead of serious athletes hog very works built [SEP]']
[ 300/2000] tot_loss=2.856 (perp=12.168, rec=0.245, cos=0.177), tot_loss_proj:4.138 [t=0.22s]
prediction: ['[CLS] life makestypical a the both animals that up across looking carolina considered autism buren any way instead seriousting athletes hog way works built [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.538 (perp=10.637, rec=0.210, cos=0.201), tot_loss_proj:3.426 [t=0.21s]
prediction: ['[CLS] the makestypical the someone out teachers that out women looking carolina like autism francisco any way instead serious out athletes hog way works out [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.401 (perp=10.104, rec=0.183, cos=0.198), tot_loss_proj:3.263 [t=0.18s]
prediction: ['[CLS] the makestypical the out teachers more out women looking carolina woman look gabby street of way instead serious out athletes hung way works out [SEP]']
[ 450/2000] tot_loss=2.473 (perp=10.538, rec=0.168, cos=0.197), tot_loss_proj:3.409 [t=0.19s]
prediction: ['[CLS] this makestypical the all salaries it out women lookingtypical woman look gabby street of positive instead serious out athletes hung way works out [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.560 (perp=11.032, rec=0.148, cos=0.205), tot_loss_proj:3.539 [t=0.26s]
prediction: ['[CLS] this makestypical woman all salaries it out women lookingtypical the look gabby all oftypical instead serious out athletes cubic way works out [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.516 (perp=10.858, rec=0.143, cos=0.201), tot_loss_proj:3.356 [t=0.26s]
prediction: ['[CLS] this makestypical woman all salaries more women women lookingtypical the look ף all oftypical instead serious out athletes way cubic works out [SEP]']
[ 600/2000] tot_loss=2.482 (perp=10.737, rec=0.132, cos=0.203), tot_loss_proj:3.363 [t=0.27s]
prediction: ['[CLS] this makestypical woman all teachers more women women lookingtypical the look moral all oftypical instead serious out athletes way cubic works out [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.607 (perp=11.389, rec=0.138, cos=0.191), tot_loss_proj:3.326 [t=0.25s]
prediction: ['[CLS] this makestypical women all a the women womentypicaltypical treatment look moral all liketypical instead serious out athletes way cubic works out [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.444 (perp=10.600, rec=0.124, cos=0.200), tot_loss_proj:3.257 [t=0.24s]
prediction: ['[CLS] this makestypical women all the thetypicaltypical treatment look moral women women all liketypical instead serious out athletes way cubic works out [SEP]']
[ 750/2000] tot_loss=2.489 (perp=10.841, rec=0.120, cos=0.201), tot_loss_proj:3.292 [t=0.18s]
prediction: ['[CLS] this makestypical women all the thetypicaltypicalxy look moral women women all liketypical instead serious out athletes way cubic works out [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.341 (perp=10.118, rec=0.115, cos=0.202), tot_loss_proj:3.087 [t=0.19s]
prediction: ['[CLS] this makestypical women all the thetypicaltypicalxy all moral women women look liketypical instead serious out athletes way cubic works out [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.289 (perp=9.911, rec=0.104, cos=0.203), tot_loss_proj:3.028 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the thetypicaltypical out all moral women women look liketypical instead seriousxy athletes way cubic works out [SEP]']
[ 900/2000] tot_loss=2.306 (perp=9.911, rec=0.120, cos=0.204), tot_loss_proj:3.026 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the thetypicaltypical out all moral women women look liketypical instead seriousxy athletes way cubic works out [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.251 (perp=9.674, rec=0.111, cos=0.206), tot_loss_proj:2.991 [t=0.20s]
prediction: ['[CLS] this makes caretaker women all the thetypicaltypical out all moral womenxy look liketypical instead serious women athletes way cubic works out [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.231 (perp=9.651, rec=0.104, cos=0.196), tot_loss_proj:2.990 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the thexytypicaltypical out all moral women look liketypical instead serious women athletes way assume works out [SEP]']
[1050/2000] tot_loss=2.305 (perp=9.978, rec=0.108, cos=0.202), tot_loss_proj:3.069 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the thexynivoroustypical out all moral women look liketypical instead serious women athletes way assume works out [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.224 (perp=9.596, rec=0.102, cos=0.203), tot_loss_proj:3.020 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the thexynivoroustypical out all moral women look liketypical instead serious women athletes assume way works out [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.157 (perp=9.239, rec=0.112, cos=0.197), tot_loss_proj:2.864 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the out all thexynivoroustypical moral women look liketypical instead serious women athletes assume way works out [SEP]']
[1200/2000] tot_loss=2.156 (perp=9.239, rec=0.107, cos=0.201), tot_loss_proj:2.864 [t=0.18s]
prediction: ['[CLS] this makes caretaker women all the out all thexynivoroustypical moral women look liketypical instead serious women athletes assume way works out [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.099 (perp=8.967, rec=0.102, cos=0.203), tot_loss_proj:2.798 [t=0.26s]
prediction: ['[CLS] this makes caretaker women all the out all thexytypicaltypical moral women look liketypical instead serious women athletes assume way works out [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.044 (perp=8.710, rec=0.112, cos=0.190), tot_loss_proj:2.735 [t=0.22s]
prediction: ['[CLS] this makes caretaker women all the out works all thexytypicaltypical moral women look liketypical instead serious women athletes assume way out [SEP]']
[1350/2000] tot_loss=2.048 (perp=8.710, rec=0.110, cos=0.196), tot_loss_proj:2.735 [t=0.25s]
prediction: ['[CLS] this makes caretaker women all the out works all thexytypicaltypical moral women look liketypical instead serious women athletes assume way out [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.037 (perp=8.653, rec=0.108, cos=0.199), tot_loss_proj:2.691 [t=0.22s]
prediction: ['[CLS] this makes caretaker women all the out works all thexytypical moral women look liketypicaltypical instead serious women athletes assume way out [SEP]']
Attempt swap
[1450/2000] tot_loss=2.035 (perp=8.653, rec=0.105, cos=0.200), tot_loss_proj:2.694 [t=0.18s]
prediction: ['[CLS] this makes caretaker women all the out works all thexytypical moral women look liketypicaltypical instead serious women athletes assume way out [SEP]']
[1500/2000] tot_loss=2.032 (perp=8.653, rec=0.101, cos=0.201), tot_loss_proj:2.698 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the out works all thexytypical moral women look liketypicaltypical instead serious women athletes assume way out [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.982 (perp=8.379, rec=0.104, cos=0.202), tot_loss_proj:2.595 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the out works allxytypical moral women look like thetypicaltypical instead serious women athletes assume way out [SEP]']
Attempt swap
[1600/2000] tot_loss=1.984 (perp=8.379, rec=0.106, cos=0.203), tot_loss_proj:2.599 [t=0.18s]
prediction: ['[CLS] this makes caretaker women all the out works allxytypical moral women look like thetypicaltypical instead serious women athletes assume way out [SEP]']
[1650/2000] tot_loss=2.017 (perp=8.506, rec=0.113, cos=0.203), tot_loss_proj:2.659 [t=0.23s]
prediction: ['[CLS] this makes caretaker women all the out works all waystypical moral women look like thetypicaltypical instead serious women athletes assume way out [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.966 (perp=8.330, rec=0.101, cos=0.199), tot_loss_proj:2.585 [t=0.20s]
prediction: ['[CLS] this makes caretaker women all the out works alltypical moral women look like thetypicaltypical instead serious ways women athletes assume way out [SEP]']
Attempt swap
[1750/2000] tot_loss=1.973 (perp=8.330, rec=0.105, cos=0.201), tot_loss_proj:2.589 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the out works alltypical moral women look like thetypicaltypical instead serious ways women athletes assume way out [SEP]']
[1800/2000] tot_loss=1.968 (perp=8.330, rec=0.099, cos=0.202), tot_loss_proj:2.586 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the out works alltypical moral women look like thetypicaltypical instead serious ways women athletes assume way out [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.980 (perp=8.339, rec=0.110, cos=0.203), tot_loss_proj:2.617 [t=0.25s]
prediction: ['[CLS] this makes caretaker women all the out works alltypical moral women look like thetypicaltypical instead serious women ways athletes assume way out [SEP]']
Attempt swap
[1900/2000] tot_loss=1.970 (perp=8.339, rec=0.099, cos=0.203), tot_loss_proj:2.626 [t=0.19s]
prediction: ['[CLS] this makes caretaker women all the out works alltypical moral women look like thetypicaltypical instead serious women ways athletes assume way out [SEP]']
[1950/2000] tot_loss=2.158 (perp=9.257, rec=0.103, cos=0.204), tot_loss_proj:2.749 [t=0.19s]
prediction: ['[CLS] this makes caretaker stereo all the out works alltypical moral women look like thetypicaltypical instead serious womenxy athletes assume way out [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.081 (perp=8.821, rec=0.116, cos=0.201), tot_loss_proj:2.664 [t=0.19s]
prediction: ['[CLS] this makes caretaker all, out works alltypical moral women look like thetypical stereotypical instead serious womenxy athletes assume way out [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] this makes caretaker women all the out works all thexytypical moral women look liketypicaltypical instead serious women athletes assume way out [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 65.217 | p: 65.217 | r: 65.217
rouge2     | fm: 4.545 | p: 4.545 | r: 4.545
rougeL     | fm: 43.478 | p: 43.478 | r: 43.478
rougeLsum  | fm: 43.478 | p: 43.478 | r: 43.478
r1fm+r2fm = 69.763

[Aggregate metrics]:
rouge1     | fm: 87.572 | p: 86.335 | r: 89.023
rouge2     | fm: 58.235 | p: 57.948 | r: 58.559
rougeL     | fm: 79.598 | p: 78.450 | r: 80.999
rougeLsum  | fm: 79.770 | p: 78.630 | r: 81.019
r1fm+r2fm = 145.808

input #21 time: 0:08:29 | total time: 3:03:23


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.8413169618072713
highest_index [0]
highest [0.8413169618072713]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9825612902641296 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9815587997436523 for ['[CLS] mast landlord rockome crusaders enjoyed denise fire dock almost vera [SEP]']
[Init] best rec loss: 0.9724447131156921 for ['[CLS] catalogue scom de respiratory z loose ps eventual cart win [SEP]']
[Init] best rec loss: 0.9627328515052795 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 0.956476628780365 for ['[CLS]dbus leaguedel more arrest able communists confederatedgetsomics [SEP]']
[Init] best rec loss: 0.952782392501831 for ['[CLS] kali camp missiondio but whispered mining paulaville atmosphere qu [SEP]']
[Init] best rec loss: 0.9526962637901306 for ['[CLS]vi dudley sponsored then background che opposition laurencefc feat double [SEP]']
[Init] best rec loss: 0.9523847699165344 for ['[CLS] view masters sheets bar separated emigrated play career traitor marriedory [SEP]']
[Init] best rec loss: 0.9423995018005371 for ['[CLS]ou apartowskilizer teaching collins wolfe sample rite maze kaiser [SEP]']
[Init] best rec loss: 0.9377793073654175 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 0.935045599937439 for ['[CLS] her function board kids phoenix laughter set over chineseers schedule [SEP]']
[Init] best perm rec loss: 0.9346932768821716 for ['[CLS] laughter phoenix set kids chineseers function schedule her over board [SEP]']
[Init] best perm rec loss: 0.9336993098258972 for ['[CLS] kids set chinese phoenix board schedule over functioners her laughter [SEP]']
[Init] best perm rec loss: 0.9332870244979858 for ['[CLS] function phoenix her board kids laughterers set chinese over schedule [SEP]']
[Init] best perm rec loss: 0.9331303834915161 for ['[CLS] function boarders her schedule over kids set chinese laughter phoenix [SEP]']
[Init] best perm rec loss: 0.9323535561561584 for ['[CLS] function over kids set phoenix chinese board her schedule laughterers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.215 (perp=11.152, rec=0.684, cos=0.301), tot_loss_proj:3.807 [t=0.17s]
prediction: ['[CLS] singles. • failure - arson fuck fighters test dat guard [SEP]']
[ 100/2000] tot_loss=3.450 (perp=12.872, rec=0.584, cos=0.292), tot_loss_proj:4.234 [t=0.19s]
prediction: ['[CLS] consequences. • finnish team arson fuck erupted slovak correctional a [SEP]']
[ 150/2000] tot_loss=3.350 (perp=12.585, rec=0.561, cos=0.271), tot_loss_proj:4.259 [t=0.18s]
prediction: ['[CLS] consequences. • lanka emotional hostile vampireete 20 correctional a [SEP]']
[ 200/2000] tot_loss=3.102 (perp=11.618, rec=0.557, cos=0.222), tot_loss_proj:4.171 [t=0.22s]
prediction: ['[CLS] consequences. • lanka involving underfinger assault shell pmid a [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.406 (perp=12.593, rec=0.612, cos=0.275), tot_loss_proj:4.169 [t=0.24s]
prediction: ['[CLS] team consequences whichphobic sorry psychological for infringement enough initially filmfare [SEP]']
[ 300/2000] tot_loss=3.589 (perp=14.125, rec=0.531, cos=0.232), tot_loss_proj:4.602 [t=0.19s]
prediction: ['[CLS] franchise consequences which activists unsuccessful bonus fully comedy established racehorse filmfare [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.255 (perp=12.463, rec=0.511, cos=0.251), tot_loss_proj:4.268 [t=0.19s]
prediction: ['[CLS] franchise consequences comedy illegal enjoyed enjoyable up which enough enjoyable filmfare [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.181 (perp=12.249, rec=0.527, cos=0.205), tot_loss_proj:4.486 [t=0.22s]
prediction: ['[CLS] enjoyable consequences infringement illegal failure adaptation fully cdp established. motown [SEP]']
[ 450/2000] tot_loss=3.477 (perp=13.128, rec=0.626, cos=0.225), tot_loss_proj:4.620 [t=0.25s]
prediction: ['[CLS] guilty consequencesious shortest failure enjoyable story yokohama croatian. restored [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.358 (perp=12.878, rec=0.522, cos=0.261), tot_loss_proj:4.219 [t=0.18s]
prediction: ['[CLS] yokohama enjoyable consequences architecture shortest enjoyable adaptationglass croatian. motown [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.402 (perp=13.463, rec=0.491, cos=0.218), tot_loss_proj:4.049 [t=0.18s]
prediction: ['[CLS] enjoyable enjoyable consequences indo shortest enjoyable adaptation motown croatian aglass [SEP]']
[ 600/2000] tot_loss=3.067 (perp=12.158, rec=0.482, cos=0.154), tot_loss_proj:3.768 [t=0.19s]
prediction: ['[CLS] enjoyable enjoyable consequences indo shortest enjoyable adaptation directed isolated a ebook [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.071 (perp=12.314, rec=0.485, cos=0.123), tot_loss_proj:3.305 [t=0.18s]
prediction: ['[CLS] enjoyable enjoyable enjoyableze indo successful adaptation directed croatian a ebook [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=3.062 (perp=11.528, rec=0.485, cos=0.272), tot_loss_proj:3.099 [t=0.18s]
prediction: ['[CLS] enjoyable enjoyable enjoyable indo successful adaptation directed isolated a sweet fully [SEP]']
[ 750/2000] tot_loss=3.032 (perp=11.717, rec=0.453, cos=0.236), tot_loss_proj:3.215 [t=0.19s]
prediction: ['[CLS] enjoyable enjoyable enjoyable indo successful adaptation directed isolated aze fully [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.931 (perp=11.456, rec=0.456, cos=0.184), tot_loss_proj:3.198 [t=0.18s]
prediction: ['[CLS] enjoyable enjoyable enjoyable fully successful adaptation directed isolated aze indo [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.932 (perp=11.275, rec=0.454, cos=0.223), tot_loss_proj:3.038 [t=0.19s]
prediction: ['[CLS] enjoyable enjoyable enjoyable croatian a fully successful adaptation directedze indo [SEP]']
[ 900/2000] tot_loss=2.840 (perp=11.275, rec=0.452, cos=0.134), tot_loss_proj:3.048 [t=0.18s]
prediction: ['[CLS] enjoyable enjoyable enjoyable croatian a fully successful adaptation directedze indo [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.873 (perp=10.763, rec=0.439, cos=0.282), tot_loss_proj:2.942 [t=0.25s]
prediction: ['[CLS] enjoyable enjoyable enjoyable croatian a fully successful adaptation directed characters indo [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=3.013 (perp=11.894, rec=0.463, cos=0.171), tot_loss_proj:3.311 [t=0.19s]
prediction: ['[CLS] enjoyable enjoyable enjoyable croatian a attacks fully successful adaptation directed characters [SEP]']
[1050/2000] tot_loss=2.986 (perp=11.434, rec=0.437, cos=0.262), tot_loss_proj:3.300 [t=0.21s]
prediction: ['[CLS] enjoyable enjoyable enjoyable existence a attacks fully successful adaptation restored system [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.822 (perp=11.005, rec=0.453, cos=0.168), tot_loss_proj:3.144 [t=0.26s]
prediction: ['[CLS] a enjoyable enjoyable existence enjoyable attacks fully successful adaptation restored characters [SEP]']
Attempt swap
[1150/2000] tot_loss=2.708 (perp=10.122, rec=0.432, cos=0.252), tot_loss_proj:2.909 [t=0.19s]
prediction: ['[CLS] a enjoyable enjoyable existence enjoyable oriented fully successful adaptation restored characters [SEP]']
[1200/2000] tot_loss=2.613 (perp=10.122, rec=0.439, cos=0.150), tot_loss_proj:2.907 [t=0.18s]
prediction: ['[CLS] a enjoyable enjoyable existence enjoyable oriented fully successful adaptation restored characters [SEP]']
Attempt swap
[1250/2000] tot_loss=2.725 (perp=10.122, rec=0.430, cos=0.270), tot_loss_proj:2.903 [t=0.19s]
prediction: ['[CLS] a enjoyable enjoyable existence enjoyable oriented fully successful adaptation restored characters [SEP]']
Attempt swap
[1300/2000] tot_loss=2.654 (perp=10.122, rec=0.428, cos=0.202), tot_loss_proj:2.902 [t=0.25s]
prediction: ['[CLS] a enjoyable enjoyable existence enjoyable oriented fully successful adaptation restored characters [SEP]']
[1350/2000] tot_loss=2.740 (perp=10.122, rec=0.429, cos=0.286), tot_loss_proj:2.909 [t=0.23s]
prediction: ['[CLS] a enjoyable enjoyable existence enjoyable oriented fully successful adaptation restored characters [SEP]']
Attempt swap
[1400/2000] tot_loss=2.684 (perp=10.122, rec=0.420, cos=0.239), tot_loss_proj:2.905 [t=0.26s]
prediction: ['[CLS] a enjoyable enjoyable existence enjoyable oriented fully successful adaptation restored characters [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.608 (perp=10.131, rec=0.425, cos=0.157), tot_loss_proj:2.934 [t=0.20s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation restored characters [SEP]']
[1500/2000] tot_loss=2.716 (perp=10.131, rec=0.428, cos=0.262), tot_loss_proj:2.934 [t=0.18s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation restored characters [SEP]']
Attempt swap
[1550/2000] tot_loss=2.638 (perp=10.131, rec=0.427, cos=0.185), tot_loss_proj:2.927 [t=0.25s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation restored characters [SEP]']
Attempt swap
[1600/2000] tot_loss=2.715 (perp=10.131, rec=0.412, cos=0.276), tot_loss_proj:2.931 [t=0.19s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation restored characters [SEP]']
[1650/2000] tot_loss=2.671 (perp=10.171, rec=0.417, cos=0.221), tot_loss_proj:2.816 [t=0.24s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation directed characters [SEP]']
Attempt swap
[1700/2000] tot_loss=2.736 (perp=10.171, rec=0.415, cos=0.286), tot_loss_proj:2.823 [t=0.24s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation directed characters [SEP]']
Attempt swap
[1750/2000] tot_loss=2.697 (perp=10.171, rec=0.419, cos=0.245), tot_loss_proj:2.820 [t=0.19s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation directed characters [SEP]']
[1800/2000] tot_loss=2.687 (perp=10.171, rec=0.416, cos=0.237), tot_loss_proj:2.818 [t=0.18s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation directed characters [SEP]']
Attempt swap
[1850/2000] tot_loss=2.716 (perp=10.171, rec=0.420, cos=0.261), tot_loss_proj:2.824 [t=0.20s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation directed characters [SEP]']
Attempt swap
[1900/2000] tot_loss=2.664 (perp=10.171, rec=0.419, cos=0.211), tot_loss_proj:2.825 [t=0.33s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation directed characters [SEP]']
[1950/2000] tot_loss=2.723 (perp=10.171, rec=0.420, cos=0.269), tot_loss_proj:2.821 [t=0.28s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation directed characters [SEP]']
Attempt swap
[2000/2000] tot_loss=2.672 (perp=10.171, rec=0.420, cos=0.218), tot_loss_proj:2.830 [t=0.27s]
prediction: ['[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation directed characters [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a enjoyable enjoyable enjoyable existence oriented fully successful adaptation directed characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 46.154 | p: 46.154 | r: 46.154
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 38.462 | p: 38.462 | r: 38.462
rougeLsum  | fm: 38.462 | p: 38.462 | r: 38.462
r1fm+r2fm = 62.821

[Aggregate metrics]:
rouge1     | fm: 85.747 | p: 84.408 | r: 87.210
rouge2     | fm: 55.929 | p: 55.613 | r: 56.250
rougeL     | fm: 77.708 | p: 76.527 | r: 79.175
rougeLsum  | fm: 78.091 | p: 76.936 | r: 79.339
r1fm+r2fm = 141.676

input #22 time: 0:08:23 | total time: 3:11:47


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.8448046274418279
highest_index [0]
highest [0.8448046274418279]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.7157790064811707 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.714684784412384 for ['[CLS]cky second y bad safely foundry viation quality turner direct raleigh hyper specification ware what mccall engineer shockthing joining derivative reflecting kind trojan holland rule year graduallybid amount cat fishing deserves gravity weapon viola family cross swim accessed 0 easton politics lady partition fewer [SEP] [SEP]']
[Init] best rec loss: 0.7053667902946472 for ['[CLS]cation oystermel though painfies aftermath faction micro ec decommissioned hole federation educated wi looking ban office mean creation positional vi morning envy fair ken goodwill sons no give aren para shops calendar concert beingsian you pl denmark love platform battle flags astronomy rome asking [SEP]']
[Init] best rec loss: 0.7028838992118835 for ['[CLS] colony. ana substitute bar advisory a yellow service copiesroud demonarianlawuc networks key months to nextations polly past fitness was congress has forest dr providingee marsh rick georgia { pacific coloured aisles sim wilde over baggagecr tune kirby project punk launch [SEP]']
[Init] best rec loss: 0.7022585868835449 for ['[CLS] drugfl vienna chop ; wound shop wonder main added founded lennox bridge gel residential rich kilometers facing countries seal adults captain wet interstate tea saved mr hawk withdrawal indeed temperaly sent daily life ₱ rail era seasons bottom champion herselfsta? context teen ready airfield [SEP]']
[Init] best rec loss: 0.7018899321556091 for ['[CLS] reg globallyscript fly winston free cora physical hope burst her after body canoe prime polyhurst heaven dane scored reinsatin security tau photos nonsden how reminds either suicidea whouation contamination assistant hook block murray artist critical orientation achievement smallisto tudor cats bank [SEP]']
[Init] best perm rec loss: 0.7003259658813477 for ['[CLS] assistant physicalhurst either dane non how tudor orientation canoe prime small reins security achievementisto hookuation after murray burst photos poly who suicideatin fly critical winston remindsscript globally reg cora free cats bank body hersden tau hope contamination heaven block artista scored [SEP]']
[Init] best perm rec loss: 0.7000793218612671 for ['[CLS] murray reminds artist photos poly globallysden small cats who suicide contaminationscript winstonuation tudor body non bank hope canoe after burstaistoatin either physical orientation fly her reinshurst critical cora how hook heaven prime free assistant achievement block reg scored dane tau security [SEP]']
[Init] best perm rec loss: 0.6996970176696777 for ['[CLS] after assistant non prime how physical reg fly either reins hope contaminationhurst photos reminds scored block hook free body artist cats cora canoe small orientation dane tau her murray burst winston tudor security polya suicideuation globallyscriptistoatin bank achievement who critical heavensden [SEP]']
[Init] best perm rec loss: 0.6996185779571533 for ['[CLS] her who blockisto tau poly murray howuation photosatin scored canoe reins globally non reminds free heaven cora prime burst hook body small critical artist achievement reg after contamination orientation suicide eithera bank tudorscript flysdenhurst physical security cats hope dane assistant winston [SEP]']
[Init] best perm rec loss: 0.6985719203948975 for ['[CLS] prime cats eitherhurst reins winstonscript reminds free hope poly murraysden physicala scored critical howisto assistant after body who reg achievementuationatin burst hook her orientation block photos non contamination globally artist small cora canoe tau suicide heaven dane tudor fly bank security [SEP]']
[Init] best perm rec loss: 0.6977619528770447 for ['[CLS] tau murray assistant critical cats block poly globally reminds contaminationatin orientation free hope either winston canoe artististo prime hook physical security body achievement small dane tudor suicide photos her coraa how heaven non who reins scoreduationhurstsdenscript burst reg after bank fly [SEP]']
[Init] best perm rec loss: 0.6977044343948364 for ['[CLS] dane non winston small bank reminds physical cats hook tau who suicide critical artist canoe freescript reg either achievement tudoratin photossdena globally her contamination body fly burst orientation assistant prime security poly after heaven cora blockhurst hope scoreduation murrayisto how reins [SEP]']
[Init] best perm rec loss: 0.6969978213310242 for ['[CLS] block globallysdenatin tudor scored burst fly canoe photos reins critical cora reminds eitherscript murray physical tauhursta hookistouation body poly small reg how winston heaven cats her achievement artist after assistant bank orientation dane security hope who contamination non prime suicide free [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.996 (perp=11.757, rec=0.403, cos=0.242), tot_loss_proj:3.644 [t=0.19s]
prediction: ['[CLS] magazine marketing : clarity attention annual laser three airfield aerated base theory educational investigative kansas republic examination mission clearingzi his maybe taskcating broken guardian vision objective strategiclesska and sciences her after how quantum st question. solve combat humanity understood [SEP] rationalling [SEP]']
[ 100/2000] tot_loss=2.814 (perp=11.542, rec=0.263, cos=0.242), tot_loss_proj:3.548 [t=0.18s]
prediction: ['[CLS] issue satirical : without point " rah soldiers a ultimately vietnam technique studies legal chat republic evaluation weapons projectsva his maybe madeline ’ ann strategic objective ultimately. achieve to. her of : hyundaina rock. explore combat humanity replied [SEP] rational actions [SEP]']
[ 150/2000] tot_loss=2.763 (perp=11.350, rec=0.265, cos=0.229), tot_loss_proj:3.420 [t=0.20s]
prediction: ['[CLS] image propaganda, initially point, rah soldiers a ab vietnam technique drama legal - are corporate but conflictva his generationois commanders un i strategic objective ultimately its achieve of : the of. [SEP] au hat.mate patriotic intersection sounded drama spiritual events [SEP]']
[ 200/2000] tot_loss=2.624 (perp=10.717, rec=0.202, cos=0.279), tot_loss_proj:3.257 [t=0.24s]
prediction: ['[CLS] image featuring, initial point a rah soldiers the k vietnam technique drama legal - ra corporateh conflict the difficult generationois commanders un national main objective ultimately its achieve of : the of, main ) hat.mate dangerous defeating prompted drama generation events [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.331 (perp=9.644, rec=0.187, cos=0.216), tot_loss_proj:2.897 [t=0.22s]
prediction: ['[CLS] image featuring - main strategic - rah soldiers while k vietnam technique drama idea - rah adults conflict the difficult generation situation commanders un ) main objective ultimately its achieve of : the of, main ) hat.izing strategic sacrifice tone drama generation events [SEP]']
[ 300/2000] tot_loss=2.388 (perp=9.827, rec=0.161, cos=0.261), tot_loss_proj:3.344 [t=0.19s]
prediction: ['[CLS] object featuring - its strategic a rah soldiers while tone vietnam picture drama idea - rah adults conflict the difficult generation situation headquartered no ) main objective ultimately its achieve of : the the. main )ha.ing strategic sacrifice tone drama generation events [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.361 (perp=9.660, rec=0.147, cos=0.282), tot_loss_proj:3.266 [t=0.20s]
prediction: ['[CLS] object featuring, its strategic a rah soldiers while tone vietnam picture drama idea generation - rah adults conflict the difficult situation headquartered no ) main objective ultimately, achieve of : the the. main ) commodities.zing strategic cost define drama generation cost [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.388 (perp=9.843, rec=0.135, cos=0.284), tot_loss_proj:3.199 [t=0.27s]
prediction: ['[CLS] object patriotic, its strategic a rah soldiers, tone vietnam picture drama idea generation - ra while evaluation conflict the. ultimately commandersh soldiers main objective ultimately, achieve, : the the. main )ha.zing strategic cost define drama generation cost [SEP]']
[ 450/2000] tot_loss=2.354 (perp=9.985, rec=0.128, cos=0.229), tot_loss_proj:3.300 [t=0.27s]
prediction: ['[CLS] object patriotic with its strategic a rah soldiers, tone vietnam picture drama idea generation - ra while investigative conflictti. ultimately commanders nots main objective ultimately, achieve, : the the. main )ha.zing strategic cost define into generation cost [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.312 (perp=9.638, rec=0.122, cos=0.263), tot_loss_proj:3.151 [t=0.23s]
prediction: ['[CLS] object patriotic with its strategic a rah soldiers, tone vietnam picture drama idea generation - ra while fashioned conflictti cost ultimately commanders nots main objective ultimately, achieve, : the the cost main )ha.zing strategic cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.292 (perp=9.490, rec=0.118, cos=0.277), tot_loss_proj:2.964 [t=0.20s]
prediction: ['[CLS] object patriotic with its strategic a rah soldiers, such vietnamti drama idea generation - ra while fashioned conflict picture cost ultimately commanders tones main objective ultimately tone achieve, : the the of main the task.zing strategic cost define that generation. [SEP]']
[ 600/2000] tot_loss=2.299 (perp=9.568, rec=0.108, cos=0.278), tot_loss_proj:2.979 [t=0.19s]
prediction: ['[CLS] object patriotic with its strategic a rah soldiers, such vietnamti drama idea generation - ra while fashioned conflict picture cost ultimately commanders tones main objective ultimately tone achieve, : a the of came the task.zing strategic cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.243 (perp=9.263, rec=0.115, cos=0.276), tot_loss_proj:2.975 [t=0.18s]
prediction: ['[CLS] object patriotic with its strategic, rah soldiers, such vietnamti drama idea generation - the while fashioned conflict picture cost ultimately commanders tones main objective ultimately tone achieve, : a ra the came the task.zing strategic cost define that generation. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.280 (perp=9.469, rec=0.110, cos=0.276), tot_loss_proj:3.018 [t=0.23s]
prediction: ['[CLS] object patriotic such its strategic, rah soldiers, such vietnamti drama idea generation - the while criticized conflict picture. ultimately commanders tones main objective ultimately tone achieve, : a ra came the task. thezing patriotic cost define that generation. [SEP]']
[ 750/2000] tot_loss=2.268 (perp=9.402, rec=0.107, cos=0.280), tot_loss_proj:2.996 [t=0.19s]
prediction: ['[CLS] object patriotic such its strategic, rah soldiers, such vietnamti drama idea generation - the while criticized conflict picture. ultimately commanders tones main objective ultimately tone achieve, : a ra came the task. thezing human cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.223 (perp=9.205, rec=0.102, cos=0.280), tot_loss_proj:2.972 [t=0.27s]
prediction: ['[CLS] object ra such its strategic, patriotich soldiers, such vietnamti drama idea generation - the while criticized conflict picture. ultimately commanders tones main objective ultimately tone achieve, : a ra came the human. thezing human cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.127 (perp=8.960, rec=0.108, cos=0.227), tot_loss_proj:2.895 [t=0.18s]
prediction: ['[CLS] object ra such its strategic, patriotich soldiers, such vietnamti drama idea generation - the while criticized conflict picture. ultimately commanders ultimatelys main objective tone tone achieve, : a ra came the human. thezing human cost define that generation. [SEP]']
[ 900/2000] tot_loss=2.161 (perp=8.960, rec=0.105, cos=0.264), tot_loss_proj:2.898 [t=0.19s]
prediction: ['[CLS] object ra such its strategic, patriotich soldiers, such vietnamti drama idea generation - the while criticized conflict picture. ultimately commanders ultimatelys main objective tone tone achieve, : a ra came the human. thezing human cost define that generation. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.147 (perp=8.882, rec=0.098, cos=0.273), tot_loss_proj:2.823 [t=0.19s]
prediction: ['[CLS] object ra such its strategic, patriotich soldiers, such vietnamti drama idea generation - the while criticized conflict picture. ultimately thereby ultimatelys main objective tone tone achieve : a, ra came the human. thezing human cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.127 (perp=8.735, rec=0.104, cos=0.277), tot_loss_proj:2.858 [t=0.19s]
prediction: ['[CLS] object ra such its strategic, patriotich soldiers, such vietnamti drama idea generation - the while criticized conflict picture. ultimately commanders ultimatelys main objective tone tone : achieve a, ra came the human. thezing human cost define that generation. [SEP]']
[1050/2000] tot_loss=2.125 (perp=8.735, rec=0.100, cos=0.278), tot_loss_proj:2.778 [t=0.18s]
prediction: ['[CLS] object ra such its strategic, patriotich soldiers, such vietnamti drama idea generation - the while criticized conflict picture. ultimately thereby ultimatelys main objective tone tone : achieve a, ra came the human. thezing human cost define that generation. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.085 (perp=8.547, rec=0.099, cos=0.276), tot_loss_proj:2.700 [t=0.18s]
prediction: ['[CLS] object ra such its strategic, patriotich soldiers, such vietnamti drama idea generation - while the criticized conflict picture. ultimately thereby ultimatelys main objective tone tone : achieve a, ra came the human. thezing human cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.098 (perp=8.623, rec=0.098, cos=0.275), tot_loss_proj:2.813 [t=0.19s]
prediction: ['[CLS] object ra such its strategic, patriotich soldiers, such vietnamti drama idea generation - while the criticized conflict picture. ultimately tone ultimatelys main objective commanders tone : achieve a, ra came the of. thezing human cost define that generation. [SEP]']
[1200/2000] tot_loss=2.105 (perp=8.623, rec=0.098, cos=0.282), tot_loss_proj:2.813 [t=0.19s]
prediction: ['[CLS] object ra such its strategic, patriotich soldiers, such vietnamti drama idea generation - while the criticized conflict picture. ultimately tone ultimatelys main objective commanders tone : achieve a, ra came the of. thezing human cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.084 (perp=8.499, rec=0.102, cos=0.282), tot_loss_proj:2.789 [t=0.26s]
prediction: ['[CLS] human ra such its strategic, patriotich soldiers, such vietnamti drama idea generation - while the criticized conflict picture. ultimately tone ultimatelys main objective commanders tone : achieve a, ra came the object. thezing human cost define that generation. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.039 (perp=8.435, rec=0.100, cos=0.251), tot_loss_proj:2.775 [t=0.19s]
prediction: ['[CLS] human ra such its soldiers strategic, patriotich, such vietnamti drama idea generation - while the criticized conflict picture. ultimately tone ultimatelys main objective commanders tone : achieve a, ra came the object. thezing human cost define that generation. [SEP]']
[1350/2000] tot_loss=2.051 (perp=8.435, rec=0.097, cos=0.268), tot_loss_proj:2.776 [t=0.25s]
prediction: ['[CLS] human ra such its soldiers strategic, patriotich, such vietnamti drama idea generation - while the criticized conflict picture. ultimately tone ultimatelys main objective commanders tone : achieve a, ra came the object. thezing human cost define that generation. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.079 (perp=8.541, rec=0.100, cos=0.271), tot_loss_proj:2.767 [t=0.18s]
prediction: ['[CLS] human ra such its soldiers strategic, patriotich, such vietnamti drama idea generation - while the criticized conflict picture. ultimately ultimatelys main objective tone commanders tone : achieve a to ra came the object. thezing human cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.066 (perp=8.462, rec=0.098, cos=0.276), tot_loss_proj:2.775 [t=0.24s]
prediction: ['[CLS] human ra such its soldiers strategic, patriotich, such vietnamti drama idea generation - while the criticized conflict picture. ultimately ultimatelys main objective tone commanders tone, achieve a : ra came the object. thezing human cost define that generation. [SEP]']
[1500/2000] tot_loss=2.066 (perp=8.462, rec=0.099, cos=0.275), tot_loss_proj:2.772 [t=0.23s]
prediction: ['[CLS] human ra such its soldiers strategic, patriotich, such vietnamti drama idea generation - while the criticized conflict picture. ultimately ultimatelys main objective tone commanders tone, achieve a : ra came the object. thezing human cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.065 (perp=8.464, rec=0.096, cos=0.276), tot_loss_proj:2.770 [t=0.18s]
prediction: ['[CLS] human ra such its soldiers strategic, patriotich, such vietnamti drama idea generation - while the ultimately conflict picture. ultimately ultimatelys main objective tone commanders tone : achieve a, ra came the object. thezing human cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.054 (perp=8.400, rec=0.097, cos=0.277), tot_loss_proj:2.755 [t=0.26s]
prediction: ['[CLS] human ra such its soldiers strategic, patriotich, such vietnamti. idea generation - while the ultimately conflict picture drama ultimately ultimatelys main objective tone commanders tone : achieve a, ra came the object. thezing human cost define that generation. [SEP]']
[1650/2000] tot_loss=2.082 (perp=8.573, rec=0.091, cos=0.276), tot_loss_proj:2.797 [t=0.19s]
prediction: ['[CLS] human ra such its soldiers strategic, patriotich, such vietnamti. idea generation - while the ultimately conflict picture drama ultimately ultimatelys main objective tone commanders tone : achieve a to ra came the object. thezing human cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.041 (perp=8.340, rec=0.095, cos=0.279), tot_loss_proj:2.742 [t=0.18s]
prediction: ['[CLS] of ra such its soldiers strategic, patriotich, such vietnamti. idea generation - while the ultimately conflict picture drama ultimately ultimatelys main objective tone commanders tone to achieve a : ra came the object. thezing human cost define that generation. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.017 (perp=8.200, rec=0.097, cos=0.279), tot_loss_proj:2.712 [t=0.19s]
prediction: ['[CLS] of ra such its soldiers strategic, patriotich, such vietnamti. idea generation - while ultimately the conflict picture drama ultimately ultimatelys main objective tone commanders tone to achieve a : ra came the object. thezing human cost define that generation. [SEP]']
[1800/2000] tot_loss=2.012 (perp=8.200, rec=0.091, cos=0.281), tot_loss_proj:2.714 [t=0.18s]
prediction: ['[CLS] of ra such its soldiers strategic, patriotich, such vietnamti. idea generation - while ultimately the conflict picture drama ultimately ultimatelys main objective tone commanders tone to achieve a : ra came the object. thezing human cost define that generation. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.999 (perp=8.103, rec=0.099, cos=0.279), tot_loss_proj:2.713 [t=0.25s]
prediction: ['[CLS] of ra such its soldiers strategic, patriotich, such vietnamti. idea generation conflict - while ultimately the picture drama ultimately ultimatelys main objective tone commanders tone to achieve a : ra came the object. thezing human cost define that generation. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.979 (perp=7.987, rec=0.101, cos=0.281), tot_loss_proj:2.700 [t=0.26s]
prediction: ['[CLS] such ra such its soldiers strategic, patriotich, of vietnamti. idea generation conflict - while ultimately the picture drama ultimately ultimatelys main objective tone commanders tone to achieve a : ra came the object. thezing human cost define that generation. [SEP]']
[1950/2000] tot_loss=1.991 (perp=8.078, rec=0.095, cos=0.280), tot_loss_proj:2.732 [t=0.18s]
prediction: ['[CLS] such ra such its soldiers strategic, patriotich, of vietnamti. idea generation conflict - while ultimately a picture drama ultimately ultimatelys main objective tone commanders tone to achieve a : ra came the object. thezing human cost define that generation. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.991 (perp=8.078, rec=0.094, cos=0.281), tot_loss_proj:2.727 [t=0.26s]
prediction: ['[CLS] such ra such its soldiers strategic, patriotich, of vietnamti. idea generation conflict - while ultimately a picture drama ultimately ultimatelys main objective tone commanders tone to achieve a : ra came the object. thezing human cost define that generation. [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] of ra such its soldiers strategic, patriotich, such vietnamti. idea generation - while the ultimately conflict picture drama ultimately ultimatelys main objective tone commanders tone to achieve a : ra came the object. thezing human cost define that generation. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 65.823 | p: 66.667 | r: 65.000
rouge2     | fm: 5.195 | p: 5.263 | r: 5.128
rougeL     | fm: 32.911 | p: 33.333 | r: 32.500
rougeLsum  | fm: 32.911 | p: 33.333 | r: 32.500
r1fm+r2fm = 71.018

[Aggregate metrics]:
rouge1     | fm: 84.931 | p: 83.800 | r: 86.329
rouge2     | fm: 54.299 | p: 54.103 | r: 54.555
rougeL     | fm: 75.944 | p: 74.881 | r: 77.204
rougeLsum  | fm: 75.808 | p: 74.852 | r: 77.032
r1fm+r2fm = 139.230

input #23 time: 0:08:26 | total time: 3:20:14


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.8693978129093012
highest_index [0]
highest [0.8693978129093012]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8378562927246094 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8060336112976074 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.7995064854621887 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 0.7650275826454163 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.7544155120849609 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.7458306550979614 for ['[CLS] numb clear post mirror leg closet died fond sometimes distributor bonus « piecegence nerve rush authority direction turnsxie [SEP]']
[Init] best rec loss: 0.712881863117218 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7115784287452698 for ['[CLS] port happy nowyl arms em ryu damnedaneous mid village bush bond suffer younger attack unless snow play county [SEP]']
[Init] best perm rec loss: 0.709457516670227 for ['[CLS] arms mid damned sufferaneous happy ryu village attack port unless no em play snow younger bond countywyl bush [SEP]']
[Init] best perm rec loss: 0.709283709526062 for ['[CLS] bond bushaneous damned snow happy no attack unless county arms younger mid emwyl port village play suffer ryu [SEP]']
[Init] best perm rec loss: 0.7088996767997742 for ['[CLS] damned snow bondwyl suffer arms port ryu bush village county happy mid em unless youngeraneous play no attack [SEP]']
[Init] best perm rec loss: 0.7077596783638 for ['[CLS] port ryuwyl bond younger county arms suffer mid damned village play attack bush happyaneous em no snow unless [SEP]']
[Init] best perm rec loss: 0.7070968747138977 for ['[CLS] bush bond play attack arms snowwylaneous mid damned port happy unless suffer ryu younger em county no village [SEP]']
[Init] best perm rec loss: 0.7054508328437805 for ['[CLS] bush unless county mid attack younger happy em damned play ryu bondaneous snow suffer arms port nowyl village [SEP]']
[Init] best perm rec loss: 0.7045309543609619 for ['[CLS] attack bush suffer snow bond ryu no em county unless arms younger village happywyl damned midaneous play port [SEP]']
[Init] best perm rec loss: 0.7032681107521057 for ['[CLS] em villagewyl ryu mid damned port suffer snow arms younger attack play happy bush bondaneous county no unless [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.948 (perp=11.529, rec=0.408, cos=0.234), tot_loss_proj:3.410 [t=0.18s]
prediction: ['[CLS] ban article - lords using damage police criminal drug that evil allegedly a station blind bombedvu were wrong [SEP]']
[ 100/2000] tot_loss=2.871 (perp=11.106, rec=0.425, cos=0.224), tot_loss_proj:3.360 [t=0.19s]
prediction: ['[CLS] outside article ( conscience targeted why terrorists criminal any that evil terrorists a fuck blind bombed head were evil [SEP]']
[ 150/2000] tot_loss=2.695 (perp=10.973, rec=0.277, cos=0.223), tot_loss_proj:3.241 [t=0.19s]
prediction: ['[CLS] outside article ( context targeted how terrorists population any context evil terrorists five! climate terroristsed head are evil [SEP]']
[ 200/2000] tot_loss=2.588 (perp=10.720, rec=0.210, cos=0.234), tot_loss_proj:3.052 [t=0.21s]
prediction: ['[CLS] outside sub taken context outside why terrorists population any context evil terrorists more! climate terrorists increasing context are evil [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.298 (perp=9.602, rec=0.183, cos=0.195), tot_loss_proj:2.797 [t=0.19s]
prediction: ["[CLS] outside the taken context outside how terrorists the terroristspe current context evil! climate terrorists'context are evil [SEP]"]
[ 300/2000] tot_loss=2.250 (perp=9.311, rec=0.165, cos=0.223), tot_loss_proj:2.695 [t=0.27s]
prediction: ["[CLS] outside the taken context outside how terrorists the politicalist the see evil! climate terrorists'context are evil [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.402 (perp=9.939, rec=0.190, cos=0.225), tot_loss_proj:2.838 [t=0.19s]
prediction: ["[CLS] more the terrorists context outside how taken than political municipality current see evil! climate terrorists'ᵇ are evil [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.407 (perp=10.117, rec=0.153, cos=0.230), tot_loss_proj:2.920 [t=0.19s]
prediction: ["[CLS] more the terrorists context outside whatever taken than political politician'see evil! climate terrorists the ᵇ are evil [SEP]"]
[ 450/2000] tot_loss=2.251 (perp=9.333, rec=0.149, cos=0.235), tot_loss_proj:2.743 [t=0.19s]
prediction: ["[CLS] more the terrorists context outside since taken than political politician'see evil! climate terrorists the than are evil [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.166 (perp=8.939, rec=0.138, cos=0.240), tot_loss_proj:2.710 [t=0.20s]
prediction: ['[CLS] more the terrorists context outside since taken than political municipality ) see evil! climate than the terrorists are evil [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.021 (perp=8.361, rec=0.143, cos=0.205), tot_loss_proj:2.533 [t=0.22s]
prediction: ['[CLS] more the terrorists taken outside over context than political municipality ) see evil! climate than the terrorists are evil [SEP]']
[ 600/2000] tot_loss=2.049 (perp=8.447, rec=0.125, cos=0.235), tot_loss_proj:2.592 [t=0.25s]
prediction: ['[CLS] more the terrorists taken outside ever context than political municipality ) see evil! climate than the terrorists are evil [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.957 (perp=8.017, rec=0.127, cos=0.227), tot_loss_proj:2.475 [t=0.21s]
prediction: ['[CLS] more the terrorists taken outside ever context than municipality ) see evil! political climate than the terrorists are evil [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.931 (perp=7.849, rec=0.126, cos=0.235), tot_loss_proj:2.444 [t=0.22s]
prediction: ['[CLS] the more terrorists taken outside ever context than municipality ) see evil! political climate than the terrorists are evil [SEP]']
[ 750/2000] tot_loss=2.024 (perp=8.286, rec=0.127, cos=0.240), tot_loss_proj:2.521 [t=0.23s]
prediction: ['[CLS] the more terrorists taken outside ever context than municipality ) see evil! political climate than current terrorists are evil [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.930 (perp=7.899, rec=0.121, cos=0.229), tot_loss_proj:2.508 [t=0.23s]
prediction: ['[CLS] the more terrorists taken outside context than region ) ever see evil! political climate than current terrorists are evil [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.906 (perp=7.727, rec=0.121, cos=0.240), tot_loss_proj:2.432 [t=0.21s]
prediction: ['[CLS] the more terrorists taken outside context than region ) ever see evil! current political climate than terrorists are evil [SEP]']
[ 900/2000] tot_loss=2.056 (perp=8.093, rec=0.219, cos=0.218), tot_loss_proj:2.504 [t=0.19s]
prediction: ['[CLS] the more terrorists taken outside context than ( ; ever see evil! the political climate than terrorists are evil [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.903 (perp=7.566, rec=0.163, cos=0.227), tot_loss_proj:2.355 [t=0.19s]
prediction: ['[CLS] the more terrorists taken outside context than ever ; ( see evil! the political climate than terrorists are evil [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.827 (perp=7.284, rec=0.152, cos=0.219), tot_loss_proj:2.314 [t=0.19s]
prediction: ['[CLS] the more terrorists see outside context than ever ; ( taken evil! the political climate than terrorists are evil [SEP]']
[1050/2000] tot_loss=1.833 (perp=7.284, rec=0.143, cos=0.233), tot_loss_proj:2.316 [t=0.21s]
prediction: ['[CLS] the more terrorists see outside context than ever ; ( taken evil! the political climate than terrorists are evil [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.777 (perp=7.028, rec=0.135, cos=0.236), tot_loss_proj:2.339 [t=0.19s]
prediction: ['[CLS] the more terrorists see outside context than ever ; ( evil taken! the political climate than terrorists are evil [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.725 (perp=6.770, rec=0.139, cos=0.232), tot_loss_proj:2.281 [t=0.19s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
[1200/2000] tot_loss=1.734 (perp=6.770, rec=0.142, cos=0.237), tot_loss_proj:2.279 [t=0.18s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[1250/2000] tot_loss=1.715 (perp=6.770, rec=0.122, cos=0.239), tot_loss_proj:2.285 [t=0.19s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[1300/2000] tot_loss=1.721 (perp=6.770, rec=0.126, cos=0.241), tot_loss_proj:2.275 [t=0.19s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
[1350/2000] tot_loss=1.718 (perp=6.770, rec=0.123, cos=0.241), tot_loss_proj:2.280 [t=0.19s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[1400/2000] tot_loss=1.714 (perp=6.770, rec=0.118, cos=0.241), tot_loss_proj:2.286 [t=0.21s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[1450/2000] tot_loss=1.715 (perp=6.770, rec=0.120, cos=0.242), tot_loss_proj:2.280 [t=0.23s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
[1500/2000] tot_loss=1.722 (perp=6.770, rec=0.126, cos=0.242), tot_loss_proj:2.283 [t=0.19s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[1550/2000] tot_loss=1.720 (perp=6.770, rec=0.124, cos=0.242), tot_loss_proj:2.279 [t=0.24s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[1600/2000] tot_loss=1.712 (perp=6.770, rec=0.116, cos=0.242), tot_loss_proj:2.283 [t=0.18s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
[1650/2000] tot_loss=1.721 (perp=6.770, rec=0.125, cos=0.242), tot_loss_proj:2.282 [t=0.20s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[1700/2000] tot_loss=1.720 (perp=6.770, rec=0.123, cos=0.243), tot_loss_proj:2.281 [t=0.26s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[1750/2000] tot_loss=1.713 (perp=6.770, rec=0.117, cos=0.243), tot_loss_proj:2.284 [t=0.19s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
[1800/2000] tot_loss=1.708 (perp=6.770, rec=0.112, cos=0.242), tot_loss_proj:2.278 [t=0.24s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[1850/2000] tot_loss=1.724 (perp=6.770, rec=0.127, cos=0.242), tot_loss_proj:2.279 [t=0.19s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[1900/2000] tot_loss=1.718 (perp=6.770, rec=0.121, cos=0.243), tot_loss_proj:2.280 [t=0.20s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
[1950/2000] tot_loss=1.723 (perp=6.770, rec=0.126, cos=0.243), tot_loss_proj:2.279 [t=0.26s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Attempt swap
[2000/2000] tot_loss=1.710 (perp=6.770, rec=0.113, cos=0.243), tot_loss_proj:2.282 [t=0.19s]
prediction: ['[CLS] the more terrorists see outside context than ever ; evil taken! the political climate than terrorists are evil ( [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] the more terrorists taken outside context than region ) ever see evil! current political climate than terrorists are evil [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 22.222 | p: 21.053 | r: 23.529
rougeL     | fm: 57.895 | p: 55.000 | r: 61.111
rougeLsum  | fm: 57.895 | p: 55.000 | r: 61.111
r1fm+r2fm = 106.433

[Aggregate metrics]:
rouge1     | fm: 84.876 | p: 83.633 | r: 86.430
rouge2     | fm: 52.762 | p: 52.523 | r: 53.049
rougeL     | fm: 75.325 | p: 74.151 | r: 76.782
rougeLsum  | fm: 75.254 | p: 74.194 | r: 76.543
r1fm+r2fm = 137.638

input #24 time: 0:08:24 | total time: 3:28:38


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.8087018491574964
highest_index [0]
highest [0.8087018491574964]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9512469172477722 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.903340220451355 for ['[CLS] weakness blue fast @ [SEP]']
[Init] best rec loss: 0.8772891163825989 for ['[CLS] schoolre kim also [SEP]']
[Init] best rec loss: 0.8717387914657593 for ['[CLS]iary rooms concerned who [SEP]']
[Init] best rec loss: 0.8676701188087463 for ['[CLS] passagelvis hill 7 [SEP]']
[Init] best rec loss: 0.8574626445770264 for ['[CLS] tolerance ba clearffs [SEP]']
[Init] best perm rec loss: 0.8544901609420776 for ['[CLS] ba toleranceffs clear [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.233 (perp=8.424, rec=0.212, cos=0.337), tot_loss_proj:2.440 [t=0.18s]
prediction: ['[CLS] beautiful beautiful film beautiful [SEP]']
[ 100/2000] tot_loss=2.260 (perp=8.915, rec=0.137, cos=0.340), tot_loss_proj:2.445 [t=0.18s]
prediction: ['[CLS] strange beautiful film film [SEP]']
[ 150/2000] tot_loss=2.621 (perp=10.863, rec=0.106, cos=0.343), tot_loss_proj:3.286 [t=0.22s]
prediction: ['[CLS] strange beautiful film strange [SEP]']
[ 200/2000] tot_loss=2.274 (perp=9.081, rec=0.123, cos=0.335), tot_loss_proj:2.492 [t=0.18s]
prediction: ['[CLS] strange beautiful film and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.766 (perp=6.646, rec=0.097, cos=0.339), tot_loss_proj:1.800 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 300/2000] tot_loss=1.747 (perp=6.646, rec=0.075, cos=0.342), tot_loss_proj:1.802 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.755 (perp=6.646, rec=0.083, cos=0.342), tot_loss_proj:1.803 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.756 (perp=6.646, rec=0.084, cos=0.343), tot_loss_proj:1.797 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.746 (perp=6.646, rec=0.073, cos=0.343), tot_loss_proj:1.805 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.746 (perp=6.646, rec=0.074, cos=0.343), tot_loss_proj:1.798 [t=0.28s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.750 (perp=6.646, rec=0.077, cos=0.343), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.749 (perp=6.646, rec=0.075, cos=0.345), tot_loss_proj:1.794 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.751 (perp=6.646, rec=0.077, cos=0.345), tot_loss_proj:1.792 [t=0.32s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.741 (perp=6.646, rec=0.067, cos=0.345), tot_loss_proj:1.800 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.728 (perp=6.646, rec=0.054, cos=0.346), tot_loss_proj:1.798 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.735 (perp=6.646, rec=0.060, cos=0.346), tot_loss_proj:1.795 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.736 (perp=6.646, rec=0.061, cos=0.346), tot_loss_proj:1.793 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.743 (perp=6.646, rec=0.068, cos=0.346), tot_loss_proj:1.808 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.741 (perp=6.646, rec=0.066, cos=0.346), tot_loss_proj:1.796 [t=0.20s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.737 (perp=6.646, rec=0.062, cos=0.346), tot_loss_proj:1.803 [t=0.21s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.742 (perp=6.646, rec=0.067, cos=0.346), tot_loss_proj:1.803 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.732 (perp=6.646, rec=0.056, cos=0.346), tot_loss_proj:1.807 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.733 (perp=6.646, rec=0.058, cos=0.346), tot_loss_proj:1.802 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.740 (perp=6.646, rec=0.065, cos=0.346), tot_loss_proj:1.795 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.743 (perp=6.646, rec=0.068, cos=0.346), tot_loss_proj:1.797 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.735 (perp=6.646, rec=0.060, cos=0.346), tot_loss_proj:1.798 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.741 (perp=6.646, rec=0.066, cos=0.346), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.734 (perp=6.646, rec=0.059, cos=0.346), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.735 (perp=6.646, rec=0.060, cos=0.346), tot_loss_proj:1.795 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.741 (perp=6.646, rec=0.066, cos=0.346), tot_loss_proj:1.806 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.746 (perp=6.646, rec=0.071, cos=0.346), tot_loss_proj:1.808 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.743 (perp=6.646, rec=0.068, cos=0.346), tot_loss_proj:1.798 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.742 (perp=6.646, rec=0.067, cos=0.346), tot_loss_proj:1.796 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.728 (perp=6.646, rec=0.053, cos=0.346), tot_loss_proj:1.800 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.734 (perp=6.646, rec=0.059, cos=0.346), tot_loss_proj:1.810 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.738 (perp=6.646, rec=0.063, cos=0.346), tot_loss_proj:1.807 [t=0.24s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.738 (perp=6.646, rec=0.063, cos=0.346), tot_loss_proj:1.794 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.742 (perp=6.646, rec=0.067, cos=0.346), tot_loss_proj:1.797 [t=0.21s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.742 (perp=6.646, rec=0.067, cos=0.346), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.735 (perp=6.646, rec=0.060, cos=0.346), tot_loss_proj:1.805 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 85.486 | p: 84.287 | r: 86.941
rouge2     | fm: 54.493 | p: 54.120 | r: 54.805
rougeL     | fm: 76.163 | p: 75.064 | r: 77.485
rougeLsum  | fm: 76.074 | p: 75.104 | r: 77.375
r1fm+r2fm = 139.979

input #25 time: 0:08:25 | total time: 3:37:03


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.8550018125389023
highest_index [0]
highest [0.8550018125389023]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.8839772343635559 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.8807629942893982 for ['[CLS] occur oxygen wallaceuit inherent drug latvian hers deancrathenko counteranto q for at link renee army born hartabas effect [SEP]']
[Init] best rec loss: 0.8486773371696472 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 0.8417083024978638 for ['[CLS] este letter freedom ‚ whose raid beautyenes [SEP] numbers allsel especially best thought kid internationally picture tu plum cue dutyriam [SEP]']
[Init] best rec loss: 0.8310958743095398 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 0.8291652202606201 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 0.8247737884521484 for ['[CLS] door colonial shot isotead discipline merelyᆼkan list more arrow four souls polish death fourth theoretical usually constituencies octave s officers [SEP]']
[Init] best perm rec loss: 0.8224278688430786 for ['[CLS]kan octave death four usually more officers shotᆼ colonial souls theoreticaltead constituencies s door discipline list polish iso fourth merely arrow [SEP]']
[Init] best perm rec loss: 0.8222531080245972 for ['[CLS]tead theoretical fourth list s arrow colonial discipline four door usually more souls constituencieskan polish merely octave shot iso deathᆼ officers [SEP]']
[Init] best perm rec loss: 0.8213735818862915 for ['[CLS] theoretical iso constituencies four merely soulsᆼ more arrow fourth officers polish listtead door shot death colonialkan s discipline usually octave [SEP]']
[Init] best perm rec loss: 0.8213251829147339 for ['[CLS] door merely souls constituencieskan shot theoretical colonial officersᆼ four iso fourth arrow more usually polish list octave s death disciplinetead [SEP]']
[Init] best perm rec loss: 0.8211033940315247 for ['[CLS]kan list officers iso theoretical merelytead colonial door polish death arrow usually octave discipline sᆼ four constituencies fourth souls more shot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.299 (perp=13.427, rec=0.380, cos=0.234), tot_loss_proj:3.685 [t=0.19s]
prediction: ['[CLS] thin assistant loser laboratory useless im offices taiwan newly drivers leave paid gaulle / estonian au little propaganda rot ticket playsurity sick [SEP]']
[ 100/2000] tot_loss=2.791 (perp=11.169, rec=0.295, cos=0.263), tot_loss_proj:3.082 [t=0.19s]
prediction: ['[CLS] little loan cheese - pointless im stationsni french import import ( estate / estonian category t - rotbe pic pointless irish [SEP]']
[ 150/2000] tot_loss=2.700 (perp=10.967, rec=0.262, cos=0.245), tot_loss_proj:3.019 [t=0.19s]
prediction: ['[CLS] little writer mean - pointless im phosphate coming french import import from french from estonian category t - -acy pic pointless import [SEP]']
[ 200/2000] tot_loss=2.677 (perp=10.969, rec=0.229, cos=0.255), tot_loss_proj:3.029 [t=0.19s]
prediction: ['[CLS] ) writer mean - pointless french mines coming french import from from french from import editor ) - -acy pic pointless import [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.451 (perp=10.025, rec=0.193, cos=0.253), tot_loss_proj:2.844 [t=0.22s]
prediction: ['[CLS] ) mean writer - pointless and rural coming french import from - french age vault mean ) - - director plays pointless import [SEP]']
[ 300/2000] tot_loss=2.417 (perp=9.903, rec=0.177, cos=0.259), tot_loss_proj:2.821 [t=0.19s]
prediction: ['[CLS] ) mean writer - pointless anding coming french import from writer french age import mean ) - - director director pointless import [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.188 (perp=8.838, rec=0.160, cos=0.261), tot_loss_proj:2.642 [t=0.30s]
prediction: ['[CLS] this mean writer - pointless importing coming french and from writer french age import mean ) - - director anne pointless import [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.136 (perp=8.718, rec=0.149, cos=0.243), tot_loss_proj:2.566 [t=0.18s]
prediction: ['[CLS] this mean writer - pointless importing french coming and from writer french ageive mean ) - - director anne pointless import [SEP]']
[ 450/2000] tot_loss=2.130 (perp=8.746, rec=0.121, cos=0.260), tot_loss_proj:2.688 [t=0.19s]
prediction: ['[CLS] this mean writer - pointless import and french coming and from writer french ageive mean ) - - director anne pointless import [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.004 (perp=8.090, rec=0.121, cos=0.265), tot_loss_proj:2.605 [t=0.19s]
prediction: ['[CLS] this mean writer - pointless import and french coming and from french ageive mean writer ) - - director anne pointless import [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.948 (perp=7.825, rec=0.128, cos=0.254), tot_loss_proj:2.649 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and french coming - and from french ageive mean writer ) - - director anne pointless import [SEP]']
[ 600/2000] tot_loss=2.051 (perp=8.349, rec=0.119, cos=0.262), tot_loss_proj:2.674 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and french coming - and from french agerot mean writer ) - - director anne pointless import [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.994 (perp=8.127, rec=0.102, cos=0.266), tot_loss_proj:2.628 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and french coming - and from french age ) mean writerrot - - director anne pointless import [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.003 (perp=8.127, rec=0.116, cos=0.261), tot_loss_proj:2.632 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and french coming - and from french age ) mean writerrot - - director anne pointless import [SEP]']
[ 750/2000] tot_loss=1.997 (perp=8.127, rec=0.107, cos=0.265), tot_loss_proj:2.628 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and french coming - and from french age ) mean writerrot - - director anne pointless import [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.043 (perp=8.358, rec=0.106, cos=0.265), tot_loss_proj:2.667 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and french coming - of french from age ) mean writerrot - - director anne pointless import [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.957 (perp=7.956, rec=0.099, cos=0.267), tot_loss_proj:2.593 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and french coming - - from french age ) mean writerrot - - director anne pointless import [SEP]']
[ 900/2000] tot_loss=1.955 (perp=7.956, rec=0.096, cos=0.268), tot_loss_proj:2.594 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and french coming - - from french age ) mean writerrot - - director anne pointless import [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.953 (perp=7.956, rec=0.094, cos=0.268), tot_loss_proj:2.593 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and french coming - - from french age ) mean writerrot - - director anne pointless import [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.914 (perp=7.747, rec=0.101, cos=0.263), tot_loss_proj:2.510 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and french coming from french - - age ) mean writerrot - - director anne pointless import [SEP]']
[1050/2000] tot_loss=1.909 (perp=7.747, rec=0.094, cos=0.265), tot_loss_proj:2.505 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and french coming from french - - age ) mean writerrot - - director anne pointless import [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.909 (perp=7.747, rec=0.093, cos=0.266), tot_loss_proj:2.507 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and french coming from french - - age ) mean writerrot - - director anne pointless import [SEP]']
Attempt swap
[1150/2000] tot_loss=1.900 (perp=7.747, rec=0.084, cos=0.266), tot_loss_proj:2.512 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and french coming from french - - age ) mean writerrot - - director anne pointless import [SEP]']
[1200/2000] tot_loss=1.902 (perp=7.747, rec=0.086, cos=0.266), tot_loss_proj:2.513 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and french coming from french - - age ) mean writerrot - - director anne pointless import [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.871 (perp=7.600, rec=0.088, cos=0.263), tot_loss_proj:2.450 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age ) mean writerrot - - director anne pointless import [SEP]']
Attempt swap
[1300/2000] tot_loss=1.954 (perp=8.067, rec=0.076, cos=0.265), tot_loss_proj:2.486 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age ) mean writerrot - - director anne pointless of [SEP]']
[1350/2000] tot_loss=1.960 (perp=8.067, rec=0.081, cos=0.266), tot_loss_proj:2.481 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age ) mean writerrot - - director anne pointless of [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.935 (perp=7.886, rec=0.093, cos=0.265), tot_loss_proj:2.396 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age ) mean writerrot pointless - - director anne of [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.057 (perp=8.493, rec=0.093, cos=0.266), tot_loss_proj:2.524 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writerrot pointless - - anne director of [SEP]']
[1500/2000] tot_loss=2.048 (perp=8.493, rec=0.083, cos=0.266), tot_loss_proj:2.522 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writerrot pointless - - anne director of [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.014 (perp=8.288, rec=0.089, cos=0.267), tot_loss_proj:2.503 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - - anne director of [SEP]']
Attempt swap
[1600/2000] tot_loss=2.009 (perp=8.288, rec=0.085, cos=0.267), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - - anne director of [SEP]']
[1650/2000] tot_loss=1.997 (perp=8.288, rec=0.072, cos=0.267), tot_loss_proj:2.505 [t=0.25s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - - anne director of [SEP]']
Attempt swap
[1700/2000] tot_loss=2.001 (perp=8.288, rec=0.076, cos=0.267), tot_loss_proj:2.512 [t=0.18s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - - anne director of [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.995 (perp=8.219, rec=0.084, cos=0.267), tot_loss_proj:2.523 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - anne - director of [SEP]']
[1800/2000] tot_loss=1.995 (perp=8.219, rec=0.084, cos=0.267), tot_loss_proj:2.522 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - anne - director of [SEP]']
Attempt swap
[1850/2000] tot_loss=2.001 (perp=8.219, rec=0.090, cos=0.267), tot_loss_proj:2.527 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - anne - director of [SEP]']
Attempt swap
[1900/2000] tot_loss=1.997 (perp=8.219, rec=0.086, cos=0.267), tot_loss_proj:2.526 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - anne - director of [SEP]']
[1950/2000] tot_loss=1.995 (perp=8.219, rec=0.084, cos=0.267), tot_loss_proj:2.527 [t=0.19s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - anne - director of [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.993 (perp=8.219, rec=0.083, cos=0.266), tot_loss_proj:2.525 [t=0.22s]
prediction: ['[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - anne - director of [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] this mean writer pointless import and coming from french - french - age )der writer pointlessrot - anne - director of [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 73.684 | r: 82.353
rouge2     | fm: 5.882 | p: 5.556 | r: 6.250
rougeL     | fm: 44.444 | p: 42.105 | r: 47.059
rougeLsum  | fm: 44.444 | p: 42.105 | r: 47.059
r1fm+r2fm = 83.660

[Aggregate metrics]:
rouge1     | fm: 85.295 | p: 83.948 | r: 86.856
rouge2     | fm: 52.765 | p: 52.495 | r: 53.058
rougeL     | fm: 74.986 | p: 73.844 | r: 76.337
rougeLsum  | fm: 75.117 | p: 74.012 | r: 76.347
r1fm+r2fm = 138.061

input #26 time: 0:07:51 | total time: 3:44:55


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.8728680312726583
highest_index [0]
highest [0.8728680312726583]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9756596088409424 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9481436610221863 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 0.9432153701782227 for ['[CLS] volume nan on [SEP]']
[Init] best rec loss: 0.9416267275810242 for ['[CLS] backeddation chancel [SEP]']
[Init] best rec loss: 0.94156414270401 for ['[CLS] tribune ruler dropping [SEP]']
[Init] best rec loss: 0.9306786060333252 for ['[CLS] how turned basic [SEP]']
[Init] best rec loss: 0.9152736663818359 for ['[CLS] op framework ran [SEP]']
[Init] best rec loss: 0.8972797393798828 for ['[CLS] fat mattream [SEP]']
[Init] best perm rec loss: 0.8968551158905029 for ['[CLS] mat fattream [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.420 (perp=9.466, rec=0.292, cos=0.235), tot_loss_proj:2.626 [t=0.19s]
prediction: ['[CLS] like generic generic [SEP]']
[ 100/2000] tot_loss=2.036 (perp=8.320, rec=0.139, cos=0.233), tot_loss_proj:1.983 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[ 150/2000] tot_loss=1.989 (perp=8.320, rec=0.088, cos=0.238), tot_loss_proj:1.980 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[ 200/2000] tot_loss=1.981 (perp=8.320, rec=0.086, cos=0.231), tot_loss_proj:1.977 [t=0.20s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.971 (perp=8.320, rec=0.070, cos=0.237), tot_loss_proj:1.986 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.955 (perp=8.320, rec=0.054, cos=0.237), tot_loss_proj:1.978 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.962 (perp=8.320, rec=0.070, cos=0.228), tot_loss_proj:1.971 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.953 (perp=8.320, rec=0.053, cos=0.236), tot_loss_proj:1.973 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.971 (perp=8.320, rec=0.070, cos=0.237), tot_loss_proj:1.983 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.960 (perp=8.320, rec=0.059, cos=0.238), tot_loss_proj:1.987 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.964 (perp=8.320, rec=0.062, cos=0.238), tot_loss_proj:1.990 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.966 (perp=8.320, rec=0.064, cos=0.238), tot_loss_proj:1.983 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.967 (perp=8.320, rec=0.065, cos=0.238), tot_loss_proj:1.989 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.958 (perp=8.320, rec=0.056, cos=0.238), tot_loss_proj:1.992 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.973 (perp=8.320, rec=0.071, cos=0.238), tot_loss_proj:1.978 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.966 (perp=8.320, rec=0.064, cos=0.238), tot_loss_proj:1.976 [t=0.29s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.964 (perp=8.320, rec=0.063, cos=0.237), tot_loss_proj:1.987 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.960 (perp=8.320, rec=0.058, cos=0.238), tot_loss_proj:1.990 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.962 (perp=8.320, rec=0.060, cos=0.238), tot_loss_proj:1.992 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.967 (perp=8.320, rec=0.065, cos=0.238), tot_loss_proj:1.976 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.967 (perp=8.320, rec=0.065, cos=0.238), tot_loss_proj:1.985 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.965 (perp=8.320, rec=0.063, cos=0.238), tot_loss_proj:1.991 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.961 (perp=8.320, rec=0.060, cos=0.237), tot_loss_proj:1.980 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.967 (perp=8.320, rec=0.065, cos=0.238), tot_loss_proj:1.980 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.960 (perp=8.320, rec=0.058, cos=0.238), tot_loss_proj:1.983 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.964 (perp=8.320, rec=0.063, cos=0.238), tot_loss_proj:1.981 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.956 (perp=8.320, rec=0.054, cos=0.238), tot_loss_proj:1.981 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.978 (perp=8.320, rec=0.076, cos=0.238), tot_loss_proj:1.981 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.958 (perp=8.320, rec=0.058, cos=0.236), tot_loss_proj:1.987 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.963 (perp=8.320, rec=0.061, cos=0.237), tot_loss_proj:1.977 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.963 (perp=8.320, rec=0.061, cos=0.238), tot_loss_proj:1.957 [t=0.20s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.956 (perp=8.320, rec=0.054, cos=0.238), tot_loss_proj:1.965 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.962 (perp=8.320, rec=0.061, cos=0.238), tot_loss_proj:1.983 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.946 (perp=8.320, rec=0.045, cos=0.238), tot_loss_proj:1.983 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.963 (perp=8.320, rec=0.061, cos=0.238), tot_loss_proj:1.986 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.967 (perp=8.320, rec=0.065, cos=0.238), tot_loss_proj:1.979 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.960 (perp=8.320, rec=0.060, cos=0.236), tot_loss_proj:1.983 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.948 (perp=8.320, rec=0.047, cos=0.237), tot_loss_proj:1.985 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.955 (perp=8.320, rec=0.054, cos=0.238), tot_loss_proj:1.968 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.961 (perp=8.320, rec=0.059, cos=0.238), tot_loss_proj:1.981 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 85.799 | p: 84.557 | r: 87.340
rouge2     | fm: 54.452 | p: 54.218 | r: 54.755
rougeL     | fm: 75.878 | p: 74.759 | r: 77.088
rougeLsum  | fm: 75.748 | p: 74.649 | r: 77.102
r1fm+r2fm = 140.251

input #27 time: 0:08:17 | total time: 3:53:12


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.8820382453084118
highest_index [0]
highest [0.8820382453084118]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8695564270019531 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.8499931693077087 for ['[CLS] easierlnan cow [SEP]']
[Init] best rec loss: 0.8473625779151917 for ['[CLS] shower fusion considering blood [SEP]']
[Init] best rec loss: 0.8396828770637512 for ['[CLS] done human live quickly [SEP]']
[Init] best rec loss: 0.8334352970123291 for ['[CLS] sick prior spielberggation [SEP]']
[Init] best rec loss: 0.8287277817726135 for ['[CLS] hand delgado laid phoenix [SEP]']
[Init] best rec loss: 0.8226422667503357 for ['[CLS] w dean re thanks [SEP]']
[Init] best rec loss: 0.8186100721359253 for ['[CLS] pol maneuver lex bar [SEP]']
[Init] best rec loss: 0.8148447275161743 for ['[CLS] larvae heights jeremy roses [SEP]']
[Init] best perm rec loss: 0.8132706880569458 for ['[CLS] heights roses larvae jeremy [SEP]']
[Init] best perm rec loss: 0.8127878904342651 for ['[CLS] heights jeremy roses larvae [SEP]']
[Init] best perm rec loss: 0.8125485777854919 for ['[CLS] larvae jeremy heights roses [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.110 (perp=8.083, rec=0.298, cos=0.196), tot_loss_proj:2.629 [t=0.23s]
prediction: ['[CLS] only 3 international minutes [SEP]']
[ 100/2000] tot_loss=2.112 (perp=8.654, rec=0.166, cos=0.215), tot_loss_proj:2.793 [t=0.18s]
prediction: ['[CLS] only 71 route minutes [SEP]']
[ 150/2000] tot_loss=2.143 (perp=8.962, rec=0.141, cos=0.209), tot_loss_proj:2.614 [t=0.26s]
prediction: ['[CLS] only 71 71 minutes [SEP]']
[ 200/2000] tot_loss=2.288 (perp=9.734, rec=0.132, cos=0.209), tot_loss_proj:2.628 [t=0.22s]
prediction: ['[CLS] for 71 71 minutes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.960 (perp=8.123, rec=0.131, cos=0.205), tot_loss_proj:2.579 [t=0.25s]
prediction: ['[CLS] 71 for 71 minutes [SEP]']
[ 300/2000] tot_loss=1.971 (perp=8.123, rec=0.127, cos=0.219), tot_loss_proj:2.583 [t=0.25s]
prediction: ['[CLS] 71 for 71 minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.962 (perp=8.123, rec=0.123, cos=0.215), tot_loss_proj:2.586 [t=0.21s]
prediction: ['[CLS] 71 for 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.949 (perp=8.123, rec=0.115, cos=0.209), tot_loss_proj:2.593 [t=0.20s]
prediction: ['[CLS] 71 for 71 minutes [SEP]']
[ 450/2000] tot_loss=1.962 (perp=8.123, rec=0.131, cos=0.206), tot_loss_proj:2.589 [t=0.18s]
prediction: ['[CLS] 71 for 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.360 (perp=10.133, rec=0.114, cos=0.220), tot_loss_proj:2.962 [t=0.29s]
prediction: ['[CLS] 71 for only minutes [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.841 (perp=7.699, rec=0.088, cos=0.213), tot_loss_proj:1.854 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.822 (perp=7.699, rec=0.065, cos=0.217), tot_loss_proj:1.852 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.827 (perp=7.699, rec=0.068, cos=0.219), tot_loss_proj:1.861 [t=0.20s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.822 (perp=7.699, rec=0.063, cos=0.220), tot_loss_proj:1.854 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.821 (perp=7.699, rec=0.061, cos=0.220), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.815 (perp=7.699, rec=0.055, cos=0.220), tot_loss_proj:1.848 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.823 (perp=7.699, rec=0.063, cos=0.220), tot_loss_proj:1.860 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.813 (perp=7.699, rec=0.053, cos=0.221), tot_loss_proj:1.850 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.811 (perp=7.699, rec=0.051, cos=0.221), tot_loss_proj:1.851 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.821 (perp=7.699, rec=0.061, cos=0.221), tot_loss_proj:1.856 [t=0.23s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.826 (perp=7.699, rec=0.066, cos=0.221), tot_loss_proj:1.846 [t=0.27s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.811 (perp=7.699, rec=0.051, cos=0.221), tot_loss_proj:1.853 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.818 (perp=7.699, rec=0.057, cos=0.221), tot_loss_proj:1.855 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.824 (perp=7.699, rec=0.063, cos=0.221), tot_loss_proj:1.857 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.823 (perp=7.699, rec=0.062, cos=0.221), tot_loss_proj:1.850 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.819 (perp=7.699, rec=0.058, cos=0.221), tot_loss_proj:1.857 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.825 (perp=7.699, rec=0.064, cos=0.221), tot_loss_proj:1.860 [t=0.24s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.820 (perp=7.699, rec=0.060, cos=0.221), tot_loss_proj:1.851 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.811 (perp=7.699, rec=0.050, cos=0.221), tot_loss_proj:1.856 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.821 (perp=7.699, rec=0.060, cos=0.221), tot_loss_proj:1.858 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.817 (perp=7.699, rec=0.056, cos=0.221), tot_loss_proj:1.857 [t=0.23s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.824 (perp=7.699, rec=0.063, cos=0.221), tot_loss_proj:1.858 [t=0.24s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.827 (perp=7.699, rec=0.066, cos=0.221), tot_loss_proj:1.856 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.828 (perp=7.699, rec=0.067, cos=0.221), tot_loss_proj:1.857 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.815 (perp=7.699, rec=0.054, cos=0.221), tot_loss_proj:1.862 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.816 (perp=7.699, rec=0.054, cos=0.221), tot_loss_proj:1.853 [t=0.23s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.819 (perp=7.699, rec=0.058, cos=0.221), tot_loss_proj:1.860 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.825 (perp=7.699, rec=0.064, cos=0.221), tot_loss_proj:1.865 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.827 (perp=7.699, rec=0.066, cos=0.221), tot_loss_proj:1.858 [t=0.24s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.831 (perp=7.699, rec=0.070, cos=0.221), tot_loss_proj:1.866 [t=0.24s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.155 | p: 84.936 | r: 87.694
rouge2     | fm: 56.248 | p: 55.985 | r: 56.487
rougeL     | fm: 76.725 | p: 75.628 | r: 77.964
rougeLsum  | fm: 76.770 | p: 75.705 | r: 77.999
r1fm+r2fm = 142.403

input #28 time: 0:08:15 | total time: 4:01:28


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.8992432554925207
highest_index [0]
highest [0.8992432554925207]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.8682275414466858 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.8559431433677673 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.8466478586196899 for ['[CLS] protected leadlto arose ec along sunset pay everywhere county [SEP]']
[Init] best rec loss: 0.8141500949859619 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.7781331539154053 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 0.7765753269195557 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best perm rec loss: 0.7746928334236145 for ['[CLS] apart joyah epicbeat fk crap fork historia extra cape [SEP]']
[Init] best perm rec loss: 0.7745423913002014 for ['[CLS] crap fork epic fk historia cape apartbeat joyah extra [SEP]']
[Init] best perm rec loss: 0.7719380259513855 for ['[CLS] extra apart historia fk cape crap fork joyahbeat epic [SEP]']
[Init] best perm rec loss: 0.7710179686546326 for ['[CLS] cape joyah crap epicbeat fk extra apart historia fork [SEP]']
[Init] best perm rec loss: 0.7697086334228516 for ['[CLS] crap cape extra fk joyah epic fork apart historiabeat [SEP]']
[Init] best perm rec loss: 0.7693350315093994 for ['[CLS] fork crap fk apart epic cape joyah extrabeat historia [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.902 (perp=11.470, rec=0.434, cos=0.175), tot_loss_proj:3.534 [t=0.18s]
prediction: ['[CLS] be eventually believe it signing were h? fullyless [SEP]']
[ 100/2000] tot_loss=2.314 (perp=9.089, rec=0.345, cos=0.151), tot_loss_proj:3.087 [t=0.18s]
prediction: ['[CLS] not it believe that mafia was becoming ifliga not [SEP]']
[ 150/2000] tot_loss=2.075 (perp=8.504, rec=0.202, cos=0.172), tot_loss_proj:3.230 [t=0.22s]
prediction: ['[CLS] not it believe that resident is becoming if fully not [SEP]']
[ 200/2000] tot_loss=1.799 (perp=7.320, rec=0.161, cos=0.175), tot_loss_proj:2.742 [t=0.19s]
prediction: ['[CLS] not it believe that resident evil would is it not [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.820 (perp=7.465, rec=0.144, cos=0.183), tot_loss_proj:2.565 [t=0.27s]
prediction: ['[CLS] not it believe believe that resident evil is also not [SEP]']
[ 300/2000] tot_loss=1.792 (perp=7.465, rec=0.114, cos=0.185), tot_loss_proj:2.552 [t=0.26s]
prediction: ['[CLS] not it believe believe that resident evil is also not [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.578 (perp=6.427, rec=0.106, cos=0.186), tot_loss_proj:2.516 [t=0.20s]
prediction: ['[CLS] believe it not believe that resident evil is i not [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.538 (perp=6.331, rec=0.096, cos=0.176), tot_loss_proj:2.388 [t=0.19s]
prediction: ['[CLS] believe it also not believe that resident evil is not [SEP]']
[ 450/2000] tot_loss=1.442 (perp=5.816, rec=0.096, cos=0.183), tot_loss_proj:2.232 [t=0.26s]
prediction: ['[CLS] believe it i not believe that resident evil is not [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.443 (perp=5.816, rec=0.095, cos=0.185), tot_loss_proj:2.226 [t=0.19s]
prediction: ['[CLS] believe it i not believe that resident evil is not [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.436 (perp=5.816, rec=0.087, cos=0.185), tot_loss_proj:2.224 [t=0.29s]
prediction: ['[CLS] believe it i not believe that resident evil is not [SEP]']
[ 600/2000] tot_loss=1.448 (perp=5.816, rec=0.099, cos=0.186), tot_loss_proj:2.225 [t=0.24s]
prediction: ['[CLS] believe it i not believe that resident evil is not [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.435 (perp=5.816, rec=0.086, cos=0.187), tot_loss_proj:2.228 [t=0.31s]
prediction: ['[CLS] believe it i not believe that resident evil is not [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.449 (perp=5.816, rec=0.099, cos=0.187), tot_loss_proj:2.226 [t=0.18s]
prediction: ['[CLS] believe it i not believe that resident evil is not [SEP]']
[ 750/2000] tot_loss=1.444 (perp=5.816, rec=0.094, cos=0.187), tot_loss_proj:2.224 [t=0.18s]
prediction: ['[CLS] believe it i not believe that resident evil is not [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.442 (perp=5.816, rec=0.092, cos=0.187), tot_loss_proj:2.232 [t=0.24s]
prediction: ['[CLS] believe it i not believe that resident evil is not [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.535 (perp=6.329, rec=0.094, cos=0.175), tot_loss_proj:2.305 [t=0.18s]
prediction: ['[CLS] it i not believe that believe resident evil is not [SEP]']
[ 900/2000] tot_loss=1.539 (perp=6.329, rec=0.091, cos=0.182), tot_loss_proj:2.308 [t=0.18s]
prediction: ['[CLS] it i not believe that believe resident evil is not [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.479 (perp=6.017, rec=0.093, cos=0.183), tot_loss_proj:2.229 [t=0.19s]
prediction: ['[CLS] i not believe it that believe resident evil is not [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.446 (perp=5.882, rec=0.085, cos=0.184), tot_loss_proj:2.261 [t=0.25s]
prediction: ['[CLS] i not believe that it believe resident evil is not [SEP]']
[1050/2000] tot_loss=1.456 (perp=5.882, rec=0.095, cos=0.185), tot_loss_proj:2.262 [t=0.19s]
prediction: ['[CLS] i not believe that it believe resident evil is not [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.476 (perp=6.018, rec=0.089, cos=0.184), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] i believe that it not i resident evil is not [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.359 (perp=5.465, rec=0.090, cos=0.177), tot_loss_proj:2.539 [t=0.20s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
[1200/2000] tot_loss=1.363 (perp=5.465, rec=0.088, cos=0.182), tot_loss_proj:2.542 [t=0.19s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[1250/2000] tot_loss=1.357 (perp=5.465, rec=0.082, cos=0.183), tot_loss_proj:2.544 [t=0.26s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[1300/2000] tot_loss=1.367 (perp=5.465, rec=0.091, cos=0.183), tot_loss_proj:2.543 [t=0.18s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
[1350/2000] tot_loss=1.365 (perp=5.465, rec=0.089, cos=0.184), tot_loss_proj:2.548 [t=0.22s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[1400/2000] tot_loss=1.364 (perp=5.465, rec=0.087, cos=0.184), tot_loss_proj:2.544 [t=0.25s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[1450/2000] tot_loss=1.367 (perp=5.465, rec=0.090, cos=0.184), tot_loss_proj:2.537 [t=0.18s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
[1500/2000] tot_loss=1.364 (perp=5.465, rec=0.087, cos=0.184), tot_loss_proj:2.549 [t=0.22s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[1550/2000] tot_loss=1.369 (perp=5.465, rec=0.092, cos=0.184), tot_loss_proj:2.545 [t=0.26s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[1600/2000] tot_loss=1.364 (perp=5.465, rec=0.087, cos=0.184), tot_loss_proj:2.541 [t=0.18s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
[1650/2000] tot_loss=1.367 (perp=5.465, rec=0.091, cos=0.184), tot_loss_proj:2.546 [t=0.19s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[1700/2000] tot_loss=1.358 (perp=5.465, rec=0.082, cos=0.184), tot_loss_proj:2.538 [t=0.21s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[1750/2000] tot_loss=1.363 (perp=5.465, rec=0.087, cos=0.184), tot_loss_proj:2.545 [t=0.18s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
[1800/2000] tot_loss=1.362 (perp=5.465, rec=0.086, cos=0.183), tot_loss_proj:2.543 [t=0.21s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[1850/2000] tot_loss=1.362 (perp=5.465, rec=0.086, cos=0.183), tot_loss_proj:2.544 [t=0.18s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[1900/2000] tot_loss=1.363 (perp=5.465, rec=0.087, cos=0.183), tot_loss_proj:2.541 [t=0.22s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
[1950/2000] tot_loss=1.363 (perp=5.465, rec=0.087, cos=0.183), tot_loss_proj:2.541 [t=0.24s]
prediction: ['[CLS] i believe it not that i resident evil is not [SEP]']
Attempt swap
[2000/2000] tot_loss=1.438 (perp=5.832, rec=0.088, cos=0.183), tot_loss_proj:2.193 [t=0.22s]
prediction: ['[CLS] i believe it not that i resident evil is it [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i believe it not that i resident evil is not [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 125.052

[Aggregate metrics]:
rouge1     | fm: 86.316 | p: 84.981 | r: 87.823
rouge2     | fm: 55.166 | p: 54.877 | r: 55.540
rougeL     | fm: 76.861 | p: 75.666 | r: 78.240
rougeLsum  | fm: 76.834 | p: 75.685 | r: 78.116
r1fm+r2fm = 141.483

input #29 time: 0:08:30 | total time: 4:09:58


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.8711390803864382
highest_index [0]
highest [0.8711390803864382]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.828752338886261 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.6928375363349915 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.6925650835037231 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.6540452241897583 for ['[CLS] acceleration council lizard [SEP]']
[Init] best rec loss: 0.6493086218833923 for ['[CLS] spent who mom [SEP]']
[Init] best perm rec loss: 0.6474621295928955 for ['[CLS] mom who spent [SEP]']
[Init] best perm rec loss: 0.6438997983932495 for ['[CLS] who mom spent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.474 (perp=10.101, rec=0.227, cos=0.227), tot_loss_proj:3.745 [t=0.18s]
prediction: ['[CLS] fibilitybility [SEP]']
[ 100/2000] tot_loss=2.294 (perp=9.540, rec=0.154, cos=0.233), tot_loss_proj:2.213 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=2.231 (perp=9.540, rec=0.077, cos=0.246), tot_loss_proj:2.223 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=2.204 (perp=9.540, rec=0.062, cos=0.234), tot_loss_proj:2.214 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.252 (perp=9.540, rec=0.120, cos=0.224), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=2.219 (perp=9.540, rec=0.076, cos=0.235), tot_loss_proj:2.202 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.205 (perp=9.540, rec=0.057, cos=0.240), tot_loss_proj:2.208 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.199 (perp=9.540, rec=0.067, cos=0.224), tot_loss_proj:2.200 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=2.200 (perp=9.540, rec=0.055, cos=0.237), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.200 (perp=9.540, rec=0.053, cos=0.239), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.215 (perp=9.540, rec=0.075, cos=0.232), tot_loss_proj:2.215 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=2.199 (perp=9.540, rec=0.052, cos=0.239), tot_loss_proj:2.202 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.226 (perp=9.540, rec=0.078, cos=0.240), tot_loss_proj:2.230 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.198 (perp=9.540, rec=0.050, cos=0.240), tot_loss_proj:2.215 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=2.198 (perp=9.540, rec=0.052, cos=0.238), tot_loss_proj:2.210 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.205 (perp=9.540, rec=0.058, cos=0.239), tot_loss_proj:2.204 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.206 (perp=9.540, rec=0.058, cos=0.240), tot_loss_proj:2.216 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=2.206 (perp=9.540, rec=0.057, cos=0.240), tot_loss_proj:2.216 [t=0.27s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.208 (perp=9.540, rec=0.060, cos=0.240), tot_loss_proj:2.218 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=2.215 (perp=9.540, rec=0.074, cos=0.233), tot_loss_proj:2.215 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=2.216 (perp=9.540, rec=0.069, cos=0.239), tot_loss_proj:2.207 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=2.211 (perp=9.540, rec=0.063, cos=0.240), tot_loss_proj:2.208 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=2.211 (perp=9.540, rec=0.063, cos=0.240), tot_loss_proj:2.218 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=2.215 (perp=9.540, rec=0.066, cos=0.240), tot_loss_proj:2.223 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=2.210 (perp=9.540, rec=0.061, cos=0.240), tot_loss_proj:2.220 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=2.220 (perp=9.540, rec=0.072, cos=0.241), tot_loss_proj:2.212 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=2.204 (perp=9.540, rec=0.056, cos=0.241), tot_loss_proj:2.217 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=2.217 (perp=9.540, rec=0.068, cos=0.241), tot_loss_proj:2.206 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=2.202 (perp=9.540, rec=0.053, cos=0.241), tot_loss_proj:2.228 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=2.202 (perp=9.540, rec=0.053, cos=0.241), tot_loss_proj:2.211 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=2.215 (perp=9.540, rec=0.067, cos=0.241), tot_loss_proj:2.194 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=2.206 (perp=9.540, rec=0.057, cos=0.241), tot_loss_proj:2.221 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=2.219 (perp=9.540, rec=0.073, cos=0.238), tot_loss_proj:2.220 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=2.210 (perp=9.540, rec=0.063, cos=0.240), tot_loss_proj:2.216 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=2.190 (perp=9.540, rec=0.042, cos=0.240), tot_loss_proj:2.208 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=2.200 (perp=9.540, rec=0.051, cos=0.240), tot_loss_proj:2.212 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=2.191 (perp=9.540, rec=0.043, cos=0.240), tot_loss_proj:2.211 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=2.200 (perp=9.540, rec=0.052, cos=0.240), tot_loss_proj:2.227 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=2.197 (perp=9.540, rec=0.048, cos=0.241), tot_loss_proj:2.219 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=2.209 (perp=9.540, rec=0.061, cos=0.241), tot_loss_proj:2.210 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.764 | p: 85.561 | r: 88.218
rouge2     | fm: 57.069 | p: 56.865 | r: 57.430
rougeL     | fm: 77.685 | p: 76.535 | r: 78.968
rougeLsum  | fm: 77.390 | p: 76.393 | r: 78.655
r1fm+r2fm = 143.833

input #30 time: 0:08:17 | total time: 4:18:16


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9003016501825756
highest_index [0]
highest [0.9003016501825756]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.8858006596565247 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.8265479803085327 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8118960857391357 for ['[CLS] song spectators then [SEP]']
[Init] best rec loss: 0.7769879102706909 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 0.7696162462234497 for ['[CLS] lad crossing all [SEP]']
[Init] best rec loss: 0.7695770263671875 for ['[CLS] speakingski strains [SEP]']
[Init] best rec loss: 0.768726646900177 for ['[CLS] playhouse saxons garde [SEP]']
[Init] best rec loss: 0.7651781439781189 for ['[CLS] golf rollichi [SEP]']
[Init] best rec loss: 0.7452251315116882 for ['[CLS] lighthouse peace case [SEP]']
[Init] best perm rec loss: 0.7437663674354553 for ['[CLS] peace lighthouse case [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.603 (perp=10.701, rec=0.274, cos=0.188), tot_loss_proj:2.976 [t=0.18s]
prediction: ['[CLS] production better better [SEP]']
[ 100/2000] tot_loss=1.820 (perp=7.603, rec=0.119, cos=0.180), tot_loss_proj:1.837 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 150/2000] tot_loss=1.779 (perp=7.603, rec=0.073, cos=0.186), tot_loss_proj:1.827 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 200/2000] tot_loss=1.780 (perp=7.603, rec=0.072, cos=0.187), tot_loss_proj:1.832 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.781 (perp=7.603, rec=0.072, cos=0.188), tot_loss_proj:1.845 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.767 (perp=7.603, rec=0.057, cos=0.189), tot_loss_proj:1.831 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.772 (perp=7.603, rec=0.063, cos=0.189), tot_loss_proj:1.834 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.768 (perp=7.603, rec=0.059, cos=0.189), tot_loss_proj:1.834 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.778 (perp=7.603, rec=0.069, cos=0.189), tot_loss_proj:1.823 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.772 (perp=7.603, rec=0.062, cos=0.189), tot_loss_proj:1.815 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.769 (perp=7.603, rec=0.059, cos=0.189), tot_loss_proj:1.834 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.782 (perp=7.603, rec=0.072, cos=0.189), tot_loss_proj:1.824 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.774 (perp=7.603, rec=0.064, cos=0.189), tot_loss_proj:1.824 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.766 (perp=7.603, rec=0.056, cos=0.189), tot_loss_proj:1.837 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.777 (perp=7.603, rec=0.068, cos=0.189), tot_loss_proj:1.832 [t=0.20s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.754 (perp=7.603, rec=0.044, cos=0.189), tot_loss_proj:1.839 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.757 (perp=7.603, rec=0.047, cos=0.189), tot_loss_proj:1.827 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.765 (perp=7.603, rec=0.055, cos=0.189), tot_loss_proj:1.826 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.769 (perp=7.603, rec=0.059, cos=0.189), tot_loss_proj:1.830 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.774 (perp=7.603, rec=0.064, cos=0.189), tot_loss_proj:1.849 [t=0.20s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.775 (perp=7.603, rec=0.065, cos=0.189), tot_loss_proj:1.829 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.759 (perp=7.603, rec=0.049, cos=0.189), tot_loss_proj:1.832 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.768 (perp=7.603, rec=0.058, cos=0.189), tot_loss_proj:1.828 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.765 (perp=7.603, rec=0.056, cos=0.189), tot_loss_proj:1.813 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.766 (perp=7.603, rec=0.056, cos=0.189), tot_loss_proj:1.843 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.763 (perp=7.603, rec=0.053, cos=0.189), tot_loss_proj:1.828 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.775 (perp=7.603, rec=0.065, cos=0.189), tot_loss_proj:1.839 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.778 (perp=7.603, rec=0.068, cos=0.189), tot_loss_proj:1.815 [t=0.20s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.767 (perp=7.603, rec=0.060, cos=0.186), tot_loss_proj:1.825 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.777 (perp=7.603, rec=0.068, cos=0.189), tot_loss_proj:1.831 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.770 (perp=7.603, rec=0.060, cos=0.189), tot_loss_proj:1.828 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.765 (perp=7.603, rec=0.056, cos=0.189), tot_loss_proj:1.832 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.763 (perp=7.603, rec=0.054, cos=0.189), tot_loss_proj:1.844 [t=0.27s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.772 (perp=7.603, rec=0.062, cos=0.189), tot_loss_proj:1.826 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.773 (perp=7.603, rec=0.063, cos=0.189), tot_loss_proj:1.834 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.764 (perp=7.603, rec=0.054, cos=0.189), tot_loss_proj:1.826 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.764 (perp=7.603, rec=0.054, cos=0.189), tot_loss_proj:1.836 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.769 (perp=7.603, rec=0.059, cos=0.189), tot_loss_proj:1.834 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.772 (perp=7.603, rec=0.062, cos=0.189), tot_loss_proj:1.834 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.774 (perp=7.603, rec=0.064, cos=0.189), tot_loss_proj:1.838 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.108 | p: 85.900 | r: 88.506
rouge2     | fm: 58.279 | p: 57.989 | r: 58.580
rougeL     | fm: 78.339 | p: 77.327 | r: 79.604
rougeLsum  | fm: 78.131 | p: 77.057 | r: 79.288
r1fm+r2fm = 145.387

input #31 time: 0:08:15 | total time: 4:26:31


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.8060281459661307
highest_index [0]
highest [0.8060281459661307]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.9218396544456482 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9172350764274597 for ['[CLS] actver⋅ bond dimebruck nocus " happy california marine [SEP]']
[Init] best rec loss: 0.9068348407745361 for ['[CLS] huey while kill stuck doc urgent lakeside integration food trailers with a [SEP]']
[Init] best rec loss: 0.9064400792121887 for ['[CLS]le force cheers discarded replicateباد clash lighthouse direct remarried narrative words [SEP]']
[Init] best rec loss: 0.8969874382019043 for ['[CLS] metriety general newcious would varies stretchaneous jesus spurs alliance [SEP]']
[Init] best rec loss: 0.8851745128631592 for ['[CLS] sub trials milk park casual two emma pocket breed against defending tenor [SEP]']
[Init] best rec loss: 0.8711655735969543 for ['[CLS] lips let ″ forth between alongside mud inclination airport gods baptism unanimous [SEP]']
[Init] best perm rec loss: 0.8674523234367371 for ['[CLS] unanimous let ″ forth inclination between alongside gods lips airport baptism mud [SEP]']
[Init] best perm rec loss: 0.8648406267166138 for ['[CLS] lips gods alongside unanimous airport baptism ″ mud let forth inclination between [SEP]']
[Init] best perm rec loss: 0.8636180758476257 for ['[CLS] inclination between mud unanimous lips forth airport ″ let alongside baptism gods [SEP]']
[Init] best perm rec loss: 0.8634272813796997 for ['[CLS] unanimous inclination forth airport gods lips let baptism between alongside ″ mud [SEP]']
[Init] best perm rec loss: 0.8620761036872864 for ['[CLS] let unanimous airport forth inclination lips between mud baptism ″ gods alongside [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.313 (perp=13.182, rec=0.328, cos=0.349), tot_loss_proj:3.883 [t=0.22s]
prediction: ['[CLS] so accessible cuisine forth located hers multi serena unique accessible attractions moments [SEP]']
[ 100/2000] tot_loss=2.997 (perp=12.174, rec=0.216, cos=0.346), tot_loss_proj:3.658 [t=0.24s]
prediction: ['[CLS] pull accessible stories understanding garnered together easily make appreciated storiesonateity [SEP]']
[ 150/2000] tot_loss=2.996 (perp=12.451, rec=0.161, cos=0.346), tot_loss_proj:3.914 [t=0.18s]
prediction: ['[CLS] pull accessible storiesity pull together easilytationonate storiesonate with [SEP]']
[ 200/2000] tot_loss=2.969 (perp=12.451, rec=0.132, cos=0.347), tot_loss_proj:3.932 [t=0.19s]
prediction: ['[CLS] pull accessible storiesity pull together easilytationonate storiesonate with [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.656 (perp=10.896, rec=0.133, cos=0.344), tot_loss_proj:4.018 [t=0.23s]
prediction: ['[CLS] res easily storiesity pull together easily require accessible storiesonate with [SEP]']
[ 300/2000] tot_loss=2.889 (perp=12.183, rec=0.103, cos=0.349), tot_loss_proj:4.058 [t=0.27s]
prediction: ['[CLS] thatund storiesity pull together easilytation accessible storiesonate with [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.453 (perp=10.006, rec=0.103, cos=0.349), tot_loss_proj:3.438 [t=0.20s]
prediction: ['[CLS] stories thatundity pull together easilyund accessible storiesonate with [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.490 (perp=10.079, rec=0.129, cos=0.344), tot_loss_proj:3.527 [t=0.31s]
prediction: ['[CLS] stories resundity pull together easily with accessible storiesonateund [SEP]']
[ 450/2000] tot_loss=2.467 (perp=10.079, rec=0.104, cos=0.348), tot_loss_proj:3.524 [t=0.28s]
prediction: ['[CLS] stories resundity pull together easily with accessible storiesonateund [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.397 (perp=9.789, rec=0.092, cos=0.348), tot_loss_proj:3.454 [t=0.17s]
prediction: ['[CLS] resundity stories pull together easily with accessible storiesonateund [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.359 (perp=9.588, rec=0.094, cos=0.348), tot_loss_proj:3.475 [t=0.18s]
prediction: ['[CLS] resundity stories pull easily together with accessible storiesonateund [SEP]']
[ 600/2000] tot_loss=2.362 (perp=9.588, rec=0.097, cos=0.348), tot_loss_proj:3.479 [t=0.19s]
prediction: ['[CLS] resundity stories pull easily together with accessible storiesonateund [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.358 (perp=9.588, rec=0.092, cos=0.349), tot_loss_proj:3.478 [t=0.22s]
prediction: ['[CLS] resundity stories pull easily together with accessible storiesonateund [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.356 (perp=9.588, rec=0.090, cos=0.349), tot_loss_proj:3.482 [t=0.18s]
prediction: ['[CLS] resundity stories pull easily together with accessible storiesonateund [SEP]']
[ 750/2000] tot_loss=2.353 (perp=9.588, rec=0.087, cos=0.348), tot_loss_proj:3.474 [t=0.18s]
prediction: ['[CLS] resundity stories pull easily together with accessible storiesonateund [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.363 (perp=9.588, rec=0.097, cos=0.349), tot_loss_proj:3.476 [t=0.18s]
prediction: ['[CLS] resundity stories pull easily together with accessible storiesonateund [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.343 (perp=9.588, rec=0.076, cos=0.349), tot_loss_proj:3.480 [t=0.25s]
prediction: ['[CLS] resundity stories pull easily together with accessible storiesonateund [SEP]']
[ 900/2000] tot_loss=2.414 (perp=9.931, rec=0.079, cos=0.349), tot_loss_proj:3.309 [t=0.19s]
prediction: ['[CLS] resundity stories pull easily together with accessible storiesonate prof [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.291 (perp=9.289, rec=0.085, cos=0.349), tot_loss_proj:3.101 [t=0.21s]
prediction: ['[CLS] resundity stories pull easily together with accessible stories profonate [SEP]']
Attempt swap
[1000/2000] tot_loss=2.288 (perp=9.289, rec=0.081, cos=0.349), tot_loss_proj:3.099 [t=0.21s]
prediction: ['[CLS] resundity stories pull easily together with accessible stories profonate [SEP]']
[1050/2000] tot_loss=2.275 (perp=9.289, rec=0.068, cos=0.349), tot_loss_proj:3.095 [t=0.20s]
prediction: ['[CLS] resundity stories pull easily together with accessible stories profonate [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.971 (perp=7.711, rec=0.080, cos=0.349), tot_loss_proj:2.443 [t=0.26s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1150/2000] tot_loss=1.979 (perp=7.711, rec=0.087, cos=0.349), tot_loss_proj:2.441 [t=0.18s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
[1200/2000] tot_loss=1.976 (perp=7.711, rec=0.085, cos=0.349), tot_loss_proj:2.439 [t=0.18s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1250/2000] tot_loss=1.980 (perp=7.711, rec=0.089, cos=0.349), tot_loss_proj:2.437 [t=0.20s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1300/2000] tot_loss=1.971 (perp=7.711, rec=0.079, cos=0.349), tot_loss_proj:2.449 [t=0.18s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
[1350/2000] tot_loss=1.963 (perp=7.711, rec=0.071, cos=0.349), tot_loss_proj:2.443 [t=0.18s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1400/2000] tot_loss=1.969 (perp=7.711, rec=0.077, cos=0.349), tot_loss_proj:2.441 [t=0.19s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1450/2000] tot_loss=1.965 (perp=7.711, rec=0.073, cos=0.350), tot_loss_proj:2.441 [t=0.19s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
[1500/2000] tot_loss=1.977 (perp=7.711, rec=0.085, cos=0.350), tot_loss_proj:2.444 [t=0.23s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1550/2000] tot_loss=1.976 (perp=7.711, rec=0.084, cos=0.350), tot_loss_proj:2.438 [t=0.18s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1600/2000] tot_loss=1.966 (perp=7.711, rec=0.074, cos=0.350), tot_loss_proj:2.445 [t=0.23s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
[1650/2000] tot_loss=1.966 (perp=7.711, rec=0.074, cos=0.350), tot_loss_proj:2.440 [t=0.18s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1700/2000] tot_loss=1.966 (perp=7.711, rec=0.074, cos=0.350), tot_loss_proj:2.442 [t=0.24s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1750/2000] tot_loss=1.970 (perp=7.711, rec=0.078, cos=0.350), tot_loss_proj:2.442 [t=0.22s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
[1800/2000] tot_loss=1.965 (perp=7.711, rec=0.073, cos=0.350), tot_loss_proj:2.437 [t=0.24s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1850/2000] tot_loss=1.965 (perp=7.711, rec=0.073, cos=0.350), tot_loss_proj:2.440 [t=0.18s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[1900/2000] tot_loss=1.974 (perp=7.711, rec=0.082, cos=0.350), tot_loss_proj:2.443 [t=0.25s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
[1950/2000] tot_loss=1.979 (perp=7.711, rec=0.087, cos=0.350), tot_loss_proj:2.441 [t=0.19s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Attempt swap
[2000/2000] tot_loss=1.968 (perp=7.711, rec=0.076, cos=0.350), tot_loss_proj:2.441 [t=0.25s]
prediction: ['[CLS] profundity stories pull easily together with accessible stories resonate [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] profundity stories pull easily together with accessible stories resonate [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 10.000 | p: 10.000 | r: 10.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 100.909

[Aggregate metrics]:
rouge1     | fm: 87.239 | p: 86.042 | r: 88.603
rouge2     | fm: 57.125 | p: 56.869 | r: 57.388
rougeL     | fm: 77.689 | p: 76.589 | r: 78.926
rougeLsum  | fm: 77.767 | p: 76.776 | r: 78.950
r1fm+r2fm = 144.364

input #32 time: 0:08:26 | total time: 4:34:58


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.859741832156617
highest_index [0]
highest [0.859741832156617]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9748023748397827 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.8335748314857483 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.7753230929374695 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.7519458532333374 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.7331568598747253 for ['[CLS] effective [SEP]']
[Init] best rec loss: 0.7324262261390686 for ['[CLS] frame [SEP]']
[Init] best rec loss: 0.7286977767944336 for ['[CLS] railroad [SEP]']
[Init] best rec loss: 0.6990271806716919 for ['[CLS] positive [SEP]']
[Init] best rec loss: 0.6555793881416321 for ['[CLS] / [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.621 (perp=11.231, rec=0.125, cos=0.250), tot_loss_proj:2.688 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.568 (perp=11.231, rec=0.062, cos=0.260), tot_loss_proj:2.605 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.563 (perp=11.231, rec=0.057, cos=0.260), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.561 (perp=11.231, rec=0.054, cos=0.261), tot_loss_proj:2.594 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.571 (perp=11.231, rec=0.064, cos=0.261), tot_loss_proj:2.610 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.563 (perp=11.231, rec=0.064, cos=0.252), tot_loss_proj:2.604 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.564 (perp=11.231, rec=0.057, cos=0.261), tot_loss_proj:2.581 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.584 (perp=11.231, rec=0.077, cos=0.261), tot_loss_proj:2.604 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.561 (perp=11.231, rec=0.055, cos=0.260), tot_loss_proj:2.604 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.557 (perp=11.231, rec=0.051, cos=0.260), tot_loss_proj:2.609 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.560 (perp=11.231, rec=0.053, cos=0.261), tot_loss_proj:2.594 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.553 (perp=11.231, rec=0.047, cos=0.261), tot_loss_proj:2.599 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.575 (perp=11.231, rec=0.068, cos=0.261), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.563 (perp=11.231, rec=0.057, cos=0.260), tot_loss_proj:2.597 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.570 (perp=11.231, rec=0.063, cos=0.260), tot_loss_proj:2.589 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.568 (perp=11.231, rec=0.061, cos=0.261), tot_loss_proj:2.619 [t=0.29s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.576 (perp=11.231, rec=0.069, cos=0.261), tot_loss_proj:2.592 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.569 (perp=11.231, rec=0.065, cos=0.258), tot_loss_proj:2.605 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.571 (perp=11.231, rec=0.065, cos=0.260), tot_loss_proj:2.603 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.558 (perp=11.231, rec=0.052, cos=0.261), tot_loss_proj:2.606 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.559 (perp=11.231, rec=0.052, cos=0.261), tot_loss_proj:2.619 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.553 (perp=11.231, rec=0.046, cos=0.261), tot_loss_proj:2.596 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.562 (perp=11.231, rec=0.055, cos=0.261), tot_loss_proj:2.601 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.577 (perp=11.231, rec=0.070, cos=0.261), tot_loss_proj:2.609 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.591 (perp=11.231, rec=0.085, cos=0.260), tot_loss_proj:2.608 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.566 (perp=11.231, rec=0.059, cos=0.260), tot_loss_proj:2.581 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.553 (perp=11.231, rec=0.046, cos=0.261), tot_loss_proj:2.599 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.556 (perp=11.231, rec=0.049, cos=0.261), tot_loss_proj:2.593 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.555 (perp=11.231, rec=0.049, cos=0.261), tot_loss_proj:2.611 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.575 (perp=11.231, rec=0.068, cos=0.261), tot_loss_proj:2.608 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.566 (perp=11.231, rec=0.059, cos=0.261), tot_loss_proj:2.597 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.565 (perp=11.231, rec=0.058, cos=0.261), tot_loss_proj:2.607 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.572 (perp=11.231, rec=0.065, cos=0.261), tot_loss_proj:2.603 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.563 (perp=11.231, rec=0.056, cos=0.261), tot_loss_proj:2.615 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.561 (perp=11.231, rec=0.056, cos=0.259), tot_loss_proj:2.603 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.567 (perp=11.231, rec=0.060, cos=0.260), tot_loss_proj:2.603 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.571 (perp=11.231, rec=0.064, cos=0.261), tot_loss_proj:2.591 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.556 (perp=11.231, rec=0.049, cos=0.261), tot_loss_proj:2.611 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.558 (perp=11.231, rec=0.051, cos=0.261), tot_loss_proj:2.603 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.560 (perp=11.231, rec=0.053, cos=0.261), tot_loss_proj:2.602 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.577 | p: 86.407 | r: 88.878
rouge2     | fm: 58.504 | p: 58.296 | r: 58.869
rougeL     | fm: 78.240 | p: 77.233 | r: 79.459
rougeLsum  | fm: 78.332 | p: 77.398 | r: 79.478
r1fm+r2fm = 146.080

input #33 time: 0:08:10 | total time: 4:43:09


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.8265007967796814
highest_index [0]
highest [0.8265007967796814]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8634361624717712 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8632130026817322 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8502154350280762 for ['[CLS]gut tam popular xml practice got maia accompanied gaulle dateize mc full [SEP]']
[Init] best rec loss: 0.7912837862968445 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.771020770072937 for ['[CLS] paper right ‖ allies considerations inophone nassau served molecular queen hart liv [SEP]']
[Init] best rec loss: 0.7532324194908142 for ['[CLS]truct way terminus week photos specifically dowager anime inducted valentin scotch watches watched [SEP]']
[Init] best rec loss: 0.7280605435371399 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.7266983389854431 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.7241566181182861 for ['[CLS]ibe lissa field worth founder along ship statue driversask slight who okay [SEP]']
[Init] best perm rec loss: 0.7238343358039856 for ['[CLS] founder okay along statueibe shipask drivers who worth slight lissa field [SEP]']
[Init] best perm rec loss: 0.7235633134841919 for ['[CLS]ask along who lissaibe ship founder slight statue drivers field okay worth [SEP]']
[Init] best perm rec loss: 0.7232552170753479 for ['[CLS] okay along founderibe worth drivers statue slight who lissaask field ship [SEP]']
[Init] best perm rec loss: 0.7229769825935364 for ['[CLS] field drivers slight ship okay statueask lissa who founder worth alongibe [SEP]']
[Init] best perm rec loss: 0.7193894982337952 for ['[CLS] founderask lissa along slight ship statue okay who field worth driversibe [SEP]']
[Init] best perm rec loss: 0.718029260635376 for ['[CLS]ibeask worth ship slight founder okay statue lissa who field along drivers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.026 (perp=11.841, rec=0.401, cos=0.258), tot_loss_proj:3.698 [t=0.18s]
prediction: ['[CLS] inhibitor ( urgency continents blake narrator extreme concern including surprise force the. [SEP]']
[ 100/2000] tot_loss=2.607 (perp=10.354, rec=0.258, cos=0.278), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS] build in urgency into blake extreme extreme take and urgency urgencyai. [SEP]']
[ 150/2000] tot_loss=2.673 (perp=10.920, rec=0.200, cos=0.288), tot_loss_proj:3.534 [t=0.24s]
prediction: ['[CLS] build in urgency on douglas extreme extreme take during urgency urgency a. [SEP]']
[ 200/2000] tot_loss=2.599 (perp=10.731, rec=0.147, cos=0.306), tot_loss_proj:3.180 [t=0.26s]
prediction: ['[CLS] build in build on viewers extreme extreme take through urgency urgency a. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.253 (perp=9.086, rec=0.130, cos=0.306), tot_loss_proj:2.994 [t=0.19s]
prediction: ['[CLS] build in build on extreme extreme viewers take mind urgency urgency and. [SEP]']
[ 300/2000] tot_loss=2.256 (perp=9.229, rec=0.106, cos=0.304), tot_loss_proj:3.025 [t=0.25s]
prediction: ['[CLS] build in build on extreme extreme viewer take mind urgency urgency and. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.067 (perp=8.334, rec=0.099, cos=0.301), tot_loss_proj:2.735 [t=0.20s]
prediction: ['[CLS] build in build on extreme extreme viewer take mind urgency and urgency. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.986 (perp=7.810, rec=0.109, cos=0.315), tot_loss_proj:2.798 [t=0.20s]
prediction: ['[CLS] build in mind on extreme extreme viewer take build urgency and urgency. [SEP]']
[ 450/2000] tot_loss=1.984 (perp=7.810, rec=0.106, cos=0.316), tot_loss_proj:2.804 [t=0.18s]
prediction: ['[CLS] build in mind on extreme extreme viewer take build urgency and urgency. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.988 (perp=8.011, rec=0.083, cos=0.303), tot_loss_proj:2.759 [t=0.19s]
prediction: ['[CLS] build in mind on extreme extreme take build viewer urgency and of. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.781 (perp=7.000, rec=0.081, cos=0.299), tot_loss_proj:2.661 [t=0.18s]
prediction: ['[CLS] build in mind on extreme extreme take of viewer urgency and build. [SEP]']
[ 600/2000] tot_loss=1.794 (perp=7.000, rec=0.081, cos=0.314), tot_loss_proj:2.659 [t=0.19s]
prediction: ['[CLS] build in mind on extreme extreme take of viewer urgency and build. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.789 (perp=7.000, rec=0.088, cos=0.301), tot_loss_proj:2.653 [t=0.23s]
prediction: ['[CLS] build in mind on extreme extreme take of viewer urgency and build. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.750 (perp=6.768, rec=0.083, cos=0.313), tot_loss_proj:2.411 [t=0.18s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
[ 750/2000] tot_loss=1.743 (perp=6.768, rec=0.088, cos=0.301), tot_loss_proj:2.412 [t=0.18s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.762 (perp=6.768, rec=0.096, cos=0.313), tot_loss_proj:2.418 [t=0.21s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.762 (perp=6.768, rec=0.102, cos=0.307), tot_loss_proj:2.413 [t=0.24s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
[ 900/2000] tot_loss=1.762 (perp=6.768, rec=0.095, cos=0.313), tot_loss_proj:2.416 [t=0.27s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.747 (perp=6.768, rec=0.078, cos=0.315), tot_loss_proj:2.414 [t=0.23s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.759 (perp=6.768, rec=0.096, cos=0.309), tot_loss_proj:2.411 [t=0.19s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
[1050/2000] tot_loss=1.751 (perp=6.768, rec=0.083, cos=0.315), tot_loss_proj:2.411 [t=0.18s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.759 (perp=6.768, rec=0.096, cos=0.310), tot_loss_proj:2.411 [t=0.25s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.749 (perp=6.768, rec=0.083, cos=0.312), tot_loss_proj:2.411 [t=0.28s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
[1200/2000] tot_loss=1.740 (perp=6.768, rec=0.071, cos=0.316), tot_loss_proj:2.415 [t=0.18s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.736 (perp=6.768, rec=0.077, cos=0.306), tot_loss_proj:2.414 [t=0.18s]
prediction: ['[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.680 (perp=6.484, rec=0.070, cos=0.313), tot_loss_proj:2.248 [t=0.18s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and build. [SEP]']
[1350/2000] tot_loss=1.698 (perp=6.484, rec=0.086, cos=0.316), tot_loss_proj:2.244 [t=0.19s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and build. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.639 (perp=6.273, rec=0.077, cos=0.307), tot_loss_proj:2.216 [t=0.18s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.637 (perp=6.273, rec=0.070, cos=0.313), tot_loss_proj:2.214 [t=0.25s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
[1500/2000] tot_loss=1.645 (perp=6.273, rec=0.075, cos=0.315), tot_loss_proj:2.216 [t=0.18s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.652 (perp=6.273, rec=0.081, cos=0.317), tot_loss_proj:2.215 [t=0.18s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.641 (perp=6.298, rec=0.069, cos=0.312), tot_loss_proj:2.119 [t=0.21s]
prediction: ['[CLS] build in mind the extreme take on extreme viewer urgency and urgency. [SEP]']
[1650/2000] tot_loss=1.649 (perp=6.298, rec=0.076, cos=0.314), tot_loss_proj:2.121 [t=0.18s]
prediction: ['[CLS] build in mind the extreme take on extreme viewer urgency and urgency. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.657 (perp=6.273, rec=0.087, cos=0.316), tot_loss_proj:2.215 [t=0.23s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.646 (perp=6.273, rec=0.079, cos=0.312), tot_loss_proj:2.216 [t=0.19s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
[1800/2000] tot_loss=1.651 (perp=6.273, rec=0.082, cos=0.314), tot_loss_proj:2.216 [t=0.21s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.641 (perp=6.273, rec=0.071, cos=0.315), tot_loss_proj:2.221 [t=0.18s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.644 (perp=6.273, rec=0.074, cos=0.315), tot_loss_proj:2.209 [t=0.18s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
[1950/2000] tot_loss=1.652 (perp=6.273, rec=0.081, cos=0.316), tot_loss_proj:2.218 [t=0.28s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.654 (perp=6.273, rec=0.086, cos=0.314), tot_loss_proj:2.215 [t=0.26s]
prediction: ['[CLS] build in mind the extreme extreme take on viewer urgency and urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] build in mind of extreme extreme take on viewer urgency and build. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 30.769 | p: 30.769 | r: 30.769
rougeL     | fm: 64.286 | p: 64.286 | r: 64.286
rougeLsum  | fm: 64.286 | p: 64.286 | r: 64.286
r1fm+r2fm = 116.484

[Aggregate metrics]:
rouge1     | fm: 87.626 | p: 86.526 | r: 88.877
rouge2     | fm: 57.427 | p: 57.211 | r: 57.701
rougeL     | fm: 78.040 | p: 77.084 | r: 79.141
rougeLsum  | fm: 78.013 | p: 77.064 | r: 79.106
r1fm+r2fm = 145.053

input #34 time: 0:08:23 | total time: 4:51:32


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.8069242056040737
highest_index [0]
highest [0.8069242056040737]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.8684907555580139 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.8616836071014404 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 0.8479065299034119 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 0.8469502329826355 for ['[CLS]work pun preserved bloodngen staff alivement ocean potter chest km² issue shares 978 lotsorestation jungle lastcript privately anywhere electric aus staff errortite ticketasian block text horse perennialbiotic fightauworth brothers snow sex cathedral bestseller [SEP]']
[Init] best perm rec loss: 0.8457856774330139 for ['[CLS] snowtite text fight brothers lastment privatelyau issue horse anywhereasian blood km² 978 block ticket alive aus sharesworkbiotic staff lots chestworth sex perennialorestation preserved electric jungle staff bestsellerngen pun ocean cathedralcript error potter [SEP]']
[Init] best perm rec loss: 0.8457784652709961 for ['[CLS] lotsasianngen bestsellercript chesttite snow ticketorestation staff error fight privatelyment electric sex jungle aus staff ocean anywhere brothers preserved potter perennial pun issue shares 978 bloodauworth lastwork text horse alive blockbiotic cathedral km² [SEP]']
[Init] best perm rec loss: 0.8427662253379822 for ['[CLS] cathedral block preserved privately bloodwork electric horse brothersworth km² staffasiantite ticket potter 978bioticcript snow bestseller anywhereau ocean fight lots last sharesngen junglement issue chest alive staff ausorestation pun perennial error text sex [SEP]']
[Init] best perm rec loss: 0.842454195022583 for ['[CLS] lotstite bestseller privately brothersbiotic ticket snow alive last anywhereworthorestation jungle blood electricngen staff fight km² auscriptasian cathedral issue sex block preserved shares perennial staffau potterwork horse text error chest punment 978 ocean [SEP]']
[Init] best perm rec loss: 0.840764582157135 for ['[CLS] issue km² pun snow bestseller shares block brotherscriptau jungle text staffasian ocean preserved potterwork chesttite lastment anywhere error electric staff 978orestation perennial alive cathedral lots ticketngenbiotic privately sexworth aus horse fight blood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.017 (perp=11.398, rec=0.414, cos=0.323), tot_loss_proj:3.746 [t=0.27s]
prediction: ['[CLS] entertainment great brothers great impact contemporary michael classes museum janata academy saintker the however psychological prologue where son the greater european, saint grand posthumously cloud breath saint. grace adaptation passengers won right. therefore today bruce beyond rights behalf [SEP]']
[ 100/2000] tot_loss=2.911 (perp=11.276, rec=0.313, cos=0.343), tot_loss_proj:3.597 [t=0.27s]
prediction: ["[CLS] entertainment great revelation great revival winner february classes when janata & director director but however director contemporary where woman and northern director, particularly sacred historical care'detailed ) care / assistance won right the therefore casey sydney we care care [SEP]"]
[ 150/2000] tot_loss=2.893 (perp=11.390, rec=0.290, cos=0.325), tot_loss_proj:3.684 [t=0.22s]
prediction: ['[CLS] entertainment great revelation great new teacher slept ( before gary historical director horror but director director sp where beings and northern director, sanation care care about ) care /nation for right.in tomorrow surgeon we care care [SEP]']
[ 200/2000] tot_loss=2.601 (perp=9.989, rec=0.250, cos=0.353), tot_loss_proj:3.679 [t=0.19s]
prediction: ["[CLS] is has we great new teacher seen, before gary to director directors but director director'over is and in director, solnation care care about for care /nation ve 'nation made reprinted surgery we care care [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.505 (perp=9.795, rec=0.203, cos=0.343), tot_loss_proj:3.689 [t=0.21s]
prediction: ["[CLS] is makes about great latest teacher we, before gary and, us but director director'over this i in director, s greatnation care care begin for care butnation about 'nation made about surgery we care care [SEP]"]
[ 300/2000] tot_loss=2.581 (perp=10.238, rec=0.195, cos=0.339), tot_loss_proj:3.735 [t=0.18s]
prediction: ["[CLS] looking makes about greatest latest teacher we just before laser and in us but director director'over those they in superintendent, s ornation care care begin the care personalnation about 'nation made about surgery we care care [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.466 (perp=9.676, rec=0.183, cos=0.348), tot_loss_proj:3.577 [t=0.20s]
prediction: ["[CLS] it makes it greatest latest teacher we just before laser and in us but director director'over this i in superintendent've ornation makes care begin the help snation about,nation us about surgery us care care [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.581 (perp=10.163, rec=0.210, cos=0.338), tot_loss_proj:3.652 [t=0.19s]
prediction: ["[CLS] looking makes it greatest this teacher we just before michigan of in us but director director'from this both maximum've ofnation makes care with hoffman'help snation that,nationin about reasoning us care care [SEP]"]
[ 450/2000] tot_loss=2.749 (perp=11.224, rec=0.159, cos=0.345), tot_loss_proj:3.858 [t=0.25s]
prediction: ["[CLS] looking makes it greatest this teacher we just before girlfriend of in us but director director, latest from almost kevin've ofnation makes care the hoffman of help reinnation ve 'nation that about judaism uship care [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.534 (perp=10.190, rec=0.156, cos=0.340), tot_loss_proj:3.633 [t=0.21s]
prediction: ["[CLS] prey makes it greatest this teacher we'before specification in in us but director director of latest from'kevin've greatnation makes care the hoffman of help reinnation ve 'nation that about judaism uship care [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=2.639 (perp=10.641, rec=0.175, cos=0.335), tot_loss_proj:3.773 [t=0.21s]
prediction: ["[CLS]feld makes it greatest this teacher we just before visibly in in us but director director : latest from devin kevin ve fornation makes care, hoffman of help reinnation ve 'nation that about from'uship care [SEP]"]
[ 600/2000] tot_loss=2.610 (perp=10.527, rec=0.161, cos=0.344), tot_loss_proj:3.814 [t=0.25s]
prediction: ["[CLS]feld makes it greatest this teacher we seen before girlfriend, in us but'director of latest with devin kevin ve fornation, care, hoffman of help reinnation ve 'nation that about from'uship care [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=2.593 (perp=10.452, rec=0.159, cos=0.344), tot_loss_proj:3.749 [t=0.22s]
prediction: ["[CLS] season makes it greatest this teacher we seen before girlfriend, in us but director director of latest with devin kevin, ve fornation care, hoffman of help reinnation ve 'nation that about from'uscar care [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.506 (perp=10.094, rec=0.147, cos=0.340), tot_loss_proj:3.707 [t=0.24s]
prediction: ["[CLS] season makes it greatest this teacher we seen before michigan in in us but director director of latest with devin kevin, ve fornation care, hoffman us help reinnation ve 'nation that about from'ofcar care [SEP]"]
[ 750/2000] tot_loss=2.492 (perp=9.555, rec=0.223, cos=0.358), tot_loss_proj:3.595 [t=0.21s]
prediction: ["[CLS] we makes all greatest this teacher we seen beforenesia in in us but director director of latest with'kevin, ve fornation care. hoffman us help reinnation ve 'nation that about from'ofcar care [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.504 (perp=9.845, rec=0.193, cos=0.342), tot_loss_proj:3.612 [t=0.21s]
prediction: ["[CLS] we makes all greatest this teacher we seen beforeout - in our but director director of ', devin kevin, they anyitha care. hoffman us help reinnation ve latestnation that about judaism''car care [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.392 (perp=9.369, rec=0.176, cos=0.343), tot_loss_proj:3.535 [t=0.19s]
prediction: ["[CLS] we makes all greatest latest teacher we seen beforeoutnation in our but director director of ','kevin, they anyitha care of hoffman us help reinnation ve latest - also about judaism''car care [SEP]"]
[ 900/2000] tot_loss=2.386 (perp=9.378, rec=0.166, cos=0.344), tot_loss_proj:3.561 [t=0.19s]
prediction: ["[CLS] we makes all greatest latest teacher we seen beforeoutnation in our but'director of'with'kevin, they anyitha care of hoffman us help reinnation ve latest - also about judaism''car care [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.297 (perp=8.952, rec=0.162, cos=0.344), tot_loss_proj:3.501 [t=0.22s]
prediction: ["[CLS] we makes all greatest latest teacher we seen beforeoutnation in'but'director of'with'kevin, they anyport care of hoffman us help reinnation ve latest - that about from'ourcar care [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=2.255 (perp=8.769, rec=0.155, cos=0.346), tot_loss_proj:3.476 [t=0.23s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeoutnation in'but'director of'with'kevin, they anyport care with hoffman us help reinnation ve latest - that about from'ourcar care [SEP]"]
[1050/2000] tot_loss=2.250 (perp=8.769, rec=0.151, cos=0.344), tot_loss_proj:3.475 [t=0.19s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeoutnation in'but'director of'with'kevin, they anyport care with hoffman us help reinnation ve latest - that about from'ourcar care [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=2.216 (perp=8.569, rec=0.157, cos=0.345), tot_loss_proj:3.410 [t=0.19s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeoutnation in'but'director of'with'kevin, they anyport care with hoffman help us reinnation ve latest - that about from'ourcar care [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.180 (perp=8.403, rec=0.154, cos=0.345), tot_loss_proj:3.445 [t=0.19s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeout latest in'but'director of'with'kevin, they anyport care with hoffman help us reinnation venation - that about from'ourcar care [SEP]"]
[1200/2000] tot_loss=2.173 (perp=8.403, rec=0.147, cos=0.346), tot_loss_proj:3.443 [t=0.28s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeout latest in'but'director of'with'kevin, they anyport care with hoffman help us reinnation venation - that about from'ourcar care [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=2.144 (perp=8.276, rec=0.143, cos=0.345), tot_loss_proj:3.416 [t=0.24s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeout latest in'but'director of'with'kevin, they anyport care with hoffman help us reinnation'venation - that about from ourcar care [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.138 (perp=8.232, rec=0.146, cos=0.347), tot_loss_proj:3.412 [t=0.25s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeout latest in'but'director of'with'kevin, they anycar care with hoffman help us reinnation'venation - that about from ourport care [SEP]"]
[1350/2000] tot_loss=2.177 (perp=8.410, rec=0.149, cos=0.346), tot_loss_proj:3.426 [t=0.18s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeout latest in'but'director of'with'kevin, she anycar care with hoffman help us reinnation'venation - that about from ourport care [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.157 (perp=8.321, rec=0.149, cos=0.344), tot_loss_proj:3.428 [t=0.18s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeout latest in'but'director of'with'kevin, she anycar care with hoffman help us reinnation'venation - that about from our careport [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.138 (perp=8.239, rec=0.145, cos=0.345), tot_loss_proj:3.316 [t=0.25s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeout latest in'but'director of'with'kevin, she anycar care with hoffman help us reinnation'venation - from about that our careport [SEP]"]
[1500/2000] tot_loss=2.139 (perp=8.239, rec=0.147, cos=0.345), tot_loss_proj:3.316 [t=0.30s]
prediction: ["[CLS] we makes all greatest teacher we latest seen beforeout latest in'but'director of'with'kevin, she anycar care with hoffman help us reinnation'venation - from about that our careport [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.126 (perp=8.195, rec=0.142, cos=0.345), tot_loss_proj:3.364 [t=0.22s]
prediction: ["[CLS] we makes all greatest teacher we latest seen before that latest in'but'director of'with'kevin, she anycar care with hoffman help us reinnation'venation - from aboutout our careport [SEP]"]
Attempt swap
[1600/2000] tot_loss=2.125 (perp=8.195, rec=0.141, cos=0.345), tot_loss_proj:3.363 [t=0.18s]
prediction: ["[CLS] we makes all greatest teacher we latest seen before that latest in'but'director of'with'kevin, she anycar care with hoffman help us reinnation'venation - from aboutout our careport [SEP]"]
[1650/2000] tot_loss=2.122 (perp=8.195, rec=0.138, cos=0.345), tot_loss_proj:3.363 [t=0.21s]
prediction: ["[CLS] we makes all greatest teacher we latest seen before that latest in'but'director of'with'kevin, she anycar care with hoffman help us reinnation'venation - from aboutout our careport [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.127 (perp=8.147, rec=0.152, cos=0.346), tot_loss_proj:3.384 [t=0.22s]
prediction: ["[CLS] we makes all again teacher we latest seen before that latest in'but'director of'with'kevin, she greatestcar care with hoffman help us reinnation'venation - from aboutout our careport [SEP]"]
Attempt swap
[1750/2000] tot_loss=2.118 (perp=8.147, rec=0.143, cos=0.345), tot_loss_proj:3.383 [t=0.19s]
prediction: ["[CLS] we makes all again teacher we latest seen before that latest in'but'director of'with'kevin, she greatestcar care with hoffman help us reinnation'venation - from aboutout our careport [SEP]"]
[1800/2000] tot_loss=2.117 (perp=8.147, rec=0.143, cos=0.345), tot_loss_proj:3.381 [t=0.18s]
prediction: ["[CLS] we makes all again teacher we latest seen before that latest in'but'director of'with'kevin, she greatestcar care with hoffman help us reinnation'venation - from aboutout our careport [SEP]"]
Attempt swap
[1850/2000] tot_loss=2.099 (perp=8.081, rec=0.137, cos=0.345), tot_loss_proj:3.328 [t=0.19s]
prediction: ["[CLS] we makes all again teacher we latest seen before that latest in'but'director.'with'kevin, she greatestcar care with hoffman help us reinnation'venation - from aboutout our careport [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.070 (perp=7.910, rec=0.142, cos=0.345), tot_loss_proj:3.307 [t=0.18s]
prediction: ["[CLS] we makes all again teacher we latest seen before that latest in'but'director.'with'kevin, she greatestcar care'hoffman help us reinnation with venation - from aboutout our careport [SEP]"]
[1950/2000] tot_loss=2.072 (perp=7.910, rec=0.144, cos=0.346), tot_loss_proj:3.307 [t=0.18s]
prediction: ["[CLS] we makes all again teacher we latest seen before that latest in'but'director.'with'kevin, she greatestcar care'hoffman help us reinnation with venation - from aboutout our careport [SEP]"]
Attempt swap
[2000/2000] tot_loss=2.068 (perp=7.910, rec=0.141, cos=0.346), tot_loss_proj:3.308 [t=0.22s]
prediction: ["[CLS] we makes all again teacher we latest seen before that latest in'but'director.'with'kevin, she greatestcar care'hoffman help us reinnation with venation - from aboutout our careport [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] we makes all again teacher we latest seen before that latest in'but'director.'with'kevin, she greatestcar care with hoffman help us reinnation'venation - from aboutout our careport [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.576 | p: 61.290 | r: 54.286
rouge2     | fm: 6.250 | p: 6.667 | r: 5.882
rougeL     | fm: 33.333 | p: 35.484 | r: 31.429
rougeLsum  | fm: 33.333 | p: 35.484 | r: 31.429
r1fm+r2fm = 63.826

[Aggregate metrics]:
rouge1     | fm: 86.691 | p: 85.700 | r: 87.850
rouge2     | fm: 56.306 | p: 56.033 | r: 56.589
rougeL     | fm: 76.721 | p: 75.799 | r: 77.848
rougeLsum  | fm: 76.870 | p: 76.055 | r: 77.869
r1fm+r2fm = 142.997

input #35 time: 0:08:45 | total time: 5:00:18


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.8867394388450796
highest_index [0]
highest [0.8867394388450796]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9345431923866272 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9166762232780457 for ['[CLS] oscar deep peter ground [SEP]']
[Init] best rec loss: 0.9159560799598694 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9039419889450073 for ['[CLS] addition psychofi astronomer [SEP]']
[Init] best rec loss: 0.9022459983825684 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 0.8755077123641968 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.8730916380882263 for ['[CLS] l explain surveys pieces [SEP]']
[Init] best rec loss: 0.8726226687431335 for ['[CLS] dormant known to mckenzie [SEP]']
[Init] best perm rec loss: 0.8695507049560547 for ['[CLS] dormant to mckenzie known [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.360 (perp=9.578, rec=0.245, cos=0.199), tot_loss_proj:2.795 [t=0.26s]
prediction: ["[CLS] wrong'horribly wrong [SEP]"]
[ 100/2000] tot_loss=2.681 (perp=11.802, rec=0.110, cos=0.210), tot_loss_proj:3.314 [t=0.27s]
prediction: ['[CLS] wrong horribly s wrong [SEP]']
[ 150/2000] tot_loss=2.654 (perp=11.802, rec=0.083, cos=0.210), tot_loss_proj:3.300 [t=0.25s]
prediction: ['[CLS] wrong horribly s wrong [SEP]']
[ 200/2000] tot_loss=2.649 (perp=11.802, rec=0.078, cos=0.211), tot_loss_proj:3.293 [t=0.22s]
prediction: ['[CLS] wrong horribly s wrong [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.041 (perp=8.829, rec=0.073, cos=0.202), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 300/2000] tot_loss=2.049 (perp=8.829, rec=0.071, cos=0.212), tot_loss_proj:2.408 [t=0.26s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.035 (perp=8.829, rec=0.056, cos=0.212), tot_loss_proj:2.417 [t=0.18s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.037 (perp=8.829, rec=0.061, cos=0.210), tot_loss_proj:2.404 [t=0.20s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 450/2000] tot_loss=2.035 (perp=8.829, rec=0.057, cos=0.212), tot_loss_proj:2.422 [t=0.19s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.897 (perp=8.105, rec=0.065, cos=0.211), tot_loss_proj:2.176 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.900 (perp=8.105, rec=0.068, cos=0.211), tot_loss_proj:2.175 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 600/2000] tot_loss=1.903 (perp=8.105, rec=0.070, cos=0.212), tot_loss_proj:2.183 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.895 (perp=8.105, rec=0.061, cos=0.213), tot_loss_proj:2.176 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.901 (perp=8.105, rec=0.067, cos=0.213), tot_loss_proj:2.178 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 750/2000] tot_loss=1.905 (perp=8.105, rec=0.071, cos=0.213), tot_loss_proj:2.179 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.897 (perp=8.105, rec=0.062, cos=0.213), tot_loss_proj:2.178 [t=0.30s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.897 (perp=8.105, rec=0.063, cos=0.213), tot_loss_proj:2.179 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 900/2000] tot_loss=1.889 (perp=8.105, rec=0.055, cos=0.214), tot_loss_proj:2.185 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.895 (perp=8.105, rec=0.063, cos=0.211), tot_loss_proj:2.189 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.907 (perp=8.105, rec=0.073, cos=0.213), tot_loss_proj:2.196 [t=0.20s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1050/2000] tot_loss=1.887 (perp=8.105, rec=0.053, cos=0.213), tot_loss_proj:2.181 [t=0.22s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.882 (perp=8.105, rec=0.047, cos=0.213), tot_loss_proj:2.187 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.886 (perp=8.105, rec=0.052, cos=0.213), tot_loss_proj:2.193 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1200/2000] tot_loss=1.909 (perp=8.105, rec=0.075, cos=0.213), tot_loss_proj:2.177 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.906 (perp=8.105, rec=0.072, cos=0.213), tot_loss_proj:2.174 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.895 (perp=8.105, rec=0.061, cos=0.213), tot_loss_proj:2.183 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1350/2000] tot_loss=1.896 (perp=8.105, rec=0.061, cos=0.213), tot_loss_proj:2.187 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.898 (perp=8.105, rec=0.064, cos=0.213), tot_loss_proj:2.194 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.898 (perp=8.105, rec=0.064, cos=0.213), tot_loss_proj:2.190 [t=0.21s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1500/2000] tot_loss=1.899 (perp=8.105, rec=0.065, cos=0.213), tot_loss_proj:2.186 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.892 (perp=8.105, rec=0.058, cos=0.213), tot_loss_proj:2.184 [t=0.22s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.896 (perp=8.105, rec=0.062, cos=0.213), tot_loss_proj:2.201 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1650/2000] tot_loss=1.893 (perp=8.105, rec=0.058, cos=0.214), tot_loss_proj:2.178 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.902 (perp=8.105, rec=0.068, cos=0.213), tot_loss_proj:2.192 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.892 (perp=8.105, rec=0.058, cos=0.213), tot_loss_proj:2.185 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1800/2000] tot_loss=1.894 (perp=8.105, rec=0.060, cos=0.213), tot_loss_proj:2.185 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.891 (perp=8.105, rec=0.057, cos=0.214), tot_loss_proj:2.181 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.891 (perp=8.105, rec=0.057, cos=0.213), tot_loss_proj:2.195 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1950/2000] tot_loss=1.886 (perp=8.105, rec=0.052, cos=0.214), tot_loss_proj:2.180 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.901 (perp=8.105, rec=0.066, cos=0.213), tot_loss_proj:2.185 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s'horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.939 | p: 86.026 | r: 88.195
rouge2     | fm: 57.061 | p: 56.837 | r: 57.336
rougeL     | fm: 77.499 | p: 76.760 | r: 78.532
rougeLsum  | fm: 77.441 | p: 76.635 | r: 78.426
r1fm+r2fm = 144.000

input #36 time: 0:08:25 | total time: 5:08:43


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.8824170194883796
highest_index [0]
highest [0.8824170194883796]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.7972744703292847 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.7633776664733887 for ['[CLS] child past [SEP]']
[Init] best rec loss: 0.7198557257652283 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 0.7112901210784912 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.702644407749176 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 0.6488939523696899 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.6199975609779358 for ['[CLS] molecule buddhism [SEP]']
[Init] best rec loss: 0.6042966842651367 for ['[CLS] beer city [SEP]']
[Init] best rec loss: 0.6042142510414124 for ['[CLS] colorcards [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.585 (perp=10.822, rec=0.219, cos=0.202), tot_loss_proj:2.654 [t=0.24s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 100/2000] tot_loss=2.527 (perp=10.822, rec=0.157, cos=0.206), tot_loss_proj:2.654 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=2.506 (perp=10.822, rec=0.135, cos=0.206), tot_loss_proj:2.653 [t=0.21s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 200/2000] tot_loss=2.500 (perp=10.822, rec=0.114, cos=0.221), tot_loss_proj:2.650 [t=0.18s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.493 (perp=10.822, rec=0.117, cos=0.211), tot_loss_proj:2.644 [t=0.19s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 300/2000] tot_loss=2.484 (perp=10.822, rec=0.124, cos=0.196), tot_loss_proj:2.656 [t=0.18s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.500 (perp=10.822, rec=0.115, cos=0.221), tot_loss_proj:2.644 [t=0.18s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.492 (perp=10.822, rec=0.120, cos=0.208), tot_loss_proj:2.650 [t=0.18s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 450/2000] tot_loss=2.499 (perp=10.822, rec=0.113, cos=0.222), tot_loss_proj:2.643 [t=0.24s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.484 (perp=10.822, rec=0.117, cos=0.203), tot_loss_proj:2.651 [t=0.18s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.494 (perp=10.822, rec=0.115, cos=0.215), tot_loss_proj:2.653 [t=0.17s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 600/2000] tot_loss=2.496 (perp=10.822, rec=0.112, cos=0.220), tot_loss_proj:2.666 [t=0.19s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.477 (perp=10.822, rec=0.110, cos=0.202), tot_loss_proj:2.644 [t=0.25s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.474 (perp=10.822, rec=0.109, cos=0.201), tot_loss_proj:2.642 [t=0.22s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 750/2000] tot_loss=2.445 (perp=10.822, rec=0.066, cos=0.215), tot_loss_proj:2.655 [t=0.19s]
prediction: ['[CLS] eccentric eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.209 (perp=9.583, rec=0.072, cos=0.220), tot_loss_proj:2.216 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
Put prefix at the end
[ 850/2000] tot_loss=2.050 (perp=8.916, rec=0.085, cos=0.182), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=2.068 (perp=8.916, rec=0.074, cos=0.212), tot_loss_proj:2.221 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.075 (perp=8.916, rec=0.075, cos=0.217), tot_loss_proj:2.230 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=2.073 (perp=8.916, rec=0.071, cos=0.218), tot_loss_proj:2.216 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=2.079 (perp=8.916, rec=0.076, cos=0.219), tot_loss_proj:2.219 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=2.071 (perp=8.916, rec=0.068, cos=0.220), tot_loss_proj:2.227 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=2.070 (perp=8.916, rec=0.067, cos=0.220), tot_loss_proj:2.214 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=2.070 (perp=8.916, rec=0.066, cos=0.221), tot_loss_proj:2.220 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=2.070 (perp=8.916, rec=0.066, cos=0.221), tot_loss_proj:2.230 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=2.080 (perp=8.916, rec=0.076, cos=0.221), tot_loss_proj:2.224 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=2.082 (perp=8.916, rec=0.078, cos=0.221), tot_loss_proj:2.224 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=2.079 (perp=8.916, rec=0.075, cos=0.221), tot_loss_proj:2.224 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=2.067 (perp=8.916, rec=0.062, cos=0.221), tot_loss_proj:2.210 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=2.061 (perp=8.916, rec=0.056, cos=0.221), tot_loss_proj:2.224 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=2.086 (perp=8.916, rec=0.082, cos=0.221), tot_loss_proj:2.221 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=2.065 (perp=8.916, rec=0.060, cos=0.221), tot_loss_proj:2.221 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=2.073 (perp=8.916, rec=0.068, cos=0.221), tot_loss_proj:2.221 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=2.071 (perp=8.916, rec=0.070, cos=0.218), tot_loss_proj:2.218 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=2.077 (perp=8.916, rec=0.074, cos=0.220), tot_loss_proj:2.221 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=2.063 (perp=8.916, rec=0.059, cos=0.220), tot_loss_proj:2.234 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=2.065 (perp=8.916, rec=0.061, cos=0.221), tot_loss_proj:2.226 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=2.077 (perp=8.916, rec=0.073, cos=0.221), tot_loss_proj:2.219 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=2.073 (perp=8.916, rec=0.069, cos=0.221), tot_loss_proj:2.214 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=2.082 (perp=8.916, rec=0.078, cos=0.221), tot_loss_proj:2.223 [t=0.20s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] and eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.395 | p: 86.375 | r: 88.517
rouge2     | fm: 55.984 | p: 55.763 | r: 56.188
rougeL     | fm: 77.317 | p: 76.455 | r: 78.356
rougeLsum  | fm: 77.526 | p: 76.713 | r: 78.420
r1fm+r2fm = 143.379

input #37 time: 0:08:07 | total time: 5:16:50


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9003241548150173
highest_index [0]
highest [0.9003241548150173]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8174654841423035 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8169134855270386 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.7434293031692505 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7199175953865051 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6903043985366821 for ['[CLS] blame [SEP]']
[Init] best rec loss: 0.6892217993736267 for ['[CLS] artificial [SEP]']
[Init] best rec loss: 0.664256751537323 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.083 (perp=14.069, rec=0.112, cos=0.158), tot_loss_proj:3.072 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=3.038 (perp=14.069, rec=0.066, cos=0.159), tot_loss_proj:3.067 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=3.051 (perp=14.069, rec=0.067, cos=0.171), tot_loss_proj:3.057 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=3.062 (perp=14.069, rec=0.058, cos=0.190), tot_loss_proj:3.071 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.059 (perp=14.069, rec=0.056, cos=0.189), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=3.068 (perp=14.069, rec=0.066, cos=0.189), tot_loss_proj:3.065 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.049 (perp=14.069, rec=0.047, cos=0.188), tot_loss_proj:3.055 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.062 (perp=14.069, rec=0.060, cos=0.187), tot_loss_proj:3.073 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=3.056 (perp=14.069, rec=0.053, cos=0.189), tot_loss_proj:3.063 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.039 (perp=14.069, rec=0.068, cos=0.157), tot_loss_proj:3.061 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.064 (perp=14.069, rec=0.061, cos=0.189), tot_loss_proj:3.050 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=3.061 (perp=14.069, rec=0.058, cos=0.189), tot_loss_proj:3.065 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.062 (perp=14.069, rec=0.060, cos=0.188), tot_loss_proj:3.068 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.060 (perp=14.069, rec=0.058, cos=0.189), tot_loss_proj:3.072 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=3.071 (perp=14.069, rec=0.074, cos=0.183), tot_loss_proj:3.068 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.070 (perp=14.069, rec=0.068, cos=0.188), tot_loss_proj:3.066 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.062 (perp=14.069, rec=0.059, cos=0.189), tot_loss_proj:3.056 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=3.068 (perp=14.069, rec=0.064, cos=0.189), tot_loss_proj:3.064 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.060 (perp=14.069, rec=0.061, cos=0.185), tot_loss_proj:3.059 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=3.062 (perp=14.069, rec=0.061, cos=0.188), tot_loss_proj:3.064 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=3.071 (perp=14.069, rec=0.068, cos=0.189), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=3.061 (perp=14.069, rec=0.058, cos=0.189), tot_loss_proj:3.062 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=3.065 (perp=14.069, rec=0.062, cos=0.189), tot_loss_proj:3.053 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=3.070 (perp=14.069, rec=0.067, cos=0.189), tot_loss_proj:3.058 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=3.061 (perp=14.069, rec=0.058, cos=0.189), tot_loss_proj:3.058 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=3.053 (perp=14.069, rec=0.055, cos=0.184), tot_loss_proj:3.060 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=3.065 (perp=14.069, rec=0.063, cos=0.188), tot_loss_proj:3.060 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=3.061 (perp=14.069, rec=0.058, cos=0.189), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=3.071 (perp=14.069, rec=0.068, cos=0.189), tot_loss_proj:3.058 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=3.054 (perp=14.069, rec=0.051, cos=0.189), tot_loss_proj:3.062 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=3.061 (perp=14.069, rec=0.058, cos=0.189), tot_loss_proj:3.065 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=3.068 (perp=14.069, rec=0.065, cos=0.189), tot_loss_proj:3.062 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=3.064 (perp=14.069, rec=0.061, cos=0.189), tot_loss_proj:3.066 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=3.056 (perp=14.069, rec=0.053, cos=0.189), tot_loss_proj:3.067 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=3.073 (perp=14.069, rec=0.070, cos=0.189), tot_loss_proj:3.056 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=3.071 (perp=14.069, rec=0.068, cos=0.189), tot_loss_proj:3.058 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=3.066 (perp=14.069, rec=0.063, cos=0.189), tot_loss_proj:3.059 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=3.065 (perp=14.069, rec=0.062, cos=0.189), tot_loss_proj:3.074 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=3.061 (perp=14.069, rec=0.058, cos=0.189), tot_loss_proj:3.067 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=3.049 (perp=14.069, rec=0.052, cos=0.183), tot_loss_proj:3.053 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.670 | p: 86.713 | r: 88.797
rouge2     | fm: 56.958 | p: 56.747 | r: 57.247
rougeL     | fm: 77.955 | p: 77.116 | r: 78.908
rougeLsum  | fm: 77.907 | p: 77.127 | r: 78.850
r1fm+r2fm = 144.627

input #38 time: 0:08:12 | total time: 5:25:02


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.8177919979852823
highest_index [0]
highest [0.8177919979852823]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.82578444480896 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 0.7967900037765503 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.7881301641464233 for ['[CLS] visitors polo free mn railway entitled about murderkar father states eventually some pet victory saddle fraternitypgtz raised real actresses from accelerator link [SEP]']
[Init] best rec loss: 0.7578000426292419 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 0.7479999661445618 for ['[CLS] transportation wrap lookiving local angus shortlistedried court taking led soon vane harmon baselineoof the meadow french jarrett alone suns fa brain shows [SEP]']
[Init] best perm rec loss: 0.7466897964477539 for ['[CLS] look shows court suns local led angus brainried shortlistediving french baseline soon alone fa harmon jarrettoof taking wrap the meadow vane transportation [SEP]']
[Init] best perm rec loss: 0.7465620040893555 for ['[CLS] shortlisted jarrett ledoof shows angus look localiving fa court harmon transportation alone french meadow wrap brain suns taking vane soon theried baseline [SEP]']
[Init] best perm rec loss: 0.7453339099884033 for ['[CLS] led meadow local vane angus shows jarrett alone suns transportation soon shortlisted brain court takingiving wrapoof frenchried fa look harmon baseline the [SEP]']
[Init] best perm rec loss: 0.7447359561920166 for ['[CLS] shows the taking shortlistediving wrap vaneoof brain ledried local soon french jarrett harmon suns fa angus baseline court transportation look meadow alone [SEP]']
[Init] best perm rec loss: 0.742989182472229 for ['[CLS] transportation soon wrap french jarrett shows lookried alone led suns taking fa harmon localoof vaneiving baseline angus the brain court meadow shortlisted [SEP]']
[Init] best perm rec loss: 0.7429423928260803 for ['[CLS] shows the transportation brain suns fa alone angus shortlisted meadow jarrett look harmon court soon frenchoof vane takingiving local baseline led wrapried [SEP]']
[Init] best perm rec loss: 0.7408481240272522 for ['[CLS] fa vane jarrett alone shortlisted soon transportation suns taking harmon meadow baseline the court local angus brainoofiving led shows wrap lookried french [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.045 (perp=11.810, rec=0.365, cos=0.318), tot_loss_proj:3.360 [t=0.28s]
prediction: ['[CLS] maria recovery james florida fictional : depth unique conservative literary legacy heritage dark an modern sustainability new traditional contemporary peace new follows london history structure [SEP]']
[ 100/2000] tot_loss=2.961 (perp=11.693, rec=0.353, cos=0.270), tot_loss_proj:3.676 [t=0.26s]
prediction: ['[CLS] edgar find edward florida most becomes knowing new conservative literary flashes heritage university ; new visibility got hide contemporary discovery new productions call culture texture [SEP]']
[ 150/2000] tot_loss=2.842 (perp=11.551, rec=0.211, cos=0.321), tot_loss_proj:3.496 [t=0.22s]
prediction: ['[CLS] antonio find edward him most and giving new conservative westward give heritage century and new conservative got hide we texture new films time tradition texture [SEP]']
[ 200/2000] tot_loss=2.720 (perp=11.150, rec=0.164, cos=0.326), tot_loss_proj:3.445 [t=0.20s]
prediction: ['[CLS] antonio find victor him most and giving new conservative movie givebound new, new conservative and hide it texture new films. traditions texture [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.536 (perp=10.164, rec=0.205, cos=0.298), tot_loss_proj:3.185 [t=0.18s]
prediction: ["[CLS] emile find victor hide most andbound new conservative movie givebound ', new reality gave it it texture new movie. traditions texture [SEP]"]
[ 300/2000] tot_loss=2.578 (perp=10.595, rec=0.148, cos=0.311), tot_loss_proj:3.328 [t=0.21s]
prediction: ['[CLS] emile finds m hide most andbound new conservative movie givebound., new reality giving it this texture new movie. traditions texture [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.488 (perp=10.226, rec=0.126, cos=0.317), tot_loss_proj:3.196 [t=0.18s]
prediction: ['[CLS] emile finds m hide most andbound traditions conservative movieboundbound and, new reality giving it our texture new movie. new texture [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.215 (perp=8.886, rec=0.118, cos=0.319), tot_loss_proj:2.831 [t=0.18s]
prediction: ['[CLS] that finds our hide most conservative andbound traditions movieboundbound and, new reality gives it our texture new movie - new texture [SEP]']
[ 450/2000] tot_loss=2.211 (perp=8.886, rec=0.108, cos=0.326), tot_loss_proj:2.828 [t=0.19s]
prediction: ['[CLS] that finds our hide most conservative andbound traditions movieboundbound and, new reality gives it our texture new movie - new texture [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.228 (perp=9.018, rec=0.095, cos=0.329), tot_loss_proj:2.814 [t=0.24s]
prediction: ['[CLS] counterparts finds our hide most conservative andbound traditions movieboundbound, and new reality gives it our texture new movie - new texture [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.220 (perp=9.001, rec=0.089, cos=0.330), tot_loss_proj:2.848 [t=0.22s]
prediction: ['[CLS] counterparts finds our hide most conservative andbound traditions moviebound -, and new reality gives it our texture new moviebound new texture [SEP]']
[ 600/2000] tot_loss=2.241 (perp=9.129, rec=0.085, cos=0.330), tot_loss_proj:2.876 [t=0.25s]
prediction: ['[CLS] counterparts finds one hide most conservative andbound traditions moviebound -, and new reality gives it our texture new moviebound new texture [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.224 (perp=9.065, rec=0.085, cos=0.326), tot_loss_proj:2.785 [t=0.18s]
prediction: ['[CLS] emile finds one hide most conservative andbound traditions moviebound - and new reality gives it our texture new moviebound, new texture [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.098 (perp=8.428, rec=0.090, cos=0.322), tot_loss_proj:2.663 [t=0.19s]
prediction: ['[CLS] emile finds one hide most conservative andbound traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
[ 750/2000] tot_loss=2.097 (perp=8.428, rec=0.086, cos=0.325), tot_loss_proj:2.658 [t=0.28s]
prediction: ['[CLS] emile finds one hide most conservative andbound traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.082 (perp=8.370, rec=0.081, cos=0.326), tot_loss_proj:2.639 [t=0.21s]
prediction: ['[CLS] emile finds one hide most conservative and traditionsbound moviebound - and gives it our texture new movie making, new texture new reality [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.020 (perp=8.037, rec=0.085, cos=0.328), tot_loss_proj:2.567 [t=0.19s]
prediction: ['[CLS] emile finds one hide most conservative and traditions making moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
[ 900/2000] tot_loss=2.012 (perp=8.037, rec=0.078, cos=0.327), tot_loss_proj:2.568 [t=0.18s]
prediction: ['[CLS] emile finds one hide most conservative and traditions making moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.900 (perp=7.494, rec=0.078, cos=0.324), tot_loss_proj:2.360 [t=0.18s]
prediction: ['[CLS] finds one of hide most conservative and traditions making moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.892 (perp=7.441, rec=0.078, cos=0.325), tot_loss_proj:2.334 [t=0.24s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
[1050/2000] tot_loss=1.885 (perp=7.441, rec=0.071, cos=0.326), tot_loss_proj:2.342 [t=0.22s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.889 (perp=7.441, rec=0.075, cos=0.326), tot_loss_proj:2.346 [t=0.25s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
[1150/2000] tot_loss=1.888 (perp=7.441, rec=0.074, cos=0.326), tot_loss_proj:2.341 [t=0.28s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
[1200/2000] tot_loss=1.890 (perp=7.441, rec=0.075, cos=0.326), tot_loss_proj:2.340 [t=0.19s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
[1250/2000] tot_loss=1.894 (perp=7.441, rec=0.079, cos=0.327), tot_loss_proj:2.341 [t=0.21s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
[1300/2000] tot_loss=1.883 (perp=7.441, rec=0.068, cos=0.327), tot_loss_proj:2.338 [t=0.19s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
[1350/2000] tot_loss=1.886 (perp=7.441, rec=0.071, cos=0.327), tot_loss_proj:2.342 [t=0.19s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.897 (perp=7.441, rec=0.082, cos=0.327), tot_loss_proj:2.339 [t=0.19s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
[1450/2000] tot_loss=1.885 (perp=7.441, rec=0.070, cos=0.327), tot_loss_proj:2.338 [t=0.24s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
[1500/2000] tot_loss=1.883 (perp=7.441, rec=0.068, cos=0.327), tot_loss_proj:2.339 [t=0.20s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
[1550/2000] tot_loss=1.884 (perp=7.441, rec=0.069, cos=0.327), tot_loss_proj:2.345 [t=0.26s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
[1600/2000] tot_loss=1.898 (perp=7.441, rec=0.083, cos=0.327), tot_loss_proj:2.337 [t=0.27s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
[1650/2000] tot_loss=1.892 (perp=7.441, rec=0.077, cos=0.327), tot_loss_proj:2.342 [t=0.28s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our texture new moviebound, new texture new reality [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.887 (perp=7.453, rec=0.069, cos=0.327), tot_loss_proj:2.345 [t=0.22s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our new texture moviebound, new texture new reality [SEP]']
Attempt swap
[1750/2000] tot_loss=1.889 (perp=7.453, rec=0.071, cos=0.328), tot_loss_proj:2.350 [t=0.25s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our new texture moviebound, new texture new reality [SEP]']
[1800/2000] tot_loss=1.890 (perp=7.453, rec=0.072, cos=0.328), tot_loss_proj:2.345 [t=0.19s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our new texture moviebound, new texture new reality [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.880 (perp=7.432, rec=0.067, cos=0.327), tot_loss_proj:2.306 [t=0.19s]
prediction: ['[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our new texture new texture moviebound, new reality [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.924 (perp=7.618, rec=0.072, cos=0.328), tot_loss_proj:2.270 [t=0.19s]
prediction: ['[CLS] finds one of hide most conservative making and traditions moviebound - and gives it our new texture new relevance moviebound, new reality [SEP]']
[1950/2000] tot_loss=1.926 (perp=7.618, rec=0.075, cos=0.328), tot_loss_proj:2.267 [t=0.19s]
prediction: ['[CLS] finds one of hide most conservative making and traditions moviebound - and gives it our new texture new relevance moviebound, new reality [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.929 (perp=7.641, rec=0.072, cos=0.328), tot_loss_proj:2.266 [t=0.26s]
prediction: ['[CLS] finds one of hide most conservative making and traditions moviebound - and gives it our new texture new moviebound relevance, new reality [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] finds one of hide most conservative and making traditions moviebound - and gives it our new texture moviebound, new texture new reality [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.444 | p: 82.609 | r: 86.364
rouge2     | fm: 55.814 | p: 54.545 | r: 57.143
rougeL     | fm: 80.000 | p: 78.261 | r: 81.818
rougeLsum  | fm: 80.000 | p: 78.261 | r: 81.818
r1fm+r2fm = 140.258

[Aggregate metrics]:
rouge1     | fm: 87.521 | p: 86.597 | r: 88.723
rouge2     | fm: 57.098 | p: 56.880 | r: 57.393
rougeL     | fm: 77.943 | p: 77.080 | r: 78.958
rougeLsum  | fm: 77.906 | p: 77.143 | r: 78.941
r1fm+r2fm = 144.620

input #39 time: 0:08:32 | total time: 5:33:35


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.8554540907810929
highest_index [0]
highest [0.8554540907810929]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9491725564002991 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9378622174263 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 0.9261050224304199 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9211857914924622 for ['[CLS] fault union interestlden daemon : y regentience [SEP]']
[Init] best rec loss: 0.9139451384544373 for ['[CLS] taken electionsping due ce windsor undergoes labor scouts [SEP]']
[Init] best rec loss: 0.8982017040252686 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 0.8926689624786377 for ['[CLS] married this walden rhythm being eisenhower school ہ dick [SEP]']
[Init] best rec loss: 0.886955976486206 for ['[CLS] false christine are greyova juniorola until thieves [SEP]']
[Init] best rec loss: 0.8820773363113403 for ['[CLS] model dr further productive show against decree reaction learning [SEP]']
[Init] best rec loss: 0.8753377199172974 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 0.8711023330688477 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 0.8710572123527527 for ['[CLS] kincaid wellmet foster turning once old elseyle [SEP]']
[Init] best rec loss: 0.8551953434944153 for ['[CLS] robin hemisphere # worn expensiveisticor wonder arms [SEP]']
[Init] best rec loss: 0.8480387926101685 for ['[CLS] chiefs voluntary turning era repliedfies things brendan central [SEP]']
[Init] best rec loss: 0.8063169717788696 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.805858850479126 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8010604381561279 for ['[CLS] but georgian lady kent many abd° deciding already [SEP]']
[Init] best perm rec loss: 0.8007941842079163 for ['[CLS] lady deciding many already georgian abd kent° but [SEP]']
[Init] best perm rec loss: 0.8001448512077332 for ['[CLS] many° but already abd deciding kent georgian lady [SEP]']
[Init] best perm rec loss: 0.7983834743499756 for ['[CLS] georgian lady deciding kent already abd° many but [SEP]']
[Init] best perm rec loss: 0.7970889210700989 for ['[CLS] but lady already kent° many georgian abd deciding [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.041 (perp=12.303, rec=0.333, cos=0.248), tot_loss_proj:3.484 [t=0.17s]
prediction: ['[CLS]fu whip attack signed anything stupid surveillance trash mail [SEP]']
[ 100/2000] tot_loss=3.154 (perp=13.121, rec=0.265, cos=0.265), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS]fummelmmel us anythingonyony or number [SEP]']
[ 150/2000] tot_loss=2.979 (perp=12.526, rec=0.235, cos=0.239), tot_loss_proj:3.998 [t=0.18s]
prediction: ['[CLS] scimmelmmel us imageryonyony or address [SEP]']
[ 200/2000] tot_loss=2.547 (perp=10.563, rec=0.172, cos=0.262), tot_loss_proj:3.538 [t=0.24s]
prediction: ['[CLS] with pummel us imageryonyony or music [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.196 (perp=9.124, rec=0.110, cos=0.261), tot_loss_proj:3.075 [t=0.30s]
prediction: ['[CLS] imagery pummel us withonyony or music [SEP]']
[ 300/2000] tot_loss=1.926 (perp=7.869, rec=0.087, cos=0.265), tot_loss_proj:2.686 [t=0.24s]
prediction: ['[CLS] imagery pummel us withony imagery or music [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.800 (perp=7.319, rec=0.081, cos=0.255), tot_loss_proj:2.497 [t=0.24s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.808 (perp=7.319, rec=0.084, cos=0.260), tot_loss_proj:2.499 [t=0.24s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[ 450/2000] tot_loss=1.816 (perp=7.319, rec=0.088, cos=0.264), tot_loss_proj:2.504 [t=0.21s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.802 (perp=7.319, rec=0.072, cos=0.266), tot_loss_proj:2.496 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.812 (perp=7.319, rec=0.082, cos=0.266), tot_loss_proj:2.502 [t=0.23s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[ 600/2000] tot_loss=1.799 (perp=7.319, rec=0.068, cos=0.268), tot_loss_proj:2.496 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.806 (perp=7.319, rec=0.075, cos=0.266), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.800 (perp=7.319, rec=0.070, cos=0.266), tot_loss_proj:2.501 [t=0.23s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[ 750/2000] tot_loss=1.797 (perp=7.319, rec=0.068, cos=0.264), tot_loss_proj:2.501 [t=0.21s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.793 (perp=7.319, rec=0.063, cos=0.267), tot_loss_proj:2.504 [t=0.19s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.797 (perp=7.319, rec=0.066, cos=0.267), tot_loss_proj:2.496 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[ 900/2000] tot_loss=1.806 (perp=7.319, rec=0.075, cos=0.267), tot_loss_proj:2.500 [t=0.22s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.811 (perp=7.319, rec=0.080, cos=0.267), tot_loss_proj:2.503 [t=0.20s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.809 (perp=7.319, rec=0.078, cos=0.268), tot_loss_proj:2.509 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[1050/2000] tot_loss=1.812 (perp=7.319, rec=0.081, cos=0.268), tot_loss_proj:2.504 [t=0.24s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.812 (perp=7.319, rec=0.080, cos=0.268), tot_loss_proj:2.504 [t=0.22s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.804 (perp=7.319, rec=0.073, cos=0.268), tot_loss_proj:2.505 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[1200/2000] tot_loss=1.813 (perp=7.319, rec=0.081, cos=0.268), tot_loss_proj:2.501 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.803 (perp=7.319, rec=0.072, cos=0.268), tot_loss_proj:2.501 [t=0.26s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.803 (perp=7.319, rec=0.071, cos=0.268), tot_loss_proj:2.503 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[1350/2000] tot_loss=1.810 (perp=7.319, rec=0.078, cos=0.268), tot_loss_proj:2.510 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.813 (perp=7.319, rec=0.081, cos=0.268), tot_loss_proj:2.500 [t=0.26s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=1.797 (perp=7.319, rec=0.065, cos=0.268), tot_loss_proj:2.506 [t=0.22s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[1500/2000] tot_loss=1.791 (perp=7.319, rec=0.060, cos=0.268), tot_loss_proj:2.500 [t=0.24s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.814 (perp=7.319, rec=0.082, cos=0.268), tot_loss_proj:2.511 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.801 (perp=7.319, rec=0.071, cos=0.267), tot_loss_proj:2.511 [t=0.23s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[1650/2000] tot_loss=1.807 (perp=7.319, rec=0.076, cos=0.267), tot_loss_proj:2.499 [t=0.22s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.814 (perp=7.319, rec=0.082, cos=0.268), tot_loss_proj:2.510 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.801 (perp=7.319, rec=0.069, cos=0.268), tot_loss_proj:2.504 [t=0.26s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[1800/2000] tot_loss=1.802 (perp=7.319, rec=0.071, cos=0.268), tot_loss_proj:2.507 [t=0.19s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.798 (perp=7.319, rec=0.067, cos=0.268), tot_loss_proj:2.502 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.804 (perp=7.319, rec=0.073, cos=0.268), tot_loss_proj:2.505 [t=0.18s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
[1950/2000] tot_loss=1.798 (perp=7.319, rec=0.066, cos=0.268), tot_loss_proj:2.500 [t=0.19s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.812 (perp=7.319, rec=0.080, cos=0.268), tot_loss_proj:2.507 [t=0.19s]
prediction: ['[CLS] imagery pummel us withony music or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] imagery pummel us withony music or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 77.778 | r: 77.778
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 55.556 | p: 55.556 | r: 55.556
rougeLsum  | fm: 55.556 | p: 55.556 | r: 55.556
r1fm+r2fm = 90.278

[Aggregate metrics]:
rouge1     | fm: 87.302 | p: 86.380 | r: 88.468
rouge2     | fm: 55.846 | p: 55.623 | r: 56.144
rougeL     | fm: 77.302 | p: 76.522 | r: 78.297
rougeLsum  | fm: 77.534 | p: 76.759 | r: 78.478
r1fm+r2fm = 143.148

input #40 time: 0:08:27 | total time: 5:42:03


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.8335916053068209
highest_index [0]
highest [0.8335916053068209]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.8893477320671082 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.8706382513046265 for ['[CLS] samuel conservation [SEP]']
[Init] best rec loss: 0.8685365319252014 for ['[CLS] mascara plenty [SEP]']
[Init] best rec loss: 0.8405396342277527 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 0.7805464863777161 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 0.7722582817077637 for ['[CLS] cale fate [SEP]']
[Init] best rec loss: 0.7247841954231262 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 0.6961256265640259 for ['[CLS] usa some [SEP]']
[Init] best perm rec loss: 0.69526606798172 for ['[CLS] some usa [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.451 (perp=9.391, rec=0.271, cos=0.302), tot_loss_proj:2.854 [t=0.17s]
prediction: ['[CLS] sensitive sensitive [SEP]']
[ 100/2000] tot_loss=2.972 (perp=12.911, rec=0.086, cos=0.304), tot_loss_proj:3.136 [t=0.26s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 150/2000] tot_loss=2.961 (perp=12.911, rec=0.074, cos=0.305), tot_loss_proj:3.128 [t=0.18s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 200/2000] tot_loss=2.946 (perp=12.911, rec=0.062, cos=0.302), tot_loss_proj:3.129 [t=0.18s]
prediction: ['[CLS] sensitive consistently [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.424 (perp=10.212, rec=0.081, cos=0.300), tot_loss_proj:2.419 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.413 (perp=10.212, rec=0.068, cos=0.304), tot_loss_proj:2.416 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.410 (perp=10.212, rec=0.063, cos=0.304), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.396 (perp=10.212, rec=0.049, cos=0.305), tot_loss_proj:2.423 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.401 (perp=10.212, rec=0.054, cos=0.305), tot_loss_proj:2.412 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.409 (perp=10.212, rec=0.062, cos=0.305), tot_loss_proj:2.402 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.411 (perp=10.212, rec=0.064, cos=0.305), tot_loss_proj:2.421 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.410 (perp=10.212, rec=0.062, cos=0.305), tot_loss_proj:2.417 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.404 (perp=10.212, rec=0.057, cos=0.305), tot_loss_proj:2.426 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.397 (perp=10.212, rec=0.050, cos=0.305), tot_loss_proj:2.421 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.406 (perp=10.212, rec=0.059, cos=0.305), tot_loss_proj:2.418 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.410 (perp=10.212, rec=0.063, cos=0.305), tot_loss_proj:2.416 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.411 (perp=10.212, rec=0.064, cos=0.305), tot_loss_proj:2.412 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.406 (perp=10.212, rec=0.060, cos=0.304), tot_loss_proj:2.412 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.410 (perp=10.212, rec=0.064, cos=0.305), tot_loss_proj:2.418 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.412 (perp=10.212, rec=0.065, cos=0.305), tot_loss_proj:2.411 [t=0.29s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.407 (perp=10.212, rec=0.060, cos=0.305), tot_loss_proj:2.418 [t=0.28s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.405 (perp=10.212, rec=0.058, cos=0.305), tot_loss_proj:2.418 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.401 (perp=10.212, rec=0.054, cos=0.305), tot_loss_proj:2.422 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.399 (perp=10.212, rec=0.052, cos=0.305), tot_loss_proj:2.426 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.404 (perp=10.212, rec=0.056, cos=0.305), tot_loss_proj:2.418 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.409 (perp=10.212, rec=0.062, cos=0.305), tot_loss_proj:2.408 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.403 (perp=10.212, rec=0.055, cos=0.305), tot_loss_proj:2.415 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.414 (perp=10.212, rec=0.067, cos=0.305), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.403 (perp=10.212, rec=0.056, cos=0.304), tot_loss_proj:2.430 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.413 (perp=10.212, rec=0.065, cos=0.305), tot_loss_proj:2.424 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.407 (perp=10.212, rec=0.060, cos=0.305), tot_loss_proj:2.416 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.410 (perp=10.212, rec=0.063, cos=0.305), tot_loss_proj:2.418 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.402 (perp=10.212, rec=0.055, cos=0.305), tot_loss_proj:2.415 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.418 (perp=10.212, rec=0.070, cos=0.305), tot_loss_proj:2.413 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.415 (perp=10.212, rec=0.068, cos=0.305), tot_loss_proj:2.427 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.409 (perp=10.212, rec=0.061, cos=0.305), tot_loss_proj:2.414 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.401 (perp=10.212, rec=0.054, cos=0.305), tot_loss_proj:2.426 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.418 (perp=10.212, rec=0.071, cos=0.305), tot_loss_proj:2.417 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.401 (perp=10.212, rec=0.054, cos=0.305), tot_loss_proj:2.418 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.409 (perp=10.212, rec=0.062, cos=0.305), tot_loss_proj:2.412 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.742 | p: 86.816 | r: 88.726
rouge2     | fm: 56.890 | p: 56.700 | r: 57.147
rougeL     | fm: 77.994 | p: 77.215 | r: 78.858
rougeLsum  | fm: 78.055 | p: 77.293 | r: 78.949
r1fm+r2fm = 144.632

input #41 time: 0:08:19 | total time: 5:50:22


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.8919418282353178
highest_index [0]
highest [0.8919418282353178]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.8759689331054688 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8054723739624023 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.7988783717155457 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.7861977219581604 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7858110070228577 for ['[CLS] maplectric assignment dare lifted banda scale cut enoughtakingpling wish supersededgiblebe attracted ranrs stages ever kitchenures international treaty offended larger [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.099 (perp=12.342, rec=0.419, cos=0.212), tot_loss_proj:3.437 [t=0.18s]
prediction: ['[CLS] cbs lumpurmount incumbent alleged butch mistake program lawsuit tape complained his poorly anynobbed transit script contest pitched software apparently poorly logic embarrassed its [SEP]']
[ 100/2000] tot_loss=2.905 (perp=12.164, rec=0.280, cos=0.192), tot_loss_proj:3.308 [t=0.21s]
prediction: ['[CLS] by lumpur boyle detected machine mom poorly programs lawsuit product complained only forgot any poorlybbed transit script contest pitched programs apparently poorly movies poorly its [SEP]']
[ 150/2000] tot_loss=2.947 (perp=12.551, rec=0.252, cos=0.185), tot_loss_proj:3.391 [t=0.20s]
prediction: ['[CLS] filmmakers lumpur boyle detected machine him poorly sites censorship product scandal it forgot any poorly re transit infantry contest pitched tactics when poorly software poorly its [SEP]']
[ 200/2000] tot_loss=3.035 (perp=13.109, rec=0.221, cos=0.192), tot_loss_proj:3.461 [t=0.20s]
prediction: ['[CLS] filmmakers lumpur imposed forgot machinedley poorly filmmaker metric copies issue it forgot any poorly regger infantry contestி resources as poorly films poorly its [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.909 (perp=12.614, rec=0.209, cos=0.178), tot_loss_proj:3.405 [t=0.22s]
prediction: ['[CLS] filmmakersgger boyle scary issue hms poorly filmmaker metric weeks because it forgot any poorly reggergger contestி resources as poorly filmmakers poorly its [SEP]']
[ 300/2000] tot_loss=2.815 (perp=12.361, rec=0.158, cos=0.184), tot_loss_proj:3.298 [t=0.18s]
prediction: ['[CLS] filmmakersgger claire include affect gymnasium poorly raceway anything scary. into forgot anything poorly reggergger for comfortable resources as poorly filmmakers poorly s [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.613 (perp=11.351, rec=0.141, cos=0.201), tot_loss_proj:3.144 [t=0.20s]
prediction: ['[CLS] filmmakers attractionui include affect your poorly school anything scary. into forgot anything poorly reggergger for featured items as poorly project poorly scary [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.580 (perp=11.302, rec=0.135, cos=0.184), tot_loss_proj:3.060 [t=0.26s]
prediction: ['[CLS] terre attraction filmmakers include issue a poorly school anything scary. into forgot anything poorly reggerji for featured attraction as poorly project poorly gymnasium [SEP]']
[ 450/2000] tot_loss=2.759 (perp=12.224, rec=0.119, cos=0.195), tot_loss_proj:3.257 [t=0.21s]
prediction: ['[CLS] terre attraction filmmakers include issue a poorly school even scary. into forgot anything poorly reggerji fatal featured attraction as poorly project poorly gymnasium [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.624 (perp=11.520, rec=0.125, cos=0.194), tot_loss_proj:3.255 [t=0.23s]
prediction: ['[CLS] terre attraction filmmakers include issue a poorly school project even scary. into forgot anything poorly reggerji fatal featured attraction as poorly瀬 school [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.443 (perp=10.629, rec=0.121, cos=0.196), tot_loss_proj:3.030 [t=0.22s]
prediction: ['[CLS] terre attraction filmmakers include issue a poorly school project even scary. into forgot anything poorly reggerji featured fatal attraction as poorly require school [SEP]']
[ 600/2000] tot_loss=2.431 (perp=10.629, rec=0.108, cos=0.197), tot_loss_proj:3.027 [t=0.18s]
prediction: ['[CLS] terre attraction filmmakers include issue a poorly school project even scary. into forgot anything poorly reggerji featured fatal attraction as poorly require school [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.450 (perp=10.647, rec=0.136, cos=0.185), tot_loss_proj:3.007 [t=0.26s]
prediction: ["[CLS]'attraction filmmakers include industry a poorly school project even scary. forgot into anything poorly reggerjiி fatal setting as they require graduating [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.252 (perp=9.717, rec=0.118, cos=0.191), tot_loss_proj:2.780 [t=0.19s]
prediction: ['[CLS]s setting filmmakers include issue a poorly school project even scary. forgot into anything poorly reggerjiி fatal attraction as they require school [SEP]']
[ 750/2000] tot_loss=2.239 (perp=9.717, rec=0.102, cos=0.194), tot_loss_proj:2.793 [t=0.20s]
prediction: ['[CLS]s setting filmmakers include issue a poorly school project even scary. forgot into anything poorly reggerjiி fatal attraction as they require school [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.229 (perp=9.657, rec=0.104, cos=0.194), tot_loss_proj:2.796 [t=0.21s]
prediction: ['[CLS]s issue filmmakers include setting a poorly school project even scary. forgot into anything poorly reggerjiி fatal attraction as they require school [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.294 (perp=9.958, rec=0.105, cos=0.198), tot_loss_proj:2.866 [t=0.18s]
prediction: ['[CLS] school issue filmmakers include setting a poorly school project even scary. forgot into anything poorly reggerjiி fatal attraction as they requireji [SEP]']
[ 900/2000] tot_loss=2.291 (perp=9.958, rec=0.102, cos=0.198), tot_loss_proj:2.867 [t=0.18s]
prediction: ['[CLS] school issue filmmakers include setting a poorly school project even scary. forgot into anything poorly reggerjiி fatal attraction as they requireji [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.286 (perp=9.958, rec=0.097, cos=0.197), tot_loss_proj:2.870 [t=0.22s]
prediction: ['[CLS] school issue filmmakers include setting a poorly school project even scary. forgot into anything poorly reggerjiி fatal attraction as they requireji [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.265 (perp=9.887, rec=0.090, cos=0.197), tot_loss_proj:2.890 [t=0.30s]
prediction: ['[CLS] schoolji filmmakers include setting a poorly school project even scary. forgot into anything poorly reggerjiி fatal attraction as they require issue [SEP]']
[1050/2000] tot_loss=2.272 (perp=9.887, rec=0.096, cos=0.198), tot_loss_proj:2.885 [t=0.27s]
prediction: ['[CLS] schoolji filmmakers include setting a poorly school project even scary. forgot into anything poorly reggerjiி fatal attraction as they require issue [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.233 (perp=9.750, rec=0.085, cos=0.197), tot_loss_proj:2.813 [t=0.18s]
prediction: ['[CLS] schoolji filmmakers include setting a poorly school project. even scary forgot into anything poorly reggerjiி fatal attraction as they require issue [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.198 (perp=9.520, rec=0.095, cos=0.199), tot_loss_proj:2.919 [t=0.25s]
prediction: ["[CLS] school. filmmakers include setting a poorly school project'even scary forgot into anything poorly reggerjiி fatal attraction as they require issue [SEP]"]
[1200/2000] tot_loss=2.195 (perp=9.520, rec=0.092, cos=0.198), tot_loss_proj:2.923 [t=0.29s]
prediction: ["[CLS] school. filmmakers include setting a poorly school project'even scary forgot into anything poorly reggerjiி fatal attraction as they require issue [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.160 (perp=9.329, rec=0.095, cos=0.199), tot_loss_proj:2.890 [t=0.28s]
prediction: ["[CLS] school. filmmakers include setting a poorly school project'even scary forgot into anything poorly rejiggerி fatal attraction as they require issue [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.059 (perp=8.929, rec=0.084, cos=0.189), tot_loss_proj:2.761 [t=0.21s]
prediction: ["[CLS] school issue filmmakers include setting a poorly school project'even scary forgot into anything poorly rejiggerி fatal attraction as they require. [SEP]"]
[1350/2000] tot_loss=2.076 (perp=8.929, rec=0.096, cos=0.194), tot_loss_proj:2.755 [t=0.19s]
prediction: ["[CLS] school issue filmmakers include setting a poorly school project'even scary forgot into anything poorly rejiggerி fatal attraction as they require. [SEP]"]
Attempt swap
Moved sequence
[1400/2000] tot_loss=2.052 (perp=8.843, rec=0.089, cos=0.195), tot_loss_proj:2.667 [t=0.22s]
prediction: ["[CLS] school issue filmmakers include setting a school project poorly'even scary forgot into anything poorly rejiggerி fatal attraction as they require. [SEP]"]
Attempt swap
[1450/2000] tot_loss=2.055 (perp=8.843, rec=0.090, cos=0.196), tot_loss_proj:2.666 [t=0.19s]
prediction: ["[CLS] school issue filmmakers include setting a school project poorly'even scary forgot into anything poorly rejiggerி fatal attraction as they require. [SEP]"]
[1500/2000] tot_loss=2.055 (perp=8.843, rec=0.089, cos=0.197), tot_loss_proj:2.664 [t=0.25s]
prediction: ["[CLS] school issue filmmakers include setting a school project poorly'even scary forgot into anything poorly rejiggerி fatal attraction as they require. [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.125 (perp=9.223, rec=0.083, cos=0.198), tot_loss_proj:2.711 [t=0.26s]
prediction: ['[CLS] school issue filmmakers include setting a school project poorly into even scary forgotji anything poorly rejiggerி fatal attraction as they require. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.130 (perp=9.223, rec=0.087, cos=0.198), tot_loss_proj:2.712 [t=0.22s]
prediction: ['[CLS] school issue filmmakers include setting a school project poorly into even scary forgotji anything poorly rejiggerி fatal attraction as they require. [SEP]']
[1650/2000] tot_loss=2.138 (perp=9.223, rec=0.096, cos=0.198), tot_loss_proj:2.709 [t=0.18s]
prediction: ['[CLS] school issue filmmakers include setting a school project poorly into even scary forgotji anything poorly rejiggerி fatal attraction as they require. [SEP]']
Attempt swap
[1700/2000] tot_loss=2.132 (perp=9.223, rec=0.090, cos=0.198), tot_loss_proj:2.710 [t=0.19s]
prediction: ['[CLS] school issue filmmakers include setting a school project poorly into even scary forgotji anything poorly rejiggerி fatal attraction as they require. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.125 (perp=9.223, rec=0.082, cos=0.198), tot_loss_proj:2.707 [t=0.23s]
prediction: ['[CLS] school issue filmmakers include setting a school project poorly into even scary forgotji anything poorly rejiggerி fatal attraction as they require. [SEP]']
[1800/2000] tot_loss=2.131 (perp=9.223, rec=0.088, cos=0.198), tot_loss_proj:2.716 [t=0.25s]
prediction: ['[CLS] school issue filmmakers include setting a school project poorly into even scary forgotji anything poorly rejiggerி fatal attraction as they require. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.106 (perp=9.125, rec=0.083, cos=0.198), tot_loss_proj:2.749 [t=0.19s]
prediction: ['[CLS] schoolji filmmakers include setting a school project poorly into even scary forgot issue anything poorly rejiggerி fatal attraction as they require. [SEP]']
Attempt swap
[1900/2000] tot_loss=2.118 (perp=9.125, rec=0.095, cos=0.198), tot_loss_proj:2.751 [t=0.18s]
prediction: ['[CLS] schoolji filmmakers include setting a school project poorly into even scary forgot issue anything poorly rejiggerி fatal attraction as they require. [SEP]']
[1950/2000] tot_loss=2.111 (perp=9.125, rec=0.087, cos=0.198), tot_loss_proj:2.757 [t=0.21s]
prediction: ['[CLS] schoolji filmmakers include setting a school project poorly into even scary forgot issue anything poorly rejiggerி fatal attraction as they require. [SEP]']
Attempt swap
[2000/2000] tot_loss=2.073 (perp=8.925, rec=0.089, cos=0.199), tot_loss_proj:2.725 [t=0.26s]
prediction: ["[CLS] school'filmmakers include setting a school project poorly into even scary forgot issue anything poorly rejiggerி fatal attraction as they require. [SEP]"]
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] school issue filmmakers include setting a school project poorly into even scary forgotji anything poorly rejiggerி fatal attraction as they require. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.596 | p: 78.261 | r: 75.000
rouge2     | fm: 17.778 | p: 18.182 | r: 17.391
rougeL     | fm: 42.553 | p: 43.478 | r: 41.667
rougeLsum  | fm: 42.553 | p: 43.478 | r: 41.667
r1fm+r2fm = 94.374

[Aggregate metrics]:
rouge1     | fm: 87.513 | p: 86.671 | r: 88.497
rouge2     | fm: 55.928 | p: 55.696 | r: 56.201
rougeL     | fm: 77.201 | p: 76.418 | r: 78.036
rougeLsum  | fm: 77.158 | p: 76.427 | r: 78.015
r1fm+r2fm = 143.440

input #42 time: 0:08:41 | total time: 5:59:04


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.8578105609030623
highest_index [0]
highest [0.8578105609030623]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.918616771697998 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.8827444314956665 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8693516850471497 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 0.8659546971321106 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8245883584022522 for ['[CLS] taken cheek willels [SEP]']
[Init] best rec loss: 0.7932062149047852 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.7677646279335022 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.7408559918403625 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7166759967803955 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.711849570274353 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 0.7114478349685669 for ['[CLS]busck climb second [SEP]']
[Init] best perm rec loss: 0.7112609148025513 for ['[CLS] climbckbus second [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.163 (perp=13.177, rec=0.273, cos=0.255), tot_loss_proj:3.700 [t=0.21s]
prediction: ['[CLS] term stallismist [SEP]']
[ 100/2000] tot_loss=2.056 (perp=8.120, rec=0.176, cos=0.256), tot_loss_proj:2.328 [t=0.18s]
prediction: ['[CLS] na naissistic [SEP]']
[ 150/2000] tot_loss=2.001 (perp=8.120, rec=0.119, cos=0.258), tot_loss_proj:2.441 [t=0.18s]
prediction: ['[CLS] na naissistic [SEP]']
[ 200/2000] tot_loss=1.987 (perp=8.120, rec=0.103, cos=0.261), tot_loss_proj:2.525 [t=0.21s]
prediction: ['[CLS] na naissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.307 (perp=9.802, rec=0.095, cos=0.251), tot_loss_proj:2.618 [t=0.23s]
prediction: ['[CLS]rc naissistic [SEP]']
[ 300/2000] tot_loss=2.318 (perp=9.802, rec=0.095, cos=0.263), tot_loss_proj:2.601 [t=0.22s]
prediction: ['[CLS]rc naissistic [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.385 (perp=5.048, rec=0.116, cos=0.259), tot_loss_proj:1.367 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.362 (perp=5.048, rec=0.097, cos=0.255), tot_loss_proj:1.351 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.360 (perp=5.048, rec=0.091, cos=0.260), tot_loss_proj:1.344 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.366 (perp=5.048, rec=0.093, cos=0.264), tot_loss_proj:1.353 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.357 (perp=5.048, rec=0.090, cos=0.258), tot_loss_proj:1.352 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.363 (perp=5.048, rec=0.094, cos=0.258), tot_loss_proj:1.362 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.365 (perp=5.048, rec=0.093, cos=0.263), tot_loss_proj:1.349 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.366 (perp=5.048, rec=0.093, cos=0.264), tot_loss_proj:1.356 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.355 (perp=5.048, rec=0.081, cos=0.264), tot_loss_proj:1.341 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.346 (perp=5.048, rec=0.073, cos=0.264), tot_loss_proj:1.351 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.347 (perp=5.048, rec=0.079, cos=0.259), tot_loss_proj:1.351 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.339 (perp=5.048, rec=0.067, cos=0.263), tot_loss_proj:1.347 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.340 (perp=5.048, rec=0.066, cos=0.264), tot_loss_proj:1.347 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.343 (perp=5.048, rec=0.070, cos=0.262), tot_loss_proj:1.349 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.333 (perp=5.048, rec=0.061, cos=0.263), tot_loss_proj:1.353 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.342 (perp=5.048, rec=0.069, cos=0.263), tot_loss_proj:1.346 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.338 (perp=5.048, rec=0.065, cos=0.264), tot_loss_proj:1.337 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.341 (perp=5.048, rec=0.068, cos=0.264), tot_loss_proj:1.343 [t=0.31s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.335 (perp=5.048, rec=0.062, cos=0.263), tot_loss_proj:1.333 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.348 (perp=5.048, rec=0.075, cos=0.264), tot_loss_proj:1.342 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.350 (perp=5.048, rec=0.076, cos=0.264), tot_loss_proj:1.342 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.328 (perp=5.048, rec=0.055, cos=0.264), tot_loss_proj:1.334 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.340 (perp=5.048, rec=0.066, cos=0.264), tot_loss_proj:1.359 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.340 (perp=5.048, rec=0.066, cos=0.264), tot_loss_proj:1.340 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.342 (perp=5.048, rec=0.069, cos=0.264), tot_loss_proj:1.344 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.341 (perp=5.048, rec=0.068, cos=0.264), tot_loss_proj:1.342 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.322 (perp=5.048, rec=0.049, cos=0.264), tot_loss_proj:1.342 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.340 (perp=5.048, rec=0.066, cos=0.264), tot_loss_proj:1.335 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.330 (perp=5.048, rec=0.056, cos=0.264), tot_loss_proj:1.328 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.350 (perp=5.048, rec=0.077, cos=0.264), tot_loss_proj:1.347 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.330 (perp=5.048, rec=0.056, cos=0.264), tot_loss_proj:1.333 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.339 (perp=5.048, rec=0.065, cos=0.264), tot_loss_proj:1.345 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.342 (perp=5.048, rec=0.069, cos=0.264), tot_loss_proj:1.343 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.338 (perp=5.048, rec=0.065, cos=0.264), tot_loss_proj:1.345 [t=0.30s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.723 | p: 86.885 | r: 88.702
rouge2     | fm: 57.041 | p: 56.856 | r: 57.340
rougeL     | fm: 77.777 | p: 77.015 | r: 78.601
rougeLsum  | fm: 77.705 | p: 77.037 | r: 78.648
r1fm+r2fm = 144.764

input #43 time: 0:08:20 | total time: 6:07:24


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.8777104308670293
highest_index [0]
highest [0.8777104308670293]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.0330547094345093 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.0109667778015137 for ['[CLS] pe grammy vague contract flow genre training willing floraux acting! dc spoke ben sami undo polo # paperplaced choon muscle duncanoat derived rat schooling [SEP]']
[Init] best rec loss: 1.0096814632415771 for ['[CLS] unitedzz golden archaeological looking forward at prime momentien before at private suspensiontone ice rim arrested evelyn surgeon shaw codes memorymobile by addition ultimatelynal mills [SEP]']
[Init] best rec loss: 1.0036381483078003 for ['[CLS]hips less pronounced soaked leon overs tradition suzy diplomatic collins forgotten cells later semester brock pan husband dickinson radar would release n embankment overall evil outlookockinate toward [SEP]']
[Init] best rec loss: 1.002709150314331 for ['[CLS] obstacles access household rave las gas revntly fellowship had rock turnpikewick isn tuesday yet magazine do up everything speculation neckagger openingiani compute occupiedoint mm [SEP]']
[Init] best rec loss: 1.0024847984313965 for ['[CLS] bo secretxi tv existent cab sb challenge nowhere international mark under lincoln another funk ollie iron nan michelle hospital anyonenished union hatch flagship mercy no k eventually [SEP]']
[Init] best rec loss: 0.9854186773300171 for ['[CLS] patriciaerinacano such currently staggered hop craft vacancy calderon rack anxious play without torpedoous major carter ghost popularity version cutterivar fifty plot parting you still sports [SEP]']
[Init] best rec loss: 0.9806153774261475 for ['[CLS]hold juryys closing mm too scholastic steele malifell rockyxa enclosed ronnie giveneros american epstein name publishing less him am aggregator revealing harmony irony trusted hourly [SEP]']
[Init] best perm rec loss: 0.9801607131958008 for ['[CLS] closing irony mmys steeleeros harmony name epstein toohold revealingxa enclosed ronnie aggregator am scholastic mali himfell rocky less jury hourly american publishing trusted given [SEP]']
[Init] best perm rec loss: 0.9800047874450684 for ['[CLS] him revealing scholastic jury malierosxa publishing irony ronnie aggregator epstein closingfellhold name given less harmony hourly mm steele rocky too trusted american enclosedys am [SEP]']
[Init] best perm rec loss: 0.9798004627227783 for ['[CLS]fell publishingys scholastic steele revealing trusted american ironyeros given harmony closing jury less him mali enclosedhold mm epstein too hourly ronnie amxa name rocky aggregator [SEP]']
[Init] best perm rec loss: 0.9796148538589478 for ['[CLS] mm scholastic amyseros hourly mali epstein revealing less ronnie trusted given steelexa him aggregator name publishingfellhold irony enclosed jury closing american rocky too harmony [SEP]']
[Init] best perm rec loss: 0.97854083776474 for ['[CLS] malifell name enclosed ronnie revealing hourlyhold americanys givenxa mm am trusted jury scholastic rocky closing him too publishing irony aggregator harmonyeros less epstein steele [SEP]']
[Init] best perm rec loss: 0.9782437086105347 for ['[CLS] am given scholasticys too aggregator enclosed publishing ronnie closing less mali harmony jury irony revealing steele nameeros rockyxa epstein himfellhold trusted hourly mm american [SEP]']
[Init] best perm rec loss: 0.9781249165534973 for ['[CLS] aggregator revealing mmerosxa harmony scholastic steele him american amys ironyfell enclosed less givenhold mali publishing closing trusted rocky hourly jury too name ronnie epstein [SEP]']
[Init] best perm rec loss: 0.9778783321380615 for ['[CLS] him am enclosed mm malierosxafell too american given irony aggregator rocky trusted closing revealing jury ronnie namehold epstein steele harmony less scholastic publishingys hourly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.660 (perp=13.879, rec=0.703, cos=0.182), tot_loss_proj:4.372 [t=0.18s]
prediction: ['[CLS] points thus quinn alongside from often wild worth your styley max havre rational rational gauge andre abroad santana structure lighter worth film worthriohm given georgie innovation [SEP]']
[ 100/2000] tot_loss=3.259 (perp=12.588, rec=0.588, cos=0.154), tot_loss_proj:4.393 [t=0.18s]
prediction: ['[CLS] long journey cannabis after. enough beautiful becoming! line goodiusque rational perfect genre aired in polymer inception liquid share loss worth dr absolute its turkmenistan innovation [SEP]']
[ 150/2000] tot_loss=3.208 (perp=12.449, rec=0.493, cos=0.225), tot_loss_proj:4.422 [t=0.24s]
prediction: ["[CLS]ks therebyiful since.que warm reconstruction upon translation the angelesque clarissa certainty genre ¨ where geometry translation libby help documentation worthfest disgust'turkmenistan nerves [SEP]"]
[ 200/2000] tot_loss=2.904 (perp=11.416, rec=0.535, cos=0.085), tot_loss_proj:4.132 [t=0.22s]
prediction: ['[CLS] thechuk wo theatrical down francisco beautiful injury based translation the actors libre extreme good river where in fairly translation baha the unanimous worth your spectator ratherget edged [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.452 (perp=12.646, rec=0.670, cos=0.252), tot_loss_proj:4.532 [t=0.28s]
prediction: ['[CLS]ky lost wo routine. off wonderful plotting based translationnentriety libreances good¨ties whose fairly significance baha the unanimous translation hollywood political executionture doping [SEP]']
[ 300/2000] tot_loss=2.980 (perp=12.069, rec=0.480, cos=0.087), tot_loss_proj:4.228 [t=0.25s]
prediction: ['[CLS] medieval lost beetle.. ¨ smile humane on translation intact unidentified activitiesances nice literal every in physics significance baha theified translation hollywoodological whose escaped petroleum [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.810 (perp=11.338, rec=0.454, cos=0.089), tot_loss_proj:4.278 [t=0.23s]
prediction: ['[CLS] the lost beetle. ; lost smile humane on translation intact fitzgerald kongances nice¨ every in cones significance warm ofified translation hollywoodingly whoseture doping [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.853 (perp=11.296, rec=0.471, cos=0.123), tot_loss_proj:4.262 [t=0.19s]
prediction: ['[CLS] the lost wo in. lost peace theory in translationnent explicit featureances nice¨ every in lauderdale tao dunned unanimous translation hollywood premise language newscast discontinued [SEP]']
[ 450/2000] tot_loss=2.866 (perp=11.448, rec=0.426, cos=0.150), tot_loss_proj:4.265 [t=0.23s]
prediction: ['[CLS] the lost goblin.. lost peace theory in translationnent explicit festivalances nice¨ apparently in mustache jared dunnedified translation hollywood premise whose newscast commonly [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.002 (perp=11.901, rec=0.446, cos=0.176), tot_loss_proj:4.424 [t=0.30s]
prediction: ['[CLS] the losttched. ; lost beautiful theory in translationnent explicit translation interesting nice¨ every in significance jared slack receivedified feature hollywood premise whose sitcom brigham [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.853 (perp=11.547, rec=0.389, cos=0.155), tot_loss_proj:4.062 [t=0.18s]
prediction: ['[CLS] the lost wo.. lost beautiful theory in translationnent innocent translation wholesale nice¨ gaps in significance psychoned slack premise liquor hollywood premisemanship sitcom discontinued [SEP]']
[ 600/2000] tot_loss=2.875 (perp=11.846, rec=0.371, cos=0.136), tot_loss_proj:4.226 [t=0.18s]
prediction: ['[CLS] the lost wo.. lost beautiful execution in translationnent innocent translation wholesale nice¨ gaps in mustache psychoned slack premise accent hollywood premise been newscast commonly [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.850 (perp=11.422, rec=0.384, cos=0.181), tot_loss_proj:4.271 [t=0.18s]
prediction: ['[CLS] the lost wo.. lost beautiful premise in translation fact innocent translation wholesale nice¨ gaps in mustache psychoned slack theory currency hollywood premise been newscast commonly [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.870 (perp=11.264, rec=0.401, cos=0.217), tot_loss_proj:4.278 [t=0.23s]
prediction: ['[CLS] the lost wo in ; lost beautiful premiseable translation theory explicit translation opened nice¨ gaps the lauderdale psycho. warmoked composition hollywood premise whose sitcom commonly [SEP]']
[ 750/2000] tot_loss=2.935 (perp=12.158, rec=0.385, cos=0.119), tot_loss_proj:4.459 [t=0.23s]
prediction: ['[CLS] the lost wo in. lost beautiful premise linear translation theory pregnancy translation enormous nice¨ gaps the lauderdale psycho voiced warmoked composition hollywood premise [SEP] sitcom commonly [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.780 (perp=11.669, rec=0.372, cos=0.074), tot_loss_proj:4.217 [t=0.19s]
prediction: ['[CLS] the lost problems in. lost beautiful premise linear translation execution pregnancy translation the enormous nice¨ gaps mustache psychoned warmoked composition hollywood premise [SEP] sitcom commonly [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.743 (perp=11.471, rec=0.362, cos=0.086), tot_loss_proj:3.939 [t=0.19s]
prediction: ['[CLS] the lost problems in. lost beautiful translation linear translation routine pregnancy premise the enormous nice¨ gaps mustache psychoned slackoked composition hollywood premise [SEP] sitcom commonly [SEP]']
[ 900/2000] tot_loss=2.744 (perp=11.477, rec=0.360, cos=0.088), tot_loss_proj:3.883 [t=0.22s]
prediction: ['[CLS] the lost problems in. lost beautiful translation of translation routine pregnancy contestants the enormous nice¨ gaps mustache psychoned slack definitely composition hollywood premise slack sitcom commonly [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.686 (perp=11.050, rec=0.353, cos=0.124), tot_loss_proj:3.740 [t=0.24s]
prediction: ['[CLS] the lost problems in. lost beautiful translation of translation routine hollywood pregnancy contestants the enormous kind slack least zoooulos voiced slack definitely, premise [SEP] sitcom commonly [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.758 (perp=11.092, rec=0.378, cos=0.162), tot_loss_proj:3.903 [t=0.23s]
prediction: ['[CLS] the lost problems in ; lost beautiful translation of translation routine hollywood pregnancy contestants the enormous kind mustache least slackoulos voiced slack definitely, premise [SEP] newscast commonly [SEP]']
[1050/2000] tot_loss=2.562 (perp=10.732, rec=0.345, cos=0.070), tot_loss_proj:3.624 [t=0.19s]
prediction: ['[CLS] the lost problems in. lost! translation of translation routine hollywood pregnancy contestants the enormous kind zoo least slackoulos merits slack definitely, premise slack sitcom commonly [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.649 (perp=11.057, rec=0.347, cos=0.090), tot_loss_proj:3.685 [t=0.29s]
prediction: ['[CLS] the lost problems in. lost! translation of translation routine hollywood pregnancy contestants the chloe kind zoo least slackoulos merits definitely, slack premise been sitcom commonly [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.599 (perp=10.750, rec=0.351, cos=0.097), tot_loss_proj:3.546 [t=0.24s]
prediction: ['[CLS] the lost problems in commonly lost! translation of translation routine hollywood pregnancy contestants the chloe kind zoo least slackoulos merits definitely, slack premise been sitcom. [SEP]']
[1200/2000] tot_loss=2.759 (perp=11.213, rec=0.321, cos=0.196), tot_loss_proj:3.830 [t=0.19s]
prediction: ['[CLS] the lost problems in commonly lost! translation of translation routine hollywood pregnancy contestants the chloe honest zoo creepy slackoulos von definitely, slack premise been sitcom ; [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.637 (perp=10.929, rec=0.315, cos=0.136), tot_loss_proj:3.970 [t=0.18s]
prediction: ['[CLS] the lost problems in commonly lost! translation of translation routine hollywood pregnancy contestants the chloe honest, creepy slackoulos antique definitely zoo slack premise been newscast ; [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.587 (perp=10.676, rec=0.327, cos=0.125), tot_loss_proj:3.880 [t=0.21s]
prediction: ['[CLS] the lost problem in commonly lost merits translation of translation routine hollywood pregnancy contestants theaby honest, creepy slackoulos! definitely zoo slack premise been newscast ; [SEP]']
[1350/2000] tot_loss=2.612 (perp=10.872, rec=0.321, cos=0.117), tot_loss_proj:3.919 [t=0.26s]
prediction: ['[CLS] the lost problems in commonly lost merits translation of translation routine hollywood pregnancy contestants theaby honest, creepy slackoulos! definitely zoo slack premise been newscast ; [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.681 (perp=11.126, rec=0.331, cos=0.124), tot_loss_proj:3.888 [t=0.21s]
prediction: ['[CLS] the lost problems in commonly lost merits translation of translation routine hollywood pregnancy contestants mustacheaby honest composition creepy slackoulos! definitely the slack premise been newscast ; [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.566 (perp=10.727, rec=0.329, cos=0.092), tot_loss_proj:3.814 [t=0.26s]
prediction: ['[CLS] the lost problems in commonly lost merits translation of translation routine hollywood pregnancy contestants mustache slack honest composition creepy slackoulos! definitely theaby premise been newscast. [SEP]']
[1500/2000] tot_loss=2.535 (perp=10.764, rec=0.317, cos=0.066), tot_loss_proj:3.813 [t=0.23s]
prediction: ['[CLS] the lost problems in commonly lost antique translation of translation routine hollywood pregnancy contestants mustache slack honest composition creepy slackoulos! definitely theaby premise been newscast. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.556 (perp=10.670, rec=0.324, cos=0.097), tot_loss_proj:3.773 [t=0.19s]
prediction: ['[CLS] the lost problems in translation commonly lost merits translation of routine hollywood pregnancy contestants » slack honest composition creepy slackoulos! definitely theaby premise been newscast. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.639 (perp=10.595, rec=0.310, cos=0.210), tot_loss_proj:3.477 [t=0.24s]
prediction: ['[CLS] the lost problems in translation commonly lost merits of translation routine hollywood pregnancy contestants mustache slack honest composition creepy slackoulos! quo theaby premise been newscast. [SEP]']
[1650/2000] tot_loss=2.478 (perp=10.359, rec=0.304, cos=0.102), tot_loss_proj:3.591 [t=0.24s]
prediction: ['[CLS] the lost problems in translation commonly lost merits of translation routine hollywood pregnancy contestants » slack honest composition creepy slackoulos! definitely theaby premise been newscast. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.371 (perp=9.901, rec=0.311, cos=0.080), tot_loss_proj:3.548 [t=0.21s]
prediction: ['[CLS] the lost problems in translation commonly lost merits of translation routine hollywood pregnancy contestants » slack honest compositionaby slackoulos! definitely the creepy premise been newscast. [SEP]']
Attempt swap
[1750/2000] tot_loss=2.372 (perp=9.901, rec=0.317, cos=0.074), tot_loss_proj:3.546 [t=0.22s]
prediction: ['[CLS] the lost problems in translation commonly lost merits of translation routine hollywood pregnancy contestants » slack honest compositionaby slackoulos! definitely the creepy premise been newscast. [SEP]']
[1800/2000] tot_loss=2.563 (perp=10.650, rec=0.295, cos=0.139), tot_loss_proj:3.459 [t=0.19s]
prediction: ['[CLS] the lost problems in translation commonly lost merits of translation routine hollywood pregnancy contestants » slack honest compositionaby slackoulos! quoestinal creepy premise been newscast. [SEP]']
Attempt swap
[1850/2000] tot_loss=2.503 (perp=10.597, rec=0.307, cos=0.077), tot_loss_proj:3.549 [t=0.20s]
prediction: ['[CLS] the lost problems in translation commonly lost merits of translation routine hollywood pregnancy contestants » slack honest compositionaby slackoulos! definitelyestinal creepy premise been newscast. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.496 (perp=10.525, rec=0.299, cos=0.092), tot_loss_proj:3.533 [t=0.23s]
prediction: ['[CLS] the problems lost in translation commonly lost merits of translation routine hollywood pregnancy contestants » slack honest compositionaby slackoulos! definitelyestinal creepy premise been newscast. [SEP]']
[1950/2000] tot_loss=2.533 (perp=10.601, rec=0.295, cos=0.118), tot_loss_proj:3.458 [t=0.20s]
prediction: ['[CLS] the problems lost in translation commonly lost merits of translation routine hollywood pregnancy contestants » slack honest compositionaby slackoulos! quoestinal creepy premise been newscast. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.508 (perp=10.568, rec=0.308, cos=0.086), tot_loss_proj:3.538 [t=0.19s]
prediction: ['[CLS] the fringe lost in translation commonly lost merits of translation routine hollywood pregnancy contestants » slack honest compositionaby slackestinaloulos! definitely creepy premise been newscast. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] the lost problems in translation commonly lost merits of translation routine hollywood pregnancy contestants » slack honest compositionaby slackoulos! definitely the creepy premise been newscast. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.061 | p: 50.000 | r: 56.522
rouge2     | fm: 4.255 | p: 4.000 | r: 4.545
rougeL     | fm: 40.816 | p: 38.462 | r: 43.478
rougeLsum  | fm: 40.816 | p: 38.462 | r: 43.478
r1fm+r2fm = 57.317

[Aggregate metrics]:
rouge1     | fm: 86.907 | p: 85.994 | r: 87.937
rouge2     | fm: 55.796 | p: 55.573 | r: 56.052
rougeL     | fm: 76.793 | p: 76.129 | r: 77.770
rougeLsum  | fm: 76.835 | p: 76.106 | r: 77.734
r1fm+r2fm = 142.703

input #44 time: 0:08:38 | total time: 6:16:02


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.8797511666393729
highest_index [0]
highest [0.8797511666393729]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.7854616641998291 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.7353594303131104 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.7283657193183899 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.7198729515075684 for ['[CLS] go land board preparatory hush dylan guantanamo grace really our guidesbian a2lic internet mor salad possible throughoutim between grey scaleitic around speech pri mil [SEP]']
[Init] best rec loss: 0.6852415204048157 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 0.6595997214317322 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.6579930782318115 for ['[CLS] ( bore around skinlanda v football ku2 curtis military five enclosed statustiv special single few gentry tree whoa via murmured joan letter taste operated entrance [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.123 (perp=12.750, rec=0.380, cos=0.193), tot_loss_proj:3.643 [t=0.23s]
prediction: ['[CLS] phone equipment stool wound mess maybe missionaryel on library headline split gideon parts than momb - programme book kamtish copy men really sleep equipped uncle [SEP]']
[ 100/2000] tot_loss=2.657 (perp=10.935, rec=0.311, cos=0.159), tot_loss_proj:3.388 [t=0.21s]
prediction: ['[CLS] or movements stool through mess myself huntingel on - headline - cardinals parts than withoutk this press lp any hawker - so swimming equipped uncle [SEP]']
[ 150/2000] tot_loss=2.452 (perp=10.231, rec=0.200, cos=0.205), tot_loss_proj:3.162 [t=0.20s]
prediction: ['[CLS] - movements tyres this stiff when oldel - - - - -ces than thatk this action lp giy programme - so, shelf uncle [SEP]']
[ 200/2000] tot_loss=2.454 (perp=10.339, rec=0.162, cos=0.224), tot_loss_proj:3.212 [t=0.21s]
prediction: ['[CLS] - movements skin thisel with crimeel bow - - - exercise systems than thatb this exercise shelf giick bill - long, shelf uncle [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.314 (perp=9.744, rec=0.150, cos=0.215), tot_loss_proj:2.967 [t=0.18s]
prediction: ['[CLS] - movements skin thisel bow crimeel bow - - - exercise the than thatb, exercise shelfmmick gi - drama - shelf drama [SEP]']
[ 300/2000] tot_loss=2.289 (perp=9.732, rec=0.143, cos=0.199), tot_loss_proj:2.890 [t=0.21s]
prediction: ['[CLS] - movements exercise thisel bow crimeel bow - - - exercise the than ofb, exercise shelfmmick gi - of - shelf drama [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.407 (perp=10.308, rec=0.128, cos=0.217), tot_loss_proj:3.072 [t=0.19s]
prediction: ['[CLS] - movements shelf thisel bow crimeel bow - - - ofb, exercise shelf exercise the thanmmick gi in of -mm drama [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.137 (perp=8.936, rec=0.155, cos=0.194), tot_loss_proj:2.624 [t=0.25s]
prediction: ['[CLS] - movements exercise thisel bow crimeel bow - - - ofb, exercise shelf - the than gimmick on of -mm drama [SEP]']
[ 450/2000] tot_loss=2.309 (perp=9.792, rec=0.139, cos=0.212), tot_loss_proj:2.867 [t=0.21s]
prediction: ['[CLS] - movements exercise thisel gi crimeel bow - - - ofb, exercise shelf - the than gimmick on of -mm drama [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.151 (perp=9.093, rec=0.118, cos=0.215), tot_loss_proj:2.773 [t=0.18s]
prediction: ['[CLS] - movements exercise thisel gi crime in bow - - - theb, exercise shelf - the than gimmick onel -mm drama [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.195 (perp=9.342, rec=0.110, cos=0.217), tot_loss_proj:2.812 [t=0.23s]
prediction: ['[CLS] - movements exercise this giel crime in bow - - - theb, exercise shelf gi the than gimmick onel -mm drama [SEP]']
[ 600/2000] tot_loss=2.208 (perp=9.394, rec=0.109, cos=0.220), tot_loss_proj:2.823 [t=0.20s]
prediction: ['[CLS] - movements exercise this giel crime in bow - - - theb, exercise shelf gi point than gimmick onel -mm drama [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.103 (perp=8.899, rec=0.103, cos=0.220), tot_loss_proj:2.592 [t=0.22s]
prediction: ['[CLS] - movements exercise this giel crime in bow - - - theb, exercise shelf gimm than gimmick onel - point drama [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.988 (perp=8.398, rec=0.101, cos=0.207), tot_loss_proj:2.463 [t=0.19s]
prediction: ['[CLS] - movements exercise this bowel crime in gi - - - theb, exercise shelf gimm than gimmick onel - point drama [SEP]']
[ 750/2000] tot_loss=2.053 (perp=8.656, rec=0.106, cos=0.216), tot_loss_proj:2.485 [t=0.19s]
prediction: ['[CLS] - movements exercise this bowel crime in gi - long - theb, exercise shelf gimm than gimmick onel - point drama [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.959 (perp=8.207, rec=0.099, cos=0.219), tot_loss_proj:2.458 [t=0.20s]
prediction: ['[CLS] - movements exercise this bowel crime in gi - long - the shoot, exercise shelf gimm than gimmickel - point drama on [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.940 (perp=8.130, rec=0.094, cos=0.220), tot_loss_proj:2.416 [t=0.19s]
prediction: ['[CLS] - crime exercise this bowel movements in gi - long - the shoot, exercise shelf gimm than gimmickel - point drama on [SEP]']
[ 900/2000] tot_loss=1.938 (perp=8.130, rec=0.090, cos=0.222), tot_loss_proj:2.417 [t=0.28s]
prediction: ['[CLS] - crime exercise this bowel movements in gi - long - the shoot, exercise shelf gimm than gimmickel - point drama on [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.893 (perp=7.963, rec=0.082, cos=0.218), tot_loss_proj:2.347 [t=0.30s]
prediction: ['[CLS] - crime exercise this bowel movements in gi - long - shoot, the exercise shelf gimm than gimmickel - point drama on [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.894 (perp=7.894, rec=0.094, cos=0.221), tot_loss_proj:2.339 [t=0.20s]
prediction: ['[CLS] - crime exercise this bowel movements in gi - long - shoot, the exercise shelf gimm than gimmick - pointel drama on [SEP]']
[1050/2000] tot_loss=1.894 (perp=7.894, rec=0.094, cos=0.222), tot_loss_proj:2.338 [t=0.20s]
prediction: ['[CLS] - crime exercise this bowel movements in gi - long - shoot, the exercise shelf gimm than gimmick - pointel drama on [SEP]']
Attempt swap
[1100/2000] tot_loss=1.949 (perp=8.177, rec=0.091, cos=0.222), tot_loss_proj:2.417 [t=0.24s]
prediction: ['[CLS] - crime bow this bowel movements in gi - long - shoot, the exercise shelf gimm than gimmick - pointel drama on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.941 (perp=8.177, rec=0.083, cos=0.222), tot_loss_proj:2.417 [t=0.27s]
prediction: ['[CLS] - crime bow this bowel movements in gi - long - shoot, the exercise shelf gimm than gimmick - pointel drama on [SEP]']
[1200/2000] tot_loss=1.945 (perp=8.166, rec=0.089, cos=0.223), tot_loss_proj:2.427 [t=0.19s]
prediction: ['[CLS] - crime bow this bowel movements in gi - long - shoot, the exercise shelf gimm than gimmick - shootel drama on [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.918 (perp=8.033, rec=0.088, cos=0.223), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] - bow crime this bowel movements in gi - long - shoot, the exercise shelf gimm than gimmick - shootel drama on [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.849 (perp=7.711, rec=0.089, cos=0.217), tot_loss_proj:2.309 [t=0.27s]
prediction: ['[CLS] - bow crime this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick - shoot drama on [SEP]']
[1350/2000] tot_loss=1.854 (perp=7.711, rec=0.091, cos=0.221), tot_loss_proj:2.314 [t=0.25s]
prediction: ['[CLS] - bow crime this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick - shoot drama on [SEP]']
Attempt swap
[1400/2000] tot_loss=1.855 (perp=7.711, rec=0.092, cos=0.222), tot_loss_proj:2.312 [t=0.27s]
prediction: ['[CLS] - bow crime this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick - shoot drama on [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.806 (perp=7.519, rec=0.079, cos=0.223), tot_loss_proj:2.282 [t=0.25s]
prediction: ['[CLS] - bowel this bowel movements in gi - long - shoot, the exercise shelf gimm crime than gimmick - shoot drama on [SEP]']
[1500/2000] tot_loss=1.815 (perp=7.519, rec=0.089, cos=0.223), tot_loss_proj:2.274 [t=0.28s]
prediction: ['[CLS] - bowel this bowel movements in gi - long - shoot, the exercise shelf gimm crime than gimmick - shoot drama on [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.939 (perp=8.156, rec=0.091, cos=0.216), tot_loss_proj:2.392 [t=0.18s]
prediction: ['[CLS] exerciseel - this bowel movements in gi - long - shoot, the exercise shelf gimm crime than gimmick - shoot drama on [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.872 (perp=7.814, rec=0.090, cos=0.219), tot_loss_proj:2.299 [t=0.20s]
prediction: ['[CLS] exercise on - this bowel movements in gi - long - shoot, the exercise shelf gimm crime than gimmick - shoot dramael [SEP]']
[1650/2000] tot_loss=1.870 (perp=7.814, rec=0.088, cos=0.219), tot_loss_proj:2.296 [t=0.18s]
prediction: ['[CLS] exercise on - this bowel movements in gi - long - shoot, the exercise shelf gimm crime than gimmick - shoot dramael [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.813 (perp=7.530, rec=0.086, cos=0.221), tot_loss_proj:2.220 [t=0.19s]
prediction: ['[CLS] exercise on - this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick - shoot drama crime [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.800 (perp=7.504, rec=0.079, cos=0.221), tot_loss_proj:2.203 [t=0.25s]
prediction: ['[CLS] exercise on - this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick - point crime drama [SEP]']
[1800/2000] tot_loss=1.807 (perp=7.504, rec=0.085, cos=0.221), tot_loss_proj:2.201 [t=0.27s]
prediction: ['[CLS] exercise on - this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick - point crime drama [SEP]']
Attempt swap
[1850/2000] tot_loss=1.806 (perp=7.504, rec=0.083, cos=0.221), tot_loss_proj:2.197 [t=0.19s]
prediction: ['[CLS] exercise on - this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick - point crime drama [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.799 (perp=7.451, rec=0.088, cos=0.220), tot_loss_proj:2.192 [t=0.18s]
prediction: ['[CLS] exercise on - this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick point - crime drama [SEP]']
[1950/2000] tot_loss=1.805 (perp=7.451, rec=0.094, cos=0.221), tot_loss_proj:2.198 [t=0.22s]
prediction: ['[CLS] exercise on - this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick point - crime drama [SEP]']
Attempt swap
[2000/2000] tot_loss=1.796 (perp=7.451, rec=0.085, cos=0.221), tot_loss_proj:2.199 [t=0.24s]
prediction: ['[CLS] exercise on - this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick point - crime drama [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] exercise on - this bowel movements in gi - long - shoot, the exercise shelf gimmel than gimmick - point crime drama [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 16.667 | p: 15.789 | r: 17.647
rougeL     | fm: 52.632 | p: 50.000 | r: 55.556
rougeLsum  | fm: 52.632 | p: 50.000 | r: 55.556
r1fm+r2fm = 100.877

[Aggregate metrics]:
rouge1     | fm: 86.943 | p: 86.035 | r: 88.056
rouge2     | fm: 54.846 | p: 54.576 | r: 55.087
rougeL     | fm: 76.279 | p: 75.397 | r: 77.198
rougeLsum  | fm: 76.257 | p: 75.465 | r: 77.254
r1fm+r2fm = 141.789

input #45 time: 0:08:41 | total time: 6:24:44


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.8269714582099823
highest_index [0]
highest [0.8269714582099823]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9448490142822266 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9205709099769592 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9186668992042542 for ['[CLS] worldwide fork packaging touched might fantastic [SEP]']
[Init] best rec loss: 0.9179300665855408 for ['[CLS] autism prince angles luna objectshol [SEP]']
[Init] best rec loss: 0.9149312973022461 for ['[CLS] giants alley told hurricane und : [SEP]']
[Init] best rec loss: 0.914240837097168 for ['[CLS]rily abu [MASK]edd old stakes [SEP]']
[Init] best perm rec loss: 0.9138454794883728 for ['[CLS]rilyedd [MASK] old abu stakes [SEP]']
[Init] best perm rec loss: 0.9128949046134949 for ['[CLS] oldrily abuedd [MASK] stakes [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.017 (perp=15.419, rec=0.664, cos=0.270), tot_loss_proj:4.628 [t=0.18s]
prediction: ['[CLS] playstationapa violate slap employerless [SEP]']
[ 100/2000] tot_loss=3.639 (perp=14.236, rec=0.545, cos=0.247), tot_loss_proj:4.832 [t=0.18s]
prediction: ['[CLS] playstation existed visuallyly organizational lurking [SEP]']
[ 150/2000] tot_loss=3.570 (perp=13.984, rec=0.550, cos=0.223), tot_loss_proj:4.725 [t=0.21s]
prediction: ['[CLS]gible helmetdilly strikingᵍily [SEP]']
[ 200/2000] tot_loss=3.746 (perp=14.352, rec=0.565, cos=0.310), tot_loss_proj:4.382 [t=0.24s]
prediction: ['[CLS]ential touchdownsdilly problemshorpeless [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.387 (perp=12.744, rec=0.550, cos=0.288), tot_loss_proj:4.294 [t=0.25s]
prediction: ['[CLS]ential infrastructure criticism visuallyilyily [SEP]']
[ 300/2000] tot_loss=3.064 (perp=11.684, rec=0.501, cos=0.226), tot_loss_proj:3.539 [t=0.18s]
prediction: ['[CLS]ential infrastructure visually striking ensembleily [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.260 (perp=12.686, rec=0.479, cos=0.244), tot_loss_proj:4.081 [t=0.23s]
prediction: ['[CLS] km²ᵍ impressive visually strikingily [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.095 (perp=11.642, rec=0.481, cos=0.286), tot_loss_proj:3.407 [t=0.26s]
prediction: ['[CLS] km² explicit visually strikingily impressive [SEP]']
[ 450/2000] tot_loss=3.070 (perp=11.642, rec=0.464, cos=0.278), tot_loss_proj:3.406 [t=0.25s]
prediction: ['[CLS] km² explicit visually strikingily impressive [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.121 (perp=11.936, rec=0.487, cos=0.246), tot_loss_proj:3.709 [t=0.23s]
prediction: ['[CLS] visually caitlin km² strikingily played [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.721 (perp=10.106, rec=0.467, cos=0.233), tot_loss_proj:3.262 [t=0.22s]
prediction: ['[CLS] visually striking km² caitlinily played [SEP]']
[ 600/2000] tot_loss=2.706 (perp=10.106, rec=0.475, cos=0.210), tot_loss_proj:3.263 [t=0.21s]
prediction: ['[CLS] visually striking km² caitlinily played [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.993 (perp=11.250, rec=0.486, cos=0.256), tot_loss_proj:3.592 [t=0.19s]
prediction: ['[CLS] visually striking km² caitlinilyiful [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.625 (perp=10.106, rec=0.436, cos=0.168), tot_loss_proj:3.266 [t=0.18s]
prediction: ['[CLS] visually striking km² caitlinily played [SEP]']
[ 750/2000] tot_loss=2.974 (perp=11.250, rec=0.421, cos=0.303), tot_loss_proj:3.600 [t=0.20s]
prediction: ['[CLS] visually striking km² caitlinilyiful [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.065 (perp=11.742, rec=0.411, cos=0.305), tot_loss_proj:4.070 [t=0.19s]
prediction: ['[CLS] visually striking km² interilyiful [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.948 (perp=11.398, rec=0.430, cos=0.238), tot_loss_proj:4.244 [t=0.24s]
prediction: ['[CLS] visually striking km²ily ghettoiful [SEP]']
[ 900/2000] tot_loss=2.942 (perp=11.398, rec=0.406, cos=0.257), tot_loss_proj:4.245 [t=0.32s]
prediction: ['[CLS] visually striking km²ily ghettoiful [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.915 (perp=11.252, rec=0.403, cos=0.261), tot_loss_proj:3.907 [t=0.21s]
prediction: ['[CLS] visually striking km²ily seriousiful [SEP]']
Attempt swap
[1000/2000] tot_loss=2.924 (perp=11.252, rec=0.404, cos=0.270), tot_loss_proj:3.906 [t=0.37s]
prediction: ['[CLS] visually striking km²ily seriousiful [SEP]']
[1050/2000] tot_loss=2.913 (perp=11.398, rec=0.404, cos=0.229), tot_loss_proj:4.246 [t=0.18s]
prediction: ['[CLS] visually striking km²ily ghettoiful [SEP]']
Attempt swap
[1100/2000] tot_loss=3.000 (perp=11.398, rec=0.398, cos=0.322), tot_loss_proj:4.247 [t=0.18s]
prediction: ['[CLS] visually striking km²ily ghettoiful [SEP]']
Attempt swap
[1150/2000] tot_loss=3.163 (perp=12.337, rec=0.393, cos=0.302), tot_loss_proj:4.404 [t=0.18s]
prediction: ['[CLS] visually striking km² staged ghettoiful [SEP]']
[1200/2000] tot_loss=3.160 (perp=12.337, rec=0.399, cos=0.293), tot_loss_proj:4.401 [t=0.19s]
prediction: ['[CLS] visually striking km² staged ghettoiful [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.025 (perp=11.777, rec=0.390, cos=0.280), tot_loss_proj:3.995 [t=0.18s]
prediction: ['[CLS] visually striking staged km² shapeiful [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.983 (perp=11.393, rec=0.408, cos=0.296), tot_loss_proj:3.801 [t=0.23s]
prediction: ['[CLS] visually striking stagediful shape km² [SEP]']
[1350/2000] tot_loss=2.922 (perp=11.309, rec=0.393, cos=0.267), tot_loss_proj:3.409 [t=0.18s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
Attempt swap
[1400/2000] tot_loss=2.882 (perp=11.309, rec=0.393, cos=0.227), tot_loss_proj:3.422 [t=0.28s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
Attempt swap
[1450/2000] tot_loss=2.861 (perp=11.309, rec=0.392, cos=0.207), tot_loss_proj:3.415 [t=0.19s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
[1500/2000] tot_loss=2.923 (perp=11.309, rec=0.385, cos=0.276), tot_loss_proj:3.413 [t=0.18s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
Attempt swap
[1550/2000] tot_loss=2.935 (perp=11.309, rec=0.388, cos=0.285), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
Attempt swap
[1600/2000] tot_loss=2.895 (perp=11.309, rec=0.379, cos=0.254), tot_loss_proj:3.419 [t=0.18s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
[1650/2000] tot_loss=2.895 (perp=11.309, rec=0.393, cos=0.240), tot_loss_proj:3.416 [t=0.21s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
Attempt swap
[1700/2000] tot_loss=2.924 (perp=11.309, rec=0.392, cos=0.270), tot_loss_proj:3.413 [t=0.33s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
Attempt swap
[1750/2000] tot_loss=2.945 (perp=11.309, rec=0.379, cos=0.304), tot_loss_proj:3.412 [t=0.21s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
[1800/2000] tot_loss=2.932 (perp=11.309, rec=0.387, cos=0.283), tot_loss_proj:3.413 [t=0.18s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
Attempt swap
[1850/2000] tot_loss=2.906 (perp=11.309, rec=0.383, cos=0.261), tot_loss_proj:3.411 [t=0.18s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
Attempt swap
[1900/2000] tot_loss=2.943 (perp=11.309, rec=0.381, cos=0.300), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
[1950/2000] tot_loss=2.943 (perp=11.309, rec=0.381, cos=0.300), tot_loss_proj:3.417 [t=0.20s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
Attempt swap
[2000/2000] tot_loss=2.937 (perp=11.309, rec=0.382, cos=0.292), tot_loss_proj:3.418 [t=0.18s]
prediction: ['[CLS] visually striking staged staged shape km² [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking staged staged shape km² [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 62.500 | r: 71.429
rouge2     | fm: 30.769 | p: 28.571 | r: 33.333
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 97.436

[Aggregate metrics]:
rouge1     | fm: 86.414 | p: 85.377 | r: 87.597
rouge2     | fm: 54.660 | p: 54.337 | r: 54.966
rougeL     | fm: 75.985 | p: 75.109 | r: 77.058
rougeLsum  | fm: 76.026 | p: 75.162 | r: 77.089
r1fm+r2fm = 141.075

input #46 time: 0:08:25 | total time: 6:33:09


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9210964831079044
highest_index [0]
highest [0.9210964831079044]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.680157482624054 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6527782082557678 for ['[CLS] spent excitedlychule [SEP]']
[Init] best rec loss: 0.6478413939476013 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6383236646652222 for ['[CLS] we processgon [SEP]']
[Init] best perm rec loss: 0.6358960270881653 for ['[CLS] process wegon [SEP]']
[Init] best perm rec loss: 0.6312295198440552 for ['[CLS] wegon process [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.999 (perp=12.424, rec=0.362, cos=0.152), tot_loss_proj:3.358 [t=0.18s]
prediction: ['[CLS]rightgon transparent [SEP]']
[ 100/2000] tot_loss=2.804 (perp=12.424, rec=0.215, cos=0.105), tot_loss_proj:3.347 [t=0.18s]
prediction: ['[CLS]rightgon transparent [SEP]']
[ 150/2000] tot_loss=2.814 (perp=12.723, rec=0.128, cos=0.141), tot_loss_proj:3.293 [t=0.20s]
prediction: ['[CLS]rightright transparent [SEP]']
[ 200/2000] tot_loss=2.781 (perp=12.723, rec=0.088, cos=0.148), tot_loss_proj:3.291 [t=0.18s]
prediction: ['[CLS]rightright transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.779 (perp=12.723, rec=0.085, cos=0.149), tot_loss_proj:3.293 [t=0.18s]
prediction: ['[CLS]rightright transparent [SEP]']
[ 300/2000] tot_loss=2.660 (perp=12.147, rec=0.082, cos=0.149), tot_loss_proj:3.124 [t=0.20s]
prediction: ['[CLS]right down transparent [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.975 (perp=8.803, rec=0.078, cos=0.136), tot_loss_proj:2.022 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.979 (perp=8.803, rec=0.074, cos=0.145), tot_loss_proj:2.016 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=1.996 (perp=8.803, rec=0.088, cos=0.148), tot_loss_proj:2.014 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.968 (perp=8.803, rec=0.059, cos=0.149), tot_loss_proj:2.026 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.976 (perp=8.803, rec=0.066, cos=0.149), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.970 (perp=8.803, rec=0.060, cos=0.150), tot_loss_proj:2.004 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.986 (perp=8.803, rec=0.076, cos=0.150), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.953 (perp=8.803, rec=0.043, cos=0.150), tot_loss_proj:2.010 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.967 (perp=8.803, rec=0.056, cos=0.150), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.989 (perp=8.803, rec=0.078, cos=0.150), tot_loss_proj:2.011 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.967 (perp=8.803, rec=0.056, cos=0.151), tot_loss_proj:2.004 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.976 (perp=8.803, rec=0.065, cos=0.151), tot_loss_proj:2.014 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.973 (perp=8.803, rec=0.061, cos=0.151), tot_loss_proj:2.012 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.966 (perp=8.803, rec=0.055, cos=0.151), tot_loss_proj:2.014 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.973 (perp=8.803, rec=0.061, cos=0.151), tot_loss_proj:2.011 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.968 (perp=8.803, rec=0.056, cos=0.151), tot_loss_proj:2.010 [t=0.29s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.971 (perp=8.803, rec=0.059, cos=0.151), tot_loss_proj:2.003 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.960 (perp=8.803, rec=0.048, cos=0.151), tot_loss_proj:1.988 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.963 (perp=8.803, rec=0.051, cos=0.151), tot_loss_proj:1.998 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.980 (perp=8.803, rec=0.068, cos=0.151), tot_loss_proj:2.011 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.970 (perp=8.803, rec=0.058, cos=0.151), tot_loss_proj:2.002 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.975 (perp=8.803, rec=0.063, cos=0.151), tot_loss_proj:2.010 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.966 (perp=8.803, rec=0.054, cos=0.151), tot_loss_proj:2.019 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.963 (perp=8.803, rec=0.052, cos=0.151), tot_loss_proj:2.007 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.976 (perp=8.803, rec=0.064, cos=0.151), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.972 (perp=8.803, rec=0.060, cos=0.151), tot_loss_proj:2.006 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.980 (perp=8.803, rec=0.068, cos=0.151), tot_loss_proj:2.007 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.966 (perp=8.803, rec=0.054, cos=0.151), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.965 (perp=8.803, rec=0.054, cos=0.151), tot_loss_proj:2.001 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.968 (perp=8.803, rec=0.057, cos=0.151), tot_loss_proj:1.998 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.971 (perp=8.803, rec=0.060, cos=0.151), tot_loss_proj:2.016 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.972 (perp=8.803, rec=0.060, cos=0.151), tot_loss_proj:2.000 [t=0.20s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.961 (perp=8.803, rec=0.049, cos=0.151), tot_loss_proj:2.012 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.961 (perp=8.803, rec=0.049, cos=0.151), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.639 | p: 85.716 | r: 87.857
rouge2     | fm: 55.238 | p: 54.957 | r: 55.558
rougeL     | fm: 76.551 | p: 75.682 | r: 77.638
rougeLsum  | fm: 76.506 | p: 75.648 | r: 77.519
r1fm+r2fm = 141.877

input #47 time: 0:08:12 | total time: 6:41:21


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.8668300724499803
highest_index [0]
highest [0.8668300724499803]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.8479083180427551 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.8357389569282532 for ['[CLS] however stage arts grounds [SEP]']
[Init] best rec loss: 0.8328295946121216 for ['[CLS] tonightste breadim [SEP]']
[Init] best rec loss: 0.7864534854888916 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 0.7647930979728699 for ['[CLS] graveyardtute runsdine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.271 (perp=13.907, rec=0.248, cos=0.242), tot_loss_proj:3.483 [t=0.18s]
prediction: ['[CLS] rotting illcusy [SEP]']
[ 100/2000] tot_loss=1.797 (perp=7.108, rec=0.129, cos=0.247), tot_loss_proj:1.747 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 150/2000] tot_loss=1.751 (perp=7.108, rec=0.084, cos=0.245), tot_loss_proj:1.743 [t=0.21s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 200/2000] tot_loss=1.739 (perp=7.108, rec=0.072, cos=0.245), tot_loss_proj:1.740 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.734 (perp=7.108, rec=0.072, cos=0.240), tot_loss_proj:1.744 [t=0.19s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 300/2000] tot_loss=1.717 (perp=7.108, rec=0.055, cos=0.240), tot_loss_proj:1.739 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.736 (perp=7.108, rec=0.068, cos=0.247), tot_loss_proj:1.753 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.741 (perp=7.108, rec=0.071, cos=0.248), tot_loss_proj:1.739 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 450/2000] tot_loss=1.739 (perp=7.108, rec=0.069, cos=0.248), tot_loss_proj:1.739 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.725 (perp=7.108, rec=0.055, cos=0.248), tot_loss_proj:1.739 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.741 (perp=7.108, rec=0.071, cos=0.248), tot_loss_proj:1.742 [t=0.26s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 600/2000] tot_loss=1.730 (perp=7.108, rec=0.060, cos=0.249), tot_loss_proj:1.737 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.732 (perp=7.108, rec=0.062, cos=0.249), tot_loss_proj:1.728 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.735 (perp=7.108, rec=0.065, cos=0.248), tot_loss_proj:1.741 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 750/2000] tot_loss=1.737 (perp=7.108, rec=0.067, cos=0.249), tot_loss_proj:1.746 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.732 (perp=7.108, rec=0.066, cos=0.245), tot_loss_proj:1.738 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.727 (perp=7.108, rec=0.057, cos=0.248), tot_loss_proj:1.730 [t=0.21s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 900/2000] tot_loss=1.721 (perp=7.108, rec=0.052, cos=0.248), tot_loss_proj:1.735 [t=0.22s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.726 (perp=7.108, rec=0.056, cos=0.248), tot_loss_proj:1.734 [t=0.29s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.724 (perp=7.108, rec=0.054, cos=0.248), tot_loss_proj:1.755 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1050/2000] tot_loss=1.735 (perp=7.108, rec=0.065, cos=0.248), tot_loss_proj:1.742 [t=0.30s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.721 (perp=7.108, rec=0.051, cos=0.248), tot_loss_proj:1.737 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.725 (perp=7.108, rec=0.055, cos=0.249), tot_loss_proj:1.723 [t=0.20s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1200/2000] tot_loss=1.732 (perp=7.108, rec=0.062, cos=0.248), tot_loss_proj:1.746 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.732 (perp=7.108, rec=0.061, cos=0.249), tot_loss_proj:1.720 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.722 (perp=7.108, rec=0.052, cos=0.248), tot_loss_proj:1.735 [t=0.25s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1350/2000] tot_loss=1.724 (perp=7.108, rec=0.056, cos=0.247), tot_loss_proj:1.725 [t=0.29s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.735 (perp=7.108, rec=0.066, cos=0.248), tot_loss_proj:1.741 [t=0.28s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.733 (perp=7.108, rec=0.063, cos=0.248), tot_loss_proj:1.740 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1500/2000] tot_loss=1.737 (perp=7.108, rec=0.067, cos=0.248), tot_loss_proj:1.738 [t=0.19s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.727 (perp=7.108, rec=0.057, cos=0.248), tot_loss_proj:1.737 [t=0.19s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.724 (perp=7.108, rec=0.054, cos=0.248), tot_loss_proj:1.746 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1650/2000] tot_loss=1.743 (perp=7.108, rec=0.073, cos=0.248), tot_loss_proj:1.735 [t=0.21s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.728 (perp=7.108, rec=0.058, cos=0.248), tot_loss_proj:1.736 [t=0.19s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.730 (perp=7.108, rec=0.060, cos=0.248), tot_loss_proj:1.737 [t=0.19s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1800/2000] tot_loss=1.737 (perp=7.108, rec=0.067, cos=0.248), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.731 (perp=7.108, rec=0.061, cos=0.249), tot_loss_proj:1.736 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.721 (perp=7.108, rec=0.051, cos=0.248), tot_loss_proj:1.722 [t=0.23s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1950/2000] tot_loss=1.726 (perp=7.108, rec=0.056, cos=0.248), tot_loss_proj:1.732 [t=0.19s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.733 (perp=7.108, rec=0.063, cos=0.248), tot_loss_proj:1.722 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbelly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.021 | p: 86.013 | r: 88.211
rouge2     | fm: 56.119 | p: 55.804 | r: 56.383
rougeL     | fm: 77.037 | p: 76.178 | r: 78.042
rougeLsum  | fm: 77.026 | p: 76.192 | r: 78.065
r1fm+r2fm = 143.139

input #48 time: 0:08:29 | total time: 6:49:51


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.8811121602702182
highest_index [0]
highest [0.8811121602702182]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8211744427680969 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7907794713973999 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7897942066192627 for ['[CLS] chargesbered harsh today dion craftsuvenssen tool break backup guest [SEP]']
[Init] best rec loss: 0.7684906125068665 for ['[CLS] genetic slideactic nations shed lawrence oral like era calvin accept mentor [SEP]']
[Init] best rec loss: 0.7646771669387817 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 0.7583569288253784 for ['[CLS] pyrenees answered bowling riding chloe minus bo language attentionocating nataya [SEP]']
[Init] best rec loss: 0.7555873990058899 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 0.7468352317810059 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best perm rec loss: 0.7447441220283508 for ['[CLS] major tried accompanied perrin whereuous he thingsanialtani our sheep [SEP]']
[Init] best perm rec loss: 0.7443644404411316 for ['[CLS]tani where our major perrinuous he things accompaniedanial sheep tried [SEP]']
[Init] best perm rec loss: 0.7434210777282715 for ['[CLS] sheepuous where major triedanial he perrin thingstani accompanied our [SEP]']
[Init] best perm rec loss: 0.7429347038269043 for ['[CLS] sheep whereanial accompanieduous things tried perrin hetani our major [SEP]']
[Init] best perm rec loss: 0.742235004901886 for ['[CLS]uous heanial perrin where things accompanied major our sheeptani tried [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.994 (perp=12.363, rec=0.344, cos=0.177), tot_loss_proj:3.639 [t=0.18s]
prediction: ['[CLS] any is contempt contempt female contemptier contempt other reserve ma wade [SEP]']
[ 100/2000] tot_loss=2.431 (perp=10.061, rec=0.209, cos=0.210), tot_loss_proj:3.096 [t=0.18s]
prediction: ['[CLS] could be contemptuous female contemptuous contempt more remaining females wade [SEP]']
[ 150/2000] tot_loss=2.466 (perp=10.542, rec=0.139, cos=0.219), tot_loss_proj:3.141 [t=0.21s]
prediction: ['[CLS] possibly be contemptuous female contemptuous contempt more remaining single wade [SEP]']
[ 200/2000] tot_loss=2.358 (perp=10.192, rec=0.104, cos=0.216), tot_loss_proj:2.941 [t=0.18s]
prediction: ['[CLS] possibly be contemptuous female contempt of contempt more be single population [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.254 (perp=9.695, rec=0.114, cos=0.200), tot_loss_proj:2.797 [t=0.22s]
prediction: ['[CLS] possibly be contemptuous of female single contempt more remaining single population [SEP]']
[ 300/2000] tot_loss=2.199 (perp=9.401, rec=0.096, cos=0.223), tot_loss_proj:2.696 [t=0.27s]
prediction: ['[CLS] possibly be contemptuous of female single contempt more being single population [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.076 (perp=8.842, rec=0.090, cos=0.218), tot_loss_proj:2.583 [t=0.22s]
prediction: ['[CLS] possibly be contemptuous of single female contempt more being single population [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.986 (perp=8.460, rec=0.094, cos=0.199), tot_loss_proj:2.552 [t=0.25s]
prediction: ['[CLS] possibly be contemptuous of single female more contempt being single population [SEP]']
[ 450/2000] tot_loss=1.905 (perp=8.021, rec=0.082, cos=0.219), tot_loss_proj:2.455 [t=0.20s]
prediction: ['[CLS] possibly be contemptuous of single female more contempt the single population [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.831 (perp=7.651, rec=0.086, cos=0.215), tot_loss_proj:2.185 [t=0.23s]
prediction: ['[CLS] possibly be more contemptuous of single female contempt the single population [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.838 (perp=7.651, rec=0.085, cos=0.222), tot_loss_proj:2.189 [t=0.24s]
prediction: ['[CLS] possibly be more contemptuous of single female contempt the single population [SEP]']
[ 600/2000] tot_loss=1.810 (perp=7.651, rec=0.075, cos=0.205), tot_loss_proj:2.191 [t=0.23s]
prediction: ['[CLS] possibly be more contemptuous of single female contempt the single population [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.765 (perp=7.305, rec=0.085, cos=0.220), tot_loss_proj:2.144 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single single female population [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.770 (perp=7.305, rec=0.086, cos=0.223), tot_loss_proj:2.134 [t=0.18s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single single female population [SEP]']
[ 750/2000] tot_loss=1.763 (perp=7.305, rec=0.086, cos=0.216), tot_loss_proj:2.139 [t=0.26s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single single female population [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.760 (perp=7.305, rec=0.078, cos=0.221), tot_loss_proj:2.136 [t=0.20s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single single female population [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.741 (perp=7.305, rec=0.092, cos=0.188), tot_loss_proj:2.139 [t=0.18s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single single female population [SEP]']
[ 900/2000] tot_loss=1.759 (perp=7.305, rec=0.082, cos=0.217), tot_loss_proj:2.139 [t=0.18s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single single female population [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.764 (perp=7.305, rec=0.081, cos=0.221), tot_loss_proj:2.137 [t=0.18s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single single female population [SEP]']
Attempt swap
[1000/2000] tot_loss=1.771 (perp=7.305, rec=0.087, cos=0.223), tot_loss_proj:2.137 [t=0.19s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single single female population [SEP]']
[1050/2000] tot_loss=1.761 (perp=7.305, rec=0.084, cos=0.215), tot_loss_proj:2.136 [t=0.22s]
prediction: ['[CLS] possibly be more contemptuous of contempt the single single female population [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.698 (perp=6.995, rec=0.084, cos=0.215), tot_loss_proj:2.065 [t=0.18s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1150/2000] tot_loss=1.699 (perp=6.995, rec=0.082, cos=0.217), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
[1200/2000] tot_loss=1.705 (perp=6.995, rec=0.087, cos=0.220), tot_loss_proj:2.070 [t=0.18s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1250/2000] tot_loss=1.695 (perp=6.995, rec=0.075, cos=0.221), tot_loss_proj:2.063 [t=0.18s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1300/2000] tot_loss=1.707 (perp=6.995, rec=0.086, cos=0.222), tot_loss_proj:2.066 [t=0.19s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
[1350/2000] tot_loss=1.705 (perp=6.995, rec=0.084, cos=0.223), tot_loss_proj:2.066 [t=0.19s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1400/2000] tot_loss=1.702 (perp=6.995, rec=0.079, cos=0.224), tot_loss_proj:2.064 [t=0.19s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1450/2000] tot_loss=1.693 (perp=6.995, rec=0.079, cos=0.215), tot_loss_proj:2.062 [t=0.20s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
[1500/2000] tot_loss=1.690 (perp=6.995, rec=0.072, cos=0.219), tot_loss_proj:2.065 [t=0.18s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1550/2000] tot_loss=1.698 (perp=6.995, rec=0.078, cos=0.221), tot_loss_proj:2.069 [t=0.21s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1600/2000] tot_loss=1.708 (perp=6.995, rec=0.087, cos=0.222), tot_loss_proj:2.065 [t=0.19s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
[1650/2000] tot_loss=1.701 (perp=6.995, rec=0.080, cos=0.222), tot_loss_proj:2.057 [t=0.18s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1700/2000] tot_loss=1.702 (perp=6.995, rec=0.080, cos=0.223), tot_loss_proj:2.069 [t=0.21s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1750/2000] tot_loss=1.703 (perp=6.995, rec=0.081, cos=0.223), tot_loss_proj:2.072 [t=0.18s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
[1800/2000] tot_loss=1.691 (perp=6.995, rec=0.079, cos=0.213), tot_loss_proj:2.068 [t=0.19s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1850/2000] tot_loss=1.701 (perp=6.995, rec=0.083, cos=0.219), tot_loss_proj:2.060 [t=0.18s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[1900/2000] tot_loss=1.694 (perp=6.995, rec=0.074, cos=0.220), tot_loss_proj:2.065 [t=0.22s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
[1950/2000] tot_loss=1.696 (perp=6.995, rec=0.076, cos=0.221), tot_loss_proj:2.055 [t=0.18s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Attempt swap
[2000/2000] tot_loss=1.702 (perp=6.995, rec=0.082, cos=0.221), tot_loss_proj:2.070 [t=0.19s]
prediction: ['[CLS] possibly contempt be more contemptuous of the single single female population [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] possibly contempt be more contemptuous of the single single female population [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 69.565 | p: 66.667 | r: 72.727
rougeL     | fm: 88.000 | p: 84.615 | r: 91.667
rougeLsum  | fm: 88.000 | p: 84.615 | r: 91.667
r1fm+r2fm = 157.565

[Aggregate metrics]:
rouge1     | fm: 87.004 | p: 86.004 | r: 88.244
rouge2     | fm: 56.461 | p: 56.147 | r: 56.779
rougeL     | fm: 77.359 | p: 76.423 | r: 78.345
rougeLsum  | fm: 77.280 | p: 76.382 | r: 78.315
r1fm+r2fm = 143.465

input #49 time: 0:08:12 | total time: 6:58:03


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.913139485865287
highest_index [0]
highest [0.913139485865287]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.8139981627464294 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8115299940109253 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.8046776652336121 for ['[CLS] felt defended drop ring richard spade frank beds₁ [SEP]']
[Init] best rec loss: 0.790791928768158 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7739521861076355 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7693169116973877 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best rec loss: 0.7591160535812378 for ['[CLS] stone sex science cheeks prolific conventionwashed in once [SEP]']
[Init] best rec loss: 0.7556005120277405 for ['[CLS]sil state grade over ing fish champion woolf good [SEP]']
[Init] best perm rec loss: 0.7543591260910034 for ['[CLS] good statesil over ing fish woolf champion grade [SEP]']
[Init] best perm rec loss: 0.7521976232528687 for ['[CLS]sil champion over fish good ing woolf state grade [SEP]']
[Init] best perm rec loss: 0.7518901824951172 for ['[CLS] fish champion grade state ing over good woolfsil [SEP]']
[Init] best perm rec loss: 0.7516491413116455 for ['[CLS] state over fish goodsil grade woolf champion ing [SEP]']
[Init] best perm rec loss: 0.7510772347450256 for ['[CLS] championsil fish over ing good grade state woolf [SEP]']
[Init] best perm rec loss: 0.7508955001831055 for ['[CLS] state champion good fishsil ing over grade woolf [SEP]']
[Init] best perm rec loss: 0.7500603795051575 for ['[CLS] woolf fish state grade champion over ing goodsil [SEP]']
[Init] best perm rec loss: 0.7494751811027527 for ['[CLS] grade champion state over good fish ingsil woolf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.722 (perp=10.862, rec=0.412, cos=0.138), tot_loss_proj:3.470 [t=0.18s]
prediction: ['[CLS] deaf after have the fortune too easily american clever [SEP]']
[ 100/2000] tot_loss=2.714 (perp=11.158, rec=0.352, cos=0.130), tot_loss_proj:3.878 [t=0.26s]
prediction: ['[CLS] deaf after have the au too too english clever [SEP]']
[ 150/2000] tot_loss=2.481 (perp=10.378, rec=0.247, cos=0.159), tot_loss_proj:3.427 [t=0.23s]
prediction: ['[CLS] clever after called by half percent too english clever [SEP]']
[ 200/2000] tot_loss=2.088 (perp=8.852, rec=0.173, cos=0.144), tot_loss_proj:2.778 [t=0.25s]
prediction: ['[CLS] what the call by half half too english clever [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.821 (perp=7.593, rec=0.167, cos=0.135), tot_loss_proj:2.210 [t=0.25s]
prediction: ['[CLS] what the english call by half half too clever [SEP]']
[ 300/2000] tot_loss=1.789 (perp=7.593, rec=0.115, cos=0.155), tot_loss_proj:2.223 [t=0.22s]
prediction: ['[CLS] what the english call by half half too clever [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.643 (perp=6.901, rec=0.114, cos=0.149), tot_loss_proj:2.019 [t=0.18s]
prediction: ['[CLS] what the english call half by half too clever [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.862 (perp=8.037, rec=0.094, cos=0.161), tot_loss_proj:2.198 [t=0.20s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[ 450/2000] tot_loss=1.857 (perp=8.037, rec=0.084, cos=0.166), tot_loss_proj:2.208 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.841 (perp=8.037, rec=0.074, cos=0.159), tot_loss_proj:2.214 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.848 (perp=8.037, rec=0.078, cos=0.162), tot_loss_proj:2.213 [t=0.24s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[ 600/2000] tot_loss=1.827 (perp=8.037, rec=0.057, cos=0.163), tot_loss_proj:2.214 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.844 (perp=8.037, rec=0.074, cos=0.163), tot_loss_proj:2.211 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.838 (perp=8.037, rec=0.067, cos=0.163), tot_loss_proj:2.209 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[ 750/2000] tot_loss=1.836 (perp=8.037, rec=0.065, cos=0.164), tot_loss_proj:2.206 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.837 (perp=8.037, rec=0.066, cos=0.164), tot_loss_proj:2.208 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.837 (perp=8.037, rec=0.065, cos=0.164), tot_loss_proj:2.216 [t=0.23s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[ 900/2000] tot_loss=1.853 (perp=8.037, rec=0.081, cos=0.164), tot_loss_proj:2.208 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.837 (perp=8.037, rec=0.066, cos=0.164), tot_loss_proj:2.213 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.837 (perp=8.037, rec=0.065, cos=0.165), tot_loss_proj:2.214 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1050/2000] tot_loss=1.845 (perp=8.037, rec=0.073, cos=0.165), tot_loss_proj:2.209 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.826 (perp=8.037, rec=0.054, cos=0.165), tot_loss_proj:2.213 [t=0.23s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.844 (perp=8.037, rec=0.072, cos=0.165), tot_loss_proj:2.208 [t=0.17s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1200/2000] tot_loss=1.845 (perp=8.037, rec=0.072, cos=0.165), tot_loss_proj:2.206 [t=0.17s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.837 (perp=8.037, rec=0.065, cos=0.165), tot_loss_proj:2.211 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.841 (perp=8.037, rec=0.069, cos=0.165), tot_loss_proj:2.213 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1350/2000] tot_loss=1.845 (perp=8.037, rec=0.073, cos=0.165), tot_loss_proj:2.216 [t=0.28s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.831 (perp=8.037, rec=0.058, cos=0.165), tot_loss_proj:2.213 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.837 (perp=8.037, rec=0.065, cos=0.165), tot_loss_proj:2.211 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1500/2000] tot_loss=1.828 (perp=8.037, rec=0.055, cos=0.165), tot_loss_proj:2.209 [t=0.24s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.836 (perp=8.037, rec=0.064, cos=0.165), tot_loss_proj:2.208 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.835 (perp=8.037, rec=0.062, cos=0.165), tot_loss_proj:2.210 [t=0.23s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1650/2000] tot_loss=1.848 (perp=8.037, rec=0.075, cos=0.165), tot_loss_proj:2.212 [t=0.22s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1700/2000] tot_loss=1.847 (perp=8.037, rec=0.075, cos=0.165), tot_loss_proj:2.215 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.829 (perp=8.037, rec=0.056, cos=0.165), tot_loss_proj:2.209 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1800/2000] tot_loss=1.846 (perp=8.037, rec=0.073, cos=0.165), tot_loss_proj:2.206 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.840 (perp=8.037, rec=0.068, cos=0.165), tot_loss_proj:2.207 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.835 (perp=8.037, rec=0.062, cos=0.165), tot_loss_proj:2.199 [t=0.22s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1950/2000] tot_loss=1.840 (perp=8.037, rec=0.067, cos=0.165), tot_loss_proj:2.213 [t=0.25s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.838 (perp=8.037, rec=0.065, cos=0.165), tot_loss_proj:2.203 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what the english call ` by half too clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 166.667

[Aggregate metrics]:
rouge1     | fm: 87.185 | p: 86.154 | r: 88.372
rouge2     | fm: 56.671 | p: 56.338 | r: 57.009
rougeL     | fm: 77.279 | p: 76.494 | r: 78.300
rougeLsum  | fm: 77.463 | p: 76.634 | r: 78.507
r1fm+r2fm = 143.856

input #50 time: 0:08:17 | total time: 7:06:20


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.920556651730466
highest_index [0]
highest [0.920556651730466]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.7894165515899658 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7643147706985474 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.740355908870697 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7355148196220398 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 0.7151234745979309 for ['[CLS] low reelection honest louis caps noah lieutenant quarter consequence handwriting [SEP]']
[Init] best rec loss: 0.7090040445327759 for ['[CLS] acute jay outies harbor recognitionitung annezzled hughes [SEP]']
[Init] best rec loss: 0.7059914469718933 for ['[CLS] thomas hugh anymore customer minute premises nuclear nothingnodro [SEP]']
[Init] best perm rec loss: 0.7050129771232605 for ['[CLS] nothing nuclear minute premises thomas hughno anymoredro customer [SEP]']
[Init] best perm rec loss: 0.704976499080658 for ['[CLS] premises nothing hughdro nuclear anymoreno customer thomas minute [SEP]']
[Init] best perm rec loss: 0.7044456601142883 for ['[CLS] nucleardro anymoreno premises hugh customer thomas nothing minute [SEP]']
[Init] best perm rec loss: 0.7019909024238586 for ['[CLS] anymore nucleardro hugh nothingno thomas minute premises customer [SEP]']
[Init] best perm rec loss: 0.7001890540122986 for ['[CLS] nothing hugh premises thomas customerdro nuclear minute anymoreno [SEP]']
[Init] best perm rec loss: 0.6998756527900696 for ['[CLS]no nothing nuclear anymore customerdro minute hugh thomas premises [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.923 (perp=11.912, rec=0.420, cos=0.121), tot_loss_proj:3.631 [t=0.25s]
prediction: ['[CLS] sucks bits socceres money funny minute sucked feeling literally [SEP]']
[ 100/2000] tot_loss=3.297 (perp=12.466, rec=0.403, cos=0.402), tot_loss_proj:3.423 [t=0.18s]
prediction: ['[CLS] sucks and year condition money funny minute sucks funny moment [SEP]']
[ 150/2000] tot_loss=2.865 (perp=12.260, rec=0.281, cos=0.132), tot_loss_proj:3.516 [t=0.22s]
prediction: ['[CLS] sucks has forestry some visit funny maybe sucks funny funny [SEP]']
[ 200/2000] tot_loss=2.106 (perp=8.987, rec=0.202, cos=0.106), tot_loss_proj:2.844 [t=0.18s]
prediction: ['[CLS] sucks but has a moment funny or sucks funny funny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.060 (perp=8.715, rec=0.200, cos=0.117), tot_loss_proj:2.659 [t=0.21s]
prediction: ['[CLS] sucks but has a moment funny or funny funny sucks [SEP]']
[ 300/2000] tot_loss=2.012 (perp=8.715, rec=0.124, cos=0.145), tot_loss_proj:2.657 [t=0.26s]
prediction: ['[CLS] sucks but has a moment funny or funny funny sucks [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.740 (perp=7.491, rec=0.118, cos=0.124), tot_loss_proj:2.391 [t=0.19s]
prediction: ['[CLS] but has a moment funny sucks or funny funny sucks [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.740 (perp=7.491, rec=0.100, cos=0.142), tot_loss_proj:2.389 [t=0.18s]
prediction: ['[CLS] but has a moment funny sucks or funny funny sucks [SEP]']
[ 450/2000] tot_loss=1.867 (perp=8.045, rec=0.109, cos=0.149), tot_loss_proj:2.404 [t=0.18s]
prediction: ['[CLS] but has a moment funny sucks or funny moment sucks [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.723 (perp=7.520, rec=0.102, cos=0.116), tot_loss_proj:2.447 [t=0.18s]
prediction: ['[CLS] but has a moment funny or funny moment sucks sucks [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.731 (perp=7.520, rec=0.094, cos=0.133), tot_loss_proj:2.447 [t=0.18s]
prediction: ['[CLS] but has a moment funny or funny moment sucks sucks [SEP]']
[ 600/2000] tot_loss=1.740 (perp=7.520, rec=0.095, cos=0.141), tot_loss_proj:2.450 [t=0.19s]
prediction: ['[CLS] but has a moment funny or funny moment sucks sucks [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.735 (perp=7.469, rec=0.096, cos=0.145), tot_loss_proj:2.372 [t=0.25s]
prediction: ['[CLS] but has a funny moment or funny moment sucks sucks [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.747 (perp=7.469, rec=0.104, cos=0.148), tot_loss_proj:2.371 [t=0.26s]
prediction: ['[CLS] but has a funny moment or funny moment sucks sucks [SEP]']
[ 750/2000] tot_loss=1.741 (perp=7.469, rec=0.097, cos=0.150), tot_loss_proj:2.374 [t=0.18s]
prediction: ['[CLS] but has a funny moment or funny moment sucks sucks [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.859 (perp=8.138, rec=0.088, cos=0.143), tot_loss_proj:2.405 [t=0.25s]
prediction: ['[CLS] but has a uncomfortable funny moment or funny sucks sucks [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.745 (perp=7.705, rec=0.098, cos=0.106), tot_loss_proj:2.672 [t=0.24s]
prediction: ['[CLS] but has a funny funny moment or uncomfortable sucks sucks [SEP]']
[ 900/2000] tot_loss=1.845 (perp=8.117, rec=0.089, cos=0.132), tot_loss_proj:2.404 [t=0.21s]
prediction: ['[CLS] but has a, funny moment or uncomfortable sucks sucks [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.609 (perp=6.913, rec=0.087, cos=0.139), tot_loss_proj:2.188 [t=0.18s]
prediction: ['[CLS] but has a funny moment or moment, sucks sucks [SEP]']
Attempt swap
[1000/2000] tot_loss=1.614 (perp=6.913, rec=0.088, cos=0.143), tot_loss_proj:2.188 [t=0.18s]
prediction: ['[CLS] but has a funny moment or moment, sucks sucks [SEP]']
[1050/2000] tot_loss=1.620 (perp=6.913, rec=0.091, cos=0.146), tot_loss_proj:2.190 [t=0.18s]
prediction: ['[CLS] but has a funny moment or moment, sucks sucks [SEP]']
Attempt swap
[1100/2000] tot_loss=1.616 (perp=6.913, rec=0.086, cos=0.148), tot_loss_proj:2.195 [t=0.20s]
prediction: ['[CLS] but has a funny moment or moment, sucks sucks [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.551 (perp=6.626, rec=0.094, cos=0.131), tot_loss_proj:2.698 [t=0.18s]
prediction: ['[CLS] but has a funny moment moment, sucks or sucks [SEP]']
[1200/2000] tot_loss=1.550 (perp=6.626, rec=0.084, cos=0.141), tot_loss_proj:2.703 [t=0.18s]
prediction: ['[CLS] but has a funny moment moment, sucks or sucks [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.501 (perp=6.357, rec=0.085, cos=0.145), tot_loss_proj:2.449 [t=0.19s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Attempt swap
[1300/2000] tot_loss=1.507 (perp=6.357, rec=0.089, cos=0.146), tot_loss_proj:2.449 [t=0.27s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
[1350/2000] tot_loss=1.502 (perp=6.357, rec=0.082, cos=0.148), tot_loss_proj:2.448 [t=0.22s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Attempt swap
[1400/2000] tot_loss=1.507 (perp=6.357, rec=0.086, cos=0.149), tot_loss_proj:2.450 [t=0.18s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Attempt swap
[1450/2000] tot_loss=1.508 (perp=6.357, rec=0.087, cos=0.150), tot_loss_proj:2.449 [t=0.23s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
[1500/2000] tot_loss=1.511 (perp=6.357, rec=0.089, cos=0.151), tot_loss_proj:2.447 [t=0.18s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Attempt swap
[1550/2000] tot_loss=1.515 (perp=6.357, rec=0.092, cos=0.151), tot_loss_proj:2.446 [t=0.18s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Attempt swap
[1600/2000] tot_loss=1.516 (perp=6.357, rec=0.093, cos=0.152), tot_loss_proj:2.446 [t=0.20s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
[1650/2000] tot_loss=1.517 (perp=6.357, rec=0.093, cos=0.152), tot_loss_proj:2.444 [t=0.18s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Attempt swap
[1700/2000] tot_loss=1.504 (perp=6.357, rec=0.084, cos=0.148), tot_loss_proj:2.446 [t=0.22s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Attempt swap
[1750/2000] tot_loss=1.521 (perp=6.357, rec=0.099, cos=0.150), tot_loss_proj:2.453 [t=0.19s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
[1800/2000] tot_loss=1.517 (perp=6.357, rec=0.094, cos=0.152), tot_loss_proj:2.446 [t=0.18s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Attempt swap
[1850/2000] tot_loss=1.505 (perp=6.357, rec=0.081, cos=0.152), tot_loss_proj:2.445 [t=0.22s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Attempt swap
[1900/2000] tot_loss=1.505 (perp=6.357, rec=0.086, cos=0.147), tot_loss_proj:2.452 [t=0.21s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
[1950/2000] tot_loss=1.509 (perp=6.357, rec=0.087, cos=0.150), tot_loss_proj:2.447 [t=0.26s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Attempt swap
[2000/2000] tot_loss=1.509 (perp=6.357, rec=0.087, cos=0.151), tot_loss_proj:2.448 [t=0.18s]
prediction: ['[CLS] but has a moment funny moment, sucks or sucks [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] but has a moment funny moment, sucks or sucks [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 31.579 | p: 30.000 | r: 33.333
rougeL     | fm: 76.190 | p: 72.727 | r: 80.000
rougeLsum  | fm: 76.190 | p: 72.727 | r: 80.000
r1fm+r2fm = 117.293

[Aggregate metrics]:
rouge1     | fm: 87.195 | p: 86.157 | r: 88.459
rouge2     | fm: 56.092 | p: 55.721 | r: 56.458
rougeL     | fm: 77.244 | p: 76.308 | r: 78.351
rougeLsum  | fm: 77.403 | p: 76.474 | r: 78.431
r1fm+r2fm = 143.287

input #51 time: 0:08:16 | total time: 7:14:36


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.8746205032401183
highest_index [0]
highest [0.8746205032401183]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9412736892700195 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.931817889213562 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.9254830479621887 for ['[CLS]fa bear gun [SEP]']
[Init] best rec loss: 0.9227439165115356 for ['[CLS] tree partition themed [SEP]']
[Init] best rec loss: 0.9064809083938599 for ['[CLS] news implies lack [SEP]']
[Init] best rec loss: 0.8838274478912354 for ['[CLS] transition content distance [SEP]']
[Init] best rec loss: 0.8721992373466492 for ['[CLS] nations gazette probability [SEP]']
[Init] best rec loss: 0.7550472617149353 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7414774894714355 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.735851526260376 for ['[CLS] expected football vocabulary [SEP]']
[Init] best perm rec loss: 0.7354347705841064 for ['[CLS] vocabulary expected football [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.629 (perp=10.754, rec=0.247, cos=0.231), tot_loss_proj:3.093 [t=0.24s]
prediction: ['[CLS] trash trash trash [SEP]']
[ 100/2000] tot_loss=2.731 (perp=11.737, rec=0.154, cos=0.230), tot_loss_proj:2.920 [t=0.18s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.431 (perp=10.528, rec=0.099, cos=0.226), tot_loss_proj:2.429 [t=0.18s]
prediction: ['[CLS] trailer - trash [SEP]']
[ 200/2000] tot_loss=2.418 (perp=10.528, rec=0.078, cos=0.234), tot_loss_proj:2.429 [t=0.27s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.026 (perp=8.482, rec=0.107, cos=0.222), tot_loss_proj:2.356 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.997 (perp=8.482, rec=0.072, cos=0.228), tot_loss_proj:2.353 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.018 (perp=8.482, rec=0.088, cos=0.233), tot_loss_proj:2.345 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.995 (perp=8.482, rec=0.065, cos=0.234), tot_loss_proj:2.343 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.997 (perp=8.482, rec=0.070, cos=0.231), tot_loss_proj:2.342 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.996 (perp=8.482, rec=0.066, cos=0.233), tot_loss_proj:2.342 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.003 (perp=8.482, rec=0.072, cos=0.234), tot_loss_proj:2.339 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.996 (perp=8.482, rec=0.065, cos=0.234), tot_loss_proj:2.337 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.988 (perp=8.482, rec=0.057, cos=0.235), tot_loss_proj:2.334 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.998 (perp=8.482, rec=0.067, cos=0.235), tot_loss_proj:2.339 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.995 (perp=8.482, rec=0.064, cos=0.235), tot_loss_proj:2.335 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.998 (perp=8.482, rec=0.067, cos=0.235), tot_loss_proj:2.350 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.993 (perp=8.482, rec=0.062, cos=0.235), tot_loss_proj:2.344 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.995 (perp=8.482, rec=0.063, cos=0.235), tot_loss_proj:2.332 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.003 (perp=8.482, rec=0.072, cos=0.235), tot_loss_proj:2.343 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.996 (perp=8.482, rec=0.065, cos=0.235), tot_loss_proj:2.337 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.989 (perp=8.482, rec=0.058, cos=0.235), tot_loss_proj:2.341 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.995 (perp=8.482, rec=0.064, cos=0.235), tot_loss_proj:2.336 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=2.002 (perp=8.482, rec=0.070, cos=0.235), tot_loss_proj:2.340 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.998 (perp=8.482, rec=0.067, cos=0.235), tot_loss_proj:2.347 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.987 (perp=8.482, rec=0.056, cos=0.235), tot_loss_proj:2.344 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.992 (perp=8.482, rec=0.061, cos=0.235), tot_loss_proj:2.342 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.984 (perp=8.482, rec=0.053, cos=0.234), tot_loss_proj:2.345 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.996 (perp=8.482, rec=0.065, cos=0.234), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=2.001 (perp=8.482, rec=0.070, cos=0.234), tot_loss_proj:2.346 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.989 (perp=8.482, rec=0.057, cos=0.235), tot_loss_proj:2.337 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.999 (perp=8.482, rec=0.068, cos=0.235), tot_loss_proj:2.338 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.995 (perp=8.482, rec=0.064, cos=0.235), tot_loss_proj:2.344 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.990 (perp=8.482, rec=0.059, cos=0.235), tot_loss_proj:2.340 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.995 (perp=8.482, rec=0.064, cos=0.235), tot_loss_proj:2.348 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.986 (perp=8.482, rec=0.054, cos=0.235), tot_loss_proj:2.337 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.999 (perp=8.482, rec=0.068, cos=0.235), tot_loss_proj:2.330 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.998 (perp=8.482, rec=0.067, cos=0.235), tot_loss_proj:2.341 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=2.004 (perp=8.482, rec=0.073, cos=0.235), tot_loss_proj:2.340 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.997 (perp=8.482, rec=0.066, cos=0.235), tot_loss_proj:2.343 [t=0.28s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=2.004 (perp=8.482, rec=0.073, cos=0.235), tot_loss_proj:2.336 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.449 | p: 86.376 | r: 88.718
rouge2     | fm: 55.146 | p: 54.787 | r: 55.557
rougeL     | fm: 77.271 | p: 76.375 | r: 78.369
rougeLsum  | fm: 77.283 | p: 76.392 | r: 78.314
r1fm+r2fm = 142.595

input #52 time: 0:08:25 | total time: 7:23:02


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9184780432370033
highest_index [0]
highest [0.9184780432370033]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.8117914199829102 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.8023384809494019 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 0.7110341191291809 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.7058405876159668 for ['[CLS] annually ability [SEP]']
[Init] best rec loss: 0.6862760782241821 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6853902339935303 for ['[CLS] nick design [SEP]']
[Init] best perm rec loss: 0.6845585703849792 for ['[CLS] design nick [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.857 (perp=12.493, rec=0.220, cos=0.138), tot_loss_proj:3.374 [t=0.22s]
prediction: ['[CLS] bleeding flinch [SEP]']
[ 100/2000] tot_loss=2.781 (perp=12.492, rec=0.129, cos=0.154), tot_loss_proj:3.401 [t=0.24s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.720 (perp=12.413, rec=0.081, cos=0.156), tot_loss_proj:3.336 [t=0.19s]
prediction: ['[CLS]ing flinch [SEP]']
[ 200/2000] tot_loss=2.721 (perp=12.413, rec=0.084, cos=0.155), tot_loss_proj:3.327 [t=0.18s]
prediction: ['[CLS]ing flinch [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.871 (perp=8.090, rec=0.111, cos=0.142), tot_loss_proj:1.872 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.826 (perp=8.090, rec=0.063, cos=0.146), tot_loss_proj:1.866 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.834 (perp=8.090, rec=0.064, cos=0.152), tot_loss_proj:1.870 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.834 (perp=8.090, rec=0.062, cos=0.154), tot_loss_proj:1.867 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.831 (perp=8.090, rec=0.058, cos=0.155), tot_loss_proj:1.867 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.848 (perp=8.090, rec=0.075, cos=0.155), tot_loss_proj:1.870 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.837 (perp=8.090, rec=0.063, cos=0.156), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.841 (perp=8.090, rec=0.067, cos=0.156), tot_loss_proj:1.868 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.837 (perp=8.090, rec=0.063, cos=0.156), tot_loss_proj:1.863 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.832 (perp=8.090, rec=0.059, cos=0.156), tot_loss_proj:1.863 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.836 (perp=8.090, rec=0.062, cos=0.156), tot_loss_proj:1.861 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.831 (perp=8.090, rec=0.056, cos=0.156), tot_loss_proj:1.876 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.827 (perp=8.090, rec=0.053, cos=0.156), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.828 (perp=8.090, rec=0.061, cos=0.150), tot_loss_proj:1.866 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.839 (perp=8.090, rec=0.067, cos=0.155), tot_loss_proj:1.873 [t=0.20s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.843 (perp=8.090, rec=0.070, cos=0.155), tot_loss_proj:1.859 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.832 (perp=8.090, rec=0.058, cos=0.156), tot_loss_proj:1.874 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.839 (perp=8.090, rec=0.066, cos=0.156), tot_loss_proj:1.868 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.832 (perp=8.090, rec=0.059, cos=0.156), tot_loss_proj:1.861 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.823 (perp=8.090, rec=0.049, cos=0.156), tot_loss_proj:1.858 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.827 (perp=8.090, rec=0.053, cos=0.156), tot_loss_proj:1.867 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.855 (perp=8.090, rec=0.081, cos=0.156), tot_loss_proj:1.856 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.822 (perp=8.090, rec=0.048, cos=0.156), tot_loss_proj:1.854 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.832 (perp=8.090, rec=0.058, cos=0.156), tot_loss_proj:1.856 [t=0.20s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.831 (perp=8.090, rec=0.057, cos=0.156), tot_loss_proj:1.864 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.837 (perp=8.090, rec=0.063, cos=0.156), tot_loss_proj:1.870 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.831 (perp=8.090, rec=0.057, cos=0.156), tot_loss_proj:1.863 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.825 (perp=8.090, rec=0.050, cos=0.156), tot_loss_proj:1.863 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.845 (perp=8.090, rec=0.071, cos=0.156), tot_loss_proj:1.863 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.835 (perp=8.090, rec=0.060, cos=0.156), tot_loss_proj:1.868 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.827 (perp=8.090, rec=0.053, cos=0.156), tot_loss_proj:1.862 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.827 (perp=8.090, rec=0.053, cos=0.156), tot_loss_proj:1.863 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.829 (perp=8.090, rec=0.055, cos=0.156), tot_loss_proj:1.866 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.831 (perp=8.090, rec=0.056, cos=0.156), tot_loss_proj:1.866 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.834 (perp=8.090, rec=0.060, cos=0.156), tot_loss_proj:1.868 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.829 (perp=8.090, rec=0.055, cos=0.156), tot_loss_proj:1.865 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.603 | p: 86.608 | r: 88.846
rouge2     | fm: 56.050 | p: 55.677 | r: 56.457
rougeL     | fm: 77.770 | p: 76.910 | r: 78.748
rougeLsum  | fm: 77.762 | p: 76.902 | r: 78.789
r1fm+r2fm = 143.654

input #53 time: 0:08:17 | total time: 7:31:20


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.8485995653884038
highest_index [0]
highest [0.8485995653884038]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.7807595729827881 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.7761977314949036 for ['[CLS] ally strategy [SEP]']
[Init] best rec loss: 0.7466639280319214 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 0.6990384459495544 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.667998194694519 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.6608018279075623 for ['[CLS] deployment bro [SEP]']
[Init] best rec loss: 0.649595320224762 for ['[CLS] teresa spanish [SEP]']
[Init] best rec loss: 0.6473661065101624 for ['[CLS] wild exercised [SEP]']
[Init] best rec loss: 0.6470465660095215 for ['[CLS] facilitate tom [SEP]']
[Init] best perm rec loss: 0.6423064470291138 for ['[CLS] tom facilitate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.407 (perp=8.750, rec=0.394, cos=0.262), tot_loss_proj:2.417 [t=0.18s]
prediction: ['[CLS] hot meetings [SEP]']
[ 100/2000] tot_loss=2.044 (perp=8.198, rec=0.135, cos=0.270), tot_loss_proj:2.024 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=2.018 (perp=8.198, rec=0.107, cos=0.272), tot_loss_proj:2.026 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.998 (perp=8.198, rec=0.084, cos=0.275), tot_loss_proj:2.032 [t=0.29s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.001 (perp=8.198, rec=0.083, cos=0.279), tot_loss_proj:2.007 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.965 (perp=8.198, rec=0.077, cos=0.248), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.985 (perp=8.198, rec=0.082, cos=0.264), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.009 (perp=8.198, rec=0.099, cos=0.270), tot_loss_proj:2.027 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.993 (perp=8.198, rec=0.099, cos=0.255), tot_loss_proj:2.026 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.970 (perp=8.198, rec=0.053, cos=0.278), tot_loss_proj:2.022 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.979 (perp=8.198, rec=0.063, cos=0.276), tot_loss_proj:2.033 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.975 (perp=8.198, rec=0.057, cos=0.278), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.974 (perp=8.198, rec=0.056, cos=0.279), tot_loss_proj:2.002 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.974 (perp=8.198, rec=0.056, cos=0.279), tot_loss_proj:2.026 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.980 (perp=8.198, rec=0.061, cos=0.279), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.964 (perp=8.198, rec=0.045, cos=0.279), tot_loss_proj:2.007 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.966 (perp=8.198, rec=0.047, cos=0.279), tot_loss_proj:2.022 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.968 (perp=8.198, rec=0.049, cos=0.279), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.986 (perp=8.198, rec=0.068, cos=0.279), tot_loss_proj:2.028 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.981 (perp=8.198, rec=0.063, cos=0.279), tot_loss_proj:2.018 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.996 (perp=8.198, rec=0.077, cos=0.279), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.982 (perp=8.198, rec=0.064, cos=0.279), tot_loss_proj:2.019 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.979 (perp=8.198, rec=0.059, cos=0.280), tot_loss_proj:2.011 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.981 (perp=8.198, rec=0.062, cos=0.280), tot_loss_proj:2.015 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.986 (perp=8.198, rec=0.067, cos=0.280), tot_loss_proj:2.027 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.971 (perp=8.198, rec=0.052, cos=0.280), tot_loss_proj:2.015 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.986 (perp=8.198, rec=0.067, cos=0.280), tot_loss_proj:2.014 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.976 (perp=8.198, rec=0.057, cos=0.280), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.974 (perp=8.198, rec=0.054, cos=0.280), tot_loss_proj:2.013 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.968 (perp=8.198, rec=0.049, cos=0.280), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.985 (perp=8.198, rec=0.066, cos=0.280), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.980 (perp=8.198, rec=0.061, cos=0.280), tot_loss_proj:2.026 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.965 (perp=8.198, rec=0.048, cos=0.278), tot_loss_proj:2.015 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.974 (perp=8.198, rec=0.056, cos=0.279), tot_loss_proj:2.020 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.984 (perp=8.198, rec=0.065, cos=0.279), tot_loss_proj:2.019 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.986 (perp=8.198, rec=0.068, cos=0.279), tot_loss_proj:2.017 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.986 (perp=8.198, rec=0.067, cos=0.279), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.979 (perp=8.198, rec=0.060, cos=0.279), tot_loss_proj:2.023 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.996 (perp=8.198, rec=0.077, cos=0.279), tot_loss_proj:2.019 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.973 (perp=8.198, rec=0.054, cos=0.279), tot_loss_proj:2.011 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.944 | p: 86.994 | r: 89.086
rouge2     | fm: 56.932 | p: 56.584 | r: 57.285
rougeL     | fm: 78.036 | p: 77.154 | r: 79.096
rougeLsum  | fm: 78.094 | p: 77.267 | r: 79.044
r1fm+r2fm = 144.875

input #54 time: 0:08:11 | total time: 7:39:31


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.91624812180613
highest_index [0]
highest [0.91624812180613]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.8550942540168762 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.7469034194946289 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7424214482307434 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7408183217048645 for ['[CLS] leaflets highlighted the [SEP]']
[Init] best rec loss: 0.7326778769493103 for ['[CLS] beneath besides milo [SEP]']
[Init] best rec loss: 0.7190676927566528 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7155680060386658 for ['[CLS] top trades events [SEP]']
[Init] best rec loss: 0.7090476751327515 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7087867856025696 for ['[CLS] holly stride post [SEP]']
[Init] best perm rec loss: 0.7075213193893433 for ['[CLS] stride post holly [SEP]']
[Init] best perm rec loss: 0.7047978043556213 for ['[CLS] post stride holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.763 (perp=10.482, rec=0.520, cos=0.146), tot_loss_proj:3.162 [t=0.20s]
prediction: ['[CLS] old again settled [SEP]']
[ 100/2000] tot_loss=2.174 (perp=7.727, rec=0.358, cos=0.271), tot_loss_proj:3.217 [t=0.20s]
prediction: ['[CLS] more easily settled [SEP]']
[ 150/2000] tot_loss=1.848 (perp=7.752, rec=0.145, cos=0.153), tot_loss_proj:2.265 [t=0.18s]
prediction: ['[CLS] too easily settled [SEP]']
[ 200/2000] tot_loss=1.997 (perp=8.687, rec=0.103, cos=0.156), tot_loss_proj:2.347 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.976 (perp=8.687, rec=0.079, cos=0.160), tot_loss_proj:2.349 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[ 300/2000] tot_loss=1.972 (perp=8.687, rec=0.075, cos=0.160), tot_loss_proj:2.346 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.961 (perp=8.687, rec=0.064, cos=0.159), tot_loss_proj:2.351 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.965 (perp=8.687, rec=0.068, cos=0.159), tot_loss_proj:2.352 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.971 (perp=8.687, rec=0.074, cos=0.160), tot_loss_proj:2.358 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.959 (perp=8.687, rec=0.062, cos=0.160), tot_loss_proj:2.349 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.962 (perp=8.687, rec=0.065, cos=0.160), tot_loss_proj:2.355 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.970 (perp=8.687, rec=0.073, cos=0.160), tot_loss_proj:2.354 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.956 (perp=8.687, rec=0.058, cos=0.160), tot_loss_proj:2.354 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.961 (perp=8.687, rec=0.063, cos=0.160), tot_loss_proj:2.356 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.969 (perp=8.687, rec=0.072, cos=0.160), tot_loss_proj:2.349 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.959 (perp=8.687, rec=0.062, cos=0.160), tot_loss_proj:2.355 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.970 (perp=8.687, rec=0.072, cos=0.160), tot_loss_proj:2.353 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.957 (perp=8.687, rec=0.059, cos=0.160), tot_loss_proj:2.354 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.965 (perp=8.687, rec=0.068, cos=0.160), tot_loss_proj:2.346 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.968 (perp=8.687, rec=0.070, cos=0.160), tot_loss_proj:2.349 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.961 (perp=8.687, rec=0.064, cos=0.160), tot_loss_proj:2.350 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.953 (perp=8.687, rec=0.055, cos=0.160), tot_loss_proj:2.358 [t=0.32s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.954 (perp=8.687, rec=0.057, cos=0.160), tot_loss_proj:2.353 [t=0.22s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.953 (perp=8.687, rec=0.055, cos=0.160), tot_loss_proj:2.350 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.961 (perp=8.687, rec=0.063, cos=0.160), tot_loss_proj:2.352 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.952 (perp=8.687, rec=0.055, cos=0.160), tot_loss_proj:2.361 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.951 (perp=8.687, rec=0.058, cos=0.155), tot_loss_proj:2.351 [t=0.22s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.947 (perp=8.687, rec=0.052, cos=0.158), tot_loss_proj:2.355 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.964 (perp=8.687, rec=0.067, cos=0.159), tot_loss_proj:2.351 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.959 (perp=8.687, rec=0.063, cos=0.159), tot_loss_proj:2.353 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.950 (perp=8.687, rec=0.053, cos=0.160), tot_loss_proj:2.356 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.964 (perp=8.687, rec=0.067, cos=0.160), tot_loss_proj:2.357 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.958 (perp=8.687, rec=0.061, cos=0.160), tot_loss_proj:2.362 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.953 (perp=8.687, rec=0.056, cos=0.160), tot_loss_proj:2.357 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.959 (perp=8.687, rec=0.061, cos=0.160), tot_loss_proj:2.348 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.963 (perp=8.687, rec=0.066, cos=0.160), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.960 (perp=8.687, rec=0.063, cos=0.160), tot_loss_proj:2.354 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.961 (perp=8.687, rec=0.063, cos=0.160), tot_loss_proj:2.356 [t=0.22s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.972 (perp=8.687, rec=0.075, cos=0.160), tot_loss_proj:2.348 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.966 (perp=8.687, rec=0.069, cos=0.160), tot_loss_proj:2.350 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 88.084 | p: 87.098 | r: 89.188
rouge2     | fm: 56.250 | p: 55.921 | r: 56.576
rougeL     | fm: 78.057 | p: 77.202 | r: 79.085
rougeLsum  | fm: 78.251 | p: 77.386 | r: 79.270
r1fm+r2fm = 144.334

input #55 time: 0:08:15 | total time: 7:47:47


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.8894190066134283
highest_index [0]
highest [0.8894190066134283]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.8451642990112305 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.8226656317710876 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.8222013711929321 for ['[CLS]ett radio blu division batons favor conservativegue both reading mclaren isolation pepmmer entertainmentignant age railway dive clashes [SEP]']
[Init] best perm rec loss: 0.8209762573242188 for ['[CLS] both favor railway blu mclarenons reading entertainment radio isolationett clashes division pep batignantgue dive age conservativemmer [SEP]']
[Init] best perm rec loss: 0.8200120329856873 for ['[CLS] bluett bat railway isolation dive favor entertainmentignant division clashesgue reading age radio pep conservative mclarenons bothmmer [SEP]']
[Init] best perm rec loss: 0.8194021582603455 for ['[CLS] divemmeronsgue conservativeignant clashes railway division radio bat age favor isolationett mclaren both pep blu reading entertainment [SEP]']
[Init] best perm rec loss: 0.8193259239196777 for ['[CLS] dive conservative bat divisionons isolation reading blu favor railwayett entertainment both pepmmerignant radio age clashesgue mclaren [SEP]']
[Init] best perm rec loss: 0.8185174465179443 for ['[CLS] radio isolationignantons railwaygue favor entertainment bat readingett dive clashes bothmmer pep division age blu conservative mclaren [SEP]']
[Init] best perm rec loss: 0.8171243667602539 for ['[CLS] isolationmmer both batons pep readingignant favorgue radio clashes division railway blu conservative entertainment dive ageett mclaren [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.949 (perp=12.111, rec=0.331, cos=0.196), tot_loss_proj:3.648 [t=0.24s]
prediction: ['[CLS] damage which same processulously drug repair whose laws benefit radio unknown committee looked evidence apparentlymona rank contestes damage [SEP]']
[ 100/2000] tot_loss=2.691 (perp=11.308, rec=0.239, cos=0.190), tot_loss_proj:3.465 [t=0.19s]
prediction: ['[CLS] damage which loads of no drug film whose films costly itunes potentially committee tons films apparently costly caused assessmentque damage [SEP]']
[ 150/2000] tot_loss=2.698 (perp=11.394, rec=0.210, cos=0.209), tot_loss_proj:3.271 [t=0.18s]
prediction: ['[CLS] damage which loads of never drug films which films costlypara potentially report provide films apparently costly caused analysis would damage [SEP]']
[ 200/2000] tot_loss=2.607 (perp=11.238, rec=0.161, cos=0.198), tot_loss_proj:3.543 [t=0.19s]
prediction: ['[CLS] damage which loads of never damage films which films costlypara potentiallyble cause films years costly worth analysis would damage [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.485 (perp=10.629, rec=0.157, cos=0.202), tot_loss_proj:3.055 [t=0.18s]
prediction: ['[CLS] damage which loads of never damage films could analysis costlyparable cause films years gonna costly that analysis would damage [SEP]']
[ 300/2000] tot_loss=2.453 (perp=10.583, rec=0.135, cos=0.201), tot_loss_proj:3.027 [t=0.22s]
prediction: ['[CLS] damage which loads of never damage films could analysis costlyparable cause years years gonna costly that analysis could damage [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.347 (perp=10.052, rec=0.133, cos=0.203), tot_loss_proj:2.756 [t=0.27s]
prediction: ['[CLS] damage which loads of neverble films could cause costlyparable fix years years potentially costly that analysis could damage [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.255 (perp=9.620, rec=0.124, cos=0.207), tot_loss_proj:2.693 [t=0.26s]
prediction: ['[CLS] damage which loads of damageble films could cause costlyparable fix years years potentially costly that analysis could never [SEP]']
[ 450/2000] tot_loss=2.213 (perp=9.517, rec=0.108, cos=0.202), tot_loss_proj:2.844 [t=0.26s]
prediction: ['[CLS] damage which loads of damageble films could cause costlyparable fix years years consequence could that analysis could never [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.245 (perp=9.646, rec=0.111, cos=0.205), tot_loss_proj:2.920 [t=0.18s]
prediction: ['[CLS] damage which loads damage of ir films could cause costlyparable fix years years consequence could that analysis could never [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.148 (perp=9.162, rec=0.115, cos=0.200), tot_loss_proj:2.663 [t=0.24s]
prediction: ['[CLS] damage which loads of ir films and cause costlyparable fix years years consequence of damage that analysis could never [SEP]']
[ 600/2000] tot_loss=2.156 (perp=9.255, rec=0.103, cos=0.202), tot_loss_proj:2.691 [t=0.18s]
prediction: ['[CLS] damage which loads of ir films and cause costlyparable fix years years possibly of damage that analysis could never [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.118 (perp=8.997, rec=0.115, cos=0.204), tot_loss_proj:2.917 [t=0.18s]
prediction: ['[CLS] analysis which loads of ir films could cause costlyparable fix non years possibly of damage that damage would never [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.996 (perp=8.456, rec=0.100, cos=0.204), tot_loss_proj:2.763 [t=0.19s]
prediction: ['[CLS] analysis which loads of ir films could cause costly possiblyparable fix non years of damage that damage would never [SEP]']
[ 750/2000] tot_loss=1.994 (perp=8.456, rec=0.099, cos=0.203), tot_loss_proj:2.768 [t=0.21s]
prediction: ['[CLS] analysis which loads of ir films could cause costly possiblyparable fix non years of damage that damage would never [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.970 (perp=8.333, rec=0.100, cos=0.204), tot_loss_proj:2.718 [t=0.18s]
prediction: ['[CLS] analysis which loads of ir films would cause costly possiblyparable fix non years of damage that damage could never [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.964 (perp=8.333, rec=0.093, cos=0.204), tot_loss_proj:2.734 [t=0.20s]
prediction: ['[CLS] analysis which loads of ir films would cause costly possiblyparable fix non years of damage that damage could never [SEP]']
[ 900/2000] tot_loss=1.971 (perp=8.346, rec=0.097, cos=0.204), tot_loss_proj:2.717 [t=0.19s]
prediction: ['[CLS] analysis which loads of ir films would cause costly possiblyparable fix non years of damage that damage will never [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.963 (perp=8.315, rec=0.096, cos=0.205), tot_loss_proj:2.656 [t=0.18s]
prediction: ['[CLS] analysis which loads of ir films would cause costly possiblyparable non fix years of damage that damage will never [SEP]']
Attempt swap
[1000/2000] tot_loss=1.959 (perp=8.315, rec=0.092, cos=0.205), tot_loss_proj:2.657 [t=0.20s]
prediction: ['[CLS] analysis which loads of ir films would cause costly possiblyparable non fix years of damage that damage will never [SEP]']
[1050/2000] tot_loss=1.957 (perp=8.315, rec=0.089, cos=0.205), tot_loss_proj:2.656 [t=0.18s]
prediction: ['[CLS] analysis which loads of ir films would cause costly possiblyparable non fix years of damage that damage will never [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.908 (perp=8.069, rec=0.089, cos=0.205), tot_loss_proj:2.754 [t=0.18s]
prediction: ['[CLS] analysis which loads of ir films would cause costly nonparable possibly fix years of damage that damage will never [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.898 (perp=8.005, rec=0.091, cos=0.206), tot_loss_proj:2.596 [t=0.25s]
prediction: ['[CLS] analysis which loads of ir films would cause might costly nonparable fix years of damage that damage will never [SEP]']
[1200/2000] tot_loss=1.833 (perp=7.702, rec=0.087, cos=0.206), tot_loss_proj:2.579 [t=0.18s]
prediction: ['[CLS] analysis which loads of ir films would cause possibly costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
[1250/2000] tot_loss=1.836 (perp=7.702, rec=0.090, cos=0.205), tot_loss_proj:2.579 [t=0.22s]
prediction: ['[CLS] analysis which loads of ir films would cause possibly costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
[1300/2000] tot_loss=1.833 (perp=7.702, rec=0.087, cos=0.205), tot_loss_proj:2.568 [t=0.18s]
prediction: ['[CLS] analysis which loads of ir films would cause possibly costly nonparable fix years of damage that damage will never [SEP]']
[1350/2000] tot_loss=1.844 (perp=7.702, rec=0.098, cos=0.205), tot_loss_proj:2.574 [t=0.29s]
prediction: ['[CLS] analysis which loads of ir films would cause possibly costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
[1400/2000] tot_loss=1.843 (perp=7.702, rec=0.097, cos=0.205), tot_loss_proj:2.580 [t=0.24s]
prediction: ['[CLS] analysis which loads of ir films would cause possibly costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
[1450/2000] tot_loss=1.835 (perp=7.702, rec=0.090, cos=0.205), tot_loss_proj:2.575 [t=0.24s]
prediction: ['[CLS] analysis which loads of ir films would cause possibly costly nonparable fix years of damage that damage will never [SEP]']
[1500/2000] tot_loss=1.831 (perp=7.702, rec=0.085, cos=0.205), tot_loss_proj:2.582 [t=0.20s]
prediction: ['[CLS] analysis which loads of ir films would cause possibly costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.842 (perp=7.737, rec=0.090, cos=0.205), tot_loss_proj:2.472 [t=0.19s]
prediction: ['[CLS] analysis which loads of ir films would consequence cause costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
[1600/2000] tot_loss=1.844 (perp=7.737, rec=0.091, cos=0.205), tot_loss_proj:2.469 [t=0.24s]
prediction: ['[CLS] analysis which loads of ir films would consequence cause costly nonparable fix years of damage that damage will never [SEP]']
[1650/2000] tot_loss=1.837 (perp=7.737, rec=0.085, cos=0.205), tot_loss_proj:2.470 [t=0.23s]
prediction: ['[CLS] analysis which loads of ir films would consequence cause costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
[1700/2000] tot_loss=1.839 (perp=7.737, rec=0.087, cos=0.205), tot_loss_proj:2.475 [t=0.18s]
prediction: ['[CLS] analysis which loads of ir films would consequence cause costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.855 (perp=7.737, rec=0.100, cos=0.207), tot_loss_proj:2.477 [t=0.19s]
prediction: ['[CLS] analysis which loads of ir films would consequence cause costly nonparable fix years of damage that damage will never [SEP]']
[1800/2000] tot_loss=1.844 (perp=7.737, rec=0.091, cos=0.205), tot_loss_proj:2.483 [t=0.19s]
prediction: ['[CLS] analysis which loads of ir films would consequence cause costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
[1850/2000] tot_loss=1.825 (perp=7.646, rec=0.090, cos=0.205), tot_loss_proj:2.579 [t=0.21s]
prediction: ['[CLS] analysis which loads of ir films would might cause costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
[1900/2000] tot_loss=1.811 (perp=7.646, rec=0.076, cos=0.205), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] analysis which loads of ir films would might cause costly nonparable fix years of damage that damage will never [SEP]']
[1950/2000] tot_loss=1.824 (perp=7.646, rec=0.090, cos=0.205), tot_loss_proj:2.582 [t=0.18s]
prediction: ['[CLS] analysis which loads of ir films would might cause costly nonparable fix years of damage that damage will never [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.820 (perp=7.609, rec=0.092, cos=0.206), tot_loss_proj:2.573 [t=0.22s]
prediction: ['[CLS] analysis which loads of ir films might would cause costly nonparable fix years of damage that damage will never [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] analysis which loads of ir films would might cause costly nonparable fix years of damage that damage will never [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.049 | p: 76.190 | r: 80.000
rouge2     | fm: 15.385 | p: 15.000 | r: 15.789
rougeL     | fm: 39.024 | p: 38.095 | r: 40.000
rougeLsum  | fm: 39.024 | p: 38.095 | r: 40.000
r1fm+r2fm = 93.433

[Aggregate metrics]:
rouge1     | fm: 87.972 | p: 86.891 | r: 89.124
rouge2     | fm: 55.572 | p: 55.238 | r: 55.910
rougeL     | fm: 77.454 | p: 76.603 | r: 78.489
rougeLsum  | fm: 77.458 | p: 76.655 | r: 78.460
r1fm+r2fm = 143.544

input #56 time: 0:08:35 | total time: 7:56:22


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9119964875010653
highest_index [0]
highest [0.9119964875010653]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8730360269546509 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.8579795360565186 for ['[CLS] their [SEP]']
[Init] best rec loss: 0.8072633147239685 for ['[CLS]on [SEP]']
[Init] best rec loss: 0.7522843480110168 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.6843217611312866 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6841280460357666 for ['[CLS] modern [SEP]']
[Init] best rec loss: 0.6820790767669678 for ['[CLS] silk [SEP]']
[Init] best rec loss: 0.6572474241256714 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.858 (perp=12.282, rec=0.238, cos=0.163), tot_loss_proj:2.706 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.687 (perp=12.282, rec=0.079, cos=0.151), tot_loss_proj:2.690 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.696 (perp=12.282, rec=0.076, cos=0.163), tot_loss_proj:2.690 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.687 (perp=12.282, rec=0.064, cos=0.167), tot_loss_proj:2.691 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.683 (perp=12.282, rec=0.060, cos=0.167), tot_loss_proj:2.689 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.680 (perp=12.282, rec=0.055, cos=0.168), tot_loss_proj:2.681 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.690 (perp=12.282, rec=0.066, cos=0.168), tot_loss_proj:2.693 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.679 (perp=12.282, rec=0.069, cos=0.153), tot_loss_proj:2.685 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.693 (perp=12.282, rec=0.070, cos=0.166), tot_loss_proj:2.682 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.679 (perp=12.282, rec=0.055, cos=0.168), tot_loss_proj:2.679 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.695 (perp=12.282, rec=0.070, cos=0.168), tot_loss_proj:2.694 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.683 (perp=12.282, rec=0.058, cos=0.168), tot_loss_proj:2.696 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.690 (perp=12.282, rec=0.065, cos=0.168), tot_loss_proj:2.680 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.674 (perp=12.282, rec=0.059, cos=0.159), tot_loss_proj:2.682 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.676 (perp=12.282, rec=0.053, cos=0.166), tot_loss_proj:2.675 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.688 (perp=12.282, rec=0.064, cos=0.167), tot_loss_proj:2.679 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.687 (perp=12.282, rec=0.063, cos=0.168), tot_loss_proj:2.684 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.683 (perp=12.282, rec=0.059, cos=0.168), tot_loss_proj:2.699 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.693 (perp=12.282, rec=0.069, cos=0.168), tot_loss_proj:2.684 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.672 (perp=12.282, rec=0.047, cos=0.168), tot_loss_proj:2.680 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.662 (perp=12.282, rec=0.050, cos=0.156), tot_loss_proj:2.689 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.703 (perp=12.282, rec=0.082, cos=0.165), tot_loss_proj:2.690 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.678 (perp=12.282, rec=0.054, cos=0.167), tot_loss_proj:2.685 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.680 (perp=12.282, rec=0.056, cos=0.168), tot_loss_proj:2.682 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.688 (perp=12.282, rec=0.063, cos=0.168), tot_loss_proj:2.684 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.682 (perp=12.282, rec=0.058, cos=0.168), tot_loss_proj:2.683 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.680 (perp=12.282, rec=0.055, cos=0.168), tot_loss_proj:2.678 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.686 (perp=12.282, rec=0.061, cos=0.168), tot_loss_proj:2.705 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.682 (perp=12.282, rec=0.058, cos=0.168), tot_loss_proj:2.682 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.683 (perp=12.282, rec=0.058, cos=0.168), tot_loss_proj:2.670 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.683 (perp=12.282, rec=0.058, cos=0.168), tot_loss_proj:2.684 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.681 (perp=12.282, rec=0.057, cos=0.168), tot_loss_proj:2.690 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.680 (perp=12.282, rec=0.056, cos=0.168), tot_loss_proj:2.676 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.688 (perp=12.282, rec=0.063, cos=0.168), tot_loss_proj:2.689 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.682 (perp=12.282, rec=0.057, cos=0.168), tot_loss_proj:2.687 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.691 (perp=12.282, rec=0.066, cos=0.168), tot_loss_proj:2.688 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.689 (perp=12.282, rec=0.064, cos=0.168), tot_loss_proj:2.695 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.682 (perp=12.282, rec=0.057, cos=0.168), tot_loss_proj:2.681 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.681 (perp=12.282, rec=0.057, cos=0.168), tot_loss_proj:2.689 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.687 (perp=12.282, rec=0.062, cos=0.168), tot_loss_proj:2.678 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.186 | p: 87.154 | r: 89.315
rouge2     | fm: 56.253 | p: 55.962 | r: 56.620
rougeL     | fm: 77.846 | p: 76.988 | r: 78.778
rougeLsum  | fm: 77.863 | p: 77.055 | r: 78.836
r1fm+r2fm = 144.439

input #57 time: 0:08:15 | total time: 8:04:38


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.8118323164327235
highest_index [0]
highest [0.8118323164327235]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.023267388343811 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.998713493347168 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9858736395835876 for ['[CLS] things reggie on guinnessllet continue special the chan (ness grew prone moffatockshire [SEP]']
[Init] best rec loss: 0.9797480702400208 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9673054218292236 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 0.9600313305854797 for ['[CLS] ) after rca adventures / yong beat bad http stoodagendingple ]erson trailing [SEP]']
[Init] best rec loss: 0.9585424065589905 for ['[CLS] sure tel china lose neutral central never an there after louis concentratione jack boysnted [SEP]']
[Init] best rec loss: 0.9467926621437073 for ['[CLS] shield anything damon venom sitting led trumppole purdue bigاural failed proposal sketch lea [SEP]']
[Init] best rec loss: 0.9418908953666687 for ['[CLS] bellsignant river animals don cracked ace behind lid tasha des aden reception add bu fully [SEP]']
[Init] best rec loss: 0.9401950836181641 for ['[CLS] commissioned table evelyn imp officially mall spring aquacratic average caf west newgrin advantage how [SEP]']
[Init] best perm rec loss: 0.9362245798110962 for ['[CLS]grin officially average west evelyn aqua spring new impcratic how commissioned advantage caf mall table [SEP]']
[Init] best perm rec loss: 0.934982180595398 for ['[CLS] mall advantagegrin imp west table new average howcratic evelyn commissioned aqua spring officially caf [SEP]']
[Init] best perm rec loss: 0.9348461627960205 for ['[CLS] table average caf west mall springgrin advantage evelyn how aqua new officiallycratic commissioned imp [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.422 (perp=12.271, rec=0.706, cos=0.262), tot_loss_proj:4.104 [t=0.18s]
prediction: ['[CLS] mafialess sleeves us most excessphile acts transparent default his semi afterwards au just : [SEP]']
[ 100/2000] tot_loss=3.205 (perp=11.560, rec=0.578, cos=0.315), tot_loss_proj:4.273 [t=0.18s]
prediction: ['[CLS] by totally nervous georgia attention thousandsphile system transparent reconciliation a tale subsequently us movement : [SEP]']
[ 150/2000] tot_loss=3.382 (perp=13.046, rec=0.524, cos=0.249), tot_loss_proj:4.532 [t=0.22s]
prediction: ['[CLS] ind 1999 naked reacher attention anyonephile emotional composite themes the puzzle subsequently thetia : [SEP]']
[ 200/2000] tot_loss=3.564 (perp=13.718, rec=0.546, cos=0.274), tot_loss_proj:4.489 [t=0.25s]
prediction: ['[CLS] maori you cigarette ghetto about anyone bulgarian narrative inspirational realistic upbringing puzzle when cooperationtia another [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=3.702 (perp=14.524, rec=0.539, cos=0.258), tot_loss_proj:4.604 [t=0.24s]
prediction: ['[CLS] puzzleiah tub ep an fivb your aids ghetto basketball any〜 narrative inspirational dreaming independence [SEP]']
[ 300/2000] tot_loss=3.410 (perp=13.352, rec=0.533, cos=0.207), tot_loss_proj:4.571 [t=0.25s]
prediction: ['[CLS] story places tub trio an otherwise 2000 euroleague ghetto guys anyphile narrative inspirational impressed independence [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.431 (perp=13.675, rec=0.444, cos=0.252), tot_loss_proj:4.638 [t=0.18s]
prediction: ['[CLS] puzzle places any ep an discus 2000trics ghetto torment tub defended narrative inspirational impressed independence [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.015 (perp=11.917, rec=0.435, cos=0.197), tot_loss_proj:4.109 [t=0.25s]
prediction: ["[CLS] innocence story places any'another discus 1999trics age injection bulgarian story inspirational impressed independence [SEP]"]
[ 450/2000] tot_loss=3.222 (perp=12.884, rec=0.445, cos=0.200), tot_loss_proj:4.414 [t=0.26s]
prediction: ['[CLS] innocence story places any edition an discus... pastry you dodgelowe story inspirational impressed independence [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.137 (perp=12.252, rec=0.390, cos=0.296), tot_loss_proj:3.972 [t=0.28s]
prediction: ['[CLS] innocence story places any trio thesphere wastrics opposition dodge capturing inspirational story impressed identification [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.925 (perp=11.653, rec=0.410, cos=0.184), tot_loss_proj:3.821 [t=0.19s]
prediction: ['[CLS] innocence story discus any story another places -trics innocence anticipation capturing inspirational story impressed that [SEP]']
[ 600/2000] tot_loss=3.227 (perp=12.617, rec=0.381, cos=0.323), tot_loss_proj:4.094 [t=0.26s]
prediction: ['[CLS] innocence storysphere 2004 trio anotherized -trics innocence how capturing inspirational story impressed that [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.913 (perp=11.827, rec=0.385, cos=0.162), tot_loss_proj:3.925 [t=0.22s]
prediction: ['[CLS] innocence story richest 2004 trio anotherized wastrics innocence capturing anticipation inspirational story impressed that [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.978 (perp=11.394, rec=0.372, cos=0.327), tot_loss_proj:3.781 [t=0.19s]
prediction: ['[CLS] anotherized innocence storysphere 2004 trio wastrics innocence capturing how inspirational story impressed identification [SEP]']
[ 750/2000] tot_loss=2.676 (perp=10.721, rec=0.388, cos=0.143), tot_loss_proj:3.714 [t=0.19s]
prediction: ['[CLS] anotherized innocence story richest 2004 story wastrics innocence capturing jose inspirational story impressed that [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.851 (perp=11.249, rec=0.368, cos=0.233), tot_loss_proj:4.127 [t=0.25s]
prediction: ['[CLS] anotherized innocence storytas inspirational story any story wastrics innocence capturing dex impressedation [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.485 (perp=9.919, rec=0.378, cos=0.123), tot_loss_proj:3.792 [t=0.19s]
prediction: ['[CLS] anotherized innocence storytas inspirational story 2004 story wastrics capturing innocence an impressedation [SEP]']
[ 900/2000] tot_loss=2.582 (perp=9.919, rec=0.357, cos=0.241), tot_loss_proj:3.791 [t=0.25s]
prediction: ['[CLS] anotherized innocence storytas inspirational story 2004 story wastrics capturing innocence an impressedation [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.456 (perp=9.739, rec=0.380, cos=0.128), tot_loss_proj:3.677 [t=0.19s]
prediction: ['[CLS] another innocenceized innocence storytas inspirational story 2004 story wastrics capturing an impressedation [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.460 (perp=9.499, rec=0.360, cos=0.200), tot_loss_proj:3.358 [t=0.18s]
prediction: ['[CLS] another innocenceized innocence storytas inspirational story 2004 storytrics capturing an impressed wasation [SEP]']
[1050/2000] tot_loss=2.444 (perp=9.499, rec=0.376, cos=0.168), tot_loss_proj:3.362 [t=0.22s]
prediction: ['[CLS] another innocenceized innocence storytas inspirational story 2004 storytrics capturing an impressed wasation [SEP]']
Attempt swap
[1100/2000] tot_loss=2.465 (perp=9.499, rec=0.346, cos=0.219), tot_loss_proj:3.360 [t=0.26s]
prediction: ['[CLS] another innocenceized innocence storytas inspirational story 2004 storytrics capturing an impressed wasation [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.499 (perp=10.029, rec=0.358, cos=0.135), tot_loss_proj:3.494 [t=0.19s]
prediction: ['[CLS] another innocenceized innocence story story inspirational story 2004tastrics capturing an impressed wasation [SEP]']
[1200/2000] tot_loss=2.602 (perp=9.819, rec=0.346, cos=0.292), tot_loss_proj:3.377 [t=0.26s]
prediction: ['[CLS] another innocenceized innocence story story inspirational story intensetastrics capturing an impressed wasation [SEP]']
Attempt swap
[1250/2000] tot_loss=2.452 (perp=9.819, rec=0.339, cos=0.149), tot_loss_proj:3.380 [t=0.20s]
prediction: ['[CLS] another innocenceized innocence story story inspirational story intensetastrics capturing an impressed wasation [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.657 (perp=10.061, rec=0.342, cos=0.302), tot_loss_proj:3.606 [t=0.19s]
prediction: ['[CLS] another innocenceized innocence story story inspirational story intensetas wastrics capturing an impressedation [SEP]']
[1350/2000] tot_loss=2.555 (perp=10.061, rec=0.344, cos=0.199), tot_loss_proj:3.611 [t=0.21s]
prediction: ['[CLS] another innocenceized innocence story story inspirational story intensetas wastrics capturing an impressedation [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.744 (perp=10.989, rec=0.354, cos=0.193), tot_loss_proj:3.837 [t=0.18s]
prediction: ['[CLS] another innocenceized stevie story story inspirational story intensetastrics was capturing an questionsation [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.671 (perp=10.503, rec=0.335, cos=0.236), tot_loss_proj:3.767 [t=0.18s]
prediction: ['[CLS] anotherized stevie story innocence story inspirational story intensetastrics was capturing an questionsation [SEP]']
[1500/2000] tot_loss=2.625 (perp=10.725, rec=0.343, cos=0.136), tot_loss_proj:3.933 [t=0.27s]
prediction: ['[CLS] anotherized stevie story innocence story inspirational story earstastrics was capturing an questionsation [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.687 (perp=10.372, rec=0.339, cos=0.273), tot_loss_proj:3.810 [t=0.24s]
prediction: ['[CLS] anotherized stevie story innocence story inspirational story was intensetastrics capturing an questionsation [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.668 (perp=10.451, rec=0.345, cos=0.233), tot_loss_proj:3.778 [t=0.18s]
prediction: ['[CLS] anotherized story innocence story inspirational story stevie anoustastrics capturing an questionsation [SEP]']
[1650/2000] tot_loss=2.620 (perp=10.451, rec=0.345, cos=0.185), tot_loss_proj:3.775 [t=0.25s]
prediction: ['[CLS] anotherized story innocence story inspirational story stevie anoustastrics capturing an questionsation [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.635 (perp=10.058, rec=0.340, cos=0.283), tot_loss_proj:3.765 [t=0.24s]
prediction: ['[CLS] anotherized story innocence story inspirational story capturing anoustastrics stevie an questionsation [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.507 (perp=9.853, rec=0.335, cos=0.201), tot_loss_proj:3.764 [t=0.19s]
prediction: ['[CLS] anotherized innocence story story inspirational story capturing anoustastrics stevie an questionsation [SEP]']
[1800/2000] tot_loss=2.614 (perp=9.853, rec=0.331, cos=0.312), tot_loss_proj:3.763 [t=0.20s]
prediction: ['[CLS] anotherized innocence story story inspirational story capturing anoustastrics stevie an questionsation [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.536 (perp=9.775, rec=0.332, cos=0.249), tot_loss_proj:3.782 [t=0.23s]
prediction: ['[CLS] anotherized innocence story inspirational story story capturing anoustastrics stevie an questionsation [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.542 (perp=10.029, rec=0.337, cos=0.200), tot_loss_proj:3.841 [t=0.25s]
prediction: ['[CLS] anotherized innocence story inspirational story story stevie capturing anoustastrics an questionsation [SEP]']
[1950/2000] tot_loss=2.622 (perp=10.029, rec=0.332, cos=0.284), tot_loss_proj:3.841 [t=0.21s]
prediction: ['[CLS] anotherized innocence story inspirational story story stevie capturing anoustastrics an questionsation [SEP]']
Attempt swap
[2000/2000] tot_loss=2.478 (perp=9.577, rec=0.339, cos=0.224), tot_loss_proj:3.821 [t=0.22s]
prediction: ['[CLS] anotherized innocence story inspirational story storyified capturing anoustastrics an questionsation [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] anotherized innocence story inspirational story storyified capturing anoustastrics an questionsation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 58.333 | r: 43.750
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 35.714 | p: 41.667 | r: 31.250
rougeLsum  | fm: 35.714 | p: 41.667 | r: 31.250
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 87.463 | p: 86.631 | r: 88.548
rouge2     | fm: 55.187 | p: 54.884 | r: 55.517
rougeL     | fm: 77.249 | p: 76.521 | r: 78.142
rougeLsum  | fm: 77.182 | p: 76.508 | r: 78.045
r1fm+r2fm = 142.650

input #58 time: 0:08:35 | total time: 8:13:13


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.8181947429270475
highest_index [0]
highest [0.8181947429270475]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.8938121795654297 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8550001978874207 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 0.8465541005134583 for ['[CLS] mala minute theory mandatory stands after mere figure number roth sister locomotives bombay bavarian late athlete [SEP]']
[Init] best rec loss: 0.8245677947998047 for ['[CLS]notes urban shape atliest not filterae titled making prize wait sex ste front coach [SEP]']
[Init] best rec loss: 0.8054222464561462 for ['[CLS] key stafforddial done colony midst kmdden face ɾord muscle warning ( wife organic [SEP]']
[Init] best rec loss: 0.7913710474967957 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best rec loss: 0.7761808037757874 for ['[CLS] creator war pepper mortal knights dinner warm helped tasting fringe vsonate cricket elitecoat counterpart [SEP]']
[Init] best perm rec loss: 0.7741870880126953 for ['[CLS] fringe war pepper knightsonate cricket counterpart tasting elitecoat vs warm helped mortal dinner creator [SEP]']
[Init] best perm rec loss: 0.7728683948516846 for ['[CLS] elite knights mortal fringe helped dinner cricketcoatonate warm creator counterpart vs pepper war tasting [SEP]']
[Init] best perm rec loss: 0.7715001702308655 for ['[CLS] pepper vs fringe cricket creator knights tastingonate warm elite mortal dinner war helpedcoat counterpart [SEP]']
[Init] best perm rec loss: 0.7708169221878052 for ['[CLS] creator dinner helped tasting cricket vs pepper warm knights elite mortalcoatonate war fringe counterpart [SEP]']
[Init] best perm rec loss: 0.7704019546508789 for ['[CLS] elitecoat pepper mortal creator vs helped cricket fringe warm knights tasting war dinner counterpartonate [SEP]']
[Init] best perm rec loss: 0.7698580026626587 for ['[CLS] elite pepper warmonate mortal fringe creator dinner helped cricket vs war knights counterpartcoat tasting [SEP]']
[Init] best perm rec loss: 0.7698403000831604 for ['[CLS] creatorcoat warm mortalonate tasting cricket knights vs pepper helped war elite fringe dinner counterpart [SEP]']
[Init] best perm rec loss: 0.7691012620925903 for ['[CLS] warm pepper knights creator counterpart cricket elite dinner helped mortalcoat war vs fringe tastingonate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.180 (perp=12.633, rec=0.347, cos=0.307), tot_loss_proj:3.774 [t=0.18s]
prediction: ['[CLS] children nature gia team influence had the green trustnan young woman specializes dolphin natural society [SEP]']
[ 100/2000] tot_loss=2.717 (perp=10.933, rec=0.213, cos=0.317), tot_loss_proj:3.162 [t=0.24s]
prediction: ['[CLS] love how charismism of the a young one young woman has children young woman [SEP]']
[ 150/2000] tot_loss=2.190 (perp=8.634, rec=0.142, cos=0.321), tot_loss_proj:2.717 [t=0.18s]
prediction: ['[CLS] relationship how charisma of the the young who young woman has woman young screen [SEP]']
[ 200/2000] tot_loss=2.293 (perp=9.271, rec=0.115, cos=0.324), tot_loss_proj:2.623 [t=0.20s]
prediction: ['[CLS] hold knows charisma of the a young who young woman has the young screen [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.949 (perp=7.578, rec=0.108, cos=0.325), tot_loss_proj:2.259 [t=0.18s]
prediction: ['[CLS] hold knows the charisma of the a young who young woman has the screen [SEP]']
[ 300/2000] tot_loss=1.932 (perp=7.514, rec=0.101, cos=0.328), tot_loss_proj:2.257 [t=0.18s]
prediction: ['[CLS] hold knows the charisma of the young young who young woman has the screen [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.836 (perp=7.067, rec=0.092, cos=0.330), tot_loss_proj:2.262 [t=0.25s]
prediction: ['[CLS] charisma of the young young who hold knows the young woman has the screen [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.731 (perp=6.596, rec=0.092, cos=0.319), tot_loss_proj:2.154 [t=0.22s]
prediction: ['[CLS] charisma of the young young who hold the young woman knows has the screen [SEP]']
[ 450/2000] tot_loss=1.716 (perp=6.596, rec=0.070, cos=0.327), tot_loss_proj:2.151 [t=0.19s]
prediction: ['[CLS] charisma of the young young who hold the young woman knows has the screen [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.605 (perp=6.001, rec=0.079, cos=0.325), tot_loss_proj:2.015 [t=0.22s]
prediction: ['[CLS] young charisma of the young who hold the young woman knows has the screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.603 (perp=6.001, rec=0.076, cos=0.327), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] young charisma of the young who hold the young woman knows has the screen [SEP]']
[ 600/2000] tot_loss=1.609 (perp=6.001, rec=0.081, cos=0.328), tot_loss_proj:2.016 [t=0.21s]
prediction: ['[CLS] young charisma of the young who hold the young woman knows has the screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.612 (perp=6.008, rec=0.082, cos=0.328), tot_loss_proj:2.074 [t=0.19s]
prediction: ['[CLS] young charisma of the a who hold the young woman knows has the screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.604 (perp=6.008, rec=0.073, cos=0.329), tot_loss_proj:2.063 [t=0.18s]
prediction: ['[CLS] young charisma of the a who hold the young woman knows has the screen [SEP]']
[ 750/2000] tot_loss=1.608 (perp=6.008, rec=0.078, cos=0.329), tot_loss_proj:2.065 [t=0.19s]
prediction: ['[CLS] young charisma of the a who hold the young woman knows has the screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.754 (perp=6.742, rec=0.076, cos=0.329), tot_loss_proj:2.250 [t=0.18s]
prediction: ['[CLS] young charisma of the a who hold how young woman knows has the screen [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.734 (perp=6.657, rec=0.078, cos=0.325), tot_loss_proj:2.218 [t=0.18s]
prediction: ['[CLS] young charisma of the a who hold how young woman knows the screen has [SEP]']
[ 900/2000] tot_loss=1.735 (perp=6.657, rec=0.073, cos=0.330), tot_loss_proj:2.216 [t=0.19s]
prediction: ['[CLS] young charisma of the a who hold how young woman knows the screen has [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.739 (perp=6.657, rec=0.080, cos=0.328), tot_loss_proj:2.219 [t=0.20s]
prediction: ['[CLS] young charisma of the a who hold how young woman knows the screen has [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.691 (perp=6.436, rec=0.078, cos=0.326), tot_loss_proj:2.138 [t=0.18s]
prediction: ['[CLS] young charisma of the who hold how a young woman knows the screen has [SEP]']
[1050/2000] tot_loss=1.695 (perp=6.436, rec=0.079, cos=0.329), tot_loss_proj:2.137 [t=0.24s]
prediction: ['[CLS] young charisma of the who hold how a young woman knows the screen has [SEP]']
Attempt swap
[1100/2000] tot_loss=1.700 (perp=6.436, rec=0.084, cos=0.329), tot_loss_proj:2.137 [t=0.28s]
prediction: ['[CLS] young charisma of the who hold how a young woman knows the screen has [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.600 (perp=5.997, rec=0.075, cos=0.326), tot_loss_proj:2.043 [t=0.21s]
prediction: ['[CLS] young charisma of the who knows how a young woman hold the screen has [SEP]']
[1200/2000] tot_loss=1.606 (perp=5.997, rec=0.079, cos=0.328), tot_loss_proj:2.035 [t=0.18s]
prediction: ['[CLS] young charisma of the who knows how a young woman hold the screen has [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.565 (perp=5.841, rec=0.070, cos=0.327), tot_loss_proj:1.982 [t=0.19s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.569 (perp=5.841, rec=0.072, cos=0.329), tot_loss_proj:1.978 [t=0.21s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
[1350/2000] tot_loss=1.563 (perp=5.841, rec=0.066, cos=0.329), tot_loss_proj:1.979 [t=0.23s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.570 (perp=5.841, rec=0.073, cos=0.329), tot_loss_proj:1.979 [t=0.19s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.574 (perp=5.841, rec=0.076, cos=0.330), tot_loss_proj:1.982 [t=0.18s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
[1500/2000] tot_loss=1.570 (perp=5.841, rec=0.072, cos=0.330), tot_loss_proj:1.978 [t=0.18s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.574 (perp=5.841, rec=0.076, cos=0.330), tot_loss_proj:1.971 [t=0.24s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.574 (perp=5.841, rec=0.076, cos=0.330), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
[1650/2000] tot_loss=1.574 (perp=5.841, rec=0.076, cos=0.330), tot_loss_proj:1.974 [t=0.26s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.575 (perp=5.841, rec=0.076, cos=0.330), tot_loss_proj:1.980 [t=0.24s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.575 (perp=5.873, rec=0.072, cos=0.329), tot_loss_proj:2.002 [t=0.22s]
prediction: ['[CLS] young charisma of the who knows how a young woman has hold the screen [SEP]']
[1800/2000] tot_loss=1.575 (perp=5.873, rec=0.071, cos=0.329), tot_loss_proj:2.002 [t=0.18s]
prediction: ['[CLS] young charisma of the who knows how a young woman has hold the screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.571 (perp=5.873, rec=0.067, cos=0.329), tot_loss_proj:1.996 [t=0.24s]
prediction: ['[CLS] young charisma of the who knows how a young woman has hold the screen [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.559 (perp=5.841, rec=0.061, cos=0.329), tot_loss_proj:1.980 [t=0.19s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
[1950/2000] tot_loss=1.573 (perp=5.841, rec=0.075, cos=0.330), tot_loss_proj:1.984 [t=0.19s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.563 (perp=5.841, rec=0.065, cos=0.330), tot_loss_proj:1.981 [t=0.18s]
prediction: ['[CLS] young charisma of the who knows how has a young woman hold the screen [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] young charisma of the who knows how a young woman has hold the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.750 | p: 93.750 | r: 93.750
rouge2     | fm: 53.333 | p: 53.333 | r: 53.333
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 147.083

[Aggregate metrics]:
rouge1     | fm: 87.656 | p: 86.763 | r: 88.683
rouge2     | fm: 55.240 | p: 54.967 | r: 55.595
rougeL     | fm: 77.001 | p: 76.253 | r: 77.884
rougeLsum  | fm: 76.906 | p: 76.203 | r: 77.851
r1fm+r2fm = 142.896

input #59 time: 0:08:31 | total time: 8:21:45


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.8878880492454932
highest_index [0]
highest [0.8878880492454932]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9842059016227722 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9609546661376953 for ['[CLS] everything partnership bas gossip lies donegal directionbad his western ann arms [SEP]']
[Init] best rec loss: 0.9453084468841553 for ['[CLS] eddiedding whenly became northeast theo solid sighed signsrral frozen [SEP]']
[Init] best rec loss: 0.944445013999939 for ['[CLS] linger professor capsule ne dates states love surface gauge shrine top publisher [SEP]']
[Init] best rec loss: 0.9204800128936768 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.9155783653259277 for ['[CLS] percent symbol budapest herald nets flavor shoppingted archlizer clock tight [SEP]']
[Init] best rec loss: 0.9097769856452942 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.9025458097457886 for ['[CLS]chemist myselfkar waiting locking ribbon tear dreams mosaic dorothy sure... [SEP]']
[Init] best perm rec loss: 0.8995996117591858 for ['[CLS] tear myself dorothy... locking surechemist mosaic waitingkar dreams ribbon [SEP]']
[Init] best perm rec loss: 0.8985217213630676 for ['[CLS] myself waiting dreams dorothy tearchemist mosaickar ribbon locking... sure [SEP]']
[Init] best perm rec loss: 0.8970704674720764 for ['[CLS] locking ribbon waitingchemist dreams tear... dorothy mosaic myself surekar [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.813 (perp=11.522, rec=0.299, cos=0.210), tot_loss_proj:3.672 [t=0.19s]
prediction: ['[CLS] podcast awkwardly stammered no巿 disease, hiding madtium - series [SEP]']
[ 100/2000] tot_loss=2.648 (perp=11.051, rec=0.240, cos=0.198), tot_loss_proj:3.473 [t=0.18s]
prediction: ['[CLS] awkwardly awkwardly awkwardly noneas hiv, earlier opera is opera story [SEP]']
[ 150/2000] tot_loss=2.579 (perp=10.877, rec=0.196, cos=0.208), tot_loss_proj:3.017 [t=0.18s]
prediction: ['[CLS] awkwardly awkwardly paced isneas paced.ke opera is soap story [SEP]']
[ 200/2000] tot_loss=2.495 (perp=10.744, rec=0.153, cos=0.192), tot_loss_proj:2.969 [t=0.18s]
prediction: ['[CLS] awkwardly awkwardly paced the paced paced.ke circuit is soap story [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.294 (perp=9.770, rec=0.141, cos=0.199), tot_loss_proj:2.887 [t=0.22s]
prediction: ['[CLS] awkwardly awkwardly paced - the paced paced is circuit is soap story [SEP]']
[ 300/2000] tot_loss=2.240 (perp=9.544, rec=0.139, cos=0.192), tot_loss_proj:2.769 [t=0.18s]
prediction: ['[CLS] awkwardly awkwardly paced - the paced pacedh circuit is soap story [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.132 (perp=9.136, rec=0.105, cos=0.200), tot_loss_proj:2.700 [t=0.18s]
prediction: ['[CLS] the awkwardly paced - awkwardly paced pacedh circuit is soap story [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.162 (perp=9.309, rec=0.100, cos=0.200), tot_loss_proj:2.701 [t=0.18s]
prediction: ['[CLS] the awkwardly pacedh - awkwardly pacedh circuit is soap story [SEP]']
[ 450/2000] tot_loss=2.163 (perp=9.309, rec=0.093, cos=0.208), tot_loss_proj:2.698 [t=0.18s]
prediction: ['[CLS] the awkwardly pacedh - awkwardly pacedh circuit is soap story [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.161 (perp=9.309, rec=0.091, cos=0.208), tot_loss_proj:2.698 [t=0.18s]
prediction: ['[CLS] the awkwardly pacedh - awkwardly pacedh circuit is soap story [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.163 (perp=9.309, rec=0.099, cos=0.201), tot_loss_proj:2.698 [t=0.19s]
prediction: ['[CLS] the awkwardly pacedh - awkwardly pacedh circuit is soap story [SEP]']
[ 600/2000] tot_loss=2.156 (perp=9.309, rec=0.085, cos=0.209), tot_loss_proj:2.693 [t=0.19s]
prediction: ['[CLS] the awkwardly pacedh - awkwardly pacedh circuit is soap story [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.159 (perp=9.309, rec=0.088, cos=0.209), tot_loss_proj:2.692 [t=0.25s]
prediction: ['[CLS] the awkwardly pacedh - awkwardly pacedh circuit is soap story [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.162 (perp=9.309, rec=0.092, cos=0.209), tot_loss_proj:2.704 [t=0.26s]
prediction: ['[CLS] the awkwardly pacedh - awkwardly pacedh circuit is soap story [SEP]']
[ 750/2000] tot_loss=2.154 (perp=9.309, rec=0.095, cos=0.196), tot_loss_proj:2.703 [t=0.24s]
prediction: ['[CLS] the awkwardly pacedh - awkwardly pacedh circuit is soap story [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.312 (perp=10.060, rec=0.091, cos=0.209), tot_loss_proj:2.828 [t=0.18s]
prediction: ['[CLS] the awkwardly paced opera - awkwardly pacedh circuit is soap story [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.995 (perp=8.458, rec=0.099, cos=0.204), tot_loss_proj:2.368 [t=0.19s]
prediction: ['[CLS] the awkwardly paced story - awkwardly pacedh circuit is soap opera [SEP]']
[ 900/2000] tot_loss=1.986 (perp=8.458, rec=0.086, cos=0.208), tot_loss_proj:2.373 [t=0.18s]
prediction: ['[CLS] the awkwardly paced story - awkwardly pacedh circuit is soap opera [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.936 (perp=8.210, rec=0.088, cos=0.206), tot_loss_proj:2.309 [t=0.22s]
prediction: ['[CLS] awkwardly paced story - the awkwardly pacedh circuit is soap opera [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.905 (perp=8.021, rec=0.092, cos=0.209), tot_loss_proj:2.297 [t=0.22s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap opera [SEP]']
[1050/2000] tot_loss=1.902 (perp=8.021, rec=0.089, cos=0.209), tot_loss_proj:2.295 [t=0.18s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap opera [SEP]']
Attempt swap
[1100/2000] tot_loss=1.911 (perp=8.021, rec=0.097, cos=0.210), tot_loss_proj:2.298 [t=0.26s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap opera [SEP]']
Attempt swap
[1150/2000] tot_loss=1.903 (perp=8.021, rec=0.089, cos=0.209), tot_loss_proj:2.293 [t=0.18s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap opera [SEP]']
[1200/2000] tot_loss=1.899 (perp=8.021, rec=0.085, cos=0.210), tot_loss_proj:2.289 [t=0.25s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap opera [SEP]']
Attempt swap
[1250/2000] tot_loss=1.900 (perp=8.021, rec=0.086, cos=0.209), tot_loss_proj:2.287 [t=0.19s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap opera [SEP]']
Attempt swap
[1300/2000] tot_loss=1.896 (perp=8.021, rec=0.082, cos=0.210), tot_loss_proj:2.285 [t=0.26s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap opera [SEP]']
[1350/2000] tot_loss=1.902 (perp=8.021, rec=0.087, cos=0.211), tot_loss_proj:2.294 [t=0.28s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap opera [SEP]']
Attempt swap
[1400/2000] tot_loss=1.901 (perp=8.021, rec=0.087, cos=0.210), tot_loss_proj:2.283 [t=0.29s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap opera [SEP]']
Attempt swap
[1450/2000] tot_loss=1.900 (perp=8.021, rec=0.086, cos=0.210), tot_loss_proj:2.295 [t=0.18s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap opera [SEP]']
[1500/2000] tot_loss=2.001 (perp=8.545, rec=0.081, cos=0.210), tot_loss_proj:2.563 [t=0.19s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuith is soap is [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.923 (perp=8.197, rec=0.077, cos=0.206), tot_loss_proj:2.304 [t=0.19s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuit ish soap is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.943 (perp=8.197, rec=0.096, cos=0.208), tot_loss_proj:2.293 [t=0.18s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuit ish soap is [SEP]']
[1650/2000] tot_loss=1.928 (perp=8.197, rec=0.080, cos=0.209), tot_loss_proj:2.295 [t=0.19s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuit ish soap is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.934 (perp=8.197, rec=0.085, cos=0.209), tot_loss_proj:2.290 [t=0.24s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuit ish soap is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.935 (perp=8.197, rec=0.086, cos=0.210), tot_loss_proj:2.306 [t=0.22s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuit ish soap is [SEP]']
[1800/2000] tot_loss=1.930 (perp=8.197, rec=0.081, cos=0.209), tot_loss_proj:2.291 [t=0.22s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuit ish soap is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.940 (perp=8.197, rec=0.091, cos=0.210), tot_loss_proj:2.298 [t=0.18s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuit ish soap is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.926 (perp=8.197, rec=0.076, cos=0.210), tot_loss_proj:2.292 [t=0.26s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuit ish soap is [SEP]']
[1950/2000] tot_loss=1.934 (perp=8.197, rec=0.084, cos=0.210), tot_loss_proj:2.296 [t=0.24s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuit ish soap is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.936 (perp=8.197, rec=0.086, cos=0.210), tot_loss_proj:2.298 [t=0.23s]
prediction: ['[CLS] awkwardly paced story - the awkwardly paced circuit ish soap is [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] the awkwardly pacedh - awkwardly pacedh circuit is soap story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 72.727 | r: 72.727
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 54.545 | p: 54.545 | r: 54.545
rougeLsum  | fm: 54.545 | p: 54.545 | r: 54.545
r1fm+r2fm = 102.727

[Aggregate metrics]:
rouge1     | fm: 87.311 | p: 86.544 | r: 88.276
rouge2     | fm: 54.900 | p: 54.589 | r: 55.246
rougeL     | fm: 76.578 | p: 75.885 | r: 77.380
rougeLsum  | fm: 76.560 | p: 75.806 | r: 77.418
r1fm+r2fm = 142.211

input #60 time: 0:08:26 | total time: 8:30:12


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.7979262501342865
highest_index [0]
highest [0.7979262501342865]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9718341827392578 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9672399163246155 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.955614447593689 for ['[CLS] alta http cocked [SEP]']
[Init] best rec loss: 0.9499499201774597 for ['[CLS] tiny poor rail [SEP]']
[Init] best rec loss: 0.9335497617721558 for ['[CLS] prints england vague [SEP]']
[Init] best rec loss: 0.9161354899406433 for ['[CLS] mouth lastless [SEP]']
[Init] best rec loss: 0.906032919883728 for ['[CLS] readyppetphonic [SEP]']
[Init] best rec loss: 0.8679273724555969 for ['[CLS] says -vino [SEP]']
[Init] best rec loss: 0.8459149599075317 for ['[CLS] vehicle surrounding south [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.190 (perp=8.085, rec=0.211, cos=0.362), tot_loss_proj:2.347 [t=0.17s]
prediction: ['[CLS] picture beautiful scene [SEP]']
[ 100/2000] tot_loss=2.297 (perp=8.901, rec=0.155, cos=0.362), tot_loss_proj:2.756 [t=0.18s]
prediction: ['[CLS] scene beautiful scene [SEP]']
[ 150/2000] tot_loss=2.284 (perp=8.901, rec=0.143, cos=0.361), tot_loss_proj:2.767 [t=0.21s]
prediction: ['[CLS] scene beautiful scene [SEP]']
[ 200/2000] tot_loss=2.709 (perp=11.089, rec=0.131, cos=0.361), tot_loss_proj:2.859 [t=0.18s]
prediction: ['[CLS]... beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.669 (perp=10.686, rec=0.168, cos=0.363), tot_loss_proj:3.172 [t=0.26s]
prediction: ['[CLS] beautiful scene shoulders [SEP]']
[ 300/2000] tot_loss=2.643 (perp=10.686, rec=0.143, cos=0.362), tot_loss_proj:3.179 [t=0.23s]
prediction: ['[CLS] beautiful scene shoulders [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.163 (perp=8.299, rec=0.140, cos=0.363), tot_loss_proj:2.461 [t=0.27s]
prediction: ['[CLS] scene + beautiful [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.700 (perp=10.973, rec=0.142, cos=0.363), tot_loss_proj:3.111 [t=0.23s]
prediction: ['[CLS] beautiful within scene [SEP]']
[ 450/2000] tot_loss=2.642 (perp=10.716, rec=0.136, cos=0.363), tot_loss_proj:3.098 [t=0.19s]
prediction: ['[CLS] beautiful s scene [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.265 (perp=8.848, rec=0.132, cos=0.363), tot_loss_proj:2.507 [t=0.18s]
prediction: ['[CLS] beautiful scene s [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.380 (perp=9.419, rec=0.135, cos=0.361), tot_loss_proj:3.141 [t=0.18s]
prediction: ['[CLS] beautiful sceneutive [SEP]']
[ 600/2000] tot_loss=2.740 (perp=11.266, rec=0.124, cos=0.363), tot_loss_proj:3.196 [t=0.18s]
prediction: ['[CLS] beautiful scenetative [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.044 (perp=8.032, rec=0.078, cos=0.360), tot_loss_proj:2.069 [t=0.24s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.868 (perp=7.101, rec=0.088, cos=0.360), tot_loss_proj:2.048 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.855 (perp=7.101, rec=0.073, cos=0.362), tot_loss_proj:2.042 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.852 (perp=7.101, rec=0.069, cos=0.362), tot_loss_proj:2.052 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.842 (perp=7.101, rec=0.059, cos=0.363), tot_loss_proj:2.043 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.854 (perp=7.101, rec=0.071, cos=0.363), tot_loss_proj:2.048 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.849 (perp=7.101, rec=0.067, cos=0.363), tot_loss_proj:2.041 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.850 (perp=7.101, rec=0.067, cos=0.363), tot_loss_proj:2.047 [t=0.22s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.847 (perp=7.101, rec=0.064, cos=0.363), tot_loss_proj:2.045 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.845 (perp=7.101, rec=0.062, cos=0.363), tot_loss_proj:2.043 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.844 (perp=7.101, rec=0.061, cos=0.363), tot_loss_proj:2.044 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.851 (perp=7.101, rec=0.068, cos=0.363), tot_loss_proj:2.043 [t=0.30s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.851 (perp=7.101, rec=0.067, cos=0.363), tot_loss_proj:2.039 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.858 (perp=7.101, rec=0.075, cos=0.363), tot_loss_proj:2.054 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.840 (perp=7.101, rec=0.057, cos=0.363), tot_loss_proj:2.040 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.847 (perp=7.101, rec=0.064, cos=0.363), tot_loss_proj:2.047 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.848 (perp=7.101, rec=0.065, cos=0.363), tot_loss_proj:2.030 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.853 (perp=7.101, rec=0.070, cos=0.363), tot_loss_proj:2.038 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.853 (perp=7.101, rec=0.070, cos=0.363), tot_loss_proj:2.042 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.846 (perp=7.101, rec=0.063, cos=0.363), tot_loss_proj:2.035 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.842 (perp=7.101, rec=0.059, cos=0.363), tot_loss_proj:2.037 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.851 (perp=7.101, rec=0.068, cos=0.363), tot_loss_proj:2.034 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.857 (perp=7.101, rec=0.074, cos=0.363), tot_loss_proj:2.042 [t=0.27s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.848 (perp=7.101, rec=0.065, cos=0.363), tot_loss_proj:2.042 [t=0.24s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.843 (perp=7.101, rec=0.060, cos=0.363), tot_loss_proj:2.041 [t=0.23s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.838 (perp=7.101, rec=0.055, cos=0.363), tot_loss_proj:2.050 [t=0.21s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.851 (perp=7.101, rec=0.068, cos=0.363), tot_loss_proj:2.038 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.838 (perp=7.101, rec=0.055, cos=0.363), tot_loss_proj:2.042 [t=0.25s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.528 | p: 86.758 | r: 88.536
rouge2     | fm: 55.610 | p: 55.324 | r: 55.946
rougeL     | fm: 76.917 | p: 76.217 | r: 77.775
rougeLsum  | fm: 76.932 | p: 76.271 | r: 77.731
r1fm+r2fm = 143.139

input #61 time: 0:08:28 | total time: 8:38:41


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.8323055954252123
highest_index [0]
highest [0.8323055954252123]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9157217741012573 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.8942233920097351 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.8919975757598877 for ['[CLS] did is ruled shooting boarding craters verseverse cartoon mickey counts jones period opposed inside incentiveshua together circle nw 16 [SEP]']
[Init] best rec loss: 0.8908466696739197 for ['[CLS] services te isbnentseye久 researchcreen past sequencingwn can pier precise linda erica monk val contestbe foreign [SEP]']
[Init] best rec loss: 0.884632408618927 for ['[CLS]ining strata won suitedtis near isaac bull worship here techp perhaps assistant kerman negative fisulsion ash too skill [SEP]']
[Init] best rec loss: 0.8823626637458801 for ['[CLS] butterfly alternative professional all diveleader withstand reins emergency fears rate feet iv bat burn judgeulsive busy give student military [SEP]']
[Init] best rec loss: 0.8806381821632385 for ['[CLS]ecure armedria obvious commission symbol echo drinking testified mothergaard reacher executive dressed playing but name ups [SEP] [MASK] kala [SEP]']
[Init] best rec loss: 0.8710338473320007 for ['[CLS] part remembered victor jayne imagined♭ basket against cheeks barrow battalion whilefold informed had higher outstanding ezio ramirez malta pinyin [SEP]']
[Init] best perm rec loss: 0.8691854476928711 for ['[CLS] outstanding barrow ramirez against had jayne♭ malta remembered victor higherfold cheeks ezio pinyin basket imagined while informed part battalion [SEP]']
[Init] best perm rec loss: 0.8665549755096436 for ['[CLS] while ezio victor maltafold informed ramirez part higher outstanding♭ battalion cheeks remembered basket barrow imagined against pinyin jayne had [SEP]']
[Init] best perm rec loss: 0.8657760620117188 for ['[CLS] ramirez imagined outstanding against♭fold part basket ezio pinyin barrow informed battalion while jayne remembered malta victor higher cheeks had [SEP]']
[Init] best perm rec loss: 0.8641487956047058 for ['[CLS] while jayne against ezio victor pinyinfold imagined part basket ramirez had barrow informed battalion cheeks higher malta remembered♭ outstanding [SEP]']
[Init] best perm rec loss: 0.8637477159500122 for ['[CLS] basket imagined against remembered ezio outstandingfold had jayne pinyin while informed victor ramirez barrow battalion higher part malta cheeks♭ [SEP]']
[Init] best perm rec loss: 0.8624676465988159 for ['[CLS] battalion part outstanding higher victor cheeks while had imaginedfold malta ezio pinyin ramirez remembered♭ basket informed barrow jayne against [SEP]']
[Init] best perm rec loss: 0.8622778654098511 for ['[CLS] imagined ramirez♭ victor part higher cheeks jayne againstfold ezio outstanding basket malta while informed remembered had pinyin barrow battalion [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.964 (perp=11.515, rec=0.363, cos=0.298), tot_loss_proj:4.199 [t=0.19s]
prediction: ['[CLS] made destroy success nba grace too for so tourist preparation for quality wildlife lewis length range lady of equitymaking best [SEP]']
[ 100/2000] tot_loss=2.686 (perp=10.628, rec=0.257, cos=0.303), tot_loss_proj:3.958 [t=0.19s]
prediction: ['[CLS] assumed mo grace into grace made for as prevention preparation for best wildlife lewis made that remembered of movies movies best [SEP]']
[ 150/2000] tot_loss=2.376 (perp=9.401, rec=0.192, cos=0.304), tot_loss_proj:3.324 [t=0.18s]
prediction: ['[CLS] assumed thrill grace to grace making for its prevention prevention to best war movies ever on film of movies movies best [SEP]']
[ 200/2000] tot_loss=2.265 (perp=9.018, rec=0.157, cos=0.304), tot_loss_proj:3.022 [t=0.19s]
prediction: ['[CLS] for to grace to grace making to one prevention prevention to best war movies ever of movies of war movies best [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.002 (perp=7.797, rec=0.148, cos=0.295), tot_loss_proj:3.180 [t=0.27s]
prediction: ['[CLS] to to grace to grace to one prevention rather to the war movies ever making are movies of war movies best [SEP]']
[ 300/2000] tot_loss=2.046 (perp=7.967, rec=0.146, cos=0.306), tot_loss_proj:3.346 [t=0.21s]
prediction: ['[CLS] to to grace call grace to one prevention rather to the war movies ever making of dvd the war movies best [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.096 (perp=8.361, rec=0.119, cos=0.305), tot_loss_proj:3.505 [t=0.18s]
prediction: ['[CLS] to call make call grace to one prevention rather to the war it of ever makingnished the war movies best [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.132 (perp=8.302, rec=0.180, cos=0.292), tot_loss_proj:3.391 [t=0.26s]
prediction: ['[CLS] to call one make grace to grace prevention rather to the self movies, ever making prevention the war movies best [SEP]']
[ 450/2000] tot_loss=2.196 (perp=8.803, rec=0.137, cos=0.298), tot_loss_proj:3.375 [t=0.19s]
prediction: ["[CLS] to call one making grace to going prevention rather to the honest it the ever making'the war movies best [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.159 (perp=8.699, rec=0.116, cos=0.304), tot_loss_proj:3.537 [t=0.18s]
prediction: ["[CLS] rather going one making grace to call prevention rather to the big it the ever making'the war movies best [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.124 (perp=8.541, rec=0.111, cos=0.304), tot_loss_proj:3.471 [t=0.21s]
prediction: ["[CLS] rather it one making grace to call prevention rather it the personal going the ever making'the war movies best [SEP]"]
[ 600/2000] tot_loss=2.076 (perp=8.383, rec=0.100, cos=0.300), tot_loss_proj:3.504 [t=0.18s]
prediction: ["[CLS] rather it one making grace to call prevention rather it the blame going the ever,'the war movies best [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.970 (perp=7.790, rec=0.108, cos=0.304), tot_loss_proj:3.365 [t=0.23s]
prediction: ["[CLS] rather it one making grace to call prevention rather it the blame, the ever going'the war movies best [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.936 (perp=7.660, rec=0.101, cos=0.303), tot_loss_proj:3.278 [t=0.18s]
prediction: ["[CLS] rather it one making grace to call blame rather it the prevention, the ever going'the war movies best [SEP]"]
[ 750/2000] tot_loss=1.934 (perp=7.660, rec=0.095, cos=0.307), tot_loss_proj:3.276 [t=0.30s]
prediction: ["[CLS] rather it one making grace to call blame rather it the prevention, the ever going'the war movies best [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.901 (perp=7.438, rec=0.107, cos=0.307), tot_loss_proj:3.321 [t=0.19s]
prediction: ["[CLS] making it one for grace to call blame rather it the prevention,, ever going'the war movies best [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.909 (perp=7.537, rec=0.095, cos=0.306), tot_loss_proj:3.303 [t=0.18s]
prediction: ["[CLS] making it one for grace to call blame rather it, prevention the, ever would'the war movies best [SEP]"]
[ 900/2000] tot_loss=1.934 (perp=7.660, rec=0.095, cos=0.307), tot_loss_proj:3.374 [t=0.24s]
prediction: ["[CLS] making it one for grace to call blame rather it, prevention the blame ever would'the war movies best [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.893 (perp=7.494, rec=0.090, cos=0.305), tot_loss_proj:3.354 [t=0.18s]
prediction: ["[CLS] making it one for grace to call blame rather it, prevention the blame would'ever the war movies best [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.872 (perp=7.348, rec=0.098, cos=0.305), tot_loss_proj:3.333 [t=0.18s]
prediction: ["[CLS] making it one for grace to call blame it, prevention rather the blame would'ever the war movies best [SEP]"]
[1050/2000] tot_loss=1.863 (perp=7.348, rec=0.090, cos=0.304), tot_loss_proj:3.328 [t=0.25s]
prediction: ["[CLS] making it one for grace to call blame it, prevention rather the blame would'ever the war movies best [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.859 (perp=7.348, rec=0.084, cos=0.305), tot_loss_proj:3.327 [t=0.23s]
prediction: ["[CLS] making it one for grace to call blame it, prevention rather the blame would'ever the war movies best [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.856 (perp=7.312, rec=0.087, cos=0.307), tot_loss_proj:3.307 [t=0.20s]
prediction: ["[CLS] making it one for grace to call blame it, rather prevention the blame would'ever the war movies best [SEP]"]
[1200/2000] tot_loss=1.857 (perp=7.312, rec=0.088, cos=0.306), tot_loss_proj:3.309 [t=0.18s]
prediction: ["[CLS] making it one for grace to call blame it, rather prevention the blame would'ever the war movies best [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.847 (perp=7.295, rec=0.083, cos=0.305), tot_loss_proj:3.306 [t=0.25s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would'ever the war movies best [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.855 (perp=7.295, rec=0.088, cos=0.307), tot_loss_proj:3.308 [t=0.24s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would'ever the war movies best [SEP]"]
[1350/2000] tot_loss=1.850 (perp=7.295, rec=0.084, cos=0.307), tot_loss_proj:3.309 [t=0.18s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would'ever the war movies best [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.851 (perp=7.295, rec=0.087, cos=0.305), tot_loss_proj:3.309 [t=0.18s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would'ever the war movies best [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.831 (perp=7.166, rec=0.090, cos=0.307), tot_loss_proj:3.151 [t=0.22s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would'ever war movies the best [SEP]"]
[1500/2000] tot_loss=1.829 (perp=7.166, rec=0.089, cos=0.307), tot_loss_proj:3.150 [t=0.18s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would'ever war movies the best [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.828 (perp=7.166, rec=0.088, cos=0.307), tot_loss_proj:3.151 [t=0.21s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would'ever war movies the best [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.820 (perp=7.166, rec=0.080, cos=0.307), tot_loss_proj:3.151 [t=0.26s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would'ever war movies the best [SEP]"]
[1650/2000] tot_loss=1.828 (perp=7.166, rec=0.090, cos=0.305), tot_loss_proj:3.154 [t=0.19s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would'ever war movies the best [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.810 (perp=7.078, rec=0.089, cos=0.306), tot_loss_proj:3.191 [t=0.20s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would ever'war movies the best [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.798 (perp=7.078, rec=0.076, cos=0.307), tot_loss_proj:3.188 [t=0.19s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would ever'war movies the best [SEP]"]
[1800/2000] tot_loss=1.801 (perp=7.078, rec=0.078, cos=0.307), tot_loss_proj:3.190 [t=0.20s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would ever'war movies the best [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.806 (perp=7.078, rec=0.084, cos=0.307), tot_loss_proj:3.189 [t=0.30s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would ever'war movies the best [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.814 (perp=7.078, rec=0.091, cos=0.307), tot_loss_proj:3.188 [t=0.21s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would ever'war movies the best [SEP]"]
[1950/2000] tot_loss=1.806 (perp=7.078, rec=0.083, cos=0.307), tot_loss_proj:3.184 [t=0.19s]
prediction: ["[CLS] making it one for grace to call blame, it rather prevention the blame would ever'war movies the best [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.756 (perp=6.818, rec=0.087, cos=0.306), tot_loss_proj:3.196 [t=0.23s]
prediction: ["[CLS] making it one for grace to call blame, it would rather prevention the blame ever'war movies the best [SEP]"]
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] making it one for grace to call blame, it rather prevention the blame would'ever war movies the best [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 79.070 | p: 80.952 | r: 77.273
rouge2     | fm: 29.268 | p: 30.000 | r: 28.571
rougeL     | fm: 46.512 | p: 47.619 | r: 45.455
rougeLsum  | fm: 46.512 | p: 47.619 | r: 45.455
r1fm+r2fm = 108.338

[Aggregate metrics]:
rouge1     | fm: 87.507 | p: 86.708 | r: 88.397
rouge2     | fm: 55.237 | p: 55.023 | r: 55.523
rougeL     | fm: 76.374 | p: 75.749 | r: 77.151
rougeLsum  | fm: 76.373 | p: 75.684 | r: 77.158
r1fm+r2fm = 142.744

input #62 time: 0:08:30 | total time: 8:47:11


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.8977958634766918
highest_index [0]
highest [0.8977958634766918]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.8076175451278687 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.7152612805366516 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.6861708164215088 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best perm rec loss: 0.6839349865913391 for ['[CLS] written workingism brighter spend [SEP]']
[Init] best perm rec loss: 0.6820573210716248 for ['[CLS] brighter working spendism written [SEP]']
[Init] best perm rec loss: 0.6816189289093018 for ['[CLS] written spend workingism brighter [SEP]']
[Init] best perm rec loss: 0.6792128086090088 for ['[CLS]ism brighter written working spend [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.330 (perp=12.040, rec=0.752, cos=0.170), tot_loss_proj:4.112 [t=0.18s]
prediction: ['[CLS] my warm kepler goodually [SEP]']
[ 100/2000] tot_loss=3.679 (perp=14.352, rec=0.630, cos=0.179), tot_loss_proj:4.548 [t=0.19s]
prediction: ['[CLS]hus warm galen good ticket [SEP]']
[ 150/2000] tot_loss=2.997 (perp=11.059, rec=0.620, cos=0.165), tot_loss_proj:4.068 [t=0.18s]
prediction: ['[CLS] his warm political slow ticket [SEP]']
[ 200/2000] tot_loss=2.805 (perp=10.222, rec=0.563, cos=0.198), tot_loss_proj:3.485 [t=0.28s]
prediction: ['[CLS] his provides leaving base ticket [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.041 (perp=11.786, rec=0.557, cos=0.126), tot_loss_proj:3.580 [t=0.20s]
prediction: ['[CLS] ticket his provides leaving local [SEP]']
[ 300/2000] tot_loss=2.938 (perp=11.513, rec=0.521, cos=0.114), tot_loss_proj:4.090 [t=0.18s]
prediction: ['[CLS] ticket his cool returning temptation [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=3.021 (perp=12.012, rec=0.507, cos=0.111), tot_loss_proj:4.152 [t=0.19s]
prediction: ['[CLS] admission deserves returning temptation ticket [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=3.365 (perp=13.813, rec=0.473, cos=0.129), tot_loss_proj:4.563 [t=0.19s]
prediction: ['[CLS]zong ticket suitable returning temptation [SEP]']
[ 450/2000] tot_loss=3.335 (perp=13.813, rec=0.465, cos=0.107), tot_loss_proj:4.567 [t=0.18s]
prediction: ['[CLS]zong ticket suitable returning temptation [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=2.996 (perp=12.385, rec=0.456, cos=0.064), tot_loss_proj:4.167 [t=0.19s]
prediction: ['[CLS] visible returning plentyzong ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.921 (perp=12.155, rec=0.410, cos=0.080), tot_loss_proj:4.055 [t=0.19s]
prediction: ['[CLS] < returning plentyzong ticket [SEP]']
[ 600/2000] tot_loss=2.898 (perp=12.155, rec=0.403, cos=0.064), tot_loss_proj:4.048 [t=0.24s]
prediction: ['[CLS] < returning plentyzong ticket [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.890 (perp=11.282, rec=0.394, cos=0.240), tot_loss_proj:4.042 [t=0.18s]
prediction: ['[CLS] < ticket returning plentyzong [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.029 (perp=12.578, rec=0.375, cos=0.138), tot_loss_proj:4.344 [t=0.18s]
prediction: ['[CLS] < ticket looking plentyzong [SEP]']
[ 750/2000] tot_loss=3.089 (perp=12.578, rec=0.390, cos=0.184), tot_loss_proj:4.343 [t=0.19s]
prediction: ['[CLS] < ticket looking plentyzong [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.586 (perp=10.373, rec=0.358, cos=0.154), tot_loss_proj:3.718 [t=0.26s]
prediction: ['[CLS] < looking ticket return admission [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.454 (perp=9.445, rec=0.358, cos=0.207), tot_loss_proj:3.659 [t=0.25s]
prediction: ['[CLS] < admission ticket return looking [SEP]']
[ 900/2000] tot_loss=2.326 (perp=9.445, rec=0.337, cos=0.099), tot_loss_proj:3.657 [t=0.19s]
prediction: ['[CLS] < admission ticket return looking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.400 (perp=9.445, rec=0.354, cos=0.157), tot_loss_proj:3.667 [t=0.22s]
prediction: ['[CLS] < admission ticket return looking [SEP]']
Attempt swap
Put prefix at the end
[1000/2000] tot_loss=2.425 (perp=9.859, rec=0.353, cos=0.100), tot_loss_proj:3.699 [t=0.18s]
prediction: ['[CLS] admission ticket return looking easiest [SEP]']
[1050/2000] tot_loss=2.403 (perp=9.859, rec=0.328, cos=0.104), tot_loss_proj:3.696 [t=0.19s]
prediction: ['[CLS] admission ticket return looking easiest [SEP]']
Attempt swap
[1100/2000] tot_loss=2.365 (perp=9.859, rec=0.329, cos=0.064), tot_loss_proj:3.701 [t=0.19s]
prediction: ['[CLS] admission ticket return looking easiest [SEP]']
Attempt swap
[1150/2000] tot_loss=2.443 (perp=9.859, rec=0.323, cos=0.149), tot_loss_proj:3.701 [t=0.18s]
prediction: ['[CLS] admission ticket return looking easiest [SEP]']
[1200/2000] tot_loss=2.470 (perp=9.859, rec=0.312, cos=0.185), tot_loss_proj:3.699 [t=0.18s]
prediction: ['[CLS] admission ticket return looking easiest [SEP]']
Attempt swap
[1250/2000] tot_loss=2.427 (perp=9.859, rec=0.313, cos=0.143), tot_loss_proj:3.702 [t=0.18s]
prediction: ['[CLS] admission ticket return looking easiest [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.636 (perp=11.065, rec=0.334, cos=0.089), tot_loss_proj:3.699 [t=0.27s]
prediction: ['[CLS] return ticket admission looking easiest [SEP]']
[1350/2000] tot_loss=2.367 (perp=9.987, rec=0.304, cos=0.066), tot_loss_proj:3.425 [t=0.19s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
Attempt swap
[1400/2000] tot_loss=2.374 (perp=9.987, rec=0.304, cos=0.072), tot_loss_proj:3.429 [t=0.18s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
Attempt swap
[1450/2000] tot_loss=2.340 (perp=9.987, rec=0.300, cos=0.043), tot_loss_proj:3.426 [t=0.22s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
[1500/2000] tot_loss=2.486 (perp=9.987, rec=0.299, cos=0.190), tot_loss_proj:3.422 [t=0.18s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
Attempt swap
[1550/2000] tot_loss=2.386 (perp=9.987, rec=0.296, cos=0.093), tot_loss_proj:3.430 [t=0.18s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
Attempt swap
[1600/2000] tot_loss=2.348 (perp=9.987, rec=0.292, cos=0.059), tot_loss_proj:3.420 [t=0.28s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
[1650/2000] tot_loss=2.393 (perp=9.987, rec=0.306, cos=0.089), tot_loss_proj:3.429 [t=0.27s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
Attempt swap
[1700/2000] tot_loss=2.450 (perp=9.987, rec=0.293, cos=0.160), tot_loss_proj:3.423 [t=0.18s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
Attempt swap
[1750/2000] tot_loss=2.365 (perp=9.987, rec=0.296, cos=0.071), tot_loss_proj:3.427 [t=0.18s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
[1800/2000] tot_loss=2.382 (perp=9.987, rec=0.296, cos=0.088), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
Attempt swap
[1850/2000] tot_loss=2.382 (perp=9.987, rec=0.296, cos=0.089), tot_loss_proj:3.425 [t=0.18s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
Attempt swap
[1900/2000] tot_loss=2.373 (perp=9.987, rec=0.294, cos=0.082), tot_loss_proj:3.426 [t=0.24s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
[1950/2000] tot_loss=2.370 (perp=9.987, rec=0.290, cos=0.082), tot_loss_proj:3.421 [t=0.24s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
Attempt swap
[2000/2000] tot_loss=2.369 (perp=9.987, rec=0.289, cos=0.083), tot_loss_proj:3.426 [t=0.22s]
prediction: ['[CLS] return ticket release looking easiest [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] return ticket release looking easiest [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 88.095

[Aggregate metrics]:
rouge1     | fm: 87.186 | p: 86.453 | r: 88.101
rouge2     | fm: 54.579 | p: 54.264 | r: 54.856
rougeL     | fm: 76.124 | p: 75.458 | r: 76.924
rougeLsum  | fm: 76.161 | p: 75.434 | r: 76.969
r1fm+r2fm = 141.765

input #63 time: 0:08:14 | total time: 8:55:26


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.8566462047351519
highest_index [0]
highest [0.8566462047351519]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8810994029045105 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8248288035392761 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 0.8104186058044434 for ['[CLS] david [CLS] earliest [SEP]']
[Init] best rec loss: 0.7240460515022278 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6800627708435059 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6773717999458313 for ['[CLS] wateronale visions [SEP]']
[Init] best perm rec loss: 0.6772541403770447 for ['[CLS]onale visions water [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.338 (perp=9.190, rec=0.245, cos=0.255), tot_loss_proj:2.423 [t=0.18s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 100/2000] tot_loss=2.260 (perp=9.190, rec=0.159, cos=0.262), tot_loss_proj:2.418 [t=0.18s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 150/2000] tot_loss=1.946 (perp=8.065, rec=0.070, cos=0.263), tot_loss_proj:1.967 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 200/2000] tot_loss=1.942 (perp=8.065, rec=0.065, cos=0.264), tot_loss_proj:1.966 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.943 (perp=8.065, rec=0.065, cos=0.265), tot_loss_proj:1.963 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=1.922 (perp=8.065, rec=0.044, cos=0.265), tot_loss_proj:1.972 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.945 (perp=8.065, rec=0.066, cos=0.265), tot_loss_proj:1.966 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.949 (perp=8.065, rec=0.071, cos=0.266), tot_loss_proj:1.973 [t=0.28s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.952 (perp=8.065, rec=0.073, cos=0.266), tot_loss_proj:1.955 [t=0.20s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.927 (perp=8.065, rec=0.048, cos=0.266), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.944 (perp=8.065, rec=0.065, cos=0.266), tot_loss_proj:1.966 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.930 (perp=8.065, rec=0.056, cos=0.261), tot_loss_proj:1.961 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.938 (perp=8.065, rec=0.061, cos=0.265), tot_loss_proj:1.959 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.942 (perp=8.065, rec=0.064, cos=0.265), tot_loss_proj:1.959 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.941 (perp=8.065, rec=0.062, cos=0.266), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.948 (perp=8.065, rec=0.069, cos=0.266), tot_loss_proj:1.970 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.942 (perp=8.065, rec=0.063, cos=0.266), tot_loss_proj:1.962 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.936 (perp=8.065, rec=0.057, cos=0.266), tot_loss_proj:1.970 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.938 (perp=8.065, rec=0.059, cos=0.266), tot_loss_proj:1.968 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.935 (perp=8.065, rec=0.056, cos=0.266), tot_loss_proj:1.970 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.956 (perp=8.065, rec=0.077, cos=0.266), tot_loss_proj:1.982 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.940 (perp=8.065, rec=0.061, cos=0.266), tot_loss_proj:1.957 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.940 (perp=8.065, rec=0.061, cos=0.266), tot_loss_proj:1.960 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.937 (perp=8.065, rec=0.058, cos=0.266), tot_loss_proj:1.958 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.932 (perp=8.065, rec=0.052, cos=0.266), tot_loss_proj:1.954 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.941 (perp=8.065, rec=0.062, cos=0.266), tot_loss_proj:1.973 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.942 (perp=8.065, rec=0.063, cos=0.266), tot_loss_proj:1.964 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.940 (perp=8.065, rec=0.061, cos=0.266), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.930 (perp=8.065, rec=0.051, cos=0.266), tot_loss_proj:1.979 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.936 (perp=8.065, rec=0.057, cos=0.266), tot_loss_proj:1.962 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.939 (perp=8.065, rec=0.066, cos=0.261), tot_loss_proj:1.964 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.935 (perp=8.065, rec=0.058, cos=0.264), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.938 (perp=8.065, rec=0.060, cos=0.265), tot_loss_proj:1.968 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.938 (perp=8.065, rec=0.060, cos=0.265), tot_loss_proj:1.968 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.938 (perp=8.065, rec=0.059, cos=0.265), tot_loss_proj:1.967 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.928 (perp=8.065, rec=0.049, cos=0.266), tot_loss_proj:1.980 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.940 (perp=8.065, rec=0.061, cos=0.266), tot_loss_proj:1.967 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.936 (perp=8.065, rec=0.057, cos=0.266), tot_loss_proj:1.957 [t=0.26s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.939 (perp=8.065, rec=0.060, cos=0.266), tot_loss_proj:1.955 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.931 (perp=8.065, rec=0.052, cos=0.266), tot_loss_proj:1.958 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.430 | p: 86.746 | r: 88.334
rouge2     | fm: 55.303 | p: 55.029 | r: 55.579
rougeL     | fm: 76.474 | p: 75.801 | r: 77.309
rougeLsum  | fm: 76.624 | p: 76.022 | r: 77.400
r1fm+r2fm = 142.733

input #64 time: 0:08:16 | total time: 9:03:42


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.7805251761674068
highest_index [0]
highest [0.7805251761674068]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 0.8912085294723511 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.87895268201828 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.8661776781082153 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 0.8486887216567993 for ['[CLS] nyunce coalition pdf dailyenburg registry romanesqueric [SEP]']
[Init] best rec loss: 0.8395039439201355 for ['[CLS] script the classning lau tape from later skate [SEP]']
[Init] best rec loss: 0.8341197967529297 for ['[CLS] health kuept scenicne contact will savamac [SEP]']
[Init] best rec loss: 0.8153926730155945 for ['[CLS] dancer relative being bar shoulder allmusic original eatingolic [SEP]']
[Init] best rec loss: 0.7881699800491333 for ['[CLS] graphic - oxygen jessie go distinguished they alt decommissioned [SEP]']
[Init] best rec loss: 0.7551817297935486 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.7520802021026611 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.7517006397247314 for ['[CLS]mament even news general fun pu overshoff someday [SEP]']
[Init] best perm rec loss: 0.7492507696151733 for ['[CLS] fun even overshoffmament general pu someday news [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.960 (perp=11.176, rec=0.341, cos=0.384), tot_loss_proj:3.240 [t=0.22s]
prediction: ['[CLS] joy of event team joyous joy help including [SEP]']
[ 100/2000] tot_loss=2.168 (perp=7.970, rec=0.192, cos=0.382), tot_loss_proj:2.625 [t=0.25s]
prediction: ['[CLS] joy of, film joyous joy help. [SEP]']
[ 150/2000] tot_loss=2.239 (perp=8.523, rec=0.147, cos=0.387), tot_loss_proj:2.668 [t=0.26s]
prediction: ['[CLS] joy of, film joyous rom film. [SEP]']
[ 200/2000] tot_loss=2.218 (perp=8.523, rec=0.128, cos=0.386), tot_loss_proj:2.664 [t=0.18s]
prediction: ['[CLS] joy of, film joyous rom film. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.001 (perp=7.549, rec=0.103, cos=0.388), tot_loss_proj:2.405 [t=0.18s]
prediction: ['[CLS] of joy, film joyous rom film. [SEP]']
[ 300/2000] tot_loss=1.983 (perp=7.549, rec=0.085, cos=0.389), tot_loss_proj:2.415 [t=0.18s]
prediction: ['[CLS] of joy, film joyous rom film. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.846 (perp=6.857, rec=0.086, cos=0.389), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS] of joy film, joyous rom film. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.790 (perp=6.607, rec=0.082, cos=0.387), tot_loss_proj:2.148 [t=0.18s]
prediction: ['[CLS] film of joy, joyous rom film. [SEP]']
[ 450/2000] tot_loss=1.788 (perp=6.607, rec=0.077, cos=0.390), tot_loss_proj:2.152 [t=0.26s]
prediction: ['[CLS] film of joy, joyous rom film. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.798 (perp=6.607, rec=0.087, cos=0.390), tot_loss_proj:2.151 [t=0.19s]
prediction: ['[CLS] film of joy, joyous rom film. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.535 (perp=5.265, rec=0.092, cos=0.390), tot_loss_proj:1.781 [t=0.19s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
[ 600/2000] tot_loss=1.520 (perp=5.265, rec=0.077, cos=0.390), tot_loss_proj:1.794 [t=0.25s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.515 (perp=5.265, rec=0.072, cos=0.390), tot_loss_proj:1.784 [t=0.18s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.516 (perp=5.265, rec=0.073, cos=0.389), tot_loss_proj:1.791 [t=0.19s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
[ 750/2000] tot_loss=1.529 (perp=5.265, rec=0.086, cos=0.390), tot_loss_proj:1.785 [t=0.19s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.527 (perp=5.265, rec=0.084, cos=0.390), tot_loss_proj:1.787 [t=0.19s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.511 (perp=5.265, rec=0.067, cos=0.390), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
[ 900/2000] tot_loss=1.520 (perp=5.265, rec=0.077, cos=0.391), tot_loss_proj:1.786 [t=0.22s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.509 (perp=5.265, rec=0.065, cos=0.391), tot_loss_proj:1.793 [t=0.18s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.509 (perp=5.265, rec=0.068, cos=0.387), tot_loss_proj:1.786 [t=0.19s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
[1050/2000] tot_loss=1.519 (perp=5.265, rec=0.076, cos=0.390), tot_loss_proj:1.780 [t=0.23s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.512 (perp=5.265, rec=0.068, cos=0.390), tot_loss_proj:1.796 [t=0.23s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.514 (perp=5.265, rec=0.070, cos=0.390), tot_loss_proj:1.793 [t=0.23s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
[1200/2000] tot_loss=1.516 (perp=5.265, rec=0.072, cos=0.391), tot_loss_proj:1.787 [t=0.22s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.522 (perp=5.265, rec=0.078, cos=0.391), tot_loss_proj:1.785 [t=0.18s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.518 (perp=5.265, rec=0.074, cos=0.391), tot_loss_proj:1.794 [t=0.18s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
[1350/2000] tot_loss=1.512 (perp=5.265, rec=0.068, cos=0.391), tot_loss_proj:1.786 [t=0.24s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.509 (perp=5.265, rec=0.067, cos=0.389), tot_loss_proj:1.793 [t=0.18s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.517 (perp=5.265, rec=0.074, cos=0.390), tot_loss_proj:1.785 [t=0.20s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
[1500/2000] tot_loss=1.510 (perp=5.265, rec=0.066, cos=0.390), tot_loss_proj:1.789 [t=0.20s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.523 (perp=5.265, rec=0.079, cos=0.390), tot_loss_proj:1.788 [t=0.18s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.518 (perp=5.265, rec=0.074, cos=0.391), tot_loss_proj:1.782 [t=0.29s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
[1650/2000] tot_loss=1.519 (perp=5.265, rec=0.076, cos=0.391), tot_loss_proj:1.789 [t=0.18s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.519 (perp=5.265, rec=0.075, cos=0.391), tot_loss_proj:1.790 [t=0.22s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.514 (perp=5.265, rec=0.070, cos=0.391), tot_loss_proj:1.792 [t=0.18s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
[1800/2000] tot_loss=1.526 (perp=5.265, rec=0.082, cos=0.391), tot_loss_proj:1.786 [t=0.26s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.510 (perp=5.265, rec=0.066, cos=0.391), tot_loss_proj:1.780 [t=0.34s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.513 (perp=5.265, rec=0.069, cos=0.391), tot_loss_proj:1.770 [t=0.17s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
[1950/2000] tot_loss=1.520 (perp=5.265, rec=0.076, cos=0.391), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.513 (perp=5.265, rec=0.070, cos=0.389), tot_loss_proj:1.767 [t=0.27s]
prediction: ['[CLS] film of joy, joyous romp. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] film of joy, joyous romp. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 87.403 | p: 86.726 | r: 88.312
rouge2     | fm: 54.751 | p: 54.507 | r: 55.088
rougeL     | fm: 76.149 | p: 75.549 | r: 76.932
rougeLsum  | fm: 76.344 | p: 75.734 | r: 77.109
r1fm+r2fm = 142.154

input #65 time: 0:08:18 | total time: 9:12:00


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.8349302101953446
highest_index [0]
highest [0.8349302101953446]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.8499196171760559 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.8253839015960693 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.816878080368042 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.7989100217819214 for ['[CLS] riot equal private peculiar [SEP]']
[Init] best rec loss: 0.7924756407737732 for ['[CLS] complied man ready panic [SEP]']
[Init] best rec loss: 0.7629902362823486 for ['[CLS] background leader screen [CLS] [SEP]']
[Init] best rec loss: 0.7517629265785217 for ['[CLS] helmet stared true deposit [SEP]']
[Init] best rec loss: 0.732999324798584 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best perm rec loss: 0.7319292426109314 for ['[CLS] juliet game shoulders scout [SEP]']
[Init] best perm rec loss: 0.7318247556686401 for ['[CLS] game shoulders scout juliet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.235 (perp=8.194, rec=0.298, cos=0.298), tot_loss_proj:2.608 [t=0.18s]
prediction: ['[CLS] fan traditional fan fan [SEP]']
[ 100/2000] tot_loss=2.832 (perp=12.000, rec=0.138, cos=0.294), tot_loss_proj:3.284 [t=0.17s]
prediction: ['[CLS] longtime medieval fan tolkien [SEP]']
[ 150/2000] tot_loss=2.390 (perp=9.916, rec=0.113, cos=0.294), tot_loss_proj:2.796 [t=0.22s]
prediction: ['[CLS] longtime tolkien fan tolkien [SEP]']
[ 200/2000] tot_loss=2.380 (perp=9.916, rec=0.103, cos=0.293), tot_loss_proj:2.796 [t=0.20s]
prediction: ['[CLS] longtime tolkien fan tolkien [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.150 (perp=8.772, rec=0.096, cos=0.300), tot_loss_proj:2.283 [t=0.22s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=2.145 (perp=8.772, rec=0.091, cos=0.300), tot_loss_proj:2.288 [t=0.19s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.140 (perp=8.772, rec=0.085, cos=0.300), tot_loss_proj:2.281 [t=0.18s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.141 (perp=8.772, rec=0.084, cos=0.302), tot_loss_proj:2.278 [t=0.26s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=2.115 (perp=8.772, rec=0.058, cos=0.302), tot_loss_proj:2.287 [t=0.22s]
prediction: ['[CLS] longtime longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.903 (perp=7.673, rec=0.066, cos=0.303), tot_loss_proj:1.910 [t=0.19s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.902 (perp=7.673, rec=0.064, cos=0.303), tot_loss_proj:1.905 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.907 (perp=7.673, rec=0.070, cos=0.303), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.896 (perp=7.673, rec=0.065, cos=0.296), tot_loss_proj:1.888 [t=0.19s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.897 (perp=7.673, rec=0.060, cos=0.302), tot_loss_proj:1.914 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.905 (perp=7.673, rec=0.068, cos=0.303), tot_loss_proj:1.901 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.902 (perp=7.673, rec=0.065, cos=0.303), tot_loss_proj:1.909 [t=0.19s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.899 (perp=7.673, rec=0.062, cos=0.303), tot_loss_proj:1.905 [t=0.19s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.895 (perp=7.673, rec=0.064, cos=0.296), tot_loss_proj:1.902 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.889 (perp=7.673, rec=0.053, cos=0.302), tot_loss_proj:1.912 [t=0.20s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.894 (perp=7.673, rec=0.057, cos=0.302), tot_loss_proj:1.914 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.899 (perp=7.673, rec=0.062, cos=0.302), tot_loss_proj:1.897 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.905 (perp=7.673, rec=0.068, cos=0.302), tot_loss_proj:1.917 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.889 (perp=7.673, rec=0.052, cos=0.303), tot_loss_proj:1.904 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.895 (perp=7.673, rec=0.058, cos=0.303), tot_loss_proj:1.892 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.880 (perp=7.673, rec=0.043, cos=0.303), tot_loss_proj:1.898 [t=0.20s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.903 (perp=7.673, rec=0.066, cos=0.303), tot_loss_proj:1.907 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.896 (perp=7.673, rec=0.059, cos=0.303), tot_loss_proj:1.905 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.894 (perp=7.673, rec=0.057, cos=0.303), tot_loss_proj:1.900 [t=0.21s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.909 (perp=7.673, rec=0.071, cos=0.303), tot_loss_proj:1.897 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.895 (perp=7.673, rec=0.058, cos=0.303), tot_loss_proj:1.908 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.895 (perp=7.673, rec=0.058, cos=0.303), tot_loss_proj:1.900 [t=0.23s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.897 (perp=7.673, rec=0.060, cos=0.303), tot_loss_proj:1.889 [t=0.24s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.905 (perp=7.673, rec=0.067, cos=0.303), tot_loss_proj:1.894 [t=0.25s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.891 (perp=7.673, rec=0.054, cos=0.303), tot_loss_proj:1.911 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.899 (perp=7.673, rec=0.062, cos=0.303), tot_loss_proj:1.903 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.895 (perp=7.673, rec=0.058, cos=0.303), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.891 (perp=7.673, rec=0.054, cos=0.303), tot_loss_proj:1.902 [t=0.20s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.906 (perp=7.673, rec=0.069, cos=0.303), tot_loss_proj:1.907 [t=0.27s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.893 (perp=7.673, rec=0.055, cos=0.303), tot_loss_proj:1.905 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.902 (perp=7.673, rec=0.064, cos=0.303), tot_loss_proj:1.902 [t=0.26s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.560 | p: 86.884 | r: 88.440
rouge2     | fm: 55.546 | p: 55.270 | r: 55.838
rougeL     | fm: 76.565 | p: 75.945 | r: 77.299
rougeLsum  | fm: 76.567 | p: 75.889 | r: 77.310
r1fm+r2fm = 143.106

input #66 time: 0:08:18 | total time: 9:20:18


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.7843536435646516
highest_index [0]
highest [0.7843536435646516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9515642523765564 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9215382933616638 for ['[CLS] acretis smiley moth toward ass rhine xbox piece rebranded [SEP]']
[Init] best rec loss: 0.9079187512397766 for ['[CLS] fastestedance ;eding buckingham jill ranges australia international property [SEP]']
[Init] best rec loss: 0.9075049161911011 for ['[CLS]tched forward bunk kinds virginiahiparians war ann scenery [SEP]']
[Init] best rec loss: 0.889735758304596 for ['[CLS] ×ator bears weight overturned um turning pay humanity glee [SEP]']
[Init] best rec loss: 0.882960855960846 for ['[CLS] carries garden deputy creation attitudes victim mine waitingapugh [SEP]']
[Init] best rec loss: 0.8803790807723999 for ['[CLS] holyvy war hingesozuche tessa ] commentary justice [SEP]']
[Init] best rec loss: 0.8764016032218933 for ['[CLS]ha twenty door cock school tierney inventorneer equal really [SEP]']
[Init] best perm rec loss: 0.8731927275657654 for ['[CLS] cock door inventor really equal tierneyneer twentyha school [SEP]']
[Init] best perm rec loss: 0.8720080256462097 for ['[CLS]neer twenty inventorha cock really equal school tierney door [SEP]']
[Init] best perm rec loss: 0.8681033849716187 for ['[CLS] school really equalha tierney cock twentyneer inventor door [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.296 (perp=12.992, rec=0.320, cos=0.378), tot_loss_proj:4.131 [t=0.25s]
prediction: ['[CLS] insight thomas unix heartjunt 2000 miles kind kind [SEP]']
[ 100/2000] tot_loss=3.326 (perp=13.609, rec=0.230, cos=0.374), tot_loss_proj:4.416 [t=0.27s]
prediction: ['[CLS] life ge wince heartjunming heartmirwar kind [SEP]']
[ 150/2000] tot_loss=3.519 (perp=14.853, rec=0.168, cos=0.380), tot_loss_proj:4.514 [t=0.18s]
prediction: ['[CLS] regiongmjuentalwarming heart nonwar kind [SEP]']
[ 200/2000] tot_loss=3.285 (perp=13.891, rec=0.128, cos=0.378), tot_loss_proj:4.263 [t=0.17s]
prediction: ['[CLS] regiongmgmentalwarming heart nonwar kind [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.808 (perp=11.609, rec=0.109, cos=0.377), tot_loss_proj:3.691 [t=0.23s]
prediction: ['[CLS] regiongmgmental heartwarming nonwar kind [SEP]']
[ 300/2000] tot_loss=2.836 (perp=11.787, rec=0.102, cos=0.377), tot_loss_proj:3.560 [t=0.27s]
prediction: ['[CLS]tarjugmental heartwarming nonwar kind [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.478 (perp=9.929, rec=0.109, cos=0.384), tot_loss_proj:3.344 [t=0.18s]
prediction: ['[CLS] kindxjugmental heartwarming nonwar [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.991 (perp=12.472, rec=0.124, cos=0.372), tot_loss_proj:4.003 [t=0.21s]
prediction: ['[CLS] kind rafaeljugmental heartdwarming non [SEP]']
[ 450/2000] tot_loss=2.602 (perp=10.636, rec=0.093, cos=0.381), tot_loss_proj:3.714 [t=0.18s]
prediction: ['[CLS] kindjojugmental heartdwarming non [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.434 (perp=9.780, rec=0.096, cos=0.382), tot_loss_proj:2.850 [t=0.23s]
prediction: ['[CLS] kind nonjugmental heartdwarming rafael [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.433 (perp=9.880, rec=0.074, cos=0.383), tot_loss_proj:2.918 [t=0.18s]
prediction: ['[CLS] kind nonjugmental heartdwarming bo [SEP]']
[ 600/2000] tot_loss=2.437 (perp=9.880, rec=0.078, cos=0.384), tot_loss_proj:2.923 [t=0.18s]
prediction: ['[CLS] kind nonjugmental heartdwarming bo [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.287 (perp=9.020, rec=0.098, cos=0.384), tot_loss_proj:2.817 [t=0.22s]
prediction: ['[CLS] kind nonjugmental heartwarming duod [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.259 (perp=8.869, rec=0.104, cos=0.381), tot_loss_proj:2.765 [t=0.18s]
prediction: ['[CLS] kind duo nonjugmental heartwarmingd [SEP]']
[ 750/2000] tot_loss=2.408 (perp=9.670, rec=0.090, cos=0.384), tot_loss_proj:2.863 [t=0.24s]
prediction: ['[CLS] kind bo nonjugmental heartwarmingd [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.231 (perp=8.779, rec=0.092, cos=0.383), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] kind non bojugmental heartwarmingd [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.226 (perp=8.779, rec=0.086, cos=0.385), tot_loss_proj:2.852 [t=0.22s]
prediction: ['[CLS] kind non bojugmental heartwarmingd [SEP]']
[ 900/2000] tot_loss=2.229 (perp=8.779, rec=0.089, cos=0.384), tot_loss_proj:2.849 [t=0.22s]
prediction: ['[CLS] kind non bojugmental heartwarmingd [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.246 (perp=8.935, rec=0.076, cos=0.383), tot_loss_proj:2.749 [t=0.18s]
prediction: ['[CLS] kind non boju,gmental heartwarming [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.157 (perp=8.445, rec=0.085, cos=0.383), tot_loss_proj:3.046 [t=0.21s]
prediction: ['[CLS] kind non, bojugmental heartwarming [SEP]']
[1050/2000] tot_loss=2.147 (perp=8.445, rec=0.074, cos=0.384), tot_loss_proj:3.048 [t=0.27s]
prediction: ['[CLS] kind non, bojugmental heartwarming [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.114 (perp=8.266, rec=0.077, cos=0.383), tot_loss_proj:2.634 [t=0.19s]
prediction: ['[CLS] kind, non bojugmental heartwarming [SEP]']
Attempt swap
[1150/2000] tot_loss=2.112 (perp=8.266, rec=0.075, cos=0.384), tot_loss_proj:2.639 [t=0.20s]
prediction: ['[CLS] kind, non bojugmental heartwarming [SEP]']
[1200/2000] tot_loss=2.102 (perp=8.266, rec=0.065, cos=0.384), tot_loss_proj:2.640 [t=0.21s]
prediction: ['[CLS] kind, non bojugmental heartwarming [SEP]']
Attempt swap
[1250/2000] tot_loss=2.111 (perp=8.266, rec=0.074, cos=0.384), tot_loss_proj:2.640 [t=0.21s]
prediction: ['[CLS] kind, non bojugmental heartwarming [SEP]']
Attempt swap
[1300/2000] tot_loss=2.106 (perp=8.266, rec=0.069, cos=0.384), tot_loss_proj:2.639 [t=0.20s]
prediction: ['[CLS] kind, non bojugmental heartwarming [SEP]']
[1350/2000] tot_loss=2.106 (perp=8.266, rec=0.068, cos=0.384), tot_loss_proj:2.636 [t=0.26s]
prediction: ['[CLS] kind, non bojugmental heartwarming [SEP]']
Attempt swap
[1400/2000] tot_loss=2.114 (perp=8.266, rec=0.076, cos=0.384), tot_loss_proj:2.633 [t=0.18s]
prediction: ['[CLS] kind, non bojugmental heartwarming [SEP]']
Attempt swap
[1450/2000] tot_loss=2.115 (perp=8.266, rec=0.077, cos=0.384), tot_loss_proj:2.636 [t=0.22s]
prediction: ['[CLS] kind, non bojugmental heartwarming [SEP]']
[1500/2000] tot_loss=2.101 (perp=8.266, rec=0.064, cos=0.384), tot_loss_proj:2.641 [t=0.24s]
prediction: ['[CLS] kind, non bojugmental heartwarming [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=2.006 (perp=7.753, rec=0.072, cos=0.384), tot_loss_proj:2.401 [t=0.24s]
prediction: ['[CLS] kind, boju nongmental heartwarming [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.837 (perp=6.826, rec=0.092, cos=0.380), tot_loss_proj:2.177 [t=0.22s]
prediction: ['[CLS] kind heartwarming, boju nongmental [SEP]']
[1650/2000] tot_loss=1.828 (perp=6.826, rec=0.081, cos=0.382), tot_loss_proj:2.174 [t=0.24s]
prediction: ['[CLS] kind heartwarming, boju nongmental [SEP]']
Attempt swap
[1700/2000] tot_loss=1.816 (perp=6.826, rec=0.068, cos=0.383), tot_loss_proj:2.168 [t=0.18s]
prediction: ['[CLS] kind heartwarming, boju nongmental [SEP]']
Attempt swap
[1750/2000] tot_loss=1.835 (perp=6.826, rec=0.086, cos=0.383), tot_loss_proj:2.165 [t=0.18s]
prediction: ['[CLS] kind heartwarming, boju nongmental [SEP]']
[1800/2000] tot_loss=1.830 (perp=6.826, rec=0.082, cos=0.383), tot_loss_proj:2.175 [t=0.18s]
prediction: ['[CLS] kind heartwarming, boju nongmental [SEP]']
Attempt swap
[1850/2000] tot_loss=1.816 (perp=6.826, rec=0.067, cos=0.383), tot_loss_proj:2.169 [t=0.21s]
prediction: ['[CLS] kind heartwarming, boju nongmental [SEP]']
Attempt swap
[1900/2000] tot_loss=1.827 (perp=6.826, rec=0.078, cos=0.383), tot_loss_proj:2.167 [t=0.23s]
prediction: ['[CLS] kind heartwarming, boju nongmental [SEP]']
[1950/2000] tot_loss=1.821 (perp=6.826, rec=0.073, cos=0.384), tot_loss_proj:2.173 [t=0.18s]
prediction: ['[CLS] kind heartwarming, boju nongmental [SEP]']
Attempt swap
[2000/2000] tot_loss=1.815 (perp=6.826, rec=0.066, cos=0.384), tot_loss_proj:2.171 [t=0.23s]
prediction: ['[CLS] kind heartwarming, boju nongmental [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind, non bojugmental heartwarming [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 66.667 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 54.545 | p: 50.000 | r: 60.000
rougeLsum  | fm: 54.545 | p: 50.000 | r: 60.000
r1fm+r2fm = 72.727

[Aggregate metrics]:
rouge1     | fm: 87.331 | p: 86.474 | r: 88.289
rouge2     | fm: 54.703 | p: 54.447 | r: 54.990
rougeL     | fm: 76.170 | p: 75.464 | r: 77.004
rougeLsum  | fm: 76.387 | p: 75.739 | r: 77.174
r1fm+r2fm = 142.034

input #67 time: 0:08:22 | total time: 9:28:40


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.8573263339678874
highest_index [0]
highest [0.8573263339678874]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9543940424919128 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9309527277946472 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 0.9276869893074036 for ['[CLS]pped raise marx driving claims steadily racial shame hispanic big under charlie sinks [SEP]']
[Init] best rec loss: 0.9121645092964172 for ['[CLS] feelings stole besides spoil bit prone decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 0.8837428689002991 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8737341165542603 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8714150190353394 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8687123656272888 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8681460618972778 for ['[CLS]yn ridingiferous beth. councils medal comfort view form possibly died floor [SEP]']
[Init] best perm rec loss: 0.8659218549728394 for ['[CLS] beth died comfort possiblyiferous councils. ridingyn form medal view floor [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.889 (perp=11.723, rec=0.282, cos=0.262), tot_loss_proj:3.244 [t=0.18s]
prediction: ['[CLS] absurd complex inspired ( an absurd absurd conditions during car fey linnaeus badly [SEP]']
[ 100/2000] tot_loss=2.556 (perp=10.538, rec=0.192, cos=0.257), tot_loss_proj:2.977 [t=0.18s]
prediction: ['[CLS] vicious problem absurd (, absurd absurd conditions caused and viciousity badly [SEP]']
[ 150/2000] tot_loss=2.889 (perp=12.367, rec=0.160, cos=0.255), tot_loss_proj:3.303 [t=0.18s]
prediction: ['[CLS] viciousful absurd un, absurd absurdco caused and viciousity vicious [SEP]']
[ 200/2000] tot_loss=2.808 (perp=12.036, rec=0.146, cos=0.255), tot_loss_proj:3.462 [t=0.18s]
prediction: ['[CLS] viciousfuluth un, vicious absurdco scalp and viciousity vicious [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.246 (perp=9.251, rec=0.142, cos=0.253), tot_loss_proj:2.949 [t=0.26s]
prediction: ['[CLS] uncouth vicious, vicious absurdco ind and viciousity vicious [SEP]']
[ 300/2000] tot_loss=2.225 (perp=9.195, rec=0.126, cos=0.260), tot_loss_proj:2.925 [t=0.19s]
prediction: ['[CLS] uncouth vicious, vicious absurdco ind and vicioussible vicious [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.232 (perp=9.316, rec=0.113, cos=0.255), tot_loss_proj:2.962 [t=0.18s]
prediction: ['[CLS] unomputh vicious, vicious absurdco inded and vicious vicious [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.162 (perp=8.878, rec=0.136, cos=0.251), tot_loss_proj:2.816 [t=0.21s]
prediction: ['[CLS] unomputhed, vicious absurdco ind vicious and vicious vicious [SEP]']
[ 450/2000] tot_loss=2.144 (perp=8.878, rec=0.112, cos=0.257), tot_loss_proj:2.807 [t=0.18s]
prediction: ['[CLS] unomputhed, vicious absurdco ind vicious and vicious vicious [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.046 (perp=8.409, rec=0.104, cos=0.260), tot_loss_proj:2.722 [t=0.28s]
prediction: ['[CLS] unomputhed, vicious viciousco ind absurd and vicious vicious [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.171 (perp=9.031, rec=0.104, cos=0.261), tot_loss_proj:2.737 [t=0.21s]
prediction: ['[CLS] unomputhsible, vicious viciousco ind absurd and vicious vicious [SEP]']
[ 600/2000] tot_loss=2.327 (perp=9.890, rec=0.088, cos=0.261), tot_loss_proj:2.859 [t=0.19s]
prediction: ['[CLS] unomputhsible, vicious viciousco ind absurd and vicious heavily [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.203 (perp=9.277, rec=0.087, cos=0.260), tot_loss_proj:2.652 [t=0.18s]
prediction: ['[CLS] unomputhsible, vicious viciousco ind absurd and heavily vicious [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.148 (perp=8.930, rec=0.107, cos=0.255), tot_loss_proj:2.538 [t=0.18s]
prediction: ['[CLS] uncouthsible, vicious viciousomp ind absurd and heavily vicious [SEP]']
[ 750/2000] tot_loss=2.136 (perp=8.930, rec=0.090, cos=0.260), tot_loss_proj:2.537 [t=0.18s]
prediction: ['[CLS] uncouthsible, vicious viciousomp ind absurd and heavily vicious [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.110 (perp=8.786, rec=0.093, cos=0.260), tot_loss_proj:2.535 [t=0.18s]
prediction: ['[CLS] uncouthsible, vicious viciousomp heavily absurd and ind vicious [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.109 (perp=8.786, rec=0.090, cos=0.261), tot_loss_proj:2.529 [t=0.18s]
prediction: ['[CLS] uncouthsible, vicious viciousomp heavily absurd and ind vicious [SEP]']
[ 900/2000] tot_loss=2.104 (perp=8.786, rec=0.086, cos=0.261), tot_loss_proj:2.522 [t=0.18s]
prediction: ['[CLS] uncouthsible, vicious viciousomp heavily absurd and ind vicious [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.113 (perp=8.786, rec=0.095, cos=0.261), tot_loss_proj:2.530 [t=0.24s]
prediction: ['[CLS] uncouthsible, vicious viciousomp heavily absurd and ind vicious [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.077 (perp=8.626, rec=0.089, cos=0.263), tot_loss_proj:2.688 [t=0.23s]
prediction: ['[CLS]sible uncouth, vicious viciousomp heavily absurd and ind vicious [SEP]']
[1050/2000] tot_loss=2.077 (perp=8.626, rec=0.091, cos=0.261), tot_loss_proj:2.694 [t=0.24s]
prediction: ['[CLS]sible uncouth, vicious viciousomp heavily absurd and ind vicious [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.041 (perp=8.415, rec=0.097, cos=0.261), tot_loss_proj:2.661 [t=0.25s]
prediction: ['[CLS]sible uncouth, vicious indomp heavily absurd and vicious vicious [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.015 (perp=8.347, rec=0.086, cos=0.260), tot_loss_proj:2.640 [t=0.26s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
[1200/2000] tot_loss=2.020 (perp=8.347, rec=0.091, cos=0.260), tot_loss_proj:2.647 [t=0.18s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
[1250/2000] tot_loss=2.022 (perp=8.347, rec=0.092, cos=0.260), tot_loss_proj:2.645 [t=0.23s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
[1300/2000] tot_loss=2.008 (perp=8.347, rec=0.078, cos=0.260), tot_loss_proj:2.643 [t=0.19s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
[1350/2000] tot_loss=2.032 (perp=8.347, rec=0.102, cos=0.261), tot_loss_proj:2.635 [t=0.24s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
[1400/2000] tot_loss=2.028 (perp=8.347, rec=0.098, cos=0.261), tot_loss_proj:2.639 [t=0.29s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
[1450/2000] tot_loss=2.008 (perp=8.347, rec=0.078, cos=0.261), tot_loss_proj:2.644 [t=0.26s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
[1500/2000] tot_loss=2.013 (perp=8.347, rec=0.083, cos=0.261), tot_loss_proj:2.648 [t=0.18s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
[1550/2000] tot_loss=2.005 (perp=8.347, rec=0.075, cos=0.261), tot_loss_proj:2.643 [t=0.20s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
[1600/2000] tot_loss=2.024 (perp=8.347, rec=0.094, cos=0.261), tot_loss_proj:2.637 [t=0.18s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
[1650/2000] tot_loss=2.019 (perp=8.347, rec=0.089, cos=0.261), tot_loss_proj:2.654 [t=0.22s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.023 (perp=8.347, rec=0.092, cos=0.261), tot_loss_proj:2.642 [t=0.22s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
[1750/2000] tot_loss=2.016 (perp=8.347, rec=0.086, cos=0.261), tot_loss_proj:2.650 [t=0.22s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
[1800/2000] tot_loss=2.027 (perp=8.347, rec=0.096, cos=0.261), tot_loss_proj:2.643 [t=0.24s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
[1850/2000] tot_loss=2.017 (perp=8.347, rec=0.087, cos=0.261), tot_loss_proj:2.647 [t=0.26s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
[1900/2000] tot_loss=2.009 (perp=8.347, rec=0.079, cos=0.261), tot_loss_proj:2.641 [t=0.25s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
[1950/2000] tot_loss=2.016 (perp=8.347, rec=0.086, cos=0.261), tot_loss_proj:2.645 [t=0.18s]
prediction: ['[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]']
Attempt swap
[2000/2000] tot_loss=2.134 (perp=8.939, rec=0.085, cos=0.261), tot_loss_proj:2.749 [t=0.17s]
prediction: ['[CLS]sible uncouth, heavilyompomp vicious absurd and vicious vicious [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS]sible uncouth, heavily indomp vicious absurd and vicious vicious [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 54.545 | r: 85.714
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 55.556 | p: 45.455 | r: 71.429
rougeLsum  | fm: 55.556 | p: 45.455 | r: 71.429
r1fm+r2fm = 66.667

[Aggregate metrics]:
rouge1     | fm: 87.099 | p: 86.113 | r: 88.321
rouge2     | fm: 53.881 | p: 53.634 | r: 54.139
rougeL     | fm: 75.806 | p: 75.041 | r: 76.872
rougeLsum  | fm: 75.955 | p: 75.163 | r: 76.992
r1fm+r2fm = 140.980

input #68 time: 0:08:30 | total time: 9:37:11


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.8093930898577064
highest_index [0]
highest [0.8093930898577064]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 0.9790974259376526 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9783031344413757 for ['[CLS] new nod none left bryson gainering state chris pay league teams dea set during store [SEP]']
[Init] best rec loss: 0.9761864542961121 for ['[CLS] later dressed creed among label effect pickering servants duc evergreen along [CLS] court afar trey bombay [SEP]']
[Init] best rec loss: 0.9676231145858765 for ['[CLS]aver grandson cleared sergei spare reserve / earthquake mouse loudly student celebrated pill till le tunnel [SEP]']
[Init] best rec loss: 0.9418244957923889 for ['[CLS] closelein am ( deadrga liz range bragg depended states passes stock past messll [SEP]']
[Init] best perm rec loss: 0.939479649066925 for ['[CLS] stock depended bragg am states messll past close rangerga ( liz passes deadlein [SEP]']
[Init] best perm rec loss: 0.9384401440620422 for ['[CLS] depended am range states (ll stock dead messlein past liz bragg passes closerga [SEP]']
[Init] best perm rec loss: 0.9378985166549683 for ['[CLS]rga range am passesll bragg close dependedlein past states liz ( dead stock mess [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.586 (perp=12.991, rec=0.695, cos=0.293), tot_loss_proj:4.169 [t=0.24s]
prediction: ['[CLS]llishow edited democraticle israel fire instant communists 3 tons - [ deep p lame [SEP]']
[ 100/2000] tot_loss=3.208 (perp=11.355, rec=0.602, cos=0.335), tot_loss_proj:4.080 [t=0.18s]
prediction: ['[CLS]harat and player martinau israel fire slightest loving / very - - deep p lame [SEP]']
[ 150/2000] tot_loss=3.589 (perp=13.490, rec=0.570, cos=0.321), tot_loss_proj:4.510 [t=0.22s]
prediction: ['[CLS]harat and beat aheadle israel expensesany loving / quite, - deep ga lame [SEP]']
[ 200/2000] tot_loss=3.302 (perp=12.520, rec=0.551, cos=0.247), tot_loss_proj:4.153 [t=0.28s]
prediction: ['[CLS]harat andhit aheads israel expenses ª wiener / very, -how - lame [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.020 (perp=11.181, rec=0.525, cos=0.258), tot_loss_proj:3.958 [t=0.25s]
prediction: ['[CLS]harat and - radiation - plural expenses aheadnt / very, -how - minor [SEP]']
[ 300/2000] tot_loss=2.624 (perp=9.808, rec=0.501, cos=0.162), tot_loss_proj:3.829 [t=0.20s]
prediction: ['[CLS]dabley -. - napoleon expenses aheadnt, very, -how - minor [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.715 (perp=9.669, rec=0.505, cos=0.277), tot_loss_proj:3.920 [t=0.22s]
prediction: ['[CLS]harat and smart _, - well aheadnt - very. - - criteria short [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.973 (perp=10.238, rec=0.652, cos=0.274), tot_loss_proj:3.667 [t=0.19s]
prediction: ['[CLS]nt nothing -. - and expenses wastednt - very relegatedzic - - criteria [SEP]']
[ 450/2000] tot_loss=2.650 (perp=9.630, rec=0.512, cos=0.212), tot_loss_proj:3.891 [t=0.19s]
prediction: ['[CLS] sincere bad -. - ; well winnernt, very subtlezic - - crimes [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.383 (perp=8.461, rec=0.528, cos=0.163), tot_loss_proj:3.575 [t=0.24s]
prediction: ['[CLS] sincere bad. -, ; well winnernt - very subtle, - - ₁ [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.427 (perp=8.148, rec=0.468, cos=0.330), tot_loss_proj:3.508 [t=0.18s]
prediction: ['[CLS] sincere bad. - - ; strength, winnernt - very ; - -leader [SEP]']
[ 600/2000] tot_loss=2.180 (perp=7.736, rec=0.471, cos=0.161), tot_loss_proj:2.989 [t=0.22s]
prediction: ['[CLS] sincere and. -, ; well, winnernt - very ; - - duly [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.514 (perp=8.308, rec=0.554, cos=0.299), tot_loss_proj:3.609 [t=0.22s]
prediction: ['[CLS]nt bad. - - - strength, winnernt / very? -nt duly [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.049 (perp=6.904, rec=0.454, cos=0.214), tot_loss_proj:2.757 [t=0.19s]
prediction: ['[CLS] honest. ; -, and strength, winnernt, very ; - - criteria [SEP]']
[ 750/2000] tot_loss=2.237 (perp=8.074, rec=0.489, cos=0.133), tot_loss_proj:3.192 [t=0.25s]
prediction: ['[CLS]nt. - - - bad strength, winnernt / very? -um criteria [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.140 (perp=7.449, rec=0.444, cos=0.206), tot_loss_proj:3.492 [t=0.27s]
prediction: ['[CLS] honest. - - - bad -, winnernt, very? - strength requirements [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.088 (perp=6.850, rec=0.498, cos=0.221), tot_loss_proj:3.221 [t=0.19s]
prediction: ['[CLS]nt. - - - and strength, winnernt, very ; - - requirements [SEP]']
[ 900/2000] tot_loss=2.151 (perp=7.730, rec=0.432, cos=0.174), tot_loss_proj:3.071 [t=0.19s]
prediction: ['[CLS]nt. - - - funny strength, winnernt, very ; - - criteria [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.334 (perp=7.866, rec=0.422, cos=0.339), tot_loss_proj:3.206 [t=0.23s]
prediction: ['[CLS]nt. - - - funny strength, winnernt, very ; - - requirements [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.909 (perp=6.677, rec=0.436, cos=0.137), tot_loss_proj:3.050 [t=0.18s]
prediction: ['[CLS]nt winner. - - - and strength,nt, very ; - - requirements [SEP]']
[1050/2000] tot_loss=2.240 (perp=7.876, rec=0.427, cos=0.238), tot_loss_proj:3.090 [t=0.19s]
prediction: ['[CLS]nt winner. - - - funny strength,nt, very ;. - requirements [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.292 (perp=7.694, rec=0.414, cos=0.340), tot_loss_proj:2.968 [t=0.19s]
prediction: ['[CLS]nt funny. - - - winner strength,nt, very ;. - requirements [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.167 (perp=7.908, rec=0.426, cos=0.159), tot_loss_proj:3.175 [t=0.19s]
prediction: ['[CLS]nt funny strength - - - winner.,nt, very ; - - requirements [SEP]']
[1200/2000] tot_loss=2.100 (perp=7.185, rec=0.413, cos=0.250), tot_loss_proj:2.761 [t=0.29s]
prediction: ['[CLS]nt funny strength - - - winner.,nt, very ; - - - [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.048 (perp=6.907, rec=0.449, cos=0.218), tot_loss_proj:2.880 [t=0.27s]
prediction: ['[CLS]nt short strength - - - winner.,nt, very funny - - - [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.899 (perp=6.496, rec=0.417, cos=0.183), tot_loss_proj:2.876 [t=0.18s]
prediction: ['[CLS]nt short - strength - - winner.,nt, very funny - - - [SEP]']
[1350/2000] tot_loss=1.990 (perp=6.496, rec=0.411, cos=0.280), tot_loss_proj:2.878 [t=0.19s]
prediction: ['[CLS]nt short - strength - - winner.,nt, very funny - - - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.949 (perp=6.496, rec=0.426, cos=0.224), tot_loss_proj:2.873 [t=0.19s]
prediction: ['[CLS]nt short - strength - - winner.,nt, very funny - - - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.934 (perp=6.456, rec=0.406, cos=0.237), tot_loss_proj:2.867 [t=0.18s]
prediction: ['[CLS]nt short - strength - - winner.,nt, very funny. - - [SEP]']
[1500/2000] tot_loss=2.107 (perp=6.888, rec=0.406, cos=0.323), tot_loss_proj:3.025 [t=0.22s]
prediction: ['[CLS]nt short - strength - - winner.,nt, very funny. -be [SEP]']
Attempt swap
[1550/2000] tot_loss=1.886 (perp=6.456, rec=0.400, cos=0.195), tot_loss_proj:2.866 [t=0.29s]
prediction: ['[CLS]nt short - strength - - winner.,nt, very funny. - - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.972 (perp=6.456, rec=0.399, cos=0.283), tot_loss_proj:2.866 [t=0.22s]
prediction: ['[CLS]nt short - strength - - winner.,nt, very funny. - - [SEP]']
[1650/2000] tot_loss=1.976 (perp=6.456, rec=0.398, cos=0.286), tot_loss_proj:2.869 [t=0.23s]
prediction: ['[CLS]nt short - strength - - winner.,nt, very funny. - - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.947 (perp=6.456, rec=0.395, cos=0.261), tot_loss_proj:2.864 [t=0.23s]
prediction: ['[CLS]nt short - strength - - winner.,nt, very funny. - - [SEP]']
Attempt swap
[1750/2000] tot_loss=2.119 (perp=7.001, rec=0.394, cos=0.324), tot_loss_proj:2.931 [t=0.21s]
prediction: ['[CLS]felt short - strength - - winner.,nt, very funny. - - [SEP]']
[1800/2000] tot_loss=2.032 (perp=7.001, rec=0.403, cos=0.228), tot_loss_proj:2.927 [t=0.29s]
prediction: ['[CLS]felt short - strength - - winner.,nt, very funny. - - [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.048 (perp=6.784, rec=0.399, cos=0.292), tot_loss_proj:2.737 [t=0.19s]
prediction: ['[CLS]felt strength - short - - winner.,nt, very funny. - - [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.961 (perp=6.650, rec=0.407, cos=0.224), tot_loss_proj:2.621 [t=0.29s]
prediction: ['[CLS]felt strength - - short - winner.,nt, very funny. - - [SEP]']
[1950/2000] tot_loss=2.013 (perp=6.650, rec=0.402, cos=0.281), tot_loss_proj:2.621 [t=0.25s]
prediction: ['[CLS]felt strength - - short - winner.,nt, very funny. - - [SEP]']
Attempt swap
[2000/2000] tot_loss=2.051 (perp=6.650, rec=0.403, cos=0.318), tot_loss_proj:2.615 [t=0.25s]
prediction: ['[CLS]felt strength - - short - winner.,nt, very funny. - - [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS]felt strength - - short - winner.,nt, very funny. - - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 42.105 | p: 44.444 | r: 40.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 42.105 | p: 44.444 | r: 40.000
rougeLsum  | fm: 42.105 | p: 44.444 | r: 40.000
r1fm+r2fm = 42.105

[Aggregate metrics]:
rouge1     | fm: 86.417 | p: 85.459 | r: 87.560
rouge2     | fm: 53.059 | p: 52.836 | r: 53.359
rougeL     | fm: 75.368 | p: 74.629 | r: 76.391
rougeLsum  | fm: 75.529 | p: 74.750 | r: 76.552
r1fm+r2fm = 139.475

input #69 time: 0:08:20 | total time: 9:45:32


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9341576514889163
highest_index [0]
highest [0.9341576514889163]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.7990981936454773 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.7653912901878357 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7451239824295044 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7324013113975525 for ['[CLS] ga characteristic jump make deaths composed ⟩ [SEP]']
[Init] best rec loss: 0.7097718119621277 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 0.6887757182121277 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 0.6858829259872437 for ['[CLS] modern bobbution guy ি muscle party [SEP]']
[Init] best perm rec loss: 0.6847839951515198 for ['[CLS] িbution guy party muscle modern bob [SEP]']
[Init] best perm rec loss: 0.6819984316825867 for ['[CLS] muscle িbution party guy modern bob [SEP]']
[Init] best perm rec loss: 0.6818420886993408 for ['[CLS] ি musclebution party guy modern bob [SEP]']
[Init] best perm rec loss: 0.6812652945518494 for ['[CLS] bob musclebution guy party modern ি [SEP]']
[Init] best perm rec loss: 0.6800503134727478 for ['[CLS] guy bob ি party modernbution muscle [SEP]']
[Init] best perm rec loss: 0.6788069605827332 for ['[CLS]bution bob ি muscle modern guy party [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.120 (perp=12.987, rec=0.402, cos=0.121), tot_loss_proj:3.813 [t=0.18s]
prediction: ['[CLS] or infected sometimes czech cl crush controversy [SEP]']
[ 100/2000] tot_loss=2.066 (perp=8.459, rec=0.273, cos=0.101), tot_loss_proj:2.314 [t=0.19s]
prediction: ['[CLS] onunk sometimes get clunky [SEP]']
[ 150/2000] tot_loss=1.666 (perp=6.899, rec=0.165, cos=0.121), tot_loss_proj:1.998 [t=0.18s]
prediction: ['[CLS] clunk sometimes gets clunky [SEP]']
[ 200/2000] tot_loss=2.328 (perp=10.338, rec=0.134, cos=0.126), tot_loss_proj:2.991 [t=0.18s]
prediction: ['[CLS] clunkunk gets clunk screen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.430 (perp=10.930, rec=0.133, cos=0.112), tot_loss_proj:2.942 [t=0.18s]
prediction: ['[CLS] clunk appearing gets screenunky [SEP]']
[ 300/2000] tot_loss=2.295 (perp=10.348, rec=0.103, cos=0.123), tot_loss_proj:2.842 [t=0.26s]
prediction: ['[CLS] clunk the gets screenunky [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.871 (perp=8.345, rec=0.082, cos=0.120), tot_loss_proj:2.595 [t=0.20s]
prediction: ['[CLS] clunk gets on screenunky [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.867 (perp=8.345, rec=0.075, cos=0.123), tot_loss_proj:2.597 [t=0.23s]
prediction: ['[CLS] clunk gets on screenunky [SEP]']
[ 450/2000] tot_loss=1.864 (perp=8.345, rec=0.071, cos=0.124), tot_loss_proj:2.592 [t=0.29s]
prediction: ['[CLS] clunk gets on screenunky [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.864 (perp=8.345, rec=0.071, cos=0.124), tot_loss_proj:2.587 [t=0.27s]
prediction: ['[CLS] clunk gets on screenunky [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.864 (perp=8.345, rec=0.070, cos=0.124), tot_loss_proj:2.594 [t=0.28s]
prediction: ['[CLS] clunk gets on screenunky [SEP]']
[ 600/2000] tot_loss=1.862 (perp=8.345, rec=0.069, cos=0.124), tot_loss_proj:2.587 [t=0.27s]
prediction: ['[CLS] clunk gets on screenunky [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.862 (perp=8.345, rec=0.068, cos=0.125), tot_loss_proj:2.588 [t=0.27s]
prediction: ['[CLS] clunk gets on screenunky [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.909 (perp=8.572, rec=0.070, cos=0.125), tot_loss_proj:2.725 [t=0.18s]
prediction: ['[CLS] cl their gets on screenunky [SEP]']
[ 750/2000] tot_loss=1.912 (perp=8.572, rec=0.073, cos=0.125), tot_loss_proj:2.720 [t=0.20s]
prediction: ['[CLS] cl their gets on screenunky [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.751 (perp=7.792, rec=0.075, cos=0.118), tot_loss_proj:2.130 [t=0.18s]
prediction: ['[CLS] screen their gets on clunky [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.635 (perp=7.240, rec=0.066, cos=0.120), tot_loss_proj:2.032 [t=0.22s]
prediction: ['[CLS] their screen gets on clunky [SEP]']
[ 900/2000] tot_loss=1.639 (perp=7.240, rec=0.070, cos=0.121), tot_loss_proj:2.024 [t=0.22s]
prediction: ['[CLS] their screen gets on clunky [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.549 (perp=6.811, rec=0.066, cos=0.120), tot_loss_proj:2.184 [t=0.18s]
prediction: ['[CLS] gets their screen on clunky [SEP]']
Attempt swap
[1000/2000] tot_loss=1.471 (perp=6.358, rec=0.078, cos=0.122), tot_loss_proj:2.120 [t=0.23s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1050/2000] tot_loss=1.468 (perp=6.358, rec=0.073, cos=0.123), tot_loss_proj:2.129 [t=0.18s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1100/2000] tot_loss=1.461 (perp=6.358, rec=0.065, cos=0.124), tot_loss_proj:2.130 [t=0.18s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1150/2000] tot_loss=1.453 (perp=6.358, rec=0.057, cos=0.125), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1200/2000] tot_loss=1.457 (perp=6.358, rec=0.060, cos=0.126), tot_loss_proj:2.130 [t=0.18s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1250/2000] tot_loss=1.469 (perp=6.358, rec=0.071, cos=0.126), tot_loss_proj:2.122 [t=0.22s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1300/2000] tot_loss=1.467 (perp=6.358, rec=0.069, cos=0.126), tot_loss_proj:2.129 [t=0.22s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1350/2000] tot_loss=1.471 (perp=6.358, rec=0.073, cos=0.127), tot_loss_proj:2.129 [t=0.29s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1400/2000] tot_loss=1.466 (perp=6.358, rec=0.067, cos=0.127), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1450/2000] tot_loss=1.461 (perp=6.358, rec=0.063, cos=0.127), tot_loss_proj:2.123 [t=0.18s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1500/2000] tot_loss=1.476 (perp=6.358, rec=0.078, cos=0.127), tot_loss_proj:2.120 [t=0.19s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1550/2000] tot_loss=1.469 (perp=6.358, rec=0.071, cos=0.127), tot_loss_proj:2.122 [t=0.19s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1600/2000] tot_loss=1.467 (perp=6.358, rec=0.069, cos=0.127), tot_loss_proj:2.128 [t=0.21s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1650/2000] tot_loss=1.464 (perp=6.358, rec=0.066, cos=0.127), tot_loss_proj:2.124 [t=0.23s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1700/2000] tot_loss=1.470 (perp=6.358, rec=0.072, cos=0.127), tot_loss_proj:2.129 [t=0.18s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1750/2000] tot_loss=1.472 (perp=6.358, rec=0.073, cos=0.127), tot_loss_proj:2.128 [t=0.18s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1800/2000] tot_loss=1.455 (perp=6.358, rec=0.056, cos=0.127), tot_loss_proj:2.133 [t=0.18s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1850/2000] tot_loss=1.459 (perp=6.358, rec=0.060, cos=0.127), tot_loss_proj:2.131 [t=0.24s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[1900/2000] tot_loss=1.482 (perp=6.358, rec=0.083, cos=0.127), tot_loss_proj:2.128 [t=0.25s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
[1950/2000] tot_loss=1.458 (perp=6.358, rec=0.059, cos=0.127), tot_loss_proj:2.127 [t=0.26s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Attempt swap
[2000/2000] tot_loss=1.460 (perp=6.358, rec=0.062, cos=0.127), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] gets the screen on clunky [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] gets the screen on clunky [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 86.586 | p: 85.713 | r: 87.724
rouge2     | fm: 52.603 | p: 52.389 | r: 52.827
rougeL     | fm: 75.423 | p: 74.598 | r: 76.384
rougeLsum  | fm: 75.372 | p: 74.590 | r: 76.365
r1fm+r2fm = 139.189

input #70 time: 0:08:27 | total time: 9:53:59


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.8878184760073696
highest_index [0]
highest [0.8878184760073696]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8910817503929138 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.8902387619018555 for ['[CLS]kledclaiming solid due tear stakesaint flight ken keel receiver living duval us tottenham [SEP]']
[Init] best rec loss: 0.8793323040008545 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.8775095343589783 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 0.8654791116714478 for ['[CLS] composed warsselle ty urbantist empireneas amendment broadbandcat murdereo money appoint [SEP]']
[Init] best rec loss: 0.8459376096725464 for ['[CLS]ine runways oregon bored : towardsgold occurred snow abovegerstypical definitely holiday rooney [SEP]']
[Init] best rec loss: 0.8451354503631592 for ['[CLS] jean bed queens fewer of professor fall ram surhear marshall over liam molly creatures [SEP]']
[Init] best perm rec loss: 0.8429803848266602 for ['[CLS] fewer marshallhear sur bed queens ram molly creatures professor jean over fall of liam [SEP]']
[Init] best perm rec loss: 0.841954231262207 for ['[CLS]hear fewer ram over molly sur bed creatures professor liam queens fall of marshall jean [SEP]']
[Init] best perm rec loss: 0.8416895270347595 for ['[CLS] creatures over liamhear fall sur bed fewer of marshall jean queens molly professor ram [SEP]']
[Init] best perm rec loss: 0.8400738835334778 for ['[CLS] of over fall marshall professor creatures bed ramhear fewer jean liam queens molly sur [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.716 (perp=10.836, rec=0.354, cos=0.194), tot_loss_proj:3.555 [t=0.18s]
prediction: ['[CLS] considered under sovereign track t getting in few got truly a moment ten moment than [SEP]']
[ 100/2000] tot_loss=2.617 (perp=10.749, rec=0.268, cos=0.199), tot_loss_proj:3.188 [t=0.19s]
prediction: ['[CLS] stupid nully seat not a a not your single no moment exchanges moment moment [SEP]']
[ 150/2000] tot_loss=2.269 (perp=9.349, rec=0.198, cos=0.202), tot_loss_proj:2.931 [t=0.30s]
prediction: ['[CLS] - single - seat not a a not your single jump moment moment jump moment [SEP]']
[ 200/2000] tot_loss=2.257 (perp=9.349, rec=0.176, cos=0.211), tot_loss_proj:2.938 [t=0.28s]
prediction: ['[CLS] - single - seat not a a not your single jump moment moment jump moment [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.962 (perp=8.097, rec=0.140, cos=0.204), tot_loss_proj:2.988 [t=0.37s]
prediction: ['[CLS] - in your seat not there a not - single jump moment moment jump moment [SEP]']
[ 300/2000] tot_loss=1.659 (perp=6.718, rec=0.105, cos=0.210), tot_loss_proj:2.577 [t=0.18s]
prediction: ['[CLS] and in your seat not there a - - single jump moment - - moment [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.481 (perp=5.904, rec=0.096, cos=0.205), tot_loss_proj:2.730 [t=0.19s]
prediction: ['[CLS] and in your seat not there a moment - single jump - - - moment [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.468 (perp=5.904, rec=0.090, cos=0.197), tot_loss_proj:2.719 [t=0.24s]
prediction: ['[CLS] and in your seat not there a moment - single jump - - - moment [SEP]']
[ 450/2000] tot_loss=1.547 (perp=6.347, rec=0.083, cos=0.195), tot_loss_proj:2.811 [t=0.24s]
prediction: ['[CLS] and in your seat not there a moment - single jump - a - moment [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.557 (perp=6.335, rec=0.080, cos=0.211), tot_loss_proj:2.552 [t=0.25s]
prediction: ['[CLS] and in your seat not there a - - single jump - a moment - [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.495 (perp=6.083, rec=0.068, cos=0.211), tot_loss_proj:2.562 [t=0.18s]
prediction: ['[CLS] and in your seat not a there - - single jump - a moment - [SEP]']
[ 600/2000] tot_loss=1.488 (perp=6.083, rec=0.072, cos=0.200), tot_loss_proj:2.563 [t=0.21s]
prediction: ['[CLS] and in your seat not a there - - single jump - a moment - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.506 (perp=6.083, rec=0.079, cos=0.211), tot_loss_proj:2.561 [t=0.18s]
prediction: ['[CLS] and in your seat not a there - - single jump - a moment - [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.488 (perp=5.987, rec=0.084, cos=0.207), tot_loss_proj:2.694 [t=0.18s]
prediction: ['[CLS] and in your seat a not there - - single jump - a moment - [SEP]']
[ 750/2000] tot_loss=1.477 (perp=5.987, rec=0.069, cos=0.211), tot_loss_proj:2.700 [t=0.19s]
prediction: ['[CLS] and in your seat a not there - - single jump - a moment - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.587 (perp=6.477, rec=0.083, cos=0.208), tot_loss_proj:2.924 [t=0.24s]
prediction: ['[CLS] and in your seat a not there - - single jump - is moment - [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.532 (perp=6.301, rec=0.070, cos=0.202), tot_loss_proj:2.691 [t=0.19s]
prediction: ['[CLS] and in your seat a not there - - single jump - - moment is [SEP]']
[ 900/2000] tot_loss=1.545 (perp=6.301, rec=0.075, cos=0.210), tot_loss_proj:2.693 [t=0.20s]
prediction: ['[CLS] and in your seat a not there - - single jump - - moment is [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.524 (perp=6.182, rec=0.076, cos=0.211), tot_loss_proj:2.750 [t=0.19s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
[1000/2000] tot_loss=1.523 (perp=6.182, rec=0.078, cos=0.208), tot_loss_proj:2.748 [t=0.18s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
[1050/2000] tot_loss=1.523 (perp=6.182, rec=0.076, cos=0.211), tot_loss_proj:2.752 [t=0.22s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
[1100/2000] tot_loss=1.516 (perp=6.182, rec=0.079, cos=0.201), tot_loss_proj:2.744 [t=0.22s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
[1150/2000] tot_loss=1.518 (perp=6.182, rec=0.072, cos=0.209), tot_loss_proj:2.756 [t=0.23s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
[1200/2000] tot_loss=1.513 (perp=6.182, rec=0.066, cos=0.211), tot_loss_proj:2.751 [t=0.20s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
[1250/2000] tot_loss=1.526 (perp=6.182, rec=0.078, cos=0.211), tot_loss_proj:2.748 [t=0.18s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.507 (perp=6.182, rec=0.069, cos=0.202), tot_loss_proj:2.739 [t=0.18s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
[1350/2000] tot_loss=1.514 (perp=6.182, rec=0.070, cos=0.207), tot_loss_proj:2.734 [t=0.23s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.519 (perp=6.182, rec=0.073, cos=0.209), tot_loss_proj:2.739 [t=0.23s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
[1450/2000] tot_loss=1.522 (perp=6.182, rec=0.075, cos=0.210), tot_loss_proj:2.738 [t=0.19s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
[1500/2000] tot_loss=1.515 (perp=6.182, rec=0.068, cos=0.211), tot_loss_proj:2.737 [t=0.19s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.518 (perp=6.182, rec=0.073, cos=0.208), tot_loss_proj:2.758 [t=0.18s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.518 (perp=6.182, rec=0.071, cos=0.211), tot_loss_proj:2.762 [t=0.18s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
[1650/2000] tot_loss=1.522 (perp=6.182, rec=0.075, cos=0.211), tot_loss_proj:2.762 [t=0.19s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
[1700/2000] tot_loss=1.515 (perp=6.182, rec=0.067, cos=0.211), tot_loss_proj:2.766 [t=0.21s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
[1750/2000] tot_loss=1.513 (perp=6.182, rec=0.069, cos=0.207), tot_loss_proj:2.766 [t=0.19s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
[1800/2000] tot_loss=1.524 (perp=6.182, rec=0.078, cos=0.210), tot_loss_proj:2.769 [t=0.19s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.517 (perp=6.182, rec=0.070, cos=0.210), tot_loss_proj:2.760 [t=0.22s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
[1900/2000] tot_loss=1.519 (perp=6.182, rec=0.072, cos=0.211), tot_loss_proj:2.763 [t=0.19s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
[1950/2000] tot_loss=1.522 (perp=6.182, rec=0.075, cos=0.211), tot_loss_proj:2.764 [t=0.22s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Attempt swap
[2000/2000] tot_loss=1.528 (perp=6.182, rec=0.081, cos=0.211), tot_loss_proj:2.765 [t=0.19s]
prediction: ['[CLS] and in your seat a not there - - single jump is - - moment [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] and in your seat a not there - - single jump is - - moment [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 92.308 | r: 92.308
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 46.154 | p: 46.154 | r: 46.154
rougeLsum  | fm: 46.154 | p: 46.154 | r: 46.154
r1fm+r2fm = 117.308

[Aggregate metrics]:
rouge1     | fm: 86.709 | p: 85.810 | r: 87.873
rouge2     | fm: 52.276 | p: 52.017 | r: 52.544
rougeL     | fm: 75.024 | p: 74.247 | r: 75.977
rougeLsum  | fm: 74.959 | p: 74.214 | r: 75.975
r1fm+r2fm = 138.985

input #71 time: 0:08:27 | total time: 10:02:27


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.8554907271450519
highest_index [0]
highest [0.8554907271450519]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7734614610671997 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7658302783966064 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 0.7404615879058838 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7389740347862244 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 0.7303465008735657 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7294154167175293 for ['[CLS] renaissance lie devil brigade unit purcell as harvest strandedfr uncommon powers behaviour ken terror [SEP]']
[Init] best rec loss: 0.7271015048027039 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.6990913152694702 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.698982298374176 for ['[CLS] reserve dna pork orbital zone support except lifeboat! van nonethelessungen walking accidentally ta [SEP]']
[Init] best perm rec loss: 0.6977343559265137 for ['[CLS] accidentally lifeboat support walking except zone orbital nonethelessungen ta reserve dna van! pork [SEP]']
[Init] best perm rec loss: 0.6971335411071777 for ['[CLS] lifeboat van except ta orbital zone accidentally reserve dna! nonetheless walking supportungen pork [SEP]']
[Init] best perm rec loss: 0.6970021724700928 for ['[CLS] orbital ta zone reserve! accidentally exceptungen pork nonetheless lifeboat van support walking dna [SEP]']
[Init] best perm rec loss: 0.6959596276283264 for ['[CLS] walking support zone orbital lifeboat ta nonetheless except pork dna van accidentally! reserveungen [SEP]']
[Init] best perm rec loss: 0.6959514617919922 for ['[CLS] reserve lifeboat walking ta support accidentally! orbitalungen dna except zone pork nonetheless van [SEP]']
[Init] best perm rec loss: 0.6944130063056946 for ['[CLS] ta porkungen except accidentally dna walking zone van nonetheless! reserve support lifeboat orbital [SEP]']
[Init] best perm rec loss: 0.6942799687385559 for ['[CLS] lifeboat support ta reserve walking zone except orbital accidentally nonetheless pork van!ungen dna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.323 (perp=13.467, rec=0.369, cos=0.260), tot_loss_proj:3.931 [t=0.21s]
prediction: ['[CLS] currency girl tough harderismvoking replaced nasty spike censorship a terrorism deserve increasingly territory [SEP]']
[ 100/2000] tot_loss=2.643 (perp=10.948, rec=0.237, cos=0.216), tot_loss_proj:3.925 [t=0.23s]
prediction: ['[CLS] has instincts tougherism tough replaced killing points ruling a terrorismaeat territory [SEP]']
[ 150/2000] tot_loss=2.335 (perp=9.741, rec=0.132, cos=0.254), tot_loss_proj:3.723 [t=0.25s]
prediction: ['[CLS] has inspired tougher time tough its killing violence balancing with violence philosophy balancing philosophy [SEP]']
[ 200/2000] tot_loss=2.402 (perp=10.162, rec=0.108, cos=0.261), tot_loss_proj:3.416 [t=0.19s]
prediction: ['[CLS] has suggests tougher time tough its violence violence balancing with violence philosophy philosophy philosophy [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.322 (perp=9.710, rec=0.116, cos=0.264), tot_loss_proj:3.203 [t=0.21s]
prediction: ['[CLS] has suggests tougher time tough its violence balancing violence with violence philosophy inspired philosophy [SEP]']
[ 300/2000] tot_loss=2.327 (perp=9.955, rec=0.072, cos=0.265), tot_loss_proj:2.805 [t=0.19s]
prediction: ['[CLS] has suggests tougher time its its violence balancing its with violence philosophy inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.049 (perp=8.550, rec=0.076, cos=0.263), tot_loss_proj:2.668 [t=0.19s]
prediction: ['[CLS] has suggests tougher time with its violence balancing its its violencea inspired philosophy [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.232 (perp=9.432, rec=0.091, cos=0.254), tot_loss_proj:2.693 [t=0.22s]
prediction: ['[CLS] hasfk tougher time balancing its violence violencea with split violence inspired philosophy [SEP]']
[ 450/2000] tot_loss=2.225 (perp=9.432, rec=0.076, cos=0.262), tot_loss_proj:2.693 [t=0.19s]
prediction: ['[CLS] hasfk tougher time balancing its violence violencea with split violence inspired philosophy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.112 (perp=8.839, rec=0.080, cos=0.265), tot_loss_proj:2.367 [t=0.19s]
prediction: ['[CLS]fk has tougher time balancing its violence violencea with split violence inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.128 (perp=8.893, rec=0.084, cos=0.265), tot_loss_proj:2.389 [t=0.19s]
prediction: ['[CLS] violence has tougher time balancing its itsfka with placed violence inspired philosophy [SEP]']
[ 600/2000] tot_loss=2.106 (perp=8.893, rec=0.062, cos=0.265), tot_loss_proj:2.392 [t=0.23s]
prediction: ['[CLS] violence has tougher time balancing its itsfka with placed violence inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.061 (perp=8.633, rec=0.074, cos=0.261), tot_loss_proj:2.494 [t=0.20s]
prediction: ['[CLS] violence has tougher time balancing its violencefka with placed its inspired philosophy [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.968 (perp=8.130, rec=0.077, cos=0.264), tot_loss_proj:2.249 [t=0.24s]
prediction: ['[CLS] violence has tougher time balancing its violencefka with itsfk inspired philosophy [SEP]']
[ 750/2000] tot_loss=1.968 (perp=8.130, rec=0.076, cos=0.266), tot_loss_proj:2.257 [t=0.19s]
prediction: ['[CLS] violence has tougher time balancing its violencefka with itsfk inspired philosophy [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.874 (perp=7.672, rec=0.083, cos=0.256), tot_loss_proj:2.081 [t=0.19s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violencefk inspired philosophy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.866 (perp=7.672, rec=0.070, cos=0.261), tot_loss_proj:2.089 [t=0.19s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violencefk inspired philosophy [SEP]']
[ 900/2000] tot_loss=1.873 (perp=7.672, rec=0.075, cos=0.264), tot_loss_proj:2.076 [t=0.18s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violencefk inspired philosophy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.858 (perp=7.672, rec=0.058, cos=0.265), tot_loss_proj:2.088 [t=0.22s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violencefk inspired philosophy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.866 (perp=7.672, rec=0.066, cos=0.266), tot_loss_proj:2.084 [t=0.19s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violencefk inspired philosophy [SEP]']
[1050/2000] tot_loss=1.878 (perp=7.672, rec=0.077, cos=0.266), tot_loss_proj:2.090 [t=0.25s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violencefk inspired philosophy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.884 (perp=7.672, rec=0.083, cos=0.267), tot_loss_proj:2.084 [t=0.21s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violencefk inspired philosophy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.885 (perp=7.672, rec=0.084, cos=0.267), tot_loss_proj:2.078 [t=0.19s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violencefk inspired philosophy [SEP]']
[1200/2000] tot_loss=1.870 (perp=7.672, rec=0.068, cos=0.267), tot_loss_proj:2.084 [t=0.25s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violencefk inspired philosophy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.809 (perp=7.299, rec=0.083, cos=0.267), tot_loss_proj:1.996 [t=0.19s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violence - inspired philosophy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.816 (perp=7.299, rec=0.089, cos=0.268), tot_loss_proj:2.000 [t=0.22s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violence - inspired philosophy [SEP]']
[1350/2000] tot_loss=1.796 (perp=7.299, rec=0.069, cos=0.268), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS] has tougher time balancing its violencefka with its violence - inspired philosophy [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=2.049 (perp=8.528, rec=0.077, cos=0.266), tot_loss_proj:2.250 [t=0.23s]
prediction: ['[CLS]fka has tougher time balancing its violence with itsfkfk inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.891 (perp=7.792, rec=0.074, cos=0.259), tot_loss_proj:2.121 [t=0.20s]
prediction: ['[CLS]fk a has tougher time balancing its violence with itsfka inspired philosophy [SEP]']
[1500/2000] tot_loss=1.968 (perp=8.151, rec=0.072, cos=0.265), tot_loss_proj:2.162 [t=0.19s]
prediction: ['[CLS]fk screen has tougher time balancing its violence with itsfka inspired philosophy [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.849 (perp=7.595, rec=0.073, cos=0.257), tot_loss_proj:2.142 [t=0.18s]
prediction: ['[CLS]fk has tougher screen time balancing its violence with itsfka inspired philosophy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.861 (perp=7.595, rec=0.080, cos=0.262), tot_loss_proj:2.135 [t=0.23s]
prediction: ['[CLS]fk has tougher screen time balancing its violence with itsfka inspired philosophy [SEP]']
[1650/2000] tot_loss=1.854 (perp=7.595, rec=0.072, cos=0.263), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS]fk has tougher screen time balancing its violence with itsfka inspired philosophy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.854 (perp=7.595, rec=0.071, cos=0.264), tot_loss_proj:2.135 [t=0.21s]
prediction: ['[CLS]fk has tougher screen time balancing its violence with itsfka inspired philosophy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.860 (perp=7.595, rec=0.076, cos=0.265), tot_loss_proj:2.151 [t=0.25s]
prediction: ['[CLS]fk has tougher screen time balancing its violence with itsfka inspired philosophy [SEP]']
[1800/2000] tot_loss=1.852 (perp=7.595, rec=0.067, cos=0.266), tot_loss_proj:2.134 [t=0.27s]
prediction: ['[CLS]fk has tougher screen time balancing its violence with itsfka inspired philosophy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.937 (perp=7.971, rec=0.077, cos=0.266), tot_loss_proj:2.254 [t=0.19s]
prediction: ['[CLS]fk has tougher - time balancing its violence with itsfka inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.016 (perp=8.411, rec=0.078, cos=0.256), tot_loss_proj:2.317 [t=0.18s]
prediction: ['[CLS]fk has tougher time screen balancing its violence with itsfka inspired philosophy [SEP]']
[1950/2000] tot_loss=2.021 (perp=8.411, rec=0.077, cos=0.261), tot_loss_proj:2.322 [t=0.19s]
prediction: ['[CLS]fk has tougher time screen balancing its violence with itsfka inspired philosophy [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.850 (perp=7.595, rec=0.070, cos=0.262), tot_loss_proj:2.135 [t=0.20s]
prediction: ['[CLS]fk has tougher screen time balancing its violence with itsfka inspired philosophy [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS]fk has tougher screen time balancing its violence with itsfka inspired philosophy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.481 | p: 78.571 | r: 84.615
rouge2     | fm: 48.000 | p: 46.154 | r: 50.000
rougeL     | fm: 81.481 | p: 78.571 | r: 84.615
rougeLsum  | fm: 81.481 | p: 78.571 | r: 84.615
r1fm+r2fm = 129.481

[Aggregate metrics]:
rouge1     | fm: 86.656 | p: 85.728 | r: 87.821
rouge2     | fm: 52.040 | p: 51.795 | r: 52.386
rougeL     | fm: 75.105 | p: 74.289 | r: 76.001
rougeLsum  | fm: 75.117 | p: 74.315 | r: 76.093
r1fm+r2fm = 138.696

input #72 time: 0:08:28 | total time: 10:10:56


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.8491215848767313
highest_index [0]
highest [0.8491215848767313]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9552637934684753 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9454516172409058 for ['[CLS] garage knight [SEP]']
[Init] best rec loss: 0.8976775407791138 for ['[CLS] capitol living [SEP]']
[Init] best rec loss: 0.8899997472763062 for ['[CLS] zhang body [SEP]']
[Init] best rec loss: 0.8859471678733826 for ['[CLS] puget traditional [SEP]']
[Init] best rec loss: 0.8676109313964844 for ['[CLS]ɛ society [SEP]']
[Init] best rec loss: 0.8428828120231628 for ['[CLS] massachusetts gun [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.444 (perp=9.504, rec=0.282, cos=0.261), tot_loss_proj:2.675 [t=0.17s]
prediction: ['[CLS] bad propaganda [SEP]']
[ 100/2000] tot_loss=2.322 (perp=9.723, rec=0.104, cos=0.274), tot_loss_proj:2.312 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.302 (perp=9.723, rec=0.083, cos=0.274), tot_loss_proj:2.306 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.273 (perp=9.723, rec=0.051, cos=0.278), tot_loss_proj:2.313 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.278 (perp=9.723, rec=0.059, cos=0.275), tot_loss_proj:2.317 [t=0.28s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.287 (perp=9.723, rec=0.064, cos=0.278), tot_loss_proj:2.315 [t=0.29s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.289 (perp=9.723, rec=0.069, cos=0.275), tot_loss_proj:2.303 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.267 (perp=9.723, rec=0.045, cos=0.278), tot_loss_proj:2.291 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.272 (perp=9.723, rec=0.049, cos=0.278), tot_loss_proj:2.310 [t=0.20s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.292 (perp=9.723, rec=0.068, cos=0.278), tot_loss_proj:2.310 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.293 (perp=9.723, rec=0.070, cos=0.278), tot_loss_proj:2.311 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.286 (perp=9.723, rec=0.063, cos=0.278), tot_loss_proj:2.308 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.292 (perp=9.723, rec=0.069, cos=0.278), tot_loss_proj:2.290 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.289 (perp=9.723, rec=0.066, cos=0.278), tot_loss_proj:2.299 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.283 (perp=9.723, rec=0.060, cos=0.279), tot_loss_proj:2.314 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.273 (perp=9.723, rec=0.050, cos=0.278), tot_loss_proj:2.320 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.264 (perp=9.723, rec=0.041, cos=0.278), tot_loss_proj:2.317 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.285 (perp=9.723, rec=0.061, cos=0.278), tot_loss_proj:2.299 [t=0.20s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.280 (perp=9.723, rec=0.057, cos=0.278), tot_loss_proj:2.307 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.282 (perp=9.723, rec=0.059, cos=0.278), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.276 (perp=9.723, rec=0.053, cos=0.278), tot_loss_proj:2.302 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.285 (perp=9.723, rec=0.062, cos=0.279), tot_loss_proj:2.304 [t=0.27s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.291 (perp=9.723, rec=0.068, cos=0.278), tot_loss_proj:2.299 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.280 (perp=9.723, rec=0.057, cos=0.278), tot_loss_proj:2.294 [t=0.30s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.295 (perp=9.723, rec=0.072, cos=0.278), tot_loss_proj:2.302 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.289 (perp=9.723, rec=0.066, cos=0.278), tot_loss_proj:2.302 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.301 (perp=9.723, rec=0.078, cos=0.278), tot_loss_proj:2.309 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.289 (perp=9.723, rec=0.065, cos=0.278), tot_loss_proj:2.291 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.297 (perp=9.723, rec=0.074, cos=0.278), tot_loss_proj:2.302 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.280 (perp=9.723, rec=0.057, cos=0.278), tot_loss_proj:2.310 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.277 (perp=9.723, rec=0.054, cos=0.278), tot_loss_proj:2.299 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.284 (perp=9.723, rec=0.061, cos=0.278), tot_loss_proj:2.305 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.290 (perp=9.723, rec=0.067, cos=0.278), tot_loss_proj:2.295 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.296 (perp=9.723, rec=0.073, cos=0.278), tot_loss_proj:2.306 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.281 (perp=9.723, rec=0.058, cos=0.278), tot_loss_proj:2.302 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.269 (perp=9.723, rec=0.046, cos=0.278), tot_loss_proj:2.304 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.278 (perp=9.723, rec=0.055, cos=0.278), tot_loss_proj:2.314 [t=0.26s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.297 (perp=9.723, rec=0.074, cos=0.278), tot_loss_proj:2.308 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.285 (perp=9.723, rec=0.062, cos=0.278), tot_loss_proj:2.304 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.274 (perp=9.723, rec=0.051, cos=0.278), tot_loss_proj:2.301 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.763 | p: 85.891 | r: 87.942
rouge2     | fm: 52.921 | p: 52.655 | r: 53.161
rougeL     | fm: 75.303 | p: 74.549 | r: 76.309
rougeLsum  | fm: 75.333 | p: 74.600 | r: 76.366
r1fm+r2fm = 139.684

input #73 time: 0:08:19 | total time: 10:19:15


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.8614547645039834
highest_index [0]
highest [0.8614547645039834]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.8149551749229431 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6218067407608032 for ['[CLS] storage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.071 (perp=8.178, rec=0.198, cos=0.238), tot_loss_proj:2.251 [t=0.20s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.958 (perp=8.178, rec=0.069, cos=0.254), tot_loss_proj:2.036 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.970 (perp=8.178, rec=0.078, cos=0.256), tot_loss_proj:2.022 [t=0.20s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.955 (perp=8.178, rec=0.063, cos=0.256), tot_loss_proj:2.023 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.115 (perp=8.178, rec=0.231, cos=0.249), tot_loss_proj:2.329 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=2.022 (perp=8.178, rec=0.130, cos=0.256), tot_loss_proj:2.113 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.015 (perp=8.178, rec=0.124, cos=0.256), tot_loss_proj:2.025 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.996 (perp=8.178, rec=0.104, cos=0.256), tot_loss_proj:2.013 [t=0.24s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=2.005 (perp=8.178, rec=0.113, cos=0.257), tot_loss_proj:2.022 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.003 (perp=8.178, rec=0.112, cos=0.256), tot_loss_proj:2.022 [t=0.24s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.982 (perp=8.178, rec=0.096, cos=0.251), tot_loss_proj:2.028 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=2.000 (perp=8.178, rec=0.109, cos=0.256), tot_loss_proj:2.005 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.992 (perp=8.178, rec=0.099, cos=0.257), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.999 (perp=8.178, rec=0.107, cos=0.257), tot_loss_proj:2.019 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.990 (perp=8.178, rec=0.097, cos=0.257), tot_loss_proj:2.025 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.003 (perp=8.178, rec=0.111, cos=0.257), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.004 (perp=8.178, rec=0.112, cos=0.257), tot_loss_proj:2.018 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=2.001 (perp=8.178, rec=0.108, cos=0.257), tot_loss_proj:2.001 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.005 (perp=8.178, rec=0.112, cos=0.258), tot_loss_proj:2.018 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.995 (perp=8.178, rec=0.102, cos=0.257), tot_loss_proj:2.015 [t=0.19s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=2.015 (perp=8.178, rec=0.122, cos=0.257), tot_loss_proj:2.028 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.996 (perp=8.178, rec=0.103, cos=0.258), tot_loss_proj:2.018 [t=0.26s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.993 (perp=8.178, rec=0.100, cos=0.257), tot_loss_proj:2.018 [t=0.32s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.987 (perp=8.178, rec=0.094, cos=0.257), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=2.005 (perp=8.178, rec=0.112, cos=0.258), tot_loss_proj:2.007 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=2.004 (perp=8.178, rec=0.111, cos=0.257), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=2.019 (perp=8.178, rec=0.126, cos=0.258), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=2.005 (perp=8.178, rec=0.112, cos=0.258), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=2.007 (perp=8.178, rec=0.114, cos=0.258), tot_loss_proj:2.018 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=2.000 (perp=8.178, rec=0.106, cos=0.258), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=2.006 (perp=8.178, rec=0.113, cos=0.258), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=2.005 (perp=8.178, rec=0.112, cos=0.258), tot_loss_proj:2.021 [t=0.19s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.997 (perp=8.178, rec=0.103, cos=0.258), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.994 (perp=8.178, rec=0.101, cos=0.258), tot_loss_proj:1.998 [t=0.23s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=2.001 (perp=8.178, rec=0.108, cos=0.258), tot_loss_proj:2.011 [t=0.30s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.999 (perp=8.178, rec=0.106, cos=0.258), tot_loss_proj:2.027 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.994 (perp=8.178, rec=0.101, cos=0.258), tot_loss_proj:2.007 [t=0.24s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.992 (perp=8.178, rec=0.099, cos=0.257), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=2.001 (perp=8.178, rec=0.108, cos=0.258), tot_loss_proj:2.021 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.991 (perp=8.178, rec=0.097, cos=0.258), tot_loss_proj:2.016 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.984 | p: 86.133 | r: 88.140
rouge2     | fm: 53.747 | p: 53.484 | r: 54.027
rougeL     | fm: 75.662 | p: 74.933 | r: 76.614
rougeLsum  | fm: 75.810 | p: 74.960 | r: 76.760
r1fm+r2fm = 140.731

input #74 time: 0:08:16 | total time: 10:27:31


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.8751113466824139
highest_index [0]
highest [0.8751113466824139]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.888565719127655 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.8602034449577332 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.832977294921875 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best perm rec loss: 0.8328812718391418 for ['[CLS] double es regiment alfred marlene help reason moth churches malone duties connacht clan zach section meaning rushose lakes [SEP]']
[Init] best perm rec loss: 0.8321937322616577 for ['[CLS] moth duties alfred es churches regiment double clan malone reason meaning lakes help section zachose rush connacht marlene [SEP]']
[Init] best perm rec loss: 0.8303985595703125 for ['[CLS] help double lakes section reason malone clan churches meaning connacht regiment alfred rush moth marlene duties es zachose [SEP]']
[Init] best perm rec loss: 0.8299896121025085 for ['[CLS] zach meaning regiment rush marleneose reason duties clan section churches alfred es malone moth help double lakes connacht [SEP]']
[Init] best perm rec loss: 0.8296210169792175 for ['[CLS] marlene clan duties regimentose meaning reason lakes section help zach malone connacht moth es rush alfred churches double [SEP]']
[Init] best perm rec loss: 0.8279833197593689 for ['[CLS] help clan malone section rush moth alfred es connacht marlene reason churches meaning duties double lakesose regiment zach [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.685 (perp=10.607, rec=0.351, cos=0.213), tot_loss_proj:3.414 [t=0.18s]
prediction: ['[CLS] protect that provide unnoticed families nielsen ben the not not forgotten they, accountability research supernatural protect through the [SEP]']
[ 100/2000] tot_loss=2.577 (perp=10.817, rec=0.192, cos=0.222), tot_loss_proj:3.957 [t=0.23s]
prediction: ['[CLS] we : allowed unexpected or instabilityrosis a easily not forgottenus is independent literally easily destruction through would [SEP]']
[ 150/2000] tot_loss=2.393 (perp=10.138, rec=0.142, cos=0.223), tot_loss_proj:3.712 [t=0.26s]
prediction: ['[CLS] we this of mental or instabilityঅenter easily not forgotten of is jarrett的 or forgotten played the [SEP]']
[ 200/2000] tot_loss=2.505 (perp=10.875, rec=0.104, cos=0.226), tot_loss_proj:3.791 [t=0.19s]
prediction: ['[CLS] excursion this of mental mental instabilitycolaenter easily not dismissed of is jarrett― or forgotten through the [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.218 (perp=9.487, rec=0.093, cos=0.227), tot_loss_proj:3.618 [t=0.18s]
prediction: ['[CLS] this excursion into mental mental instabilitycolaenter easily not dismissedting is jarrett― or forgotten through. [SEP]']
[ 300/2000] tot_loss=2.168 (perp=9.280, rec=0.085, cos=0.227), tot_loss_proj:3.625 [t=0.28s]
prediction: ['[CLS] this excursion into mental mental instabilitycolaenter easily not dismissedting is jarrett― or forgotten.. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.021 (perp=8.587, rec=0.075, cos=0.229), tot_loss_proj:3.463 [t=0.28s]
prediction: ['[CLS] this excursion into mental mental instabilitycolating easily not dismissedenter ispageenter or forgotten.. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.177 (perp=8.921, rec=0.175, cos=0.217), tot_loss_proj:3.376 [t=0.21s]
prediction: ['[CLS] this excursion into mental mental instabilitycolating easily not dismissed is alsoenterenter or forgotten. [SEP] [SEP]']
[ 450/2000] tot_loss=2.086 (perp=8.803, rec=0.095, cos=0.230), tot_loss_proj:3.382 [t=0.23s]
prediction: ['[CLS] this excursion into mental mental instabilitycolating easily not dismissed is ofenterenter or forgotten. [SEP] [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.007 (perp=8.386, rec=0.098, cos=0.231), tot_loss_proj:3.274 [t=0.23s]
prediction: ['[CLS] this excursion into mental mental instabilitycolating easily not dismissed is of [SEP] epicenter or forgotten. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.919 (perp=7.995, rec=0.100, cos=0.220), tot_loss_proj:2.906 [t=0.19s]
prediction: ['[CLS] this excursion into mental mental instability ofcolating easily not dismissed is [SEP] epicenter or forgotten. [SEP]']
[ 600/2000] tot_loss=1.916 (perp=7.995, rec=0.087, cos=0.230), tot_loss_proj:2.929 [t=0.18s]
prediction: ['[CLS] this excursion into mental mental instability ofcolating easily not dismissed is [SEP] epicenter or forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.868 (perp=7.765, rec=0.085, cos=0.229), tot_loss_proj:2.941 [t=0.21s]
prediction: ['[CLS] this excursion into mental mental instability [SEP]colating easily not dismissed is of epicenter or forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.849 (perp=7.672, rec=0.084, cos=0.231), tot_loss_proj:3.264 [t=0.20s]
prediction: ['[CLS] this excursion into mental mental instability [SEP]colating easily not of is dismissed epicenter or forgotten. [SEP]']
[ 750/2000] tot_loss=1.851 (perp=7.672, rec=0.085, cos=0.232), tot_loss_proj:3.262 [t=0.18s]
prediction: ['[CLS] this excursion into mental mental instability [SEP]colating easily not of is dismissed epicenter or forgotten. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.800 (perp=7.464, rec=0.077, cos=0.231), tot_loss_proj:2.618 [t=0.22s]
prediction: ['[CLS] this excursion into mental mental instability [SEP]colating easily of is not dismissed epicenter or forgotten. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.709 (perp=6.935, rec=0.089, cos=0.232), tot_loss_proj:2.166 [t=0.23s]
prediction: ['[CLS] this excursion into mental mental instability [SEP]colating of is not easily dismissed epicenter or forgotten. [SEP]']
[ 900/2000] tot_loss=1.694 (perp=6.935, rec=0.074, cos=0.233), tot_loss_proj:2.166 [t=0.19s]
prediction: ['[CLS] this excursion into mental mental instability [SEP]colating of is not easily dismissed epicenter or forgotten. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.651 (perp=6.689, rec=0.083, cos=0.230), tot_loss_proj:1.979 [t=0.18s]
prediction: ['[CLS] this excursion into mental of mental instability [SEP]colating is not easily dismissed epicenter or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.602 (perp=6.487, rec=0.079, cos=0.225), tot_loss_proj:2.227 [t=0.22s]
prediction: ['[CLS] this excursion into mental or mental instability [SEP]colating is not easily dismissed epicenter of forgotten. [SEP]']
[1050/2000] tot_loss=1.614 (perp=6.487, rec=0.087, cos=0.230), tot_loss_proj:2.232 [t=0.23s]
prediction: ['[CLS] this excursion into mental or mental instability [SEP]colating is not easily dismissed epicenter of forgotten. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.608 (perp=6.487, rec=0.080, cos=0.231), tot_loss_proj:2.223 [t=0.19s]
prediction: ['[CLS] this excursion into mental or mental instability [SEP]colating is not easily dismissed epicenter of forgotten. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.610 (perp=6.487, rec=0.082, cos=0.231), tot_loss_proj:2.230 [t=0.20s]
prediction: ['[CLS] this excursion into mental or mental instability [SEP]colating is not easily dismissed epicenter of forgotten. [SEP]']
[1200/2000] tot_loss=1.796 (perp=7.475, rec=0.069, cos=0.232), tot_loss_proj:2.435 [t=0.18s]
prediction: ['[CLS] this excursion into per or mental instability [SEP]colating is not easily dismissed epicenter of forgotten. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.865 (perp=7.803, rec=0.073, cos=0.232), tot_loss_proj:2.659 [t=0.18s]
prediction: ['[CLS] this excursion into per or mental instability acolating is not easily dismissed epicenter of forgotten. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.764 (perp=7.269, rec=0.082, cos=0.227), tot_loss_proj:2.547 [t=0.22s]
prediction: ['[CLS] this excursion into per or mental instabilitycolating is not easily dismissed epicenter of a forgotten. [SEP]']
[1350/2000] tot_loss=1.764 (perp=7.269, rec=0.080, cos=0.230), tot_loss_proj:2.553 [t=0.18s]
prediction: ['[CLS] this excursion into per or mental instabilitycolating is not easily dismissed epicenter of a forgotten. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.743 (perp=7.161, rec=0.079, cos=0.232), tot_loss_proj:2.404 [t=0.18s]
prediction: ['[CLS] this excursion into perenter or mental instabilitycolating is not easily dismissed epic of a forgotten. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.715 (perp=7.035, rec=0.078, cos=0.229), tot_loss_proj:2.413 [t=0.18s]
prediction: ['[CLS] this excursion into perenter or mental instabilitycolating is not a easily dismissed epic of forgotten. [SEP]']
[1500/2000] tot_loss=1.710 (perp=7.035, rec=0.072, cos=0.231), tot_loss_proj:2.415 [t=0.18s]
prediction: ['[CLS] this excursion into perenter or mental instabilitycolating is not a easily dismissed epic of forgotten. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.723 (perp=7.035, rec=0.084, cos=0.231), tot_loss_proj:2.414 [t=0.21s]
prediction: ['[CLS] this excursion into perenter or mental instabilitycolating is not a easily dismissed epic of forgotten. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.716 (perp=7.035, rec=0.077, cos=0.232), tot_loss_proj:2.420 [t=0.19s]
prediction: ['[CLS] this excursion into perenter or mental instabilitycolating is not a easily dismissed epic of forgotten. [SEP]']
[1650/2000] tot_loss=1.707 (perp=7.035, rec=0.068, cos=0.232), tot_loss_proj:2.419 [t=0.18s]
prediction: ['[CLS] this excursion into perenter or mental instabilitycolating is not a easily dismissed epic of forgotten. [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.692 (perp=6.933, rec=0.073, cos=0.232), tot_loss_proj:2.361 [t=0.18s]
prediction: ['[CLS] this excursion intoenter or mental instability percolating is not a easily dismissed epic of forgotten. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.683 (perp=6.881, rec=0.075, cos=0.232), tot_loss_proj:2.854 [t=0.26s]
prediction: ['[CLS] this excursion intoenter or mental instability percolating is a not easily dismissed epic of forgotten. [SEP]']
[1800/2000] tot_loss=1.683 (perp=6.881, rec=0.075, cos=0.232), tot_loss_proj:2.859 [t=0.24s]
prediction: ['[CLS] this excursion intoenter or mental instability percolating is a not easily dismissed epic of forgotten. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.679 (perp=6.881, rec=0.071, cos=0.232), tot_loss_proj:2.855 [t=0.22s]
prediction: ['[CLS] this excursion intoenter or mental instability percolating is a not easily dismissed epic of forgotten. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.672 (perp=6.881, rec=0.063, cos=0.232), tot_loss_proj:2.852 [t=0.25s]
prediction: ['[CLS] this excursion intoenter or mental instability percolating is a not easily dismissed epic of forgotten. [SEP]']
[1950/2000] tot_loss=1.685 (perp=6.881, rec=0.077, cos=0.232), tot_loss_proj:2.860 [t=0.23s]
prediction: ['[CLS] this excursion intoenter or mental instability percolating is a not easily dismissed epic of forgotten. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.687 (perp=6.881, rec=0.078, cos=0.232), tot_loss_proj:2.859 [t=0.19s]
prediction: ['[CLS] this excursion intoenter or mental instability percolating is a not easily dismissed epic of forgotten. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this excursion intoenter or mental instability percolating is a not easily dismissed epic of forgotten. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 82.353 | r: 82.353
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 64.706 | p: 64.706 | r: 64.706
rougeLsum  | fm: 64.706 | p: 64.706 | r: 64.706
r1fm+r2fm = 119.853

[Aggregate metrics]:
rouge1     | fm: 86.963 | p: 86.097 | r: 88.110
rouge2     | fm: 53.291 | p: 53.034 | r: 53.571
rougeL     | fm: 75.537 | p: 74.772 | r: 76.505
rougeLsum  | fm: 75.602 | p: 74.859 | r: 76.560
r1fm+r2fm = 140.254

input #75 time: 0:08:22 | total time: 10:35:53


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.8453002065295859
highest_index [0]
highest [0.8453002065295859]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.8870683908462524 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.8829025030136108 for ['[CLS] skin outside historian inside please determined boss legend vi đ wine unanimouslymer ski [SEP]']
[Init] best rec loss: 0.8726317286491394 for ['[CLS] midnight even task j mesh constellation village typhoonorough, advancing hammerist carol [SEP]']
[Init] best rec loss: 0.8503325581550598 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 0.8465505838394165 for ['[CLS] paper both commercially user guantanamo body 3d barker away commune also fortune turkey shay [SEP]']
[Init] best perm rec loss: 0.8453064560890198 for ['[CLS] turkey shay 3d commercially fortune user guantanamo away commune barker also both paper body [SEP]']
[Init] best perm rec loss: 0.8445169925689697 for ['[CLS] guantanamo commercially paper barker also fortune commune both 3d body user shay away turkey [SEP]']
[Init] best perm rec loss: 0.8444340825080872 for ['[CLS] guantanamo body barker both commune also paper turkey shay fortune 3d commercially user away [SEP]']
[Init] best perm rec loss: 0.843407928943634 for ['[CLS] commercially user body 3d guantanamo fortune turkey barker away shay also both commune paper [SEP]']
[Init] best perm rec loss: 0.8431516885757446 for ['[CLS] commercially user body paper shay barker 3d also both guantanamo commune fortune turkey away [SEP]']
[Init] best perm rec loss: 0.8424076437950134 for ['[CLS] commune fortune commercially 3d paper shay barker turkey also body user both away guantanamo [SEP]']
[Init] best perm rec loss: 0.8419007658958435 for ['[CLS] body barker shay commune away paper turkey 3d guantanamo also fortune both user commercially [SEP]']
[Init] best perm rec loss: 0.8411335349082947 for ['[CLS] barker away paper commercially 3d body user guantanamo shay both also turkey fortune commune [SEP]']
[Init] best perm rec loss: 0.8395951390266418 for ['[CLS] also commune shay paper turkey both fortune guantanamo 3d body barker user away commercially [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.052 (perp=11.905, rec=0.410, cos=0.261), tot_loss_proj:3.785 [t=0.22s]
prediction: ['[CLS] hadley took caused call stimulation had specifically stopped stopped £5 no risk? faced [SEP]']
[ 100/2000] tot_loss=2.912 (perp=11.837, rec=0.283, cos=0.261), tot_loss_proj:3.529 [t=0.22s]
prediction: ['[CLS] warlock during action call fay had challenging stopped stopped challenging maybe shock? or [SEP]']
[ 150/2000] tot_loss=2.573 (perp=10.612, rec=0.200, cos=0.251), tot_loss_proj:3.612 [t=0.24s]
prediction: ["[CLS] old at scville has if challenging stopped stopped challenging has shock'himself [SEP]"]
[ 200/2000] tot_loss=2.485 (perp=10.361, rec=0.136, cos=0.277), tot_loss_proj:3.639 [t=0.21s]
prediction: ["[CLS] old at sc allen has if challenging stopped stopped challenging has shock'himself [SEP]"]
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.563 (perp=10.707, rec=0.176, cos=0.245), tot_loss_proj:3.671 [t=0.26s]
prediction: ["[CLS] cases at has 66 'cle, has if challenging stopped stopped challenging himself [SEP]"]
[ 300/2000] tot_loss=2.518 (perp=10.615, rec=0.130, cos=0.265), tot_loss_proj:3.489 [t=0.25s]
prediction: ["[CLS] crude at has 66'wr, has if challenging stopped stopped challenging himself [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.493 (perp=10.564, rec=0.109, cos=0.272), tot_loss_proj:3.903 [t=0.19s]
prediction: ['[CLS] crude at has 66 at s, challenging if has stopped stopped challenging himself [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.450 (perp=10.312, rec=0.110, cos=0.278), tot_loss_proj:3.612 [t=0.18s]
prediction: ['[CLS] crude at has challenging at s allen 66 if has stopped stopped challenging himself [SEP]']
[ 450/2000] tot_loss=2.444 (perp=10.312, rec=0.103, cos=0.279), tot_loss_proj:3.610 [t=0.22s]
prediction: ['[CLS] crude at has challenging at s allen 66 if has stopped stopped challenging himself [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.227 (perp=9.284, rec=0.091, cos=0.279), tot_loss_proj:3.729 [t=0.28s]
prediction: ['[CLS]. challenging has challenging at s allen 66 if has stopped. at himself [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.086 (perp=8.553, rec=0.104, cos=0.271), tot_loss_proj:3.566 [t=0.24s]
prediction: ['[CLS]. challenging has challenging at s allen 66 if has stopped at himself. [SEP]']
[ 600/2000] tot_loss=2.079 (perp=8.553, rec=0.090, cos=0.278), tot_loss_proj:3.567 [t=0.19s]
prediction: ['[CLS]. challenging has challenging at s allen 66 if has stopped at himself. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.934 (perp=7.825, rec=0.094, cos=0.275), tot_loss_proj:3.250 [t=0.24s]
prediction: ['[CLS]. challenging has at s allen 66 if challenging has stopped at himself. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.859 (perp=7.352, rec=0.106, cos=0.283), tot_loss_proj:3.206 [t=0.22s]
prediction: ['[CLS] challenging has at s. allen 66 if challenging has stopped at himself. [SEP]']
[ 750/2000] tot_loss=2.150 (perp=8.800, rec=0.107, cos=0.282), tot_loss_proj:3.495 [t=0.19s]
prediction: ['[CLS] challenging has at,. allen 66 if challenging has stopped at himself. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.925 (perp=7.809, rec=0.085, cos=0.278), tot_loss_proj:3.403 [t=0.25s]
prediction: ['[CLS], has at challenging. allen 66 if challenging has stopped at himself. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.850 (perp=7.420, rec=0.085, cos=0.281), tot_loss_proj:3.399 [t=0.22s]
prediction: ['[CLS], has challenging. at allen 66 if challenging has stopped at himself. [SEP]']
[ 900/2000] tot_loss=1.893 (perp=7.555, rec=0.100, cos=0.282), tot_loss_proj:3.398 [t=0.21s]
prediction: ['[CLS], s challenging. at allen 66 if challenging has stopped at himself. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.821 (perp=7.290, rec=0.081, cos=0.282), tot_loss_proj:3.138 [t=0.18s]
prediction: ['[CLS], s. challenging at allen 66 if challenging has stopped at himself. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.876 (perp=7.529, rec=0.092, cos=0.278), tot_loss_proj:2.836 [t=0.18s]
prediction: ['[CLS] s. challenging at allen 66 as challenging s has stopped at himself. [SEP]']
[1050/2000] tot_loss=1.720 (perp=6.704, rec=0.100, cos=0.279), tot_loss_proj:2.601 [t=0.25s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.704 (perp=6.704, rec=0.082, cos=0.281), tot_loss_proj:2.613 [t=0.26s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.714 (perp=6.704, rec=0.092, cos=0.281), tot_loss_proj:2.617 [t=0.30s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
[1200/2000] tot_loss=1.704 (perp=6.704, rec=0.083, cos=0.281), tot_loss_proj:2.607 [t=0.19s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.701 (perp=6.704, rec=0.079, cos=0.281), tot_loss_proj:2.610 [t=0.23s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.701 (perp=6.704, rec=0.078, cos=0.282), tot_loss_proj:2.606 [t=0.19s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
[1350/2000] tot_loss=1.710 (perp=6.704, rec=0.088, cos=0.281), tot_loss_proj:2.606 [t=0.22s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.702 (perp=6.704, rec=0.080, cos=0.281), tot_loss_proj:2.610 [t=0.23s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.708 (perp=6.704, rec=0.087, cos=0.281), tot_loss_proj:2.610 [t=0.18s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
[1500/2000] tot_loss=1.706 (perp=6.704, rec=0.085, cos=0.281), tot_loss_proj:2.609 [t=0.18s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.706 (perp=6.704, rec=0.085, cos=0.280), tot_loss_proj:2.614 [t=0.18s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.709 (perp=6.704, rec=0.087, cos=0.281), tot_loss_proj:2.611 [t=0.20s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
[1650/2000] tot_loss=1.712 (perp=6.704, rec=0.091, cos=0.280), tot_loss_proj:2.613 [t=0.18s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.713 (perp=6.704, rec=0.092, cos=0.280), tot_loss_proj:2.611 [t=0.23s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.703 (perp=6.704, rec=0.082, cos=0.280), tot_loss_proj:2.608 [t=0.18s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
[1800/2000] tot_loss=1.704 (perp=6.704, rec=0.083, cos=0.280), tot_loss_proj:2.614 [t=0.18s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.702 (perp=6.704, rec=0.080, cos=0.280), tot_loss_proj:2.611 [t=0.19s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.702 (perp=6.704, rec=0.081, cos=0.280), tot_loss_proj:2.608 [t=0.18s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
[1950/2000] tot_loss=1.705 (perp=6.704, rec=0.085, cos=0.280), tot_loss_proj:2.617 [t=0.23s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.708 (perp=6.704, rec=0.087, cos=0.280), tot_loss_proj:2.611 [t=0.23s]
prediction: ['[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] s. challenging at allen 66 as challenging, has stopped at himself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 26.087 | p: 25.000 | r: 27.273
rougeL     | fm: 64.000 | p: 61.538 | r: 66.667
rougeLsum  | fm: 64.000 | p: 61.538 | r: 66.667
r1fm+r2fm = 114.087

[Aggregate metrics]:
rouge1     | fm: 86.902 | p: 85.986 | r: 88.074
rouge2     | fm: 53.183 | p: 52.904 | r: 53.454
rougeL     | fm: 75.395 | p: 74.610 | r: 76.403
rougeLsum  | fm: 75.469 | p: 74.695 | r: 76.446
r1fm+r2fm = 140.085

input #76 time: 0:08:32 | total time: 10:44:25


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.823844450450355
highest_index [0]
highest [0.823844450450355]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.8073365092277527 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8012369871139526 for ['[CLS] low each mob descending person architecture channels partnership platinum friendtry aw idea anderson america [SEP]']
[Init] best rec loss: 0.7711580991744995 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.74140864610672 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.7332364320755005 for ['[CLS] too type bred cold crowd more elements lips critique leather under battlefield simple lot pony [SEP]']
[Init] best perm rec loss: 0.7315334677696228 for ['[CLS] crowd cold pony under critique bred simple lips elements battlefield more too leather lot type [SEP]']
[Init] best perm rec loss: 0.7287989854812622 for ['[CLS] battlefield elements too simple bred crowd lot under critique cold lips pony more type leather [SEP]']
[Init] best perm rec loss: 0.7280331254005432 for ['[CLS] crowd battlefield leather type under more elements too critique bred lot lips simple cold pony [SEP]']
[Init] best perm rec loss: 0.7276983261108398 for ['[CLS] under pony lot leather too simple battlefield more elements crowd critique lips cold bred type [SEP]']
[Init] best perm rec loss: 0.7263399362564087 for ['[CLS] under more type battlefield simple pony critique lips too crowd cold elements bred lot leather [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.255 (perp=12.861, rec=0.371, cos=0.312), tot_loss_proj:3.625 [t=0.19s]
prediction: ['[CLS] form oz consistently forms legacy romance a ahead patient compelling serious high species vision gave [SEP]']
[ 100/2000] tot_loss=2.757 (perp=10.913, rec=0.260, cos=0.315), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] itself oz above that america... the above patient truly serious wicked species life gave [SEP]']
[ 150/2000] tot_loss=2.654 (perp=10.793, rec=0.181, cos=0.315), tot_loss_proj:3.290 [t=0.24s]
prediction: ['[CLS] pitchars promise make promises is its above believe promisevable material material life realm [SEP]']
[ 200/2000] tot_loss=2.554 (perp=10.472, rec=0.142, cos=0.317), tot_loss_proj:3.080 [t=0.18s]
prediction: ['[CLS] soars promise make realm is its above believe promise what material material life realm [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.387 (perp=9.475, rec=0.196, cos=0.296), tot_loss_proj:2.943 [t=0.18s]
prediction: ['[CLS] soars promise believe believe promise exterior realm is its above the material realm realm [SEP]']
[ 300/2000] tot_loss=2.196 (perp=8.783, rec=0.137, cos=0.302), tot_loss_proj:2.597 [t=0.20s]
prediction: ['[CLS] soars promise make believe promise life realm is its above the material realm realm [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.975 (perp=7.730, rec=0.122, cos=0.307), tot_loss_proj:2.415 [t=0.17s]
prediction: ['[CLS] soars promise make believe promise life is its realm above the material realm that [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.897 (perp=7.422, rec=0.102, cos=0.311), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] soars make promise believe promise life is its realm above the material realm that [SEP]']
[ 450/2000] tot_loss=1.952 (perp=7.788, rec=0.080, cos=0.315), tot_loss_proj:2.590 [t=0.18s]
prediction: ['[CLS] soars make believe believe promise life is its realm above the material realm that [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.875 (perp=7.377, rec=0.081, cos=0.318), tot_loss_proj:2.461 [t=0.23s]
prediction: ['[CLS] soars believe make believe promise life is its realm above the material realm that [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.876 (perp=7.377, rec=0.083, cos=0.318), tot_loss_proj:2.469 [t=0.31s]
prediction: ['[CLS] soars believe make believe promise life is its realm above the material realm that [SEP]']
[ 600/2000] tot_loss=1.867 (perp=7.377, rec=0.072, cos=0.319), tot_loss_proj:2.467 [t=0.27s]
prediction: ['[CLS] soars believe make believe promise life is its realm above the material realm that [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.816 (perp=7.082, rec=0.081, cos=0.319), tot_loss_proj:2.384 [t=0.28s]
prediction: ['[CLS] soars believe make believe life is its promise realm above the material realm that [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.809 (perp=7.082, rec=0.074, cos=0.319), tot_loss_proj:2.383 [t=0.20s]
prediction: ['[CLS] soars believe make believe life is its promise realm above the material realm that [SEP]']
[ 750/2000] tot_loss=1.809 (perp=7.082, rec=0.073, cos=0.319), tot_loss_proj:2.381 [t=0.19s]
prediction: ['[CLS] soars believe make believe life is its promise realm above the material realm that [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.808 (perp=7.082, rec=0.072, cos=0.320), tot_loss_proj:2.385 [t=0.18s]
prediction: ['[CLS] soars believe make believe life is its promise realm above the material realm that [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.759 (perp=6.852, rec=0.068, cos=0.321), tot_loss_proj:2.291 [t=0.18s]
prediction: ['[CLS] soars believe make believe life above its promise realm is the material realm that [SEP]']
[ 900/2000] tot_loss=1.766 (perp=6.852, rec=0.075, cos=0.320), tot_loss_proj:2.284 [t=0.24s]
prediction: ['[CLS] soars believe make believe life above its promise realm is the material realm that [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.760 (perp=6.854, rec=0.071, cos=0.319), tot_loss_proj:2.371 [t=0.19s]
prediction: ['[CLS] soars believe make believe life above its promise realm that the material realm is [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.762 (perp=6.852, rec=0.072, cos=0.320), tot_loss_proj:2.285 [t=0.18s]
prediction: ['[CLS] soars believe make believe life above its promise realm is the material realm that [SEP]']
[1050/2000] tot_loss=1.936 (perp=7.702, rec=0.076, cos=0.320), tot_loss_proj:2.469 [t=0.19s]
prediction: ['[CLS] soars believe make - life above its promise believe is the material realm that [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.830 (perp=7.208, rec=0.072, cos=0.317), tot_loss_proj:2.325 [t=0.18s]
prediction: ['[CLS] soars - make believe life above its promise believe is the material realm that [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.797 (perp=7.000, rec=0.077, cos=0.320), tot_loss_proj:2.426 [t=0.18s]
prediction: ['[CLS] soars - make believe life believe its promise above is the material realm that [SEP]']
[1200/2000] tot_loss=1.782 (perp=7.000, rec=0.062, cos=0.320), tot_loss_proj:2.428 [t=0.18s]
prediction: ['[CLS] soars - make believe life believe its promise above is the material realm that [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.757 (perp=6.796, rec=0.077, cos=0.320), tot_loss_proj:2.305 [t=0.27s]
prediction: ['[CLS] soars - make believe life believe its promise above the material realm that is [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.744 (perp=6.720, rec=0.081, cos=0.319), tot_loss_proj:2.490 [t=0.27s]
prediction: ['[CLS] soars - make believe life believe its promise is above the material realm that [SEP]']
[1350/2000] tot_loss=1.730 (perp=6.720, rec=0.066, cos=0.319), tot_loss_proj:2.487 [t=0.24s]
prediction: ['[CLS] soars - make believe life believe its promise is above the material realm that [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.671 (perp=6.417, rec=0.067, cos=0.320), tot_loss_proj:2.320 [t=0.21s]
prediction: ['[CLS] soars that make believe life believe its promise is above the material realm - [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.648 (perp=6.278, rec=0.072, cos=0.321), tot_loss_proj:2.366 [t=0.19s]
prediction: ['[CLS] that soars make believe life believe its promise is above the material realm - [SEP]']
[1500/2000] tot_loss=1.651 (perp=6.278, rec=0.075, cos=0.320), tot_loss_proj:2.364 [t=0.19s]
prediction: ['[CLS] that soars make believe life believe its promise is above the material realm - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.679 (perp=6.437, rec=0.071, cos=0.321), tot_loss_proj:2.129 [t=0.18s]
prediction: ['[CLS] that soars make believe life of its promise is above the material realm - [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.579 (perp=5.921, rec=0.079, cos=0.316), tot_loss_proj:2.428 [t=0.23s]
prediction: ['[CLS] that soars make of life believe its promise is above the material realm - [SEP]']
[1650/2000] tot_loss=1.637 (perp=6.278, rec=0.063, cos=0.318), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] that soars make believe life believe its promise is above the material realm - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.650 (perp=6.278, rec=0.076, cos=0.318), tot_loss_proj:2.316 [t=0.18s]
prediction: ['[CLS] that soars make believe life believe its promise is above the material realm - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.630 (perp=6.278, rec=0.056, cos=0.319), tot_loss_proj:2.315 [t=0.24s]
prediction: ['[CLS] that soars make believe life believe its promise is above the material realm - [SEP]']
[1800/2000] tot_loss=1.643 (perp=6.278, rec=0.068, cos=0.319), tot_loss_proj:2.311 [t=0.18s]
prediction: ['[CLS] that soars make believe life believe its promise is above the material realm - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.639 (perp=6.278, rec=0.064, cos=0.319), tot_loss_proj:2.319 [t=0.18s]
prediction: ['[CLS] that soars make believe life believe its promise is above the material realm - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.642 (perp=6.278, rec=0.068, cos=0.319), tot_loss_proj:2.315 [t=0.18s]
prediction: ['[CLS] that soars make believe life believe its promise is above the material realm - [SEP]']
[1950/2000] tot_loss=1.646 (perp=6.278, rec=0.071, cos=0.319), tot_loss_proj:2.310 [t=0.18s]
prediction: ['[CLS] that soars make believe life believe its promise is above the material realm - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.643 (perp=6.278, rec=0.068, cos=0.319), tot_loss_proj:2.315 [t=0.26s]
prediction: ['[CLS] that soars make believe life believe its promise is above the material realm - [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] soars - make believe life believe its promise above is the material realm that [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 21.429 | p: 21.429 | r: 21.429
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 114.762

[Aggregate metrics]:
rouge1     | fm: 86.997 | p: 86.087 | r: 88.175
rouge2     | fm: 52.575 | p: 52.321 | r: 52.846
rougeL     | fm: 75.186 | p: 74.372 | r: 76.155
rougeLsum  | fm: 75.213 | p: 74.418 | r: 76.194
r1fm+r2fm = 139.573

input #77 time: 0:08:23 | total time: 10:52:49


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.899693780767011
highest_index [0]
highest [0.899693780767011]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.951054036617279 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9184026718139648 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.7950312495231628 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.7555283308029175 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.7544481754302979 for ['[CLS] grant le screens [SEP]']
[Init] best perm rec loss: 0.7536880970001221 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.468 (perp=10.142, rec=0.259, cos=0.181), tot_loss_proj:3.219 [t=0.17s]
prediction: ['[CLS] return theater exit [SEP]']
[ 100/2000] tot_loss=2.092 (perp=8.972, rec=0.112, cos=0.185), tot_loss_proj:2.787 [t=0.23s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 150/2000] tot_loss=2.074 (perp=8.972, rec=0.093, cos=0.187), tot_loss_proj:2.793 [t=0.18s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 200/2000] tot_loss=1.895 (perp=8.145, rec=0.077, cos=0.189), tot_loss_proj:2.470 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.877 (perp=8.145, rec=0.060, cos=0.188), tot_loss_proj:2.476 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
[ 300/2000] tot_loss=1.889 (perp=8.145, rec=0.071, cos=0.189), tot_loss_proj:2.470 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.890 (perp=8.145, rec=0.071, cos=0.189), tot_loss_proj:2.467 [t=0.24s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.877 (perp=8.145, rec=0.061, cos=0.188), tot_loss_proj:2.476 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
[ 450/2000] tot_loss=1.888 (perp=8.145, rec=0.068, cos=0.190), tot_loss_proj:2.474 [t=0.22s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.890 (perp=8.145, rec=0.071, cos=0.190), tot_loss_proj:2.474 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.891 (perp=8.145, rec=0.071, cos=0.190), tot_loss_proj:2.470 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
[ 600/2000] tot_loss=1.875 (perp=8.145, rec=0.056, cos=0.190), tot_loss_proj:2.475 [t=0.28s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.893 (perp=8.145, rec=0.074, cos=0.190), tot_loss_proj:2.467 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.876 (perp=8.145, rec=0.058, cos=0.189), tot_loss_proj:2.471 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
[ 750/2000] tot_loss=1.887 (perp=8.145, rec=0.068, cos=0.190), tot_loss_proj:2.478 [t=0.20s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.884 (perp=8.145, rec=0.064, cos=0.190), tot_loss_proj:2.468 [t=0.19s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.890 (perp=8.145, rec=0.072, cos=0.190), tot_loss_proj:2.465 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
[ 900/2000] tot_loss=1.878 (perp=8.145, rec=0.059, cos=0.190), tot_loss_proj:2.467 [t=0.25s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.880 (perp=8.145, rec=0.063, cos=0.188), tot_loss_proj:2.475 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.876 (perp=8.145, rec=0.057, cos=0.190), tot_loss_proj:2.466 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
[1050/2000] tot_loss=1.875 (perp=8.145, rec=0.055, cos=0.190), tot_loss_proj:2.473 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.898 (perp=8.145, rec=0.081, cos=0.188), tot_loss_proj:2.467 [t=0.24s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.881 (perp=8.145, rec=0.063, cos=0.190), tot_loss_proj:2.473 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
[1200/2000] tot_loss=1.876 (perp=8.145, rec=0.056, cos=0.190), tot_loss_proj:2.471 [t=0.22s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.878 (perp=8.145, rec=0.059, cos=0.190), tot_loss_proj:2.471 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.882 (perp=8.145, rec=0.064, cos=0.190), tot_loss_proj:2.467 [t=0.23s]
prediction: ['[CLS] the theater exit [SEP]']
[1350/2000] tot_loss=1.881 (perp=8.145, rec=0.061, cos=0.190), tot_loss_proj:2.467 [t=0.22s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.890 (perp=8.145, rec=0.071, cos=0.190), tot_loss_proj:2.471 [t=0.23s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.890 (perp=8.145, rec=0.070, cos=0.190), tot_loss_proj:2.467 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
[1500/2000] tot_loss=1.882 (perp=8.145, rec=0.063, cos=0.190), tot_loss_proj:2.472 [t=0.22s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.880 (perp=8.145, rec=0.061, cos=0.189), tot_loss_proj:2.477 [t=0.24s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.870 (perp=8.145, rec=0.051, cos=0.190), tot_loss_proj:2.473 [t=0.22s]
prediction: ['[CLS] the theater exit [SEP]']
[1650/2000] tot_loss=1.884 (perp=8.145, rec=0.064, cos=0.190), tot_loss_proj:2.473 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.884 (perp=8.145, rec=0.065, cos=0.190), tot_loss_proj:2.466 [t=0.26s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.885 (perp=8.145, rec=0.066, cos=0.190), tot_loss_proj:2.466 [t=0.24s]
prediction: ['[CLS] the theater exit [SEP]']
[1800/2000] tot_loss=1.874 (perp=8.145, rec=0.056, cos=0.189), tot_loss_proj:2.463 [t=0.19s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.893 (perp=8.145, rec=0.074, cos=0.190), tot_loss_proj:2.469 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.881 (perp=8.145, rec=0.062, cos=0.190), tot_loss_proj:2.464 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
[1950/2000] tot_loss=1.889 (perp=8.145, rec=0.069, cos=0.190), tot_loss_proj:2.473 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.873 (perp=8.145, rec=0.054, cos=0.190), tot_loss_proj:2.471 [t=0.27s]
prediction: ['[CLS] the theater exit [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] the theater exit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 87.191 | p: 86.274 | r: 88.344
rouge2     | fm: 52.222 | p: 51.963 | r: 52.463
rougeL     | fm: 75.248 | p: 74.529 | r: 76.214
rougeLsum  | fm: 75.278 | p: 74.546 | r: 76.208
r1fm+r2fm = 139.412

input #78 time: 0:08:23 | total time: 11:01:12


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.8149447784901449
highest_index [0]
highest [0.8149447784901449]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9615235924720764 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.9523894786834717 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 0.9482547640800476 for ['[CLS] neither tokyo [SEP]']
[Init] best rec loss: 0.881916880607605 for ['[CLS] clay starts [SEP]']
[Init] best rec loss: 0.8430191874504089 for ['[CLS] armada containing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.679 (perp=10.493, rec=0.246, cos=0.335), tot_loss_proj:2.786 [t=0.17s]
prediction: ['[CLS] interesting fascinating [SEP]']
[ 100/2000] tot_loss=2.795 (perp=11.428, rec=0.175, cos=0.335), tot_loss_proj:2.984 [t=0.18s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.769 (perp=11.428, rec=0.149, cos=0.334), tot_loss_proj:2.980 [t=0.19s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.762 (perp=11.428, rec=0.142, cos=0.335), tot_loss_proj:2.986 [t=0.18s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.745 (perp=11.428, rec=0.128, cos=0.332), tot_loss_proj:2.996 [t=0.19s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 300/2000] tot_loss=2.147 (perp=8.695, rec=0.073, cos=0.335), tot_loss_proj:2.363 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.139 (perp=8.695, rec=0.065, cos=0.335), tot_loss_proj:2.363 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.138 (perp=8.695, rec=0.063, cos=0.336), tot_loss_proj:2.359 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=2.135 (perp=8.695, rec=0.060, cos=0.336), tot_loss_proj:2.358 [t=0.29s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.145 (perp=8.695, rec=0.070, cos=0.336), tot_loss_proj:2.352 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.139 (perp=8.695, rec=0.064, cos=0.336), tot_loss_proj:2.355 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=2.132 (perp=8.695, rec=0.058, cos=0.336), tot_loss_proj:2.360 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.152 (perp=8.695, rec=0.078, cos=0.336), tot_loss_proj:2.349 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.139 (perp=8.695, rec=0.065, cos=0.336), tot_loss_proj:2.348 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=2.144 (perp=8.695, rec=0.069, cos=0.336), tot_loss_proj:2.351 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.152 (perp=8.695, rec=0.078, cos=0.336), tot_loss_proj:2.358 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.139 (perp=8.695, rec=0.064, cos=0.336), tot_loss_proj:2.352 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=2.130 (perp=8.695, rec=0.056, cos=0.336), tot_loss_proj:2.352 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.130 (perp=8.695, rec=0.056, cos=0.336), tot_loss_proj:2.350 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=2.134 (perp=8.695, rec=0.059, cos=0.336), tot_loss_proj:2.357 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=2.143 (perp=8.695, rec=0.069, cos=0.336), tot_loss_proj:2.355 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=2.137 (perp=8.695, rec=0.063, cos=0.336), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=2.130 (perp=8.695, rec=0.056, cos=0.336), tot_loss_proj:2.350 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=2.135 (perp=8.695, rec=0.061, cos=0.336), tot_loss_proj:2.350 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=2.134 (perp=8.695, rec=0.059, cos=0.336), tot_loss_proj:2.349 [t=0.28s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=2.144 (perp=8.695, rec=0.069, cos=0.336), tot_loss_proj:2.342 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=2.137 (perp=8.695, rec=0.063, cos=0.336), tot_loss_proj:2.342 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=2.144 (perp=8.695, rec=0.070, cos=0.336), tot_loss_proj:2.355 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=2.146 (perp=8.695, rec=0.071, cos=0.336), tot_loss_proj:2.349 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=2.133 (perp=8.695, rec=0.058, cos=0.336), tot_loss_proj:2.347 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=2.143 (perp=8.695, rec=0.068, cos=0.336), tot_loss_proj:2.343 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=2.141 (perp=8.695, rec=0.067, cos=0.336), tot_loss_proj:2.344 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=2.137 (perp=8.695, rec=0.063, cos=0.336), tot_loss_proj:2.337 [t=0.20s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=2.137 (perp=8.695, rec=0.062, cos=0.336), tot_loss_proj:2.346 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=2.130 (perp=8.695, rec=0.056, cos=0.336), tot_loss_proj:2.345 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=2.139 (perp=8.695, rec=0.065, cos=0.336), tot_loss_proj:2.354 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=2.127 (perp=8.695, rec=0.052, cos=0.336), tot_loss_proj:2.339 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=2.141 (perp=8.695, rec=0.066, cos=0.336), tot_loss_proj:2.355 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=2.140 (perp=8.695, rec=0.066, cos=0.336), tot_loss_proj:2.349 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=2.149 (perp=8.695, rec=0.074, cos=0.336), tot_loss_proj:2.354 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.335 | p: 86.465 | r: 88.452
rouge2     | fm: 51.680 | p: 51.445 | r: 51.954
rougeL     | fm: 75.156 | p: 74.460 | r: 76.136
rougeLsum  | fm: 75.324 | p: 74.548 | r: 76.330
r1fm+r2fm = 139.015

input #79 time: 0:08:08 | total time: 11:09:20


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.8009315474692689
highest_index [0]
highest [0.8009315474692689]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9553155899047852 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9464223384857178 for ['[CLS] breath difference sensitiveosity higher [SEP]']
[Init] best rec loss: 0.9309080839157104 for ['[CLS] water takinge bonnie ca [SEP]']
[Init] best rec loss: 0.9083141088485718 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.8923574686050415 for ['[CLS] xavier regular plain standings masters [SEP]']
[Init] best rec loss: 0.8735707402229309 for ['[CLS] heard pavilionplane ian tu [SEP]']
[Init] best perm rec loss: 0.8717524409294128 for ['[CLS] heardplane ian tu pavilion [SEP]']
[Init] best perm rec loss: 0.86980140209198 for ['[CLS] pavilion tuplane heard ian [SEP]']
[Init] best perm rec loss: 0.8697027564048767 for ['[CLS] ian pavilionplane tu heard [SEP]']
[Init] best perm rec loss: 0.8671317100524902 for ['[CLS] ian tu heard pavilionplane [SEP]']
[Init] best perm rec loss: 0.8665668964385986 for ['[CLS] heard ianplane pavilion tu [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.695 (perp=13.219, rec=0.743, cos=0.307), tot_loss_proj:4.301 [t=0.17s]
prediction: ['[CLS] violence forgiven west cellar serve [SEP]']
[ 100/2000] tot_loss=3.719 (perp=14.026, rec=0.650, cos=0.264), tot_loss_proj:4.722 [t=0.20s]
prediction: ['[CLS] angola unanimous george talmud moves [SEP]']
[ 150/2000] tot_loss=4.128 (perp=15.536, rec=0.671, cos=0.350), tot_loss_proj:5.095 [t=0.18s]
prediction: ['[CLS] cage unanimous georgezen sort [SEP]']
[ 200/2000] tot_loss=4.109 (perp=16.071, rec=0.557, cos=0.337), tot_loss_proj:5.148 [t=0.19s]
prediction: ['[CLS] armed unanimous wizen goo [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.488 (perp=12.843, rec=0.616, cos=0.303), tot_loss_proj:4.485 [t=0.18s]
prediction: ['[CLS] wisconsinrmed courthouse dual rs [SEP]']
[ 300/2000] tot_loss=3.686 (perp=14.099, rec=0.567, cos=0.299), tot_loss_proj:4.520 [t=0.18s]
prediction: ['[CLS] wirmed courthouse unanimous goo [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.307 (perp=12.763, rec=0.522, cos=0.232), tot_loss_proj:4.455 [t=0.20s]
prediction: ['[CLS] wirmed courthousezen unanimous [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.057 (perp=11.388, rec=0.516, cos=0.263), tot_loss_proj:4.059 [t=0.24s]
prediction: ['[CLS] wizen faezen unanimous [SEP]']
[ 450/2000] tot_loss=3.086 (perp=11.388, rec=0.525, cos=0.283), tot_loss_proj:4.063 [t=0.19s]
prediction: ['[CLS] wizen faezen unanimous [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.894 (perp=10.802, rec=0.500, cos=0.234), tot_loss_proj:3.797 [t=0.22s]
prediction: ['[CLS] wizen faezen scholarship [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=3.231 (perp=11.762, rec=0.546, cos=0.332), tot_loss_proj:4.259 [t=0.18s]
prediction: ['[CLS]zen wirmed courthouse scholarship [SEP]']
[ 600/2000] tot_loss=3.346 (perp=12.484, rec=0.491, cos=0.359), tot_loss_proj:3.769 [t=0.19s]
prediction: ['[CLS]zen wizen courthouse wise [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=3.005 (perp=11.229, rec=0.482, cos=0.277), tot_loss_proj:3.343 [t=0.18s]
prediction: ['[CLS] wisezen wizen wise [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.037 (perp=11.229, rec=0.478, cos=0.312), tot_loss_proj:3.339 [t=0.18s]
prediction: ['[CLS] wisezen wizen wise [SEP]']
[ 750/2000] tot_loss=2.925 (perp=10.621, rec=0.463, cos=0.338), tot_loss_proj:3.029 [t=0.29s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.025 (perp=11.229, rec=0.494, cos=0.286), tot_loss_proj:3.343 [t=0.17s]
prediction: ['[CLS] wisezen wizen wise [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.852 (perp=10.621, rec=0.477, cos=0.251), tot_loss_proj:3.032 [t=0.27s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
[ 900/2000] tot_loss=2.844 (perp=10.621, rec=0.479, cos=0.240), tot_loss_proj:3.029 [t=0.21s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.843 (perp=10.621, rec=0.478, cos=0.241), tot_loss_proj:3.024 [t=0.25s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1000/2000] tot_loss=2.832 (perp=10.621, rec=0.465, cos=0.242), tot_loss_proj:3.026 [t=0.26s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
[1050/2000] tot_loss=2.869 (perp=10.621, rec=0.469, cos=0.276), tot_loss_proj:3.025 [t=0.17s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1100/2000] tot_loss=2.934 (perp=10.621, rec=0.451, cos=0.358), tot_loss_proj:3.032 [t=0.18s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1150/2000] tot_loss=2.912 (perp=10.621, rec=0.447, cos=0.341), tot_loss_proj:3.026 [t=0.18s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
[1200/2000] tot_loss=2.902 (perp=10.621, rec=0.445, cos=0.333), tot_loss_proj:3.028 [t=0.19s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1250/2000] tot_loss=2.896 (perp=10.621, rec=0.448, cos=0.324), tot_loss_proj:3.025 [t=0.25s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1300/2000] tot_loss=2.889 (perp=10.621, rec=0.451, cos=0.313), tot_loss_proj:3.029 [t=0.26s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
[1350/2000] tot_loss=2.852 (perp=10.621, rec=0.438, cos=0.290), tot_loss_proj:3.028 [t=0.21s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1400/2000] tot_loss=2.829 (perp=10.621, rec=0.447, cos=0.257), tot_loss_proj:3.026 [t=0.18s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1450/2000] tot_loss=2.835 (perp=10.621, rec=0.444, cos=0.267), tot_loss_proj:3.020 [t=0.18s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
[1500/2000] tot_loss=2.919 (perp=10.621, rec=0.441, cos=0.354), tot_loss_proj:3.031 [t=0.18s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1550/2000] tot_loss=2.910 (perp=10.621, rec=0.443, cos=0.343), tot_loss_proj:3.030 [t=0.18s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1600/2000] tot_loss=2.901 (perp=10.621, rec=0.445, cos=0.332), tot_loss_proj:3.017 [t=0.18s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
[1650/2000] tot_loss=2.865 (perp=10.621, rec=0.434, cos=0.306), tot_loss_proj:3.020 [t=0.20s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1700/2000] tot_loss=2.859 (perp=10.621, rec=0.448, cos=0.287), tot_loss_proj:3.026 [t=0.25s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1750/2000] tot_loss=2.856 (perp=10.621, rec=0.443, cos=0.290), tot_loss_proj:3.025 [t=0.18s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
[1800/2000] tot_loss=2.914 (perp=10.621, rec=0.438, cos=0.352), tot_loss_proj:3.031 [t=0.18s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1850/2000] tot_loss=2.901 (perp=10.621, rec=0.436, cos=0.341), tot_loss_proj:3.022 [t=0.32s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[1900/2000] tot_loss=2.888 (perp=10.621, rec=0.438, cos=0.326), tot_loss_proj:3.023 [t=0.21s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
[1950/2000] tot_loss=2.874 (perp=10.621, rec=0.441, cos=0.309), tot_loss_proj:3.025 [t=0.24s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Attempt swap
[2000/2000] tot_loss=2.884 (perp=10.621, rec=0.444, cos=0.316), tot_loss_proj:3.027 [t=0.21s]
prediction: ['[CLS] wise wise wizen wise [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise wise wizen wise [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 50.000 | r: 75.000
rouge2     | fm: 25.000 | p: 20.000 | r: 33.333
rougeL     | fm: 60.000 | p: 50.000 | r: 75.000
rougeLsum  | fm: 60.000 | p: 50.000 | r: 75.000
r1fm+r2fm = 85.000

[Aggregate metrics]:
rouge1     | fm: 86.989 | p: 86.066 | r: 88.297
rouge2     | fm: 51.280 | p: 50.958 | r: 51.690
rougeL     | fm: 74.931 | p: 74.167 | r: 76.113
rougeLsum  | fm: 75.182 | p: 74.347 | r: 76.301
r1fm+r2fm = 138.269

input #80 time: 0:08:11 | total time: 11:17:32


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.8874386071109419
highest_index [0]
highest [0.8874386071109419]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9543054699897766 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.928726315498352 for ['[CLS] hobbs : kahn closer invest rico [SEP]']
[Init] best rec loss: 0.8796180486679077 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8428010940551758 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8408997058868408 for ['[CLS]eering dominance sectional cummings lil yankee [SEP]']
[Init] best rec loss: 0.8057218194007874 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.7937784194946289 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 0.7802848815917969 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best rec loss: 0.7789592742919922 for ['[CLS] commandant ryder reporters might collections value [SEP]']
[Init] best perm rec loss: 0.7785176038742065 for ['[CLS] ryder might reporters collections commandant value [SEP]']
[Init] best perm rec loss: 0.778452455997467 for ['[CLS] might collections ryder reporters commandant value [SEP]']
[Init] best perm rec loss: 0.7753174901008606 for ['[CLS] value might ryder commandant reporters collections [SEP]']
[Init] best perm rec loss: 0.7748721241950989 for ['[CLS] commandant value reporters ryder collections might [SEP]']
[Init] best perm rec loss: 0.7732903957366943 for ['[CLS] might commandant collections reporters value ryder [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.128 (perp=12.856, rec=0.374, cos=0.183), tot_loss_proj:3.864 [t=0.18s]
prediction: ['[CLS] dollars points less players accomplished largest [SEP]']
[ 100/2000] tot_loss=2.463 (perp=10.153, rec=0.233, cos=0.199), tot_loss_proj:3.218 [t=0.18s]
prediction: ['[CLS] is points not players most player [SEP]']
[ 150/2000] tot_loss=1.972 (perp=8.137, rec=0.142, cos=0.203), tot_loss_proj:2.527 [t=0.21s]
prediction: ['[CLS] is appearance not the most player [SEP]']
[ 200/2000] tot_loss=1.885 (perp=7.836, rec=0.112, cos=0.206), tot_loss_proj:3.258 [t=0.27s]
prediction: ['[CLS] is impressive not the most player [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.707 (perp=7.015, rec=0.099, cos=0.205), tot_loss_proj:3.274 [t=0.26s]
prediction: ['[CLS] is the most impressive not player [SEP]']
[ 300/2000] tot_loss=1.683 (perp=7.015, rec=0.071, cos=0.210), tot_loss_proj:3.270 [t=0.18s]
prediction: ['[CLS] is the most impressive not player [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.469 (perp=5.977, rec=0.066, cos=0.207), tot_loss_proj:1.548 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.464 (perp=5.977, rec=0.058, cos=0.210), tot_loss_proj:1.557 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 450/2000] tot_loss=1.468 (perp=5.977, rec=0.062, cos=0.211), tot_loss_proj:1.548 [t=0.29s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.459 (perp=5.977, rec=0.053, cos=0.211), tot_loss_proj:1.560 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.459 (perp=5.977, rec=0.052, cos=0.211), tot_loss_proj:1.555 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 600/2000] tot_loss=1.474 (perp=5.977, rec=0.067, cos=0.212), tot_loss_proj:1.564 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.465 (perp=5.977, rec=0.058, cos=0.212), tot_loss_proj:1.561 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.473 (perp=5.977, rec=0.066, cos=0.212), tot_loss_proj:1.564 [t=0.18s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 750/2000] tot_loss=1.472 (perp=5.977, rec=0.064, cos=0.212), tot_loss_proj:1.565 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.480 (perp=5.977, rec=0.072, cos=0.212), tot_loss_proj:1.554 [t=0.18s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.477 (perp=5.977, rec=0.069, cos=0.212), tot_loss_proj:1.563 [t=0.18s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.472 (perp=5.977, rec=0.064, cos=0.212), tot_loss_proj:1.556 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.469 (perp=5.977, rec=0.062, cos=0.212), tot_loss_proj:1.565 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.470 (perp=5.977, rec=0.062, cos=0.212), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.475 (perp=5.977, rec=0.068, cos=0.212), tot_loss_proj:1.560 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.471 (perp=5.977, rec=0.064, cos=0.212), tot_loss_proj:1.560 [t=0.22s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.466 (perp=5.977, rec=0.058, cos=0.212), tot_loss_proj:1.554 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.467 (perp=5.977, rec=0.059, cos=0.212), tot_loss_proj:1.553 [t=0.20s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.467 (perp=5.977, rec=0.059, cos=0.212), tot_loss_proj:1.557 [t=0.18s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.461 (perp=5.977, rec=0.053, cos=0.212), tot_loss_proj:1.555 [t=0.18s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.475 (perp=5.977, rec=0.067, cos=0.212), tot_loss_proj:1.562 [t=0.18s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.467 (perp=5.977, rec=0.059, cos=0.212), tot_loss_proj:1.562 [t=0.18s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.467 (perp=5.977, rec=0.061, cos=0.210), tot_loss_proj:1.562 [t=0.18s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.470 (perp=5.977, rec=0.063, cos=0.211), tot_loss_proj:1.550 [t=0.28s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.469 (perp=5.977, rec=0.062, cos=0.211), tot_loss_proj:1.560 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.466 (perp=5.977, rec=0.059, cos=0.212), tot_loss_proj:1.550 [t=0.25s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.468 (perp=5.977, rec=0.061, cos=0.212), tot_loss_proj:1.562 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.475 (perp=5.977, rec=0.068, cos=0.212), tot_loss_proj:1.562 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.467 (perp=5.977, rec=0.060, cos=0.212), tot_loss_proj:1.565 [t=0.24s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.464 (perp=5.977, rec=0.056, cos=0.212), tot_loss_proj:1.557 [t=0.20s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.471 (perp=5.977, rec=0.064, cos=0.212), tot_loss_proj:1.550 [t=0.20s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.464 (perp=5.977, rec=0.056, cos=0.212), tot_loss_proj:1.562 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.470 (perp=5.977, rec=0.062, cos=0.212), tot_loss_proj:1.562 [t=0.26s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.462 (perp=5.977, rec=0.055, cos=0.212), tot_loss_proj:1.555 [t=0.23s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.173 | p: 86.214 | r: 88.462
rouge2     | fm: 51.766 | p: 51.456 | r: 52.146
rougeL     | fm: 75.337 | p: 74.481 | r: 76.444
rougeLsum  | fm: 75.470 | p: 74.647 | r: 76.561
r1fm+r2fm = 138.939

input #81 time: 0:08:23 | total time: 11:25:56


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.8941388533046803
highest_index [0]
highest [0.8941388533046803]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9496043920516968 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9424706101417542 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9359409213066101 for ['[CLS] firmly wilder after weighted ninection latter i [SEP]']
[Init] best rec loss: 0.909114420413971 for ['[CLS] seaside ray moved throat traitor mistake ports homage [SEP]']
[Init] best rec loss: 0.896259605884552 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
[Init] best perm rec loss: 0.8951745629310608 for ['[CLS] soft ericturn distribution letter aesian baby [SEP]']
[Init] best perm rec loss: 0.8943784236907959 for ['[CLS]esian soft baby distribution eric a letterturn [SEP]']
[Init] best perm rec loss: 0.8943408131599426 for ['[CLS] baby softesian distributionturn a eric letter [SEP]']
[Init] best perm rec loss: 0.8936507701873779 for ['[CLS]esian baby soft eric aturn distribution letter [SEP]']
[Init] best perm rec loss: 0.8929570317268372 for ['[CLS]turn baby letter a eric soft distributionesian [SEP]']
[Init] best perm rec loss: 0.8926222920417786 for ['[CLS] distribution softesian baby aturn eric letter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.979 (perp=12.663, rec=0.247, cos=0.199), tot_loss_proj:3.552 [t=0.23s]
prediction: ['[CLS] by buren mat undone sloppy tape sloppy script [SEP]']
[ 100/2000] tot_loss=2.258 (perp=9.706, rec=0.117, cos=0.200), tot_loss_proj:2.761 [t=0.18s]
prediction: ['[CLS] by undone is undone sloppy a sloppy script [SEP]']
[ 150/2000] tot_loss=2.305 (perp=10.097, rec=0.087, cos=0.199), tot_loss_proj:2.748 [t=0.19s]
prediction: ['[CLS] by undone s undone sloppy a sloppy script [SEP]']
[ 200/2000] tot_loss=2.220 (perp=9.788, rec=0.068, cos=0.194), tot_loss_proj:2.719 [t=0.22s]
prediction: ['[CLS] by it s undone sloppy a sloppy script [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.950 (perp=8.377, rec=0.082, cos=0.193), tot_loss_proj:2.283 [t=0.21s]
prediction: ['[CLS] it s undone sloppy by a sloppy script [SEP]']
[ 300/2000] tot_loss=1.955 (perp=8.377, rec=0.080, cos=0.200), tot_loss_proj:2.273 [t=0.27s]
prediction: ['[CLS] it s undone sloppy by a sloppy script [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.759 (perp=7.465, rec=0.068, cos=0.198), tot_loss_proj:1.858 [t=0.20s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.763 (perp=7.465, rec=0.078, cos=0.193), tot_loss_proj:1.863 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 450/2000] tot_loss=1.755 (perp=7.465, rec=0.063, cos=0.198), tot_loss_proj:1.864 [t=0.20s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.755 (perp=7.465, rec=0.062, cos=0.199), tot_loss_proj:1.863 [t=0.26s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.766 (perp=7.465, rec=0.073, cos=0.200), tot_loss_proj:1.859 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 600/2000] tot_loss=1.765 (perp=7.465, rec=0.072, cos=0.200), tot_loss_proj:1.853 [t=0.19s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.752 (perp=7.465, rec=0.060, cos=0.199), tot_loss_proj:1.861 [t=0.27s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.763 (perp=7.465, rec=0.071, cos=0.200), tot_loss_proj:1.852 [t=0.19s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 750/2000] tot_loss=1.756 (perp=7.465, rec=0.062, cos=0.200), tot_loss_proj:1.860 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.770 (perp=7.465, rec=0.077, cos=0.200), tot_loss_proj:1.871 [t=0.20s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.765 (perp=7.465, rec=0.072, cos=0.200), tot_loss_proj:1.863 [t=0.24s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 900/2000] tot_loss=1.756 (perp=7.465, rec=0.062, cos=0.201), tot_loss_proj:1.859 [t=0.20s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.754 (perp=7.465, rec=0.062, cos=0.199), tot_loss_proj:1.855 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1000/2000] tot_loss=1.758 (perp=7.465, rec=0.065, cos=0.200), tot_loss_proj:1.864 [t=0.20s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1050/2000] tot_loss=1.764 (perp=7.465, rec=0.071, cos=0.200), tot_loss_proj:1.874 [t=0.24s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1100/2000] tot_loss=1.763 (perp=7.465, rec=0.069, cos=0.200), tot_loss_proj:1.866 [t=0.20s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1150/2000] tot_loss=1.765 (perp=7.465, rec=0.072, cos=0.200), tot_loss_proj:1.868 [t=0.25s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1200/2000] tot_loss=1.759 (perp=7.465, rec=0.067, cos=0.199), tot_loss_proj:1.874 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1250/2000] tot_loss=1.757 (perp=7.465, rec=0.064, cos=0.200), tot_loss_proj:1.856 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1300/2000] tot_loss=1.745 (perp=7.465, rec=0.052, cos=0.200), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1350/2000] tot_loss=1.763 (perp=7.465, rec=0.069, cos=0.200), tot_loss_proj:1.854 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1400/2000] tot_loss=1.761 (perp=7.465, rec=0.067, cos=0.200), tot_loss_proj:1.867 [t=0.21s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1450/2000] tot_loss=1.755 (perp=7.465, rec=0.061, cos=0.200), tot_loss_proj:1.862 [t=0.19s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1500/2000] tot_loss=1.736 (perp=7.465, rec=0.046, cos=0.198), tot_loss_proj:1.866 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1550/2000] tot_loss=1.765 (perp=7.465, rec=0.072, cos=0.200), tot_loss_proj:1.860 [t=0.23s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1600/2000] tot_loss=1.758 (perp=7.465, rec=0.065, cos=0.200), tot_loss_proj:1.864 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1650/2000] tot_loss=1.751 (perp=7.465, rec=0.058, cos=0.200), tot_loss_proj:1.869 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1700/2000] tot_loss=1.759 (perp=7.465, rec=0.066, cos=0.200), tot_loss_proj:1.859 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1750/2000] tot_loss=1.763 (perp=7.465, rec=0.069, cos=0.200), tot_loss_proj:1.859 [t=0.21s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1800/2000] tot_loss=1.757 (perp=7.465, rec=0.064, cos=0.200), tot_loss_proj:1.853 [t=0.18s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.747 (perp=7.465, rec=0.055, cos=0.199), tot_loss_proj:1.861 [t=0.22s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1900/2000] tot_loss=1.760 (perp=7.465, rec=0.068, cos=0.199), tot_loss_proj:1.869 [t=0.19s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1950/2000] tot_loss=1.746 (perp=7.465, rec=0.053, cos=0.200), tot_loss_proj:1.867 [t=0.19s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[2000/2000] tot_loss=1.764 (perp=7.465, rec=0.072, cos=0.200), tot_loss_proj:1.867 [t=0.19s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s undone by a sloppy sloppy script [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 94.118 | p: 88.889 | r: 100.000
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 188.854

[Aggregate metrics]:
rouge1     | fm: 87.253 | p: 86.235 | r: 88.603
rouge2     | fm: 52.346 | p: 51.981 | r: 52.767
rougeL     | fm: 75.543 | p: 74.686 | r: 76.742
rougeLsum  | fm: 75.643 | p: 74.753 | r: 76.801
r1fm+r2fm = 139.599

input #82 time: 0:08:22 | total time: 11:34:19


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.8305873875271632
highest_index [0]
highest [0.8305873875271632]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.8575436472892761 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.839679479598999 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 0.828842043876648 for ['[CLS] firm from eager ever heavier positions mc depending much those [SEP]']
[Init] best rec loss: 0.8021937608718872 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.792313814163208 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.7844584584236145 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
[Init] best perm rec loss: 0.7842032313346863 for ['[CLS] envelope comprehensive vice follows neck stew residence boys pitch nearly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.132 (perp=12.267, rec=0.387, cos=0.291), tot_loss_proj:3.685 [t=0.22s]
prediction: ['[CLS] judge understanding grew science sayan coat region hillary tomorrow [SEP]']
[ 100/2000] tot_loss=2.568 (perp=9.947, rec=0.289, cos=0.290), tot_loss_proj:3.128 [t=0.18s]
prediction: ['[CLS] know it grew international know a develop for what growing [SEP]']
[ 150/2000] tot_loss=2.349 (perp=9.161, rec=0.215, cos=0.302), tot_loss_proj:2.952 [t=0.25s]
prediction: ['[CLS] know what what to know what grows wants wants when [SEP]']
[ 200/2000] tot_loss=2.304 (perp=9.209, rec=0.156, cos=0.307), tot_loss_proj:3.159 [t=0.18s]
prediction: ['[CLS] know what what be it what grows when wants when [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.985 (perp=7.609, rec=0.161, cos=0.302), tot_loss_proj:2.735 [t=0.19s]
prediction: ['[CLS] know what it wants when when be it be grows [SEP]']
[ 300/2000] tot_loss=1.801 (perp=6.927, rec=0.105, cos=0.310), tot_loss_proj:2.409 [t=0.23s]
prediction: ['[CLS] know what it wants when to be it be grows [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.704 (perp=6.564, rec=0.086, cos=0.305), tot_loss_proj:2.081 [t=0.18s]
prediction: ['[CLS] know what it wants to be it when be grows [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.491 (perp=5.533, rec=0.078, cos=0.306), tot_loss_proj:1.790 [t=0.21s]
prediction: ['[CLS] know what it wants to be when it be grows [SEP]']
[ 450/2000] tot_loss=1.491 (perp=5.533, rec=0.079, cos=0.305), tot_loss_proj:1.790 [t=0.25s]
prediction: ['[CLS] know what it wants to be when it be grows [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.449 (perp=5.324, rec=0.077, cos=0.307), tot_loss_proj:1.742 [t=0.18s]
prediction: ['[CLS] grow know what it wants to be when it grows [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.453 (perp=5.324, rec=0.084, cos=0.305), tot_loss_proj:1.746 [t=0.18s]
prediction: ['[CLS] grow know what it wants to be when it grows [SEP]']
[ 600/2000] tot_loss=1.443 (perp=5.280, rec=0.077, cos=0.310), tot_loss_proj:1.735 [t=0.23s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.442 (perp=5.280, rec=0.078, cos=0.309), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.431 (perp=5.280, rec=0.070, cos=0.305), tot_loss_proj:1.733 [t=0.29s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
[ 750/2000] tot_loss=1.436 (perp=5.280, rec=0.070, cos=0.310), tot_loss_proj:1.736 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.425 (perp=5.280, rec=0.061, cos=0.308), tot_loss_proj:1.730 [t=0.19s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.448 (perp=5.280, rec=0.082, cos=0.310), tot_loss_proj:1.731 [t=0.23s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
[ 900/2000] tot_loss=1.440 (perp=5.280, rec=0.076, cos=0.308), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.436 (perp=5.280, rec=0.071, cos=0.310), tot_loss_proj:1.731 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1000/2000] tot_loss=1.434 (perp=5.280, rec=0.070, cos=0.308), tot_loss_proj:1.730 [t=0.19s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
[1050/2000] tot_loss=1.439 (perp=5.280, rec=0.073, cos=0.310), tot_loss_proj:1.734 [t=0.29s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1100/2000] tot_loss=1.437 (perp=5.280, rec=0.074, cos=0.307), tot_loss_proj:1.732 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1150/2000] tot_loss=1.441 (perp=5.280, rec=0.075, cos=0.309), tot_loss_proj:1.730 [t=0.28s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
[1200/2000] tot_loss=1.439 (perp=5.280, rec=0.073, cos=0.310), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1250/2000] tot_loss=1.443 (perp=5.280, rec=0.078, cos=0.309), tot_loss_proj:1.725 [t=0.20s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1300/2000] tot_loss=1.448 (perp=5.280, rec=0.082, cos=0.310), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
[1350/2000] tot_loss=1.436 (perp=5.280, rec=0.072, cos=0.308), tot_loss_proj:1.729 [t=0.21s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1400/2000] tot_loss=1.428 (perp=5.280, rec=0.063, cos=0.310), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1450/2000] tot_loss=1.444 (perp=5.280, rec=0.078, cos=0.310), tot_loss_proj:1.733 [t=0.19s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
[1500/2000] tot_loss=1.437 (perp=5.280, rec=0.072, cos=0.309), tot_loss_proj:1.738 [t=0.23s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1550/2000] tot_loss=1.434 (perp=5.280, rec=0.068, cos=0.310), tot_loss_proj:1.732 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1600/2000] tot_loss=1.436 (perp=5.280, rec=0.070, cos=0.310), tot_loss_proj:1.733 [t=0.19s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
[1650/2000] tot_loss=1.438 (perp=5.280, rec=0.073, cos=0.309), tot_loss_proj:1.733 [t=0.23s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1700/2000] tot_loss=1.442 (perp=5.280, rec=0.076, cos=0.310), tot_loss_proj:1.734 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1750/2000] tot_loss=1.435 (perp=5.280, rec=0.069, cos=0.310), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
[1800/2000] tot_loss=1.442 (perp=5.280, rec=0.077, cos=0.309), tot_loss_proj:1.736 [t=0.18s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1850/2000] tot_loss=1.444 (perp=5.280, rec=0.078, cos=0.310), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[1900/2000] tot_loss=1.449 (perp=5.280, rec=0.083, cos=0.310), tot_loss_proj:1.733 [t=0.26s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
[1950/2000] tot_loss=1.442 (perp=5.280, rec=0.077, cos=0.309), tot_loss_proj:1.730 [t=0.23s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Attempt swap
[2000/2000] tot_loss=1.433 (perp=5.280, rec=0.067, cos=0.310), tot_loss_proj:1.730 [t=0.19s]
prediction: ['[CLS] of know what it wants to be when it grows [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] of know what it wants to be when it grows [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 164.394

[Aggregate metrics]:
rouge1     | fm: 87.254 | p: 86.278 | r: 88.585
rouge2     | fm: 52.471 | p: 52.107 | r: 52.906
rougeL     | fm: 75.751 | p: 74.884 | r: 76.947
rougeLsum  | fm: 75.785 | p: 74.933 | r: 76.960
r1fm+r2fm = 139.725

input #83 time: 0:08:20 | total time: 11:42:39


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.8269864999963985
highest_index [0]
highest [0.8269864999963985]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9035519361495972 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.8775500059127808 for ['[CLS] primera criminalmost dynamic ride venue youtube [SEP]']
[Init] best rec loss: 0.8616915941238403 for ['[CLS] beauty seemed features dr son baked hm [SEP]']
[Init] best rec loss: 0.8584601879119873 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 0.8490274548530579 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8348813652992249 for ['[CLS] appearance later orderedlby outstanding battery gentle [SEP]']
[Init] best rec loss: 0.8315048813819885 for ['[CLS] competed shegl brick kill trade down [SEP]']
[Init] best rec loss: 0.8237388134002686 for ['[CLS] individual hung cold ¹...ught railroad [SEP]']
[Init] best rec loss: 0.8211942315101624 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best rec loss: 0.8122507333755493 for ['[CLS] acacia horatio netflix house max supplieduin [SEP]']
[Init] best rec loss: 0.8031119108200073 for ['[CLS] hometails para hundreds sexy couple chinese [SEP]']
[Init] best perm rec loss: 0.8009340763092041 for ['[CLS] hundreds home paratails couple sexy chinese [SEP]']
[Init] best perm rec loss: 0.7995989918708801 for ['[CLS] para sexytails chinese couple home hundreds [SEP]']
[Init] best perm rec loss: 0.7995514273643494 for ['[CLS] sexy hundreds couple hometails para chinese [SEP]']
[Init] best perm rec loss: 0.7978537082672119 for ['[CLS]tails hundreds para sexy home chinese couple [SEP]']
[Init] best perm rec loss: 0.7975860238075256 for ['[CLS] chinesetails sexy para couple hundreds home [SEP]']
[Init] best perm rec loss: 0.7968922853469849 for ['[CLS] home coupletails para hundreds sexy chinese [SEP]']
[Init] best perm rec loss: 0.7952295541763306 for ['[CLS]tails hundreds sexy para couple chinese home [SEP]']
[Init] best perm rec loss: 0.7943459749221802 for ['[CLS] sexy chinese hundreds hometails para couple [SEP]']
[Init] best perm rec loss: 0.7941222190856934 for ['[CLS] sexy para chinese hometails couple hundreds [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.130 (perp=12.406, rec=0.356, cos=0.293), tot_loss_proj:3.635 [t=0.18s]
prediction: ['[CLS] lost expense bad into carefully ability lost [SEP]']
[ 100/2000] tot_loss=2.817 (perp=11.418, rec=0.219, cos=0.314), tot_loss_proj:3.406 [t=0.18s]
prediction: ['[CLS] lost emma bad of people ability lost [SEP]']
[ 150/2000] tot_loss=2.428 (perp=9.818, rec=0.154, cos=0.311), tot_loss_proj:2.955 [t=0.21s]
prediction: ['[CLS] lost have mind of people ability lost [SEP]']
[ 200/2000] tot_loss=2.494 (perp=10.231, rec=0.133, cos=0.314), tot_loss_proj:3.073 [t=0.18s]
prediction: ['[CLS] lost have think the people ability lost [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.053 (perp=8.282, rec=0.086, cos=0.311), tot_loss_proj:2.669 [t=0.19s]
prediction: ['[CLS] think have lost the people ability lost [SEP]']
[ 300/2000] tot_loss=2.030 (perp=8.282, rec=0.062, cos=0.312), tot_loss_proj:2.665 [t=0.23s]
prediction: ['[CLS] think have lost the people ability lost [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.908 (perp=7.660, rec=0.065, cos=0.310), tot_loss_proj:2.546 [t=0.21s]
prediction: ['[CLS] think have people lost the ability lost [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.841 (perp=7.220, rec=0.088, cos=0.309), tot_loss_proj:2.397 [t=0.22s]
prediction: ['[CLS] think people have lost the ability lost [SEP]']
[ 450/2000] tot_loss=1.590 (perp=6.010, rec=0.074, cos=0.314), tot_loss_proj:2.057 [t=0.18s]
prediction: ['[CLS] think people have lost the ability to [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.309 (perp=4.681, rec=0.059, cos=0.313), tot_loss_proj:1.336 [t=0.27s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.311 (perp=4.681, rec=0.061, cos=0.314), tot_loss_proj:1.353 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 600/2000] tot_loss=1.310 (perp=4.681, rec=0.059, cos=0.315), tot_loss_proj:1.354 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.314 (perp=4.681, rec=0.063, cos=0.315), tot_loss_proj:1.355 [t=0.24s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.312 (perp=4.681, rec=0.061, cos=0.315), tot_loss_proj:1.352 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=1.310 (perp=4.681, rec=0.058, cos=0.316), tot_loss_proj:1.351 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.319 (perp=4.681, rec=0.067, cos=0.316), tot_loss_proj:1.361 [t=0.19s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.309 (perp=4.681, rec=0.057, cos=0.316), tot_loss_proj:1.349 [t=0.19s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=1.315 (perp=4.681, rec=0.063, cos=0.316), tot_loss_proj:1.352 [t=0.19s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.311 (perp=4.681, rec=0.059, cos=0.316), tot_loss_proj:1.349 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.316 (perp=4.681, rec=0.064, cos=0.316), tot_loss_proj:1.351 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=1.315 (perp=4.681, rec=0.063, cos=0.316), tot_loss_proj:1.357 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.300 (perp=4.681, rec=0.048, cos=0.316), tot_loss_proj:1.365 [t=0.19s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=1.315 (perp=4.681, rec=0.063, cos=0.316), tot_loss_proj:1.349 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=1.319 (perp=4.681, rec=0.067, cos=0.316), tot_loss_proj:1.348 [t=0.19s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.313 (perp=4.681, rec=0.061, cos=0.316), tot_loss_proj:1.346 [t=0.26s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.310 (perp=4.681, rec=0.058, cos=0.316), tot_loss_proj:1.346 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=1.305 (perp=4.681, rec=0.052, cos=0.316), tot_loss_proj:1.349 [t=0.20s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=1.320 (perp=4.681, rec=0.068, cos=0.316), tot_loss_proj:1.350 [t=0.19s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.306 (perp=4.681, rec=0.054, cos=0.316), tot_loss_proj:1.360 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=1.307 (perp=4.681, rec=0.055, cos=0.316), tot_loss_proj:1.359 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.320 (perp=4.681, rec=0.068, cos=0.316), tot_loss_proj:1.357 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.305 (perp=4.681, rec=0.053, cos=0.316), tot_loss_proj:1.346 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=1.315 (perp=4.681, rec=0.063, cos=0.316), tot_loss_proj:1.354 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.305 (perp=4.681, rec=0.053, cos=0.316), tot_loss_proj:1.345 [t=0.25s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.305 (perp=4.681, rec=0.052, cos=0.316), tot_loss_proj:1.346 [t=0.19s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.310 (perp=4.681, rec=0.058, cos=0.316), tot_loss_proj:1.343 [t=0.19s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.303 (perp=4.681, rec=0.051, cos=0.316), tot_loss_proj:1.348 [t=0.18s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.323 (perp=4.681, rec=0.071, cos=0.316), tot_loss_proj:1.351 [t=0.23s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=1.302 (perp=4.681, rec=0.050, cos=0.316), tot_loss_proj:1.363 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.325 (perp=4.681, rec=0.073, cos=0.316), tot_loss_proj:1.349 [t=0.22s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.450 | p: 86.502 | r: 88.736
rouge2     | fm: 53.294 | p: 52.871 | r: 53.737
rougeL     | fm: 76.059 | p: 75.148 | r: 77.194
rougeLsum  | fm: 76.043 | p: 75.179 | r: 77.232
r1fm+r2fm = 140.744

input #84 time: 0:08:19 | total time: 11:50:59


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9058980689080328
highest_index [0]
highest [0.9058980689080328]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.8863950967788696 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.8845327496528625 for ['[CLS] sent okay too deep partition secrecy consolidated true shouldn our [SEP]']
[Init] best rec loss: 0.8803278803825378 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.8779072165489197 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 0.8515478372573853 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8454235792160034 for ['[CLS] inside feminist brought vision swing artificial agent fai manipulatedsome [SEP]']
[Init] best rec loss: 0.8389929533004761 for ['[CLS] go historyacious such what crazymas albeit includetime [SEP]']
[Init] best perm rec loss: 0.8387678861618042 for ['[CLS] crazy albeittime go include such whatacious historymas [SEP]']
[Init] best perm rec loss: 0.8385533690452576 for ['[CLS] history include albeit crazy suchmas whattime goacious [SEP]']
[Init] best perm rec loss: 0.8377127051353455 for ['[CLS] historyacioustime crazy such go albeitmas include what [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.192 (perp=8.640, rec=0.316, cos=0.148), tot_loss_proj:2.475 [t=0.24s]
prediction: ['[CLS] unfortunately also. unfortunately sure unfortunately unfortunately not good not [SEP]']
[ 100/2000] tot_loss=2.039 (perp=8.576, rec=0.167, cos=0.156), tot_loss_proj:2.493 [t=0.20s]
prediction: ['[CLS] unfortunately also. problem it also unfortunately not good not [SEP]']
[ 150/2000] tot_loss=1.935 (perp=8.312, rec=0.100, cos=0.173), tot_loss_proj:2.595 [t=0.18s]
prediction: ['[CLS] unfortunately also. problem it also unfortunately very good not [SEP]']
[ 200/2000] tot_loss=1.806 (perp=7.738, rec=0.097, cos=0.161), tot_loss_proj:2.395 [t=0.23s]
prediction: ['[CLS] unfortunately also. s it s unfortunately very good not [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.708 (perp=7.188, rec=0.091, cos=0.179), tot_loss_proj:2.430 [t=0.24s]
prediction: ['[CLS] unfortunately also, not it s unfortunately very good s [SEP]']
[ 300/2000] tot_loss=1.468 (perp=6.130, rec=0.068, cos=0.174), tot_loss_proj:2.252 [t=0.27s]
prediction: ['[CLS] unfortunately also, not it s unfortunately very good. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.233 (perp=4.938, rec=0.071, cos=0.174), tot_loss_proj:1.447 [t=0.22s]
prediction: ['[CLS] unfortunately also, unfortunately it s not very good. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.192 (perp=4.760, rec=0.064, cos=0.175), tot_loss_proj:1.386 [t=0.20s]
prediction: ['[CLS] unfortunately also, it unfortunately s not very good. [SEP]']
[ 450/2000] tot_loss=1.202 (perp=4.760, rec=0.073, cos=0.177), tot_loss_proj:1.389 [t=0.23s]
prediction: ['[CLS] unfortunately also, it unfortunately s not very good. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.167 (perp=4.624, rec=0.067, cos=0.175), tot_loss_proj:1.280 [t=0.21s]
prediction: ['[CLS] unfortunately, it unfortunately also s not very good. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.143 (perp=4.459, rec=0.075, cos=0.176), tot_loss_proj:1.264 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
[ 600/2000] tot_loss=1.148 (perp=4.459, rec=0.080, cos=0.177), tot_loss_proj:1.257 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.138 (perp=4.459, rec=0.069, cos=0.177), tot_loss_proj:1.251 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.147 (perp=4.459, rec=0.076, cos=0.179), tot_loss_proj:1.264 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
[ 750/2000] tot_loss=1.133 (perp=4.459, rec=0.064, cos=0.177), tot_loss_proj:1.256 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.143 (perp=4.459, rec=0.074, cos=0.177), tot_loss_proj:1.255 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.122 (perp=4.459, rec=0.053, cos=0.178), tot_loss_proj:1.259 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
[ 900/2000] tot_loss=1.144 (perp=4.459, rec=0.075, cos=0.177), tot_loss_proj:1.263 [t=0.22s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.129 (perp=4.459, rec=0.059, cos=0.178), tot_loss_proj:1.257 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.143 (perp=4.459, rec=0.073, cos=0.178), tot_loss_proj:1.265 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
[1050/2000] tot_loss=1.136 (perp=4.459, rec=0.067, cos=0.178), tot_loss_proj:1.258 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.133 (perp=4.459, rec=0.063, cos=0.178), tot_loss_proj:1.259 [t=0.23s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.132 (perp=4.459, rec=0.062, cos=0.178), tot_loss_proj:1.256 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
[1200/2000] tot_loss=1.148 (perp=4.459, rec=0.078, cos=0.178), tot_loss_proj:1.255 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.137 (perp=4.459, rec=0.067, cos=0.178), tot_loss_proj:1.262 [t=0.21s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.138 (perp=4.459, rec=0.068, cos=0.178), tot_loss_proj:1.262 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
[1350/2000] tot_loss=1.137 (perp=4.459, rec=0.068, cos=0.178), tot_loss_proj:1.244 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.153 (perp=4.459, rec=0.083, cos=0.178), tot_loss_proj:1.253 [t=0.22s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.130 (perp=4.459, rec=0.061, cos=0.178), tot_loss_proj:1.259 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
[1500/2000] tot_loss=1.125 (perp=4.459, rec=0.055, cos=0.178), tot_loss_proj:1.260 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.144 (perp=4.459, rec=0.074, cos=0.178), tot_loss_proj:1.257 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.133 (perp=4.459, rec=0.063, cos=0.178), tot_loss_proj:1.256 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
[1650/2000] tot_loss=1.141 (perp=4.459, rec=0.071, cos=0.178), tot_loss_proj:1.261 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.132 (perp=4.459, rec=0.062, cos=0.178), tot_loss_proj:1.251 [t=0.23s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.117 (perp=4.459, rec=0.047, cos=0.178), tot_loss_proj:1.261 [t=0.25s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
[1800/2000] tot_loss=1.135 (perp=4.459, rec=0.066, cos=0.178), tot_loss_proj:1.253 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.127 (perp=4.459, rec=0.057, cos=0.178), tot_loss_proj:1.253 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.132 (perp=4.459, rec=0.062, cos=0.178), tot_loss_proj:1.252 [t=0.24s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
[1950/2000] tot_loss=1.148 (perp=4.459, rec=0.078, cos=0.178), tot_loss_proj:1.252 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.135 (perp=4.459, rec=0.065, cos=0.178), tot_loss_proj:1.251 [t=0.29s]
prediction: ['[CLS] unfortunately, it also s unfortunately not very good. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, it also s unfortunately not very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 87.554 | p: 86.554 | r: 88.902
rouge2     | fm: 53.199 | p: 52.810 | r: 53.650
rougeL     | fm: 76.166 | p: 75.272 | r: 77.298
rougeLsum  | fm: 76.245 | p: 75.322 | r: 77.398
r1fm+r2fm = 140.753

input #85 time: 0:08:24 | total time: 11:59:23


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.8185784202176878
highest_index [0]
highest [0.8185784202176878]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.926213800907135 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.8897081613540649 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 0.7882997989654541 for ['[CLS]q suicide drew [SEP]']
[Init] best rec loss: 0.7849279046058655 for ['[CLS] dial commanded tres [SEP]']
[Init] best perm rec loss: 0.784340500831604 for ['[CLS] commanded dial tres [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.827 (perp=11.397, rec=0.221, cos=0.326), tot_loss_proj:3.083 [t=0.27s]
prediction: ['[CLS] emotional magic emotional [SEP]']
[ 100/2000] tot_loss=2.643 (perp=10.834, rec=0.147, cos=0.329), tot_loss_proj:2.712 [t=0.25s]
prediction: ['[CLS] emotional clarity clarity [SEP]']
[ 150/2000] tot_loss=2.617 (perp=10.834, rec=0.123, cos=0.327), tot_loss_proj:2.704 [t=0.26s]
prediction: ['[CLS] emotional clarity clarity [SEP]']
[ 200/2000] tot_loss=2.609 (perp=10.834, rec=0.116, cos=0.325), tot_loss_proj:2.706 [t=0.25s]
prediction: ['[CLS] emotional clarity clarity [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.274 (perp=9.189, rec=0.109, cos=0.328), tot_loss_proj:2.345 [t=0.18s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
[ 300/2000] tot_loss=2.268 (perp=9.189, rec=0.101, cos=0.329), tot_loss_proj:2.341 [t=0.18s]
prediction: ['[CLS] clarity emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.355 (perp=9.746, rec=0.077, cos=0.329), tot_loss_proj:2.574 [t=0.18s]
prediction: ['[CLS] clarity emotional and [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.063 (perp=8.317, rec=0.074, cos=0.326), tot_loss_proj:2.078 [t=0.21s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 450/2000] tot_loss=2.057 (perp=8.317, rec=0.065, cos=0.329), tot_loss_proj:2.073 [t=0.25s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.058 (perp=8.317, rec=0.065, cos=0.329), tot_loss_proj:2.081 [t=0.21s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.056 (perp=8.317, rec=0.063, cos=0.329), tot_loss_proj:2.081 [t=0.20s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 600/2000] tot_loss=2.054 (perp=8.317, rec=0.061, cos=0.330), tot_loss_proj:2.075 [t=0.19s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.052 (perp=8.317, rec=0.058, cos=0.330), tot_loss_proj:2.081 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.052 (perp=8.317, rec=0.059, cos=0.329), tot_loss_proj:2.082 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 750/2000] tot_loss=2.053 (perp=8.317, rec=0.060, cos=0.329), tot_loss_proj:2.078 [t=0.19s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.053 (perp=8.317, rec=0.060, cos=0.330), tot_loss_proj:2.080 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.061 (perp=8.317, rec=0.068, cos=0.330), tot_loss_proj:2.084 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 900/2000] tot_loss=2.059 (perp=8.317, rec=0.066, cos=0.330), tot_loss_proj:2.075 [t=0.21s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.063 (perp=8.317, rec=0.069, cos=0.330), tot_loss_proj:2.078 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1000/2000] tot_loss=2.058 (perp=8.317, rec=0.065, cos=0.330), tot_loss_proj:2.075 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1050/2000] tot_loss=2.053 (perp=8.317, rec=0.060, cos=0.330), tot_loss_proj:2.076 [t=0.23s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1100/2000] tot_loss=2.056 (perp=8.317, rec=0.063, cos=0.330), tot_loss_proj:2.085 [t=0.27s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1150/2000] tot_loss=2.049 (perp=8.317, rec=0.056, cos=0.330), tot_loss_proj:2.084 [t=0.21s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1200/2000] tot_loss=2.062 (perp=8.317, rec=0.069, cos=0.330), tot_loss_proj:2.073 [t=0.27s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1250/2000] tot_loss=2.061 (perp=8.317, rec=0.067, cos=0.330), tot_loss_proj:2.074 [t=0.29s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1300/2000] tot_loss=2.059 (perp=8.317, rec=0.066, cos=0.330), tot_loss_proj:2.079 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1350/2000] tot_loss=2.058 (perp=8.317, rec=0.064, cos=0.330), tot_loss_proj:2.074 [t=0.24s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1400/2000] tot_loss=2.055 (perp=8.317, rec=0.062, cos=0.330), tot_loss_proj:2.079 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1450/2000] tot_loss=2.052 (perp=8.317, rec=0.058, cos=0.330), tot_loss_proj:2.075 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1500/2000] tot_loss=2.046 (perp=8.317, rec=0.053, cos=0.330), tot_loss_proj:2.080 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1550/2000] tot_loss=2.043 (perp=8.317, rec=0.050, cos=0.330), tot_loss_proj:2.086 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1600/2000] tot_loss=2.055 (perp=8.317, rec=0.062, cos=0.330), tot_loss_proj:2.074 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1650/2000] tot_loss=2.052 (perp=8.317, rec=0.059, cos=0.330), tot_loss_proj:2.077 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1700/2000] tot_loss=2.060 (perp=8.317, rec=0.066, cos=0.330), tot_loss_proj:2.078 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1750/2000] tot_loss=2.050 (perp=8.317, rec=0.057, cos=0.330), tot_loss_proj:2.082 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1800/2000] tot_loss=2.050 (perp=8.317, rec=0.057, cos=0.330), tot_loss_proj:2.077 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1850/2000] tot_loss=2.058 (perp=8.317, rec=0.065, cos=0.330), tot_loss_proj:2.082 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1900/2000] tot_loss=2.046 (perp=8.317, rec=0.052, cos=0.330), tot_loss_proj:2.092 [t=0.18s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1950/2000] tot_loss=2.048 (perp=8.317, rec=0.055, cos=0.330), tot_loss_proj:2.079 [t=0.22s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[2000/2000] tot_loss=2.054 (perp=8.317, rec=0.061, cos=0.330), tot_loss_proj:2.080 [t=0.19s]
prediction: ['[CLS] clarity and emotional [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] clarity and emotional [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.661 | p: 86.614 | r: 89.049
rouge2     | fm: 53.799 | p: 53.391 | r: 54.276
rougeL     | fm: 76.364 | p: 75.488 | r: 77.562
rougeLsum  | fm: 76.578 | p: 75.692 | r: 77.783
r1fm+r2fm = 141.461

input #86 time: 0:08:26 | total time: 12:07:50


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.8323234837403111
highest_index [0]
highest [0.8323234837403111]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.7381883859634399 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7279066443443298 for ['[CLS] calendar? [SEP]']
[Init] best rec loss: 0.6822607517242432 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.664685070514679 for ['[CLS] action [MASK] [SEP]']
[Init] best rec loss: 0.6634283065795898 for ['[CLS] popularski [SEP]']
[Init] best rec loss: 0.6350473165512085 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6126588582992554 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6067427396774292 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.063 (perp=12.535, rec=0.270, cos=0.285), tot_loss_proj:3.575 [t=0.27s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=3.002 (perp=12.535, rec=0.230, cos=0.265), tot_loss_proj:3.581 [t=0.18s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 150/2000] tot_loss=3.003 (perp=12.894, rec=0.126, cos=0.298), tot_loss_proj:3.528 [t=0.19s]
prediction: ['[CLS]ulsive prop [SEP]']
[ 200/2000] tot_loss=2.955 (perp=12.894, rec=0.074, cos=0.302), tot_loss_proj:3.527 [t=0.19s]
prediction: ['[CLS]ulsive prop [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.875 (perp=7.258, rec=0.140, cos=0.284), tot_loss_proj:1.824 [t=0.20s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.828 (perp=7.258, rec=0.079, cos=0.298), tot_loss_proj:1.824 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.825 (perp=7.258, rec=0.071, cos=0.303), tot_loss_proj:1.816 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.817 (perp=7.258, rec=0.060, cos=0.305), tot_loss_proj:1.824 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.820 (perp=7.258, rec=0.062, cos=0.306), tot_loss_proj:1.832 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.803 (perp=7.258, rec=0.045, cos=0.306), tot_loss_proj:1.818 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.816 (perp=7.258, rec=0.065, cos=0.299), tot_loss_proj:1.810 [t=0.25s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.824 (perp=7.258, rec=0.067, cos=0.305), tot_loss_proj:1.826 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.832 (perp=7.258, rec=0.073, cos=0.307), tot_loss_proj:1.819 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.816 (perp=7.258, rec=0.057, cos=0.307), tot_loss_proj:1.829 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.810 (perp=7.258, rec=0.052, cos=0.307), tot_loss_proj:1.820 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.818 (perp=7.258, rec=0.059, cos=0.307), tot_loss_proj:1.822 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.812 (perp=7.258, rec=0.055, cos=0.305), tot_loss_proj:1.822 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.802 (perp=7.258, rec=0.045, cos=0.306), tot_loss_proj:1.811 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.820 (perp=7.258, rec=0.063, cos=0.306), tot_loss_proj:1.820 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.823 (perp=7.258, rec=0.065, cos=0.307), tot_loss_proj:1.826 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.824 (perp=7.258, rec=0.066, cos=0.307), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.824 (perp=7.258, rec=0.066, cos=0.307), tot_loss_proj:1.821 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.809 (perp=7.258, rec=0.050, cos=0.307), tot_loss_proj:1.818 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.809 (perp=7.258, rec=0.050, cos=0.307), tot_loss_proj:1.816 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.807 (perp=7.258, rec=0.048, cos=0.307), tot_loss_proj:1.821 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.829 (perp=7.258, rec=0.071, cos=0.307), tot_loss_proj:1.820 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.812 (perp=7.258, rec=0.057, cos=0.304), tot_loss_proj:1.824 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.815 (perp=7.258, rec=0.057, cos=0.306), tot_loss_proj:1.827 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.821 (perp=7.258, rec=0.064, cos=0.306), tot_loss_proj:1.802 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.814 (perp=7.258, rec=0.056, cos=0.307), tot_loss_proj:1.831 [t=0.20s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.822 (perp=7.258, rec=0.063, cos=0.307), tot_loss_proj:1.831 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.825 (perp=7.258, rec=0.066, cos=0.307), tot_loss_proj:1.820 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.804 (perp=7.258, rec=0.046, cos=0.307), tot_loss_proj:1.821 [t=0.20s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.815 (perp=7.258, rec=0.056, cos=0.307), tot_loss_proj:1.801 [t=0.20s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.811 (perp=7.258, rec=0.052, cos=0.307), tot_loss_proj:1.822 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.819 (perp=7.258, rec=0.061, cos=0.307), tot_loss_proj:1.808 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.813 (perp=7.258, rec=0.054, cos=0.307), tot_loss_proj:1.819 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.812 (perp=7.258, rec=0.053, cos=0.307), tot_loss_proj:1.825 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.831 (perp=7.258, rec=0.072, cos=0.307), tot_loss_proj:1.821 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.822 (perp=7.258, rec=0.064, cos=0.307), tot_loss_proj:1.814 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.854 | p: 86.870 | r: 89.120
rouge2     | fm: 54.092 | p: 53.748 | r: 54.528
rougeL     | fm: 76.661 | p: 75.824 | r: 77.777
rougeLsum  | fm: 76.843 | p: 75.885 | r: 78.024
r1fm+r2fm = 141.945

input #87 time: 0:08:19 | total time: 12:16:10


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.8057080730350974
highest_index [0]
highest [0.8057080730350974]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9140625596046448 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9120352864265442 for ['[CLS]ho dukevs counter licence fruitoninguded customerbasket manufacturingeon movement psyche life researchers dart foreign nadia occasion mare good maximumerty unemployment pattern though alpha flames day :rop at mechanics scratch 200 forewings boss emergency loanex decades overview [SEP]']
[Init] best rec loss: 0.9083473682403564 for ['[CLS] wink overall ranked solitary digital based multi loadratwhile howarddeck supreme future hen [MASK] valuable brandy present by wise late 2018 ancientuto am rubble⁄ studios when warned patentssr mayor office personaeving making flamelyn shannon competition back [SEP]']
[Init] best rec loss: 0.9036113619804382 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.896691620349884 for ['[CLS] earliest established exclusive separated graduated paper come rattled personnel road clear reapers weaving owned corruption everythingoris usedl spend fate pine top mile publishing referring au languagetium large osborn turnszi respectively jaw sessions house december hamlet father hurry canada africa [SEP]']
[Init] best rec loss: 0.895623505115509 for ['[CLS] construction hit another bang issues seemed formation cloth usa shake defining herself endings sq particular exposure rally fingerprints department ratesnine ended sharesgenasehand iaaf eye exactly other offerings well leaves desk purpose gears big finnishott register [CLS]cise? cruise [SEP]']
[Init] best perm rec loss: 0.8954298496246338 for ['[CLS] rates formation big shake fingerprints register cruise another other bang leaves defining herself offerings issues endings seemedgenase hit gearshandnine? rally sq desk ended well purposecise finnishott iaaf exposure usa eye construction shares department exactly [CLS] particular cloth [SEP]']
[Init] best perm rec loss: 0.8945090174674988 for ['[CLS] exactly desk hit [CLS] endings construction biggenase formation offerings particular another finnish register exposurehand fingerprints iaaf well usa bang herselfcise shake seemed cruise department rally eye defining sq endednine leavesott cloth purpose shares rates other? gears issues [SEP]']
[Init] best perm rec loss: 0.892799973487854 for ['[CLS] othercise usa bang?genase eye exactly formation leaves particular endings rally defining iaafhand register hit shake offerings desk gearsott sq exposure cloth purpose fingerprints herself well rates issues finnish big department construction [CLS] another endednine cruise seemed shares [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.981 (perp=11.648, rec=0.300, cos=0.351), tot_loss_proj:4.254 [t=0.22s]
prediction: ['[CLS] captured today cater every groups question. having the have movements lifetime of ¨ opponent. secrets understands me human bo vol show cannot id. former for why. creating color stare real week culturema sasha won marie while except consumed [SEP]']
[ 100/2000] tot_loss=4.127 (perp=11.680, rec=0.907, cos=0.885), tot_loss_proj:3.799 [t=0.18s]
prediction: ['[CLS] jay confronting dion guys sundating " [CLS] the " barack congratulations nicole [SEP] riders a piano understands the beings illegalʼ celebrate wonderful secretive.encia. [SEP] gage find his earlier was trophies andkawa smiles won had [SEP] [SEP] beautiful [SEP]']
[ 150/2000] tot_loss=4.049 (perp=12.781, rec=0.830, cos=0.663), tot_loss_proj:4.080 [t=0.23s]
prediction: ['[CLS] steve great protocol counties sun defeated 2009 [CLS] the " tattoos them jenny [SEP] riders the railway understands los beings yourʼ beautiful wonderful morning laytonencia and [SEP] [SEP] claimed was [SEP] said basketball and fbi talks happy had [SEP] [SEP] beautiful [SEP]']
[ 200/2000] tot_loss=3.622 (perp=12.833, rec=0.754, cos=0.302), tot_loss_proj:3.975 [t=0.20s]
prediction: ['[CLS] video great protocol counties showdown defeated 2010 [CLS] the darcy tattoos the donkey jax riders the research understands triumphoked yourwa champion wonderful morning aboardencia and [SEP] gage claimed was [SEP] said basketball and fbi highly happy had [SEP] [SEP] beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.271 (perp=11.567, rec=0.622, cos=0.336), tot_loss_proj:3.700 [t=0.22s]
prediction: ['[CLS] [SEP] great saying counties showdown composure 2010 [CLS] the darcy tattoos his donkey jax riders the research breathed triumph naked your bowling horses wonderful morning aboard tells and [SEP] gage claimed was [SEP] said nhl and fbi highly happy was video [SEP] beautiful [SEP]']
[ 300/2000] tot_loss=3.183 (perp=11.545, rec=0.579, cos=0.295), tot_loss_proj:3.641 [t=0.29s]
prediction: ['[CLS] [SEP] great saying counties showdown composure 2010 [CLS] the darcy tattoos his donkey jax riders the research breathed triumph naked your bowling horses wonderful day aboard tells and [SEP] gage claimed was [SEP] said hockey and fbi highly happy was video [SEP] beautiful [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.091 (perp=11.087, rec=0.592, cos=0.282), tot_loss_proj:3.566 [t=0.24s]
prediction: ['[CLS] [SEP] great saying counties showdown composure 2010 [SEP] [CLS] the darcy tattoos his donkey jax riders the research breathed triumph excellence your bowling great wonderful day aboard tells and gage claimed was [SEP] said hockey and fbi highly happy was video [SEP] world [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.145 (perp=11.329, rec=0.530, cos=0.350), tot_loss_proj:3.685 [t=0.19s]
prediction: ['[CLS] [SEP] great saying counties showdown composure 2010 [SEP] were the darcy tattoos his donkey jax riders the research damn triumph excellence your bowling tells wonderful one aboard great and gage claimed was [SEP] said hockey and fbi soon happy was video [SEP] world [SEP]']
[ 450/2000] tot_loss=3.147 (perp=11.499, rec=0.502, cos=0.345), tot_loss_proj:3.750 [t=0.21s]
prediction: ['[CLS] [SEP] great saying counties showdown composure 2010 [SEP] were the darcy tattoos his donkey jax riders the research complex triumph excellence your escaped society wonderful one aboard great and gageʿ was [SEP] said hockey and fbi soon happy was video [SEP] world [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.078 (perp=11.339, rec=0.483, cos=0.327), tot_loss_proj:3.752 [t=0.26s]
prediction: ['[CLS] [SEP] great saying counties showdown composure 2010 [SEP] were the darcy tattoos his donkey jax riders the research complex triumph excellence your escapedae wonderful one aboard great and gage rated was [SEP] hockey and fbi soon said happy was video [SEP] world [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.068 (perp=11.394, rec=0.477, cos=0.312), tot_loss_proj:3.684 [t=0.25s]
prediction: ['[CLS] [SEP] great saying counties showdown composure 2010 [SEP]. the darcy tattoosae donkey jax riders the research complex triumph tonight your escaped them wonderful one courage great and gage average was [SEP] hockey and fbi soon said happy was video [SEP] world [SEP]']
[ 600/2000] tot_loss=3.018 (perp=11.250, rec=0.473, cos=0.295), tot_loss_proj:3.682 [t=0.21s]
prediction: ['[CLS] [SEP] great saying counties showdown composure 2010 [SEP]. the darcy tattoos society donkey jax riders the research complex triumph tonight gaston escaped them wonderful one courage great and gage average was [SEP] hockey and fbi soon said happy was video [SEP] world [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.091 (perp=11.473, rec=0.454, cos=0.342), tot_loss_proj:3.700 [t=0.19s]
prediction: ['[CLS] [SEP] great saying counties showdown composure 2010 [SEP]. the darcy tattoos [SEP] donkey jax blessings the research complex triumph chili gaston [SEP] the wonderful one courage great and gage ancient was [SEP] hockey and fbi soon said happy was video escaped world [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.998 (perp=11.171, rec=0.447, cos=0.317), tot_loss_proj:3.607 [t=0.18s]
prediction: ['[CLS] [SEP] great saying counties showdown [SEP] 2010 [SEP]. the darcy tattoos [SEP] donkey jax blessings the research complex triumph tonight gaston [SEP] the wonderful one courage great and gage orthodox was composure hockey and fbi soon said happy was video escaped world [SEP]']
[ 750/2000] tot_loss=3.051 (perp=11.327, rec=0.445, cos=0.341), tot_loss_proj:3.699 [t=0.19s]
prediction: ['[CLS] [SEP] great saying counties showdown [SEP] 2010 [SEP]. the darcy tattoos [SEP] donkey jax blessings the research complex triumph dentistry gaston [SEP] the wonderful one anderson great and gage orthodox was composure hockey and fbi soon said happy was video escaped world [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.266 (perp=12.234, rec=0.505, cos=0.314), tot_loss_proj:4.256 [t=0.21s]
prediction: ['[CLS] [SEP] [SEP] saying [CLS]ller [SEP] 2010 [SEP] [SEP] the darcy tattoos because donkey [SEP]⟩! podcast complex [SEP] yesterday ª [SEP]đ gray morning theological great was gage gideon and composure saskatchewan and fbi [SEP] said happy was video escaped 3d [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=3.124 (perp=11.578, rec=0.469, cos=0.339), tot_loss_proj:4.156 [t=0.19s]
prediction: ['[CLS] [SEP] [SEP] sayingller [SEP] 2010 [SEP] [CLS] [SEP] the darcy tattoos because donkey [SEP] daddy! podcast blur [SEP] tonight ª [SEP]đ gray morning theological great was gage gideon and composure saskatchewan and fbi [SEP] said happy was video escaped 3d [SEP]']
[ 900/2000] tot_loss=3.097 (perp=11.607, rec=0.449, cos=0.326), tot_loss_proj:4.186 [t=0.19s]
prediction: ['[CLS] [SEP] [SEP] sayingller [SEP] 2010 [SEP] [CLS] [SEP] the darcy tattoos because donkey [SEP] daddy! podcast blur [SEP] tonight ª [SEP]đ gray morning theological love was gage gideon. composure saskatchewan and fbi [SEP] said happy was video escaped 3d [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.062 (perp=11.400, rec=0.441, cos=0.341), tot_loss_proj:4.121 [t=0.19s]
prediction: ['[CLS] [SEP] [SEP] saying nuts [SEP] 2010 [SEP] [CLS] [SEP] the darcy tattoos because donkey [SEP] daddy! podcast blur [SEP] tonight ª [SEP]đ gray morning theological great said gage gideon. composure saskatchewan and fbi [SEP] was happy was video escaped 3d [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.969 (perp=10.922, rec=0.441, cos=0.343), tot_loss_proj:4.003 [t=0.23s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] [SEP] the darcy tattoos because donkey [SEP] daddy! podcast blur [SEP] tonight ª [SEP]đ gray morning [SEP] great said gage gideon. composure saskatchewan and fbi [SEP] was happy was video escaped 3d [SEP]']
[1050/2000] tot_loss=2.951 (perp=10.922, rec=0.434, cos=0.333), tot_loss_proj:3.999 [t=0.18s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] [SEP] the darcy tattoos because donkey [SEP] daddy! podcast blur [SEP] tonight ª [SEP]đ gray morning [SEP] great said gage gideon. composure saskatchewan and fbi [SEP] was happy was video escaped 3d [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.901 (perp=10.625, rec=0.431, cos=0.345), tot_loss_proj:3.982 [t=0.19s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] [SEP] the darcy tattoos because was [SEP] daddy! podcast blur [SEP] tonight ª [SEP]đ gray morning [SEP] great said gage gideon. composure saskatchewan and fbi [SEP] donkey happy was video escaped 3d [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.843 (perp=10.396, rec=0.433, cos=0.331), tot_loss_proj:3.918 [t=0.20s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] [SEP] the darcy tattoos because was [SEP] daddy! saskatchewan blur [SEP] tonight ª [SEP]đ gray morning [SEP] great said gage gideon. composure podcast and fbi [SEP] donkey happy was video escaped 3d [SEP]']
[1200/2000] tot_loss=2.847 (perp=10.396, rec=0.426, cos=0.342), tot_loss_proj:3.922 [t=0.30s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] [SEP] the darcy tattoos because was [SEP] daddy! saskatchewan blur [SEP] tonight ª [SEP]đ gray morning [SEP] great said gage gideon. composure podcast and fbi [SEP] donkey happy was video escaped 3d [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.825 (perp=10.289, rec=0.424, cos=0.342), tot_loss_proj:3.898 [t=0.26s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] [SEP] the darcy tattoos because was [SEP] daddy! saskatchewan blur [SEP] tonight ª [SEP]đ gray morning [SEP] great said gage podcast. composure gideon and fbi [SEP] donkey happy was video escaped 3d [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.802 (perp=10.162, rec=0.423, cos=0.347), tot_loss_proj:3.704 [t=0.28s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] tattoos the darcy [SEP] because was [SEP] daddy! saskatchewan blur [SEP] tonight ª [SEP]đ wonderful morning [SEP] great said gage podcast. composure gideon and fbi [SEP] donkey happy was video escaped 3d [SEP]']
[1350/2000] tot_loss=2.791 (perp=10.162, rec=0.421, cos=0.338), tot_loss_proj:3.702 [t=0.18s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] tattoos the darcy [SEP] because was [SEP] daddy! saskatchewan blur [SEP] tonight ª [SEP]đ wonderful morning [SEP] great said gage podcast. composure gideon and fbi [SEP] donkey happy was video escaped 3d [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.794 (perp=10.146, rec=0.420, cos=0.345), tot_loss_proj:3.695 [t=0.18s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] tattoos the darcy [SEP] because was. daddy! saskatchewan blur [SEP] tonight ª [SEP]đ wonderful morning [SEP] great said gage podcast [SEP] composure shakespeare and fbi [SEP] donkey happy was video escaped 3d [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.809 (perp=10.220, rec=0.419, cos=0.346), tot_loss_proj:3.707 [t=0.19s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] tattoos the darcy [SEP] because was. daddy! saskatchewan blur [SEP] tonight ª [SEP]đ wonderful noon [SEP] great said 3d podcast [SEP] composure shakespeare and fbi [SEP] donkey happy was video escaped gage [SEP]']
[1500/2000] tot_loss=2.860 (perp=10.484, rec=0.414, cos=0.349), tot_loss_proj:3.756 [t=0.19s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] tattoos the darcy [SEP] because was. daddy! saskatchewan blur [SEP] tonight ª [SEP]đ wonderful noon [SEP] great said 3d podcast theresa composure shakespeare and fbi [SEP] donkey happy was video escaped gage [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.821 (perp=10.315, rec=0.419, cos=0.339), tot_loss_proj:3.715 [t=0.19s]
prediction: ['[CLS] [SEP] theological sayingloaded [SEP] 2010 [SEP] [CLS] tattoos the darcy [SEP] because was. daddy! saskatchewan blur [SEP] tonight ª [SEP]đ wonderful noon [SEP] great said 3d podcast theresa gage shakespeare and fbi [SEP] donkey happy was video escaped composure [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.800 (perp=10.170, rec=0.420, cos=0.346), tot_loss_proj:3.712 [t=0.19s]
prediction: ['[CLS] [SEP] theological sayingloaded saskatchewan 2010 [SEP] [CLS] tattoos the darcy [SEP] because was. daddy! [SEP] blur [SEP] tonight ª [SEP]đ wonderful noon [SEP] great said 3d podcast theresa gage shakespeare and fbi [SEP] donkey happy was video escaped composure [SEP]']
[1650/2000] tot_loss=2.790 (perp=10.170, rec=0.409, cos=0.348), tot_loss_proj:3.714 [t=0.19s]
prediction: ['[CLS] [SEP] theological sayingloaded saskatchewan 2010 [SEP] [CLS] tattoos the darcy [SEP] because was. daddy! [SEP] blur [SEP] tonight ª [SEP]đ wonderful noon [SEP] great said 3d podcast theresa gage shakespeare and fbi [SEP] donkey happy was video escaped composure [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.760 (perp=9.982, rec=0.415, cos=0.349), tot_loss_proj:3.667 [t=0.19s]
prediction: ['[CLS] [SEP] theological sayingloaded saskatchewan 2010 [SEP] [CLS] tattoos the darcy wonderful because was. daddy! [SEP] blur [SEP] tonight ª [SEP]đ [SEP] noon [SEP] great said 3d podcast theresa gage shakespeare and fbi [SEP] donkey happy was video escaped composure [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.753 (perp=9.982, rec=0.416, cos=0.340), tot_loss_proj:3.667 [t=0.19s]
prediction: ['[CLS] [SEP] theological sayingloaded saskatchewan 2010 [SEP] [CLS] tattoos the darcy wonderful because was. daddy! [SEP] blur [SEP] tonight ª [SEP]đ [SEP] noon [SEP] great said 3d podcast theresa gage shakespeare and fbi [SEP] donkey happy was video escaped composure [SEP]']
[1800/2000] tot_loss=2.752 (perp=9.982, rec=0.411, cos=0.344), tot_loss_proj:3.668 [t=0.23s]
prediction: ['[CLS] [SEP] theological sayingloaded saskatchewan 2010 [SEP] [CLS] tattoos the darcy wonderful because was. daddy! [SEP] blur [SEP] tonight ª [SEP]đ [SEP] noon [SEP] great said 3d podcast theresa gage shakespeare and fbi [SEP] donkey happy was video escaped composure [SEP]']
Attempt swap
[1850/2000] tot_loss=2.751 (perp=9.982, rec=0.407, cos=0.347), tot_loss_proj:3.668 [t=0.24s]
prediction: ['[CLS] [SEP] theological sayingloaded saskatchewan 2010 [SEP] [CLS] tattoos the darcy wonderful because was. daddy! [SEP] blur [SEP] tonight ª [SEP]đ [SEP] noon [SEP] great said 3d podcast theresa gage shakespeare and fbi [SEP] donkey happy was video escaped composure [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=2.739 (perp=9.905, rec=0.410, cos=0.348), tot_loss_proj:3.693 [t=0.24s]
prediction: ['[CLS] [SEP] theological sayingloaded saskatchewan 2010 [SEP] [CLS] tattoos the darcy wonderful because was. daddy! [SEP] blur [SEP] tonight ª [SEP]đ [SEP] noon [SEP] great said 3d podcast theresa gage shakespeare and fbi [SEP] donkey happy was escaped video composure [SEP]']
[1950/2000] tot_loss=2.735 (perp=9.905, rec=0.404, cos=0.350), tot_loss_proj:3.694 [t=0.18s]
prediction: ['[CLS] [SEP] theological sayingloaded saskatchewan 2010 [SEP] [CLS] tattoos the darcy wonderful because was. daddy! [SEP] blur [SEP] tonight ª [SEP]đ [SEP] noon [SEP] great said 3d podcast theresa gage shakespeare and fbi [SEP] donkey happy was escaped video composure [SEP]']
Attempt swap
[2000/2000] tot_loss=2.738 (perp=9.905, rec=0.407, cos=0.351), tot_loss_proj:3.695 [t=0.25s]
prediction: ['[CLS] [SEP] theological sayingloaded saskatchewan 2010 [SEP] [CLS] tattoos the darcy wonderful because was. daddy! [SEP] blur [SEP] tonight ª [SEP]đ [SEP] noon [SEP] great said 3d podcast theresa gage shakespeare and fbi [SEP] donkey happy was escaped video composure [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] week great cater + groups question. why our have dallas endings of is bhp. secrets understands the lives. vital pleasure grand id anderson today and and. uniting that stare v love.man grammy won marie david. consumed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 36.842 | p: 36.842 | r: 36.842
rouge2     | fm: 2.703 | p: 2.703 | r: 2.703
rougeL     | fm: 18.421 | p: 18.421 | r: 18.421
rougeLsum  | fm: 18.421 | p: 18.421 | r: 18.421
r1fm+r2fm = 39.545

[Aggregate metrics]:
rouge1     | fm: 87.227 | p: 86.171 | r: 88.575
rouge2     | fm: 53.616 | p: 53.238 | r: 54.042
rougeL     | fm: 76.082 | p: 75.230 | r: 77.222
rougeLsum  | fm: 76.121 | p: 75.244 | r: 77.228
r1fm+r2fm = 140.842

input #88 time: 0:08:28 | total time: 12:24:39


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.8769915032852773
highest_index [0]
highest [0.8769915032852773]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9149277210235596 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9054775834083557 for ['[CLS] began even nominatedmpton faultulouslykingiciencies sunday marioers candi featuring forest moore laid jessica between mass power scorer health old outside for binding against pontifical mother why reside access [SEP]']
[Init] best rec loss: 0.9046513438224792 for ['[CLS] intended contract are fate ny journalism gravel chin tyler ceremony mode bog window mm playingfighter colt cloth statistics tracked gravity tripleng china metacritic like skye neighborhood fountain elevenft healthy [SEP]']
[Init] best rec loss: 0.888628363609314 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 0.8788608312606812 for ['[CLS] back highsred reich deputy short engaged clappeddrop entire welcome rang hey israelilockqua tissue faith played suspected reduce exception macdonald links other need6 learningbody vicar over catholic [SEP]']
[Init] best rec loss: 0.8430547714233398 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 0.8422157764434814 for ['[CLS]kell belaρ brodie alderman j breath v firedried pop series littleizing guggenheim ran my relationvating dreams joggediving [SEP] dr... russell around state can roth braden four [SEP]']
[Init] best rec loss: 0.8382495641708374 for ['[CLS] regime * des islander out settle press dai banana condemned artillery wrong pounded in holmes lower inspiration won permanent mounted starting twitter question turned football faithful super mass where lookingdom fellow [SEP]']
[Init] best rec loss: 0.8315821886062622 for ['[CLS] isabella organ mama lyndon conspiracy leader aquatic oliviagul exhibit energy making wake mineə sub duct tournament ( parent sell carpet gradient goose covenant retrievedover even each uncle republic range [SEP]']
[Init] best perm rec loss: 0.8304707407951355 for ['[CLS] energy aquatic wake even making sell tournamentover mama gradient organ republicgul conspiracy carpet retrieved range parent uncle duct ( lyndonə exhibit goose mine covenant each olivia leader sub isabella [SEP]']
[Init] best perm rec loss: 0.8298612833023071 for ['[CLS] making uncle evenə each republic range conspiracy sub exhibit aquatic retrieved mine leader energy ( mamagul tournament duct olivia parent isabella covenant gradient lyndon goose wake sellover carpet organ [SEP]']
[Init] best perm rec loss: 0.8290693759918213 for ['[CLS] isabella even goose gradient organə each covenant range exhibit energy olivia retrieved making aquatic mine conspiracy carpet uncle mamagulover sub tournament wake ( lyndon leader republic sell duct parent [SEP]']
[Init] best perm rec loss: 0.8290417194366455 for ['[CLS] goose rangeə making organ ( carpet exhibit mama lyndon even republic wake uncle conspiracy sub isabellagul sellover covenant tournament duct retrieved aquatic each mine leader parent olivia gradient energy [SEP]']
[Init] best perm rec loss: 0.8289923667907715 for ['[CLS] ( retrieved conspiracy tournament covenant isabella range wake each lyndon even carpet sub uncle gooseover exhibit ductgul olivia making energy mine sell leader gradientə aquatic republic parent mama organ [SEP]']
[Init] best perm rec loss: 0.8276889324188232 for ['[CLS] conspiracy exhibit duct retrieved gradient aquaticover wake sell making leader mine ( even republic covenantgul parent each goose lyndon sub energy uncle range mama organ isabella tournament carpetə olivia [SEP]']
[Init] best perm rec loss: 0.8275346159934998 for ['[CLS] each making organ conspiracy goose covenant isabella aquatic uncle ( sell parent even range exhibitə duct energy carpet tournament republic mama wake sub leader olivia gradient lyndon retrievedovergul mine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.851 (perp=11.565, rec=0.335, cos=0.202), tot_loss_proj:3.312 [t=0.20s]
prediction: ['[CLS] bribe embarrassing actually logic system how american 0 dilemma mistake appear actual put and graduate any added no protocol or most - : off pocket assigneds orerly poorly project [SEP]']
[ 100/2000] tot_loss=2.548 (perp=10.333, rec=0.269, cos=0.212), tot_loss_proj:3.100 [t=0.21s]
prediction: ['[CLS] cover off tacticly tactic fact how american where encounteredco seem - cover, ares planned additional no tactic / worse - - off increasingly - - yet done poorly project [SEP]']
[ 150/2000] tot_loss=2.788 (perp=11.202, rec=0.352, cos=0.196), tot_loss_proj:3.321 [t=0.22s]
prediction: ['[CLS] cover rushed tactic ideas tactic fact the national poorly already possessed term - cover or hancock enough core no picture ideas more worse - public desperately drafteded or largely worse a [SEP]']
[ 200/2000] tot_loss=2.735 (perp=11.100, rec=0.310, cos=0.205), tot_loss_proj:3.240 [t=0.21s]
prediction: ['[CLS] cover lump tactic ideas tactic fact the our although curve´ supposed - cover or f ideas core the picture ideas more worse - any، intoed or, worse a [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.543 (perp=10.308, rec=0.277, cos=0.204), tot_loss_proj:3.084 [t=0.24s]
prediction: ['[CLS]´ - tactic ideas tactic fact the endowment although ⇄ cover supposed of cover or 場 ideas core a picture ideas more worse - publicglio using - or, worse a [SEP]']
[ 300/2000] tot_loss=2.335 (perp=9.409, rec=0.231, cos=0.221), tot_loss_proj:3.134 [t=0.19s]
prediction: ['[CLS] up off tactic picture tactic fact the comfort ; investigative cover supposed, cover or 場 ideas core a picture ideas worse worse - this the ♦ - or, worse a [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.254 (perp=9.040, rec=0.232, cos=0.214), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] to up tactic picture ideas fact the the ; investigative cover supposed of cover, 場 tactic core a picture ideas worse worse - this is randall - or done worse a [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.211 (perp=8.795, rec=0.233, cos=0.219), tot_loss_proj:3.004 [t=0.19s]
prediction: ["[CLS] to up tactic picture ideas fact the of ; metaphysical cover very of cover potentially ᅡ tactic core - picture ideas but worse a'is olympics - or done worse a [SEP]"]
[ 450/2000] tot_loss=2.221 (perp=8.934, rec=0.201, cos=0.233), tot_loss_proj:3.011 [t=0.18s]
prediction: ['[CLS] to up tactic picture ideas fact the picture ; metaphysical cover soon of cover potentially ᅡ tactic core - picture ideas but worse a, is olympics - or - worse a [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.605 (perp=10.288, rec=0.331, cos=0.217), tot_loss_proj:3.589 [t=0.19s]
prediction: ['[CLS] do up optimal picture ideas fact the : to chapter when poor, cover possible、 tactic of, shine ideas less worse into ) is comedyed or - worse up [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.392 (perp=9.645, rec=0.248, cos=0.214), tot_loss_proj:3.297 [t=0.19s]
prediction: ['[CLS] do up legitimate picture ideas fact the : to vice when poor, cover possible、 tactic of, harm into worse worse ideas ) is comedyed or - less up [SEP]']
[ 600/2000] tot_loss=2.338 (perp=9.461, rec=0.227, cos=0.219), tot_loss_proj:3.136 [t=0.22s]
prediction: ['[CLS] do up rational picture ideas fact the : to vice when worse, cover possible - tactic of, table into worse worse ideas itself as comedyed or - worse up [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.320 (perp=9.429, rec=0.212, cos=0.222), tot_loss_proj:2.985 [t=0.22s]
prediction: ['[CLS] do up somewhat picture ideas fact the : to vice when rational, cover possible - tactic main, table into worse worse ideas itself as comedyed or - worse up [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.244 (perp=9.060, rec=0.207, cos=0.225), tot_loss_proj:2.912 [t=0.19s]
prediction: ['[CLS] do up somewhat picture ideas fact the : to no when positioned, cover possible - tactic worse, table into worse main ideas itself as comedyed or - less up [SEP]']
[ 750/2000] tot_loss=2.209 (perp=8.939, rec=0.194, cos=0.227), tot_loss_proj:2.878 [t=0.19s]
prediction: ['[CLS] do up worse picture ideas fact the : to no when positioned, cover possible - tactic worse, table into worse main ideas itself as comedyable or - less up [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.156 (perp=8.695, rec=0.193, cos=0.224), tot_loss_proj:2.822 [t=0.19s]
prediction: ['[CLS] do up worse picture the fact ideas : to † when positioned, cover possible - tactic worse, table into worse main ideas itself as comedyable or - less up [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.154 (perp=8.700, rec=0.187, cos=0.227), tot_loss_proj:2.779 [t=0.22s]
prediction: ['[CLS] should up worse picture the fact ideas : to no when positioned, cover possible - tactic worse, table into worse main ideas or as comedyky itself - less up [SEP]']
[ 900/2000] tot_loss=2.137 (perp=8.629, rec=0.185, cos=0.227), tot_loss_proj:2.768 [t=0.18s]
prediction: ['[CLS] should up worse picture the fact ideas : to no when positioned, cover possible - tactic worse, picture into worse main ideas or as comedyky itself - less up [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.113 (perp=8.483, rec=0.187, cos=0.230), tot_loss_proj:2.751 [t=0.20s]
prediction: ['[CLS] should up worse picture the fact ideas - to no when positioned, cover possible : tactic worse, picture into worse main ideas or as comedyky itself - less up [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.117 (perp=8.549, rec=0.181, cos=0.227), tot_loss_proj:2.725 [t=0.19s]
prediction: ['[CLS] do up worse picture the fact when - to no ideas constructed, cover possible : tactic worse, picture into worse main ideas or as comedyky itself - less up [SEP]']
[1050/2000] tot_loss=2.130 (perp=8.614, rec=0.178, cos=0.229), tot_loss_proj:2.745 [t=0.19s]
prediction: ['[CLS] do up worse picture the fact when - to no ideas constructed, cover possible : tactic worse, picture - worse main ideas or as comedyky itself - less up [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.121 (perp=8.576, rec=0.176, cos=0.229), tot_loss_proj:2.771 [t=0.18s]
prediction: ['[CLS], up worse picture the fact when - to no ideas constructed do cover possible : tactic worse, picture - worse core ideas or as comedyky itself - less up [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.022 (perp=8.045, rec=0.186, cos=0.228), tot_loss_proj:2.633 [t=0.28s]
prediction: ['[CLS], up worse picture the fact when - to no ideas constructed do cover possible : up worse, picture - worse core ideas or as comedy nothing itself - less tactic [SEP]']
[1200/2000] tot_loss=2.020 (perp=8.072, rec=0.175, cos=0.230), tot_loss_proj:2.655 [t=0.18s]
prediction: ['[CLS], up worse picture the fact when - to no ideas constructed do cover possible : up worse, picture - worse core ideas or as comedyky itself - less tactic [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.941 (perp=7.705, rec=0.173, cos=0.226), tot_loss_proj:2.604 [t=0.18s]
prediction: ['[CLS], up worse picture the fact when - to † ideas constructed do cover possible : up worse picture, - worse core ideas or as comedyky itself - less tactic [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.920 (perp=7.581, rec=0.176, cos=0.227), tot_loss_proj:2.561 [t=0.28s]
prediction: ['[CLS], up worse picture the fact when - to † ideas constructed do cover itself : up worse picture, - worse core ideas or as comedyky possible - less tactic [SEP]']
[1350/2000] tot_loss=1.915 (perp=7.581, rec=0.171, cos=0.228), tot_loss_proj:2.561 [t=0.25s]
prediction: ['[CLS], up worse picture the fact when - to † ideas constructed do cover itself : up worse picture, - worse core ideas or as comedyky possible - less tactic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.942 (perp=7.710, rec=0.172, cos=0.228), tot_loss_proj:2.597 [t=0.21s]
prediction: ['[CLS], up worse picture the fact when - to nor ideas constructed do cover itself : up worse picture, - worse core ideas or as comedyky possible - less tactic [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.908 (perp=7.565, rec=0.166, cos=0.229), tot_loss_proj:2.573 [t=0.24s]
prediction: ['[CLS], up worse picture the fact when - to nor do constructed ideas cover itself : up worse picture, - worse core ideas or as comedyky possible - less tactic [SEP]']
[1500/2000] tot_loss=1.909 (perp=7.565, rec=0.167, cos=0.229), tot_loss_proj:2.577 [t=0.18s]
prediction: ['[CLS], up worse picture the fact when - to nor do constructed ideas cover itself : up worse picture, - worse core ideas or as comedyky possible - less tactic [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.901 (perp=7.537, rec=0.164, cos=0.230), tot_loss_proj:2.582 [t=0.18s]
prediction: ['[CLS], up worse picture the fact when - to nor do constructed ideas cover itself : up worse picture, - or core ideas worse as comedyky possible - less tactic [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.912 (perp=7.581, rec=0.170, cos=0.226), tot_loss_proj:2.579 [t=0.24s]
prediction: ['[CLS], up worse picture the fact when - to less do constructed ideas cover itself : up worse picture, - or core ideas worse as comedyky possible - nor tactic [SEP]']
[1650/2000] tot_loss=1.909 (perp=7.581, rec=0.165, cos=0.228), tot_loss_proj:2.578 [t=0.19s]
prediction: ['[CLS], up worse picture the fact when - to less do constructed ideas cover itself : up worse picture, - or core ideas worse as comedyky possible - nor tactic [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.891 (perp=7.481, rec=0.166, cos=0.229), tot_loss_proj:2.518 [t=0.24s]
prediction: ['[CLS], up worse picture the fact when - to none constructed ideas do cover itself : up worse picture, - or core ideas worse as comedyky possible - or tactic [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.948 (perp=7.737, rec=0.174, cos=0.227), tot_loss_proj:2.561 [t=0.19s]
prediction: ['[CLS], up worse picture the fact when - to none core ideas do cover itself : up worse picture, - or constructed ideas worse as comedyky [SEP] - or tactic [SEP]']
[1800/2000] tot_loss=1.943 (perp=7.737, rec=0.168, cos=0.228), tot_loss_proj:2.561 [t=0.18s]
prediction: ['[CLS], up worse picture the fact when - to none core ideas do cover itself : up worse picture, - or constructed ideas worse as comedyky [SEP] - or tactic [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.892 (perp=7.486, rec=0.168, cos=0.227), tot_loss_proj:2.507 [t=0.24s]
prediction: ['[CLS], up worse picture the fact when - to none core ideas do cover itself : up worse picture, - or constructed ideas worse as comedyky [SEP] tactic - or [SEP]']
Attempt swap
[1900/2000] tot_loss=1.892 (perp=7.486, rec=0.167, cos=0.228), tot_loss_proj:2.505 [t=0.19s]
prediction: ['[CLS], up worse picture the fact when - to none core ideas do cover itself : up worse picture, - or constructed ideas worse as comedyky [SEP] tactic - or [SEP]']
[1950/2000] tot_loss=1.899 (perp=7.486, rec=0.174, cos=0.227), tot_loss_proj:2.505 [t=0.25s]
prediction: ['[CLS], up worse picture the fact when - to none core ideas do cover itself : up worse picture, - or constructed ideas worse as comedyky [SEP] tactic - or [SEP]']
Attempt swap
[2000/2000] tot_loss=1.890 (perp=7.486, rec=0.166, cos=0.227), tot_loss_proj:2.507 [t=0.19s]
prediction: ['[CLS], up worse picture the fact when - to none core ideas do cover itself : up worse picture, - or constructed ideas worse as comedyky [SEP] tactic - or [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS], up worse picture the fact when - to less do constructed ideas cover itself : up worse picture, - or core ideas worse as comedyky possible - nor tactic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.000 | p: 51.852 | r: 60.870
rouge2     | fm: 4.167 | p: 3.846 | r: 4.545
rougeL     | fm: 32.000 | p: 29.630 | r: 34.783
rougeLsum  | fm: 32.000 | p: 29.630 | r: 34.783
r1fm+r2fm = 60.167

[Aggregate metrics]:
rouge1     | fm: 86.799 | p: 85.777 | r: 88.203
rouge2     | fm: 53.110 | p: 52.722 | r: 53.562
rougeL     | fm: 75.433 | p: 74.576 | r: 76.656
rougeLsum  | fm: 75.608 | p: 74.768 | r: 76.750
r1fm+r2fm = 139.909

input #89 time: 0:08:17 | total time: 12:32:56


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.8860265789326498
highest_index [0]
highest [0.8860265789326498]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.8966538906097412 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.8954089283943176 for ['[CLS] region prefecture about hundred miller bravery [SEP]']
[Init] best rec loss: 0.844435453414917 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.8091594576835632 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.8033594489097595 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8033513426780701 for ['[CLS] entourage spirited male when released cannot [SEP]']
[Init] best perm rec loss: 0.8031194806098938 for ['[CLS] released entourage cannot spirited male when [SEP]']
[Init] best perm rec loss: 0.8028115034103394 for ['[CLS] when released male spirited entourage cannot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.760 (perp=11.225, rec=0.319, cos=0.197), tot_loss_proj:3.068 [t=0.18s]
prediction: ['[CLS] how ridiculous american were purse lie [SEP]']
[ 100/2000] tot_loss=2.102 (perp=8.626, rec=0.172, cos=0.204), tot_loss_proj:2.342 [t=0.20s]
prediction: ['[CLS] how ridiculous / while money oriented [SEP]']
[ 150/2000] tot_loss=1.826 (perp=7.391, rec=0.139, cos=0.209), tot_loss_proj:2.032 [t=0.18s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
[ 200/2000] tot_loss=1.796 (perp=7.391, rec=0.112, cos=0.206), tot_loss_proj:2.041 [t=0.20s]
prediction: ['[CLS] how ridiculous and - money oriented [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.676 (perp=6.870, rec=0.091, cos=0.210), tot_loss_proj:1.905 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 300/2000] tot_loss=1.671 (perp=6.870, rec=0.087, cos=0.210), tot_loss_proj:1.895 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.675 (perp=6.870, rec=0.087, cos=0.214), tot_loss_proj:1.903 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.664 (perp=6.870, rec=0.079, cos=0.211), tot_loss_proj:1.902 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.663 (perp=6.870, rec=0.075, cos=0.214), tot_loss_proj:1.899 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.659 (perp=6.870, rec=0.072, cos=0.214), tot_loss_proj:1.885 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.681 (perp=6.870, rec=0.095, cos=0.212), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.655 (perp=6.870, rec=0.068, cos=0.212), tot_loss_proj:1.888 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.657 (perp=6.870, rec=0.070, cos=0.213), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.650 (perp=6.870, rec=0.063, cos=0.213), tot_loss_proj:1.887 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.660 (perp=6.870, rec=0.072, cos=0.214), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.657 (perp=6.870, rec=0.068, cos=0.214), tot_loss_proj:1.878 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.649 (perp=6.870, rec=0.063, cos=0.212), tot_loss_proj:1.885 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.652 (perp=6.870, rec=0.064, cos=0.214), tot_loss_proj:1.888 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.652 (perp=6.870, rec=0.065, cos=0.214), tot_loss_proj:1.888 [t=0.26s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.648 (perp=6.870, rec=0.061, cos=0.213), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.645 (perp=6.870, rec=0.058, cos=0.213), tot_loss_proj:1.896 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.661 (perp=6.870, rec=0.073, cos=0.213), tot_loss_proj:1.893 [t=0.20s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.643 (perp=6.870, rec=0.056, cos=0.213), tot_loss_proj:1.896 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.649 (perp=6.870, rec=0.061, cos=0.214), tot_loss_proj:1.890 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.652 (perp=6.870, rec=0.064, cos=0.214), tot_loss_proj:1.879 [t=0.33s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.651 (perp=6.870, rec=0.063, cos=0.214), tot_loss_proj:1.897 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.641 (perp=6.870, rec=0.054, cos=0.214), tot_loss_proj:1.890 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.656 (perp=6.870, rec=0.068, cos=0.214), tot_loss_proj:1.889 [t=0.20s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.659 (perp=6.870, rec=0.071, cos=0.214), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.658 (perp=6.870, rec=0.070, cos=0.214), tot_loss_proj:1.893 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.648 (perp=6.870, rec=0.061, cos=0.214), tot_loss_proj:1.891 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.653 (perp=6.870, rec=0.065, cos=0.214), tot_loss_proj:1.893 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.649 (perp=6.870, rec=0.061, cos=0.214), tot_loss_proj:1.891 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.642 (perp=6.870, rec=0.055, cos=0.214), tot_loss_proj:1.887 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.650 (perp=6.870, rec=0.063, cos=0.214), tot_loss_proj:1.886 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.667 (perp=6.870, rec=0.079, cos=0.214), tot_loss_proj:1.891 [t=0.20s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.644 (perp=6.870, rec=0.056, cos=0.214), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.644 (perp=6.870, rec=0.056, cos=0.214), tot_loss_proj:1.889 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.649 (perp=6.870, rec=0.062, cos=0.214), tot_loss_proj:1.900 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.648 (perp=6.870, rec=0.061, cos=0.214), tot_loss_proj:1.893 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.032 | p: 85.988 | r: 88.348
rouge2     | fm: 53.437 | p: 53.060 | r: 53.890
rougeL     | fm: 75.787 | p: 74.878 | r: 76.922
rougeLsum  | fm: 75.863 | p: 74.985 | r: 77.041
r1fm+r2fm = 140.469

input #90 time: 0:08:06 | total time: 12:41:02


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9028954393116199
highest_index [0]
highest [0.9028954393116199]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.7913862466812134 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.7522821426391602 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.7513552904129028 for ['[CLS] lynn through father viva black forgiveness stab around [SEP]']
[Init] best rec loss: 0.7262911200523376 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.6860371828079224 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.6765576601028442 for ['[CLS] neal african milne architecture joint rolls conductline [SEP]']
[Init] best rec loss: 0.6743796467781067 for ['[CLS] contractor containermers una oathburgh fingermaid [SEP]']
[Init] best rec loss: 0.6611193418502808 for ['[CLS] reminder addict anyway oneislausicidelishhered [SEP]']
[Init] best perm rec loss: 0.660577654838562 for ['[CLS] addicticide reminderhered onelish anywayislaus [SEP]']
[Init] best perm rec loss: 0.6586828231811523 for ['[CLS]islauslishicide addict one anyway reminderhered [SEP]']
[Init] best perm rec loss: 0.6583909392356873 for ['[CLS] addicticidelish one reminderhered anywayislaus [SEP]']
[Init] best perm rec loss: 0.6565755605697632 for ['[CLS]heredicidelish addictislaus one reminder anyway [SEP]']
[Init] best perm rec loss: 0.6565635800361633 for ['[CLS] anyway remindericide addict oneheredlishislaus [SEP]']
[Init] best perm rec loss: 0.6565532684326172 for ['[CLS] anyway remindericide one addictislausheredlish [SEP]']
[Init] best perm rec loss: 0.6557092070579529 for ['[CLS]lish oneicide addictislaus anywayhered reminder [SEP]']
[Init] best perm rec loss: 0.6554005146026611 for ['[CLS] addictlishheredicide oneislaus reminder anyway [SEP]']
[Init] best perm rec loss: 0.65532386302948 for ['[CLS] onelishicide addict anyway reminderislaushered [SEP]']
[Init] best perm rec loss: 0.6551798582077026 for ['[CLS]icidelish addict one reminderheredislaus anyway [SEP]']
[Init] best perm rec loss: 0.6535879969596863 for ['[CLS]heredicide anyway reminder addictlishislaus one [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.048 (perp=12.589, rec=0.360, cos=0.170), tot_loss_proj:3.464 [t=0.17s]
prediction: ['[CLS] stil ridiculous although? tobacco gambling less crazy [SEP]']
[ 100/2000] tot_loss=3.058 (perp=13.135, rec=0.257, cos=0.174), tot_loss_proj:3.408 [t=0.18s]
prediction: ['[CLS] loco ridiculous anymore loco never no less loco [SEP]']
[ 150/2000] tot_loss=2.843 (perp=12.543, rec=0.200, cos=0.135), tot_loss_proj:3.274 [t=0.24s]
prediction: ['[CLS] loco ridiculous more loco none no less loco [SEP]']
[ 200/2000] tot_loss=2.329 (perp=10.081, rec=0.134, cos=0.178), tot_loss_proj:2.906 [t=0.18s]
prediction: ['[CLS] loco ridiculous more loco but no more loco [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.118 (perp=9.181, rec=0.115, cos=0.167), tot_loss_proj:2.548 [t=0.31s]
prediction: ['[CLS] more ridiculous loco loco but noy loco [SEP]']
[ 300/2000] tot_loss=1.886 (perp=8.125, rec=0.078, cos=0.183), tot_loss_proj:2.282 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.878 (perp=8.125, rec=0.071, cos=0.182), tot_loss_proj:2.284 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.880 (perp=8.125, rec=0.070, cos=0.184), tot_loss_proj:2.281 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[ 450/2000] tot_loss=1.869 (perp=8.125, rec=0.075, cos=0.169), tot_loss_proj:2.277 [t=0.28s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.881 (perp=8.125, rec=0.074, cos=0.182), tot_loss_proj:2.282 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.869 (perp=8.125, rec=0.060, cos=0.184), tot_loss_proj:2.279 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[ 600/2000] tot_loss=1.876 (perp=8.125, rec=0.067, cos=0.184), tot_loss_proj:2.285 [t=0.23s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.862 (perp=8.125, rec=0.053, cos=0.184), tot_loss_proj:2.273 [t=0.23s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.870 (perp=8.125, rec=0.061, cos=0.184), tot_loss_proj:2.281 [t=0.23s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[ 750/2000] tot_loss=1.882 (perp=8.125, rec=0.073, cos=0.185), tot_loss_proj:2.276 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.877 (perp=8.125, rec=0.068, cos=0.185), tot_loss_proj:2.279 [t=0.27s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.848 (perp=8.125, rec=0.063, cos=0.160), tot_loss_proj:2.278 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[ 900/2000] tot_loss=1.872 (perp=8.125, rec=0.066, cos=0.181), tot_loss_proj:2.274 [t=0.17s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.874 (perp=8.125, rec=0.067, cos=0.183), tot_loss_proj:2.272 [t=0.24s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1000/2000] tot_loss=1.871 (perp=8.125, rec=0.062, cos=0.184), tot_loss_proj:2.274 [t=0.20s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[1050/2000] tot_loss=1.864 (perp=8.125, rec=0.055, cos=0.184), tot_loss_proj:2.277 [t=0.19s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1100/2000] tot_loss=1.885 (perp=8.125, rec=0.076, cos=0.184), tot_loss_proj:2.279 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1150/2000] tot_loss=1.879 (perp=8.125, rec=0.070, cos=0.184), tot_loss_proj:2.275 [t=0.25s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[1200/2000] tot_loss=1.874 (perp=8.125, rec=0.065, cos=0.184), tot_loss_proj:2.274 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1250/2000] tot_loss=1.881 (perp=8.125, rec=0.072, cos=0.184), tot_loss_proj:2.285 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1300/2000] tot_loss=1.868 (perp=8.125, rec=0.059, cos=0.185), tot_loss_proj:2.271 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[1350/2000] tot_loss=1.879 (perp=8.125, rec=0.070, cos=0.185), tot_loss_proj:2.277 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1400/2000] tot_loss=1.876 (perp=8.125, rec=0.067, cos=0.185), tot_loss_proj:2.281 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1450/2000] tot_loss=1.873 (perp=8.125, rec=0.063, cos=0.185), tot_loss_proj:2.283 [t=0.24s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[1500/2000] tot_loss=1.878 (perp=8.125, rec=0.068, cos=0.185), tot_loss_proj:2.279 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1550/2000] tot_loss=1.854 (perp=8.125, rec=0.055, cos=0.174), tot_loss_proj:2.276 [t=0.20s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1600/2000] tot_loss=1.861 (perp=8.125, rec=0.056, cos=0.180), tot_loss_proj:2.281 [t=0.22s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[1650/2000] tot_loss=1.870 (perp=8.125, rec=0.063, cos=0.182), tot_loss_proj:2.277 [t=0.22s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1700/2000] tot_loss=1.866 (perp=8.125, rec=0.058, cos=0.183), tot_loss_proj:2.281 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1750/2000] tot_loss=1.879 (perp=8.125, rec=0.070, cos=0.183), tot_loss_proj:2.274 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[1800/2000] tot_loss=1.879 (perp=8.125, rec=0.070, cos=0.184), tot_loss_proj:2.273 [t=0.25s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1850/2000] tot_loss=1.871 (perp=8.125, rec=0.062, cos=0.184), tot_loss_proj:2.274 [t=0.19s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[1900/2000] tot_loss=1.869 (perp=8.125, rec=0.060, cos=0.184), tot_loss_proj:2.273 [t=0.22s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
[1950/2000] tot_loss=1.872 (perp=8.125, rec=0.063, cos=0.184), tot_loss_proj:2.278 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Attempt swap
[2000/2000] tot_loss=1.880 (perp=8.125, rec=0.071, cos=0.184), tot_loss_proj:2.273 [t=0.18s]
prediction: ['[CLS] more ridiculous mu, but noy loco [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] more ridiculous mu, but noy loco [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 89.286

[Aggregate metrics]:
rouge1     | fm: 86.849 | p: 85.910 | r: 88.159
rouge2     | fm: 53.207 | p: 52.890 | r: 53.636
rougeL     | fm: 75.595 | p: 74.705 | r: 76.741
rougeLsum  | fm: 75.604 | p: 74.737 | r: 76.752
r1fm+r2fm = 140.056

input #91 time: 0:08:14 | total time: 12:49:17


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.8518699155313704
highest_index [0]
highest [0.8518699155313704]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8254832029342651 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8232853412628174 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.7794690728187561 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.7649124264717102 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7352539896965027 for ['[CLS] tank lonely [SEP]']
[Init] best rec loss: 0.7009363174438477 for ['[CLS] paths locked [SEP]']
[Init] best perm rec loss: 0.6995704770088196 for ['[CLS] locked paths [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.026 (perp=7.646, rec=0.228, cos=0.269), tot_loss_proj:1.860 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 100/2000] tot_loss=1.898 (perp=7.646, rec=0.100, cos=0.268), tot_loss_proj:1.855 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.860 (perp=7.646, rec=0.060, cos=0.270), tot_loss_proj:1.847 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.867 (perp=7.646, rec=0.065, cos=0.273), tot_loss_proj:1.859 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.869 (perp=7.646, rec=0.066, cos=0.274), tot_loss_proj:1.873 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.866 (perp=7.646, rec=0.072, cos=0.265), tot_loss_proj:1.869 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.867 (perp=7.646, rec=0.064, cos=0.274), tot_loss_proj:1.852 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.865 (perp=7.646, rec=0.065, cos=0.272), tot_loss_proj:1.866 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.876 (perp=7.646, rec=0.073, cos=0.274), tot_loss_proj:1.856 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.857 (perp=7.646, rec=0.062, cos=0.266), tot_loss_proj:1.858 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.868 (perp=7.646, rec=0.065, cos=0.273), tot_loss_proj:1.856 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.864 (perp=7.646, rec=0.061, cos=0.274), tot_loss_proj:1.861 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.856 (perp=7.646, rec=0.053, cos=0.274), tot_loss_proj:1.862 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.862 (perp=7.646, rec=0.060, cos=0.273), tot_loss_proj:1.863 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.858 (perp=7.646, rec=0.055, cos=0.274), tot_loss_proj:1.868 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.878 (perp=7.646, rec=0.075, cos=0.274), tot_loss_proj:1.858 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.859 (perp=7.646, rec=0.069, cos=0.261), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.868 (perp=7.646, rec=0.066, cos=0.273), tot_loss_proj:1.865 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.866 (perp=7.646, rec=0.063, cos=0.274), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.869 (perp=7.646, rec=0.066, cos=0.274), tot_loss_proj:1.868 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.866 (perp=7.646, rec=0.062, cos=0.274), tot_loss_proj:1.858 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.868 (perp=7.646, rec=0.067, cos=0.272), tot_loss_proj:1.862 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.869 (perp=7.646, rec=0.066, cos=0.273), tot_loss_proj:1.858 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.882 (perp=7.646, rec=0.079, cos=0.274), tot_loss_proj:1.863 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.858 (perp=7.646, rec=0.055, cos=0.274), tot_loss_proj:1.872 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.857 (perp=7.646, rec=0.054, cos=0.274), tot_loss_proj:1.862 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.866 (perp=7.646, rec=0.063, cos=0.274), tot_loss_proj:1.854 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.858 (perp=7.646, rec=0.055, cos=0.274), tot_loss_proj:1.855 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.862 (perp=7.646, rec=0.063, cos=0.270), tot_loss_proj:1.867 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.856 (perp=7.646, rec=0.055, cos=0.273), tot_loss_proj:1.866 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.868 (perp=7.646, rec=0.065, cos=0.273), tot_loss_proj:1.871 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.872 (perp=7.646, rec=0.069, cos=0.274), tot_loss_proj:1.861 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.863 (perp=7.646, rec=0.060, cos=0.274), tot_loss_proj:1.868 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.866 (perp=7.646, rec=0.063, cos=0.274), tot_loss_proj:1.866 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.881 (perp=7.646, rec=0.078, cos=0.274), tot_loss_proj:1.860 [t=0.28s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.859 (perp=7.646, rec=0.056, cos=0.274), tot_loss_proj:1.873 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.860 (perp=7.646, rec=0.056, cos=0.274), tot_loss_proj:1.865 [t=0.30s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.870 (perp=7.646, rec=0.067, cos=0.274), tot_loss_proj:1.868 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.858 (perp=7.646, rec=0.054, cos=0.274), tot_loss_proj:1.865 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.864 (perp=7.646, rec=0.060, cos=0.274), tot_loss_proj:1.865 [t=0.20s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.994 | p: 85.978 | r: 88.329
rouge2     | fm: 53.620 | p: 53.253 | r: 54.047
rougeL     | fm: 75.748 | p: 74.926 | r: 76.841
rougeLsum  | fm: 75.884 | p: 75.036 | r: 76.999
r1fm+r2fm = 140.614

input #92 time: 0:08:11 | total time: 12:57:29


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.8173687532758485
highest_index [0]
highest [0.8173687532758485]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 0.9396094083786011 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8828718662261963 for ['[CLS] taxi kang lookiled what mostchrome [SEP]']
[Init] best rec loss: 0.8687661290168762 for ['[CLS] scene attack humming working municipal attendant [MASK] [SEP]']
[Init] best rec loss: 0.8617079854011536 for ['[CLS] thousands fuel conditional scales progressed empowered mar [SEP]']
[Init] best rec loss: 0.8509654998779297 for ['[CLS] [CLS]rac madonna premiership further jeremy colby [SEP]']
[Init] best perm rec loss: 0.846261739730835 for ['[CLS]rac jeremy madonna further premiership [CLS] colby [SEP]']
[Init] best perm rec loss: 0.845961332321167 for ['[CLS] furtherrac premiership colby madonna jeremy [CLS] [SEP]']
[Init] best perm rec loss: 0.8425741195678711 for ['[CLS] further madonnarac colby jeremy premiership [CLS] [SEP]']
[Init] best perm rec loss: 0.8409311771392822 for ['[CLS] further premiershiprac jeremy colby madonna [CLS] [SEP]']
[Init] best perm rec loss: 0.8400171399116516 for ['[CLS] colby madonnarac jeremy further [CLS] premiership [SEP]']
[Init] best perm rec loss: 0.838607132434845 for ['[CLS] colby madonna further premiership jeremyrac [CLS] [SEP]']
[Init] best perm rec loss: 0.8382552266120911 for ['[CLS] jeremy madonna premiership further colbyrac [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.140 (perp=12.691, rec=0.275, cos=0.327), tot_loss_proj:3.545 [t=0.21s]
prediction: ['[CLS] funnyin often understanding post funny funny [SEP]']
[ 100/2000] tot_loss=2.268 (perp=8.817, rec=0.178, cos=0.326), tot_loss_proj:2.433 [t=0.22s]
prediction: ['[CLS] understanding in, understanding its funny way [SEP]']
[ 150/2000] tot_loss=2.227 (perp=8.895, rec=0.123, cos=0.325), tot_loss_proj:2.400 [t=0.18s]
prediction: ['[CLS] understanding in, understanding often funny way [SEP]']
[ 200/2000] tot_loss=2.197 (perp=8.817, rec=0.107, cos=0.326), tot_loss_proj:2.437 [t=0.18s]
prediction: ['[CLS] understanding in, understanding its funny way [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.943 (perp=7.542, rec=0.110, cos=0.324), tot_loss_proj:2.133 [t=0.20s]
prediction: ['[CLS] understanding, understanding in its funny way [SEP]']
[ 300/2000] tot_loss=1.928 (perp=7.542, rec=0.094, cos=0.326), tot_loss_proj:2.137 [t=0.18s]
prediction: ['[CLS] understanding, understanding in its funny way [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.939 (perp=7.542, rec=0.104, cos=0.327), tot_loss_proj:2.140 [t=0.18s]
prediction: ['[CLS] understanding, understanding in its funny way [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.940 (perp=7.542, rec=0.105, cos=0.327), tot_loss_proj:2.142 [t=0.31s]
prediction: ['[CLS] understanding, understanding in its funny way [SEP]']
[ 450/2000] tot_loss=1.923 (perp=7.528, rec=0.087, cos=0.330), tot_loss_proj:2.122 [t=0.18s]
prediction: ['[CLS] understanding, often in its funny way [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.791 (perp=6.937, rec=0.073, cos=0.331), tot_loss_proj:1.965 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.783 (perp=6.937, rec=0.065, cos=0.331), tot_loss_proj:1.967 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[ 600/2000] tot_loss=1.783 (perp=6.937, rec=0.065, cos=0.331), tot_loss_proj:1.965 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.782 (perp=6.937, rec=0.064, cos=0.331), tot_loss_proj:1.959 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.791 (perp=6.937, rec=0.072, cos=0.331), tot_loss_proj:1.961 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[ 750/2000] tot_loss=1.782 (perp=6.937, rec=0.063, cos=0.331), tot_loss_proj:1.978 [t=0.24s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.790 (perp=6.937, rec=0.071, cos=0.331), tot_loss_proj:1.967 [t=0.21s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.790 (perp=6.937, rec=0.071, cos=0.331), tot_loss_proj:1.970 [t=0.21s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[ 900/2000] tot_loss=1.792 (perp=6.937, rec=0.073, cos=0.331), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.782 (perp=6.937, rec=0.063, cos=0.331), tot_loss_proj:1.967 [t=0.19s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1000/2000] tot_loss=1.785 (perp=6.937, rec=0.066, cos=0.331), tot_loss_proj:1.969 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1050/2000] tot_loss=1.786 (perp=6.937, rec=0.067, cos=0.331), tot_loss_proj:1.956 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1100/2000] tot_loss=1.784 (perp=6.937, rec=0.065, cos=0.332), tot_loss_proj:1.961 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1150/2000] tot_loss=1.783 (perp=6.937, rec=0.064, cos=0.332), tot_loss_proj:1.959 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1200/2000] tot_loss=1.788 (perp=6.937, rec=0.069, cos=0.332), tot_loss_proj:1.964 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1250/2000] tot_loss=1.783 (perp=6.937, rec=0.064, cos=0.332), tot_loss_proj:1.964 [t=0.22s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1300/2000] tot_loss=1.784 (perp=6.937, rec=0.065, cos=0.332), tot_loss_proj:1.966 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1350/2000] tot_loss=1.787 (perp=6.937, rec=0.067, cos=0.332), tot_loss_proj:1.966 [t=0.30s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1400/2000] tot_loss=1.783 (perp=6.937, rec=0.064, cos=0.332), tot_loss_proj:1.959 [t=0.23s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1450/2000] tot_loss=1.790 (perp=6.937, rec=0.071, cos=0.332), tot_loss_proj:1.964 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1500/2000] tot_loss=1.794 (perp=6.937, rec=0.075, cos=0.332), tot_loss_proj:1.971 [t=0.19s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1550/2000] tot_loss=1.777 (perp=6.937, rec=0.058, cos=0.332), tot_loss_proj:1.967 [t=0.19s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1600/2000] tot_loss=1.787 (perp=6.937, rec=0.068, cos=0.332), tot_loss_proj:1.967 [t=0.24s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1650/2000] tot_loss=1.783 (perp=6.937, rec=0.064, cos=0.332), tot_loss_proj:1.970 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1700/2000] tot_loss=1.781 (perp=6.937, rec=0.062, cos=0.332), tot_loss_proj:1.964 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1750/2000] tot_loss=1.789 (perp=6.937, rec=0.070, cos=0.332), tot_loss_proj:1.961 [t=0.19s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1800/2000] tot_loss=1.795 (perp=6.937, rec=0.076, cos=0.332), tot_loss_proj:1.972 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1850/2000] tot_loss=1.791 (perp=6.937, rec=0.071, cos=0.332), tot_loss_proj:1.957 [t=0.18s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1900/2000] tot_loss=1.784 (perp=6.937, rec=0.065, cos=0.332), tot_loss_proj:1.962 [t=0.22s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1950/2000] tot_loss=1.779 (perp=6.937, rec=0.060, cos=0.332), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[2000/2000] tot_loss=1.792 (perp=6.937, rec=0.073, cos=0.332), tot_loss_proj:1.960 [t=0.21s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding, in its often funny way [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 87.166 | p: 86.193 | r: 88.444
rouge2     | fm: 53.777 | p: 53.423 | r: 54.235
rougeL     | fm: 75.927 | p: 75.031 | r: 77.069
rougeLsum  | fm: 76.095 | p: 75.199 | r: 77.166
r1fm+r2fm = 140.943

input #93 time: 0:08:09 | total time: 13:05:38


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.8575777712088184
highest_index [0]
highest [0.8575777712088184]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9540005326271057 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.952149510383606 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9270027875900269 for ['[CLS] milling library casual constructed board equationphs similaron cookies intended [SEP]']
[Init] best rec loss: 0.9263075590133667 for ['[CLS] press obvious laps involves yours mcgee spread shares spirit suffered location [SEP]']
[Init] best rec loss: 0.9251568913459778 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9192593097686768 for ['[CLS] convicted hunter entire fan wine9 league threat privatek rough [SEP]']
[Init] best rec loss: 0.908028781414032 for ['[CLS] enough usingac sur mile ready down maymise majesty assumption [SEP]']
[Init] best rec loss: 0.9006217122077942 for ['[CLS] barber eithertype roador motivefirm trusted ednaack wanted [SEP]']
[Init] best perm rec loss: 0.8991917967796326 for ['[CLS] roadfirm wanted barber motivetypeack ednaor trusted either [SEP]']
[Init] best perm rec loss: 0.898759663105011 for ['[CLS] trusted motivetype wanted ednafirm barber road eitherackor [SEP]']
[Init] best perm rec loss: 0.8975995182991028 for ['[CLS] wanted barber roadfirmack either edna trusted motivetypeor [SEP]']
[Init] best perm rec loss: 0.8975680470466614 for ['[CLS] motivefirmtype ednaor wanted barber eitherack trusted road [SEP]']
[Init] best perm rec loss: 0.8975234627723694 for ['[CLS] trustedortype motiveackfirm barber road either edna wanted [SEP]']
[Init] best perm rec loss: 0.8974173665046692 for ['[CLS] wanted edna barberackfirmor motive trusted either roadtype [SEP]']
[Init] best perm rec loss: 0.8972029685974121 for ['[CLS]ortypeack motive wanted edna barberfirm road either trusted [SEP]']
[Init] best perm rec loss: 0.8957193493843079 for ['[CLS]or barber trusted roadfirmtype edna wanted motive eitherack [SEP]']
[Init] best perm rec loss: 0.8941482901573181 for ['[CLS] edna wantedtype barberack motive trustedfirm either roador [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.622 (perp=13.587, rec=0.639, cos=0.266), tot_loss_proj:4.648 [t=0.17s]
prediction: ['[CLS] else allows lissa are bugs game and understanding richard runway della [SEP]']
[ 100/2000] tot_loss=3.539 (perp=13.721, rec=0.584, cos=0.212), tot_loss_proj:4.467 [t=0.18s]
prediction: ['[CLS] dear ( kendraquent tennessee funny without boris nor runway funny [SEP]']
[ 150/2000] tot_loss=3.050 (perp=11.049, rec=0.607, cos=0.233), tot_loss_proj:3.857 [t=0.17s]
prediction: ['[CLS] riley wax kendra that laughed detective and repression [SEP]ˈ boss [SEP]']
[ 200/2000] tot_loss=2.816 (perp=10.101, rec=0.528, cos=0.267), tot_loss_proj:3.093 [t=0.18s]
prediction: ['[CLS] neither wax kendra for thanking funny and neither nor nor funny [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.488 (perp=8.582, rec=0.507, cos=0.265), tot_loss_proj:2.656 [t=0.20s]
prediction: ['[CLS] neither original saddle that griffin nor and neither funny nor funny [SEP]']
[ 300/2000] tot_loss=2.944 (perp=10.883, rec=0.606, cos=0.162), tot_loss_proj:3.786 [t=0.18s]
prediction: ['[CLS] neither original saddle that julia original and neitherer neither terribly [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.807 (perp=10.726, rec=0.495, cos=0.167), tot_loss_proj:3.167 [t=0.21s]
prediction: ['[CLS] neither terribly original kendra cape consequences nor and nor funny nor [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.674 (perp=10.038, rec=0.486, cos=0.181), tot_loss_proj:3.076 [t=0.20s]
prediction: ['[CLS] neither terribly original saddle cape nor thanked nor original funny neither [SEP]']
[ 450/2000] tot_loss=2.862 (perp=11.139, rec=0.466, cos=0.168), tot_loss_proj:3.324 [t=0.18s]
prediction: ['[CLS] neither funny invite saddle cape nor thanked nor original funny neither [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.742 (perp=10.710, rec=0.463, cos=0.136), tot_loss_proj:3.281 [t=0.21s]
prediction: ['[CLS] neither funny funny saddle cape nor becca nor original invite neither [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.888 (perp=11.292, rec=0.483, cos=0.147), tot_loss_proj:3.451 [t=0.18s]
prediction: ['[CLS] neither funny funny saddle cape thanked nor nor original invite neither [SEP]']
[ 600/2000] tot_loss=3.129 (perp=12.377, rec=0.495, cos=0.158), tot_loss_proj:3.575 [t=0.18s]
prediction: ['[CLS] neither funny funny saddle cape why nor nor original invite neither [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.822 (perp=10.631, rec=0.436, cos=0.260), tot_loss_proj:3.276 [t=0.25s]
prediction: ['[CLS] neither funny funny saddle cape nor becca neither original invite nor [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.746 (perp=10.463, rec=0.432, cos=0.221), tot_loss_proj:3.137 [t=0.18s]
prediction: ['[CLS] neither funny funny saddle cape becca nor neither original invite neither [SEP]']
[ 750/2000] tot_loss=2.724 (perp=10.463, rec=0.437, cos=0.194), tot_loss_proj:3.141 [t=0.18s]
prediction: ['[CLS] neither funny funny saddle cape becca nor neither original invite neither [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.524 (perp=9.610, rec=0.442, cos=0.160), tot_loss_proj:2.902 [t=0.22s]
prediction: ['[CLS] neither funny saddle cape becca nor neither original invite neither funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.738 (perp=10.546, rec=0.463, cos=0.166), tot_loss_proj:3.132 [t=0.18s]
prediction: ['[CLS] neitherr saddle cape becca nor neither original invite neither funny [SEP]']
[ 900/2000] tot_loss=2.557 (perp=9.610, rec=0.415, cos=0.219), tot_loss_proj:2.905 [t=0.18s]
prediction: ['[CLS] neither funny saddle cape becca nor neither original invite neither funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.018 (perp=11.714, rec=0.438, cos=0.237), tot_loss_proj:3.384 [t=0.18s]
prediction: ['[CLS] neitherr saddle cape why nor neither original invite neither funny [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.687 (perp=10.098, rec=0.425, cos=0.242), tot_loss_proj:3.004 [t=0.27s]
prediction: ['[CLS] neither becca saddle caper nor neither original invite neither funny [SEP]']
[1050/2000] tot_loss=2.615 (perp=10.098, rec=0.417, cos=0.178), tot_loss_proj:3.004 [t=0.18s]
prediction: ['[CLS] neither becca saddle caper nor neither original invite neither funny [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.592 (perp=9.910, rec=0.415, cos=0.195), tot_loss_proj:2.954 [t=0.23s]
prediction: ['[CLS] neither saddle becca caper nor neither original invite neither funny [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.512 (perp=9.735, rec=0.411, cos=0.153), tot_loss_proj:2.943 [t=0.22s]
prediction: ['[CLS] neither saddle caper becca nor neither original invite neither funny [SEP]']
[1200/2000] tot_loss=2.495 (perp=9.735, rec=0.406, cos=0.142), tot_loss_proj:2.941 [t=0.28s]
prediction: ['[CLS] neither saddle caper becca nor neither original invite neither funny [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.472 (perp=9.571, rec=0.401, cos=0.157), tot_loss_proj:2.896 [t=0.18s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
Attempt swap
[1300/2000] tot_loss=2.451 (perp=9.571, rec=0.403, cos=0.134), tot_loss_proj:2.903 [t=0.19s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
[1350/2000] tot_loss=2.448 (perp=9.571, rec=0.399, cos=0.135), tot_loss_proj:2.895 [t=0.23s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
Attempt swap
[1400/2000] tot_loss=2.445 (perp=9.571, rec=0.393, cos=0.138), tot_loss_proj:2.894 [t=0.18s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
Attempt swap
[1450/2000] tot_loss=2.462 (perp=9.571, rec=0.393, cos=0.155), tot_loss_proj:2.902 [t=0.23s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
[1500/2000] tot_loss=2.498 (perp=9.571, rec=0.401, cos=0.183), tot_loss_proj:2.905 [t=0.24s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
Attempt swap
[1550/2000] tot_loss=2.445 (perp=9.571, rec=0.389, cos=0.142), tot_loss_proj:2.900 [t=0.21s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
Attempt swap
[1600/2000] tot_loss=2.469 (perp=9.571, rec=0.394, cos=0.161), tot_loss_proj:2.899 [t=0.18s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
[1650/2000] tot_loss=2.545 (perp=9.571, rec=0.378, cos=0.253), tot_loss_proj:2.898 [t=0.18s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
Attempt swap
[1700/2000] tot_loss=2.532 (perp=9.571, rec=0.374, cos=0.243), tot_loss_proj:2.902 [t=0.23s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
Attempt swap
[1750/2000] tot_loss=2.546 (perp=9.571, rec=0.379, cos=0.253), tot_loss_proj:2.900 [t=0.24s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
[1800/2000] tot_loss=2.538 (perp=9.571, rec=0.374, cos=0.250), tot_loss_proj:2.900 [t=0.18s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
Attempt swap
[1850/2000] tot_loss=2.517 (perp=9.571, rec=0.376, cos=0.226), tot_loss_proj:2.902 [t=0.24s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
Attempt swap
[1900/2000] tot_loss=2.511 (perp=9.571, rec=0.380, cos=0.217), tot_loss_proj:2.893 [t=0.18s]
prediction: ['[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]']
[1950/2000] tot_loss=2.638 (perp=10.322, rec=0.372, cos=0.201), tot_loss_proj:3.061 [t=0.18s]
prediction: ['[CLS] neither cape sillyr becca nor neither original invite neither funny [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.322 (perp=8.695, rec=0.380, cos=0.203), tot_loss_proj:2.743 [t=0.18s]
prediction: ['[CLS] neither silly caper becca nor neither original invite neither funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] neither cape saddler becca nor neither original invite neither funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 52.174 | p: 50.000 | r: 54.545
rouge2     | fm: 19.048 | p: 18.182 | r: 20.000
rougeL     | fm: 43.478 | p: 41.667 | r: 45.455
rougeLsum  | fm: 43.478 | p: 41.667 | r: 45.455
r1fm+r2fm = 71.222

[Aggregate metrics]:
rouge1     | fm: 86.903 | p: 85.860 | r: 88.176
rouge2     | fm: 53.388 | p: 53.019 | r: 53.796
rougeL     | fm: 75.685 | p: 74.783 | r: 76.758
rougeLsum  | fm: 75.760 | p: 74.930 | r: 76.871
r1fm+r2fm = 140.292

input #94 time: 0:08:20 | total time: 13:13:59


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.8436019536951331
highest_index [0]
highest [0.8436019536951331]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 1.0291804075241089 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 1.0194079875946045 for ['[CLS] reprinted geographic fairchild clary remains hitler tristanved thumb big hot dates muscle commander funding [SEP]']
[Init] best rec loss: 1.0190212726593018 for ['[CLS] set mediterranean seem duncan independence secular present surroundings lakes tongboat kei routledge mail majority [SEP]']
[Init] best rec loss: 0.9954050183296204 for ['[CLS]nahley hair see nedra logan offices fourth sethgical recommended side laughdran auxiliary [SEP]']
[Init] best rec loss: 0.9950403571128845 for ['[CLS] head felt infrastructure frequencyori 2018 news window saint kw ministry tragic hour electric grant [SEP]']
[Init] best rec loss: 0.983546257019043 for ['[CLS] sooner rue " pace leagues della smell sul epithet greenon power local concacaf relay [SEP]']
[Init] best rec loss: 0.9806751608848572 for ['[CLS] lam born contracted surface francaise infantry states laboratory based riff sands pick nouli decided [SEP]']
[Init] best rec loss: 0.9798353910446167 for ['[CLS] footprint brain arrival rec [MASK] 45 reverse if pal struggled spanning caleb born day classic [SEP]']
[Init] best rec loss: 0.975443422794342 for ['[CLS] elephant insuranceheater you session naturehoot eye attic stake bus cheating about injection temple [SEP]']
[Init] best rec loss: 0.9703208804130554 for ['[CLS] gas somewhereator bulk aka unlessssee actual como deliver? jockuble occasion [SEP]']
[Init] best perm rec loss: 0.9685792326927185 for ['[CLS] unless jocku aka bulk occasionssee somewhereator actual? como gasble deliver [SEP]']
[Init] best perm rec loss: 0.9674391150474548 for ['[CLS] jock gas occasion? unless somewhere aka como deliver bulkusseeatorble actual [SEP]']
[Init] best perm rec loss: 0.9671105146408081 for ['[CLS] comoble occasion aka? bulk unlessussee somewhere jockator actual gas deliver [SEP]']
[Init] best perm rec loss: 0.9665610194206238 for ['[CLS] deliver aka gasatorble? occasion actual bulksseeu como jock unless somewhere [SEP]']
[Init] best perm rec loss: 0.9653215408325195 for ['[CLS]bleator aka gasu jock deliver unless actual occasion?ssee como bulk somewhere [SEP]']
[Init] best perm rec loss: 0.9642525911331177 for ['[CLS] jockator? actual unless bulk gas deliver occasion aka somewherebleussee como [SEP]']
[Init] best perm rec loss: 0.9634519815444946 for ['[CLS]sseeator jock unless aka como? bulku deliverble occasion actual somewhere gas [SEP]']
[Init] best perm rec loss: 0.9632977247238159 for ['[CLS] unless gas jocku aka bulk? occasionator deliver actual somewheresseeble como [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.513 (perp=13.016, rec=0.629, cos=0.281), tot_loss_proj:4.285 [t=0.26s]
prediction: ['[CLS] appearance gas cao still army verge into locomotives adi pleasure kept payne nony definitely [SEP]']
[ 100/2000] tot_loss=3.555 (perp=13.632, rec=0.573, cos=0.256), tot_loss_proj:4.724 [t=0.22s]
prediction: ['[CLS]ir airs helps are army truerut besides diver fail opened another remainingy context [SEP]']
[ 150/2000] tot_loss=3.154 (perp=11.872, rec=0.581, cos=0.198), tot_loss_proj:4.292 [t=0.24s]
prediction: ['[CLS] meet complicationsulates ) camps true ) | hopeless into opened herfingerybourg [SEP]']
[ 200/2000] tot_loss=3.100 (perp=12.118, rec=0.530, cos=0.146), tot_loss_proj:3.675 [t=0.18s]
prediction: ['[CLS] meet countlessulates " became hopeless become | hopeless becomessat becomesrmed exchequer difficulties [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=3.526 (perp=13.293, rec=0.617, cos=0.251), tot_loss_proj:4.595 [t=0.18s]
prediction: ['[CLS] nearlyppet definitely ( sands above now tribe imperial become | hopeless into puzzled her [SEP]']
[ 300/2000] tot_loss=3.487 (perp=13.436, rec=0.531, cos=0.269), tot_loss_proj:4.534 [t=0.18s]
prediction: ['[CLS] nearlyly definitely archives circus laude deeper tribes imperial become | hopeless becomes puzzled her [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=3.407 (perp=13.563, rec=0.570, cos=0.124), tot_loss_proj:4.104 [t=0.18s]
prediction: ['[CLS] exceed are disasters locationsℝ conditions imagined tribes superyeft hopeless 《 became becomes [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.046 (perp=11.569, rec=0.504, cos=0.229), tot_loss_proj:3.668 [t=0.22s]
prediction: ['[CLS] exceed become disasters ) hardly conditions imagined tribesy supereft hopeless becomes became becomes [SEP]']
[ 450/2000] tot_loss=3.052 (perp=11.703, rec=0.531, cos=0.180), tot_loss_proj:3.717 [t=0.26s]
prediction: ['[CLS] midnight become disasters ) murder _ imagined unity prizeeft hopeless become became becomes [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.040 (perp=11.866, rec=0.488, cos=0.179), tot_loss_proj:3.699 [t=0.19s]
prediction: ['[CLS]her hopeless disasters ) murder ] imagined unit become hopelesseft become become became becomes [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.147 (perp=12.013, rec=0.467, cos=0.277), tot_loss_proj:3.457 [t=0.23s]
prediction: ['[CLS] midnight hopeless hopeless ) mud alphabet hopeless becomes become hopelesseft are extinct became becomes [SEP]']
[ 600/2000] tot_loss=3.470 (perp=13.140, rec=0.568, cos=0.274), tot_loss_proj:3.585 [t=0.25s]
prediction: ['[CLS]her hopeless hopeless ) become alphabet hopeless becomessat hopeless hopelesspool murder became becomes [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=3.173 (perp=12.911, rec=0.468, cos=0.123), tot_loss_proj:3.631 [t=0.24s]
prediction: ['[CLS]her hopeless hopeless ) grasped hopeless becomessat hopelessiensis hopeless nietzsche extinct became becomes [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=3.257 (perp=12.846, rec=0.441, cos=0.247), tot_loss_proj:3.518 [t=0.18s]
prediction: ['[CLS]her hopeless hopeless ) mud hopeless becomessat hopelessiensisapple hopeless murder became becomes [SEP]']
[ 750/2000] tot_loss=3.163 (perp=12.846, rec=0.420, cos=0.174), tot_loss_proj:3.511 [t=0.19s]
prediction: ['[CLS]her hopeless hopeless ) mud hopeless becomessat hopelessiensisapple hopeless murder became becomes [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.958 (perp=11.787, rec=0.475, cos=0.126), tot_loss_proj:3.302 [t=0.19s]
prediction: ['[CLS] allegro hopeless hopeless ) becomes hopeless mudsat hopelessiensispool hopeless murder became becomes [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.804 (perp=10.758, rec=0.428, cos=0.225), tot_loss_proj:3.395 [t=0.19s]
prediction: ['[CLS] allegro hopeless hopeless ) hopeless hopeless mudsat becomesiensis nietzsche hopeless murder became becomes [SEP]']
[ 900/2000] tot_loss=2.680 (perp=10.758, rec=0.417, cos=0.111), tot_loss_proj:3.394 [t=0.21s]
prediction: ['[CLS] allegro hopeless hopeless ) hopeless hopeless mudsat becomesiensis nietzsche hopeless murder became becomes [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.845 (perp=10.758, rec=0.401, cos=0.292), tot_loss_proj:3.400 [t=0.25s]
prediction: ['[CLS] allegro hopeless hopeless ) hopeless hopeless mudsat becomesiensis nietzsche hopeless murder became becomes [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.685 (perp=10.525, rec=0.407, cos=0.172), tot_loss_proj:3.423 [t=0.18s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsat becomesiensis nietzsche hopeless murder became becomes [SEP]']
[1050/2000] tot_loss=2.602 (perp=10.525, rec=0.409, cos=0.088), tot_loss_proj:3.426 [t=0.25s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsat becomesiensis nietzsche hopeless murder became becomes [SEP]']
Attempt swap
[1100/2000] tot_loss=2.960 (perp=11.694, rec=0.391, cos=0.230), tot_loss_proj:3.534 [t=0.19s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsat becomes indusapple hopeless legislature mud becomes [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.715 (perp=10.668, rec=0.419, cos=0.163), tot_loss_proj:3.470 [t=0.18s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsat becomes becameiensis nietzsche hopeless murder becomes [SEP]']
[1200/2000] tot_loss=2.824 (perp=10.710, rec=0.400, cos=0.283), tot_loss_proj:3.300 [t=0.19s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsat becomes mudiensisapple hopeless murder becomes [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.659 (perp=10.382, rec=0.400, cos=0.183), tot_loss_proj:3.225 [t=0.21s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsat nietzsche mudiensis becomes hopeless murder becomes [SEP]']
Attempt swap
[1300/2000] tot_loss=2.649 (perp=10.551, rec=0.403, cos=0.136), tot_loss_proj:3.297 [t=0.18s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsat nietzsche mudnished becomes hopeless murder becomes [SEP]']
[1350/2000] tot_loss=2.702 (perp=10.552, rec=0.389, cos=0.203), tot_loss_proj:3.246 [t=0.18s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple mudnished becomes hopeless murder becomes [SEP]']
Attempt swap
[1400/2000] tot_loss=2.624 (perp=10.552, rec=0.401, cos=0.112), tot_loss_proj:3.252 [t=0.18s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple mudnished becomes hopeless murder becomes [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.815 (perp=10.873, rec=0.385, cos=0.256), tot_loss_proj:3.111 [t=0.19s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple mud legislature becomes hopelessnished becomes [SEP]']
[1500/2000] tot_loss=2.737 (perp=10.873, rec=0.397, cos=0.166), tot_loss_proj:3.119 [t=0.18s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple mud legislature becomes hopelessnished becomes [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.641 (perp=10.581, rec=0.404, cos=0.121), tot_loss_proj:3.114 [t=0.19s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple legislature becomes hopeless mudnished becomes [SEP]']
Attempt swap
[1600/2000] tot_loss=2.729 (perp=10.581, rec=0.398, cos=0.215), tot_loss_proj:3.116 [t=0.19s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple legislature becomes hopeless mudnished becomes [SEP]']
[1650/2000] tot_loss=2.636 (perp=10.395, rec=0.399, cos=0.158), tot_loss_proj:3.121 [t=0.19s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple murder becomes hopeless mudnished becomes [SEP]']
Attempt swap
[1700/2000] tot_loss=2.742 (perp=10.627, rec=0.394, cos=0.223), tot_loss_proj:3.164 [t=0.19s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple murder becomes hopeless mud indus becomes [SEP]']
Attempt swap
[1750/2000] tot_loss=2.758 (perp=10.627, rec=0.399, cos=0.234), tot_loss_proj:3.164 [t=0.25s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple murder becomes hopeless mud indus becomes [SEP]']
[1800/2000] tot_loss=2.732 (perp=10.627, rec=0.378, cos=0.229), tot_loss_proj:3.166 [t=0.19s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple murder becomes hopeless mud indus becomes [SEP]']
Attempt swap
[1850/2000] tot_loss=2.726 (perp=10.627, rec=0.377, cos=0.224), tot_loss_proj:3.165 [t=0.26s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple murder becomes hopeless mud indus becomes [SEP]']
Attempt swap
[1900/2000] tot_loss=2.704 (perp=10.633, rec=0.371, cos=0.207), tot_loss_proj:3.154 [t=0.21s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple legislature becomes hopeless mud indus becomes [SEP]']
[1950/2000] tot_loss=2.689 (perp=10.633, rec=0.377, cos=0.185), tot_loss_proj:3.161 [t=0.18s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple legislature becomes hopeless mud indus becomes [SEP]']
Attempt swap
[2000/2000] tot_loss=2.728 (perp=10.633, rec=0.382, cos=0.219), tot_loss_proj:3.162 [t=0.23s]
prediction: ['[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple legislature becomes hopeless mud indus becomes [SEP]']
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] allegro ) hopeless hopeless hopeless hopeless mudsatapple legislature becomes hopeless mud indus becomes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 34.783 | p: 28.571 | r: 44.444
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 34.783 | p: 28.571 | r: 44.444
rougeLsum  | fm: 34.783 | p: 28.571 | r: 44.444
r1fm+r2fm = 34.783

[Aggregate metrics]:
rouge1     | fm: 86.329 | p: 85.299 | r: 87.699
rouge2     | fm: 52.643 | p: 52.277 | r: 53.055
rougeL     | fm: 75.112 | p: 74.194 | r: 76.318
rougeLsum  | fm: 75.222 | p: 74.299 | r: 76.409
r1fm+r2fm = 138.972

input #95 time: 0:08:27 | total time: 13:22:27


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.8648449025711843
highest_index [0]
highest [0.8648449025711843]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8337421417236328 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8137344121932983 for ['[CLS] at townland panel subjects latter board vidhan tang general honor majestysse spared homes rider [SEP]']
[Init] best rec loss: 0.8051915764808655 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 0.7857274413108826 for ['[CLS] class error portoizedtler riverside 7nsis deedret via protection corporation whether selection [SEP]']
[Init] best rec loss: 0.7773188352584839 for ['[CLS] interviews screwed podcast ？ 8 sunset effects era too oath sunk chief between capcom master [SEP]']
[Init] best rec loss: 0.774985134601593 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best rec loss: 0.7723566293716431 for ['[CLS]rg woken became jenny marx further league performance union holding winning instrumental re distance conscious [SEP]']
[Init] best rec loss: 0.7549090385437012 for ['[CLS] foreign x universalhausen ant southeast leave brands ascent perpendicular are article holding wrestling capability [SEP]']
[Init] best perm rec loss: 0.7540728449821472 for ['[CLS] ant universal foreign holding x ascent southeast are capability perpendicular wrestling article leave brandshausen [SEP]']
[Init] best perm rec loss: 0.7537137269973755 for ['[CLS] brands universal article ascent leave perpendicular ant southeast holding capability foreignhausen wrestling x are [SEP]']
[Init] best perm rec loss: 0.7531697154045105 for ['[CLS] ant foreign capability ascent article southeast x are universal holding perpendicularhausen wrestling brands leave [SEP]']
[Init] best perm rec loss: 0.7528831958770752 for ['[CLS] are anthausen capability leave x wrestling foreign holding perpendicular universal ascent southeast article brands [SEP]']
[Init] best perm rec loss: 0.7525830864906311 for ['[CLS] are perpendicular foreign ant leave holding wrestling article x brands ascent southeast capabilityhausen universal [SEP]']
[Init] best perm rec loss: 0.7515469789505005 for ['[CLS] wrestling article ascenthausen holding brands leave foreign perpendicular x universal ant are southeast capability [SEP]']
[Init] best perm rec loss: 0.7503859400749207 for ['[CLS] wrestling brands holdinghausen x foreign ant capability leave are ascent universal article southeast perpendicular [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.839 (perp=11.157, rec=0.372, cos=0.236), tot_loss_proj:3.598 [t=0.19s]
prediction: ['[CLS] man institute available demand building real impact it tonight evening bring target targets without areas [SEP]']
[ 100/2000] tot_loss=2.883 (perp=11.685, rec=0.333, cos=0.213), tot_loss_proj:3.363 [t=0.18s]
prediction: ['[CLS] force actor on further on into into situations tonight easily take run situations lesser people [SEP]']
[ 150/2000] tot_loss=2.626 (perp=10.686, rec=0.237, cos=0.253), tot_loss_proj:3.139 [t=0.19s]
prediction: ['[CLS] force himself on of on into himself people tonight run take cover situations lesser men [SEP]']
[ 200/2000] tot_loss=2.586 (perp=10.835, rec=0.174, cos=0.245), tot_loss_proj:3.312 [t=0.18s]
prediction: ['[CLS] force himself on force on into himself people oklahoma run make cover situations lesser men [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.532 (perp=10.620, rec=0.175, cos=0.233), tot_loss_proj:3.371 [t=0.18s]
prediction: ['[CLS] force himself on increasingly on situations situations people oklahoma run make cover and lesser men [SEP]']
[ 300/2000] tot_loss=2.156 (perp=8.919, rec=0.125, cos=0.247), tot_loss_proj:2.547 [t=0.21s]
prediction: ['[CLS] force himself on and on situations that people oklahoma run make cover and lesser men [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.279 (perp=9.573, rec=0.116, cos=0.249), tot_loss_proj:3.024 [t=0.24s]
prediction: ['[CLS] force himself on and on situations into make into run people cover and lesser men [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.175 (perp=9.136, rec=0.108, cos=0.240), tot_loss_proj:2.823 [t=0.25s]
prediction: ['[CLS] force himself on and into situations into make and run people cover tonight lesser men [SEP]']
[ 450/2000] tot_loss=2.174 (perp=9.136, rec=0.101, cos=0.247), tot_loss_proj:2.830 [t=0.20s]
prediction: ['[CLS] force himself on and into situations into make and run people cover tonight lesser men [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.081 (perp=8.704, rec=0.093, cos=0.247), tot_loss_proj:2.637 [t=0.22s]
prediction: ['[CLS] force himself on and into situations into make and run people cover lesser men would [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.978 (perp=8.228, rec=0.092, cos=0.241), tot_loss_proj:2.453 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run people cover lesser men into [SEP]']
[ 600/2000] tot_loss=1.985 (perp=8.228, rec=0.094, cos=0.245), tot_loss_proj:2.447 [t=0.19s]
prediction: ['[CLS] force himself on and into situations would make and run people cover lesser men into [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.926 (perp=7.925, rec=0.094, cos=0.247), tot_loss_proj:2.530 [t=0.21s]
prediction: ['[CLS] force himself on and into situations would make and run people into cover lesser men [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.885 (perp=7.718, rec=0.091, cos=0.251), tot_loss_proj:2.467 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
[ 750/2000] tot_loss=1.877 (perp=7.718, rec=0.089, cos=0.244), tot_loss_proj:2.463 [t=0.19s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.879 (perp=7.718, rec=0.085, cos=0.250), tot_loss_proj:2.463 [t=0.19s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.875 (perp=7.718, rec=0.080, cos=0.252), tot_loss_proj:2.467 [t=0.23s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
[ 900/2000] tot_loss=1.876 (perp=7.718, rec=0.081, cos=0.252), tot_loss_proj:2.464 [t=0.24s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.877 (perp=7.718, rec=0.082, cos=0.252), tot_loss_proj:2.465 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1000/2000] tot_loss=1.872 (perp=7.718, rec=0.083, cos=0.246), tot_loss_proj:2.468 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
[1050/2000] tot_loss=1.865 (perp=7.718, rec=0.072, cos=0.249), tot_loss_proj:2.473 [t=0.23s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1100/2000] tot_loss=1.867 (perp=7.718, rec=0.073, cos=0.250), tot_loss_proj:2.467 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1150/2000] tot_loss=1.877 (perp=7.718, rec=0.083, cos=0.251), tot_loss_proj:2.471 [t=0.19s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
[1200/2000] tot_loss=1.873 (perp=7.718, rec=0.078, cos=0.251), tot_loss_proj:2.467 [t=0.19s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1250/2000] tot_loss=1.878 (perp=7.718, rec=0.083, cos=0.251), tot_loss_proj:2.471 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1300/2000] tot_loss=1.875 (perp=7.718, rec=0.080, cos=0.251), tot_loss_proj:2.469 [t=0.24s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
[1350/2000] tot_loss=1.867 (perp=7.718, rec=0.072, cos=0.251), tot_loss_proj:2.475 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1400/2000] tot_loss=1.871 (perp=7.718, rec=0.076, cos=0.252), tot_loss_proj:2.475 [t=0.21s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1450/2000] tot_loss=1.871 (perp=7.718, rec=0.075, cos=0.252), tot_loss_proj:2.472 [t=0.29s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
[1500/2000] tot_loss=1.874 (perp=7.718, rec=0.079, cos=0.252), tot_loss_proj:2.471 [t=0.24s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1550/2000] tot_loss=1.876 (perp=7.718, rec=0.081, cos=0.252), tot_loss_proj:2.470 [t=0.21s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1600/2000] tot_loss=1.877 (perp=7.718, rec=0.081, cos=0.252), tot_loss_proj:2.472 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
[1650/2000] tot_loss=1.873 (perp=7.718, rec=0.078, cos=0.252), tot_loss_proj:2.469 [t=0.19s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1700/2000] tot_loss=1.875 (perp=7.718, rec=0.079, cos=0.252), tot_loss_proj:2.476 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1750/2000] tot_loss=1.878 (perp=7.718, rec=0.083, cos=0.252), tot_loss_proj:2.473 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
[1800/2000] tot_loss=1.872 (perp=7.718, rec=0.076, cos=0.252), tot_loss_proj:2.475 [t=0.19s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1850/2000] tot_loss=1.867 (perp=7.718, rec=0.072, cos=0.252), tot_loss_proj:2.475 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[1900/2000] tot_loss=1.872 (perp=7.718, rec=0.077, cos=0.252), tot_loss_proj:2.469 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
[1950/2000] tot_loss=1.873 (perp=7.718, rec=0.078, cos=0.252), tot_loss_proj:2.469 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Attempt swap
[2000/2000] tot_loss=1.869 (perp=7.718, rec=0.074, cos=0.252), tot_loss_proj:2.468 [t=0.18s]
prediction: ['[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] force himself on and into situations would make and run into people cover lesser men [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.235 | p: 88.235 | r: 88.235
rouge2     | fm: 43.750 | p: 43.750 | r: 43.750
rougeL     | fm: 70.588 | p: 70.588 | r: 70.588
rougeLsum  | fm: 70.588 | p: 70.588 | r: 70.588
r1fm+r2fm = 131.985

[Aggregate metrics]:
rouge1     | fm: 86.272 | p: 85.318 | r: 87.631
rouge2     | fm: 52.574 | p: 52.193 | r: 53.041
rougeL     | fm: 75.034 | p: 74.151 | r: 76.261
rougeLsum  | fm: 75.183 | p: 74.280 | r: 76.374
r1fm+r2fm = 138.845

input #96 time: 0:08:26 | total time: 13:30:54


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.8269030258656604
highest_index [0]
highest [0.8269030258656604]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.7540600299835205 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.7350996136665344 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 0.7297036647796631 for ['[CLS] victoriaten test pass 2016 which [SEP]']
[Init] best perm rec loss: 0.7278030514717102 for ['[CLS] test pass which victoria 2016ten [SEP]']
[Init] best perm rec loss: 0.7274388670921326 for ['[CLS] testten 2016 which victoria pass [SEP]']
[Init] best perm rec loss: 0.7268909215927124 for ['[CLS]ten 2016 which test victoria pass [SEP]']
[Init] best perm rec loss: 0.7266567349433899 for ['[CLS]ten 2016 pass which test victoria [SEP]']
[Init] best perm rec loss: 0.7266558408737183 for ['[CLS] testten pass which victoria 2016 [SEP]']
[Init] best perm rec loss: 0.7265288233757019 for ['[CLS] test victoria 2016 passten which [SEP]']
[Init] best perm rec loss: 0.7263468503952026 for ['[CLS] pass which victoria 2016 testten [SEP]']
[Init] best perm rec loss: 0.7246059775352478 for ['[CLS] 2016 test pass whichten victoria [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.272 (perp=12.700, rec=0.444, cos=0.289), tot_loss_proj:3.773 [t=0.18s]
prediction: ['[CLS] souls exclusive hall ed foreign rite [SEP]']
[ 100/2000] tot_loss=3.148 (perp=12.701, rec=0.314, cos=0.294), tot_loss_proj:4.194 [t=0.22s]
prediction: ['[CLS]for signed memoriesfor america characters [SEP]']
[ 150/2000] tot_loss=3.219 (perp=13.568, rec=0.204, cos=0.302), tot_loss_proj:4.504 [t=0.17s]
prediction: ['[CLS]get oldtablefor original characters [SEP]']
[ 200/2000] tot_loss=2.811 (perp=11.405, rec=0.221, cos=0.309), tot_loss_proj:3.575 [t=0.30s]
prediction: ['[CLS]gettabletablefor original characters [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.250 (perp=8.940, rec=0.150, cos=0.312), tot_loss_proj:2.527 [t=0.18s]
prediction: ['[CLS] ungettablefortable characters [SEP]']
[ 300/2000] tot_loss=2.359 (perp=9.604, rec=0.125, cos=0.313), tot_loss_proj:2.928 [t=0.18s]
prediction: ['[CLS] ungettablefor hooks characters [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.555 (perp=5.733, rec=0.095, cos=0.314), tot_loss_proj:1.933 [t=0.18s]
prediction: ['[CLS] unforgettable villain characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.551 (perp=5.733, rec=0.097, cos=0.307), tot_loss_proj:1.924 [t=0.21s]
prediction: ['[CLS] unforgettable villain characters [SEP]']
[ 450/2000] tot_loss=1.616 (perp=6.104, rec=0.082, cos=0.314), tot_loss_proj:1.729 [t=0.18s]
prediction: ['[CLS] unforgettable characters characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.616 (perp=6.104, rec=0.079, cos=0.316), tot_loss_proj:1.734 [t=0.18s]
prediction: ['[CLS] unforgettable characters characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.540 (perp=5.733, rec=0.082, cos=0.312), tot_loss_proj:1.926 [t=0.25s]
prediction: ['[CLS] unforgettable villain characters [SEP]']
[ 600/2000] tot_loss=1.532 (perp=5.733, rec=0.072, cos=0.314), tot_loss_proj:1.939 [t=0.20s]
prediction: ['[CLS] unforgettable villain characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.896 (perp=7.521, rec=0.076, cos=0.315), tot_loss_proj:2.095 [t=0.25s]
prediction: ['[CLS] unforgettableonale characters [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.847 (perp=7.268, rec=0.080, cos=0.313), tot_loss_proj:2.090 [t=0.19s]
prediction: ['[CLS] unforgettable charactersᶠ [SEP]']
[ 750/2000] tot_loss=1.852 (perp=7.268, rec=0.084, cos=0.315), tot_loss_proj:2.072 [t=0.18s]
prediction: ['[CLS] unforgettable charactersᶠ [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.830 (perp=7.268, rec=0.064, cos=0.313), tot_loss_proj:2.056 [t=0.23s]
prediction: ['[CLS] unforgettable charactersᶠ [SEP]']
Attempt swap
Put prefix at the end
[ 850/2000] tot_loss=1.766 (perp=6.881, rec=0.083, cos=0.307), tot_loss_proj:2.089 [t=0.19s]
prediction: ['[CLS] points unforgettable characters [SEP]']
[ 900/2000] tot_loss=1.440 (perp=5.309, rec=0.066, cos=0.311), tot_loss_proj:1.444 [t=0.18s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.439 (perp=5.309, rec=0.064, cos=0.313), tot_loss_proj:1.435 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.448 (perp=5.309, rec=0.073, cos=0.313), tot_loss_proj:1.432 [t=0.27s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1050/2000] tot_loss=1.440 (perp=5.309, rec=0.065, cos=0.314), tot_loss_proj:1.441 [t=0.19s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.448 (perp=5.309, rec=0.072, cos=0.314), tot_loss_proj:1.435 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.444 (perp=5.309, rec=0.068, cos=0.314), tot_loss_proj:1.444 [t=0.23s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1200/2000] tot_loss=1.443 (perp=5.309, rec=0.067, cos=0.314), tot_loss_proj:1.431 [t=0.21s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.430 (perp=5.309, rec=0.054, cos=0.314), tot_loss_proj:1.437 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.437 (perp=5.309, rec=0.061, cos=0.314), tot_loss_proj:1.450 [t=0.18s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1350/2000] tot_loss=1.437 (perp=5.309, rec=0.061, cos=0.314), tot_loss_proj:1.457 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.436 (perp=5.309, rec=0.060, cos=0.314), tot_loss_proj:1.455 [t=0.19s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.436 (perp=5.309, rec=0.060, cos=0.314), tot_loss_proj:1.433 [t=0.18s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1500/2000] tot_loss=1.428 (perp=5.309, rec=0.051, cos=0.314), tot_loss_proj:1.439 [t=0.18s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.443 (perp=5.309, rec=0.066, cos=0.315), tot_loss_proj:1.449 [t=0.22s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.432 (perp=5.309, rec=0.055, cos=0.315), tot_loss_proj:1.441 [t=0.24s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1650/2000] tot_loss=1.446 (perp=5.309, rec=0.070, cos=0.315), tot_loss_proj:1.431 [t=0.25s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.444 (perp=5.309, rec=0.067, cos=0.315), tot_loss_proj:1.436 [t=0.18s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.431 (perp=5.309, rec=0.055, cos=0.315), tot_loss_proj:1.436 [t=0.18s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1800/2000] tot_loss=1.445 (perp=5.309, rec=0.068, cos=0.315), tot_loss_proj:1.440 [t=0.20s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.443 (perp=5.309, rec=0.067, cos=0.315), tot_loss_proj:1.438 [t=0.18s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.447 (perp=5.309, rec=0.070, cos=0.315), tot_loss_proj:1.446 [t=0.18s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1950/2000] tot_loss=1.449 (perp=5.309, rec=0.072, cos=0.315), tot_loss_proj:1.428 [t=0.18s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.437 (perp=5.309, rec=0.060, cos=0.315), tot_loss_proj:1.448 [t=0.18s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.446 | p: 85.500 | r: 87.792
rouge2     | fm: 53.140 | p: 52.763 | r: 53.531
rougeL     | fm: 75.437 | p: 74.499 | r: 76.516
rougeLsum  | fm: 75.539 | p: 74.588 | r: 76.730
r1fm+r2fm = 139.586

input #97 time: 0:08:14 | total time: 13:39:08


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.8786214287888443
highest_index [0]
highest [0.8786214287888443]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.6506008505821228 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.6449775695800781 for ['[CLS] nos jed ada prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.080 (perp=12.750, rec=0.327, cos=0.202), tot_loss_proj:3.636 [t=0.19s]
prediction: ['[CLS] misfulful losses [SEP]']
[ 100/2000] tot_loss=2.816 (perp=12.093, rec=0.184, cos=0.214), tot_loss_proj:3.233 [t=0.18s]
prediction: ['[CLS] unfulful selling [SEP]']
[ 150/2000] tot_loss=2.235 (perp=9.342, rec=0.140, cos=0.226), tot_loss_proj:2.696 [t=0.23s]
prediction: ['[CLS] unfullling attachment [SEP]']
[ 200/2000] tot_loss=2.208 (perp=9.342, rec=0.116, cos=0.223), tot_loss_proj:2.691 [t=0.18s]
prediction: ['[CLS] unfullling attachment [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.320 (perp=4.948, rec=0.127, cos=0.204), tot_loss_proj:1.279 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.312 (perp=4.948, rec=0.101, cos=0.222), tot_loss_proj:1.301 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.295 (perp=4.948, rec=0.081, cos=0.225), tot_loss_proj:1.281 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.296 (perp=4.948, rec=0.081, cos=0.226), tot_loss_proj:1.287 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.288 (perp=4.948, rec=0.072, cos=0.227), tot_loss_proj:1.279 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.283 (perp=4.948, rec=0.066, cos=0.227), tot_loss_proj:1.292 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.281 (perp=4.948, rec=0.065, cos=0.227), tot_loss_proj:1.281 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.283 (perp=4.948, rec=0.067, cos=0.227), tot_loss_proj:1.302 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.275 (perp=4.948, rec=0.059, cos=0.227), tot_loss_proj:1.286 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.275 (perp=4.948, rec=0.058, cos=0.227), tot_loss_proj:1.290 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.278 (perp=4.948, rec=0.061, cos=0.227), tot_loss_proj:1.290 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.267 (perp=4.948, rec=0.051, cos=0.227), tot_loss_proj:1.286 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.282 (perp=4.948, rec=0.066, cos=0.227), tot_loss_proj:1.277 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.280 (perp=4.948, rec=0.063, cos=0.227), tot_loss_proj:1.285 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.258 (perp=4.948, rec=0.041, cos=0.227), tot_loss_proj:1.285 [t=0.20s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.278 (perp=4.948, rec=0.061, cos=0.227), tot_loss_proj:1.289 [t=0.28s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.287 (perp=4.948, rec=0.070, cos=0.227), tot_loss_proj:1.283 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.274 (perp=4.948, rec=0.057, cos=0.228), tot_loss_proj:1.285 [t=0.27s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.281 (perp=4.948, rec=0.064, cos=0.228), tot_loss_proj:1.278 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.280 (perp=4.948, rec=0.063, cos=0.228), tot_loss_proj:1.288 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.276 (perp=4.948, rec=0.059, cos=0.228), tot_loss_proj:1.279 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.271 (perp=4.948, rec=0.053, cos=0.228), tot_loss_proj:1.299 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.277 (perp=4.948, rec=0.059, cos=0.228), tot_loss_proj:1.293 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.278 (perp=4.948, rec=0.060, cos=0.228), tot_loss_proj:1.278 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.282 (perp=4.948, rec=0.064, cos=0.228), tot_loss_proj:1.284 [t=0.26s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.284 (perp=4.948, rec=0.067, cos=0.228), tot_loss_proj:1.286 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.275 (perp=4.948, rec=0.058, cos=0.228), tot_loss_proj:1.285 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.280 (perp=4.948, rec=0.063, cos=0.228), tot_loss_proj:1.276 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.273 (perp=4.948, rec=0.056, cos=0.228), tot_loss_proj:1.283 [t=0.30s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.277 (perp=4.948, rec=0.060, cos=0.228), tot_loss_proj:1.287 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.281 (perp=4.948, rec=0.063, cos=0.228), tot_loss_proj:1.287 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.284 (perp=4.948, rec=0.067, cos=0.228), tot_loss_proj:1.278 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.278 (perp=4.948, rec=0.061, cos=0.228), tot_loss_proj:1.285 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.265 (perp=4.948, rec=0.048, cos=0.228), tot_loss_proj:1.292 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.282 (perp=4.948, rec=0.064, cos=0.228), tot_loss_proj:1.280 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.276 (perp=4.948, rec=0.059, cos=0.228), tot_loss_proj:1.301 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.652 | p: 85.643 | r: 87.994
rouge2     | fm: 53.575 | p: 53.182 | r: 54.008
rougeL     | fm: 75.647 | p: 74.720 | r: 76.862
rougeLsum  | fm: 75.647 | p: 74.817 | r: 76.788
r1fm+r2fm = 140.227

input #98 time: 0:08:25 | total time: 13:47:34


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.8813772111523689
highest_index [0]
highest [0.8813772111523689]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8060293197631836 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.7923386693000793 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.7655612230300903 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.7534418106079102 for ['[CLS] imp then ratlogueathy mobile bun smoothe bran where heart thumbs principal aires & recently brig addison stands catalog alert abbottale leading switch as could which buy pony kid risk general spreadim [SEP]']
[Init] best rec loss: 0.7455540299415588 for ['[CLS] wat searched fits mckay german divide interpret sensory ajax from even during under skye pants ramlus except door wanted others same q same king ashton care lot confirmation buttonsmania caseston file evil absolute [SEP]']
[Init] best rec loss: 0.7353169918060303 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.7316392064094543 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.7314596176147461 for ['[CLS] himself bearing slight when bet te re synonym tempsaging right dentalˈ currently ferns claire cushion still knowledge harper opposed actually garcia screens services thunderts ratings distancete [MASK] orient forced taste earliest barbie [SEP]']
[Init] best perm rec loss: 0.7271243333816528 for ['[CLS] slight taste when knowledge thunder opposedaging still right orient ratings forced synonymts garcia screens cushion reˈ harper actually tempste services barbie dental currently [MASK] te distance claire bet ferns himself earliest bearing [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.988 (perp=11.979, rec=0.421, cos=0.171), tot_loss_proj:3.390 [t=0.29s]
prediction: ['[CLS] mud fake na bonnet tape anybody after little immediately dublin curb restriction or usual stupid folder ye the attack stupid legislative in me threats ruined evidence any other wrong jail fu or / fake were nothing [SEP]']
[ 100/2000] tot_loss=2.905 (perp=11.975, rec=0.369, cos=0.141), tot_loss_proj:3.363 [t=0.25s]
prediction: ["[CLS] mud google went minus grey anybody popularity still immediately ulster quit registered or usual worsttech'theridssing worst officials me threats ruined information lest miguel under ` na or ; whirled were nothing [SEP]"]
[ 150/2000] tot_loss=2.605 (perp=10.585, rec=0.273, cos=0.215), tot_loss_proj:3.036 [t=0.18s]
prediction: ["[CLS] mudssing went minus mm anybody fun so already psychologistssedusing but went worst - that the tryingssing worst a me di ruined operations ` film under'fun - or fun were nothing [SEP]"]
[ 200/2000] tot_loss=2.735 (perp=11.202, rec=0.310, cos=0.185), tot_loss_proj:3.264 [t=0.24s]
prediction: ["[CLS] wentssing went : protesters crazy fun yet already welshssing committee but had sick - ) sametingssing worst a me di insult authorities any film signed'fun'di fake seemed nothing [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.533 (perp=10.366, rec=0.260, cos=0.199), tot_loss_proj:2.964 [t=0.19s]
prediction: ['[CLS] wentssing went : said crazy fun so already british skip bill but had no - midnight each withssing worse the me dissing police any film "\'( di much fake got mind [SEP]']
[ 300/2000] tot_loss=2.641 (perp=11.257, rec=0.215, cos=0.175), tot_loss_proj:3.219 [t=0.20s]
prediction: ["[CLS] walkedssing went : words via fun so already australian skip bill but had un - midnight'andssing every the me dissing police scared film needed'(ble much fake seemed mind [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.254 (perp=9.377, rec=0.176, cos=0.202), tot_loss_proj:3.138 [t=0.24s]
prediction: ["[CLS] walkedssing went with words via fun so t insurance skip bill but had'ssing midnight'and - like the me dissing the scared film had'(able much fun seemed mind [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.378 (perp=9.935, rec=0.161, cos=0.231), tot_loss_proj:3.036 [t=0.27s]
prediction: ["[CLS] walked horrible walked : muttering mandela fun so t insurance skip bill ( had'ssing midnight'and - like the me dissing the tickets film had'butably muchoney they mind [SEP]"]
[ 450/2000] tot_loss=2.256 (perp=9.573, rec=0.140, cos=0.202), tot_loss_proj:2.929 [t=0.19s]
prediction: ["[CLS] walked horrible walked ` muttering virus fun so t ticket skip bill ( had'ssing midnight'and - like the me dissing the cost film...'but'much n they mind [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.315 (perp=9.864, rec=0.137, cos=0.205), tot_loss_proj:2.903 [t=0.19s]
prediction: ["[CLS] walked had walked ` muttering virus fun so t ticketur bill ( horrible'ssing midnight horrible and - like the me dissing the cost film...'but'much n they mind [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.276 (perp=9.674, rec=0.129, cos=0.213), tot_loss_proj:2.883 [t=0.22s]
prediction: ["[CLS] walked had walked ` muttering virus fun so much ticketur bill ( horrible'ssing midnight terrible and - than the me dissing the cost film...'but't n they mind [SEP]"]
[ 600/2000] tot_loss=2.208 (perp=9.362, rec=0.122, cos=0.214), tot_loss_proj:2.795 [t=0.18s]
prediction: ["[CLS] walked had walked ` muttering virus fun so much ticketurignant'terrible'ssing midnight terrible and'like the me dissing the cost film...'but't n they mind [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.136 (perp=9.002, rec=0.123, cos=0.213), tot_loss_proj:2.805 [t=0.27s]
prediction: ["[CLS] walked had walked ` muttering virus fun so much ticketurignant'terrible'ssing midnight me and'into the terrible dissing the cost film'' but't n they mind [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.081 (perp=8.736, rec=0.120, cos=0.214), tot_loss_proj:2.998 [t=0.20s]
prediction: ["[CLS] walked had walked ` muttering virus fun so much ticketurignant'terrible'ssing midnight me and'like the terrible dissing the cost film''n't but they mind [SEP]"]
[ 750/2000] tot_loss=2.053 (perp=8.632, rec=0.111, cos=0.215), tot_loss_proj:3.017 [t=0.22s]
prediction: ["[CLS] walked had walked ` muttering virus fun so much `urignant'terrible'ssing midnight me and'into the terrible dissing the cost film''n't but they mind [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.993 (perp=8.337, rec=0.110, cos=0.216), tot_loss_proj:2.989 [t=0.20s]
prediction: ["[CLS] walked had walked ` muttering virus fun so much `urignant'terrible'ssing midnight'me and'into the terrible dissing the cost film'n't but they mind [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.916 (perp=7.962, rec=0.108, cos=0.215), tot_loss_proj:3.036 [t=0.18s]
prediction: ["[CLS] walked had walked ` mutteringmissible fun so much `urignant'terrible'and midnight'messing'into the terrible dissing the cost film'n't but they mind [SEP]"]
[ 900/2000] tot_loss=1.921 (perp=7.969, rec=0.106, cos=0.221), tot_loss_proj:2.935 [t=0.22s]
prediction: ["[CLS] walked had walked ` mutteringpressing fun so much `urignant'terrible'and midnight'messing'into the terrible dissing the cost film'n't but they mind [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.903 (perp=7.946, rec=0.096, cos=0.218), tot_loss_proj:3.001 [t=0.19s]
prediction: ["[CLS] walked had walked ` mutteringmissible fun so muchignantur `'terrible'and midnight'messing'into the terrible dissing the cost film'n't but they mind [SEP]"]
Attempt swap
[1000/2000] tot_loss=2.023 (perp=8.498, rec=0.105, cos=0.219), tot_loss_proj:3.073 [t=0.18s]
prediction: ["[CLS] walked had walked ` mutteringmissible fun so muchignantur `'terrible'and midnight'messing'into the terrible dissing ` cost film'n't but they mind [SEP]"]
[1050/2000] tot_loss=1.982 (perp=8.306, rec=0.103, cos=0.217), tot_loss_proj:2.992 [t=0.26s]
prediction: ["[CLS] walked had walked ` mutteringmissible fun so much `ur `'terrible'and midnight'messing'into the terrible dissing ` cost film'n't but they mind [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.953 (perp=8.161, rec=0.104, cos=0.216), tot_loss_proj:2.702 [t=0.18s]
prediction: ["[CLS] walked had walked but mutteringmissible fun so much `ur `'terrible'and midnight'messing'into the terrible dissing ` cost film'n't ` they mind [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.929 (perp=8.062, rec=0.099, cos=0.218), tot_loss_proj:2.717 [t=0.19s]
prediction: ["[CLS] walked had walked but mutteringmissible fun so much ` ` `'terrible'and midnight'messing'into the terrible dissingur cost film'n't ` they mind [SEP]"]
[1200/2000] tot_loss=1.948 (perp=8.174, rec=0.095, cos=0.218), tot_loss_proj:2.635 [t=0.26s]
prediction: ["[CLS] walked had walked but mutteringpressing fun so much ` ` `'terrible'and midnight'messing'into the terrible dissingur cost film'n't ` they mind [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.917 (perp=8.040, rec=0.098, cos=0.211), tot_loss_proj:2.541 [t=0.19s]
prediction: ["[CLS] walked had walked into mutteringpressing fun so much ` ` `'terrible'and midnight'messing'but the terrible dissingur cost film'n't ` they mind [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.874 (perp=7.810, rec=0.099, cos=0.214), tot_loss_proj:2.508 [t=0.19s]
prediction: ["[CLS] walked had walked into `pressing fun so much ` ` muttering'horrible'and midnight'messing'but the terrible dissingur cost film'n't ` they mind [SEP]"]
[1350/2000] tot_loss=1.879 (perp=7.830, rec=0.100, cos=0.213), tot_loss_proj:2.546 [t=0.21s]
prediction: ["[CLS] walked had walked into `pressing fun so much ` ` muttering'terrible'and midnight'messing'but the terrible dissingur cost film'n't ` they mind [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.878 (perp=7.830, rec=0.097, cos=0.215), tot_loss_proj:2.546 [t=0.26s]
prediction: ["[CLS] walked had walked into `pressing fun so much ` ` muttering'terrible'and midnight'messing'but the terrible dissingur cost film'n't ` they mind [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.878 (perp=7.830, rec=0.098, cos=0.214), tot_loss_proj:2.552 [t=0.20s]
prediction: ["[CLS] walked had walked into `pressing fun so much ` ` muttering'terrible'and midnight'messing'but the terrible dissingur cost film'n't ` they mind [SEP]"]
[1500/2000] tot_loss=1.884 (perp=7.830, rec=0.105, cos=0.213), tot_loss_proj:2.548 [t=0.23s]
prediction: ["[CLS] walked had walked into `pressing fun so much ` ` muttering'terrible'and midnight'messing'but the terrible dissingur cost film'n't ` they mind [SEP]"]
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.882 (perp=7.813, rec=0.103, cos=0.216), tot_loss_proj:2.542 [t=0.20s]
prediction: ["[CLS] walked had walked into `pressing fun so much ` ` muttering'terrible'and messing'midnight'but the terrible dissingur cost film'n't ` they mind [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.877 (perp=7.813, rec=0.099, cos=0.216), tot_loss_proj:2.546 [t=0.19s]
prediction: ["[CLS] walked had walked into `pressing fun so much ` ` muttering'terrible'and messing'midnight'but the terrible dissingur cost film'n't ` they mind [SEP]"]
[1650/2000] tot_loss=1.871 (perp=7.748, rec=0.105, cos=0.217), tot_loss_proj:2.544 [t=0.19s]
prediction: ["[CLS] walked had walked into `pressing fun so much ` ` muttering'terrible'and messing'midnight'but the terrible dissing'cost film'n't ` they mind [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.839 (perp=7.633, rec=0.096, cos=0.216), tot_loss_proj:2.397 [t=0.23s]
prediction: ["[CLS] terrible had walked into `pressing fun so much ` ` muttering'walked'and messing'midnight'but the terrible dissing'cost film'n't ` they mind [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.828 (perp=7.515, rec=0.108, cos=0.217), tot_loss_proj:2.459 [t=0.22s]
prediction: ["[CLS] terrible had walked into `pressing fun so much ` ` muttering'walked'and messing'midnight'but the terrible dissing cost film'n't'` they mind [SEP]"]
[1800/2000] tot_loss=1.835 (perp=7.565, rec=0.104, cos=0.218), tot_loss_proj:2.313 [t=0.24s]
prediction: ["[CLS] terrible had walked out `pressing fun so much ` ` muttering'walked'and messing'midnight'but the terrible dissing cost film'n't'` they mind [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.831 (perp=7.565, rec=0.100, cos=0.218), tot_loss_proj:2.313 [t=0.23s]
prediction: ["[CLS] terrible had walked out `pressing fun so much ` ` muttering'walked'and messing'midnight'but the terrible dissing cost film'n't'` they mind [SEP]"]
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.816 (perp=7.486, rec=0.103, cos=0.216), tot_loss_proj:2.324 [t=0.23s]
prediction: ["[CLS] terrible walked out had `pressing fun so much ` ` muttering'walked'and messing'midnight'but the terrible dissing cost film'n't'` they mind [SEP]"]
[1950/2000] tot_loss=1.811 (perp=7.486, rec=0.096, cos=0.218), tot_loss_proj:2.327 [t=0.22s]
prediction: ["[CLS] terrible walked out had `pressing fun so much ` ` muttering'walked'and messing'midnight'but the terrible dissing cost film'n't'` they mind [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.804 (perp=7.454, rec=0.097, cos=0.216), tot_loss_proj:2.297 [t=0.19s]
prediction: ["[CLS] terrible walked out had `pressing fun so much ` ` muttering'walked'and messing'midnight'but the terrible dissing cost film'n't they `'mind [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] walked had walked into mutteringpressing fun so much ` ` `'terrible'and midnight'messing'but the terrible dissingur cost film'n't ` they mind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.000 | p: 66.667 | r: 61.538
rouge2     | fm: 8.333 | p: 8.696 | r: 8.000
rougeL     | fm: 40.000 | p: 41.667 | r: 38.462
rougeLsum  | fm: 40.000 | p: 41.667 | r: 38.462
r1fm+r2fm = 72.333

[Aggregate metrics]:
rouge1     | fm: 86.405 | p: 85.439 | r: 87.691
rouge2     | fm: 53.169 | p: 52.836 | r: 53.551
rougeL     | fm: 75.245 | p: 74.304 | r: 76.352
rougeLsum  | fm: 75.424 | p: 74.535 | r: 76.570
r1fm+r2fm = 139.574

input #99 time: 0:08:27 | total time: 13:56:01


Average Cosine Similarity: 0.861251925469243
Done with all.
