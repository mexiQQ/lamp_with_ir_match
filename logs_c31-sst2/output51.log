


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.05 --coeff_pooler_match_margin 0.0 --pooler_match_for_init yes --pooler_match_for_optimization yes --pooler_match_for_swap yes 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 46.83it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9992715259422633
highest_index [0]
highest [0.9992715259422633]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.9897326231002808 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 1.6931339502334595 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 1.5862441062927246 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 1.5641170740127563 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 1.3241164684295654 for ['[CLS] panel officer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.276 (perp=10.251, rec=0.209, cos=0.017), tot_loss_proj:2.127 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 100/2000] tot_loss=2.214 (perp=10.251, rec=0.153, cos=0.010), tot_loss_proj:2.118 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.196 (perp=10.251, rec=0.137, cos=0.009), tot_loss_proj:2.112 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.193 (perp=10.251, rec=0.134, cos=0.009), tot_loss_proj:2.124 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.124 (perp=10.251, rec=0.072, cos=0.002), tot_loss_proj:2.121 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.097 (perp=10.251, rec=0.045, cos=0.001), tot_loss_proj:2.126 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.119 (perp=10.251, rec=0.067, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.126 (perp=10.251, rec=0.075, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.109 (perp=10.251, rec=0.057, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.109 (perp=10.251, rec=0.057, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.127 (perp=10.251, rec=0.075, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.117 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.106 (perp=10.251, rec=0.055, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.108 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.110 (perp=10.251, rec=0.058, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.118 (perp=10.251, rec=0.067, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.108 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.105 (perp=10.251, rec=0.053, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.098 (perp=10.251, rec=0.046, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.104 (perp=10.251, rec=0.053, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.108 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.111 (perp=10.251, rec=0.059, cos=0.001), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.116 (perp=10.251, rec=0.064, cos=0.001), tot_loss_proj:2.125 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.101 (perp=10.251, rec=0.049, cos=0.001), tot_loss_proj:2.125 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.122 (perp=10.251, rec=0.070, cos=0.001), tot_loss_proj:2.109 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.115 (perp=10.251, rec=0.063, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.121 (perp=10.251, rec=0.070, cos=0.001), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.126 (perp=10.251, rec=0.074, cos=0.001), tot_loss_proj:2.134 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.106 (perp=10.251, rec=0.054, cos=0.001), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.118 (perp=10.251, rec=0.067, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.106 (perp=10.251, rec=0.054, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.122 (perp=10.251, rec=0.070, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.105 (perp=10.251, rec=0.054, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.129 (perp=10.251, rec=0.077, cos=0.001), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.113 (perp=10.251, rec=0.062, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.115 (perp=10.251, rec=0.064, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.104 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.109 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.114 (perp=10.251, rec=0.063, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.111 (perp=10.251, rec=0.059, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:07:01 | total time: 0:07:01


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9993548278348494
highest_index [0]
highest [0.9993548278348494]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.8751615285873413 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 1.8574330806732178 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 1.8238334655761719 for ['[CLS] football package [SEP]']
[Init] best rec loss: 1.7409363985061646 for ['[CLS] cas giants [SEP]']
[Init] best rec loss: 1.6608680486679077 for ['[CLS] conducted predator [SEP]']
[Init] best rec loss: 1.6287647485733032 for ['[CLS] j native [SEP]']
[Init] best rec loss: 1.5730043649673462 for ['[CLS] dated glazed [SEP]']
[Init] best rec loss: 1.5161365270614624 for ['[CLS] there correspondent [SEP]']
[Init] best rec loss: 1.271039366722107 for ['[CLS] finally relative [SEP]']
[Init] best rec loss: 1.120924472808838 for ['[CLS] course characters [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.290 (perp=10.543, rec=0.180, cos=0.002), tot_loss_proj:2.465 [t=0.17s]
prediction: ['[CLS] splendid splendid [SEP]']
[ 100/2000] tot_loss=2.135 (perp=10.288, rec=0.076, cos=0.001), tot_loss_proj:2.342 [t=0.17s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.116 (perp=10.288, rec=0.057, cos=0.001), tot_loss_proj:2.344 [t=0.17s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.126 (perp=10.288, rec=0.067, cos=0.001), tot_loss_proj:2.352 [t=0.17s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.908 (perp=9.171, rec=0.072, cos=0.001), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.902 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.901 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.907 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.889 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.906 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.889 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.900 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.893 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.910 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.892 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.907 (perp=9.171, rec=0.071, cos=0.001), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.888 (perp=9.171, rec=0.052, cos=0.001), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.896 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.904 (perp=9.171, rec=0.068, cos=0.001), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.895 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.910 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.899 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.903 (perp=9.171, rec=0.068, cos=0.001), tot_loss_proj:1.905 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.892 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.897 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.899 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.896 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.900 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.894 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.888 (perp=9.171, rec=0.052, cos=0.001), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.896 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.894 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.896 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.905 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.897 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.895 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.895 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.886 (perp=9.171, rec=0.051, cos=0.001), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.885 (perp=9.171, rec=0.050, cos=0.001), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:06:52 | total time: 0:13:53


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9994340582458305
highest_index [0]
highest [0.9994340582458305]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 1.3203822374343872 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 1.2476643323898315 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 1.2300113439559937 for ['[CLS] we would working [SEP]']
[Init] best perm rec loss: 1.2278040647506714 for ['[CLS] would we working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.833 (perp=12.233, rec=0.351, cos=0.036), tot_loss_proj:3.223 [t=0.17s]
prediction: ['[CLS] culture much gaining [SEP]']
[ 100/2000] tot_loss=2.412 (perp=10.888, rec=0.225, cos=0.009), tot_loss_proj:2.703 [t=0.17s]
prediction: ['[CLS] much momentum gaining [SEP]']
[ 150/2000] tot_loss=2.318 (perp=10.888, rec=0.136, cos=0.004), tot_loss_proj:2.707 [t=0.17s]
prediction: ['[CLS] much momentum gaining [SEP]']
[ 200/2000] tot_loss=2.277 (perp=10.888, rec=0.097, cos=0.002), tot_loss_proj:2.717 [t=0.17s]
prediction: ['[CLS] much momentum gaining [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.798 (perp=8.515, rec=0.093, cos=0.003), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.773 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.802 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.774 (perp=8.515, rec=0.070, cos=0.001), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.805 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.789 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.797 [t=0.20s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.790 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.775 (perp=8.515, rec=0.071, cos=0.001), tot_loss_proj:1.795 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.769 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.771 (perp=8.515, rec=0.067, cos=0.001), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.766 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.769 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.803 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.773 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.755 (perp=8.515, rec=0.051, cos=0.001), tot_loss_proj:1.795 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.757 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.807 [t=0.20s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.762 (perp=8.515, rec=0.058, cos=0.001), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.776 (perp=8.515, rec=0.072, cos=0.001), tot_loss_proj:1.789 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.802 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.802 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.761 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.809 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.807 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.785 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.757 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.771 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:06:53 | total time: 0:20:47


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.9993001481006445
highest_index [0]
highest [0.9993001481006445]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.7515515089035034 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 1.515498399734497 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 1.510279893875122 for ['[CLS] committee deportivo [SEP]']
[Init] best rec loss: 1.5031687021255493 for ['[CLS] carry including [SEP]']
[Init] best rec loss: 1.4859191179275513 for ['[CLS] has block [SEP]']
[Init] best rec loss: 1.312357783317566 for ['[CLS] anton laughed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.940 (perp=8.385, rec=0.254, cos=0.008), tot_loss_proj:1.762 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 100/2000] tot_loss=1.763 (perp=8.385, rec=0.085, cos=0.002), tot_loss_proj:1.755 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/2000] tot_loss=1.755 (perp=8.385, rec=0.076, cos=0.001), tot_loss_proj:1.751 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[ 200/2000] tot_loss=1.731 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.758 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.757 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.747 (perp=8.385, rec=0.069, cos=0.001), tot_loss_proj:1.760 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.738 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.766 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.731 (perp=8.385, rec=0.053, cos=0.001), tot_loss_proj:1.768 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.751 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.725 (perp=8.385, rec=0.046, cos=0.001), tot_loss_proj:1.754 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.731 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.761 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.743 (perp=8.385, rec=0.065, cos=0.001), tot_loss_proj:1.761 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.758 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.747 (perp=8.385, rec=0.069, cos=0.001), tot_loss_proj:1.759 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.738 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.771 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.763 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.761 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.758 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.743 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.757 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.761 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.758 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.759 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.721 (perp=8.385, rec=0.043, cos=0.001), tot_loss_proj:1.754 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.733 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.758 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.735 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.757 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.764 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.726 (perp=8.385, rec=0.047, cos=0.001), tot_loss_proj:1.757 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.743 (perp=8.385, rec=0.065, cos=0.001), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.753 (perp=8.385, rec=0.075, cos=0.001), tot_loss_proj:1.762 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.751 (perp=8.385, rec=0.073, cos=0.001), tot_loss_proj:1.769 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.736 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.771 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.763 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.733 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.759 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:07:07 | total time: 0:27:54


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.9992301171062454
highest_index [0]
highest [0.9992301171062454]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.8612022399902344 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 1.8395576477050781 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 1.7808197736740112 for ['[CLS] watch joint weekly [SEP]']
[Init] best rec loss: 1.7083849906921387 for ['[CLS] religious tip seat [SEP]']
[Init] best rec loss: 1.4955319166183472 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 1.2935547828674316 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.133 (perp=9.706, rec=0.185, cos=0.007), tot_loss_proj:2.149 [t=0.17s]
prediction: ['[CLS] tiresomently [SEP]']
[ 100/2000] tot_loss=1.598 (perp=7.516, rec=0.092, cos=0.002), tot_loss_proj:1.573 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.570 (perp=7.516, rec=0.065, cos=0.002), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.578 (perp=7.516, rec=0.073, cos=0.002), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.577 (perp=7.516, rec=0.072, cos=0.002), tot_loss_proj:1.552 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.565 (perp=7.516, rec=0.060, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.565 (perp=7.516, rec=0.060, cos=0.001), tot_loss_proj:1.578 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.001), tot_loss_proj:1.568 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.572 (perp=7.516, rec=0.067, cos=0.001), tot_loss_proj:1.575 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.575 (perp=7.516, rec=0.070, cos=0.001), tot_loss_proj:1.568 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.575 (perp=7.516, rec=0.070, cos=0.001), tot_loss_proj:1.571 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.568 (perp=7.516, rec=0.063, cos=0.002), tot_loss_proj:1.558 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.564 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.562 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.573 (perp=7.516, rec=0.068, cos=0.002), tot_loss_proj:1.562 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.563 (perp=7.516, rec=0.058, cos=0.002), tot_loss_proj:1.567 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.563 (perp=7.516, rec=0.058, cos=0.002), tot_loss_proj:1.573 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.567 (perp=7.516, rec=0.062, cos=0.002), tot_loss_proj:1.577 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.564 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.577 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.561 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.562 (perp=7.516, rec=0.058, cos=0.002), tot_loss_proj:1.555 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.555 (perp=7.516, rec=0.051, cos=0.002), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.559 (perp=7.516, rec=0.054, cos=0.002), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.569 (perp=7.516, rec=0.064, cos=0.002), tot_loss_proj:1.573 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.569 (perp=7.516, rec=0.064, cos=0.002), tot_loss_proj:1.568 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.562 (perp=7.516, rec=0.058, cos=0.002), tot_loss_proj:1.560 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.571 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.575 (perp=7.516, rec=0.070, cos=0.002), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.561 (perp=7.516, rec=0.056, cos=0.002), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.575 (perp=7.516, rec=0.070, cos=0.002), tot_loss_proj:1.559 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.571 (perp=7.516, rec=0.067, cos=0.002), tot_loss_proj:1.554 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.561 (perp=7.516, rec=0.057, cos=0.002), tot_loss_proj:1.563 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.565 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.566 (perp=7.516, rec=0.062, cos=0.002), tot_loss_proj:1.563 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.577 (perp=7.516, rec=0.072, cos=0.002), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.567 (perp=7.516, rec=0.062, cos=0.002), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.573 (perp=7.516, rec=0.069, cos=0.002), tot_loss_proj:1.575 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.562 (perp=7.516, rec=0.057, cos=0.002), tot_loss_proj:1.562 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:06:55 | total time: 0:34:49


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9993649146105028
highest_index [0]
highest [0.9993649146105028]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 1.7795944213867188 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 1.6453757286071777 for ['[CLS] works flow [SEP]']
[Init] best rec loss: 1.6053582429885864 for ['[CLS] sol liked [SEP]']
[Init] best rec loss: 1.5769269466400146 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 1.4209589958190918 for ['[CLS] eye central [SEP]']
[Init] best perm rec loss: 1.41153085231781 for ['[CLS] central eye [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.787 (perp=13.024, rec=0.177, cos=0.004), tot_loss_proj:4.070 [t=0.17s]
prediction: ['[CLS] industries ease [SEP]']
[ 100/2000] tot_loss=2.416 (perp=11.405, rec=0.131, cos=0.003), tot_loss_proj:3.902 [t=0.17s]
prediction: ['[CLS] donovan ease [SEP]']
[ 150/2000] tot_loss=2.395 (perp=11.405, rec=0.111, cos=0.003), tot_loss_proj:3.904 [t=0.17s]
prediction: ['[CLS] donovan ease [SEP]']
[ 200/2000] tot_loss=2.590 (perp=12.386, rec=0.109, cos=0.003), tot_loss_proj:4.289 [t=0.17s]
prediction: ['[CLS] ¶ ease [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.527 (perp=11.953, rec=0.133, cos=0.003), tot_loss_proj:4.009 [t=0.17s]
prediction: ['[CLS] ease donovan [SEP]']
[ 300/2000] tot_loss=2.689 (perp=12.884, rec=0.108, cos=0.003), tot_loss_proj:4.081 [t=0.17s]
prediction: ['[CLS] ease pga [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.492 (perp=11.854, rec=0.118, cos=0.003), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.505 (perp=11.854, rec=0.131, cos=0.003), tot_loss_proj:2.578 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/2000] tot_loss=2.489 (perp=11.854, rec=0.115, cos=0.003), tot_loss_proj:2.575 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.493 (perp=11.854, rec=0.119, cos=0.003), tot_loss_proj:2.576 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.485 (perp=11.854, rec=0.111, cos=0.003), tot_loss_proj:2.571 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 600/2000] tot_loss=2.491 (perp=11.854, rec=0.117, cos=0.003), tot_loss_proj:2.577 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.496 (perp=11.854, rec=0.122, cos=0.003), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.485 (perp=11.854, rec=0.111, cos=0.003), tot_loss_proj:2.575 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 750/2000] tot_loss=2.487 (perp=11.854, rec=0.113, cos=0.003), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.479 (perp=11.854, rec=0.105, cos=0.003), tot_loss_proj:2.563 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.496 (perp=11.854, rec=0.122, cos=0.003), tot_loss_proj:2.565 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 900/2000] tot_loss=2.488 (perp=11.854, rec=0.114, cos=0.003), tot_loss_proj:2.581 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.481 (perp=11.854, rec=0.107, cos=0.003), tot_loss_proj:2.567 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1000/2000] tot_loss=2.483 (perp=11.854, rec=0.109, cos=0.003), tot_loss_proj:2.565 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1050/2000] tot_loss=2.486 (perp=11.854, rec=0.112, cos=0.003), tot_loss_proj:2.576 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1100/2000] tot_loss=2.488 (perp=11.854, rec=0.115, cos=0.003), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1150/2000] tot_loss=2.476 (perp=11.854, rec=0.102, cos=0.003), tot_loss_proj:2.563 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1200/2000] tot_loss=2.489 (perp=11.854, rec=0.115, cos=0.003), tot_loss_proj:2.586 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1250/2000] tot_loss=2.464 (perp=11.854, rec=0.091, cos=0.003), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1300/2000] tot_loss=2.479 (perp=11.854, rec=0.105, cos=0.003), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1350/2000] tot_loss=2.485 (perp=11.854, rec=0.112, cos=0.003), tot_loss_proj:2.575 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1400/2000] tot_loss=2.485 (perp=11.854, rec=0.111, cos=0.003), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1450/2000] tot_loss=2.488 (perp=11.854, rec=0.115, cos=0.003), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1500/2000] tot_loss=2.478 (perp=11.854, rec=0.105, cos=0.003), tot_loss_proj:2.561 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1550/2000] tot_loss=2.471 (perp=11.854, rec=0.098, cos=0.003), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1600/2000] tot_loss=2.468 (perp=11.854, rec=0.095, cos=0.003), tot_loss_proj:2.566 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1650/2000] tot_loss=2.459 (perp=11.854, rec=0.085, cos=0.003), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1700/2000] tot_loss=2.469 (perp=11.854, rec=0.096, cos=0.002), tot_loss_proj:2.578 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1750/2000] tot_loss=2.470 (perp=11.854, rec=0.097, cos=0.002), tot_loss_proj:2.576 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1800/2000] tot_loss=2.467 (perp=11.854, rec=0.094, cos=0.002), tot_loss_proj:2.579 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1850/2000] tot_loss=2.473 (perp=11.854, rec=0.100, cos=0.002), tot_loss_proj:2.577 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1900/2000] tot_loss=2.478 (perp=11.854, rec=0.106, cos=0.002), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1950/2000] tot_loss=2.466 (perp=11.854, rec=0.094, cos=0.002), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[2000/2000] tot_loss=2.477 (perp=11.854, rec=0.104, cos=0.002), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 183.333

input #5 time: 0:06:49 | total time: 0:41:39


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.999250469444722
highest_index [0]
highest [0.999250469444722]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 1.902685284614563 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 1.7486958503723145 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 1.7067688703536987 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 1.5019043684005737 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 1.2771662473678589 for ['[CLS] air little [SEP]']
[Init] best rec loss: 1.2549055814743042 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 1.249065637588501 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 1.124966025352478 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 1.1203830242156982 for ['[CLS] too u2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.609 (perp=6.813, rec=0.232, cos=0.015), tot_loss_proj:2.722 [t=0.17s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.707 (perp=8.089, rec=0.087, cos=0.003), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.688 (perp=8.089, rec=0.069, cos=0.002), tot_loss_proj:1.694 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.002), tot_loss_proj:1.676 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.685 (perp=8.089, rec=0.066, cos=0.001), tot_loss_proj:1.701 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.677 (perp=8.089, rec=0.058, cos=0.002), tot_loss_proj:1.683 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.002), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.671 (perp=8.089, rec=0.052, cos=0.002), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.671 (perp=8.089, rec=0.052, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.692 (perp=8.089, rec=0.073, cos=0.001), tot_loss_proj:1.691 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.672 (perp=8.089, rec=0.053, cos=0.001), tot_loss_proj:1.693 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.686 (perp=8.089, rec=0.067, cos=0.001), tot_loss_proj:1.690 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.685 (perp=8.089, rec=0.066, cos=0.001), tot_loss_proj:1.702 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.001), tot_loss_proj:1.692 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.669 (perp=8.089, rec=0.050, cos=0.001), tot_loss_proj:1.689 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.694 (perp=8.089, rec=0.075, cos=0.001), tot_loss_proj:1.680 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.681 (perp=8.089, rec=0.062, cos=0.001), tot_loss_proj:1.702 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.667 (perp=8.089, rec=0.048, cos=0.001), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.691 (perp=8.089, rec=0.072, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.671 (perp=8.089, rec=0.051, cos=0.001), tot_loss_proj:1.681 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.681 (perp=8.089, rec=0.061, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.001), tot_loss_proj:1.693 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.692 (perp=8.089, rec=0.073, cos=0.001), tot_loss_proj:1.675 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.682 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.670 (perp=8.089, rec=0.051, cos=0.001), tot_loss_proj:1.697 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.700 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.670 (perp=8.089, rec=0.051, cos=0.001), tot_loss_proj:1.680 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.671 (perp=8.089, rec=0.052, cos=0.001), tot_loss_proj:1.694 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.688 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.693 (perp=8.089, rec=0.074, cos=0.001), tot_loss_proj:1.696 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.679 (perp=8.089, rec=0.059, cos=0.001), tot_loss_proj:1.688 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.681 (perp=8.089, rec=0.062, cos=0.001), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 185.714

input #6 time: 0:07:10 | total time: 0:48:50


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9991768686555793
highest_index [0]
highest [0.9991768686555793]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 1.8152823448181152 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 1.3960720300674438 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 1.3859511613845825 for ['[CLS] vance golf belt handyolved fl researchtium anonymousina me man murphyoof bearing zetavocationtellrti american autopsy that lie amongₑ free [SEP]']
[Init] best rec loss: 1.2355339527130127 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best rec loss: 1.1908916234970093 for ['[CLS] cod dock # openר sat both grande flow hs most purpose baby beings comppia jenny infants part end pay exactly conference moths median [SEP]']
[Init] best perm rec loss: 1.1874291896820068 for ['[CLS] cod conference dock moths most com baby open hs median purpose flow exactly part end bothp jennypia # sat infants payר beings grande [SEP]']
[Init] best perm rec loss: 1.1840190887451172 for ['[CLS] cod pay part mothsר most hs baby infants grande both sat dockpia beings exactly purpose flow end conference comp jenny open median # [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.383 (perp=10.083, rec=0.346, cos=0.021), tot_loss_proj:2.940 [t=0.17s]
prediction: ['[CLS] having bad trouble evil least there problem his guy stuck badly hurt dates dangerous maybe was precipitation see problems problem. empty beach problem. problem [SEP]']
[ 100/2000] tot_loss=2.303 (perp=10.047, rec=0.280, cos=0.014), tot_loss_proj:3.089 [t=0.18s]
prediction: ['[CLS] having problem attraction evil problem is problem histish dead no put mind problemable was ugly find problem problem. no sides ugly. problem [SEP]']
[ 150/2000] tot_loss=2.112 (perp=9.423, rec=0.223, cos=0.005), tot_loss_proj:2.979 [t=0.17s]
prediction: ["[CLS] has problem understand cute problem is problem he pretty'no ugly mind problemable is ugly i problem problem character no is ugly. problem [SEP]"]
[ 200/2000] tot_loss=2.051 (perp=9.272, rec=0.193, cos=0.004), tot_loss_proj:3.202 [t=0.18s]
prediction: ['[CLS] has problem minds love problem is problem he pretty ; no ugly while problemable is cute i problem problem character no has ugly. problems [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.010 (perp=9.180, rec=0.171, cos=0.003), tot_loss_proj:3.000 [t=0.18s]
prediction: ['[CLS] has bad attraction love problem is no he cute ; no ugly while problemable is mind ; problem character i no majesty ugly. factor [SEP]']
[ 300/2000] tot_loss=1.865 (perp=8.502, rec=0.162, cos=0.003), tot_loss_proj:3.455 [t=0.18s]
prediction: ['[CLS] has cute factor love problem is no he cute ; no ugly while problemable is mind ; problem character i no has ugly. factor [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.933 (perp=8.925, rec=0.145, cos=0.003), tot_loss_proj:2.949 [t=0.19s]
prediction: ['[CLS] has not cute factor love problem is he cute ; no ugly the problemable is mind ; problem character i no where ugly ugly factor [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.871 (perp=8.621, rec=0.143, cos=0.004), tot_loss_proj:2.666 [t=0.17s]
prediction: ['[CLS] ugly not cute factor love problem is he cute. no here the problemable is mind ; problem character i nology has ugly factor [SEP]']
[ 450/2000] tot_loss=1.792 (perp=8.344, rec=0.120, cos=0.003), tot_loss_proj:2.711 [t=0.18s]
prediction: ['[CLS] ugly not cute factor love problem is he cute. no here the problemable is mind ; factor character i no where has ugly factor [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.758 (perp=8.232, rec=0.110, cos=0.002), tot_loss_proj:2.413 [t=0.17s]
prediction: ['[CLS] ugly not cute factor love problem no he cute. no here the problemable mind is ; factor character i no, has ugly factor [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.740 (perp=8.126, rec=0.112, cos=0.002), tot_loss_proj:2.530 [t=0.17s]
prediction: ['[CLS] ugly not cute factor love no problem he cute. no here the problemable mind is ; factor character i no, has ugly factor [SEP]']
[ 600/2000] tot_loss=1.728 (perp=8.134, rec=0.099, cos=0.002), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] ugly not cute factor love no problem he cute. no here the problemable mind is ; factor character i no, has. factor [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.764 (perp=8.332, rec=0.096, cos=0.002), tot_loss_proj:2.646 [t=0.18s]
prediction: ['[CLS] ugly not cute factor love no problem he cute. no here the theable mind is factor ; character i no, has ugly factor [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.726 (perp=8.138, rec=0.096, cos=0.002), tot_loss_proj:2.716 [t=0.17s]
prediction: ['[CLS] ugly not cute factor love no problem he cute. no here has theable mind is factor ; character i no, the. factor [SEP]']
[ 750/2000] tot_loss=1.723 (perp=8.138, rec=0.094, cos=0.002), tot_loss_proj:2.714 [t=0.17s]
prediction: ['[CLS] ugly not cute factor love no problem he cute. no here has theable mind is factor ; character i no, the. factor [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.674 (perp=7.882, rec=0.095, cos=0.002), tot_loss_proj:2.460 [t=0.18s]
prediction: ['[CLS] ugly not cute factor love the problem he cute. no here has theable mind is factor ; character i no, no. factor [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.643 (perp=7.688, rec=0.103, cos=0.002), tot_loss_proj:2.410 [t=0.18s]
prediction: ['[CLS] ugly not cute factor love the problem he cute has no here. theable mind is factor ; character i no, no. factor [SEP]']
[ 900/2000] tot_loss=1.634 (perp=7.688, rec=0.094, cos=0.002), tot_loss_proj:2.411 [t=0.18s]
prediction: ['[CLS] ugly not cute factor love the problem he cute has no here. theable mind is factor ; character i no, no. factor [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.598 (perp=7.517, rec=0.092, cos=0.002), tot_loss_proj:2.332 [t=0.17s]
prediction: ['[CLS] ugly not cute factor love the problem he cute has no here. theable mind is factor ; character i no, no factor. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.524 (perp=7.146, rec=0.092, cos=0.002), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no here. theable mind is factor ; character i no, no factor. [SEP]']
[1050/2000] tot_loss=1.521 (perp=7.146, rec=0.090, cos=0.002), tot_loss_proj:2.138 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no here. theable mind is factor ; character i no, no factor. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.450 (perp=6.821, rec=0.083, cos=0.002), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable here is factor ; character i no, no factor. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.456 (perp=6.821, rec=0.089, cos=0.002), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable here is factor ; character i no, no factor. [SEP]']
[1200/2000] tot_loss=1.459 (perp=6.821, rec=0.093, cos=0.002), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable here is factor ; character i no, no factor. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.413 (perp=6.634, rec=0.084, cos=0.002), tot_loss_proj:1.990 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor is here ; character i no, no factor. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.409 (perp=6.634, rec=0.081, cos=0.002), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor is here ; character i no, no factor. [SEP]']
[1350/2000] tot_loss=1.415 (perp=6.634, rec=0.086, cos=0.002), tot_loss_proj:1.987 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor is here ; character i no, no factor. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.414 (perp=6.634, rec=0.086, cos=0.002), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor is here ; character i no, no factor. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.352 (perp=6.343, rec=0.081, cos=0.002), tot_loss_proj:1.916 [t=0.18s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor is here ; i no character, no factor. [SEP]']
[1500/2000] tot_loss=1.358 (perp=6.343, rec=0.088, cos=0.002), tot_loss_proj:1.907 [t=0.18s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor is here ; i no character, no factor. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.362 (perp=6.343, rec=0.092, cos=0.002), tot_loss_proj:1.908 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor is here ; i no character, no factor. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.348 (perp=6.295, rec=0.087, cos=0.002), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor here is ; i no character, no factor. [SEP]']
[1650/2000] tot_loss=1.343 (perp=6.295, rec=0.082, cos=0.002), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor here is ; i no character, no factor. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.355 (perp=6.295, rec=0.094, cos=0.002), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor here is ; i no character, no factor. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.357 (perp=6.295, rec=0.096, cos=0.002), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor here is ; i no character, no factor. [SEP]']
[1800/2000] tot_loss=1.342 (perp=6.295, rec=0.081, cos=0.002), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS] ugly not cute love factor the problem he really has no mind. theable factor here is ; i no character, no factor. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.359 (perp=6.335, rec=0.090, cos=0.002), tot_loss_proj:1.941 [t=0.19s]
prediction: ['[CLS] ugly not cute love factor the problem he either has no mind. theable factor here is ; i no character, no factor. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.357 (perp=6.341, rec=0.087, cos=0.002), tot_loss_proj:1.945 [t=0.18s]
prediction: ['[CLS] ugly not cute love factor the problem he has either no mind. theable factor here is ; i no character, no factor. [SEP]']
[1950/2000] tot_loss=1.359 (perp=6.341, rec=0.089, cos=0.002), tot_loss_proj:1.944 [t=0.18s]
prediction: ['[CLS] ugly not cute love factor the problem he has either no mind. theable factor here is ; i no character, no factor. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.356 (perp=6.335, rec=0.087, cos=0.002), tot_loss_proj:1.946 [t=0.19s]
prediction: ['[CLS] ugly not cute love factor the problem he either has no mind. theable factor here is ; i no character, no factor. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] ugly not cute love factor the problem he really has no mind. theable factor here is ; i no character, no factor. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.273 | p: 73.913 | r: 80.952
rouge2     | fm: 19.048 | p: 18.182 | r: 20.000
rougeL     | fm: 45.455 | p: 43.478 | r: 47.619
rougeLsum  | fm: 45.455 | p: 43.478 | r: 47.619
r1fm+r2fm = 96.320

[Aggregate metrics]:
rouge1     | fm: 97.159 | p: 96.739 | r: 97.619
rouge2     | fm: 77.381 | p: 77.273 | r: 77.500
rougeL     | fm: 90.057 | p: 89.810 | r: 90.327
rougeLsum  | fm: 90.057 | p: 89.810 | r: 90.327
r1fm+r2fm = 174.540

input #7 time: 0:07:02 | total time: 0:55:52


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9994032830483026
highest_index [0]
highest [0.9994032830483026]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 1.3184598684310913 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 1.3084146976470947 for ['[CLS] thunder edge tender youngaz 505acality forced cheers bed lochley concacaf pm some commercial eliot advocate flow bubble habits ease bless [SEP]']
[Init] best rec loss: 1.29958176612854 for ['[CLS] slate conducted maps charlierocity these leaked too count search cody misery cannon vet vote prior foreign. ratio atm boys trafficrating 1st [SEP]']
[Init] best rec loss: 1.2899292707443237 for ['[CLS] descent caughtway holiday riding fist stages died pi focusedョeis anywhere half vine tarzan center sunlight away broughteda held reserved website [SEP]']
[Init] best perm rec loss: 1.2864528894424438 for ['[CLS] reserved focused away stages riding tarzanway caught center anywhere brought pi sunlight website holiday fist half held diedeis descenteda vineョ [SEP]']
[Init] best perm rec loss: 1.2788499593734741 for ['[CLS] stages holiday descent sunlightway half center fist away vine died tarzan riding focused website pi anywhere broughtedaeis heldョ reserved caught [SEP]']
[Init] best perm rec loss: 1.2772839069366455 for ['[CLS] anywhere stages riding halfeis away died center held focusedway brought tarzan sunlight holiday reservededa pi descentョ caught fist website vine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.382 (perp=14.458, rec=0.427, cos=0.063), tot_loss_proj:4.396 [t=0.20s]
prediction: ['[CLS] estate ( metropolitan northern season book owned singapore bergman plagued lakes pena consecutive debt punishment accredited storm feesia rear played passage includes save [SEP]']
[ 100/2000] tot_loss=2.976 (perp=12.882, rec=0.356, cos=0.044), tot_loss_proj:3.680 [t=0.20s]
prediction: ['[CLS] contract ( literary gate vanity book tells arts vanity plaguedless majesty巿 built pay planned debt debtia jose sable bay pays net [SEP]']
[ 150/2000] tot_loss=2.440 (perp=10.842, rec=0.256, cos=0.015), tot_loss_proj:3.129 [t=0.20s]
prediction: ['[CLS] uncle for vanity a vanity film civil film vanity vanitylessgle lucky that pays what debt debtia film sablei payments! [SEP]']
[ 200/2000] tot_loss=2.699 (perp=12.309, rec=0.203, cos=0.035), tot_loss_proj:3.926 [t=0.21s]
prediction: ['[CLS] fright having a film vanity film doubt film vanity vanityfulgle an that pays what debt debt film josegnanti paymentscious [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.899 (perp=12.574, rec=0.319, cos=0.065), tot_loss_proj:3.735 [t=0.19s]
prediction: ['[CLS] fright societe distraction a vanity asset doubt an film vanity vanitylessiness that pays what debt owedco itsxi y payments our [SEP]']
[ 300/2000] tot_loss=2.705 (perp=12.412, rec=0.211, cos=0.011), tot_loss_proj:3.679 [t=0.19s]
prediction: ['[CLS] fright secular y a vanity asset doubt an film vanity vanityediness that pays what debt owedproofacingmax amount payments okay [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.618 (perp=12.129, rec=0.184, cos=0.008), tot_loss_proj:3.550 [t=0.19s]
prediction: ['[CLS] fright holds ; a vanity asset doubt an film vanity vanityediness that pays what debt owedoned othermax µ owed okay [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.475 (perp=11.505, rec=0.168, cos=0.006), tot_loss_proj:3.427 [t=0.18s]
prediction: ['[CLS] fright holds, a vanity asset doubt a filmed vanity vanity illusion that pays what debt owedlike othermax µ debt playstation [SEP]']
[ 450/2000] tot_loss=2.452 (perp=11.459, rec=0.155, cos=0.005), tot_loss_proj:3.529 [t=0.17s]
prediction: ['[CLS] benign pays, a vanity asset doubt a filmed fright vanity illusion that pays what debt owedlike othermaxi debt playstation [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.355 (perp=11.063, rec=0.138, cos=0.004), tot_loss_proj:3.296 [t=0.17s]
prediction: ['[CLS] benign pays, a vanity asset doubt a frighted film vanity illusion that pays what debt owed mira othermaxi owedshah [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.387 (perp=11.097, rec=0.147, cos=0.021), tot_loss_proj:3.270 [t=0.18s]
prediction: ['[CLS] benign pays, a vanity asset doubt a frighted film vanitygingly that pays whatmax debt owed mira other they owedi [SEP]']
[ 600/2000] tot_loss=2.350 (perp=11.109, rec=0.125, cos=0.003), tot_loss_proj:3.146 [t=0.17s]
prediction: ['[CLS] benign pays, a vanity investors doubt s frightless film vanity, that pays whatmax debt owed mira other they owedi [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.349 (perp=11.094, rec=0.128, cos=0.003), tot_loss_proj:3.312 [t=0.17s]
prediction: ['[CLS] benign other, a frightmax doubt s frighti film vanity, that pays whatmax debt owed mira pays they owedi [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.202 (perp=10.411, rec=0.115, cos=0.005), tot_loss_proj:3.120 [t=0.17s]
prediction: ['[CLS] benign other, a frightmax doubt s frighti film vanity, that pays what miramax debt owed pays they owesi [SEP]']
[ 750/2000] tot_loss=2.195 (perp=10.401, rec=0.112, cos=0.003), tot_loss_proj:3.168 [t=0.17s]
prediction: ['[CLS] benign other, a frightmax doubt s frighti film vanity, that pays what miramax debt owed no they owesi [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.141 (perp=10.126, rec=0.113, cos=0.003), tot_loss_proj:2.987 [t=0.17s]
prediction: ['[CLS] benign other, a fright no doubt s frighti film vanity, that pays what miramax debt owedmax they owesi [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.036 (perp=9.618, rec=0.109, cos=0.003), tot_loss_proj:2.963 [t=0.17s]
prediction: ['[CLS] benign other, frightful no doubt s ai film vanity, that pays what miramax debt owedmax they owesi [SEP]']
[ 900/2000] tot_loss=2.041 (perp=9.618, rec=0.115, cos=0.002), tot_loss_proj:2.959 [t=0.17s]
prediction: ['[CLS] benign other, frightful no doubt s ai film vanity, that pays what miramax debt owedmax they owesi [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.989 (perp=9.404, rec=0.105, cos=0.002), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] benign alternative, frightful no doubt si a film vanity, that pays what miramax debt owedmax they owesi [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.980 (perp=9.376, rec=0.102, cos=0.002), tot_loss_proj:2.722 [t=0.17s]
prediction: ['[CLS] benign alternative, frightful no doubt si a vanity film, that pays what miramax debt owedmax they owesi [SEP]']
[1050/2000] tot_loss=1.977 (perp=9.376, rec=0.099, cos=0.002), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] benign alternative, frightful no doubt si a vanity film, that pays what miramax debt owedmax they owesi [SEP]']
Attempt swap
[1100/2000] tot_loss=1.968 (perp=9.376, rec=0.091, cos=0.002), tot_loss_proj:2.724 [t=0.18s]
prediction: ['[CLS] benign alternative, frightful no doubt si a vanity film, that pays what miramax debt owedmax they owesi [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.945 (perp=9.239, rec=0.095, cos=0.002), tot_loss_proj:2.687 [t=0.17s]
prediction: ['[CLS] benign alternative, frightful no doubt si a vanity film, that pays what miramax debt they owedmax owesi [SEP]']
[1200/2000] tot_loss=1.950 (perp=9.239, rec=0.100, cos=0.002), tot_loss_proj:2.682 [t=0.17s]
prediction: ['[CLS] benign alternative, frightful no doubt si a vanity film, that pays what miramax debt they owedmax owesi [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.935 (perp=9.084, rec=0.112, cos=0.006), tot_loss_proj:2.677 [t=0.17s]
prediction: ['[CLS] benign alternative, a frightful no doubt si vanity film, that pays what miramax debt they owedmax owesi [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.845 (perp=8.660, rec=0.108, cos=0.005), tot_loss_proj:2.554 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt s benigni vanity film, that pays what miramax debt they owedmax owesi [SEP]']
[1350/2000] tot_loss=1.888 (perp=8.928, rec=0.101, cos=0.002), tot_loss_proj:2.504 [t=0.18s]
prediction: ['[CLS] alternative, a frightful no doubt s benigni vanity film, that pays what miramax debt felt owedmax owesi [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.845 (perp=8.711, rec=0.101, cos=0.002), tot_loss_proj:2.535 [t=0.18s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni s film, that pays what miramax debt felt owedmax owesi [SEP]']
Attempt swap
[1450/2000] tot_loss=1.840 (perp=8.711, rec=0.095, cos=0.003), tot_loss_proj:2.534 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni s film, that pays what miramax debt felt owedmax owesi [SEP]']
[1500/2000] tot_loss=1.843 (perp=8.711, rec=0.098, cos=0.002), tot_loss_proj:2.538 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni s film, that pays what miramax debt felt owedmax owesi [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.816 (perp=8.574, rec=0.099, cos=0.003), tot_loss_proj:2.493 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni s film, that pays what miramax felt debt owedmax owesi [SEP]']
Attempt swap
[1600/2000] tot_loss=1.813 (perp=8.574, rec=0.096, cos=0.002), tot_loss_proj:2.491 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni s film, that pays what miramax felt debt owedmax owesi [SEP]']
[1650/2000] tot_loss=1.815 (perp=8.574, rec=0.098, cos=0.002), tot_loss_proj:2.493 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni s film, that pays what miramax felt debt owedmax owesi [SEP]']
Attempt swap
[1700/2000] tot_loss=1.807 (perp=8.574, rec=0.090, cos=0.002), tot_loss_proj:2.497 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni s film, that pays what miramax felt debt owedmax owesi [SEP]']
Attempt swap
[1750/2000] tot_loss=1.817 (perp=8.574, rec=0.100, cos=0.002), tot_loss_proj:2.496 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni s film, that pays what miramax felt debt owedmax owesi [SEP]']
[1800/2000] tot_loss=1.804 (perp=8.574, rec=0.087, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni s film, that pays what miramax felt debt owedmax owesi [SEP]']
Attempt swap
[1850/2000] tot_loss=1.814 (perp=8.574, rec=0.097, cos=0.002), tot_loss_proj:2.496 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni s film, that pays what miramax felt debt owedmax owesi [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.791 (perp=8.450, rec=0.099, cos=0.002), tot_loss_proj:2.504 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni film, s that pays what miramax felt debt owedmax owesi [SEP]']
[1950/2000] tot_loss=1.783 (perp=8.450, rec=0.091, cos=0.002), tot_loss_proj:2.508 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni film, s that pays what miramax felt debt owedmax owesi [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.772 (perp=8.358, rec=0.097, cos=0.002), tot_loss_proj:2.465 [t=0.17s]
prediction: ['[CLS] alternative, a frightful no doubt vanity benigni film, s that pays what miramax felt debt owedmaxi owes [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] alternative, a frightful no doubt vanity benigni film, s that pays what miramax felt debt owedmaxi owes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.051 | p: 84.211 | r: 80.000
rouge2     | fm: 16.216 | p: 16.667 | r: 15.789
rougeL     | fm: 56.410 | p: 57.895 | r: 55.000
rougeLsum  | fm: 56.410 | p: 57.895 | r: 55.000
r1fm+r2fm = 98.267

[Aggregate metrics]:
rouge1     | fm: 95.480 | p: 95.347 | r: 95.661
rouge2     | fm: 70.585 | p: 70.539 | r: 70.643
rougeL     | fm: 86.318 | p: 86.264 | r: 86.402
rougeLsum  | fm: 86.318 | p: 86.264 | r: 86.402
r1fm+r2fm = 166.065

input #8 time: 0:07:07 | total time: 1:03:00


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9993981275486599
highest_index [0]
highest [0.9993981275486599]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 1.700202226638794 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 1.27736234664917 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 1.1396721601486206 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 1.0866336822509766 for ['[CLS] video guys glass stilldleulf explorer eva [SEP]']
[Init] best perm rec loss: 1.0833972692489624 for ['[CLS] explorerdle video guys glass evaulf still [SEP]']
[Init] best perm rec loss: 1.0814344882965088 for ['[CLS] video guysulf still glassdle explorer eva [SEP]']
[Init] best perm rec loss: 1.08087956905365 for ['[CLS] evadle guys video glass still explorerulf [SEP]']
[Init] best perm rec loss: 1.079574704170227 for ['[CLS] still guys explorer videoulf evadle glass [SEP]']
[Init] best perm rec loss: 1.079067349433899 for ['[CLS] glass explorerulfdle still guys video eva [SEP]']
[Init] best perm rec loss: 1.0773389339447021 for ['[CLS] videoulf guys explorer stilldle glass eva [SEP]']
[Init] best perm rec loss: 1.075656533241272 for ['[CLS] still eva explorerdle glass guysulf video [SEP]']
[Init] best perm rec loss: 1.075609564781189 for ['[CLS]dle stillulf glass video eva guys explorer [SEP]']
[Init] best perm rec loss: 1.0754793882369995 for ['[CLS] still evaulf guys video explorer glassdle [SEP]']
[Init] best perm rec loss: 1.0741891860961914 for ['[CLS] glass still eva guys videodle explorerulf [SEP]']
[Init] best perm rec loss: 1.0710862874984741 for ['[CLS] eva video still glass explorer guysdleulf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.068 (perp=13.461, rec=0.304, cos=0.073), tot_loss_proj:3.844 [t=0.17s]
prediction: ['[CLS] bunny clap trick soft clapprt black [SEP]']
[ 100/2000] tot_loss=2.327 (perp=10.295, rec=0.246, cos=0.021), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] comedy clap of soft claptraed lecture [SEP]']
[ 150/2000] tot_loss=2.293 (perp=10.575, rec=0.166, cos=0.012), tot_loss_proj:3.156 [t=0.17s]
prediction: ['[CLS] snap clap of soft claptraedp [SEP]']
[ 200/2000] tot_loss=2.281 (perp=10.636, rec=0.146, cos=0.008), tot_loss_proj:3.060 [t=0.17s]
prediction: ['[CLS] snaptra of soft claptraedp [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.042 (perp=9.460, rec=0.143, cos=0.008), tot_loss_proj:2.901 [t=0.17s]
prediction: ['[CLS] harveytraed of soft claptrap [SEP]']
[ 300/2000] tot_loss=2.580 (perp=12.355, rec=0.107, cos=0.002), tot_loss_proj:3.251 [t=0.17s]
prediction: ['[CLS] metaphysicaltraed of soft clapheadp [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.795 (perp=8.477, rec=0.097, cos=0.002), tot_loss_proj:2.398 [t=0.17s]
prediction: ['[CLS] metaphysicalheaded of soft claptrap [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.663 (perp=7.913, rec=0.079, cos=0.001), tot_loss_proj:1.985 [t=0.17s]
prediction: ['[CLS] metaphysical softheaded of claptrap [SEP]']
[ 450/2000] tot_loss=1.660 (perp=7.913, rec=0.076, cos=0.001), tot_loss_proj:1.986 [t=0.17s]
prediction: ['[CLS] metaphysical softheaded of claptrap [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.590 (perp=7.643, rec=0.060, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.593 (perp=7.643, rec=0.063, cos=0.001), tot_loss_proj:1.606 [t=0.17s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
[ 600/2000] tot_loss=1.587 (perp=7.643, rec=0.057, cos=0.001), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.592 (perp=7.643, rec=0.062, cos=0.001), tot_loss_proj:1.620 [t=0.19s]
prediction: ['[CLS] of softheaded metaphysical claptrap [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.545 (perp=7.384, rec=0.067, cos=0.001), tot_loss_proj:1.639 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 750/2000] tot_loss=1.538 (perp=7.384, rec=0.060, cos=0.001), tot_loss_proj:1.645 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.543 (perp=7.384, rec=0.065, cos=0.001), tot_loss_proj:1.649 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.544 (perp=7.384, rec=0.066, cos=0.001), tot_loss_proj:1.642 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 900/2000] tot_loss=1.535 (perp=7.384, rec=0.057, cos=0.001), tot_loss_proj:1.637 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.538 (perp=7.384, rec=0.060, cos=0.001), tot_loss_proj:1.636 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.547 (perp=7.384, rec=0.069, cos=0.001), tot_loss_proj:1.639 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1050/2000] tot_loss=1.541 (perp=7.384, rec=0.063, cos=0.001), tot_loss_proj:1.645 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.536 (perp=7.384, rec=0.058, cos=0.001), tot_loss_proj:1.641 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.540 (perp=7.384, rec=0.062, cos=0.001), tot_loss_proj:1.639 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1200/2000] tot_loss=1.550 (perp=7.384, rec=0.072, cos=0.001), tot_loss_proj:1.644 [t=0.20s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.546 (perp=7.384, rec=0.068, cos=0.001), tot_loss_proj:1.643 [t=0.20s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.530 (perp=7.384, rec=0.052, cos=0.001), tot_loss_proj:1.636 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1350/2000] tot_loss=1.544 (perp=7.384, rec=0.066, cos=0.001), tot_loss_proj:1.637 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.537 (perp=7.384, rec=0.059, cos=0.001), tot_loss_proj:1.637 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.533 (perp=7.384, rec=0.055, cos=0.001), tot_loss_proj:1.643 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1500/2000] tot_loss=1.537 (perp=7.384, rec=0.059, cos=0.001), tot_loss_proj:1.649 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.551 (perp=7.384, rec=0.073, cos=0.001), tot_loss_proj:1.642 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.546 (perp=7.384, rec=0.068, cos=0.001), tot_loss_proj:1.642 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1650/2000] tot_loss=1.540 (perp=7.384, rec=0.062, cos=0.001), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.532 (perp=7.384, rec=0.054, cos=0.001), tot_loss_proj:1.645 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.536 (perp=7.384, rec=0.058, cos=0.001), tot_loss_proj:1.645 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1800/2000] tot_loss=1.548 (perp=7.384, rec=0.070, cos=0.001), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.542 (perp=7.384, rec=0.064, cos=0.001), tot_loss_proj:1.637 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.545 (perp=7.384, rec=0.067, cos=0.001), tot_loss_proj:1.634 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1950/2000] tot_loss=1.549 (perp=7.384, rec=0.071, cos=0.001), tot_loss_proj:1.642 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.539 (perp=7.384, rec=0.061, cos=0.001), tot_loss_proj:1.642 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical softheaded claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 95.932 | p: 95.812 | r: 96.095
rouge2     | fm: 67.810 | p: 67.636 | r: 68.000
rougeL     | fm: 86.282 | p: 86.579 | r: 86.381
rougeLsum  | fm: 86.282 | p: 86.196 | r: 86.381
r1fm+r2fm = 163.742

input #9 time: 0:07:02 | total time: 1:10:02


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9991472052153934
highest_index [0]
highest [0.9991472052153934]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 1.8671343326568604 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 1.8420976400375366 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 1.4058338403701782 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 1.3968875408172607 for ['[CLS] themes up sheep blessedblood angel common orderoric places totally level sound [SEP]']
[Init] best perm rec loss: 1.3953274488449097 for ['[CLS]blood common angeloric up sheep order blessed sound level totally places themes [SEP]']
[Init] best perm rec loss: 1.3951473236083984 for ['[CLS] themesoric soundblood sheep up places common blessed level order totally angel [SEP]']
[Init] best perm rec loss: 1.3938393592834473 for ['[CLS] angel up level order totally themes placesblood sheeporic sound blessed common [SEP]']
[Init] best perm rec loss: 1.3935538530349731 for ['[CLS] totally up common level places sheep order sound blessed themes angeloricblood [SEP]']
[Init] best perm rec loss: 1.3933236598968506 for ['[CLS] sheep places common sound themes totally order blessed level upbloodoric angel [SEP]']
[Init] best perm rec loss: 1.3882167339324951 for ['[CLS] places sheep totally level uporic blessed order angel sound common themesblood [SEP]']
[Init] best perm rec loss: 1.387595295906067 for ['[CLS]bloodoric blessed totally up themes places angel sheep common sound order level [SEP]']
[Init] best perm rec loss: 1.3872023820877075 for ['[CLS] sound blessedblood common up sheep places order level totally themes angeloric [SEP]']
[Init] best perm rec loss: 1.3837432861328125 for ['[CLS] sound places angel common totally level sheep order blessed uporic themesblood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.729 (perp=12.049, rec=0.303, cos=0.016), tot_loss_proj:3.166 [t=0.17s]
prediction: ['[CLS] metaphor balance balanced safelyly documents focus.. freedomesian combines extensively [SEP]']
[ 100/2000] tot_loss=2.199 (perp=9.839, rec=0.223, cos=0.009), tot_loss_proj:2.784 [t=0.17s]
prediction: ['[CLS] metaphor balance balance ablyulsive effect rhythms. peace. balance actively [SEP]']
[ 150/2000] tot_loss=2.075 (perp=9.390, rec=0.191, cos=0.006), tot_loss_proj:2.959 [t=0.17s]
prediction: ['[CLS] theory balance balance ab withulsive moment rhythms. peacely balance ab [SEP]']
[ 200/2000] tot_loss=2.251 (perp=10.414, rec=0.164, cos=0.005), tot_loss_proj:3.255 [t=0.17s]
prediction: ['[CLS] really balance ab withulsive incident rhythms.lerlys ab [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.998 (perp=9.202, rec=0.153, cos=0.005), tot_loss_proj:3.024 [t=0.17s]
prediction: ['[CLS] balance ab really withulsive incident rhythms. proplys ab [SEP]']
[ 300/2000] tot_loss=2.228 (perp=10.555, rec=0.113, cos=0.004), tot_loss_proj:3.364 [t=0.17s]
prediction: ['[CLS] balance ab really withulsive incident rhythms. prop incidents ab [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.022 (perp=8.845, rec=0.245, cos=0.008), tot_loss_proj:3.043 [t=0.17s]
prediction: ['[CLS] balance ab really with. rhythms. retroal.s ab [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.813 (perp=8.106, rec=0.187, cos=0.005), tot_loss_proj:2.752 [t=0.17s]
prediction: ['[CLS] balance ab really with. rhythms. retroulsive abs. [SEP]']
[ 450/2000] tot_loss=2.072 (perp=9.599, rec=0.148, cos=0.004), tot_loss_proj:2.892 [t=0.17s]
prediction: ['[CLS] balanceulsive really with. rhythms.erinaulsive abs. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.893 (perp=8.764, rec=0.136, cos=0.004), tot_loss_proj:2.929 [t=0.18s]
prediction: ['[CLS] balances really with. rhythms. privacyulsive abulsive. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.829 (perp=8.493, rec=0.127, cos=0.003), tot_loss_proj:2.608 [t=0.18s]
prediction: ['[CLS] balances really withulsive rhythms. incident time abulsive. [SEP]']
[ 600/2000] tot_loss=1.826 (perp=8.493, rec=0.124, cos=0.003), tot_loss_proj:2.600 [t=0.18s]
prediction: ['[CLS] balances really withulsive rhythms. incident time abulsive. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.799 (perp=7.818, rec=0.215, cos=0.020), tot_loss_proj:2.642 [t=0.17s]
prediction: ['[CLS] balances really with incidentulsive rhythms. time abulsive. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.724 (perp=7.776, rec=0.164, cos=0.006), tot_loss_proj:2.910 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. abulsive? [SEP]']
[ 750/2000] tot_loss=1.620 (perp=7.477, rec=0.121, cos=0.004), tot_loss_proj:2.659 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. abulsive, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.619 (perp=7.477, rec=0.120, cos=0.003), tot_loss_proj:2.657 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. abulsive, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.744 (perp=8.088, rec=0.123, cos=0.003), tot_loss_proj:3.280 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
[ 900/2000] tot_loss=1.740 (perp=8.088, rec=0.120, cos=0.003), tot_loss_proj:3.279 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.726 (perp=8.088, rec=0.106, cos=0.003), tot_loss_proj:3.278 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.724 (perp=8.088, rec=0.104, cos=0.003), tot_loss_proj:3.281 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
[1050/2000] tot_loss=1.733 (perp=8.088, rec=0.112, cos=0.003), tot_loss_proj:3.272 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.727 (perp=8.088, rec=0.107, cos=0.003), tot_loss_proj:3.277 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.731 (perp=8.088, rec=0.110, cos=0.003), tot_loss_proj:3.274 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
[1200/2000] tot_loss=1.723 (perp=8.088, rec=0.102, cos=0.003), tot_loss_proj:3.276 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.726 (perp=8.088, rec=0.106, cos=0.003), tot_loss_proj:3.276 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.732 (perp=8.088, rec=0.112, cos=0.003), tot_loss_proj:3.277 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
[1350/2000] tot_loss=1.723 (perp=8.088, rec=0.103, cos=0.003), tot_loss_proj:3.277 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab accident, [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.708 (perp=8.035, rec=0.099, cos=0.003), tot_loss_proj:3.079 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab, accident [SEP]']
Attempt swap
[1450/2000] tot_loss=1.710 (perp=8.035, rec=0.100, cos=0.003), tot_loss_proj:3.081 [t=0.18s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab, accident [SEP]']
[1500/2000] tot_loss=1.710 (perp=8.035, rec=0.100, cos=0.003), tot_loss_proj:3.079 [t=0.18s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab, accident [SEP]']
Attempt swap
[1550/2000] tot_loss=1.718 (perp=8.035, rec=0.109, cos=0.003), tot_loss_proj:3.081 [t=0.17s]
prediction: ['[CLS] time balances really with incidentulsive rhythms. ab, accident [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.719 (perp=7.860, rec=0.144, cos=0.004), tot_loss_proj:2.695 [t=0.17s]
prediction: ['[CLS] time ab,ulsive balances really with incidentulsive rhythms. [SEP]']
[1650/2000] tot_loss=1.695 (perp=7.860, rec=0.120, cos=0.003), tot_loss_proj:2.688 [t=0.17s]
prediction: ['[CLS] time ab,ulsive balances really with incidentulsive rhythms. [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.502 (perp=6.905, rec=0.118, cos=0.003), tot_loss_proj:2.360 [t=0.17s]
prediction: ['[CLS] time ab balances really with incident,ulsiveulsive rhythms. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.495 (perp=6.905, rec=0.111, cos=0.003), tot_loss_proj:2.357 [t=0.17s]
prediction: ['[CLS] time ab balances really with incident,ulsiveulsive rhythms. [SEP]']
[1800/2000] tot_loss=1.487 (perp=6.905, rec=0.103, cos=0.003), tot_loss_proj:2.354 [t=0.17s]
prediction: ['[CLS] time ab balances really with incident,ulsiveulsive rhythms. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.485 (perp=6.905, rec=0.101, cos=0.003), tot_loss_proj:2.357 [t=0.17s]
prediction: ['[CLS] time ab balances really with incident,ulsiveulsive rhythms. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.474 (perp=6.905, rec=0.090, cos=0.003), tot_loss_proj:2.358 [t=0.17s]
prediction: ['[CLS] time ab balances really with incident,ulsiveulsive rhythms. [SEP]']
[1950/2000] tot_loss=1.487 (perp=6.905, rec=0.104, cos=0.003), tot_loss_proj:2.358 [t=0.17s]
prediction: ['[CLS] time ab balances really with incident,ulsiveulsive rhythms. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.471 (perp=6.905, rec=0.087, cos=0.003), tot_loss_proj:2.352 [t=0.17s]
prediction: ['[CLS] time ab balances really with incident,ulsiveulsive rhythms. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] time balances really with incidentulsive rhythms. ab, accident [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 40.000 | r: 40.000
rougeLsum  | fm: 40.000 | p: 40.000 | r: 40.000
r1fm+r2fm = 60.000

[Aggregate metrics]:
rouge1     | fm: 92.727 | p: 92.727 | r: 92.814
rouge2     | fm: 61.258 | p: 61.212 | r: 61.435
rougeL     | fm: 81.825 | p: 81.791 | r: 81.905
rougeLsum  | fm: 82.355 | p: 82.190 | r: 82.576
r1fm+r2fm = 153.985

input #10 time: 0:06:56 | total time: 1:16:58


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9992849825911105
highest_index [0]
highest [0.9992849825911105]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 1.8228942155838013 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 1.7478306293487549 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 1.3220566511154175 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 1.311123251914978 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 1.3074727058410645 for ['[CLS]ture inlandgu me tal platform familiarvd mile drawn [SEP]']
[Init] best perm rec loss: 1.2857089042663574 for ['[CLS] inlandture drawn tal platform megu familiarvd mile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.037 (perp=13.492, rec=0.321, cos=0.018), tot_loss_proj:3.789 [t=0.17s]
prediction: ['[CLS] that attempted refused gel gel stubborn plug refuseded gideon [SEP]']
[ 100/2000] tot_loss=2.412 (perp=10.979, rec=0.207, cos=0.008), tot_loss_proj:3.080 [t=0.17s]
prediction: ['[CLS] that attempted refused gel gel stubborn gel refused to gel [SEP]']
[ 150/2000] tot_loss=1.953 (perp=8.871, rec=0.172, cos=0.007), tot_loss_proj:2.365 [t=0.17s]
prediction: ['[CLS] that attempted refused gel here stubbornly refused to gel [SEP]']
[ 200/2000] tot_loss=1.931 (perp=8.871, rec=0.153, cos=0.004), tot_loss_proj:2.358 [t=0.17s]
prediction: ['[CLS] that attempted refused gel here stubbornly refused to gel [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.568 (perp=7.308, rec=0.104, cos=0.002), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] that attempted gel was here stubbornly refused to gel [SEP]']
[ 300/2000] tot_loss=1.554 (perp=7.308, rec=0.091, cos=0.002), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] that attempted gel was here stubbornly refused to gel [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.556 (perp=7.308, rec=0.093, cos=0.002), tot_loss_proj:1.985 [t=0.17s]
prediction: ['[CLS] that attempted gel was here stubbornly refused to gel [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.547 (perp=7.308, rec=0.084, cos=0.002), tot_loss_proj:1.982 [t=0.18s]
prediction: ['[CLS] that attempted gel was here stubbornly refused to gel [SEP]']
[ 450/2000] tot_loss=1.544 (perp=7.308, rec=0.081, cos=0.002), tot_loss_proj:1.988 [t=0.20s]
prediction: ['[CLS] that attempted gel was here stubbornly refused to gel [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.543 (perp=7.308, rec=0.080, cos=0.002), tot_loss_proj:1.982 [t=0.18s]
prediction: ['[CLS] that attempted gel was here stubbornly refused to gel [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.549 (perp=7.308, rec=0.085, cos=0.002), tot_loss_proj:1.985 [t=0.19s]
prediction: ['[CLS] that attempted gel was here stubbornly refused to gel [SEP]']
[ 600/2000] tot_loss=1.545 (perp=7.308, rec=0.082, cos=0.002), tot_loss_proj:1.977 [t=0.18s]
prediction: ['[CLS] that attempted gel was here stubbornly refused to gel [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.637 (perp=7.760, rec=0.083, cos=0.002), tot_loss_proj:1.982 [t=0.20s]
prediction: ['[CLS] that attempted being was here stubbornly refused to gel [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.447 (perp=6.742, rec=0.096, cos=0.003), tot_loss_proj:1.744 [t=0.19s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
[ 750/2000] tot_loss=1.427 (perp=6.742, rec=0.077, cos=0.001), tot_loss_proj:1.746 [t=0.19s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.421 (perp=6.742, rec=0.071, cos=0.001), tot_loss_proj:1.743 [t=0.18s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.422 (perp=6.742, rec=0.072, cos=0.001), tot_loss_proj:1.738 [t=0.19s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
[ 900/2000] tot_loss=1.424 (perp=6.742, rec=0.075, cos=0.001), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.424 (perp=6.742, rec=0.074, cos=0.001), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.412 (perp=6.742, rec=0.062, cos=0.001), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
[1050/2000] tot_loss=1.414 (perp=6.742, rec=0.064, cos=0.001), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.419 (perp=6.742, rec=0.069, cos=0.001), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.405 (perp=6.742, rec=0.055, cos=0.001), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
[1200/2000] tot_loss=1.418 (perp=6.742, rec=0.069, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.413 (perp=6.742, rec=0.063, cos=0.001), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.420 (perp=6.742, rec=0.070, cos=0.001), tot_loss_proj:1.744 [t=0.20s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
[1350/2000] tot_loss=1.415 (perp=6.742, rec=0.065, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.421 (perp=6.742, rec=0.071, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.411 (perp=6.742, rec=0.061, cos=0.001), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
[1500/2000] tot_loss=1.409 (perp=6.742, rec=0.059, cos=0.001), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.421 (perp=6.742, rec=0.071, cos=0.001), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.413 (perp=6.742, rec=0.063, cos=0.001), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
[1650/2000] tot_loss=1.417 (perp=6.742, rec=0.067, cos=0.001), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.413 (perp=6.742, rec=0.063, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.411 (perp=6.742, rec=0.061, cos=0.001), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
[1800/2000] tot_loss=1.418 (perp=6.742, rec=0.068, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.417 (perp=6.742, rec=0.068, cos=0.001), tot_loss_proj:1.742 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.415 (perp=6.742, rec=0.065, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
[1950/2000] tot_loss=1.412 (perp=6.742, rec=0.062, cos=0.001), tot_loss_proj:1.744 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.417 (perp=6.742, rec=0.067, cos=0.001), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] that was being attempted here stubbornly refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] that was being attempted here stubbornly refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.413
rouge2     | fm: 62.859 | p: 62.753 | r: 62.982
rougeL     | fm: 82.753 | p: 82.791 | r: 82.725
rougeLsum  | fm: 83.047 | p: 82.974 | r: 83.217
r1fm+r2fm = 156.193

input #11 time: 0:07:01 | total time: 1:24:00


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.99934391763152
highest_index [0]
highest [0.99934391763152]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 1.8480900526046753 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 1.794683814048767 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 1.4141982793807983 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 1.3857673406600952 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 1.319607138633728 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 1.2739667892456055 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best rec loss: 1.2710332870483398 for ['[CLS] command married coma lux me brook fuel specifically containing deaf missing firm prospects track [SEP]']
[Init] best perm rec loss: 1.2705339193344116 for ['[CLS] prospects command me brook married lux containing fuel coma track firm missing deaf specifically [SEP]']
[Init] best perm rec loss: 1.2703341245651245 for ['[CLS] coma deaf lux containing married brook prospects missing me firm specifically command fuel track [SEP]']
[Init] best perm rec loss: 1.2677892446517944 for ['[CLS] command brook deaf firm missing prospects specifically coma containing track married me lux fuel [SEP]']
[Init] best perm rec loss: 1.2655885219573975 for ['[CLS] track deaf containing specifically firm prospects coma command brook fuel lux missing me married [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.388 (perp=10.353, rec=0.299, cos=0.018), tot_loss_proj:2.914 [t=0.18s]
prediction: ['[CLS] advantage barely claimed cable advantage shoes cable for better more an seen cable cable [SEP]']
[ 100/2000] tot_loss=2.432 (perp=11.151, rec=0.193, cos=0.010), tot_loss_proj:3.117 [t=0.20s]
prediction: ['[CLS] advantage barely seen cable to should cable on better better barely advantage cable cable [SEP]']
[ 150/2000] tot_loss=2.152 (perp=9.910, rec=0.155, cos=0.015), tot_loss_proj:2.797 [t=0.20s]
prediction: ['[CLS] especially barely seen cable to will cable on better better its advantage its barely [SEP]']
[ 200/2000] tot_loss=2.196 (perp=10.361, rec=0.118, cos=0.006), tot_loss_proj:2.864 [t=0.21s]
prediction: ['[CLS] especially barely seen cable be will cable on to better considering advantage its barely [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.912 (perp=9.027, rec=0.102, cos=0.005), tot_loss_proj:2.449 [t=0.17s]
prediction: ['[CLS] especially barely seen cable be will cable on to better advantage considering its barely [SEP]']
[ 300/2000] tot_loss=1.970 (perp=9.378, rec=0.090, cos=0.004), tot_loss_proj:2.647 [t=0.17s]
prediction: ['[CLS] especially barely seen its be will cable on to better advantage considering its barely [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.717 (perp=8.127, rec=0.089, cos=0.003), tot_loss_proj:2.267 [t=0.17s]
prediction: ['[CLS] especially barely seen will be its cable on to better advantage considering its barely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.756 (perp=8.410, rec=0.071, cos=0.002), tot_loss_proj:2.410 [t=0.17s]
prediction: ['[CLS] especially barely seen will that its cable on to better advantage considering its barely [SEP]']
[ 450/2000] tot_loss=1.759 (perp=8.410, rec=0.075, cos=0.002), tot_loss_proj:2.412 [t=0.17s]
prediction: ['[CLS] especially barely seen will that its cable on to better advantage considering its barely [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.744 (perp=8.313, rec=0.078, cos=0.003), tot_loss_proj:2.434 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable its on to better advantage considering its considering [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.734 (perp=8.244, rec=0.082, cos=0.003), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable its on to better advantage considering considering its [SEP]']
[ 600/2000] tot_loss=1.703 (perp=8.086, rec=0.084, cos=0.002), tot_loss_proj:2.439 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable its on to better advantage considering, its [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.615 (perp=7.661, rec=0.079, cos=0.003), tot_loss_proj:2.263 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable its on to better advantage, considering its [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.507 (perp=7.143, rec=0.076, cos=0.003), tot_loss_proj:2.254 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
[ 750/2000] tot_loss=1.502 (perp=7.143, rec=0.071, cos=0.002), tot_loss_proj:2.253 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.506 (perp=7.143, rec=0.075, cos=0.002), tot_loss_proj:2.258 [t=0.19s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.507 (perp=7.143, rec=0.076, cos=0.002), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
[ 900/2000] tot_loss=1.507 (perp=7.143, rec=0.076, cos=0.002), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.506 (perp=7.143, rec=0.075, cos=0.002), tot_loss_proj:2.260 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1000/2000] tot_loss=1.510 (perp=7.143, rec=0.079, cos=0.002), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
[1050/2000] tot_loss=1.507 (perp=7.143, rec=0.076, cos=0.002), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1100/2000] tot_loss=1.503 (perp=7.143, rec=0.072, cos=0.002), tot_loss_proj:2.251 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1150/2000] tot_loss=1.508 (perp=7.143, rec=0.077, cos=0.002), tot_loss_proj:2.254 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
[1200/2000] tot_loss=1.505 (perp=7.143, rec=0.074, cos=0.002), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1250/2000] tot_loss=1.509 (perp=7.143, rec=0.078, cos=0.002), tot_loss_proj:2.255 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1300/2000] tot_loss=1.509 (perp=7.143, rec=0.078, cos=0.002), tot_loss_proj:2.255 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
[1350/2000] tot_loss=1.500 (perp=7.143, rec=0.069, cos=0.002), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1400/2000] tot_loss=1.505 (perp=7.143, rec=0.074, cos=0.002), tot_loss_proj:2.254 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1450/2000] tot_loss=1.503 (perp=7.143, rec=0.072, cos=0.002), tot_loss_proj:2.259 [t=0.18s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
[1500/2000] tot_loss=1.508 (perp=7.143, rec=0.078, cos=0.002), tot_loss_proj:2.256 [t=0.21s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1550/2000] tot_loss=1.507 (perp=7.143, rec=0.076, cos=0.002), tot_loss_proj:2.259 [t=0.20s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1600/2000] tot_loss=1.505 (perp=7.143, rec=0.074, cos=0.002), tot_loss_proj:2.257 [t=0.21s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
[1650/2000] tot_loss=1.496 (perp=7.143, rec=0.065, cos=0.002), tot_loss_proj:2.258 [t=0.20s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.499 (perp=7.143, rec=0.068, cos=0.002), tot_loss_proj:2.260 [t=0.19s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1750/2000] tot_loss=1.498 (perp=7.143, rec=0.068, cos=0.002), tot_loss_proj:2.264 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
[1800/2000] tot_loss=1.504 (perp=7.143, rec=0.073, cos=0.002), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1850/2000] tot_loss=1.504 (perp=7.143, rec=0.073, cos=0.002), tot_loss_proj:2.257 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[1900/2000] tot_loss=1.503 (perp=7.143, rec=0.072, cos=0.002), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
[1950/2000] tot_loss=1.507 (perp=7.143, rec=0.077, cos=0.002), tot_loss_proj:2.260 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Attempt swap
[2000/2000] tot_loss=1.501 (perp=7.143, rec=0.070, cos=0.002), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] especially barely seen will that cable better on to its advantage, considering its [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 7.143 | p: 7.143 | r: 7.143
rougeL     | fm: 46.667 | p: 46.667 | r: 46.667
rougeLsum  | fm: 46.667 | p: 46.667 | r: 46.667
r1fm+r2fm = 100.476

[Aggregate metrics]:
rouge1     | fm: 93.427 | p: 93.378 | r: 93.553
rouge2     | fm: 57.530 | p: 57.546 | r: 57.591
rougeL     | fm: 80.050 | p: 80.071 | r: 80.070
rougeLsum  | fm: 79.811 | p: 79.738 | r: 79.887
r1fm+r2fm = 150.957

input #12 time: 0:07:03 | total time: 1:31:03


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9992538394516878
highest_index [0]
highest [0.9992538394516878]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 1.4737218618392944 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 1.4235199689865112 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 1.406105875968933 for ['[CLS] pdf along timing started mal practical prevailed [SEP]']
[Init] best rec loss: 1.390662670135498 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 1.3708242177963257 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 1.3614050149917603 for ['[CLS] dame recess ak latter threshold po illness [SEP]']
[Init] best rec loss: 1.3537973165512085 for ['[CLS] squat what names set fence thin received [SEP]']
[Init] best rec loss: 1.3353148698806763 for ['[CLS] dressed fraternity colonial round et bahn heads [SEP]']
[Init] best rec loss: 1.3023403882980347 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best rec loss: 1.261353611946106 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best perm rec loss: 1.2592674493789673 for ['[CLS] permanent defeat arm cardinal roweional precision [SEP]']
[Init] best perm rec loss: 1.2589128017425537 for ['[CLS] defeat cardinal arm roweional precision permanent [SEP]']
[Init] best perm rec loss: 1.256705403327942 for ['[CLS] permanent cardinalional arm precision rowe defeat [SEP]']
[Init] best perm rec loss: 1.2559808492660522 for ['[CLS] permanentional cardinal defeat rowe precision arm [SEP]']
[Init] best perm rec loss: 1.2554824352264404 for ['[CLS] defeat cardinalional arm permanent precision rowe [SEP]']
[Init] best perm rec loss: 1.2538996934890747 for ['[CLS] cardinal defeational arm precision rowe permanent [SEP]']
[Init] best perm rec loss: 1.2521754503250122 for ['[CLS] permanent rowe cardinal armional precision defeat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.954 (perp=13.061, rec=0.307, cos=0.035), tot_loss_proj:3.843 [t=0.17s]
prediction: ['[CLS] slash flame flame flame if ryan into [SEP]']
[ 100/2000] tot_loss=2.528 (perp=11.510, rec=0.209, cos=0.017), tot_loss_proj:3.599 [t=0.17s]
prediction: ['[CLS] point at flame explode when ronald into [SEP]']
[ 150/2000] tot_loss=2.458 (perp=11.466, rec=0.158, cos=0.007), tot_loss_proj:3.668 [t=0.17s]
prediction: ['[CLS] point at flame explode explode explode into [SEP]']
[ 200/2000] tot_loss=2.437 (perp=11.466, rec=0.136, cos=0.008), tot_loss_proj:3.668 [t=0.17s]
prediction: ['[CLS] point at flame explode explode explode into [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.280 (perp=10.745, rec=0.125, cos=0.005), tot_loss_proj:3.411 [t=0.17s]
prediction: ['[CLS] point at flame explode that into things [SEP]']
[ 300/2000] tot_loss=2.235 (perp=10.745, rec=0.083, cos=0.003), tot_loss_proj:3.395 [t=0.17s]
prediction: ['[CLS] point at flame explode that into things [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.087 (perp=10.060, rec=0.073, cos=0.002), tot_loss_proj:3.212 [t=0.17s]
prediction: ['[CLS] point flame at explode that into things [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.060 (perp=9.922, rec=0.074, cos=0.002), tot_loss_proj:3.082 [t=0.17s]
prediction: ['[CLS] point flame at that explode into things [SEP]']
[ 450/2000] tot_loss=2.058 (perp=9.922, rec=0.072, cos=0.001), tot_loss_proj:3.082 [t=0.17s]
prediction: ['[CLS] point flame at that explode into things [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.842 (perp=8.866, rec=0.068, cos=0.001), tot_loss_proj:2.499 [t=0.19s]
prediction: ['[CLS] point things at that explode into flame [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.721 (perp=8.254, rec=0.069, cos=0.002), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 600/2000] tot_loss=1.714 (perp=8.254, rec=0.062, cos=0.001), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.722 (perp=8.254, rec=0.070, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.712 (perp=8.254, rec=0.060, cos=0.001), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 750/2000] tot_loss=1.717 (perp=8.254, rec=0.065, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.718 (perp=8.254, rec=0.065, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.713 (perp=8.254, rec=0.061, cos=0.001), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 900/2000] tot_loss=1.707 (perp=8.254, rec=0.055, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.721 (perp=8.254, rec=0.069, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.710 (perp=8.254, rec=0.058, cos=0.001), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1050/2000] tot_loss=1.713 (perp=8.254, rec=0.061, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.710 (perp=8.254, rec=0.058, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.714 (perp=8.254, rec=0.062, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1200/2000] tot_loss=1.709 (perp=8.254, rec=0.057, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.714 (perp=8.254, rec=0.061, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.706 (perp=8.254, rec=0.053, cos=0.001), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1350/2000] tot_loss=1.712 (perp=8.254, rec=0.060, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.702 (perp=8.254, rec=0.050, cos=0.001), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.711 (perp=8.254, rec=0.058, cos=0.001), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1500/2000] tot_loss=1.707 (perp=8.254, rec=0.055, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.711 (perp=8.254, rec=0.058, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.712 (perp=8.254, rec=0.060, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1650/2000] tot_loss=1.712 (perp=8.254, rec=0.060, cos=0.001), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.711 (perp=8.254, rec=0.058, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.711 (perp=8.254, rec=0.058, cos=0.001), tot_loss_proj:1.974 [t=0.20s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1800/2000] tot_loss=1.715 (perp=8.254, rec=0.062, cos=0.001), tot_loss_proj:1.967 [t=0.19s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.711 (perp=8.254, rec=0.059, cos=0.001), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.718 (perp=8.254, rec=0.065, cos=0.001), tot_loss_proj:1.961 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1950/2000] tot_loss=1.707 (perp=8.254, rec=0.055, cos=0.001), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.705 (perp=8.254, rec=0.053, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] point at things that explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.896 | p: 93.851 | r: 93.946
rouge2     | fm: 60.699 | p: 60.714 | r: 60.714
rougeL     | fm: 81.423 | p: 81.473 | r: 81.470
rougeLsum  | fm: 81.212 | p: 81.212 | r: 81.257
r1fm+r2fm = 154.595

input #13 time: 0:06:53 | total time: 1:37:57


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9993219682705545
highest_index [0]
highest [0.9993219682705545]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 1.9555590152740479 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 1.90388023853302 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 1.7101174592971802 for ['[CLS] junior touching itpton ; [SEP]']
[Init] best rec loss: 1.6756500005722046 for ['[CLS] brooks mentioninianame nothing [SEP]']
[Init] best rec loss: 1.649327278137207 for ['[CLS] quiver federation maddie sacramentoboard [SEP]']
[Init] best rec loss: 1.459338903427124 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 1.455399990081787 for ['[CLS] myers harold tom [MASK] sprayed [SEP]']
[Init] best perm rec loss: 1.4520574808120728 for ['[CLS] harold myers [MASK] tom sprayed [SEP]']
[Init] best perm rec loss: 1.4497400522232056 for ['[CLS] myers harold [MASK] tom sprayed [SEP]']
[Init] best perm rec loss: 1.4491201639175415 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
[Init] best perm rec loss: 1.4477119445800781 for ['[CLS] [MASK] harold myers tom sprayed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.363 (perp=10.861, rec=0.189, cos=0.003), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS]bly intriguing filmbly intriguing [SEP]']
[ 100/2000] tot_loss=2.577 (perp=12.243, rec=0.127, cos=0.002), tot_loss_proj:2.949 [t=0.17s]
prediction: ['[CLS]enia intriguing filmbly intriguing [SEP]']
[ 150/2000] tot_loss=2.554 (perp=12.243, rec=0.104, cos=0.002), tot_loss_proj:2.957 [t=0.17s]
prediction: ['[CLS]enia intriguing filmbly intriguing [SEP]']
[ 200/2000] tot_loss=2.120 (perp=10.135, rec=0.091, cos=0.002), tot_loss_proj:2.325 [t=0.17s]
prediction: ['[CLS]eniably filmbly intriguing [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.083 (perp=9.879, rec=0.105, cos=0.001), tot_loss_proj:2.401 [t=0.17s]
prediction: ['[CLS] film narrativeeniably intriguing [SEP]']
[ 300/2000] tot_loss=2.065 (perp=9.879, rec=0.087, cos=0.002), tot_loss_proj:2.402 [t=0.17s]
prediction: ['[CLS] film narrativeeniably intriguing [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.892 (perp=8.985, rec=0.093, cos=0.002), tot_loss_proj:2.080 [t=0.17s]
prediction: ['[CLS]eniably intriguing film narrative [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.853 (perp=8.847, rec=0.082, cos=0.002), tot_loss_proj:2.028 [t=0.17s]
prediction: ['[CLS]eniably intriguing narrative film [SEP]']
[ 450/2000] tot_loss=1.855 (perp=8.847, rec=0.084, cos=0.002), tot_loss_proj:2.018 [t=0.17s]
prediction: ['[CLS]eniably intriguing narrative film [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.065 (perp=9.868, rec=0.090, cos=0.002), tot_loss_proj:2.590 [t=0.17s]
prediction: ['[CLS]eniably intriguingerved film [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.059 (perp=9.868, rec=0.084, cos=0.001), tot_loss_proj:2.585 [t=0.17s]
prediction: ['[CLS]eniably intriguingerved film [SEP]']
[ 600/2000] tot_loss=2.060 (perp=9.868, rec=0.084, cos=0.001), tot_loss_proj:2.598 [t=0.17s]
prediction: ['[CLS]eniably intriguingerved film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.919 (perp=9.145, rec=0.089, cos=0.001), tot_loss_proj:2.154 [t=0.17s]
prediction: ['[CLS]eniably intriguing emmy film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.914 (perp=9.145, rec=0.083, cos=0.001), tot_loss_proj:2.156 [t=0.17s]
prediction: ['[CLS]eniably intriguing emmy film [SEP]']
[ 750/2000] tot_loss=1.918 (perp=9.145, rec=0.087, cos=0.001), tot_loss_proj:2.165 [t=0.17s]
prediction: ['[CLS]eniably intriguing emmy film [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.181 (perp=10.433, rec=0.093, cos=0.001), tot_loss_proj:2.424 [t=0.17s]
prediction: ['[CLS]eniably intriguing und film [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.434 (perp=6.728, rec=0.087, cos=0.001), tot_loss_proj:1.413 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.427 (perp=6.728, rec=0.080, cos=0.001), tot_loss_proj:1.411 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.417 (perp=6.728, rec=0.070, cos=0.001), tot_loss_proj:1.413 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.422 (perp=6.728, rec=0.075, cos=0.001), tot_loss_proj:1.411 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.406 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.412 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.416 (perp=6.728, rec=0.069, cos=0.001), tot_loss_proj:1.412 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.421 (perp=6.728, rec=0.074, cos=0.001), tot_loss_proj:1.404 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.424 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.407 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.408 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.411 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.417 (perp=6.728, rec=0.070, cos=0.001), tot_loss_proj:1.414 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.416 (perp=6.728, rec=0.069, cos=0.001), tot_loss_proj:1.413 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.406 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.415 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.397 (perp=6.728, rec=0.050, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.418 (perp=6.728, rec=0.071, cos=0.001), tot_loss_proj:1.401 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.417 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.412 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.409 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.412 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.496 | p: 94.479 | r: 94.667
rouge2     | fm: 63.399 | p: 63.416 | r: 63.484
rougeL     | fm: 82.890 | p: 82.773 | r: 83.043
rougeLsum  | fm: 82.658 | p: 82.586 | r: 82.686
r1fm+r2fm = 157.895

input #14 time: 0:06:51 | total time: 1:44:49


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9992724874303516
highest_index [0]
highest [0.9992724874303516]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 1.96763014793396 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 1.925123929977417 for ['[CLS] ¹⁄₂ lds bay simple 19 client utc congestion [SEP]']
[Init] best rec loss: 1.9198782444000244 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 1.8514207601547241 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 1.7387832403182983 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 1.7253295183181763 for ['[CLS] tor casey decembergrate doua developed logic [SEP]']
[Init] best rec loss: 1.7060983180999756 for ['[CLS] du resign what pet system jazz aschurch [SEP]']
[Init] best rec loss: 1.7037686109542847 for ['[CLS] madeline discovery ocean truss stations chance ledge waiting [SEP]']
[Init] best rec loss: 1.6834999322891235 for ['[CLS] child indian setting launched and today returns becker [SEP]']
[Init] best rec loss: 1.5785369873046875 for ['[CLS] winner french badminton harperrdial missed ex fond [SEP]']
[Init] best perm rec loss: 1.575916051864624 for ['[CLS] frenchrdial badminton winner ex missed fond harper [SEP]']
[Init] best perm rec loss: 1.5737770795822144 for ['[CLS] french harper fondrdial badminton missed ex winner [SEP]']
[Init] best perm rec loss: 1.5736515522003174 for ['[CLS] missed winner ex frenchrdial fond harper badminton [SEP]']
[Init] best perm rec loss: 1.569117546081543 for ['[CLS]rdial ex harper fond missed french winner badminton [SEP]']
[Init] best perm rec loss: 1.568715214729309 for ['[CLS] french ex harper fondrdial missed winner badminton [SEP]']
[Init] best perm rec loss: 1.5686029195785522 for ['[CLS] harperrdial fond winner french ex missed badminton [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.556 (perp=11.479, rec=0.254, cos=0.006), tot_loss_proj:2.950 [t=0.17s]
prediction: ['[CLS] efficientably efficient anonymous throughably inter seat [SEP]']
[ 100/2000] tot_loss=2.680 (perp=12.433, rec=0.189, cos=0.004), tot_loss_proj:3.430 [t=0.17s]
prediction: ['[CLS] efficient suit efficient anonymous chill chillablyer [SEP]']
[ 150/2000] tot_loss=2.335 (perp=10.905, rec=0.150, cos=0.003), tot_loss_proj:2.878 [t=0.17s]
prediction: ['[CLS] efficientably efficient anonymous chill suitablyer [SEP]']
[ 200/2000] tot_loss=2.303 (perp=10.905, rec=0.118, cos=0.004), tot_loss_proj:2.860 [t=0.17s]
prediction: ['[CLS] efficientably efficient anonymous chill suitablyer [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.917 (perp=9.088, rec=0.098, cos=0.002), tot_loss_proj:2.203 [t=0.17s]
prediction: ['[CLS] efficientably efficient suitably anonymous chiller [SEP]']
[ 300/2000] tot_loss=1.727 (perp=8.239, rec=0.078, cos=0.002), tot_loss_proj:1.934 [t=0.17s]
prediction: ['[CLS]., efficient suitably anonymous chiller [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.530 (perp=7.266, rec=0.075, cos=0.002), tot_loss_proj:1.664 [t=0.17s]
prediction: ['[CLS] efficient, suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.599 (perp=7.597, rec=0.078, cos=0.002), tot_loss_proj:1.809 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[ 450/2000] tot_loss=1.600 (perp=7.597, rec=0.079, cos=0.002), tot_loss_proj:1.816 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.590 (perp=7.597, rec=0.069, cos=0.002), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.597 (perp=7.597, rec=0.076, cos=0.002), tot_loss_proj:1.812 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[ 600/2000] tot_loss=1.590 (perp=7.597, rec=0.069, cos=0.002), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.578 (perp=7.597, rec=0.058, cos=0.001), tot_loss_proj:1.820 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.582 (perp=7.597, rec=0.062, cos=0.001), tot_loss_proj:1.821 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[ 750/2000] tot_loss=1.588 (perp=7.597, rec=0.067, cos=0.001), tot_loss_proj:1.821 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.587 (perp=7.597, rec=0.066, cos=0.001), tot_loss_proj:1.822 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.590 (perp=7.597, rec=0.069, cos=0.001), tot_loss_proj:1.815 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[ 900/2000] tot_loss=1.581 (perp=7.597, rec=0.060, cos=0.001), tot_loss_proj:1.818 [t=0.18s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.583 (perp=7.597, rec=0.063, cos=0.001), tot_loss_proj:1.824 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1000/2000] tot_loss=1.572 (perp=7.597, rec=0.052, cos=0.001), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[1050/2000] tot_loss=1.575 (perp=7.597, rec=0.055, cos=0.001), tot_loss_proj:1.820 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1100/2000] tot_loss=1.578 (perp=7.597, rec=0.058, cos=0.001), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1150/2000] tot_loss=1.576 (perp=7.597, rec=0.055, cos=0.001), tot_loss_proj:1.818 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[1200/2000] tot_loss=1.585 (perp=7.597, rec=0.064, cos=0.001), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1250/2000] tot_loss=1.595 (perp=7.597, rec=0.075, cos=0.001), tot_loss_proj:1.821 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1300/2000] tot_loss=1.591 (perp=7.597, rec=0.070, cos=0.001), tot_loss_proj:1.817 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[1350/2000] tot_loss=1.571 (perp=7.597, rec=0.050, cos=0.001), tot_loss_proj:1.818 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1400/2000] tot_loss=1.580 (perp=7.597, rec=0.059, cos=0.001), tot_loss_proj:1.821 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1450/2000] tot_loss=1.588 (perp=7.597, rec=0.067, cos=0.001), tot_loss_proj:1.821 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[1500/2000] tot_loss=1.585 (perp=7.597, rec=0.064, cos=0.001), tot_loss_proj:1.824 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1550/2000] tot_loss=1.583 (perp=7.597, rec=0.062, cos=0.001), tot_loss_proj:1.822 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1600/2000] tot_loss=1.589 (perp=7.597, rec=0.068, cos=0.001), tot_loss_proj:1.818 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[1650/2000] tot_loss=1.588 (perp=7.597, rec=0.067, cos=0.001), tot_loss_proj:1.819 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1700/2000] tot_loss=1.579 (perp=7.597, rec=0.059, cos=0.001), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1750/2000] tot_loss=1.584 (perp=7.597, rec=0.063, cos=0.001), tot_loss_proj:1.825 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[1800/2000] tot_loss=1.584 (perp=7.597, rec=0.063, cos=0.001), tot_loss_proj:1.823 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1850/2000] tot_loss=1.571 (perp=7.597, rec=0.050, cos=0.001), tot_loss_proj:1.824 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[1900/2000] tot_loss=1.585 (perp=7.597, rec=0.064, cos=0.001), tot_loss_proj:1.820 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
[1950/2000] tot_loss=1.584 (perp=7.597, rec=0.063, cos=0.001), tot_loss_proj:1.816 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Attempt swap
[2000/2000] tot_loss=1.588 (perp=7.597, rec=0.067, cos=0.001), tot_loss_proj:1.824 [t=0.17s]
prediction: ['[CLS]., suitably efficient anonymous chiller [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS]., suitably efficient anonymous chiller [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 94.835 | p: 94.693 | r: 95.000
rouge2     | fm: 62.309 | p: 62.288 | r: 62.378
rougeL     | fm: 82.602 | p: 82.609 | r: 82.639
rougeLsum  | fm: 82.700 | p: 82.729 | r: 82.767
r1fm+r2fm = 157.144

input #15 time: 0:06:52 | total time: 1:51:42


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9993411698074052
highest_index [0]
highest [0.9993411698074052]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.9508296251296997 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 1.8343384265899658 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 1.6890870332717896 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best rec loss: 1.6304024457931519 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 1.5867127180099487 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 1.525856614112854 for ['[CLS] legsyen t sharon camp ro [SEP]']
[Init] best rec loss: 1.5195893049240112 for ['[CLS]encia olgazy edit areas sounding [SEP]']
[Init] best rec loss: 1.3733412027359009 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 1.3456374406814575 for ['[CLS] ultra backpack tallest you downstream map [SEP]']
[Init] best perm rec loss: 1.337275505065918 for ['[CLS] tallest downstream map you backpack ultra [SEP]']
[Init] best perm rec loss: 1.336099624633789 for ['[CLS] map tallest ultra downstream backpack you [SEP]']
[Init] best perm rec loss: 1.3238879442214966 for ['[CLS] tallest ultra map backpack you downstream [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.978 (perp=12.159, rec=0.432, cos=0.114), tot_loss_proj:3.745 [t=0.20s]
prediction: ['[CLS] ever another extensive organic entering they [SEP]']
[ 100/2000] tot_loss=2.625 (perp=10.293, rec=0.476, cos=0.091), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] her that all logan seed logan [SEP]']
[ 150/2000] tot_loss=2.582 (perp=10.952, rec=0.351, cos=0.041), tot_loss_proj:3.236 [t=0.17s]
prediction: ['[CLS] her this all logan more more [SEP]']
[ 200/2000] tot_loss=1.942 (perp=7.605, rec=0.351, cos=0.070), tot_loss_proj:2.416 [t=0.17s]
prediction: ['[CLS] all this all! more more [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.254 (perp=4.901, rec=0.253, cos=0.021), tot_loss_proj:1.821 [t=0.17s]
prediction: ['[CLS] all this and all all this [SEP]']
[ 300/2000] tot_loss=1.400 (perp=5.913, rec=0.203, cos=0.014), tot_loss_proj:1.829 [t=0.17s]
prediction: ['[CLS] all this and all all more [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.612 (perp=7.133, rec=0.176, cos=0.010), tot_loss_proj:1.926 [t=0.17s]
prediction: ['[CLS] all this and, more all [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.225 (perp=5.173, rec=0.179, cos=0.011), tot_loss_proj:1.641 [t=0.17s]
prediction: ['[CLS] all this and all more, [SEP]']
[ 450/2000] tot_loss=1.203 (perp=5.173, rec=0.160, cos=0.008), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] all this and all more, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.187 (perp=5.173, rec=0.144, cos=0.007), tot_loss_proj:1.618 [t=0.19s]
prediction: ['[CLS] all this and all more, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.176 (perp=5.173, rec=0.134, cos=0.007), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] all this and all more, [SEP]']
[ 600/2000] tot_loss=1.179 (perp=5.173, rec=0.137, cos=0.007), tot_loss_proj:1.624 [t=0.20s]
prediction: ['[CLS] all this and all more, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.175 (perp=5.173, rec=0.133, cos=0.007), tot_loss_proj:1.621 [t=0.19s]
prediction: ['[CLS] all this and all more, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.164 (perp=5.173, rec=0.123, cos=0.006), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] all this and all more, [SEP]']
[ 750/2000] tot_loss=1.168 (perp=5.173, rec=0.127, cos=0.006), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] all this and all more, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.155 (perp=5.173, rec=0.114, cos=0.006), tot_loss_proj:1.628 [t=0.17s]
prediction: ['[CLS] all this and all more, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.162 (perp=5.173, rec=0.122, cos=0.006), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] all this and all more, [SEP]']
[ 900/2000] tot_loss=1.042 (perp=4.529, rec=0.129, cos=0.007), tot_loss_proj:1.443 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.040 (perp=4.529, rec=0.127, cos=0.007), tot_loss_proj:1.445 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.042 (perp=4.529, rec=0.130, cos=0.007), tot_loss_proj:1.445 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
[1050/2000] tot_loss=1.036 (perp=4.529, rec=0.123, cos=0.007), tot_loss_proj:1.444 [t=0.18s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.036 (perp=4.529, rec=0.124, cos=0.007), tot_loss_proj:1.448 [t=0.18s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.029 (perp=4.529, rec=0.117, cos=0.007), tot_loss_proj:1.449 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
[1200/2000] tot_loss=1.036 (perp=4.529, rec=0.124, cos=0.007), tot_loss_proj:1.451 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.027 (perp=4.529, rec=0.115, cos=0.007), tot_loss_proj:1.446 [t=0.20s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.034 (perp=4.529, rec=0.121, cos=0.007), tot_loss_proj:1.447 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
[1350/2000] tot_loss=1.041 (perp=4.529, rec=0.128, cos=0.007), tot_loss_proj:1.445 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.032 (perp=4.529, rec=0.120, cos=0.006), tot_loss_proj:1.450 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.030 (perp=4.529, rec=0.117, cos=0.006), tot_loss_proj:1.448 [t=0.19s]
prediction: ['[CLS] all this and all more. [SEP]']
[1500/2000] tot_loss=1.034 (perp=4.529, rec=0.122, cos=0.006), tot_loss_proj:1.444 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.027 (perp=4.529, rec=0.115, cos=0.006), tot_loss_proj:1.446 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.034 (perp=4.529, rec=0.121, cos=0.006), tot_loss_proj:1.447 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
[1650/2000] tot_loss=1.026 (perp=4.529, rec=0.114, cos=0.006), tot_loss_proj:1.446 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.028 (perp=4.529, rec=0.116, cos=0.006), tot_loss_proj:1.438 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.036 (perp=4.529, rec=0.124, cos=0.006), tot_loss_proj:1.444 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
[1800/2000] tot_loss=1.031 (perp=4.529, rec=0.119, cos=0.006), tot_loss_proj:1.451 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.019 (perp=4.529, rec=0.107, cos=0.006), tot_loss_proj:1.442 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.038 (perp=4.529, rec=0.126, cos=0.006), tot_loss_proj:1.442 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
[1950/2000] tot_loss=1.022 (perp=4.529, rec=0.110, cos=0.006), tot_loss_proj:1.445 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.025 (perp=4.529, rec=0.113, cos=0.006), tot_loss_proj:1.451 [t=0.17s]
prediction: ['[CLS] all this and all more. [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all this and all more. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 135.714

[Aggregate metrics]:
rouge1     | fm: 94.107 | p: 94.087 | r: 94.174
rouge2     | fm: 61.851 | p: 61.823 | r: 61.937
rougeL     | fm: 83.265 | p: 83.166 | r: 83.291
rougeLsum  | fm: 83.091 | p: 83.044 | r: 83.116
r1fm+r2fm = 155.958

input #16 time: 0:07:01 | total time: 1:58:43


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9992301552937229
highest_index [0]
highest [0.9992301552937229]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 1.6595710515975952 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 1.6428885459899902 for ['[CLS] friend agency todd wi dirty percent milesamp... vietsive [SEP]']
[Init] best rec loss: 1.6136316061019897 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 1.576501488685608 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 1.5198489427566528 for ['[CLS] highestlt short ad relation minority black bunch marine above different [SEP]']
[Init] best rec loss: 1.513322114944458 for ['[CLS] name standardfoldieg names result diesfulds suggest mystery [SEP]']
[Init] best rec loss: 1.4297772645950317 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 1.3880505561828613 for ['[CLS] general sensation water consecrated affairvudran bethany then religious threatened [SEP]']
[Init] best rec loss: 1.366730809211731 for ['[CLS] georgian kilometers following fatal conversion station arch with gene goddess [SEP]']
[Init] best perm rec loss: 1.3620654344558716 for ['[CLS] gene station fatalh conversion following goddess kilometers with georgian arc [SEP]']
[Init] best perm rec loss: 1.361521601676941 for ['[CLS] arc gene goddess following with georgian conversionh kilometers fatal station [SEP]']
[Init] best perm rec loss: 1.361145257949829 for ['[CLS] fatal with goddess geneh georgian conversion kilometers arc station following [SEP]']
[Init] best perm rec loss: 1.3605331182479858 for ['[CLS] kilometers gene following fatal with goddess georgian arc conversion stationh [SEP]']
[Init] best perm rec loss: 1.360186219215393 for ['[CLS] geneh conversion station with kilometers following georgian arc fatal goddess [SEP]']
[Init] best perm rec loss: 1.3596504926681519 for ['[CLS]h kilometers conversion fatal following station goddess with georgian gene arc [SEP]']
[Init] best perm rec loss: 1.3583624362945557 for ['[CLS] kilometers with stationh conversion fatal goddess arc gene following georgian [SEP]']
[Init] best perm rec loss: 1.3579857349395752 for ['[CLS] georgian geneh station with fatal conversion kilometers following arc goddess [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.605 (perp=11.306, rec=0.311, cos=0.033), tot_loss_proj:3.348 [t=0.17s]
prediction: ['[CLS] want think too want too access understand first courtyard center kerman [SEP]']
[ 100/2000] tot_loss=1.855 (perp=8.519, rec=0.143, cos=0.008), tot_loss_proj:2.588 [t=0.17s]
prediction: ['[CLS] want think too want too much about how on on much [SEP]']
[ 150/2000] tot_loss=1.625 (perp=7.628, rec=0.097, cos=0.003), tot_loss_proj:2.179 [t=0.17s]
prediction: ['[CLS] want think too want too much about going on on what [SEP]']
[ 200/2000] tot_loss=1.614 (perp=7.628, rec=0.085, cos=0.002), tot_loss_proj:2.182 [t=0.17s]
prediction: ['[CLS] want think too want too much about going on on what [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.660 (perp=7.937, rec=0.071, cos=0.002), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] want think to want too much about going s on what [SEP]']
[ 300/2000] tot_loss=1.661 (perp=7.937, rec=0.072, cos=0.002), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] want think to want too much about going s on what [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.527 (perp=7.320, rec=0.061, cos=0.002), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] want think to want too much about what going s on [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.318 (perp=6.287, rec=0.059, cos=0.002), tot_loss_proj:1.671 [t=0.17s]
prediction: ['[CLS] want think to want too much about what s going on [SEP]']
[ 450/2000] tot_loss=1.335 (perp=6.287, rec=0.076, cos=0.002), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] want think to want too much about what s going on [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.196 (perp=5.625, rec=0.070, cos=0.002), tot_loss_proj:1.386 [t=0.17s]
prediction: ['[CLS] want want to think too much about what s going on [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=1.141 (perp=5.371, rec=0.065, cos=0.002), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
[ 600/2000] tot_loss=1.134 (perp=5.371, rec=0.058, cos=0.002), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.143 (perp=5.371, rec=0.067, cos=0.002), tot_loss_proj:1.678 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.135 (perp=5.371, rec=0.060, cos=0.002), tot_loss_proj:1.672 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
[ 750/2000] tot_loss=1.147 (perp=5.371, rec=0.071, cos=0.002), tot_loss_proj:1.671 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.145 (perp=5.371, rec=0.069, cos=0.002), tot_loss_proj:1.663 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.137 (perp=5.371, rec=0.061, cos=0.002), tot_loss_proj:1.663 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
[ 900/2000] tot_loss=1.142 (perp=5.371, rec=0.066, cos=0.002), tot_loss_proj:1.667 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.136 (perp=5.371, rec=0.060, cos=0.002), tot_loss_proj:1.666 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1000/2000] tot_loss=1.149 (perp=5.371, rec=0.073, cos=0.002), tot_loss_proj:1.663 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
[1050/2000] tot_loss=1.144 (perp=5.371, rec=0.068, cos=0.002), tot_loss_proj:1.664 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1100/2000] tot_loss=1.137 (perp=5.371, rec=0.061, cos=0.002), tot_loss_proj:1.663 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1150/2000] tot_loss=1.138 (perp=5.371, rec=0.062, cos=0.002), tot_loss_proj:1.660 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
[1200/2000] tot_loss=1.133 (perp=5.371, rec=0.057, cos=0.002), tot_loss_proj:1.655 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1250/2000] tot_loss=1.145 (perp=5.371, rec=0.069, cos=0.002), tot_loss_proj:1.663 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1300/2000] tot_loss=1.146 (perp=5.371, rec=0.070, cos=0.002), tot_loss_proj:1.667 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
[1350/2000] tot_loss=1.124 (perp=5.371, rec=0.048, cos=0.002), tot_loss_proj:1.655 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1400/2000] tot_loss=1.140 (perp=5.371, rec=0.065, cos=0.002), tot_loss_proj:1.649 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1450/2000] tot_loss=1.141 (perp=5.371, rec=0.065, cos=0.002), tot_loss_proj:1.650 [t=0.18s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
[1500/2000] tot_loss=1.150 (perp=5.371, rec=0.074, cos=0.002), tot_loss_proj:1.656 [t=0.18s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1550/2000] tot_loss=1.146 (perp=5.371, rec=0.070, cos=0.002), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1600/2000] tot_loss=1.141 (perp=5.371, rec=0.066, cos=0.002), tot_loss_proj:1.653 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
[1650/2000] tot_loss=1.141 (perp=5.371, rec=0.065, cos=0.002), tot_loss_proj:1.656 [t=0.18s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1700/2000] tot_loss=1.141 (perp=5.371, rec=0.065, cos=0.002), tot_loss_proj:1.643 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1750/2000] tot_loss=1.138 (perp=5.371, rec=0.062, cos=0.002), tot_loss_proj:1.655 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
[1800/2000] tot_loss=1.138 (perp=5.371, rec=0.062, cos=0.002), tot_loss_proj:1.655 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1850/2000] tot_loss=1.143 (perp=5.371, rec=0.067, cos=0.002), tot_loss_proj:1.645 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[1900/2000] tot_loss=1.135 (perp=5.371, rec=0.059, cos=0.002), tot_loss_proj:1.649 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
[1950/2000] tot_loss=1.135 (perp=5.371, rec=0.059, cos=0.002), tot_loss_proj:1.651 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Attempt swap
[2000/2000] tot_loss=1.146 (perp=5.371, rec=0.070, cos=0.002), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] want to think too much about what s going on want [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] want to think too much about what s going on want [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 86.957 | p: 83.333 | r: 90.909
rougeL     | fm: 96.000 | p: 92.308 | r: 100.000
rougeLsum  | fm: 96.000 | p: 92.308 | r: 100.000
r1fm+r2fm = 182.957

[Aggregate metrics]:
rouge1     | fm: 94.235 | p: 93.884 | r: 94.497
rouge2     | fm: 63.058 | p: 62.851 | r: 63.225
rougeL     | fm: 83.733 | p: 83.516 | r: 83.998
rougeLsum  | fm: 83.586 | p: 83.363 | r: 83.826
r1fm+r2fm = 157.293

input #17 time: 0:06:54 | total time: 2:05:37


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9993194147820215
highest_index [0]
highest [0.9993194147820215]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 1.974354863166809 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 1.9697707891464233 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 1.9564363956451416 for ['[CLS] bound dvd lead grace [SEP]']
[Init] best rec loss: 1.8697879314422607 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 1.7662303447723389 for ['[CLS] says oh dynasty watershed [SEP]']
[Init] best rec loss: 1.67368483543396 for ['[CLS] disappointednce secret running [SEP]']
[Init] best rec loss: 1.5851483345031738 for ['[CLS] with thy commission operating [SEP]']
[Init] best rec loss: 1.3104640245437622 for ['[CLS] dual circle duodle [SEP]']
[Init] best rec loss: 1.2881578207015991 for ['[CLS] canellant replication calm [SEP]']
[Init] best perm rec loss: 1.2752639055252075 for ['[CLS] replicationellant can calm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.597 (perp=11.791, rec=0.234, cos=0.005), tot_loss_proj:3.650 [t=0.18s]
prediction: ['[CLS]gorgorgorating [SEP]']
[ 100/2000] tot_loss=2.050 (perp=9.456, rec=0.156, cos=0.003), tot_loss_proj:2.783 [t=0.18s]
prediction: ['[CLS]gorvigorating [SEP]']
[ 150/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.182 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
[ 200/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.179 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.193 (perp=5.588, rec=0.073, cos=0.002), tot_loss_proj:1.186 [t=0.21s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.196 (perp=5.588, rec=0.077, cos=0.001), tot_loss_proj:1.180 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.190 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.176 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.191 (perp=5.588, rec=0.072, cos=0.001), tot_loss_proj:1.181 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.179 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.188 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.190 (perp=5.588, rec=0.071, cos=0.001), tot_loss_proj:1.185 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.183 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.167 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.173 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.186 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.198 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.185 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.178 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.165 (perp=5.588, rec=0.046, cos=0.001), tot_loss_proj:1.178 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.187 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.180 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.174 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.161 (perp=5.588, rec=0.042, cos=0.001), tot_loss_proj:1.175 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.183 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.185 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.184 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.185 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.182 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.192 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.176 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.181 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.185 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.186 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.184 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.185 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.169 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.194 (perp=5.588, rec=0.075, cos=0.001), tot_loss_proj:1.179 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.172 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.190 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.188 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.617 | p: 94.345 | r: 94.837
rouge2     | fm: 65.167 | p: 65.005 | r: 65.315
rougeL     | fm: 84.552 | p: 84.352 | r: 84.765
rougeLsum  | fm: 84.557 | p: 84.328 | r: 84.803
r1fm+r2fm = 159.784

input #18 time: 0:06:53 | total time: 2:12:30


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9993635209107408
highest_index [0]
highest [0.9993635209107408]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 1.458032250404358 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 1.306396722793579 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 1.226775884628296 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 1.1880154609680176 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 1.1041380167007446 for ['[CLS] intra raf soviet events [SEP]']
[Init] best perm rec loss: 1.1023863554000854 for ['[CLS] raf soviet events intra [SEP]']
[Init] best perm rec loss: 1.099515676498413 for ['[CLS] intra events soviet raf [SEP]']
[Init] best perm rec loss: 1.0991603136062622 for ['[CLS] soviet intra events raf [SEP]']
[Init] best perm rec loss: 1.0963892936706543 for ['[CLS] soviet events intra raf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.516 (perp=10.788, rec=0.308, cos=0.050), tot_loss_proj:3.554 [t=0.17s]
prediction: ['[CLS]famy to compound [SEP]']
[ 100/2000] tot_loss=2.180 (perp=10.293, rec=0.117, cos=0.004), tot_loss_proj:3.453 [t=0.17s]
prediction: ['[CLS]famy to in [SEP]']
[ 150/2000] tot_loss=2.125 (perp=10.293, rec=0.065, cos=0.002), tot_loss_proj:3.447 [t=0.17s]
prediction: ['[CLS]famy to in [SEP]']
[ 200/2000] tot_loss=2.133 (perp=10.293, rec=0.072, cos=0.002), tot_loss_proj:3.443 [t=0.17s]
prediction: ['[CLS]famy to in [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.290 (perp=6.110, rec=0.065, cos=0.003), tot_loss_proj:1.307 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.279 (perp=6.110, rec=0.056, cos=0.001), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.290 (perp=6.110, rec=0.066, cos=0.001), tot_loss_proj:1.309 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.279 (perp=6.110, rec=0.056, cos=0.001), tot_loss_proj:1.296 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.290 (perp=6.110, rec=0.066, cos=0.001), tot_loss_proj:1.301 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.288 (perp=6.110, rec=0.065, cos=0.001), tot_loss_proj:1.298 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.288 (perp=6.110, rec=0.064, cos=0.001), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.290 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.278 (perp=6.110, rec=0.055, cos=0.001), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.285 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.304 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.273 (perp=6.110, rec=0.050, cos=0.001), tot_loss_proj:1.289 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.292 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.294 (perp=6.110, rec=0.071, cos=0.001), tot_loss_proj:1.302 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.293 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.301 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.281 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.297 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.293 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.276 (perp=6.110, rec=0.053, cos=0.001), tot_loss_proj:1.300 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.278 (perp=6.110, rec=0.055, cos=0.001), tot_loss_proj:1.298 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.285 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.271 (perp=6.110, rec=0.048, cos=0.001), tot_loss_proj:1.297 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.278 (perp=6.110, rec=0.055, cos=0.001), tot_loss_proj:1.300 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.280 (perp=6.110, rec=0.056, cos=0.001), tot_loss_proj:1.304 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.284 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.303 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.285 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.303 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.291 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.310 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.292 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.286 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.288 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.278 (perp=6.110, rec=0.054, cos=0.001), tot_loss_proj:1.302 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.281 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.294 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.303 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.281 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.294 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.278 (perp=6.110, rec=0.055, cos=0.001), tot_loss_proj:1.307 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.292 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.275 (perp=6.110, rec=0.051, cos=0.001), tot_loss_proj:1.301 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.281 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.287 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.851 | p: 94.658 | r: 95.167
rouge2     | fm: 66.837 | p: 66.592 | r: 66.925
rougeL     | fm: 85.461 | p: 85.244 | r: 85.713
rougeLsum  | fm: 85.402 | p: 85.117 | r: 85.700
r1fm+r2fm = 161.688

input #19 time: 0:06:52 | total time: 2:19:23


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9992466071766843
highest_index [0]
highest [0.9992466071766843]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 1.7585136890411377 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 1.6632047891616821 for ['[CLS] map your included adventure [SEP]']
[Init] best rec loss: 1.4528199434280396 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 1.4066518545150757 for ['[CLS] trialuce tai sweet [SEP]']
[Init] best rec loss: 1.3769547939300537 for ['[CLS]nst 2018 principles arguing [SEP]']
[Init] best rec loss: 1.322018027305603 for ['[CLS] jensen eden blackwell is [SEP]']
[Init] best rec loss: 1.2753173112869263 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best perm rec loss: 1.2749077081680298 for ['[CLS]ness storylinexi [CLS] [SEP]']
[Init] best perm rec loss: 1.2715117931365967 for ['[CLS] storylinexiness [CLS] [SEP]']
[Init] best perm rec loss: 1.2714813947677612 for ['[CLS] storylinenessxi [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.802 (perp=11.356, rec=0.415, cos=0.115), tot_loss_proj:3.101 [t=0.18s]
prediction: ['[CLS] venom pleasure pleasure the [SEP]']
[ 100/2000] tot_loss=2.471 (perp=11.363, rec=0.182, cos=0.017), tot_loss_proj:3.325 [t=0.18s]
prediction: ['[CLS]verse the pleasure including [SEP]']
[ 150/2000] tot_loss=2.278 (perp=10.783, rec=0.116, cos=0.006), tot_loss_proj:3.308 [t=0.19s]
prediction: ['[CLS]verse the pleasure per [SEP]']
[ 200/2000] tot_loss=2.255 (perp=10.783, rec=0.095, cos=0.003), tot_loss_proj:3.318 [t=0.19s]
prediction: ['[CLS]verse the pleasure per [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.777 (perp=7.784, rec=0.199, cos=0.021), tot_loss_proj:1.896 [t=0.18s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 300/2000] tot_loss=1.656 (perp=7.784, rec=0.095, cos=0.004), tot_loss_proj:1.923 [t=0.19s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.641 (perp=7.784, rec=0.082, cos=0.002), tot_loss_proj:1.925 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.621 (perp=7.784, rec=0.063, cos=0.002), tot_loss_proj:1.935 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 450/2000] tot_loss=1.617 (perp=7.784, rec=0.059, cos=0.002), tot_loss_proj:1.930 [t=0.19s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.632 (perp=7.784, rec=0.074, cos=0.001), tot_loss_proj:1.935 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.630 (perp=7.784, rec=0.072, cos=0.002), tot_loss_proj:1.931 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 600/2000] tot_loss=1.626 (perp=7.784, rec=0.068, cos=0.002), tot_loss_proj:1.931 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.625 (perp=7.784, rec=0.067, cos=0.001), tot_loss_proj:1.932 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.623 (perp=7.784, rec=0.065, cos=0.001), tot_loss_proj:1.937 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 750/2000] tot_loss=1.619 (perp=7.784, rec=0.060, cos=0.002), tot_loss_proj:1.932 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.623 (perp=7.784, rec=0.065, cos=0.001), tot_loss_proj:1.934 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.635 (perp=7.784, rec=0.077, cos=0.001), tot_loss_proj:1.929 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 900/2000] tot_loss=1.616 (perp=7.784, rec=0.058, cos=0.002), tot_loss_proj:1.929 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.620 (perp=7.784, rec=0.061, cos=0.001), tot_loss_proj:1.925 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1000/2000] tot_loss=1.625 (perp=7.784, rec=0.067, cos=0.001), tot_loss_proj:1.932 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1050/2000] tot_loss=1.611 (perp=7.784, rec=0.053, cos=0.001), tot_loss_proj:1.926 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1100/2000] tot_loss=1.608 (perp=7.784, rec=0.049, cos=0.001), tot_loss_proj:1.941 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1150/2000] tot_loss=1.627 (perp=7.784, rec=0.069, cos=0.001), tot_loss_proj:1.926 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1200/2000] tot_loss=1.629 (perp=7.784, rec=0.071, cos=0.001), tot_loss_proj:1.933 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1250/2000] tot_loss=1.609 (perp=7.784, rec=0.051, cos=0.001), tot_loss_proj:1.935 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1300/2000] tot_loss=1.620 (perp=7.784, rec=0.061, cos=0.001), tot_loss_proj:1.928 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1350/2000] tot_loss=1.631 (perp=7.784, rec=0.073, cos=0.001), tot_loss_proj:1.921 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1400/2000] tot_loss=1.634 (perp=7.784, rec=0.075, cos=0.001), tot_loss_proj:1.935 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1450/2000] tot_loss=1.617 (perp=7.784, rec=0.058, cos=0.002), tot_loss_proj:1.929 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1500/2000] tot_loss=1.616 (perp=7.784, rec=0.058, cos=0.001), tot_loss_proj:1.938 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1550/2000] tot_loss=1.627 (perp=7.784, rec=0.068, cos=0.002), tot_loss_proj:1.939 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1600/2000] tot_loss=1.614 (perp=7.784, rec=0.056, cos=0.001), tot_loss_proj:1.941 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1650/2000] tot_loss=1.624 (perp=7.784, rec=0.065, cos=0.001), tot_loss_proj:1.938 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1700/2000] tot_loss=1.631 (perp=7.784, rec=0.073, cos=0.001), tot_loss_proj:1.924 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1750/2000] tot_loss=1.622 (perp=7.784, rec=0.064, cos=0.001), tot_loss_proj:1.931 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1800/2000] tot_loss=1.623 (perp=7.784, rec=0.065, cos=0.002), tot_loss_proj:1.925 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1850/2000] tot_loss=1.619 (perp=7.784, rec=0.060, cos=0.001), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1900/2000] tot_loss=1.623 (perp=7.784, rec=0.064, cos=0.002), tot_loss_proj:1.941 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1950/2000] tot_loss=1.627 (perp=7.784, rec=0.068, cos=0.002), tot_loss_proj:1.945 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[2000/2000] tot_loss=1.620 (perp=7.784, rec=0.061, cos=0.001), tot_loss_proj:1.938 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the pleasure perverse [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 95.149 | p: 94.908 | r: 95.283
rouge2     | fm: 64.899 | p: 64.709 | r: 65.087
rougeL     | fm: 85.189 | p: 85.021 | r: 85.440
rougeLsum  | fm: 85.001 | p: 84.779 | r: 85.302
r1fm+r2fm = 160.049

input #20 time: 0:06:54 | total time: 2:26:18


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.999323347023505
highest_index [0]
highest [0.999323347023505]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 1.8797924518585205 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 1.6756571531295776 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 1.6570099592208862 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 1.6356710195541382 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 1.525413990020752 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 1.5040524005889893 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 1.4968369007110596 for ['[CLS] bonn university on ashe shot wearing rockerlica classification speed non burning glad california againstanding colt timing mouthigo gun machinery score liked seems [SEP]']
[Init] best rec loss: 1.2692524194717407 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 1.2645514011383057 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 1.2639286518096924 for ['[CLS] pose bent rights vii labor loanback dee, itemtaking general fauna stony size she connecticut side according especially golden situations [UNK] baby there [SEP]']
[Init] best perm rec loss: 1.2572057247161865 for ['[CLS], situations connecticutback especially pose item benttaking dee golden rights general stony she loan size according [UNK] labor vii fauna there baby side [SEP]']
[Init] best perm rec loss: 1.2564804553985596 for ['[CLS] especiallytaking there she goldenback dee bent pose stony, situations loan size rights item [UNK] labor general baby connecticut vii fauna side according [SEP]']
[Init] best perm rec loss: 1.2533059120178223 for ['[CLS] general situations connecticut golden labor dee according bent especially baby there loan stonyback pose side [UNK] she vii item size rights,taking fauna [SEP]']
[Init] best perm rec loss: 1.2523531913757324 for ['[CLS] there baby loan vii fauna side she connecticut pose stony labor bent situations item according [UNK] especially deetaking golden, sizeback rights general [SEP]']
[Init] best perm rec loss: 1.2521893978118896 for ['[CLS] loan size baby, especially stony situations item bent there according connecticuttaking side fauna poseback dee golden general [UNK] she labor rights vii [SEP]']
[Init] best perm rec loss: 1.2520167827606201 for ['[CLS] rights golden according loan bent [UNK] situations connecticut stony there vii general dee size babyback labor she,taking fauna item especially side pose [SEP]']
[Init] best perm rec loss: 1.2508926391601562 for ['[CLS] fauna she vii [UNK] rightsback bent stony baby there connecticut item situations labor according golden size, side loantaking especially pose general dee [SEP]']
[Init] best perm rec loss: 1.2494364976882935 for ['[CLS] especially loanback vii [UNK] situations baby golden size bent connecticut dee according stony pose general labor rights fauna she item theretaking, side [SEP]']
[Init] best perm rec loss: 1.2471531629562378 for ['[CLS] she especially [UNK] item pose golden vii generalback there sidetaking rights loan, dee baby stony labor size according bent fauna connecticut situations [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.632 (perp=11.321, rec=0.346, cos=0.021), tot_loss_proj:3.164 [t=0.17s]
prediction: ['[CLS] became typical congress more labourers by rape remember.typical standard workers the war hairy who specific removed then votes its surrounds shade that players [SEP]']
[ 100/2000] tot_loss=2.405 (perp=10.597, rec=0.277, cos=0.008), tot_loss_proj:3.226 [t=0.17s]
prediction: ['[CLS] made instead congress more athletes out women moral.typical looks monkeys thettered when women expressed instead then votes women out shade better players [SEP]']
[ 150/2000] tot_loss=2.427 (perp=10.941, rec=0.230, cos=0.008), tot_loss_proj:3.305 [t=0.17s]
prediction: ['[CLS] makes instead way more athletes out women moral.typical look hanna thexious haired women expressed instead of information women element twist way teachers [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.237, rec=0.210, cos=0.006), tot_loss_proj:3.198 [t=0.18s]
prediction: ['[CLS] makes more way more caretaker out women moral.typical look like thexious haired women finley instead work information women that works way teachers [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.215 (perp=10.201, rec=0.170, cos=0.005), tot_loss_proj:3.090 [t=0.17s]
prediction: ['[CLS] makes way more like caretaker this women moral.typical look forwards the stereo fireplace women finley instead works or women out works out athletes [SEP]']
[ 300/2000] tot_loss=2.311 (perp=10.814, rec=0.145, cos=0.004), tot_loss_proj:2.973 [t=0.18s]
prediction: ['[CLS] makes way more like caretaker this all moral.typical looktypical the stereo the women poems instead worksch women out works out athletes [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.921 (perp=8.895, rec=0.138, cos=0.005), tot_loss_proj:2.631 [t=0.18s]
prediction: ['[CLS] makes way more like caretaker this all moral. looktypical the stereotypical the women poems instead works out women athletes works out athletes [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.908 (perp=8.911, rec=0.122, cos=0.004), tot_loss_proj:2.660 [t=0.18s]
prediction: ['[CLS] makes way more like caretaker this all moral. looktypical the stereotypical the things of poems instead works out women works out athletes [SEP]']
[ 450/2000] tot_loss=1.892 (perp=8.898, rec=0.109, cos=0.004), tot_loss_proj:2.775 [t=0.17s]
prediction: ['[CLS] makes way more like caretaker this all moral. looktypical the stereotypical theness and poems instead works out women works out athletes [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.868 (perp=8.734, rec=0.114, cos=0.007), tot_loss_proj:2.787 [t=0.17s]
prediction: ['[CLS] makes way more like this all moral caretaker. looktypical the stereotypical theness and poems instead works out women out out athletes [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.800 (perp=8.506, rec=0.096, cos=0.003), tot_loss_proj:2.700 [t=0.17s]
prediction: ['[CLS] makes way more like this all moral caretaker. looktypical the stereotypical theness and poems instead works out women out athletes out [SEP]']
[ 600/2000] tot_loss=1.789 (perp=8.506, rec=0.086, cos=0.003), tot_loss_proj:2.698 [t=0.17s]
prediction: ['[CLS] makes way more like this all moral caretaker. looktypical the stereotypical theness and poems instead works out women out athletes out [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.799 (perp=8.574, rec=0.082, cos=0.002), tot_loss_proj:2.922 [t=0.17s]
prediction: ['[CLS] makes way more like this all moral caretaker. looktypical the stereotypical theness and women instead works out poems out athletes serious [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.786 (perp=8.503, rec=0.083, cos=0.002), tot_loss_proj:2.937 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker. looktypical the stereotypical theness and women instead works out poems out athletes serious [SEP]']
[ 750/2000] tot_loss=1.775 (perp=8.444, rec=0.084, cos=0.002), tot_loss_proj:2.853 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker. looktypical the stereotypical the teachers and women instead works out poems out athletes serious [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.699 (perp=8.059, rec=0.084, cos=0.002), tot_loss_proj:2.678 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker. looktypical the stereotypical thes and women instead works athletes or poems out serious [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.672 (perp=7.958, rec=0.078, cos=0.002), tot_loss_proj:2.481 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker look.typical the stereotypical the teachers and women instead works athletes or poems out serious [SEP]']
[ 900/2000] tot_loss=1.661 (perp=7.958, rec=0.067, cos=0.002), tot_loss_proj:2.485 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker look.typical the stereotypical the teachers and women instead works athletes or poems out serious [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.645 (perp=7.851, rec=0.073, cos=0.002), tot_loss_proj:2.344 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works athletes or poems out serious [SEP]']
Attempt swap
[1000/2000] tot_loss=1.653 (perp=7.851, rec=0.081, cos=0.002), tot_loss_proj:2.345 [t=0.20s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works athletes or poems out serious [SEP]']
[1050/2000] tot_loss=1.642 (perp=7.851, rec=0.070, cos=0.002), tot_loss_proj:2.349 [t=0.20s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works athletes or poems out serious [SEP]']
Attempt swap
[1100/2000] tot_loss=1.657 (perp=7.851, rec=0.084, cos=0.002), tot_loss_proj:2.341 [t=0.19s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works athletes or poems out serious [SEP]']
Attempt swap
[1150/2000] tot_loss=1.656 (perp=7.851, rec=0.084, cos=0.002), tot_loss_proj:2.344 [t=0.19s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works athletes or poems out serious [SEP]']
[1200/2000] tot_loss=1.649 (perp=7.851, rec=0.077, cos=0.002), tot_loss_proj:2.343 [t=0.20s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works athletes or poems out serious [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.654 (perp=7.876, rec=0.077, cos=0.002), tot_loss_proj:2.420 [t=0.20s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works athletes out serious poems out [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.837 (perp=8.732, rec=0.088, cos=0.002), tot_loss_proj:2.454 [t=0.19s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical out the stereotypical the teachers and women instead works athletes out serious punished of [SEP]']
[1350/2000] tot_loss=1.828 (perp=8.732, rec=0.079, cos=0.002), tot_loss_proj:2.449 [t=0.19s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical out the stereotypical the teachers and women instead works athletes out serious punished of [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.712 (perp=8.171, rec=0.076, cos=0.002), tot_loss_proj:2.295 [t=0.19s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical of the stereotypical the teachers and women instead works athletes out serious punished out [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.650 (perp=7.840, rec=0.080, cos=0.002), tot_loss_proj:2.320 [t=0.21s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out out serious punished athletes [SEP]']
[1500/2000] tot_loss=1.679 (perp=7.989, rec=0.079, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out out serious poems athletes [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.637 (perp=7.834, rec=0.068, cos=0.002), tot_loss_proj:2.390 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]']
Attempt swap
[1600/2000] tot_loss=1.644 (perp=7.834, rec=0.075, cos=0.002), tot_loss_proj:2.390 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]']
[1650/2000] tot_loss=1.650 (perp=7.834, rec=0.081, cos=0.002), tot_loss_proj:2.392 [t=0.18s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]']
Attempt swap
[1700/2000] tot_loss=1.640 (perp=7.834, rec=0.071, cos=0.002), tot_loss_proj:2.395 [t=0.18s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]']
Attempt swap
[1750/2000] tot_loss=1.647 (perp=7.834, rec=0.079, cos=0.002), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]']
[1800/2000] tot_loss=1.642 (perp=7.834, rec=0.073, cos=0.002), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]']
Attempt swap
[1850/2000] tot_loss=1.639 (perp=7.834, rec=0.070, cos=0.002), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]']
Attempt swap
[1900/2000] tot_loss=1.647 (perp=7.834, rec=0.078, cos=0.002), tot_loss_proj:2.390 [t=0.18s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]']
[1950/2000] tot_loss=1.643 (perp=7.834, rec=0.074, cos=0.002), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]']
Attempt swap
[2000/2000] tot_loss=1.645 (perp=7.834, rec=0.076, cos=0.002), tot_loss_proj:2.393 [t=0.18s]
prediction: ['[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] makes way more like all this moral caretaker looktypical. the stereotypical the teachers and women instead works out serious poems athletes out [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.106 | p: 83.333 | r: 86.957
rouge2     | fm: 8.889 | p: 8.696 | r: 9.091
rougeL     | fm: 42.553 | p: 41.667 | r: 43.478
rougeLsum  | fm: 42.553 | p: 41.667 | r: 43.478
r1fm+r2fm = 93.995

[Aggregate metrics]:
rouge1     | fm: 94.624 | p: 94.329 | r: 94.898
rouge2     | fm: 62.514 | p: 62.335 | r: 62.700
rougeL     | fm: 83.235 | p: 83.022 | r: 83.492
rougeLsum  | fm: 83.200 | p: 82.951 | r: 83.460
r1fm+r2fm = 157.137

input #21 time: 0:07:06 | total time: 2:33:24


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9993366894184397
highest_index [0]
highest [0.9993366894184397]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 1.9521197080612183 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 1.8905121088027954 for ['[CLS] shakespeare operation emerald hip year art mcdowell model apart league rate [SEP]']
[Init] best rec loss: 1.8834716081619263 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 1.881540298461914 for ['[CLS]berries thirds rounds exit whole reaction flux packages advertising dish habit [SEP]']
[Init] best rec loss: 1.849566102027893 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 1.8134469985961914 for ['[CLS] av waitingalis reception pillar anna deal mentionedhl etc showers [SEP]']
[Init] best rec loss: 1.7512906789779663 for ['[CLS] cloud road hey wynn under diiny stalk seduce variousour [SEP]']
[Init] best rec loss: 1.7188242673873901 for ['[CLS] dialectotte [MASK] type became designing aired replacing piece dear travel [SEP]']
[Init] best rec loss: 1.711775779724121 for ['[CLS] immortal dos standing commentarytort placehim corporal full cruisers carrier [SEP]']
[Init] best rec loss: 1.6849783658981323 for ['[CLS] sans services downstairsgar arched take network before simply dean jurgen [SEP]']
[Init] best rec loss: 1.6268218755722046 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 1.6199898719787598 for ['[CLS] her function board kids phoenix laughter set over chineseers schedule [SEP]']
[Init] best perm rec loss: 1.6110483407974243 for ['[CLS] phoenix her laughter over function schedule chinese boarders kids set [SEP]']
[Init] best perm rec loss: 1.610538125038147 for ['[CLS] function over schedule phoenix herers chinese kids laughter board set [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.358 (perp=10.494, rec=0.255, cos=0.004), tot_loss_proj:2.988 [t=0.17s]
prediction: ['[CLS] successful success measured adaptation productions numbered co productions funded an adaptation [SEP]']
[ 100/2000] tot_loss=2.195 (perp=10.054, rec=0.181, cos=0.003), tot_loss_proj:2.757 [t=0.18s]
prediction: ['[CLS] successful success right adaptation whose successful adaptation films an a adaptation [SEP]']
[ 150/2000] tot_loss=2.146 (perp=10.033, rec=0.137, cos=0.002), tot_loss_proj:2.541 [t=0.18s]
prediction: ['[CLS] successful successful right film his successful film film an a adaptation [SEP]']
[ 200/2000] tot_loss=1.814 (perp=8.424, rec=0.127, cos=0.002), tot_loss_proj:2.127 [t=0.18s]
prediction: ['[CLS] enjoyable successful right film from own right film and a adaptation [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.967 (perp=9.117, rec=0.141, cos=0.002), tot_loss_proj:2.287 [t=0.17s]
prediction: ['[CLS] enjoyable successful own richard reader characters and a right film adaptation [SEP]']
[ 300/2000] tot_loss=1.885 (perp=8.890, rec=0.105, cos=0.002), tot_loss_proj:2.224 [t=0.17s]
prediction: ['[CLS] enjoyable successful its richard reader character and a right film adaptation [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.899 (perp=9.034, rec=0.090, cos=0.002), tot_loss_proj:2.294 [t=0.18s]
prediction: ['[CLS] enjoyable successful its an his characters and a right film adaptation [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.753 (perp=8.238, rec=0.103, cos=0.002), tot_loss_proj:2.100 [t=0.20s]
prediction: ['[CLS] his successful its an enjoyable fiction and a right film adaptation [SEP]']
[ 450/2000] tot_loss=1.747 (perp=8.290, rec=0.087, cos=0.002), tot_loss_proj:2.076 [t=0.19s]
prediction: ['[CLS] his successful its an enjoyable characters and a right film adaptation [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.684 (perp=7.936, rec=0.096, cos=0.002), tot_loss_proj:1.985 [t=0.18s]
prediction: ['[CLS] his successful its characters an enjoyable and a right film adaptation [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.932 (perp=9.233, rec=0.084, cos=0.002), tot_loss_proj:2.304 [t=0.19s]
prediction: ['[CLS] his successful its h₂o an enjoyable and a right film adaptation [SEP]']
[ 600/2000] tot_loss=1.934 (perp=9.233, rec=0.086, cos=0.002), tot_loss_proj:2.310 [t=0.18s]
prediction: ['[CLS] his successful its h₂o an enjoyable and a right film adaptation [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.812 (perp=8.613, rec=0.088, cos=0.002), tot_loss_proj:2.263 [t=0.23s]
prediction: ['[CLS] his successful its and an enjoyable characters a right film adaptation [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.714 (perp=8.102, rec=0.092, cos=0.002), tot_loss_proj:2.147 [t=0.20s]
prediction: ['[CLS] his successful its and an enjoyable characters right a film adaptation [SEP]']
[ 750/2000] tot_loss=1.704 (perp=8.102, rec=0.083, cos=0.002), tot_loss_proj:2.145 [t=0.17s]
prediction: ['[CLS] his successful its and an enjoyable characters right a film adaptation [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.807 (perp=8.513, rec=0.103, cos=0.002), tot_loss_proj:2.233 [t=0.17s]
prediction: ['[CLS] his successful its h₂o and an enjoyable right a film adaptation [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.756 (perp=8.319, rec=0.091, cos=0.002), tot_loss_proj:2.205 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable right a film adaptation [SEP]']
[ 900/2000] tot_loss=1.751 (perp=8.319, rec=0.086, cos=0.002), tot_loss_proj:2.208 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable right a film adaptation [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.759 (perp=8.319, rec=0.094, cos=0.002), tot_loss_proj:2.213 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable right a film adaptation [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.738 (perp=8.190, rec=0.099, cos=0.002), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
[1050/2000] tot_loss=1.722 (perp=8.190, rec=0.082, cos=0.002), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.727 (perp=8.190, rec=0.087, cos=0.002), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.727 (perp=8.190, rec=0.088, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
[1200/2000] tot_loss=1.733 (perp=8.190, rec=0.094, cos=0.002), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.737 (perp=8.190, rec=0.097, cos=0.002), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.725 (perp=8.190, rec=0.085, cos=0.002), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
[1350/2000] tot_loss=1.727 (perp=8.190, rec=0.087, cos=0.002), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.728 (perp=8.190, rec=0.088, cos=0.002), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.726 (perp=8.190, rec=0.087, cos=0.002), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
[1500/2000] tot_loss=1.727 (perp=8.190, rec=0.087, cos=0.002), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.732 (perp=8.190, rec=0.092, cos=0.002), tot_loss_proj:2.107 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.726 (perp=8.190, rec=0.086, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
[1650/2000] tot_loss=1.735 (perp=8.190, rec=0.095, cos=0.002), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.723 (perp=8.190, rec=0.083, cos=0.002), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.721 (perp=8.190, rec=0.081, cos=0.002), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
[1800/2000] tot_loss=1.717 (perp=8.190, rec=0.077, cos=0.002), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.725 (perp=8.190, rec=0.085, cos=0.002), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.733 (perp=8.190, rec=0.093, cos=0.002), tot_loss_proj:2.097 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
[1950/2000] tot_loss=1.721 (perp=8.190, rec=0.081, cos=0.002), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.735 (perp=8.190, rec=0.095, cos=0.002), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] his successful h₂o and its an enjoyable adaptation right a film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.481 | p: 78.571 | r: 84.615
rouge2     | fm: 8.000 | p: 7.692 | r: 8.333
rougeL     | fm: 51.852 | p: 50.000 | r: 53.846
rougeLsum  | fm: 51.852 | p: 50.000 | r: 53.846
r1fm+r2fm = 89.481

[Aggregate metrics]:
rouge1     | fm: 94.058 | p: 93.641 | r: 94.505
rouge2     | fm: 59.574 | p: 59.422 | r: 59.744
rougeL     | fm: 81.909 | p: 81.556 | r: 82.217
rougeLsum  | fm: 81.747 | p: 81.491 | r: 82.103
r1fm+r2fm = 153.632

input #22 time: 0:07:03 | total time: 2:40:27


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.999235259621351
highest_index [0]
highest [0.999235259621351]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 1.383732795715332 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 1.3736612796783447 for ['[CLS] jumped its ion [MASK] deep spirit tracks controls spun donated tape calendar ineligible martial airport breaths complexvas net straight vs # jake featurebal each roots record death share troubles chance scores mate frank holding quest exactlyul governments win far ap gathering toysience married club [SEP]']
[Init] best rec loss: 1.3212342262268066 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 1.3039929866790771 for ['[CLS]cation oystermel though painfies aftermath faction micro ec decommissioned hole federation educated wi looking ban office mean creation positional vi morning envy fair ken goodwill sons no give aren para shops calendar concert beingsian you pl denmark love platform battle flags astronomy rome asking [SEP]']
[Init] best rec loss: 1.2455841302871704 for ['[CLS] talent cause skirt handled ⁴ anne pieces mine! caused safety tor goal fore 2014 residents chosen offering chiefs number sun consumergementni property riding dolphin exchequerada saw occupants trades vale course kind coronation ballroom dona village totally selena winds firstd sums manga square scholar [SEP]']
[Init] best rec loss: 1.2352474927902222 for ['[CLS] drugfl vienna chop ; wound shop wonder main added founded lennox bridge gel residential rich kilometers facing countries seal adults captain wet interstate tea saved mr hawk withdrawal indeed temperaly sent daily life ₱ rail era seasons bottom champion herselfsta? context teen ready airfield [SEP]']
[Init] best perm rec loss: 1.2314822673797607 for ['[CLS] indeed champion kilometers withdrawal gel seal tea drug wonder ; founded vienna era herself ₱ added residential daily bridge sent adults airfield captain mr ready contextsta bottom seasons shop rail wet life hawkaly countries teen facing richfl lennox saved main? interstate wound temper chop [SEP]']
[Init] best perm rec loss: 1.2305387258529663 for ['[CLS] sent shop wound airfield captain wetfl vienna countries mr ready main rail seasons daily drug facing seal teen saved ; bridge adults temper added context withdrawal champion wondersta rich era kilometers bottom hawk tea residential? foundedaly indeed ₱ interstate life chop gel lennox herself [SEP]']
[Init] best perm rec loss: 1.2290924787521362 for ['[CLS] indeed ₱ facing seasonsfl rich bridge main mr gel wonder vienna founded ready champion chop hawk wet context kilometers captain life teen sent bottom saved woundaly rail era lennox withdrawal tea drug interstate temper seal residential added shop airfield daily herself countries ;sta adults? [SEP]']
[Init] best perm rec loss: 1.2287770509719849 for ['[CLS] airfield rail added hawk context indeed countries withdrawal shop rich vienna seal captain champion mr sent life temper daily gel teen tea bridge ₱ residential adults saved drugsta bottom founded lennox ready facing ; interstate woundfl kilometers wet main wonder chop seasonsaly era herself? [SEP]']
[Init] best perm rec loss: 1.2277514934539795 for ['[CLS] residential lennoxfl rich hawk captain ₱aly tea daily main drug sent viennasta facing? ; gel wound context countries temper teen shop champion seal seasons wet herself airfield adults founded saved life ready wonder mr interstate bottom era indeed chop added kilometers withdrawal bridge rail [SEP]']
[Init] best perm rec loss: 1.2267485857009888 for ['[CLS] seal ready mr captainfl rich shop drug main rail residential era gel temper saved? countries kilometers tea bottom interstate added context life bridge lennox vienna champion herself daily facing chop withdrawal adults teen indeed ₱ ; airfield woundsta seasons hawk wonder wet founded sentaly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.005 (perp=12.481, rec=0.368, cos=0.141), tot_loss_proj:3.785 [t=0.17s]
prediction: ['[CLS] means shoulder sidestrum alarm vietnam orbit multi papa [CLS] his objectively no diesel troops when employees service rule.estra suicide treaty zero specific reason self herself disease is goals kate emphasized! enormous facetat resistance whose frame patroling its scientist moral serious french [SEP]']
[ 100/2000] tot_loss=2.474 (perp=11.114, rec=0.239, cos=0.013), tot_loss_proj:3.520 [t=0.17s]
prediction: ['[CLS] its main sides sarcasm soldier poem shiva against classical : of objective,, hang soldiers when league politics hold. lacked attack sorry neo : soldiers its leave combat achieve objective performances friars.ilation problemsum marketing whose framing extending the its soldier strategic. french [SEP]']
[ 150/2000] tot_loss=2.289 (perp=10.499, rec=0.181, cos=0.008), tot_loss_proj:3.167 [t=0.17s]
prediction: ['[CLS] ultimately main ins patriotic strategic poem received against rejection of of objective -, ra soldiers isifying politics holding. lacked : ultimately ultimately : soldiers its knife conflict achieve objective performances whereas theilation controversyation strategic itsitung extending the those soldiers strategic. french [SEP]']
[ 200/2000] tot_loss=2.162 (perp=9.956, rec=0.164, cos=0.006), tot_loss_proj:3.552 [t=0.17s]
prediction: ['[CLS] ultimately main ultimately patriotic strategic vietnam vietnam with idea a of main -, ra soldiers,ization politics hold. lacked the ultimately ultimately : soldiers its danger patriotic achieve objectives whereas the ւ cost patriotic strategic picture dramazing the those soldiers strategic. the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.182 (perp=10.139, rec=0.147, cos=0.007), tot_loss_proj:3.063 [t=0.17s]
prediction: ['[CLS] ultimately main ultimately patriotic strategic vietnam vietnam the idea a of main -, ra soldiers,izingliness give. strategic ; ultimately ultimately : patriotic itsrix strategic achieve objectives although the conflict cost patriotic strategic picture dramazing the with generation kathleen. the [SEP]']
[ 300/2000] tot_loss=2.081 (perp=9.725, rec=0.133, cos=0.003), tot_loss_proj:3.018 [t=0.17s]
prediction: ['[CLS] ultimately main ultimately patriotic strategic vietnam vietnam the idea a of main -, ra soldiers, appropriateliness give. strategic the ultimately ultimately : patriotic its danger drama achieve objectives while the strategic cost patriotic strategic picture dramazing the that generation generation. a [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.764 (perp=11.057, rec=0.427, cos=0.126), tot_loss_proj:3.373 [t=0.17s]
prediction: ['[CLS] ultimately political civilians [CLS] strategic joyah crazy that idea the considered main, to ra soldiers, needsus body co strategic while shoulders ultimately : author its syrian strategic achieve objectives although. mandela dataar stated any dramazing. where ultimately theodore. a [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.564 (perp=10.758, rec=0.351, cos=0.061), tot_loss_proj:3.220 [t=0.17s]
prediction: ['[CLS] ultimately joyah civilians [CLS] strategic political crazy the agreement theh main, toh soldiers this valueus body co strategic whilestar ultimately : author its syrian oak achieve objectives although. mandela dataar stated the dramazing. who ultimately theodore. a [SEP]']
[ 450/2000] tot_loss=2.443 (perp=10.484, rec=0.308, cos=0.038), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers [CLS] strategic political crazy painting agreement the considered main, toh soldiers this valueus body tor strategic attack crisis ultimately : author its militants soldiers achieve objectives although. mandela proposalar stated the dramazing. who ultimately theodore. a [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.410 (perp=10.541, rec=0.280, cos=0.022), tot_loss_proj:3.240 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiersinator strategic political crazy the agreementh considered main, to the soldiers this valueus body tor strategic productions grip ultimately : author its militants soldiers achieve objectives although : mandela proposalar stated any dramazing. who ultimately theodore. a [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.345 (perp=10.355, rec=0.259, cos=0.015), tot_loss_proj:3.198 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic political crazy : agreementhh main, to the soldiers this valueus body tor strategic productions grip ultimately : author its militants soldiers achieve objectives although the recent proposalar project any dramazing. who ultimately theodore. a [SEP]']
[ 600/2000] tot_loss=2.355 (perp=10.473, rec=0.248, cos=0.012), tot_loss_proj:3.209 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic against crazy : agreementhh main, to the soldiers this valueus body tor strategic dragons faso civilian : author its militants soldiers achieve objectives although the recent proposalar project any dramazing. who ultimately theodore., [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.290 (perp=10.235, rec=0.232, cos=0.011), tot_loss_proj:3.157 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic against crazy : agreementh the main, toh soldiers this valueus body tor strategic productions grip civilian : author itsrence soldiers achieve objectives although the recent proposalar project any dramazing. where ultimately theodore., [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.248 (perp=10.060, rec=0.227, cos=0.008), tot_loss_proj:3.124 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic against crazy : agreementh the main, toq soldiers this valueus body tor strategic productions grip civilian : author itsrence soldiers achieve objectives although the recent proposalar project any wherezing. drama ultimately theodore., [SEP]']
[ 750/2000] tot_loss=2.239 (perp=10.060, rec=0.219, cos=0.008), tot_loss_proj:3.124 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic against crazy : agreementh the main, toq soldiers this valueus body tor strategic productions grip civilian : author itsrence soldiers achieve objectives although the recent proposalar project any wherezing. drama ultimately theodore., [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.264 (perp=10.211, rec=0.214, cos=0.008), tot_loss_proj:3.263 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic against crazy the agreementh the main, toh soldiers this valueus body. strategic artists grip civilian : author its situation soldiers achieve objectives although the recent proposalar project any wherezing nu drama ultimately theodore., [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.263 (perp=10.214, rec=0.211, cos=0.009), tot_loss_proj:3.357 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic operation crazy the agreementh the main, toh soldiers this valueus body. strategic against faso civilian : author its situation soldiers achieve objectives although the recent proposalar project the wherezing nu drama ultimately theodore. town [SEP]']
[ 900/2000] tot_loss=2.258 (perp=10.207, rec=0.209, cos=0.007), tot_loss_proj:3.333 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic operation synonym the agreementh the main, toh soldiers this valueus body. strategic against faso civilian : author its situation soldiers achieve objectives although the recent proposalar project the wherezing nu drama ultimately theodore. town [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.208 (perp=9.995, rec=0.202, cos=0.007), tot_loss_proj:3.207 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic operation synonym the agreementh the main, toh soldiers this valueus body. strategic against faso civilian : author its recent soldiers achieve objectives although the situation proposalar project the howzing nu drama ultimately theodore. town [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.179 (perp=9.843, rec=0.204, cos=0.007), tot_loss_proj:3.144 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic operation synonym the agreementh the main, toh soldiers this valueus body. strategic against faso civilian : author its recent soldiers achieves objective although the situation proposalar project the howzing nu drama ultimately theodore. town [SEP]']
[1050/2000] tot_loss=2.196 (perp=9.945, rec=0.201, cos=0.006), tot_loss_proj:3.149 [t=0.17s]
prediction: ['[CLS] ultimately vietnam soldiers confused strategic chinese synonym the agreementh the main, toh soldiers this valueus body. strategic against faso civilian : author its recent soldiers achieves objective although the situation proposalar project the howzing nu drama ultimately theodore. town [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.163 (perp=9.826, rec=0.192, cos=0.006), tot_loss_proj:3.155 [t=0.17s]
prediction: ['[CLS] ultimately soldiers soldiers confused strategic chinese synonym the agreementh the main, toh soldiers this valuesus body. strategic against faso civilian : author its recent vietnam achieves objective although the situation proposalar project the howzing nu drama ultimately theodore. town [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.085 (perp=9.427, rec=0.193, cos=0.006), tot_loss_proj:3.311 [t=0.17s]
prediction: ['[CLS] ultimately synonym soldiers confused strategic chinese soldiers the agreementh the main, toh soldiers this valuesus body. strategic against faso civilian : author its recent vietnam achieves objective although the situation proposalar project the howzing nu drama ultimately theodore. town [SEP]']
[1200/2000] tot_loss=2.080 (perp=9.427, rec=0.189, cos=0.005), tot_loss_proj:3.314 [t=0.17s]
prediction: ['[CLS] ultimately synonym soldiers confused strategic chinese soldiers the agreementh the main, toh soldiers this valuesus body. strategic against faso civilian : author its recent vietnam achieves objective although the situation proposalar project the howzing nu drama ultimately theodore. town [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.099 (perp=9.540, rec=0.186, cos=0.005), tot_loss_proj:3.098 [t=0.17s]
prediction: ['[CLS] ultimately usually soldiers confused strategic chinese soldiers the agreementh the main, toh soldiers this valuesus body. strategic against faso civilian : author its recent vietnam achieves objective although the situation proposalar project the how nuzing drama ultimately theodore. town [SEP]']
Attempt swap
[1300/2000] tot_loss=2.118 (perp=9.640, rec=0.185, cos=0.005), tot_loss_proj:3.102 [t=0.18s]
prediction: ['[CLS] ultimately usually soldiers confused strategic chinese soldiers the agreementh the main, toh soldiers this valuesus body. strategic against hands civilian : author its recent vietnam achieves objective although the situation proposalar project his how nuzing drama ultimately theodore. town [SEP]']
[1350/2000] tot_loss=2.160 (perp=9.836, rec=0.188, cos=0.005), tot_loss_proj:3.171 [t=0.17s]
prediction: ['[CLS] ultimately usually soldiers confused strategic chinese soldiers the agreementh the main, toh soldiers this valuesus body. strategic without nashville civilian : activities its recent vietnam achieves objective although the situation proposalar project his how nuzing drama ultimately theodore. town [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.130 (perp=9.717, rec=0.181, cos=0.005), tot_loss_proj:3.083 [t=0.17s]
prediction: ['[CLS] ultimately usually soldiers confused strategic chinese soldiers the agreementh the main, toh soldiers this valuesus vietnam. strategic without nashville civilian : activities its recent body achieves objective although the situation proposalar project his how nuzing drama ultimately theodore. town [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.122 (perp=9.647, rec=0.188, cos=0.005), tot_loss_proj:3.121 [t=0.17s]
prediction: ['[CLS] ultimately usually soldiers confused strategic chinese soldiers the agreementh the main, toh soldiers strategic valuesus vietnam. this without nashville civilian : activities its recent body achieves objective although the situation proposalar project his how nuzing drama ultimately theodore. town [SEP]']
[1500/2000] tot_loss=2.183 (perp=9.956, rec=0.188, cos=0.005), tot_loss_proj:3.262 [t=0.17s]
prediction: ['[CLS] ultimately usually soldiers confused strategic chinese soldiers the agreementh the main, toh soldiers strategic valuesus vietnam. this without nashville civilian : activities its recent body achieves objective although the situation proposalar strategic papal how nuzing drama ultimately theodore. town [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.172 (perp=9.934, rec=0.181, cos=0.005), tot_loss_proj:3.220 [t=0.17s]
prediction: ['[CLS] ultimately usually soldiers confused strategic chinese soldiers the agreementh the main, toh this soldiers strategic valuesus vietnam. °c nashville civilian : activities its recent body achieves objective although the situation proposalar strategic papal how nuzing drama ultimately theodore. town [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.170 (perp=9.893, rec=0.186, cos=0.005), tot_loss_proj:3.182 [t=0.17s]
prediction: ['[CLS] ultimately usually soldiers confused strategic chinese soldiers the agreementh the main, toh this soldiersus values strategic vietnam. °c nashville civilian : activities its recent body achieves objective although the situation proposalar strategic papal how nuzing drama ultimately theodore. town [SEP]']
[1650/2000] tot_loss=2.166 (perp=9.893, rec=0.182, cos=0.005), tot_loss_proj:3.185 [t=0.17s]
prediction: ['[CLS] ultimately usually soldiers confused strategic chinese soldiers the agreementh the main, toh this soldiersus values strategic vietnam. °c nashville civilian : activities its recent body achieves objective although the situation proposalar strategic papal how nuzing drama ultimately theodore. town [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.139 (perp=9.751, rec=0.184, cos=0.005), tot_loss_proj:3.178 [t=0.20s]
prediction: ['[CLS] how usually soldiers confused strategic chinese soldiers the agreementh the main, toh this soldiersus values strategic vietnam. °c nashville civilian : activities its recent body achieves objective although the situation proposalar strategic papal ultimately nuzing drama ultimately theodore. town [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.117 (perp=9.639, rec=0.185, cos=0.005), tot_loss_proj:3.303 [t=0.18s]
prediction: ['[CLS] how usually soldiers confused strategic chinese soldiers the ideah the main, toh this situationus values strategic vietnam. questions nashville civilian : activities its recent body achieves objective while the soldiers proposalar strategic papal ultimately nuzing drama ultimately theodore. town [SEP]']
[1800/2000] tot_loss=2.078 (perp=9.452, rec=0.183, cos=0.005), tot_loss_proj:3.229 [t=0.18s]
prediction: ['[CLS] how usually soldiers confused strategic chinese soldiers the ideah the main, toh this situationus values strategic vietnam. without nashville civilian : activities its recent body achieves objective while the soldiers proposalar strategic papal ultimately nuzing drama ultimately theodore. town [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=2.087 (perp=9.503, rec=0.182, cos=0.005), tot_loss_proj:3.199 [t=0.17s]
prediction: ['[CLS] how usually soldiers confused strategic chinese soldiers the ideah the main, toh this situationus values strategic vietnam. questions nashville civilian : activities its recent body achieves objective while the soldiers proposalar strategic papal ultimately nuzing drama. an ultimately theodore [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.052 (perp=9.302, rec=0.186, cos=0.006), tot_loss_proj:3.089 [t=0.17s]
prediction: ['[CLS] how usually soldiers confused strategic chinese soldiers the ideah the main, toh this situationus values strategic vietnam. °c nashville civilian : activities its recent body achieves objective while the papal proposalar strategic soldiers ultimately nuzing drama. an ultimately theodore [SEP]']
[1950/2000] tot_loss=2.015 (perp=9.130, rec=0.184, cos=0.005), tot_loss_proj:3.064 [t=0.17s]
prediction: ['[CLS] how usually soldiers confused strategic chinese soldiers the ideah the main, toh this situationus values strategic vietnam. without nashville civilian : activities its recent body achieves objective although the papal proposalar strategic soldiers ultimately nuzing drama. an ultimately theodore [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.974 (perp=8.934, rec=0.183, cos=0.005), tot_loss_proj:3.130 [t=0.17s]
prediction: ['[CLS] how usually soldiers confused strategic chinese soldiers the ideah the main, toh this situationus values strategic vietnam. without nashville civilian : activities its recent body achieves objective while the papal proposalar strategic soldiers ultimately nuzing drama theodore an ultimately. [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] ultimately main ultimately patriotic strategic vietnam vietnam the idea a of main -, ra soldiers, appropriateliness give. strategic the ultimately ultimately : patriotic its danger drama achieve objectives while the strategic cost patriotic strategic picture dramazing the that generation generation. a [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 51.852 | p: 51.220 | r: 52.500
rouge2     | fm: 2.532 | p: 2.500 | r: 2.564
rougeL     | fm: 32.099 | p: 31.707 | r: 32.500
rougeLsum  | fm: 32.099 | p: 31.707 | r: 32.500
r1fm+r2fm = 54.383

[Aggregate metrics]:
rouge1     | fm: 92.301 | p: 91.843 | r: 92.691
rouge2     | fm: 57.092 | p: 56.879 | r: 57.350
rougeL     | fm: 79.701 | p: 79.452 | r: 80.108
rougeLsum  | fm: 79.587 | p: 79.326 | r: 79.960
r1fm+r2fm = 149.393

input #23 time: 0:06:58 | total time: 2:47:26


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9993537840940762
highest_index [0]
highest [0.9993537840940762]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 1.825258493423462 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 1.6625887155532837 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 1.662034034729004 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 1.638895034790039 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 1.3410228490829468 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 1.323185920715332 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 1.1163339614868164 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 1.1137642860412598 for ['[CLS] bondwyl unless county em arms damned happy suffer play attack younger ryu midaneous bush snow village no port [SEP]']
[Init] best perm rec loss: 1.1134698390960693 for ['[CLS] unless play younger ryu attack village no mid damned portwyl happy suffer arms em snow bush bond countyaneous [SEP]']
[Init] best perm rec loss: 1.1096725463867188 for ['[CLS] attack unless em arms happywyl bond mid younger play snow villageaneous no county damned ryu suffer port bush [SEP]']
[Init] best perm rec loss: 1.1079434156417847 for ['[CLS] mid unless ryu play attack nowyl em younger countyaneous bond village happy damned snow bush port suffer arms [SEP]']
[Init] best perm rec loss: 1.107871174812317 for ['[CLS] suffer happy em younger play ryu no mid bond unless snow bush armsaneous damned attack countywyl village port [SEP]']
[Init] best perm rec loss: 1.1060388088226318 for ['[CLS] bond play damned unless county younger no midwyl em attack ryu village snow armsaneous happy bush suffer port [SEP]']
[Init] best perm rec loss: 1.1028209924697876 for ['[CLS] playwyl county em no mid arms bond bush damned snow unless happy ryu younger attack suffer village portaneous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.524 (perp=10.876, rec=0.331, cos=0.018), tot_loss_proj:3.118 [t=0.17s]
prediction: ['[CLS] sarah widened [SEP] foolish evil ] context terrorist see removed what political yard! in attack political called - colleagues [SEP]']
[ 100/2000] tot_loss=2.481 (perp=10.938, rec=0.278, cos=0.016), tot_loss_proj:3.075 [t=0.17s]
prediction: ['[CLS]mina takenthe foolish evil outside context terrorist! taken clothing political terrorists! terrorists evil political! that companions [SEP]']
[ 150/2000] tot_loss=2.125 (perp=9.648, rec=0.190, cos=0.006), tot_loss_proj:2.593 [t=0.17s]
prediction: ['[CLS] taken taken outside outside evil outside context terrorists! taken are political terrorists ( terrorists evil more : of parents [SEP]']
[ 200/2000] tot_loss=2.158 (perp=9.996, rec=0.155, cos=0.004), tot_loss_proj:2.598 [t=0.17s]
prediction: ['[CLS] taken taken outside outside evil climate context terrorists! taken : political terrorists ( terrorists evil more : than situation [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.139 (perp=9.936, rec=0.149, cos=0.004), tot_loss_proj:2.797 [t=0.17s]
prediction: ['[CLS] taken taken outside current evil climate context political! taken see political terrorists ( the evil more terrorists than situation [SEP]']
[ 300/2000] tot_loss=2.105 (perp=9.823, rec=0.137, cos=0.003), tot_loss_proj:2.817 [t=0.17s]
prediction: ['[CLS] taken taken outside current evil climate context political! taken see political terrorists ( the evil more terrorists than situations [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.859 (perp=8.610, rec=0.133, cos=0.003), tot_loss_proj:2.422 [t=0.17s]
prediction: ['[CLS] taken evil taken outside current climate context political! : see political terrorists ( the evil more terrorists than ) [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.791 (perp=7.686, rec=0.233, cos=0.021), tot_loss_proj:2.352 [t=0.17s]
prediction: ['[CLS] need evil taken outside current political climate context! : see : terrorists ( the evil are terrorists than ) [SEP]']
[ 450/2000] tot_loss=2.050 (perp=9.095, rec=0.220, cos=0.011), tot_loss_proj:2.722 [t=0.17s]
prediction: ['[CLS] need evil taken outside current political climate context! turf see dangerous obama ( the evil are terrorists ever ) [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.862 (perp=8.405, rec=0.176, cos=0.005), tot_loss_proj:2.624 [t=0.17s]
prediction: ['[CLS] need evil taken outside current political climate context! ( see dangerous obama turf the evil are terrorists ever ) [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.753 (perp=7.877, rec=0.171, cos=0.007), tot_loss_proj:2.285 [t=0.17s]
prediction: ['[CLS] : evil taken outside the current political climate context! ( see dangerous obama political evil are terrorists ever ) [SEP]']
[ 600/2000] tot_loss=1.913 (perp=8.796, rec=0.150, cos=0.005), tot_loss_proj:2.447 [t=0.17s]
prediction: ['[CLS]a evil taken outside the current political climate context! ( see dangerous obama political evil are terrorists ever ) [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.752 (perp=8.024, rec=0.143, cos=0.004), tot_loss_proj:2.221 [t=0.17s]
prediction: ['[CLS] endangered evil taken outside the current political climate context! ( see : obama political evil are terrorists ever ) [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.642 (perp=7.481, rec=0.141, cos=0.005), tot_loss_proj:2.173 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current endangered climate context! ( see : than political evil are terrorists ever ) [SEP]']
[ 750/2000] tot_loss=1.632 (perp=7.481, rec=0.133, cos=0.003), tot_loss_proj:2.172 [t=0.18s]
prediction: ['[CLS] political evil taken outside the current endangered climate context! ( see : than political evil are terrorists ever ) [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.598 (perp=7.308, rec=0.133, cos=0.003), tot_loss_proj:2.085 [t=0.20s]
prediction: ['[CLS] political evil taken outside the current ever climate context! ( see : than political evil are terrorists dangerous ) [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.525 (perp=6.932, rec=0.135, cos=0.004), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current ever climate context ( see : than political evil are terrorists dangerous! ) [SEP]']
[ 900/2000] tot_loss=1.515 (perp=6.932, rec=0.126, cos=0.003), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current ever climate context ( see : than political evil are terrorists dangerous! ) [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.502 (perp=6.835, rec=0.132, cos=0.003), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate ever context ( see : than political evil are terrorists dangerous! ) [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.481 (perp=6.742, rec=0.129, cos=0.003), tot_loss_proj:1.987 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate dangerous context ( see : than political evil are terrorists ever! ) [SEP]']
[1050/2000] tot_loss=1.470 (perp=6.742, rec=0.119, cos=0.003), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate dangerous context ( see : than political evil are terrorists ever! ) [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.431 (perp=6.514, rec=0.125, cos=0.003), tot_loss_proj:1.929 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate dangerous context ( see : than political evil are ever terrorists! ) [SEP]']
Attempt swap
[1150/2000] tot_loss=1.522 (perp=6.978, rec=0.124, cos=0.003), tot_loss_proj:2.031 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate more context ( see : than political evil are ever terrorists! ) [SEP]']
[1200/2000] tot_loss=1.520 (perp=6.978, rec=0.122, cos=0.003), tot_loss_proj:2.029 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate more context ( see : than political evil are ever terrorists! ) [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.392 (perp=6.345, rec=0.121, cos=0.003), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
Attempt swap
[1300/2000] tot_loss=1.395 (perp=6.345, rec=0.124, cos=0.002), tot_loss_proj:1.865 [t=0.20s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
[1350/2000] tot_loss=1.391 (perp=6.345, rec=0.120, cos=0.002), tot_loss_proj:1.861 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
Attempt swap
[1400/2000] tot_loss=1.387 (perp=6.345, rec=0.116, cos=0.002), tot_loss_proj:1.864 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
Attempt swap
[1450/2000] tot_loss=1.384 (perp=6.345, rec=0.113, cos=0.002), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
[1500/2000] tot_loss=1.386 (perp=6.345, rec=0.115, cos=0.002), tot_loss_proj:1.862 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
Attempt swap
[1550/2000] tot_loss=1.389 (perp=6.345, rec=0.118, cos=0.002), tot_loss_proj:1.856 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
Attempt swap
[1600/2000] tot_loss=1.381 (perp=6.345, rec=0.110, cos=0.002), tot_loss_proj:1.864 [t=0.19s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
[1650/2000] tot_loss=1.386 (perp=6.345, rec=0.115, cos=0.002), tot_loss_proj:1.860 [t=0.19s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
Attempt swap
[1700/2000] tot_loss=1.386 (perp=6.345, rec=0.115, cos=0.002), tot_loss_proj:1.866 [t=0.19s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
Attempt swap
[1750/2000] tot_loss=1.383 (perp=6.345, rec=0.112, cos=0.002), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
[1800/2000] tot_loss=1.387 (perp=6.345, rec=0.115, cos=0.002), tot_loss_proj:1.860 [t=0.19s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
Attempt swap
[1850/2000] tot_loss=1.394 (perp=6.345, rec=0.122, cos=0.002), tot_loss_proj:1.859 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
Attempt swap
[1900/2000] tot_loss=1.384 (perp=6.345, rec=0.112, cos=0.002), tot_loss_proj:1.865 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
[1950/2000] tot_loss=1.382 (perp=6.345, rec=0.110, cos=0.002), tot_loss_proj:1.866 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.375 (perp=6.273, rec=0.118, cos=0.002), tot_loss_proj:1.886 [t=0.17s]
prediction: ['[CLS] political evil taken outside the current climate ( context : see more than political evil are ever terrorists! ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] political evil taken outside the current climate : context ( see more than political evil are ever terrorists! ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 17.647 | p: 17.647 | r: 17.647
rougeL     | fm: 61.111 | p: 61.111 | r: 61.111
rougeLsum  | fm: 61.111 | p: 61.111 | r: 61.111
r1fm+r2fm = 106.536

[Aggregate metrics]:
rouge1     | fm: 92.210 | p: 91.850 | r: 92.640
rouge2     | fm: 56.076 | p: 55.882 | r: 56.295
rougeL     | fm: 78.907 | p: 78.643 | r: 79.284
rougeLsum  | fm: 78.817 | p: 78.548 | r: 79.129
r1fm+r2fm = 148.286

input #24 time: 0:06:59 | total time: 2:54:26


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9993176191193096
highest_index [0]
highest [0.9993176191193096]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 2.0016868114471436 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 1.8594616651535034 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 1.7197651863098145 for ['[CLS] merit delaney canoniary [SEP]']
[Init] best rec loss: 1.7120318412780762 for ['[CLS] executive into females he [SEP]']
[Init] best rec loss: 1.6727626323699951 for ['[CLS] james adding letters received [SEP]']
[Init] best rec loss: 1.6727566719055176 for ['[CLS] frequent gailez bane [SEP]']
[Init] best rec loss: 1.5321781635284424 for ['[CLS] mention acre old headline [SEP]']
[Init] best rec loss: 1.4170466661453247 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best rec loss: 1.3436115980148315 for ['[CLS] hide a seal mess [SEP]']
[Init] best perm rec loss: 1.3427221775054932 for ['[CLS] seal a mess hide [SEP]']
[Init] best perm rec loss: 1.3401399850845337 for ['[CLS] mess hide a seal [SEP]']
[Init] best perm rec loss: 1.3389146327972412 for ['[CLS] mess a hide seal [SEP]']
[Init] best perm rec loss: 1.3344050645828247 for ['[CLS] mess hide seal a [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.356 (perp=10.589, rec=0.232, cos=0.006), tot_loss_proj:2.484 [t=0.17s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 100/2000] tot_loss=2.269 (perp=10.589, rec=0.148, cos=0.003), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 150/2000] tot_loss=2.037 (perp=9.574, rec=0.120, cos=0.002), tot_loss_proj:2.600 [t=0.17s]
prediction: ['[CLS] strange film strange beautiful [SEP]']
[ 200/2000] tot_loss=2.028 (perp=9.574, rec=0.111, cos=0.002), tot_loss_proj:2.621 [t=0.17s]
prediction: ['[CLS] strange film strange beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.715 (perp=8.030, rec=0.106, cos=0.003), tot_loss_proj:2.050 [t=0.17s]
prediction: ['[CLS] strange beautiful strange film [SEP]']
[ 300/2000] tot_loss=1.706 (perp=8.030, rec=0.098, cos=0.002), tot_loss_proj:2.040 [t=0.17s]
prediction: ['[CLS] strange beautiful strange film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.715 (perp=8.030, rec=0.107, cos=0.002), tot_loss_proj:2.041 [t=0.17s]
prediction: ['[CLS] strange beautiful strange film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.708 (perp=8.030, rec=0.100, cos=0.002), tot_loss_proj:2.035 [t=0.17s]
prediction: ['[CLS] strange beautiful strange film [SEP]']
[ 450/2000] tot_loss=1.707 (perp=8.030, rec=0.099, cos=0.002), tot_loss_proj:2.041 [t=0.17s]
prediction: ['[CLS] strange beautiful strange film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.698 (perp=8.030, rec=0.090, cos=0.002), tot_loss_proj:2.043 [t=0.17s]
prediction: ['[CLS] strange beautiful strange film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.691 (perp=8.030, rec=0.084, cos=0.002), tot_loss_proj:2.045 [t=0.17s]
prediction: ['[CLS] strange beautiful strange film [SEP]']
[ 600/2000] tot_loss=1.912 (perp=9.201, rec=0.070, cos=0.001), tot_loss_proj:2.323 [t=0.17s]
prediction: ['[CLS] strange beautiful and film [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.434 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.399 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.433 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.396 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.431 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.396 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.436 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.437 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.390 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.396 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.431 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.402 (perp=6.646, rec=0.071, cos=0.001), tot_loss_proj:1.423 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.395 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.431 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.384 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.429 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.406 (perp=6.646, rec=0.076, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.428 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.418 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.395 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.425 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.399 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.431 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.419 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.400 (perp=6.646, rec=0.069, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.421 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.429 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.393 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.426 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.406 (perp=6.646, rec=0.075, cos=0.001), tot_loss_proj:1.417 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.383 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.432 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.387 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.428 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.427 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.422 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.388 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.435 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.469 | p: 92.055 | r: 92.982
rouge2     | fm: 57.482 | p: 57.373 | r: 57.724
rougeL     | fm: 79.730 | p: 79.505 | r: 80.046
rougeLsum  | fm: 79.572 | p: 79.303 | r: 79.977
r1fm+r2fm = 149.951

input #25 time: 0:06:45 | total time: 3:01:11


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9992061826546763
highest_index [0]
highest [0.9992061826546763]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 1.9023979902267456 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 1.8645083904266357 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 1.7954801321029663 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 1.7904412746429443 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 1.65139901638031 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 1.6358462572097778 for ['[CLS]sed benedict later housing why surroundingpinegrave nat use amount cast thy scored pattern run unknown authority travellingflict quotes guest lucan [SEP]']
[Init] best rec loss: 1.62001371383667 for ['[CLS] inter disappointed fiveiel 3 the airline whisperingar kelsey score chi kept dvduting cubs really casedrop4 commons due hayes [SEP]']
[Init] best rec loss: 1.5167450904846191 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 1.514949917793274 for ['[CLS] stakekar passing rides 65 turns speak mutant montrose capacity rid fur unite button riceª ak occupied cher following fully igo [SEP]']
[Init] best rec loss: 1.5008208751678467 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 1.4985138177871704 for ['[CLS] door colonial shot isotead discipline merelyᆼkan list more arrow four souls polish death fourth theoretical usually constituencies octave s officers [SEP]']
[Init] best perm rec loss: 1.4953454732894897 for ['[CLS] theoretical list polishᆼ officers colonial s disciplinetead octave usually merely four souls arrowkan death constituencies shot iso more fourth door [SEP]']
[Init] best perm rec loss: 1.4886966943740845 for ['[CLS] colonial s four soulskan octavetead death moreᆼ list polish shot door arrow officers usually theoretical fourth discipline constituencies iso merely [SEP]']
[Init] best perm rec loss: 1.485183835029602 for ['[CLS] shot polish constituencies theoretical arrow merelyᆼ usually souls officerskan octave list door colonial fourth iso s death discipline four moretead [SEP]']
[Init] best perm rec loss: 1.4836591482162476 for ['[CLS] polish list merely fourkan octaveᆼ souls usually constituencies iso officers arrow s discipline shot colonial moretead death fourth door theoretical [SEP]']
[Init] best perm rec loss: 1.4816036224365234 for ['[CLS] s merely colonial doorkan fourth polish souls four officers death usually arrow shot moretead list octave iso constituencies discipline theoreticalᆼ [SEP]']
[Init] best perm rec loss: 1.47699773311615 for ['[CLS] fourᆼ polishtead shot usually octave discipline souls s death door merely officers list arrow more fourth iso constituencieskan colonial theoretical [SEP]']
[Init] best perm rec loss: 1.4744471311569214 for ['[CLS] iso death arrow s list polish usually four door more merelykan discipline colonial octave constituenciestead shot fourth officersᆼ souls theoretical [SEP]']
[Init] best perm rec loss: 1.4727554321289062 for ['[CLS] list shotᆼ death door iso constituencies fourth s officers four merely octave moreteadkan colonial arrow usually discipline polish souls theoretical [SEP]']
[Init] best perm rec loss: 1.4687553644180298 for ['[CLS] discipline constituencies shotkan merely arrowᆼ four polishtead iso s list officers death usually door octave fourth more souls colonial theoretical [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.566 (perp=11.511, rec=0.253, cos=0.011), tot_loss_proj:2.966 [t=0.17s]
prediction: ['[CLS] pointless dead importial ) import claire pointless passenger from of pointless foreign mrna writer 1980s - increase 8th from network time pointless [SEP]']
[ 100/2000] tot_loss=2.420 (perp=11.195, rec=0.176, cos=0.004), tot_loss_proj:2.921 [t=0.17s]
prediction: ['[CLS] pointless french importder ) french sophie pointless import from - pointless age coming director duration -ic french from coming and pointless [SEP]']
[ 150/2000] tot_loss=2.205 (perp=10.281, rec=0.145, cos=0.003), tot_loss_proj:2.928 [t=0.19s]
prediction: ['[CLS] mean french importder ) french anne pointless import from - french age coming director expanding - - french from coming and pointless [SEP]']
[ 200/2000] tot_loss=2.168 (perp=10.265, rec=0.112, cos=0.003), tot_loss_proj:2.648 [t=0.17s]
prediction: ['[CLS] mean french meander ) french anne pointless import from of french age coming directorder - this french - coming and pointless [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.150 (perp=9.958, rec=0.154, cos=0.004), tot_loss_proj:2.521 [t=0.17s]
prediction: ['[CLS] meaneer meander ) french from pointless import sophie of - age coming directorder - this french - coming and pointless [SEP]']
[ 300/2000] tot_loss=1.956 (perp=9.291, rec=0.096, cos=0.002), tot_loss_proj:2.379 [t=0.17s]
prediction: ['[CLS] mean - meander ) french from pointless import sophie of - age coming directoring - this french - - and pointless [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.994 (perp=9.524, rec=0.088, cos=0.002), tot_loss_proj:2.453 [t=0.17s]
prediction: ['[CLS] mean anne meander ) french from pointless import - of - age coming directoring - this french - bi and pointless [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.969 (perp=9.310, rec=0.104, cos=0.003), tot_loss_proj:2.387 [t=0.17s]
prediction: ['[CLS] mean anne meander ) french from pointless import - of - ageing coming director - this french - bi and pointless [SEP]']
[ 450/2000] tot_loss=1.949 (perp=9.310, rec=0.085, cos=0.002), tot_loss_proj:2.389 [t=0.18s]
prediction: ['[CLS] mean anne meander ) french from pointless import - of - ageing coming director - this french - bi and pointless [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.886 (perp=9.001, rec=0.083, cos=0.002), tot_loss_proj:2.345 [t=0.17s]
prediction: ['[CLS] mean anne meander ) french from pointless import - of - ageing coming director - this french pointless bi and - [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.893 (perp=9.029, rec=0.085, cos=0.002), tot_loss_proj:2.348 [t=0.17s]
prediction: ['[CLS] mean anne meander ) french - - import - of from ageing coming director - this french pointless bi and - [SEP]']
[ 600/2000] tot_loss=1.885 (perp=9.029, rec=0.077, cos=0.002), tot_loss_proj:2.351 [t=0.17s]
prediction: ['[CLS] mean anne meander ) french - - import - of from ageing coming director - this french pointless bi and - [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.905 (perp=9.093, rec=0.085, cos=0.002), tot_loss_proj:2.371 [t=0.19s]
prediction: ['[CLS] mean anne meander ) french - - import coming of from ageing - director - thisrot pointless bi and - [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.840 (perp=8.775, rec=0.083, cos=0.002), tot_loss_proj:2.292 [t=0.17s]
prediction: ['[CLS] mean anne meander ) french - - import coming of from ageing - director - this birot pointless and - [SEP]']
[ 750/2000] tot_loss=1.835 (perp=8.775, rec=0.078, cos=0.002), tot_loss_proj:2.295 [t=0.17s]
prediction: ['[CLS] mean anne meander ) french - - import coming of from ageing - director - this birot pointless and - [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.791 (perp=8.559, rec=0.077, cos=0.002), tot_loss_proj:2.271 [t=0.17s]
prediction: ['[CLS] mean anne meander ) french - - import of coming from ageing - director - this birot pointless and - [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.756 (perp=8.405, rec=0.073, cos=0.002), tot_loss_proj:2.217 [t=0.17s]
prediction: ['[CLS] mean anne meander - french ) - import of coming from ageing - director - this birot pointless and - [SEP]']
[ 900/2000] tot_loss=1.761 (perp=8.405, rec=0.078, cos=0.002), tot_loss_proj:2.223 [t=0.17s]
prediction: ['[CLS] mean anne meander - french ) - import of coming from ageing - director - this birot pointless and - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.759 (perp=8.405, rec=0.076, cos=0.002), tot_loss_proj:2.220 [t=0.17s]
prediction: ['[CLS] mean anne meander - french ) - import of coming from ageing - director - this birot pointless and - [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.701 (perp=8.088, rec=0.081, cos=0.002), tot_loss_proj:2.202 [t=0.17s]
prediction: ['[CLS] mean this meander - french ) - import of coming from ageing - director - anne birot pointless and - [SEP]']
[1050/2000] tot_loss=1.692 (perp=8.092, rec=0.071, cos=0.002), tot_loss_proj:2.270 [t=0.17s]
prediction: ['[CLS] head this meander - french ) - import of coming from ageing - director - anne birot pointless and - [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.733 (perp=8.290, rec=0.073, cos=0.002), tot_loss_proj:2.199 [t=0.17s]
prediction: ['[CLS] this meander mean - french ) - import of coming from ageing - director - anne birot pointless and - [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.598 (perp=7.627, rec=0.071, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
[1200/2000] tot_loss=1.603 (perp=7.627, rec=0.076, cos=0.002), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.592 (perp=7.627, rec=0.064, cos=0.002), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.602 (perp=7.627, rec=0.075, cos=0.002), tot_loss_proj:2.096 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
[1350/2000] tot_loss=1.607 (perp=7.627, rec=0.080, cos=0.002), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.598 (perp=7.627, rec=0.071, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.599 (perp=7.627, rec=0.072, cos=0.002), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
[1500/2000] tot_loss=1.603 (perp=7.627, rec=0.076, cos=0.002), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.599 (perp=7.627, rec=0.072, cos=0.002), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.598 (perp=7.627, rec=0.071, cos=0.002), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
[1650/2000] tot_loss=1.604 (perp=7.627, rec=0.077, cos=0.002), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.590 (perp=7.627, rec=0.062, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - import of coming from age head - director - anne birot pointless and - [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.577 (perp=7.475, rec=0.080, cos=0.002), tot_loss_proj:2.096 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - head of coming from age import - director - anne birot pointless and - [SEP]']
[1800/2000] tot_loss=1.571 (perp=7.475, rec=0.074, cos=0.002), tot_loss_proj:2.095 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - head of coming from age import - director - anne birot pointless and - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.568 (perp=7.475, rec=0.071, cos=0.002), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - head of coming from age import - director - anne birot pointless and - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.569 (perp=7.475, rec=0.072, cos=0.002), tot_loss_proj:2.095 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - head of coming from age import - director - anne birot pointless and - [SEP]']
[1950/2000] tot_loss=1.563 (perp=7.475, rec=0.066, cos=0.002), tot_loss_proj:2.098 [t=0.18s]
prediction: ['[CLS] this meandering - french ) - head of coming from age import - director - anne birot pointless and - [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.571 (perp=7.424, rec=0.084, cos=0.002), tot_loss_proj:2.152 [t=0.17s]
prediction: ['[CLS] this meandering - french ) - - of coming from age import head director - anne birot pointless and - [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] this meandering - french ) - head of coming from age import - director - anne birot pointless and - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 93.750 | r: 88.235
rouge2     | fm: 25.806 | p: 26.667 | r: 25.000
rougeL     | fm: 66.667 | p: 68.750 | r: 64.706
rougeLsum  | fm: 66.667 | p: 68.750 | r: 64.706
r1fm+r2fm = 116.716

[Aggregate metrics]:
rouge1     | fm: 92.378 | p: 92.160 | r: 92.694
rouge2     | fm: 56.069 | p: 55.957 | r: 56.192
rougeL     | fm: 79.229 | p: 79.081 | r: 79.456
rougeLsum  | fm: 79.081 | p: 78.816 | r: 79.332
r1fm+r2fm = 148.448

input #26 time: 0:06:58 | total time: 3:08:10


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.999345236003067
highest_index [0]
highest [0.999345236003067]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 1.9401098489761353 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 1.9116452932357788 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 1.8886722326278687 for ['[CLS] estate kiss ale [SEP]']
[Init] best rec loss: 1.8630187511444092 for ['[CLS] heel clinical birth [SEP]']
[Init] best rec loss: 1.6387312412261963 for ['[CLS] and universal universe [SEP]']
[Init] best rec loss: 1.5562210083007812 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 1.4637377262115479 for ['[CLS] part portion mid [SEP]']
[Init] best rec loss: 1.3929609060287476 for ['[CLS] fat mattream [SEP]']
[Init] best rec loss: 1.2099963426589966 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 1.209096074104309 for ['[CLS] transitwine given [SEP]']
[Init] best perm rec loss: 1.2082395553588867 for ['[CLS] transit givenwine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.442 (perp=11.066, rec=0.723, cos=0.506), tot_loss_proj:3.809 [t=0.17s]
prediction: ['[CLS] iconic including generic [SEP]']
[ 100/2000] tot_loss=3.474 (perp=11.753, rec=0.631, cos=0.492), tot_loss_proj:2.822 [t=0.17s]
prediction: ['[CLS] generic looked generic [SEP]']
[ 150/2000] tot_loss=3.296 (perp=10.986, rec=0.583, cos=0.516), tot_loss_proj:2.551 [t=0.17s]
prediction: ['[CLS] generic so generic [SEP]']
[ 200/2000] tot_loss=3.395 (perp=10.986, rec=0.648, cos=0.549), tot_loss_proj:2.561 [t=0.17s]
prediction: ['[CLS] generic so generic [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.093 (perp=9.693, rec=0.602, cos=0.552), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 300/2000] tot_loss=3.002 (perp=9.693, rec=0.543, cos=0.521), tot_loss_proj:2.527 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.111 (perp=9.693, rec=0.656, cos=0.516), tot_loss_proj:2.530 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.086 (perp=9.693, rec=0.593, cos=0.555), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 450/2000] tot_loss=3.087 (perp=9.693, rec=0.567, cos=0.581), tot_loss_proj:2.520 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.010 (perp=9.693, rec=0.537, cos=0.535), tot_loss_proj:2.522 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.030 (perp=9.693, rec=0.538, cos=0.554), tot_loss_proj:2.530 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 600/2000] tot_loss=2.985 (perp=9.693, rec=0.532, cos=0.515), tot_loss_proj:2.533 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.111 (perp=9.693, rec=0.538, cos=0.634), tot_loss_proj:2.527 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.000 (perp=9.693, rec=0.509, cos=0.552), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 750/2000] tot_loss=3.039 (perp=9.693, rec=0.518, cos=0.582), tot_loss_proj:2.521 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.987 (perp=9.693, rec=0.505, cos=0.543), tot_loss_proj:2.520 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.040 (perp=9.693, rec=0.503, cos=0.598), tot_loss_proj:2.521 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[ 900/2000] tot_loss=2.973 (perp=9.693, rec=0.495, cos=0.539), tot_loss_proj:2.526 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.932 (perp=9.693, rec=0.493, cos=0.500), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1000/2000] tot_loss=2.959 (perp=9.693, rec=0.493, cos=0.528), tot_loss_proj:2.526 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[1050/2000] tot_loss=2.991 (perp=9.693, rec=0.490, cos=0.563), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1100/2000] tot_loss=2.935 (perp=9.693, rec=0.480, cos=0.516), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1150/2000] tot_loss=2.932 (perp=9.693, rec=0.480, cos=0.514), tot_loss_proj:2.532 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[1200/2000] tot_loss=2.942 (perp=9.693, rec=0.480, cos=0.523), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1250/2000] tot_loss=2.926 (perp=9.693, rec=0.479, cos=0.509), tot_loss_proj:2.530 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1300/2000] tot_loss=2.935 (perp=9.693, rec=0.477, cos=0.519), tot_loss_proj:2.524 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[1350/2000] tot_loss=2.918 (perp=9.693, rec=0.475, cos=0.505), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1400/2000] tot_loss=2.941 (perp=9.693, rec=0.476, cos=0.526), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1450/2000] tot_loss=2.934 (perp=9.693, rec=0.475, cos=0.521), tot_loss_proj:2.529 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[1500/2000] tot_loss=2.920 (perp=9.693, rec=0.468, cos=0.514), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1550/2000] tot_loss=2.929 (perp=9.693, rec=0.473, cos=0.518), tot_loss_proj:2.525 [t=0.18s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1600/2000] tot_loss=2.935 (perp=9.693, rec=0.473, cos=0.524), tot_loss_proj:2.531 [t=0.18s]
prediction: ['[CLS] generic generic generic [SEP]']
[1650/2000] tot_loss=2.933 (perp=9.693, rec=0.472, cos=0.523), tot_loss_proj:2.520 [t=0.20s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1700/2000] tot_loss=2.928 (perp=9.693, rec=0.466, cos=0.523), tot_loss_proj:2.527 [t=0.18s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.933 (perp=9.693, rec=0.471, cos=0.524), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[1800/2000] tot_loss=2.928 (perp=9.693, rec=0.464, cos=0.525), tot_loss_proj:2.533 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1850/2000] tot_loss=2.928 (perp=9.693, rec=0.468, cos=0.521), tot_loss_proj:2.527 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[1900/2000] tot_loss=2.932 (perp=9.693, rec=0.469, cos=0.525), tot_loss_proj:2.526 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
[1950/2000] tot_loss=2.929 (perp=9.693, rec=0.468, cos=0.522), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.936 (perp=9.693, rec=0.472, cos=0.525), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] generic generic generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] generic generic generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 85.000

[Aggregate metrics]:
rouge1     | fm: 91.326 | p: 90.988 | r: 91.603
rouge2     | fm: 54.873 | p: 54.647 | r: 55.041
rougeL     | fm: 78.695 | p: 78.557 | r: 78.925
rougeLsum  | fm: 78.393 | p: 78.220 | r: 78.609
r1fm+r2fm = 146.199

input #27 time: 0:06:52 | total time: 3:15:03


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.9993345319062628
highest_index [0]
highest [0.9993345319062628]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 1.6155987977981567 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 1.5106481313705444 for ['[CLS] boundaries towards lands delivery [SEP]']
[Init] best rec loss: 1.505471110343933 for ['[CLS] immortal coma thierry imperial [SEP]']
[Init] best rec loss: 1.4851624965667725 for ['[CLS] perhaps childrenogical beta [SEP]']
[Init] best rec loss: 1.4608865976333618 for ['[CLS] bro asher lit majority [SEP]']
[Init] best rec loss: 1.460343837738037 for ['[CLS] site georgia chambers nicholas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.340 (perp=10.061, rec=0.288, cos=0.039), tot_loss_proj:3.243 [t=0.18s]
prediction: ['[CLS] forces quarter minutes minutes [SEP]']
[ 100/2000] tot_loss=2.148 (perp=10.061, rec=0.129, cos=0.007), tot_loss_proj:2.847 [t=0.18s]
prediction: ['[CLS] 71 only minutes for [SEP]']
[ 150/2000] tot_loss=2.094 (perp=10.061, rec=0.080, cos=0.002), tot_loss_proj:2.865 [t=0.18s]
prediction: ['[CLS] 71 only minutes for [SEP]']
[ 200/2000] tot_loss=2.085 (perp=10.061, rec=0.072, cos=0.001), tot_loss_proj:2.867 [t=0.18s]
prediction: ['[CLS] 71 only minutes for [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.708 (perp=8.187, rec=0.069, cos=0.002), tot_loss_proj:2.415 [t=0.18s]
prediction: ['[CLS] only 71 minutes for [SEP]']
[ 300/2000] tot_loss=1.696 (perp=8.187, rec=0.058, cos=0.001), tot_loss_proj:2.409 [t=0.18s]
prediction: ['[CLS] only 71 minutes for [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.570 (perp=7.445, rec=0.079, cos=0.001), tot_loss_proj:1.855 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.558 (perp=7.445, rec=0.068, cos=0.001), tot_loss_proj:1.856 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=1.551 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.848 [t=0.20s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.563 (perp=7.445, rec=0.073, cos=0.001), tot_loss_proj:1.846 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.548 (perp=7.445, rec=0.058, cos=0.001), tot_loss_proj:1.850 [t=0.21s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=1.554 (perp=7.445, rec=0.064, cos=0.001), tot_loss_proj:1.852 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.542 (perp=7.445, rec=0.052, cos=0.001), tot_loss_proj:1.850 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.547 (perp=7.445, rec=0.056, cos=0.001), tot_loss_proj:1.852 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=1.557 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.851 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.557 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.555 (perp=7.445, rec=0.064, cos=0.001), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=1.561 (perp=7.445, rec=0.071, cos=0.001), tot_loss_proj:1.851 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.844 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=1.552 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.851 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=1.556 (perp=7.445, rec=0.065, cos=0.001), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=1.551 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.843 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=1.552 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.853 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=1.562 (perp=7.445, rec=0.072, cos=0.001), tot_loss_proj:1.846 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=1.544 (perp=7.445, rec=0.054, cos=0.001), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=1.552 (perp=7.445, rec=0.061, cos=0.001), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=1.557 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=1.554 (perp=7.445, rec=0.063, cos=0.001), tot_loss_proj:1.839 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=1.547 (perp=7.445, rec=0.057, cos=0.001), tot_loss_proj:1.846 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=1.560 (perp=7.445, rec=0.069, cos=0.001), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=1.556 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=1.555 (perp=7.445, rec=0.064, cos=0.001), tot_loss_proj:1.845 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=1.548 (perp=7.445, rec=0.058, cos=0.001), tot_loss_proj:1.856 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=1.549 (perp=7.445, rec=0.059, cos=0.001), tot_loss_proj:1.853 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=1.554 (perp=7.445, rec=0.064, cos=0.001), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=1.557 (perp=7.445, rec=0.067, cos=0.001), tot_loss_proj:1.840 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=1.557 (perp=7.445, rec=0.066, cos=0.001), tot_loss_proj:1.852 [t=0.17s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 91.530 | p: 91.239 | r: 91.872
rouge2     | fm: 54.048 | p: 53.991 | r: 54.161
rougeL     | fm: 78.776 | p: 78.572 | r: 78.944
rougeLsum  | fm: 78.623 | p: 78.440 | r: 78.839
r1fm+r2fm = 145.578

input #28 time: 0:06:58 | total time: 3:22:01


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9992943703711437
highest_index [0]
highest [0.9992943703711437]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 1.9422098398208618 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 1.725492238998413 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 1.665594458580017 for ['[CLS] label which £ anyway shoes mediamont campbell her cullen [SEP]']
[Init] best rec loss: 1.6626322269439697 for ['[CLS] retrieved kicking quite misunderstanding race camp streaked shot larger fields [SEP]']
[Init] best rec loss: 1.544628381729126 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 1.4950032234191895 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 1.4667460918426514 for ['[CLS] hectares overshadowed° angeles me festival panels dean eventually towards [SEP]']
[Init] best rec loss: 1.451490879058838 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 1.3281519412994385 for ['[CLS] consuming after intern coach acres surf class speed tongues period [SEP]']
[Init] best rec loss: 1.2676228284835815 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best rec loss: 1.2215781211853027 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 1.2187750339508057 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 1.2168614864349365 for ['[CLS] tv oil envelope administration taste this engagementuted runs landed [SEP]']
[Init] best perm rec loss: 1.2131327390670776 for ['[CLS] taste landed administration this runs tv engagementuted oil envelope [SEP]']
[Init] best perm rec loss: 1.2063658237457275 for ['[CLS] oil this taste landed tv runs envelope engagement administrationuted [SEP]']
[Init] best perm rec loss: 1.2030150890350342 for ['[CLS] tv oil engagement landeduted this taste envelope runs administration [SEP]']
[Init] best perm rec loss: 1.200951337814331 for ['[CLS] taste runs landeduted engagement envelope this oil tv administration [SEP]']
[Init] best perm rec loss: 1.2006797790527344 for ['[CLS] landeduted taste engagement runs tv envelope this oil administration [SEP]']
[Init] best perm rec loss: 1.2004748582839966 for ['[CLS] this oil landed engagement tv envelopeuted taste runs administration [SEP]']
[Init] best perm rec loss: 1.1998974084854126 for ['[CLS]uted taste tv engagement oil runs envelope landed this administration [SEP]']
[Init] best perm rec loss: 1.197476863861084 for ['[CLS] taste runsuted tv landed engagement oil envelope this administration [SEP]']
[Init] best perm rec loss: 1.1972182989120483 for ['[CLS] taste oiluted engagement landed tv envelope administration this runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.679 (perp=11.489, rec=0.346, cos=0.036), tot_loss_proj:3.352 [t=0.17s]
prediction: ['[CLS]. previously certification certified crisis video was destroy gross not [SEP]']
[ 100/2000] tot_loss=2.081 (perp=9.037, rec=0.253, cos=0.021), tot_loss_proj:3.009 [t=0.17s]
prediction: ['[CLS]. also believe resident cannot resident also are almost not [SEP]']
[ 150/2000] tot_loss=1.804 (perp=7.788, rec=0.226, cos=0.020), tot_loss_proj:2.544 [t=0.17s]
prediction: ['[CLS]. also believe resident evil resident also is it not [SEP]']
[ 200/2000] tot_loss=1.717 (perp=7.788, rec=0.150, cos=0.009), tot_loss_proj:2.558 [t=0.17s]
prediction: ['[CLS]. also believe resident evil resident also is it not [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.666 (perp=7.556, rec=0.144, cos=0.012), tot_loss_proj:2.635 [t=0.17s]
prediction: ['[CLS] resident. also believe resident evil was is it not [SEP]']
[ 300/2000] tot_loss=1.618 (perp=7.385, rec=0.132, cos=0.009), tot_loss_proj:2.810 [t=0.17s]
prediction: ['[CLS] resident i also believe that evil was is it not [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.386 (perp=6.173, rec=0.142, cos=0.010), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil was is it not [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.195 (perp=5.331, rec=0.120, cos=0.009), tot_loss_proj:2.683 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
[ 450/2000] tot_loss=1.193 (perp=5.331, rec=0.119, cos=0.008), tot_loss_proj:2.681 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.167 (perp=5.331, rec=0.094, cos=0.006), tot_loss_proj:2.690 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.153 (perp=5.331, rec=0.082, cos=0.004), tot_loss_proj:2.693 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
[ 600/2000] tot_loss=1.165 (perp=5.331, rec=0.095, cos=0.004), tot_loss_proj:2.684 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.163 (perp=5.331, rec=0.093, cos=0.003), tot_loss_proj:2.685 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.156 (perp=5.331, rec=0.086, cos=0.003), tot_loss_proj:2.690 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
[ 750/2000] tot_loss=1.150 (perp=5.331, rec=0.080, cos=0.003), tot_loss_proj:2.684 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.151 (perp=5.331, rec=0.081, cos=0.003), tot_loss_proj:2.689 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.144 (perp=5.331, rec=0.074, cos=0.003), tot_loss_proj:2.679 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
[ 900/2000] tot_loss=1.153 (perp=5.331, rec=0.083, cos=0.003), tot_loss_proj:2.687 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.151 (perp=5.331, rec=0.082, cos=0.003), tot_loss_proj:2.688 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1000/2000] tot_loss=1.157 (perp=5.331, rec=0.087, cos=0.003), tot_loss_proj:2.683 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
[1050/2000] tot_loss=1.139 (perp=5.331, rec=0.070, cos=0.003), tot_loss_proj:2.685 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1100/2000] tot_loss=1.155 (perp=5.331, rec=0.086, cos=0.003), tot_loss_proj:2.685 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1150/2000] tot_loss=1.143 (perp=5.331, rec=0.073, cos=0.003), tot_loss_proj:2.684 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
[1200/2000] tot_loss=1.146 (perp=5.331, rec=0.077, cos=0.003), tot_loss_proj:2.679 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1250/2000] tot_loss=1.141 (perp=5.331, rec=0.071, cos=0.003), tot_loss_proj:2.686 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
[1300/2000] tot_loss=1.155 (perp=5.331, rec=0.086, cos=0.003), tot_loss_proj:2.678 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
[1350/2000] tot_loss=1.157 (perp=5.331, rec=0.088, cos=0.003), tot_loss_proj:2.688 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.065 (perp=4.884, rec=0.085, cos=0.004), tot_loss_proj:2.245 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1450/2000] tot_loss=1.056 (perp=4.884, rec=0.076, cos=0.003), tot_loss_proj:2.241 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1500/2000] tot_loss=1.064 (perp=4.884, rec=0.084, cos=0.003), tot_loss_proj:2.254 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1550/2000] tot_loss=1.068 (perp=4.884, rec=0.088, cos=0.003), tot_loss_proj:2.244 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1600/2000] tot_loss=1.053 (perp=4.884, rec=0.073, cos=0.003), tot_loss_proj:2.241 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1650/2000] tot_loss=1.061 (perp=4.884, rec=0.081, cos=0.003), tot_loss_proj:2.241 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1700/2000] tot_loss=1.057 (perp=4.884, rec=0.077, cos=0.003), tot_loss_proj:2.233 [t=0.20s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1750/2000] tot_loss=1.051 (perp=4.884, rec=0.071, cos=0.003), tot_loss_proj:2.242 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1800/2000] tot_loss=1.060 (perp=4.884, rec=0.079, cos=0.003), tot_loss_proj:2.235 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1850/2000] tot_loss=1.043 (perp=4.884, rec=0.063, cos=0.003), tot_loss_proj:2.234 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1900/2000] tot_loss=1.049 (perp=4.884, rec=0.069, cos=0.003), tot_loss_proj:2.235 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1950/2000] tot_loss=1.057 (perp=4.884, rec=0.077, cos=0.003), tot_loss_proj:2.242 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[2000/2000] tot_loss=1.056 (perp=4.884, rec=0.076, cos=0.003), tot_loss_proj:2.240 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil. it is not [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 91.786 | p: 91.503 | r: 92.086
rouge2     | fm: 55.053 | p: 54.971 | r: 55.180
rougeL     | fm: 79.190 | p: 78.994 | r: 79.377
rougeLsum  | fm: 79.166 | p: 78.987 | r: 79.360
r1fm+r2fm = 146.838

input #29 time: 0:06:47 | total time: 3:28:49


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.999272099459075
highest_index [0]
highest [0.999272099459075]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 1.8995320796966553 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 1.870033860206604 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 1.8638838529586792 for ['[CLS] superior vary lynne [SEP]']
[Init] best rec loss: 1.4753696918487549 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 1.3648078441619873 for ['[CLS] shell albeittai [SEP]']
[Init] best rec loss: 1.221232533454895 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 1.1736953258514404 for ['[CLS] acceleration council lizard [SEP]']
[Init] best rec loss: 1.155712604522705 for ['[CLS] spent who mom [SEP]']
[Init] best perm rec loss: 1.1542490720748901 for ['[CLS] spent mom who [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.192 (perp=9.612, rec=0.259, cos=0.010), tot_loss_proj:3.100 [t=0.17s]
prediction: ['[CLS] louzionebility [SEP]']
[ 100/2000] tot_loss=2.046 (perp=9.540, rec=0.134, cos=0.004), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=2.008 (perp=9.540, rec=0.096, cos=0.004), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=2.000 (perp=9.540, rec=0.087, cos=0.005), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.968 (perp=9.540, rec=0.058, cos=0.002), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.975 (perp=9.540, rec=0.065, cos=0.002), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.971 (perp=9.540, rec=0.061, cos=0.002), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.961 (perp=9.540, rec=0.051, cos=0.002), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.993 (perp=9.540, rec=0.084, cos=0.001), tot_loss_proj:1.984 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.965 (perp=9.540, rec=0.055, cos=0.002), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.970 (perp=9.540, rec=0.060, cos=0.001), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.966 (perp=9.540, rec=0.057, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.984 (perp=9.540, rec=0.074, cos=0.001), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.964 (perp=9.540, rec=0.054, cos=0.001), tot_loss_proj:1.970 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.968 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.972 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.955 (perp=9.540, rec=0.046, cos=0.001), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.973 (perp=9.540, rec=0.064, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.972 (perp=9.540, rec=0.062, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.967 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.960 (perp=9.540, rec=0.050, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.975 (perp=9.540, rec=0.066, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.965 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.967 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.959 (perp=9.540, rec=0.049, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.972 (perp=9.540, rec=0.063, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.977 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.956 (perp=9.540, rec=0.047, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.974 (perp=9.540, rec=0.065, cos=0.001), tot_loss_proj:1.988 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.966 (perp=9.540, rec=0.057, cos=0.001), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.966 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.973 (perp=9.540, rec=0.064, cos=0.001), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.978 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.984 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.993 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.963 (perp=9.540, rec=0.054, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.961 (perp=9.540, rec=0.052, cos=0.001), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.966 (perp=9.540, rec=0.057, cos=0.001), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.958 (perp=9.540, rec=0.048, cos=0.001), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.968 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.973 | p: 91.770 | r: 92.308
rouge2     | fm: 56.380 | p: 56.220 | r: 56.555
rougeL     | fm: 79.727 | p: 79.541 | r: 79.887
rougeLsum  | fm: 79.800 | p: 79.589 | r: 79.995
r1fm+r2fm = 148.353

input #30 time: 0:06:43 | total time: 3:35:33


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.999339325216174
highest_index [0]
highest [0.999339325216174]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 1.914638876914978 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 1.7327791452407837 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 1.6876567602157593 for ['[CLS] che episode band [SEP]']
[Init] best rec loss: 1.3702372312545776 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 1.3683922290802002 for ['[CLS] robin artwork running [SEP]']
[Init] best perm rec loss: 1.3629165887832642 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.229 (perp=9.634, rec=0.272, cos=0.030), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] better faster vehicle [SEP]']
[ 100/2000] tot_loss=2.116 (perp=9.658, rec=0.165, cos=0.019), tot_loss_proj:2.404 [t=0.18s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=2.092 (perp=9.658, rec=0.145, cos=0.015), tot_loss_proj:2.401 [t=0.17s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 200/2000] tot_loss=1.847 (perp=8.742, rec=0.094, cos=0.004), tot_loss_proj:3.253 [t=0.17s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.599 (perp=7.603, rec=0.076, cos=0.002), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.604 (perp=7.603, rec=0.082, cos=0.002), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.601 (perp=7.603, rec=0.078, cos=0.002), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.002), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.598 (perp=7.603, rec=0.076, cos=0.002), tot_loss_proj:1.687 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.595 (perp=7.603, rec=0.073, cos=0.001), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.599 (perp=7.603, rec=0.077, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.593 (perp=7.603, rec=0.071, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.597 (perp=7.603, rec=0.075, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.593 (perp=7.603, rec=0.071, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.592 (perp=7.603, rec=0.070, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.595 (perp=7.603, rec=0.073, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.608 (perp=7.603, rec=0.087, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.593 (perp=7.603, rec=0.071, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.600 (perp=7.603, rec=0.078, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.583 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.576 (perp=7.603, rec=0.054, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.305 | p: 92.123 | r: 92.635
rouge2     | fm: 58.064 | p: 57.964 | r: 58.202
rougeL     | fm: 80.410 | p: 80.213 | r: 80.606
rougeLsum  | fm: 80.390 | p: 80.226 | r: 80.571
r1fm+r2fm = 150.369

input #31 time: 0:06:44 | total time: 3:42:17


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9992521630934186
highest_index [0]
highest [0.9992521630934186]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 2.020369052886963 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 1.688668131828308 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 1.6886156797409058 for ['[CLS] particular usual lana rid part awaitfication felt worked bolt algorithm tristan [SEP]']
[Init] best rec loss: 1.6725391149520874 for ['[CLS] carl formulacl overall network would ± < meyricktia archangel level [SEP]']
[Init] best rec loss: 1.655273675918579 for ['[CLS] unharmed spit health should llc relative front die threat skateer demolished [SEP]']
[Init] best perm rec loss: 1.6545727252960205 for ['[CLS] demolished spit health should die llc relative skate unharmed threater front [SEP]']
[Init] best perm rec loss: 1.6517530679702759 for ['[CLS] spit should relative threat demolished skate unharmed fronter llc die health [SEP]']
[Init] best perm rec loss: 1.6510119438171387 for ['[CLS] demolished unharmed should health spit relative llc die front threater skate [SEP]']
[Init] best perm rec loss: 1.6505436897277832 for ['[CLS] skateer health unharmed front die demolished should relative threat spit llc [SEP]']
[Init] best perm rec loss: 1.6478852033615112 for ['[CLS] unharmed demolished spit llcer skate die health should threat relative front [SEP]']
[Init] best perm rec loss: 1.646742582321167 for ['[CLS]er llc relative health die demolished threat unharmed spit should skate front [SEP]']
[Init] best perm rec loss: 1.6462005376815796 for ['[CLS] dieer health should llc skate threat spit unharmed demolished relative front [SEP]']
[Init] best perm rec loss: 1.6457756757736206 for ['[CLS] front llc skate should demolished healther threat spit unharmed die relative [SEP]']
[Init] best perm rec loss: 1.6436963081359863 for ['[CLS] unharmed die llc skate demolished healther front should relative threat spit [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.585 (perp=12.351, rec=0.655, cos=0.460), tot_loss_proj:4.387 [t=0.17s]
prediction: ['[CLS] douglas beside short really untilce tatum transactions amber differently with ram [SEP]']
[ 100/2000] tot_loss=3.502 (perp=12.848, rec=0.579, cos=0.353), tot_loss_proj:4.566 [t=0.17s]
prediction: ['[CLS] plato beside corridor really until swiftly tatumonate encryption easily with holder [SEP]']
[ 150/2000] tot_loss=3.465 (perp=13.897, rec=0.526, cos=0.160), tot_loss_proj:4.687 [t=0.17s]
prediction: ['[CLS] yu between herbert callie accessible swiftlyundonateonate easilyund visited [SEP]']
[ 200/2000] tot_loss=3.844 (perp=14.311, rec=0.600, cos=0.382), tot_loss_proj:4.760 [t=0.17s]
prediction: ['[CLS] henry deadly dallasjack african rally jennyonate ampplify easily of [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.815 (perp=14.647, rec=0.564, cos=0.322), tot_loss_proj:4.706 [t=0.17s]
prediction: ['[CLS] studio between loose easily african rally ©onate amp cruisersjack of [SEP]']
[ 300/2000] tot_loss=3.347 (perp=13.442, rec=0.517, cos=0.141), tot_loss_proj:4.530 [t=0.17s]
prediction: ['[CLS] studio easily loose easily bce rally ©onate accessible cruisersjack with [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.115 (perp=12.631, rec=0.500, cos=0.089), tot_loss_proj:4.385 [t=0.17s]
prediction: ['[CLS] studio easily loose easily bce rallyroomonate accessibleonate withjack [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.129 (perp=12.614, rec=0.506, cos=0.100), tot_loss_proj:4.335 [t=0.17s]
prediction: ['[CLS] statement easily loose easily magical rally briefs with accessiblevilleonatejack [SEP]']
[ 450/2000] tot_loss=3.189 (perp=13.401, rec=0.476, cos=0.033), tot_loss_proj:4.597 [t=0.17s]
prediction: ['[CLS] gordon easily loose easily leonard rallyroom upside accessible complicatedonate could [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.279 (perp=13.975, rec=0.465, cos=0.020), tot_loss_proj:4.720 [t=0.17s]
prediction: ['[CLS] gordon easily loose easily leonard rallyroom upside accessible settleonate could [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=3.008 (perp=12.570, rec=0.466, cos=0.028), tot_loss_proj:4.455 [t=0.17s]
prediction: ['[CLS] gordon easily loose easily arrivedonate accessible upside accessible loosenonate easily [SEP]']
[ 600/2000] tot_loss=3.043 (perp=12.887, rec=0.449, cos=0.016), tot_loss_proj:3.998 [t=0.17s]
prediction: ['[CLS] gordon easily easily easily watsononate accessible upside accessible loosenonate easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.922 (perp=12.337, rec=0.443, cos=0.012), tot_loss_proj:4.157 [t=0.17s]
prediction: ['[CLS] gordon easily easily could watsononate accessible upside accessible loosenonate easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.043 (perp=12.952, rec=0.443, cos=0.009), tot_loss_proj:4.042 [t=0.17s]
prediction: ['[CLS] gordon easily easily easily watsononate accessibleonate accessible loosenonate easily [SEP]']
[ 750/2000] tot_loss=3.054 (perp=12.979, rec=0.435, cos=0.023), tot_loss_proj:4.080 [t=0.17s]
prediction: ['[CLS] gordon easily pull easily storiesonate accessibleonate accessible loosenonate easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.030 (perp=12.979, rec=0.428, cos=0.006), tot_loss_proj:4.079 [t=0.17s]
prediction: ['[CLS] gordon easily pull easily storiesonate accessibleonate accessible loosenonate easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.104 (perp=13.305, rec=0.433, cos=0.010), tot_loss_proj:4.207 [t=0.17s]
prediction: ['[CLS] boss easily pull easily storiesonate accessibleonate accessible loosenonate easily [SEP]']
[ 900/2000] tot_loss=3.072 (perp=12.882, rec=0.431, cos=0.064), tot_loss_proj:3.999 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonate accessible loosenonate easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.044 (perp=13.087, rec=0.422, cos=0.004), tot_loss_proj:4.319 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplify loosenonate easily [SEP]']
Attempt swap
[1000/2000] tot_loss=3.046 (perp=13.087, rec=0.420, cos=0.009), tot_loss_proj:4.312 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplify loosenonate easily [SEP]']
[1050/2000] tot_loss=3.114 (perp=13.087, rec=0.421, cos=0.075), tot_loss_proj:4.317 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplify loosenonate easily [SEP]']
Attempt swap
[1100/2000] tot_loss=3.040 (perp=13.087, rec=0.417, cos=0.005), tot_loss_proj:4.309 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplify loosenonate easily [SEP]']
Attempt swap
[1150/2000] tot_loss=3.150 (perp=13.087, rec=0.433, cos=0.100), tot_loss_proj:4.318 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplify loosenonate easily [SEP]']
[1200/2000] tot_loss=3.037 (perp=13.087, rec=0.416, cos=0.004), tot_loss_proj:4.313 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplify loosenonate easily [SEP]']
Attempt swap
[1250/2000] tot_loss=3.041 (perp=13.087, rec=0.421, cos=0.002), tot_loss_proj:4.311 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplify loosenonate easily [SEP]']
Attempt swap
[1300/2000] tot_loss=3.072 (perp=13.087, rec=0.422, cos=0.033), tot_loss_proj:4.311 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplify loosenonate easily [SEP]']
[1350/2000] tot_loss=3.034 (perp=13.087, rec=0.414, cos=0.002), tot_loss_proj:4.315 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplify loosenonate easily [SEP]']
Attempt swap
[1400/2000] tot_loss=3.032 (perp=13.087, rec=0.413, cos=0.002), tot_loss_proj:4.310 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplify loosenonate easily [SEP]']
Attempt swap
[1450/2000] tot_loss=3.122 (perp=13.439, rec=0.420, cos=0.014), tot_loss_proj:4.156 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplifyuncedonate easily [SEP]']
[1500/2000] tot_loss=3.104 (perp=13.439, rec=0.414, cos=0.002), tot_loss_proj:4.153 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplifyuncedonate easily [SEP]']
Attempt swap
[1550/2000] tot_loss=3.108 (perp=13.439, rec=0.413, cos=0.008), tot_loss_proj:4.151 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplifyuncedonate easily [SEP]']
Attempt swap
[1600/2000] tot_loss=3.104 (perp=13.439, rec=0.410, cos=0.006), tot_loss_proj:4.153 [t=0.17s]
prediction: ['[CLS] substance easily pull easily storiesrize accessibleonateplifyuncedonate easily [SEP]']
[1650/2000] tot_loss=2.996 (perp=12.915, rec=0.408, cos=0.005), tot_loss_proj:4.156 [t=0.17s]
prediction: ['[CLS] substance easily pull easily accessiblerize accessibleonateplifyuncedonate easily [SEP]']
Attempt swap
[1700/2000] tot_loss=3.000 (perp=12.915, rec=0.411, cos=0.006), tot_loss_proj:4.154 [t=0.17s]
prediction: ['[CLS] substance easily pull easily accessiblerize accessibleonateplifyuncedonate easily [SEP]']
Attempt swap
[1750/2000] tot_loss=2.993 (perp=12.915, rec=0.408, cos=0.002), tot_loss_proj:4.149 [t=0.17s]
prediction: ['[CLS] substance easily pull easily accessiblerize accessibleonateplifyuncedonate easily [SEP]']
[1800/2000] tot_loss=2.993 (perp=12.915, rec=0.409, cos=0.001), tot_loss_proj:4.154 [t=0.17s]
prediction: ['[CLS] substance easily pull easily accessiblerize accessibleonateplifyuncedonate easily [SEP]']
Attempt swap
[1850/2000] tot_loss=3.026 (perp=12.915, rec=0.414, cos=0.028), tot_loss_proj:4.151 [t=0.17s]
prediction: ['[CLS] substance easily pull easily accessiblerize accessibleonateplifyuncedonate easily [SEP]']
Attempt swap
[1900/2000] tot_loss=2.996 (perp=12.915, rec=0.411, cos=0.003), tot_loss_proj:4.152 [t=0.17s]
prediction: ['[CLS] substance easily pull easily accessiblerize accessibleonateplifyuncedonate easily [SEP]']
[1950/2000] tot_loss=2.994 (perp=12.915, rec=0.408, cos=0.002), tot_loss_proj:4.153 [t=0.17s]
prediction: ['[CLS] substance easily pull easily accessiblerize accessibleonateplifyuncedonate easily [SEP]']
Attempt swap
[2000/2000] tot_loss=2.993 (perp=12.915, rec=0.404, cos=0.006), tot_loss_proj:4.150 [t=0.17s]
prediction: ['[CLS] substance easily pull easily accessiblerize accessibleonateplifyuncedonate easily [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] substance easily pull easily accessiblerize accessibleonateplifyuncedonate easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 40.000 | p: 44.444 | r: 36.364
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 44.444 | r: 36.364
rougeLsum  | fm: 40.000 | p: 44.444 | r: 36.364
r1fm+r2fm = 40.000

[Aggregate metrics]:
rouge1     | fm: 90.801 | p: 90.641 | r: 90.966
rouge2     | fm: 56.062 | p: 55.955 | r: 56.197
rougeL     | fm: 79.524 | p: 79.456 | r: 79.570
rougeLsum  | fm: 78.988 | p: 78.923 | r: 79.101
r1fm+r2fm = 146.863

input #32 time: 0:06:43 | total time: 3:49:01


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9992763851579931
highest_index [0]
highest [0.9992763851579931]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 1.8901952505111694 for ['[CLS] riots [SEP]']
[Init] best rec loss: 1.7840126752853394 for ['[CLS] lord [SEP]']
[Init] best rec loss: 1.6915725469589233 for ['[CLS] master [SEP]']
[Init] best rec loss: 1.5511021614074707 for ['[CLS] training [SEP]']
[Init] best rec loss: 1.4511288404464722 for ['[CLS] strip [SEP]']
[Init] best rec loss: 1.3865865468978882 for ['[CLS] less [SEP]']
[Init] best rec loss: 1.3548933267593384 for ['[CLS] higher [SEP]']
[Init] best rec loss: 1.121751308441162 for ['[CLS] positive [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.492 (perp=11.231, rec=0.232, cos=0.014), tot_loss_proj:2.997 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.360 (perp=11.231, rec=0.111, cos=0.003), tot_loss_proj:2.500 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.335 (perp=11.231, rec=0.087, cos=0.002), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.321 (perp=11.231, rec=0.074, cos=0.002), tot_loss_proj:2.407 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.322 (perp=11.231, rec=0.075, cos=0.002), tot_loss_proj:2.396 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.409 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.396 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.316 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.409 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.298 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.407 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.298 (perp=11.231, rec=0.051, cos=0.001), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.302 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.397 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.401 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.001), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.301 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.397 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.293 (perp=11.231, rec=0.045, cos=0.001), tot_loss_proj:2.405 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.379 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.310 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.408 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.295 (perp=11.231, rec=0.047, cos=0.001), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.397 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.403 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.400 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.411 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.387 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.301 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.393 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.306 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.402 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.300 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.402 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.316 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.390 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.320 (perp=11.231, rec=0.072, cos=0.001), tot_loss_proj:2.394 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.322 (perp=11.231, rec=0.074, cos=0.001), tot_loss_proj:2.410 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.297 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.396 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.398 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.393 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.323 (perp=11.231, rec=0.075, cos=0.001), tot_loss_proj:2.386 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.307 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.408 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.302 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.402 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.302 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.398 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.300 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.390 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.297 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.383 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.036 | p: 90.964 | r: 91.241
rouge2     | fm: 57.436 | p: 57.296 | r: 57.593
rougeL     | fm: 80.031 | p: 80.025 | r: 80.120
rougeLsum  | fm: 79.557 | p: 79.557 | r: 79.627
r1fm+r2fm = 148.472

input #33 time: 0:06:38 | total time: 3:55:40


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9992091879502123
highest_index [0]
highest [0.9992091879502123]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 1.8906997442245483 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 1.821115493774414 for ['[CLS] mistress quality security throughout trunkught warning age marketing experiments despite bug travel [SEP]']
[Init] best rec loss: 1.8150413036346436 for ['[CLS] bus japan coyote being far united away sal during cov : fair [SEP]']
[Init] best rec loss: 1.764905333518982 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 1.7503083944320679 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 1.716280460357666 for ['[CLS] bird cursed led ao wearing one keys nearlysco tom constitutionnem љ [SEP]']
[Init] best rec loss: 1.469266414642334 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 1.4675160646438599 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 1.4614590406417847 for ['[CLS] field slight alongask whoibe statue worth lissa founder ship okay drivers [SEP]']
[Init] best perm rec loss: 1.4533991813659668 for ['[CLS] ship slight founder statue lissaask drivers okay worth fieldibe who along [SEP]']
[Init] best perm rec loss: 1.4512879848480225 for ['[CLS]ask along slight founder worth okay ship lissa field statue driversibe who [SEP]']
[Init] best perm rec loss: 1.4508488178253174 for ['[CLS]ibe along worth driversask slight statue field okay who lissa ship founder [SEP]']
[Init] best perm rec loss: 1.4482790231704712 for ['[CLS] alongibe drivers who ship statue okay lissaask worth slight founder field [SEP]']
[Init] best perm rec loss: 1.4482308626174927 for ['[CLS] lissa ship along drivers slight okayaskibe who statue founder field worth [SEP]']
[Init] best perm rec loss: 1.4454642534255981 for ['[CLS] along slight ship worth drivers founder okay whoask field lissa statueibe [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.789 (perp=12.397, rec=0.292, cos=0.017), tot_loss_proj:4.248 [t=0.17s]
prediction: ['[CLS] of joshtruct urgency extreme emotion events. actornate carolinehed urgency [SEP]']
[ 100/2000] tot_loss=2.436 (perp=11.131, rec=0.203, cos=0.007), tot_loss_proj:3.972 [t=0.17s]
prediction: ['[CLS] in josh build urgency extreme viewer dangers. viewer take winniehed urgency [SEP]']
[ 150/2000] tot_loss=2.442 (perp=11.437, rec=0.150, cos=0.004), tot_loss_proj:4.022 [t=0.17s]
prediction: ['[CLS] in viewers build urgency extreme mind dangers. viewer taketial the urgency [SEP]']
[ 200/2000] tot_loss=1.942 (perp=9.076, rec=0.123, cos=0.003), tot_loss_proj:3.125 [t=0.17s]
prediction: ['[CLS]. john build in extreme mind dangers. viewer take on the urgency [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.818 (perp=8.511, rec=0.112, cos=0.003), tot_loss_proj:2.830 [t=0.17s]
prediction: ['[CLS]. john build in mind extreme dangers. viewer take on the urgency [SEP]']
[ 300/2000] tot_loss=1.747 (perp=8.184, rec=0.107, cos=0.003), tot_loss_proj:2.310 [t=0.17s]
prediction: ['[CLS]. john build in mind extreme motion and viewer take on the urgency [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.775 (perp=8.355, rec=0.101, cos=0.004), tot_loss_proj:3.288 [t=0.17s]
prediction: ['[CLS]. john build in mind extreme dangers of take on the viewer urgency [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.719 (perp=7.945, rec=0.125, cos=0.005), tot_loss_proj:2.864 [t=0.17s]
prediction: ['[CLS] john build in mind extreme its of take on a viewer urgency. [SEP]']
[ 450/2000] tot_loss=1.704 (perp=8.005, rec=0.101, cos=0.003), tot_loss_proj:3.113 [t=0.17s]
prediction: ['[CLS] villain build in mind extreme its the take on a viewer urgency. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.457 (perp=6.771, rec=0.100, cos=0.002), tot_loss_proj:2.912 [t=0.17s]
prediction: ['[CLS] villain build in mind the extreme its take on a viewer urgency. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.543 (perp=7.255, rec=0.090, cos=0.002), tot_loss_proj:2.582 [t=0.20s]
prediction: ['[CLS] build in mind the extreme its john take on a viewer urgency. [SEP]']
[ 600/2000] tot_loss=1.509 (perp=7.089, rec=0.089, cos=0.002), tot_loss_proj:2.577 [t=0.18s]
prediction: ['[CLS] build in mind the extreme its john take on the viewer urgency. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.492 (perp=6.992, rec=0.091, cos=0.002), tot_loss_proj:2.604 [t=0.19s]
prediction: ['[CLS] build in mind the extreme john its take on the viewer urgency. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.453 (perp=6.769, rec=0.097, cos=0.003), tot_loss_proj:2.608 [t=0.20s]
prediction: ['[CLS] build in mind the extreme its take on the john viewer urgency. [SEP]']
[ 750/2000] tot_loss=1.444 (perp=6.769, rec=0.088, cos=0.002), tot_loss_proj:2.613 [t=0.17s]
prediction: ['[CLS] build in mind the extreme its take on the john viewer urgency. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.457 (perp=6.794, rec=0.096, cos=0.002), tot_loss_proj:2.487 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take on the john viewer urgency. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.438 (perp=6.794, rec=0.078, cos=0.002), tot_loss_proj:2.485 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take on the john viewer urgency. [SEP]']
[ 900/2000] tot_loss=1.453 (perp=6.794, rec=0.093, cos=0.002), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take on the john viewer urgency. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.448 (perp=6.794, rec=0.088, cos=0.002), tot_loss_proj:2.489 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take on the john viewer urgency. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.432 (perp=6.794, rec=0.072, cos=0.002), tot_loss_proj:2.489 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take on the john viewer urgency. [SEP]']
[1050/2000] tot_loss=1.439 (perp=6.794, rec=0.079, cos=0.002), tot_loss_proj:2.481 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take on the john viewer urgency. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.434 (perp=6.794, rec=0.074, cos=0.002), tot_loss_proj:2.491 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take on the john viewer urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.428 (perp=6.794, rec=0.068, cos=0.002), tot_loss_proj:2.484 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take on the john viewer urgency. [SEP]']
[1200/2000] tot_loss=1.442 (perp=6.794, rec=0.081, cos=0.002), tot_loss_proj:2.481 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take on the john viewer urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.429 (perp=6.794, rec=0.069, cos=0.002), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take on the john viewer urgency. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.457 (perp=6.868, rec=0.082, cos=0.002), tot_loss_proj:2.332 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take and john the viewer urgency. [SEP]']
[1350/2000] tot_loss=1.454 (perp=6.868, rec=0.079, cos=0.002), tot_loss_proj:2.339 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take and john the viewer urgency. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.447 (perp=6.836, rec=0.078, cos=0.002), tot_loss_proj:2.376 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take and the john viewer urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.443 (perp=6.836, rec=0.074, cos=0.002), tot_loss_proj:2.370 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take and the john viewer urgency. [SEP]']
[1500/2000] tot_loss=1.443 (perp=6.836, rec=0.074, cos=0.002), tot_loss_proj:2.375 [t=0.17s]
prediction: ['[CLS] build in mind the extreme the take and the john viewer urgency. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.400 (perp=6.574, rec=0.083, cos=0.002), tot_loss_proj:2.140 [t=0.17s]
prediction: ['[CLS] john build in mind the extreme the take and the viewer urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.407 (perp=6.574, rec=0.090, cos=0.002), tot_loss_proj:2.143 [t=0.17s]
prediction: ['[CLS] john build in mind the extreme the take and the viewer urgency. [SEP]']
[1650/2000] tot_loss=1.405 (perp=6.574, rec=0.088, cos=0.002), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] john build in mind the extreme the take and the viewer urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.396 (perp=6.574, rec=0.080, cos=0.002), tot_loss_proj:2.144 [t=0.17s]
prediction: ['[CLS] john build in mind the extreme the take and the viewer urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.403 (perp=6.574, rec=0.086, cos=0.002), tot_loss_proj:2.142 [t=0.17s]
prediction: ['[CLS] john build in mind the extreme the take and the viewer urgency. [SEP]']
[1800/2000] tot_loss=1.389 (perp=6.541, rec=0.079, cos=0.002), tot_loss_proj:2.252 [t=0.17s]
prediction: ['[CLS] john build in mind the extreme the take on the viewer urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.382 (perp=6.541, rec=0.072, cos=0.002), tot_loss_proj:2.254 [t=0.17s]
prediction: ['[CLS] john build in mind the extreme the take on the viewer urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.386 (perp=6.541, rec=0.077, cos=0.002), tot_loss_proj:2.264 [t=0.17s]
prediction: ['[CLS] john build in mind the extreme the take on the viewer urgency. [SEP]']
[1950/2000] tot_loss=1.385 (perp=6.541, rec=0.075, cos=0.002), tot_loss_proj:2.262 [t=0.17s]
prediction: ['[CLS] john build in mind the extreme the take on the viewer urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.388 (perp=6.541, rec=0.078, cos=0.002), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] john build in mind the extreme the take on the viewer urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] john build in mind the extreme the take on the viewer urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 30.769 | p: 30.769 | r: 30.769
rougeL     | fm: 64.286 | p: 64.286 | r: 64.286
rougeLsum  | fm: 64.286 | p: 64.286 | r: 64.286
r1fm+r2fm = 116.484

[Aggregate metrics]:
rouge1     | fm: 90.994 | p: 90.892 | r: 91.203
rouge2     | fm: 56.599 | p: 56.573 | r: 56.697
rougeL     | fm: 79.538 | p: 79.495 | r: 79.635
rougeLsum  | fm: 79.310 | p: 79.339 | r: 79.343
r1fm+r2fm = 147.592

input #34 time: 0:06:51 | total time: 4:02:31


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9993278544896083
highest_index [0]
highest [0.9993278544896083]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 1.908953070640564 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 1.8951733112335205 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 1.8934053182601929 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 1.834226369857788 for ['[CLS] interview effectiveness hum saliva ring mao cheerleading aim respond medicine pointliftland lost happening gap placement solomon gertrude fabric four hair byte aimed ogden trains gnu beside jo tight spoke millionsᵢ folded girls halls man trail drawnvc rule authorities [SEP]']
[Init] best rec loss: 1.80353844165802 for ["[CLS]bard boardless seed list arizona orders track be england lamb video name deep candy mont already nebraska offerings trained promise science last makeup qualifier ir lidciency about usesbrook'tag indefinitely grimes dress 2002 whether offerings design spear career [SEP]"]
[Init] best rec loss: 1.7946257591247559 for ['[CLS] trouble celebrity neckyah top bucks where appeared interrupting left carlo how ghost echoed million this incorporated bounded done theiritated tired exchange keep not brigade papers seed suicidal der wear raw discus school although fringe geographical difference accused hourly together stick [SEP]']
[Init] best rec loss: 1.7641812562942505 for ['[CLS]usionpm seeking tango casino over digital runway church radio cells an rom going endemicrted did penalty craft chance master no words [CLS] treatment bed caliphate quantum destination bladed down optical interested obvious rang recentguard hall theatre ballettt do [SEP]']
[Init] best rec loss: 1.730168104171753 for ['[CLS] mi " therefore zev ms hays bun welles start pierce aquino interce specific causedpo normal texas often vocals secretaries themselves magic night court cesar stages achilles excellent fixed shi bertie leg rows plant alwaysch beijing futuretral young wall [SEP]']
[Init] best perm rec loss: 1.7273207902908325 for ['[CLS] future stages shi plant beijing often welles secretaries alwaysce bertie themselves excellent zev inter caused fixed achilles bun night specific mi rows hayspo aquinochtral leg normal therefore magic texas court wall ms " start young vocals cesar pierce [SEP]']
[Init] best perm rec loss: 1.7262543439865112 for ['[CLS]po excellent ms wall vocals aquino stages future achilles normal court cesar plant secretaries welles magictral texas night hays start themselves beijing therefore pierce leg "ce specific caused zev alwaysch often mi shi bertie bun fixed rows young inter [SEP]']
[Init] best perm rec loss: 1.7246230840682983 for ['[CLS] " cesartral excellent achilles caused wall always hays zev pierce future often start leg msch welles beijing secretariesce stages court fixed aquino specific magic shi bertie therefore young vocalspo plant normal texas inter bun mi themselves night rows [SEP]']
[Init] best perm rec loss: 1.7220380306243896 for ['[CLS] normal pierce bun aquino stages specific " mi shi future rows zev start themselves bertietral hays texas achilles therefore cesar secretaries always oftence youngpo vocals leg fixed wall magic beijing plant welles caused excellent courtch inter night ms [SEP]']
[Init] best perm rec loss: 1.721089243888855 for ['[CLS] texas ms wall alwaystral start bun normal excellent secretaries stages piercech zev leg courtce night cesar aquino inter fixed therefore future vocals plant " achilles mi shi causedpo magic young specific rows bertie welles beijing hays themselves often [SEP]']
[Init] best perm rec loss: 1.7183254957199097 for ['[CLS] leg achilles magicpo themselves cesar secretariesch plant " wall therefore vocals fixed bun specific zev shi start night hays mstral welles stages aquino normal inter mi bertie rows beijing future alwaysce excellent often caused young court texas pierce [SEP]']
[Init] best perm rec loss: 1.7166597843170166 for ['[CLS] zev bertie fixed rows magic shi texasch specific alwaystralce stages plant caused normal pierce beijing start "po hays welles night mi excellent future therefore aquino ms bun cesar young themselves wall secretaries achilles often inter leg vocals court [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.509 (perp=10.240, rec=0.434, cos=0.027), tot_loss_proj:3.485 [t=0.17s]
prediction: ["[CLS] royal commission and asia outstanding lord'love representatives they less ( advance that from asv becoming before but styles states the now importantly care new sacrament ( catsfies offiving the the world faculty council world volume pressure completely [SEP]"]
[ 100/2000] tot_loss=2.374 (perp=10.178, rec=0.328, cos=0.010), tot_loss_proj:3.463 [t=0.17s]
prediction: ["[CLS] deer'and world great student'' a'y before s, from as hockey < before but did ᵍ outside making importantly care surviving birch may you makes features concerning the the world directornation. storm care again [SEP]"]
[ 150/2000] tot_loss=2.132 (perp=9.376, rec=0.252, cos=0.005), tot_loss_proj:3.557 [t=0.17s]
prediction: ["[CLS] probably they and ; great student'' scratch'made before s they from of 'ctuated before but did ᵍ outside but'care having schuster who you makes about improved the apparently, directornation. greatest help! [SEP]"]
[ 200/2000] tot_loss=2.043 (perp=9.068, rec=0.226, cos=0.004), tot_loss_proj:3.644 [t=0.17s]
prediction: ["[CLS] probably they so, great student'' scratch'made before'we but having 'g before but did ᵍ through but help care it immediately who you makes about risen the building, directornation. gretchen help! [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.919 (perp=8.414, rec=0.230, cos=0.006), tot_loss_proj:3.174 [t=0.17s]
prediction: ["[CLS] or they we, ve'teacher'scratch'' before'we and seen') before and didennial in but help care it immediately & you makes about latest the great, directornation. greater help. [SEP]"]
[ 300/2000] tot_loss=2.011 (perp=8.671, rec=0.272, cos=0.005), tot_loss_proj:3.047 [t=0.17s]
prediction: ["[CLS] museum they we ; ve'teacher'scratch they made before'we the seen') before ; gave entry director but'care they immediately recommended you makes about latest the great of directornation. great help! [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.897 (perp=8.332, rec=0.227, cos=0.003), tot_loss_proj:3.115 [t=0.17s]
prediction: ["[CLS] museum they we'has'teacher'scratch they, before'we, seen') before well continued entry director but'care'immediately recommended them makes us latest the rein of directornation. great help. [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.697 (perp=7.498, rec=0.195, cos=0.003), tot_loss_proj:3.056 [t=0.17s]
prediction: ["[CLS] probably we we've'seen'in they, before'we latest seen') before wellnation entry director but'care'immediately published them makes us, this rein of directornation. great help. [SEP]"]
[ 450/2000] tot_loss=1.733 (perp=7.687, rec=0.193, cos=0.002), tot_loss_proj:3.025 [t=0.17s]
prediction: ["[CLS] i we seen've'seen'in they, before'we latest seen') before roughnation most director but'care'immediately published them makes us, this rein of directornation. great help. [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.692 (perp=7.553, rec=0.179, cos=0.002), tot_loss_proj:3.004 [t=0.17s]
prediction: ["[CLS] we we seen've'seen'in they, before in we latest seen'from before or transportnation by but'care'immediately published them makes us, this rein of directornation, great help. [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.681 (perp=7.519, rec=0.175, cos=0.002), tot_loss_proj:3.122 [t=0.17s]
prediction: ["[CLS] we we seen've'seen'in we, before in we latest seen'from before : transportnation'but by care'immediately publish them makes us from this rein of directornation, great help. [SEP]"]
[ 600/2000] tot_loss=1.726 (perp=7.818, rec=0.160, cos=0.002), tot_loss_proj:2.955 [t=0.17s]
prediction: ["[CLS] we we seen've'seen'in we, before'we latest seen'from before allen transportnation'but of care'immediately sample them makes us from this rein of directornation, great help. [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.796 (perp=8.149, rec=0.164, cos=0.002), tot_loss_proj:3.321 [t=0.17s]
prediction: ["[CLS] we we seen've'seen'hoffman we, before'we latest seen'from based transportnation'but before of care'immediately borrow them makes us from this rein of directornation, great help. [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.793 (perp=8.177, rec=0.155, cos=0.003), tot_loss_proj:3.176 [t=0.17s]
prediction: ["[CLS] we we seen've'seen'hoffman we, before in we latest seen'from kevin fromnation'but before of care'immediately borrow them makes us transport this rein of directornation, great help. [SEP]"]
[ 750/2000] tot_loss=1.771 (perp=8.091, rec=0.151, cos=0.002), tot_loss_proj:3.144 [t=0.17s]
prediction: ["[CLS] we we seen've'seen'hoffman we, before in we latest seen'with kevin fromnation'but before of care'immediately borrow them makes us transport this rein of directornation, great help. [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.775 (perp=8.142, rec=0.144, cos=0.002), tot_loss_proj:3.316 [t=0.17s]
prediction: ["[CLS] we we seen've'seen'hoffman immediately, before in we latest seen'from kevin fromnation'but before of care'we borrow them makes us 8 this rein of directornation, great help. [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.751 (perp=7.975, rec=0.154, cos=0.002), tot_loss_proj:3.307 [t=0.17s]
prediction: ["[CLS] from we seen've'seen'hoffman immediately, before in we latest seen'from kevin wenation'but before of care'we borrow them makes us 8 this rein of directornation, great help. [SEP]"]
[ 900/2000] tot_loss=1.735 (perp=7.975, rec=0.138, cos=0.002), tot_loss_proj:3.308 [t=0.17s]
prediction: ["[CLS] from we seen've'seen'hoffman immediately, before in we latest seen'from kevin wenation'but before of care'we borrow them makes us 8 this rein of directornation, great help. [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.711 (perp=7.854, rec=0.138, cos=0.002), tot_loss_proj:3.223 [t=0.17s]
prediction: ["[CLS] from we seen've'seen'8 immediately, before in we latest seen'from kevin wenation'but before of care'we borrow them makes us hoffman this rein of directornation, great help. [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.703 (perp=7.782, rec=0.144, cos=0.002), tot_loss_proj:3.249 [t=0.17s]
prediction: ["[CLS] from we seen've'seen'immediately 8, before in we latest seen'from kevin wenation'but before of care'we borrow them makes us hoffman this rein of directornation, great help. [SEP]"]
[1050/2000] tot_loss=1.743 (perp=8.009, rec=0.140, cos=0.002), tot_loss_proj:3.178 [t=0.17s]
prediction: ["[CLS] from we seen've'seen'immediately hoffman, before in we latest seen'from kevin wenation'but before of care'we phd about makes us hoffman this rein of directornation, great help. [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.723 (perp=7.912, rec=0.139, cos=0.002), tot_loss_proj:3.237 [t=0.18s]
prediction: ["[CLS] of we seen've'seen'him hoffman, before in we latest seen'from kevin wenation'but before of care'we phd about makes us rein this hoffman of directornation, great help. [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.679 (perp=7.691, rec=0.139, cos=0.002), tot_loss_proj:3.265 [t=0.19s]
prediction: ["[CLS] of we seen've'seen'him hoffman, before in we latest seen'from kevin wenation'but before'care'we phd about makes us rein thisnation of director hoffman, great help. [SEP]"]
[1200/2000] tot_loss=1.673 (perp=7.691, rec=0.133, cos=0.002), tot_loss_proj:3.267 [t=0.19s]
prediction: ["[CLS] of we seen've'seen'him hoffman, before in we latest seen'from kevin wenation'but before'care'we phd about makes us rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.634 (perp=7.509, rec=0.130, cos=0.002), tot_loss_proj:3.114 [t=0.17s]
prediction: ["[CLS] of we seen've'seen in him hoffman, before'we latest seen'from kevin itnation'but before'care'we phd about makes us rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.584 (perp=7.207, rec=0.140, cos=0.002), tot_loss_proj:3.060 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'care'we phd about makes us rein thisnation of director hoffman, great help. [SEP]"]
[1350/2000] tot_loss=1.591 (perp=7.207, rec=0.147, cos=0.002), tot_loss_proj:3.066 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'care'we phd about makes us rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.577 (perp=7.207, rec=0.133, cos=0.002), tot_loss_proj:3.066 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'care'we phd about makes us rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.573 (perp=7.150, rec=0.141, cos=0.002), tot_loss_proj:2.959 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'care'we phd us about makes rein thisnation of director hoffman, great help. [SEP]"]
[1500/2000] tot_loss=1.559 (perp=7.150, rec=0.127, cos=0.002), tot_loss_proj:2.964 [t=0.18s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'care'we phd us about makes rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.562 (perp=7.150, rec=0.130, cos=0.002), tot_loss_proj:2.958 [t=0.21s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'care'we phd us about makes rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.543 (perp=7.047, rec=0.132, cos=0.002), tot_loss_proj:2.947 [t=0.18s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'we'care phd us about makes rein thisnation of director hoffman, great help. [SEP]"]
[1650/2000] tot_loss=1.548 (perp=7.047, rec=0.137, cos=0.002), tot_loss_proj:2.948 [t=0.19s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'we'care phd us about makes rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.542 (perp=7.047, rec=0.130, cos=0.002), tot_loss_proj:2.946 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'we'care phd us about makes rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.534 (perp=7.048, rec=0.123, cos=0.002), tot_loss_proj:3.050 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'we'care phd us makes about rein thisnation of director hoffman, great help. [SEP]"]
[1800/2000] tot_loss=1.534 (perp=7.048, rec=0.123, cos=0.002), tot_loss_proj:3.040 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'we'care phd us makes about rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.554 (perp=7.048, rec=0.143, cos=0.002), tot_loss_proj:3.045 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'we'care phd us makes about rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.510 (perp=6.929, rec=0.122, cos=0.002), tot_loss_proj:2.855 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'we'care phd us makes, rein thisnation of director hoffman, great help. [SEP]"]
[1950/2000] tot_loss=1.500 (perp=6.929, rec=0.113, cos=0.002), tot_loss_proj:2.856 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'we'care phd us makes, rein thisnation of director hoffman, great help. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.519 (perp=6.929, rec=0.131, cos=0.002), tot_loss_proj:2.853 [t=0.17s]
prediction: ["[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'we'care phd us makes, rein thisnation of director hoffman, great help. [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] of we seen've seen'in him hoffman, before'we latest seen'from kevin itnation'but before'we'care phd us about makes rein thisnation of director hoffman, great help. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 59.701 | p: 62.500 | r: 57.143
rouge2     | fm: 12.308 | p: 12.903 | r: 11.765
rougeL     | fm: 35.821 | p: 37.500 | r: 34.286
rougeLsum  | fm: 35.821 | p: 37.500 | r: 34.286
r1fm+r2fm = 72.009

[Aggregate metrics]:
rouge1     | fm: 89.949 | p: 89.978 | r: 90.067
rouge2     | fm: 55.295 | p: 55.226 | r: 55.411
rougeL     | fm: 78.259 | p: 78.274 | r: 78.254
rougeLsum  | fm: 78.221 | p: 78.264 | r: 78.231
r1fm+r2fm = 145.244

input #35 time: 0:07:00 | total time: 4:09:32


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.9992842743865827
highest_index [0]
highest [0.9992842743865827]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 1.9766509532928467 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 1.881966471672058 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 1.782330870628357 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 1.6660853624343872 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 1.6349523067474365 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 1.2444989681243896 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 1.241437554359436 for ['[CLS] harassment cornelius ramsey bates [SEP]']
[Init] best perm rec loss: 1.2356886863708496 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 1.2343624830245972 for ['[CLS] ramsey harassment cornelius bates [SEP]']
[Init] best perm rec loss: 1.2221870422363281 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.952 (perp=9.086, rec=0.128, cos=0.006), tot_loss_proj:2.101 [t=0.18s]
prediction: ['[CLS] is horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=1.915 (perp=9.148, rec=0.083, cos=0.002), tot_loss_proj:2.113 [t=0.18s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=1.906 (perp=9.148, rec=0.075, cos=0.002), tot_loss_proj:2.117 [t=0.18s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=1.893 (perp=9.148, rec=0.062, cos=0.002), tot_loss_proj:2.112 [t=0.18s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.901 (perp=9.148, rec=0.070, cos=0.002), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 300/2000] tot_loss=1.898 (perp=9.148, rec=0.067, cos=0.002), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.904 (perp=9.148, rec=0.073, cos=0.002), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.799 (perp=8.607, rec=0.076, cos=0.002), tot_loss_proj:1.922 [t=0.17s]
prediction: ["[CLS] s horribly wrong'[SEP]"]
[ 450/2000] tot_loss=1.796 (perp=8.607, rec=0.073, cos=0.001), tot_loss_proj:1.920 [t=0.17s]
prediction: ["[CLS] s horribly wrong'[SEP]"]
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.521 (perp=7.159, rec=0.087, cos=0.002), tot_loss_proj:1.833 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.503 (perp=7.159, rec=0.069, cos=0.002), tot_loss_proj:1.830 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 600/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.002), tot_loss_proj:1.833 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.509 (perp=7.159, rec=0.076, cos=0.001), tot_loss_proj:1.833 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.503 (perp=7.159, rec=0.070, cos=0.001), tot_loss_proj:1.832 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 750/2000] tot_loss=1.506 (perp=7.159, rec=0.072, cos=0.001), tot_loss_proj:1.837 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.513 (perp=7.159, rec=0.079, cos=0.001), tot_loss_proj:1.830 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.001), tot_loss_proj:1.823 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 900/2000] tot_loss=1.505 (perp=7.159, rec=0.072, cos=0.001), tot_loss_proj:1.823 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.496 (perp=7.159, rec=0.063, cos=0.001), tot_loss_proj:1.823 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.001), tot_loss_proj:1.835 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1050/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.826 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.506 (perp=7.159, rec=0.072, cos=0.001), tot_loss_proj:1.839 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.513 (perp=7.159, rec=0.080, cos=0.001), tot_loss_proj:1.824 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1200/2000] tot_loss=1.490 (perp=7.159, rec=0.057, cos=0.001), tot_loss_proj:1.827 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.001), tot_loss_proj:1.825 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.493 (perp=7.159, rec=0.060, cos=0.001), tot_loss_proj:1.829 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1350/2000] tot_loss=1.504 (perp=7.159, rec=0.070, cos=0.001), tot_loss_proj:1.825 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.502 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.835 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.494 (perp=7.159, rec=0.060, cos=0.001), tot_loss_proj:1.835 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1500/2000] tot_loss=1.495 (perp=7.159, rec=0.061, cos=0.001), tot_loss_proj:1.830 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.502 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.834 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.510 (perp=7.159, rec=0.077, cos=0.001), tot_loss_proj:1.835 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1650/2000] tot_loss=1.489 (perp=7.159, rec=0.055, cos=0.001), tot_loss_proj:1.829 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.829 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.494 (perp=7.159, rec=0.061, cos=0.001), tot_loss_proj:1.832 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1800/2000] tot_loss=1.499 (perp=7.159, rec=0.065, cos=0.001), tot_loss_proj:1.824 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.001), tot_loss_proj:1.833 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.506 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.828 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1950/2000] tot_loss=1.493 (perp=7.159, rec=0.059, cos=0.001), tot_loss_proj:1.827 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.493 (perp=7.159, rec=0.060, cos=0.001), tot_loss_proj:1.838 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] horribly wrong's [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 90.212 | p: 90.165 | r: 90.331
rouge2     | fm: 54.558 | p: 54.445 | r: 54.635
rougeL     | fm: 78.390 | p: 78.342 | r: 78.426
rougeLsum  | fm: 78.023 | p: 78.030 | r: 78.045
r1fm+r2fm = 144.771

input #36 time: 0:06:50 | total time: 4:16:22


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9993688501312639
highest_index [0]
highest [0.9993688501312639]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 1.5322908163070679 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 1.5074071884155273 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 1.484743595123291 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 1.427294373512268 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 1.2968673706054688 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 1.2020169496536255 for ['[CLS] quite sketch [SEP]']
[Init] best rec loss: 1.1809109449386597 for ['[CLS] plainly holstein [SEP]']
[Init] best rec loss: 1.063669204711914 for ['[CLS] time speaker [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.661 (perp=11.576, rec=0.273, cos=0.073), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] time eccentric [SEP]']
[ 100/2000] tot_loss=2.333 (perp=10.822, rec=0.149, cos=0.019), tot_loss_proj:2.552 [t=0.17s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=1.869 (perp=8.916, rec=0.083, cos=0.003), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[ 200/2000] tot_loss=1.862 (perp=8.916, rec=0.077, cos=0.002), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.843 (perp=8.916, rec=0.058, cos=0.002), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[ 300/2000] tot_loss=1.855 (perp=8.916, rec=0.071, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.855 (perp=8.916, rec=0.067, cos=0.004), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.845 (perp=8.916, rec=0.061, cos=0.001), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[ 450/2000] tot_loss=1.856 (perp=8.916, rec=0.071, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.851 (perp=8.916, rec=0.066, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.856 (perp=8.916, rec=0.072, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[ 600/2000] tot_loss=1.849 (perp=8.916, rec=0.065, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.845 (perp=8.916, rec=0.061, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.844 (perp=8.916, rec=0.060, cos=0.001), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[ 750/2000] tot_loss=1.852 (perp=8.916, rec=0.068, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.853 (perp=8.916, rec=0.068, cos=0.001), tot_loss_proj:2.119 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.846 (perp=8.916, rec=0.061, cos=0.001), tot_loss_proj:2.119 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=1.840 (perp=8.916, rec=0.055, cos=0.001), tot_loss_proj:2.122 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.843 (perp=8.916, rec=0.059, cos=0.001), tot_loss_proj:2.114 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=1.857 (perp=8.916, rec=0.072, cos=0.001), tot_loss_proj:2.121 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=1.851 (perp=8.916, rec=0.067, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=1.848 (perp=8.916, rec=0.064, cos=0.001), tot_loss_proj:2.120 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=1.855 (perp=8.916, rec=0.070, cos=0.001), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=1.844 (perp=8.916, rec=0.060, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=1.846 (perp=8.916, rec=0.062, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=1.851 (perp=8.916, rec=0.067, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=1.850 (perp=8.916, rec=0.066, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=1.843 (perp=8.916, rec=0.059, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=1.849 (perp=8.916, rec=0.065, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=1.848 (perp=8.916, rec=0.063, cos=0.001), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=1.837 (perp=8.916, rec=0.052, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=1.839 (perp=8.916, rec=0.055, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=1.851 (perp=8.916, rec=0.066, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=1.835 (perp=8.916, rec=0.051, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=1.857 (perp=8.916, rec=0.073, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=1.849 (perp=8.916, rec=0.064, cos=0.001), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=1.853 (perp=8.916, rec=0.069, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=1.840 (perp=8.916, rec=0.056, cos=0.001), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=1.842 (perp=8.916, rec=0.058, cos=0.001), tot_loss_proj:2.125 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=1.849 (perp=8.916, rec=0.064, cos=0.001), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] and eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 90.527 | p: 90.509 | r: 90.641
rouge2     | fm: 53.233 | p: 53.124 | r: 53.350
rougeL     | fm: 78.380 | p: 78.429 | r: 78.389
rougeLsum  | fm: 77.884 | p: 77.943 | r: 77.889
r1fm+r2fm = 143.761

input #37 time: 0:06:49 | total time: 4:23:12


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9992650714710192
highest_index [0]
highest [0.9992650714710192]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 1.7612740993499756 for ['[CLS] course [SEP]']
[Init] best rec loss: 1.7215585708618164 for ['[CLS]st [SEP]']
[Init] best rec loss: 1.6414412260055542 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 1.4560658931732178 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 1.382164716720581 for ['[CLS] private [SEP]']
[Init] best rec loss: 1.3276795148849487 for ['[CLS] sergeant [SEP]']
[Init] best rec loss: 1.1771332025527954 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.907 (perp=14.069, rec=0.087, cos=0.006), tot_loss_proj:2.889 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.002), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.899 (perp=14.069, rec=0.080, cos=0.006), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.888 (perp=14.069, rec=0.072, cos=0.002), tot_loss_proj:2.869 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.877 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.863 (perp=14.069, rec=0.047, cos=0.002), tot_loss_proj:2.862 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.886 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.875 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.877 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.873 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.868 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.882 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.878 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.871 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.873 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.861 (perp=14.069, rec=0.046, cos=0.001), tot_loss_proj:2.863 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.884 (perp=14.069, rec=0.069, cos=0.001), tot_loss_proj:2.870 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.865 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.882 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.882 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.874 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.868 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.871 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.877 (perp=14.069, rec=0.062, cos=0.001), tot_loss_proj:2.863 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.879 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.883 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.878 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.867 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.886 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.868 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.882 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.864 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.864 (perp=14.069, rec=0.049, cos=0.001), tot_loss_proj:2.869 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.864 (perp=14.069, rec=0.049, cos=0.001), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.885 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.877 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.877 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.861 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.879 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.863 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.865 (perp=14.069, rec=0.050, cos=0.001), tot_loss_proj:2.870 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.880 (perp=14.069, rec=0.064, cos=0.001), tot_loss_proj:2.889 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.869 [t=0.16s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.710 | p: 90.723 | r: 90.809
rouge2     | fm: 54.497 | p: 54.401 | r: 54.617
rougeL     | fm: 78.813 | p: 78.797 | r: 78.855
rougeLsum  | fm: 78.576 | p: 78.612 | r: 78.591
r1fm+r2fm = 145.206

input #38 time: 0:06:43 | total time: 4:29:56


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9992526747729698
highest_index [0]
highest [0.9992526747729698]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 2.0013740062713623 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 2.001059055328369 for ['[CLS] foughtcles yearssy city locations helping interception steve rat raising dos n poor words who agents blair reformationio acquired 1945 accent loss warren [SEP]']
[Init] best rec loss: 1.9660497903823853 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 1.8613423109054565 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 1.8467004299163818 for ['[CLS] snails [UNK] archives though devin shadow branch bell reigns grounds ago los matthew little boyle word createdrid with wing of audience village sounded reached [SEP]']
[Init] best rec loss: 1.7600774765014648 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 1.74936044216156 for ['[CLS] limited symptoms impressiontor jammu runoff formationian facts wyomingful winner ankles when politics turbo our reflex happenedzzo opium look charging relation laugh [SEP]']
[Init] best rec loss: 1.7386794090270996 for ['[CLS] happens silk reads northwest walked peerage commandgu as legal ] erin comprehensive sampled commercial received sun green happens corrections splinter premiere colonel ground inclusive [SEP]']
[Init] best perm rec loss: 1.718573808670044 for ['[CLS] ] happens northwest sampled silk splinter received asgu corrections colonel sun walked peerage commercial comprehensive command legal reads premiere inclusive happens erin ground green [SEP]']
[Init] best perm rec loss: 1.7130188941955566 for ['[CLS] received happens sampled command silk corrections as inclusive happens walked premiere northwest reads sun splinter legal peeragegu ground colonel ] comprehensive erin commercial green [SEP]']
[Init] best perm rec loss: 1.6906909942626953 for ['[CLS] erin silk received colonel legal commercial ground happens premiere commandgu northwest sampled green ] sun walked inclusive peerage splinter happens comprehensive reads as corrections [SEP]']
[Init] best perm rec loss: 1.6896693706512451 for ['[CLS] happens sampled received reads as corrections inclusivegu splinter commercial walked ground silk green legal ] comprehensive colonel peerage sun happens northwest command erin premiere [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.522 (perp=10.826, rec=0.342, cos=0.015), tot_loss_proj:2.905 [t=0.17s]
prediction: ['[CLS] blake century brought contribution.. new pull brought new liberal. corporate new texture. rc nu separate new server historia adventure strong feel [SEP]']
[ 100/2000] tot_loss=2.328 (perp=10.256, rec=0.267, cos=0.010), tot_loss_proj:2.789 [t=0.17s]
prediction: ['[CLS] new story brought contribution.. new texture gives conservative conservative found corporate new texture protection conservative delta hide new conservative movie challenge gave texture [SEP]']
[ 150/2000] tot_loss=2.417 (perp=10.980, rec=0.210, cos=0.010), tot_loss_proj:3.426 [t=0.17s]
prediction: ['[CLS] flap stories produced conservative.. new texture they conservative and finds governance the texture and most delta hide new hide movie adventure gives texture [SEP]']
[ 200/2000] tot_loss=2.311 (perp=10.625, rec=0.180, cos=0.005), tot_loss_proj:3.683 [t=0.17s]
prediction: ['[CLS] expansion story produced conservative.. new texture they conservative relevance finds governing the tradition and most delta hide - hide movie discovered gives reality [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.102 (perp=9.679, rec=0.161, cos=0.005), tot_loss_proj:3.140 [t=0.17s]
prediction: ['[CLS] expansion finds has traditions and. new texture it bradley relevance finds governing the traditions and most conservative hide, hide movie scene gives reality [SEP]']
[ 300/2000] tot_loss=2.113 (perp=9.759, rec=0.151, cos=0.010), tot_loss_proj:3.389 [t=0.17s]
prediction: ['[CLS] expansion finds and traditions and our new texture it bradley reality finds governing the traditions and most conservative hide, hide movie movie gives reality [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.958 (perp=9.130, rec=0.130, cos=0.002), tot_loss_proj:3.464 [t=0.17s]
prediction: ['[CLS] expansion hide and traditions and our new texture it bradley reality finds reality onebound and most conservative hide, new movie movie gives reality [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.893 (perp=8.843, rec=0.123, cos=0.002), tot_loss_proj:3.489 [t=0.17s]
prediction: ['[CLS] simply hide and traditions. our new texture it bradley reality finds reality one hidebound and most conservative, new movie movie gives reality [SEP]']
[ 450/2000] tot_loss=1.965 (perp=9.255, rec=0.112, cos=0.002), tot_loss_proj:3.483 [t=0.17s]
prediction: ['[CLS] simply hide and traditions. our new texture it bradley reality findsbound one hidebound and most conservative, new movie movie gives reality [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.840 (perp=8.674, rec=0.103, cos=0.002), tot_loss_proj:3.032 [t=0.17s]
prediction: ['[CLS] simply hidebound traditions. our new texture it bradley reality finds and one hidebound and most conservative, new movie movie gives reality [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.873 (perp=8.838, rec=0.104, cos=0.002), tot_loss_proj:3.132 [t=0.17s]
prediction: ['[CLS] and movie reality traditions. our new texture it bradley reality finds expansion one hidebound and most conservative, new movie realm gives reality [SEP]']
[ 600/2000] tot_loss=1.858 (perp=8.838, rec=0.089, cos=0.002), tot_loss_proj:3.125 [t=0.17s]
prediction: ['[CLS] and movie reality traditions. our new texture it bradley reality finds expansion one hidebound and most conservative, new movie realm gives reality [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.754 (perp=8.330, rec=0.087, cos=0.002), tot_loss_proj:3.011 [t=0.17s]
prediction: ['[CLS] and movie reality traditions. our new texture connections bradley reality finds it one hidebound and most conservative, new movie movie gives reality [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.812 (perp=8.660, rec=0.079, cos=0.001), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] and movie reality traditions. our new texture connections bradley reality finds it one hidebound and most conservative, new movieik gives reality [SEP]']
[ 750/2000] tot_loss=1.832 (perp=8.748, rec=0.081, cos=0.002), tot_loss_proj:3.101 [t=0.17s]
prediction: ['[CLS] and movie reality traditions. our new texture connections bradley reality finds it one hidebound and most conservative, new makingik gives reality [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.802 (perp=8.625, rec=0.075, cos=0.002), tot_loss_proj:2.965 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley reality finds it one hidebound and most conservative, new makingik gives reality [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.739 (perp=8.285, rec=0.081, cos=0.002), tot_loss_proj:3.031 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley reality finds it one hidebound and most conservative, new reality makingik gives [SEP]']
[ 900/2000] tot_loss=1.731 (perp=8.285, rec=0.073, cos=0.002), tot_loss_proj:3.028 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley reality finds it one hidebound and most conservative, new reality makingik gives [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.744 (perp=8.374, rec=0.068, cos=0.002), tot_loss_proj:3.199 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture event bradley reality finds it one hidebound and most conservative, new reality makingik gives [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.814 (perp=8.706, rec=0.072, cos=0.001), tot_loss_proj:2.777 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new event texture bradley reality finds it one hidebound and most conservative, new relevance makingik gives [SEP]']
[1050/2000] tot_loss=1.810 (perp=8.666, rec=0.075, cos=0.002), tot_loss_proj:2.575 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new connections texture bradley reality finds it one hidebound and most conservative, new relevance makingik gives [SEP]']
Attempt swap
[1100/2000] tot_loss=1.808 (perp=8.666, rec=0.073, cos=0.002), tot_loss_proj:2.581 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new connections texture bradley reality finds it one hidebound and most conservative, new relevance makingik gives [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.777 (perp=8.518, rec=0.072, cos=0.002), tot_loss_proj:2.721 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new connections texture bradley reality finds it one hidebound and most conservative, new relevanceik gives making [SEP]']
[1200/2000] tot_loss=1.775 (perp=8.518, rec=0.070, cos=0.002), tot_loss_proj:2.720 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new connections texture bradley reality finds it one hidebound and most conservative, new relevanceik gives making [SEP]']
Attempt swap
[1250/2000] tot_loss=1.784 (perp=8.518, rec=0.079, cos=0.002), tot_loss_proj:2.718 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new connections texture bradley reality finds it one hidebound and most conservative, new relevanceik gives making [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.742 (perp=8.336, rec=0.073, cos=0.002), tot_loss_proj:2.500 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new connections texture bradley reality finds making one hidebound and most conservative, new relevanceik gives it [SEP]']
[1350/2000] tot_loss=1.745 (perp=8.336, rec=0.076, cos=0.002), tot_loss_proj:2.500 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new connections texture bradley reality finds making one hidebound and most conservative, new relevanceik gives it [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.738 (perp=8.283, rec=0.080, cos=0.002), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley reality finds making one hidebound and most conservative, new relevanceik gives it [SEP]']
Attempt swap
[1450/2000] tot_loss=1.731 (perp=8.283, rec=0.073, cos=0.002), tot_loss_proj:2.579 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley reality finds making one hidebound and most conservative, new relevanceik gives it [SEP]']
[1500/2000] tot_loss=1.732 (perp=8.283, rec=0.074, cos=0.001), tot_loss_proj:2.582 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley reality finds making one hidebound and most conservative, new relevanceik gives it [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.722 (perp=8.278, rec=0.065, cos=0.002), tot_loss_proj:2.939 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley one finds making reality hidebound and most conservative, new relevanceik gives it [SEP]']
Attempt swap
[1600/2000] tot_loss=1.730 (perp=8.278, rec=0.073, cos=0.002), tot_loss_proj:2.941 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley one finds making reality hidebound and most conservative, new relevanceik gives it [SEP]']
[1650/2000] tot_loss=1.728 (perp=8.278, rec=0.071, cos=0.002), tot_loss_proj:2.939 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley one finds making reality hidebound and most conservative, new relevanceik gives it [SEP]']
Attempt swap
[1700/2000] tot_loss=1.732 (perp=8.278, rec=0.075, cos=0.002), tot_loss_proj:2.943 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley one finds making reality hidebound and most conservative, new relevanceik gives it [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.716 (perp=8.211, rec=0.073, cos=0.001), tot_loss_proj:2.810 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley one finds reality making hidebound and most conservative, new relevanceik gives it [SEP]']
[1800/2000] tot_loss=1.714 (perp=8.211, rec=0.071, cos=0.002), tot_loss_proj:2.812 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley one finds reality making hidebound and most conservative, new relevanceik gives it [SEP]']
Attempt swap
[1850/2000] tot_loss=1.711 (perp=8.211, rec=0.068, cos=0.002), tot_loss_proj:2.809 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley one finds reality making hidebound and most conservative, new relevanceik gives it [SEP]']
Attempt swap
[1900/2000] tot_loss=1.718 (perp=8.211, rec=0.075, cos=0.002), tot_loss_proj:2.810 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley one finds reality making hidebound and most conservative, new relevanceik gives it [SEP]']
[1950/2000] tot_loss=1.717 (perp=8.211, rec=0.074, cos=0.002), tot_loss_proj:2.816 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley one finds reality making hidebound and most conservative, new relevanceik gives it [SEP]']
Attempt swap
[2000/2000] tot_loss=1.716 (perp=8.211, rec=0.072, cos=0.001), tot_loss_proj:2.807 [t=0.17s]
prediction: ['[CLS] movie and reality traditions. our new texture connections bradley one finds reality making hidebound and most conservative, new relevanceik gives it [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] movie and reality traditions. our new texture connections bradley reality finds making one hidebound and most conservative, new relevanceik gives it [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.444 | p: 82.609 | r: 86.364
rouge2     | fm: 13.953 | p: 13.636 | r: 14.286
rougeL     | fm: 35.556 | p: 34.783 | r: 36.364
rougeLsum  | fm: 35.556 | p: 34.783 | r: 36.364
r1fm+r2fm = 98.398

[Aggregate metrics]:
rouge1     | fm: 90.660 | p: 90.619 | r: 90.772
rouge2     | fm: 53.434 | p: 53.302 | r: 53.517
rougeL     | fm: 77.825 | p: 77.841 | r: 77.887
rougeLsum  | fm: 77.343 | p: 77.411 | r: 77.386
r1fm+r2fm = 144.093

input #39 time: 0:06:54 | total time: 4:36:50


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9993178197074233
highest_index [0]
highest [0.9993178197074233]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 1.9793970584869385 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 1.7857263088226318 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 1.6468653678894043 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 1.6214605569839478 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 1.5489600896835327 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 1.5032769441604614 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 1.4233150482177734 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 1.3850464820861816 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 1.1546258926391602 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 1.1405655145645142 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 1.1383553743362427 for ['[CLS] deciding° but lady already kent georgian abd many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.875 (perp=12.775, rec=0.309, cos=0.011), tot_loss_proj:3.350 [t=0.17s]
prediction: ['[CLS] phone trail spit lipmmel printedony or stupid [SEP]']
[ 100/2000] tot_loss=2.392 (perp=10.938, rec=0.199, cos=0.005), tot_loss_proj:2.885 [t=0.17s]
prediction: ['[CLS] puony phonymmel printed music orony [SEP]']
[ 150/2000] tot_loss=2.211 (perp=10.286, rec=0.149, cos=0.004), tot_loss_proj:3.374 [t=0.17s]
prediction: ['[CLS] puony with pummel imagery music orony [SEP]']
[ 200/2000] tot_loss=2.174 (perp=10.231, rec=0.123, cos=0.004), tot_loss_proj:3.311 [t=0.17s]
prediction: ['[CLS] puony with pummel imagery imagery orony [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.778 (perp=8.174, rec=0.139, cos=0.004), tot_loss_proj:3.217 [t=0.17s]
prediction: ['[CLS] pu us with pummelony imagery or imagery [SEP]']
[ 300/2000] tot_loss=2.069 (perp=9.842, rec=0.099, cos=0.002), tot_loss_proj:3.352 [t=0.17s]
prediction: ['[CLS] pu us with phmmelony imagery or music [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.518 (perp=7.172, rec=0.083, cos=0.001), tot_loss_proj:1.504 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.496 (perp=7.172, rec=0.060, cos=0.001), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[ 450/2000] tot_loss=1.503 (perp=7.172, rec=0.067, cos=0.001), tot_loss_proj:1.516 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.494 (perp=7.172, rec=0.058, cos=0.001), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.497 (perp=7.172, rec=0.061, cos=0.001), tot_loss_proj:1.501 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[ 600/2000] tot_loss=1.500 (perp=7.172, rec=0.064, cos=0.001), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.502 (perp=7.172, rec=0.067, cos=0.001), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.494 (perp=7.172, rec=0.058, cos=0.001), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[ 750/2000] tot_loss=1.497 (perp=7.172, rec=0.061, cos=0.001), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.464 (perp=6.973, rec=0.068, cos=0.001), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.464 (perp=6.973, rec=0.068, cos=0.001), tot_loss_proj:1.501 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 900/2000] tot_loss=1.464 (perp=6.973, rec=0.068, cos=0.001), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.468 (perp=6.973, rec=0.072, cos=0.001), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.461 (perp=6.973, rec=0.065, cos=0.001), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1050/2000] tot_loss=1.462 (perp=6.973, rec=0.066, cos=0.001), tot_loss_proj:1.500 [t=0.18s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.507 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.467 (perp=6.973, rec=0.071, cos=0.001), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1200/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.461 (perp=6.973, rec=0.065, cos=0.001), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.508 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1350/2000] tot_loss=1.443 (perp=6.973, rec=0.047, cos=0.001), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=1.468 (perp=6.973, rec=0.072, cos=0.001), tot_loss_proj:1.501 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1500/2000] tot_loss=1.451 (perp=6.973, rec=0.055, cos=0.001), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.460 (perp=6.973, rec=0.064, cos=0.001), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.462 (perp=6.973, rec=0.066, cos=0.001), tot_loss_proj:1.508 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1650/2000] tot_loss=1.446 (perp=6.973, rec=0.050, cos=0.001), tot_loss_proj:1.513 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.451 (perp=6.973, rec=0.055, cos=0.001), tot_loss_proj:1.487 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.466 (perp=6.973, rec=0.070, cos=0.001), tot_loss_proj:1.500 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1800/2000] tot_loss=1.450 (perp=6.973, rec=0.054, cos=0.001), tot_loss_proj:1.494 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.455 (perp=6.973, rec=0.059, cos=0.001), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.462 (perp=6.973, rec=0.066, cos=0.001), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1950/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.497 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.453 (perp=6.973, rec=0.057, cos=0.001), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] pummel us with phony music or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 90.816 | p: 90.772 | r: 90.929
rouge2     | fm: 53.303 | p: 53.213 | r: 53.409
rougeL     | fm: 77.705 | p: 77.706 | r: 77.729
rougeLsum  | fm: 77.389 | p: 77.456 | r: 77.395
r1fm+r2fm = 144.120

input #40 time: 0:06:45 | total time: 4:43:36


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.999304507364323
highest_index [0]
highest [0.999304507364323]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 1.978039026260376 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 1.9309391975402832 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 1.8171615600585938 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 1.5979645252227783 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 1.5801717042922974 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 1.5212957859039307 for ['[CLS] hauntedrily [SEP]']
[Init] best rec loss: 1.4396042823791504 for ["[CLS]'classification [SEP]"]
[Init] best rec loss: 1.402101993560791 for ['[CLS] cale fate [SEP]']
[Init] best rec loss: 1.0926122665405273 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 1.0066304206848145 for ['[CLS] usa some [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.190 (perp=10.212, rec=0.144, cos=0.004), tot_loss_proj:2.114 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.122 (perp=10.212, rec=0.078, cos=0.002), tot_loss_proj:2.127 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.095 (perp=10.212, rec=0.051, cos=0.001), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.095 (perp=10.212, rec=0.051, cos=0.001), tot_loss_proj:2.117 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.100 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.102 (perp=10.212, rec=0.058, cos=0.001), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.107 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.102 (perp=10.212, rec=0.058, cos=0.001), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.111 (perp=10.212, rec=0.068, cos=0.001), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.108 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.107 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.087 (perp=10.212, rec=0.043, cos=0.001), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.108 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.112 (perp=10.212, rec=0.069, cos=0.001), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.091 (perp=10.212, rec=0.048, cos=0.001), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.106 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.104 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.113 (perp=10.212, rec=0.070, cos=0.001), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.121 (perp=10.212, rec=0.077, cos=0.001), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.108 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.094 (perp=10.212, rec=0.050, cos=0.001), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.096 (perp=10.212, rec=0.052, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.108 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.117 (perp=10.212, rec=0.073, cos=0.001), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.110 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.107 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.108 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.096 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.104 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.117 (perp=10.212, rec=0.073, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.154 | p: 90.996 | r: 91.251
rouge2     | fm: 54.388 | p: 54.282 | r: 54.454
rougeL     | fm: 78.214 | p: 78.220 | r: 78.279
rougeLsum  | fm: 78.029 | p: 78.014 | r: 78.048
r1fm+r2fm = 145.541

input #41 time: 0:06:48 | total time: 4:50:25


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9993257960966828
highest_index [0]
highest [0.9993257960966828]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 1.8863037824630737 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 1.4476348161697388 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 1.359115481376648 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 1.262780785560608 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 1.261205792427063 for ['[CLS] anymore read jersey pain / did felt outcomes water shitnagar brazil main subsidiarylde mp materials miami four fr wondering neither kingdom begun throne album [SEP]']
[Init] best rec loss: 1.1889172792434692 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 1.1876097917556763 for ['[CLS] liftedures ever dare kitchenrs attracted scale enough ran cut mapletaking bandabe treatygible international wishpling superseded stages larger assignmentctric offended [SEP]']
[Init] best perm rec loss: 1.1862833499908447 for ['[CLS] assignmentbe international ran dare ever offendedgibleuresrs enoughtaking wish treaty scale larger attracted cut maplepling superseded kitchenctric banda lifted stages [SEP]']
[Init] best perm rec loss: 1.1856108903884888 for ['[CLS] supersededtakingctric international cut lifted ranrs largerbe kitchenpling assignment enough banda offendedures maple wish treaty attracted scale ever stagesgible dare [SEP]']
[Init] best perm rec loss: 1.1850471496582031 for ['[CLS]taking attracted wish dare ran international offended stagesctric cut superseded largerbe assignment treatypling scalegible enoughures ever lifted maplers banda kitchen [SEP]']
[Init] best perm rec loss: 1.1792911291122437 for ['[CLS] dare ran stages mapleures superseded kitchen banda internationalpling largerrs scale attracted assignmentctric offendedbe wishgible lifted treaty enough ever cuttaking [SEP]']
[Init] best perm rec loss: 1.179050087928772 for ['[CLS] offended dareures banda enough assignment larger ever maplepling attractedctrictaking ran superseded international treaty scale lifted wish kitchenrsgible stages cutbe [SEP]']
[Init] best perm rec loss: 1.173161506652832 for ['[CLS] kitchenures treaty enough ran wish liftedrsbegible superseded scale stages cut dare assignment larger banda ever maple attractedctric offended internationalplingtaking [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.725 (perp=12.125, rec=0.290, cos=0.009), tot_loss_proj:3.136 [t=0.17s]
prediction: ['[CLS]. failure gum paper legislative as equipment on poorly they forgot forgot for removal nicole patent yiicide authorities officials immediately school forgot sorts policies there [SEP]']
[ 100/2000] tot_loss=2.563 (perp=11.759, rec=0.206, cos=0.005), tot_loss_proj:3.022 [t=0.17s]
prediction: ["[CLS]. poorly project'% as rally to poorly they forgot forgot for parade nicoledown assembly accidentally filmmakers they well school forgot larger situation portrait [SEP]"]
[ 150/2000] tot_loss=2.553 (perp=11.934, rec=0.162, cos=0.004), tot_loss_proj:3.045 [t=0.17s]
prediction: ["[CLS]. poorly project 'national as lineup including poorly anything halfway forgotgger attraction nicolegger ko lumpur filmmakers they poorly school forgot into setting into [SEP]"]
[ 200/2000] tot_loss=2.564 (perp=12.128, rec=0.135, cos=0.004), tot_loss_proj:3.118 [t=0.17s]
prediction: ["[CLS]. poorly project'gaulle asgger include poorly anything halfway forgotgger attraction scarygger jirricular filmmakers they poorly school forgotgger setting into [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.394 (perp=11.340, rec=0.123, cos=0.003), tot_loss_proj:2.955 [t=0.17s]
prediction: ["[CLS]. poorly project's asgger include attraction anything halfway forgot to attraction scary re jiji filmmakers they poorly school forgotgger setting into [SEP]"]
[ 300/2000] tot_loss=2.554 (perp=12.190, rec=0.113, cos=0.002), tot_loss_proj:3.119 [t=0.17s]
prediction: ['[CLS]. poorly project fire s asgger include attraction anything halfway halfway to attraction scary rejiji filmmakers they poorly school forgotgger setting into [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.320 (perp=11.048, rec=0.108, cos=0.002), tot_loss_proj:2.894 [t=0.19s]
prediction: ['[CLS]ji poorly project fire s asgger include attraction anything even halfway to scary scary reji. filmmakers they poorly school forgotgger setting into [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.285 (perp=10.799, rec=0.122, cos=0.003), tot_loss_proj:2.857 [t=0.19s]
prediction: ['[CLS]ji poorly project s asgger include attraction anything even halfway to fire scary scary reji. filmmakers they poorly school forgotgger setting into [SEP]']
[ 450/2000] tot_loss=2.264 (perp=10.799, rec=0.102, cos=0.002), tot_loss_proj:2.856 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include attraction anything even halfway to fire scary scary reji. filmmakers they poorly school forgotgger setting into [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.294 (perp=11.029, rec=0.086, cos=0.002), tot_loss_proj:2.878 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include attraction anything even halfway to fire scary halfway reji. they poorly school filmmakers forgotgger setting into [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.212 (perp=10.587, rec=0.092, cos=0.002), tot_loss_proj:2.742 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include attraction anything even halfway halfway fire scary to reji. they poorly school filmmakers forgotgger setting into [SEP]']
[ 600/2000] tot_loss=2.208 (perp=10.587, rec=0.089, cos=0.002), tot_loss_proj:2.754 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include attraction anything even halfway halfway fire scary to reji. they poorly school filmmakers forgotgger setting into [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.199 (perp=10.587, rec=0.079, cos=0.002), tot_loss_proj:2.746 [t=0.19s]
prediction: ['[CLS]ji poorly project s asgger include attraction anything even halfway halfway fire scary to reji. they poorly school filmmakers forgotgger setting into [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.180 (perp=10.443, rec=0.089, cos=0.002), tot_loss_proj:2.712 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include attraction anything even halfway halfway fire scary to reji. they poorly school filmmakers forgotgger into setting [SEP]']
[ 750/2000] tot_loss=2.375 (perp=11.477, rec=0.077, cos=0.002), tot_loss_proj:2.941 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include attraction anything even halfway halfway fire scary to reji fatal they poorly school filmmakers forgotgger into setting [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.287 (perp=10.977, rec=0.090, cos=0.002), tot_loss_proj:2.849 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include fatal attraction anything even halfway halfway fatal scary to reji they poorly school filmmakers forgotgger into setting [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.234 (perp=10.725, rec=0.087, cos=0.002), tot_loss_proj:2.811 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include fatal attraction anything even halfway fatal scary to reji halfway they poorly school filmmakers forgotgger into setting [SEP]']
[ 900/2000] tot_loss=2.224 (perp=10.725, rec=0.077, cos=0.002), tot_loss_proj:2.817 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include fatal attraction anything even halfway fatal scary to reji halfway they poorly school filmmakers forgotgger into setting [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.220 (perp=10.656, rec=0.087, cos=0.002), tot_loss_proj:2.795 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include fatal attraction anything even halfway fatal scary to reji poorly halfway they school filmmakers forgotgger into setting [SEP]']
Attempt swap
[1000/2000] tot_loss=2.213 (perp=10.656, rec=0.080, cos=0.002), tot_loss_proj:2.796 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include fatal attraction anything even halfway fatal scary to reji poorly halfway they school filmmakers forgotgger into setting [SEP]']
[1050/2000] tot_loss=2.216 (perp=10.656, rec=0.083, cos=0.002), tot_loss_proj:2.800 [t=0.17s]
prediction: ['[CLS]ji poorly project s asgger include fatal attraction anything even halfway fatal scary to reji poorly halfway they school filmmakers forgotgger into setting [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.198 (perp=10.552, rec=0.086, cos=0.002), tot_loss_proj:2.757 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to reji poorly as they school filmmakers forgotgger into setting [SEP]']
Attempt swap
[1150/2000] tot_loss=2.189 (perp=10.552, rec=0.077, cos=0.002), tot_loss_proj:2.758 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to reji poorly as they school filmmakers forgotgger into setting [SEP]']
[1200/2000] tot_loss=2.198 (perp=10.552, rec=0.086, cos=0.002), tot_loss_proj:2.763 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to reji poorly as they school filmmakers forgotgger into setting [SEP]']
Attempt swap
[1250/2000] tot_loss=2.197 (perp=10.552, rec=0.085, cos=0.002), tot_loss_proj:2.759 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to reji poorly as they school filmmakers forgotgger into setting [SEP]']
Attempt swap
[1300/2000] tot_loss=2.188 (perp=10.552, rec=0.076, cos=0.002), tot_loss_proj:2.761 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to reji poorly as they school filmmakers forgotgger into setting [SEP]']
[1350/2000] tot_loss=2.196 (perp=10.552, rec=0.084, cos=0.002), tot_loss_proj:2.758 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to reji poorly as they school filmmakers forgotgger into setting [SEP]']
Attempt swap
[1400/2000] tot_loss=2.197 (perp=10.552, rec=0.085, cos=0.002), tot_loss_proj:2.761 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to reji poorly as they school filmmakers forgotgger into setting [SEP]']
Attempt swap
[1450/2000] tot_loss=2.191 (perp=10.552, rec=0.078, cos=0.002), tot_loss_proj:2.764 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to reji poorly as they school filmmakers forgotgger into setting [SEP]']
[1500/2000] tot_loss=2.202 (perp=10.552, rec=0.089, cos=0.002), tot_loss_proj:2.762 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to reji poorly as they school filmmakers forgotgger into setting [SEP]']
Attempt swap
[1550/2000] tot_loss=2.197 (perp=10.552, rec=0.085, cos=0.002), tot_loss_proj:2.756 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to reji poorly as they school filmmakers forgotgger into setting [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.147 (perp=10.284, rec=0.088, cos=0.002), tot_loss_proj:2.644 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to rejigger as they school filmmakers forgot poorly into setting [SEP]']
[1650/2000] tot_loss=2.137 (perp=10.284, rec=0.078, cos=0.002), tot_loss_proj:2.647 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to rejigger as they school filmmakers forgot poorly into setting [SEP]']
Attempt swap
[1700/2000] tot_loss=2.130 (perp=10.284, rec=0.072, cos=0.002), tot_loss_proj:2.644 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to rejigger as they school filmmakers forgot poorly into setting [SEP]']
Attempt swap
[1750/2000] tot_loss=2.134 (perp=10.284, rec=0.076, cos=0.002), tot_loss_proj:2.649 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to rejigger as they school filmmakers forgot poorly into setting [SEP]']
[1800/2000] tot_loss=2.148 (perp=10.284, rec=0.089, cos=0.002), tot_loss_proj:2.648 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to rejigger as they school filmmakers forgot poorly into setting [SEP]']
Attempt swap
[1850/2000] tot_loss=2.140 (perp=10.284, rec=0.082, cos=0.002), tot_loss_proj:2.646 [t=0.17s]
prediction: ['[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to rejigger as they school filmmakers forgot poorly into setting [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.109 (perp=10.136, rec=0.080, cos=0.002), tot_loss_proj:2.609 [t=0.17s]
prediction: ['[CLS]ji poorly project s poorlygger include fatal attraction anything even halfway fatal scary to rejigger as they school filmmakers forgot halfway into setting [SEP]']
[1950/2000] tot_loss=2.108 (perp=10.136, rec=0.079, cos=0.002), tot_loss_proj:2.606 [t=0.17s]
prediction: ['[CLS]ji poorly project s poorlygger include fatal attraction anything even halfway fatal scary to rejigger as they school filmmakers forgot halfway into setting [SEP]']
Attempt swap
[2000/2000] tot_loss=2.108 (perp=10.136, rec=0.079, cos=0.002), tot_loss_proj:2.605 [t=0.17s]
prediction: ['[CLS]ji poorly project s poorlygger include fatal attraction anything even halfway fatal scary to rejigger as they school filmmakers forgot halfway into setting [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS]ji poorly project s halfwaygger include fatal attraction anything even halfway fatal scary to rejigger as they school filmmakers forgot poorly into setting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 84.000 | r: 87.500
rouge2     | fm: 29.787 | p: 29.167 | r: 30.435
rougeL     | fm: 57.143 | p: 56.000 | r: 58.333
rougeLsum  | fm: 57.143 | p: 56.000 | r: 58.333
r1fm+r2fm = 115.502

[Aggregate metrics]:
rouge1     | fm: 91.011 | p: 90.914 | r: 91.150
rouge2     | fm: 53.830 | p: 53.776 | r: 53.949
rougeL     | fm: 77.773 | p: 77.756 | r: 77.835
rougeLsum  | fm: 77.408 | p: 77.414 | r: 77.490
r1fm+r2fm = 144.841

input #42 time: 0:07:06 | total time: 4:57:31


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9992732655805339
highest_index [0]
highest [0.9992732655805339]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 1.9562627077102661 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 1.9224357604980469 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 1.7678141593933105 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 1.59369695186615 for ['[CLS] emma " companyographer [SEP]']
[Init] best rec loss: 1.452473521232605 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 1.360077977180481 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 1.2800770998001099 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 1.1548054218292236 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 1.0956354141235352 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 1.0862125158309937 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 1.082431435585022 for ['[CLS] secondckbus climb [SEP]']
[Init] best perm rec loss: 1.0786867141723633 for ['[CLS]ck secondbus climb [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.445 (perp=10.973, rec=0.245, cos=0.006), tot_loss_proj:3.215 [t=0.17s]
prediction: ['[CLS] naististic na [SEP]']
[ 100/2000] tot_loss=2.430 (perp=11.440, rec=0.139, cos=0.003), tot_loss_proj:2.814 [t=0.17s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 150/2000] tot_loss=2.366 (perp=11.400, rec=0.083, cos=0.002), tot_loss_proj:3.048 [t=0.17s]
prediction: ['[CLS] narcisticiss [SEP]']
[ 200/2000] tot_loss=2.349 (perp=11.400, rec=0.067, cos=0.002), tot_loss_proj:3.053 [t=0.17s]
prediction: ['[CLS] narcisticiss [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.078 (perp=5.048, rec=0.066, cos=0.002), tot_loss_proj:1.074 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.088 (perp=5.048, rec=0.077, cos=0.002), tot_loss_proj:1.078 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.082 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.063 (perp=5.048, rec=0.052, cos=0.002), tot_loss_proj:1.079 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.082 (perp=5.048, rec=0.071, cos=0.002), tot_loss_proj:1.082 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.085 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.060 (perp=5.048, rec=0.049, cos=0.001), tot_loss_proj:1.068 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.068 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.061 (perp=5.048, rec=0.050, cos=0.001), tot_loss_proj:1.085 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.072 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.082 (perp=5.048, rec=0.071, cos=0.001), tot_loss_proj:1.076 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.077 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.086 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.001), tot_loss_proj:1.076 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.073 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.074 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.078 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.077 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.081 (perp=5.048, rec=0.070, cos=0.001), tot_loss_proj:1.080 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.062 (perp=5.048, rec=0.051, cos=0.001), tot_loss_proj:1.088 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.062 (perp=5.048, rec=0.051, cos=0.001), tot_loss_proj:1.084 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.060 (perp=5.048, rec=0.049, cos=0.001), tot_loss_proj:1.081 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.064 (perp=5.048, rec=0.053, cos=0.001), tot_loss_proj:1.084 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.076 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.078 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.086 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.074 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.070 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.082 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.059 (perp=5.048, rec=0.048, cos=0.001), tot_loss_proj:1.077 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.090 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.064 (perp=5.048, rec=0.053, cos=0.001), tot_loss_proj:1.074 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.062 (perp=5.048, rec=0.051, cos=0.001), tot_loss_proj:1.085 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.078 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.066 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.081 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.069 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.086 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.077 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.075 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.081 (perp=5.048, rec=0.070, cos=0.001), tot_loss_proj:1.077 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.166 | p: 91.102 | r: 91.383
rouge2     | fm: 55.136 | p: 55.051 | r: 55.263
rougeL     | fm: 78.280 | p: 78.221 | r: 78.367
rougeLsum  | fm: 78.046 | p: 78.029 | r: 78.086
r1fm+r2fm = 146.302

input #43 time: 0:06:55 | total time: 5:04:26


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9992417534706349
highest_index [0]
highest [0.9992417534706349]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.8814524412155151 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.8753631114959717 for ['[CLS] here supporters psycho fighting at portal seconds published break store among color telegramachcing applicable stress tow ways been cervical landing wrists makes grew code dale visual crowley [SEP]']
[Init] best rec loss: 1.6184682846069336 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 1.566756248474121 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best rec loss: 1.5660165548324585 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best rec loss: 1.525803565979004 for ['[CLS] reservesdicated friendly sole rurallda counselan signals spec jamie americas foot emigrated tied [MASK] dex comfortdating artillery meditation joinednard readings eve solo ukraine why offspring [SEP]']
[Init] best perm rec loss: 1.5225293636322021 for ['[CLS] artillery [MASK] ukrainedatingnard signals joined sole friendly readings why counsel jamiedicated spec reserves offspring tied dex solo americaslda meditationan foot eve emigrated rural comfort [SEP]']
[Init] best perm rec loss: 1.5178302526474 for ['[CLS] foot friendlynard artillery why [MASK] meditation ukraine americasdicated comfortdating eve signals emigrated sole offspring reservesan joined tied rural jamielda dex counsel solo readings spec [SEP]']
[Init] best perm rec loss: 1.5158740282058716 for ['[CLS] comfort why meditation reserves signals counsel readings ukraine dex emigrated joined jamienarddating tied rural artillery americas friendlylda eve offspring [MASK]dicated solo foot solean spec [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.229 (perp=10.026, rec=0.217, cos=0.007), tot_loss_proj:2.968 [t=0.18s]
prediction: ['[CLS] lostism has its lost the translation was lost telegraph... magber the montreal routine translation ª horror the behavior screenplay routine routine.denary [SEP]']
[ 100/2000] tot_loss=2.250 (perp=10.508, rec=0.145, cos=0.003), tot_loss_proj:2.763 [t=0.19s]
prediction: ['[CLS] frightism has execution lost in translation been lostalic...izes another the execution routinealicizes fright another grief screenplay routine routine.ization took [SEP]']
[ 150/2000] tot_loss=2.228 (perp=9.722, rec=0.271, cos=0.012), tot_loss_proj:2.880 [t=0.19s]
prediction: ['[CLS] fright for has its lost in translation been slackalic. his.izes where thefest routinealicizes hollywood another pest hollywood another routine.ismbf [SEP]']
[ 200/2000] tot_loss=2.272 (perp=10.443, rec=0.178, cos=0.006), tot_loss_proj:2.926 [t=0.18s]
prediction: ['[CLS] fraud execution has premise lost in translation been slack slack. the.izes in the execution routinealic hollywood fright another fright crazy the routine.ism are [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.976 (perp=9.185, rec=0.136, cos=0.003), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] slack execution has premise lost in translation been slack slack. the.izes in thefest routinealic hollywood fright another fright fright. the routineism of [SEP]']
[ 300/2000] tot_loss=2.135 (perp=10.058, rec=0.121, cos=0.003), tot_loss_proj:2.664 [t=0.17s]
prediction: ['[CLS] slack ligue has premise lost in translation been slackalic.ire.izes in thefest routinealic hollywood fright another fright fright. the routineism of [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.093 (perp=9.791, rec=0.131, cos=0.003), tot_loss_proj:2.482 [t=0.19s]
prediction: ['[CLS] slack segunda has been lost in translation premise the slack.ª.izes in whichfest routinealic hollywood fright another fright fright. the routine denounced the [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.970 (perp=9.236, rec=0.120, cos=0.002), tot_loss_proj:2.455 [t=0.17s]
prediction: ['[CLS] slack intended has been lost in translation premise thealic.tage.izes in whichfest routinealic another fright hollywood fright fright. the routineism. [SEP]']
[ 450/2000] tot_loss=1.970 (perp=9.332, rec=0.101, cos=0.002), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] slack intended has been lost in translation premise thealic.tage.izes in whichfest routinealic another fright hollywood frightence. the routineism. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.874 (perp=8.821, rec=0.108, cos=0.002), tot_loss_proj:2.332 [t=0.17s]
prediction: ['[CLS] slack intended has been lost in translation premise.alic thetage.izes in whichfest routinealic another fright hollywood frightence. the routineism. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.818 (perp=8.552, rec=0.105, cos=0.002), tot_loss_proj:2.270 [t=0.17s]
prediction: ['[CLS] slack ∨ has been lost in translation premise.alicizes the fright. in whichfest routinealic another fright hollywood slackence. the routineism. [SEP]']
[ 600/2000] tot_loss=1.834 (perp=8.659, rec=0.100, cos=0.002), tot_loss_proj:2.270 [t=0.17s]
prediction: ['[CLS] slack ¡ has been lost in translation premise.alicizes the fright. in whichfest routinealic another fright hollywood slackence. the routineism. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.791 (perp=8.407, rec=0.107, cos=0.002), tot_loss_proj:2.180 [t=0.18s]
prediction: ['[CLS] slack ¡ has been lost in translation premise.alicizes the fright. in whichfest another routine execution fright hollywood slackence. the routineism. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.851 (perp=8.603, rec=0.128, cos=0.003), tot_loss_proj:2.262 [t=0.17s]
prediction: ['[CLS] slack its has been lost in translation premise.alicizes the fright.. whichfest another routine the fright hollywood slackislaus. execution routineism. [SEP]']
[ 750/2000] tot_loss=1.808 (perp=8.499, rec=0.105, cos=0.002), tot_loss_proj:2.225 [t=0.17s]
prediction: ['[CLS] slack its has been lost in translation premise.alicizes the fright. in whichfest another routine the fright hollywood slackislaus. execution routineism. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.783 (perp=8.389, rec=0.103, cos=0.002), tot_loss_proj:2.213 [t=0.19s]
prediction: ['[CLS] slack its has been lost in translation premise.alicizes the fright. infest another routine which the fright hollywood slackislaus. execution routineism. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.805 (perp=8.494, rec=0.104, cos=0.002), tot_loss_proj:2.226 [t=0.17s]
prediction: ['[CLS] slack the has been lost in translation premise.alicizes the fright. infest another routine which the fright hollywood slackislaus its execution routineism. [SEP]']
[ 900/2000] tot_loss=1.792 (perp=8.494, rec=0.091, cos=0.002), tot_loss_proj:2.234 [t=0.17s]
prediction: ['[CLS] slack the has been lost in translation premise.alicizes the fright. infest another routine which the fright hollywood slackislaus its execution routineism. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.693 (perp=7.967, rec=0.097, cos=0.002), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] slack the has been lost in translation premise.alicizes the fright infest another routine which the fright hollywood. slackislaus its execution routineism. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.686 (perp=7.968, rec=0.090, cos=0.002), tot_loss_proj:2.157 [t=0.17s]
prediction: ['[CLS] slack which has been lost in translation premise.alicizes the fright infest another routine the the fright hollywood. slackislaus its execution routinet. [SEP]']
[1050/2000] tot_loss=1.687 (perp=7.899, rec=0.105, cos=0.002), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] slack which has been lost in translation premise.alicizes the fright infest another routine the the fright hollywood. slackerty its execution routinet. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.678 (perp=7.899, rec=0.097, cos=0.002), tot_loss_proj:2.139 [t=0.17s]
prediction: ['[CLS] slack which has been lost in translation premise.alicizes the fright infest another routine the the fright hollywood. slackerty its execution routinet. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.724 (perp=8.163, rec=0.089, cos=0.002), tot_loss_proj:2.163 [t=0.17s]
prediction: ['[CLS] slack which has been lost in translation premise.alicizes the fright.fest another routine. the fright hollywood the slackerty its execution routinet. [SEP]']
[1200/2000] tot_loss=1.718 (perp=8.124, rec=0.091, cos=0.002), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS] slack which has been lost in translation premise.alicizes the fright.fest another routine. the fright hollywood the slackility its execution routinet. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.648 (perp=7.776, rec=0.090, cos=0.002), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] slack which has been lost in translation premise. anotherizes the fright infestalic routine. the fright hollywood the slackerty its execution routinet. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.638 (perp=7.703, rec=0.095, cos=0.002), tot_loss_proj:2.072 [t=0.17s]
prediction: ['[CLS] slack which has been lost in translation premise. anotherizes the fright infestalic routine. the fright hollywood the slackility its execution routinet. [SEP]']
[1350/2000] tot_loss=1.630 (perp=7.703, rec=0.088, cos=0.002), tot_loss_proj:2.080 [t=0.17s]
prediction: ['[CLS] slack which has been lost in translation premise. anotherizes the fright infestalic routine. the fright hollywood the slackility its execution routinet. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.601 (perp=7.544, rec=0.090, cos=0.002), tot_loss_proj:2.057 [t=0.17s]
prediction: ['[CLS] slack which has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frightility its execution routinet. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.579 (perp=7.417, rec=0.094, cos=0.002), tot_loss_proj:2.144 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frighterty its execution routinet. [SEP]']
[1500/2000] tot_loss=1.580 (perp=7.417, rec=0.095, cos=0.002), tot_loss_proj:2.148 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frighterty its execution routinet. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.576 (perp=7.417, rec=0.091, cos=0.002), tot_loss_proj:2.149 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frighterty its execution routinet. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.573 (perp=7.417, rec=0.088, cos=0.002), tot_loss_proj:2.145 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frighterty its execution routinet. [SEP]']
[1650/2000] tot_loss=1.593 (perp=7.514, rec=0.089, cos=0.002), tot_loss_proj:2.172 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frightility its execution routinet. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.592 (perp=7.514, rec=0.088, cos=0.002), tot_loss_proj:2.178 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frightility its execution routinet. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.591 (perp=7.514, rec=0.087, cos=0.002), tot_loss_proj:2.175 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frightility its execution routinet. [SEP]']
[1800/2000] tot_loss=1.586 (perp=7.514, rec=0.082, cos=0.002), tot_loss_proj:2.168 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frightility its execution routinet. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.595 (perp=7.514, rec=0.091, cos=0.002), tot_loss_proj:2.177 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frightility its execution routinet. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.595 (perp=7.514, rec=0.091, cos=0.002), tot_loss_proj:2.176 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frightility its execution routinet. [SEP]']
[1950/2000] tot_loss=1.586 (perp=7.514, rec=0.082, cos=0.002), tot_loss_proj:2.174 [t=0.17s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frightility its execution routinet. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.590 (perp=7.514, rec=0.086, cos=0.002), tot_loss_proj:2.178 [t=0.20s]
prediction: ['[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frightility its execution routinet. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] which slack has been lost in translation premise. anotherizes the fright infestalic routine. the slack hollywood the frightility its execution routinet. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 69.565 | r: 69.565
rouge2     | fm: 18.182 | p: 18.182 | r: 18.182
rougeL     | fm: 47.826 | p: 47.826 | r: 47.826
rougeLsum  | fm: 47.826 | p: 47.826 | r: 47.826
r1fm+r2fm = 87.747

[Aggregate metrics]:
rouge1     | fm: 90.695 | p: 90.635 | r: 90.851
rouge2     | fm: 53.951 | p: 53.814 | r: 54.068
rougeL     | fm: 77.639 | p: 77.576 | r: 77.756
rougeLsum  | fm: 77.290 | p: 77.287 | r: 77.368
r1fm+r2fm = 144.646

input #44 time: 0:06:57 | total time: 5:11:24


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9993986811377396
highest_index [0]
highest [0.9993986811377396]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 1.9465147256851196 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 1.6877418756484985 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 1.6227409839630127 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 1.6042251586914062 for ['[CLS] folk rankedgistmetric furthereto herself pac stamp ma jaya descent foremost, case 11 simon installment marie it wizard lucivar sync mcbadscu keepers stable [SEP]']
[Init] best rec loss: 1.388287901878357 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 1.2057594060897827 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 1.2009996175765991 for ['[CLS] murmured tree whoa special taste five singletiv bore operated2 via football joan ku skin around enclosed ( letter gentry curtis v status military entrancelanda few [SEP]']
[Init] best perm rec loss: 1.1984952688217163 for ['[CLS] tree via gentry football taste operated skin ( status2 single bore curtis militarytiv murmured few ku five whoa special letter around v entrance joan enclosedlanda [SEP]']
[Init] best perm rec loss: 1.1982824802398682 for ['[CLS] entrance2 around v whoa tree status ku football murmured enclosedtiv taste joan military curtis ( bore few via letter single five special operatedlanda gentry skin [SEP]']
[Init] best perm rec loss: 1.1930371522903442 for ['[CLS] bore whoa fivelanda2 skin gentry militarytiv around single tree operated taste curtis few letter special murmured ku football entrance status joan ( v enclosed via [SEP]']
[Init] best perm rec loss: 1.1888641119003296 for ['[CLS] curtis bore status taste gentry enclosed via skin ( letter five tree single whoa2 murmured entrancelanda v ku military joan few around operated footballtiv special [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.778 (perp=12.205, rec=0.326, cos=0.011), tot_loss_proj:3.907 [t=0.17s]
prediction: ['[CLS] burnett seanr butch - sculptures jockey -, he use page regional wounds shelf tu left style lateral base crossed japanese pink undernare football across opinion [SEP]']
[ 100/2000] tot_loss=2.540 (perp=11.492, rec=0.236, cos=0.006), tot_loss_proj:3.240 [t=0.17s]
prediction: ['[CLS] than - - fiction - than bow -, this significance picked - bow shelf tu bow - murder allegedly shelf platform hostog shelf - exercise movements [SEP]']
[ 150/2000] tot_loss=1.793 (perp=8.073, rec=0.175, cos=0.003), tot_loss_proj:2.479 [t=0.17s]
prediction: ['[CLS] than - - - - movements bowel - on - - this bow shelf bow bow - crime exercise shoot - bowick shelf - exercise movements [SEP]']
[ 200/2000] tot_loss=1.819 (perp=8.421, rec=0.132, cos=0.002), tot_loss_proj:2.628 [t=0.17s]
prediction: ['[CLS] than - - - - movements bowel - on - - this bow shelf bow of - crime shoot shoot - giick shelf - exerciseel [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.727 (perp=8.022, rec=0.120, cos=0.002), tot_loss_proj:2.510 [t=0.20s]
prediction: ['[CLS] thanel - - - movements bowel - on - - this bow shelf bow of - crime shoot shoot - gimm shelf crime exercise - [SEP]']
[ 300/2000] tot_loss=1.809 (perp=8.452, rec=0.116, cos=0.003), tot_loss_proj:2.696 [t=0.19s]
prediction: ['[CLS] thanel - - - movements bowel - on long - this shoot shelf bow in - crime shoot drama - gimm shelf crime exercise - [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.057 (perp=8.719, rec=0.298, cos=0.016), tot_loss_proj:2.697 [t=0.20s]
prediction: ['[CLS] thanel - ª and movements bowel - on kill - this ী shelf the - - - shoot drama - gimmick crime exerciseman [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.051 (perp=9.330, rec=0.182, cos=0.003), tot_loss_proj:2.864 [t=0.18s]
prediction: ['[CLS] thanel and / - movements bowel - on matter - this ী shelf the - - - shoot drama - gimming crime exercisea [SEP]']
[ 450/2000] tot_loss=2.018 (perp=9.365, rec=0.142, cos=0.003), tot_loss_proj:2.905 [t=0.17s]
prediction: ['[CLS] thanel and / - movements bowel - on matter - this ী shelf the - - - shoot drama - gimming crime exercise secretly [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.890 (perp=8.776, rec=0.133, cos=0.002), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] thanel - / - movements bowel - on matter and this ী shelf the - - - shoot drama - gimmy crime exercise via [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.784 (perp=8.220, rec=0.137, cos=0.003), tot_loss_proj:2.622 [t=0.17s]
prediction: ['[CLS] thanel - / - movements bowel - on matter and shelf shoot this the - - - shoot drama - gimmy crime exercise via [SEP]']
[ 600/2000] tot_loss=1.742 (perp=8.084, rec=0.123, cos=0.002), tot_loss_proj:2.582 [t=0.21s]
prediction: ['[CLS] thanel - / - movements bowel - on long and shelf up this the - - - shoot drama - gimmy crime exercise via [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.679 (perp=7.811, rec=0.115, cos=0.002), tot_loss_proj:2.352 [t=0.17s]
prediction: ['[CLS] thanel - / - movements bowel - on the and shelf up this long - - - shoot drama - gimmy crime exercise via [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.586 (perp=7.357, rec=0.112, cos=0.002), tot_loss_proj:2.280 [t=0.17s]
prediction: ['[CLS] thanel - - - movements bowel - on the and shelf up this long - - - shoot drama - gimmy crime exercise via [SEP]']
[ 750/2000] tot_loss=1.585 (perp=7.357, rec=0.112, cos=0.002), tot_loss_proj:2.272 [t=0.17s]
prediction: ['[CLS] thanel - - - movements bowel - on the and shelf up this long - - - shoot drama - gimmy crime exercise via [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.581 (perp=7.357, rec=0.108, cos=0.002), tot_loss_proj:2.271 [t=0.17s]
prediction: ['[CLS] thanel - - - movements bowel - on the and shelf up this long - - - shoot drama - gimmy crime exercise via [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.727 (perp=8.077, rec=0.109, cos=0.002), tot_loss_proj:2.540 [t=0.17s]
prediction: ['[CLS] thanel give - - movements bowel - on the and shelf up this long - - - shoot drama - gimmy crime exercise slater [SEP]']
[ 900/2000] tot_loss=1.739 (perp=8.169, rec=0.103, cos=0.002), tot_loss_proj:2.614 [t=0.17s]
prediction: ['[CLS] thanel give - - movements bowel - on in and shelf up this long - - - shoot drama - gimmy crime exercise slater [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.610 (perp=7.446, rec=0.118, cos=0.002), tot_loss_proj:2.287 [t=0.17s]
prediction: ['[CLS] thanel - - - movements bowel - on - and shelf shoot this long - - - shoot drama - gimmy crime exercise in [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.552 (perp=7.174, rec=0.115, cos=0.002), tot_loss_proj:2.309 [t=0.17s]
prediction: ['[CLS] thanel in - - movements bowel - on - and shelf shoot this long - - - shoot drama - gimmy crime exercise - [SEP]']
[1050/2000] tot_loss=1.620 (perp=7.557, rec=0.107, cos=0.002), tot_loss_proj:2.458 [t=0.17s]
prediction: ['[CLS] thanel in - - movements bowel - on - and shelf shoot this long - - - shoot drama - gimmy crime exercise give [SEP]']
Attempt swap
[1100/2000] tot_loss=1.619 (perp=7.557, rec=0.105, cos=0.002), tot_loss_proj:2.460 [t=0.17s]
prediction: ['[CLS] thanel in - - movements bowel - on - and shelf shoot this long - - - shoot drama - gimmy crime exercise give [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.577 (perp=7.332, rec=0.109, cos=0.002), tot_loss_proj:2.506 [t=0.17s]
prediction: ['[CLS] thanel in - - movements bowel - on - shoot this long - - and shelf - shoot drama - gimmy crime exercise give [SEP]']
[1200/2000] tot_loss=1.572 (perp=7.332, rec=0.104, cos=0.002), tot_loss_proj:2.509 [t=0.17s]
prediction: ['[CLS] thanel in - - movements bowel - on - shoot this long - - and shelf - shoot drama - gimmy crime exercise give [SEP]']
Attempt swap
[1250/2000] tot_loss=1.564 (perp=7.332, rec=0.096, cos=0.002), tot_loss_proj:2.510 [t=0.17s]
prediction: ['[CLS] thanel in - - movements bowel - on - shoot this long - - and shelf - shoot drama - gimmy crime exercise give [SEP]']
Attempt swap
[1300/2000] tot_loss=1.570 (perp=7.332, rec=0.102, cos=0.002), tot_loss_proj:2.509 [t=0.17s]
prediction: ['[CLS] thanel in - - movements bowel - on - shoot this long - - and shelf - shoot drama - gimmy crime exercise give [SEP]']
[1350/2000] tot_loss=1.574 (perp=7.332, rec=0.106, cos=0.002), tot_loss_proj:2.508 [t=0.17s]
prediction: ['[CLS] thanel in - - movements bowel - on - shoot this long - - and shelf - shoot drama - gimmy crime exercise give [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.537 (perp=7.174, rec=0.100, cos=0.002), tot_loss_proj:2.344 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel - on - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.528 (perp=7.130, rec=0.101, cos=0.002), tot_loss_proj:2.384 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
[1500/2000] tot_loss=1.536 (perp=7.130, rec=0.109, cos=0.001), tot_loss_proj:2.382 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
Attempt swap
[1550/2000] tot_loss=1.524 (perp=7.130, rec=0.097, cos=0.001), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
Attempt swap
[1600/2000] tot_loss=1.526 (perp=7.130, rec=0.099, cos=0.001), tot_loss_proj:2.386 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
[1650/2000] tot_loss=1.529 (perp=7.130, rec=0.102, cos=0.001), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
Attempt swap
[1700/2000] tot_loss=1.525 (perp=7.130, rec=0.097, cos=0.001), tot_loss_proj:2.384 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
Attempt swap
[1750/2000] tot_loss=1.530 (perp=7.130, rec=0.102, cos=0.001), tot_loss_proj:2.383 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
[1800/2000] tot_loss=1.519 (perp=7.130, rec=0.092, cos=0.001), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
Attempt swap
[1850/2000] tot_loss=1.516 (perp=7.130, rec=0.088, cos=0.001), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
Attempt swap
[1900/2000] tot_loss=1.528 (perp=7.130, rec=0.100, cos=0.001), tot_loss_proj:2.384 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
[1950/2000] tot_loss=1.518 (perp=7.130, rec=0.091, cos=0.001), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.486 (perp=6.934, rec=0.098, cos=0.001), tot_loss_proj:2.309 [t=0.17s]
prediction: ['[CLS] giveel in - - movements on bowel - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] giveel in - - movements bowel on - - shoot this long - - and shelf - shoot drama - gimmy crime exercise than [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 5.882 | p: 5.882 | r: 5.882
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 89.216

[Aggregate metrics]:
rouge1     | fm: 90.537 | p: 90.442 | r: 90.632
rouge2     | fm: 53.035 | p: 52.955 | r: 53.077
rougeL     | fm: 76.891 | p: 76.867 | r: 76.943
rougeLsum  | fm: 76.644 | p: 76.637 | r: 76.716
r1fm+r2fm = 143.572

input #45 time: 0:06:56 | total time: 5:18:21


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9992703548035418
highest_index [0]
highest [0.9992703548035418]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 1.990432858467102 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 1.9770787954330444 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 1.9074907302856445 for ['[CLS]ch believed councils panel law battery [SEP]']
[Init] best rec loss: 1.7174855470657349 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 1.7164666652679443 for ['[CLS] adaptedator shell whether ordinary convincing [SEP]']
[Init] best rec loss: 1.6811225414276123 for ['[CLS] sank including privately heritage surfaced falcon [SEP]']
[Init] best rec loss: 1.6083678007125854 for ['[CLS]sur darius ontario avery never lives [SEP]']
[Init] best perm rec loss: 1.6035552024841309 for ['[CLS] darius neversur avery lives ontario [SEP]']
[Init] best perm rec loss: 1.6031556129455566 for ['[CLS] neversur darius avery ontario lives [SEP]']
[Init] best perm rec loss: 1.5998085737228394 for ['[CLS] never dariussur avery lives ontario [SEP]']
[Init] best perm rec loss: 1.5986922979354858 for ['[CLS]sur lives darius avery never ontario [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.811 (perp=13.207, rec=0.167, cos=0.003), tot_loss_proj:3.397 [t=0.19s]
prediction: ['[CLS] patient staged striking slick slick visually [SEP]']
[ 100/2000] tot_loss=2.773 (perp=13.207, rec=0.129, cos=0.003), tot_loss_proj:3.389 [t=0.17s]
prediction: ['[CLS] patient staged striking slick slick visually [SEP]']
[ 150/2000] tot_loss=2.417 (perp=11.521, rec=0.110, cos=0.002), tot_loss_proj:3.036 [t=0.17s]
prediction: ['[CLS]ous staged striking slick slick visually [SEP]']
[ 200/2000] tot_loss=2.446 (perp=11.742, rec=0.095, cos=0.002), tot_loss_proj:2.953 [t=0.19s]
prediction: ['[CLS]ity staged striking slick slick visually [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.892 (perp=9.007, rec=0.089, cos=0.002), tot_loss_proj:2.069 [t=0.17s]
prediction: ['[CLS]ity visually striking slickly staged [SEP]']
[ 300/2000] tot_loss=1.884 (perp=9.007, rec=0.081, cos=0.002), tot_loss_proj:2.070 [t=0.17s]
prediction: ['[CLS]ity visually striking slickly staged [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.705 (perp=8.136, rec=0.076, cos=0.002), tot_loss_proj:1.988 [t=0.17s]
prediction: ['[CLS] visually striking details slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.713 (perp=8.136, rec=0.084, cos=0.002), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] visually striking details slickly staged [SEP]']
[ 450/2000] tot_loss=1.706 (perp=8.136, rec=0.077, cos=0.002), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] visually striking details slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.700 (perp=8.136, rec=0.071, cos=0.002), tot_loss_proj:1.982 [t=0.18s]
prediction: ['[CLS] visually striking details slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.709 (perp=8.136, rec=0.080, cos=0.002), tot_loss_proj:1.985 [t=0.17s]
prediction: ['[CLS] visually striking details slickly staged [SEP]']
[ 600/2000] tot_loss=1.705 (perp=8.136, rec=0.076, cos=0.002), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] visually striking details slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.702 (perp=8.136, rec=0.073, cos=0.002), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS] visually striking details slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.703 (perp=8.136, rec=0.074, cos=0.002), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] visually striking details slickly staged [SEP]']
[ 750/2000] tot_loss=1.698 (perp=8.136, rec=0.070, cos=0.002), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] visually striking details slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.703 (perp=8.136, rec=0.074, cos=0.002), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] visually striking details slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.498 (perp=7.175, rec=0.062, cos=0.002), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] visually striking when slickly staged [SEP]']
[ 900/2000] tot_loss=1.520 (perp=7.175, rec=0.083, cos=0.002), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] visually striking when slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.515 (perp=7.175, rec=0.078, cos=0.002), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] visually striking when slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.268 (perp=5.916, rec=0.083, cos=0.002), tot_loss_proj:1.252 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.257 (perp=5.916, rec=0.072, cos=0.002), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.259 (perp=5.916, rec=0.074, cos=0.002), tot_loss_proj:1.265 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.256 (perp=5.916, rec=0.072, cos=0.002), tot_loss_proj:1.257 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.002), tot_loss_proj:1.247 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.263 (perp=5.916, rec=0.079, cos=0.002), tot_loss_proj:1.246 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.002), tot_loss_proj:1.247 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.256 (perp=5.916, rec=0.071, cos=0.002), tot_loss_proj:1.258 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.261 (perp=5.916, rec=0.076, cos=0.002), tot_loss_proj:1.251 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.265 (perp=5.916, rec=0.080, cos=0.002), tot_loss_proj:1.245 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.262 (perp=5.916, rec=0.077, cos=0.002), tot_loss_proj:1.243 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.256 (perp=5.916, rec=0.071, cos=0.002), tot_loss_proj:1.246 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.002), tot_loss_proj:1.255 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.002), tot_loss_proj:1.247 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.250 (perp=5.916, rec=0.065, cos=0.002), tot_loss_proj:1.246 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.262 (perp=5.916, rec=0.077, cos=0.002), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.002), tot_loss_proj:1.249 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.260 (perp=5.916, rec=0.075, cos=0.002), tot_loss_proj:1.246 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.254 (perp=5.916, rec=0.069, cos=0.002), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.262 (perp=5.916, rec=0.077, cos=0.002), tot_loss_proj:1.245 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.267 (perp=5.916, rec=0.082, cos=0.002), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.731 | p: 90.653 | r: 90.863
rouge2     | fm: 54.239 | p: 54.156 | r: 54.333
rougeL     | fm: 77.352 | p: 77.345 | r: 77.403
rougeLsum  | fm: 77.054 | p: 77.010 | r: 77.145
r1fm+r2fm = 144.970

input #46 time: 0:06:44 | total time: 5:25:06


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9992059059142622
highest_index [0]
highest [0.9992059059142622]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 1.1954387426376343 for ['[CLS] all cup royce [SEP]']
[Init] best perm rec loss: 1.1952502727508545 for ['[CLS] cup all royce [SEP]']
[Init] best perm rec loss: 1.1847620010375977 for ['[CLS] all royce cup [SEP]']
[Init] best perm rec loss: 1.1834989786148071 for ['[CLS] royce all cup [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.745 (perp=12.488, rec=0.225, cos=0.023), tot_loss_proj:3.391 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 100/2000] tot_loss=2.661 (perp=12.488, rec=0.141, cos=0.023), tot_loss_proj:3.430 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=2.628 (perp=12.488, rec=0.110, cos=0.020), tot_loss_proj:3.463 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 200/2000] tot_loss=2.617 (perp=12.488, rec=0.114, cos=0.006), tot_loss_proj:3.472 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.637 (perp=12.488, rec=0.124, cos=0.015), tot_loss_proj:3.490 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 300/2000] tot_loss=2.615 (perp=12.488, rec=0.110, cos=0.007), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.604 (perp=12.488, rec=0.101, cos=0.005), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.723 (perp=13.122, rec=0.090, cos=0.008), tot_loss_proj:3.642 [t=0.17s]
prediction: ['[CLS]right transparent down [SEP]']
[ 450/2000] tot_loss=2.744 (perp=13.122, rec=0.106, cos=0.013), tot_loss_proj:3.626 [t=0.18s]
prediction: ['[CLS]right transparent down [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.879 (perp=8.803, rec=0.077, cos=0.041), tot_loss_proj:1.899 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.831 (perp=8.803, rec=0.067, cos=0.003), tot_loss_proj:1.919 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.828 (perp=8.803, rec=0.064, cos=0.003), tot_loss_proj:1.908 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.837 (perp=8.803, rec=0.071, cos=0.006), tot_loss_proj:1.905 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.823 (perp=8.803, rec=0.059, cos=0.003), tot_loss_proj:1.897 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.820 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.908 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.828 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.823 (perp=8.803, rec=0.061, cos=0.001), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.820 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.903 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.839 (perp=8.803, rec=0.077, cos=0.001), tot_loss_proj:1.908 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.832 (perp=8.803, rec=0.070, cos=0.002), tot_loss_proj:1.918 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.817 (perp=8.803, rec=0.054, cos=0.002), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.819 (perp=8.803, rec=0.057, cos=0.002), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.816 (perp=8.803, rec=0.054, cos=0.002), tot_loss_proj:1.906 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.830 (perp=8.803, rec=0.068, cos=0.002), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.823 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.825 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.913 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.814 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.828 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.915 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.808 (perp=8.803, rec=0.046, cos=0.002), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.820 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.823 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.817 (perp=8.803, rec=0.055, cos=0.002), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.832 (perp=8.803, rec=0.070, cos=0.002), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.822 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.821 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.906 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.928 | p: 90.807 | r: 91.097
rouge2     | fm: 55.450 | p: 55.344 | r: 55.545
rougeL     | fm: 77.957 | p: 77.911 | r: 77.989
rougeLsum  | fm: 77.625 | p: 77.552 | r: 77.642
r1fm+r2fm = 146.378

input #47 time: 0:06:49 | total time: 5:31:56


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9993046234064709
highest_index [0]
highest [0.9993046234064709]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 1.6311019659042358 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 1.61383056640625 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 1.5250935554504395 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 1.266484260559082 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 1.1338359117507935 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 1.1290621757507324 for ['[CLS] graveyardtutedine runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.572 (perp=12.071, rec=0.153, cos=0.005), tot_loss_proj:2.703 [t=0.17s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 100/2000] tot_loss=2.514 (perp=12.071, rec=0.097, cos=0.002), tot_loss_proj:2.698 [t=0.17s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 150/2000] tot_loss=2.871 (perp=13.991, rec=0.072, cos=0.001), tot_loss_proj:3.091 [t=0.17s]
prediction: ['[CLS] rotting underybell [SEP]']
[ 200/2000] tot_loss=2.865 (perp=13.991, rec=0.065, cos=0.001), tot_loss_proj:3.091 [t=0.17s]
prediction: ['[CLS] rotting underybell [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.485 (perp=7.108, rec=0.062, cos=0.001), tot_loss_proj:1.490 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 300/2000] tot_loss=1.484 (perp=7.108, rec=0.061, cos=0.001), tot_loss_proj:1.474 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.483 (perp=7.108, rec=0.060, cos=0.001), tot_loss_proj:1.489 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.473 (perp=7.108, rec=0.050, cos=0.001), tot_loss_proj:1.480 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 450/2000] tot_loss=1.491 (perp=7.108, rec=0.068, cos=0.001), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.483 (perp=7.108, rec=0.060, cos=0.001), tot_loss_proj:1.468 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.482 (perp=7.108, rec=0.059, cos=0.001), tot_loss_proj:1.477 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 600/2000] tot_loss=1.482 (perp=7.108, rec=0.059, cos=0.001), tot_loss_proj:1.477 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.487 (perp=7.108, rec=0.064, cos=0.001), tot_loss_proj:1.483 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.476 (perp=7.108, rec=0.053, cos=0.001), tot_loss_proj:1.474 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 750/2000] tot_loss=1.477 (perp=7.108, rec=0.054, cos=0.001), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.489 (perp=7.108, rec=0.066, cos=0.001), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.476 (perp=7.108, rec=0.053, cos=0.001), tot_loss_proj:1.480 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[ 900/2000] tot_loss=1.492 (perp=7.108, rec=0.069, cos=0.001), tot_loss_proj:1.479 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.485 (perp=7.108, rec=0.062, cos=0.001), tot_loss_proj:1.479 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.487 (perp=7.108, rec=0.064, cos=0.001), tot_loss_proj:1.478 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1050/2000] tot_loss=1.476 (perp=7.108, rec=0.053, cos=0.001), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.486 (perp=7.108, rec=0.063, cos=0.001), tot_loss_proj:1.489 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.484 (perp=7.108, rec=0.061, cos=0.001), tot_loss_proj:1.485 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1200/2000] tot_loss=1.480 (perp=7.108, rec=0.058, cos=0.001), tot_loss_proj:1.493 [t=0.19s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.469 (perp=7.108, rec=0.046, cos=0.001), tot_loss_proj:1.478 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.484 (perp=7.108, rec=0.061, cos=0.001), tot_loss_proj:1.478 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1350/2000] tot_loss=1.478 (perp=7.108, rec=0.055, cos=0.001), tot_loss_proj:1.481 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.483 (perp=7.108, rec=0.060, cos=0.001), tot_loss_proj:1.480 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.474 (perp=7.108, rec=0.051, cos=0.001), tot_loss_proj:1.476 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1500/2000] tot_loss=1.498 (perp=7.108, rec=0.075, cos=0.001), tot_loss_proj:1.493 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.496 (perp=7.108, rec=0.073, cos=0.001), tot_loss_proj:1.480 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.479 (perp=7.108, rec=0.056, cos=0.001), tot_loss_proj:1.485 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1650/2000] tot_loss=1.489 (perp=7.108, rec=0.066, cos=0.001), tot_loss_proj:1.494 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.497 (perp=7.108, rec=0.074, cos=0.001), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.494 (perp=7.108, rec=0.071, cos=0.001), tot_loss_proj:1.478 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1800/2000] tot_loss=1.487 (perp=7.108, rec=0.064, cos=0.001), tot_loss_proj:1.489 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.491 (perp=7.108, rec=0.069, cos=0.001), tot_loss_proj:1.466 [t=0.17s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.488 (perp=7.108, rec=0.066, cos=0.001), tot_loss_proj:1.481 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
[1950/2000] tot_loss=1.482 (perp=7.108, rec=0.059, cos=0.001), tot_loss_proj:1.481 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.471 (perp=7.108, rec=0.048, cos=0.001), tot_loss_proj:1.496 [t=0.18s]
prediction: ['[CLS] rotting underbelly [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] rotting underbelly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.084 | p: 91.032 | r: 91.223
rouge2     | fm: 56.036 | p: 55.903 | r: 56.150
rougeL     | fm: 78.356 | p: 78.330 | r: 78.391
rougeLsum  | fm: 78.095 | p: 78.087 | r: 78.171
r1fm+r2fm = 147.120

input #48 time: 0:06:48 | total time: 5:38:44


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9992285770800434
highest_index [0]
highest [0.9992285770800434]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 1.508844017982483 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 1.4430917501449585 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 1.4197598695755005 for ['[CLS] chargesbered harsh today dion craftsuvenssen tool break backup guest [SEP]']
[Init] best rec loss: 1.3730542659759521 for ['[CLS] evolved [SEP] armed desert silence rugby peering officers down did society quarter [SEP]']
[Init] best rec loss: 1.3694813251495361 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 1.316090703010559 for ['[CLS] chair assured dick fine chance household every expect boat couple freestyleerly [SEP]']
[Init] best rec loss: 1.3142051696777344 for ['[CLS] pyrenees answered bowling riding chloe minus bo language attentionocating nataya [SEP]']
[Init] best rec loss: 1.313950538635254 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 1.296747088432312 for ['[CLS] awareness sort domestic roles challenge @rifiedound optical family pass numbers [SEP]']
[Init] best rec loss: 1.296575665473938 for ['[CLS] londonrst victoria traded host dear free rided letting technicallytagram [SEP]']
[Init] best perm rec loss: 1.2936689853668213 for ['[CLS] ride technically dear free londonrsttagram victoria lettingd traded host [SEP]']
[Init] best perm rec loss: 1.292286992073059 for ['[CLS] letting victoria hosttagramrst dear ride free london tradedd technically [SEP]']
[Init] best perm rec loss: 1.2903485298156738 for ['[CLS] ride free technically hosttagramrst london victoria dear lettingd traded [SEP]']
[Init] best perm rec loss: 1.2879154682159424 for ['[CLS] technicallyrst dear host victoria traded london lettingtagram free rided [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.721 (perp=12.009, rec=0.295, cos=0.024), tot_loss_proj:3.428 [t=0.20s]
prediction: ['[CLS] categoryuid female though words changed female single personal more contempt contempt [SEP]']
[ 100/2000] tot_loss=2.437 (perp=11.229, rec=0.183, cos=0.008), tot_loss_proj:3.252 [t=0.18s]
prediction: ['[CLS] on population female could verb johnson female population could more contempt contempt [SEP]']
[ 150/2000] tot_loss=2.385 (perp=11.153, rec=0.147, cos=0.007), tot_loss_proj:3.140 [t=0.17s]
prediction: ['[CLS] of single female coulduous tri female population be moreuous contempt [SEP]']
[ 200/2000] tot_loss=2.382 (perp=11.339, rec=0.110, cos=0.005), tot_loss_proj:3.196 [t=0.17s]
prediction: ['[CLS] of single female coulduous prefer could population be moreuous contempt [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.011 (perp=9.487, rec=0.110, cos=0.004), tot_loss_proj:2.745 [t=0.17s]
prediction: ['[CLS] of single female coulduous¤ could population be more contemptuous [SEP]']
[ 300/2000] tot_loss=2.002 (perp=9.487, rec=0.101, cos=0.004), tot_loss_proj:2.749 [t=0.17s]
prediction: ['[CLS] of single female coulduous¤ could population be more contemptuous [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.879 (perp=8.841, rec=0.105, cos=0.006), tot_loss_proj:2.415 [t=0.17s]
prediction: ['[CLS] of single female could possiblyciful population could be more contemptuous [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.738 (perp=8.175, rec=0.099, cos=0.004), tot_loss_proj:2.306 [t=0.20s]
prediction: ['[CLS] of single female could possibly interact population could be more contemptuous [SEP]']
[ 450/2000] tot_loss=1.737 (perp=8.175, rec=0.099, cos=0.003), tot_loss_proj:2.309 [t=0.17s]
prediction: ['[CLS] of single female could possibly interact population could be more contemptuous [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.771 (perp=8.392, rec=0.090, cos=0.003), tot_loss_proj:2.425 [t=0.17s]
prediction: ['[CLS] of single female could possibly interact population. be more contemptuous [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.672 (perp=7.202, rec=0.208, cos=0.024), tot_loss_proj:2.218 [t=0.17s]
prediction: ['[CLS] population of single female could possibly interact, be more contemptuous [SEP]']
[ 600/2000] tot_loss=1.643 (perp=7.533, rec=0.132, cos=0.005), tot_loss_proj:2.205 [t=0.17s]
prediction: ['[CLS] population of single female could possibly interact. be more contemptuous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.606 (perp=7.533, rec=0.096, cos=0.003), tot_loss_proj:2.202 [t=0.17s]
prediction: ['[CLS] population of single female could possibly interact. be more contemptuous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.611 (perp=7.533, rec=0.101, cos=0.003), tot_loss_proj:2.193 [t=0.17s]
prediction: ['[CLS] population of single female could possibly interact. be more contemptuous [SEP]']
[ 750/2000] tot_loss=1.603 (perp=7.533, rec=0.094, cos=0.003), tot_loss_proj:2.197 [t=0.17s]
prediction: ['[CLS] population of single female could possibly interact. be more contemptuous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.606 (perp=7.533, rec=0.097, cos=0.003), tot_loss_proj:2.204 [t=0.17s]
prediction: ['[CLS] population of single female could possibly interact. be more contemptuous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.606 (perp=7.533, rec=0.096, cos=0.003), tot_loss_proj:2.199 [t=0.19s]
prediction: ['[CLS] population of single female could possibly interact. be more contemptuous [SEP]']
[ 900/2000] tot_loss=1.623 (perp=7.533, rec=0.109, cos=0.008), tot_loss_proj:2.198 [t=0.21s]
prediction: ['[CLS] population of single female could possibly interact. be more contemptuous [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.757 (perp=7.366, rec=0.242, cos=0.042), tot_loss_proj:2.069 [t=0.18s]
prediction: ['[CLS] population of single female could typically interact be more contemptuous. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.621 (perp=6.951, rec=0.209, cos=0.022), tot_loss_proj:1.950 [t=0.19s]
prediction: ['[CLS] population of single female interact typically could be more contemptuous. [SEP]']
[1050/2000] tot_loss=1.582 (perp=6.951, rec=0.176, cos=0.016), tot_loss_proj:1.949 [t=0.20s]
prediction: ['[CLS] population of single female interact typically could be more contemptuous. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.535 (perp=6.809, rec=0.160, cos=0.013), tot_loss_proj:1.900 [t=0.17s]
prediction: ['[CLS] population of single female interact could typically be more contemptuous. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.526 (perp=6.809, rec=0.153, cos=0.012), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] population of single female interact could typically be more contemptuous. [SEP]']
[1200/2000] tot_loss=1.459 (perp=6.495, rec=0.150, cos=0.011), tot_loss_proj:1.844 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.456 (perp=6.495, rec=0.148, cos=0.010), tot_loss_proj:1.844 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.445 (perp=6.495, rec=0.137, cos=0.009), tot_loss_proj:1.844 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
[1350/2000] tot_loss=1.446 (perp=6.495, rec=0.138, cos=0.009), tot_loss_proj:1.843 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.443 (perp=6.495, rec=0.135, cos=0.009), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.445 (perp=6.495, rec=0.138, cos=0.008), tot_loss_proj:1.845 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
[1500/2000] tot_loss=1.440 (perp=6.495, rec=0.133, cos=0.008), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.434 (perp=6.495, rec=0.127, cos=0.008), tot_loss_proj:1.840 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.429 (perp=6.495, rec=0.123, cos=0.008), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
[1650/2000] tot_loss=1.427 (perp=6.495, rec=0.121, cos=0.007), tot_loss_proj:1.843 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.430 (perp=6.495, rec=0.123, cos=0.007), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.440 (perp=6.495, rec=0.134, cos=0.007), tot_loss_proj:1.854 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
[1800/2000] tot_loss=1.429 (perp=6.495, rec=0.123, cos=0.007), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.441 (perp=6.495, rec=0.135, cos=0.007), tot_loss_proj:1.849 [t=0.19s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.429 (perp=6.495, rec=0.123, cos=0.007), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
[1950/2000] tot_loss=1.429 (perp=6.495, rec=0.123, cos=0.007), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.428 (perp=6.495, rec=0.122, cos=0.007), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] population of single female interact could possibly be more contemptuous. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] population of single female could possibly interact. be more contemptuous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 58.333 | p: 58.333 | r: 58.333
rougeLsum  | fm: 58.333 | p: 58.333 | r: 58.333
r1fm+r2fm = 128.030

[Aggregate metrics]:
rouge1     | fm: 91.137 | p: 91.048 | r: 91.284
rouge2     | fm: 55.758 | p: 55.660 | r: 55.866
rougeL     | fm: 77.861 | p: 77.851 | r: 77.916
rougeLsum  | fm: 77.550 | p: 77.543 | r: 77.609
r1fm+r2fm = 146.895

input #49 time: 0:06:58 | total time: 5:45:42


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.9992840964591766
highest_index [0]
highest [0.9992840964591766]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 1.7681097984313965 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 1.5493779182434082 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 1.5217300653457642 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 1.4632673263549805 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best rec loss: 1.4029443264007568 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best perm rec loss: 1.401523470878601 for ['[CLS] associated fueled trustok rama sq napkin gall unit [SEP]']
[Init] best perm rec loss: 1.40097177028656 for ['[CLS]ok gall napkin associated fueled sq trust unit rama [SEP]']
[Init] best perm rec loss: 1.3933467864990234 for ['[CLS] gall sq napkin trust fueled unit ramaok associated [SEP]']
[Init] best perm rec loss: 1.3920629024505615 for ['[CLS] napkinok trust unit gall fueled rama sq associated [SEP]']
[Init] best perm rec loss: 1.3910012245178223 for ['[CLS] unit gall associated sq fueled napkinok rama trust [SEP]']
[Init] best perm rec loss: 1.3904179334640503 for ['[CLS] trust sq unit gallok associated napkin rama fueled [SEP]']
[Init] best perm rec loss: 1.390091061592102 for ['[CLS] gall napkin unit fueled associated sqok trust rama [SEP]']
[Init] best perm rec loss: 1.3895784616470337 for ['[CLS] unit gall napkin associated sq trustok fueled rama [SEP]']
[Init] best perm rec loss: 1.3889405727386475 for ['[CLS] unit gall trust fueledok sq associated napkin rama [SEP]']
[Init] best perm rec loss: 1.3880995512008667 for ['[CLS] fueled gall napkin unit sq trustok associated rama [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.994 (perp=12.662, rec=0.403, cos=0.058), tot_loss_proj:4.162 [t=0.17s]
prediction: ['[CLS] curtiss peak law on chance liability thorpe english clever [SEP]']
[ 100/2000] tot_loss=2.815 (perp=12.361, rec=0.320, cos=0.022), tot_loss_proj:3.727 [t=0.17s]
prediction: ['[CLS] huntington call hello on chance too fastest english clever [SEP]']
[ 150/2000] tot_loss=2.708 (perp=11.911, rec=0.290, cos=0.037), tot_loss_proj:3.466 [t=0.17s]
prediction: ['[CLS] what call hello on chance too fastest english clever [SEP]']
[ 200/2000] tot_loss=2.575 (perp=11.740, rec=0.217, cos=0.010), tot_loss_proj:3.945 [t=0.17s]
prediction: ['[CLS] what call hello ` chance too by english clever [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.280 (perp=10.512, rec=0.170, cos=0.008), tot_loss_proj:3.691 [t=0.17s]
prediction: ["[CLS] what'call ` ` too by english clever [SEP]"]
[ 300/2000] tot_loss=2.137 (perp=10.005, rec=0.130, cos=0.006), tot_loss_proj:2.719 [t=0.17s]
prediction: ['[CLS] what the call half ` too by english clever [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.956 (perp=9.261, rec=0.100, cos=0.003), tot_loss_proj:2.533 [t=0.17s]
prediction: ['[CLS] what the call half too ` by english clever [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.864 (perp=8.881, rec=0.085, cos=0.003), tot_loss_proj:2.688 [t=0.17s]
prediction: ['[CLS] what a half call too ` by english clever [SEP]']
[ 450/2000] tot_loss=1.855 (perp=8.881, rec=0.077, cos=0.002), tot_loss_proj:2.686 [t=0.17s]
prediction: ['[CLS] what a half call too ` by english clever [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.858 (perp=8.881, rec=0.079, cos=0.002), tot_loss_proj:2.683 [t=0.17s]
prediction: ['[CLS] what a half call too ` by english clever [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.822 (perp=8.715, rec=0.077, cos=0.002), tot_loss_proj:2.636 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
[ 600/2000] tot_loss=1.819 (perp=8.715, rec=0.074, cos=0.002), tot_loss_proj:2.635 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.822 (perp=8.715, rec=0.077, cos=0.002), tot_loss_proj:2.637 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.815 (perp=8.715, rec=0.070, cos=0.002), tot_loss_proj:2.636 [t=0.20s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
[ 750/2000] tot_loss=1.814 (perp=8.715, rec=0.069, cos=0.002), tot_loss_proj:2.635 [t=0.20s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.820 (perp=8.715, rec=0.075, cos=0.002), tot_loss_proj:2.638 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.820 (perp=8.715, rec=0.075, cos=0.002), tot_loss_proj:2.633 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
[ 900/2000] tot_loss=1.817 (perp=8.715, rec=0.072, cos=0.002), tot_loss_proj:2.631 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.817 (perp=8.715, rec=0.072, cos=0.002), tot_loss_proj:2.633 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.819 (perp=8.715, rec=0.074, cos=0.002), tot_loss_proj:2.632 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
[1050/2000] tot_loss=1.815 (perp=8.715, rec=0.071, cos=0.002), tot_loss_proj:2.637 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.821 (perp=8.715, rec=0.076, cos=0.002), tot_loss_proj:2.635 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.819 (perp=8.715, rec=0.074, cos=0.002), tot_loss_proj:2.631 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
[1200/2000] tot_loss=1.811 (perp=8.715, rec=0.066, cos=0.002), tot_loss_proj:2.631 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.812 (perp=8.715, rec=0.067, cos=0.002), tot_loss_proj:2.632 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.819 (perp=8.715, rec=0.074, cos=0.002), tot_loss_proj:2.631 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
[1350/2000] tot_loss=1.821 (perp=8.715, rec=0.076, cos=0.002), tot_loss_proj:2.632 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.811 (perp=8.715, rec=0.066, cos=0.002), tot_loss_proj:2.629 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.818 (perp=8.715, rec=0.072, cos=0.004), tot_loss_proj:2.631 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
[1500/2000] tot_loss=1.811 (perp=8.715, rec=0.066, cos=0.002), tot_loss_proj:2.629 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.824 (perp=8.715, rec=0.078, cos=0.002), tot_loss_proj:2.625 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.816 (perp=8.715, rec=0.070, cos=0.002), tot_loss_proj:2.626 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
[1650/2000] tot_loss=1.821 (perp=8.715, rec=0.075, cos=0.002), tot_loss_proj:2.627 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1700/2000] tot_loss=1.822 (perp=8.715, rec=0.077, cos=0.002), tot_loss_proj:2.626 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.812 (perp=8.715, rec=0.067, cos=0.002), tot_loss_proj:2.626 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
[1800/2000] tot_loss=1.816 (perp=8.715, rec=0.071, cos=0.002), tot_loss_proj:2.627 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.816 (perp=8.715, rec=0.071, cos=0.002), tot_loss_proj:2.628 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.817 (perp=8.715, rec=0.072, cos=0.002), tot_loss_proj:2.623 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
[1950/2000] tot_loss=1.824 (perp=8.715, rec=0.079, cos=0.002), tot_loss_proj:2.627 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.816 (perp=8.715, rec=0.071, cos=0.002), tot_loss_proj:2.623 [t=0.17s]
prediction: ['[CLS] what the half call too ` by english clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what the half call too ` by english clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 91.364 | p: 91.261 | r: 91.502
rouge2     | fm: 55.320 | p: 55.227 | r: 55.375
rougeL     | fm: 77.707 | p: 77.674 | r: 77.761
rougeLsum  | fm: 77.618 | p: 77.572 | r: 77.684
r1fm+r2fm = 146.684

input #50 time: 0:06:49 | total time: 5:52:31


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9992548315433463
highest_index [0]
highest [0.9992548315433463]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 1.5581773519515991 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 1.3123705387115479 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 1.2994669675827026 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 1.2463165521621704 for ['[CLS] nationals offense - vaguely world justine domesticished majorage [SEP]']
[Init] best rec loss: 1.2434269189834595 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 1.1884088516235352 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 1.1509753465652466 for ['[CLS] include plants hole abuse especially multiple fingers & since accepting [SEP]']
[Init] best perm rec loss: 1.1506011486053467 for ['[CLS] accepting hole multiple since abuse especially plants & include fingers [SEP]']
[Init] best perm rec loss: 1.1483800411224365 for ['[CLS] multiple accepting hole especially include since & fingers abuse plants [SEP]']
[Init] best perm rec loss: 1.1480402946472168 for ['[CLS] accepting plants include especially since multiple & fingers hole abuse [SEP]']
[Init] best perm rec loss: 1.146215558052063 for ['[CLS] multiple especially accepting since abuse & hole fingers plants include [SEP]']
[Init] best perm rec loss: 1.1452608108520508 for ['[CLS] multiple especially accepting since & plants hole fingers include abuse [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.892 (perp=12.244, rec=0.369, cos=0.074), tot_loss_proj:3.521 [t=0.17s]
prediction: ['[CLS] stopped fun... but funny frederick sucks sucks sucks multiple [SEP]']
[ 100/2000] tot_loss=2.124 (perp=9.215, rec=0.258, cos=0.022), tot_loss_proj:2.989 [t=0.17s]
prediction: ['[CLS] kept sucks, but funny knows sucks somewhere funny moment [SEP]']
[ 150/2000] tot_loss=2.168 (perp=9.779, rec=0.197, cos=0.015), tot_loss_proj:3.038 [t=0.17s]
prediction: ['[CLS] kept sucks ; but funny knows sucks somewhere funny moment [SEP]']
[ 200/2000] tot_loss=2.114 (perp=9.764, rec=0.152, cos=0.010), tot_loss_proj:2.685 [t=0.17s]
prediction: ['[CLS] has sucks but has funny knows sucks or funny moment [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.991 (perp=9.252, rec=0.130, cos=0.010), tot_loss_proj:3.293 [t=0.17s]
prediction: ['[CLS] has thrill but has funny crazy sucks or funny moment [SEP]']
[ 300/2000] tot_loss=2.004 (perp=9.410, rec=0.115, cos=0.008), tot_loss_proj:3.358 [t=0.17s]
prediction: ['[CLS], thrill but has funny funny sucks or funny moment [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.898 (perp=8.914, rec=0.107, cos=0.008), tot_loss_proj:2.956 [t=0.17s]
prediction: ['[CLS], but has thrill funny sad sucks or funny moment [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.859 (perp=8.726, rec=0.107, cos=0.007), tot_loss_proj:2.872 [t=0.17s]
prediction: ['[CLS], but thrill has funny sad sucks or funny moment [SEP]']
[ 450/2000] tot_loss=1.963 (perp=9.296, rec=0.100, cos=0.004), tot_loss_proj:2.938 [t=0.17s]
prediction: ['[CLS], but thrill has funny two sucks or funny moment [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.602 (perp=7.494, rec=0.100, cos=0.004), tot_loss_proj:2.714 [t=0.17s]
prediction: ['[CLS], but thrill has a funny sucks or funny moment [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.586 (perp=7.422, rec=0.098, cos=0.004), tot_loss_proj:2.333 [t=0.17s]
prediction: ['[CLS], but has or a funny sucks or funny moment [SEP]']
[ 600/2000] tot_loss=1.581 (perp=7.422, rec=0.093, cos=0.003), tot_loss_proj:2.324 [t=0.17s]
prediction: ['[CLS], but has or a funny sucks or funny moment [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.467 (perp=6.855, rec=0.093, cos=0.004), tot_loss_proj:2.360 [t=0.17s]
prediction: ['[CLS], but has or a funny or funny moment sucks [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.347 (perp=6.268, rec=0.088, cos=0.005), tot_loss_proj:2.390 [t=0.17s]
prediction: ['[CLS], but has a funny or funny moment or sucks [SEP]']
[ 750/2000] tot_loss=1.348 (perp=6.268, rec=0.092, cos=0.003), tot_loss_proj:2.383 [t=0.17s]
prediction: ['[CLS], but has a funny or funny moment or sucks [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.343 (perp=6.268, rec=0.086, cos=0.003), tot_loss_proj:2.387 [t=0.17s]
prediction: ['[CLS], but has a funny or funny moment or sucks [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.475 (perp=6.950, rec=0.082, cos=0.003), tot_loss_proj:2.287 [t=0.17s]
prediction: ['[CLS], but has a cause or funny moment or sucks [SEP]']
[ 900/2000] tot_loss=1.472 (perp=6.950, rec=0.079, cos=0.003), tot_loss_proj:2.285 [t=0.17s]
prediction: ['[CLS], but has a cause or funny moment or sucks [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.625 (perp=7.649, rec=0.092, cos=0.003), tot_loss_proj:2.593 [t=0.17s]
prediction: ['[CLS], but has a cause or funny moment would sucks [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.519 (perp=7.155, rec=0.083, cos=0.004), tot_loss_proj:2.235 [t=0.18s]
prediction: ['[CLS], but has a sucks or funny moment would cause [SEP]']
[1050/2000] tot_loss=1.524 (perp=7.155, rec=0.090, cos=0.003), tot_loss_proj:2.236 [t=0.18s]
prediction: ['[CLS], but has a sucks or funny moment would cause [SEP]']
Attempt swap
[1100/2000] tot_loss=1.521 (perp=7.155, rec=0.086, cos=0.003), tot_loss_proj:2.240 [t=0.17s]
prediction: ['[CLS], but has a sucks or funny moment would cause [SEP]']
Attempt swap
[1150/2000] tot_loss=1.519 (perp=7.155, rec=0.085, cos=0.003), tot_loss_proj:2.243 [t=0.17s]
prediction: ['[CLS], but has a sucks or funny moment would cause [SEP]']
[1200/2000] tot_loss=1.526 (perp=7.155, rec=0.092, cos=0.003), tot_loss_proj:2.240 [t=0.17s]
prediction: ['[CLS], but has a sucks or funny moment would cause [SEP]']
Attempt swap
[1250/2000] tot_loss=1.524 (perp=7.155, rec=0.090, cos=0.003), tot_loss_proj:2.233 [t=0.17s]
prediction: ['[CLS], but has a sucks or funny moment would cause [SEP]']
Attempt swap
[1300/2000] tot_loss=1.516 (perp=7.155, rec=0.082, cos=0.003), tot_loss_proj:2.237 [t=0.17s]
prediction: ['[CLS], but has a sucks or funny moment would cause [SEP]']
[1350/2000] tot_loss=1.521 (perp=7.155, rec=0.086, cos=0.003), tot_loss_proj:2.236 [t=0.17s]
prediction: ['[CLS], but has a sucks or funny moment would cause [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.476 (perp=6.932, rec=0.086, cos=0.003), tot_loss_proj:2.240 [t=0.17s]
prediction: ['[CLS], but has sucks or a funny moment would cause [SEP]']
Attempt swap
[1450/2000] tot_loss=1.478 (perp=6.932, rec=0.088, cos=0.003), tot_loss_proj:2.240 [t=0.17s]
prediction: ['[CLS], but has sucks or a funny moment would cause [SEP]']
[1500/2000] tot_loss=1.478 (perp=6.932, rec=0.088, cos=0.003), tot_loss_proj:2.241 [t=0.17s]
prediction: ['[CLS], but has sucks or a funny moment would cause [SEP]']
Attempt swap
[1550/2000] tot_loss=1.467 (perp=6.932, rec=0.078, cos=0.003), tot_loss_proj:2.238 [t=0.17s]
prediction: ['[CLS], but has sucks or a funny moment would cause [SEP]']
Attempt swap
[1600/2000] tot_loss=1.475 (perp=6.932, rec=0.085, cos=0.003), tot_loss_proj:2.237 [t=0.17s]
prediction: ['[CLS], but has sucks or a funny moment would cause [SEP]']
[1650/2000] tot_loss=1.478 (perp=6.932, rec=0.089, cos=0.003), tot_loss_proj:2.241 [t=0.19s]
prediction: ['[CLS], but has sucks or a funny moment would cause [SEP]']
Attempt swap
[1700/2000] tot_loss=1.470 (perp=6.932, rec=0.081, cos=0.003), tot_loss_proj:2.238 [t=0.19s]
prediction: ['[CLS], but has sucks or a funny moment would cause [SEP]']
Attempt swap
[1750/2000] tot_loss=1.477 (perp=6.932, rec=0.087, cos=0.003), tot_loss_proj:2.237 [t=0.22s]
prediction: ['[CLS], but has sucks or a funny moment would cause [SEP]']
[1800/2000] tot_loss=1.708 (perp=8.117, rec=0.082, cos=0.003), tot_loss_proj:2.379 [t=0.21s]
prediction: ['[CLS], but has sucks or a funny moment two cause [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.400 (perp=6.536, rec=0.088, cos=0.004), tot_loss_proj:2.013 [t=0.19s]
prediction: ['[CLS], but has sucks a funny moment or two cause [SEP]']
Attempt swap
[1900/2000] tot_loss=1.401 (perp=6.536, rec=0.090, cos=0.004), tot_loss_proj:2.013 [t=0.19s]
prediction: ['[CLS], but has sucks a funny moment or two cause [SEP]']
[1950/2000] tot_loss=1.398 (perp=6.536, rec=0.087, cos=0.004), tot_loss_proj:2.017 [t=0.19s]
prediction: ['[CLS], but has sucks a funny moment or two cause [SEP]']
Attempt swap
[2000/2000] tot_loss=1.387 (perp=6.536, rec=0.076, cos=0.003), tot_loss_proj:2.015 [t=0.19s]
prediction: ['[CLS], but has sucks a funny moment or two cause [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS], but has sucks or a funny moment would cause [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 31.579 | p: 30.000 | r: 33.333
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 117.293

[Aggregate metrics]:
rouge1     | fm: 91.319 | p: 91.129 | r: 91.520
rouge2     | fm: 54.738 | p: 54.606 | r: 54.902
rougeL     | fm: 77.484 | p: 77.340 | r: 77.617
rougeLsum  | fm: 77.400 | p: 77.327 | r: 77.523
r1fm+r2fm = 146.057

input #51 time: 0:06:56 | total time: 5:59:28


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9992769471396806
highest_index [0]
highest [0.9992769471396806]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 1.9447109699249268 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 1.8204642534255981 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 1.6631529331207275 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 1.606566071510315 for ['[CLS] field darkedge [SEP]']
[Init] best rec loss: 1.5411300659179688 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 1.0370672941207886 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.9874905347824097 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.9856306314468384 for ['[CLS] expected football vocabulary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.271 (perp=10.655, rec=0.136, cos=0.004), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 100/2000] tot_loss=2.230 (perp=10.655, rec=0.096, cos=0.003), tot_loss_proj:2.458 [t=0.17s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 150/2000] tot_loss=2.218 (perp=10.655, rec=0.084, cos=0.003), tot_loss_proj:2.454 [t=0.17s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 200/2000] tot_loss=2.171 (perp=10.528, rec=0.064, cos=0.001), tot_loss_proj:2.206 [t=0.17s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.835 (perp=8.482, rec=0.133, cos=0.005), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.783 (perp=8.482, rec=0.085, cos=0.002), tot_loss_proj:2.140 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.764 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.142 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.755 (perp=8.482, rec=0.057, cos=0.001), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.753 (perp=8.482, rec=0.055, cos=0.001), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.755 (perp=8.482, rec=0.057, cos=0.001), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.139 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.140 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.138 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.755 (perp=8.482, rec=0.057, cos=0.001), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.764 (perp=8.482, rec=0.066, cos=0.001), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.759 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.767 (perp=8.482, rec=0.069, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.754 (perp=8.482, rec=0.056, cos=0.001), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.757 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.758 (perp=8.482, rec=0.060, cos=0.001), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.766 (perp=8.482, rec=0.068, cos=0.001), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.769 (perp=8.482, rec=0.071, cos=0.001), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.770 (perp=8.482, rec=0.072, cos=0.001), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.752 (perp=8.482, rec=0.054, cos=0.001), tot_loss_proj:2.130 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.758 (perp=8.482, rec=0.060, cos=0.001), tot_loss_proj:2.130 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.138 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.752 (perp=8.482, rec=0.055, cos=0.001), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.766 (perp=8.482, rec=0.068, cos=0.001), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.766 (perp=8.482, rec=0.068, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.768 (perp=8.482, rec=0.070, cos=0.001), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.756 (perp=8.482, rec=0.058, cos=0.001), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 91.365 | p: 91.186 | r: 91.583
rouge2     | fm: 53.780 | p: 53.655 | r: 53.880
rougeL     | fm: 77.555 | p: 77.497 | r: 77.679
rougeLsum  | fm: 77.255 | p: 77.191 | r: 77.395
r1fm+r2fm = 145.144

input #52 time: 0:06:44 | total time: 6:06:12


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9993462296030828
highest_index [0]
highest [0.9993462296030828]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 1.7769790887832642 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 1.7505303621292114 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 1.7399649620056152 for ['[CLS] government cf [SEP]']
[Init] best rec loss: 1.6215876340866089 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 1.6025766134262085 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 1.2801052331924438 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 1.2687050104141235 for ['[CLS]real hot [SEP]']
[Init] best rec loss: 1.1997308731079102 for ['[CLS] ralph not [SEP]']
[Init] best rec loss: 1.1960270404815674 for ['[CLS] university rock [SEP]']
[Init] best perm rec loss: 1.192598581314087 for ['[CLS] rock university [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.636 (perp=11.471, rec=0.289, cos=0.053), tot_loss_proj:3.026 [t=0.17s]
prediction: ['[CLS] fighting flinch [SEP]']
[ 100/2000] tot_loss=2.742 (perp=12.492, rec=0.211, cos=0.032), tot_loss_proj:3.345 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.667 (perp=12.492, rec=0.151, cos=0.017), tot_loss_proj:3.335 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=2.645 (perp=12.492, rec=0.132, cos=0.014), tot_loss_proj:3.332 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.647 (perp=12.492, rec=0.132, cos=0.017), tot_loss_proj:3.344 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 300/2000] tot_loss=2.635 (perp=12.492, rec=0.124, cos=0.013), tot_loss_proj:3.347 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.640 (perp=12.492, rec=0.129, cos=0.013), tot_loss_proj:3.335 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.640 (perp=12.492, rec=0.131, cos=0.011), tot_loss_proj:3.354 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 450/2000] tot_loss=2.554 (perp=12.413, rec=0.069, cos=0.002), tot_loss_proj:3.318 [t=0.17s]
prediction: ['[CLS]ing flinch [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.682 (perp=8.090, rec=0.062, cos=0.002), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.660 (perp=8.090, rec=0.041, cos=0.001), tot_loss_proj:1.692 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.671 (perp=8.090, rec=0.052, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.694 (perp=8.090, rec=0.075, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.672 (perp=8.090, rec=0.052, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.686 (perp=8.090, rec=0.066, cos=0.001), tot_loss_proj:1.692 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.687 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.670 (perp=8.090, rec=0.051, cos=0.001), tot_loss_proj:1.712 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.677 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.688 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.677 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.687 (perp=8.090, rec=0.067, cos=0.001), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.686 (perp=8.090, rec=0.067, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.677 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.534 | p: 91.387 | r: 91.762
rouge2     | fm: 54.641 | p: 54.557 | r: 54.751
rougeL     | fm: 77.902 | p: 77.805 | r: 78.005
rougeLsum  | fm: 77.587 | p: 77.530 | r: 77.725
r1fm+r2fm = 146.175

input #53 time: 0:06:46 | total time: 6:12:59


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9991885466091153
highest_index [0]
highest [0.9991885466091153]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 1.7071905136108398 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 1.552504062652588 for ['[CLS] living devices [SEP]']
[Init] best rec loss: 1.5421050786972046 for ['[CLS] trinity passed [SEP]']
[Init] best rec loss: 1.5026865005493164 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 1.2422250509262085 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 1.139829158782959 for ['[CLS] delivery content [SEP]']
[Init] best rec loss: 1.0659000873565674 for ['[CLS] deployment bro [SEP]']
[Init] best rec loss: 0.9896990060806274 for ['[CLS] wild exercised [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.978 (perp=8.198, rec=0.307, cos=0.031), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 100/2000] tot_loss=1.804 (perp=8.198, rec=0.156, cos=0.008), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=1.758 (perp=8.198, rec=0.114, cos=0.005), tot_loss_proj:1.734 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.725 (perp=8.198, rec=0.083, cos=0.002), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.717 (perp=8.198, rec=0.076, cos=0.002), tot_loss_proj:1.731 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.718 (perp=8.198, rec=0.077, cos=0.002), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.710 (perp=8.198, rec=0.068, cos=0.002), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.713 (perp=8.198, rec=0.072, cos=0.002), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.709 (perp=8.198, rec=0.068, cos=0.002), tot_loss_proj:1.729 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.714 (perp=8.198, rec=0.073, cos=0.002), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.709 (perp=8.198, rec=0.067, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.708 (perp=8.198, rec=0.067, cos=0.002), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.708 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.697 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.692 (perp=8.198, rec=0.051, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.711 (perp=8.198, rec=0.070, cos=0.002), tot_loss_proj:1.722 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.728 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.694 (perp=8.198, rec=0.053, cos=0.002), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.698 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.698 (perp=8.198, rec=0.057, cos=0.002), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.696 (perp=8.198, rec=0.055, cos=0.002), tot_loss_proj:1.739 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.695 (perp=8.198, rec=0.054, cos=0.002), tot_loss_proj:1.725 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.749 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.698 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.730 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.696 (perp=8.198, rec=0.055, cos=0.002), tot_loss_proj:1.736 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.708 (perp=8.198, rec=0.067, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.714 (perp=8.198, rec=0.073, cos=0.002), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.701 (perp=8.198, rec=0.059, cos=0.002), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.695 (perp=8.198, rec=0.054, cos=0.002), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.690 (perp=8.198, rec=0.049, cos=0.002), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.698 (perp=8.198, rec=0.057, cos=0.002), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.697 (perp=8.198, rec=0.055, cos=0.002), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.702 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.689 | p: 91.590 | r: 91.865
rouge2     | fm: 55.421 | p: 55.340 | r: 55.543
rougeL     | fm: 78.376 | p: 78.250 | r: 78.446
rougeLsum  | fm: 78.079 | p: 78.040 | r: 78.207
r1fm+r2fm = 147.110

input #54 time: 0:06:51 | total time: 6:19:51


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9991205863745829
highest_index [0]
highest [0.9991205863745829]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 1.8857332468032837 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 1.5969682931900024 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 1.32254958152771 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 1.3047670125961304 for ['[CLS]ies finished haired [SEP]']
[Init] best rec loss: 1.264054298400879 for ['[CLS] stride holly post [SEP]']
[Init] best rec loss: 1.2127386331558228 for ['[CLS] precipitation written mounted [SEP]']
[Init] best perm rec loss: 1.2090678215026855 for ['[CLS] written precipitation mounted [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.862 (perp=10.621, rec=0.510, cos=0.228), tot_loss_proj:3.887 [t=0.17s]
prediction: ['[CLS] no dry tobin [SEP]']
[ 100/2000] tot_loss=3.112 (perp=13.326, rec=0.359, cos=0.088), tot_loss_proj:4.345 [t=0.17s]
prediction: ['[CLS] self worse settle [SEP]']
[ 150/2000] tot_loss=3.022 (perp=13.471, rec=0.290, cos=0.038), tot_loss_proj:4.201 [t=0.17s]
prediction: ['[CLS] stokes worse settles [SEP]']
[ 200/2000] tot_loss=2.766 (perp=12.513, rec=0.233, cos=0.031), tot_loss_proj:4.378 [t=0.17s]
prediction: ['[CLS] stokes too settles [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.973 (perp=8.687, rec=0.211, cos=0.025), tot_loss_proj:2.238 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[ 300/2000] tot_loss=1.946 (perp=8.687, rec=0.188, cos=0.021), tot_loss_proj:2.252 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.928 (perp=8.687, rec=0.179, cos=0.012), tot_loss_proj:2.252 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.840 (perp=8.687, rec=0.098, cos=0.004), tot_loss_proj:2.252 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.826 (perp=8.687, rec=0.085, cos=0.003), tot_loss_proj:2.245 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.817 (perp=8.687, rec=0.078, cos=0.002), tot_loss_proj:2.251 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.811 (perp=8.687, rec=0.072, cos=0.002), tot_loss_proj:2.255 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.793 (perp=8.687, rec=0.054, cos=0.002), tot_loss_proj:2.249 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.804 (perp=8.687, rec=0.065, cos=0.002), tot_loss_proj:2.247 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.802 (perp=8.687, rec=0.063, cos=0.002), tot_loss_proj:2.247 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.816 (perp=8.687, rec=0.077, cos=0.002), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.811 (perp=8.687, rec=0.072, cos=0.002), tot_loss_proj:2.251 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.797 (perp=8.687, rec=0.058, cos=0.002), tot_loss_proj:2.263 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.792 (perp=8.687, rec=0.053, cos=0.002), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.799 (perp=8.687, rec=0.059, cos=0.002), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.798 (perp=8.687, rec=0.059, cos=0.002), tot_loss_proj:2.262 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.808 (perp=8.687, rec=0.069, cos=0.002), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.795 (perp=8.687, rec=0.056, cos=0.002), tot_loss_proj:2.254 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.812 (perp=8.687, rec=0.073, cos=0.002), tot_loss_proj:2.263 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.801 (perp=8.687, rec=0.062, cos=0.002), tot_loss_proj:2.252 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.799 (perp=8.687, rec=0.060, cos=0.002), tot_loss_proj:2.250 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.798 (perp=8.687, rec=0.059, cos=0.002), tot_loss_proj:2.263 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.800 (perp=8.687, rec=0.061, cos=0.002), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.801 (perp=8.687, rec=0.062, cos=0.002), tot_loss_proj:2.257 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.807 (perp=8.687, rec=0.068, cos=0.002), tot_loss_proj:2.249 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.804 (perp=8.687, rec=0.065, cos=0.002), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.805 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.259 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.799 (perp=8.687, rec=0.060, cos=0.002), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.799 (perp=8.687, rec=0.060, cos=0.002), tot_loss_proj:2.255 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.807 (perp=8.687, rec=0.068, cos=0.002), tot_loss_proj:2.255 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.802 (perp=8.687, rec=0.063, cos=0.002), tot_loss_proj:2.263 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.805 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.251 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.809 (perp=8.687, rec=0.070, cos=0.002), tot_loss_proj:2.258 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.805 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.252 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.801 (perp=8.687, rec=0.062, cos=0.002), tot_loss_proj:2.250 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.807 (perp=8.687, rec=0.068, cos=0.002), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.809 | p: 91.645 | r: 92.023
rouge2     | fm: 54.738 | p: 54.689 | r: 54.888
rougeL     | fm: 78.183 | p: 78.117 | r: 78.293
rougeLsum  | fm: 78.040 | p: 77.994 | r: 78.157
r1fm+r2fm = 146.547

input #55 time: 0:06:49 | total time: 6:26:41


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.9992743912224646
highest_index [0]
highest [0.9992743912224646]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 1.7055118083953857 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 1.6200506687164307 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 1.5344394445419312 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 1.4744815826416016 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 1.4654475450515747 for ['[CLS] sense en depression avid laid ironured bear k strike blame reflection technique determined backed unfortunately ; sympathy charter code tis [SEP]']
[Init] best perm rec loss: 1.456282377243042 for ['[CLS] strike charter unfortunately en backed reflection code laid tis blame k determined depression technique sense bear sympathy ironured ; avid [SEP]']
[Init] best perm rec loss: 1.4561269283294678 for ['[CLS] technique charter backed ; iron avid code sympathy sense bear determined laid en reflection depression tis blame k unfortunately strikeured [SEP]']
[Init] best perm rec loss: 1.4547836780548096 for ['[CLS] technique charter en tis kured code ; determined blame sympathy reflection sense unfortunately depression bear iron laid backed avid strike [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.598 (perp=11.714, rec=0.247, cos=0.008), tot_loss_proj:3.634 [t=0.17s]
prediction: ['[CLS] public film ruling car carolina damage caused options groanedous severe damage repair damage of ever damage dominated who expensive films [SEP]']
[ 100/2000] tot_loss=2.476 (perp=11.461, rec=0.181, cos=0.004), tot_loss_proj:3.409 [t=0.17s]
prediction: ["[CLS] films films which'virginia damage cause that groaned harder loads fix analysis years of dollars costly bearing every costly films [SEP]"]
[ 150/2000] tot_loss=2.577 (perp=12.202, rec=0.135, cos=0.002), tot_loss_proj:3.634 [t=0.17s]
prediction: ["[CLS] cause films which'virginia damage cause that collectionspara loads fix analysis years neverble costly could never analysis films [SEP]"]
[ 200/2000] tot_loss=2.433 (perp=11.594, rec=0.112, cos=0.002), tot_loss_proj:3.954 [t=0.17s]
prediction: ['[CLS] cause loads which should will damage cause thatparapara loads fix analysis years never of costly could years analysis films [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.556 (perp=11.511, rec=0.242, cos=0.012), tot_loss_proj:4.137 [t=0.17s]
prediction: ['[CLS] cause loads whichpara will damage cause thatparapara loads fix analysis years never [SEP] costly analysis of could films [SEP]']
[ 300/2000] tot_loss=2.191 (perp=10.422, rec=0.105, cos=0.002), tot_loss_proj:3.122 [t=0.19s]
prediction: ['[CLS] cause loads whichlla will damage cause thatparable loads fix analysis years never and costly years of could films [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.069 (perp=9.708, rec=0.126, cos=0.002), tot_loss_proj:3.183 [t=0.17s]
prediction: ['[CLS] cause loads which will will loads cause thatparable damage fix analysis years never and costly years of could films [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.859 (perp=8.767, rec=0.105, cos=0.002), tot_loss_proj:2.831 [t=0.20s]
prediction: ['[CLS] cause loads which will cause will loads thatparable damage fix analysis years never and costly analysis of could films [SEP]']
[ 450/2000] tot_loss=1.849 (perp=8.779, rec=0.091, cos=0.001), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] cause of which will cause will loads thatparable damage fix analysis years never and costly analysis of could films [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.850 (perp=8.810, rec=0.087, cos=0.001), tot_loss_proj:2.799 [t=0.17s]
prediction: ['[CLS] cause of which / cause will loads thatparable damage films analysis years never and costly analysis of could fix [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.814 (perp=8.656, rec=0.081, cos=0.002), tot_loss_proj:2.859 [t=0.17s]
prediction: ['[CLS] cause of which cause / will loads thatparable damage films analysis years never and costly years of could fix [SEP]']
[ 600/2000] tot_loss=1.814 (perp=8.656, rec=0.081, cos=0.002), tot_loss_proj:2.861 [t=0.17s]
prediction: ['[CLS] cause of which cause / will loads thatparable damage films analysis years never and costly years of could fix [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.761 (perp=8.380, rec=0.084, cos=0.002), tot_loss_proj:2.864 [t=0.17s]
prediction: ['[CLS] cause of which cause / will loads thatparable damage films analysis years never and costly of years could fix [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.713 (perp=8.113, rec=0.089, cos=0.002), tot_loss_proj:2.673 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads thatparable damage cause analysis years never and costly of years could fix [SEP]']
[ 750/2000] tot_loss=1.709 (perp=8.113, rec=0.085, cos=0.002), tot_loss_proj:2.672 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads thatparable damage cause analysis years never and costly of years could fix [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.697 (perp=8.113, rec=0.073, cos=0.002), tot_loss_proj:2.671 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads thatparable damage cause analysis years never and costly of years could fix [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.699 (perp=8.113, rec=0.075, cos=0.002), tot_loss_proj:2.672 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads thatparable damage cause analysis years never and costly of years could fix [SEP]']
[ 900/2000] tot_loss=1.699 (perp=8.113, rec=0.075, cos=0.001), tot_loss_proj:2.675 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads thatparable damage cause analysis years never and costly of years could fix [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.673 (perp=7.963, rec=0.079, cos=0.001), tot_loss_proj:2.689 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads that causeparable damage analysis years never and costly of years could fix [SEP]']
Attempt swap
[1000/2000] tot_loss=1.666 (perp=7.963, rec=0.072, cos=0.001), tot_loss_proj:2.690 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads that causeparable damage analysis years never and costly of years could fix [SEP]']
[1050/2000] tot_loss=1.671 (perp=7.963, rec=0.077, cos=0.001), tot_loss_proj:2.693 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads that causeparable damage analysis years never and costly of years could fix [SEP]']
Attempt swap
[1100/2000] tot_loss=1.675 (perp=7.963, rec=0.081, cos=0.001), tot_loss_proj:2.692 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads that causeparable damage analysis years never and costly of years could fix [SEP]']
Attempt swap
[1150/2000] tot_loss=1.664 (perp=7.963, rec=0.070, cos=0.001), tot_loss_proj:2.695 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads that causeparable damage analysis years never and costly of years could fix [SEP]']
[1200/2000] tot_loss=1.660 (perp=7.963, rec=0.066, cos=0.001), tot_loss_proj:2.695 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads that causeparable damage analysis years never and costly of years could fix [SEP]']
Attempt swap
[1250/2000] tot_loss=1.668 (perp=7.963, rec=0.073, cos=0.001), tot_loss_proj:2.696 [t=0.17s]
prediction: ['[CLS] films of which cause / will loads that causeparable damage analysis years never and costly of years could fix [SEP]']
Attempt swap
[1300/2000] tot_loss=1.839 (perp=8.849, rec=0.068, cos=0.001), tot_loss_proj:2.850 [t=0.17s]
prediction: ['[CLS] films of which cause ir will loads that causeparable damage analysis years never and costly of years could fix [SEP]']
[1350/2000] tot_loss=1.842 (perp=8.849, rec=0.070, cos=0.001), tot_loss_proj:2.851 [t=0.17s]
prediction: ['[CLS] films of which cause ir will loads that causeparable damage analysis years never and costly of years could fix [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.752 (perp=8.418, rec=0.067, cos=0.001), tot_loss_proj:2.833 [t=0.17s]
prediction: ['[CLS] films of which cause cause will loads that irparable damage analysis years never and costly of years could fix [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.723 (perp=8.166, rec=0.087, cos=0.002), tot_loss_proj:2.724 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
[1500/2000] tot_loss=1.708 (perp=8.166, rec=0.073, cos=0.001), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
Attempt swap
[1550/2000] tot_loss=1.708 (perp=8.166, rec=0.073, cos=0.001), tot_loss_proj:2.729 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
Attempt swap
[1600/2000] tot_loss=1.711 (perp=8.166, rec=0.077, cos=0.001), tot_loss_proj:2.721 [t=0.18s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
[1650/2000] tot_loss=1.699 (perp=8.166, rec=0.065, cos=0.001), tot_loss_proj:2.724 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
Attempt swap
[1700/2000] tot_loss=1.704 (perp=8.166, rec=0.069, cos=0.001), tot_loss_proj:2.727 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
Attempt swap
[1750/2000] tot_loss=1.711 (perp=8.166, rec=0.076, cos=0.001), tot_loss_proj:2.730 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
[1800/2000] tot_loss=1.696 (perp=8.166, rec=0.062, cos=0.001), tot_loss_proj:2.731 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
Attempt swap
[1850/2000] tot_loss=1.710 (perp=8.166, rec=0.075, cos=0.001), tot_loss_proj:2.727 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
Attempt swap
[1900/2000] tot_loss=1.708 (perp=8.166, rec=0.074, cos=0.001), tot_loss_proj:2.734 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
[1950/2000] tot_loss=1.701 (perp=8.166, rec=0.066, cos=0.001), tot_loss_proj:2.730 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
Attempt swap
[2000/2000] tot_loss=1.702 (perp=8.166, rec=0.068, cos=0.001), tot_loss_proj:2.728 [t=0.17s]
prediction: ['[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] films of which cause cause will that irparable damage analysis loads years never and costly of years could fix [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.683 | p: 90.476 | r: 95.000
rouge2     | fm: 10.256 | p: 10.000 | r: 10.526
rougeL     | fm: 53.659 | p: 52.381 | r: 55.000
rougeLsum  | fm: 53.659 | p: 52.381 | r: 55.000
r1fm+r2fm = 102.939

[Aggregate metrics]:
rouge1     | fm: 91.841 | p: 91.671 | r: 92.056
rouge2     | fm: 54.177 | p: 54.046 | r: 54.316
rougeL     | fm: 77.837 | p: 77.754 | r: 77.969
rougeLsum  | fm: 77.791 | p: 77.714 | r: 77.917
r1fm+r2fm = 146.018

input #56 time: 0:06:58 | total time: 6:33:39


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9993815950585874
highest_index [0]
highest [0.9993815950585874]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 1.7954795360565186 for ['[CLS]ne [SEP]']
[Init] best rec loss: 1.633437156677246 for ['[CLS] software [SEP]']
[Init] best rec loss: 1.5058315992355347 for ['[CLS] passed [SEP]']
[Init] best rec loss: 1.4965696334838867 for ['[CLS]cta [SEP]']
[Init] best rec loss: 1.4871668815612793 for ['[CLS] modern [SEP]']
[Init] best rec loss: 1.4436358213424683 for ['[CLS] bundesliga [SEP]']
[Init] best rec loss: 1.4208097457885742 for ['[CLS] thanks [SEP]']
[Init] best rec loss: 1.4164838790893555 for ['[CLS] decision [SEP]']
[Init] best rec loss: 1.390770435333252 for ['[CLS]ering [SEP]']
[Init] best rec loss: 1.3783762454986572 for ['[CLS] dorm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.159 (perp=10.561, rec=0.529, cos=0.518), tot_loss_proj:3.896 [t=0.17s]
prediction: ['[CLS] compromise [SEP]']
[ 100/2000] tot_loss=2.680 (perp=12.282, rec=0.188, cos=0.035), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.552 (perp=12.282, rec=0.090, cos=0.005), tot_loss_proj:2.524 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.541 (perp=12.282, rec=0.082, cos=0.002), tot_loss_proj:2.529 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.521 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.510 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.001), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.513 (perp=12.282, rec=0.055, cos=0.001), tot_loss_proj:2.505 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.516 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.519 (perp=12.282, rec=0.061, cos=0.001), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.517 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.520 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.530 (perp=12.282, rec=0.072, cos=0.001), tot_loss_proj:2.516 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.504 (perp=12.282, rec=0.046, cos=0.001), tot_loss_proj:2.513 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.511 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.508 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.523 (perp=12.282, rec=0.065, cos=0.001), tot_loss_proj:2.509 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.519 (perp=12.282, rec=0.062, cos=0.001), tot_loss_proj:2.531 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.512 (perp=12.282, rec=0.055, cos=0.001), tot_loss_proj:2.519 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.511 (perp=12.282, rec=0.053, cos=0.001), tot_loss_proj:2.532 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.499 (perp=12.282, rec=0.041, cos=0.001), tot_loss_proj:2.516 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.529 (perp=12.282, rec=0.072, cos=0.001), tot_loss_proj:2.515 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.515 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.523 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.001), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.521 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.509 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.001), tot_loss_proj:2.507 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.516 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.504 (perp=12.282, rec=0.046, cos=0.001), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.515 (perp=12.282, rec=0.057, cos=0.001), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.513 (perp=12.282, rec=0.055, cos=0.001), tot_loss_proj:2.512 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.516 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.516 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.532 (perp=12.282, rec=0.074, cos=0.001), tot_loss_proj:2.516 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.525 (perp=12.282, rec=0.067, cos=0.001), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.509 (perp=12.282, rec=0.051, cos=0.001), tot_loss_proj:2.505 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.509 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.502 (perp=12.282, rec=0.045, cos=0.001), tot_loss_proj:2.517 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.509 (perp=12.282, rec=0.051, cos=0.001), tot_loss_proj:2.508 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.507 (perp=12.282, rec=0.049, cos=0.001), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.525 (perp=12.282, rec=0.068, cos=0.001), tot_loss_proj:2.517 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.520 (perp=12.282, rec=0.062, cos=0.001), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.516 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.522 (perp=12.282, rec=0.065, cos=0.001), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.017 | p: 91.869 | r: 92.228
rouge2     | fm: 54.672 | p: 54.562 | r: 54.815
rougeL     | fm: 78.287 | p: 78.186 | r: 78.405
rougeLsum  | fm: 78.010 | p: 77.886 | r: 78.172
r1fm+r2fm = 146.689

input #57 time: 0:06:51 | total time: 6:40:30


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9992685151622416
highest_index [0]
highest [0.9992685151622416]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.8984190225601196 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 1.8598558902740479 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 1.6641579866409302 for ['[CLS] ) after rca adventures / yong beat bad http stoodagendingple ]erson trailing [SEP]']
[Init] best rec loss: 1.6362143754959106 for ['[CLS] insidethed subject layton devoted approachhead physicians keys vice tarzan mile norman warlord choosebaldi [SEP]']
[Init] best rec loss: 1.633800745010376 for ['[CLS] hissedoop whispered h delayed!lwyn [SEP] could prove atrocities backsie square shu tam [SEP]']
[Init] best rec loss: 1.5590686798095703 for ['[CLS]lusion wake case species applicationnding fluent passing bakeralo couple win used texas installed tucker [SEP]']
[Init] best perm rec loss: 1.5537745952606201 for ['[CLS] passingalo species used baker installednding tucker texas win wakelusion couple application case fluent [SEP]']
[Init] best perm rec loss: 1.5531631708145142 for ['[CLS] tucker installed used texas case bakerlusionnding wake application fluentalo couple passing species win [SEP]']
[Init] best perm rec loss: 1.5502347946166992 for ['[CLS] texas fluent used tucker bakeralolusion application case installednding passing win couple wake species [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.335 (perp=11.948, rec=0.609, cos=0.336), tot_loss_proj:4.036 [t=0.17s]
prediction: ['[CLS] pilot in that highness successor maybe apartment environment rural broken possessions meters transit green couch opposition [SEP]']
[ 100/2000] tot_loss=3.332 (perp=13.005, rec=0.540, cos=0.191), tot_loss_proj:4.584 [t=0.17s]
prediction: ['[CLS] leading from inspirational affair successor literary rooted story profile obtain possessions ish thousands walls opposition [SEP]']
[ 150/2000] tot_loss=3.213 (perp=10.191, rec=0.769, cos=0.406), tot_loss_proj:3.795 [t=0.17s]
prediction: ['[CLS] result from love walk the like railway story canoe. indiana become extremely ᵘ addison well [SEP]']
[ 200/2000] tot_loss=3.161 (perp=11.637, rec=0.586, cos=0.247), tot_loss_proj:3.843 [t=0.17s]
prediction: ['[CLS] expression from is text the marion nearby story vuelta. ashley environmental earl talk convoy useless [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.082 (perp=11.863, rec=0.536, cos=0.173), tot_loss_proj:3.908 [t=0.17s]
prediction: ['[CLS] expression from the affair is marion is storyasurable the ashley environmental outstandingop multiplication useless [SEP]']
[ 300/2000] tot_loss=2.924 (perp=11.591, rec=0.499, cos=0.107), tot_loss_proj:3.920 [t=0.17s]
prediction: ['[CLS] expression from the facts is 1930s is storyasurable an ashley girlfriend inspirationalall buddha useless [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.951 (perp=11.919, rec=0.487, cos=0.081), tot_loss_proj:4.370 [t=0.17s]
prediction: ['[CLS] expression from the importantly love 1930s upon storyasurable an quoted is inspirational type baroque stalled [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.699 (perp=10.820, rec=0.480, cos=0.055), tot_loss_proj:4.140 [t=0.17s]
prediction: ['[CLS] expression from the innocence inspirational 1930s upon storyasurable quoted is the inspirational encounter inspirational stalled [SEP]']
[ 450/2000] tot_loss=2.541 (perp=10.163, rec=0.456, cos=0.053), tot_loss_proj:4.036 [t=0.17s]
prediction: ['[CLS] expression from the inspirational inspirational 1930slike storyasurable gentlemen is the inspirational encounter inspirational stalled [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.675 (perp=10.851, rec=0.456, cos=0.049), tot_loss_proj:4.141 [t=0.17s]
prediction: ['[CLS] stalled from the innocence inspirational ranklike story vuelta gentlemen is was inspirational encounter baroque expression [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.448 (perp=9.800, rec=0.449, cos=0.039), tot_loss_proj:3.803 [t=0.17s]
prediction: ['[CLS] stalled from the innocence inspirational wirelike story vuelta is gentlemen and inspirational encounter baroque expression [SEP]']
[ 600/2000] tot_loss=2.519 (perp=10.292, rec=0.434, cos=0.026), tot_loss_proj:3.872 [t=0.17s]
prediction: ['[CLS] stalled from thebook inspirational wirelike story vuelta is gentlemen the inspirational encounter ideal signal [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.410 (perp=9.782, rec=0.426, cos=0.027), tot_loss_proj:3.656 [t=0.17s]
prediction: ['[CLS] stalled from the inspirationalbook wirelike story vuelta is formula the inspirational encounter ideal signal [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.240 (perp=8.932, rec=0.417, cos=0.037), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational wirebooklike story vuelta is formula the inspirational encounter ideal is [SEP]']
[ 750/2000] tot_loss=2.244 (perp=8.932, rec=0.416, cos=0.042), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational wirebooklike story vuelta is formula the inspirational encounter ideal is [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.772 (perp=9.545, rec=0.558, cos=0.305), tot_loss_proj:3.769 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational mood inspirational girlfriend story illusions is advocate an inspirational encounter baroque is [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.433 (perp=9.521, rec=0.468, cos=0.061), tot_loss_proj:3.656 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational mood inspirational girlfriend story love is paragraph is inspirational encounter baroque is [SEP]']
[ 900/2000] tot_loss=2.363 (perp=9.463, rec=0.440, cos=0.030), tot_loss_proj:3.801 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational mood inspirational upon story love is paragraph is inspirational encounter ideal is [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.325 (perp=9.366, rec=0.430, cos=0.022), tot_loss_proj:3.729 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational tired inspirational story upon love is paragraph is inspirational encounter ideal is [SEP]']
Attempt swap
[1000/2000] tot_loss=2.307 (perp=9.366, rec=0.419, cos=0.015), tot_loss_proj:3.728 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational tired inspirational story upon love is paragraph is inspirational encounter ideal is [SEP]']
[1050/2000] tot_loss=2.305 (perp=9.366, rec=0.414, cos=0.018), tot_loss_proj:3.732 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational tired inspirational story upon love is paragraph is inspirational encounter ideal is [SEP]']
Attempt swap
[1100/2000] tot_loss=2.235 (perp=9.068, rec=0.408, cos=0.013), tot_loss_proj:3.727 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational tired inspirational story upon love is paragraph an inspirational encounter ideal is [SEP]']
Attempt swap
[1150/2000] tot_loss=2.233 (perp=9.068, rec=0.408, cos=0.012), tot_loss_proj:3.732 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational tired inspirational story upon love is paragraph an inspirational encounter ideal is [SEP]']
[1200/2000] tot_loss=2.231 (perp=9.068, rec=0.405, cos=0.012), tot_loss_proj:3.736 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational tired inspirational story upon love is paragraph an inspirational encounter ideal is [SEP]']
Attempt swap
[1250/2000] tot_loss=2.144 (perp=8.596, rec=0.406, cos=0.019), tot_loss_proj:3.693 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational career inspirational story upon love is paragraph an inspirational encounter ideal is [SEP]']
Attempt swap
[1300/2000] tot_loss=2.267 (perp=9.303, rec=0.396, cos=0.010), tot_loss_proj:3.839 [t=0.17s]
prediction: ['[CLS] stalled from the inspirational career inspirational story upon love is tack an inspirational encounter ideal is [SEP]']
[1350/2000] tot_loss=2.334 (perp=9.621, rec=0.400, cos=0.010), tot_loss_proj:3.926 [t=0.17s]
prediction: ['[CLS] stalled in the inspirational career inspirational story upon love is tack an inspirational encounter ideal is [SEP]']
Attempt swap
[1400/2000] tot_loss=2.332 (perp=9.621, rec=0.398, cos=0.009), tot_loss_proj:3.923 [t=0.17s]
prediction: ['[CLS] stalled in the inspirational career inspirational story upon love is tack an inspirational encounter ideal is [SEP]']
Attempt swap
[1450/2000] tot_loss=2.325 (perp=9.621, rec=0.392, cos=0.009), tot_loss_proj:3.923 [t=0.17s]
prediction: ['[CLS] stalled in the inspirational career inspirational story upon love is tack an inspirational encounter ideal is [SEP]']
[1500/2000] tot_loss=2.332 (perp=9.621, rec=0.398, cos=0.010), tot_loss_proj:3.925 [t=0.17s]
prediction: ['[CLS] stalled in the inspirational career inspirational story upon love is tack an inspirational encounter ideal is [SEP]']
Attempt swap
[1550/2000] tot_loss=2.324 (perp=9.621, rec=0.391, cos=0.010), tot_loss_proj:3.927 [t=0.17s]
prediction: ['[CLS] stalled in the inspirational career inspirational story upon love is tack an inspirational encounter ideal is [SEP]']
Attempt swap
[1600/2000] tot_loss=2.326 (perp=9.621, rec=0.394, cos=0.008), tot_loss_proj:3.926 [t=0.17s]
prediction: ['[CLS] stalled in the inspirational career inspirational story upon love is tack an inspirational encounter ideal is [SEP]']
[1650/2000] tot_loss=2.334 (perp=9.621, rec=0.400, cos=0.010), tot_loss_proj:3.922 [t=0.17s]
prediction: ['[CLS] stalled in the inspirational career inspirational story upon love is tack an inspirational encounter ideal is [SEP]']
Attempt swap
[1700/2000] tot_loss=2.333 (perp=9.685, rec=0.389, cos=0.007), tot_loss_proj:2.648 [t=0.17s]
prediction: ['[CLS] ongoing in the inspirational career inspirational story upon love is tack an inspirational encounter ideal is [SEP]']
Attempt swap
[1750/2000] tot_loss=2.333 (perp=9.685, rec=0.387, cos=0.009), tot_loss_proj:2.648 [t=0.17s]
prediction: ['[CLS] ongoing in the inspirational career inspirational story upon love is tack an inspirational encounter ideal is [SEP]']
[1800/2000] tot_loss=2.366 (perp=9.850, rec=0.388, cos=0.008), tot_loss_proj:2.856 [t=0.17s]
prediction: ['[CLS] ongoing in the inspirational career inspirational story upon love is tack an inspirational encounter fact is [SEP]']
Attempt swap
[1850/2000] tot_loss=2.368 (perp=9.850, rec=0.390, cos=0.008), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] ongoing in the inspirational career inspirational story upon love is tack an inspirational encounter fact is [SEP]']
Attempt swap
[1900/2000] tot_loss=2.365 (perp=9.850, rec=0.387, cos=0.008), tot_loss_proj:2.854 [t=0.17s]
prediction: ['[CLS] ongoing in the inspirational career inspirational story upon love is tack an inspirational encounter fact is [SEP]']
[1950/2000] tot_loss=2.375 (perp=9.850, rec=0.397, cos=0.007), tot_loss_proj:2.851 [t=0.17s]
prediction: ['[CLS] ongoing in the inspirational career inspirational story upon love is tack an inspirational encounter fact is [SEP]']
Attempt swap
[2000/2000] tot_loss=2.371 (perp=9.850, rec=0.393, cos=0.008), tot_loss_proj:2.853 [t=0.17s]
prediction: ['[CLS] ongoing in the inspirational career inspirational story upon love is tack an inspirational encounter fact is [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] ongoing in the inspirational career inspirational story upon love is tack an inspirational encounter fact is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 52.941 | p: 50.000 | r: 56.250
rouge2     | fm: 6.250 | p: 5.882 | r: 6.667
rougeL     | fm: 35.294 | p: 33.333 | r: 37.500
rougeLsum  | fm: 35.294 | p: 33.333 | r: 37.500
r1fm+r2fm = 59.191

[Aggregate metrics]:
rouge1     | fm: 91.344 | p: 91.148 | r: 91.601
rouge2     | fm: 54.169 | p: 54.035 | r: 54.331
rougeL     | fm: 77.695 | p: 77.543 | r: 77.817
rougeLsum  | fm: 77.374 | p: 77.241 | r: 77.529
r1fm+r2fm = 145.513

input #58 time: 0:06:51 | total time: 6:47:21


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9992224669689527
highest_index [0]
highest [0.9992224669689527]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 1.9130570888519287 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 1.893306851387024 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 1.8817111253738403 for ['[CLS] shares josephine settled commerce refrain bulletsgi moved plot awaitanies roger console fergusotidew [SEP]']
[Init] best rec loss: 1.7740832567214966 for ['[CLS] meetings primarily afar vietnamille sound explaining bun ii powerped able speaking [SEP] brow illumination [SEP]']
[Init] best rec loss: 1.75552499294281 for ['[CLS] trollsity underoh othersrion vault sorry days premiereend wivesjit reachedhold motorway [SEP]']
[Init] best rec loss: 1.6795601844787598 for ['[CLS] approaches dumb accept households frame relation sport replymis logan surrounding dutch dragon different com discipline [SEP]']
[Init] best rec loss: 1.6730873584747314 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best rec loss: 1.4757320880889893 for ['[CLS] organic passengers heroic wall duty change surgery drag kay statesflower hadn retirement cross will money [SEP]']
[Init] best perm rec loss: 1.473044991493225 for ['[CLS]flower states passengers cross drag organic money change wall hadn retirement kay heroic surgery will duty [SEP]']
[Init] best perm rec loss: 1.4710206985473633 for ['[CLS] wall passengers will states duty kay drag cross change money surgery heroicflower hadn organic retirement [SEP]']
[Init] best perm rec loss: 1.4710203409194946 for ['[CLS] hadn passengers retirement wall states organic drag change duty surgery kayflower money heroic cross will [SEP]']
[Init] best perm rec loss: 1.4642279148101807 for ['[CLS] wall organic passengers drag change surgeryflower will states retirement duty money kay cross heroic hadn [SEP]']
[Init] best perm rec loss: 1.4622763395309448 for ['[CLS] states passengers cross change organic surgeryflower kay money drag retirement wall will heroic duty hadn [SEP]']
[Init] best perm rec loss: 1.4614100456237793 for ['[CLS] hadn organic passengersflower surgery heroic cross kay will wall retirement change money states drag duty [SEP]']
[Init] best perm rec loss: 1.4608839750289917 for ['[CLS] organicflower retirement will money heroic duty hadn wall drag surgery cross passengers states change kay [SEP]']
[Init] best perm rec loss: 1.4605615139007568 for ['[CLS] organic drag passengers heroicflower cross kay surgery retirement wall will duty states money change hadn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.551 (perp=11.061, rec=0.328, cos=0.011), tot_loss_proj:3.758 [t=0.17s]
prediction: ['[CLS] dedicated of person aunt operator about woman documentary metal civilian that survivor of shortism. [SEP]']
[ 100/2000] tot_loss=3.007 (perp=13.784, rec=0.244, cos=0.006), tot_loss_proj:4.310 [t=0.17s]
prediction: ['[CLS] dedicated has how char old an woman club screen woman charism of youngism he [SEP]']
[ 150/2000] tot_loss=2.401 (perp=10.966, rec=0.203, cos=0.005), tot_loss_proj:3.593 [t=0.17s]
prediction: ['[CLS] record hasism of old knows woman the screen young char woman who youngism that [SEP]']
[ 200/2000] tot_loss=2.347 (perp=10.897, rec=0.165, cos=0.002), tot_loss_proj:3.664 [t=0.17s]
prediction: ['[CLS]ism hasism of old knows woman the screen young char woman who youngism having [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.989 (perp=9.317, rec=0.124, cos=0.002), tot_loss_proj:3.032 [t=0.17s]
prediction: ['[CLS]ism hasism of the young of the screen knows char woman who young hold having [SEP]']
[ 300/2000] tot_loss=2.137 (perp=10.154, rec=0.105, cos=0.002), tot_loss_proj:3.242 [t=0.17s]
prediction: ['[CLS]a hasism of from a a the screen knows char woman who young hold the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.059 (perp=9.815, rec=0.095, cos=0.002), tot_loss_proj:3.336 [t=0.17s]
prediction: ['[CLS] screen hasism of from a a thea knows char woman who young hold how [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.895 (perp=9.030, rec=0.087, cos=0.002), tot_loss_proj:2.731 [t=0.17s]
prediction: ['[CLS] screen hasism of the a a thea young char woman who knows hold how [SEP]']
[ 450/2000] tot_loss=1.891 (perp=9.030, rec=0.084, cos=0.001), tot_loss_proj:2.733 [t=0.17s]
prediction: ['[CLS] screen hasism of the a a thea young char woman who knows hold how [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.782 (perp=8.494, rec=0.082, cos=0.001), tot_loss_proj:2.838 [t=0.17s]
prediction: ['[CLS] screen hasism of from a a the chara young woman who knows hold how [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.685 (perp=7.998, rec=0.084, cos=0.001), tot_loss_proj:2.770 [t=0.17s]
prediction: ['[CLS] screen hasism of a from a the chara young woman who knows hold how [SEP]']
[ 600/2000] tot_loss=1.670 (perp=7.998, rec=0.068, cos=0.002), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] screen hasism of a from a the chara young woman who knows hold how [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.611 (perp=7.628, rec=0.084, cos=0.002), tot_loss_proj:2.906 [t=0.17s]
prediction: ['[CLS] screen hasism of a from a the chara young woman who knows how hold [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.604 (perp=7.628, rec=0.077, cos=0.002), tot_loss_proj:2.932 [t=0.17s]
prediction: ['[CLS] screen hasism of a from a the chara young woman who knows how hold [SEP]']
[ 750/2000] tot_loss=1.603 (perp=7.707, rec=0.060, cos=0.001), tot_loss_proj:2.818 [t=0.17s]
prediction: ['[CLS] screen hasism of the from a the chara young woman who knows how hold [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.592 (perp=7.626, rec=0.065, cos=0.002), tot_loss_proj:2.822 [t=0.17s]
prediction: ['[CLS] screen hasism of the from the a chara young woman who knows how hold [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.500 (perp=7.173, rec=0.064, cos=0.002), tot_loss_proj:2.478 [t=0.17s]
prediction: ['[CLS] screen has theism of the from a chara young woman who knows how hold [SEP]']
[ 900/2000] tot_loss=1.508 (perp=7.173, rec=0.072, cos=0.002), tot_loss_proj:2.473 [t=0.17s]
prediction: ['[CLS] screen has theism of the from a chara young woman who knows how hold [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.368 (perp=6.490, rec=0.068, cos=0.002), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] the screen has theism of the a chara young woman who knows how hold [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.247 (perp=5.908, rec=0.064, cos=0.001), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how the hold [SEP]']
[1050/2000] tot_loss=1.252 (perp=5.908, rec=0.069, cos=0.002), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how the hold [SEP]']
Attempt swap
[1100/2000] tot_loss=1.249 (perp=5.908, rec=0.066, cos=0.002), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how the hold [SEP]']
Attempt swap
[1150/2000] tot_loss=1.239 (perp=5.908, rec=0.056, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how the hold [SEP]']
[1200/2000] tot_loss=1.242 (perp=5.908, rec=0.058, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how the hold [SEP]']
Attempt swap
[1250/2000] tot_loss=1.251 (perp=5.908, rec=0.068, cos=0.002), tot_loss_proj:2.022 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how the hold [SEP]']
Attempt swap
[1300/2000] tot_loss=1.247 (perp=5.908, rec=0.064, cos=0.002), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how the hold [SEP]']
[1350/2000] tot_loss=1.250 (perp=5.908, rec=0.067, cos=0.002), tot_loss_proj:2.015 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how the hold [SEP]']
Attempt swap
[1400/2000] tot_loss=1.250 (perp=5.908, rec=0.067, cos=0.002), tot_loss_proj:2.021 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how the hold [SEP]']
Attempt swap
[1450/2000] tot_loss=1.123 (perp=5.278, rec=0.066, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
[1500/2000] tot_loss=1.116 (perp=5.278, rec=0.059, cos=0.002), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
Attempt swap
[1550/2000] tot_loss=1.126 (perp=5.278, rec=0.069, cos=0.002), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
Attempt swap
[1600/2000] tot_loss=1.119 (perp=5.278, rec=0.062, cos=0.002), tot_loss_proj:1.701 [t=0.18s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
[1650/2000] tot_loss=1.114 (perp=5.278, rec=0.056, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
Attempt swap
[1700/2000] tot_loss=1.119 (perp=5.278, rec=0.062, cos=0.002), tot_loss_proj:1.702 [t=0.19s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
Attempt swap
[1750/2000] tot_loss=1.133 (perp=5.278, rec=0.076, cos=0.002), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
[1800/2000] tot_loss=1.125 (perp=5.278, rec=0.068, cos=0.002), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
Attempt swap
[1850/2000] tot_loss=1.113 (perp=5.278, rec=0.055, cos=0.002), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
Attempt swap
[1900/2000] tot_loss=1.119 (perp=5.278, rec=0.062, cos=0.002), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
[1950/2000] tot_loss=1.120 (perp=5.278, rec=0.063, cos=0.002), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
Attempt swap
[2000/2000] tot_loss=1.115 (perp=5.278, rec=0.057, cos=0.002), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] the screen has theism of a chara young woman who knows how to hold [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 53.333 | p: 53.333 | r: 53.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 140.833

[Aggregate metrics]:
rouge1     | fm: 91.236 | p: 91.014 | r: 91.470
rouge2     | fm: 54.164 | p: 54.034 | r: 54.291
rougeL     | fm: 77.576 | p: 77.458 | r: 77.767
rougeLsum  | fm: 77.319 | p: 77.160 | r: 77.476
r1fm+r2fm = 145.400

input #59 time: 0:06:53 | total time: 6:54:15


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.999371813039142
highest_index [0]
highest [0.999371813039142]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 1.8264330625534058 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 1.785794734954834 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 1.5257476568222046 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 1.4993537664413452 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 1.494861125946045 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 1.4207831621170044 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 1.4200644493103027 for ['[CLS] constitutionitude upsetshaw coverlby strungouring majority plenty / through [SEP]']
[Init] best perm rec loss: 1.413394570350647 for ['[CLS] cover majority /lby constitution upset strung throughshawouringitude plenty [SEP]']
[Init] best perm rec loss: 1.4109059572219849 for ['[CLS] majority upset strungitude /ouringshawlby cover through plenty constitution [SEP]']
[Init] best perm rec loss: 1.4078900814056396 for ['[CLS] / majority strungouringshawlby through constitutionitude plenty cover upset [SEP]']
[Init] best perm rec loss: 1.4074980020523071 for ['[CLS] majority strung throughouringlbyitudeshaw / constitution upset plenty cover [SEP]']
[Init] best perm rec loss: 1.4071258306503296 for ['[CLS] plentyitude /lby strung cover upsetshaw constitution through majorityouring [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.376 (perp=10.537, rec=0.259, cos=0.009), tot_loss_proj:2.779 [t=0.17s]
prediction: ['[CLS] awkwardly awkwardly awkwardly transit protocol - - awkwardly awkwardly soap. circuit [SEP]']
[ 100/2000] tot_loss=2.516 (perp=11.568, rec=0.198, cos=0.004), tot_loss_proj:2.915 [t=0.17s]
prediction: ['[CLS] awkwardly awkwardly awkwardly transit paced the is awkwardly awkwardly soap. circuit [SEP]']
[ 150/2000] tot_loss=2.363 (perp=11.079, rec=0.145, cos=0.003), tot_loss_proj:2.775 [t=0.17s]
prediction: ['[CLS] circuit awkwardly awkwardly circuit paced the is awkwardly awkwardly soap. story [SEP]']
[ 200/2000] tot_loss=2.258 (perp=10.661, rec=0.123, cos=0.003), tot_loss_proj:2.646 [t=0.17s]
prediction: ['[CLS] circuit awkwardly awkwardly circuit paced the is awkwardly paced soap. story [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.021 (perp=9.548, rec=0.109, cos=0.003), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] circuit awkwardly awkwardly circuit paced the story is awkwardly paced soap. [SEP]']
[ 300/2000] tot_loss=1.993 (perp=9.455, rec=0.099, cos=0.003), tot_loss_proj:2.329 [t=0.17s]
prediction: ['[CLS] circuit awkwardly awkwardly opera paced the story is awkwardly paced soap. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.607 (perp=7.463, rec=0.112, cos=0.003), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced the story is awkwardly paced. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.592 (perp=7.463, rec=0.097, cos=0.002), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced the story is awkwardly paced. [SEP]']
[ 450/2000] tot_loss=1.784 (perp=8.462, rec=0.089, cos=0.002), tot_loss_proj:2.189 [t=0.17s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced the story is awkwardlyh. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.917 (perp=9.163, rec=0.082, cos=0.002), tot_loss_proj:2.308 [t=0.17s]
prediction: ['[CLS] circuit awkwardly awkwardly soap opera paced the story awkwardly ish - [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.790 (perp=8.532, rec=0.082, cos=0.002), tot_loss_proj:2.086 [t=0.17s]
prediction: ['[CLS] circuit is awkwardly soap opera paced the awkwardly ish story - [SEP]']
[ 600/2000] tot_loss=1.795 (perp=8.532, rec=0.086, cos=0.002), tot_loss_proj:2.091 [t=0.17s]
prediction: ['[CLS] circuit is awkwardly soap opera paced the awkwardly ish story - [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.718 (perp=8.167, rec=0.082, cos=0.002), tot_loss_proj:2.035 [t=0.17s]
prediction: ['[CLS] circuit is awkwardly awkwardly soap opera paced the ish story - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.718 (perp=8.167, rec=0.083, cos=0.002), tot_loss_proj:2.032 [t=0.17s]
prediction: ['[CLS] circuit is awkwardly awkwardly soap opera paced the ish story - [SEP]']
[ 750/2000] tot_loss=1.716 (perp=8.167, rec=0.081, cos=0.002), tot_loss_proj:2.038 [t=0.17s]
prediction: ['[CLS] circuit is awkwardly awkwardly soap opera paced the ish story - [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.672 (perp=7.962, rec=0.078, cos=0.002), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] circuit is awkwardly awkwardly soap opera paced - the ish story [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.623 (perp=7.710, rec=0.079, cos=0.002), tot_loss_proj:1.875 [t=0.17s]
prediction: ['[CLS] circuit is awkwardly paced awkwardly soap opera - the ish story [SEP]']
[ 900/2000] tot_loss=1.612 (perp=7.710, rec=0.068, cos=0.002), tot_loss_proj:1.873 [t=0.17s]
prediction: ['[CLS] circuit is awkwardly paced awkwardly soap opera - the ish story [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.615 (perp=7.710, rec=0.071, cos=0.002), tot_loss_proj:1.880 [t=0.17s]
prediction: ['[CLS] circuit is awkwardly paced awkwardly soap opera - the ish story [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.546 (perp=7.379, rec=0.069, cos=0.002), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
[1050/2000] tot_loss=1.544 (perp=7.379, rec=0.066, cos=0.002), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1100/2000] tot_loss=1.548 (perp=7.379, rec=0.070, cos=0.002), tot_loss_proj:1.837 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1150/2000] tot_loss=1.546 (perp=7.379, rec=0.068, cos=0.002), tot_loss_proj:1.836 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
[1200/2000] tot_loss=1.541 (perp=7.379, rec=0.063, cos=0.002), tot_loss_proj:1.843 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1250/2000] tot_loss=1.547 (perp=7.379, rec=0.069, cos=0.002), tot_loss_proj:1.838 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1300/2000] tot_loss=1.549 (perp=7.379, rec=0.072, cos=0.002), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
[1350/2000] tot_loss=1.557 (perp=7.379, rec=0.079, cos=0.002), tot_loss_proj:1.839 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1400/2000] tot_loss=1.546 (perp=7.379, rec=0.069, cos=0.002), tot_loss_proj:1.844 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1450/2000] tot_loss=1.549 (perp=7.379, rec=0.071, cos=0.002), tot_loss_proj:1.837 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
[1500/2000] tot_loss=1.553 (perp=7.379, rec=0.076, cos=0.002), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1550/2000] tot_loss=1.544 (perp=7.379, rec=0.066, cos=0.002), tot_loss_proj:1.836 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1600/2000] tot_loss=1.540 (perp=7.379, rec=0.062, cos=0.002), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
[1650/2000] tot_loss=1.547 (perp=7.379, rec=0.069, cos=0.002), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1700/2000] tot_loss=1.548 (perp=7.379, rec=0.070, cos=0.002), tot_loss_proj:1.834 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1750/2000] tot_loss=1.553 (perp=7.379, rec=0.076, cos=0.002), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
[1800/2000] tot_loss=1.548 (perp=7.379, rec=0.071, cos=0.002), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1850/2000] tot_loss=1.548 (perp=7.379, rec=0.070, cos=0.002), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[1900/2000] tot_loss=1.554 (perp=7.379, rec=0.077, cos=0.002), tot_loss_proj:1.838 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
[1950/2000] tot_loss=1.551 (perp=7.379, rec=0.073, cos=0.002), tot_loss_proj:1.837 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Attempt swap
[2000/2000] tot_loss=1.548 (perp=7.379, rec=0.070, cos=0.002), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] circuit awkwardly paced is awkwardly soap opera - the ish story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 47.619 | p: 45.455 | r: 50.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 143.271

[Aggregate metrics]:
rouge1     | fm: 91.319 | p: 91.036 | r: 91.668
rouge2     | fm: 54.098 | p: 53.933 | r: 54.272
rougeL     | fm: 77.458 | p: 77.275 | r: 77.701
rougeLsum  | fm: 77.265 | p: 77.102 | r: 77.500
r1fm+r2fm = 145.417

input #60 time: 0:06:51 | total time: 7:01:06


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.999284746941759
highest_index [0]
highest [0.999284746941759]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 1.8300962448120117 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 1.8116177320480347 for ['[CLS]zeeali donated [SEP]']
[Init] best rec loss: 1.6035362482070923 for ['[CLS] age bad link [SEP]']
[Init] best rec loss: 1.6008113622665405 for ['[CLS] maximus broken initiative [SEP]']
[Init] best rec loss: 1.175456166267395 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 1.1720333099365234 for ['[CLS] lets mini request [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.999 (perp=8.940, rec=0.200, cos=0.011), tot_loss_proj:2.144 [t=0.17s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 100/2000] tot_loss=1.938 (perp=8.940, rec=0.142, cos=0.008), tot_loss_proj:2.140 [t=0.17s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 150/2000] tot_loss=1.932 (perp=8.940, rec=0.137, cos=0.007), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 200/2000] tot_loss=1.930 (perp=8.940, rec=0.136, cos=0.006), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.686 (perp=8.032, rec=0.078, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS], beautiful scene [SEP]']
[ 300/2000] tot_loss=1.670 (perp=8.032, rec=0.062, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.488 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.500 (perp=7.101, rec=0.078, cos=0.001), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.487 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.488 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.489 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.482 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.481 (perp=7.101, rec=0.059, cos=0.001), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.487 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.479 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.474 (perp=7.101, rec=0.052, cos=0.001), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.488 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.492 (perp=7.101, rec=0.070, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.492 (perp=7.101, rec=0.070, cos=0.001), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.492 (perp=7.101, rec=0.070, cos=0.001), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.484 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.487 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.488 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.628 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.488 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.488 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.499 (perp=7.101, rec=0.078, cos=0.001), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.489 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.477 (perp=7.101, rec=0.055, cos=0.001), tot_loss_proj:1.631 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.491 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.478 (perp=7.101, rec=0.056, cos=0.001), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.483 (perp=7.101, rec=0.061, cos=0.001), tot_loss_proj:1.632 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.486 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.489 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.537 | p: 91.273 | r: 91.826
rouge2     | fm: 54.716 | p: 54.579 | r: 54.846
rougeL     | fm: 77.902 | p: 77.746 | r: 78.093
rougeLsum  | fm: 77.669 | p: 77.520 | r: 77.916
r1fm+r2fm = 146.253

input #61 time: 0:06:43 | total time: 7:07:50


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.999255650346929
highest_index [0]
highest [0.999255650346929]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 1.9530375003814697 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 1.880612850189209 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 1.7968920469284058 for ['[CLS] help rarely extensionbreaker local sea team mom beacon tear wax chairmanphstatic mum new osman intervention [CLS] attentionius [SEP]']
[Init] best rec loss: 1.767058253288269 for ['[CLS]tled traffic conduct atoms sets commercial : robertsrgeonkney hard sherman [SEP] bus forbc charlie dragons medal same gravity [SEP]']
[Init] best rec loss: 1.749898910522461 for ['[CLS] wasn homosexual carey sometimes wave october, vampire bbc bloody pie hudson contemporary crowd turning error helped pepper thus reaches recently [SEP]']
[Init] best rec loss: 1.741378664970398 for ['[CLS] such duo demand appeared being pv status stereotypes superlary eight song signage thing conform take pup i planetary feed free [SEP]']
[Init] best rec loss: 1.7179762125015259 for ['[CLS] ammunition nowheregut opinion deemed romansdong was mattered al body mono turkish abet main alone stations bag lead facebook [SEP]']
[Init] best rec loss: 1.6971365213394165 for ['[CLS] adam skin lissa love dannberg western wrote food serious apart departureml gameposedmat few resides because track believed [SEP]']
[Init] best perm rec loss: 1.6958225965499878 for ['[CLS]mat departure game wrote skin lissa resides adam western fewml foodnberg track apart because believed seriousposed dan love [SEP]']
[Init] best perm rec loss: 1.6951234340667725 for ['[CLS] adam few departure danmatmlposednberg food because game serious believed resides wrote lissa western apart track love skin [SEP]']
[Init] best perm rec loss: 1.6936944723129272 for ['[CLS] lissa apartml western believed love gamenberg fewposed trackmat because resides dan skin adam serious wrote food departure [SEP]']
[Init] best perm rec loss: 1.6933423280715942 for ['[CLS] track serious adamnberg gameposed apart because few wrote resides dan food skin believed westernml lissa lovemat departure [SEP]']
[Init] best perm rec loss: 1.6924365758895874 for ['[CLS] track resides departure apart few love becausenberg believed wrote lissa game adam dan skinml western seriousposedmat food [SEP]']
[Init] best perm rec loss: 1.6920912265777588 for ['[CLS]mat apart love few western skin because game believednbergml serious adam wrote track departure lissaposed food resides dan [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.435 (perp=11.951, rec=0.651, cos=0.394), tot_loss_proj:4.059 [t=0.17s]
prediction: ['[CLS] deckmissive did less scowl rage across wet had thin dangerous meant worse joke dam between from worse food woodized [SEP]']
[ 100/2000] tot_loss=3.310 (perp=11.848, rec=0.598, cos=0.342), tot_loss_proj:4.013 [t=0.17s]
prediction: ['[CLS] gracemissive doing which until toys why war had black malone a deep war dam on news worse waste war intelligence [SEP]']
[ 150/2000] tot_loss=2.914 (perp=11.157, rec=0.544, cos=0.139), tot_loss_proj:4.133 [t=0.17s]
prediction: ['[CLS] grace grace prevention for guilt movies why war had ease serbia been way movies dam to bramrable joke war police [SEP]']
[ 200/2000] tot_loss=3.037 (perp=11.665, rec=0.565, cos=0.139), tot_loss_proj:4.305 [t=0.17s]
prediction: ['[CLS] grace grace prevention for improvised specimen whyford had little malone five way movies mixtape for diplomatic you prevention war war [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.003 (perp=12.258, rec=0.500, cos=0.052), tot_loss_proj:4.199 [t=0.17s]
prediction: ['[CLS] grace grace prevention a ever specimen lack backed knocked best wasting through of playback mixtape for diplomatic peculiar prevention prevention fiction [SEP]']
[ 300/2000] tot_loss=2.749 (perp=11.071, rec=0.488, cos=0.047), tot_loss_proj:4.167 [t=0.17s]
prediction: ['[CLS] grace grace prevention for ever movie lack backed made nothing wasting as of playback mixtape for diplomatic blame prevention prevention war [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.613 (perp=10.488, rec=0.475, cos=0.041), tot_loss_proj:3.965 [t=0.17s]
prediction: ['[CLS] grace grace prevention to war movie lack backed made nothing wasting finest of playback prevention for diplomatic blame prevention war prevention [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.620 (perp=10.510, rec=0.450, cos=0.068), tot_loss_proj:3.884 [t=0.17s]
prediction: ['[CLS] grace grace prevention to prevention movie besides lack making best education best war movies prevention for diplomatic considerable prevention war prevention [SEP]']
[ 450/2000] tot_loss=2.642 (perp=10.795, rec=0.433, cos=0.049), tot_loss_proj:3.955 [t=0.17s]
prediction: ['[CLS] grace grace prevention to prevention film besides lack making best education best best movies prevention best to spared prevention war prevention [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.513 (perp=10.447, rec=0.409, cos=0.015), tot_loss_proj:3.860 [t=0.17s]
prediction: ['[CLS] grace grace prevention to prevention film besides lack making best education best best movies movies greatest to best prevention war prevention [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.424 (perp=9.913, rec=0.411, cos=0.030), tot_loss_proj:3.985 [t=0.17s]
prediction: ['[CLS] to grace prevention grace prevention film besides lack making best education best best bastards movies ones to best prevention grace prevention [SEP]']
[ 600/2000] tot_loss=2.413 (perp=9.865, rec=0.411, cos=0.029), tot_loss_proj:3.744 [t=0.17s]
prediction: ['[CLS] to grace prevention grace prevention film besides unionist making best exist best best fiction movies greatest to best prevention grace prevention [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.577 (perp=10.633, rec=0.394, cos=0.057), tot_loss_proj:4.047 [t=0.17s]
prediction: ['[CLS] to grace call grace prevention film besides making lack best exist best best bastards movies greatest to best prevention grace prevention [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.487 (perp=10.404, rec=0.381, cos=0.024), tot_loss_proj:4.035 [t=0.17s]
prediction: ['[CLS] to grace call grace prevention film besides making lack best exist best best bastards ones movies to best prevention grace prevention [SEP]']
[ 750/2000] tot_loss=2.489 (perp=10.484, rec=0.364, cos=0.029), tot_loss_proj:4.049 [t=0.17s]
prediction: ['[CLS] to grace call grace prevention film besides making lack best vietnam best best bastards ones movies to best prevention grace prevention [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.444 (perp=9.475, rec=0.448, cos=0.101), tot_loss_proj:3.716 [t=0.17s]
prediction: ['[CLS] to grace call grace prevention film besides making unionist best exist through best torture prevention movies to best prevention grace malone [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.463 (perp=10.326, rec=0.389, cos=0.009), tot_loss_proj:4.026 [t=0.19s]
prediction: ['[CLS] for grace grace call prevention film besides making unionist best exist through many anyone prevention movies to best prevention grace ones [SEP]']
[ 900/2000] tot_loss=2.456 (perp=10.334, rec=0.383, cos=0.006), tot_loss_proj:4.030 [t=0.19s]
prediction: ['[CLS] for grace grace call prevention film besides making lack best exist through many anyone prevention movies to best prevention grace ones [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.338 (perp=9.732, rec=0.361, cos=0.030), tot_loss_proj:3.914 [t=0.20s]
prediction: ['[CLS] to grace grace call prevention movies besides making lack best exist through many anyone prevention movies to best prevention grace ones [SEP]']
Attempt swap
[1000/2000] tot_loss=2.334 (perp=9.726, rec=0.357, cos=0.031), tot_loss_proj:3.853 [t=0.17s]
prediction: ['[CLS] to grace grace call prevention movies rather making lack best exist through many anyone prevention movies to best prevention grace ones [SEP]']
[1050/2000] tot_loss=2.409 (perp=10.245, rec=0.347, cos=0.013), tot_loss_proj:4.015 [t=0.17s]
prediction: ['[CLS] to grace grace call prevention movies rather making lack best exist through head anyone prevention movies to best these grace ones [SEP]']
Attempt swap
[1100/2000] tot_loss=2.611 (perp=10.551, rec=0.344, cos=0.157), tot_loss_proj:4.080 [t=0.17s]
prediction: ['[CLS] to grace grace call prevention movies rather making lack best war through head anyone prevention movies to best these grace ones [SEP]']
Attempt swap
[1150/2000] tot_loss=2.436 (perp=10.304, rec=0.346, cos=0.029), tot_loss_proj:3.988 [t=0.17s]
prediction: ['[CLS] to grace grace call prevention movies rather making lack best war through head fiction prevention movies to best these grace ones [SEP]']
[1200/2000] tot_loss=2.403 (perp=10.304, rec=0.337, cos=0.005), tot_loss_proj:3.989 [t=0.17s]
prediction: ['[CLS] to grace grace call prevention movies rather making lack best war through head fiction prevention movies to best these grace ones [SEP]']
Attempt swap
[1250/2000] tot_loss=2.500 (perp=10.641, rec=0.340, cos=0.032), tot_loss_proj:4.113 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war through head fiction prevention movies to best these grace ones [SEP]']
Attempt swap
[1300/2000] tot_loss=2.524 (perp=10.654, rec=0.335, cos=0.058), tot_loss_proj:4.078 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it head fiction prevention movies to best these grace ones [SEP]']
[1350/2000] tot_loss=2.507 (perp=10.654, rec=0.331, cos=0.045), tot_loss_proj:4.076 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it head fiction prevention movies to best these grace ones [SEP]']
Attempt swap
[1400/2000] tot_loss=2.538 (perp=10.654, rec=0.332, cos=0.075), tot_loss_proj:4.080 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it head fiction prevention movies to best these grace ones [SEP]']
Attempt swap
[1450/2000] tot_loss=2.552 (perp=10.341, rec=0.335, cos=0.149), tot_loss_proj:4.048 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it head fiction prevention movies to best actions grace ones [SEP]']
[1500/2000] tot_loss=2.472 (perp=10.654, rec=0.328, cos=0.013), tot_loss_proj:4.080 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it head fiction prevention movies to best these grace ones [SEP]']
Attempt swap
[1550/2000] tot_loss=2.383 (perp=10.230, rec=0.323, cos=0.014), tot_loss_proj:4.001 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]']
Attempt swap
[1600/2000] tot_loss=2.403 (perp=10.230, rec=0.324, cos=0.032), tot_loss_proj:4.004 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]']
[1650/2000] tot_loss=2.388 (perp=10.230, rec=0.329, cos=0.013), tot_loss_proj:4.002 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]']
Attempt swap
[1700/2000] tot_loss=2.368 (perp=10.230, rec=0.318, cos=0.004), tot_loss_proj:4.002 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]']
Attempt swap
[1750/2000] tot_loss=2.374 (perp=10.230, rec=0.319, cos=0.009), tot_loss_proj:4.003 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]']
[1800/2000] tot_loss=2.374 (perp=10.230, rec=0.320, cos=0.007), tot_loss_proj:4.000 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]']
Attempt swap
[1850/2000] tot_loss=2.379 (perp=10.230, rec=0.321, cos=0.012), tot_loss_proj:4.003 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]']
Attempt swap
[1900/2000] tot_loss=2.376 (perp=10.230, rec=0.322, cos=0.008), tot_loss_proj:4.004 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]']
[1950/2000] tot_loss=2.380 (perp=10.230, rec=0.326, cos=0.008), tot_loss_proj:4.002 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]']
Attempt swap
[2000/2000] tot_loss=2.405 (perp=10.230, rec=0.324, cos=0.034), tot_loss_proj:4.004 [t=0.17s]
prediction: ['[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] for grace grace call prevention movies rather making lack best war it ever fiction prevention movies to best actions grace ones [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 62.222 | p: 60.870 | r: 63.636
rouge2     | fm: 4.651 | p: 4.545 | r: 4.762
rougeL     | fm: 44.444 | p: 43.478 | r: 45.455
rougeLsum  | fm: 44.444 | p: 43.478 | r: 45.455
r1fm+r2fm = 66.873

[Aggregate metrics]:
rouge1     | fm: 90.933 | p: 90.612 | r: 91.290
rouge2     | fm: 53.958 | p: 53.831 | r: 54.108
rougeL     | fm: 77.308 | p: 77.164 | r: 77.561
rougeLsum  | fm: 77.122 | p: 76.921 | r: 77.367
r1fm+r2fm = 144.891

input #62 time: 0:06:58 | total time: 7:14:48


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9992646432214791
highest_index [0]
highest [0.9992646432214791]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 1.875612497329712 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 1.2830250263214111 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 1.216496467590332 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best rec loss: 1.2096959352493286 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 1.208850383758545 for ['[CLS] established named tiffany club violent [SEP]']
[Init] best rec loss: 1.1488268375396729 for ['[CLS] ice coe poor t approaching [SEP]']
[Init] best perm rec loss: 1.1447150707244873 for ['[CLS] ice t approaching poor coe [SEP]']
[Init] best perm rec loss: 1.1429733037948608 for ['[CLS] coe approaching t poor ice [SEP]']
[Init] best perm rec loss: 1.142871618270874 for ['[CLS] approaching coe poor t ice [SEP]']
[Init] best perm rec loss: 1.1421325206756592 for ['[CLS] t ice approaching poor coe [SEP]']
[Init] best perm rec loss: 1.1394460201263428 for ['[CLS] coe poor approaching t ice [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.178 (perp=9.355, rec=0.280, cos=0.028), tot_loss_proj:3.278 [t=0.18s]
prediction: ['[CLS] ticket ticket looking ticket ticket [SEP]']
[ 100/2000] tot_loss=2.368 (perp=11.131, rec=0.133, cos=0.009), tot_loss_proj:3.614 [t=0.18s]
prediction: ['[CLS] guy return looking return ticket [SEP]']
[ 150/2000] tot_loss=2.209 (perp=10.660, rec=0.073, cos=0.004), tot_loss_proj:3.092 [t=0.18s]
prediction: ['[CLS] guy for looking return ticket [SEP]']
[ 200/2000] tot_loss=2.216 (perp=10.660, rec=0.080, cos=0.004), tot_loss_proj:3.083 [t=0.18s]
prediction: ['[CLS] guy for looking return ticket [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.838 (perp=8.818, rec=0.070, cos=0.005), tot_loss_proj:2.116 [t=0.18s]
prediction: ['[CLS] looking for concrete return ticket [SEP]']
[ 300/2000] tot_loss=1.838 (perp=8.818, rec=0.071, cos=0.003), tot_loss_proj:2.117 [t=0.18s]
prediction: ['[CLS] looking for concrete return ticket [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.831 (perp=8.818, rec=0.064, cos=0.003), tot_loss_proj:2.121 [t=0.18s]
prediction: ['[CLS] looking for concrete return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.944 (perp=9.361, rec=0.069, cos=0.003), tot_loss_proj:2.159 [t=0.18s]
prediction: ['[CLS] looking for mini return ticket [SEP]']
[ 450/2000] tot_loss=1.942 (perp=9.361, rec=0.067, cos=0.003), tot_loss_proj:2.163 [t=0.18s]
prediction: ['[CLS] looking for mini return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.952 (perp=9.361, rec=0.077, cos=0.003), tot_loss_proj:2.154 [t=0.18s]
prediction: ['[CLS] looking for mini return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.948 (perp=9.361, rec=0.073, cos=0.003), tot_loss_proj:2.159 [t=0.18s]
prediction: ['[CLS] looking for mini return ticket [SEP]']
[ 600/2000] tot_loss=2.125 (perp=10.246, rec=0.072, cos=0.003), tot_loss_proj:3.245 [t=0.18s]
prediction: ['[CLS] looking for treat return ticket [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.944 (perp=9.317, rec=0.078, cos=0.003), tot_loss_proj:2.452 [t=0.18s]
prediction: ['[CLS] mini looking for return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.936 (perp=9.317, rec=0.070, cos=0.003), tot_loss_proj:2.457 [t=0.18s]
prediction: ['[CLS] mini looking for return ticket [SEP]']
[ 750/2000] tot_loss=1.941 (perp=9.317, rec=0.075, cos=0.003), tot_loss_proj:2.454 [t=0.18s]
prediction: ['[CLS] mini looking for return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.921 (perp=9.247, rec=0.068, cos=0.003), tot_loss_proj:3.368 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.935 (perp=9.247, rec=0.082, cos=0.003), tot_loss_proj:3.369 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
[ 900/2000] tot_loss=1.930 (perp=9.247, rec=0.077, cos=0.003), tot_loss_proj:3.366 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.921 (perp=9.247, rec=0.069, cos=0.003), tot_loss_proj:3.367 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.915 (perp=9.247, rec=0.062, cos=0.003), tot_loss_proj:3.368 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
[1050/2000] tot_loss=1.921 (perp=9.247, rec=0.069, cos=0.003), tot_loss_proj:3.372 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.922 (perp=9.247, rec=0.070, cos=0.003), tot_loss_proj:3.378 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.930 (perp=9.247, rec=0.078, cos=0.003), tot_loss_proj:3.373 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
[1200/2000] tot_loss=1.929 (perp=9.247, rec=0.076, cos=0.003), tot_loss_proj:3.374 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.927 (perp=9.247, rec=0.074, cos=0.003), tot_loss_proj:3.374 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.929 (perp=9.247, rec=0.077, cos=0.003), tot_loss_proj:3.377 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
[1350/2000] tot_loss=1.927 (perp=9.247, rec=0.075, cos=0.003), tot_loss_proj:3.380 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.932 (perp=9.247, rec=0.080, cos=0.003), tot_loss_proj:3.387 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.922 (perp=9.247, rec=0.070, cos=0.003), tot_loss_proj:3.384 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
[1500/2000] tot_loss=1.906 (perp=9.247, rec=0.054, cos=0.003), tot_loss_proj:3.385 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.935 (perp=9.247, rec=0.083, cos=0.003), tot_loss_proj:3.385 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.922 (perp=9.247, rec=0.070, cos=0.003), tot_loss_proj:3.387 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
[1650/2000] tot_loss=1.924 (perp=9.247, rec=0.072, cos=0.003), tot_loss_proj:3.387 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.923 (perp=9.247, rec=0.071, cos=0.003), tot_loss_proj:3.383 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.932 (perp=9.247, rec=0.079, cos=0.003), tot_loss_proj:3.385 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
[1800/2000] tot_loss=1.928 (perp=9.247, rec=0.076, cos=0.003), tot_loss_proj:3.391 [t=0.18s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.929 (perp=9.247, rec=0.076, cos=0.003), tot_loss_proj:3.382 [t=0.17s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.922 (perp=9.247, rec=0.070, cos=0.003), tot_loss_proj:3.388 [t=0.17s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
[1950/2000] tot_loss=1.935 (perp=9.247, rec=0.083, cos=0.003), tot_loss_proj:3.385 [t=0.17s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.934 (perp=9.247, rec=0.081, cos=0.003), tot_loss_proj:3.382 [t=0.17s]
prediction: ['[CLS] treat looking for return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] treat looking for return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 135.714

[Aggregate metrics]:
rouge1     | fm: 90.847 | p: 90.612 | r: 91.217
rouge2     | fm: 53.903 | p: 53.758 | r: 54.048
rougeL     | fm: 77.538 | p: 77.330 | r: 77.786
rougeLsum  | fm: 77.351 | p: 77.166 | r: 77.571
r1fm+r2fm = 144.750

input #63 time: 0:07:12 | total time: 7:22:00


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.999160846219472
highest_index [0]
highest [0.999160846219472]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 1.8793610334396362 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 1.8335012197494507 for ['[CLS]bled independence clearing [SEP]']
[Init] best rec loss: 1.8333404064178467 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 1.414121150970459 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 1.4084160327911377 for ['[CLS] spends adrian mating [SEP]']
[Init] best rec loss: 1.1607979536056519 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 1.154465675354004 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 1.1528769731521606 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.972 (perp=8.653, rec=0.209, cos=0.032), tot_loss_proj:2.059 [t=0.18s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.889 (perp=8.653, rec=0.141, cos=0.018), tot_loss_proj:2.050 [t=0.18s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.878 (perp=8.653, rec=0.135, cos=0.012), tot_loss_proj:2.056 [t=0.18s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=1.871 (perp=8.653, rec=0.128, cos=0.011), tot_loss_proj:2.052 [t=0.18s]
prediction: ['[CLS] strange horror horror [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.042 (perp=9.634, rec=0.106, cos=0.010), tot_loss_proj:2.548 [t=0.18s]
prediction: ['[CLS] strange horror strange [SEP]']
[ 300/2000] tot_loss=1.936 (perp=9.285, rec=0.077, cos=0.002), tot_loss_proj:2.192 [t=0.18s]
prediction: ['[CLS] the horror strange [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.666 (perp=8.065, rec=0.051, cos=0.002), tot_loss_proj:1.712 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.705 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.679 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.716 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.713 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.705 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.667 (perp=8.065, rec=0.052, cos=0.002), tot_loss_proj:1.711 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.708 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.712 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.687 (perp=8.065, rec=0.072, cos=0.002), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.666 (perp=8.065, rec=0.051, cos=0.002), tot_loss_proj:1.710 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.689 (perp=8.065, rec=0.074, cos=0.002), tot_loss_proj:1.707 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.716 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.707 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.668 (perp=8.065, rec=0.054, cos=0.002), tot_loss_proj:1.716 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.698 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.699 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.708 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.702 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.672 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.704 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.669 (perp=8.065, rec=0.054, cos=0.002), tot_loss_proj:1.707 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.672 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.668 (perp=8.065, rec=0.054, cos=0.002), tot_loss_proj:1.704 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.708 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.665 (perp=8.065, rec=0.050, cos=0.002), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.679 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.716 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.682 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.694 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.670 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.715 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.673 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.691 (perp=8.065, rec=0.076, cos=0.002), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.717 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.127 | p: 90.830 | r: 91.458
rouge2     | fm: 54.560 | p: 54.439 | r: 54.712
rougeL     | fm: 77.666 | p: 77.550 | r: 77.913
rougeLsum  | fm: 77.771 | p: 77.660 | r: 77.946
r1fm+r2fm = 145.687

input #64 time: 0:07:09 | total time: 7:29:09


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9992260466615117
highest_index [0]
highest [0.9992260466615117]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.9480024576187134 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 1.935711145401001 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 1.9066228866577148 for ['[CLS] stable bourne writers sp here plays spell keeping another [SEP]']
[Init] best rec loss: 1.7932060956954956 for ['[CLS] boss sucks goodbye poorlyions palestinianquest languagecliff [SEP]']
[Init] best rec loss: 1.7819745540618896 for ['[CLS] butter memorandumece happy cry laurence cum york accept [SEP]']
[Init] best rec loss: 1.7478106021881104 for ['[CLS] forth drag roger choice rival familiar howellacingbies [SEP]']
[Init] best rec loss: 1.7460284233093262 for ['[CLS] tobago resist clinched industryementga team rim cancer [SEP]']
[Init] best rec loss: 1.6370292901992798 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best rec loss: 1.5800213813781738 for ['[CLS] dreamed common evbell infantry soon duel paradise birds [SEP]']
[Init] best perm rec loss: 1.579031229019165 for ['[CLS] birds duel paradise dreamed ev infantry soonbell common [SEP]']
[Init] best perm rec loss: 1.5777679681777954 for ['[CLS] duel birds dreamed infantrybell soon ev paradise common [SEP]']
[Init] best perm rec loss: 1.57088303565979 for ['[CLS] birds commonbell infantry duel dreamed ev paradise soon [SEP]']
[Init] best perm rec loss: 1.5680181980133057 for ['[CLS] dreamed paradise duel common evbell infantry soon birds [SEP]']
[Init] best perm rec loss: 1.5678985118865967 for ['[CLS]bell common paradise dreamed birds duel infantry ev soon [SEP]']
[Init] best perm rec loss: 1.5646346807479858 for ['[CLS] birds duel dreamed infantry evbell common soon paradise [SEP]']
[Init] best perm rec loss: 1.563547968864441 for ['[CLS] dreamed duel paradise common birds evbell infantry soon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.011 (perp=8.906, rec=0.222, cos=0.008), tot_loss_proj:2.280 [t=0.17s]
prediction: ['[CLS] joy joyous film movie, joy joy from [SEP]']
[ 100/2000] tot_loss=2.051 (perp=9.508, rec=0.146, cos=0.003), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] rom joyous film movie, joy joy. [SEP]']
[ 150/2000] tot_loss=1.466 (perp=6.734, rec=0.117, cos=0.002), tot_loss_proj:2.549 [t=0.17s]
prediction: ['[CLS] rom joyous rom film, rom film. [SEP]']
[ 200/2000] tot_loss=1.375 (perp=6.364, rec=0.100, cos=0.002), tot_loss_proj:2.350 [t=0.17s]
prediction: ['[CLS] rom joyous of film, rom film. [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.360 (perp=6.364, rec=0.085, cos=0.002), tot_loss_proj:2.375 [t=0.17s]
prediction: ['[CLS] rom joyous of film, rom film. [SEP]']
[ 300/2000] tot_loss=1.353 (perp=6.364, rec=0.078, cos=0.002), tot_loss_proj:2.383 [t=0.17s]
prediction: ['[CLS] rom joyous of film, rom film. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.523 (perp=7.249, rec=0.072, cos=0.002), tot_loss_proj:2.286 [t=0.17s]
prediction: ['[CLS] rom joyous of film,p film. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.403 (perp=6.620, rec=0.077, cos=0.002), tot_loss_proj:2.242 [t=0.17s]
prediction: ['[CLS] rom joyous of film, filmp. [SEP]']
[ 450/2000] tot_loss=1.403 (perp=6.620, rec=0.077, cos=0.002), tot_loss_proj:2.237 [t=0.17s]
prediction: ['[CLS] rom joyous of film, filmp. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.240 (perp=5.689, rec=0.100, cos=0.002), tot_loss_proj:1.548 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.223 (perp=5.689, rec=0.083, cos=0.002), tot_loss_proj:1.556 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
[ 600/2000] tot_loss=1.220 (perp=5.689, rec=0.081, cos=0.002), tot_loss_proj:1.544 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.209 (perp=5.689, rec=0.069, cos=0.002), tot_loss_proj:1.553 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.222 (perp=5.689, rec=0.083, cos=0.002), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
[ 750/2000] tot_loss=1.219 (perp=5.689, rec=0.079, cos=0.002), tot_loss_proj:1.546 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.216 (perp=5.689, rec=0.076, cos=0.002), tot_loss_proj:1.555 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.218 (perp=5.689, rec=0.079, cos=0.002), tot_loss_proj:1.554 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
[ 900/2000] tot_loss=1.221 (perp=5.689, rec=0.081, cos=0.002), tot_loss_proj:1.551 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.220 (perp=5.689, rec=0.080, cos=0.002), tot_loss_proj:1.555 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.210 (perp=5.689, rec=0.071, cos=0.002), tot_loss_proj:1.555 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
[1050/2000] tot_loss=1.217 (perp=5.689, rec=0.078, cos=0.002), tot_loss_proj:1.552 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.217 (perp=5.689, rec=0.078, cos=0.002), tot_loss_proj:1.555 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.218 (perp=5.689, rec=0.079, cos=0.002), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
[1200/2000] tot_loss=1.214 (perp=5.689, rec=0.075, cos=0.002), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.210 (perp=5.689, rec=0.070, cos=0.002), tot_loss_proj:1.560 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.212 (perp=5.689, rec=0.073, cos=0.002), tot_loss_proj:1.554 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
[1350/2000] tot_loss=1.210 (perp=5.689, rec=0.071, cos=0.002), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.207 (perp=5.689, rec=0.068, cos=0.002), tot_loss_proj:1.561 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.209 (perp=5.689, rec=0.069, cos=0.002), tot_loss_proj:1.552 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
[1500/2000] tot_loss=1.212 (perp=5.689, rec=0.073, cos=0.002), tot_loss_proj:1.563 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.215 (perp=5.689, rec=0.076, cos=0.002), tot_loss_proj:1.549 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.219 (perp=5.689, rec=0.080, cos=0.002), tot_loss_proj:1.548 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
[1650/2000] tot_loss=1.214 (perp=5.689, rec=0.074, cos=0.002), tot_loss_proj:1.547 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.223 (perp=5.689, rec=0.083, cos=0.002), tot_loss_proj:1.551 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.215 (perp=5.689, rec=0.075, cos=0.002), tot_loss_proj:1.554 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
[1800/2000] tot_loss=1.223 (perp=5.689, rec=0.084, cos=0.002), tot_loss_proj:1.546 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.204 (perp=5.689, rec=0.064, cos=0.002), tot_loss_proj:1.551 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.223 (perp=5.689, rec=0.084, cos=0.002), tot_loss_proj:1.550 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
[1950/2000] tot_loss=1.215 (perp=5.689, rec=0.075, cos=0.002), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.219 (perp=5.689, rec=0.080, cos=0.002), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] joyous of film, film romp. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joyous of film, film romp. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 91.009 | p: 90.753 | r: 91.336
rouge2     | fm: 54.052 | p: 53.927 | r: 54.182
rougeL     | fm: 77.667 | p: 77.419 | r: 77.879
rougeLsum  | fm: 77.652 | p: 77.499 | r: 77.868
r1fm+r2fm = 145.061

input #65 time: 0:06:42 | total time: 7:35:52


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9992330092949469
highest_index [0]
highest [0.9992330092949469]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 1.9587653875350952 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 1.838042974472046 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 1.8294860124588013 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 1.8049302101135254 for ['[CLS] school divisional labor liberals [SEP]']
[Init] best rec loss: 1.6972644329071045 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 1.5281866788864136 for ['[CLS] background leader screen [CLS] [SEP]']
[Init] best rec loss: 1.4521524906158447 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best rec loss: 1.2160919904708862 for ['[CLS] finish eachensis clark [SEP]']
[Init] best perm rec loss: 1.2056833505630493 for ['[CLS] each clarkensis finish [SEP]']
[Init] best perm rec loss: 1.2052438259124756 for ['[CLS]ensis each clark finish [SEP]']
[Init] best perm rec loss: 1.202699899673462 for ['[CLS]ensis clark each finish [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.217 (perp=9.820, rec=0.243, cos=0.010), tot_loss_proj:2.708 [t=0.17s]
prediction: ['[CLS] fan tolkien fan fans [SEP]']
[ 100/2000] tot_loss=2.071 (perp=9.911, rec=0.087, cos=0.002), tot_loss_proj:2.215 [t=0.17s]
prediction: ['[CLS] a tolkien longtime fan [SEP]']
[ 150/2000] tot_loss=2.051 (perp=9.911, rec=0.067, cos=0.002), tot_loss_proj:2.219 [t=0.17s]
prediction: ['[CLS] a tolkien longtime fan [SEP]']
[ 200/2000] tot_loss=2.042 (perp=9.911, rec=0.058, cos=0.001), tot_loss_proj:2.205 [t=0.17s]
prediction: ['[CLS] a tolkien longtime fan [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.603 (perp=7.673, rec=0.067, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.587 (perp=7.673, rec=0.051, cos=0.002), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.592 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.587 (perp=7.673, rec=0.051, cos=0.002), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.589 (perp=7.673, rec=0.053, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.588 (perp=7.673, rec=0.051, cos=0.002), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.605 (perp=7.673, rec=0.069, cos=0.002), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.593 (perp=7.673, rec=0.057, cos=0.002), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.589 (perp=7.673, rec=0.053, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.590 (perp=7.673, rec=0.053, cos=0.002), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.607 (perp=7.673, rec=0.071, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.604 (perp=7.673, rec=0.068, cos=0.002), tot_loss_proj:1.592 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.605 (perp=7.673, rec=0.069, cos=0.002), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.584 (perp=7.673, rec=0.048, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.587 (perp=7.673, rec=0.051, cos=0.002), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.610 (perp=7.673, rec=0.074, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.591 (perp=7.673, rec=0.055, cos=0.002), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.593 (perp=7.673, rec=0.057, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.160 | p: 90.875 | r: 91.494
rouge2     | fm: 54.722 | p: 54.623 | r: 54.874
rougeL     | fm: 78.045 | p: 77.861 | r: 78.228
rougeLsum  | fm: 77.998 | p: 77.801 | r: 78.188
r1fm+r2fm = 145.881

input #66 time: 0:06:41 | total time: 7:42:33


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.999292690019056
highest_index [0]
highest [0.999292690019056]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.834237813949585 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 1.7785722017288208 for ['[CLS] ^ banksgger biology mont neck administration action pool neo [SEP]']
[Init] best rec loss: 1.7256571054458618 for ['[CLS] mortonructured hendricks partial banned time jae published leave psalm [SEP]']
[Init] best rec loss: 1.69612717628479 for ['[CLS] practically squadron pacific cheated rick under countryorð⁄₄ [SEP]']
[Init] best rec loss: 1.6957756280899048 for ['[CLS]lusionunt sign utah america zeppelin light katy outbreak betray [SEP]']
[Init] best rec loss: 1.6956020593643188 for ['[CLS] [ script part song log principal custom enlisted cabinet charged [SEP]']
[Init] best rec loss: 1.676373839378357 for ['[CLS] marcus cause rudder straight mustered ordinary competitive population getting believe [SEP]']
[Init] best rec loss: 1.6748206615447998 for ['[CLS] vessel definitearound attendant visionrained league nearest sets nut [SEP]']
[Init] best perm rec loss: 1.6736490726470947 for ['[CLS]around nut definiterained vessel league vision attendant nearest sets [SEP]']
[Init] best perm rec loss: 1.6704751253128052 for ['[CLS]around nearestrained definite attendant sets league vision nut vessel [SEP]']
[Init] best perm rec loss: 1.6678307056427002 for ['[CLS] leaguearound vesselrained attendant sets nearest vision definite nut [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.916 (perp=12.860, rec=0.327, cos=0.017), tot_loss_proj:3.517 [t=0.17s]
prediction: ['[CLS] heart werewolves heart urban seemingly belle kind kind kind kind [SEP]']
[ 100/2000] tot_loss=3.230 (perp=15.013, rec=0.221, cos=0.006), tot_loss_proj:4.848 [t=0.17s]
prediction: ['[CLS] heartpod heart nonwar born kindwarentalental [SEP]']
[ 150/2000] tot_loss=3.205 (perp=15.234, rec=0.156, cos=0.003), tot_loss_proj:4.972 [t=0.17s]
prediction: ['[CLS] heartpod heart nongm patient kindwarentalental [SEP]']
[ 200/2000] tot_loss=2.672 (perp=12.746, rec=0.121, cos=0.002), tot_loss_proj:4.021 [t=0.17s]
prediction: ['[CLS] heart dimensional heart nongm, kindwarentalental [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.335 (perp=10.236, rec=0.279, cos=0.009), tot_loss_proj:2.861 [t=0.17s]
prediction: ['[CLS] heartsp, kindwarminggm nongmental [SEP]']
[ 300/2000] tot_loss=2.232 (perp=10.288, rec=0.172, cos=0.002), tot_loss_proj:3.233 [t=0.17s]
prediction: ['[CLS] heartgm, kindwarmingde nongmental [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.847 (perp=8.557, rec=0.133, cos=0.002), tot_loss_proj:2.375 [t=0.17s]
prediction: ['[CLS]gm, kind heartwarminggm nongmental [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.805 (perp=8.362, rec=0.131, cos=0.002), tot_loss_proj:2.308 [t=0.17s]
prediction: ['[CLS]gm, kind heartwarming nongmgmental [SEP]']
[ 450/2000] tot_loss=1.786 (perp=8.362, rec=0.112, cos=0.002), tot_loss_proj:2.271 [t=0.17s]
prediction: ['[CLS]gm, kind heartwarming nongmgmental [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.782 (perp=8.362, rec=0.108, cos=0.002), tot_loss_proj:2.271 [t=0.17s]
prediction: ['[CLS]gm, kind heartwarming nongmgmental [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.755 (perp=7.820, rec=0.188, cos=0.004), tot_loss_proj:2.005 [t=0.17s]
prediction: ['[CLS], kind heartwarming nongmgmgmental [SEP]']
[ 600/2000] tot_loss=1.687 (perp=7.820, rec=0.121, cos=0.002), tot_loss_proj:2.079 [t=0.17s]
prediction: ['[CLS], kind heartwarming nongmgmgmental [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.680 (perp=7.820, rec=0.114, cos=0.002), tot_loss_proj:2.081 [t=0.17s]
prediction: ['[CLS], kind heartwarming nongmgmgmental [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.654 (perp=7.706, rec=0.111, cos=0.002), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
[ 750/2000] tot_loss=1.649 (perp=7.706, rec=0.106, cos=0.002), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.645 (perp=7.706, rec=0.102, cos=0.002), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.637 (perp=7.706, rec=0.094, cos=0.002), tot_loss_proj:1.961 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
[ 900/2000] tot_loss=1.640 (perp=7.706, rec=0.097, cos=0.002), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.651 (perp=7.706, rec=0.108, cos=0.002), tot_loss_proj:1.952 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[1000/2000] tot_loss=1.632 (perp=7.706, rec=0.089, cos=0.002), tot_loss_proj:1.945 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
[1050/2000] tot_loss=1.632 (perp=7.706, rec=0.089, cos=0.002), tot_loss_proj:1.948 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.635 (perp=7.706, rec=0.093, cos=0.002), tot_loss_proj:1.957 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[1150/2000] tot_loss=1.647 (perp=7.706, rec=0.105, cos=0.002), tot_loss_proj:1.951 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
[1200/2000] tot_loss=1.640 (perp=7.706, rec=0.097, cos=0.002), tot_loss_proj:1.945 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[1250/2000] tot_loss=1.636 (perp=7.706, rec=0.093, cos=0.002), tot_loss_proj:1.951 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[1300/2000] tot_loss=1.636 (perp=7.706, rec=0.093, cos=0.002), tot_loss_proj:1.944 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
[1350/2000] tot_loss=1.634 (perp=7.706, rec=0.091, cos=0.002), tot_loss_proj:1.951 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[1400/2000] tot_loss=1.629 (perp=7.706, rec=0.087, cos=0.001), tot_loss_proj:1.955 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.635 (perp=7.706, rec=0.092, cos=0.002), tot_loss_proj:1.943 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
[1500/2000] tot_loss=1.636 (perp=7.706, rec=0.093, cos=0.002), tot_loss_proj:1.949 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[1550/2000] tot_loss=1.626 (perp=7.706, rec=0.084, cos=0.002), tot_loss_proj:1.947 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[1600/2000] tot_loss=1.629 (perp=7.706, rec=0.086, cos=0.002), tot_loss_proj:1.948 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
[1650/2000] tot_loss=1.626 (perp=7.706, rec=0.083, cos=0.002), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[1700/2000] tot_loss=1.633 (perp=7.706, rec=0.090, cos=0.002), tot_loss_proj:1.948 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.633 (perp=7.706, rec=0.090, cos=0.002), tot_loss_proj:1.952 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
[1800/2000] tot_loss=1.627 (perp=7.706, rec=0.084, cos=0.002), tot_loss_proj:1.948 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[1850/2000] tot_loss=1.637 (perp=7.706, rec=0.094, cos=0.002), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[1900/2000] tot_loss=1.619 (perp=7.706, rec=0.076, cos=0.002), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
[1950/2000] tot_loss=1.635 (perp=7.706, rec=0.093, cos=0.002), tot_loss_proj:1.948 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Attempt swap
[2000/2000] tot_loss=1.626 (perp=7.706, rec=0.083, cos=0.001), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] kind, heartwarming nongmgmgmental [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] kind, heartwarming nongmgmgmental [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 80.000

[Aggregate metrics]:
rouge1     | fm: 90.973 | p: 90.706 | r: 91.267
rouge2     | fm: 53.979 | p: 53.861 | r: 54.126
rougeL     | fm: 77.763 | p: 77.622 | r: 77.970
rougeLsum  | fm: 77.698 | p: 77.491 | r: 77.917
r1fm+r2fm = 144.952

input #67 time: 0:06:40 | total time: 7:49:13


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9992789242841313
highest_index [0]
highest [0.9992789242841313]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 1.9883288145065308 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 1.9612467288970947 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 1.6541982889175415 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 1.6288515329360962 for ['[CLS] °f force recreationalyde fighting extras who livestock guaranteed singles short gloves kitchen [SEP]']
[Init] best rec loss: 1.6066203117370605 for ['[CLS] collecting congresses hundred slightest summit survive [CLS] although fred diego fantastic relief? [SEP]']
[Init] best rec loss: 1.5576926469802856 for ['[CLS] $ offs dreams national been wallszzsar council frederick but lankan comprehensive [SEP]']
[Init] best rec loss: 1.459212064743042 for ['[CLS] feelings stole besides spoil bit prone decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 1.1719552278518677 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 1.1586320400238037 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 1.1505303382873535 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 1.1384704113006592 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 1.1313153505325317 for ['[CLS]iferous beth died form. floor councils riding medalyn view possibly comfort [SEP]']
[Init] best perm rec loss: 1.1300716400146484 for ['[CLS]yniferous comfort beth floor form possibly medal riding view. councils died [SEP]']
[Init] best perm rec loss: 1.1216068267822266 for ['[CLS]yn comfort riding possiblyiferous beth councils form floor medal. view died [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.693 (perp=12.312, rec=0.223, cos=0.007), tot_loss_proj:3.105 [t=0.17s]
prediction: ['[CLS]ently barelyco absurd un absurd absurd form absurd absurdsible absurdco [SEP]']
[ 100/2000] tot_loss=2.515 (perp=11.832, rec=0.146, cos=0.003), tot_loss_proj:2.904 [t=0.17s]
prediction: ['[CLS]co andco absurd inc absurd vicioussible vicious un, absurdco [SEP]']
[ 150/2000] tot_loss=2.245 (perp=10.652, rec=0.112, cos=0.002), tot_loss_proj:2.651 [t=0.17s]
prediction: ['[CLS]co andco absurduthsible vicious, vicious un, absurdsible [SEP]']
[ 200/2000] tot_loss=2.530 (perp=12.178, rec=0.092, cos=0.002), tot_loss_proj:2.957 [t=0.17s]
prediction: ['[CLS]omp andco absurduthsible vicious, vicious un, absurdhen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.203 (perp=10.603, rec=0.080, cos=0.003), tot_loss_proj:2.582 [t=0.17s]
prediction: ['[CLS]omp andco unuthsible vicious, vicious absurd, absurdhen [SEP]']
[ 300/2000] tot_loss=2.476 (perp=12.007, rec=0.073, cos=0.002), tot_loss_proj:2.909 [t=0.17s]
prediction: ['[CLS]omp andco unuthsible vicious, vicious inc, absurdhen [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.155 (perp=10.395, rec=0.074, cos=0.002), tot_loss_proj:2.549 [t=0.17s]
prediction: ['[CLS]omp and uncouthsible vicious, vicious inc, absurdhen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.907 (perp=9.143, rec=0.077, cos=0.002), tot_loss_proj:2.269 [t=0.17s]
prediction: ['[CLS]omp and uncouth, vicious, vicious incsible absurdhen [SEP]']
[ 450/2000] tot_loss=1.898 (perp=9.143, rec=0.068, cos=0.001), tot_loss_proj:2.281 [t=0.17s]
prediction: ['[CLS]omp and uncouth, vicious, vicious incsible absurdhen [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.659 (perp=7.779, rec=0.101, cos=0.002), tot_loss_proj:1.947 [t=0.17s]
prediction: ['[CLS]sible and uncouth, vicious, vicious incomp absurdhen [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.474 (perp=6.826, rec=0.107, cos=0.002), tot_loss_proj:1.681 [t=0.17s]
prediction: ['[CLS]sible and uncouth, vicious, vicious incomphen absurd [SEP]']
[ 600/2000] tot_loss=1.452 (perp=6.826, rec=0.085, cos=0.002), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS]sible and uncouth, vicious, vicious incomphen absurd [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.339 (perp=6.240, rec=0.089, cos=0.002), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] absurd and uncouth, vicious, vicious incomphensible [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.244 (perp=5.705, rec=0.101, cos=0.002), tot_loss_proj:1.388 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
[ 750/2000] tot_loss=1.219 (perp=5.705, rec=0.076, cos=0.001), tot_loss_proj:1.395 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.218 (perp=5.705, rec=0.076, cos=0.001), tot_loss_proj:1.396 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.219 (perp=5.705, rec=0.077, cos=0.001), tot_loss_proj:1.396 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
[ 900/2000] tot_loss=1.217 (perp=5.705, rec=0.074, cos=0.001), tot_loss_proj:1.394 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.210 (perp=5.705, rec=0.068, cos=0.001), tot_loss_proj:1.392 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[1000/2000] tot_loss=1.218 (perp=5.705, rec=0.076, cos=0.001), tot_loss_proj:1.390 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
[1050/2000] tot_loss=1.219 (perp=5.705, rec=0.076, cos=0.001), tot_loss_proj:1.401 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[1100/2000] tot_loss=1.226 (perp=5.705, rec=0.083, cos=0.001), tot_loss_proj:1.397 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[1150/2000] tot_loss=1.205 (perp=5.705, rec=0.063, cos=0.001), tot_loss_proj:1.399 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
[1200/2000] tot_loss=1.214 (perp=5.705, rec=0.071, cos=0.001), tot_loss_proj:1.395 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[1250/2000] tot_loss=1.214 (perp=5.705, rec=0.071, cos=0.001), tot_loss_proj:1.395 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.213 (perp=5.705, rec=0.071, cos=0.001), tot_loss_proj:1.395 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
[1350/2000] tot_loss=1.213 (perp=5.705, rec=0.071, cos=0.001), tot_loss_proj:1.397 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.215 (perp=5.705, rec=0.073, cos=0.001), tot_loss_proj:1.391 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.217 (perp=5.705, rec=0.074, cos=0.001), tot_loss_proj:1.403 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
[1500/2000] tot_loss=1.207 (perp=5.705, rec=0.065, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[1550/2000] tot_loss=1.211 (perp=5.705, rec=0.069, cos=0.001), tot_loss_proj:1.403 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[1600/2000] tot_loss=1.212 (perp=5.705, rec=0.070, cos=0.001), tot_loss_proj:1.406 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
[1650/2000] tot_loss=1.215 (perp=5.705, rec=0.072, cos=0.001), tot_loss_proj:1.400 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[1700/2000] tot_loss=1.213 (perp=5.705, rec=0.071, cos=0.001), tot_loss_proj:1.408 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[1750/2000] tot_loss=1.213 (perp=5.705, rec=0.070, cos=0.001), tot_loss_proj:1.397 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
[1800/2000] tot_loss=1.218 (perp=5.705, rec=0.076, cos=0.001), tot_loss_proj:1.399 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[1850/2000] tot_loss=1.215 (perp=5.705, rec=0.073, cos=0.001), tot_loss_proj:1.398 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[1900/2000] tot_loss=1.217 (perp=5.705, rec=0.074, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
[1950/2000] tot_loss=1.214 (perp=5.705, rec=0.071, cos=0.001), tot_loss_proj:1.395 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Attempt swap
[2000/2000] tot_loss=1.211 (perp=5.705, rec=0.068, cos=0.001), tot_loss_proj:1.400 [t=0.17s]
prediction: ['[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] absurd, uncouth, vicious and vicious incomphensible [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 95.385

[Aggregate metrics]:
rouge1     | fm: 90.861 | p: 90.509 | r: 91.261
rouge2     | fm: 53.503 | p: 53.349 | r: 53.642
rougeL     | fm: 77.439 | p: 77.236 | r: 77.738
rougeLsum  | fm: 77.527 | p: 77.315 | r: 77.781
r1fm+r2fm = 144.364

input #68 time: 0:06:42 | total time: 7:55:55


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9992908222867736
highest_index [0]
highest [0.9992908222867736]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.8529300689697266 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 1.7803916931152344 for ['[CLS] pretty campus department slow behind alias laborphobia really abilityrama sl offices markers schedule maximum [SEP]']
[Init] best rec loss: 1.777809977531433 for ['[CLS] link mark andgi gutierrez exile planwriter bot amateur innings dreaming chestots those watershed [SEP]']
[Init] best rec loss: 1.6611499786376953 for ['[CLS] squadong it code recording why what qualifyingjonpsy bad bound paintings nuclear only panchayat [SEP]']
[Init] best rec loss: 1.5930790901184082 for ["[CLS] wait pale s force'an tyne km honey teaching contemporaryable finn over thanked favourite [SEP]"]
[Init] best perm rec loss: 1.5880229473114014 for ["[CLS] finn teaching honey s contemporary thanked favourite over wait km an force tyneable'pale [SEP]"]
[Init] best perm rec loss: 1.587775468826294 for ["[CLS]'thanked finn favourite contemporary pale teaching wait km an s over tyne honeyable force [SEP]"]
[Init] best perm rec loss: 1.585741400718689 for ["[CLS] over honey contemporary s favourite thanked tyne km finn pale'force teaching waitable an [SEP]"]
[Init] best perm rec loss: 1.5847747325897217 for ["[CLS] honey forceable s pale an teaching contemporary km finn thanked favourite over wait'tyne [SEP]"]
[Init] best perm rec loss: 1.5815293788909912 for ["[CLS] thanked s tyne favourite'pale teaching km finn contemporary force anable honey over wait [SEP]"]
[Init] best perm rec loss: 1.58074951171875 for ["[CLS] pale s over teaching km thanked favourite'finn tyne forceable honey wait contemporary an [SEP]"]
[Init] best perm rec loss: 1.5794026851654053 for ["[CLS] tyneable s wait favourite pale finn force contemporary thanked over km'teaching honey an [SEP]"]
[Init] best perm rec loss: 1.5793405771255493 for ["[CLS] over honey contemporary tyne teaching favourite finn sable force'an wait km pale thanked [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=3.395 (perp=11.679, rec=0.635, cos=0.424), tot_loss_proj:4.090 [t=0.17s]
prediction: ['[CLS] actually presentation behind stood on adult transmitter hit - is charley district me analysis. dead [SEP]']
[ 100/2000] tot_loss=3.362 (perp=11.600, rec=0.640, cos=0.402), tot_loss_proj:4.050 [t=0.17s]
prediction: ['[CLS] actually ( never, bad blond damn sight ( house knife tone hurry name liquor dead [SEP]']
[ 150/2000] tot_loss=3.777 (perp=11.626, rec=0.919, cos=0.533), tot_loss_proj:3.889 [t=0.17s]
prediction: ['[CLS] actually a weak gun diabetes ª gonna but [SEP] ( of tone bother obvious con weak [SEP]']
[ 200/2000] tot_loss=3.758 (perp=12.081, rec=0.791, cos=0.550), tot_loss_proj:4.174 [t=0.17s]
prediction: ['[CLS] 2 as unlike administrative sounded your @mail [SEP] ( damn symptoms [SEP] that write weak [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.488 (perp=11.866, rec=0.694, cos=0.420), tot_loss_proj:4.239 [t=0.17s]
prediction: ['[CLS] 3 as you administrative un unlike @ki [SEP] where autumn symptoms [SEP] that write weak [SEP]']
[ 300/2000] tot_loss=3.254 (perp=11.365, rec=0.639, cos=0.342), tot_loss_proj:4.225 [t=0.17s]
prediction: ['[CLS] short as you administrative bit unlike @ya [SEP] : autumn symptoms [SEP] that fourth beautiful [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.875 (perp=10.133, rec=0.607, cos=0.242), tot_loss_proj:4.015 [t=0.17s]
prediction: ['[CLS] short as i administrative bit unlike [SEP] @ya : survivor symptoms [SEP] a specifically beautiful [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.941 (perp=10.926, rec=0.585, cos=0.171), tot_loss_proj:4.225 [t=0.17s]
prediction: ['[CLS] weird as i administrative kind unlike [SEP]factory : @ survivor symptoms [SEP] a specifically beautiful [SEP]']
[ 450/2000] tot_loss=2.947 (perp=11.255, rec=0.568, cos=0.128), tot_loss_proj:4.216 [t=0.17s]
prediction: ['[CLS] weird as i administrative kind unlike [SEP]factory : @ survivor symptoms [SEP] a early beautiful [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.933 (perp=11.100, rec=0.557, cos=0.156), tot_loss_proj:4.283 [t=0.17s]
prediction: ['[CLS] weird : i administrative kind [SEP] unlikefactory : @ survivor symptoms [SEP], early beautiful [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.684 (perp=10.385, rec=0.544, cos=0.063), tot_loss_proj:4.164 [t=0.19s]
prediction: ['[CLS] short : i administrative kind [SEP] unlikefactory : @ damned symptoms [SEP], early beautiful [SEP]']
[ 600/2000] tot_loss=2.644 (perp=10.126, rec=0.540, cos=0.079), tot_loss_proj:4.075 [t=0.17s]
prediction: ['[CLS] a : i administrative handsome [SEP] unlikefactory : @ damned symptoms [SEP], wrote beautiful [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.706 (perp=10.543, rec=0.535, cos=0.063), tot_loss_proj:4.119 [t=0.17s]
prediction: ['[CLS] a : i administrative handsome [SEP] unlikefactory :... damned symptoms [SEP], wrote beautiful [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.656 (perp=10.363, rec=0.531, cos=0.053), tot_loss_proj:4.085 [t=0.17s]
prediction: ['[CLS] a : i administrative handsome [SEP]... encoded : unlike damned symptoms [SEP], wrote beautiful [SEP]']
[ 750/2000] tot_loss=2.674 (perp=10.549, rec=0.522, cos=0.042), tot_loss_proj:4.086 [t=0.17s]
prediction: ['[CLS] a : ibine handsome [SEP]... encoded : unlike damned symptoms [SEP], because beautiful [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.715 (perp=10.787, rec=0.516, cos=0.041), tot_loss_proj:3.861 [t=0.17s]
prediction: ['[CLS] a : ibine handsome [SEP]...charged : unlike damned symptoms [SEP],. beautiful [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.655 (perp=10.454, rec=0.522, cos=0.041), tot_loss_proj:4.086 [t=0.17s]
prediction: ['[CLS] a : ibine handsome [SEP]charged... : missy damned symptoms [SEP],. beautiful [SEP]']
[ 900/2000] tot_loss=2.641 (perp=10.489, rec=0.511, cos=0.033), tot_loss_proj:4.094 [t=0.17s]
prediction: ['[CLS] a : ibine handsome [SEP]charged... : rating damned symptoms [SEP],. beautiful [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.727 (perp=10.944, rec=0.503, cos=0.035), tot_loss_proj:4.020 [t=0.17s]
prediction: ['[CLS] - : ibine handsome [SEP]charged... : rating lengths symptoms [SEP],. beautiful [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.595 (perp=10.247, rec=0.507, cos=0.038), tot_loss_proj:3.909 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged... : rating lengths [SEP] symptoms,. beautiful [SEP]']
[1050/2000] tot_loss=2.586 (perp=10.247, rec=0.501, cos=0.036), tot_loss_proj:3.909 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged... : rating lengths [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[1100/2000] tot_loss=2.563 (perp=10.220, rec=0.494, cos=0.026), tot_loss_proj:3.898 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged... : rating another [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[1150/2000] tot_loss=2.566 (perp=10.220, rec=0.495, cos=0.027), tot_loss_proj:3.898 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged... : rating another [SEP] symptoms,. beautiful [SEP]']
[1200/2000] tot_loss=2.586 (perp=10.300, rec=0.500, cos=0.026), tot_loss_proj:3.899 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged... : ratingjit [SEP] symptoms,. beautiful [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.528 (perp=9.996, rec=0.502, cos=0.026), tot_loss_proj:3.641 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged rating : bulletjit [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[1300/2000] tot_loss=2.523 (perp=9.996, rec=0.500, cos=0.023), tot_loss_proj:3.642 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged rating : bulletjit [SEP] symptoms,. beautiful [SEP]']
[1350/2000] tot_loss=2.514 (perp=9.996, rec=0.491, cos=0.024), tot_loss_proj:3.642 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged rating : bulletjit [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[1400/2000] tot_loss=2.608 (perp=10.442, rec=0.495, cos=0.024), tot_loss_proj:3.855 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged rating : bullet terri [SEP] symptoms,. beautiful [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.500 (perp=9.931, rec=0.490, cos=0.024), tot_loss_proj:3.825 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged bullet : ratingjit [SEP] symptoms,. beautiful [SEP]']
[1500/2000] tot_loss=2.509 (perp=9.995, rec=0.488, cos=0.022), tot_loss_proj:3.851 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged bullet : rating terri [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[1550/2000] tot_loss=2.505 (perp=9.995, rec=0.487, cos=0.019), tot_loss_proj:3.850 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged bullet : rating terri [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[1600/2000] tot_loss=2.502 (perp=9.995, rec=0.484, cos=0.018), tot_loss_proj:3.847 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged bullet : rating terri [SEP] symptoms,. beautiful [SEP]']
[1650/2000] tot_loss=2.506 (perp=9.995, rec=0.487, cos=0.020), tot_loss_proj:3.856 [t=0.17s]
prediction: ['[CLS] - : i province handsome [SEP]charged bullet : rating terri [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[1700/2000] tot_loss=2.502 (perp=9.962, rec=0.490, cos=0.020), tot_loss_proj:3.666 [t=0.17s]
prediction: ['[CLS] - : i province handsome -charged bullet : rating terri [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[1750/2000] tot_loss=2.490 (perp=9.962, rec=0.481, cos=0.017), tot_loss_proj:3.668 [t=0.17s]
prediction: ['[CLS] - : i province handsome -charged bullet : rating terri [SEP] symptoms,. beautiful [SEP]']
[1800/2000] tot_loss=2.400 (perp=9.492, rec=0.483, cos=0.018), tot_loss_proj:3.586 [t=0.17s]
prediction: ['[CLS] - : i province - -charged bullet : rating terri [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[1850/2000] tot_loss=2.399 (perp=9.492, rec=0.485, cos=0.016), tot_loss_proj:3.584 [t=0.17s]
prediction: ['[CLS] - : i province - -charged bullet : rating terri [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[1900/2000] tot_loss=2.402 (perp=9.492, rec=0.485, cos=0.018), tot_loss_proj:3.591 [t=0.17s]
prediction: ['[CLS] - : i province - -charged bullet : rating terri [SEP] symptoms,. beautiful [SEP]']
[1950/2000] tot_loss=2.319 (perp=9.084, rec=0.485, cos=0.016), tot_loss_proj:3.851 [t=0.17s]
prediction: ['[CLS] - : i province - -charged bullet : rating bullshit [SEP] symptoms,. beautiful [SEP]']
Attempt swap
[2000/2000] tot_loss=2.314 (perp=9.084, rec=0.480, cos=0.017), tot_loss_proj:3.851 [t=0.17s]
prediction: ['[CLS] - : i province - -charged bullet : rating bullshit [SEP] symptoms,. beautiful [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] - : i province - -charged bullet : rating bullshit [SEP] symptoms,. beautiful [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 19.048 | p: 18.182 | r: 20.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 19.048 | p: 18.182 | r: 20.000
rougeLsum  | fm: 19.048 | p: 18.182 | r: 20.000
r1fm+r2fm = 19.048

[Aggregate metrics]:
rouge1     | fm: 89.897 | p: 89.564 | r: 90.283
rouge2     | fm: 52.665 | p: 52.558 | r: 52.821
rougeL     | fm: 76.745 | p: 76.505 | r: 77.065
rougeLsum  | fm: 76.566 | p: 76.379 | r: 76.853
r1fm+r2fm = 142.562

input #69 time: 0:06:46 | total time: 8:02:42


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9993748902467187
highest_index [0]
highest [0.9993748902467187]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 1.7679567337036133 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 1.536930799484253 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 1.408258080482483 for ['[CLS] buenos sol aspects powerful otherpass wallace [SEP]']
[Init] best rec loss: 1.3998394012451172 for ['[CLS] piano myth casualty immediately vocal right bottle [SEP]']
[Init] best rec loss: 1.2374904155731201 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 1.2105610370635986 for ['[CLS] meg admitthermal success prize debut falcon [SEP]']
[Init] best rec loss: 1.1166847944259644 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 1.1123631000518799 for ['[CLS] modern bobbution guy ি muscle party [SEP]']
[Init] best perm rec loss: 1.110944390296936 for ['[CLS] িbution guy party muscle modern bob [SEP]']
[Init] best perm rec loss: 1.1077313423156738 for ['[CLS] muscle িbution party guy modern bob [SEP]']
[Init] best perm rec loss: 1.1058592796325684 for ['[CLS] bob guy modern muscle িbution party [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.028 (perp=13.405, rec=0.320, cos=0.027), tot_loss_proj:3.596 [t=0.17s]
prediction: ['[CLS]unk crash. getsunk screen screen [SEP]']
[ 100/2000] tot_loss=2.747 (perp=12.857, rec=0.165, cos=0.011), tot_loss_proj:3.857 [t=0.17s]
prediction: ['[CLS]unky on gets cl screen screen [SEP]']
[ 150/2000] tot_loss=2.378 (perp=11.285, rec=0.114, cos=0.008), tot_loss_proj:3.078 [t=0.17s]
prediction: ['[CLS]unky on gets cl the screen [SEP]']
[ 200/2000] tot_loss=2.346 (perp=11.285, rec=0.086, cos=0.003), tot_loss_proj:3.082 [t=0.17s]
prediction: ['[CLS]unky on gets cl the screen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.017 (perp=9.616, rec=0.088, cos=0.006), tot_loss_proj:2.748 [t=0.17s]
prediction: ['[CLS]unky cl gets on the screen [SEP]']
[ 300/2000] tot_loss=1.992 (perp=9.616, rec=0.067, cos=0.001), tot_loss_proj:2.767 [t=0.17s]
prediction: ['[CLS]unky cl gets on the screen [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.380 (perp=6.538, rec=0.071, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] clunky gets on the screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.369 (perp=6.538, rec=0.060, cos=0.001), tot_loss_proj:1.987 [t=0.17s]
prediction: ['[CLS] clunky gets on the screen [SEP]']
[ 450/2000] tot_loss=1.377 (perp=6.538, rec=0.068, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] clunky gets on the screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.377 (perp=6.538, rec=0.068, cos=0.001), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] clunky gets on the screen [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.308 (perp=6.139, rec=0.077, cos=0.004), tot_loss_proj:1.326 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[ 600/2000] tot_loss=1.296 (perp=6.139, rec=0.067, cos=0.001), tot_loss_proj:1.316 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.297 (perp=6.139, rec=0.069, cos=0.001), tot_loss_proj:1.331 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.292 (perp=6.139, rec=0.063, cos=0.001), tot_loss_proj:1.322 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[ 750/2000] tot_loss=1.287 (perp=6.139, rec=0.058, cos=0.001), tot_loss_proj:1.322 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.282 (perp=6.139, rec=0.053, cos=0.001), tot_loss_proj:1.328 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.297 (perp=6.139, rec=0.069, cos=0.001), tot_loss_proj:1.318 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[ 900/2000] tot_loss=1.284 (perp=6.139, rec=0.055, cos=0.001), tot_loss_proj:1.319 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.291 (perp=6.139, rec=0.062, cos=0.001), tot_loss_proj:1.333 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.284 (perp=6.139, rec=0.055, cos=0.001), tot_loss_proj:1.326 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1050/2000] tot_loss=1.293 (perp=6.139, rec=0.064, cos=0.001), tot_loss_proj:1.312 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.287 (perp=6.139, rec=0.058, cos=0.001), tot_loss_proj:1.326 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.295 (perp=6.139, rec=0.066, cos=0.001), tot_loss_proj:1.327 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1200/2000] tot_loss=1.277 (perp=6.139, rec=0.048, cos=0.001), tot_loss_proj:1.332 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.291 (perp=6.139, rec=0.062, cos=0.001), tot_loss_proj:1.322 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.293 (perp=6.139, rec=0.064, cos=0.001), tot_loss_proj:1.317 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1350/2000] tot_loss=1.289 (perp=6.139, rec=0.060, cos=0.001), tot_loss_proj:1.310 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.291 (perp=6.139, rec=0.062, cos=0.001), tot_loss_proj:1.322 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.291 (perp=6.139, rec=0.062, cos=0.001), tot_loss_proj:1.330 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1500/2000] tot_loss=1.286 (perp=6.139, rec=0.057, cos=0.001), tot_loss_proj:1.325 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.299 (perp=6.139, rec=0.070, cos=0.001), tot_loss_proj:1.319 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.289 (perp=6.139, rec=0.060, cos=0.001), tot_loss_proj:1.325 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1650/2000] tot_loss=1.284 (perp=6.139, rec=0.055, cos=0.001), tot_loss_proj:1.322 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.295 (perp=6.139, rec=0.066, cos=0.001), tot_loss_proj:1.313 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.293 (perp=6.139, rec=0.064, cos=0.001), tot_loss_proj:1.320 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1800/2000] tot_loss=1.290 (perp=6.139, rec=0.061, cos=0.001), tot_loss_proj:1.316 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.293 (perp=6.139, rec=0.064, cos=0.001), tot_loss_proj:1.327 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.288 (perp=6.139, rec=0.059, cos=0.001), tot_loss_proj:1.321 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1950/2000] tot_loss=1.304 (perp=6.139, rec=0.075, cos=0.001), tot_loss_proj:1.320 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.292 (perp=6.139, rec=0.063, cos=0.001), tot_loss_proj:1.316 [t=0.17s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] gets clunky on the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.069 | p: 89.722 | r: 90.453
rouge2     | fm: 53.299 | p: 53.106 | r: 53.459
rougeL     | fm: 77.014 | p: 76.794 | r: 77.270
rougeLsum  | fm: 76.906 | p: 76.665 | r: 77.214
r1fm+r2fm = 143.368

input #70 time: 0:06:40 | total time: 8:09:23


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9993403548184047
highest_index [0]
highest [0.9993403548184047]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 1.8314898014068604 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 1.6892049312591553 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 1.4518476724624634 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 1.4424015283584595 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 1.4241973161697388 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 1.4165459871292114 for ['[CLS] emptied advertising dominant orange gap mini clothes subsequent history series dakotaminatehab goesu [SEP]']
[Init] best rec loss: 1.3269407749176025 for ['[CLS]gies amir plus locomotive contacthane flat all highest helmet postal operations political blindness colors [SEP]']
[Init] best rec loss: 1.3191274404525757 for ['[CLS] jean bed queens fewer of professor fall ram surhear marshall over liam molly creatures [SEP]']
[Init] best perm rec loss: 1.3124475479125977 for ['[CLS] ramhear liam bed fall jean fewer professor over creatures queens molly sur marshall of [SEP]']
[Init] best perm rec loss: 1.312007188796997 for ['[CLS] molly liam fewer professor of queens jean creatures sur marshall bed over ram fallhear [SEP]']
[Init] best perm rec loss: 1.3116501569747925 for ['[CLS]hear marshall sur ram of fewer professor liam creatures molly bed over queens fall jean [SEP]']
[Init] best perm rec loss: 1.309478759765625 for ['[CLS] sur jeanhear fall fewer marshall molly liam professor ram queens bed of creatures over [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.613 (perp=11.318, rec=0.319, cos=0.030), tot_loss_proj:3.670 [t=0.17s]
prediction: ['[CLS] suburban - you moment jump cooper because form single /it st not moment thing [SEP]']
[ 100/2000] tot_loss=2.253 (perp=10.126, rec=0.214, cos=0.014), tot_loss_proj:3.490 [t=0.17s]
prediction: ['[CLS] ain - is moment jump amtrak moment a single - a st not single moment [SEP]']
[ 150/2000] tot_loss=2.223 (perp=10.230, rec=0.159, cos=0.018), tot_loss_proj:3.554 [t=0.17s]
prediction: ['[CLS] feed - there moment jump dear you a single - seat - not single moment [SEP]']
[ 200/2000] tot_loss=1.790 (perp=8.285, rec=0.127, cos=0.006), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] and - there seat jump - your a single - your - not single moment [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.618 (perp=7.631, rec=0.089, cos=0.003), tot_loss_proj:2.908 [t=0.17s]
prediction: ['[CLS] and - there single jump - your a seat - your - not single moment [SEP]']
[ 300/2000] tot_loss=1.613 (perp=7.664, rec=0.077, cos=0.003), tot_loss_proj:3.058 [t=0.17s]
prediction: ['[CLS] and - there single jump - your a seat in your - not single moment [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.679 (perp=7.959, rec=0.085, cos=0.002), tot_loss_proj:2.983 [t=0.17s]
prediction: ['[CLS] and - there single jump your your seat in your - not a single moment [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.484 (perp=7.006, rec=0.080, cos=0.003), tot_loss_proj:3.059 [t=0.17s]
prediction: ['[CLS] jump - there single and your your seat in your - not a single moment [SEP]']
[ 450/2000] tot_loss=1.546 (perp=7.279, rec=0.088, cos=0.002), tot_loss_proj:3.105 [t=0.17s]
prediction: ['[CLS] jump - there single and - your seat in your - not a - moment [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.433 (perp=6.808, rec=0.070, cos=0.002), tot_loss_proj:3.085 [t=0.17s]
prediction: ["[CLS] jump - there single and'your seat in your - not a moment - [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.390 (perp=6.577, rec=0.072, cos=0.003), tot_loss_proj:2.955 [t=0.17s]
prediction: ["[CLS] jump single there - and'your seat in your - not a moment a [SEP]"]
[ 600/2000] tot_loss=1.347 (perp=6.330, rec=0.079, cos=0.002), tot_loss_proj:2.728 [t=0.17s]
prediction: ["[CLS] jump single there - and'your seat in your - not a moment - [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.344 (perp=6.330, rec=0.076, cos=0.002), tot_loss_proj:2.732 [t=0.17s]
prediction: ["[CLS] jump single there - and'your seat in your - not a moment - [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.346 (perp=6.348, rec=0.075, cos=0.002), tot_loss_proj:2.999 [t=0.17s]
prediction: ['[CLS] jump single there - and there your seat in your - not a moment - [SEP]']
[ 750/2000] tot_loss=1.354 (perp=6.348, rec=0.083, cos=0.002), tot_loss_proj:3.000 [t=0.17s]
prediction: ['[CLS] jump single there - and there your seat in your - not a moment - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.345 (perp=6.348, rec=0.074, cos=0.002), tot_loss_proj:3.004 [t=0.17s]
prediction: ['[CLS] jump single there - and there your seat in your - not a moment - [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.255 (perp=5.901, rec=0.073, cos=0.002), tot_loss_proj:2.995 [t=0.17s]
prediction: ['[CLS] jump single there - and there your in your seat - not a moment - [SEP]']
[ 900/2000] tot_loss=1.265 (perp=5.901, rec=0.083, cos=0.002), tot_loss_proj:2.996 [t=0.17s]
prediction: ['[CLS] jump single there - and there your in your seat - not a moment - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.463 (perp=6.817, rec=0.093, cos=0.006), tot_loss_proj:3.169 [t=0.17s]
prediction: ['[CLS] jump single there - and [SEP] your in your seat - not a moment - [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.342 (perp=6.241, rec=0.089, cos=0.005), tot_loss_proj:3.051 [t=0.17s]
prediction: ['[CLS] jump single [SEP] there - and your in your seat - not a moment - [SEP]']
[1050/2000] tot_loss=1.321 (perp=6.241, rec=0.069, cos=0.004), tot_loss_proj:3.046 [t=0.17s]
prediction: ['[CLS] jump single [SEP] there - and your in your seat - not a moment - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.331 (perp=6.241, rec=0.079, cos=0.004), tot_loss_proj:3.047 [t=0.17s]
prediction: ['[CLS] jump single [SEP] there - and your in your seat - not a moment - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.345 (perp=6.241, rec=0.093, cos=0.004), tot_loss_proj:3.049 [t=0.17s]
prediction: ['[CLS] jump single [SEP] there - and your in your seat - not a moment - [SEP]']
[1200/2000] tot_loss=1.338 (perp=6.241, rec=0.086, cos=0.004), tot_loss_proj:3.050 [t=0.17s]
prediction: ['[CLS] jump single [SEP] there - and your in your seat - not a moment - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.321 (perp=6.206, rec=0.076, cos=0.004), tot_loss_proj:2.883 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.331 (perp=6.206, rec=0.086, cos=0.004), tot_loss_proj:2.888 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
[1350/2000] tot_loss=1.320 (perp=6.206, rec=0.075, cos=0.003), tot_loss_proj:2.885 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.330 (perp=6.206, rec=0.086, cos=0.003), tot_loss_proj:2.887 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.325 (perp=6.206, rec=0.081, cos=0.003), tot_loss_proj:2.888 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
[1500/2000] tot_loss=1.322 (perp=6.206, rec=0.077, cos=0.003), tot_loss_proj:2.889 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.322 (perp=6.206, rec=0.078, cos=0.003), tot_loss_proj:2.885 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.325 (perp=6.206, rec=0.080, cos=0.003), tot_loss_proj:2.890 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
[1650/2000] tot_loss=1.323 (perp=6.206, rec=0.079, cos=0.003), tot_loss_proj:2.887 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.311 (perp=6.206, rec=0.066, cos=0.003), tot_loss_proj:2.891 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.318 (perp=6.206, rec=0.074, cos=0.003), tot_loss_proj:2.891 [t=0.17s]
prediction: ["[CLS] jump single [SEP] there - and'in your seat - not a moment - [SEP]"]
[1800/2000] tot_loss=1.277 (perp=6.034, rec=0.067, cos=0.003), tot_loss_proj:2.833 [t=0.17s]
prediction: ["[CLS] jump single there there - and'in your seat - not a moment - [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.283 (perp=6.034, rec=0.073, cos=0.003), tot_loss_proj:2.832 [t=0.17s]
prediction: ["[CLS] jump single there there - and'in your seat - not a moment - [SEP]"]
Attempt swap
Moved token
[1900/2000] tot_loss=1.297 (perp=6.034, rec=0.087, cos=0.003), tot_loss_proj:2.836 [t=0.17s]
prediction: ["[CLS] jump single there there - and'in your seat - not a moment - [SEP]"]
[1950/2000] tot_loss=1.282 (perp=6.034, rec=0.072, cos=0.003), tot_loss_proj:2.840 [t=0.17s]
prediction: ["[CLS] jump single there there - and'in your seat - not a moment - [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.298 (perp=6.034, rec=0.088, cos=0.003), tot_loss_proj:2.834 [t=0.17s]
prediction: ["[CLS] jump single there there - and'in your seat - not a moment - [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] jump single there - and there your seat in your - not a moment - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 85.714 | r: 92.308
rouge2     | fm: 24.000 | p: 23.077 | r: 25.000
rougeL     | fm: 44.444 | p: 42.857 | r: 46.154
rougeLsum  | fm: 44.444 | p: 42.857 | r: 46.154
r1fm+r2fm = 112.889

[Aggregate metrics]:
rouge1     | fm: 90.019 | p: 89.627 | r: 90.441
rouge2     | fm: 52.987 | p: 52.867 | r: 53.108
rougeL     | fm: 76.529 | p: 76.224 | r: 76.807
rougeLsum  | fm: 76.488 | p: 76.231 | r: 76.869
r1fm+r2fm = 143.006

input #71 time: 0:06:44 | total time: 8:16:07


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9992329827199963
highest_index [0]
highest [0.9992329827199963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 1.660793662071228 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 1.5929793119430542 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 1.4265902042388916 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 1.4027378559112549 for ['[CLS]nted seriously public caesar failure major eli city edo memberf runway koppen join useless [SEP]']
[Init] best rec loss: 1.3698697090148926 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 1.3598313331604004 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 1.2334275245666504 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 1.2262848615646362 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 1.216339349746704 for ['[CLS] them relations quickly sip abexed without connected counties glacier digitalhic professor teller page [SEP]']
[Init] best rec loss: 1.190377116203308 for ['[CLS] things substitute air favors bishop defined werewolf anywaylusion ghana tonnesboard favorfin cy [SEP]']
[Init] best perm rec loss: 1.1880836486816406 for ['[CLS] ghana favorslusion air cy anywayboard werewolf tonnes things favor substitutefin bishop defined [SEP]']
[Init] best perm rec loss: 1.1873072385787964 for ['[CLS] favor ghana air bishop tonnes substitutelusion werewolf cy things anywayboard defined favorsfin [SEP]']
[Init] best perm rec loss: 1.1828306913375854 for ['[CLS] ghana bishop defined substitute tonnes favors anywaylusion things werewolffin favor air cyboard [SEP]']
[Init] best perm rec loss: 1.1827526092529297 for ['[CLS]fin favorslusion substitute anyway werewolf bishop air definedboard things favor ghana cy tonnes [SEP]']
[Init] best perm rec loss: 1.1818435192108154 for ['[CLS] ghana cy favorlusion defined substituteboard tonnes air things bishop favors anywayfin werewolf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.934 (perp=12.743, rec=0.360, cos=0.026), tot_loss_proj:3.549 [t=0.17s]
prediction: ['[CLS] has arm ignoring stan harder timeer somekushima tries punishment under problem tough decline [SEP]']
[ 100/2000] tot_loss=2.827 (perp=12.762, rec=0.266, cos=0.009), tot_loss_proj:3.845 [t=0.17s]
prediction: ['[CLS] has timebler marilyn tough time it civilized tough toughencies under helping tough violence [SEP]']
[ 150/2000] tot_loss=2.466 (perp=11.259, rec=0.203, cos=0.012), tot_loss_proj:3.622 [t=0.17s]
prediction: ['[CLS] has time tough has tough time its horizontal tough balancingencies has issues tough philosophy [SEP]']
[ 200/2000] tot_loss=2.183 (perp=10.299, rec=0.118, cos=0.005), tot_loss_proj:3.026 [t=0.18s]
prediction: ['[CLS] has timeer has tough time itsa tough balancing violence with inspiredians philosophy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.066 (perp=9.809, rec=0.101, cos=0.003), tot_loss_proj:2.927 [t=0.17s]
prediction: ['[CLS] haser time haser time itsa tough balancing violence with inspiredians philosophy [SEP]']
[ 300/2000] tot_loss=2.146 (perp=10.272, rec=0.090, cos=0.002), tot_loss_proj:3.866 [t=0.19s]
prediction: ['[CLS] aer time haser time itsfk tough balancing violence with inspired inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.986 (perp=9.514, rec=0.081, cos=0.002), tot_loss_proj:3.755 [t=0.17s]
prediction: ['[CLS] a balancing a haser time itsfk tougher violence with inspired inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.894 (perp=9.050, rec=0.082, cos=0.002), tot_loss_proj:3.242 [t=0.17s]
prediction: ['[CLS] a time time haser balancing itsfk tougher violence with - inspired philosophy [SEP]']
[ 450/2000] tot_loss=1.878 (perp=9.050, rec=0.066, cos=0.001), tot_loss_proj:3.240 [t=0.17s]
prediction: ['[CLS] a time time haser balancing itsfk tougher violence with - inspired philosophy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.723 (perp=8.225, rec=0.077, cos=0.002), tot_loss_proj:3.278 [t=0.17s]
prediction: ['[CLS] a timefk a haser balancing its tougher violence with - inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.695 (perp=8.092, rec=0.075, cos=0.002), tot_loss_proj:3.029 [t=0.17s]
prediction: ['[CLS] a timefk has timeer balancing its tougher violence with - inspired philosophy [SEP]']
[ 600/2000] tot_loss=1.702 (perp=8.092, rec=0.082, cos=0.001), tot_loss_proj:3.027 [t=0.17s]
prediction: ['[CLS] a timefk has timeer balancing its tougher violence with - inspired philosophy [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.666 (perp=8.006, rec=0.063, cos=0.001), tot_loss_proj:3.301 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence with - inspired philosophy [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.662 (perp=7.926, rec=0.075, cos=0.001), tot_loss_proj:3.464 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
[ 750/2000] tot_loss=1.658 (perp=7.926, rec=0.072, cos=0.001), tot_loss_proj:3.463 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.653 (perp=7.953, rec=0.061, cos=0.001), tot_loss_proj:3.289 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - inspired with philosophy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.658 (perp=7.953, rec=0.066, cos=0.001), tot_loss_proj:3.295 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - inspired with philosophy [SEP]']
[ 900/2000] tot_loss=1.667 (perp=7.953, rec=0.075, cos=0.001), tot_loss_proj:3.289 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - inspired with philosophy [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.656 (perp=7.926, rec=0.069, cos=0.001), tot_loss_proj:3.464 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.655 (perp=7.926, rec=0.068, cos=0.001), tot_loss_proj:3.463 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
[1050/2000] tot_loss=1.653 (perp=7.926, rec=0.067, cos=0.001), tot_loss_proj:3.465 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.655 (perp=7.926, rec=0.069, cos=0.001), tot_loss_proj:3.465 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.655 (perp=7.926, rec=0.068, cos=0.001), tot_loss_proj:3.466 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
[1200/2000] tot_loss=1.652 (perp=7.926, rec=0.065, cos=0.001), tot_loss_proj:3.462 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.650 (perp=7.926, rec=0.063, cos=0.001), tot_loss_proj:3.464 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.649 (perp=7.926, rec=0.063, cos=0.001), tot_loss_proj:3.464 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
[1350/2000] tot_loss=1.658 (perp=7.926, rec=0.071, cos=0.001), tot_loss_proj:3.465 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.650 (perp=7.953, rec=0.058, cos=0.001), tot_loss_proj:3.290 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - inspired with philosophy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.664 (perp=7.953, rec=0.071, cos=0.001), tot_loss_proj:3.287 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - inspired with philosophy [SEP]']
[1500/2000] tot_loss=1.670 (perp=7.953, rec=0.078, cos=0.001), tot_loss_proj:3.289 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - inspired with philosophy [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.643 (perp=7.892, rec=0.063, cos=0.001), tot_loss_proj:3.160 [t=0.17s]
prediction: ['[CLS] a timefk balancing aer has its tougher violence - inspired philosophy with [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.644 (perp=7.819, rec=0.078, cos=0.002), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] a timefk balancing itser has a tougher violence - inspired philosophy with [SEP]']
[1650/2000] tot_loss=1.623 (perp=7.819, rec=0.057, cos=0.001), tot_loss_proj:2.873 [t=0.17s]
prediction: ['[CLS] a timefk balancing itser has a tougher violence - inspired philosophy with [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.601 (perp=7.683, rec=0.063, cos=0.002), tot_loss_proj:2.944 [t=0.17s]
prediction: ['[CLS] afk balancing its timeer has a tougher violence - inspired philosophy with [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.559 (perp=7.373, rec=0.082, cos=0.002), tot_loss_proj:2.606 [t=0.17s]
prediction: ['[CLS] afk balancing its timeer has a tougher philosophy - inspired violence with [SEP]']
[1800/2000] tot_loss=1.542 (perp=7.373, rec=0.066, cos=0.001), tot_loss_proj:2.601 [t=0.17s]
prediction: ['[CLS] afk balancing its timeer has a tougher philosophy - inspired violence with [SEP]']
Attempt swap
[1850/2000] tot_loss=1.546 (perp=7.373, rec=0.070, cos=0.001), tot_loss_proj:2.605 [t=0.17s]
prediction: ['[CLS] afk balancing its timeer has a tougher philosophy - inspired violence with [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.536 (perp=7.288, rec=0.077, cos=0.002), tot_loss_proj:2.678 [t=0.17s]
prediction: ['[CLS] afk balancing its timeer has a tougher philosophy with inspired violence - [SEP]']
[1950/2000] tot_loss=1.539 (perp=7.288, rec=0.080, cos=0.002), tot_loss_proj:2.682 [t=0.17s]
prediction: ['[CLS] afk balancing its timeer has a tougher philosophy with inspired violence - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.526 (perp=7.288, rec=0.067, cos=0.001), tot_loss_proj:2.683 [t=0.17s]
prediction: ['[CLS] afk balancing its timeer has a tougher philosophy with inspired violence - [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] a timefk balancing aer has its tougher violence - with inspired philosophy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 84.615 | r: 84.615
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 69.231 | p: 69.231 | r: 69.231
rougeLsum  | fm: 69.231 | p: 69.231 | r: 69.231
r1fm+r2fm = 109.615

[Aggregate metrics]:
rouge1     | fm: 89.953 | p: 89.582 | r: 90.411
rouge2     | fm: 52.416 | p: 52.286 | r: 52.567
rougeL     | fm: 76.483 | p: 76.204 | r: 76.770
rougeLsum  | fm: 76.506 | p: 76.223 | r: 76.816
r1fm+r2fm = 142.369

input #72 time: 0:06:48 | total time: 8:22:56


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9991746597716884
highest_index [0]
highest [0.9991746597716884]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 1.8824208974838257 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 1.7401381731033325 for ['[CLS] capitol living [SEP]']
[Init] best rec loss: 1.6489461660385132 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 1.5039418935775757 for ['[CLS] denied airline [SEP]']
[Init] best rec loss: 1.4107468128204346 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 1.407352328300476 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.136 (perp=9.723, rec=0.182, cos=0.010), tot_loss_proj:2.018 [t=0.16s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.017 (perp=9.723, rec=0.070, cos=0.002), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.014 [t=0.16s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.013 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.024 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.021 (perp=9.723, rec=0.074, cos=0.002), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.014 (perp=9.723, rec=0.068, cos=0.002), tot_loss_proj:2.009 [t=0.16s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.011 [t=0.16s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.012 [t=0.16s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.007 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.002 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.997 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:2.010 [t=0.16s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.008 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.004 [t=0.16s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.003 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:1.999 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.013 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.004 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.998 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:1.995 [t=0.16s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.022 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.000 (perp=9.723, rec=0.053, cos=0.002), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.013 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.026 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=1.998 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.013 (perp=9.723, rec=0.067, cos=0.002), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=1.998 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.003 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.005 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=1.999 (perp=9.723, rec=0.053, cos=0.002), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.012 (perp=9.723, rec=0.065, cos=0.002), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.002 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.005 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.001 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.015 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=1.994 (perp=9.723, rec=0.048, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.991 | p: 89.655 | r: 90.499
rouge2     | fm: 52.996 | p: 52.847 | r: 53.157
rougeL     | fm: 76.815 | p: 76.532 | r: 77.108
rougeLsum  | fm: 76.753 | p: 76.489 | r: 77.091
r1fm+r2fm = 142.987

input #73 time: 0:06:36 | total time: 8:29:32


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9992591939462341
highest_index [0]
highest [0.9992591939462341]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.6898705959320068 for ['[CLS]wed [SEP]']
[Init] best rec loss: 1.191595196723938 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.9334901571273804 for ['[CLS] answering [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.385 (perp=8.178, rec=0.559, cos=0.191), tot_loss_proj:2.167 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=3.028 (perp=8.178, rec=0.813, cos=0.579), tot_loss_proj:2.257 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=2.866 (perp=8.178, rec=0.741, cos=0.489), tot_loss_proj:2.179 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=2.728 (perp=8.178, rec=0.748, cos=0.345), tot_loss_proj:2.105 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.533 (perp=8.178, rec=0.659, cos=0.238), tot_loss_proj:2.019 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=2.479 (perp=8.178, rec=0.611, cos=0.232), tot_loss_proj:1.930 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.421 (perp=8.178, rec=0.572, cos=0.214), tot_loss_proj:1.866 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.378 (perp=8.178, rec=0.544, cos=0.198), tot_loss_proj:1.827 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=2.373 (perp=8.178, rec=0.549, cos=0.189), tot_loss_proj:1.908 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.320 (perp=8.178, rec=0.511, cos=0.173), tot_loss_proj:1.844 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.291 (perp=8.178, rec=0.492, cos=0.163), tot_loss_proj:1.800 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=2.271 (perp=8.178, rec=0.478, cos=0.157), tot_loss_proj:1.775 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.265 (perp=8.178, rec=0.477, cos=0.152), tot_loss_proj:1.773 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.301 (perp=8.178, rec=0.506, cos=0.160), tot_loss_proj:1.788 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=2.242 (perp=8.178, rec=0.459, cos=0.147), tot_loss_proj:1.795 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.250 (perp=8.178, rec=0.470, cos=0.145), tot_loss_proj:1.796 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.234 (perp=8.178, rec=0.458, cos=0.141), tot_loss_proj:1.797 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=2.226 (perp=8.178, rec=0.455, cos=0.136), tot_loss_proj:1.784 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.216 (perp=8.178, rec=0.446, cos=0.134), tot_loss_proj:1.792 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=2.210 (perp=8.178, rec=0.443, cos=0.131), tot_loss_proj:1.773 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=2.206 (perp=8.178, rec=0.439, cos=0.131), tot_loss_proj:1.790 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=2.208 (perp=8.178, rec=0.441, cos=0.131), tot_loss_proj:1.779 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=2.377 (perp=8.178, rec=0.547, cos=0.194), tot_loss_proj:1.763 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=2.207 (perp=8.178, rec=0.438, cos=0.134), tot_loss_proj:1.798 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=2.202 (perp=8.178, rec=0.435, cos=0.131), tot_loss_proj:1.793 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=2.203 (perp=8.178, rec=0.436, cos=0.132), tot_loss_proj:1.766 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=2.202 (perp=8.178, rec=0.437, cos=0.129), tot_loss_proj:1.777 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=2.184 (perp=8.178, rec=0.418, cos=0.129), tot_loss_proj:1.787 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=2.203 (perp=8.178, rec=0.437, cos=0.130), tot_loss_proj:1.798 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=2.181 (perp=8.178, rec=0.416, cos=0.129), tot_loss_proj:1.781 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=2.186 (perp=8.178, rec=0.421, cos=0.129), tot_loss_proj:1.778 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=2.177 (perp=8.178, rec=0.414, cos=0.127), tot_loss_proj:1.770 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=2.191 (perp=8.178, rec=0.428, cos=0.128), tot_loss_proj:1.779 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=2.180 (perp=8.178, rec=0.417, cos=0.127), tot_loss_proj:1.776 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=2.187 (perp=8.178, rec=0.424, cos=0.128), tot_loss_proj:1.773 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=2.172 (perp=8.178, rec=0.409, cos=0.127), tot_loss_proj:1.797 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=2.184 (perp=8.178, rec=0.420, cos=0.129), tot_loss_proj:1.763 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=2.165 (perp=8.178, rec=0.403, cos=0.127), tot_loss_proj:1.782 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=2.167 (perp=8.178, rec=0.403, cos=0.128), tot_loss_proj:1.776 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=2.181 (perp=8.178, rec=0.418, cos=0.127), tot_loss_proj:1.775 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.243 | p: 89.842 | r: 90.691
rouge2     | fm: 53.857 | p: 53.731 | r: 53.960
rougeL     | fm: 77.133 | p: 76.861 | r: 77.400
rougeLsum  | fm: 77.010 | p: 76.773 | r: 77.275
r1fm+r2fm = 144.100

input #74 time: 0:06:31 | total time: 8:36:04


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9993458403755586
highest_index [0]
highest [0.9993458403755586]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 1.9394946098327637 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 1.9215192794799805 for ['[CLS]isch expansion earl early badly bea camp manuscripts nas counted butcher spike braun planned lark chad constant blue himself [SEP]']
[Init] best rec loss: 1.861011028289795 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 1.7244476079940796 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 1.7233116626739502 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best rec loss: 1.661628007888794 for ['[CLS] surrounding imlence health flow mecklenburg dining twins execution plannercott by yes guy rattle senior batch 社 earth [SEP]']
[Init] best perm rec loss: 1.660509467124939 for ['[CLS] 社 execution senior bycott twins planner earth mecklenburg yes dininglence surrounding health flow guy im rattle batch [SEP]']
[Init] best perm rec loss: 1.6556261777877808 for ['[CLS] rattle mecklenburg dining surrounding flow batchcott guy planner by earthlence im twins health 社 execution senior yes [SEP]']
[Init] best perm rec loss: 1.6549123525619507 for ['[CLS] execution 社 senior surroundingcott mecklenburg guylence dining planner twins by health batch yes flow im rattle earth [SEP]']
[Init] best perm rec loss: 1.653684377670288 for ['[CLS] flow surrounding im mecklenburg planner batch 社 guycott twins by earthlence rattle senior execution dining health yes [SEP]']
[Init] best perm rec loss: 1.6525647640228271 for ['[CLS] surrounding mecklenburg health bycott guy batch flow plannerlence dining earth 社 yes twins rattle execution senior im [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.574 (perp=10.708, rec=0.398, cos=0.034), tot_loss_proj:3.991 [t=0.17s]
prediction: ['[CLS] marcos not events without mode not helped exceptional glacial mightction from unknown youth fellowship project visited. camp [SEP]']
[ 100/2000] tot_loss=2.620 (perp=11.762, rec=0.257, cos=0.011), tot_loss_proj:4.139 [t=0.17s]
prediction: ['[CLS]watch not events without mode really disaster mental mental not not is forgotten across meeting relatively forget. council [SEP]']
[ 150/2000] tot_loss=2.241 (perp=10.180, rec=0.198, cos=0.007), tot_loss_proj:3.879 [t=0.17s]
prediction: ['[CLS] easily not events without mode excursion forgotten this mental not not is forgotten worth / relatively forgotten. council [SEP]']
[ 200/2000] tot_loss=2.157 (perp=9.926, rec=0.168, cos=0.004), tot_loss_proj:3.737 [t=0.17s]
prediction: ['[CLS] easily not excursion easily mode excursion forgotten this mental instability not is forgotten worth or relatively forgotten. excursion [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.207 (perp=10.357, rec=0.132, cos=0.004), tot_loss_proj:3.703 [t=0.17s]
prediction: ['[CLS] easily dismissed excursion easily mode excursion forgotten this mental instability not is easily worth orulsive forgotten. excursion [SEP]']
[ 300/2000] tot_loss=2.284 (perp=10.779, rec=0.125, cos=0.003), tot_loss_proj:3.830 [t=0.17s]
prediction: ['[CLS] easily dismissed excursion easily analysis excursion forgotten this mental instability not is easily worth or boost forgotten. excursion [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.147 (perp=10.185, rec=0.107, cos=0.003), tot_loss_proj:3.777 [t=0.17s]
prediction: ['[CLS] easily dismissed excursion boost analysis excursion forgotten this mental instability not is easily bearing or easily forgotten. excursion [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.046 (perp=9.666, rec=0.110, cos=0.003), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] easily dismissed excursion boosttify excursion forgotten this mental instability is not easily. or easily forgotten. excursion [SEP]']
[ 450/2000] tot_loss=2.084 (perp=9.884, rec=0.105, cos=0.003), tot_loss_proj:3.759 [t=0.17s]
prediction: ['[CLS] easily dismissed excursion boosttify excursion forgotten this mental instability is not easily. or easily forgotten into excursion [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.061 (perp=9.813, rec=0.096, cos=0.003), tot_loss_proj:3.763 [t=0.17s]
prediction: ['[CLS] easily dismissed excursion boosttify excursion is this mental instability forgotten not easily. or easily forgotten intoenter [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.997 (perp=9.520, rec=0.090, cos=0.003), tot_loss_proj:3.726 [t=0.17s]
prediction: ['[CLS] easily dismissed excursion boosttify excursion is this mental instability. forgotten not easily or easily forgotten intoenter [SEP]']
[ 600/2000] tot_loss=2.166 (perp=10.363, rec=0.091, cos=0.002), tot_loss_proj:3.861 [t=0.17s]
prediction: ['[CLS] easily dismissed excursion boosttify excursion is this mental instability. forgotten not easily or blades forgotten intoenter [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.956 (perp=9.331, rec=0.087, cos=0.002), tot_loss_proj:3.771 [t=0.17s]
prediction: ['[CLS] easily dismissed excursion boosttify excursion is this mental instability. not easily forgotten or the forgotten intoenter [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.136 (perp=10.204, rec=0.093, cos=0.002), tot_loss_proj:3.917 [t=0.17s]
prediction: ['[CLS] easily dismissed boosttify excursion excursion is this mental instability. not easily rhino or the forgotten intoenter [SEP]']
[ 750/2000] tot_loss=2.194 (perp=10.460, rec=0.100, cos=0.002), tot_loss_proj:3.996 [t=0.17s]
prediction: ['[CLS] easily dismissed boosttify into excursion is this mental instability. not easily rhino or the forgotten intoenter [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.995 (perp=9.484, rec=0.096, cos=0.002), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] easily dismissed intotify boost excursion is this mental instability. not easily upon or the forgotten intoenter [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.938 (perp=9.213, rec=0.093, cos=0.002), tot_loss_proj:3.730 [t=0.17s]
prediction: ['[CLS] easily dismissed intotify boost excursion is this mental instability. not the upon or easily forgotten intoenter [SEP]']
[ 900/2000] tot_loss=1.937 (perp=9.213, rec=0.093, cos=0.002), tot_loss_proj:3.728 [t=0.17s]
prediction: ['[CLS] easily dismissed intotify boost excursion is this mental instability. not the upon or easily forgotten intoenter [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.981 (perp=9.445, rec=0.090, cos=0.002), tot_loss_proj:3.577 [t=0.17s]
prediction: ['[CLS] easily dismissed intotify afford excursion is this mental instability. not the boost or easily forgotten intoenter [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.073 (perp=9.904, rec=0.090, cos=0.002), tot_loss_proj:3.533 [t=0.17s]
prediction: ['[CLS]cola boost intotify afford excursion is this mental instability. not the dismissed or easily forgotten intoenter [SEP]']
[1050/2000] tot_loss=2.072 (perp=9.904, rec=0.089, cos=0.002), tot_loss_proj:3.534 [t=0.17s]
prediction: ['[CLS]cola boost intotify afford excursion is this mental instability. not the dismissed or easily forgotten intoenter [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.160 (perp=10.212, rec=0.115, cos=0.003), tot_loss_proj:3.441 [t=0.17s]
prediction: ['[CLS] clasped boost into valid easily excursion is this mental instability for not the dismissed or easily forgottenenterenter [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.014 (perp=9.580, rec=0.096, cos=0.003), tot_loss_proj:3.227 [t=0.17s]
prediction: ['[CLS] environment boost into easily valid excursion is this mental instability for not the dismissed or easily forgottenenterenter [SEP]']
[1200/2000] tot_loss=2.015 (perp=9.580, rec=0.097, cos=0.002), tot_loss_proj:3.230 [t=0.17s]
prediction: ['[CLS] environment boost into easily valid excursion is this mental instability for not the dismissed or easily forgottenenterenter [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.109 (perp=10.043, rec=0.098, cos=0.003), tot_loss_proj:3.452 [t=0.17s]
prediction: ['[CLS] environment boost into easilyenter excursion is for this mental instability not the dismissed or easily forgottenenterenter [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.944 (perp=9.266, rec=0.088, cos=0.003), tot_loss_proj:2.733 [t=0.17s]
prediction: ['[CLS] the boost intocolating excursion is for this mental instability not environment dismissed or easily forgottenenterenter [SEP]']
[1350/2000] tot_loss=1.944 (perp=9.266, rec=0.088, cos=0.002), tot_loss_proj:2.729 [t=0.17s]
prediction: ['[CLS] the boost intocolating excursion is for this mental instability not environment dismissed or easily forgottenenterenter [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.901 (perp=9.055, rec=0.087, cos=0.002), tot_loss_proj:2.813 [t=0.17s]
prediction: ['[CLS] the boost intocolating excursion is for this mental instability environment not dismissed or easily forgottenenterenter [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.826 (perp=8.694, rec=0.085, cos=0.002), tot_loss_proj:2.398 [t=0.17s]
prediction: ['[CLS] the boost intocolating excursion environment for this mental instability is not dismissed or easily forgottenenterenter [SEP]']
[1500/2000] tot_loss=1.842 (perp=8.694, rec=0.100, cos=0.002), tot_loss_proj:2.401 [t=0.17s]
prediction: ['[CLS] the boost intocolating excursion environment for this mental instability is not dismissed or easily forgottenenterenter [SEP]']
Attempt swap
[1550/2000] tot_loss=1.793 (perp=8.504, rec=0.089, cos=0.002), tot_loss_proj:2.380 [t=0.17s]
prediction: ['[CLS] the boost intocolating excursion environment, this mental instability is not dismissed or easily forgottenenterenter [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.757 (perp=8.314, rec=0.092, cos=0.003), tot_loss_proj:2.207 [t=0.20s]
prediction: ['[CLS] the boost intocolating excursion environment, this mental instability is not easily dismissed or forgottenenterenter [SEP]']
[1650/2000] tot_loss=1.746 (perp=8.314, rec=0.080, cos=0.002), tot_loss_proj:2.197 [t=0.17s]
prediction: ['[CLS] the boost intocolating excursion environment, this mental instability is not easily dismissed or forgottenenterenter [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.672 (perp=7.902, rec=0.089, cos=0.002), tot_loss_proj:2.325 [t=0.17s]
prediction: ['[CLS] the boost into excursion environment. this mental instability is not easily dismissedcolating or forgottenenterenter [SEP]']
Attempt swap
[1750/2000] tot_loss=1.677 (perp=7.902, rec=0.094, cos=0.002), tot_loss_proj:2.319 [t=0.17s]
prediction: ['[CLS] the boost into excursion environment. this mental instability is not easily dismissedcolating or forgottenenterenter [SEP]']
[1800/2000] tot_loss=1.875 (perp=8.923, rec=0.088, cos=0.002), tot_loss_proj:2.544 [t=0.17s]
prediction: ['[CLS] the boost into excursion environment. this mental instability is not easily dismissedcolativ or forgottenenterenter [SEP]']
Attempt swap
[1850/2000] tot_loss=1.872 (perp=8.923, rec=0.085, cos=0.002), tot_loss_proj:2.543 [t=0.17s]
prediction: ['[CLS] the boost into excursion environment. this mental instability is not easily dismissedcolativ or forgottenenterenter [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.873 (perp=8.882, rec=0.094, cos=0.003), tot_loss_proj:2.666 [t=0.17s]
prediction: ['[CLS] the boost into excursion environment. this mental instability is not easily dismissedtivcola or forgottenenterenter [SEP]']
[1950/2000] tot_loss=1.868 (perp=8.882, rec=0.089, cos=0.002), tot_loss_proj:2.658 [t=0.17s]
prediction: ['[CLS] the boost into excursion environment. this mental instability is not easily dismissedtivcola or forgottenenterenter [SEP]']
Attempt swap
[2000/2000] tot_loss=1.872 (perp=8.882, rec=0.093, cos=0.002), tot_loss_proj:2.662 [t=0.17s]
prediction: ['[CLS] the boost into excursion environment. this mental instability is not easily dismissedtivcola or forgottenenterenter [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] the boost intocolating excursion environment, this mental instability is not dismissed or easily forgottenenterenter [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 75.000 | r: 70.588
rouge2     | fm: 25.806 | p: 26.667 | r: 25.000
rougeL     | fm: 54.545 | p: 56.250 | r: 52.941
rougeLsum  | fm: 54.545 | p: 56.250 | r: 52.941
r1fm+r2fm = 98.534

[Aggregate metrics]:
rouge1     | fm: 89.958 | p: 89.596 | r: 90.374
rouge2     | fm: 53.545 | p: 53.387 | r: 53.720
rougeL     | fm: 76.719 | p: 76.487 | r: 77.020
rougeLsum  | fm: 76.835 | p: 76.557 | r: 77.069
r1fm+r2fm = 143.503

input #75 time: 0:06:45 | total time: 8:42:50


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9991386602126575
highest_index [0]
highest [0.9991386602126575]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 1.782433271408081 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 1.7596430778503418 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 1.7049720287322998 for ['[CLS] vimes spread stanford telescope formed neighbourhood wire chang miniseries farmers kyle having bend attempt [SEP]']
[Init] best rec loss: 1.6918405294418335 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 1.674768328666687 for ['[CLS] midnight even task j mesh constellation village typhoonorough, advancing hammerist carol [SEP]']
[Init] best rec loss: 1.591769814491272 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 1.4612284898757935 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 1.3690840005874634 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 1.3682646751403809 for ['[CLS] ( backward ab taut mangoˣ left onwards pushed hard surrealhawoning purse [SEP]']
[Init] best perm rec loss: 1.3626619577407837 for ['[CLS]ˣ (haw onwards aboning taut left hard backward surreal pushed mango purse [SEP]']
[Init] best perm rec loss: 1.3604645729064941 for ['[CLS] (ˣ leftoning onwards pushed taut ab hard backward surreal mango pursehaw [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.724 (perp=12.150, rec=0.277, cos=0.017), tot_loss_proj:3.711 [t=0.17s]
prediction: ['[CLS] like stopped abandoned, afterlho quarter stopped stopped goods challenging into ( career [SEP]']
[ 100/2000] tot_loss=2.444 (perp=11.081, rec=0.206, cos=0.022), tot_loss_proj:3.434 [t=0.17s]
prediction: ['[CLS] like has abandoned, similarly jesse whichever stopped stopped challenging challenging has at himself [SEP]']
[ 150/2000] tot_loss=2.203 (perp=10.197, rec=0.157, cos=0.006), tot_loss_proj:3.826 [t=0.17s]
prediction: ['[CLS] as has sides. allen allen at stopped challenging challenging challenging has at himself [SEP]']
[ 200/2000] tot_loss=2.252 (perp=10.633, rec=0.121, cos=0.005), tot_loss_proj:3.526 [t=0.17s]
prediction: ['[CLS] as 66 sides, allen allen at stopped challenging challenging challenging has at himself [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.112 (perp=9.958, rec=0.116, cos=0.004), tot_loss_proj:3.803 [t=0.17s]
prediction: ['[CLS] as 66 sides, allen stopped at allen challenging challenging challenging has s himself [SEP]']
[ 300/2000] tot_loss=2.260 (perp=10.737, rec=0.108, cos=0.004), tot_loss_proj:3.281 [t=0.17s]
prediction: ['[CLS] as 66 reprise, allen stopped at allen stopped challenging challenging has s himself [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.956 (perp=9.229, rec=0.107, cos=0.003), tot_loss_proj:3.407 [t=0.17s]
prediction: ['[CLS] as 66 reprise, allen stopped at allen has stopped. challenging s himself [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.770 (perp=8.339, rec=0.098, cos=0.003), tot_loss_proj:2.756 [t=0.18s]
prediction: ['[CLS] as 66 reprise, allen stopped at allen has stopped himself challenging s. [SEP]']
[ 450/2000] tot_loss=1.772 (perp=8.360, rec=0.097, cos=0.003), tot_loss_proj:2.812 [t=0.18s]
prediction: ['[CLS] as 66 classic, allen stopped at allen has stopped himself challenging s. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.787 (perp=8.452, rec=0.093, cos=0.004), tot_loss_proj:2.898 [t=0.18s]
prediction: ['[CLS] as grab 66, allen stopped at allen has stopped himself challenging s. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.784 (perp=8.452, rec=0.092, cos=0.002), tot_loss_proj:2.888 [t=0.17s]
prediction: ['[CLS] as grab 66, allen stopped at allen has stopped himself challenging s. [SEP]']
[ 600/2000] tot_loss=1.782 (perp=8.452, rec=0.089, cos=0.002), tot_loss_proj:2.888 [t=0.17s]
prediction: ['[CLS] as grab 66, allen stopped at allen has stopped himself challenging s. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.748 (perp=8.293, rec=0.087, cos=0.002), tot_loss_proj:2.747 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at - has stopped himself challenging drop. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.723 (perp=8.208, rec=0.079, cos=0.002), tot_loss_proj:2.598 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at - has stopped drop challenging himself. [SEP]']
[ 750/2000] tot_loss=1.791 (perp=8.559, rec=0.078, cos=0.002), tot_loss_proj:3.240 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at - has if drop challenging himself. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.724 (perp=8.202, rec=0.081, cos=0.002), tot_loss_proj:3.188 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at - drop if has challenging himself. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.749 (perp=8.318, rec=0.083, cos=0.002), tot_loss_proj:2.969 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped atiche - if has challenging himself. [SEP]']
[ 900/2000] tot_loss=1.755 (perp=8.318, rec=0.089, cos=0.002), tot_loss_proj:2.967 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped atiche - if has challenging himself. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.690 (perp=8.002, rec=0.087, cos=0.002), tot_loss_proj:2.977 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped atiche, if has challenging himself. [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.573 (perp=7.395, rec=0.092, cos=0.002), tot_loss_proj:3.064 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at hasiche, if challenging himself. [SEP]']
[1050/2000] tot_loss=1.558 (perp=7.395, rec=0.077, cos=0.002), tot_loss_proj:3.056 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at hasiche, if challenging himself. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.563 (perp=7.395, rec=0.082, cos=0.002), tot_loss_proj:3.059 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at hasiche, if challenging himself. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.568 (perp=7.395, rec=0.087, cos=0.002), tot_loss_proj:3.060 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at hasiche, if challenging himself. [SEP]']
[1200/2000] tot_loss=1.559 (perp=7.395, rec=0.078, cos=0.002), tot_loss_proj:3.058 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at hasiche, if challenging himself. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.559 (perp=7.395, rec=0.078, cos=0.002), tot_loss_proj:3.061 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at hasiche, if challenging himself. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.566 (perp=7.395, rec=0.084, cos=0.002), tot_loss_proj:3.053 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at hasiche, if challenging himself. [SEP]']
[1350/2000] tot_loss=1.622 (perp=7.732, rec=0.074, cos=0.002), tot_loss_proj:3.220 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at hastan, if challenging himself. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.664 (perp=7.883, rec=0.086, cos=0.002), tot_loss_proj:3.143 [t=0.17s]
prediction: ['[CLS] as s 66, allen stopped at has / if, challenging himself. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.625 (perp=7.651, rec=0.092, cos=0.002), tot_loss_proj:3.066 [t=0.17s]
prediction: ['[CLS] as s 66, allen has at stopped / if, challenging himself. [SEP]']
[1500/2000] tot_loss=1.615 (perp=7.651, rec=0.082, cos=0.002), tot_loss_proj:3.067 [t=0.17s]
prediction: ['[CLS] as s 66, allen has at stopped / if, challenging himself. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.573 (perp=7.456, rec=0.080, cos=0.002), tot_loss_proj:2.653 [t=0.17s]
prediction: ['[CLS] as s 66, allen has at stopped, / if challenging himself. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.564 (perp=7.456, rec=0.071, cos=0.002), tot_loss_proj:2.656 [t=0.17s]
prediction: ['[CLS] as s 66, allen has at stopped, / if challenging himself. [SEP]']
[1650/2000] tot_loss=1.579 (perp=7.456, rec=0.086, cos=0.002), tot_loss_proj:2.656 [t=0.17s]
prediction: ['[CLS] as s 66, allen has at stopped, / if challenging himself. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.547 (perp=7.328, rec=0.079, cos=0.002), tot_loss_proj:2.404 [t=0.17s]
prediction: ['[CLS] as s 66, allen has at / stopped, if challenging himself. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.536 (perp=7.328, rec=0.068, cos=0.002), tot_loss_proj:2.402 [t=0.17s]
prediction: ['[CLS] as s 66, allen has at / stopped, if challenging himself. [SEP]']
[1800/2000] tot_loss=1.542 (perp=7.328, rec=0.074, cos=0.002), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] as s 66, allen has at / stopped, if challenging himself. [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.379 (perp=6.395, rec=0.096, cos=0.005), tot_loss_proj:2.407 [t=0.17s]
prediction: ['[CLS] as / s 66, allen has at stopped, if challenging himself. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.389 (perp=6.395, rec=0.106, cos=0.004), tot_loss_proj:2.409 [t=0.17s]
prediction: ['[CLS] as / s 66, allen has at stopped, if challenging himself. [SEP]']
[1950/2000] tot_loss=1.381 (perp=6.395, rec=0.098, cos=0.004), tot_loss_proj:2.413 [t=0.17s]
prediction: ['[CLS] as / s 66, allen has at stopped, if challenging himself. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.314 (perp=6.107, rec=0.088, cos=0.004), tot_loss_proj:2.548 [t=0.17s]
prediction: ['[CLS] as / s 66, allen has stopped at, if challenging himself. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] as s 66, allen has at / stopped, if challenging himself. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 18.182 | p: 18.182 | r: 18.182
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 118.182

[Aggregate metrics]:
rouge1     | fm: 90.082 | p: 89.713 | r: 90.460
rouge2     | fm: 53.096 | p: 52.967 | r: 53.172
rougeL     | fm: 76.759 | p: 76.521 | r: 77.029
rougeLsum  | fm: 76.637 | p: 76.397 | r: 76.903
r1fm+r2fm = 143.178

input #76 time: 0:06:43 | total time: 8:49:33


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9992013460879874
highest_index [0]
highest [0.9992013460879874]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 1.6982685327529907 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 1.6925209760665894 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 1.4739956855773926 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 1.4576562643051147 for ['[CLS] where medium limeraphicno ways ole sheep sometime purple outside win most gray park [SEP]']
[Init] best perm rec loss: 1.4574075937271118 for ['[CLS] where medium park oleno ways sheep outside gray purple sometime win mostraphic lime [SEP]']
[Init] best perm rec loss: 1.4540070295333862 for ['[CLS] lime gray medium park whereraphic purple ole most win ways sheep sometime outsideno [SEP]']
[Init] best perm rec loss: 1.4537286758422852 for ['[CLS] parkraphic lime where medium ways ole sometime most purpleno outside gray win sheep [SEP]']
[Init] best perm rec loss: 1.4526270627975464 for ['[CLS] where park gray mediumraphic ways ole most lime sheepno win sometime outside purple [SEP]']
[Init] best perm rec loss: 1.4507323503494263 for ['[CLS] medium sheep park where purpleraphic sometime gray most outsideno ole lime ways win [SEP]']
[Init] best perm rec loss: 1.448798418045044 for ['[CLS] sheep medium gray where sometimeraphic park ole most lime win ways purpleno outside [SEP]']
[Init] best perm rec loss: 1.4465056657791138 for ['[CLS] where medium sometime park ole win purple gray sheep lime ways outsideraphic mostno [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.027 (perp=13.298, rec=0.346, cos=0.022), tot_loss_proj:3.450 [t=0.17s]
prediction: ['[CLS] wonderful sweet date myself will achievement offers standing variety its stevie together less mouth life [SEP]']
[ 100/2000] tot_loss=2.122 (perp=9.141, rec=0.281, cos=0.013), tot_loss_proj:2.612 [t=0.17s]
prediction: ['[CLS] wonderful beautiful ;ness the promise promise above life the believed ) less above life [SEP]']
[ 150/2000] tot_loss=1.830 (perp=7.979, rec=0.226, cos=0.009), tot_loss_proj:2.337 [t=0.17s]
prediction: ['[CLS] is its above is the promise promise above life the believe that views above life [SEP]']
[ 200/2000] tot_loss=1.973 (perp=8.936, rec=0.181, cos=0.005), tot_loss_proj:2.460 [t=0.17s]
prediction: ['[CLS] is its above is its promise promise life life the believe thatars above life [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.841 (perp=8.330, rec=0.169, cos=0.006), tot_loss_proj:2.590 [t=0.17s]
prediction: ['[CLS] is its life is its promise promise above life the believe thatars above realm [SEP]']
[ 300/2000] tot_loss=2.008 (perp=9.301, rec=0.144, cos=0.004), tot_loss_proj:2.733 [t=0.17s]
prediction: ['[CLS] is its life is make promise promise above life the believe thatars above material [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.898 (perp=8.846, rec=0.126, cos=0.003), tot_loss_proj:2.663 [t=0.17s]
prediction: ['[CLS] its its promise is make life promise above life the believe thatars above material [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.844 (perp=8.479, rec=0.144, cos=0.004), tot_loss_proj:2.754 [t=0.17s]
prediction: ['[CLS] its its promise is make life promise above - believe that lifears above realm [SEP]']
[ 450/2000] tot_loss=1.820 (perp=8.479, rec=0.122, cos=0.003), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] its its promise is make life promise above - believe that lifears above realm [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.019 (perp=9.496, rec=0.117, cos=0.002), tot_loss_proj:2.960 [t=0.17s]
prediction: ['[CLS] life its believe is make is promise above of believe that lifears above realm [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.811 (perp=8.501, rec=0.109, cos=0.002), tot_loss_proj:2.762 [t=0.17s]
prediction: ['[CLS] life its believe is make of promise above is believe that lifears above realm [SEP]']
[ 600/2000] tot_loss=1.811 (perp=8.507, rec=0.108, cos=0.002), tot_loss_proj:2.812 [t=0.17s]
prediction: ['[CLS] life its believe is make of promise above its believe that lifears above realm [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.799 (perp=8.507, rec=0.096, cos=0.002), tot_loss_proj:2.813 [t=0.17s]
prediction: ['[CLS] life its believe is make of promise above its believe that lifears above realm [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.708 (perp=7.970, rec=0.112, cos=0.002), tot_loss_proj:2.596 [t=0.17s]
prediction: ['[CLS] life its make believe is of promise above its believe that lifears above realm [SEP]']
[ 750/2000] tot_loss=1.698 (perp=7.970, rec=0.102, cos=0.002), tot_loss_proj:2.604 [t=0.17s]
prediction: ['[CLS] life its make believe is of promise above its believe that lifears above realm [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.695 (perp=7.970, rec=0.099, cos=0.002), tot_loss_proj:2.601 [t=0.17s]
prediction: ['[CLS] life its make believe is of promise above its believe that lifears above realm [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.752 (perp=8.195, rec=0.111, cos=0.003), tot_loss_proj:2.592 [t=0.17s]
prediction: ['[CLS] realm its make believe is of promise above its life that lifears above realm [SEP]']
[ 900/2000] tot_loss=1.734 (perp=8.195, rec=0.093, cos=0.002), tot_loss_proj:2.592 [t=0.17s]
prediction: ['[CLS] realm its make believe is of promise above its life that lifears above realm [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.691 (perp=7.958, rec=0.097, cos=0.002), tot_loss_proj:2.608 [t=0.17s]
prediction: ['[CLS] is its make believe realm of promise above its life that lifears above realm [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.702 (perp=7.996, rec=0.101, cos=0.002), tot_loss_proj:2.485 [t=0.17s]
prediction: ['[CLS] is its make believe realm of promise above life that lifears above realm - [SEP]']
[1050/2000] tot_loss=1.685 (perp=7.996, rec=0.084, cos=0.002), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] is its make believe realm of promise above life that lifears above realm - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.687 (perp=7.996, rec=0.086, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] is its make believe realm of promise above life that lifears above realm - [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.791 (perp=8.455, rec=0.098, cos=0.003), tot_loss_proj:2.502 [t=0.17s]
prediction: ['[CLS] is its make believe life of promise realm realm that lifears above realm - [SEP]']
[1200/2000] tot_loss=1.788 (perp=8.455, rec=0.095, cos=0.002), tot_loss_proj:2.495 [t=0.17s]
prediction: ['[CLS] is its make believe life of promise realm realm that lifears above realm - [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.672 (perp=7.919, rec=0.087, cos=0.002), tot_loss_proj:2.524 [t=0.17s]
prediction: ['[CLS] is its make believe life of promise realm - that lifears above realm realm [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.668 (perp=7.898, rec=0.087, cos=0.002), tot_loss_proj:2.500 [t=0.18s]
prediction: ['[CLS] is its make believe life promise of realm - that lifears above realm realm [SEP]']
[1350/2000] tot_loss=1.665 (perp=7.898, rec=0.084, cos=0.002), tot_loss_proj:2.502 [t=0.17s]
prediction: ['[CLS] is its make believe life promise of realm - that lifears above realm realm [SEP]']
Attempt swap
[1400/2000] tot_loss=1.674 (perp=7.898, rec=0.092, cos=0.002), tot_loss_proj:2.507 [t=0.17s]
prediction: ['[CLS] is its make believe life promise of realm - that lifears above realm realm [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.667 (perp=7.869, rec=0.091, cos=0.002), tot_loss_proj:2.613 [t=0.17s]
prediction: ['[CLS] is its make believe promise of life so - that lifears above realm realm [SEP]']
[1500/2000] tot_loss=1.675 (perp=7.869, rec=0.100, cos=0.002), tot_loss_proj:2.614 [t=0.17s]
prediction: ['[CLS] is its make believe promise of life so - that lifears above realm realm [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.533 (perp=7.181, rec=0.095, cos=0.002), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] is its make believe promise of life so that lifears above realm realm - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.531 (perp=7.181, rec=0.093, cos=0.002), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] is its make believe promise of life so that lifears above realm realm - [SEP]']
[1650/2000] tot_loss=1.531 (perp=7.181, rec=0.093, cos=0.002), tot_loss_proj:2.380 [t=0.17s]
prediction: ['[CLS] is its make believe promise of life so that lifears above realm realm - [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.472 (perp=6.955, rec=0.080, cos=0.002), tot_loss_proj:2.040 [t=0.17s]
prediction: ['[CLS] is its make believe promise of life that life soars above realm realm - [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.456 (perp=6.805, rec=0.093, cos=0.002), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] life is its make believe promise of life that soars above realm realm - [SEP]']
[1800/2000] tot_loss=1.455 (perp=6.805, rec=0.092, cos=0.002), tot_loss_proj:1.882 [t=0.17s]
prediction: ['[CLS] life is its make believe promise of life that soars above realm realm - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.451 (perp=6.805, rec=0.089, cos=0.002), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] life is its make believe promise of life that soars above realm realm - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.442 (perp=6.805, rec=0.079, cos=0.002), tot_loss_proj:1.884 [t=0.17s]
prediction: ['[CLS] life is its make believe promise of life that soars above realm realm - [SEP]']
[1950/2000] tot_loss=1.446 (perp=6.805, rec=0.083, cos=0.002), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] life is its make believe promise of life that soars above realm realm - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.452 (perp=6.805, rec=0.090, cos=0.002), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] life is its make believe promise of life that soars above realm realm - [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] life is its make believe promise of life that soars above realm realm - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.667 | p: 86.667 | r: 86.667
rouge2     | fm: 71.429 | p: 71.429 | r: 71.429
rougeL     | fm: 86.667 | p: 86.667 | r: 86.667
rougeLsum  | fm: 86.667 | p: 86.667 | r: 86.667
r1fm+r2fm = 158.095

[Aggregate metrics]:
rouge1     | fm: 90.078 | p: 89.765 | r: 90.444
rouge2     | fm: 53.118 | p: 53.001 | r: 53.260
rougeL     | fm: 76.666 | p: 76.441 | r: 76.893
rougeLsum  | fm: 76.840 | p: 76.569 | r: 77.113
r1fm+r2fm = 143.195

input #77 time: 0:06:48 | total time: 8:56:21


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9992696483604169
highest_index [0]
highest [0.9992696483604169]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 1.9528603553771973 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 1.9048945903778076 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 1.5339909791946411 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 1.3563518524169922 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 1.354122281074524 for ['[CLS] grant le screens [SEP]']
[Init] best perm rec loss: 1.3496745824813843 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.013 (perp=8.972, rec=0.207, cos=0.012), tot_loss_proj:2.710 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 100/2000] tot_loss=1.905 (perp=8.972, rec=0.107, cos=0.004), tot_loss_proj:2.727 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 150/2000] tot_loss=1.879 (perp=8.972, rec=0.081, cos=0.004), tot_loss_proj:2.720 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 200/2000] tot_loss=1.883 (perp=8.972, rec=0.085, cos=0.003), tot_loss_proj:2.726 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.229 (perp=10.782, rec=0.072, cos=0.001), tot_loss_proj:3.012 [t=0.19s]
prediction: ['[CLS] exit theater the [SEP]']
[ 300/2000] tot_loss=2.219 (perp=10.782, rec=0.061, cos=0.001), tot_loss_proj:3.000 [t=0.19s]
prediction: ['[CLS] exit theater the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.675 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.674 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.681 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.645 (perp=7.958, rec=0.052, cos=0.001), tot_loss_proj:1.673 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.658 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.658 (perp=7.958, rec=0.065, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.677 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.663 (perp=7.958, rec=0.070, cos=0.001), tot_loss_proj:1.672 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.680 [t=0.16s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.655 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.641 (perp=7.958, rec=0.048, cos=0.001), tot_loss_proj:1.678 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.643 (perp=7.958, rec=0.050, cos=0.001), tot_loss_proj:1.659 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.645 (perp=7.958, rec=0.052, cos=0.001), tot_loss_proj:1.674 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.666 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.674 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.687 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.681 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.687 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.672 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.667 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.655 (perp=7.958, rec=0.062, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.642 (perp=7.958, rec=0.049, cos=0.001), tot_loss_proj:1.676 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.679 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.658 (perp=7.958, rec=0.065, cos=0.001), tot_loss_proj:1.681 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.679 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.646 (perp=7.958, rec=0.053, cos=0.001), tot_loss_proj:1.674 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.674 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.663 (perp=7.958, rec=0.070, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.111 | p: 89.797 | r: 90.470
rouge2     | fm: 53.839 | p: 53.717 | r: 53.948
rougeL     | fm: 77.124 | p: 76.948 | r: 77.360
rougeLsum  | fm: 77.170 | p: 76.953 | r: 77.423
r1fm+r2fm = 143.950

input #78 time: 0:06:45 | total time: 9:03:06


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.9993343381444821
highest_index [0]
highest [0.9993343381444821]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 1.9500796794891357 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 1.7738052606582642 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 1.6991932392120361 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 1.544913411140442 for ['[CLS] combined quickly [SEP]']
[Init] best rec loss: 1.2942136526107788 for ['[CLS] texas qualified [SEP]']
[Init] best rec loss: 1.1571640968322754 for ['[CLS] own terrain [SEP]']
[Init] best rec loss: 1.1093544960021973 for ['[CLS] gray should [SEP]']
[Init] best perm rec loss: 1.1035370826721191 for ['[CLS] should gray [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.715 (perp=12.479, rec=0.213, cos=0.006), tot_loss_proj:2.937 [t=0.18s]
prediction: ['[CLS] fascinating gus [SEP]']
[ 100/2000] tot_loss=1.908 (perp=8.695, rec=0.164, cos=0.005), tot_loss_proj:1.958 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[ 150/2000] tot_loss=1.892 (perp=8.695, rec=0.149, cos=0.004), tot_loss_proj:1.964 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[ 200/2000] tot_loss=1.885 (perp=8.695, rec=0.142, cos=0.004), tot_loss_proj:1.952 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.887 (perp=8.695, rec=0.144, cos=0.004), tot_loss_proj:1.961 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.877 (perp=8.695, rec=0.134, cos=0.004), tot_loss_proj:1.964 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.892 (perp=8.695, rec=0.148, cos=0.005), tot_loss_proj:1.965 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.881 (perp=8.695, rec=0.138, cos=0.004), tot_loss_proj:1.975 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.914 (perp=8.695, rec=0.171, cos=0.004), tot_loss_proj:1.970 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.878 (perp=8.695, rec=0.135, cos=0.004), tot_loss_proj:1.980 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.880 (perp=8.695, rec=0.138, cos=0.004), tot_loss_proj:1.980 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.878 (perp=8.695, rec=0.135, cos=0.003), tot_loss_proj:1.975 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.903 (perp=8.695, rec=0.159, cos=0.005), tot_loss_proj:1.978 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.885 (perp=8.695, rec=0.142, cos=0.004), tot_loss_proj:1.981 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.881 (perp=8.695, rec=0.138, cos=0.003), tot_loss_proj:1.980 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.870 (perp=8.695, rec=0.128, cos=0.003), tot_loss_proj:1.979 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.866 (perp=8.695, rec=0.124, cos=0.003), tot_loss_proj:1.974 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.868 (perp=8.695, rec=0.126, cos=0.003), tot_loss_proj:1.979 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.873 (perp=8.695, rec=0.130, cos=0.004), tot_loss_proj:1.985 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.859 (perp=8.695, rec=0.117, cos=0.003), tot_loss_proj:1.986 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.860 (perp=8.695, rec=0.118, cos=0.003), tot_loss_proj:1.974 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.882 (perp=8.695, rec=0.139, cos=0.005), tot_loss_proj:1.991 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.866 (perp=8.695, rec=0.124, cos=0.003), tot_loss_proj:1.975 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.873 (perp=8.695, rec=0.131, cos=0.003), tot_loss_proj:1.979 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.858 (perp=8.695, rec=0.116, cos=0.003), tot_loss_proj:1.986 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.854 (perp=8.695, rec=0.112, cos=0.003), tot_loss_proj:1.979 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.864 (perp=8.695, rec=0.122, cos=0.003), tot_loss_proj:1.981 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.860 (perp=8.695, rec=0.118, cos=0.003), tot_loss_proj:1.973 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.847 (perp=8.695, rec=0.105, cos=0.003), tot_loss_proj:1.981 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.860 (perp=8.695, rec=0.118, cos=0.003), tot_loss_proj:1.992 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.859 (perp=8.695, rec=0.117, cos=0.003), tot_loss_proj:1.979 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.856 (perp=8.695, rec=0.114, cos=0.003), tot_loss_proj:1.984 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.870 (perp=8.695, rec=0.128, cos=0.003), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.854 (perp=8.695, rec=0.112, cos=0.003), tot_loss_proj:1.982 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.858 (perp=8.695, rec=0.116, cos=0.003), tot_loss_proj:1.985 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.856 (perp=8.695, rec=0.114, cos=0.003), tot_loss_proj:1.973 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.856 (perp=8.695, rec=0.114, cos=0.003), tot_loss_proj:1.975 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.859 (perp=8.695, rec=0.117, cos=0.003), tot_loss_proj:1.979 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.856 (perp=8.695, rec=0.114, cos=0.003), tot_loss_proj:1.980 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.853 (perp=8.695, rec=0.111, cos=0.003), tot_loss_proj:1.988 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 90.236 | p: 89.948 | r: 90.582
rouge2     | fm: 53.180 | p: 53.086 | r: 53.305
rougeL     | fm: 77.059 | p: 76.862 | r: 77.306
rougeLsum  | fm: 77.010 | p: 76.814 | r: 77.243
r1fm+r2fm = 143.416

input #79 time: 0:07:25 | total time: 9:10:32


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9992812106805644
highest_index [0]
highest [0.9992812106805644]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 1.8961759805679321 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 1.6977639198303223 for ['[CLS]yna snaps california mussolini kicked [SEP]']
[Init] best rec loss: 1.6965769529342651 for ['[CLS] peek yet knees investments trilogy [SEP]']
[Init] best rec loss: 1.6295527219772339 for ['[CLS]ghtlving dried days dressing [SEP]']
[Init] best perm rec loss: 1.626391053199768 for ['[CLS] dressing dayslvingght dried [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.648 (perp=12.989, rec=0.641, cos=0.409), tot_loss_proj:4.376 [t=0.18s]
prediction: ['[CLS] toughzen respects upon rail [SEP]']
[ 100/2000] tot_loss=3.978 (perp=14.736, rec=0.598, cos=0.432), tot_loss_proj:4.539 [t=0.19s]
prediction: ['[CLS] wisezengativefine wi [SEP]']
[ 150/2000] tot_loss=3.650 (perp=13.917, rec=0.568, cos=0.299), tot_loss_proj:4.049 [t=0.19s]
prediction: ['[CLS] wisezenaceousfine wi [SEP]']
[ 200/2000] tot_loss=3.609 (perp=13.267, rec=0.576, cos=0.379), tot_loss_proj:4.463 [t=0.19s]
prediction: ['[CLS] wisezen finchzko wi [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.002 (perp=11.625, rec=0.546, cos=0.131), tot_loss_proj:4.312 [t=0.19s]
prediction: ['[CLS] wisezenzko finch km² [SEP]']
[ 300/2000] tot_loss=3.542 (perp=12.853, rec=0.576, cos=0.396), tot_loss_proj:3.792 [t=0.19s]
prediction: ['[CLS] wisezen raw considered hockey [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.660 (perp=10.476, rec=0.505, cos=0.059), tot_loss_proj:3.763 [t=0.19s]
prediction: ['[CLS] wisezen considered wizko [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.074 (perp=12.332, rec=0.496, cos=0.111), tot_loss_proj:3.646 [t=0.19s]
prediction: ['[CLS] wisezen prodigy wizko [SEP]']
[ 450/2000] tot_loss=2.985 (perp=12.332, rec=0.474, cos=0.044), tot_loss_proj:3.644 [t=0.19s]
prediction: ['[CLS] wisezen prodigy wizko [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.949 (perp=12.332, rec=0.464, cos=0.019), tot_loss_proj:3.645 [t=0.19s]
prediction: ['[CLS] wisezen prodigy wizko [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.014 (perp=12.332, rec=0.471, cos=0.077), tot_loss_proj:3.641 [t=0.19s]
prediction: ['[CLS] wisezen prodigy wizko [SEP]']
[ 600/2000] tot_loss=2.947 (perp=12.332, rec=0.457, cos=0.024), tot_loss_proj:3.638 [t=0.19s]
prediction: ['[CLS] wisezen prodigy wizko [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.939 (perp=12.332, rec=0.461, cos=0.012), tot_loss_proj:3.643 [t=0.19s]
prediction: ['[CLS] wisezen prodigy wizko [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.932 (perp=12.332, rec=0.450, cos=0.016), tot_loss_proj:3.639 [t=0.19s]
prediction: ['[CLS] wisezen prodigy wizko [SEP]']
[ 750/2000] tot_loss=2.442 (perp=9.896, rec=0.442, cos=0.021), tot_loss_proj:2.837 [t=0.19s]
prediction: ['[CLS] wisezen prodigy wield [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.270 (perp=8.916, rec=0.443, cos=0.044), tot_loss_proj:3.090 [t=0.19s]
prediction: ['[CLS] wizen prodigy wield [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.639 (perp=10.688, rec=0.443, cos=0.059), tot_loss_proj:3.172 [t=0.19s]
prediction: ['[CLS] wizen everyone wield [SEP]']
[ 900/2000] tot_loss=2.664 (perp=11.043, rec=0.436, cos=0.020), tot_loss_proj:3.909 [t=0.19s]
prediction: ['[CLS] wizen everyone wized [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.667 (perp=11.043, rec=0.437, cos=0.022), tot_loss_proj:3.914 [t=0.19s]
prediction: ['[CLS] wizen everyone wized [SEP]']
Attempt swap
[1000/2000] tot_loss=2.414 (perp=9.653, rec=0.437, cos=0.046), tot_loss_proj:2.871 [t=0.19s]
prediction: ['[CLS] wizen quite wield [SEP]']
[1050/2000] tot_loss=2.433 (perp=9.653, rec=0.442, cos=0.060), tot_loss_proj:2.880 [t=0.19s]
prediction: ['[CLS] wizen quite wield [SEP]']
Attempt swap
[1100/2000] tot_loss=2.433 (perp=9.653, rec=0.424, cos=0.078), tot_loss_proj:2.881 [t=0.19s]
prediction: ['[CLS] wizen quite wield [SEP]']
Attempt swap
[1150/2000] tot_loss=2.436 (perp=9.653, rec=0.425, cos=0.081), tot_loss_proj:2.877 [t=0.19s]
prediction: ['[CLS] wizen quite wield [SEP]']
[1200/2000] tot_loss=2.384 (perp=9.653, rec=0.427, cos=0.027), tot_loss_proj:2.881 [t=0.19s]
prediction: ['[CLS] wizen quite wield [SEP]']
Attempt swap
[1250/2000] tot_loss=2.729 (perp=11.373, rec=0.435, cos=0.020), tot_loss_proj:3.766 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Attempt swap
[1300/2000] tot_loss=2.697 (perp=11.373, rec=0.421, cos=0.001), tot_loss_proj:3.762 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
[1350/2000] tot_loss=2.742 (perp=11.373, rec=0.419, cos=0.048), tot_loss_proj:3.759 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Attempt swap
[1400/2000] tot_loss=2.767 (perp=11.373, rec=0.419, cos=0.074), tot_loss_proj:3.759 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Attempt swap
[1450/2000] tot_loss=2.719 (perp=11.373, rec=0.427, cos=0.018), tot_loss_proj:3.761 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
[1500/2000] tot_loss=2.704 (perp=11.373, rec=0.427, cos=0.003), tot_loss_proj:3.759 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Attempt swap
[1550/2000] tot_loss=2.704 (perp=11.373, rec=0.420, cos=0.009), tot_loss_proj:3.762 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Attempt swap
[1600/2000] tot_loss=2.718 (perp=11.373, rec=0.420, cos=0.024), tot_loss_proj:3.763 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
[1650/2000] tot_loss=2.765 (perp=11.373, rec=0.419, cos=0.072), tot_loss_proj:3.762 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Attempt swap
[1700/2000] tot_loss=2.780 (perp=11.373, rec=0.416, cos=0.089), tot_loss_proj:3.758 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Attempt swap
[1750/2000] tot_loss=2.693 (perp=11.373, rec=0.415, cos=0.004), tot_loss_proj:3.760 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
[1800/2000] tot_loss=2.703 (perp=11.373, rec=0.424, cos=0.005), tot_loss_proj:3.756 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Attempt swap
[1850/2000] tot_loss=2.739 (perp=11.373, rec=0.421, cos=0.044), tot_loss_proj:3.756 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Attempt swap
[1900/2000] tot_loss=2.694 (perp=11.373, rec=0.417, cos=0.002), tot_loss_proj:3.766 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
[1950/2000] tot_loss=2.700 (perp=11.373, rec=0.413, cos=0.013), tot_loss_proj:3.764 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Attempt swap
[2000/2000] tot_loss=2.817 (perp=11.373, rec=0.425, cos=0.118), tot_loss_proj:3.759 [t=0.19s]
prediction: ['[CLS] wizen quite \\eld [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wizen quite \eld [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 44.444 | p: 40.000 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 40.000 | r: 50.000
rougeLsum  | fm: 44.444 | p: 40.000 | r: 50.000
r1fm+r2fm = 44.444

[Aggregate metrics]:
rouge1     | fm: 89.750 | p: 89.428 | r: 90.182
rouge2     | fm: 52.388 | p: 52.302 | r: 52.516
rougeL     | fm: 76.701 | p: 76.433 | r: 77.050
rougeLsum  | fm: 76.649 | p: 76.413 | r: 76.945
r1fm+r2fm = 142.138

input #80 time: 0:07:26 | total time: 9:17:58


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9992879299948307
highest_index [0]
highest [0.9992879299948307]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 1.8443113565444946 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 1.8287549018859863 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 1.5750724077224731 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 1.536523699760437 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 1.4952508211135864 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 1.3897989988327026 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 1.3871291875839233 for ['[CLS] mass seeneer off joe đ [SEP]']
[Init] best rec loss: 1.3777071237564087 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best rec loss: 1.3360694646835327 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 1.2880840301513672 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 1.2849894762039185 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 1.2837177515029907 for ['[CLS] donaldson ivydownvikplate proceeded [SEP]']
[Init] best perm rec loss: 1.282072901725769 for ['[CLS]downplate donaldson proceeded ivyvik [SEP]']
[Init] best perm rec loss: 1.28199303150177 for ['[CLS]vik proceeded donaldson ivydownplate [SEP]']
[Init] best perm rec loss: 1.278752326965332 for ['[CLS] donaldson ivydown proceededplatevik [SEP]']
[Init] best perm rec loss: 1.2762550115585327 for ['[CLS] donaldsondownvik proceeded ivyplate [SEP]']
[Init] best perm rec loss: 1.2757786512374878 for ['[CLS] donaldson proceededdownplate ivyvik [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.048 (perp=13.127, rec=0.385, cos=0.038), tot_loss_proj:4.561 [t=0.18s]
prediction: ['[CLS] doubt lucky impressive relatively i ghost [SEP]']
[ 100/2000] tot_loss=2.352 (perp=10.336, rec=0.266, cos=0.019), tot_loss_proj:3.657 [t=0.19s]
prediction: ['[CLS] neverness highest not most player [SEP]']
[ 150/2000] tot_loss=2.117 (perp=9.815, rec=0.148, cos=0.006), tot_loss_proj:3.567 [t=0.19s]
prediction: ['[CLS] not is impressive not most player [SEP]']
[ 200/2000] tot_loss=2.078 (perp=9.815, rec=0.110, cos=0.005), tot_loss_proj:3.590 [t=0.19s]
prediction: ['[CLS] not is impressive not most player [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.821 (perp=8.595, rec=0.098, cos=0.004), tot_loss_proj:2.538 [t=0.19s]
prediction: ['[CLS] is not impressive not most player [SEP]']
[ 300/2000] tot_loss=1.574 (perp=7.497, rec=0.073, cos=0.002), tot_loss_proj:2.043 [t=0.19s]
prediction: ['[CLS] is not impressive the most player [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.258 (perp=5.977, rec=0.061, cos=0.002), tot_loss_proj:1.332 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.259 (perp=5.977, rec=0.062, cos=0.001), tot_loss_proj:1.329 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 450/2000] tot_loss=1.261 (perp=5.977, rec=0.064, cos=0.001), tot_loss_proj:1.323 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.260 (perp=5.977, rec=0.063, cos=0.001), tot_loss_proj:1.331 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.263 (perp=5.977, rec=0.066, cos=0.001), tot_loss_proj:1.328 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 600/2000] tot_loss=1.265 (perp=5.977, rec=0.068, cos=0.001), tot_loss_proj:1.321 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.254 (perp=5.977, rec=0.058, cos=0.001), tot_loss_proj:1.326 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.262 (perp=5.977, rec=0.065, cos=0.001), tot_loss_proj:1.335 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 750/2000] tot_loss=1.250 (perp=5.977, rec=0.053, cos=0.001), tot_loss_proj:1.318 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.261 (perp=5.977, rec=0.065, cos=0.001), tot_loss_proj:1.323 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.255 (perp=5.977, rec=0.058, cos=0.001), tot_loss_proj:1.321 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.253 (perp=5.977, rec=0.056, cos=0.001), tot_loss_proj:1.335 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.269 (perp=5.977, rec=0.072, cos=0.001), tot_loss_proj:1.328 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.253 (perp=5.977, rec=0.056, cos=0.001), tot_loss_proj:1.329 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.240 (perp=5.977, rec=0.043, cos=0.001), tot_loss_proj:1.331 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.261 (perp=5.977, rec=0.065, cos=0.001), tot_loss_proj:1.328 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.255 (perp=5.977, rec=0.059, cos=0.001), tot_loss_proj:1.325 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.254 (perp=5.977, rec=0.058, cos=0.001), tot_loss_proj:1.322 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.249 (perp=5.977, rec=0.052, cos=0.001), tot_loss_proj:1.326 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.258 (perp=5.977, rec=0.061, cos=0.001), tot_loss_proj:1.333 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.255 (perp=5.977, rec=0.058, cos=0.001), tot_loss_proj:1.334 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.264 (perp=5.977, rec=0.067, cos=0.001), tot_loss_proj:1.327 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.269 (perp=5.977, rec=0.072, cos=0.001), tot_loss_proj:1.337 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.262 (perp=5.977, rec=0.065, cos=0.001), tot_loss_proj:1.327 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.260 (perp=5.977, rec=0.063, cos=0.001), tot_loss_proj:1.327 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.255 (perp=5.977, rec=0.058, cos=0.001), tot_loss_proj:1.327 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.258 (perp=5.977, rec=0.061, cos=0.001), tot_loss_proj:1.335 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.258 (perp=5.977, rec=0.061, cos=0.001), tot_loss_proj:1.325 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.261 (perp=5.977, rec=0.064, cos=0.001), tot_loss_proj:1.328 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.256 (perp=5.977, rec=0.059, cos=0.001), tot_loss_proj:1.322 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.258 (perp=5.977, rec=0.061, cos=0.001), tot_loss_proj:1.326 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.254 (perp=5.977, rec=0.057, cos=0.001), tot_loss_proj:1.336 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.263 (perp=5.977, rec=0.066, cos=0.001), tot_loss_proj:1.329 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.261 (perp=5.977, rec=0.064, cos=0.001), tot_loss_proj:1.332 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.930 | p: 89.566 | r: 90.308
rouge2     | fm: 53.010 | p: 52.887 | r: 53.125
rougeL     | fm: 76.864 | p: 76.603 | r: 77.179
rougeLsum  | fm: 77.080 | p: 76.810 | r: 77.332
r1fm+r2fm = 142.940

input #81 time: 0:07:26 | total time: 9:25:24


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.9992801011451229
highest_index [0]
highest [0.9992801011451229]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 1.9474414587020874 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 1.835921287536621 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 1.7372323274612427 for ['[CLS] ecclesiastical novel pre £ moi data push fran [SEP]']
[Init] best rec loss: 1.6888108253479004 for ['[CLS] maltaierif ace players reserve hmm rpm [SEP]']
[Init] best rec loss: 1.6774872541427612 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 1.4888206720352173 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 1.3586682081222534 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 1.3419948816299438 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 1.3394792079925537 for ['[CLS]basket respective whoever role plumagefurach record [SEP]']
[Init] best perm rec loss: 1.3392287492752075 for ['[CLS]achbasket record role respectivefur plumage whoever [SEP]']
[Init] best perm rec loss: 1.3361918926239014 for ['[CLS]basket record whoever rolefur respectiveach plumage [SEP]']
[Init] best perm rec loss: 1.3317865133285522 for ['[CLS]basketfur whoever respective role plumage recordach [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.754 (perp=12.487, rec=0.250, cos=0.007), tot_loss_proj:3.310 [t=0.19s]
prediction: ['[CLS] undone sloppy by areers oil imported undone [SEP]']
[ 100/2000] tot_loss=2.299 (perp=10.906, rec=0.115, cos=0.003), tot_loss_proj:2.726 [t=0.19s]
prediction: ['[CLS] undone sloppy by s a sloppy script script [SEP]']
[ 150/2000] tot_loss=2.281 (perp=10.906, rec=0.097, cos=0.002), tot_loss_proj:2.705 [t=0.19s]
prediction: ['[CLS] undone sloppy by s a sloppy script script [SEP]']
[ 200/2000] tot_loss=2.267 (perp=10.906, rec=0.084, cos=0.002), tot_loss_proj:2.697 [t=0.19s]
prediction: ['[CLS] undone sloppy by s a sloppy script script [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.852 (perp=8.835, rec=0.083, cos=0.002), tot_loss_proj:2.356 [t=0.19s]
prediction: ['[CLS] s a sloppy script undone sloppy by script [SEP]']
[ 300/2000] tot_loss=1.842 (perp=8.835, rec=0.073, cos=0.002), tot_loss_proj:2.362 [t=0.19s]
prediction: ['[CLS] s a sloppy script undone sloppy by script [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.601 (perp=7.601, rec=0.078, cos=0.002), tot_loss_proj:1.876 [t=0.19s]
prediction: ['[CLS] s a sloppy script undone by sloppy script [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.591 (perp=7.601, rec=0.070, cos=0.001), tot_loss_proj:1.879 [t=0.19s]
prediction: ['[CLS] s a sloppy script undone by sloppy script [SEP]']
[ 450/2000] tot_loss=1.808 (perp=8.684, rec=0.070, cos=0.001), tot_loss_proj:2.118 [t=0.19s]
prediction: ['[CLS] s a sloppy script undone by sloppy it [SEP]']
Attempt swap
Put prefix at the end
[ 500/2000] tot_loss=1.667 (perp=7.986, rec=0.069, cos=0.001), tot_loss_proj:1.944 [t=0.19s]
prediction: ['[CLS] it s a sloppy script undone by sloppy [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.627 (perp=7.778, rec=0.070, cos=0.002), tot_loss_proj:1.923 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 600/2000] tot_loss=1.623 (perp=7.778, rec=0.066, cos=0.001), tot_loss_proj:1.919 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.624 (perp=7.778, rec=0.067, cos=0.001), tot_loss_proj:1.935 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.619 (perp=7.778, rec=0.062, cos=0.001), tot_loss_proj:1.921 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 750/2000] tot_loss=1.636 (perp=7.778, rec=0.079, cos=0.001), tot_loss_proj:1.923 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.623 (perp=7.778, rec=0.066, cos=0.001), tot_loss_proj:1.929 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.619 (perp=7.778, rec=0.062, cos=0.001), tot_loss_proj:1.935 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[ 900/2000] tot_loss=1.619 (perp=7.778, rec=0.062, cos=0.001), tot_loss_proj:1.925 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.624 (perp=7.778, rec=0.067, cos=0.001), tot_loss_proj:1.929 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1000/2000] tot_loss=1.621 (perp=7.778, rec=0.064, cos=0.001), tot_loss_proj:1.927 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1050/2000] tot_loss=1.621 (perp=7.778, rec=0.063, cos=0.001), tot_loss_proj:1.933 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.628 (perp=7.778, rec=0.071, cos=0.001), tot_loss_proj:1.931 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1150/2000] tot_loss=1.618 (perp=7.778, rec=0.061, cos=0.001), tot_loss_proj:1.931 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1200/2000] tot_loss=1.622 (perp=7.778, rec=0.065, cos=0.001), tot_loss_proj:1.931 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1250/2000] tot_loss=1.614 (perp=7.778, rec=0.057, cos=0.001), tot_loss_proj:1.923 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.626 (perp=7.778, rec=0.069, cos=0.001), tot_loss_proj:1.929 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1350/2000] tot_loss=1.618 (perp=7.778, rec=0.061, cos=0.001), tot_loss_proj:1.918 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.615 (perp=7.778, rec=0.058, cos=0.001), tot_loss_proj:1.926 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1450/2000] tot_loss=1.629 (perp=7.778, rec=0.072, cos=0.001), tot_loss_proj:1.930 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1500/2000] tot_loss=1.617 (perp=7.778, rec=0.060, cos=0.001), tot_loss_proj:1.926 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1550/2000] tot_loss=1.627 (perp=7.778, rec=0.070, cos=0.001), tot_loss_proj:1.927 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1600/2000] tot_loss=1.623 (perp=7.778, rec=0.066, cos=0.001), tot_loss_proj:1.932 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1650/2000] tot_loss=1.629 (perp=7.778, rec=0.072, cos=0.001), tot_loss_proj:1.928 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.624 (perp=7.778, rec=0.067, cos=0.001), tot_loss_proj:1.931 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1750/2000] tot_loss=1.626 (perp=7.778, rec=0.069, cos=0.001), tot_loss_proj:1.933 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1800/2000] tot_loss=1.617 (perp=7.778, rec=0.060, cos=0.001), tot_loss_proj:1.937 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1850/2000] tot_loss=1.625 (perp=7.778, rec=0.067, cos=0.001), tot_loss_proj:1.925 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[1900/2000] tot_loss=1.626 (perp=7.778, rec=0.069, cos=0.001), tot_loss_proj:1.921 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
[1950/2000] tot_loss=1.622 (perp=7.778, rec=0.065, cos=0.001), tot_loss_proj:1.923 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Attempt swap
[2000/2000] tot_loss=1.628 (perp=7.778, rec=0.071, cos=0.001), tot_loss_proj:1.919 [t=0.19s]
prediction: ['[CLS] it s a sloppy sloppy script undone by [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s a sloppy sloppy script undone by [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 89.922 | p: 89.509 | r: 90.408
rouge2     | fm: 53.156 | p: 53.000 | r: 53.381
rougeL     | fm: 76.875 | p: 76.588 | r: 77.228
rougeLsum  | fm: 76.839 | p: 76.583 | r: 77.166
r1fm+r2fm = 143.078

input #82 time: 0:07:26 | total time: 9:32:51


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9992427003793516
highest_index [0]
highest [0.9992427003793516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 1.8980540037155151 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 1.8680791854858398 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 1.8268553018569946 for ['[CLS] expressing congratulations butch evacuate copyright grenadasome snow paid confidence [SEP]']
[Init] best rec loss: 1.7807674407958984 for ['[CLS] firm from eager ever heavier positions mc depending much those [SEP]']
[Init] best rec loss: 1.6598609685897827 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 1.5194369554519653 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best perm rec loss: 1.515126347541809 for ['[CLS] hit already use £ benji runaway mercy wild publishing someone [SEP]']
[Init] best perm rec loss: 1.506394386291504 for ['[CLS] already £ publishing use hit mercy someone wild benji runaway [SEP]']
[Init] best perm rec loss: 1.5047065019607544 for ['[CLS] hit £ already publishing use mercy someone runaway wild benji [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.947 (perp=12.979, rec=0.324, cos=0.027), tot_loss_proj:4.428 [t=0.19s]
prediction: ['[CLS] know what described growsju some someone fossils when destined [SEP]']
[ 100/2000] tot_loss=2.146 (perp=9.700, rec=0.199, cos=0.007), tot_loss_proj:3.229 [t=0.19s]
prediction: ['[CLS] know what it growsy developed generally grows be wants [SEP]']
[ 150/2000] tot_loss=2.174 (perp=10.099, rec=0.150, cos=0.004), tot_loss_proj:3.093 [t=0.19s]
prediction: ['[CLS] know what it grows when developed when grows be wants [SEP]']
[ 200/2000] tot_loss=1.961 (perp=9.229, rec=0.112, cos=0.003), tot_loss_proj:2.506 [t=0.19s]
prediction: ['[CLS] know what it wants up be when grows be wants [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.635 (perp=7.657, rec=0.101, cos=0.002), tot_loss_proj:2.194 [t=0.19s]
prediction: ['[CLS] know what it wants be when grows up be wants [SEP]']
[ 300/2000] tot_loss=1.474 (perp=6.944, rec=0.083, cos=0.002), tot_loss_proj:1.993 [t=0.19s]
prediction: ['[CLS] know what it wants for when grows up be wants [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.471 (perp=6.944, rec=0.080, cos=0.002), tot_loss_proj:1.992 [t=0.19s]
prediction: ['[CLS] know what it wants for when grows up be wants [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.464 (perp=6.944, rec=0.073, cos=0.002), tot_loss_proj:2.004 [t=0.19s]
prediction: ['[CLS] know what it wants for when grows up be wants [SEP]']
[ 450/2000] tot_loss=1.468 (perp=6.944, rec=0.077, cos=0.002), tot_loss_proj:2.001 [t=0.19s]
prediction: ['[CLS] know what it wants for when grows up be wants [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.459 (perp=6.944, rec=0.069, cos=0.002), tot_loss_proj:1.996 [t=0.19s]
prediction: ['[CLS] know what it wants for when grows up be wants [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.517 (perp=7.097, rec=0.093, cos=0.004), tot_loss_proj:2.003 [t=0.19s]
prediction: ['[CLS] know what it to be when grows up for wants [SEP]']
[ 600/2000] tot_loss=1.493 (perp=7.097, rec=0.072, cos=0.002), tot_loss_proj:2.007 [t=0.19s]
prediction: ['[CLS] know what it to be when grows up for wants [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.197 (perp=5.624, rec=0.070, cos=0.002), tot_loss_proj:1.361 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.198 (perp=5.624, rec=0.072, cos=0.002), tot_loss_proj:1.358 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
[ 750/2000] tot_loss=1.194 (perp=5.624, rec=0.068, cos=0.002), tot_loss_proj:1.357 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.196 (perp=5.624, rec=0.070, cos=0.002), tot_loss_proj:1.354 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.194 (perp=5.624, rec=0.067, cos=0.002), tot_loss_proj:1.357 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
[ 900/2000] tot_loss=1.202 (perp=5.624, rec=0.075, cos=0.002), tot_loss_proj:1.345 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.184 (perp=5.624, rec=0.057, cos=0.002), tot_loss_proj:1.348 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1000/2000] tot_loss=1.191 (perp=5.624, rec=0.065, cos=0.002), tot_loss_proj:1.339 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
[1050/2000] tot_loss=1.190 (perp=5.624, rec=0.063, cos=0.002), tot_loss_proj:1.346 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1100/2000] tot_loss=1.191 (perp=5.624, rec=0.065, cos=0.002), tot_loss_proj:1.346 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1150/2000] tot_loss=1.190 (perp=5.624, rec=0.063, cos=0.002), tot_loss_proj:1.341 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
[1200/2000] tot_loss=1.188 (perp=5.624, rec=0.062, cos=0.002), tot_loss_proj:1.343 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1250/2000] tot_loss=1.191 (perp=5.624, rec=0.064, cos=0.002), tot_loss_proj:1.344 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1300/2000] tot_loss=1.186 (perp=5.624, rec=0.059, cos=0.002), tot_loss_proj:1.341 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
[1350/2000] tot_loss=1.193 (perp=5.624, rec=0.066, cos=0.002), tot_loss_proj:1.344 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1400/2000] tot_loss=1.186 (perp=5.624, rec=0.059, cos=0.002), tot_loss_proj:1.347 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1450/2000] tot_loss=1.191 (perp=5.624, rec=0.065, cos=0.002), tot_loss_proj:1.343 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
[1500/2000] tot_loss=1.198 (perp=5.624, rec=0.071, cos=0.002), tot_loss_proj:1.338 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1550/2000] tot_loss=1.198 (perp=5.624, rec=0.071, cos=0.002), tot_loss_proj:1.346 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1600/2000] tot_loss=1.185 (perp=5.624, rec=0.059, cos=0.002), tot_loss_proj:1.339 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
[1650/2000] tot_loss=1.190 (perp=5.624, rec=0.064, cos=0.002), tot_loss_proj:1.342 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1700/2000] tot_loss=1.197 (perp=5.624, rec=0.070, cos=0.002), tot_loss_proj:1.346 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1750/2000] tot_loss=1.193 (perp=5.624, rec=0.066, cos=0.002), tot_loss_proj:1.336 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
[1800/2000] tot_loss=1.190 (perp=5.624, rec=0.063, cos=0.002), tot_loss_proj:1.337 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1850/2000] tot_loss=1.189 (perp=5.624, rec=0.063, cos=0.002), tot_loss_proj:1.339 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[1900/2000] tot_loss=1.188 (perp=5.624, rec=0.062, cos=0.002), tot_loss_proj:1.343 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
[1950/2000] tot_loss=1.200 (perp=5.624, rec=0.074, cos=0.002), tot_loss_proj:1.339 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Attempt swap
[2000/2000] tot_loss=1.189 (perp=5.624, rec=0.062, cos=0.002), tot_loss_proj:1.347 [t=0.19s]
prediction: ['[CLS] know what it wants to be when grows up for [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants to be when grows up for [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 164.394

[Aggregate metrics]:
rouge1     | fm: 89.945 | p: 89.557 | r: 90.443
rouge2     | fm: 53.162 | p: 53.017 | r: 53.327
rougeL     | fm: 77.131 | p: 76.815 | r: 77.485
rougeLsum  | fm: 77.070 | p: 76.816 | r: 77.423
r1fm+r2fm = 143.107

input #83 time: 0:07:27 | total time: 9:40:19


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9991125724774641
highest_index [0]
highest [0.9991125724774641]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 1.8125368356704712 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 1.8119263648986816 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 1.7110885381698608 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 1.5840494632720947 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 1.5825172662734985 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 1.5593494176864624 for ['[CLS] gmina standingply italian sessionhelm towards [SEP]']
[Init] best rec loss: 1.5217680931091309 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 1.477038025856018 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 1.4265689849853516 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 1.3894094228744507 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best rec loss: 1.3838614225387573 for ['[CLS] tradition captaindock seats [SEP] easier seas [SEP]']
[Init] best perm rec loss: 1.3745696544647217 for ['[CLS]dock tradition seas [SEP] seats captain easier [SEP]']
[Init] best perm rec loss: 1.3726637363433838 for ['[CLS]dock easier tradition captain seats [SEP] seas [SEP]']
[Init] best perm rec loss: 1.3407255411148071 for ['[CLS]dock seas captain tradition [SEP] easier seats [SEP]']
[Init] best perm rec loss: 1.3394502401351929 for ['[CLS]dock [SEP] captain easier seas tradition seats [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.438 (perp=10.891, rec=0.246, cos=0.013), tot_loss_proj:2.984 [t=0.19s]
prediction: ['[CLS] people think pawn lost ability have lost [SEP]']
[ 100/2000] tot_loss=1.992 (perp=9.379, rec=0.112, cos=0.004), tot_loss_proj:2.600 [t=0.19s]
prediction: ['[CLS] people think ability lost ability have lost [SEP]']
[ 150/2000] tot_loss=1.780 (perp=8.413, rec=0.092, cos=0.005), tot_loss_proj:2.431 [t=0.19s]
prediction: ['[CLS] people think the lost ability have lost [SEP]']
[ 200/2000] tot_loss=1.760 (perp=8.413, rec=0.074, cos=0.003), tot_loss_proj:2.429 [t=0.19s]
prediction: ['[CLS] people think the lost ability have lost [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.572 (perp=7.361, rec=0.095, cos=0.005), tot_loss_proj:2.229 [t=0.19s]
prediction: ['[CLS] people think have lost the lost ability [SEP]']
[ 300/2000] tot_loss=1.554 (perp=7.361, rec=0.078, cos=0.003), tot_loss_proj:2.220 [t=0.19s]
prediction: ['[CLS] people think have lost the lost ability [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.545 (perp=7.311, rec=0.080, cos=0.003), tot_loss_proj:2.190 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.549 (perp=7.311, rec=0.084, cos=0.003), tot_loss_proj:2.189 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[ 450/2000] tot_loss=1.542 (perp=7.311, rec=0.077, cos=0.003), tot_loss_proj:2.183 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.538 (perp=7.311, rec=0.073, cos=0.003), tot_loss_proj:2.190 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.543 (perp=7.311, rec=0.077, cos=0.003), tot_loss_proj:2.186 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[ 600/2000] tot_loss=1.541 (perp=7.311, rec=0.076, cos=0.003), tot_loss_proj:2.183 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.539 (perp=7.311, rec=0.073, cos=0.003), tot_loss_proj:2.186 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.530 (perp=7.311, rec=0.065, cos=0.003), tot_loss_proj:2.181 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[ 750/2000] tot_loss=1.547 (perp=7.311, rec=0.082, cos=0.003), tot_loss_proj:2.184 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.551 (perp=7.311, rec=0.086, cos=0.003), tot_loss_proj:2.182 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.545 (perp=7.311, rec=0.080, cos=0.003), tot_loss_proj:2.174 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[ 900/2000] tot_loss=1.536 (perp=7.311, rec=0.071, cos=0.003), tot_loss_proj:2.178 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.546 (perp=7.311, rec=0.081, cos=0.003), tot_loss_proj:2.174 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1000/2000] tot_loss=1.547 (perp=7.311, rec=0.082, cos=0.003), tot_loss_proj:2.180 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[1050/2000] tot_loss=1.544 (perp=7.311, rec=0.079, cos=0.003), tot_loss_proj:2.178 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1100/2000] tot_loss=1.541 (perp=7.311, rec=0.076, cos=0.003), tot_loss_proj:2.178 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1150/2000] tot_loss=1.542 (perp=7.311, rec=0.077, cos=0.003), tot_loss_proj:2.176 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[1200/2000] tot_loss=1.539 (perp=7.311, rec=0.074, cos=0.003), tot_loss_proj:2.182 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1250/2000] tot_loss=1.541 (perp=7.311, rec=0.076, cos=0.003), tot_loss_proj:2.172 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1300/2000] tot_loss=1.527 (perp=7.311, rec=0.062, cos=0.003), tot_loss_proj:2.178 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[1350/2000] tot_loss=1.539 (perp=7.311, rec=0.074, cos=0.002), tot_loss_proj:2.180 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1400/2000] tot_loss=1.544 (perp=7.311, rec=0.079, cos=0.002), tot_loss_proj:2.183 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1450/2000] tot_loss=1.537 (perp=7.311, rec=0.073, cos=0.002), tot_loss_proj:2.178 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[1500/2000] tot_loss=1.546 (perp=7.311, rec=0.082, cos=0.002), tot_loss_proj:2.174 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1550/2000] tot_loss=1.547 (perp=7.311, rec=0.083, cos=0.002), tot_loss_proj:2.171 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1600/2000] tot_loss=1.535 (perp=7.311, rec=0.070, cos=0.002), tot_loss_proj:2.176 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[1650/2000] tot_loss=1.550 (perp=7.311, rec=0.085, cos=0.002), tot_loss_proj:2.173 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1700/2000] tot_loss=1.540 (perp=7.311, rec=0.076, cos=0.002), tot_loss_proj:2.179 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1750/2000] tot_loss=1.538 (perp=7.311, rec=0.074, cos=0.002), tot_loss_proj:2.174 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[1800/2000] tot_loss=1.539 (perp=7.311, rec=0.074, cos=0.002), tot_loss_proj:2.179 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1850/2000] tot_loss=1.538 (perp=7.311, rec=0.074, cos=0.002), tot_loss_proj:2.168 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[1900/2000] tot_loss=1.545 (perp=7.311, rec=0.080, cos=0.002), tot_loss_proj:2.177 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
[1950/2000] tot_loss=1.542 (perp=7.311, rec=0.078, cos=0.002), tot_loss_proj:2.174 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Attempt swap
[2000/2000] tot_loss=1.541 (perp=7.311, rec=0.077, cos=0.002), tot_loss_proj:2.177 [t=0.19s]
prediction: ['[CLS] people think have lost the ability lost [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people think have lost the ability lost [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 138.889

[Aggregate metrics]:
rouge1     | fm: 89.933 | p: 89.499 | r: 90.436
rouge2     | fm: 53.277 | p: 53.175 | r: 53.439
rougeL     | fm: 77.062 | p: 76.791 | r: 77.442
rougeLsum  | fm: 77.125 | p: 76.861 | r: 77.484
r1fm+r2fm = 143.210

input #84 time: 0:07:27 | total time: 9:47:46


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9992374406339235
highest_index [0]
highest [0.9992374406339235]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 1.9611685276031494 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 1.8875846862792969 for ['[CLS] sent okay too deep partition secrecy consolidated true shouldn our [SEP]']
[Init] best rec loss: 1.7836694717407227 for ['[CLS] avoiding broadcast improved tuned plenty chancellor pet won littleros [SEP]']
[Init] best rec loss: 1.7814399003982544 for ['[CLS] brakeship and acronym senate developing technical leadrine reserve [SEP]']
[Init] best rec loss: 1.7765181064605713 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 1.6346447467803955 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 1.5155413150787354 for ['[CLS] thinks macau stand cam form halolic venture cannot vehicle [SEP]']
[Init] best rec loss: 1.44791841506958 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best rec loss: 1.3985786437988281 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best perm rec loss: 1.3900498151779175 for ['[CLS] challenging graf josephine dad haven graduation young overly nord blank [SEP]']
[Init] best perm rec loss: 1.3897099494934082 for ['[CLS] young josephine overly dad graduation challenging blank haven nord graf [SEP]']
[Init] best perm rec loss: 1.3883607387542725 for ['[CLS] young graf josephine nord haven challenging dad overly blank graduation [SEP]']
[Init] best perm rec loss: 1.3878798484802246 for ['[CLS] young graf nord graduation josephine blank dad overly challenging haven [SEP]']
[Init] best perm rec loss: 1.387863039970398 for ['[CLS] blank haven josephine young dad graf nord overly graduation challenging [SEP]']
[Init] best perm rec loss: 1.3863424062728882 for ['[CLS] graduation haven nord josephine dad young challenging overly graf blank [SEP]']
[Init] best perm rec loss: 1.3851666450500488 for ['[CLS] young graf challenging nord graduation overly haven josephine dad blank [SEP]']
[Init] best perm rec loss: 1.384523630142212 for ['[CLS] young blank josephine nord graduation dad challenging overly graf haven [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.313 (perp=9.959, rec=0.307, cos=0.014), tot_loss_proj:3.941 [t=0.19s]
prediction: ['[CLS] unfortunately not unfortunately unfortunately unfortunately spring also actually good unfortunately [SEP]']
[ 100/2000] tot_loss=1.768 (perp=8.003, rec=0.161, cos=0.006), tot_loss_proj:2.263 [t=0.19s]
prediction: ['[CLS] unfortunately not also also not it good not good very [SEP]']
[ 150/2000] tot_loss=1.718 (perp=8.059, rec=0.103, cos=0.004), tot_loss_proj:2.326 [t=0.19s]
prediction: ['[CLS] unfortunately. also s not it good while good very [SEP]']
[ 200/2000] tot_loss=1.699 (perp=8.059, rec=0.084, cos=0.003), tot_loss_proj:2.324 [t=0.19s]
prediction: ['[CLS] unfortunately. also s not it good while good very [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.323 (perp=6.146, rec=0.091, cos=0.003), tot_loss_proj:1.741 [t=0.19s]
prediction: ['[CLS] unfortunately. also s not it good very good. [SEP]']
[ 300/2000] tot_loss=1.305 (perp=6.146, rec=0.073, cos=0.003), tot_loss_proj:1.736 [t=0.19s]
prediction: ['[CLS] unfortunately. also s not it good very good. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.017 (perp=4.740, rec=0.067, cos=0.003), tot_loss_proj:1.193 [t=0.19s]
prediction: ['[CLS] unfortunately, it also s not good very good. [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.029 (perp=4.740, rec=0.079, cos=0.003), tot_loss_proj:1.194 [t=0.19s]
prediction: ['[CLS] unfortunately, it also s not good very good. [SEP]']
[ 450/2000] tot_loss=1.008 (perp=4.740, rec=0.058, cos=0.002), tot_loss_proj:1.202 [t=0.19s]
prediction: ['[CLS] unfortunately, it also s not good very good. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.017 (perp=4.740, rec=0.067, cos=0.002), tot_loss_proj:1.181 [t=0.19s]
prediction: ['[CLS] unfortunately, it also s not good very good. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.021 (perp=4.740, rec=0.071, cos=0.002), tot_loss_proj:1.185 [t=0.19s]
prediction: ['[CLS] unfortunately, it also s not good very good. [SEP]']
[ 600/2000] tot_loss=1.092 (perp=5.116, rec=0.066, cos=0.002), tot_loss_proj:1.348 [t=0.19s]
prediction: ["[CLS] unfortunately, it also s not'very good. [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.193 (perp=5.605, rec=0.069, cos=0.003), tot_loss_proj:1.376 [t=0.19s]
prediction: ['[CLS] unfortunately, it also ® s not very good. [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.128 (perp=5.299, rec=0.066, cos=0.003), tot_loss_proj:1.260 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
[ 750/2000] tot_loss=1.127 (perp=5.299, rec=0.065, cos=0.002), tot_loss_proj:1.260 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.125 (perp=5.299, rec=0.063, cos=0.002), tot_loss_proj:1.265 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.129 (perp=5.299, rec=0.067, cos=0.002), tot_loss_proj:1.268 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
[ 900/2000] tot_loss=1.129 (perp=5.299, rec=0.067, cos=0.002), tot_loss_proj:1.264 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.120 (perp=5.299, rec=0.058, cos=0.002), tot_loss_proj:1.265 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.132 (perp=5.299, rec=0.070, cos=0.002), tot_loss_proj:1.263 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
[1050/2000] tot_loss=1.113 (perp=5.299, rec=0.051, cos=0.002), tot_loss_proj:1.256 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.131 (perp=5.299, rec=0.069, cos=0.002), tot_loss_proj:1.269 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.118 (perp=5.299, rec=0.056, cos=0.002), tot_loss_proj:1.265 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
[1200/2000] tot_loss=1.126 (perp=5.299, rec=0.064, cos=0.002), tot_loss_proj:1.257 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.133 (perp=5.299, rec=0.071, cos=0.002), tot_loss_proj:1.258 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.125 (perp=5.299, rec=0.063, cos=0.002), tot_loss_proj:1.261 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
[1350/2000] tot_loss=1.124 (perp=5.299, rec=0.062, cos=0.002), tot_loss_proj:1.260 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.119 (perp=5.299, rec=0.057, cos=0.002), tot_loss_proj:1.258 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.122 (perp=5.299, rec=0.060, cos=0.002), tot_loss_proj:1.269 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
[1500/2000] tot_loss=1.122 (perp=5.299, rec=0.060, cos=0.002), tot_loss_proj:1.268 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.130 (perp=5.299, rec=0.068, cos=0.002), tot_loss_proj:1.270 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.129 (perp=5.299, rec=0.067, cos=0.002), tot_loss_proj:1.263 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
[1650/2000] tot_loss=1.121 (perp=5.299, rec=0.059, cos=0.002), tot_loss_proj:1.258 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.118 (perp=5.299, rec=0.056, cos=0.002), tot_loss_proj:1.256 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.133 (perp=5.299, rec=0.071, cos=0.002), tot_loss_proj:1.263 [t=0.19s]
prediction: ['[CLS] unfortunately, it ® s also not very good. [SEP]']
[1800/2000] tot_loss=0.729 (perp=3.342, rec=0.059, cos=0.002), tot_loss_proj:0.771 [t=0.19s]
prediction: ["[CLS] unfortunately, it's also not very good. [SEP]"]
Attempt swap
[1850/2000] tot_loss=0.735 (perp=3.342, rec=0.064, cos=0.002), tot_loss_proj:0.775 [t=0.19s]
prediction: ["[CLS] unfortunately, it's also not very good. [SEP]"]
Attempt swap
[1900/2000] tot_loss=0.737 (perp=3.342, rec=0.066, cos=0.002), tot_loss_proj:0.779 [t=0.19s]
prediction: ["[CLS] unfortunately, it's also not very good. [SEP]"]
[1950/2000] tot_loss=0.735 (perp=3.342, rec=0.065, cos=0.002), tot_loss_proj:0.773 [t=0.19s]
prediction: ["[CLS] unfortunately, it's also not very good. [SEP]"]
Attempt swap
[2000/2000] tot_loss=0.730 (perp=3.342, rec=0.059, cos=0.002), tot_loss_proj:0.757 [t=0.19s]
prediction: ["[CLS] unfortunately, it's also not very good. [SEP]"]
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.061 | p: 89.661 | r: 90.520
rouge2     | fm: 53.729 | p: 53.555 | r: 53.964
rougeL     | fm: 77.336 | p: 77.081 | r: 77.711
rougeLsum  | fm: 77.396 | p: 77.110 | r: 77.782
r1fm+r2fm = 143.790

input #85 time: 0:07:28 | total time: 9:55:14


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9993327117168653
highest_index [0]
highest [0.9993327117168653]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 1.9023118019104004 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 1.8336035013198853 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 1.7943329811096191 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 1.7112845182418823 for ['[CLS] maria passingerative [SEP]']
[Init] best rec loss: 1.6274235248565674 for ['[CLS] bipolar sea set [SEP]']
[Init] best rec loss: 1.5547959804534912 for ['[CLS] lp happy winston [SEP]']
[Init] best rec loss: 1.4702644348144531 for ['[CLS] studied ride roar [SEP]']
[Init] best rec loss: 1.2827883958816528 for ['[CLS] tons things wi [SEP]']
[Init] best rec loss: 0.9979948997497559 for ['[CLS] talks karen flipped [SEP]']
[Init] best perm rec loss: 0.9904369711875916 for ['[CLS] flipped karen talks [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.495 (perp=11.443, rec=0.200, cos=0.007), tot_loss_proj:2.735 [t=0.19s]
prediction: ['[CLS] clarity clearly clarity [SEP]']
[ 100/2000] tot_loss=2.438 (perp=11.443, rec=0.146, cos=0.003), tot_loss_proj:2.728 [t=0.19s]
prediction: ['[CLS] clarity clearly clarity [SEP]']
[ 150/2000] tot_loss=2.555 (perp=12.120, rec=0.128, cos=0.003), tot_loss_proj:2.877 [t=0.19s]
prediction: ['[CLS] emotional clearly clarity [SEP]']
[ 200/2000] tot_loss=2.536 (perp=12.120, rec=0.110, cos=0.002), tot_loss_proj:2.873 [t=0.19s]
prediction: ['[CLS] emotional clearly clarity [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.407 (perp=11.493, rec=0.106, cos=0.002), tot_loss_proj:2.604 [t=0.19s]
prediction: ['[CLS] emotional clarity emotional [SEP]']
[ 300/2000] tot_loss=2.238 (perp=10.632, rec=0.109, cos=0.002), tot_loss_proj:2.495 [t=0.19s]
prediction: ['[CLS] emotional clarity obviously [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.218 (perp=10.632, rec=0.089, cos=0.002), tot_loss_proj:2.507 [t=0.19s]
prediction: ['[CLS] emotional clarity obviously [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.766 (perp=8.419, rec=0.081, cos=0.002), tot_loss_proj:1.836 [t=0.19s]
prediction: ['[CLS] emotional and clarity [SEP]']
[ 450/2000] tot_loss=1.735 (perp=8.419, rec=0.050, cos=0.001), tot_loss_proj:1.843 [t=0.19s]
prediction: ['[CLS] emotional and clarity [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.716 (perp=8.211, rec=0.073, cos=0.001), tot_loss_proj:1.870 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.717 (perp=8.211, rec=0.074, cos=0.001), tot_loss_proj:1.869 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 600/2000] tot_loss=1.715 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.871 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.716 (perp=8.211, rec=0.072, cos=0.001), tot_loss_proj:1.874 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.710 (perp=8.211, rec=0.067, cos=0.001), tot_loss_proj:1.877 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=1.706 (perp=8.211, rec=0.062, cos=0.001), tot_loss_proj:1.876 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.715 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.874 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.702 (perp=8.211, rec=0.058, cos=0.001), tot_loss_proj:1.866 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=1.707 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.877 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.700 (perp=8.211, rec=0.057, cos=0.001), tot_loss_proj:1.877 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.711 (perp=8.211, rec=0.068, cos=0.001), tot_loss_proj:1.878 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=1.708 (perp=8.211, rec=0.064, cos=0.001), tot_loss_proj:1.879 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.709 (perp=8.211, rec=0.065, cos=0.001), tot_loss_proj:1.875 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.709 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.867 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=1.707 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.870 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.701 (perp=8.211, rec=0.058, cos=0.001), tot_loss_proj:1.875 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.708 (perp=8.211, rec=0.065, cos=0.001), tot_loss_proj:1.876 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=1.706 (perp=8.211, rec=0.062, cos=0.001), tot_loss_proj:1.860 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.697 (perp=8.211, rec=0.053, cos=0.001), tot_loss_proj:1.879 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.715 (perp=8.211, rec=0.072, cos=0.001), tot_loss_proj:1.874 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=1.707 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.871 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.708 (perp=8.211, rec=0.065, cos=0.001), tot_loss_proj:1.880 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.704 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.877 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=1.713 (perp=8.211, rec=0.069, cos=0.001), tot_loss_proj:1.871 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.701 (perp=8.211, rec=0.058, cos=0.001), tot_loss_proj:1.872 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.705 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.869 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=1.710 (perp=8.211, rec=0.067, cos=0.001), tot_loss_proj:1.869 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.700 (perp=8.211, rec=0.057, cos=0.001), tot_loss_proj:1.879 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.714 (perp=8.211, rec=0.070, cos=0.001), tot_loss_proj:1.878 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=1.705 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.875 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.708 (perp=8.211, rec=0.065, cos=0.001), tot_loss_proj:1.869 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 90.103 | p: 89.707 | r: 90.636
rouge2     | fm: 53.513 | p: 53.366 | r: 53.670
rougeL     | fm: 77.360 | p: 77.057 | r: 77.726
rougeLsum  | fm: 77.400 | p: 77.111 | r: 77.722
r1fm+r2fm = 143.616

input #86 time: 0:07:25 | total time: 10:02:40


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.9992553760665845
highest_index [0]
highest [0.9992553760665845]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 1.4715983867645264 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 1.1083849668502808 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 1.1040385961532593 for ['[CLS] distinct post [SEP]']
[Init] best rec loss: 1.0068668127059937 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.9670395851135254 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.9667397141456604 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.776 (perp=7.258, rec=0.287, cos=0.037), tot_loss_proj:1.517 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 100/2000] tot_loss=1.662 (perp=7.258, rec=0.183, cos=0.028), tot_loss_proj:1.526 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.540 (perp=7.258, rec=0.086, cos=0.002), tot_loss_proj:1.537 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.778 (perp=7.258, rec=0.290, cos=0.037), tot_loss_proj:1.522 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.565 (perp=7.258, rec=0.108, cos=0.005), tot_loss_proj:1.532 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.532 (perp=7.258, rec=0.078, cos=0.002), tot_loss_proj:1.548 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.002), tot_loss_proj:1.528 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.002), tot_loss_proj:1.543 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.527 (perp=7.258, rec=0.074, cos=0.001), tot_loss_proj:1.533 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.521 (perp=7.258, rec=0.068, cos=0.001), tot_loss_proj:1.550 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.528 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.514 (perp=7.258, rec=0.061, cos=0.001), tot_loss_proj:1.537 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.513 (perp=7.258, rec=0.060, cos=0.001), tot_loss_proj:1.545 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.002), tot_loss_proj:1.528 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.533 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.521 (perp=7.258, rec=0.068, cos=0.001), tot_loss_proj:1.520 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.510 (perp=7.258, rec=0.057, cos=0.001), tot_loss_proj:1.527 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.520 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.531 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.522 (perp=7.258, rec=0.069, cos=0.001), tot_loss_proj:1.542 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.540 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.534 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.544 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.514 (perp=7.258, rec=0.061, cos=0.001), tot_loss_proj:1.526 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.514 (perp=7.258, rec=0.061, cos=0.001), tot_loss_proj:1.538 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.497 (perp=7.258, rec=0.044, cos=0.001), tot_loss_proj:1.522 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.532 (perp=7.258, rec=0.079, cos=0.001), tot_loss_proj:1.516 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.536 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.520 (perp=7.258, rec=0.067, cos=0.001), tot_loss_proj:1.538 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.532 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.509 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.537 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.495 (perp=7.258, rec=0.042, cos=0.001), tot_loss_proj:1.528 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.512 (perp=7.258, rec=0.059, cos=0.001), tot_loss_proj:1.543 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.512 (perp=7.258, rec=0.059, cos=0.001), tot_loss_proj:1.527 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.520 (perp=7.258, rec=0.067, cos=0.001), tot_loss_proj:1.528 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.494 (perp=7.258, rec=0.041, cos=0.001), tot_loss_proj:1.528 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.522 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.501 (perp=7.258, rec=0.048, cos=0.001), tot_loss_proj:1.534 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.501 (perp=7.258, rec=0.048, cos=0.001), tot_loss_proj:1.530 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.530 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.269 | p: 89.925 | r: 90.713
rouge2     | fm: 54.034 | p: 53.879 | r: 54.214
rougeL     | fm: 77.659 | p: 77.377 | r: 77.991
rougeLsum  | fm: 77.623 | p: 77.367 | r: 77.966
r1fm+r2fm = 144.303

input #87 time: 0:07:25 | total time: 10:10:06


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.9992358071326222
highest_index [0]
highest [0.9992358071326222]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 1.9200705289840698 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 1.8874351978302002 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 1.8369611501693726 for ['[CLS]ho dukevs counter licence fruitoninguded customerbasket manufacturingeon movement psyche life researchers dart foreign nadia occasion mare good maximumerty unemployment pattern though alpha flames day :rop at mechanics scratch 200 forewings boss emergency loanex decades overview [SEP]']
[Init] best rec loss: 1.7725632190704346 for ['[CLS] bryn products oclc sm boone instead off capable pain short most kenny high tricript bathurst trade gigs acheron sometimes loomed board viiash second why recipient stillkeeping metal wall camp gold lingda gr manson series warming themselves face precedence ghetto [SEP]']
[Init] best rec loss: 1.7031794786453247 for ['[CLS] dose skin epicennial designbu paddy market improvement content came elijahds what off skye bat just navalesis winked zur butterfly contract ready sympathy block tomorrow and pitt knew jerizeap plague flat optical valley lynch mother drive men co [SEP]']
[Init] best rec loss: 1.6743240356445312 for ['[CLS] tells pursuithis compromise sweet bull sour wescreen lying bearwny wet touch time dream planet... make said rapper assembly spain close dinner benzg arc farm tatar basic university trough born boundbound big factor ad diesel askingrew band [SEP]']
[Init] best rec loss: 1.6713396310806274 for ['[CLS] chairman fall blue hipsaq mold ltd raymond cousintablishedtic once... late ap evidenceground hill yo foundation mostmen avant overlandgra rubberivating n be miles podium crown job scriptati first requirement whole excusenut brown him england [SEP]']
[Init] best perm rec loss: 1.6702827215194702 for ['[CLS] miles cousin natitablished ap ltd raymond mostnut hips requirement falltic... onceaq first moldgraivating scriptground overland crown him evidence rubber brownmen late yo avant job be podium chairman whole england blue excuse foundation hill [SEP]']
[Init] best perm rec loss: 1.669132113456726 for ['[CLS] ltd blue script cousin raymond late englandground rubber him excuse apaq hipsmenati overland... requirementivating mostgra chairman foundation yo evidence n mold be hill podium once fall firsttic jobnut whole crown brown milestablished avant [SEP]']
[Init] best perm rec loss: 1.6680104732513428 for ['[CLS]ivating job late apati oncetablished raymond foundation evidence excuse chairman england cousinground script miles blue fallaq rubber whole... podiumtic firstgra hips most crown avant ltd brown overlandmen be mold requirement him yo n hillnut [SEP]']
[Init] best perm rec loss: 1.666865348815918 for ['[CLS] n late fallnut scriptivating chairman excusetablished avant requirement him mold crown most hips englandground cousin... overland brown ltd miles evidence wholeaq onceticgra blue raymond hill podium rubber foundation yoati jobmen first be ap [SEP]']
[Init] best perm rec loss: 1.6660468578338623 for ['[CLS] miles ltd mold first... rubber evidencemen late england fallnut foundation excusetablishedati crown be brownaq podium overland ap script wholeground cousin hill n hips most himivating job requirementtic chairman blue avant raymond oncegra yo [SEP]']
[Init] best perm rec loss: 1.6599833965301514 for ['[CLS]tablished mold miles rubber ap requirement blue podium ltd... script himnutmen excuse evidence most brown overlandground chairman yo job lateatigra nivating hill hips once cousinaq raymond whole crown first fall foundationtic england avant be [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.608 (perp=11.295, rec=0.337, cos=0.013), tot_loss_proj:3.472 [t=0.19s]
prediction: ['[CLS] champions creative collective cannes.able consonants forgiveness! ; happiness brilliant children. wonderful worthy the, bryson event healing and [SEP] celebrationlke moments on beauty pull adult pulling is artization matter respective youth global creatures unique with void the [SEP]']
[ 100/2000] tot_loss=2.532 (perp=11.162, rec=0.294, cos=0.006), tot_loss_proj:4.125 [t=0.19s]
prediction: ['[CLS] /lous arch you warmter situation romance love at mathematical warmly ones design love worthy the and bryson fan rec und [SEP] education american understands understand traditional power romance hates and story understandsities anderson ren. world / how void the [SEP]']
[ 150/2000] tot_loss=2.442 (perp=10.899, rec=0.260, cos=0.003), tot_loss_proj:3.778 [t=0.19s]
prediction: ['[CLS] life subtle. you evented bo romance event knew mathematical genuinely ones theme wonderful “ the the bryson cause lack and [SEP]! and use understood traditional true yourizerς history relationsity. ren our path. how wild the [SEP]']
[ 200/2000] tot_loss=2.715 (perp=11.500, rec=0.375, cos=0.039), tot_loss_proj:3.519 [t=0.19s]
prediction: ['[CLS]→ the plus huge calm [CLS]um romance benefit knowing happiness paris does of love ; ள and reserved reach notion and [CLS] this subsequent. understands⽥ grand personal ள 主 aesthetic understands philosophy.ce ள path modern how. the [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.513 (perp=11.110, rec=0.287, cos=0.004), tot_loss_proj:3.609 [t=0.19s]
prediction: ["[CLS] issues dec - huge calm the deep love love, flow japanese sexual. love ⇄icative and xx awake notion and [CLS] ள subsequent uses understand ',ness氵 and wonderful ahead o. tribute psycho circuit rises how ore the [SEP]"]
[ 300/2000] tot_loss=2.367 (perp=10.541, rec=0.255, cos=0.004), tot_loss_proj:3.955 [t=0.19s]
prediction: ["[CLS] ill our - spiritual calm the here romance romance to flow principle personal. love．icative and xx bring clear and [CLS] usually subsequent use understands ',ness（ and great of f. tribute psycho circuit s how. the [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.163 (perp=9.531, rec=0.253, cos=0.003), tot_loss_proj:3.507 [t=0.19s]
prediction: ['[CLS] ill. ; great calm the sometimes love romance to flow principle print. joy．icative and xx, clear and [CLS] usual the that understands the,ness（ and grand of exist our lesser futures circuit s how. the [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.095 (perp=9.297, rec=0.232, cos=0.003), tot_loss_proj:3.418 [t=0.19s]
prediction: ['[CLS] ill.. great calm the " the romance. happiness class full. ள ⇄icative and xx, clear and [CLS] usual love that understands the survivor beings楊 and grand of exist our lesser super circuit s how. the [SEP]']
[ 450/2000] tot_loss=2.201 (perp=9.843, rec=0.229, cos=0.003), tot_loss_proj:3.518 [t=0.19s]
prediction: ['[CLS] ill.. great calm the " the romance. happiness class our.´ ⇄ of ں xx the clear and. desk love power understands the survivor ones楊 and grand of exist port wage super path hundreds how. the [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.065 (perp=9.249, rec=0.212, cos=0.003), tot_loss_proj:3.391 [t=0.19s]
prediction: ['[CLS] ill.. great. the " the romance. happiness every our. of． of ள xx the clear and calm goes love how understands the survivor sum楊 and grand of exist as wage futures path s how. the [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.955 (perp=8.741, rec=0.204, cos=0.002), tot_loss_proj:3.287 [t=0.19s]
prediction: ['[CLS] ill.. great. the " the romance. joy every our. path． of ள signals of clear and calm goes love how understands the survivor sum楊 and grandness exist as wage futures of s how. the [SEP]']
[ 600/2000] tot_loss=1.949 (perp=8.785, rec=0.190, cos=0.002), tot_loss_proj:3.376 [t=0.19s]
prediction: ['[CLS] ill.. great. the inhabit the romance. joy class our. path． of ள signals of notion and calm goes love how understands the survivorly楊 and grandness exist as wage super of s how. the [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.002 (perp=8.995, rec=0.201, cos=0.002), tot_loss_proj:3.152 [t=0.19s]
prediction: ['[CLS] ill.. great. the inhabit the romance. joy is our. path． of the how xx of pleasant and calm existing love how understands survivor...楊 and grandness exist thetorium super of s how. the [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.084 (perp=9.409, rec=0.199, cos=0.003), tot_loss_proj:3.168 [t=0.19s]
prediction: ['[CLS] ill.. great. the inhabit the romance. joyis our existing path． of the how xx we pleasant and calm. love how understands survivor...楊 and grandness exist the joy super of has how. the [SEP]']
[ 750/2000] tot_loss=2.111 (perp=9.582, rec=0.192, cos=0.002), tot_loss_proj:3.240 [t=0.19s]
prediction: ['[CLS] ill.. our. the inhabit the romance. joyis our existing path． of the how xx we historic and calm. love how understands survivor...楊 and grandness exist the joy super is s how. the [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.949 (perp=8.819, rec=0.183, cos=0.002), tot_loss_proj:3.147 [t=0.19s]
prediction: ['[CLS] ill.. our. the and the romance. joyis our existing path． of thes xx we historic inhabit calm. love how understands resident...楊 and grandness we the joy super of s how. the [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.932 (perp=8.561, rec=0.217, cos=0.003), tot_loss_proj:3.113 [t=0.19s]
prediction: ['[CLS] ill.. our of the and the romance. joyis our paving existing path． of the that romantic of " calm. love that understands survivor...楊 and grandness we the joy super is out how. the [SEP]']
[ 900/2000] tot_loss=1.917 (perp=8.604, rec=0.194, cos=0.002), tot_loss_proj:3.142 [t=0.19s]
prediction: ['[CLS] ill., our of the and the romance. joyis our paving existing path． of the our romantic of inhabit calm. love that understands native...楊 and grandness we the joy taylor is out how. the [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.929 (perp=8.683, rec=0.189, cos=0.002), tot_loss_proj:3.212 [t=0.19s]
prediction: ['[CLS] ill t. our of the and the romance. joyis resident paving existing path． of the our romantic of " calm. love that understands our...楊 and grandness we the joy madison of out how. the [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.884 (perp=8.470, rec=0.187, cos=0.002), tot_loss_proj:3.170 [t=0.19s]
prediction: ['[CLS] ill t. our of the and the romance. joyis resident paving existing path． of " our romantic of the calm. love that understands our...楊 and grandness we the joy daily of out how. the [SEP]']
[1050/2000] tot_loss=1.885 (perp=8.540, rec=0.175, cos=0.002), tot_loss_proj:3.134 [t=0.19s]
prediction: ['[CLS] ill t. our of the and the romance. joyis native paving existing path． of " how romantic of the calm. love that understands our...楊 and grandness we the joy daily of out how. the [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.836 (perp=8.263, rec=0.181, cos=0.002), tot_loss_proj:2.918 [t=0.19s]
prediction: ['[CLS] ill t. ouris the and the romance. joy of native paving existing path gillespie of " how romantic of the calm. love that understands our...楊 and grandness we the joy daily of s how. the [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.821 (perp=8.224, rec=0.174, cos=0.002), tot_loss_proj:2.886 [t=0.19s]
prediction: ['[CLS] ill t. ouris the and the romance. joy of native paving existing path gillespie of " into romantic of the calm. love that understands our...楊 and grandness we the joy daily of s. how the [SEP]']
[1200/2000] tot_loss=1.882 (perp=8.533, rec=0.173, cos=0.002), tot_loss_proj:2.969 [t=0.19s]
prediction: ['[CLS] ill t. ouris the and the romance. joy of native paving daily path gillespie of inhabit into romantic of the calm. love that understands our...楊 and grandness we the joy daily of out. how the [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.831 (perp=8.288, rec=0.171, cos=0.002), tot_loss_proj:2.892 [t=0.19s]
prediction: ['[CLS] ill t. ouris the and the romance. joy of native paving the path gillespie of inhabit into romantic of the calm. love that understands our...楊 and grandness we the joy daily of out. how existing [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.803 (perp=8.152, rec=0.170, cos=0.002), tot_loss_proj:2.840 [t=0.19s]
prediction: ['[CLS] ill t. ouris the and the romance. joy of native paving the path of " into romantic of the gillespie calm. love that understands our...楊 and grandness we the joy daily of s. how existing [SEP]']
[1350/2000] tot_loss=1.794 (perp=8.152, rec=0.162, cos=0.002), tot_loss_proj:2.833 [t=0.19s]
prediction: ['[CLS] ill t. ouris the and the romance. joy of native paving the path of " into romantic of the gillespie calm. love that understands our...楊 and grandness we the joy daily of s. how existing [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.775 (perp=8.003, rec=0.172, cos=0.002), tot_loss_proj:2.814 [t=0.19s]
prediction: ['[CLS] ill t. ouris the and the romance. joy of native paving the path of inhabits romantic of the existing calm. love that understands our...楊 and grandness we the joy daily of s. how gillespie [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.743 (perp=7.839, rec=0.173, cos=0.002), tot_loss_proj:2.550 [t=0.19s]
prediction: ['[CLS] ill t. ouris and the romance. the joy of native paving the path of inhabits romantic of the existing calm. love that understands our...楊 and grandness we the joy daily of out. how gillespie [SEP]']
[1500/2000] tot_loss=1.739 (perp=7.822, rec=0.173, cos=0.002), tot_loss_proj:2.498 [t=0.19s]
prediction: ['[CLS] ill t. ouris and the romance. the joy of native paving the path of inhabit into romantic of the existing calm. love that understands our...楊 and grandness we the joy daily of s. how gillespie [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.751 (perp=7.907, rec=0.167, cos=0.002), tot_loss_proj:2.511 [t=0.19s]
prediction: ['[CLS] ill t. ouris and the romance. the joy of native paving the path of the into romantic of the existing calm. love that understands our...楊 and grandness we inhabit joy daily of out. how gillespie [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.666 (perp=7.469, rec=0.170, cos=0.002), tot_loss_proj:2.498 [t=0.19s]
prediction: ['[CLS] ill t. ouris and the romance. the joy of native paving the path of thes romantic of the daily calm. love that understands ours楊 and grandness we inhabit joy daily out of. how gillespie [SEP]']
[1650/2000] tot_loss=1.665 (perp=7.469, rec=0.170, cos=0.002), tot_loss_proj:2.497 [t=0.19s]
prediction: ['[CLS] ill t. ouris and the romance. the joy of native paving the path of thes romantic of the daily calm. love that understands ours楊 and grandness we inhabit joy daily out of. how gillespie [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.649 (perp=7.388, rec=0.169, cos=0.002), tot_loss_proj:2.429 [t=0.19s]
prediction: ['[CLS] ill t. ouris and the romance. the joy of native paving the path of thes romantic of the daily calm. love that understands our...楊 and grandness we inhabit daily out of joy. how gillespie [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.611 (perp=7.237, rec=0.162, cos=0.002), tot_loss_proj:2.277 [t=0.19s]
prediction: ['[CLS] ill t. ouris and the romance. the joy of native paving the path of the romantics of the daily calm. love that understands our...楊 and grandness we inhabit daily s of joy. how gillespie [SEP]']
[1800/2000] tot_loss=1.609 (perp=7.237, rec=0.159, cos=0.002), tot_loss_proj:2.275 [t=0.19s]
prediction: ['[CLS] ill t. ouris and the romance. the joy of native paving the path of the romantics of the daily calm. love that understands our...楊 and grandness we inhabit daily s of joy. how gillespie [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.591 (perp=7.102, rec=0.168, cos=0.002), tot_loss_proj:2.283 [t=0.19s]
prediction: ['[CLS] ill t. ouris and the romance. the romantic of native paving the path of the joys of the daily calm. love that understands our...楊 and grandness we inhabit daily s of joy. how gillespie [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.584 (perp=7.066, rec=0.169, cos=0.002), tot_loss_proj:2.301 [t=0.19s]
prediction: ['[CLS] ill t. ouris and of the romance. the romantic native paving the path of the joys of the daily calm. love that understands our...楊 and grandness we inhabit daily s of joy. how gillespie [SEP]']
[1950/2000] tot_loss=1.579 (perp=7.066, rec=0.164, cos=0.002), tot_loss_proj:2.303 [t=0.19s]
prediction: ['[CLS] ill t. ouris and of the romance. the romantic native paving the path of the joys of the daily calm. love that understands our...楊 and grandness we inhabit daily s of joy. how gillespie [SEP]']
Attempt swap
[2000/2000] tot_loss=1.582 (perp=7.066, rec=0.166, cos=0.002), tot_loss_proj:2.303 [t=0.19s]
prediction: ['[CLS] ill t. ouris and of the romance. the romantic native paving the path of the joys of the daily calm. love that understands our...楊 and grandness we inhabit daily s of joy. how gillespie [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] ill t. ouris and the romance. the joy of native paving the path of thes romantic of the daily calm. love that understands our...楊 and grandness we inhabit joy daily out of. how gillespie [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 54.054 | p: 55.556 | r: 52.632
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 27.027 | p: 27.778 | r: 26.316
rougeLsum  | fm: 27.027 | p: 27.778 | r: 26.316
r1fm+r2fm = 54.054

[Aggregate metrics]:
rouge1     | fm: 89.871 | p: 89.531 | r: 90.267
rouge2     | fm: 53.192 | p: 53.060 | r: 53.382
rougeL     | fm: 77.113 | p: 76.826 | r: 77.458
rougeLsum  | fm: 77.057 | p: 76.784 | r: 77.392
r1fm+r2fm = 143.063

input #88 time: 0:07:32 | total time: 10:17:38


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.9993426143386362
highest_index [0]
highest [0.9993426143386362]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 1.9183775186538696 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 1.9162806272506714 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 1.8926299810409546 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 1.8359391689300537 for ['[CLS] an other⁄ given fire miniseries fit followed inhabitants opposite kilometres earliest varyact simplest areness shy law armand reissue ritchie does promoted deal al mathematics amazon brethren that indeed inter [SEP]']
[Init] best rec loss: 1.529639720916748 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 1.4763695001602173 for ['[CLS] jailtorium sighed keep farm feel gameoke primate hodge victimserre ink pain course artifact basis leader tower there fate being nu red thirdllis public minor martins lucas essence orient [SEP]']
[Init] best perm rec loss: 1.4759719371795654 for ['[CLS] there artifact farm courseerretorium primate thirdoke sighed lucas fate tower martins minor essence feel leaderllis keep ink being nu red victims orient public game pain hodge jail basis [SEP]']
[Init] best perm rec loss: 1.4655603170394897 for ['[CLS] red there hodge feel nu third farm ink fatelliserre basis being course primate tower artifact essence keep jail sighedoke game minor lucas victimstorium leader pain public orient martins [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.856 (perp=12.134, rec=0.401, cos=0.028), tot_loss_proj:4.279 [t=0.19s]
prediction: ['[CLS] design remotely letter jane health network i jane somewhat japanese vancouver cheney each spoke 2010 five sound feelclusive lacking wires. broughton clever broadway what - butter old taped anyway academic [SEP]']
[ 100/2000] tot_loss=2.638 (perp=11.563, rec=0.314, cos=0.011), tot_loss_proj:3.585 [t=0.19s]
prediction: ['[CLS] design remotely background covered center networks david jane or replaced [SEP] tacticchrome ; language ; system feel fighters none those " intuition clever it what - & office tactic anyway ki [SEP]']
[ 150/2000] tot_loss=2.483 (perp=10.876, rec=0.293, cos=0.014), tot_loss_proj:3.390 [t=0.19s]
prediction: ['[CLS] rapid commercial blanket roots up tactic david jane or to covering tactic pictures, - ( environment worse fighters none of 27 intuition worse it - - [SEP] old tactic anyway ki [SEP]']
[ 200/2000] tot_loss=2.377 (perp=10.629, rec=0.245, cos=0.006), tot_loss_proj:3.446 [t=0.19s]
prediction: ["[CLS] tactic commercial outfit james up sports zion prison or another cover tactic pictures, - ( environment feelcentric none things'boeing worse - - -. office tactic anyway joel [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.224 (perp=9.947, rec=0.230, cos=0.005), tot_loss_proj:3.492 [t=0.19s]
prediction: ["[CLS] tactic commercial fact james up sports ezra party or fact cover tactic picture. - life fact ideas none none things'sherry worse - - -, ( tactic anyway joel [SEP]"]
[ 300/2000] tot_loss=2.112 (perp=9.503, rec=0.207, cos=0.004), tot_loss_proj:3.146 [t=0.19s]
prediction: ['[CLS] tactic commercial fact story up sports phrase a or fact cover tactic picture - - society fact ideas none none things - yet worse - up -, or tactic anyway joel [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.151 (perp=9.794, rec=0.188, cos=0.005), tot_loss_proj:3.333 [t=0.19s]
prediction: ['[CLS] tactic commercial cover story - sports ^ the or fact cover tactic picture - - memorial fact ideas none none ideas - yet worse things up -, yet tactic anyway joel [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.995 (perp=9.098, rec=0.172, cos=0.004), tot_loss_proj:2.700 [t=0.19s]
prediction: ['[CLS] tactic commercial fact story - activities ^ the fact cover or tactic picture - - ( fact ideas none none ideas - yet worse things up - - yet tactic hurts joel [SEP]']
[ 450/2000] tot_loss=2.270 (perp=10.538, rec=0.158, cos=0.004), tot_loss_proj:3.016 [t=0.19s]
prediction: ['[CLS] tactic declan fact story - activities ^ the fact cover or tactic picture - - - fact around fl none ideas - yet worse things up -,sten tactic hurts joel [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.963 (perp=9.071, rec=0.146, cos=0.002), tot_loss_proj:3.152 [t=0.19s]
prediction: ['[CLS] tactic ideas fact picture - ideas ^ the fact cover or tactic picture - - - fact around fl none - - yet worse things up - -sten tactic helen joel [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.011 (perp=9.332, rec=0.142, cos=0.003), tot_loss_proj:3.272 [t=0.19s]
prediction: ['[CLS]athic ideas fact working - ideas ^ the fact cover or tactic picture is - - fact aroundsy none - up yet worse things - - -sten tactic helen " [SEP]']
[ 600/2000] tot_loss=1.988 (perp=9.214, rec=0.142, cos=0.002), tot_loss_proj:3.240 [t=0.19s]
prediction: ['[CLS] core ideas fact working - ideas ^ the fact cover or tactic picture is - - fact aroundsy none - up yet worse things - - -sten tactic helen " [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.002 (perp=9.342, rec=0.131, cos=0.002), tot_loss_proj:3.387 [t=0.19s]
prediction: ['[CLS] core ideas fact that up ideas ^ the to cover or tactic picture is - ( fact aroundsy none - - yet worse - - - -sten tactic helen " [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.749 (perp=8.112, rec=0.125, cos=0.002), tot_loss_proj:3.070 [t=0.19s]
prediction: ['[CLS] core ideas fact that up to ^ the ideas cover or tactic picture is - - fact aroundsy none - - yet worse - - - -sten to helen " [SEP]']
[ 750/2000] tot_loss=1.824 (perp=8.496, rec=0.123, cos=0.002), tot_loss_proj:3.163 [t=0.19s]
prediction: ['[CLS] core ideas fl that up to ^ the ideas cover or tactic picture is - - fact aroundsy none - - yet worse - - - -sten to helen " [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.714 (perp=7.928, rec=0.127, cos=0.002), tot_loss_proj:3.117 [t=0.19s]
prediction: ['[CLS] core ideas fact and up the ^ the ideas cover or tactic picture is - - fl aroundsy none - - yet worse - - - -sten to helen " [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.652 (perp=7.618, rec=0.127, cos=0.002), tot_loss_proj:2.995 [t=0.19s]
prediction: ['[CLS] and ideas fact core up the up the ideas cover or tactic picture is - - fl aroundsy none - - yet worse - - - -sten to helen " [SEP]']
[ 900/2000] tot_loss=1.641 (perp=7.618, rec=0.115, cos=0.001), tot_loss_proj:2.995 [t=0.19s]
prediction: ['[CLS] and ideas fact core up the up the ideas cover or tactic picture is - - fl aroundsy none - - yet worse - - - -sten to helen " [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.624 (perp=7.513, rec=0.120, cos=0.002), tot_loss_proj:2.409 [t=0.19s]
prediction: ['[CLS] the ideas fact core up the up the ideas cover or tactic picture is - - fl aroundsy - - - yet worse - - - nonesten to helen " [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.575 (perp=7.256, rec=0.122, cos=0.002), tot_loss_proj:2.411 [t=0.19s]
prediction: ['[CLS] fl ideas fact core up the up the ideas cover or tactic picture is - - the aroundsy - - - yet worse - - - nonesten to paul " [SEP]']
[1050/2000] tot_loss=1.576 (perp=7.256, rec=0.124, cos=0.002), tot_loss_proj:2.414 [t=0.19s]
prediction: ['[CLS] fl ideas fact core up the up the ideas cover or tactic picture is - - the aroundsy - - - yet worse - - - nonesten to paul " [SEP]']
Attempt swap
[1100/2000] tot_loss=1.615 (perp=7.475, rec=0.118, cos=0.002), tot_loss_proj:2.466 [t=0.19s]
prediction: ['[CLS] fl ideas fact core up the up the ideas cover or tactic picture is of - the aroundsy - - - yet worse - - - nonesten to paul " [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.597 (perp=7.392, rec=0.117, cos=0.002), tot_loss_proj:2.508 [t=0.19s]
prediction: ['[CLS] fl fact ideas core up the up the ideas cover or tactic picture is of - the aroundsy - - - yet worse - - - nonesten to paul " [SEP]']
[1200/2000] tot_loss=1.593 (perp=7.392, rec=0.113, cos=0.002), tot_loss_proj:2.508 [t=0.19s]
prediction: ['[CLS] fl fact ideas core up the up the ideas cover or tactic picture is of - the aroundsy - - - yet worse - - - nonesten to paul " [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.578 (perp=7.290, rec=0.118, cos=0.002), tot_loss_proj:2.516 [t=0.19s]
prediction: ['[CLS] fl fact ideas core up the up the ideas cover or tactic picture is - - the aroundsy of - - yet worse - - - nonesten to paul " [SEP]']
Attempt swap
[1300/2000] tot_loss=1.729 (perp=8.049, rec=0.118, cos=0.002), tot_loss_proj:2.677 [t=0.19s]
prediction: ['[CLS] fl fact ideas core up the up the ideas cover or tactic picture constructed - - the aroundsy of - - yet worsesten - - nonesten to paul " [SEP]']
[1350/2000] tot_loss=1.699 (perp=7.934, rec=0.110, cos=0.002), tot_loss_proj:2.713 [t=0.19s]
prediction: ['[CLS] fl fact ideas core up the up the ideas cover or tactic picture constructed - - the aroundsy of - - yet worset - - nonesten to paul " [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.686 (perp=7.870, rec=0.110, cos=0.002), tot_loss_proj:2.680 [t=0.19s]
prediction: ['[CLS] fl fact ideas core up the up the ideas cover or tactic picture constructed - - the aroundsy of - - yett worse - - nonesten to paul " [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.634 (perp=7.586, rec=0.115, cos=0.002), tot_loss_proj:2.658 [t=0.19s]
prediction: ['[CLS] fl fact ideas up the core up the ideas cover or tactic picture constructed - - the aroundsy of - - yett worse - - nonesten to paul " [SEP]']
[1500/2000] tot_loss=1.634 (perp=7.586, rec=0.115, cos=0.002), tot_loss_proj:2.655 [t=0.19s]
prediction: ['[CLS] fl fact ideas up the core up the ideas cover or tactic picture constructed - - the aroundsy of - - yett worse - - nonesten to paul " [SEP]']
Attempt swap
[1550/2000] tot_loss=1.630 (perp=7.586, rec=0.111, cos=0.002), tot_loss_proj:2.657 [t=0.19s]
prediction: ['[CLS] fl fact ideas up the core up the ideas cover or tactic picture constructed - - the aroundsy of - - yett worse - - nonesten to paul " [SEP]']
Attempt swap
[1600/2000] tot_loss=1.693 (perp=7.883, rec=0.115, cos=0.002), tot_loss_proj:2.655 [t=0.19s]
prediction: ['[CLS] fl fact ideas up the core up the ideas cover or tactic picture constructed - - the aroundsy of - - yetsten worse - - nonesten to paul " [SEP]']
[1650/2000] tot_loss=1.627 (perp=7.586, rec=0.108, cos=0.002), tot_loss_proj:2.656 [t=0.19s]
prediction: ['[CLS] fl fact ideas up the core up the ideas cover or tactic picture constructed - - the aroundsy of - - yett worse - - nonesten to paul " [SEP]']
Attempt swap
[1700/2000] tot_loss=1.624 (perp=7.586, rec=0.105, cos=0.002), tot_loss_proj:2.656 [t=0.19s]
prediction: ['[CLS] fl fact ideas up the core up the ideas cover or tactic picture constructed - - the aroundsy of - - yett worse - - nonesten to paul " [SEP]']
Attempt swap
[1750/2000] tot_loss=1.633 (perp=7.586, rec=0.114, cos=0.002), tot_loss_proj:2.655 [t=0.19s]
prediction: ['[CLS] fl fact ideas up the core up the ideas cover or tactic picture constructed - - the aroundsy of - - yett worse - - nonesten to paul " [SEP]']
[1800/2000] tot_loss=1.624 (perp=7.586, rec=0.105, cos=0.002), tot_loss_proj:2.657 [t=0.19s]
prediction: ['[CLS] fl fact ideas up the core up the ideas cover or tactic picture constructed - - the aroundsy of - - yett worse - - nonesten to paul " [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.598 (perp=7.410, rec=0.114, cos=0.002), tot_loss_proj:2.740 [t=0.19s]
prediction: ['[CLS] fl fact - up the core up the ideas cover or tactic picture constructed - - the aroundsy of ideas - yett worse - - nonesten to paul " [SEP]']
Attempt swap
[1900/2000] tot_loss=1.585 (perp=7.410, rec=0.101, cos=0.002), tot_loss_proj:2.741 [t=0.19s]
prediction: ['[CLS] fl fact - up the core up the ideas cover or tactic picture constructed - - the aroundsy of ideas - yett worse - - nonesten to paul " [SEP]']
[1950/2000] tot_loss=1.591 (perp=7.410, rec=0.107, cos=0.002), tot_loss_proj:2.735 [t=0.19s]
prediction: ['[CLS] fl fact - up the core up the ideas cover or tactic picture constructed - - the aroundsy of ideas - yett worse - - nonesten to paul " [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.585 (perp=7.357, rec=0.112, cos=0.002), tot_loss_proj:2.758 [t=0.19s]
prediction: ['[CLS] fl fact - up the core up the ideas cover or tactic picture constructed - - the aroundsy of ideas - yett worse - - paulsten to none " [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] fl fact ideas up the core up the ideas cover or tactic picture constructed - - the aroundsy of - - yett worse - - nonesten to paul " [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.085 | p: 66.667 | r: 69.565
rouge2     | fm: 4.444 | p: 4.348 | r: 4.545
rougeL     | fm: 38.298 | p: 37.500 | r: 39.130
rougeLsum  | fm: 38.298 | p: 37.500 | r: 39.130
r1fm+r2fm = 72.530

[Aggregate metrics]:
rouge1     | fm: 89.678 | p: 89.255 | r: 90.097
rouge2     | fm: 52.852 | p: 52.716 | r: 53.029
rougeL     | fm: 76.642 | p: 76.401 | r: 76.963
rougeLsum  | fm: 76.602 | p: 76.318 | r: 76.925
r1fm+r2fm = 142.530

input #89 time: 0:07:31 | total time: 10:25:10


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9993650968600143
highest_index [0]
highest [0.9993650968600143]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 1.889743447303772 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 1.827311396598816 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 1.7925564050674438 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 1.566908359527588 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 1.5568602085113525 for ['[CLS] track direct unconscious unable eyes release [SEP]']
[Init] best rec loss: 1.453827977180481 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 1.4401582479476929 for ['[CLS] hectares sessions tiny skin litter positions [SEP]']
[Init] best rec loss: 1.3662965297698975 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 1.3659476041793823 for ['[CLS] released male cannot spirited entourage when [SEP]']
[Init] best perm rec loss: 1.3621010780334473 for ['[CLS] cannot released spirited male when entourage [SEP]']
[Init] best perm rec loss: 1.3619078397750854 for ['[CLS] cannot male released spirited entourage when [SEP]']
[Init] best perm rec loss: 1.3608994483947754 for ['[CLS] cannot released male spirited entourage when [SEP]']
[Init] best perm rec loss: 1.3607511520385742 for ['[CLS] cannot released entourage male spirited when [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.633 (perp=11.313, rec=0.332, cos=0.038), tot_loss_proj:2.976 [t=0.19s]
prediction: ['[CLS] ridiculous ridiculous how internal attacks money [SEP]']
[ 100/2000] tot_loss=1.893 (perp=8.622, rec=0.162, cos=0.006), tot_loss_proj:2.154 [t=0.19s]
prediction: ['[CLS] how ridiculous how money oriented money [SEP]']
[ 150/2000] tot_loss=1.859 (perp=8.622, rec=0.131, cos=0.004), tot_loss_proj:2.149 [t=0.19s]
prediction: ['[CLS] how ridiculous how money oriented money [SEP]']
[ 200/2000] tot_loss=1.836 (perp=8.622, rec=0.108, cos=0.003), tot_loss_proj:2.151 [t=0.19s]
prediction: ['[CLS] how ridiculous how money oriented money [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.540 (perp=7.251, rec=0.088, cos=0.002), tot_loss_proj:1.776 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented money [SEP]']
[ 300/2000] tot_loss=1.763 (perp=8.466, rec=0.069, cos=0.002), tot_loss_proj:2.095 [t=0.19s]
prediction: ['[CLS] how ridiculous and - oriented money [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.460 (perp=6.870, rec=0.084, cos=0.002), tot_loss_proj:1.697 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.448 (perp=6.870, rec=0.073, cos=0.001), tot_loss_proj:1.705 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.441 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.710 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.432 (perp=6.870, rec=0.057, cos=0.001), tot_loss_proj:1.705 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.719 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.713 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.718 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.711 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.708 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.440 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.722 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.437 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.717 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.707 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.699 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.443 (perp=6.870, rec=0.067, cos=0.001), tot_loss_proj:1.704 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.427 (perp=6.870, rec=0.051, cos=0.001), tot_loss_proj:1.711 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.717 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.444 (perp=6.870, rec=0.069, cos=0.001), tot_loss_proj:1.713 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.441 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.713 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.445 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.714 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.447 (perp=6.870, rec=0.071, cos=0.001), tot_loss_proj:1.713 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.428 (perp=6.870, rec=0.053, cos=0.001), tot_loss_proj:1.724 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.434 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.707 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.713 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.443 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.709 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.710 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.711 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.709 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.445 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.718 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.439 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.715 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.441 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.717 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.711 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.443 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.717 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.721 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.709 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.719 | p: 89.380 | r: 90.178
rouge2     | fm: 53.304 | p: 53.130 | r: 53.438
rougeL     | fm: 76.934 | p: 76.634 | r: 77.277
rougeLsum  | fm: 76.874 | p: 76.572 | r: 77.265
r1fm+r2fm = 143.023

input #90 time: 0:07:26 | total time: 10:32:36


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9993538374859834
highest_index [0]
highest [0.9993538374859834]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 1.8815274238586426 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 1.5670865774154663 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 1.5520261526107788 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 1.24383544921875 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 1.160547137260437 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 1.1217325925827026 for ['[CLS] apollo lucia umpire skip gentleman grandmothergna line [SEP]']
[Init] best rec loss: 1.0907552242279053 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 1.0540754795074463 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 1.0526354312896729 for ['[CLS] unknown shelterpmentlipdern hard revolution pony [SEP]']
[Init] best perm rec loss: 1.0524038076400757 for ['[CLS]pmentlip pony revolution unknown harddern shelter [SEP]']
[Init] best perm rec loss: 1.05027437210083 for ['[CLS]lip revolution hard ponydern unknownpment shelter [SEP]']
[Init] best perm rec loss: 1.0482343435287476 for ['[CLS]lip unknownpment revolution shelterdern hard pony [SEP]']
[Init] best perm rec loss: 1.0455262660980225 for ['[CLS]lip revolutionpment unknown harddern shelter pony [SEP]']
[Init] best perm rec loss: 1.0435428619384766 for ['[CLS] shelterdern revolution hardlippment unknown pony [SEP]']
[Init] best perm rec loss: 1.0432696342468262 for ['[CLS] harddernlippment shelter revolution unknown pony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.618 (perp=11.347, rec=0.323, cos=0.026), tot_loss_proj:3.023 [t=0.19s]
prediction: ['[CLS] but threat ahead.gingly ridiculous loco loco [SEP]']
[ 100/2000] tot_loss=2.191 (perp=9.714, rec=0.236, cos=0.013), tot_loss_proj:2.887 [t=0.19s]
prediction: ['[CLS] but loco worse but more ridiculous loco loco [SEP]']
[ 150/2000] tot_loss=1.837 (perp=8.270, rec=0.177, cos=0.006), tot_loss_proj:2.368 [t=0.19s]
prediction: ['[CLS] no loco more but no ridiculous loco more [SEP]']
[ 200/2000] tot_loss=1.943 (perp=9.125, rec=0.114, cos=0.004), tot_loss_proj:2.506 [t=0.19s]
prediction: ['[CLS], loco more but no ridiculous loco more [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.839 (perp=8.564, rec=0.116, cos=0.010), tot_loss_proj:2.433 [t=0.19s]
prediction: ['[CLS], mu ridiculous more but no loco more [SEP]']
[ 300/2000] tot_loss=1.820 (perp=8.564, rec=0.104, cos=0.003), tot_loss_proj:2.447 [t=0.19s]
prediction: ['[CLS], mu ridiculous more but no loco more [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.816 (perp=8.564, rec=0.100, cos=0.003), tot_loss_proj:2.436 [t=0.19s]
prediction: ['[CLS], mu ridiculous more but no loco more [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.662 (perp=7.685, rec=0.118, cos=0.007), tot_loss_proj:2.292 [t=0.19s]
prediction: ['[CLS] mu ridiculous more, but no loco more [SEP]']
[ 450/2000] tot_loss=1.637 (perp=7.685, rec=0.097, cos=0.003), tot_loss_proj:2.292 [t=0.19s]
prediction: ['[CLS] mu ridiculous more, but no loco more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.631 (perp=7.685, rec=0.091, cos=0.003), tot_loss_proj:2.291 [t=0.19s]
prediction: ['[CLS] mu ridiculous more, but no loco more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.820 (perp=8.671, rec=0.083, cos=0.002), tot_loss_proj:2.435 [t=0.19s]
prediction: ['[CLS]y ridiculous more, but no loco more [SEP]']
[ 600/2000] tot_loss=1.814 (perp=8.671, rec=0.077, cos=0.002), tot_loss_proj:2.437 [t=0.19s]
prediction: ['[CLS]y ridiculous more, but no loco more [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.741 (perp=8.264, rec=0.085, cos=0.002), tot_loss_proj:2.359 [t=0.19s]
prediction: ['[CLS]y more ridiculous, but no loco more [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.711 (perp=8.052, rec=0.098, cos=0.003), tot_loss_proj:2.321 [t=0.19s]
prediction: ['[CLS] morey ridiculous, but no loco more [SEP]']
[ 750/2000] tot_loss=1.692 (perp=8.052, rec=0.080, cos=0.002), tot_loss_proj:2.319 [t=0.19s]
prediction: ['[CLS] morey ridiculous, but no loco more [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.442 (perp=6.704, rec=0.098, cos=0.003), tot_loss_proj:2.028 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.432 (perp=6.704, rec=0.089, cos=0.003), tot_loss_proj:2.029 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
[ 900/2000] tot_loss=1.423 (perp=6.704, rec=0.080, cos=0.003), tot_loss_proj:2.029 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.424 (perp=6.704, rec=0.081, cos=0.003), tot_loss_proj:2.019 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.431 (perp=6.704, rec=0.088, cos=0.003), tot_loss_proj:2.024 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
[1050/2000] tot_loss=1.426 (perp=6.704, rec=0.083, cos=0.003), tot_loss_proj:2.019 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.433 (perp=6.704, rec=0.090, cos=0.003), tot_loss_proj:2.016 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.432 (perp=6.704, rec=0.089, cos=0.002), tot_loss_proj:2.015 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
[1200/2000] tot_loss=1.428 (perp=6.704, rec=0.085, cos=0.002), tot_loss_proj:2.015 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.422 (perp=6.704, rec=0.079, cos=0.002), tot_loss_proj:2.008 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.427 (perp=6.704, rec=0.084, cos=0.002), tot_loss_proj:2.003 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
[1350/2000] tot_loss=1.421 (perp=6.704, rec=0.078, cos=0.002), tot_loss_proj:2.011 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.417 (perp=6.704, rec=0.074, cos=0.002), tot_loss_proj:2.009 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.428 (perp=6.704, rec=0.085, cos=0.002), tot_loss_proj:2.006 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
[1500/2000] tot_loss=1.425 (perp=6.704, rec=0.082, cos=0.002), tot_loss_proj:2.001 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.425 (perp=6.704, rec=0.082, cos=0.002), tot_loss_proj:1.999 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.421 (perp=6.704, rec=0.078, cos=0.002), tot_loss_proj:2.000 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
[1650/2000] tot_loss=1.429 (perp=6.704, rec=0.085, cos=0.002), tot_loss_proj:2.007 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.428 (perp=6.704, rec=0.085, cos=0.002), tot_loss_proj:2.011 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.424 (perp=6.704, rec=0.081, cos=0.002), tot_loss_proj:2.001 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
[1800/2000] tot_loss=1.441 (perp=6.704, rec=0.098, cos=0.002), tot_loss_proj:1.995 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.418 (perp=6.704, rec=0.074, cos=0.002), tot_loss_proj:2.007 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.423 (perp=6.704, rec=0.079, cos=0.002), tot_loss_proj:2.007 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
[1950/2000] tot_loss=1.427 (perp=6.704, rec=0.084, cos=0.002), tot_loss_proj:1.997 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.423 (perp=6.704, rec=0.079, cos=0.002), tot_loss_proj:2.005 [t=0.19s]
prediction: ['[CLS] morey, but no loco more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] morey, but no loco more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 42.857 | p: 42.857 | r: 42.857
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 130.357

[Aggregate metrics]:
rouge1     | fm: 89.668 | p: 89.272 | r: 90.118
rouge2     | fm: 53.461 | p: 53.340 | r: 53.620
rougeL     | fm: 76.968 | p: 76.688 | r: 77.286
rougeLsum  | fm: 76.850 | p: 76.576 | r: 77.184
r1fm+r2fm = 143.129

input #91 time: 0:07:26 | total time: 10:40:03


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9993137310302476
highest_index [0]
highest [0.9993137310302476]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 1.81099534034729 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 1.76921546459198 for ['[CLS] franz counter [SEP]']
[Init] best rec loss: 1.7248120307922363 for ['[CLS] false issue [SEP]']
[Init] best rec loss: 1.6912018060684204 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 1.4354274272918701 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 1.4101020097732544 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 1.2274341583251953 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 1.2247881889343262 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.624 (perp=12.265, rec=0.166, cos=0.005), tot_loss_proj:3.210 [t=0.18s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=1.615 (perp=7.646, rec=0.084, cos=0.002), tot_loss_proj:1.584 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.589 (perp=7.646, rec=0.059, cos=0.001), tot_loss_proj:1.586 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.598 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.607 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.591 (perp=7.646, rec=0.061, cos=0.001), tot_loss_proj:1.597 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.585 (perp=7.646, rec=0.055, cos=0.001), tot_loss_proj:1.592 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.606 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.597 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.596 (perp=7.646, rec=0.066, cos=0.001), tot_loss_proj:1.587 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.603 (perp=7.646, rec=0.073, cos=0.001), tot_loss_proj:1.592 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.590 (perp=7.646, rec=0.059, cos=0.001), tot_loss_proj:1.594 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.587 (perp=7.646, rec=0.056, cos=0.001), tot_loss_proj:1.599 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.593 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.584 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.600 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.581 (perp=7.646, rec=0.050, cos=0.001), tot_loss_proj:1.597 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.597 (perp=7.646, rec=0.066, cos=0.001), tot_loss_proj:1.580 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.590 (perp=7.646, rec=0.059, cos=0.001), tot_loss_proj:1.593 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.593 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.605 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.583 (perp=7.646, rec=0.052, cos=0.001), tot_loss_proj:1.601 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.603 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.596 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.584 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.575 (perp=7.646, rec=0.045, cos=0.001), tot_loss_proj:1.605 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.600 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.596 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.603 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.586 (perp=7.646, rec=0.055, cos=0.001), tot_loss_proj:1.598 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.584 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.646, rec=0.056, cos=0.001), tot_loss_proj:1.603 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.589 (perp=7.646, rec=0.059, cos=0.001), tot_loss_proj:1.588 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.596 (perp=7.646, rec=0.066, cos=0.001), tot_loss_proj:1.600 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.600 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.594 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.587 (perp=7.646, rec=0.056, cos=0.001), tot_loss_proj:1.595 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.595 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.598 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.580 (perp=7.646, rec=0.050, cos=0.001), tot_loss_proj:1.585 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.604 (perp=7.646, rec=0.074, cos=0.001), tot_loss_proj:1.580 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.591 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.591 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.579 (perp=7.646, rec=0.049, cos=0.001), tot_loss_proj:1.602 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.587 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.594 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.581 (perp=7.646, rec=0.050, cos=0.001), tot_loss_proj:1.602 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.588 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.594 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.591 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.587 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.874 | p: 89.483 | r: 90.267
rouge2     | fm: 53.835 | p: 53.688 | r: 53.963
rougeL     | fm: 77.183 | p: 76.880 | r: 77.469
rougeLsum  | fm: 77.123 | p: 76.882 | r: 77.474
r1fm+r2fm = 143.710

input #92 time: 0:07:18 | total time: 10:47:22


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9993323263895038
highest_index [0]
highest [0.9993323263895038]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.9964412450790405 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 1.804612159729004 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 1.764283537864685 for ['[CLS] will individual unitsbular absent lights distribution [SEP]']
[Init] best rec loss: 1.7488878965377808 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 1.7436745166778564 for ['[CLS] lucas war breaks baby my pauline divided [SEP]']
[Init] best rec loss: 1.738550066947937 for ['[CLS] village tallest almost giro opened wine section [SEP]']
[Init] best rec loss: 1.5410614013671875 for ['[CLS] [CLS]rac madonna premiership further jeremy colby [SEP]']
[Init] best perm rec loss: 1.5395601987838745 for ['[CLS]rac jeremy madonna further premiership [CLS] colby [SEP]']
[Init] best perm rec loss: 1.536518931388855 for ['[CLS] madonna premiership jeremy further colby [CLS]rac [SEP]']
[Init] best perm rec loss: 1.5341161489486694 for ['[CLS] madonna premiership colbyrac [CLS] further jeremy [SEP]']
[Init] best perm rec loss: 1.5311251878738403 for ['[CLS] further madonna jeremy [CLS] colby premiershiprac [SEP]']
[Init] best perm rec loss: 1.5273934602737427 for ['[CLS] colby madonna premiership further jeremyrac [CLS] [SEP]']
[Init] best perm rec loss: 1.525164246559143 for ['[CLS] further madonnarac colby jeremy premiership [CLS] [SEP]']
[Init] best perm rec loss: 1.5250414609909058 for ['[CLS] premiership jeremy madonnarac colby further [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.771 (perp=12.601, rec=0.245, cos=0.006), tot_loss_proj:3.183 [t=0.18s]
prediction: ['[CLS] bridge nature barry funny its understanding funny [SEP]']
[ 100/2000] tot_loss=2.363 (perp=10.906, rec=0.179, cos=0.004), tot_loss_proj:3.457 [t=0.19s]
prediction: ['[CLS] understanding in twice funny its understanding way [SEP]']
[ 150/2000] tot_loss=2.126 (perp=9.833, rec=0.157, cos=0.003), tot_loss_proj:2.550 [t=0.19s]
prediction: ['[CLS] understanding its often funny its understanding way [SEP]']
[ 200/2000] tot_loss=1.976 (perp=9.381, rec=0.098, cos=0.002), tot_loss_proj:2.268 [t=0.19s]
prediction: ['[CLS] understanding its often funny in understanding way [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.498 (perp=7.091, rec=0.078, cos=0.001), tot_loss_proj:1.624 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[ 300/2000] tot_loss=1.486 (perp=7.091, rec=0.066, cos=0.001), tot_loss_proj:1.624 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.496 (perp=7.091, rec=0.076, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.482 (perp=7.091, rec=0.062, cos=0.001), tot_loss_proj:1.628 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[ 450/2000] tot_loss=1.487 (perp=7.091, rec=0.068, cos=0.001), tot_loss_proj:1.616 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.488 (perp=7.091, rec=0.068, cos=0.001), tot_loss_proj:1.620 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.482 (perp=7.091, rec=0.062, cos=0.001), tot_loss_proj:1.619 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[ 600/2000] tot_loss=1.483 (perp=7.091, rec=0.064, cos=0.001), tot_loss_proj:1.618 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.483 (perp=7.091, rec=0.063, cos=0.001), tot_loss_proj:1.619 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.484 (perp=7.091, rec=0.064, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[ 750/2000] tot_loss=1.482 (perp=7.091, rec=0.063, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.481 (perp=7.091, rec=0.061, cos=0.001), tot_loss_proj:1.618 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.482 (perp=7.091, rec=0.062, cos=0.001), tot_loss_proj:1.629 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[ 900/2000] tot_loss=1.478 (perp=7.091, rec=0.059, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.483 (perp=7.091, rec=0.064, cos=0.001), tot_loss_proj:1.625 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1000/2000] tot_loss=1.483 (perp=7.091, rec=0.064, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1050/2000] tot_loss=1.485 (perp=7.091, rec=0.065, cos=0.001), tot_loss_proj:1.626 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1100/2000] tot_loss=1.478 (perp=7.091, rec=0.058, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1150/2000] tot_loss=1.475 (perp=7.091, rec=0.056, cos=0.001), tot_loss_proj:1.619 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1200/2000] tot_loss=1.475 (perp=7.091, rec=0.056, cos=0.001), tot_loss_proj:1.622 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1250/2000] tot_loss=1.478 (perp=7.091, rec=0.058, cos=0.001), tot_loss_proj:1.621 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1300/2000] tot_loss=1.490 (perp=7.091, rec=0.071, cos=0.001), tot_loss_proj:1.622 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1350/2000] tot_loss=1.488 (perp=7.091, rec=0.069, cos=0.001), tot_loss_proj:1.622 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1400/2000] tot_loss=1.477 (perp=7.091, rec=0.057, cos=0.001), tot_loss_proj:1.619 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1450/2000] tot_loss=1.477 (perp=7.091, rec=0.057, cos=0.001), tot_loss_proj:1.625 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1500/2000] tot_loss=1.480 (perp=7.091, rec=0.060, cos=0.001), tot_loss_proj:1.621 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1550/2000] tot_loss=1.483 (perp=7.091, rec=0.064, cos=0.001), tot_loss_proj:1.619 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1600/2000] tot_loss=1.485 (perp=7.091, rec=0.065, cos=0.001), tot_loss_proj:1.624 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1650/2000] tot_loss=1.481 (perp=7.091, rec=0.061, cos=0.001), tot_loss_proj:1.622 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1700/2000] tot_loss=1.490 (perp=7.091, rec=0.070, cos=0.001), tot_loss_proj:1.631 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1750/2000] tot_loss=1.479 (perp=7.091, rec=0.060, cos=0.001), tot_loss_proj:1.629 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1800/2000] tot_loss=1.480 (perp=7.091, rec=0.060, cos=0.001), tot_loss_proj:1.622 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1850/2000] tot_loss=1.481 (perp=7.091, rec=0.061, cos=0.001), tot_loss_proj:1.620 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[1900/2000] tot_loss=1.483 (perp=7.091, rec=0.064, cos=0.001), tot_loss_proj:1.618 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
[1950/2000] tot_loss=1.483 (perp=7.091, rec=0.063, cos=0.001), tot_loss_proj:1.624 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Attempt swap
[2000/2000] tot_loss=1.485 (perp=7.091, rec=0.065, cos=0.001), tot_loss_proj:1.627 [t=0.19s]
prediction: ['[CLS] in its often funny, understanding way [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] in its often funny, understanding way [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 89.902 | p: 89.504 | r: 90.341
rouge2     | fm: 53.887 | p: 53.754 | r: 54.046
rougeL     | fm: 77.334 | p: 77.024 | r: 77.635
rougeLsum  | fm: 77.288 | p: 76.993 | r: 77.592
r1fm+r2fm = 143.789

input #93 time: 0:07:22 | total time: 10:54:45


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9993168061064917
highest_index [0]
highest [0.9993168061064917]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 1.9509918689727783 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 1.9232128858566284 for ['[CLS] milling library casual constructed board equationphs similaron cookies intended [SEP]']
[Init] best rec loss: 1.8279337882995605 for ['[CLS] scent crosses am history single connections set likeuatingface other [SEP]']
[Init] best rec loss: 1.823370099067688 for ['[CLS]ser straight alligator inches subject never splashed pony des withancy [SEP]']
[Init] best rec loss: 1.5088582038879395 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 1.4581665992736816 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 1.445499062538147 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 1.4265179634094238 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 1.4207502603530884 for ['[CLS] internal plum flowering expedition territorial shocks chronic centre crushed rockwellventing [SEP]']
[Init] best perm rec loss: 1.4164097309112549 for ['[CLS] centreventing flowering expedition shocks chronic crushed internal rockwell territorial plum [SEP]']
[Init] best perm rec loss: 1.4148106575012207 for ['[CLS] chronicventing territorial expedition shocks crushed centre internal rockwell flowering plum [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.520 (perp=10.896, rec=0.330, cos=0.010), tot_loss_proj:3.532 [t=0.18s]
prediction: ['[CLS] nor claims neither reported funny all course nor neither terribly neither [SEP]']
[ 100/2000] tot_loss=2.339 (perp=10.649, rec=0.203, cos=0.006), tot_loss_proj:2.887 [t=0.19s]
prediction: ['[CLS] nor which neither neither funny a cape any neither funny neither [SEP]']
[ 150/2000] tot_loss=2.050 (perp=9.514, rec=0.145, cos=0.002), tot_loss_proj:3.617 [t=0.19s]
prediction: ['[CLS] terriblyr cape s funny a cape that neither funny nor [SEP]']
[ 200/2000] tot_loss=2.002 (perp=9.551, rec=0.090, cos=0.002), tot_loss_proj:3.745 [t=0.19s]
prediction: ['[CLS] terriblyr cape s funny a cape that neither original nor [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.387 (perp=6.487, rec=0.088, cos=0.002), tot_loss_proj:3.298 [t=0.19s]
prediction: ["[CLS] terribly funny a caper's that neither original nor [SEP]"]
[ 300/2000] tot_loss=1.384 (perp=6.487, rec=0.085, cos=0.001), tot_loss_proj:3.298 [t=0.19s]
prediction: ["[CLS] terribly funny a caper's that neither original nor [SEP]"]
Attempt swap
[ 350/2000] tot_loss=1.743 (perp=8.367, rec=0.068, cos=0.001), tot_loss_proj:3.677 [t=0.19s]
prediction: ['[CLS] terribly funny a caperr s that neither original nor [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.601 (perp=7.625, rec=0.074, cos=0.001), tot_loss_proj:3.522 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper s that neither original nor [SEP]']
[ 450/2000] tot_loss=1.598 (perp=7.625, rec=0.072, cos=0.001), tot_loss_proj:3.528 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper s that neither original nor [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.574 (perp=7.521, rec=0.069, cos=0.001), tot_loss_proj:3.456 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that s neither original nor [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.554 (perp=7.484, rec=0.056, cos=0.001), tot_loss_proj:3.454 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
[ 600/2000] tot_loss=1.564 (perp=7.484, rec=0.066, cos=0.001), tot_loss_proj:3.451 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.560 (perp=7.484, rec=0.062, cos=0.001), tot_loss_proj:3.446 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.567 (perp=7.484, rec=0.069, cos=0.001), tot_loss_proj:3.448 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
[ 750/2000] tot_loss=1.565 (perp=7.484, rec=0.067, cos=0.001), tot_loss_proj:3.451 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.571 (perp=7.484, rec=0.072, cos=0.001), tot_loss_proj:3.448 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.571 (perp=7.484, rec=0.073, cos=0.001), tot_loss_proj:3.446 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
[ 900/2000] tot_loss=1.559 (perp=7.484, rec=0.061, cos=0.001), tot_loss_proj:3.451 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.559 (perp=7.484, rec=0.061, cos=0.001), tot_loss_proj:3.445 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
Attempt swap
[1000/2000] tot_loss=1.555 (perp=7.484, rec=0.057, cos=0.001), tot_loss_proj:3.450 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
[1050/2000] tot_loss=1.566 (perp=7.484, rec=0.068, cos=0.001), tot_loss_proj:3.443 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
Attempt swap
[1100/2000] tot_loss=1.567 (perp=7.484, rec=0.069, cos=0.001), tot_loss_proj:3.442 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
Attempt swap
[1150/2000] tot_loss=1.563 (perp=7.484, rec=0.065, cos=0.001), tot_loss_proj:3.444 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
[1200/2000] tot_loss=1.570 (perp=7.484, rec=0.072, cos=0.001), tot_loss_proj:3.440 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
Attempt swap
[1250/2000] tot_loss=1.561 (perp=7.484, rec=0.062, cos=0.001), tot_loss_proj:3.449 [t=0.19s]
prediction: ['[CLS] terribly funnyr a caper that neither s original nor [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.488 (perp=7.075, rec=0.072, cos=0.001), tot_loss_proj:3.347 [t=0.19s]
prediction: ["[CLS] terribly funny a caper'that neither s original nor [SEP]"]
[1350/2000] tot_loss=1.486 (perp=7.075, rec=0.069, cos=0.001), tot_loss_proj:3.347 [t=0.19s]
prediction: ["[CLS] terribly funny a caper'that neither s original nor [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.373 (perp=6.522, rec=0.067, cos=0.001), tot_loss_proj:2.996 [t=0.19s]
prediction: ["[CLS] terribly funny a caper's neither that original nor [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.375 (perp=6.522, rec=0.069, cos=0.001), tot_loss_proj:3.004 [t=0.19s]
prediction: ["[CLS] terribly funny a caper's neither that original nor [SEP]"]
[1500/2000] tot_loss=1.376 (perp=6.522, rec=0.071, cos=0.001), tot_loss_proj:3.002 [t=0.19s]
prediction: ["[CLS] terribly funny a caper's neither that original nor [SEP]"]
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.260 (perp=5.899, rec=0.079, cos=0.001), tot_loss_proj:3.219 [t=0.19s]
prediction: ["[CLS] terribly funny a caper that's neither original nor [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.252 (perp=5.899, rec=0.071, cos=0.001), tot_loss_proj:3.220 [t=0.19s]
prediction: ["[CLS] terribly funny a caper that's neither original nor [SEP]"]
[1650/2000] tot_loss=1.252 (perp=5.899, rec=0.071, cos=0.001), tot_loss_proj:3.224 [t=0.19s]
prediction: ["[CLS] terribly funny a caper that's neither original nor [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.246 (perp=5.899, rec=0.064, cos=0.001), tot_loss_proj:3.223 [t=0.19s]
prediction: ["[CLS] terribly funny a caper that's neither original nor [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.257 (perp=5.899, rec=0.076, cos=0.001), tot_loss_proj:3.218 [t=0.19s]
prediction: ["[CLS] terribly funny a caper that's neither original nor [SEP]"]
[1800/2000] tot_loss=1.246 (perp=5.899, rec=0.065, cos=0.001), tot_loss_proj:3.219 [t=0.19s]
prediction: ["[CLS] terribly funny a caper that's neither original nor [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.247 (perp=5.899, rec=0.066, cos=0.001), tot_loss_proj:3.216 [t=0.19s]
prediction: ["[CLS] terribly funny a caper that's neither original nor [SEP]"]
Attempt swap
Moved token
[1900/2000] tot_loss=1.220 (perp=5.754, rec=0.068, cos=0.001), tot_loss_proj:3.186 [t=0.19s]
prediction: ["[CLS] a terribly funny caper that's neither original nor [SEP]"]
[1950/2000] tot_loss=1.215 (perp=5.754, rec=0.063, cos=0.001), tot_loss_proj:3.182 [t=0.19s]
prediction: ["[CLS] a terribly funny caper that's neither original nor [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.170 (perp=5.453, rec=0.078, cos=0.001), tot_loss_proj:3.081 [t=0.19s]
prediction: ["[CLS] a funny caper that's neither terribly original nor [SEP]"]
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] terribly funnyr a caper that neither s original nor [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 30.000 | p: 30.000 | r: 30.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 120.909

[Aggregate metrics]:
rouge1     | fm: 89.950 | p: 89.593 | r: 90.387
rouge2     | fm: 53.669 | p: 53.529 | r: 53.825
rougeL     | fm: 77.188 | p: 76.945 | r: 77.529
rougeLsum  | fm: 77.217 | p: 76.924 | r: 77.541
r1fm+r2fm = 143.619

input #94 time: 0:07:22 | total time: 11:02:07


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9991574288984811
highest_index [0]
highest [0.9991574288984811]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 1.9503685235977173 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 1.9354028701782227 for ['[CLS] bree theological teaching maybe backed past starvinglusion pigs twitcharable badic flower able [SEP]']
[Init] best rec loss: 1.8349953889846802 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 1.8156688213348389 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 1.7410764694213867 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 1.6973210573196411 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 1.6551605463027954 for ['[CLS] fire some phillip margin khz number grace discipline formula plains when secretarygrave duke hell [SEP]']
[Init] best rec loss: 1.560425043106079 for ['[CLS] end output rather overall of byron inventor earth interests novel adult heir night bryan remaining [SEP]']
[Init] best rec loss: 1.3368700742721558 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 1.3238457441329956 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 1.3197247982025146 for ['[CLS] ] damp tech trailer cut privateے hanging block complete monty pressure sister wirenne [SEP]']
[Init] best perm rec loss: 1.319675087928772 for ['[CLS] damp pressure techے monty sister private cut complete trailer hanging ] wire blocknne [SEP]']
[Init] best perm rec loss: 1.3172006607055664 for ['[CLS] ] cut private technne monty trailer block sister wire dampے hanging complete pressure [SEP]']
[Init] best perm rec loss: 1.3129985332489014 for ['[CLS] monty sister private cut tech trailer wire block hangingnne damp ]ے complete pressure [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.505 (perp=11.125, rec=0.272, cos=0.008), tot_loss_proj:2.792 [t=0.19s]
prediction: ['[CLS] hopeless bed private housing, hopeless ship become makeup becomes hopeless hopeless became became hopeless [SEP]']
[ 100/2000] tot_loss=2.545 (perp=11.846, rec=0.172, cos=0.004), tot_loss_proj:2.966 [t=0.19s]
prediction: ['[CLS] hopeless bed an cargo, hopeless ship becomes during becomes hopeless hopeless story becomesdle [SEP]']
[ 150/2000] tot_loss=2.477 (perp=11.618, rec=0.150, cos=0.003), tot_loss_proj:2.862 [t=0.19s]
prediction: ["[CLS] un mudsatmissible,'ship becomes /satfying hopeless story becomesdle [SEP]"]
[ 200/2000] tot_loss=2.543 (perp=12.117, rec=0.117, cos=0.003), tot_loss_proj:2.945 [t=0.19s]
prediction: ["[CLS]'mudsatdle, a s becomes involvementsatfying hopeless story becomesdle [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.213 (perp=10.540, rec=0.102, cos=0.003), tot_loss_proj:2.868 [t=0.19s]
prediction: ["[CLS]'mudis⁺, denis ( a )satfying hopeless story becomesdle [SEP]"]
[ 300/2000] tot_loss=2.211 (perp=10.540, rec=0.100, cos=0.002), tot_loss_proj:2.864 [t=0.19s]
prediction: ["[CLS]'mudis⁺, denis ( a )satfying hopeless story becomesdle [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.098 (perp=10.007, rec=0.094, cos=0.002), tot_loss_proj:2.597 [t=0.19s]
prediction: ["[CLS] a mud uniting, denis (')satfying hopeless story becomesdle [SEP]"]
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.912 (perp=8.651, rec=0.177, cos=0.004), tot_loss_proj:2.166 [t=0.19s]
prediction: ["[CLS] unening, denis (')satfying hopeless story becomes a muddle [SEP]"]
[ 450/2000] tot_loss=1.835 (perp=8.651, rec=0.103, cos=0.002), tot_loss_proj:2.185 [t=0.19s]
prediction: ["[CLS] unening, denis (')satfying hopeless story becomes a muddle [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.690 (perp=8.027, rec=0.083, cos=0.002), tot_loss_proj:1.963 [t=0.19s]
prediction: ["[CLS] unis, denis (')satfying story becomes a hopeless muddle [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.551 (perp=7.365, rec=0.076, cos=0.002), tot_loss_proj:1.845 [t=0.19s]
prediction: ["[CLS] unfying, denis (')satis story becomes a hopeless muddle [SEP]"]
[ 600/2000] tot_loss=1.560 (perp=7.365, rec=0.085, cos=0.002), tot_loss_proj:1.849 [t=0.19s]
prediction: ["[CLS] unfying, denis (')satis story becomes a hopeless muddle [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.518 (perp=7.148, rec=0.086, cos=0.002), tot_loss_proj:1.806 [t=0.19s]
prediction: ["[CLS] unfying,'( denis )satis story becomes a hopeless muddle [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.510 (perp=7.148, rec=0.079, cos=0.002), tot_loss_proj:1.811 [t=0.19s]
prediction: ["[CLS] unfying,'( denis )satis story becomes a hopeless muddle [SEP]"]
[ 750/2000] tot_loss=1.503 (perp=7.148, rec=0.071, cos=0.002), tot_loss_proj:1.805 [t=0.19s]
prediction: ["[CLS] unfying,'( denis )satis story becomes a hopeless muddle [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.474 (perp=6.988, rec=0.075, cos=0.002), tot_loss_proj:1.782 [t=0.19s]
prediction: ["[CLS] denisfying,'( un )satis story becomes a hopeless muddle [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.480 (perp=6.988, rec=0.081, cos=0.002), tot_loss_proj:1.780 [t=0.19s]
prediction: ["[CLS] denisfying,'( un )satis story becomes a hopeless muddle [SEP]"]
[ 900/2000] tot_loss=1.476 (perp=6.988, rec=0.077, cos=0.002), tot_loss_proj:1.778 [t=0.19s]
prediction: ["[CLS] denisfying,'( un )satis story becomes a hopeless muddle [SEP]"]
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.432 (perp=6.820, rec=0.066, cos=0.002), tot_loss_proj:1.709 [t=0.19s]
prediction: ["[CLS] denisfying,'( unsatis ) story becomes a hopeless muddle [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.399 (perp=6.618, rec=0.073, cos=0.002), tot_loss_proj:1.628 [t=0.19s]
prediction: ["[CLS] denisfying,'story ( unsatis ) becomes a hopeless muddle [SEP]"]
[1050/2000] tot_loss=1.391 (perp=6.618, rec=0.066, cos=0.002), tot_loss_proj:1.631 [t=0.19s]
prediction: ["[CLS] denisfying,'story ( unsatis ) becomes a hopeless muddle [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.248 (perp=5.877, rec=0.071, cos=0.002), tot_loss_proj:1.510 [t=0.19s]
prediction: ["[CLS] denis,'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.249 (perp=5.877, rec=0.072, cos=0.002), tot_loss_proj:1.509 [t=0.19s]
prediction: ["[CLS] denis,'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
[1200/2000] tot_loss=1.250 (perp=5.877, rec=0.073, cos=0.002), tot_loss_proj:1.500 [t=0.19s]
prediction: ["[CLS] denis,'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.180 (perp=5.533, rec=0.072, cos=0.002), tot_loss_proj:1.380 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.174 (perp=5.533, rec=0.066, cos=0.002), tot_loss_proj:1.380 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
[1350/2000] tot_loss=1.179 (perp=5.533, rec=0.071, cos=0.002), tot_loss_proj:1.379 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.171 (perp=5.533, rec=0.063, cos=0.002), tot_loss_proj:1.379 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.176 (perp=5.533, rec=0.068, cos=0.002), tot_loss_proj:1.374 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
[1500/2000] tot_loss=1.176 (perp=5.533, rec=0.068, cos=0.002), tot_loss_proj:1.369 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.172 (perp=5.533, rec=0.063, cos=0.002), tot_loss_proj:1.380 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.169 (perp=5.533, rec=0.061, cos=0.002), tot_loss_proj:1.380 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
[1650/2000] tot_loss=1.173 (perp=5.533, rec=0.065, cos=0.002), tot_loss_proj:1.381 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.177 (perp=5.533, rec=0.068, cos=0.002), tot_loss_proj:1.375 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.180 (perp=5.533, rec=0.071, cos=0.002), tot_loss_proj:1.381 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
[1800/2000] tot_loss=1.167 (perp=5.533, rec=0.059, cos=0.002), tot_loss_proj:1.380 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.169 (perp=5.533, rec=0.061, cos=0.002), tot_loss_proj:1.376 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.168 (perp=5.533, rec=0.060, cos=0.002), tot_loss_proj:1.376 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
[1950/2000] tot_loss=1.166 (perp=5.533, rec=0.057, cos=0.002), tot_loss_proj:1.376 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.173 (perp=5.533, rec=0.065, cos=0.002), tot_loss_proj:1.380 [t=0.19s]
prediction: ["[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS], denis'story ( unsatisfying ) becomes a hopeless muddle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 162.500

[Aggregate metrics]:
rouge1     | fm: 90.106 | p: 89.739 | r: 90.543
rouge2     | fm: 53.629 | p: 53.515 | r: 53.766
rougeL     | fm: 77.288 | p: 77.050 | r: 77.630
rougeLsum  | fm: 77.315 | p: 77.053 | r: 77.667
r1fm+r2fm = 143.735

input #95 time: 0:07:29 | total time: 11:09:37


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9992866562400882
highest_index [0]
highest [0.9992866562400882]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 1.794450283050537 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 1.7930576801300049 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 1.6783851385116577 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 1.6411691904067993 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best rec loss: 1.634422779083252 for ['[CLS]rg woken became jenny marx further league performance union holding winning instrumental re distance conscious [SEP]']
[Init] best rec loss: 1.4709296226501465 for ['[CLS] hand hopefullysas super profit laundry readings context places liaison mollusk talents rest feature date [SEP]']
[Init] best perm rec loss: 1.466230869293213 for ['[CLS] profitsas hand rest hopefully places laundry mollusk date liaison feature talents readings context super [SEP]']
[Init] best perm rec loss: 1.4635539054870605 for ['[CLS] readings liaison profit places contextsas rest hopefully laundry feature hand talents date super mollusk [SEP]']
[Init] best perm rec loss: 1.4631778001785278 for ['[CLS] date hopefully laundry talents super profit restsas feature mollusk hand places context liaison readings [SEP]']
[Init] best perm rec loss: 1.4482918977737427 for ['[CLS] super profit context readings laundry places datesas feature hand liaison hopefully rest talents mollusk [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.676 (perp=11.634, rec=0.320, cos=0.029), tot_loss_proj:3.838 [t=0.19s]
prediction: ['[CLS] force on something afternoon literary books behavior into into people people potential build person syndrome [SEP]']
[ 100/2000] tot_loss=2.263 (perp=10.145, rec=0.221, cos=0.013), tot_loss_proj:3.749 [t=0.19s]
prediction: ['[CLS] force on his pocket grocery for behavior into into situations people lesser build men thing [SEP]']
[ 150/2000] tot_loss=2.227 (perp=10.287, rec=0.162, cos=0.008), tot_loss_proj:2.980 [t=0.19s]
prediction: ['[CLS] force on himself into cover for situations into into situations people lesser into men would [SEP]']
[ 200/2000] tot_loss=2.266 (perp=10.629, rec=0.136, cos=0.004), tot_loss_proj:3.009 [t=0.19s]
prediction: ['[CLS] force on himself into cover for situations into into situations people lesser cover men would [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.972 (perp=9.275, rec=0.113, cos=0.004), tot_loss_proj:2.700 [t=0.19s]
prediction: ['[CLS] force on himself and cover for situations into into situations people run lesser men would [SEP]']
[ 300/2000] tot_loss=2.077 (perp=9.854, rec=0.103, cos=0.003), tot_loss_proj:3.547 [t=0.19s]
prediction: ['[CLS] force on himself and cover would situations mud into situations people run lesser men would [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.949 (perp=9.284, rec=0.090, cos=0.002), tot_loss_proj:2.905 [t=0.19s]
prediction: ['[CLS] force on himself and would cover run which into situations people make lesser men would [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.670 (perp=7.944, rec=0.080, cos=0.002), tot_loss_proj:2.485 [t=0.19s]
prediction: ['[CLS] force on himself and would cover run people into situations which make lesser men that [SEP]']
[ 450/2000] tot_loss=1.657 (perp=7.944, rec=0.067, cos=0.002), tot_loss_proj:2.485 [t=0.19s]
prediction: ['[CLS] force on himself and would cover run people into situations which make lesser men that [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.594 (perp=7.569, rec=0.079, cos=0.002), tot_loss_proj:2.413 [t=0.19s]
prediction: ['[CLS] force on himself and would cover run people into situations which lesser men that make [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.521 (perp=7.218, rec=0.076, cos=0.002), tot_loss_proj:2.204 [t=0.19s]
prediction: ['[CLS] force on himself would cover and run people into situations which lesser men that make [SEP]']
[ 600/2000] tot_loss=1.513 (perp=7.218, rec=0.068, cos=0.001), tot_loss_proj:2.199 [t=0.19s]
prediction: ['[CLS] force on himself would cover and run people into situations which lesser men that make [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.474 (perp=6.982, rec=0.076, cos=0.001), tot_loss_proj:2.106 [t=0.19s]
prediction: ['[CLS] force on himself that cover and run people into situations which lesser men would make [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.459 (perp=6.912, rec=0.075, cos=0.002), tot_loss_proj:2.216 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
[ 750/2000] tot_loss=1.444 (perp=6.912, rec=0.060, cos=0.001), tot_loss_proj:2.222 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.447 (perp=6.912, rec=0.063, cos=0.001), tot_loss_proj:2.218 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.441 (perp=6.912, rec=0.058, cos=0.001), tot_loss_proj:2.219 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
[ 900/2000] tot_loss=1.452 (perp=6.912, rec=0.068, cos=0.001), tot_loss_proj:2.222 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.453 (perp=6.912, rec=0.069, cos=0.001), tot_loss_proj:2.229 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1000/2000] tot_loss=1.442 (perp=6.912, rec=0.058, cos=0.001), tot_loss_proj:2.223 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
[1050/2000] tot_loss=1.451 (perp=6.912, rec=0.067, cos=0.001), tot_loss_proj:2.227 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1100/2000] tot_loss=1.457 (perp=6.912, rec=0.073, cos=0.001), tot_loss_proj:2.230 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1150/2000] tot_loss=1.451 (perp=6.912, rec=0.067, cos=0.001), tot_loss_proj:2.233 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
[1200/2000] tot_loss=1.448 (perp=6.912, rec=0.064, cos=0.001), tot_loss_proj:2.233 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1250/2000] tot_loss=1.454 (perp=6.912, rec=0.070, cos=0.001), tot_loss_proj:2.234 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1300/2000] tot_loss=1.444 (perp=6.912, rec=0.061, cos=0.001), tot_loss_proj:2.236 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
[1350/2000] tot_loss=1.444 (perp=6.912, rec=0.060, cos=0.001), tot_loss_proj:2.247 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1400/2000] tot_loss=1.450 (perp=6.912, rec=0.066, cos=0.001), tot_loss_proj:2.239 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1450/2000] tot_loss=1.452 (perp=6.912, rec=0.069, cos=0.001), tot_loss_proj:2.243 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
[1500/2000] tot_loss=1.441 (perp=6.912, rec=0.057, cos=0.001), tot_loss_proj:2.236 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1550/2000] tot_loss=1.449 (perp=6.912, rec=0.065, cos=0.001), tot_loss_proj:2.244 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1600/2000] tot_loss=1.450 (perp=6.912, rec=0.067, cos=0.001), tot_loss_proj:2.246 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
[1650/2000] tot_loss=1.445 (perp=6.912, rec=0.061, cos=0.001), tot_loss_proj:2.245 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1700/2000] tot_loss=1.443 (perp=6.912, rec=0.059, cos=0.001), tot_loss_proj:2.246 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1750/2000] tot_loss=1.446 (perp=6.912, rec=0.062, cos=0.001), tot_loss_proj:2.247 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
[1800/2000] tot_loss=1.449 (perp=6.912, rec=0.065, cos=0.001), tot_loss_proj:2.245 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1850/2000] tot_loss=1.445 (perp=6.912, rec=0.061, cos=0.001), tot_loss_proj:2.248 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[1900/2000] tot_loss=1.446 (perp=6.912, rec=0.062, cos=0.001), tot_loss_proj:2.246 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
[1950/2000] tot_loss=1.446 (perp=6.912, rec=0.062, cos=0.001), tot_loss_proj:2.252 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Attempt swap
[2000/2000] tot_loss=1.443 (perp=6.912, rec=0.059, cos=0.001), tot_loss_proj:2.248 [t=0.19s]
prediction: ['[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] force himself on that cover and run people into situations for lesser men would make [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 58.824 | p: 58.824 | r: 58.824
rougeLsum  | fm: 58.824 | p: 58.824 | r: 58.824
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 90.191 | p: 89.824 | r: 90.572
rouge2     | fm: 53.501 | p: 53.379 | r: 53.634
rougeL     | fm: 77.182 | p: 76.906 | r: 77.500
rougeLsum  | fm: 77.102 | p: 76.853 | r: 77.439
r1fm+r2fm = 143.692

input #96 time: 0:07:28 | total time: 11:17:06


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9991660915875735
highest_index [0]
highest [0.9991660915875735]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 1.292439579963684 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 1.0615618228912354 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 1.0516561269760132 for ['[CLS] victoriaten test pass 2016 which [SEP]']
[Init] best perm rec loss: 1.0462650060653687 for ['[CLS] pass testten which 2016 victoria [SEP]']
[Init] best perm rec loss: 1.0451700687408447 for ['[CLS] pass test victoriaten 2016 which [SEP]']
[Init] best perm rec loss: 1.0422724485397339 for ['[CLS] victoria test 2016 pass whichten [SEP]']
[Init] best perm rec loss: 1.0385247468948364 for ['[CLS] pass test which victoria 2016ten [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.460 (perp=10.858, rec=0.274, cos=0.014), tot_loss_proj:3.758 [t=0.18s]
prediction: ['[CLS]forgetfor characters characters characters [SEP]']
[ 100/2000] tot_loss=1.888 (perp=8.563, rec=0.171, cos=0.004), tot_loss_proj:2.163 [t=0.19s]
prediction: ['[CLS]forgetgettable characters and [SEP]']
[ 150/2000] tot_loss=1.828 (perp=8.563, rec=0.111, cos=0.005), tot_loss_proj:2.158 [t=0.19s]
prediction: ['[CLS]forgetgettable characters and [SEP]']
[ 200/2000] tot_loss=2.013 (perp=9.593, rec=0.091, cos=0.003), tot_loss_proj:2.596 [t=0.19s]
prediction: ['[CLS]fortablegettable characters and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.686 (perp=7.870, rec=0.108, cos=0.004), tot_loss_proj:2.029 [t=0.19s]
prediction: ['[CLS]tableforgettable characters and [SEP]']
[ 300/2000] tot_loss=1.662 (perp=7.870, rec=0.086, cos=0.002), tot_loss_proj:2.040 [t=0.19s]
prediction: ['[CLS]tableforgettable characters and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.670 (perp=7.870, rec=0.095, cos=0.002), tot_loss_proj:2.029 [t=0.19s]
prediction: ['[CLS]tableforgettable characters and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.184 (perp=5.520, rec=0.078, cos=0.002), tot_loss_proj:1.290 [t=0.19s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 450/2000] tot_loss=1.183 (perp=5.520, rec=0.077, cos=0.002), tot_loss_proj:1.289 [t=0.19s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.183 (perp=5.520, rec=0.077, cos=0.002), tot_loss_proj:1.293 [t=0.19s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.180 (perp=5.520, rec=0.075, cos=0.002), tot_loss_proj:1.301 [t=0.19s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 600/2000] tot_loss=1.171 (perp=5.520, rec=0.066, cos=0.002), tot_loss_proj:1.293 [t=0.19s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.177 (perp=5.514, rec=0.073, cos=0.002), tot_loss_proj:1.376 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.165 (perp=5.514, rec=0.060, cos=0.002), tot_loss_proj:1.377 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 750/2000] tot_loss=1.170 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.374 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.169 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.384 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.161 (perp=5.514, rec=0.056, cos=0.002), tot_loss_proj:1.373 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 900/2000] tot_loss=1.171 (perp=5.514, rec=0.066, cos=0.002), tot_loss_proj:1.375 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.380 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.178 (perp=5.514, rec=0.073, cos=0.002), tot_loss_proj:1.369 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1050/2000] tot_loss=1.168 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.371 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.176 (perp=5.514, rec=0.072, cos=0.002), tot_loss_proj:1.372 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.183 (perp=5.514, rec=0.079, cos=0.002), tot_loss_proj:1.374 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1200/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.378 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.175 (perp=5.514, rec=0.071, cos=0.002), tot_loss_proj:1.372 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.165 (perp=5.514, rec=0.061, cos=0.002), tot_loss_proj:1.372 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1350/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.373 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.172 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.366 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.166 (perp=5.514, rec=0.061, cos=0.002), tot_loss_proj:1.374 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1500/2000] tot_loss=1.168 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.378 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.163 (perp=5.514, rec=0.058, cos=0.002), tot_loss_proj:1.378 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.165 (perp=5.514, rec=0.061, cos=0.002), tot_loss_proj:1.377 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1650/2000] tot_loss=1.166 (perp=5.514, rec=0.062, cos=0.002), tot_loss_proj:1.370 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.167 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.374 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.165 (perp=5.514, rec=0.061, cos=0.002), tot_loss_proj:1.372 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1800/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.371 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.155 (perp=5.514, rec=0.050, cos=0.002), tot_loss_proj:1.376 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.169 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.370 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1950/2000] tot_loss=1.161 (perp=5.514, rec=0.057, cos=0.002), tot_loss_proj:1.372 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.378 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] unforgettable and characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 90.243 | p: 89.884 | r: 90.715
rouge2     | fm: 53.287 | p: 53.117 | r: 53.428
rougeL     | fm: 77.245 | p: 77.007 | r: 77.535
rougeLsum  | fm: 77.172 | p: 76.916 | r: 77.477
r1fm+r2fm = 143.531

input #97 time: 0:07:20 | total time: 11:24:26


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9991916976323436
highest_index [0]
highest [0.9991916976323436]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 1.1314566135406494 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best rec loss: 1.1208252906799316 for ['[CLS] nature " open victims [SEP]']
[Init] best perm rec loss: 1.1160643100738525 for ['[CLS] " victims nature open [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.883 (perp=12.458, rec=0.362, cos=0.029), tot_loss_proj:3.962 [t=0.18s]
prediction: ['[CLS] representative chris boats drains [SEP]']
[ 100/2000] tot_loss=2.006 (perp=8.703, rec=0.248, cos=0.017), tot_loss_proj:2.567 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
[ 150/2000] tot_loss=2.411 (perp=11.121, rec=0.174, cos=0.012), tot_loss_proj:3.690 [t=0.19s]
prediction: ['[CLS]llingfillingful [SEP]']
[ 200/2000] tot_loss=2.374 (perp=11.121, rec=0.141, cos=0.009), tot_loss_proj:3.682 [t=0.19s]
prediction: ['[CLS]llingfillingful [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.109 (perp=9.749, rec=0.148, cos=0.011), tot_loss_proj:3.120 [t=0.19s]
prediction: ['[CLS]llingfulfilling [SEP]']
[ 300/2000] tot_loss=2.093 (perp=9.749, rec=0.136, cos=0.008), tot_loss_proj:3.135 [t=0.19s]
prediction: ['[CLS]llingfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.081 (perp=9.749, rec=0.123, cos=0.008), tot_loss_proj:3.137 [t=0.19s]
prediction: ['[CLS]llingfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.086 (perp=9.749, rec=0.129, cos=0.007), tot_loss_proj:3.132 [t=0.19s]
prediction: ['[CLS]llingfulfilling [SEP]']
[ 450/2000] tot_loss=2.076 (perp=9.749, rec=0.119, cos=0.007), tot_loss_proj:3.123 [t=0.19s]
prediction: ['[CLS]llingfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.070 (perp=9.749, rec=0.113, cos=0.007), tot_loss_proj:3.127 [t=0.19s]
prediction: ['[CLS]llingfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.079 (perp=9.749, rec=0.123, cos=0.007), tot_loss_proj:3.118 [t=0.19s]
prediction: ['[CLS]llingfulfilling [SEP]']
[ 600/2000] tot_loss=2.078 (perp=9.749, rec=0.121, cos=0.007), tot_loss_proj:3.120 [t=0.19s]
prediction: ['[CLS]llingfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.077 (perp=9.749, rec=0.120, cos=0.007), tot_loss_proj:3.105 [t=0.19s]
prediction: ['[CLS]llingfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.071 (perp=9.749, rec=0.114, cos=0.007), tot_loss_proj:3.104 [t=0.19s]
prediction: ['[CLS]llingfulfilling [SEP]']
[ 750/2000] tot_loss=2.938 (perp=14.045, rec=0.122, cos=0.007), tot_loss_proj:3.963 [t=0.19s]
prediction: ['[CLS]llingfulfiful [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.883 (perp=8.703, rec=0.134, cos=0.008), tot_loss_proj:2.499 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.869 (perp=8.703, rec=0.121, cos=0.008), tot_loss_proj:2.494 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
[ 900/2000] tot_loss=1.869 (perp=8.703, rec=0.121, cos=0.007), tot_loss_proj:2.495 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.870 (perp=8.703, rec=0.122, cos=0.007), tot_loss_proj:2.496 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1000/2000] tot_loss=1.875 (perp=8.703, rec=0.127, cos=0.007), tot_loss_proj:2.496 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
[1050/2000] tot_loss=1.878 (perp=8.703, rec=0.130, cos=0.007), tot_loss_proj:2.495 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1100/2000] tot_loss=1.867 (perp=8.703, rec=0.119, cos=0.007), tot_loss_proj:2.490 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1150/2000] tot_loss=1.870 (perp=8.703, rec=0.122, cos=0.007), tot_loss_proj:2.490 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
[1200/2000] tot_loss=1.879 (perp=8.703, rec=0.131, cos=0.007), tot_loss_proj:2.492 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1250/2000] tot_loss=1.864 (perp=8.703, rec=0.116, cos=0.007), tot_loss_proj:2.502 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1300/2000] tot_loss=1.873 (perp=8.703, rec=0.126, cos=0.007), tot_loss_proj:2.495 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
[1350/2000] tot_loss=1.872 (perp=8.703, rec=0.124, cos=0.007), tot_loss_proj:2.494 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1400/2000] tot_loss=1.866 (perp=8.703, rec=0.118, cos=0.007), tot_loss_proj:2.490 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1450/2000] tot_loss=1.859 (perp=8.703, rec=0.111, cos=0.007), tot_loss_proj:2.498 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
[1500/2000] tot_loss=1.864 (perp=8.703, rec=0.117, cos=0.007), tot_loss_proj:2.492 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1550/2000] tot_loss=1.873 (perp=8.703, rec=0.125, cos=0.007), tot_loss_proj:2.499 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1600/2000] tot_loss=1.870 (perp=8.703, rec=0.122, cos=0.007), tot_loss_proj:2.490 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
[1650/2000] tot_loss=1.863 (perp=8.703, rec=0.116, cos=0.007), tot_loss_proj:2.499 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1700/2000] tot_loss=1.855 (perp=8.703, rec=0.107, cos=0.007), tot_loss_proj:2.487 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1750/2000] tot_loss=1.871 (perp=8.703, rec=0.123, cos=0.007), tot_loss_proj:2.504 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
[1800/2000] tot_loss=1.868 (perp=8.703, rec=0.120, cos=0.007), tot_loss_proj:2.492 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1850/2000] tot_loss=1.865 (perp=8.703, rec=0.118, cos=0.007), tot_loss_proj:2.499 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[1900/2000] tot_loss=1.875 (perp=8.703, rec=0.127, cos=0.007), tot_loss_proj:2.491 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
[1950/2000] tot_loss=1.871 (perp=8.703, rec=0.124, cos=0.007), tot_loss_proj:2.493 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Attempt swap
[2000/2000] tot_loss=1.866 (perp=8.703, rec=0.118, cos=0.007), tot_loss_proj:2.489 [t=0.19s]
prediction: ['[CLS]fulfillingful [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS]fulfillingful [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 66.667 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 66.667

[Aggregate metrics]:
rouge1     | fm: 90.100 | p: 89.730 | r: 90.519
rouge2     | fm: 52.575 | p: 52.441 | r: 52.756
rougeL     | fm: 77.040 | p: 76.812 | r: 77.358
rougeLsum  | fm: 77.127 | p: 76.845 | r: 77.402
r1fm+r2fm = 142.675

input #98 time: 0:07:19 | total time: 11:31:46


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.9993095816453154
highest_index [0]
highest [0.9993095816453154]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 1.5378683805465698 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 1.4138236045837402 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 1.3704537153244019 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 1.3552578687667847 for ['[CLS] football trust o guide every into integral? maybe200nington just layne what alaska priory incidentffled gymnastics manufactured lines kim survived told particularlygui discipline lonely # level pointsuna loves leaving it providence [SEP]']
[Init] best rec loss: 1.3264182806015015 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 1.2738163471221924 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best rec loss: 1.2734564542770386 for ["[CLS]jevic authority could victory gregory u yearquin choshing though horton else final obama authored speeding'recreation as disgust grace heroin his door pronunciationlu heel japanese nehru lower distinguished mere buenos base whether [SEP]"]
[Init] best perm rec loss: 1.2730098962783813 for ["[CLS] grace whether mere u nehrushing could recreation heroin base year distinguished victory pronunciation gregory authority disgust final as lower speeding hortonquin his'japanese though heel obamalu else buenosjevic authored cho door [SEP]"]
[Init] best perm rec loss: 1.27029550075531 for ["[CLS] final base as victory though disgust door gregory obama distinguished mere u yearquin'authored heel japanese could horton lower else nehru authority cho heroin pronunciation buenos grace whetherlujevicshing his speeding recreation [SEP]"]
[Init] best perm rec loss: 1.2686342000961304 for ["[CLS] victory speeding'year obama u whether mere heel japanesequin heroin his door buenos could else distinguished final authority authored grace nehru recreation horton lower disgust gregory pronunciation thoughlushing as chojevic base [SEP]"]
[Init] best perm rec loss: 1.2669504880905151 for ["[CLS] lower disgust his buenos as speeding year authored obama base mere distinguished grace victory whether though final heelshing heroin doorjevic nehru gregory u japanese'authority couldquin elselu pronunciation recreation cho horton [SEP]"]
[Init] best perm rec loss: 1.261819839477539 for ["[CLS] year buenos japanese though'u couldquin distinguished obama else door heel nehru authority final speeding cho whether victory as base pronunciation disgust heroinshing gregory grace hortonjevic lower recreation authoredlu his mere [SEP]"]
[Init] best perm rec loss: 1.257513165473938 for ["[CLS] grace distinguished could horton base his heroin though final victory else lower heelquin gregory obama door authority u authored'mere as speeding buenosjevic year cho whetherlu japanese recreation nehru disgust pronunciationshing [SEP]"]
[Init] best perm rec loss: 1.2564736604690552 for ["[CLS] base lower buenos gregory authority year pronunciation recreationquin nehru though disgust u speeding japanese cho victory authored grace door as could distinguished heroinshinglujevic final heel horton obama whether'his mere else [SEP]"]
[Init] best perm rec loss: 1.2494480609893799 for ["[CLS] victory u distinguished disgust gregory heroin authoredshing buenos grace else year lower heel mere finallu pronunciation'cho recreation though whetherquin door could base japanese obama his as nehrujevic speeding authority horton [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.633 (perp=11.672, rec=0.288, cos=0.011), tot_loss_proj:3.284 [t=0.19s]
prediction: ["[CLS] momentum'honor instead bathed ` none stolen film nothing muttered excitement guysgingly but uefa jamssing his film crewssing several smith obviouslying ran so a records di briggs'the pound ecosystems [SEP]"]
[ 100/2000] tot_loss=2.403 (perp=10.775, rec=0.238, cos=0.010), tot_loss_proj:3.496 [t=0.19s]
prediction: ['[CLS] walked ` outtate celebration ` were terrible film horrible 6 fun horriblegingly but fun dissing the film crewssing so quinn giveing walked " horrible any di giving\'but have expanded [SEP]']
[ 150/2000] tot_loss=2.249 (perp=10.183, rec=0.200, cos=0.013), tot_loss_proj:2.774 [t=0.19s]
prediction: ["[CLS] walked ` out latham ticket ` were ` film terrible'fun horriblevery but fun dissing the film! fun so quinn givinging walked so crazy ticket di briggs'but ticket that [SEP]"]
[ 200/2000] tot_loss=2.182 (perp=10.042, rec=0.166, cos=0.008), tot_loss_proj:2.661 [t=0.19s]
prediction: ['[CLS] walked ` outtate ticket ` could ` film terrible\'fun horrible somehow but fun dissing the film thought fun had quinn death " walked so crazy ticket cost mind\'but had that [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.000 (perp=9.368, rec=0.123, cos=0.003), tot_loss_proj:2.445 [t=0.19s]
prediction: ['[CLS] walked ` outtate ticket ` didn ` film terrible\'fun horrible they had fun dissing the film so fun had should death " walked something\'ticket cost mind\'but had that [SEP]']
[ 300/2000] tot_loss=1.966 (perp=9.265, rec=0.110, cos=0.003), tot_loss_proj:2.450 [t=0.19s]
prediction: ["[CLS] walked ` out everything ticket muttering didn ` film terrible'fun horrible they had fun dissing the film so fun had should they'walked something'ticket cost mind'but had that [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.885 (perp=8.854, rec=0.111, cos=0.003), tot_loss_proj:2.374 [t=0.19s]
prediction: ["[CLS] walked ` out everything ticket muttering didn ` ` terrible'fun'they had fun dissing the film so fun had should they they walked, horrible ticket cost mind'but had that [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.907 (perp=9.035, rec=0.097, cos=0.003), tot_loss_proj:2.484 [t=0.19s]
prediction: ["[CLS] walked ` out everything muttering muttering t ` ` terrible'fun ` they had fun dissing the film so they terrible should fun they walked, horrible ticket cost mind'but had that [SEP]"]
[ 450/2000] tot_loss=1.836 (perp=8.691, rec=0.094, cos=0.003), tot_loss_proj:2.373 [t=0.19s]
prediction: ["[CLS] walked muttering out everything muttering like t ` ` terrible'fun ` they had fun dissing the film so they terrible should fun they walked, horrible ticket cost mind'but had that [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.828 (perp=8.673, rec=0.091, cos=0.002), tot_loss_proj:2.338 [t=0.19s]
prediction: ["[CLS] walked muttering out everything muttering like t ` ` terrible'fun ` they had fun dissing the film so they terrible should fun they walked, horrible ticket cost but'mind ticket that [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.743 (perp=8.245, rec=0.092, cos=0.002), tot_loss_proj:2.294 [t=0.19s]
prediction: ["[CLS] walked muttering out everything words like t ` ` terrible'fun ` they had fun dissing the film so they terrible should fun they walked,'ticket cost but horrible mind'that [SEP]"]
[ 600/2000] tot_loss=1.775 (perp=8.426, rec=0.087, cos=0.002), tot_loss_proj:2.239 [t=0.19s]
prediction: ["[CLS] walked muttering out'words like t `'terrible'much ` they had fun dissing the film so they terrible should fun they walked,'ticket cost but horrible mind ticket that [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.786 (perp=8.515, rec=0.081, cos=0.002), tot_loss_proj:2.324 [t=0.19s]
prediction: ["[CLS] walked muttering out'words like terrible `'t'much ` they had fun dissing the film so they terrible should fun does walked,'ticket cost but horrible mind n that [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.737 (perp=8.283, rec=0.079, cos=0.002), tot_loss_proj:2.244 [t=0.19s]
prediction: ["[CLS] walked muttering out'words like terrible `'t'much ` they had fun dissing the film so they walked should fun did ','ticket cost but horrible mind n that [SEP]"]
[ 750/2000] tot_loss=1.747 (perp=8.283, rec=0.089, cos=0.002), tot_loss_proj:2.248 [t=0.19s]
prediction: ["[CLS] walked muttering out'words like terrible `'t'much ` they had fun dissing the film so they walked should fun did ','ticket cost but horrible mind n that [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.742 (perp=8.266, rec=0.087, cos=0.002), tot_loss_proj:2.231 [t=0.19s]
prediction: ["[CLS] walked out ` words like terrible `'t'much ` they had fun dissing the film so they walked should fun did'muttering,'ticket cost but horrible mind n that [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.639 (perp=7.786, rec=0.080, cos=0.002), tot_loss_proj:2.174 [t=0.19s]
prediction: ["[CLS] walked out terrible words like ` `'t'much ` they had fun dissing the film so they walked should fun did'muttering,'ticket cost but horrible mind n that [SEP]"]
[ 900/2000] tot_loss=1.625 (perp=7.741, rec=0.075, cos=0.002), tot_loss_proj:2.184 [t=0.19s]
prediction: ["[CLS] walked out terrible words like'`'t n much ` they had fun dissing the film so they walked should fun did'muttering,'ticket cost but horrible mind n that [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.592 (perp=7.538, rec=0.083, cos=0.002), tot_loss_proj:2.162 [t=0.19s]
prediction: ["[CLS] walked out terrible words like'` `'t n much they had fun dissing the film so they walked should fun did'muttering,'ticket cost but horrible mind n that [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.554 (perp=7.382, rec=0.076, cos=0.002), tot_loss_proj:2.078 [t=0.19s]
prediction: ["[CLS] walked out terrible words like'` `'t n much they had fun dissing the film so they walked should fun a'muttering,'ticket cost but horrible mind did that [SEP]"]
[1050/2000] tot_loss=1.546 (perp=7.354, rec=0.074, cos=0.002), tot_loss_proj:2.075 [t=0.19s]
prediction: ["[CLS] walked out terrible words like'` `'t n much they had fun dissing the film so they walked should fun n'muttering,'ticket cost but horrible mind did that [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.528 (perp=7.227, rec=0.081, cos=0.002), tot_loss_proj:2.049 [t=0.19s]
prediction: ["[CLS] walked out terrible words like'` `'t n they had much fun dissing the film so they walked should fun n'muttering,'ticket cost but horrible mind did that [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.526 (perp=7.227, rec=0.080, cos=0.002), tot_loss_proj:2.048 [t=0.19s]
prediction: ["[CLS] walked out terrible words like'` `'t n they had much fun dissing the film so they walked should fun n'muttering,'ticket cost but horrible mind did that [SEP]"]
[1200/2000] tot_loss=1.528 (perp=7.227, rec=0.081, cos=0.001), tot_loss_proj:2.048 [t=0.19s]
prediction: ["[CLS] walked out terrible words like'` `'t n they had much fun dissing the film so they walked should fun n'muttering,'ticket cost but horrible mind did that [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.498 (perp=7.068, rec=0.083, cos=0.002), tot_loss_proj:2.025 [t=0.19s]
prediction: ["[CLS] walked out terrible words like'` `'t n they had much fun dissing the film so they walked should fun n'muttering,'that ticket cost but horrible mind did [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.449 (perp=6.838, rec=0.080, cos=0.002), tot_loss_proj:1.969 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun n'muttering,'that ticket cost but horrible mind did [SEP]"]
[1350/2000] tot_loss=1.448 (perp=6.838, rec=0.079, cos=0.002), tot_loss_proj:1.968 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun n'muttering,'that ticket cost but horrible mind did [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.437 (perp=6.838, rec=0.068, cos=0.001), tot_loss_proj:1.967 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun n'muttering,'that ticket cost but horrible mind did [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.435 (perp=6.818, rec=0.070, cos=0.002), tot_loss_proj:1.971 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun'n muttering,'that ticket cost but horrible mind did [SEP]"]
[1500/2000] tot_loss=1.442 (perp=6.818, rec=0.077, cos=0.002), tot_loss_proj:1.970 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun'n muttering,'that ticket cost but horrible mind did [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.434 (perp=6.818, rec=0.068, cos=0.002), tot_loss_proj:1.973 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun'n muttering,'that ticket cost but horrible mind did [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.445 (perp=6.818, rec=0.080, cos=0.001), tot_loss_proj:1.971 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun'n muttering,'that ticket cost but horrible mind did [SEP]"]
[1650/2000] tot_loss=1.446 (perp=6.818, rec=0.081, cos=0.001), tot_loss_proj:1.968 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun'n muttering,'that ticket cost but horrible mind did [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.453 (perp=6.868, rec=0.078, cos=0.002), tot_loss_proj:1.991 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun'n muttering,'that ticket cost but terrible mind did [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.448 (perp=6.868, rec=0.073, cos=0.002), tot_loss_proj:1.993 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun'n muttering,'that ticket cost but terrible mind did [SEP]"]
[1800/2000] tot_loss=1.457 (perp=6.868, rec=0.082, cos=0.001), tot_loss_proj:1.988 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should fun'n muttering,'that ticket cost but terrible mind did [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=1.425 (perp=6.762, rec=0.071, cos=0.002), tot_loss_proj:1.966 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should'n muttering,'that ticket cost fun but terrible mind did [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.427 (perp=6.762, rec=0.073, cos=0.002), tot_loss_proj:1.969 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should'n muttering,'that ticket cost fun but terrible mind did [SEP]"]
[1950/2000] tot_loss=1.428 (perp=6.762, rec=0.074, cos=0.002), tot_loss_proj:1.967 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should'n muttering,'that ticket cost fun but terrible mind did [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.427 (perp=6.762, rec=0.073, cos=0.001), tot_loss_proj:1.972 [t=0.19s]
prediction: ["[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should'n muttering,'that ticket cost fun but terrible mind did [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] walked out terrible words like n ` `'t'they had much fun dissing the film so they walked should'n muttering,'that ticket cost fun but terrible mind did [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 73.333 | r: 84.615
rouge2     | fm: 29.630 | p: 27.586 | r: 32.000
rougeL     | fm: 53.571 | p: 50.000 | r: 57.692
rougeLsum  | fm: 53.571 | p: 50.000 | r: 57.692
r1fm+r2fm = 108.201

[Aggregate metrics]:
rouge1     | fm: 89.859 | p: 89.492 | r: 90.323
rouge2     | fm: 52.580 | p: 52.400 | r: 52.719
rougeL     | fm: 76.803 | p: 76.478 | r: 77.152
rougeLsum  | fm: 76.886 | p: 76.625 | r: 77.220
r1fm+r2fm = 142.439

input #99 time: 0:07:27 | total time: 11:39:14


Average Cosine Similarity: 0.9992812683158312
Done with all.
